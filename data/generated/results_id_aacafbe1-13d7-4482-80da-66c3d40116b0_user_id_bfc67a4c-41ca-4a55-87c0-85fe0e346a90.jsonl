{"question":"How do caffeine and alcohol differ in their effects on the body's fluid regulation?","answer":"Caffeine and alcohol have different effects on the body's fluid regulation mechanisms. Caffeine works by preventing the breakdown of cAMP, which leads to increased production of adrenaline and noradrenaline, putting the body in fight-or-flight mode. In contrast, alcohol inhibits the production of vasopressin, a hormone that helps conserve body fluids. Without vasopressin, urination increases and the body begins excreting alcohol within 20-25 minutes of consumption.","context":["It’s fair to say that a lot of us are obsessed with coffee. Its rich, aromatic scent and diverse flavours delight millions across the globe every single day.\nFor some people, it’s a social badge of honour. They meet their friends over a hot cup of coffee, scour laneways and city streets for the best brews, and pride themselves on their fair-trade, single-source coffee beans. Deciding whether to buy a cafetière, espresso machine or coffee pot is a very serious decision, indeed.\nWe hail caffeine as a remedy for fatigue. It improves our concentration, focus and memory and gives us some extra get-up-and-go to help tackle the day ahead. It’s the same reason that people love tea, chocolate and energy drinks.\nBut why does caffeine cause this energy rush? And why, if you have too much of it, can you start feeling jittery, on-edge and agitated?\nTo find out, let’s look to the science.\nHow Caffeine affects the Body\nCaffeine works in our bodies by preventing the breakdown of a molecule called cAMP. One of cAMP’s tasks is to tell the body to make more adrenaline and noradrenaline.\nWhen cAMP doesn’t get broken down, the body produces more of these chemicals than it usually would. This kicks your body into fight-or-flight mode and causes your heart to beat faster and harder, pushing oxygen through your brain and body.\nThis helps you to feel energised and seize the day.\nHow Caffeine Affects the Brain\nA lot of the benefits we get from caffeine also come from the effect it has on our brain. As each day progresses, a chemical called adenosine starts to build up in our brains. It binds to specific receptors and kicks off a chain reaction that primes the body for sleep, making us feel tired.\nLike most drugs, caffeine uses the bloodstream to hitch a ride into the brain. Once it’s there, it starts working as a gatekeeper at the adenosine receptors. It stops adenosine from binding to the receptors, which means the normal chain reaction that causes us to feel drowsy and drained never gets started. This helps us to stay alert and focussed.\nDoes it affect us all the same way?\nUnfortunately, if you drink too much coffee, you can end up feeling jittery, tense and even nauseous as the body’s fight-or-flight response goes into overdrive. Although a lot of people will experience these sensations if they drink more coffee than they’re used to, some people are particularly sensitive to caffeine’s effects because of their genes.\nThe ADORA2A gene controls how your brain copes with the caffeine that floods into it after you drink a cappuccino or a coke. Some people have a variation of this gene that makes them feel jittery more easily than those with a different version of the gene. Caffeine can make their reasoning, problem solving and reaction times worse and might not be such a bright idea if they’re trying to get through some difficult work.\nFortunately, it seems like most people can adjust to increased levels of caffeine. So, if you’ve developed a taste for espresso or flat whites, you don’t have to go without. Your body will eventually acclimatise to the new levels of caffeine and you’ll probably start feeling less jittery.\nInterestingly, the ADORA2A gene seems to be a double-edged sword. People who have been spared from the genetic curse of feeling on-edge when they drink coffee are actually more likely to have problems sleeping if they drink it too late in the day. They wake up more easily during the night, have worse quality sleep and sometimes struggle to fall asleep in the first place.\nWhat else comes into play?\nAlthough our genes play an important role in determining how caffeine affects us, there are many other factors that also play a part. A person’s age, diet, medications and even smoking status can influence how quickly they metabolise caffeine.\nFor some people, it’s also an interaction between their genes and their environment. If you have a particular version of the CYP1A2 gene, then you can speed up how quickly you metabolise of caffeine by eating certain foods.","How Long Does Alcohol Stay In Your System?\nHow long does alcohol stay in your system is an important question. It can mean going to jail or keeping a job. Drug testing takes place in the workplace and on the road. A small amount of alcohol can impair judgment and the ability to operate a motor vehicle safely.\n- The legal limit for driving is .08% BAC or above.\n- Receiving a DWI conviction could mean going to prison for years.\nDetermining blood alcohol content (BAC) depends primarily on the amount of alcohol consumed over the time spent drinking.\nAlcohol metabolizes at a rate between .012% to .015% per hour.\nBlood Alcohol Content\nBAC is the unit of measurement of how much alcohol is in someone’s body (percentage in the blood) at any given moment. BAC is still considered the primary standard for alcohol testing in some labs.\n- BAC is the grams of ethanol in 100 milliliters of blood.\nGenerally, beer is 4.5% – 5% alcohol for most tests. Wine uses a 5 oz glass, and hard liquor (shots & mixed drinks) uses 1.5 oz at 80 proof.\n- one beer (12 ounces)\n- one glass of wine (5 ounces)\n- 1.5 ounces of liquor (shot)\nUse the quick calculator to determine the approximate BAC when a person quits drinking. It also calculates how long it might take for the BAC to go to zero.\nHow to use\n- Using the standard drink list above, count the drinks the person had during a continuous drinking episode. Enter it in the top line reading “Number of Drinks Consumed.”\n- Determine how many hours were spent drinking, and round up to the nearest half-hour. Enter it in the second line reading the “Number of hours Spent Drinking.\nQuick BAC Calculator\nThese results are calculations based on the average rate of human alcohol metabolization. It will be affected by these variables.\nThe reason gender is a crucial factor is men have a higher percentage (.58) of water weight than women (.49) by almost 10%. That means a woman’s BAC will be slightly higher.\nAlso, women have a smaller amount of vasopressin or ADH than men.\nAbsorption rate factors involving gender indicate that a man weighing 140 pounds who consumes two drinks in one hour will have a lower blood alcohol level than a 140-pound woman who drinks the same amount of alcohol in the same amount of time. It is because men possess higher levels of the enzyme hydrogenase in their stomachs.\nHow much someone weighs is a factor because BAC is a function of grams of ethanol in 100 milliliters of blood. So, the more someone’s weight, the higher the blood volume in their body.\nOther aspects affecting BAC include age, tolerance, and physical fitness. These variabilities could produce a small fraction of error in the final answer. Here is how they might affect the outcome of our formulation.\nYounger people have a higher proportion of body water as a fraction of their total weight, and older people have less. So, a younger person may have a lower rate than an older person.\nIndividuals who may be overweight may have a smaller proportion of their body weight than water. Lean people tend to have a more significant fraction of their body weight as water. Therefore, overweight people may have a lower BAC than our formula indicates.\nA regular drinker will have a higher ability to metabolize alcohol than someone who does not drink as often.\nMost alcohol testing labs now test the body’s chemicals to process alcohol, namely EtG.\nThis test detects the presence of EtG in the urine. EtG is a direct metabolite the body uses to process alcohol. Its presence detects alcohol consumption in the past 80 hours.\nThe time factor is dependent on many variables not in this calculation. Therefore, it is merely a rough estimate and not a guarantee of passing a test.\nThe liver metabolizes most alcohol, with the remainder excreting through urine, sweat, and breath. The human body metabolizes alcohol as soon as the person begins to drink. So, in theory, if you drank at a rate of approximately .015% BAC per hour, your BAC would stay very low.\nOnce alcohol reaches the stomach, hydrogenase starts breaking down alcohol molecules.\nAdditionally, alcohol inhibits the production of vasopressin, a hormone that helps conserve body fluids. Without vasopressin to prevent fluid loss, urination increases, and the body usually begins excreting alcohol within 20 to 25 minutes of being consumed.\n- When five percent of absorbed alcohol reaches the kidneys, the body excretes alcohol through urination.\n- Metabolism varies and runs primarily on liver metabolism. Still, it is also related to age, gender, weight, presence of food in the stomach, drinks per hour, percentage of alcohol in the glass, and if the person takes other drugs or medicines."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"sensitive"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:e0e23d48-2fe8-41fe-9800-b1ea668bffbd>","<urn:uuid:0100cb65-7606-4375-9590-77ccd4974eb5>"],"error":null}
{"question":"What are the historical patterns of major earthquakes in the Manila Trench versus the Cascadia Subduction Zone? I'm interested in understanding their respective seismic histories.","answer":"The Manila Trench has no recorded mega earthquakes (magnitude 8 or above) since written records began in 1560. According to analysis, it has a recurrence interval of 205 years for magnitude 8.5 earthquakes and 667 years for magnitude 9.0 earthquakes. In contrast, the Cascadia Subduction Zone has experienced 40 major earthquakes over the last 10,000 years - 20 magnitude 9+ earthquakes along its entire length and 20 magnitude 8.5+ earthquakes in its southern 300 miles. 75% of these earthquakes occurred within 310 years of each other, with the most recent one in 1700.","context":["Mar 17, 2011, 6 days after the mega earthquake hitting North-east Japan, Dr.Tso-Ren Wu, Associate Professor at the Graduate Institute of Hydrological and Oceanic Sciences of the National Central University of Taiwan, has published an article titled “Research and Reflection on Japan’s Mega Tsunami 2011”.\nIt explained that for such a massive tsunami to take place in Fukushima, it is because this tsunami has all the necessary conditions that enable a mega tsunami:\n1. It requires an undersea megathrust earthquake. This time the scale was a 9-magnitude megathrust earthquake.\n2. It must be a Thrust Fault (or reverse fault). This earthquake was caused by plate subduction, which is a standard Thrust Fault. Out-of-sequence thrust fault causes direct vertical displacement of the seafloor, carrying a column of water and thus forming tsunamis.\n3. The epicenter must be shallow. The focal depth of the epicenter was 25km in the South-Asia tsunami while that of Fukushima earthquake was only 10km. Therefore the energy release could be converted to tsunami energy more completely.\n4. The underwater depth must be deep to allow sufficient volume of water to store potential energy. The underwater depth of Fukushima Tsunami was about 3km. It is of sufficient water depth to store the seismic energy and be converted into Tsunami waves.\n5. There is a uniform slope. Slopes can magnify tsunamis and create Edge Wave Effect. There are some beautiful slopes in the outer ocean of Fukushima.\nAlthough Hong Kong is not located within the subduction zone, therefore seemingly less a chance for earthquakes to happen, does it really mean that mega earthquakes and tsunamis that took place in North-east Japan will not happen here in Hong Kong?\nWe got to understand that opposite to the shore of Hong Kong, at the eastern side of the South China Sea is the Luzon Island of Philippines. Its west coast sits the notorious Manila Trench.\nThe article points out that this trench has been identified as the most active trench in the world by the USGS. Its extremely long thrust length of approx. 1,500km is similar to that causing the South-Asia Tsunami. Also, it is a subduction plate in which the Eurasian Plate is subducting under the Philippine Sea Plate.\nThe GPS geodesy measurements show that the convergence rate across the Megathrust is at 8.7cm per year, which is considered as an active thrust fault.\nAlso, there is no record of any mega earthquake since 1560, a time when the Philippines started written records; even the monitoring in recent years has not shown any earthquakes that are of magnitude 8 or above.\nThis is very similar to the South-Asia and the Fukushima Tsunamis. Energy is being accumulated under the crust which is potentially of serious danger.\nThe article also points out that according to the analysis of earthquake recurrence interval, the recurrence interval of a 8.5-magnitude earthquake in the Manila Trench is 205 years and that of a 9.0 magnitude is 667 years.\nFrom the data above, it shows that the Manila Trench has already stored a considerable amount of energy that can potentially lead to a mega earthquake in the future.\nAnd if a mega earthquake takes place in the Manila Trench, the tsunami created can potentially be impacting Hong Kong.","Seismic and anthropological research over the last thirty years has revealed the deep history of the Pacific Northwest’s earthquake and tsunami activity. As mentioned on previous blog posts, the Pacific Northwest is bordered to the west by the Cascadia Subduction Zone, a point where two tectonic plates, the Juan de Fuca plate, and the North American plate meet – about fifty to seventy five miles off the coast, running from southern British Columbia, roughly seven hundred miles south, to northern California. (The Juan de Fuca plate is subducting under the North American plate at a rate of ~ / =1.6″ per year to the east / northeast. The North American plate is moving to the south / southwest at a rate of ~ / = 1″ per year. Ref link: http://pnsn.org/outreach/about-earthquakes/plate-tectonics).\nAccording to James Roddey (formerly of Oregon Geology Department) in a video published on January 9, 2014, using information from Dr. Chris Goldfinger of Oceanic and Atmospheric Science at OSU (https://www.youtube.com/watch?v=0amLbhxCiqc&spfreload=10), over the last 10,000 years, there have been twenty magnitude 9+ earthquakes with epicenters varying along the length of the Cascadia Subduction Zone, with another twenty 8.5+ magnitude earthquakes epicentered in the southern 300 miles of the subduction zone. Seventy five percent of those forty earthquakes took place within three hundred and ten years of each other. The last one being in the year 1700.\nSo, how do scientists discern when earthquakes occurred, their magnitude, and resulting damage? They play in the dirt…. (http://www.iris.edu/hq/files/programs/education_and_outreach/aotm/22/1b.EarthquakesVolcanoesInThePacificNW.pdf)… see page six. Okay, so they do more than play in the dirt. But ‘playing in the dirt’, is a huge part of learning about the history of earthquakes and tsunamis. Earthquakes can cause moderate to severe elevation changes, alter the course of creeks, streams, and rivers, and change cultures and societies. These are known as Seismoarcheaological Indicators. Unlike evidence from volcanic eruptions and floods, which can be recognized in excavation sites by changes in stratigraphy or soil composition, earthquake evidence can be more difficult to ascertain or interpret. Often times, archeaological dig sites are concentrating more on the anthropological history than on the geological history of the dig site; seismic evidence may be overlooked or destroyed during the excavation. Unless the excavation is intent on seismic discovery, evidence of past earthquakes such as damage to buildings or other structures, and ecological changes, may be misinterpreted, or as previously mentioned, overlooked or destroyed.\nHow structures, anthropological evidence (human remains, etc…), and other organic evidence (trees, fossils, etc…) are buried may help answer questions about magnitude, duration, damage, and other time related questions that scientists are looking to answer. Separation and striation of strata may also offer evidence of past earthquakes. Returning to page 6 referenced above at IRIS.edu, evidence of a major geological catastrophe (tsunami) may be indicated by the layers of sand deposits over previous topsoil, followed by tidal mud and finally current topsoil. This as a result of the major earthquake and the following tsunami in 1700. Layers of sediment found off the coast of BC, OR, and WA show widespread, simultaneous shaking region-wide was highly likely.\nWritten accounts, folklore, and other cultural evidence may also help ascertain earthquake history. The last megathrust earthquake to hit this region occurred on January 26th, 1700… scientists even have it down to a time – 9PM. They were able to ascertain the date and time by collaboration with Japanese scientists and historians who identify the Cascadia Subduction Zone as the origin of a deadly tsunami that hit the coast of Japan the following day. Accounts of the tsunami were documented by Samurai in the regions affected by the tsunami (see previously referenced IRIS.edu). Native American’s in the region handed down tales and legends of strong shaking throughout the region, followed by severe flooding. Much of this can be cross-checked with physical evidence, such as the Ghost Forests (http://www.burkemuseum.org/static/earthquakes/bigone/detective.html), an area decimated by the flood of 1700, which is now all dead cedar stands, swamp land, and sea marshland.\nEvidence of other past earthquakes are found in turbidites, layers of sand, silt, and muck, found at the bottom of the sea where two plates meet. The sheer drop-off from one plate to another provides excellent sources for turbidites and their secrets. According to Chris Goldfinger, turbidites provide “very, very obvious ” evidence of earthquake deposits (http://www.livescience.com/22248-earthquake-records-pacific-northwest-cascadia.html). Only the strongest earthquakes send sand, silt, and other seabottom particulates tumbling to the oceanic plate below, which over time, create these turbidites. Unlocking their secrets with carbon dating shows evidence that correlates with land based time frames for seismic events. Turbidites have proven to be highly accurate, not only for large earthquakes, but for much smaller ones, too, providing more information on smaller earthquakes than can be garnered on land.\nGiven the depth and breadth of discussions on ‘The Big One’, it is hard to point to any one study and say that is the right one. Based on evidence provided by turbidtes, Goldfinger says he’s not taking and chances, and has purchased earthquake insurance and made necessary modifications to his house. Probably not a bad idea in this tumultuously seismic environment we live in."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:fcd935cb-75b2-4ac9-ad4a-a2fbf5a0e1bd>","<urn:uuid:1448f54c-8e64-4cff-8b15-fc2771ef9f8b>"],"error":null}
{"question":"How did Charlie Parker transform jazz music's purpose and style, and what legacy did he leave for future generations?","answer":"Charlie Parker transformed jazz by starting the bebop movement, which changed jazz from dance music into a fine art form for listening. He was the first true modern jazz virtuoso who mastered complex harmonies, rhythms, and melodies, and popularized a new songwriting format by borrowing chord changes from existing songs and creating new melodies. His influence was so significant that even 70 years later, musicians still play his phrases and techniques. This lasting impact is reflected in current jazz education philosophy, as emphasized by Chuck Israels who states that learning jazz is like learning a language - it requires studying the history and repertoire of its usage, with no shortcuts possible, making Parker's contributions an essential part of jazz education.","context":["Just like in any other genre, there are certain artists who have had an enormous impact on the whole jazz scene. Those who follow try to copy their sound and then move beyond to be creative forces in their own right. Despite living in different eras, and representing different niches of jazz, some qualities are common to all of them. Qualities like passion, leadership, virtuosity, and fearless innovation.\nRead on to discover six of the true “giants” of jazz improvisation through the ages and what you can learn from them to inspire your own improvising.\n1. Charlie Parker\nCharlie Parker created the blueprint for post-swing jazz improvisation. Even now, 70 years later, musicians play the phrases and techniques he created. Serious jazz students internalize Charlie Parker’s personal language of jazz improvisation through transcribing and playing his solos, analyzing them in detail, and learning specific quotes (i.e. musical phrases) in all the keys.\nSo why is Charlie Parker so important to the jazz scene?\n- He was the guy who started the bebop movement, which transformed jazz music into a fine art form for listening rather than dancing.\n- He was the first true modern jazz virtuoso, who mastered complex harmonies, rhythms, and melodies.\n- He popularized a songwriting format for jazz by borrowing and altering chord changes from existing songs and creating new melodies on top.\nListen to Parker’s solo on “Confirmation” starting at [0:43]. It’s a virtual catalogue of his trademark techniques—endless arpeggios, chromatic lines, impeccable sense of swing and instrumental dexterity. His influence extended beyond the jazz world: the cartoon Woody Woodpecker laugh is actually an imitation of a famous Charlie Parker lick.\n2. John Coltrane\nStorming the scene in the 1950s, John Coltrane collaborated with such seminal artists as Miles Davis and Thelonious Monk. Coltrane’s unmatched virtuosity has carved him a place as one of most sophisticated jazz improvisers to date.\nColtrane’s groundbreaking improvisations are studied intensely by many jazz aspirants. He explored the frontiers of tonality with pieces like “Giant Steps”, and helped define modal jazz, free jazz, and beyond with works like “My Favorite Things” and “A Love Supreme.”\nLike Charlie Parker in his day, Coltrane’s new harmonic concept challenged his peers. When he broke free from traditional tonal chord progressions with “Giant Steps” he was pretty much the only one to nail it. The harmonic changes of this record became known as the Coltrane Changes. The chord roots are all a major third apart, thus integrating whole-tone scales, interesting sequential patterns, and the scale now known as Coltrane’s Pentatonic (playing the 1st, 2nd, 3rd and 5th degree of the current chord).\nBesides constantly shifting tonality every bar, “Giant Steps” is also played at an insane 300 BPM. Watch this animated sheet music video of “Giant Steps” and see the Coltrane Changes and Coltrane Pentatonics come to life in his jaw-dropping solo [0:35].\n3. Bill Evans\nA quiet guy, Bill Evans made a huge impact. Among the people he influenced are Miles Davis, Herbie Hancock, Pat Metheny, and Keith Jarrett His exquisite taste in harmony—he was left handed which explains his complex accompaniment—and melodic approach earned Evans an iconic status among generations of jazz musicians. A little-known fact is that he helped develop George Russell’s Lydian Chromatic Concept of Tonal Organization. This concept was the foundation for styles like Modal Jazz and later on, Fusion.\nThis is one of the most famous performances by Bill Evans called “Waltz For Debby”. His solo starts at [2:43].\nAs did Charlie Parker, Bill Evans created a blueprint of jazz improvisation, but for pianists. His beautiful lines, stylish accompaniment and perfect phrasing are studied by all pianists, and pretty much any jazz musician. Bill Evans created a new way for pianists to comp by using rootless voicings. He used the 3rd and the 7th degrees of the chord (these are responsible for the minor, major qualities of the chord) combined with upper structures, or embellishment tones. He left the root of the chord to the upright bass.\n4. Miles Davis\nKnown as not one of the most pleasant guys in the scene but, nonetheless, perhaps the most important genre innovator in jazz. Miles Davis started his journey alongside Charlie Parker playing bebop and moved forward helping to shape Cool Jazz, Modal Jazz, and Fusion.\nHe created one of the most-played jazz records of all time, was known to nurture the talents of the most important musicians in the generations to come.\nMiles’ style of improvisation is usually very laid back, relying more on melody rather than playing the changes. Jump to [1:15] to hear an example of his improvisation. You can always recognize his “cool” approach when listening to his solo. He is great at working with motifs and developing them from a single note to a beautiful flow of ideas, just like classical composers would do.\n5. Thelonious Monk\nThelonious Monk is an amazing example of a pianist with a strong signature sound. While it may be somewhat difficult to distinguish between instrumentalists at times, you will never confuse his seemingly-sloppy piano stabbing style for anyone else’s. Making an enormous contribution to the overall repertoire of jazz standards, Monk is a musician and composer to be reckoned with.\nHere’s a recording of “Blue Monk”. The tenor sax solo starts at [1:04]. Pay attention to the quirky accompaniment provided by Thelonious Monk: he was one of the first guys to inadvertently “brand” instrumental playing. Monk’s solo starts at [3:08]: notice the deliberate silences and the staccato approach. Additionally, he plays a lot with sparse intervals, and all with a certain swagger and rough humor.\n6. Pat Metheny\nWinner of a total of 20 Grammy awards, Pat Metheny is one of the pioneers of Jazz Fusion. Drawing a lot of his influences from the sounds of South America, Middle East and the works of classical composers (especially Claude Debussy) this guy can really paint a whole sonic landscape in front of you.\nAlso known for his work with synthesizers, he was one of the first musicians to start using a guitar synthesizer. Check his solo starting at [6:06], on “Imaginary Day”. One of the improvisation techniques that he uses a lot is a highly modal approach with diatonic and chromatic sequences. All coupled with tons of FX processing on his guitar (often made to sound like a trumpet), his shows are one of the most spectacular in the jazz realm.\nOn the Shoulders of Giants\nAs Igor Stravinsky, a great composer of the 20th century, once said, “Lesser artists borrow, great artists steal.” The giants of jazz spend lifetimes acquiring their sound and style, leaving behind the gift of their massive legacies. As jazz improvisers, why not open our ears, hands, and minds to receive these gifts?\nAs children, we mastered the language of our parents through listening and practicing our skills until we could reproduce the sounds. Eventually we learned to express our most complex thoughts with fluency. So we can stand on the shoulders of the jazz giants by listening, transcribing, and practicing their language of jazz until it becomes our own.\nWant to grow your jazz improvisation to massive proportions? Here’s the recipe: grab your favorite jazz solo, find your favorite lick, sing it, transcribe it, learn it on your instrument, and transpose it. Each small bite of this “giant food” will leave you wanting more!","Chuck Israels: Evans, Education and Philosophy\nAll About Jazz: You were a member of the groundbreaking Bill Evans Trio. What was the musical climate like in the jazz arena at this time? And how was the trio being received by audiences during this period?\nChuck Israels: Very different than it is today. The trio was at the top of its form and was popular enough that we could find good work and an attentive, appreciative and knowledgeable audience almost all year-round.\nAAJ: It's been written that Evans worked tirelessly on assimilating new material, and also worked at perfecting his own musical ideas towards a very high standard. If this is correct, how did this attitude affect the trio?\nCI: It made my job easy. I was unprepared to do that kind of organizing/arranging work at that time. Bill was meticulous and thorough, and was continuously prepared with beautifully worked out material. Once exposed to Bill's versions of familiar pieces, I was hard pressed to accept other ways of hearing them.\nAAJ: While you were with the trio, the level of musical communication was almost magical. What were some of Evans' methods of communication with the rest of the group in performance (if he had any)?\nCI: Everythingeverythingwas communicated through the sound of the music. There were no other signals of any kind everno count-offs, head nods, spoken instructions...nothing.\nAAJ: As an educator who has developed such high musical standards through an impressive career, you have also been in the trenches with scores of budding musicians. Have you encountered any hindering mindsets that young players commonly hold?\nCI: The most common is that one can learn a language by studying its alphabet and grammarand maybe a word or two. Languages exist in the history of their usagetheir prose and poetry. You cannot learn to be a poet without knowing a repertoire of existing poetry. There are no shortcuts to this.\nAAJ: On your site, your \"An Unpopular Perspective On Jazz Education\" article is both profound and insightful, with several of your thoughts resonating deeply. What is your opinion of jazz education as it stands today?\nCI: With few exceptions, jazz education survives within a system that often pretends to separation from popular and commercial influences while, in fact, it is deeply affected by those influences. It is difficult to maintain a high level of musical (or educational) integrity in the face of an impoverished world of inane popular music. Even worse are those educational institutions that mistakenly embrace weak and mindless music in the belief that its momentary popularity represents sufficient value to warrant teaching young people how to pursue this music under the guise of defensible music education.\nIt may be education. Commercial music is a trade, and there is a place for trade schools but, given the state of musical contemporary musical commerce, pretending that pursuing its values is any kind of art is misguided at least and fraudulent at the worst. Unfortunately, a good deal of this poor music falls under the rubric of jazzsome of it blatantly mundane and some high minded and pretentious, but weak and vapid nonetheless.\nAAJ: What of the modern music that is harsh and dissonant. This music sometimes finds its way into current trends, and it seems that many players use this biting, disjunct vocabulary without first developing a solid harmonic foundation. What are your thoughts?\nCI: Music needs the juxtaposition of opposites to achieve its drama, so harshness and dissonance are simply part of the material a musician can use to create a musical work. All one thing is a boreall dissonance, or all fatuous consonance. George Winstonand Guns and Roses are two sides of the same worthless coin in my esthetic world.\nAAJ: If you had to choose a few basic principlesones that have guided you as a composer, arranger, and musicianthat you view as most vital in your own musical development, what would they be?\nCI: Things that turn out to be durablethat have a lasting good effect on my psyche, are also the things that have the most telling effect on the short term, so I listen to things that I continue to like over long periods and try to include the elements I find in those things in whatever I am doing at the moment. I have no time to waste on listening to disposable music.\nAAJ: In your long musical career, has there been a particularly defining experience that you continue to reflect on, and continue to carry with you?\nCI: Too many to recount, but I can say that being part of making music with Bill remains a standard to which I aspire every day of my musical life.\nAAJ: Let me talk about composition for a moment. In general, what would you say that you strive for in your own personal composition? That is to say, when you set out in a certain direction, when do you know that you've achieved your intentions when you are involved in a new work?\nCI: It's be nice to think that I could turn out something half as good as Billy Strayhorn's work. If I have done what I intend, [then] at some point what I'm working on solidifies and seems to have completed itself, and I become satisfied with it. That doesn't happen with every project, so some get abandoned and some get reworked until they reach that point. Needless to say, some never get there.\nChuck Israels/Metropole Orkestra, Eindhoven Concert (Anzic, 1997)\nBarry Harris, Barry Harris In Spain (Nuba, 1991)\nBill Evans, Trio '65 (Verve, 1965)\nHerbie Hancock, My Point of View (Blue Note, 1963)\nBill Evans Trio, How My Heart Sings! (Riverside, 1962)\nEric Dolphy, Copenhagen Concert (Prestige, 1961)\nGeorge Russell Sextet, A the Five Spot (Verve, 1960)\nCecil Taylor, Hard Driving Jazz (Gambit, 1958)\nJohn Coltrane, Coltrane Time (Blue Note, 1958)"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:27faac0b-942e-4db7-9807-43ae02acacd2>","<urn:uuid:6ca24bc4-34cf-429e-af53-a42b9042e2d9>"],"error":null}
{"question":"How does laughter function as a pre-human communication mode, and what role does it play in modern stress responses?","answer":"Laughter originated as a pre-human mode of communication that activates pre-linguistic, preconscious abilities that coexist with linguistic communication. Philosophers like Kant noted that laughter involves a sudden transformation of consciousness to lower cognitive activities shared with evolutionary predecessors. In modern contexts, laughter and humor serve as responses to stress, being part of the body's physiological reaction system. During stress responses, the body undergoes non-specific changes whether the stimuli are positive (eustress) or negative (distress), though eustress causes less damage than distress.","context":["The Evolution of Human Language: Scenarios, principles, and cultural dynamics (Advances in Consciousness Research)\nBy Wolfgang Wildgen\nWolfgang Wildgen offers 3 views at the evolution of language as a key point within the evolution of mankind when it comes to the improvement of human image use. (1) He methods this query through developing attainable eventualities within which mechanisms helpful for symbolic habit can have constructed, at the foundation of the cutting-edge in evolutionary anthropology and genetics. (2) Non-linguistic symbolic habit reminiscent of cave artwork is investigated as an incredible clue to the developmental history to the beginning of language. Creativity and innovation and a population's skill to combine person experiments are thought of in regards to ancient examples of symbolic creativity within the visible arts and traditional sciences. (3) possible linguistic 'fossils' of such linguistic techniques are tested. the result of this examine let for brand new proposals for a 'protolanguage' and for a idea of language inside a broader philosophical and semiotic framework, and increases fascinating questions as to human attention, common grammar, and linguistic method. (Series B)\nPreview of The Evolution of Human Language: Scenarios, principles, and cultural dynamics (Advances in Consciousness Research) PDF\nBest Anthropology books\nBig apple occasions Bestseller\"I might suggest this publication to a person attracted to a enjoyable, enticing examine early human history…you’ll have a difficult time placing it down. \"--Bill Gates\"Thank God an individual eventually wrote [this] unique e-book. \"--Sebastian JungerFrom a popular historian comes a groundbreaking narrative of humanity’s construction and evolution—a number 1 overseas bestseller—that explores the ways that biology and historical past have outlined us and greater our figuring out of what it skill to be “human.\nUsed to be love invented by way of eu poets within the heart a long time or is it a part of human nature? Will profitable t. .. .\nSea ice and the hour of darkness sunlight, flaming aurora and unending iciness night--the arctic of traveler's stories and romantic novels is the inconceivable dream of an enormous and desolate world--the final imaginary position in the world. Now, during this attention-grabbing quantity, popular archeologist Robert McGhee lifts the veil to bare the genuine Arctic.\nThis publication strains the social and environmental determinants of human infectious illnesses from the Neolithic to the current day. regardless of contemporary excessive profile discoveries of latest pathogens, the foremost determinants of those rising infections are old and habitual. those comprise altering modes of subsistence, moving populations, environmental disruptions, and social inequalities.\n- Imagining Landscapes: Past, Present and Future\n- Myths of Male Dominance: Collected Articles on Women Cross-Culturally\n- Encyclopedia of Population\n- Malta, Mediterranean Bridge\n- The Making of Law: An Ethnography of the Conseil d'Etat\n- Ethnomusicology : A Contemporary Reader\nExtra resources for The Evolution of Human Language: Scenarios, principles, and cultural dynamics (Advances in Consciousness Research)\nClassical analyses of laughter and the comical pathways result in glossy theories of the comical: the literary style known as “comedy” in keeping with theories of comedy, e. g. , in Aristotle’s poetics, and the rhetorical means of making humans giggle generally on the cost of somebody. a selected research of the comical (e. g. , of humor) outdoor those major strains has merely existed because the seventeenth century. In his “Leviathan” (1651), Hobbes says that “laughter”: (. . . ) is prompted both by way of a few surprising act in their personal, that pleaseth them; or via the apprehension of a few deformed factor in one other, by means of comparability whereof they abruptly applaud themselves. (Cf. Burtt 1967: 152. ) “Laughter” is taken care of within the bankruptcy on ardour and preceded through “vain-glory” from which it really is distinctive as “sudden glory”. it's via “sudden dejection (. . . ) the fervour that causeth weeping” (ibidem: 153). For Hobbes, the criterion of unexpected influence applies to either “laughing and weeping”. If Hobbes considers laughter as a typical ardour associated with “vital motions” (ibidem: 148), he belongs to the classical culture seeing that Aristotle and issues to the idea of humor within the clinical context of Galen (i. e. , humor as a standard mix of the 4 drinks within the human body). In Kant’s “Kritik der Urteilskraft” (1790) the scope has replaced; the comical item, state of affairs, or individual isn't any longer the guts of the argument, it is vitally the hearer and his brain, which specify the style of the comical: Expression and attraction in animal and human conversation Laughter is an impact caused by the surprising transformation of a annoying expectation into not anything. this modification, that's absolutely now not friendly to the brain, nonetheless pleases in a roundabout way for one second in a truly brilliant demeanour. hence, the reason for it has to be sought within the impact of mind's eye at the physique and its reciprocal impact at the soul. (Kant 1790/1974: 273; translated through the writer. ) Kant’s definition refers to expectation, unexpected transformation and not anything. After Kant the romantic philosophers Tieck and Novalis attempted a “deeper” specification of Kant’s “sudden transformation to nothing”. The comical factors the ego to step out of itself and establishes “Being outdoor Being inside of Being. ” (Novalis mentioned by way of Frank 1992: 218. ) This research comprises an engaging aspect: The comical relates attention to sub-consciousness or just to reduce cognitive actions like belief, reminiscence and mind's eye. In a feeling, it transforms a wakeful job of the brain (a point basically available to people) into an job at a decrease point of the cognitive procedure (shared with evolutionary predecessors of man). therefore the intuitive research by way of philosophers (Hobbes, Kant, Novalis) shows that the comical is grounded in pre-linguistic, preconscious and therefore pre-human modes of communique. Laughter and the culturally derived sorts of the comical style turn on pre-human communicative abilities, which coexist with the linguistic form of verbal exchange. As this research does in simple terms minimally reflect on the social nature of laughter (Hobbes pointed to the person who laughs, Kant to the hearer laid low with the comical) i'll flip to the communicative point of laughter.","What is Stress?\n“People are disturbed not by a thing, but by their perception of a thing.” — Epictetus\nThere has been no definition of stress that everyone accepts. Therefore, it’s difficult to measure stress if there is no agreement on what the definition of stress should be.\nPeople have very different ideas with respect to their definition of stress. Probably the most common is, “physical, mental, or emotional strain or tension”. Another popular definition of stress is, “a condition or feeling experienced when a person perceives that demands exceed the personal and social resources the individual is able to mobilize.”\nMost people consider the definition of stress to be something that causes distress. However, stress is not always harmful since increased stress results in increased productivity. A definition of stress should also embrace this type of healthy stress, which is usually ignored when you ask someone about their definition of stress.\nAny definition of stress should also include good stress, or eustress. For example, winning a race or election is just as stressful as losing, or more so. A passionate kiss and contemplating what might follow is stressful, but hardly the same as having root canal work. Any definition of stress should similarly explain the difference between eustress and distress.\nThe definition of stress for most people tends to focus on the negative feelings and emotions it produces. Almost every definition of stress also discusses certain resultant physical, physiological or biochemical responses that are experienced or observed. A very comprehensive definition of stress that includes these and more is the biopsychosocial model, which, as it name suggests, has three components. This definition of stress distinguishes between an external element, another that is internal, as well as a third that represents the interaction between these two factors.\nIn the biopsychosocial definition of stress the external component is made up of elements in the external environment. The internal component in this definition of stress consists of physiological and biochemical factors in the internal environment or body. The interaction between these two components in this definition of stress represents the cognitive processes that result from the interaction between external and internal components. Some of the physical reactions experienced during stress include hypertension, headaches, gastrointestinal and skin complaints, etc. Any definition of stress that does include these potentially dangerous physical responses is incomplete.\nA definition of stress that does not refer to the role of the hypothalamic-pituitary- adrenal axis or stimulation of the sympathetic nervous system and adrenalin secretion in the “fight or flight” response should also be considered to be a deficient definition of stress. Since stress is such a subjective phenomenon that differs for each of us, there really is no satisfactory definition of stress that all scientists agree on. The original definition of stress by Hans Selye, who coined the term as it is presently used, was, “the non-specific response of the body to any demand for change”. This definition of stress was confusing when Selye’s experimental animal results were extrapolated to humans and stress became a buzzword. For some, the definition of stress was something external, like a bad boss, for others the definition of stress referred to chest or stomach pain or some other disturbing reaction you experienced, but the definition of stress could also be the end result of these responses such as a heart attack or peptic ulcer. Selye subsequently had to create a new word, stressor, to distinguish between stimulus and response. He struggled unsuccessfully to find a satisfactory definition of stress and in his later years suggested that the best definition of stress was “the rate of wear and tear on the body”. He was also unaware that the definition of stress in physics that had been in use for several centuries was the degree of distortion in a malleable metal when it was subjected to an external load. Thus, his original definition of stress was really a description of strain.\nFight or flight. The body prepares to defend itself. It takes about 90 minutes for the metabolism to return to normal when the response is over.\nThe cost of daily living: bills, kids, jobs…This is the stress we tend to ignore or push down. Left uncontrolled this stress affects your health- your body and your immune system.\nStress in daily life that has positive connotations such as:\nStress in daily life that has negative connotations such as:\n2014 Stress Statistics\n|Source: American Psychological Association, American Institute of Stress, NY|\n|Research Date: 7.8.2014|\n|Top Causes of Stress in the U.S.|\n|Job Pressure||Co-Worker Tension, Bosses, Work Overload|\n|Money||Loss of Job, Reduced Retirement, Medical Expenses|\n|Health||Health Crisis, Terminal or Chronic Illness|\n|Relationships||Divorce, Death of Spouse, Arguments with Friends, Loneliness|\n|Poor Nutrition||Inadequate Nutrition, Caffeine, Processed Foods, Refined Sugars|\n|Media Overload||Television, Radio, Internet, E-Mail, Social Networking|\n|Sleep Deprivation||Inability to release adrenaline and other stress hormones|\n|U.S Stress Statistics||Data|\n|Percent of people who regularly experience physical symptoms caused by stress||77 %|\n|Regularly experience psychological symptoms caused by stress||73 %|\n|Feel they are living with extreme stress||33 %|\n|Feel their stress has increased over the past five years||48 %|\n|Cited money and work as the leading cause of their stress||76 %|\n|Reported lying awake at night due to stress||48 %|\n|Stress Impact Statistics|\n|Percent who say stress has a negative impact on their personal and professional life||48 %|\n|Employed adults who say they have difficulty managing work and family responsibilities.||31 %|\n|Percent who cited jobs interfering with their family or personal time as a significant source of stress.||35 %|\n|Perccent who said stress has caused them to fight with people close to them||54 %|\n|Reported being alienated from a friend or family member because of stress||26 %|\n|Annual costs to employers in stress related health care and missed work.||$300 Billion|\n|Percent who say they are “always” or “often” under stress at work||30 %|\n|People who cited physical symptoms experienced the following|\n|Upset stomach||34 %|\n|Muscle tension||30 %|\n|Change in appetite||23 %|\n|Teeth grinding||17 %|\n|Change in sex drive||15 %|\n|Feeling dizzy||13 %|\n|People who cited psychological symptoms experienced the following|\n|Irritability or anger||50 %|\n|Feeling nervous||45 %|\n|Lack of energy||45 %|\n|Feeling as though you could cry||35 %|\nGeneral Stress Response\nHans Selye defined stress as the body’s nonspecific response to any demand, whether it is caused by or results in pleasant or unpleasant stimuli. It is essential to differentiate between the unpleasant or harmful variety of stress termed distress, which often connotes disease, and eustress, which often connotes euphoria. During both eustress and distress, the body undergoes virtually the same non-specific responses to the various positive or negative stimuli acting upon it. However, eustress causes much less damage than distress. This demonstrates conclusively that it is how an individual accepts stress that determines ultimately whether the person can adapt successfully to change. Selye hypothesized a General Adaptation or Stress Syndrome; this General Stress Syndrome affects the whole body. Stress always manifests itself by a syndrome, a sum of changes, not by simply one change.\nThere are three components to the General Stress Syndrome. The first stage, which is termed the alarm stage, represents a mobilization of the body’s defensive forces. In other words, the body is preparing for the “fight or flight” syndrome. This involves a number of hormones and chemical excreted at high levels, as well as an increase in heart rate, blood pressure, perspiration, respiration rate, etc. In the second phase — the stage of resistance — the body becomes adaptive to the challenge and even begins to resist it. The length of this stage of resistance is dependent upon the body’s innate and stored adaptation energy reserves and upon the intensity of the stressor. Just as any machine wears out even if it has been properly maintained, so do living organisms that sooner or later become the victim of this constant wear and tear. The acquired adaptation is lost if the individual is subject to still greater exposure to the stressor. The organism enters into the third and final stage — the exhaustion stage — and then dies because it has used up its resources of adaptation energy. Thankfully, few people ever experience this last stage!\nStress diseases are maladies caused principally by errors in the body’s general adaptation process. They will not occur when all the body’s regulatory processes are properly checked and balanced. They will not develop when adaptation is facilitated by improved perception and interpretation. The biggest problems with derailing the General Stress Syndrome and causing disease is an absolute excess, deficiency, or disequilibrium in the amount of adaptive hormones — for example, corticoid, ACTH, and growth hormones produced during stress. Unfortunately, if stress is induced chronically, our defense response lowers its resistance since fewer antibodies are produced and an inflammatory response dwindles.\nPhysiology of the Stress Response\nThe following list of topic links are historically of great interest to guests of AIS:\nCranial Electrotherapy Stimulation for Treatment of Anxiety, Depression, and Insomnia –The full article was originally published by published The Psychiatric Clinics and is posted here with permission. Visit www.psych.theclinics.com."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:fbe1facf-12a1-457a-a395-ff82c040a4e6>","<urn:uuid:8c33f2f8-a8dc-471a-99c4-eba7446883a4>"],"error":null}
{"question":"What are the primary benefits of greenhouse plastic compared to glass, and what ventilation options are available for different greenhouse coverings?","answer":"Greenhouse plastic offers several benefits compared to glass, including lower costs, lightweight construction requiring less structural framing, and light diffusion equal to glass greenhouses. For ventilation, greenhouses with polyethylene film can be more challenging to ventilate, while polycarbonate and glass windows can use automatic openers with fluid-filled cylinders that respond to temperature changes by expanding and contracting to open and close windows.","context":["Greenhouse plastic is primarily accountable for maintaining a hothouse effect within a greenhouse. Greenhouse plastic produces a appropriate and warm growing environment that permits numerous kinds of plants to cultivate magnificently. It develops an enclosure that protects plants from the harmful ultraviolet rays of the sun while making the most of its natural warmth and light. The filtered environment produced by greenhouse plastic makes it possible for garden lovers to grow luscious plants like veggies and flowers in the cold dead of winter season.\nGreenhouse plastic is explicitly designed to withstand wear and tear unlike traditional building and construction plastic that can not filter ultraviolet rays from the sun. Greenhouse plastic is resilient due to its knitted design that allows it to be cut and sized to meet the needed length for a structure without fraying, tearing or ripping. The product can easily be framed around any greenhouse opening like a vent, door or windows.\nGreenhouse plastic is the favored covering of many garden lovers compared to other types of greenhouse covering. When greenhouse plastic is used considering that it lightweight and does not require durable structural framing, at the same time expenses are considerably lowered. The diffusion of light into a structure constructed of greenhouse plastic is as great as that of a glass greenhouse.\nKinds Of Greenhouse Plastic\nGreenhouse plastic movies are usually made of three kinds of plastics particularly, PVC or polyvinyl pe, chloride or polyethylene and copolymers. Although, there are other kinds of plastic used these 3 are most widely used amongst all.\nPolyethylene greenhouse plastic is offered in two types, the energy grade and the industrial grade greenhouse plastic. Utility grade polyethylene check here greenhouse plastic is cost regional hardware shops and normally remains in excellent condition for practically a year. Commercial grade polyethylene greenhouse plastic last longer that utility grade PE as much as eighteen months and is treated with ultraviolet inhibitors that filter out ultraviolet rays.\nIngenious ingredients introduced into greenhouse plastic allow it to simulate the exact same impacts of a glass greenhouse at significantly lowered expenses. Polyvinyl chloride is more pricey compared to polyethylene however this type get more info of greenhouse plastic can last up to 5 years.\nHow to Attach Greenhouse Plastic to Frame\nWhen the frame has been built it is time to put on the greenhouse plastic film to confine the whole structure. Before laying the greenhouse plastic covering on the frame it is essential to mask the joints of the frames with numerous rounds of tape or a rubber material to avoid it from puncturing the covering.\nThe greenhouse plastic movie can be secured in location using a staple gun. A more stiff construction utilizing 1\" by 2\" wood strips and wood screws can also be utilized to secure the greenhouse plastic movie in location. The wood strips are connected to the frame so that the greenhouse plastic read more movie does not come in direct contact with the frame.\nAir is presented into the framed plastics that produce a dead air zone, which can effectively insulate the whole greenhouse. Various tapes like poly patching tape and batten tape can be used to protect greenhouse plastic into place.\nPoly patching tape is built from UV protected acrylic in addition to the adhesive to safeguard the greenhouse plastic from deteriorating on contact with it. This type of tape can be used to patch holes and rips that may occur to the plastic movie. Its outstanding holding strength and broad tape make a suitable for securing the plastic movie to the frame of the greenhouse. On the other hand batten tape can be attached the plastic movie using staples or tacks to the greenhouse structure. It is also made from heavy gauge vinyl that is also UV safeguarded.","Learn something new every day\nMore Info... by email\nOne way to lengthen the growing season for plants is to create a special space, or greenhouse, where a gardener can make optimal use of sunlight, temperature, humidity and other growing conditions. The term \"greenhouse window\" can be used to refer to a window in a freestanding or lean-to greenhouse, or a type of window installed in a house that projects past the exterior, similar to a bow window. When trying to design the best growing space, gardeners should choose greenhouse windows that provide the light, temperature, humidity, and ventilation required by the plants they want to grow. In addition, greenhouse windows should fit the gardener's budget, and be appropriate for the design and location.\nIn-house greenhouse windows provide a space in the house with shelves for growing herbs or other small plants year-round. These greenhouse windows may use special low-e glass to prevent condensation build up. Brackets running from the outer edge of the shelf to the exterior of the house may be installed to help support the weight of the shelves and plants. These greenhouse windows are commonly available with vinyl or aluminum frames; aluminum frames tend to be lighter and stronger, but also allow for more heat loss and condensation build up than vinyl frames. Greenhouse windows should fit tightly into the window opening to prevent cold air from harming the growing plants.\nFor gardeners who want a larger greenhouse space, there are many options. Greenhouses or sun rooms can be installed as additions, or as lean-to or freestanding structures. Ready-to-assemble greenhouse kits are available in a wide range of sizes and materials. Gardeners can also build a greenhouse themselves using a plan. Which greenhouse windows are best for these types of structures may be determined by the choice of design.\nNot all greenhouse windows are made of glass; in fact, many popular greenhouse models do not use windows at all. One of the more common materials used in greenhouse design is polyethylene film, a kind of plastic sheeting that covers the greenhouse frame. Polyethylene film comes in various thicknesses and degrees of translucence, and more opaque film can prevent excess sunlight from reaching cool-season or shade-loving plants. Polyethylene film can easily conform to the shape of the greenhouse frame and is relatively inexpensive, but may not be as durable as a more rigid material. Ventilating a greenhouse covered with polyethylene film can also be more difficult.\nPolycarbonate, a clear, rigid plastic, is another common material used for greenhouse coverings and windows. It often has multiple layers with a space between them to trap air to help control temperature and prevent condensation inside the greenhouse. If designed to be operable, polycarbonate windows can use automatic openers to provide ventilation. Automatic openers have a fluid-filled cylinder that expands and contracts to open and close the window in response to higher and lower inside temperatures. In contrast to other materials, polycarbonate is generally more expensive than polyethylene film, and also does not allow as much light or heat to pass through as glass.\nGlass windows are heavier and can be more or less expensive than other options depending on whether the windows are new or used. Many times, a gardener can find used windows for free, or purchase them fairly cheaply. This is a good option for gardeners who want to build an inexpensive greenhouse from a plan.\nWhether new or used, certain features may determine which window is suitable to the greenhouse design. The number of panes is one consideration; single-paned windows allow better transfer of sunlight and heat, but make it more difficult to control temperature than double-paned windows. Windows with UV-protection or low-solar-gain low-e glass may be a better choice when the gardener wants to limit the amount of sunlight plants receive, such as in summer months or in warmer, sunnier climates. As with polycarbonate, glass windows can make use of an automatic opener to provide ventilation.\nIf the gardener has decided to purchase a greenhouse kit, or has chosen a professional installation, then he may be limited in the choice of window or covering material. Kits may come with either polyethylene film, polycarbonate, or glass windows. Professionals may or may not be able to alter the design of the greenhouse to incorporate the gardener's choice of materials.\nOne of our editors will review your suggestion and make changes if warranted. Note that depending on the number of suggestions we receive, this can take anywhere from a few hours to a few days. Thank you for helping to improve wiseGEEK!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:cb1d5c54-52bb-4ba8-8125-fdf32eada56b>","<urn:uuid:4029606c-1ec9-4688-b8a9-1a4a59a6e789>"],"error":null}
{"question":"Could you please help me understand how Jewish and Moorish designs are connected in both the Eldridge Street Synagogue and Dubai's artistic scene today?","answer":"The Eldridge Street Synagogue in New York exemplifies the synthesis of Moorish design with Jewish architecture, influenced by structures like the Alhambra and the Mezquita. The synagogue's interior is a mix of architectural styles including Moorish, Renaissance, and Gothic. In Dubai's contemporary art scene, this Jewish-Islamic artistic connection continues through artists like Chama Mechtaly, who creates designs blending Jewish and Islamic themes, similar to how the Magen David was inspired by jewelry models on Al-Azhar Mosque in Cairo. The synthesis of these designs represents a historical continuation of Jewish-Muslim artistic cooperation, from ancient architectural examples to modern artistic expressions.","context":["Moroccan Visual Artist Chama Mechtaly Builds Aesthetic Bridges Fostering the Abraham Accords\nA new golden era and the ideology of peace in Middle East region has the potential to blossom at last. This vision is shared by Dubai-based, Moroccan visual artist and activist Chama Mechtaly. Her focus has been to introduce the unique Jewish History of Morocco, North Africa through multimedia art and jewelry design.\nOriginally from Casablanca, Chama Mechtaly, claims, “I am a romantic and I dwell on the romanticism of Andalusia.” Mechtaly is the Creative Director of the company, Moors and Saints, which makes handcrafted products in Dubai and is committed to interfaith dialogue and pluralism.\nIn the wake of the Abraham Accords and the recent peace deal between Israel, Bahrain and the United Arab Emirates along with improving relations between Israel and Morocco, these actions have increased importance and continued to inspire artists like Chama Mechtaly is working with the Jerusalem Biennale on the first Jerusalem-Dubai art residency and exhibition, which will foster co-creation and artistic development through Hebrew and Arabic calligraphy.\n“I can’t help but think of the golden era of Ibn Ezra and Judah Halevi, Solomon Ibn Gabirol and the giants of Hebrew poetry who developed in close contact and under the influence of Arabic poetry.” says Mechtaly. This is a cultural renaissance that is being ignited in Dubai. Now the flames are being fanned and fed. Dubai and Jerusalem have many similarities, such as ‘Jerusalem of Gold’ and Dubai as a ‘City of Gold.’”\nMechtaly grew up in Casablanca, Morocco and moved to Boston when she was awarded a scholarship to study at Brandeis University. Her interest to discover more about about her family’s history and the origins of her last name inspired a new, artistic journey. Chama set out to dig through her identity in effort to decolonize her own Moroccan history. She discovered that her father did not share his family story being her grandfather had come from a Moroccan Jewish family and converted to marry a Muslim woman. Morocco’s extensive Jewish Heritage and historic Jewish community are notable with thousands of Israeli Jews having roots in Morocco.\nMechtaly raised the question of what her family’s identity means to them however some of her relatives were sensitive and did not wish to discuss the topic at the time. Intern, she decided to express her feelings through art. “I had always painted since I was a kid and I took those questions [I had] to the canvas. I used to paint portraits of Amazigh [Berber] women who were Jewish. This is what is referred to intersectionality today; when you sit at the intersection of multiple forms of oppression and accumulate layers of invisibility.”\nWith her mother, Mechtaly’s objective was to better understand her past by removing the layers of complexity of North African Jewry and also those that exist particularly within the history of Moroccan Jews. Although many Jews emigrated to Morocco during the time of the Spanish Inquisition, the origination of their traditions and history run much deeper.\nChama discovered another narrative that was shared by her mother, when researching Amazigh Jewry. Her mother shared how Jews were indigenous to Morocco for over 3,000 years, perhaps even more. She observed transformation where her work was exhibited given it attracted North African communities from the diaspora. People noticed the women featured in her works had similarities to their grandparents yet these women were Jewish. They began to process the resemblance of Jews and Muslims facial and bone structure within the context of North Africa. It helped to dismantle the idea of the “othering” of people that had gone on for decades.” This “othering” is present when Jews are seen as outsiders instead of part of Middle Eastern countries.\nThat transformation is what pushed Chama to continue to use her art for social transformation.. She received messages from strangers, both Muslims and Jews, about how her work made them feel seen and repaired something within them.\nMechtaly moved back to the UAE four and a half years ago. At the time the Abraham Accords were not even a dream. “I couldn’t even access Jewish websites for scholarship and research purposes at the time,” she recalls. I had studied conflict resolution and international relations at Brandeis, so I was interested in reconciliation work and activism for the inclusion of the history of minorities of the region in school curricula, especially because I don’t believe that peace can be sustainable without addressing historical grievances and narratives of trauma,” she states.\nChama Mechtaly’s concept for Moors and Saints involves blending Jewish and Islamic themes.\nMechtaly’s concept of her company Moors and Saints sprung from her experience living in Dubai. Moors and Saints became more than a jewelry design startup. Its purpose is to connect global cultures in meaningful ways with the goal to reveal powerful examples of tolerance and coexistence throughout history. Her aim is to continue the mission she embarked on through painting in a “language of luxury goods and fine jewelry,\nHer concept for Moors and Saints involves blending Jewish and Islamic themes similar to how Magen David inspired by jewelry models on Al-Azhar Mosque in Cairo. “I knew that people were ready to embrace the shared history between Muslims and Jews in the region even if they didn’t necessarily express it in public. This could bring dialogue and reconciliation and highlight the shared history between Jews and Muslims in the region without threatening or offending anyone.” she adds.\nMechtaly is a solid example of the hope of the Abraham Accords. Her life embodies this bridge between Jewish and Muslim history, the region and the mosaic of cultures from the Atlas Mountains to Jerusalem and the exquisite nightlife of Dubai.\nWhen she was studying at Brandeis, she exhibited in the Boston area and abroad. Chamaa spoke about Amazigh Jewry and the Berber Jews of North Africa. She had friends and colleagues who were baffled when she mentioned the Amazigh Jews… so many people were taken by surprise.\nThe responses from Chama Mechtaly’s works have been primarily positive however at times her work was considered political in North Africa and became the subject of censorship by government authorities. A work she created of the Moroccan Flag Revisited was originally censored yet five years later she was asked to exhibit in Morocco. Her work has been well-received since the news broke of diplomatic relations between Israel and Morocco. Now people are sharing the painting and displaying it as the profile picture of new WhatsApp groups, and talking about it on videos.\nIbn Khaldoun, a North African scholar of Islam, claims the Amazigh Jewish community in Morocco was the result of many historic factors.\nIbn Khaldoun, a North African scholar of Islam, social scientist, philosopher and historian who has been described as the founder of the modern disciplines of historiography, sociology, economics, and demography claims the Amazigh Jewish community in Morocco was the result of many historic factors. The wave of Jewish migration after the destruction of the Second Temple Mount and settling elsewhere along with local conversions expanded Jewish communities. Some theories say that Jews settled in the Maghreb region even before. The Amazigh community was pagan prior to the arrival of Jews in the Maghreb therefore conversions or interactions with Judaism go back for at least 3,000 years. Chama supports the idea that there is a deep connection between Muslims and Jews, this strongly influenced artistry and craftsmanship. “There is a museum in the south of Morocco that shows how this visual syncretism takes place, with the Star of David in jewelry or on old flags and Hebrew scripture on a wooden guillotine.” she says.\nMechtaly met many Jews in Dubai who came from Israel who were interested in Amazigh history. The mayor of Yeruham said her dream was to have a museum of Amazigh Jewry in Israel. When it comes to design, Mechtaly emphasizes how important it is to acknowledge the Andalusian and Sephardi history of the region. Without the influence and pairing of multiple religions, Moorish design and Andalusian architecture would not exist nor would the Golden Era of Islam or Golden Age of Hebrew poetry in Andalusia. Both were crucial to the creation of the golden moment in history referred to as Andalusia.\nExamples of the synthesis of Moorish design can be found in the Dohány Synagogue in Budapest and the Eldridge Street Synagogue in New York .\nExamples of the synthesis of Moorish design can be found in the Dohány Synagogue in Budapest and the Eldridge Street Synagogue in New York . Both were influenced by Moorish design when Jews embraced their Moorish architecture in the 19th and early 20th centuries in architecture. These Moorish synagogue designs were influenced by the Alhambra and the Mezquita; the grand Mosque–Cathedral of Córdoba.","Kiki Smith is an artist best known for sculpture and largely black-and-white or pale-colored prints inspired by feminist themes or Catholicism. She is not the first person one would think of to design an imposing stained glass window for an historic Orthodox synagogue. So it came as something of a surprise when the Museum at Eldridge Street announced November 23, that Smith, along with architect Deborah Gans, had been commissioned to do just that for the landmark Eldridge Street Synagogue building.\nThe window, on the eastern wall of the 120-year-old synagogue, has been missing since 1944, when the then cash-strapped congregation chose to have it removed because it was proving too costly to maintain. No records were kept of the original design, so Smith and Gans came up with a totally new concept that they hope will complement the eclectic interior, which is already a mix of architectural styles that includes Moorish, Renaissance, and Gothic. “I don’t have such a big ego that I had to make something completely confrontational,” said Smith. “You want to make something new but you want to be pragmatic. You don’t need to make it nostalgic, but at the same time it can reference what is already there.”\nSmith has experience of working with stained glass. But the collaboration with Gans, who Smith met when Gans designed her house, was crucial because of Gans’ experience working on commissions and her technical knowledge for the construction and framing of what is essentially a 16-ft glass wall.\nThe pair have asked the museum not to release sketches of the 16-ft circular window because the design has not been finalized. But they both said that it will continue the pattern of the surrounding wall and ceiling domes — a sky-blue background peppered with gold, five-pointed stars. At the center of the window will sit a Star of David, radiating out towards the wall in a swirl, like the stars, dust and gas that emanate from the center of a galaxy.\nGans said that she and Smith sat in the women’s gallery of the synagogue contemplating the eastern wall for some time. “There was a kind of sky with a field of stars already imprinted on the skin of the synagogue,” she said. “We wanted to extend that into the opening and then have it transformed by the presence of light.”\nThe Eldridge Street Synagogue, founded on the Lower East Side in 1887, was the first great Orthodox synagogue built in America by East European Jews. But it fell into disrepair after the majority of the community either died or moved to the suburbs. Today, a small congregation, Congregation Kahal Adath Jeshurun still uses the premises to pray.\nThe Museum at Eldridge Street is a non-profit which has its roots in a movement to preserve the synagogue that began in the 1970’s. In 2007, it announced — prematurely it seems — the completion of an almost 20-year, $18.5-million renovation of the synagogue. The window in the eastern wall is the final piece in the puzzle.\nAccording to synagogue minutes, the original window was a continual financial burden. It had a wooden frame, rather than a terra cotta frame like the stained glass window on the façade, and it demanded constant repair. It was long thought that a 1938 hurricane that struck New York destroyed the window. But museum deputy director Amy Stein-Milford said the hurricane merely damaged it.\nIn 1944, the congregation decided to replace the window with plain glass blocks arranged in a pillar formation. A December 19, 1944, letter from Knauer & Christensen, the firm that installed the blocks, states that the company would “remove the existing stained glass window as best as possible, saving the stained glass, and depositing same where directed by you within the premises.” No one knows if or how this directive was carried out.\nThe only record of the window that remains are documents in the synagogue archives and oral histories. Stein-Milford said that one document mentions the window’s original circular shape while congregants of the day remembered that its design was similar to the grand rose window on the synagogue façade.\nThough Smith has worked with stained glass many times in the past, it has never been on this scale. She said that she was also unused to designing something for a specific purpose. “I usually work from my own necessity,” she said, “not in response to situations in the world already.” Nevertheless, there were many aspects that drew Smith to the project. She said that she is very interested in religious and spiritual space. And much of her work in the past has made “loose and convoluted” references to the Old Testament.\nSmith and Gans’ original concept for the window was to emulate one of the synagogue’s 11 ceiling domes. They had hoped to make the window curve outwards in a dome shape, but Gans said the cost was prohibitive — the window is already budgeted at $400,000. Instead, the Star of David at the center of the window, which will measure about two feet in diameter, will project outwards slightly, giving it a three-dimensional aspect.\nThe stained glass has also been a complicating factor. Traditional stained glass comes in small sheets, of approximately 12 inches square, that are usually held together by lead. To avoid using lead for this window, individual stained glass plates will be glued onto one large piece of glass. Once the window is finished it will be mounted in the wall next spring. Then, one of the longest-running restorations in the city’s history will finally be complete."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:a04b9106-c5c1-45f8-a5fe-722a6b8d0a76>","<urn:uuid:3407c23f-dbf6-430d-b04b-ebb4771175a1>"],"error":null}
{"question":"How does Scotland's variable climate affect both sightseeing plans in the Campbell territories and recommended packing approaches?","answer":"In the Campbell territories, the tour covers diverse climatic areas from the Highlands to coastal regions, visiting locations like Glen Coe, Loch Awe, and the Great Glen. For packing consideration for such variable climates, it's recommended to use a layering approach with items like long-sleeved shirts with button-up sleeves that can be adjusted, and lightweight thermal underwear for colder areas. Additionally, multi-purpose items like a soft shell or lightweight fleece jacket are advised for weather variations. This allows travelers to adapt to temperature changes while keeping luggage minimal.","context":["Clan Campbell Tour\nWe have developed the Clan Campbell Tour for anyone fascinated by the history of the great Campbell clan and its involvement with Scotland’s story. It’s also for those who want to experience some of Scotland’s most dramatic scenery, and to get a flavour of local Scottish culture.\nThe tour has been designed by Lord Gray, whose seat is in Argyll and who is closely connected to the clan. Andrew Gray is a knowledgeable and experienced guide in his own right, and will, depending on timings, be available to lead the tour.\nEach tour is with a group small enough to access the best places to stay and the most interesting sites, but with a convivial feel. It is for a maximum of seven people, travelling in a car or nine seater minibus. It includes:\n- All accommodation (with breakfast)\n- Transport including ferries\n- Entry to key sites\n- Meeting local clan members and chiefs\n- A knowledgeable driver/guide\nThis seven night tour takes you into the heartland of Campbell country. We visit the territory of several of the clan's branches and their ancient castles. Our journey takes you through the most dramatic parts of Scotland, including Argyll, the Great Glen and Lochaber.\nThe tour is designed to fit around a working week for those who can’t take more time off, but the holiday can of course be extended at either end for those who want to spend more time exploring Scotland. We’d be happy to offer advice and ideas for an extended vacation.\nIf you are interested in this tour, please get in touch with preferred dates and group numbers. Prices are available on application and will depend on the time of year and numbers in the group. We can also help to bring groups together if you wish to travel with others.\nCastle Campbell in Dollar Glen\nExperience teaches us that people prefer to give themselves at least a full day to recover from the flight, adjust to the time zone and explore a little on their own. We are therefore including a night at a chic Bed and Breakfast close to Edinburgh city centre before you meet your tour guide.\nDay 1 with guide\nLeaving Edinburgh we cross the Firth of Forth, heading to Castle Campbell situated in the hills above the town of Dollar. This was the chief seat of power in the Lowlands for the Earls of Argyll until they moved to Argyll's Lodging, adjacent to Stirling Castle, which is where we travel on to next. We can have a tour of the castle, the Royal Residence of the Stuart Kings, then visit the Lodging itself. The plains of Stirling behind us, we drive northwest via Doune & Dunblane to Sherrifmuir and the site of the major battle of the 1715 Jacobite Rebellion. Thereafter we travel north through the Cairngorm National Park up towards Inverness, where we will stay.\nWe travel East along the Moray Firth and up on to the bleak moor at Culloden for a visit to the fantastic battlefield exhibition centre. Aside from any specific Campbell involvement, the Jacobite Rebellion of 1745 and its bitter end here at Culloden makes this site well worth seeing. Following this we travel on to Cawdor Castle, home of the Campbells of Cawdor. There is a range of curious history attached to it (including William Shakespeare...). The architecture and interiors are interesting and the gardens are beautiful. Following a pit-stop in Nairn, we make our way to the village of Auldearn, the site of a significant battle in the Covenanter Wars of the 1640s and a defeat for the Campbell Earl of Argyll.\nToday we travel southwards down the Great Glen along Loch Ness via Fort Augustus towards the West Coast & Argyll. We stop just north of Fort William at Inverlochy, to visit Old Inverlochy Castle and the site of another bloody battle in the Wars of the Three Kingdoms; an infamous rout of the Earl of Argyll's Covenanter forces. After this, we continue South, heading into Argyll and crossing the bridge at Ballachulish, we pass nearby the spot where Colin Campbell of Glenure was murdered in 1752. Just above Port Appin, we catch a view over Castle Stalker with its backdrop of the Firth of Lorn, heading on for a short visit to the 'Black Castle' of Barcaldine to round things off.\nToday follows a circular route, first heading north over the Connel Bridge, retracing the coast we finished with yesterday as far as Ballachulish before turning southeast, taking the road that leads us through Glen Coe. ( Pit-stop at the very good National Trust visitor centre ). Surrounded on all sides by increasingly craggy mountains, the route climbs steadily. We make a stop at a viewpoint across from 'The Three Sisters' peaks and hear about events leading up to the infamous Glen Coe Massacre of 1692. Climbing up out of the Glen we cross the bleak plateau of Rannoch Moor before making our descent down through the beautiful Glen Orchy and back Loch Awe-side where we visit St. Conans Kirk, the architectural curiosity built by a Campbell.\nThe day incorporates much of the Clan Campbell Argyll heartlands. We visit Dunstaffnage Castle on the edge of the Firth of Lorn, once a McDougall Clan seat but forfeit to the Campbells.\nHeading inland we make a brief stop in the village of Taynuilt, home to a little-known monument to Admiral Lord Nelson's naval victory at Trafalgar. Driving on to Loch Awe and rounding the head of the loch we make our next stop to take a walk out to the iconic ruins of Kilchurn Castle, built by Duncan Campbell of Glen Orchy. A narrow road follows along the southern shores of Loch Awe and we pause to view all that remains of Innischonnell castle, earliest stronghold of the line of Clan chiefs. We reach the southern tip of Loch Awe at Ford, re-joining the main road. There is an option to see the standing stones in Kilmartin Glen before travelling back up the coast towards Oban.\nThe final day saves a major Campbell gem till last. Leaving the West coast, again taking the road round the shores of Loch Etive & Loch Awe, as we salute Kilchurn once more, we turn south to Inveraray. Here we visit the ancestral seat of the Clan Chiefs for a tour of the castle. With a pit-stop offered at the Loch Fyne Oyster Bar, we then follow the military road through to Loch Lomond and so to the Glasgow area. Onward travel from here or returning again to the Edinburgh area and a final night in a comfortable hotel.\nPrice, Transport, Guide, Accommodation and Shopping\nThe tour will be for a maximum of seven people travelling in a nine seater minibus. Prices on application - they will depend on dates and numbers on the tour.\nBreakfast is included throughout. At the other meals there is a range of bar meals, snacks and more formal options available to choose from.\nLuggage- we suggest a medium sized case plus hand luggage for easy access at your seat. If you are continuing your trip please ask us about left luggage facilities in Edinburgh.\n- Bed and Breakfast for all nights\n- Services of expert tour guides\n- Entry to castles (occasionally, by mutual consent, we change one castle for another)\n- Meeting key clan figures including the chance of a chief or two!\n- Air Fares\n- Lunches and dinners, drinks and snacks\n- Trip insurance\nThe balance is payable eight weeks prior to the start of the tour.\nWe strongly recommend that you take out trip insurance in case of unforeseen circumstances.\nPrice varies according to dates of travel. If you would like to know, more about the trip then send an email to me, Diana Gray","Tips for Packing Light When Travelling\nFirst, Decide What to Pack\nWhen travelling, it's always a challenge to fit everything you want to bring into a suitcase. While there are certainly tricks to squeezing everything into a small space, the easiest way to pack light is to take less stuff in the first place!\nIn order to do this, assemble all the clothing you think you'll need during your holiday, before you start packing.\nNow, before you put one single thing in your case or backpack, take a look at what you've laid out and pick out some items you can wear on the journey. This approach will avoid the most common travel mistake—packing everything you'll need, then wearing something else as a “going away” outfit. That outfit likely won't be worn again till you come home, and it's just dead weight! Sure, the climate where you’re going may be very different to where you start, but that doesn’t have to be a problem if you think laterally.\nSay it’s cold at home and you’re going somewhere tropical. If you wear a thick sweater or padded jacket on your outward trip, it’ll be useless at your destination. Instead, wear a long-sleeved tee-shirt, and add a fine wool cardigan or sweater, a rainproof/windproof jacket and a pashmina or scarf.\nEach of these things, individually or in combination, could be useful on your holiday (nights can be cold, even in the tropics!).\nChoose \"Double Duty\" Clothes\nApplying the principle of \"double duty\" like this is the main secret to saving space. Avoid items of clothing that can only be worn one way, because chances are they’ll only be worn once or twice and won’t “earn their keep”. For women, stick to separates you can mix and match to produce different outfits. If you're going to one major evening event, then an evening gown is fine - but for something like a cruise, where you have several special nights, bustiers and skirts/pants will give you more different outfits in far less space.\nOn a recent trip to the Middle East, our best investment (for both myself and my guy) was undoubtedly convertible long pants (“double duty” again!). Be careful with fabrics—many convertible styles are made of quick-dry synthetic fabrics, which claim to be cool but often aren't! These are made of soft synthetic material. That means they won't crease like cotton and will dry much faster. Most importantly, they are also breathable, unlike some travel pants which can be sweaty. Columbia convertible travel pants\nPacking for a Cruise\nOur other most-worn items were lightweight long-sleeved shirts with button-up sleeves. Roll the sleeves up when it's hot, roll them down when it's cool—and unlike my husband, I had the added bonus of being able to tie mine as a midriff top!\nIf you’re really worried about the cold, today's thermal underwear is featherlight and scrunches down into nothing—however it may be too warm for milder climates. Unless you're going somewhere really cold, consider taking lightweight singlet tops or t-shirts which can be worn under or over shirts as an extra layer.\nFor a multi-purpose jacket, a soft shell or lightweight fleece is a good buy.\nNow you’ve chosen your clothes, it’s time to pack them.\nRoll, Don't Fold!\nRolled clothes are easier to fit into odd spaces in your suitcase, and won't crease nearly as much as if you fold them. Pack big items first, and fill in the gaps with rolled-up undies or socks.\nDon't roll up belts or ties. Leave them unfurled, and tuck them around the edges of the suitcase. That way they'll take up almost no space at all, and you'll be able to find them easily too.\nA Different Approach for Touring\nWhile rolling maximises the amount of clothing you can squeeze into your case, searching for clothes can turn your whole case into a glorious muddle. If you're touring, that means you'll have to do a total repack every morning!\nThe solution is travel packs. You can buy specialist travel cubes, but I just buy the biggest size of Ziplock bag from the supermarket. They're not nearly as sturdy as the proper travel packs, but I always carry a few spares in case I burst one or two. Sort your clothes into categories, and roll and pack each category into a separate bag.\nBecause you can't make use of every nook and cranny, using bags means you won't fit quite as much into your case. But the joy of being able to get up and pack your case in minutes for that early morning start—priceless!\nI don't recommend the vacuum bags (where you suck out the air after packing), unless you don't mind walking around in wrinkled clothes. Besides, if I'm touring I don't have time to muck around with sucking out the air every morning!\nShoes are always a problem, because they’re heavy and take up space. If you can, wear your heaviest/bulkiest shoes on the outward journey, so you don’t have to fit them in your luggage. You may be reluctant to do that (who wants to wear heavy shoes on a long trip?), but you can take a pair of light slippers or socks that you can change into on the plane (you can stash your shoes in the overhead locker). Just make sure your shoes are not too tight, or you may have trouble getting them on again at the end of the trip!\nNever pack empty shoes. Find small items to put inside them (socks, hairbrush, pens, ties etc). Put your shoes in shoebags so they don’t dirty your clothes.\nIf you're staying in hotels, there's no need to take towels. Sure, hotels say you shouldn't use their towels at the pool or beach—but that’s only because they’re worried about them getting lost. I’ve used room towels at beaches and pools all over the world, and never had a problem.\nIf you don’t want to take the risk, ask the hotel if they have pool or beach towels—many do.\nIf you feel absolutely lost without your own towel, pack a microfibre travel towel instead (but check the size - most are much smaller than a regular towel).\nToiletries for Travel\nAt the time of writing, there are severe restrictions on the amount of liquid you can carry when travelling. Your liquid or gels must all be packed in 3-oz bottles, and they all have to fit in one small pouch. For most people, that's mostly a problem when it comes to toiletries.\nThe solution is to look for toiletries that aren't gel or liquid. For instance, I don't pack cleanser or toner - instead, I take make-up remover wipes. Sunscreen and self-tanning wipes are good, too. Dove or Neutrogena soap is solid, and just as gentle on your skin as a liquid cleanser.\nThe principle of double duty applies here, too. I always pack a conditioning shampoo, so I don’t need conditioner, and I choose a body sunscreen which is also a good moisturizer.\nFor the face, I take a good quality SPF15 tinted moisturiser, so I don’t need separate face moisturiser, sunscreen and foundation. A bronzer can be used as blusher and eyeshadow. Soft eyeliner and lipliner pencils take up no space and can be used as eyeshadow and lip tint.\nIf you're staying at hotels, you may not need to pack shampoo, conditioner or body lotion at all, as there's likely to be a free supply in the room. It's worth asking.\nIf you're decanting, be careful not to overfill the bottles, because the contents will expand with the changes in air pressure—and you don’t want sunscreen all over your clothes. Always put your toiletries inside a plastic bag, in case of spillage.\nThe restrictions on toiletries can be a nuisance, but you can also be seen as an opportunity! I've never travelled with lots of toiletries, even on a long holiday. For me, part of the fun of going overseas is trying new things, so I love the excuse to buy some French shower gel or an Italian face cream!\nFor my last overseas trip, which lasted six weeks, I travelled with one medium-sized wheelie duffle bag and a carry-on bag. My husband had one medium wheeled suitcase and a shoulder tote. That trip took us from the heat of Africa to the chill of Northern Europe, and we never had any trouble keeping warm (or cool).\nWe’ve all heard the saying “pack everything you think you need, then halve it”. I’ve never been able to apply that rule—but then again, thanks to my own “rules”, I’ve never had to!\nMore Tips on Packing Light\n- 7 Reasons to Travel With One Bag\n7 Reasons to Travel With One Bag. There is a great debate among travelers about how to pack for a trip. Should you pack everything but the kitchen sink so you're sure to have everything you need, or strip down all the superfluous ...\n- Rick Steves' Europe: Packing Light and Right\nPlanning tips to help maximize your time and money spent in Europe.\n- Travel Light with One Bag!\nleisure and business travel packing list - travel light - carry-on luggage\n- How to Pack Light\n- Cruise Packing Tips\nCruise Packing Tips from Cruise Diva's Cruise Planner\n© 2007 Kate Swanson"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:6b8af0f8-4b7c-46ce-aaba-86e8edaad786>","<urn:uuid:9476bd2e-9c37-40ff-a83b-a3536d051bc7>"],"error":null}
{"question":"How does online journalism training combine flexibility and hands-on practice? Looking for info on remote learning + practical experience","answer":"Online journalism training through platforms like Poynter's News University offers 24/7 availability with over 400 free and affordable courses that can be taken remotely without traveling to St. Petersburg. The training maintains high levels of interaction through virtual environments, allowing students to practice tasks repeatedly at their own pace while directly interacting with trainers. Research has shown that this type of immersive learning technology creates engaging environments that enable practical experience through detailed 3D imagery and life-like representations, making it an effective way to develop technical skills through experience.","context":["What is The Poynter Institute?\nThe Poynter Institute is a global leader in journalism. It is the world’s leading instructor, innovator, convener and resource for anyone who aspires to engage and inform citizens in 21st century democracies. We train reporters, broadcasters, documentarians and storytellers to pursue excellence in media and public discourse. Our faculty of Pulitzer Prize and Edward R. Murrow award winners teach seminars both in-person at our campus in St. Petersburg, Fla. and virtually host e-courses, webinars and video tutorials. Poynter.org is one of the world's most visited websites for news about the news business and our e-learning site, News University, hosts one of the world's largest online journalism curricula.\nWhat is NewsU?\nPoynter's News University is one of the world's most innovative online journalism and media training programs ever created. From multimedia techniques to writing and reporting, we've got more than 400 free and affordable courses. As the e-learning project of The Poynter Institute, NewsU extends Poynter’s mission as a school for journalists, future journalists, teachers of journalism and anyone interested in the craft and values of storytelling.\nBegun in 2005 with generous support from the John S. and James L. Knight Foundation, Poynter's News University currently has more than 400,000 registered users, including a growing percentage from outside North America.\nWho can benefit from being Poynter Prepared?\nAnyone can benefit by being Poynter Prepared. If you want to learn new skills or improve on existing skills in writing and editing, you can benefit. We also have a variety of courses available in subjects such as design, graphics, typography, ethics, leadership, software and technical training.\nWhat is the difference between the three levels?\nGenerally speaking, the higher the membership levels, the more you get.\nHow do I check my profile to see my course status and information?\nWhere can I find a list of all the classes that Poynter offers?\nWhat credit cards do you accept? Do you accept checks?\nWe accept Visa, MasterCard, Discover and Amex credit cards. We also accept checks as payment.\nCan I retake courses that I have already completed?\nAbsolutely! You may feel the need to take a Webinar or any of our courses another time to refresh your memory. Once you purchase the course, it is yours to retake as much as you like. However, though you can retake the Certificate Program self-directed courses as many times as you'd like, you can only retake the assessments three times.\nAre scholarships available?\nYes, for specific learning opportunities. Check the course description page for info on whether scholarships are available.\nHow do I receive my NewsU promo codes?\nYour promo codes will be sent to you via email after purchase.\nCan I combine Training Points or member discounts?\nTraining Points are tied to your account at Poynter's NewsU and may be combined with promo codes. Poynter values its relationships with all of our training partners. To that end, members of many media organizations are eligible for discounts on our programs as a member benefit. However, these discounts cannot be combined if you are a Poynter member as well as a member of one of our participating partner organizations.\nDo I have to travel to St. Petersburg, Fla. to be trained?\nNo. Although there are great educational opportunities at the Institute, you can get a majority of our training right from your computer. Seminars that take place in St. Petersburg, Fla. are often available online as a live-stream.\nAre there other training partnerships with Poynter and other journalism organizations or media companies?\nPoynter also has created customized programs for over 20 organizations to meet strategic training needs. Its training partners include Google, Gannett, McClatchy, Journal Media, The Associated Press, National Geographic, Univision and the Institute of International Education's Fulbright Scholar program. For more information on training partnerships or custom training, click here.\nDoes the Poynter Prepared membership automatically renew or will I receive notification?\nYou will receive a reminder email 14 days before your membership expires. We will not automatically renew your membership without your permission.\nWhat if I am not in the United States?\nIt does not matter what country you live in. Just make sure your system meets the minimum technical requirements that can be viewed at the bottom of each course page.\nI’m a Poynter 365 Member, how do I arrange my coaching schedule and who can I receive coaching from?\nWhen and how do I get my badge?\nYour digital badge will be sent to you the moment you sign up for one of our membership plans. You can then download it and post it on your LinkedIn, Facebook, or any other site you would like.\nMy company has a training partnership with Poynter. Does that make me a member?\nNo. Training partnerships are different from our membership program.\nI have been affiliated with Poynter in the past. How do I become a member?\nWhile you are certainly an alum, this new program was created to benefit both past, present and future affiliates of Poynter. This requires you to sign up for membership on the membership page.\nI registered, but I haven’t received my confirmation email\nPlease contact email@example.com or call us at (727) 821-9494\nWhat formats are available for my coaching sessions?\nPersonal coaching sessions are available through: Skype, FaceTime, Google Hangouts and via phone.\nI am a journalism educator. Are group discounts available for my students or colleagues?\nPlease contact firstname.lastname@example.org or call call us at (727) 821-9494\nI work in a big newsroom. How do I refer my colleagues?\nIn your profile, the \"Refer a Friend\" section can be used to enter the email address of anyone you want to refer to the membership program.\nI’ve attended a Poynter seminar, Webinar or an event at Poynter. Does that make me a member?\nUnfortunately, this does not make you a member, but we hope you enjoyed the course and would still like to join the Poynter family through our membership program.\nHow often is Poynter training available to me?\nPoynter training is available to you 24 hours a day, 7 days a week. Poynter also adds new training to its course list frequently. Go here to view our upcoming courses.\nHow do I upgrade my membership?\nPlease contact email@example.com or call us at (727) 821-9494\nHow can I unsubscribe from the newsletters?\nPlease email firstname.lastname@example.org and request to be unsubscribed or simply click the unsubscribe button at the bottom of the latest newsletter.\nAre there opportunities to train in St. Petersburg?\nGo here to view our training opportunities at The Poynter Institute in St. Petersburg, Fla. We can also create a private training for you and your team.\nI have more questions. What should I do?\nContact us at email@example.com or call us at (727) 821-9494 for any additional questions.","TECHNICAL AND PRACTICAL TRAINING FOR EMPLOYEES PRESENTS SEVERAL DIFFICULTIES, FROM THE COSTS INVOLVED IN TRAINING WITH REAL MACHINERY TO THE HEALTH AND SAFETY RISKS THAT SUCH TRAINING CAN POSE.\nImmersive learning technology provides a valuable opportunity to engage in practical training in an easier, safer and more flexible way and, unlike other alternative methods, maintains a high level of interaction with the learning content.\nA research study conducted by the Virtual Human Interaction Lab at Stanford University, “The Effects of Fully Immersive Virtual Reality on the Learning of Physical Tasks”, highlights the positive impacts that virtual reality can have on technical training.(1) Its findings show that virtual reality technology obtained better results than traditional video methods in the learning of practical tasks and participants in the study also reported feeling a higher social presence within the virtual environment.\nResearch has shown that repeating practical tasks reinforces learning. Immersive learning environments allow students to repeat tasks as many times as they like at their own pace and, importantly, away from the social pressures of a real classroom. For training in high-risk situations, virtual reality provides a much safer environment in which to make initial mistakes. Like face-to-face training, virtual training also allows students to interact directly with their trainer and environment. Detailed 3D imagery provides life-like representations of objects and their surroundings, giving students a very ‘real’ training experience.\nTechnical training in an immersive learning environment\n“Learning is the development of experience into experience” (James, 1892).\nThe learning and understanding of practical tasks relies on experience and virtual reality training is highly experiential and immersive. Students can interact with objects and machinery and view them up-close, as well as experiencing how to operate them. Effective training is also reliant on students’ interest and motivation (2); immersive learning technology can create stimulating and engaging learning environments for students, increasing their motivation to learn. Such environments are flexible and programmable, meaning that they can be tailored to meet individual needs.\nAccording to Fabrizia Mantovani (3), students learn more effectively when they engage directly with learning content and build their own understanding of it. Immersion in and interaction with learning content encourages the active engagement and motivation of students.\nExperience, repetition and interaction are important processes in practical training. Virtual reality training provides this in a controlled and programmable environment. The application of virtual reality with a live trainer yields particularly high motivation from students and allows for technical tasks to be carried out under guidance in a safe and engaging environment.\n(1) Patel, K., Bailenson, J.N., Hack-Jung, S., Diankov , R., & Bajcsy , R. (2006). The effects of fully immersive virtual reality on the learning of physical tasks. Proceedings of PRESENCE 2006: The 9th Annual International Workshop on Presence. August 24 – 26, Cleveland, Ohio, USA.\n(2) Bricken, M. (1991). Virtual reality learning environments: potentials and challenges. Human Interface Technology Lab (HITL) Washington Technology Center, University of Washington\n(3) Mantovani, F. Virtual Reality Learning: Potential and Challenges for the Use of 3D Environments in Education and Training in Towards Cyberpsychology: Mind, Cognition and Society in the Internet Age, Riva, G. and Galimberti, C., 2001"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:b902456a-dbdc-4f2f-a5af-9483c55c1889>","<urn:uuid:fad1c0af-b656-4505-8236-99aff755e94c>"],"error":null}
{"question":"Could you please explain how the cryptographic security features compare between the AVR Xmega and AURIX microcontrollers? I'm particularly interested in their encryption capabilities.","answer":"The AVR Xmega and AURIX microcontrollers both offer cryptographic features, but with different capabilities. The Xmega includes AES and DES crypto engines as basic encryption features. In contrast, the AURIX's Hardware Security Module (HSM) provides more comprehensive security with an AES-128 hardware accelerator, secure key storage, random number generation, and a firewall-separated secure computing platform. The AURIX HSM also offers additional features like 256-bit password protection for debugger access and compliance with automotive security standards like SHE HIS and Evita Medium.","context":["Introduction: Build an AVR Xmega Prototyping Board!\n- Direct Memory Access (DMA) controller capable of transferring data between memories and peripherals (ie between the USB and USART) with minimal MCU intervention\n- An Event System allows peripherals to trigger actions in other peripherals (think interrupts) without the need for the MCU to get involved directly. Peripherals supported include ADC, DAC, DMA, and all the ports.\n- AWex - Advanced Waveform Extension for extremely precise waveform generation\n- Hi-Res - High Resolution Extension for AWeX and timers.\n- IR Communications module\n- AES and DES crypto engines\n- External Bus Interface to fast-track external memory\n- An Analog-to-Digital converter and Digital-to-analog converters\nNot having a PDIP version makes it more difficult to get into the Xmega line because to prototype and program your Xmega you will need specific hardware that interfaces to the SMD (surface mount) chips. But if you don't get into the Xmega line you are missing out on such good peripherals and coding fun, so what's a guy to do?\nThis instructable will walk you through making a complete, working AVR Xmega programming and development board. This board will allow you to connect Xmega chips, program them, then put them in your device in the field (or in your house!).\nStep 1: Requirements\nThe Xmega programming and development board requires a few pieces of hardware to complete the build that you may or may not have lying about your place. First, the design was etched onto 1oz double-sided copper clad and a silk screen layer was then layered over the top. This entails having a 3.25\" x 3.75\" double-sided copper clad board (a 1/2oz board works well, too), your favourite etchant, soldering equipment, etc.\nThe second part includes the chip carrier, which can be purchased from futurelec.com. You may need the TQFP44 carrier for ATXmega32A4 and other TQFP44 chips, while the TQFP64 carrier can be used for the ATXmega64/128/256A3's. From the website I mentioned in this paragraph, the cost is $1.20 and $1.30, respectively. That's very economical for an adapter board.\nFinally, you'll need the electronic components that I use in this design. The components range from double-row female sockets to 10uF tantalum capacitors to 3mm LED's. To avoid listing every part in my design here, I've attached a BOM at the bottom of the page.\nI've skipped mentioning anything about software as that's dependent on your style and flow. I prefer using NetBeans IDE with custom-compiled AVR GCC toolchain on a Solaris UNIX system, although AVR Studio, NetBeans, and Visual Studio are options on Windows. This is all ancillary to our hardware build that we'll get into when you turn the page!\nStep 2: ATXmega Programming Board Design\nThe DesignMy primary design for the board came from suggestions in Atmel's AVR042: Hardware Considerations guide as well as eyeballing different reference designs. The board accepts DC power and has an on-board regulator for clean 3.3V power. I decided to use the internal 32MHz oscillator and only include a 32kHz watch crystal for real time clock management. It also has support for USART-to-USB via an FTDI chip on a USB BUB from Moderndevice.com for $14, so pin headers are on the board for that. I'm a big fan of visual indication of action, so I've included a green 3mm LED to indicate power and a red 3mm LED connected to the reset switch to verify a hard reset of the chip.\nMy primary goal, though, was to produce a board that allowed access to most all pins without having to setup the many decoupling capacitors needed for each new chip to be programmed. As mentioned, the programming interface is PDI because it doesn't support SPI and I don't have a JTAG debugger/programmer (it's on my wishlist) so there's no JTAG support on the board.\nIncluded below are pictures of the latest design along with Eagle CAD schematic and board files. I've also created a panel of bottom, mirrored top, and silkscreen layers at 300dpi (consider printing at 1200dpi) in PDF format. This is what I use to print out on transparency or toner transfer paper, so I've included it as a convenience. Take a minute to look at the layout of the board.\nIdioms of Hardware DesignIf you've taken a minute to look at the board you've probably noticed that it can be broken into little pieces that I like to call Hardware Design Idioms (or Patterns). These are little circuits that you make over and over again for each (or many) designs. I've partitioned the whole design into the following idioms:\nPowerThe power subsystem is the component I make the most on my boards because I've found pulling too many mA from USB can cause serious problems (I burned a USB hub once). Plus having its own power subsystem allows you to just hook it up to a DC wall wart from 5V to ~20V and run it stand-alone while you program. An external source of power is necessary if you're using the AVRISP mkII as it doesn't supply the board with power like some of the other programmers out there.\nThe basic design of the power component is simple and straight-forward. A DC jack accepts a plug that delivers power with a rather large polarized capacitor across the positive and negative rails. Run (+) into an LDO regulator of fixed 3.3V followed by two more filtering capacitors at 1uF and 0.1uF. They do not need to be polarized as the schematic suggests.\nThe final (+) rail out of the last capacitor is a very stable, regulated 3.3V. You may choose to use through-hole components over the SMD components I've used and that's totally up to you. I use what I have on hand for the most part. I've also used a 27uH inductor on the AVCC port to make the analog power a little cleaner.\nI've also included two other power constituents: a two-pronged header for exporting power, and a 3-pin jumper used to indicate whether the power is coming from the DC jack or from the USB. It's your option. Picture below.\nResetI almost always include a reset circuit in my designs. It's handy. This hardware pattern consists of the following:\n- Pull up !RESET to Vcc\n- Connect one side of tactile switch to the !RESET with the other side connected to a resistor/LED pair going to ground.\n- Strap a 0.1uF capacitor between both sides of the switch (ie both pins you used).\nPush the reset button, the red LED comes on, and release. The ATXmega chip is hardware reset and reboots. See the picture below.\nDecouplingIn analog designs, decoupling (or bypass here) is used to shunt high-frequency signals on the power line to ground. This is found at the analog Vcc input. In digital designs, the purpose is different. The amperage draw from the MCU and onboard devices is an average and when many pins are in use and operation, the current draw can be hundreds of mA or more. The capacitors placed across the Vcc and ground act as mini reservoirs of charge that can supply a port the current it needs when the power supply is a distance away. It's optimal to place these capacitors as insanely close to the port they are servicing as possible.\nIn my design, you'll find the decoupling capacitors under the carrier chip (that is, between the dual-row sockets This inclusion is important at the ATXmega, AVR32, and ARM levels because many of these chips have many Vcc and AVcc connections that must all be decoupled. It's a pain to do it manually....just don't do it. Do it on the programming board and be done with it.\nUSBI often like to have an outlet for debug output. An LCD can be too restricting for getting lots of debug data from your firmware. Therefore, I often include a 6-pin right-angle pin header that interfaces to the Modern Devices' USB BUB module. It allows you to simply write to your RS232 USART and is passed over USB via an FTDI chip. On the PC, I then use AVR Terminal to visualize my debug data. This is invaluable (for me, at least).\nYou may choose to remove this if you don't have the USB capabilities, although for $14 the USB BUB is a great buy. Picture below.\nCrystalContrary to the hardware design found in many AVR designs, a 16MHz or 20MHz external crystal isn't really used for the system clock on Xmegas. I use the internal 32MHz oscillator and only include a 32kHz watch crystal for use in real time clock timekeeping. It's not necessary to use, but it's on board if you need timekeeping functionality. Again, it's parallel capacitive and uses two small (usually 18pF to 22pF) capacitors to GND.\nAs an added benefit, the PLL can use the external 32kHz crystal for runtime compensation of temperature and drift, thereby further enhancing the accuracy of the 32MHz oscillator.\nProgrammingNow, what would a programming board be without a programming interface? Here we use a simple 2x3 male pin header; the same as used for SPI programming. Check below for the pinout of the PDI interface. I simply provide power and make the two appropriate PDI connections and call it a day. PDI eliminates the need for SPI isolation resistors.\nSocketsSo, for the ATXmega programming/devel board, you'll find it bristling with socket headers. There are four (2 in parallel) dual-row 2 x 8 female headers to accept the 2x8 male headers from the Xmega carrier board. I've also tried to bring out as many MCU pins to headers for access in development and these can be found in the single row female headers around the outside edges. These are marked with a silk screen layer indicating what pin is brought out to which socket.\nThis wraps up the hardware idioms. The complete design is an amalgamation of these patterns with a few ancillary side-items (like an inductor filter for analog power) thrown in to complete the design.\nStep 3: Build Your Board\nYour mission, should you chose to accept it, is to print to toner transfer paper (with or without your modifications), transfer to your copper clad board, etch and drill -- or follow whatever established etching protocol you use. Although I've successfully etched 0.12 traces, you will notice I enlarged the traces and pads for easier homemade etching. When you are finished the board should look something like the pictures below.\nAt this point (or before I silkscreen), I take steel wool and buff both sides while wearing nitrile gloves to give the copper a super shine and remove any built-up oxidation or oil from fingerprints.\nPin your vias first (since homemade etching doesn't through-hole plate, I've found it more effective to solder a wire from top to bottom layers. Next place your SMD components, if you have any, followed by resistors, capacitors, switches. Finally, place your taller components, such as the headers and power jack. Before you power it, place standoffs in the corners.\nYour finished board might look like the one below.\nStep 4: Carrier Board\nSoldering TQFP44/48/64 chips is surprisingly simple.\n- Wipe off the carrier board to remove dirt, dust, and fingerprint oil.\n- Put a light coat of solder flux over the pin pads on the carrier board\n- Place the MCU in the correct orientation on the board (notice where pin 1 is) and hold it down. I use the head of an eraser on a pencil because it has good grip but is soft on the chip.\n- After ensuring all pins are aligned on their correct pads, solder one corner.\n- Get solder on your gun and run it across the pins quickly. Don't worry about cross connects. Make sure all pins have solder.\n- Take solder wick and wick up any excess solder on all four sides.\n- Check your work with a loupe or high-power magnifying glass.\nNext step: get it goin' on!\nStep 5: Attach Carrier and PDI\nYou're now ready to attach the carrier board to the female counterparts on the board. Seat it nice and firmly. Connect a DC power source and the power light should light up. Push the reset button and the red LED should flash.\nNext connect your PDI programmer to the PDI interface. In the picture below you'll see the carrier on the programming board as well as a pic of the board connected to AVR Studio via an AVRISP mkII where I query the device for its signature.\nThe only thing left is for you program the chip to do whatever you are using the Xmega for. There are plenty of socket ports to play with and extend your own design.\nStep 6: Conclussion\nIn this instructable, I've shared my knowledge and some insight into building your own complete AVR ATXmega programming/development board. This will allow you to break into the low-power, full-featured Xmega chip market to use in your own custom designs.\nI hope this instructable was helpful and useful to you. As always, I am open to suggestions for improving this and any of my instructables. Feel free to leave comments, send me an email, or catch me on iRC on freenode.net as nevdull.","AURIX Security Solutions\nInfineon’s AURIX 32-bit microcontroller family, with its embedded Hardware Security Module (HSM), is a perfect fit for automotive applications, where specific security functionalities are required. Typical examples of such applications are tuning protection, immobilizer, secure on-board communication etc. Infineon not only offers a scalable portfolio of compatible AURIX devices, with integrated HSM, but also the necessary SW packages as well as support services. This provides our customers with everything they need to fulfill the security requirements of their applications.\nTypical automotive security applications, which can be addressed with AURIX microcontrollers, are:\n|Tuning Protection||Immobilizer||Secure-on-board communication|\nAURIX™ Security Solutions - Get more Information\nInfineon’s AURIX 32-bit microcontroller family offers a wide portfolio of compatible devices, with embedded Hardware Security Module (HSM), which offer cost efficient solutions for all typical automotive security applications.\nHardware Security Module (HSM)\nHSM provides a secure computing platform, consisting of a 32-bit CPU, special access-protected memory for storing the cryptographic key\nand the unique subscriber identifiers, a hardware accelerator for the state-of-the-art AES-128 encryption that can be operated in different modes\nand pecific hardware for generation of random numbers. A firewall separates HSM from the rest of AURIX microcontroller.\n- Secure Platform\nHSM provides a secure platform, separated from the rest of the microcontroller by a firewall, thereby creating a trusted execution environment.\n- Security Standard Compliance\nAurix HSM fulfills SHE HIS and Evita Medium standards as well as provide some additional functionalities.\n- Backward Compatibility\nAurix security solutions are backward compatible to security SHE HIS implementations in previous TriCore based microcontroller families.\n- Security Differentiation\nCustomized secure OEM or Tier1 crypto apps can be processed within trusted HSM execution environment and therefore allow independent HSM specific SW code review in reference to the huge application host SW from multiple parties. This helps to harden the security level by reliably avoiding potential security backdoors.\n- Convergence of security and safety\nAURIX microcontrollers address both functional safety as well as IT-security requirements, making sure those are properly integrated and not conflicting with one another.\n- Secure Process\nInfineon can provide a secure personalization flow. 1st personalization step usually happens at the Tier1, where initial HSM SW and optional transportation key(s) are injected to the ECU. 2nd personalization step happens at the OEM, where a car specific Individual key(s) are injected. AURIX HSM offers device specific, individual random read-only key. Read-only key can be used for injected keys and make them invisible for the application SW layer.\n- Secure Failure Analysis\nFor the purpose of preventing unpermitted debug access, AURIX HSM offers 256 bit password for debugger access protection. It is possible to create car specific debugger password, which can be stored in OEM/TIER1 data base or generated by secret algorithm. Destructive Debugger Entry functionality opens debugger access but initiates a persistent destructive action - device gets inoperable in native ECU car environment.\nInfineon’s AURIX 32-bit microcontroller family offers a wide portfolio of compatible devices, with embedded Hardware Security Module (HSM), which offers cost efficient solutions for all typical automotive security applications. The SHE+ driver controls the hardware security peripheral in the HSM domain and interacts to the TriCore host core. SHE+ offers the AUTOSAR CRY interface to integrate the HSM security features into an automotive application including interface to AUTOSAR, communication from TriCore to HSM and vice versa, key storage functionality and security peripheral drivers.\nInfineon can provide basic trainings on automotive security as well as detailed insights into:\n- specific security implementations for different automotive applications\n- Hardware Security Module (HSM) functionalities and use cases\n- HIS SHE and HSM SHE+ software functionalities and use cases\nThrough its network of technical experts, Infineon can support its customers throughout their development process.\nFirst level of support is provided by local field application engineers, second level more complex topics addressed by\ndedicated automotive security experts.\nDedicated on-site consulting can also be organized, to help customers reduce development time and costs.\nCustomer Specific Implementation\nInfineon can also help with customer specific implementation of software security functionalities in automotive applications.\nThrough so called Premium Consulting Support, requirements are defined jointly between OEM, Tier1 and Infineon.\nThereafter Infineon takes over the implementation and qualification of agreed upon modules/functionalities.\nPlease check the Microcontroller Mediacenter for more Videos\nThe Infineon \"HOT\" hands on training series is dedicated to support your design.\nThe training material shows you examples for your application.\nTo execute the trainings you need to order the specific kits shown in the \"HOT Shopping List\".\nThe training material contains:\nComplete project files for Keil and DAvE Bench environments\nPowerpoint slides to guide you through each topic step by step\nAll examples have been built as described in the powerpoint slides\nFinden Sie eine Antwort auf Ihre Frage\nTechnical Assistance Center (TAC)\nInfineon begrüßt Ihre Kommentare und Fragen.\nWenn Sie Fragen zu unseren Produkten haben, füllen Sie bitte das folgende Formular aus. Ihre Anfrage wird an einen entsprechenden Spezialisten gesendet, der so bald wie möglich eine Antwort senden wird.\nSie erhalten eine Bestätigungs-E-Mail um Ihre Adresse in unserem System zu validieren. Jede angehängte Datei in Ihrer Antwort, die uns helfen kann, Ihre Anfrage bestmöglich zu beantworten, ist willkommen."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:8be24598-028f-4aff-8176-c9a5767e8be8>","<urn:uuid:f659601f-fb05-4b6e-a538-65102dc3977e>"],"error":null}
{"question":"How do written business communications differ across cultures, and what are the cultural considerations for hand gestures in international business settings?","answer":"Written business communication is formal and binding, with key factors including the writer, content, language used, and purpose. It offers benefits like precise accuracy, permanent record-keeping, and legal validity, though it can be slower and costlier. When conducting international business, cultural considerations for hand gestures are crucial as they vary significantly across regions. For example, in Mexico, payments should be handed directly to the person rather than left on the counter to show respect. In the Middle East, the left hand should never be used for eating or handling documents as it's considered unclean. Similarly, common gestures like thumbs up can be offensive in the Middle East, Nigeria, and parts of South America, while in Germany it simply indicates the number one.","context":["Forms of Business Communication8th February 2020\nThe word verbal means ‘connected with words and use of words.’ Any communication using words is verbal communication.\nWords are the most precise and powerful sets of symbols. Words denote as well as connote meanings. That is why all serious or formal communication is usually in words. Words, as we are all aware, can be written or spoken.\nThus, verbal communication can further be divided into two types:\n(a) Oral Communication\n“A wound inflicted by speech is more painful than a wound inflicted by a sword”. As the term itself suggests, communication through the spoken word is known as oral communication. Of the working time spent in verbal communication, 9 % is in writing, 16 % in reading, 30 % in speaking and 45 % in listening.\nIn oral communication, words should be chosen very carefully so that what they connote has the precise shade of meaning. The sender of the message or his representative is usually the speaker, while the receiver or his representative, the listener. Listening is also an important aspect of oral communication.\nFactors in oral communication\n(i) The speaker\n(ii) How he speaks\n(iii) What he speaks\n(iv) To whom he speaks\n(v) Whether he receives a feedback\nPre-requisites of oral communication\n(i) Clear and proper pronunciation of words\n(ii) Clarity and exactitude\n(iv) Right tone\n(v) Right style and vocabulary\nMerits of oral communication\n- Saving of time and money\n- Immediate feedback\n- Saves paperwork\n- An effective tool for exhortation\n- Builds a healthy climate\n- Best tool during emergency\nDemerits of oral communication (limitations)\n- Greater chances of misunderstanding\n- Bad speaker\n- Ineffective for lengthy communication\n- Lower retention rate\n- No legal validity\n- Difficult to fix responsibility\n(b) Written communication\nA message constitutes written communication when it is put in “black and white.” It is a formal type of communication. The sender of the message or his representative constitutes the writer.\nWritten communication is usually considered binding on business organizations and is often used as evidence. Technological advancement has enlarged the gamut of written communication through email and other such facilities.\nFactors in written communication\n(i) The writer\n(ii) The content\n(iii) The language used\n(iv) The purpose of the communication\n(v) The style adopted – formal or friendly\n(vi) The receiver\nPre-requisites of written communication\n(i) How much to put in writing\n(ii) What to leave out\n(iii) When to stop\n(iv) When to convey\n(v) By what means to convey\nMerits of written communication\n- Precise and accurate\n- Easily verified\n- Permanent record\n- Suitable for lengthy and complicated messages\n- Responsibility can be easily fixed\n- Has legal validity\nDemerits of written communication\n- Slower method of communication\n- Further delay if clarifications are required\n- Leads to too much of paperwork\n- Always a possibility of ambiguity or lack of comprehensibility\n- Costly in terms of money and man-hours\n- No flexibility\nScientific analysis has shown that body movements and gestures constitute 55% of effective communication. Hence, non-verbal communication merits great consideration.\nNon-verbal communication involves things such as gestures, posture, physical appearance etc. It takes place without written or spoken words.\nNon-verbal communication is those messages that are expressed by means other than linguistic. While you can refuse to speak or write, it is impossible to avoid behaving non-verbally.\nTypes of Nonverbal Communication\n- Eye contact\n- Facial expressions\n- Posture and body orientation\n- Body Language\n- Space and Distance\n- Personal Appearance\n- Visual Communication\n- Eye contact\nEye contact, an important channel of interpersonal communication, helps regulate the flow of communication. And it signals interest in others.\nFurthermore, Eye contact with audiences increases the speaker’s credibility. Teachers who make eye contact open the flow of communication and convey interest, concern, warmth, and credibility.\n- Facial expressions\nThe face is an important communicator. It is commonly said that face is the index of the mind. It expresses the type of emotions or feelings such as joy, love, interest, sorrow, anger, annoyance, confusion, enthusiasm, fear, hatred surprise, and uncertainty.\nFacial expressions are indicated through the mouth (open, wide or closed), eyelids (raised or lowered), nose (wrinkled or relaxed), cheeks (drawn up or back) and the forehead (lowered or raised).\nWithin the facial area, eyes are especially effective for indicating attention and interest. However, interpretations of facial expressions differ from culture to culture.\nSmiling is a powerful cue that transmits:\nThus, if you smile frequently you will be perceived as more likable, friendly, warm and approachable.\nSmiling is often contagious and students will react favorably and learn more.\nIf you fail to gesture while speaking, you may be perceived as boring, stiff and un-animated. A lively and animated teaching style captures students attention, makes the material more interesting, facilitates learning and provides a bit of entertainment.\nHead nods, a form of gestures, communicate positive reinforcement to students and indicate that you are listening.\nGestures are movements of the arms, legs, hands, and head.7 Some authors opine that gesture is the deliberate body movement as because they express specific and intentional meaning.\nFor example; a wave of the hand has a specific meaning-“hello” or “good-bye”; a forefinger and a thumb touching to form a circle have the meaning -“ok”.\nAlike facial expressions, interpretations of some gestures also differ across cultures.\nFor example, in Europe, raising thumb is used to convey that someone has done something excellent while in Bangladesh the same gesture means something idiotic.\n- Posture and body orientation\nYou communicate numerous messages by the way you walk, talk, stand and sit.\nStanding erect, but not rigid, and leaning slightly forward communicates to students that you are approachable, receptive and friendly.\nFurthermore, Interpersonal closeness results when you and your students face each other.\nSpeaking with your back turned or looking at the floor or ceiling should be avoided; it communicates disinterest to your class.\n- Body Language\nBody language is another widely recognized form of non-verbal communication. Body movements can convey meanings and message. Body language may take two forms of unconscious movements and consciously controlled movements.\nFor example; When a person is bored, he may gaze around the room rather than look at the speaker or he may shift positions frequently.\nWhen a person is nervous, he may bite his nails or mash hair. These are usually made unconsciously. On the other hand, leaning forward toward the speaker to express interest is the case of conscious body movements.\n- Space and Distance\nSpace and distance are significant non-verbal tools in the case of organizational communication. A spacious and well-decorated room indicates a person’s position in the organization hierarchy and external people gets a message about his importance and authority only by visiting his room.\nDistance is another communication tool, which expresses the degree of intimacy and individual acceptance.\nCultural norms dictate a comfortable distance for interaction with students.\nYou should look for signals of discomfort caused by invading students’ space. Some of these are:\n- Leg swinging\n- Gaze aversion\nTypically, in large college classes space invasion is not a problem. In fact, there is usually too much distance.\nTo counteract this, move around the classroom to increase interaction with your students.\nIncreasing proximity enables you to make better eye contact and increases the opportunities for students to speak.\nThis facet of nonverbal communication includes such vocal elements as:\nFor maximum teaching effectiveness, learn to vary these six elements of your voice.\nOne of the major criticisms is of instructors who speak in a monotone. Listeners perceive these instructors as boring and dull.\nStudents report that they learn less and lose interest more quickly when listening to teachers who have not learned to modulate their voices.\nHumor is often overlooked as a teaching tool, and it is too often not encouraged in college classrooms. Laughter releases stress and tension for both instructor and student.\nYou should develop the ability to laugh at yourself and encourage students to do the same. It fosters a friendly environment that facilitates learning.\nObviously, adequate knowledge of the subject matter is crucial to your success; however, it’s not the only crucial element.\nCreating a climate that facilitates learning and retention demands good nonverbal and verbal skills.\nTouch is a widely used form of non-verbal communication tool.\nBy touching, one can express a wide range of emotions. However, the accepted modes of touch vary depending on the gender, age, relative status, intimacy and cultural background of the persons.\nFor example, in the context of our culture, when one touches you from the back of the examination hall, your understanding is that he wants to know something.\nSilence is a powerful tool for communication. It may have a positive or negative meaning.\nIn a classroom, silence indicates that students are listening carefully and attentively. In the same way, through silence one can communicate his lack of interest or a failure to understand.\nFor example, silence often indicates that a person receiving instruction does not understand the action required or sometimes silence indicates consent.\n- Personal Appearance\nAppearance is also an important non-verbal communication tool. Appearance includes dress, hair, jewelry, makeup, belt buckles and so on.\nAppearance indicates the degree of importance or interest a person conveys to an occasion. By means of uniform, we can identify a student, a doctor, a lawyer, a police officer, etc.\nIn an organization, one’s dress is keenly observed to see whether it conforms to accepted standards of appearance. As an example, workers may wear different clothes when they are on strike than they do when they are working.\nA symbol is something which represents an idea, a physical entity or a process but is distinct from it. The purpose of a symbol is to communicate meaning.\nFor example, a red octagon may be a symbol for “stop”.\nOn a map, a picture of a tent might represent a campsite. Numerals are symbols for numbers. Personal names are symbols representing individuals. A red rose symbolizes love and compassion.\n- Visual Communication\nWhen communication occurs by means of any visual aids, it is known as visual communication.\nThus, communication that occurs through facial expression, personal appearance, gesture, posture, printed picture, sign, signal, symbol, map, poster, slide, chart, diagram, graph, etc. is called visual communication.\nFor example, to indicate ‘danger’, we use red sign; to mean ‘dangerous’, we use a skull placed between two pieces of bone put in crosswise fashion; to indicate ‘no smoking’, we use an image showing a lighted cigarette with a cross mark on it.\nImportance of Nonverbal Communication\nSome important points expressing the importance, necessity, advantages or functions of non-verbal communication are discussed below:\n(i) Well Expression of the Speaker’s Attitude\nVarious non-verbal cues of the speaker like physical movements, facial expression, a way of expression, etc. play an important role in expressing the inner meaning of the messages in face-to-face conversation and interview.\nFor example, the facial expression of the speaker indicates his attitude, determination depth of knowledge, etc.\n(ii) Providing Information Regarding the Sender of the Written Message\nThe format, neatness, language and the appearance of the envelope used in a written message send a non-verbal message regarding the writer’s tests, choice, level of education, etc.\n(iii) Expressing the Attitude of the Listener and Receiver\nSometimes the appearance of the listeners and receivers conveys their attitudes, feelings, and thoughts regarding the messages they have read or heard.\n(iv) Gaining Knowledge about a Class of People\nClothing, hairstyle, neatness, jewelry, cosmetics, and stature of people convey impressions regarding their occupation, age, nationality, social or economic level, job status, etc.\nFor example; students, policemen, nurses, etc. can easily be identified through their dresses.\n(v) Gaining Knowledge about the Status of a Person\nNon-verbal cues also help to determine the relative status of persons working in an organization. For example, room size, location, furnishings, decorations, lightings, etc. indicate the position of a person in the organization.\n(vi) Communicating Common Message to All People\nIn some cases, non-verbal cues can effectively express many true messages more accurately than those of any other method of communication.\nFor example; use of red, yellow and green lights and use of various signs in controlling vehicles on the roads.\n(vii) Communicating with the Handicapped People\nNon- verbal cues of communication greatly help in communicating with the handicapped people.\nFor example; the language of communication with the deaf depends on the movements of the hands, fingers, and eyeball.\n(viii) Conveying Message to the Illiterate People\nCommunication with illiterate people through written media is impossible. There may also be some situations that do not allow the use of oral media to communicate with them.\nIn such situations, non-verbal methods like pictures, colors, graphs, signs, and symbols are used as the media of communication.\nFor example; to indicate danger we use red sign and to mean dangerous we use a skull placed between two pieces of bone put in a crosswise fashion.\n(ix) Quick Expression of Message\nNon-verbal cues like sign and symbol can also communicate some messages very quickly than written or oral media.\nFor example; when drivers of a running vehicle are to be communicated that the road ahead is narrow or there is a turn in the road ahead, we generally use signs or symbols rather than using any written or oral message.\n(x) Presenting Information Precisely\nSometimes quantitative information on any issue may require a lengthy written message. But this quantitative information can be presented easily and precisely through tables, graphs, charts, etc.","Body language of the world: Body signs to avoid in travel...\nBody language of the world: A traveller's guide to avoiding faux pas\nSarah Bennett & Lee Slater\nAugust 10, 201110:21AM\nIn the Middle East always eat with your right hand. Eating with your left is considered unclean. Picture: Flickr user hiyori13\nIn Japan bowing is a sign of respect. Picture: Flickr user alf melin\nEVERY country has its cultural quirks. To avoid being the subject of tut tuts and disapproving looks while you're travelling, we take you through the top taboos from Japan to the Middle East.\nThe most common greeting in Japan is the bow; the timing, posture and movement of which should reflect sincerity, respect and graciousness. A beautiful bow is often compared to a ripe rice stalk swaying in the wind: the more mature the person, the deeper the head is lowered. An improper bow hints at a lack of education and maturity. As a foreign visitor you are not expected to emulate this ritual faithfully - a gentle nod will do. -Lonely Planet Japanese Phrasebook\nPersonal space boundaries vary from country to country, but in Latin America they are set closer than in Anglo-Saxon countries. People stand closer when talking to one another, and casual touching of the arm or shoulder during conversation is not unusual. Good friends will typically greet each other with an abrazo (hug) or beso (kiss), and it’s quite normal to see people of the same sex walking down the street arm in arm.\n-Lonely Planet Latin American Spanish Phrasebook\nIn Mexico, when paying for something, place your cash or credit card directly into the hand of the person you’re dealing with. This applies in cafes and restaurants, as well as hotels and shops. Leaving payment on the counter can be interpreted as a sign that you don’t respect the person enough to have contact with them. -Lonely Planet Mexican Spanish Phrasebook\nThe traditional greeting of New Zealand Maori is the simultaneous pressing of noses and forehead, known as the hongi. The word directly translates as smell or sniff, but is more evocatively described as an exchange of ha, the breath of life. Such greetings are commonplace on marae, the open space in front of a Maori meetinghouse where visitors are welcomed, nowadays with a handshake at the same time as the hongi. -Hirini Moko Mead, Tikanga Maori (Huia, 2003) & Lonely Planet South Pacific Phrasebook\nThe hongi is a traditional New Zealand Maori greeting. Picture: Lonely Planet\nWhen ‘no’ gets mistaken for ‘yes’ there can be all sorts of trouble, but you can always rely on a shake of the head or a nod, can’t you? Not in Bulgaria, where the nod means no and the shake means yes. To complicate matters further, polite Bulgarians will often try to compensate by reversing their normal habit. For absolute verification, familiarise yourself with the words da (yes) and ne (no). -Lonely Planet Bulgarian Phrasebook\nBefore you whip the big thumbs up out of your pocket to convey that ‘all is well’ or ‘I’d like to hitch a ride’, be warned that you may be about to make a boo-boo. In some parts of the Middle East you may as well be flipping the bird, and the gesture has a similarly negative meaning in Nigeria and parts of South America. In Germany, you will be indicating the numeral one, which will be fine unless you really want to order two.\nMeanwhile, eating with your hand is acceptable in the Middle East, as long as it’s the right one! The left hand is considered unclean. Practicing this custom is particularly important at communal dinners, where many hands may come into contact with shared food, but it’s also important when shaking hands or giving and receiving gifts. -Roger Axtel, Gestures: The do’s and taboos of body language around the world\nJust don't raise your thumb in the Middle East. Picture: Lonely Planet\nAs you would expect in a country that came up with the word etiquette, it is easy for foreigners to commit faux pas in France. At the dining table the odds increase dramatically. To avoid offence, keep your hands on the table, not in your lap. Break up your bread roll into nibbles, rather than shoving the whole thing in your gob, but beyond that try to avoid eating anything with your fingers. Peel fruit with a knife and eat it with a fork; avoid man-handling sandwiches if you can. -Lonely Planet French Phrasebook\nIn India - as in much of Asia - it is the feet that are considered unclean. Do your utmost to avoid touching any part of someone else’s body with your foot or shoes, and if you do so, apologise straight away. Pointing the soles of your feet at someone is also offensive, so don’t prop your feet on chairs or tables while sitting, and take care how you arrange yourself when sitting on the floor. -Lonely Planet Hindi, Urdu & Bengali Phrasebook\nThe ultimate beau geste (gracious gesture) is one that is used in every country on earth. Although in some cultures in certain circumstances it can have negative connotations, it is seldom misunderstood and can be used in many situations. It conveys an array of positive emotions, and as such is the great bridge builder between peoples of the world. It involves only the eyes and the mouth, and so requires minimal effort. It is particularly useful in sticky situations. It is so powerful it is thought to release endorphins into the body that generate a feeling of euphoria. It is, of course, the smile."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:55f98065-8ee9-4450-a2f7-5786c55dded5>","<urn:uuid:43448c08-edca-41cd-af2f-7d6b11e809df>"],"error":null}
{"question":"I'm interested in recycling - what's the difference between recycling aluminum cans versus using compost for recycling organic waste?","answer":"Aluminum can recycling and composting represent different types of recycling with distinct benefits. Aluminum can recycling is highly energy-efficient - a recycled can returns to the shelf in 60 days, uses 95% less energy than producing new cans, and recycling one can saves enough energy to power a 100-watt bulb for almost four hours. Composting, on the other hand, recycles organic waste into a natural material that improves soil quality. When microorganisms break down organic residue, they create compost that enhances soil structure, provides slow-release nutrients, improves water retention, and helps suppress plant diseases. While aluminum recycling primarily saves energy, composting creates a valuable product that directly benefits soil and plant health.","context":["For the Animals. For the Earth.\nIn addition to our commitment to the exhibition and conservation of endangered animal species, Cheyenne Mountain Zoo also strives to be a green business. That’s why we have multiple programs for onsite recycling and conservation of energy and natural resources.\nNot only do we adhere to tight conservation standards here at our home, but we also try to help you do the same by providing comprehensive conservation information and resources. It is our hope that you will join us in taking action—for the good of us all.\nWhat YOU can DO.\nRecycle. Stop the Waste.\nThere are lots of ways you can make a difference in our natural world—and recycling is one of the easiest.\nEven recycling your aluminum cans saves more energy than you might know:\n- A used aluminum can is recycled and back on the grocery shelf as a new can in as little as 60 days.\n- Making new aluminum cans from used cans takes 95 percent less energy, and 20 recycled cans can be made with the energy needed to produce one can using virgin ore.\n- Recycling one aluminum can saves enough energy to keep a 100-watt bulb burning for almost four hours or to run your television for three hours.\n- Throwing away an aluminum can wastes as much energy as pouring out half of the can’s volume of gasoline.\n- Last year, 54 billion cans were recycled, saving the energy equivalent of 15 million barrels of crude oil—America’s entire gas consumption for one day.\nDiscover more ways your recycling can help the environment—and the Zoo:\nCarpool, ride a bicycle or use public transportation whenever possible. If you do drive, here are a few tips to help your vehicle run more efficiently:\n- Keep your engine tuned up and performing to its standards.\n- Replace air filters regularly to maintain fuel efficiency.\n- Keep tires inflated to achieve the best fuel efficiency.\n- Avoid unnecessary idling and car trips whenever possible.\nEliminate water waste so there’s enough to go around. Here are a few things you can do at home to preserve our planet’s water supply:\n- Turn off the faucet while you shave, brush your teeth and lather up your hands.\n- Wash only full loads of laundry to save water and electricity.\n- Fill the kitchen sink with soapy and clean water when washing dishes by hand, instead of letting the water run.\n- Completely fill the dishwasher before running it to save water and electricity.\n- Take short, five-minute showers instead of baths to save about 40 gallons of water.\n- Keep an eye out for plumbing and irrigation leaks, and then fixing them promptly.\n- Plant only native, drought-tolerant plant species throughout your home landscape and use mulch to minimize evaporation.\n- Irrigate efficiently through wise sprinkler head selection, which can ensure that water is directed to exactly where it is needed and control the amount of water put on the ground at one time.\n- Water deeply, not frequently. In new landscapes, wean new plants off of frequent waterings after their second year and give periodic deep waterings instead.\n- Use a bucket of soapy water or shut-off nozzle for your hose when washing your car.\nDonate Your Vehicle\nCall Vehicles for Charity at 1 866.628.CARS (2277) or complete the online donation form at www.vehiclesforcharity.org.\nPlease select Cheyenne Mountain Zoo as the recipient of the proceeds from the sale of your vehicle. Paperwork and arrangements for towing your vehicle will be handled at no expense to you. For more information, call 719-633-9925, x115, or e-mail email@example.com.\nProceeds from the salvage sales will help the Zoo!\nGreen Consumer Action.\n- GET A LIVE TREE! – Believe it or not, a live tree is actually a relatively eco-friendly choice, so long as you’re conscious about where it goes once the holidays are over. According to the National Christmas Tree Association, nearly all cut holiday trees are grown on tree farms – meaning their stock is replenished yearly and forests aren’t hurt by choosing a cut tree. Go to earth911.org and enter your ZIP code to find out where to have your tree recycled. Or even better, get a LIVE one and plant it !\nFake trees are a different story, requiring a significant amount of energy and petroleum-based materials to manufacture. Plus, artificial trees are often manufactured overseas and shipped thousands of miles before they reach our living rooms.\n- BE BRIGHT! – Instead of buying more standard holiday lights to replace bad strings, opt for energy-efficient light strings. When they’re made using light-emitting diode bulbs, LEDs, they’re 90% more efficient than traditional holiday lights. LEDs also last longer – up to 10,000 hours compared with 5,000 hours for standard incandescent bulbs. AND- you can go one better by getting light strands with a small SOLAR panel to power those LEDs!!\n- REDUCE, REUSE, RECYCLE, REPURPOSE – This tip is an oldy but a goody. It just requires being a responsible consumer, user, and disposer.\nREDUCE – Once you have pared down your consumption, be sure to buy responsibly. Look for things made of recycled materials, that support your local economy, with minimal packaging, or that help support conservation causes.\nREUSE – Be creative about how and when to reuse.\nWhat you can’t reuse, RECYCLE! Visit the EPA’s Reducing and Reusing Basics for more information on how to conserve during the holidays and year-round.\nIf you are an online shopper, check out links below for some great environmentally conscious gift items and ideas:\n- BORROW FROM NATURE – Think of how your grandmother or great or even great-great grandmother decorated during the holiday – with natural evergreen boughs cut from evergreen trees (holly, pine, magnolia) handmade ornaments, and bowls of fruit or pine cones. With a backdrop of seasonal poinsettias and cyclamen they create a warm, fragrant and welcoming feel – and they aren’t made of petroleum and chemicals and shipped from across the world.\n- GIFT WRAP – Start your own recycling program for wrapping.\n- Use old posters, comics, colorful shopping bags, old calendars, even old maps are cool wraps!\n- Design your own gift-wrap by using a paper grocery or department store bag and adding decorations such as drawings, stamped patterns, or pictures cut from magazines.\n- Let the kids do the designing. It will keep them busy on stormy days.\n- If you do use store bought wrapping paper, buy the kind with recycled content (the more post consumer, the better).\n- When you receive gifts, be sure to save the ribbons and bows. For additional tips on how to reduce your gift wrapping waste, visit http://www.ciwmb.ca.gov/publiced/Holidays/.\nRecycle Cell Phones & Printer Cartridges\nUsed Cell Phones\nRecycle your old cell phones at the Zoo—and we’ll all benefit. The Earth will have fewer toxic, heavy metals in its landfills. The Zoo, in partnership with Eco-Cell, will get $1 to $50 per phone to put toward conservation efforts. And you, will receive $2 off the regular Zoo admission price for each cell phone you turn in to us for recycling. Limit is one discount per cell phone. This offer is not valid for special events, and can not be combined with other offers or discounts.\nOn your next visit, just place your old cell phones in the bins at the Zoo admissions booth. It’s a win for everyone!\nEach of us can make a difference in saving energy. Do your part to conserve energy at home by following these simple energy-wise practices—and save money at the same time:\n- Turn your thermostat up two degrees in the summer and down two degrees in the winter.\n- Turn off the air conditioner when no one is home or install a programmable thermostat.\n- Close curtains or blinds in the summer to keep the sun from heating your house.\n- Replace incandescent bulbs with compact fluorescent bulbs. They last longer, give off less heat and save money on your energy bill. Bulb varieties and availability are expanding all the time.\n- Turn off lights and appliances when they’re not in use and unplug them when you’re gone for long periods of time; standby power still pulls energy.\nItems we purchase in our everyday lives have an impact on the environment. Here are some things to think about:\n- Buy products with certified sustainable palm oil.\nPalm oil is a product in many everyday products, and its production is seriously threatening the lives of orangutans in Southeast Asia. Learn more about the Palm Oil Crisis\n- Select ocean-friendly seafood.\nThough you may be far from the ocean, you can still have an impact on its residents. Whether you’re buying seafood in a store or a restaurant, know which seafood to choose and why. Visit Seafood Watch for more.\n- Stop drinking bottled water.\nBuy a durable water bottle and reuse it instead of using disposable plastic bottles that never decompose in landfills.\n- Try reusable and bio-compostable paper goods.\nOn your next picnic or camping trip, take reusable tableware instead of disposable paper products, or use bio-compostable paper ware.\n- Replace plastic bags with canvas.\nUse canvas tote bags while shopping and reduce the use of plastic and disposable bags.\n- Recycle old cell phones and their batteries.\nInstead of sending your old cell phones—and their toxic metals—to your local landfill, bring them to the Zoo for recycling. Also, coltan, a metal in cell phone batteries, is mined in endangered gorilla habitat, contributing to their decline. Visit Eco-cell for more.\n- Refill or recycle printer cartridges.\nReduce waste by recycling your used printer cartridges instead of throwing them away. Buy recycled cartridges, too, and close the loop!\n- Choose recycled paper products.\nBuy recycled paper towels and toilet paper to close the loop on the recycling process.\nWaste Disposal & Compost\nThink Twice about Trash.\nAvoid polluting our environment by disposing of your household waste items appropriately.\n- Reduce, reuse and recycle whenever possible. Learn about recycling in El Paso County, Colorado. View El Paso County Recycling Directory PDF .\n- Dispose of items containing mercury with care. Mercury appears in many household items such as fluorescent light tubes, mechanical thermostats, silver-bulb thermometers, watch batteries and clothes irons. Visit El Paso County Hazardous Waste to learn more about disposing of them properly.\n- Practice responsible medication disposal to help reduce their environmental impact.\nNationally learn more at http://water.epa.gov/scitech/swguidance/ppcp/upload/ppcpflyer.pdf.\nFor Colorado Springs area drug disposal information visit CHSP’s Colorado Clean Program.\n- Reduce or avoid the use of pesticides on your lawn. If you do use them, follow their directions carefully.\n- Go organic! Compost food items and use them on your garden as fertilizer. Learn more at www.howtocompost.org.\nGet the Scoop on Poop.\nDoo you know the best way to keep annoying deer away? From our yard to yours, Zoo Doo is made from Cheyenne Mountain Zoo big cat feces and sold by the pound. Gardeners swear by this all-natural deer deterrent to protect their plants and trees. Even better, your purchase supports the zoo!\nWhat’s in Zoo Doo?\nZoo Doo contains Cheyenne Mountain Zoo tiger, leopard and African lion feces. Mountain lion feces is not used to prevent attracting mountain lions to your yard. Please note, Zoo Doo is a deer deterrent, not a fertilizer.\nDoes it smell?\nYou may notice an initial odor, however, it’s generally unnoticeable to humans after a short time. The effect on deer lasts much longer.\nHow long does it last?\nThe effects of Zoo Doo vary. Some gardeners may only need to purchase Zoo Doo once a year, while others may need to purchase more after a few weeks.\n$2.00/pound; 15-pound minimum\nAvailable Tuesday – Saturday, by appointment only.\nCall 719-633-9925 x 150","Lawn and Garden Shop\nWHAT IS COMPOST?\nCompost is a natural organic material produced when microorganisms break down organic residue. This process occurs continually in nature, resulting in a sweet, earthy smelling brown material called compost. Compost adds food for many organisms and an enormous diversity of organisms to your garden soil when you use it as a soil amendment. It is a rich source of organic matter. Although compost contains plant nutrients, it is typically characterized as a soil amendment rather than as a fertilizer because most of the nutrients are not readily available and only become available slowly, over many years.\nThere are several ways to acquire and use compost to benefit the soil and plants in your own yard and garden:\nThe best way to improve the soil is to mix in plenty of compost or other organic matter before planting. Thoroughly mixing these materials deep into the soil helps retain water and air, and provides nutrients to the plant roots.\nWhen: Mix in organic matter with existing soil before planting perennials, lawns, trees and shrubs, each time annual beds are replanted, and when dividing perennials or repotting container plants.\nHow: Use a shovel or digging fork to mix amendments into the top 6 to 12 inches of soil. Amend large planting areas not just small holes for each plant.\nHow Much: Amount of compost recommended to be tilled into each 100 square\nfeet of planting area. Use these following guidelines.\nIn clay soils: 8 cu. feet (0.3 cu. Yd.) = 1\" layer of compost.\nIn sandy soils: 13 cu. feet (0.5 cu. Yd.) = 1 ½\" layer of compost.\nIn sandy soils: 24 cu. feet (0.9 cu. Yd.) = 4\" layer of compost.\nSoil Testing: For a list of local laboratories who can test the amount of sand, silt and clay in your soil call your County Extension Service.\nWhat: Different types of organic amendments may provide special benefits for certain plants or soil types, as the chart below shows. Any clean organic amendment will improve the soil. The best advice is to use what is reasonably priced, plentiful and easy to get. Use as Mulch for Vegetable and Perennial Gardens - Mulch means placing compost (or another material) on the soil’s surface around a plant. Mulching with compost is especially beneficial because earthworms and other soil life move through the mulch and help carry these materials down into the soil. Placing mulch around plants also helps to limit weed growth, reduce evaporation, moderate fluctuations in soil temperature, and reduce soil erosion.\nUse to Top-dress and Renovate your Lawn - Spreading a thin layer of compost on your lawn can do wonders for the soil underneath. This technique works best if you first aerate the lawn.\nIn the spring or fall when the soil is moist, use an aerator tool (you can rent one) to remove plugs of soil and thatch from your lawn.\nNext, using a spreader tool or a rake, spread a thin layer (about ½ \") of compost over the lawn. The grass should be standing up through the compost after application, not bent over or buried.\nYou can also mix grass seed in with the compost to encourage new growth and fill in bare spots where weeds might take hold.\nConsider a Retrofit If the soil under your lawn is unhealthy, one of the best actions you can take is to retrofit your lawn. Grass thrives in 8-12\" of healthy soil. In addition, seed-grown lawns are more sustainable in healthy soil than sod-grown lawns because roots grow directly into the soil rather than through layers of potentially different soil types. Retrofitting a lawn with healthy soil and reseeding may be worth it-in fact, several local studies have indicated that a lawn grown on a deep layer of healthy soil pays for itself in 5-7 years based on water savings alone!\nWhat Does Compost Do? Improved soil structure creates passageways in the soil for air and water. In heavy clay soils, the addition of compost enhances the physical make-up of soil which improves soil structure, porosity and bulk density to create a better environment for plant growth.\nSupplies Slow-Release Nutrients to Plants without using fertilizers Compost is a good source of nutrients including nitrogen, phosphorus, potassium, sulfur, and microorganisms essential for plant growth. Since compost is made of relatively stable organic matter, nutrients are slowly made available for root uptake and. In this way, nutrients are less likely to be lost through leaching.\nHolds Moisture and Reduces Erosion Compost has a large capacity to hold water-many times its own weight. This reduces water loss and leaching in soil. The soil-binding properties of compost result from its humus content which acts like a glue, holding soil particles together, making soil resistant to erosion and improving moisture retention.\nImmobilizes and Degrades Pollutants Compost has the ability to bind heavy metals, pesticides, herbicides and other contaminants, reducing both their leachability and absorption by plants. The soil microorganisms that compost supports also help break down pesticides, fertilizers and hydrocarbons. This same binding effect allows compost to be used as a filter for storm water and other runoff.\nProvides Organic Matter Compost supplies organic matter to the soil which increases the presence of microorganisms. The activity of microorganisms promotes root development and assists in the extraction of nutrients from the soil. It also encourages the growth of earthworms and other macro-organisms, whose tunneling increases water infiltration and aeration.\nSuppresses Soil-Borne Diseases and Plant Pathogens Plant disease is influenced by both the level and type of organic matter as well as the microorganisms present in soil. Detrimental organisms like oot-eating nematodes, a number of specific plant diseases and several lawn diseases are suppressed by microorganisms found in compost.\nHow good is the compost? The quality of the compost used for soil enhancement is important. Commercial compost should have a sweet, earthy smell. Compost should meet your Department of Ecology’s guidelines for Grade A compost.\nSuggested Reading: Soil Biology Primer, Soil and Water Conservation Society, Revised 2000. See web site for ordering information - www.swcs.org.\nThe Rodale Book of Composting, Deborah L. Martin and Grace Gershumy, editors, 1992.\nWorms Eat My Garbage, Mary Appelhof, Flower Press, 1982. Recycle With Earthworms: The Red Wiggler Connection, Shelley C. Grossman, Toby Weitzel, Lucy Warren (Editor), and I. Donnabella, Shield’sPublications, 1997\nLet An Earthworm Be Your Garbage Man, Home, Farm and Garden Research Associates, Shield’s Publications, 1954.\nThe Worm Book, Loren Nancarrow and Janet Hogan Taylor, Ten Speed Press, Berkeley, CA, 1998.\nUse these Browser Boxes to locate books on composting, building garden soil, plant identification books, find any book, or any product at Amazon.com.\nUse these browser boxes by choosing a category from their pull-down menu. Enter a keyword where applicable. Then click on Go!.\nHOW TO USE:\nHOW TO USE:\nOrdering your books and all products at Amazon.com through Lübeck Haus & Bookstore is convenient, safe and easy, guaranteed.\nThis web site was first published February 24, 2002.\nThis page was last updated September 18, 2015."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:114bdb4a-c9fc-4dcc-b555-0eb11448ac58>","<urn:uuid:222cf42e-1638-4571-8bd4-b4d1d8fcdfef>"],"error":null}
{"question":"What are the main differences between contour farming and conservation agriculture in terms of their soil management approaches?","answer":"Contour farming and conservation agriculture differ in their soil management approaches. Contour farming focuses on ploughing along natural contours of sloped land to create furrows and ridges that control water flow and reduce erosion by up to 50%. In contrast, conservation agriculture emphasizes three main practices: limiting or eliminating tillage, using crop rotations, and maintaining permanent organic coverage on fields to maximize soil organic matter and reduce CO2 release. While both methods aim to conserve soil, conservation agriculture specifically targets improving soil structure and organic carbon levels, whereas contour farming primarily addresses water runoff control on slopes.","context":["Can conservation agriculture (CA) help farmers in sub-Saharan Africa build resilience to the problem of climate change? Professor Andy Dougill believes it is possible, but that more coordinated planning and coherent policy support across sectors nationally, on a district level, and to a range of local farmer groups and community leaders is needed.\nFor over a decade now, most development organisations have been advocating conservation agriculture as a ‘climate-smart agriculture’ approach. The idea behind conservation agriculture is that farmers maximise organic matter in their soil and reduce CO2 release by limiting or eliminating tillage, using crop rotations and by keeping a permanent organic coverage on the fields. In return, the argument goes, they get improved soils that are able to hold water for longer and sustain yields in dry years, making maize harvests more resilient to the impacts of climate change.\nThere is growing evidence globally to suggest that no-till farming works when good crop residue management practices are followed, but that local context remains critical, and further research insights, such as those being provided by the GCRF-AFRICAP project, are essential. Why is the evidence base still so poor, given that conservation agriculture – sometimes billed as ‘farming God’s way’ – has been promoted to farmers for so long?\nWebinar on 23 Feb: Improving soil health through climate-smart agriculture\nA threefold problem\nPart of the problem is the patchy take up of conservation agriculture across countries such as Malawi, Zambia and Zimbabwe. Many farmers are reluctant to change to this method of farming or, once started, fail to maintain it after a donor-supported project leaves. The reasons for this are threefold: practical, cultural and institutional.\nOn the practical side, good conservation agriculture can be more labour intensive at certain times of the year, requiring more weeding and more work to prepare the ground and sow a crop. Leaving organic matter on the surface, such as maize stalks, can encourage pests such as mice, which are deterred when the stalks are burned. Because the benefits take a while to be seen and are largely evident only in drought years, farmers can easily be put off by more immediate changes in their farming practices.\nCulturally, many farmers hold the view that conventional ploughing of land and creation of ridges and furrows is what epitomises good, modern farming. It is imperative that such views are questioned and that locally appropriate land management practices are discussed and supported by farmers, groups, community leaders and government extension services.\nAt an institutional level, take up of conservation agriculture is often incentivised through provision of additional fertiliser and new seed, which makes it hard to identify the impact of the change in farming method alone. Malawian studies have shown that when the incentives end, for the reasons above, farmers often revert to their former methods.\nAlthough conservation agriculture has been promoted for many years, this has been done by many different organisations – governmental and non-governmental – in various ways and for diverse reasons, resulting in confused messages as to why farmers should take up the practice and sometimes even what the practice should consist of.\nRecent studies – conducted under auspices of the GCRF-AFRICAP project – looking at how policy on conservation agriculture is implemented in Malawi highlight the need for better communication and collaboration between all relevant parties within a country: government departments, local government and NGOs. Effective implementation of conservation agriculture requires government departments responsible for agriculture to move outside their traditional responsibilities and link with departments working on climate change adaptation, meteorology, health, and water distribution.\nGiven these limitations, what reliable evidence do we have of the benefits that conservation agriculture can bring, particularly in relation to climate resilience? A recent paper has shown that conservation agriculture improves soil structure and can increase organic carbon levels in soil aggregates leading to improved maize yields in drought years. However, most of this work has been undertaken on government research stations rather than in the ‘real world’ of smallholder farming systems. Furthermore, there is a lack of robust findings to determine whether these benefits will hold up in the face of climate change.\nWe’ve been working with farmers in Malawi for the last 10 years and know many of those who have taken up conservation agriculture – currently around 2–3%. Those connections are helped us to run a fast-turnaround study, comparing how the crops of conservation agriculture farmers in Malawi survived the 2015/16 drought compared to those using conventional methods.\nThis work, funded by the UK government through the National Environment Research Council (NERC), can help us understand just how ‘climate-smart’ conservation agriculture can be. This research also looked at the impact of El Niño in Kenya, to assess whether conservation agriculture helped farmers retain yields in the face of the floods there. Interim results from Malawi indicate that, where the drought was most severe, all farmers lost their crops; however, in more marginal areas, conservation agriculture did provide benefits where household labour was available (linked to the effectiveness of village health services) and crop residue management had been possible for the last 5 years.\nResearch is starting to provide a much-needed evidence base to show farmers when it is in their interest to move to conservation agriculture. Farmers need a clear message to help them understand which practices will work best for them, so that they can make an informed decision. We need both the evidence and better collaborative working amongst key organisations at both a national and district level to make that happen. Ongoing studies in the GCRF-AFRICAP project and the future work of the Food Systems Research Network for Africa (FSNet-Africa) offer scope to provide further empirical insights on how land management can build climate resilience in African Agricultural Systems.\nWebinar on 23 Feb\nLearn more about AFRICAP’s research on Conservation Agriculture and soils science at our webinar on 23 February, ‘Improving soil health through climate-smart agriculture’. Visit the event page for full details and to register.\nThis blog and associated vlog is part of a joint campaign for World Food Day led by the ARUA-UKRI GCRF Food Systems Research Network for Africa (FSNet-Africa) in partnership with the Food, Agriculture, and Natural Resources Policy Analysis Network (FANRPAN), the University of Leeds’ Global Food and Environment Institute (GFEI), and the GCRF AFRICAP programme. Follow the campaign on Twitter @gcrfafricap, or visit our partners’ websites over the next two weeks – University of Pretoria, FANRPAN, and GFEI.","04 Sep, 2023\nThe landscape of farming is evolving with each passing day and is making way for innovative agriculture practices. Seeing the current trends, this evolution is now based on adopting sustainable and eco-friendly approaches.\nContour farming stands as a remarkable example of this. With a focus on conserving the soil, this type of farming is revolutionizing the way we cultivate and conserve our lands.\nIn this guide, we delve deeper into this concept, the process involved, and the numerous benefits that it brings to the table. So, if you’re interested to learn about contour cultivation, stay tuned.\nLet’s begin the guide by knowing the meaning of court or farming. Contour farming is a time-tested agricultural practice that focuses on tillage conservation. It involves cultivating crops along the natural contours of the land.\nIn contour farming, farmers create rows of crops that follow the contour lines of the land, resembling the curves of a topographic map. The primary goal is to slow down the flow of water across the field, allowing it to infiltrate the soil rather than causing erosion.\nContouring is the practice of farming in row patterns that are almost levelled around hills rather than up and down. Numerous little dams are created by the rows, which promote infiltration and decrease water flow to lessen erosion.\nThe act of ploughing horizontally along a piece of land's contours is known as contouring. By catching the water flow, this kind of ploughing reduces soil erosion in hilly and contoured locations. Additionally, the contour lines produce a water break that lessens the development of gullies and rills during periods of heavy rainfall, allowing water to percolate into the soil. In hilly and sloped terrain, contour cultivation is a sustainable kind of agriculture.\nDuring the 1930s, the US Soil Conservation Service (now the Natural Resources Conservation Service) heavily pushed this practice. In 1935, during the Dust Bowl, the US Department of Agriculture founded the Soil Conservation Service after realizing that desertification and soil erosion were both major issues.\nContour agriculture is suitable only for specific types of crops like:\nBefore you get started with contour farming and plan to derive commendable results from it, you need to learn about the ideal conditions that this type of farming requires. Here is a list of these conditions.\nContour farming is successful only with slopes having gradients between 2% and 10%.\nThe area you’re planning to use for contour farming must receive a specific rainfall during a certain time of the year.\nThe land should have identifiable contour lines. These lines are best established through accurate topographic surveys or using tools like A-frames, laser levels, or GPS technology.\nThe land must have even contour intervals to ensure that the water flow is evenly distributed.\nWaterways should be grassed to reduce water runoff. Else, water conversation on the slopes won’t be possible.\nConsidering all these factors, Assam and Meghalaya are two ideal states for contour farming.\nContoured regions or hills are first levelled by farmers who use contour ploughing. As a result, the hill where crops are produced has a set of steps. To stop the water from flowing downward, water breaks — small ridges or raised platforms — are constructed around the edges of these steps. These water breaks to aid in keeping the water contained in distinct step levels, giving the earth more time to absorb the water.\nThe Contour farming process:\nThe land's contour guides the plough.\nThis causes the earth to be lifted, making a furrow on the slope.\nThe length of the land and the slope's gradient determine the size of the furrow.\nOn the opposite side of the hill, a ridge is then built using the soil from the furrow.\nRepeat this procedure until the entire field has been ploughed.\nContour ploughing improves soil quality and composition while minimising soil erosion by up to 50%, regulating runoff water, boosting moisture infiltration and retention, and decreasing crop damage from floods, storms, and landslides.\nSoil conservation is accomplished through contour ploughing. Soil conservation involves avoiding the loss of the topsoil owing to erosion to avoid reduced fertility brought on by excessive use, salinization, acidification, and other chemical soil contaminants.\nContour farming is a careful practice and farmers have to do some preparations before using land for contour cultivation. As a preparatory process, we recommend:\nArranging a typographic survey of the field to learn the appropriateness of the land for contour farming.\nConstructing proper borders across the field so that there is enough space for the tractor movement.\nMaking grassways around the water canals so that the water loss is minimal.\nWhen done correctly, contour farming is going to bring a lot of benefits to the table. To begin with, it prompts:\nSoil erosion control - As crops are planted along the natural contours of the land, water flow remains under control and generally has a reduced force. This prevents dislodging, which generally happens due to high water pressure, and conservation of the topsoil as it’s not washed away with water streams.\nWater conservation - When water flows along the contours, water infiltrates into the soil in a better way. There will be less surface runoff, improved water retention, and reduced water wastage.\nBetter crop yield - As soil erosion is reduced and soil structure improves over time, crops yielded as a result of couture farming are likely to have optimal root growth.\nNutrient conservation - Contour cultivation helps in maintaining the nutrients in the soil as soil erosion will be less. When nutrients are preserved in the soil, fertilizer application is less.\nFarming sustainability- With contour cultivation, farmers can easily promote sustainability and preserve the land’s productivity.\nTerrace farming stops rain from washing away soil nutrients. Healthy crop growth results from this. Second, it stops plants from being carried away by swiftly running rivers of water. Sometimes rainwater washes crops away, resulting in low agricultural output. Thirdly, terraces aid in reducing water loss and soil erosion. The fourth advantage of terrace farming is that it has transformed unproductive hillside land into useful land.\nReduced soil erosion on slopes from tilled fields is achieved through contour ploughing and terrace farming, respectively. The comparison between contour ploughing and terrace farming is provided below.\n|Terrace Farming||Contour Farming|\n|The structure of the slope is altered by terrace farming, resulting in flat regions that can catch water.||The slope's natural shape is suited by contour ploughing without being altered.|\n|Wide flat steps or terraces are created on steep slopes so that level surfaces can be used for cultivation, reducing surface run-off and soil erosion.||Creating a natural barrier to prevent liquids from draining down a slope by ploughing parallel to the contours of the hill.|\nWhile contour agriculture is beneficial at multiple levels and promotes soil conservation, it's not 100% flawless. It comes with certain disadvantages and knowing them beforehand is important.\nBelow are a few major drawbacks linked with contour farming.\nIt’s very labour-intensive. Farmers have to spend days and even months marking the contour lines on the lands.\nYou can’t adopt it anywhere. It has limited applicability. Only farmers of hilly or sloped areas can use it.\nTo succeed in contour agriculture, adequate training and skills are required. Without adequate knowledge, mistakes in contour placement can lead to ineffective erosion control.\nIt’s very difficult to use farm machinery and equipment on the natural curvature of contour rows. Hence, farmers have to depend on manual work a lot.\nIt demands huge efforts at the maintenance front as maintaining contour rows, terraces, and structures is not easy. If not properly maintained, erosion control will be less over time.\nNot every crop is suitable to cultivate that way. Hence, farmers are left with limited crop choices. This limitation can impact the diversity of crops that farmers can grow.\nIt demands huge investment even at the early stage. Farmers have to invest in buying tools and equipment for surveying. So, not every farmer can go for it immediately.\nThe implementation time is very high. Proper surveying and implementing contour farming can take days and even months. This affects the timing of the agricultural calendar.\nContour farming is a great way to use sloppy lands for farming while promoting soil conservation. However, the process itself is so tedious that farmers have to have patience, time, and money to get started.\nNonetheless, contour farming in India is widely adopted in hilly terrains and you can also try it. Just keep in mind the best contour agriculture practices that we shared through this blog.\nTractor Gyan aims to provide the best possible and updated farming-related information to farmers. With us, trying new farming techniques and knowing about their procedures is easy. So, stay tuned and stay updated.\nTractor Gyan is an expert-led platform that aims to empower Indian farmers by providing accurate and timely information, and technological advancement about tractors and farm equipment in India.\nTractorGyan helps farmers with New Tractor information, Compare Tractors, Tractor prices, Buying and selling of second-hand tractors, Tractor Insurance, Tractor Finance, Tractor tyre, Tractor Implements, Tractor EMI calculator and more.\nOn our Platform, we have information about leading brands :\n- In Tyres like BKT, Ceat, Apollo etc.\n- In Tractor Loan/Finance like Central Bank Of India, Hdfc Bank, etc.\n- In Tractor Insurance like Mahindra Finance, Axis Bank, ICICI Bank, etc.\nTractorGyan is Helping India mechanise by delivering crucial information about tractor buying and guiding farmers at every step so that they get a tractor or farm equipment that empowers and equips them to produce quality yield.\nVst Tillers Tractors sold 421 tractors and 3616 power tillers in August 2023\nVST Tillers Tractors shows a decline in their tractor sales with 421 units sold, which is comparatively lower than its August 2022 sales, which shows ...\nवीएसटी टिलर ट्रैक्टर्स ने अगस्त'23 में 421 ट्रैक्टर और 3616 पावर टिलर बेचे\nवीएसटी टिलर्स ट्रैक्टर्स लिमिटेड कंपनी ने आज अगस्त 2023 में होने वाली कुल ट्रैक्टर और पावर टिलर की बिक्री की रिपोर्ट जारी की है जिससे पता चलता है कि व...\nSonalika records overall sales of 10,634 tractors & highest ever monthly production of 16,300+ tractors in August'23\nSonalika records sales of 10,634 tractors and manufacturing team has put up a great team work to clock the highest ever monthly production of 16,300+ ...\nContour farming is an agricultural practice that involves cultivating crops along the natural contours of the land to reduce soil erosion and conserve water.\nCrops like corn, wheat, grass, soybeans, and legumes are suitable for contour farming.\nContour farming helps control soil erosion, conserve water, improve crop yield, and promote sustainable agriculture.\nContour farming follows the natural contours of the soil without changing its shape, whereas terrace farming modifies the slope's structure to produce flat areas for cultivation.\nContour farming does have some disadvantages, like:\nDifficult to plow and plant crops along the contours of the land.\nReduce the amount of land available for farming.\nMore difficult to control pests and diseases.\n|Top 10 Tractor brands in india||To 10 Agro Based Indutries in India|\n|Rabi Crops and Zaid Crops seasons in India||Commercial Farming|\n|DBT agriculture||Traditional and Modern Farming|\n|Top 9 mileage tractor in India||Top 5 tractor tyres brands|\n|Top 11 agriculture states in India||top 13 powerful tractors in india|\n|Tractor Subsidy in India||Top 10 tractors under 5 Lakhs|\n|Top 12 agriculture tools in India||40 Hp-50 Hp Tractors in India|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:155d6dc0-5127-42b9-938c-416288b657bc>","<urn:uuid:92889402-ad3f-4336-a870-ddc32bff750c>"],"error":null}
{"question":"How do workplace sanitation standards and water quality regulations intersect in developed countries?","answer":"In developed countries, workplace sanitation and water quality regulations work together through multiple mechanisms. For workplaces, OSHA mandates specific portable toilet requirements and handwashing stations to maintain hygiene. Meanwhile, water quality is protected through the Clean Water Act, which sets standards for pollutants and requires permits for discharge. Between 1972-2002, these combined efforts helped increase fishable and swimmable streams from 36% to 60%, with 74% of the population served by proper sewage treatment. However, challenges remain as 45% of lakes and 40% of streams still don't meet quality standards.","context":["Portable toilets made their first appearances about 80 years ago. Since that time, more than a few people have come to turn up their noses at the thought of a restroom housed inside a tiny movable closet. Of course, many have also benefited immensely from having porta-potties around when there weren’t any other options available. Thanks to the many advantages of these modern conveniences, as well as the growing need for them, they’ve made their way to work sites, public events, and other places across the globe.\nUnderstanding the Requirements for Portable Restrooms\nSome companies make sure they have portable restrooms on job sites for their workers as a basic courtesy. Many people are unaware that stringent requirements are in place for these types of facilities as well. These apply to work sites specifically, such as construction areas and on jobs where providing conventional restrooms wouldn’t be possible or practical. For business owners and managers who are in charge of compliance and accommodating employees’ needs, knowing the regulations for Satellite portable restrooms is particularly important.\nAccording to the latest standards set forth by the Occupational Safety and Health Administration, the required number of portable toilets on a job site varies based on the number of employees working there. On sites with less than 20 workers, only one porta potty is required. For more than 20 workers, job sites should have no less than one toilet and one urinal for every 20 employees. Those with 200 workers or more should be equipped with at least one toilet and one urinal per 50 employees.\nLooking Beyond the Basics\nThose are the standard requirements for job sites where permanent restroom facilities aren’t available. It’s a good idea to look beyond simply remaining in compliance with the regulations, though. Different groups of workers often have varying needs. Consider how often crew members might need to use the restroom and whether everyone on the job will have the access they need to those portable toilets.\nThink about others who might be coming to the job site and using the restrooms, too. These might include delivery drivers bringing in construction materials and drivers hauling away dirt and construction debris. They can’t always stop whenever they’d like to use the restroom, so portable toilets at the work sites they visit may be the only options available to them. If those types of outside contractors routinely come to a job site, they could cause a bit of congestion at the restrooms, though, keeping other employees from being able to take full advantage of them.\nSize of the work site factors into the equation as well. Per regulations, portable restrooms need to be easily accessible for workers. They should be able to make their way to the facilities within 10 minutes. If that’s not possible, more porta-potties should be added to the mix. Sanitation is a consideration, too. Regulations developed by the American National Standards Institute state that portable toilets should be cleaned at least twice per week depending on the surrounding circumstances. Experts advise having handwashing stations on site as well to further foster cleanliness and reduce the spread of germs.\nKeeping Workers Healthy and Happy\nProviding restrooms for workers on job sites isn’t just a thoughtful gesture; it’s a necessity. It’s also a requirement based on national regulations. Failing to provide this convenience can result in hefty fines and other consequences. When determining the number of portable toilets required for a job site, factor in the number of people who will be using them, the size of the site, and other aspects. Be sure to keep sanitation in mind as well.","Presentation on theme: \"Any chemical, biological, or physical change in water quality that has a harmful effect on living organisms or makes water unsuitable for desired usage.\"— Presentation transcript:\nAny chemical, biological, or physical change in water quality that has a harmful effect on living organisms or makes water unsuitable for desired usage.\nWHO: * 3.4 million premature deaths each year from waterborne diseases * 1.9 million from diarrhea * U.S. 1.5 million illnesses * 1993 Milwaukee 370,000 sick\nInfectious Agents: - bacteria and viruses often from animal wastes Oxygen Demanding Wastes: - organic waste that needs oxygen often from animal waste, paper mills and food processing. Inorganic Chemicals: - Acids and toxic chemicals often from runoff, industries and household cleaners Organic Chemicals: - oil, gasoline, plastics, detergents often from surface runoff, industries and cleaners Plant Nutrients: - water soluble nitrates, ammonia and phosphates often from sewage, agriculture and urban fertilizers Sediment: - soils and silts from land erosion can disrupt photosynthesis, destroy spawning grounds, clog rivers and streams Heat Pollution and Radioativity: mostly from power plants\nPoint sources Nonpoint sources Water quality\nNONPOINT SOURCES Urban streets Suburban development Wastewater treatment plant Rural homes Cropland Factory Animal feedlot POINT SOURCES Fig. 22-4 p. 494\nPoint Source Pollution: - There is one major source of the pollution and it can be identified. - Examples: Pipe coming out of a factory directly into a river. Nonpoint Source Pollution: - There can be many sources for a body of water being polluted. - Example: A river being polluted due to urban runoff.\nAgriculture:(A.K.A: Farms) * Sediment: Heavy rains cause soil erosion. * Fertilizers and Herbicides: Farmers use these on their crops for bug and weed control. They runoff during rain. * Bacteria from livestock: Animals use the land as their bathroom. Their feces contains nitrates which pollute river during rain runoff. * Salt from soil irrigation\nIndustrial: * Clearing of land for businesses to be built can cause soil erosion. * Waste a sewage dumping by factories. * Big power plants use rivers, streams, and lakes to dispose of waste heat. * Fort Meyers, Florida Manatee Park * http://www.leeparks.org/panoramas/p anoramas-parks-i-n.html#manatee http://www.leeparks.org/panoramas/p anoramas-parks-i-n.html#manatee * Factories dump toxic or radioactive materials. * Burning fuels causes “acid rain”.\nHome: * Sewage and septic leak in water source. * Fertilizers, herbicides, pesticides used for lawn maintenance. * Putting hazardous chemicals down the drain. * Oil and antifreeze leak from cars onto the driveway.\nDeveloped Countries U.S. and other developed countries sharply reduced point sources even with population and economic growth * Nonpoint still a problem * Toxic chemicals still problem * Success Cuyahoga River, Thames River\nDeveloping Countries: Serious and growing problem * Half of world’s 500 major rivers heavily polluted * Sewage treatment minimal $$$ * Law enforcement difficult * 10% of sewage in China treated * Economic growth with little $$$ to clean up\n* Holy River (1 million take daily holy dip) * 350 million (1/3 rd of pop) live in watershed * Little sewage treatment * Used for bathing, drinking etc. * Bodies (cremated or not) thrown in river * Good news is the Indian government is beginning to work on problem\n* How successful has the U.S. been at reducing water pollution? Clean Water Act * What law governs water pollution in the United States?\nMost developed countries use laws to set water pollution standards. Federal Water Pollution Control Act (Clean Water Act 1972, ’77, ’87) * Regulates navigable waterways..streams, wetlands, rivers, lake\n* Sets standards for key pollutants * Requires permits for discharge * Requires sewage treatment * Require permits for wetland destruction * Does not deal with nonpoint sources well * Goal All Waterways fishable and swimable\n* Between 1972 – 2002 fishable and swimmable streams 36% to 60% * 74% served by sewage treatment * Wetlands loss dropped by 80% * Topsoil losses dropped by 1 billion tons annually\n* 45% of Lakes, 40% streams still not fishable and swimmable * Nonpoint sources still huge problem * Livestock and Ag. Runoff * Fish with toxins\n* How is waste water cleaned? * How is drinking water purified? High tech way. * How can we purify drinking water in developing nations? * Is bottled water a good answer or an expensive rip-off? * How do sewage treatment plants work?\nSeptic Systems Fig. 22-15 p. 510 ¼ of all U.S. homes have Septic tanks Septic tanks are used primarily outside city limits. How does it work? The Septic Tank — A septic tank's purpose is to separate solids from the wastewater, store and partially decompose as much solid material as possible, while allowing the liquid (or effluent) to go to the drainfield....more The Drainfield — After solids settle in the septic tank, the liquid wastewater (or effluent) is discharged to the drainfield, also known as an absorption or leach field....more The Soil — The soil below the drainfield provides the final treatment and disposal of the septic tank effluent. After the wastewater has passed into the soil, organisms in the soil treat the effluent before it percolates downward and outward, eventually entering ground or surface water. The type of soil also impacts the effectiveness of the drainfield; for instance, clay soils may be too tight to allow much wastewater to pass through and gravelly soil may be too coarse to provide much treatment."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:c1f38636-f23e-441a-94bf-c5e31b4cf106>","<urn:uuid:0cda344a-b301-4d07-87f9-3c1466f55e0b>"],"error":null}
{"question":"How did the Navy manage to reduce the time needed to sanitize large spaces like mess decks from 3 hours to just 30 minutes during the COVID-19 pandemic?","answer":"Through the work of a new task group, the Navy was able to dramatically improve the efficiency of sanitizing large spaces. The process that initially took about three hours was reduced to approximately 30 minutes. Additionally, there are plans to potentially automate this process in the future through the use of UV-C light cleaners that would be capable of sanitizing entire rooms.","context":["An E-2C Hawkeye from the Sun Kings of Carrier Airborne Early Warning Squadron (VAW) 116 prepares to land on the flight deck of the aircraft carrier USS Nimitz (CVN-68) during a composite training unit exercise (COMPTUEX) on May 15, 2020. US Navy Photo\nThis post has been updated to correct a statement from U.S. 3rd Fleet on which date the Nimitz Carrier Strike Group completed COMPTUEX.\nUSS Nimitz (CVN-68) is pier-side in California after completing its final series of exercises ahead of a planned deployment to the Western Pacific, USNI News has learned. Read More →\nThe following is the June 3, 2020 statement from Chief of Naval Operations Adm. Mike Gilday to the fleet on the death George Floyd and current national unrest. Read More →\nUSS Theodore Roosevelt (CVN 71) flies a replica of Capt. Oliver Hazard Perry’s ‘Don’t Give Up the Ship’ flag as Theodore Roosevelt approaches Apra Harbor, Guam on June 3, 2020. US Navy Photo\nUSS Theodore Roosevelt (CVN-71) and its embarked air wing are ready to go back on deployment after completing carrier qualifications, following a two-month fight against a COVID-19 outbreak on the carrier, U.S. 7th Fleet announced. Read More →\nAttack boat Vermont (SSN-792) float-off on March 29, 2019. General Dynamics Electric Boats Photo\nThe Columbia ballistic-missile submarine program has seen some COVID-19-related challenges – including difficulties conducting oversight audits to ensure suppliers can keep to the tight schedule that has no room for further delays – but the program executive officer is confident that the prime shipbuilder is managing the situation and keeping the program on track. Read More →\nSecretary of the Navy Kenneth Braithwaite to serve as the next Secretary of the Navy on May 29, 2020 in the Pentagon. DoD Photo\nKenneth Braithwaite was sworn in as the newest secretary of the Navy during a private ceremony today at the Pentagon, capping what has been a tumultuous six months for the department’s leadership.\nRead More →\nOperations Specialist 2nd Class Alejandro Agosto disinfects surfaces during cleaning stations aboard the guided-missile destroyer USS Paul Hamilton (DDG-60) on May 6, 2020. US Navy Photo\nAs ship crews find themselves cleaning common spaces much more to prevent the potential spread of COVID-19, the process of sanitizing a large area like the mess deck at the beginning of the pandemic took about three hours. Thanks to a new task group, that’s down to about 30 minutes. And in the future, it could be automated through the use of UV-C light cleaners that can sanitize an entire room. Read More →\nSailors assigned to the aircraft carrier USS Theodore Roosevelt (CVN-71), run on the pier of Naval Base Guam, May 8, 2020. US Navy Photo\nAn investigation into the circumstances around the March COVID-19 outbreak aboard the aircraft carrier USS Theodore Roosevelt (CVN-71) has been handed over to Chief of Naval Operations Adm. Mike Gilday for review, Navy officials told USNI News on Wednesday. Read More →\nA U.S. Coast Guard MH-65 Dolphin helicopter flies by the national security cutter USCGC Bertholf (WMSL 750) in the Arctic Ocean Coast Guard photo\nThe U.S. Coast Guard’s operations in a COVID-19 environment require constantly gauging risk and accepting that large-scale exercises like Rim of the Pacific (RIMPAC) 2020 “will feel a little different,” senior service officials said last week.\nRead More →\nHospital Corpsman 2nd Class Amy Peterson (left), checks Electronics Technician Seaman James Love’s temperature at a medical screening check point for the aircraft carrier USS Abraham Lincoln (CVN-72). Navy photo\nThe Navy released a new set of COVID-19 guidelines Wednesday to standardize the fleet’s response to the pandemic and establish a framework for commanders to use as the Pentagon moves toward resuming full operations.\nRead More →\nSecretary of Defense Mark Esper addresses local Colorado Springs media outlets during his visit to the North American Aerospace Defense Command and U.S. Northern Command’s headquarters, May 7. DoD Photo\nSecretary of Defense Mark Esper ordered replacing the military’s expansive movement restrictions on Tuesday with a regional conditions-based set of guidelines governing when and where service members, civilian employees and dependents can travel. Read More →"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:0b038ed6-1856-46f5-af9d-97c8f1ded248>"],"error":null}
{"question":"I'm researching industrial heritage sites and sustainable manufacturing. Could you tell me about the historical significance of the Val d'Abois region's ironworks and how modern cement production is addressing environmental concerns in similar industrial areas?","answer":"The Val d'Abois ironworks were globally renowned, producing weapons for the French Revolution, pipelines for major cities, and components for the Eiffel Tower. The region was one of France's leading iron and steel processing centers, producing 15% of all French cast steel by 1850, benefiting from abundant resources like forests, waterways, and iron ore. However, the industry declined by the late 19th century. In terms of modern industrial sustainability, the cement industry has become a major player in the circular economy. Current cement production facilities are addressing environmental concerns through co-processing, which uses non-recyclable waste as both fuel and raw material replacement. This approach could save up to €12.2 billion in additional waste-to-energy plants and avoid 26 million tonnes of CO2 emissions annually, demonstrating how modern industry is evolving to meet environmental challenges.","context":["The ironworks in the Pays Loire Val d'Abois were once known all over the world. The area manufactured weapons for the French Revolution, pipelines for Madrid and Paris, and components for building the Eiffel Tower. Visitors can find out how this came about in the extensively restored former Charcoal Hall in Grossouvre that dates back to 1844 and covers an area of almost 100 square metres. Multimedia and interactive facilities provide a lively image of the regional iron industry. The blast furnace at Grossouvre also fell victim to the decline of the industry towards the end of the 19th century. However you can still visit a building with workers apartments nearby. The brick-making factory is also in the vicinity: it has been in operation since around 1900. A further brick-making factory - now disused - in La Guerche sur l'Aubois is currently being restored. Torteron in the north of the Val d'Abois shows the extent to which urban planning was influenced by the regional industries. Beffes has a rich tradition of cement-making: the gigantic cement works owes its origins to old quarries and blast furnace plants. The 300 metre long aqueduct over the canal in Cuffy is a classic example of the early development of industrial transport routes. Grossouvre is an ideal starting and information point for all these different industrial monuments.\nIndustrialisation in France extended far into rural regions where a number of different industries became established. The Pays Loire Val d'Abois is a very clear example of this: the preconditions were favourable: large stretches of forest and waterways served as sources of power, raw materials were on hand in the form of easily extractable iron ore, high-quality limestone and clay.\nThe Cistercian monks in the Abbey of Fontmorigny are credited with triggering this dynamic industrial development. They are reckoned to have started processing iron as early as the 12th century. Much later, in 1825, a certain Georges Dufaud returned from a journey to Merthyr in South Wales with new ideas that had a long-lasting influence on the techniques of coal-firing and the use of rolling mills in the region. At the time the Val d'Abois was one of the leading centres of iron and steel processing in France. Canals and railway lines linked the industrial region to Northern Europe and the Mediterranean. Furthermore the new steam engine technology was introduced near Torteron in 1824 and this led to the construction of large casting plants, as can be seen from the many remains. Around 1850 15% of all the cast steel made in France came from the Val d'Abois.\nGrossouvres first blast furnace was probably built in the early 16th century, but possibly even earlier. Today the remains of a blast furnace from the 18th century lie sunk beneath a 40 hectare lake. The 1860s were difficult years for the regional steel industry, and steel manufacturing in Grossouvre came to an end in 1879. Here as elsewhere alternative industries moved in: these included brickworks and cement factories. Now the restored Charcoal Hall in Grossouvre is the centre and starting point for exploring the history of iron-making techniques in the region. Trained museum staff also lead visitors to the neighbouring workers housing estate (\"Les Galeries\") and other industrial monuments including Torteron, an industrial site that was once planned to contain a model housing estate.\n|Recommended duration of visit:||1 Hours|\n|Access for persons with disabilities:||Available|\nFebruary to June and September to December\nTuesday - Sunday 9.30-12.30am, 2-5.30pm\nJuly to August","With the environmental impact of raw materials used in the construction industry attracting increasing scrutiny, sustainable solutions are needed.\nThe construction sector is entering a challenging yet exciting time. Demand for new homes and infrastructure means that materials such as cement are needed now more than ever.\n“Co-processing of waste in cement kilns is a circular approach that generates multiple environmental, social and economic benefits.” - Thomas Guillot, Geocycle Europe\nAt the same time, environmental concerns mean that construction – which has traditionally relied on fossil fuels and vital raw materials – is under pressure to ensure the sector uses materials in a way that is environmentally friendly, not only to comply with regulatory requirements but also to exceed consumer expectations.\nFor this reason, the sector has become a major part of the circular economy through its adoption of co-processing – the use of non-recyclable waste as both an alternative fuel source and as a replacement for raw materials.\nThe potential for co-processing\nA recent study conducted by CEMBUREAU / Ecofys shows that co-processing of waste in cement kilns is already being widely employed across the EU, but that the potential for further uptake remains large.\nIncreased co-processing rates across the member states can further contribute to overcoming challenges such as climate change, waste management and fossil fuel depletion, while utilising the principles of the circular economy.\nThere is no technical limitation at cement plants preventing an increase in the share of alternative fuels from 44% now to 60% across the EU, apart from the general challenges of implementing the circular economy at an industrial scale. If this can be achieved, it could save expenditures in additional waste-to-energy plants of up to €12.2 billion and avoid emissions of 26 million tonnes of CO2 per year.\nCo-processing: a closer look\nTypically, within the cement production process, cement kilns use a mixture of fuels such as coal, oil and natural gas to create the high temperatures needed.\nThis is where co-processing comes in, says Thomas Guillot, head of Geocycle Europe, who explains how a number of alternative materials can be used as a fuel instead.\n“In Europe, cement kilns treat municipal solid waste, used tyres, sewage sludge, waste oils, contaminated soils, construction and demolition waste or plastics,” he says.\nPart of the LafargeHolcim group, Geocycle has led the way on the co-processing of waste materials within the industry. The group collects industrial or municipal waste and co-processes or reuses it in LafargeHolcim cement plants.\n“In Europe, cement kilns treat municipal solid waste, used tyres, sewage sludge, waste oils, contaminated soils, construction and demolition waste or plastics” - Thomas Guillot, Geocycle Europe\nGeocycle has over 180 cement plants with dedicated co-processing installations and is investing and partnering in the sector across Europe.\nGuillot says: “Co-processing of waste in cement kilns is a circular approach that generates multiple environmental, social and economic benefits.”\nHe adds that it “optimises the use of waste by recycling the mineral part and by recovering the energy part”, offering alternatives to landfill or incineration, while being energy efficient.\nThis point is echoed by other experts in the field, including in the Technological Education Institute of Piraeus and Columbia University collaborative research paper 'Use of alternative fuels in cement industry', which says that co-processing offers “a safe and sound solution for society, the environment and the cement industry, by substituting non-renewable resources with societal waste under strictly controlled conditions”.\nAlternative fuels from waste\nLooking at specific examples of co-processing in action, the results speak for themselves.\nAt LafargeHolcim, several plants across Europe substitute a staggering 95% of their fossil fuels with waste, while 30% of their mineral resources in cement production are recycled waste from sectors such as construction and demolition – which is itself responsible for 32% of the total waste generated in Europe.\nElsewhere, at the Retznei cement plant in Austria, Geocycle has constructed a recycling centre that means 12% of the raw materials used to produce the cement at this site comes from re-used waste.\nThis has resulted in 100,000 tonnes of construction and demolition waste being reused every year and has seen Retznei become one the top performers worldwide for substituting thermal energy with alternative fuel.\nAt LafargeHolcim, several plants across Europe substitute a staggering 95% of their fossil fuels with waste\nBuilding materials supplier, Hanson UK, meanwhile, has halved the amount of waste sent to landfill in the past 12 months by reusing and recycling more than 100,000 tonnes of controlled waste in the production of cement.\nSimilar approaches can be seen across the world in countries such as India, which has mounting environmental pressures around waste management.\nIn the southern Indian city of Thiruvananthapuram, solid waste materials, such as plastic and old mattresses, are being used as alternative fuel sources within the cement industry – a solution which could save money and reduce carbon dioxide emissions.\nCreating innovative materials and aggregates\nFurther innovation is taking place across the sector to make use of non-recyclable products within the material itself.\nMicroalgae-products, which are used in the cosmetic industry, have been employed as an alternative to agricultural oils.\nBruno Bujoli, director of research at CNRS (Centre National de la Recherche Scientifique), who was involved in developing the technology, recently spoke of the potential environmental benefits.\nHe told the Guardian: “The benefits of microalgae over other sources include low competition for arable land, high per hectare biomass yields and large harvesting turnovers.”\nSuch advancements hold exciting possibilities for the future of the wider construction materials sector.\nThe industry is also testing the use of certain plastics as a replacement for aggregate within concrete mixtures, which could have huge environmental benefits. Some 300 million tonnes of plastic are produced globally each year, according to research by Plastic Oceans.\nTarmac, a CRH company, is working with Carbon 8 – a carbon negative aggregate manufacturer – on several incinerator projects in the UK. Here lime is supplied, spent lime is reprocessed using CO2 and resulting product used as an aggregate in building blocks.\nWhile co-pressing presents a string of exciting possibilities, both in environmental terms and for cement production as a whole, it’s not without its challenges.\nAs Guillot notes: “The sector is still facing local acceptance when implementing circular economy approaches such as co-processing of waste, which is a safe waste treatment solution.”\nIt is vital, then, that the sector continues to champion innovative approaches to take the public on this journey with them, to ensure the industry can grow sustainably in the years ahead."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:0fd09e44-25ed-4306-af14-3e947c00d749>","<urn:uuid:912a8e51-1261-4a9f-a0cb-84e053705a25>"],"error":null}
{"question":"What role does the labrum play in maintaining hip joint stability?","answer":"The labrum is a ring of strong fibrocartilaginous tissue that acts as a shock absorber, lubricates the joint, and distributes pressure equally. It holds the femur head in place, prevents lateral and vertical movement of the femoral head within the joint, deepens the acetabular cavity, and provides stability against femoral head translation.","context":["Normal Anatomy of the Hip joint\nHow does the Hip joint work?\nFind out more in this web based movie.\nOsteoarthritis, also called degenerative joint disease is the most common form of hip arthritis. It occurs most often in older people. This disease affects the tissue covering the ends of bones in a joint (cartilage). In a person with osteoarthritis, the cartilage becomes damaged and worn out causing pain, swelling, stiffness and restricted movement in the affected joint. Although osteoarthritis may affect various joints including hips, knees, hands, and spine, hip joint is most commonly affected. Rarely, the disease may affect the shoulders, wrists and feet.\nFor more information about Hip Arthritis, click on below tab.\nThe hip joint is a “ball and socket” joint. The “ball” is the head of the femur or thigh bone and the “socket” is the cup shaped acetabulum. The joint surface is covered by a smooth articular surface that allows pain free movement in the joint.\nFor more information about Hip Fractures, click on below tab.\nHip bursitis is a painful condition caused by inflammation of a bursa in the hip. Bursae are fluid filled sacs present in joints between bone and soft tissue to reduce friction and provide cushioning during movement.\nFor more information about Hip Bursitis, click on below tabs.\nFemoroacetabular Impingement (FAI)\nFemoroacetabular Impingement FAI is a condition resulting from abnormal pressure and friction between the ball and socket of the hip joint resulting in pain and progressive hip dysfunction. This when left untreated leads to the development of secondary osteoarthritis of the hip.\nFor more information about Femoro Acetabular Impingement FAI, click on below tabs.\nSnapping Hip Syndrome\nThe hip is an important joint that helps us walk, run and jump. The ball-and-socket joint in the hip is formed between the round end of the femur (thighbone) and the cup-shaped socket of the acetabulum (part of the hip bone). Joint stability in the hip region is achieved through the labrum (a strong fibrous cartilage), which covers the acetabulum and seals it, and ligaments (tissue connecting bone to bone) and tendons (tissue connecting muscle to bone) that encase the hip and control the hip movements.\nFor more information about Snapping Hip Syndrome, click on below tab.\nHip pain, one of the common symptoms patients complain of, may not always be felt precisely over the hip joint. Pain may be felt in and around the hip joint and the cause for pain is multifactorial. The exact position of your hip pain suggests the probable cause or underlying condition causing pain. Pain felt inside the hip joint or your groin area is more likely to be because of the problems within the hip joint. Likewise, the pain felt on the outer side of your hip, upper thigh or buttocks may be a result of the problems of the muscles, ligaments, tendons and soft tissues surrounding the hip joint. However certain disease conditions affecting other parts of your body such as lower back or knees also cause hip pain.\nFor more information about Hip Pain, click on below tab.\nThe gluteal muscles are a major group of muscles located at the back of the pelvis forming the buttocks that helps in the stability of the hip. The gluteal muscles comprise of three muscles: gluteus maximus, gluteus medius, and the gluteus minimus. These muscles facilitate in abduction, extension, internal and external rotational movements of the hip. Gluteal tears occur either as a result of injury or strain of the muscle.\nFor more information about Gluteal Tear, click on below tabs.\nHip Labral Tear\nLabrum is a ring of strong fibrocartilaginous tissue lining around the socket of the hip joint. Labrum serves many functions where it acts as shock absorber, lubricates the joint, and distributes the pressure equally. It holds the head of the femur in place and prevents the lateral and vertical movement of the femur head with in the joint. It also deepens the acetabular cavity and offers stability against femoral head translation.\nFor more information about Hip Labral Tear, click on below tabs.\nThe hip plays an important role in supporting the upper body weight while standing, walking and running, and hip stability is crucial for these functions. The femur (thigh bone) and acetabulum (hip bone) join to form the hip joint, while the labrum (tissue rim that seals the hip joint) and the ligaments lining the hip capsule maintain the stability of the hip. Injury or damage to these structures can lead to a condition called hip instability. Hip instability happens when the hip joint becomes unstable causing various symptoms.\nFor more information about Hip Instability, click on below tab.\nHip dysplasia is a condition which is seen in infants and young children as a result of developmental problems in the hip joint. The femur (thigh bone) partially or completely slips out of the hip socket causing dislocation at the hip joint. It is most common in first born baby with family history of the disorder. The exact cause for hip dysplasia is not known. Genetic factors play an important role in causing this birth defect.\nFor more information about Hip Dysplasia, click on below tab.\nAvascular necrosis, also called osteonecrosis is a condition in which bone death occurs because of inadequate blood supply to it. Lack of blood flow may occur when there is a fracture in the bone or a joint dislocation that may damage nearby blood vessels. Chronic use of high doses of steroid medications and heavy alcohol consumption are the two main risk factors of avascular necrosis. Initially, small breaks appear in the bone that may eventually collapse. Hip joint is most commonly affected; however the knee and shoulder may also be involved.\nFor more information about Avascular Necrosis, click on below tab.\nTotal Hip Replacement (THR)\nTotal Hip Replacement (THR) procedure replaces total or part of the hip joint with an artificial device (prosthesis) to alleviate pain and restore joint movement.\nFor more information about Total Hip Replacement (THR), click on below tabs.\nHip Resurfacing or bone conserving procedure replaces the acetabulum (hip socket) and resurfaces the femoral head. This means the femoral head has some or very little bone removed and replaced with the metal component. This spares the femoral canal.\nFor more information about Hip Resurfacing, click on below tabs.\nRevision Hip Replacement\nThis maybe because complete or a part of your previous hip replacement needs to be revised. This operation varies from a very minor adjustment to a massive operation replacing significant amount of bone and hence is difficult to describe in full.\nFor more information about Revision Hip Replacement, click on below tabs.\nHip Fracture Surgery\nClick on the topics below to find out more from the Orthopaedic connection website of American Academy of Orthopaedic Surgeons.\n- Patient Resources"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:3983691b-6207-4028-8c06-c4c4672c3058>"],"error":null}
{"question":"Are both the original Emerald Buddha and the new Sacred Emerald Buddha made from real emerald stone?","answer":"No, they are made from different materials. The original Emerald Buddha in Bangkok is actually made of nephrite jade, not emerald. The new Sacred Emerald Buddha was carved from a genuine 3,600-carat natural emerald crystal discovered in Africa.","context":["Home to Thailand's most sacred Buddha image\nPublished/Last edited or updated: 28th August, 2017\nThe Temple of the Emerald Buddha, or Wat Phra Kaew, is arguably the grandest wat in Bangkok and the standard by which others are judged. The namesake Buddha image is Thailand’s most sacred, carved from solid jade and featuring in enough legends to fill several books. Yet it’s the temple’s ornate details that leave most visitors spellbound.\nCompleted three years after King Rama I founded the still-existent Chakri dynasty and moved the Thai capital to Bangkok in 1782, Wat Phra Si Rattana Satsadaram, to use the temple’s official name, and the Phra Kaew (“Emerald Buddha”) image that it enshrines, continue to symbolise the unifying interplay between Buddhism and the monarchy in Thailand.\nPhra Kaew can also be seen as the ultimate level of Thai superstition—the grandmaster of the many Buddha images and other objects, like talismans and amulets, believed to be imbued with a range of mysterious powers. It would not be an understatement to say that the unity of the Thai kingdom depends on Phra Kaew, a belief that was cemented by its arrival in Bangkok around the same time as the current royal lineage’s founding.\nThe deeply revered Thai king draws much of his moral and spiritual authority from a perceived connection to Phra Kaew, itself thought to encapsulate the kingly virtues. The term Rattanakosin, coined by Rama I as the name for his new capital and now used broadly to label centuries of Thai art and architecture, was originally a reference to this single Buddha image, translating as “Repository of the Gem Image”.\nWhere and when Phra Kaew was created remains a mystery. Legends claim it was conjured by the Hindu god Indra over 2,000 years ago in India, where the sage Nagasena is said to have predicted that Buddhism would flourish wherever it was enshrined. Some say it reached Thailand via Sri Lanka, Cambodia or Burma.\nThe artistic style of the image seems to derive from what’s now Northern Thailand in the 13th or 14th centuries. No one but the Thai king or crown prince has been permitted to touch Phra Kaew over the past couple of centuries, meaning that art historians can only guesstimate from afar. One thing is for certain: Phra Kaew became incredibly highly revered at some point along its path.\nThe image first appeared in historical records around the 15th century, when it was supposedly covered in stucco and kept in a chedi in Chiang Rai. When lightning struck the chedi, as the story goes, the image’s outer shell was chipped to reveal its true nephrite composition. Still one of the world’s most valuable minerals, nephrite is a type of jade with a deep-emerald hue. (So, no, the Emerald Buddha is not actually made of emerald.)\nPhra Kaew then spent relatively short stints in Lampang, Chiang Mai and Luang Prabang before being enshrined in Vientiane’s own Wat Phra Kaew for over two centuries. While still a general, the man who would soon become King Rama I led a successful attack on the Lao capital and carted the image to Bangkok, where it was sometimes paraded during the early days of the Rattanakosin period. Many believed that a glimpse of it could cure sickness.\nNow for the spoiler: the Emerald Buddha is only 66 centimetres tall, depicted in seated meditation posture atop an ornate gilded pedestal. Photos are not allowed and visitors must stay several metres away, making it difficult to see the finer details. While Thai studies enthusiasts will appreciate its unrivalled importance, Phra Kaew does not make the jaw drop in the same way as Wat Pho’s massive reclining Buddha or Wat Traimit’s solid gold image.\nBut there’s a lot more to Wat Phra Kaew than Phra Kaew alone. Guarded by tall and angry-looking yakshas (“giants” or “demons”), the grounds include eight Khmer-style prangs, a large bell-shaped chedi supposedly containing a relic of the Buddha himself, and a mondop that glistens with finely detailed mother-of-pearl doors and mosaic-encrusted pillars. Everything is awash in gold leaf, ornate jewels and glazed ceramics in many different colours, all placed on solid marble pediments.\nRimming the temple on all sides, long cloisters are adorned with exquisite late-18th century murals depicting the Ramakien epic (the Thai version of the Indian Ramayana) from start to finish. Statues of one of the Ramakien’s star characters, the monkey-king Hanuman, can be seen repeatedly, “bearing the weight” of chedis or guarding entrances to some of the minor buildings.\nGolden naga serpents are topped with five angelic heads. Half-bird half-angel khinaree depictions seem to materialise from the sparkling gold-and-indigo walls. Many other oddly elegant beings from the mythological Himmaphan forest stand near a miniature replica of Angkor Wat. These are just a few of the countless details that overwhelm the eyes while attempting to transport visitors beyond the earthly realm.\nWhat you won’t find are monks’ living quarters, as Wat Phra Kaew is one of the only functioning temples in Thailand that doesn’t have a single monk in residence. This is due to its one-of-a-kind status as the royal palace’s own front-yard temple, following in the footsteps of Ayutthaya’s Wat Phra Si Sanphet. The temple is occasionally closed for ceremonies involving the royal family and high-ranking monks, the most well-known being the changing of the Emerald Buddha’s golden robes to mark the beginning of the cool, hot and rainy seasons.\nPart of the larger Grand Palace complex and included with a single 500-baht ticket, Wat Phra Kaew is an extremely popular tourist attraction—and for good reason. The selfie-stick wielding hordes can detract from the overall experience, and pickpockets are occasionally reported. Apart from (perhaps) first thing in the morning, there’s no time of day or year when the crowds can be avoided.\nIgnore any well-dressed men or tuk tuk drivers who approach you near the entrance and tell you that the complex is closed, as this is a scam. Personal guides can be arranged next to the ticket window, where you can also rent an audio guide for 200 baht. If you’re not dressed appropriately, with long pants/skirts and shirts covering the shoulders, you can rent a sarong to cover yourself near the front gate. Plan on at least two hours to take in both Wat Phra Kaew and the Grand Palace.\nIf you want to see some of the temple’s centuries-old statues and carvings that have since been replaced, don’t miss the Wat Phra Kaew museum in the western corner of the Grand Palace complex, near the exit. It also houses the bones of a royal white elephant, 5,000-year-old painted ceramics from Ban Chiang, and mini-models of the whole Grand Palace complex that allow you to compare its past to its present.\nVia the Chao Phraya River Express Boat, jump off at Tha Maharaj pier, walk out to the street and take a right, and the Grand Palace will appear in front of you. Buses servicing the area include 1, 3, 6, 25, 44, 47, 53, 82, 91, 508 and 512. Beware of touts telling you that the temple is closed.\nAddress: Na Phra Lan Rd, Bangkok\nCoordinates (for GPS): 100º29'33.03\" E, 13º45'5.62\" N\nSee position in Apple or Google Maps: Apple Maps | Google Maps\nAdmission: 500 baht\nDavid Luekens first came to Thailand in 2005 when Thai friends from his former home of Burlington, Vermont led him on a life-changing trip. Based in Thailand since 2011, he spends much of his time eating in Bangkok street markets and island hopping the Andaman Sea.\nThese tours are provided by Travelfish partner GetYourGuide.\nOur top 10 other sights and activities in and around Bangkok","The Sacred Emerald Buddha\nThe world-famous Emerald Buddha is housed in The Temple of The Emerald Buddha (Wat Phra Keo) on the grounds of the Grand Palace in Bangkok, Thailand. This statue is an historic, extensively documented, and highly revered icon of Buddhism. Mindful of this context, Jeffery Bergman of PrimaGem in Bangkok (a longtime IGS member) and gem carver Aung Nyein have created an entirely new “Sacred Emerald Buddha.” This work was not intended to compete with or lessen the spiritual importance or historic value of the Emerald Buddha.\nIn 1994, a 3,600-carat (25.4 ounce) natural emerald crystal was discovered in Africa. The exact country of origin has been disputed (with possibilities ranging from Madagascar to Zambia). By September of that year, the large gemstone was exported to Thailand in search of a suitable buyer.\nUpon arrival, one astute gem dealer realized this was a very special crystal. He wanted to maximize its potential rather than breaking it up into smaller pieces as other competing dealers desired. After several months of intense negotiations, he finally won out. What followed was a quest for the best subject matter and design for this potentially world record-breaking emerald crystal.\nMany design ideas were considered. Ultimately, the shape of the crystal and the acknowledgement of the nation of Thailand as its final destination suggested a standing Buddha image. After extensive research into the history and art of Buddha images, the classic standing Buddha posture known in Thai as Harm Yhard was chosen. Traditionally, this was the Buddha’s admonition to his family members to stop quarrelling amongst themselves.\nThe world suffered a great loss when Taliban extremists destroyed the giant standing Buddhas of Bamiyan, Afghanistan in 2001. A standing Buddha image in pure emerald, a gem highly revered by the Islamic faith, seemed an appropriate replacement, especially with the theme of the Buddha’s message to “stop quarrelling amongst yourselves”!\nSeeking a suitable craftsman to carve a standing Buddha image in fragile emerald proved no easy task. Europeans are considered the world’s best gemstone carvers but they lack experience with Buddhist subject matter. China and Burma have many fine jadeite Buddha carvers, but both locations present complicated security issues. In the end, the decision to locate an experienced jadeite Buddha carver in Thailand seemed the best solution.\nJadeite carving factories were visited in Chanthaburi, Mae Sai, Chiang Mai, and Mae Sot. Eventually two were chosen to carve prototype images in jadeite and low-grade aquamarine (from the same gem family as emerald). Carver Aung Nyein, then 36-years old, was selected. Originally from Burma, Aung Nyein had lived in Mae Sot for 16 years. He had been carving Buddha images in jadeite for over 20 years and was considered a master in his community.\nWhat followed were weeks of studying the crystal with high intensity lights, rulers, calipers, and a sketchpad. Finally satisfied with his plan, Aung began his work. Measure, mark, cut, grind, measure, mark, cut, grind. The process continued for over a week before a distinct Buddha image began to emerge from the depths of the green crystal. As the sculpting continued, ever smaller grinding bits were used, as the fine detail of the Buddha demanded.\nPolishing the entire piece required several more weeks. Aung moved from extra fine sand paper to medium diamond powder and, finally, to the finest of all diamond powder in order to obtain the high gloss finish on the Sacred Emerald Buddha’s surface. Late one afternoon in February 2006, Aung announced he was finished. We all celebrated with a fine bottle of imported brandy.\nWith a great sense of pride, dignity, and honor, we present to the world the 2,620-carat “Sacred Emerald Buddha.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:b526e3e3-06af-4eb4-8bb3-26db0f143e6a>","<urn:uuid:3e896dda-49e6-4eca-83c2-fa742e3510e5>"],"error":null}
{"question":"Do professional indemnity insurance and arboricultural consultants' insurance serve the same purpose?","answer":"While both are types of professional insurance, they serve different purposes. Professional indemnity insurance protects against mistakes made at work that result in financial loss to clients after providing service or advice. For arboricultural consultants, public liability and professional indemnity insurance are specifically needed to cover legal liabilities, particularly when carrying out tree risk assessments.","context":["Selection and appointment of an arboricultural or tree expert\nIt is important to seek expert advice when applying for planning permission, managing your trees or woodland, ensuring that your trees are not a risk to people or property, investigating potential subsidence claims etc.\nAs it can be difficult to find the correct expert, this web-page provides some ideas on where and how to find the appropriate consultant.\nGuide to selecting and appointing an arboricultural (tree) consultant\nThe choice of arboricultural consultants able to undertake work in relation to planning applications or other tree work can be guided by the following principles:\nMembership of an appropriate institute or professional association\nMany arboricultural consultants are members of the Arboricultural Association, who can provide a list of registered consultants who have been found competent to provide arboricultural consultancy services.\nThe Institute of Chartered Foresters provides a register of tree professionals who specialise in forest, woodland and tree management and have been vetted for their professionalism, qualifications, and experience.\nWhere a Environmental Impact Analysis is required, a useful indication of competence of a consultancy or individuals is membership of the Institute of Environmental Management and Assessment.\nKnowledge of the local area\nKnowledge of the local area is useful in understanding the local soil types, ecology, topography etc and in having good contacts with local contractors and suppliers, for example specialist plant nurseries. It can also lead to a better understanding of local arboricultural policies, constraints and opportunities.\nRelevant experience and knowledge\nAny arboricultural consultant appointed should be qualified and experienced in the relevant fields. For example, an arboricultural consultant with extensive experience of preparing tree assessments for residential development sites may not have the appropriate expertise to advise on the management of ancient trees.\nIn house expertise\nNot all environmental consultancies have their own in-house tree specialists, so contract arboricultural consultants may be used, particularly on sites that require a multi-skilled approach. It is advisable to find out who the arboricultural consultant will be, and what professional qualifications or relevant expertise he or she possesses.\nIt is important to ascertain whether the consultant you have appointed has all the appropriate legal documentation, licences and qualifications that are required, both within their profession and for health and safety.\nBefore you appoint, find out if your expert is based locally and if you will be charged for travelling time and mileage.\nQuotations and detailed written proposals\nIt is always advisable to seek several quotations that include details of the work the consultants would undertake. It may be helpful to ask for a day rate for any additional work that may be needed. Be very clear in explaining what type of output you wish from the consultant - a detailed written report, a verbal report, liaison with the Planning Authority etc. It will then be easier to compare quotations.\nPublic Liability and Professional Indemnity Insurance should be held by the consultants to cover the costs of any legal liabilities established against them. This is particularly important where the arboricultural consultant is carrying out risk assessments of trees.\nReferences and recommendations\nIt may be useful to ask any potential consultant for references from similar projects they have carried out. Local contacts can also be a good source of recommendations.","What does my business insurance policy cover me for?\nInsurance is one of those things that you must have, but often loathe spending time and money on; partly because it is something you may never need. Only when something unthinkable happens is the true value of the correct cover and the right insurance policy fully appreciated.\nAs every client’s needs and businesses are individual, it is difficult to write a one size fits all guide, but below I have tried to summarise the basics to help you understand what cover you and your business may need.\nPublic liability insurance\nPublic Liability Insurance is an essential product for any business as it protects against legal liabilities towards innumerable third parties, even trespassers! All businesses need this cover!\nPublic liability includes cover against death or bodily injury to third party persons, or third party property from incidents arising from your business activities.\nA good example would be a window cleaner who is cleaning a second floor window on a busy street and drops his bucket. There could be many possible outcomes and claims from this.\nAnother example would be a builder who leaves some tools out when nipping to answer his phone while a member of the public is walking past and trips up, breaking their wrist.\nPublic Liability Insurance Cover limits will often start at £2,000,000. In some cases, you may find a contract requires you to hold £5,000,000 or even £10,000,000, which is often the case if you’re working on a local council or government contract. We can quote for these limits upon referral.\nProducts Liability Insurance\nThis covers the same type of insurance as Public Liability (legal liabilities), the difference being that this is protecting you for liability arising from a product supplied, installed, maintained or manufactured by you. It also covers the supply of goods to someone else which through your negligence causes injury or damage, as well as solicitors fees and all costs and litigation expenses, damages and claimant costs which you would be legally liable for.\nThis is not the same as a warranty however and only provides insurance for damage or injury caused by your product. It is also not a ‘product recall’ cover, although with some products this may be required.\nUs, like most insurers sell our Public and Products Liability as one package.\nEmployers’ liability insurance is cover required by law. It provides insurance for employees who are taken ill, or who have an accident, whilst working for you.\nThere are some rare exceptions to businesses requiring this cover, however, it is usually sold in a package alongside Public and Products Liability and possibly other covers as well.\nAlthough the law states £5,000,000 is required, the insurance standard limit of indemnity is £10,000,000.\nPlease note, you are required to display a certificate of insurance where your employees can see it – on a noticeboard and/or intranet, for example.\nIf you need to arrange an insurance policy to cover for your building, maybe your shop or office, you need to firstly calculate the rebuild value of your property (how much it would cost to rebuild the property from scratch including fixtures and fittings, parts and labour, and professional costs such as architect’s fees). It is always this figure and not the resale or market value that is the basis of the insurance.\nIf you’re not sure what the rebuild cost should be, you can get this from a qualified surveyor, your mortgage advisor or letting agent, or if you’ve recently had a property survey. You can visit http://abi.bcis.co.uk/ to use the Association of British Insurers’ rebuilding cost calculator, which could help.\nContents, Fixtures and Fittings\nContents cover protects your equipment, furniture and fixtures and fittings (such as shelving and display cases) against theft, vandalism or damage caused by fire or flood.\nIf you rent the buildings which you occupy from a Landlord, check through your commercial insurance policy to ensure you have an item for Tenants Improvements. Your own Contents/Fixtures & Fittings insurance is likely to only cover you for the value of those items you would take with you should you leave. If having moved into the premises you have installed fixtures and fittings that will not be taken with you should you leave, these items will be regarded as Tenants Improvements e.g. partition walls and fixed cupboards & lighting. Your Landlord’s Insurance only covers Landlord’s Fixtures and Fittings, and therefore as being the tenant, you would require your own Tenants Improvements insurance to cover these remaining items.\nStock cover protects the items you sell against theft, vandalism or damage caused by fire or flood.\nSome property insurance policies (where subsidence is requested) cover loss or damage caused by subsidence, heave and landslip. However, they only cover the cost of repairing the loss or damage. They do not cover the cost of preventing further subsidence.\nThis means the cost of repairing damage (such as cracks) to the building’s superstructure is generally covered , but the cost of stopping the building from moving in the future is not covered.\nDeterioration of stock/Frozen Food\nThis is a cover for accidental defrosting of frozen food, typically this is covered subject to freezer units being under 10 years old and annually maintained (as detailed in the\nwarranties/endorsements section in your insurance policy).\nGoods in Transit\nGoods (generally stock) that have departed from the premises but have not yet arrived at the delivery point. This cover also extends to include contents cover from a cash and carry, although this is dependent on your insurers policy wording.\nMoney cover is, as the name suggests, cover for any money that the business may have on their premises or in transit. If you have money in an overnight safe, or have employees who handle money or take it to the bank, then Money cover is worth considering. We give automatic limits on all our quotes with an option to increase these during the quotation stages.\nLoss of Rent Receivable\nThis cover pays out in the event of a claim for loss or damage caused, for example by fire or flood, that means your tenants can no longer stay in the property. Loss of rent insurance won’t protect you against your tenants simply defaulting on their rent, as that is a separate matter.\nLegal expenses cover will empower you to pursue or defend your commercial legal rights in the future. Your business could be protected from legal costs arising from: employment disputes and compensation awards, tax protection, property protection, compliance and regulation. This is strictly subject to immediate contact via the helpline and use of insurer appointed solicitors.\nBusiness Interruption Cover\nThis covers Loss of trading profits, including additional cost of working. Choose 12 or 24 months indemnity.\nWhen deciding upon the length of the period you need to work out how long it would take your business to recover back to today’s trading levels following a Fire, Theft or Flood. – Levels vary from 12 to 24 months or even longer. Standard cover is typically £250,000 over a 12 months indemnity period; if a longer period or higher amount is required this is available at the quotation premium offer stage by entering the additional amounts required.\nProfessional Indemnity Insurance\nProfessional indemnity insurance protects you from mistakes you make at work that result in a financial loss to your client, specifically after you’ve provided them with a service or advice.\nWe will write more on this later, but some of the most common professions requiring professional indemnity insurance are:\n- Architects and engineers\n- Accountants and bookkeepers\n- IT Contractors\nInsurance Terms Defined\nWith all property insurance, particularly buildings and contents, it’s important that you don’t ‘underinsure’. Underinsurance commonly occurs when someone insures a lower value than the total, thinking that it may save money, or they’ll never need it all anyway!\nIf you haven’t insured the correct total value then you will be ‘underinsured’ and most insurers will apply ‘average’ to your claim, proportionately reducing the amount you are paid out. Please see our article on that here.\nLimit of Indemnity\nThis is the maximum sum that the insurer will pay for any event, occurrence or accident, or in aggregate in any one year on your insurance policy.\nIndemnity Period is the period during which the business’ results are affected due to the loss or damage, beginning with the date of the loss or damage and ending not later than the Maximum Indemnity Period. The Maximum Indemnity Period is stated within your Policy Schedule.\nFraudulent liability claims\nFraudulent claims are becoming increasingly more common and your insurer will still protect you, should you fall victim to such.\nAlways notify your insurer as soon as an incident has occurred, whether you believe it will lead to a claim or not, and even if you suspect it is a dubious incident. The sooner your insurer has the information, the better the job they can do of protecting you.\nDon’t forget though, we are a friendly bunch! If you have a specific question or query about your insurance policy, please give us a call, a message on live chat, an email or come to the office and see us – we are always happy to help!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"}],"document_ids":["<urn:uuid:716b68bd-6417-45e6-9dee-94004d94cb97>","<urn:uuid:6d47ef3e-bafe-4251-a2e0-a9acdcb80ea0>"],"error":null}
{"question":"Do cold weather and getting wet directly cause pneumonia?","answer":"No, cold weather and getting wet do not directly cause pneumonia. Pneumonia is caused by infectious agents like viruses, bacteria, and fungi. The most common causes are bacteria like Streptococcus pneumoniae and Haemophilus influenzae type b, as well as viruses. While getting wet can weaken your immune system by lowering your body temperature, making you more susceptible to these infectious agents, it does not directly cause pneumonia. The infection occurs when these germs enter the lungs and cause inflammation in the air sacs called alveoli, leading to a buildup of fluid and pus that makes breathing difficult.","context":["- In 2019 an estimated 5.2 million children under 5 years died mostly from preventable and treatable causes. Children aged 1 to 11 months accounted for 1.5 million of these deaths while children aged 1 to 4 years accounted for 1.3 million deaths. Newborns (under 28 days) accounted for the remaining 2.4 million deaths.\n- An additional 500,000 older children (5 to 9 years) died in 2019.\n- Leading causes of death in children under-5 years are preterm birth complications, birth asphyxia/trauma, pneumonia, congenital anomalies, diarrhoea and malaria, all of which can be prevented or treated with access to simple, affordable interventions including immunization, adequate nutrition, safe water and food and quality care by a trained health provider when needed.\n- Older children (5-9 years) had one of the largest declines in mortality since 1990 (61%), due to a decline in infectious diseases. Injuries (including road traffic injuries and drowning) are the leading causes of death among older children.\nWho is most at risk?\nChildren under the age of 5\nSubstantial global progress has been made in reducing child deaths since 1990. The total number of under-5 deaths worldwide has declined from 12.6 million in 1990 to 5.2 million in 2019. Since 1990, the global under-5 mortality rate has dropped by 59%, from 93 deaths per 1,000 live births in 1990 to 38 in 2019. This is equivalent to 1 in 11 children dying before reaching age 5 in 1990, compared to 1 in 27 in 2019.\nAlthough the world as a whole has been accelerating progress in reducing the under-5 mortality rate, difference exist in under-5 mortality across regions and countries. Sub-Saharan Africa remains the region with the highest under-5 mortality rate in the world, with 1 child in 13 dying before his or her fifth birthday, 20 years behind the world average which achieved a 1 in 13 rate in 1999. Two regions, Sub-Saharan Africa and Central and Southern Asia, account for more than 80 per cent of the 5.2 million under-five deaths in 2019, while they only account for 52 per cent of the global under-five population. Half of all under-five deaths in 2019 occurred in just five countries: Nigeria, India, Pakistan, the Democratic Republic of the Congo and Ethiopia. Nigeria and India alone account for almost a third of all deaths.\nAt the country level, mortality rates for older children ranged from 0.2 to 16.8 deaths per 1,000 children aged 5 years. As for children under five, higher mortality countries are concentrated in sub-Saharan Africa. Countries with the highest number of deaths for 5 to 9-year-olds include India, Nigeria, Democratic Republic of the Congo, Pakistan and China.\nTop 10 countries with the highest numbers of deaths (thousands) for children under-5 years, 2019\n|Country||Under-five deaths||Lower bound||Upper bound|\n|Democratic Republic of the Congo||291||187||440|\n|United Republic of Tanzania||103||78||172|\nGlobally, infectious diseases, including pneumonia, diarrhoea and malaria, along with pre-term birth, birth asphyxia and trauma, and congenital anomalies remain the leading causes of death for children under five. Access to basic lifesaving interventions such as skilled delivery at birth, postnatal care, breastfeeding and adequate nutrition, vaccinations, and treatment for common childhood diseases can save many young lives. Malnourished children, particularly those with severe acute malnutrition, have a higher risk of death from common childhood illness such as diarrhoea, pneumonia, and malaria. Nutrition-related factors contribute to about 45% of deaths in children under-5 years of age.\nThe patterns of death in older children reflect the underlying risk profiles of this age group, with a shift away from infectious diseases of childhood and towards accidents and injuries, notably drowning and road traffic injuries. The rise of injury deaths changes the nature of interventions to improve older child survival. There is a shift from health sector actions to prevent and treat the infectious diseases of early childhood towards other government sectors including education, transportation and road infrastructure, water and sanitation and law enforcement. All of these need to work together to prevent premature mortality in older children.\nGlobal response: Sustainable Development Goal 3.2.1\nThe Sustainable Development Goals (SDGs) adopted by the United Nations in 2015 were developed to promote healthy lives and well-being for all children. The SDG Goal 3.2.1 is to end preventable deaths of newborns and under-5 children by 2030. There are two targets:\n- Reduce newborn mortality to at least as low as 12 per 1 000 live births in every country; and\n- Reduce under-five mortality to at least as low as 25 per 1,000 live births in every country.\nTarget 3.2.1 is closely linked with target 3.1.1, to reduce the global maternal mortality ratio to less than 70 deaths per 100 000 live births, and target 2.2.1 on ending all forms of malnutrition, as malnutrition is a frequent cause of death for under-5 children. These have been translated into the new “Global Strategy for Women’s, Children’s and Adolescent’s Health” (Global Strategy), which calls for ending preventable child deaths while addressing emerging child health priorities. Member States need to set their own targets and develop specific strategies to reduce child mortality and monitor their progress towards the reduction.\nIn 2019, 122 countries have met the SDG target for under-5 mortality and a further 20 countries are expected to meet the target by 2030 if current trends continue. However, accelerated progress will be needed in 53 countries, which will not achieve the target by 2030 on current trends. Thirty of these countries will need to double their current rate of reduction and 23 will need to triple their current rate of reduction. Meeting the SDG target would reduce the number of under-5 deaths by 11 million between 2019 and 2030. Focused efforts are still needed in Sub-Saharan Africa and South East Asia to prevent 80 per cent of these deaths.\nWHO calls on Member States to address health equity through universal health coverage so that all children are able to access essential health services without undue financial hardship. Moving from “business as usual” to innovative, multiple, and tailored approaches to increase access, coverage, and quality of child health services will require strategic direction and an optimal mix of community and facility-based care. Health sector and multisectoral efforts are also needed to overcome the inequalities and the social determinants of health.","What Happens To Your Lungs When You Are Diagnosed With Pneumonia\nPneumonia, as discussed above, is an infection in the lungs that mainly leads to inflammation in the air sacs called alveoli. Pneumonia leads to the formation of pus and fluid in the lungs, which hinders the breathing process of the individual. There are two categories of patients who are suffering from Pneumonia – Viral pneumonia, and Bacterial pneumonia. Both these types of Pneumonia are contagious and can spread easily from one infected person to another healthy body. In simpler words, Pneumonia damages the lungs by causing inflammation and jamming the way for the oxygen to enter and mix with the bloodstream. Thus Pneumonia can lead to serious breathing issues and death.\nWhen Should I See My Doctor\nPneumonia can be life-threatening if left untreated, especially for certain at-risk people. You should call your doctor if you have a cough that wont go away, shortness of breath, chest pain, or a fever. You should also call your doctor if you suddenly begin to feel worse after having a cold or the flu.\nTrouble In Breathing Due To Inflammed Air Sacs Or Alveoli\nYou may experience a steady drop in your breathing rate or an unexplained rise in your breathing counts. One may also notice that there is sudden trouble which one may notice every time he/she breathes. This condition is also known as laboured breathing. “The patient may notice that the breathing rate post-COVID recovery has drastically changed. It is either rapid or shallow. One can also find him/herself becoming breathless even while resting,” Dr. Mukherjee told TheHealthSite.com.\nYou May Like: Do You Have To Get The Pneumonia Vaccine Every Year\nLimit Contact With Others\nOne of the best things you can do when recovering from pneumonia is to limit your contact with others. As weve learned throughout the COVID-19 pandemicwhich can cause viral pneumoniastaying at least six feet away from others reduces the amount of viral or bacterial content they are exposed to as you breathe or talk.\nCan Cold Weather Cause Pneumonia\nPneumonia is a form of acute respiratory infection that affects the lungs. The lungs are made up of small sacs called alveoli, which fill with air when a healthy person breathes. When an individual has pneumonia, the alveoli are filled with pus and fluid, which makes breathing painful and limits oxygen intake.\nPneumonia is the single largest infectious cause of death in children worldwide. Pneumonia killed 808 694 children under the age of 5 in 2017, accounting for 15% of all deaths of children under five years old. Pneumonia affects children and families everywhere but is most prevalent in South Asia and sub-Saharan Africa. Children can be protected from pneumonia, it can be prevented with simple interventions, and treated with low-cost, low-tech medication and care.\nIn Nigeria, 19% of child deaths were due to pneumonia in 2018, and it was the biggest killer of children under-five in 2017. There are an estimated 56 million episodes of lung infections among Nigerian children every year. Although not all episodes will lead to death, these infections nevertheless cause suffering and require treatment\nPneumonia is caused by a number of infectious agents, including viruses, bacteria, and fungi. The most common are:\nStreptococcus pneumoniae the most common cause of bacterial pneumonia in children\nHaemophilus influenzae type b the second most common cause of bacterial pneumonia\nAlso Check: Do You Have A Dry Cough With Pneumonia\nVisit A Mana Clinic Today\nEven healthy people can get the flu and suffer complications from the flu. Dont take your chances with pneumonia. Get your flu shot today, and talk your doctor if you suspect that you have the flu, or if you have cold symptoms that last more than a few days.\nmyMANA makes scheduling appointments easy, and MediServe Walk-In clinics are are open from 7:00 a.m. to 7:00 p.m. 7 days a week for your convenience.\nOur pediatric walk-in clinic is open Monday Friday 8 am to 7:30 pm and Saturday 8 am to 11 am.\nSeveral Family Medicine clinics and Fayetteville Diagnostic Clinic offer walk-in hours as well or you can request a same day appointment.\nWhen Would I Need To Be Hospitalized For Pneumonia\nIf your case of pneumonia is more severe, you may need tostay in the hospital for treatment. Hospital treatments may include:\n- Fluids, antibiotics and other medicines given through an IV\n- Breathing treatments and exercises to help loosen mucus\nPeople most likely to be hospitalized are those who are most frail and/or at increased risk, including:\n- Babies and young children\n- People with weakened immune systems\n- People with health conditions that affect the heart and lungs\nIt may take six to eight weeks to return to a normal level of functioning and well-being if youve been hospitalized with pneumonia.\nDon’t Miss: Allergic Reaction To Pneumonia Shot\nDebunked: 5 Myths About Pneumonia\nDirector of Vaccine Delivery at The Bill & Melinda Gates Foundation\nToday the global health community recognizes the third annual World Pneumonia Day with the release of two new studies on pneumonia and events in more than 15 countries calling attention to the disease, which remains the world’s leading killer of young children. Yet despite renewed global attention and its dramatic toll, pneumonia remains one of the world’s least-understood conditions.\nAs we recommit ourselves to defeating this deadly disease on Nov. 12, let’s tackle a few of the leading myths head-on:\nPneumonia is really just a bad cold. In fact, it’s much worse. Pneumonia is an infection of your lungs that can require antibiotics or treatment in a hospital. A “common cold” usually lasts a few days or perhaps a week or two, and causes a runny nose, sore throat, sneezing and coughing. Pneumonia, on the other hand, kills more than 50,000 Americans and more than 1 million children worldwide each year.\nThe confusion exists because, at its start, pneumonia symptoms can be similar to those of a cold, including cough, fever and shortness of breath. Unfortunately, that’s where the similarities end. Left untreated, most colds will run their course as the body’s immune system naturally restores health. In contrast, ignoring early signs of bacterial pneumonia can be a death sentence.\nWhat Are The Common Causes Of Pneumonia For Older Adults\nPneumonia is typically caused by bacteria or viruses. These germs are breathed into your lungs. When your immune system is strong you may be able to quickly fight these germs off.\nThe elderly may be more likely to have the germs cause an infection in their lungs due to weakened immune systems.\nEven if they are usually healthy and fit, they can get pneumonia after you have caught a simple cold or flu. They may even catch pneumonia from being in the hospital.\nThe causes of pneumonia are broken down into three groups:\nYou May Like: How To Tell If It’s Pneumonia\nWhy Is Pneumonia Dangerous What Are The Possible Complications Of Leaving This Condition Untreated\nPneumonia can usually be treated successfully without leading to complications. However, complications like the ones listed below can develop in some patients, especially those in high-risk groups.\nFluid or pus could get accumulated between the covering of the lungs and the inner lining of the chest wall this is called a pleural effusion . A chest tube may be needed to drain the fluid/pus.\nPus might collect in the lung area infected with pneumonia . Rarely this may require surgery.\nBacteria can spread to the bloodstream and other organs. This is a serious complication since the infection can cause the blood pressure to be dangerously low.\nAlthough most people recover from pneumonia, it can be fatal in some cases. Approximately 5 to 10 percent of patients admitted to a general medical ward, and almost 30 percent of patients with severe infection admitted to an intensive care unit can die.\nCauses And Risk Factors Of Pneumonia\nHow do you get pneumonia? The majority of the germs that cause infection are spread from person to person through droplets, from coughing or sneezing.\n- A weakened immune system due to human immunodeficiency virus or cancer\nPeople who smoke are at higher risk for pneumonia, as are people on immunosuppressive medications, and people who are frequently in close, crowded spaces with others, such as college students and military personnel.\nAlso Check: When Can You Get Pneumonia Vaccine\nSpreading Pneumonia To Others\nIf your pneumonia is caused by a virus or bacteria, you may spread the infection to other people while you are contagious. How long you are contagious depends on what is causing the pneumonia and whether you get treatment. You may be contagious for several days to a week.\nIf you get antibiotics, you usually cannot spread the infection to others after a day of treatment.\nWhat Are The Symptoms Of A Common Cold\nThe common cold is a simple illness that typically is not a serious infection. Its little more than a nuisance unless, of course, you’re the one with the cold symptoms.\n“Colds are caused by viruses, and the most common virus that causes the cold is rhinovirus,” says Aaron M. Milstone, MD, assistant professor of pediatric infectious diseases at Johns Hopkins Children’s Center in Baltimore.\nWhile a common cold is no fun to deal with, it is not as dangerous as the influenza virus, which can spread to other people more quickly, and even kill, adds Dr. Milstone. There are also far fewer hospitalizations associated with the common cold than with the flu, he adds.\nThe symptoms of the common cold often include:\n- Some muscle aches and headaches\n- Low or no fever\nGenerally, says Milstone, people feel bad and a little run down for a couple of days, then start to perk up as the cold runs its course.\nA good way to tell whether you have the common cold or the flu is by how quickly the symptoms appear. Symptoms of the common cold take their time. Flu symptoms, on the other hand, hit fast.\nRecommended Reading: Do You Need Pneumonia Shot Every Year\nWhat Are The Signs And Symptoms Of Pneumonia In Children\nThe signs and symptoms of pneumonia in children vary from child to child and also depend on your childs age, cause of the infection, and severity of their illness.\nUsual symptoms include:\n- Cry more than usual. Are restless or more fussy.\nAdolescents have the same symptoms as adults, including:\n- Difficulty breathing/shortness of breath.\n- Chest pain.\nNewborns are at greater risk of pneumonia caused by bacteria present in the birth canal. In young children, viruses are the main cause of pneumonia.\nPneumonia caused by bacteria tends to happen suddenly, starting with fever and fast breathing. Symptoms appear more slowly and tend to be less severe when pneumonia is caused by viruses.\nPneumonia From Getting Wet Where Does That Come From\nFacts About Pneumonia\nDespite what your parents and grandparents said, a person cant actually catch pneumonia from getting wet. What people catch is a bacteria or virus that can cause pneumonia. Pneumonia refers to an infection of the lungs caused by these organisms. This infection causes fluid and mucus to block the alveoli, making it difficult for oxygen to travel through your lungs. This will make it harder to breathe, especially if both of your lungs are infected.\nWhere Does the Old Wives Tale Come From ?\nRemember, pneumonia is caused by a bacteria or virus. But you dont necessarily get the bacteria or viruses from getting wet either. What happens is that your immune system can be weakened when youre dealing with physical stresses such as hypothermia and hyperthermia. Just think, when you get wet, your body temperature drops, which can impact your immune system. When your immune system isnt working like it should, you become more susceptible to bacteria and viruses that are all around us.\nEven everyday stress can weaken your immune system and make you more prone to illnesses in general. And because little kids have immune systems that arent fully developed and elderly folks have weaker immune systems, theyre more vulnerable to getting sick, including pneumonia. So although you cant catch pneumonia directly from getting wet, you probably understand what your parents were trying to say now.\nWhen to See a Doctor for Pneumonia\nYou May Like: When Should You Get The Pneumonia Shot\nCaring For Your Symptoms At Home\nMany chest infections aren’t serious and get better within a few days or weeks. You won’t usually need to see your GP, unless your symptoms suggest you have a more serious infection .\nWhile you recover at home, you can improve your symptoms by:\n- getting plenty of rest\n- drinking lots of fluid to prevent dehydration and to loosen the mucus in your lungs, making it easier to cough up\n- treating headaches, fever and aches and pains with painkillers such as paracetamol or ibuprofen\n- drinking a warm drink of honey and lemon to relieve a sore throat caused by persistent coughing\n- raising your head up with extra pillows while you’re sleeping to make breathing easier\n- using an air humidifier or inhaling steam from a bowl of hot water to ease your cough\n- stopping smoking\nAvoid cough medicines, as there’s little evidence they work. Coughing actually helps you clear the infection more quickly by getting rid of the phlegm from your lungs.\nAntibiotics aren’t recommended for many chest infections. They only work if the infection is caused by bacteria, rather than a virus.\nYour GP will usually only prescribe antibiotics if they think you have pneumonia, or you’re at risk of complications such as fluid building up around the lungs .\nIf there’s a flu outbreak in your local area and you’re at risk of serious infection, your GP may also prescribe antiviral medication.\nHow You Catch Pneumonia\nWhile anyone can catch pneumonia, some people are more likely to come down with illness when coming into contact with the germs. Like many other illnesses, pneumonia is caught through contact with the bacteria or virus that creates pneumonia.\nCoughing and sneezing are the most common ways these germs spread.\nIts also possible to catch the illness by touching something like a counter or door handle, sharing cups and utensils, and touching your face without washing your hands first.\nRead Also: How Often Are You Supposed To Have A Pneumonia Shot\nHow Do You Get Pneumonia\nHave you ever been told to bundle up to avoid catching pneumonia? Or told a friend or family member not to walk outside with wet hair because he or she could get it? It might surprise you to find out that neither cold weather nor wet hair can cause you to catch pneumonia. In fact, pneumonia in itself isnt contagious, so you cant really catch it at all.\nIf you are wondering how do you get pneumonia, or have any other questions about this condition, FastMed can help. We are open 365 days a year to provide treatment for non-life-threatening illness and injuries, as well as ready to answer all of your health related questions.\nWhat Is Pneumonia Symptoms Causes Diagnosis Treatment And Prevention\nPneumonia is a lower respiratory lung infection that causes inflammation in one or both lungs.\nAir sacs in your lungs called alveoli can then fill up with fluid or pus, causing flu-like symptoms that can persist for weeks or cause rapid deterioration of breathing leading to hospitalization. Pneumonia doesn’t respond to over-the-counter cold and sinus medicines.\nPneumonia comes in different forms and is caused primarily by bacteria or viruses, which are contagious, and less commonly by fungi or parasites.\nThe type of germ contributes to how serious the illness can become and how its treated. The severity of an infection depends on many factors, including your age and overall health, as well as where you may have acquired the illness.\nYou May Like: Best Treatment For Walking Pneumonia\nTreatment And Medication Options For Pneumonia\nA lot of treatment aspects, as well as outcome, depend on the person, as well as the type of pneumonia they have, says Dr. Barron. Sometimes youll be fine just resting, but if you have things like trouble breathing, you should get to a doctor right away.\nYour doctor will outline a plan that’s specific to you, considering the type of pneumonia you have, the severity of the condition, your age, and your overall health. From there, you’ll know whether you can be treated at home or need to go to the hospital, and whether you require antibiotics.\nCan You Really Catch Pneumonia From Getting Wet\nDont go out in the rainyou might catch pneumonia. Thanks to our parents and grandparents, that all-too-familiar phrase rings through our minds each time we step out into cold, rainy weather. But just as youre about to parrot back that same exact reminder to your kids as they walk out into the rain, you pause for a second and wonder, Can you really catch pneumonia from getting wet? Was this just another old wives tale? How exactly do you catch pneumonia?\nAlso Check: Where Can You Get Pneumonia Shots"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:3431dc5f-52d7-4d9e-bb67-eafdf4965714>","<urn:uuid:6e5eb4d3-e645-4bc8-90d6-de5503b7add6>"],"error":null}
{"question":"What role do diagnostic tests play in monitoring Sturge-Weber syndrome compared to blood coagulation disorders? 🤔","answer":"In Sturge-Weber syndrome, perfusion MR imaging is used to track treatment response and neurologic progression, while urine vascular biomarkers are being developed to monitor disease severity. For blood coagulation disorders, monitoring relies on different measures - specifically prothrombin time needs to be frequently monitored, particularly when changing medications, and platelet counts are used to track disease status and guide treatment decisions.","context":["Changes in venous anatomy associated with sustained venous insufficiency in Sturge-Weber disease (Csaba Juhasz, USA)\nOk, looking up Sturge Weber disease again.http://www.sturge-weber.org/about-sws/c ... drome.html\nIt affects the brain and eyes. An overabundance of capillaries make for a port wine stain on the face, and excessive blood vessel growth on the surface of the brain lead to neurological issues.\nHere's a picture of Dr. Csaba Juhasz. He's at Wayne State University. I like him already for his name alone. http://www.neurology.med.wayne.edu/depa ... p?id=42219\nDr. Juhász’s research interests are in functional and structural neuroimaging of epilepsy, brain tumors and developmental brain disorders, with a particular interest in the pathophysiology and progression of Sturge-Weber syndrome. He performed extensive research applying multimodal neuroimaging, combining magnetic resonance imaging techniques with PET imaging using various radiotracers to measure brain glucose metabolism, benzodiazepine receptor binding and tryptophan metabolism. He has also combined these techniques with EEG to improve localization of epileptic foci in patients with medically uncontrolled epilepsy and provides multimodal imaging support to the pediatric epilepsy surgery program at CHM. Dr. Juhász is the principal investigator of several grant projects funded by the National Institutes of Health to study progression of brain structural and functional abnormalities in Sturge-Weber syndrome and to explore the clinical use of tryptophan PET imaging in the detection and monitoring of brain tumors and extracerebral cancers\nCould we do PET imaging using radiotracers to measure brain glucose metabolism in CCSVI? If there were changes from before CCSVI treatment compared to after CCSVI treatment, that might be relevant.\nIt might only be of use in the study of epilepsy, I don't know?http://www.ncbi.nlm.nih.gov/pmc/articles/PMC557957/\nOh, this is interesting: http://sturgeweber.kennedykrieger.org/c ... search.jsp\nThis work demonstrated that perfusion MR deficits correlate with the severity of neurologic impairment in SWS indicating that it will likely be useful for tracking response to treatment in a clinical trial and neurologic progression.\nIn SWS, PWI indicates cerebral hypoperfusion predominantly due to impaired venous drainage, with only the most severely affected regions in some patients also showing arterial perfusion deficiency. The extent and severity of the perfusion abnormality and neuronal loss/dysfunction reflect the severity of neurological symptoms and disability, and the highest correlation is found with the degree of hemiparesis.\nWhat's that? Impaired venous drainage can lead to cerebral hypoperfusion, and the extent of the hypoperfusion will reflect the severity of neurological symptoms? That is very relevant to what we are seeing in CCSVI. http://www.ncbi.nlm.nih.gov/pubmed/18056693\nDecreased arterial flow velocity and increased pulsatility index in the middle cerebral artery and posterior cerebral artery suggests a high resistance pattern that may reflect venous stasis and may contribute to chronic hypoperfusion of brain tissue.\nWe report the case of a 9-month-old boy with Sturge-Weber syndrome and new onset of seizure. Perfusion MR imaging showed early changes compatible with impaired venous drainage in the affected hemisphere, whereas proton MR spectroscopic imaging revealed a focal parietal area of elevated choline without significant alteration of N-acetylaspartate levels.\nAgain, impaired venous drainage.\nFibronectin, which is critical in angiogenesis and blood vessel development, is abnormally expressed in Sturge-Weber syndrome; in CCSVI, fibronectin is presumably normal.\nBoston Urine Testing\nThe purpose of this study is to determine if urine vascular factors in SWS can help us understand more about the pathogenesis of SWS and whether it can be used to monitor response to treatment or predict outcome.\nThis study is measuring blood vessel factors in the urine of individuals with Sturge-Weber syndrome in collaboration with the laboratory of Dr. Marsha Moses. Urine vascular biomarkers have been developed for other vascular malformations to monitor response to treatment or predict disease severity and we are working on similar progress with Sturge-Weber syndrome.\nCould urine vascular biomarkers be found for CCSVI?","Hemorrhagic disorders of vascular origin\n- Purpura simplex occurs with a higher susceptibility to ecchymosis, and for an increased vascular fragility. The disease is not serious.\n- Hereditary hemorrhagic telangiectasia or Rendu-Osler-Weber disease with generalized vascular malformations can bleed frequently provoking epistaxis and sometimes serious hemorrhage of gastrointestinal origin.\n- The treatment is that of the hemorrhagic complication and of the anemia caused.Gastrointestinal disorders are frequent, including abdominal pain and bleeding, and renal injuries with hematuria and proteinuria. Renal injury sometimes progresses to chronic renal insufficiency.The episode subsides in a few weeks, but frequently relapses after a disease-free interval. The treatment is symptomatic and corticoids help to improve the edema, and abdominal and joint pain.Schönlein-Henoch purpura is sometimes associated with the use of drugs and is characterized by purpura skin rash in the feet, legs, buttocks and leg extensor parts and often with fever, polyarthralgia and edema of the large joints, hands and feet.\n- Some drugs, such as long-term corticoids, penicillins and sulfonamides, can also cause hemorrhagic disorders.\nAdvice on Hemorrhagic disorders of vascular origin\n- Purpura simplex does not interfere with driving.\n- Any hemorrhagic manifestation prevents from driving until the causal diagnosis is established and the hemorrhagic site is controlled.\n- If nasal bleeding occurs while driving, it is very important to keep calm and stop the car as soon as possible ensuring the environment, which includes looking for the appropriate place, far from curves, such as the hard shoulder or entry to a track.\n- If the condition does not subside in few minutes with compression, local ice, cold environment, it is recommended to ask for assistance to be transferred to an emergency department.\n- In addition, the patient cannot drive while bleeding from the nose, that forces him to have one hand busy, with difficulty to see, to control the car controls, and the lack of attention in driving from being concerning with bleeding.\n- Furthermore, the patient cannot drive while bleeding from the nose because it can be the symptom of another more serious disease that can also interfere with driving.\n- Once the epistaxis is controlled and the cause identified, the physician will recommend driving if there is no risk of relapse of the clinical condition.\n- If the patient has received medication, he will not leave the emergency driving even if he feels well.\n- While the tamponade is in place, the patient can suffer craniofacial pain. It is advised against driving until it is removed by the physician and the absence of new bleeding is verified.\n- The ability to drive is limited by lightheadedness, drowsiness and lack of attention, that are caused by anemia from repeated bleeding.\n- Since drivers are more susceptible for the risk of bleeding, they should be recommended to maximize their caution when driving, in order to avoid any crash no matter how minimal it is.\nAdvice on Schönlein-Henoch purpura\n- During the symptomatic period, the patient cannot drive, and he must be warned about it.\n- The favorable evolution of the patient without organ involvement will enable the patient to drive again, always with a report from his physician in this regard.\n- In the event of any evidence of recurrence, the patient cannot drive and must inform his physician and follow his directions.\nAdvice on Some drugs, such as long-term corticoids\n- Any hemorrhagic episode prevents from driving until the hemorrhagic site is controlled and causal treatment is adjusted or removed.\n- Lightheadedness, drowsiness, and lack of attention caused by anemia limit the ability to drive until the patient is stabilized.\nHemorrhagic disorders from platelet disease\nThrombocytopenia can be due to bone marrow injury, splenic sequestration, dilution, and increase in its destruction or use.\nThrombocytopenia can be associated in HIV infection, recent blood transfusion, significant alcohol intake, immunological disorders, systemic lupus erythematosus, lymphoma, and in therapy with heparin.\nOther drugs that can cause thrombocytopenia in susceptible patients include quinidine, sulfonamides, oral antidiabetics, gold salts, rifampicin, thiazides, methyldopa, estrogens and chemotherapeutic agents.\nSevere thrombocytopenia causes a hemorrhagic condition with multiple petechiae in the\nlegs, ecchymosis, epistaxis, and gastrointestinal, urologic or vaginal hemorrhages. Severe gastrointestinal and central nervous system bleeding can be very serious, and life-threatening.\nFever usually occurs in thrombocytopenia secondary to infection, in active systemic lupus erythematosus, and in thrombotic thrombocytopenic purpura.\nSplenomegaly is frequent in patients with thrombocytopenia secondary to splenic platelet-sequestration, to lymphoma, or to myeloproliferative disease.\nIn secondary thrombocytopenia, the cause should be corrected, including discontinuation of heparin and the drugs in patients susceptible to them, treat the infection causing endotoxins, or induce remission in a patient with acute leukemia.\n- In most adults, idiopathic thrombocytopenic purpura (ITP) starts with petechiae, purpura, and hemorrhage of various severities in the mucosal membrane, always with reduced platelet number.\nThe treatment starts with high doses of corticoids, requiring, if the patient responds, several weeks for platelet normalization, and some cases require splenectomy.\n- Thrombotic thrombocytopenic purpura (TTP) is an acute disease that can beserious, and is associated with severe thrombocytopenia, hemolysis, fever and ischemic injuries in multiple organs, such as the central nervous system, the kidney, the myocardium and the digestive system.\nThis condition requires emergency hospital treatment.\nAdvice on Hemorrhagic disorders from platelet disease\n- Any hemorrhagic episode prevents from driving until the hemorrhagic site is controlled and the causal treatment is adjusted or removed.\n- The lightheadedness, drowsiness, and lack of attention caused by anemia limit the ability to drive until the patient is stabilized.\n- The diseases associated with thrombocytopenia will establish, from the clinical condition, the real ability to drive at each time, always with a report and indication from the physician.\nAdvice on Idiopathic thrombocytopenic purpura\n- The hemorrhage prevents from driving until the causal site is controlled and platelets return to normal ranges.\n- The lightheadedness, drowsiness, and lack of attention caused by anemia limit the ability to drive until the patient is stabilized.\n- Cases requiring splenectomy need a postoperative recovery period without driving, until the specialist physician reports on the complete recovery of the patient, both in hematology and wound healing.\nAdvice on Thrombotic thrombocytopenic purpura\n- The patient cannot drive until the clinical condition has subsided completely, and always requires a favorable physician’s report indicating it.\n- 6.5 Coagulation and thrombotic disorders and their interference with driving.\nBlood coagulation disorders\nThey are characterized by a platelet count that may be normal, but these are not able to form normal hemostatic plugs.\nThey can be due to a frequently hereditary intrinsic platelet defect, or to an extrinsic factor affecting the function of previously normal platelets.\nHemophilia A and B:\n- They can cause bleeding of various severity, so blows, surgical procedures and dental extractions should be avoided.\n- In these patients the prevention of bleeding is essential; therefore, the patients should not take acetyl salicylic acid, and the use of ibuprofen in indispensable cases should be made with utmost care.\nVon Willebrand’s disease:\n- This platelet dysfunction is characterized by frequent bruising, mild to moderate bleeding evidenced in skin cuts, metrorrhagia, dental extractions and surgical procedures.\n- The treatment indicated to beat bleeding episodes is prescribed on an individual basis by the specialized physician.\nAcquired coagulation disorders:\n- They are relatively frequent and associated with a broad range of myeloproliferative and myelodysplastic clinical conditions, uremia, macroglobulinemia, and multiple myeloma, cirrhosis and systemic lupus erythematosus.\n- The drugs can also cause platelet dysfunction, as it is the case of penicillin and its derivatives, and acetyl salicylic acid.\n- The leading causes of the acquired coagulation disorders are vitamin K deficits and liver diseases.\n- Liver diseases cause disorders in the synthesis of coagulation factors, increased fibrinolysis, thrombocytopenia and together they can affect hemostasis.\n- In some cases the manifestations are different, as in the case of some dysfibrinogenemias that can be associated with significant bleeding or with susceptibility to thrombosis.\n- The thrombotic manifestations occurring in the adult age can be related to surgery or contraceptives, but in many cases no associated cause is identified.\n- These patients with thrombotic episodes of congenital origin should receive anticoagulation therapy, based on the criterion of the specialist physician in each case.\nAdvice on Blood coagulation disorders.\n- Any bleeding episodes is disabling for driving until the bleeding site is controlled.\n- The replenishment of the factor deficit will be carried out by the specialized physician, who will report on the stabilization of the patient to be able to drive without risk increases.\n- The ability to drive is limited by the dizziness, drowsiness, and lack of attention caused by anemia.\n- The patient should be warned of the greater risk of suffering hemorrhages in case of minor blows, so caution should be exerted when driving.\nAdvice on Acquired coagulation disorders\n- Patients with advanced liver disease are highly susceptible, not only for the increased risk of hemorrhage, but also for the associated symptoms making driving difficult for him.\n- The physician will inform each patient of his ability to drive, without increasing the risks.\n- Patients at risk of hemorrhage for the disease itself or for the anticoagulation therapy prescribed for the risk of thrombosis, should be closely monitored and warned of the risks of bleeding that can occur.\n- They should be recommended to maximize precautionary measures when driving, since any small blow can be dramatic in them.\n- The physician will advise against driving in the cases of high risk of bleeding or thrombosis.\nThe causes are many and varied, including venous stasis post-operatively, pregnancy, immobilization, etc., also vasculitis, myeloproliferative disorders, contraceptives, autoimmune conditions, thrombocytopenia by heparin, endogenous anticoagulation factors deficit, dysfibrinogenemia, etc.\n- Anticoagulant drugs and their complications:\n- Heparin is the agent of choice parenterally and its main complication is bleeding that requires discontinuation and, in serious cases, administration of protamine.\n- Vitamin K antagonists are the treatment of choice by oral route, but require strict, individualized monitoring of doses.\nMultiple drugs show pharmacological interactions with oral anticoagulants, due to the clinical importance involved by changes in hemostatic mechanisms.\nIts effect is potentiated by chlorpromazine, sulfonamides, chloramphenicol, allopurinol, tricyclic antidepressants, laxatives, salicylates, thyroxin, androgens, antiarrhythmic such as amiodarone and quinidine, clofibrate, H2 antagonists, glucagon, disulfiram and some antibiotics including erythromycin, tetracycline, neomycin and imidazole-derivatives.\nIts effect is reduced by vitamin K, barbiturates, rifampicin, cholestyramine, thiazides, carbamazepine, griseofulvin, and some oral contraceptives.\nThe administration with substances modifying hemostasis such as acetyl salicylic acid, phenylbutazone and pyrazolone derivatives is not recommended.\nVitamin K antagonists can increase hydantoin serum concentration and can also potentiate the hypoglycemic effect of sulfonylurea.\nPatients treated with oral anticoagulants are susceptible to hemorrhagic complications, so anticoagulation therapy is adjusted individually for the dose and time.\nPatients with chronic disease associated with a high incidence of thromboembolism will possibly require anticoagulation therapy in the long term.\nAdvice on Thrombotic disorders\n- In the event of any suspect symptom or sign of thrombosis, the patient should be advised against driving, until the etiological diagnosis and the indicated treatment reverse the clinical symptoms.\n- They patient cannot drive until the increased risk of a new episodes of thrombosis or embolism persists.\n- Patients treated with oral anticoagulants should not take drugs containing acetyl salicylic acid.\n- The patient should be warned not to take over-the-counter drugs, or those indicated by a physician who does not know that the patient is receiving anticoagulation therapy.\n- Any new drug can destabilize the patient on anticoagulation therapy.\n- When a drug is added or removed from the therapeutic regimen, prothrombin time should be monitored more frequently.\n- It is advisable that patients treated on an ambulatory basis carry in their car a coagulation control sheet in case they are injured\n- The patient should know his risk and to be responsible for his situation trying to perform a safe driving, that reduces the possibility of blows that, even if minor, can have dramatic consequences in him."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:3b824d31-41a1-4785-a247-9eb3e2ea78e2>","<urn:uuid:a6b18724-fc82-4d73-be86-38a5322d08a8>"],"error":null}
{"question":"When did NZ finally allow women in combat roles? 🤔","answer":"By 2000, all restrictions on women engaging in combat roles in the New Zealand armed forces had been lifted. This change was later reflected in law through the Human Rights (Women in Armed Forces) Amendment Act 2007.","context":["Story: Armed forces\nPage 1 – Historical overview\nNew Zealand has had its own armed forces since the early days of European colonisation. The first unofficial military organisation was the Kororareka Association (1838–40). Local volunteer forces were established in the early 1840s but were disbanded when the Militia Ordinance 1845, which authorised the raising of compulsory militias to supplement imperial (British) troops, was issued. Imperial troops were stationed in New Zealand from 1840 to 1870.\nUnder the Militia Ordinance 1845 all able-bodied European men aged between 18 and 60 could be called out for compulsory training or service within 25 miles (40 kilometres) of their town. Militia service was unpopular because the pay was low, and communities and families suffered economically when their men had to leave paid work to attend. Militia forces saw active service during the New Zealand wars, and the last force – the Taranaki Militia – was released from service in 1872. Militias were never used again but provisions for their use remained in legislation until 1950.\nVolunteer units were established during the New Zealand wars. The first permanent military force was the Colonial Defence Force, which was active from 1862. This was replaced by the Armed Constabulary, which performed both military and policing roles, in 1867. After being renamed the New Zealand Constabulary Force, it was divided into separate military and police forces in 1886. The military force was called the Permanent Militia and later renamed the Permanent Force.\nIn 1910 the Territorial Force was established, replacing Volunteers. This reserve force formed the foundation of the army. By then, the Permanent Force had evolved into the Royal New Zealand Artillery. This, along with the Royal New Zealand Engineers and the New Zealand Staff Corps (who were in charge of the Territorial Force) became the army’s professional, permanent centre.\nNew Zealand naval volunteers were first formed in the 1860s. The New Zealand Naval Forces and a New Zealand branch of the Royal Naval Reserve were established by the Naval Defence Act 1913. The first warship (HMS Philomel) was purchased in 1914. This was followed by the formation of the New Zealand Division of the Royal Navy in 1921 and the Royal New Zealand Navy in 1941.\nNew Zealand’s air force has its origins in the gift of an aircraft to New Zealand by the United Kingdom-based Imperial Air Fleet Committee in 1913. The New Zealand Permanent Air Force was created within the army in 1923, and the name was changed to the Royal New Zealand Air Force in 1934. It separated from the army in 1937.\nCompulsory military training and conscription\nCompulsory military training (CMT) began in 1911 and formed the basis of the Territorial Force. During the First World War the compulsory scheme was, in effect, replaced by conscription for overseas service from 1916. CMT continued after the war, but budget restrictions limited its scope and it was suspended in 1930.\nConscription was re-introduced in the Second World War. During both wars, conscription was used because the number who volunteered did not match the needs of the war effort.\nCMT was introduced again in 1949 but could not meet the technical needs of the navy and air force, and produced more servicemen than were required for the army. The scheme ended in 1959 and the strength of the Territorial Force declined almost immediately. By this time the balance had shifted from amateurs to professionals. Large-scale warfare was now unlikely, and highly trained permanent or regular forces were needed mostly for more localised conflicts overseas.\nA more limited form of national service (selective conscription by ballot) was introduced in 1961. This ended in 1972. The Territorial Force became a voluntary reserve service which supplemented the regular, professional force.\nDuring the First and Second world wars, the armed forces expanded to meet the needs of global warfare. In the Second World War 194,000 men (67% of those between 18 and 45) and 10,000 women served.\nThe armed forces diversified over time. Compulsory training initially did not apply to Māori, but some had volunteered for the Volunteers and Territorial Force. A small contingent of Māori fought in the First World War, but it was not until the Second World War that Māori participation became more prominent.\nAs Māori moved into the cities after the war, their proportion in the armed forces increased and they became moderately overrepresented compared to their proportion of the general population. In 2011 Māori comprised 17% of the regular force (compared to 14.6% of the general population in the 2006 census).\nWomen served as nurses in the First World War. In the Second World War women’s roles diversified, though no women actually fought. After the war women’s armed services were retained but participation was low – around 4–5% of the forces in the 1950s and 1960s.\nOver time more branches of the armed forces were opened to women and separate women’s services ended in 1977. However, human-rights laws reserved the right of the armed forces to give preferential treatment on the basis of gender in relation to combat roles. The Human Rights Commission Act 1977 and the Human Rights Act 1993 both contained particular provisions which allowed this discrimination. These provisions were repealed by the Human Rights (Women in Armed Forces) Amendment Act 2007. By this stage, restrictions on women’s service had already been lifted by the New Zealand Defence Force – the change in law reflected an existing change in practice.\nBy 2000 all restrictions on women engaging in combat had been lifted. In 2011, 16% of the regular forces were women.\nHomosexual acts between men were illegal in New Zealand until 1986. During the first and second world wars, members of the armed forces found to have engaged in homosexual acts were imprisoned for disgraceful conduct and ignominiously discharged. From 1950 most were discharged from the forces without prosecution.\nThe Homosexual Law Reform Act 1986 decriminalised homosexuality, but the armed forces were exempted from its provisions. Discrimination based on sexuality in the armed forces became unlawful after the passing of the Human Rights Act 1993. The chief of defence force approved the establishment of an LGBT (lesbian, gay, bisexual and transgender) support group in 2011."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:34ec2ec4-5362-49bb-a5a0-23a55b57e57f>"],"error":null}
{"question":"What are the key differences between genealogical records for Polish nobility versus those for immigrants like the May family from Scotland to New Zealand?","answer":"Polish nobility genealogical records were often privately held by individuals in Poland who collected unpublished records about their own families, making them generally inaccessible unless contact could be established with the appropriate individuals. In contrast, the May family's genealogical information was documented through more accessible sources, including their family bible which recorded Janet May's thirteen children, and public records of their immigration and settlement in New Zealand in 1886, which tracked their movements from Peterhead to Auckland, then to Christchurch, Blenheim, and finally their establishment at The Halfway where they purchased a 65-acre farm.","context":["Poland Compiled GenealogiesEdit This Page\nFrom FamilySearch Wiki\nThe term genealogy is used in this Wiki article and in the Family History Library Catalog to describe a variety of records containing family information gathered by individuals, other researchers, societies, or archives.\nThese records may include pedigree charts, compiled information on families, correspondence, ancestor lists, research exchange files, record abstracts, and collections of original or copied documents. These can be excellent sources of information that can save you valuable time. Because they are compiled from other sources of information, they must be carefully evaluated for accuracy.\nAdditional genealogical sources for Polish nobility are described in Poland Nobility.\nMajor Collections and Databases\nThe Family History Library has several sources that contain previous research or can lead you to other people who are interested in sharing family information. These sources include:\nInternational Genealogical Index (IGI). The index has names and vital information for thousands of people (deceased) who lived in Poland. It lists birth, christening, or marriage dates as well as Latter-day Saint temple ordinance information. The index for Poland has names extracted from parish registers by volunteers (mostly from places formerly under Germany) and names submitted by other researchers.\nIGI is available on microfiche, on compact disc as part of FamilySearch at http://www.familysearch.org, and on the Internet. If you are using microfiche, you need to know which county to search. If you are using the compact disc edition, the computer will search the entire country for any name.\nAncestral File. Part of FamilySearch, this file contains family history information, linked in family groups and pedigrees, that has been contributed since 1979. You can print pedigree charts, family group records, and individual summary sheets for any person in Ancestral File.\nFamily Group Records Collection. More than 8 million family group record forms have been microfilmed in the Family Group Records Collection, including many Polish families. There are two major sections: the Archive Section and the Patrons Section. The film numbers for both sections are listed in the Author/Title search of the Family History Library Catalog under:\nFAMILY GROUP RECORDS COLLECTION\nA few Polish families have produced histories or newsletters that may include genealogical information, biographies, photographs, and other information. These usually include several generations of the family.\nThe Family History Library has only a limited number of published Polish family histories and newsletters. Copies are listed in the surname section of the catalog, but not every name found in a family history will be listed. Only the major surnames discussed in the family history are included in the catalog.\nUnpublished family histories, usually of Polish nobility and their descendants, are sometimes in the possession of private individuals in Poland. These individuals may have collected a variety of unpublished records pertaining to their own families.\nSuch materials are generally inaccessible for research unless you can establish contact with the appropriate individuals.\nThe Family History Library has some collections of genealogical material for Polish families. These may include published and unpublished collections of family histories and lineages. Some of the major genealogical collections are:\nBorchert, Reinhard, Die Kartei Quassowski (The Quassowski index). Hamburg: Verein für Familienforschung in Ost- und Westpreußen e.v., 1992. (FHL book 943.8 D22k.) This work is arranged alphabetically by the main surname of the family. Incidental names are indexed in a separate index.\nSchlesische Ahnenlisten (Silesia ancestor lists). Breslau: Der Schlesische Familienforscher, 1938–. (FHL book 943.82 B2sf.) This lists ancestors from the former Prussian territory of Silesia, now in Poland.\nGenealogical collections are listed in the Family History Library Catalog under:\nPOLAND - GENEALOGY\nPOLAND, (COUNTY) - GENEALOGY\nPOLAND, (COUNTY), (TOWN) - GENEALOGY\nIf you find your surname in any of the sources described in this section, determine whether the entry actually pertains to your family. People with the same surname are not necessarily related. You might have to do some original research before you can connect your ancestry to families listed in these sources.\nThe catalog also lists books about how to do genealogical research in Poland. Examples are:\nGnacinski, Jan and Len,Polish and Proud, Tracing Your Polish Ancestry.Revised Ed. Indianapolis, Indiana: Ye Olde Genealogie Shoppe, 1995. (FHL book 943.8 D27g.)\nChorzempa, Rosemary.Korzenie polskie: Polish Roots.Baltimore, Maryland: Genealogical Publishing Co., 1993. (FHL book 943.8 D27gr.)\nGenealogical instructional books are listed in the Family History Library Catalog under:\nPOLAND - GENEALOGY - HANDBOOKS, MANUALS, ETC.\nPOLAND, (COUNTY) - GENEALOGY HANDBOOKS, MANUALS, ETC.\nHandbooks and Resources\nPolish Roots, Rosemary Chorzempa. 1993. Basic guide to Polish Research sources. (FHL book 943.8 D27c.)\nPolish and Proud, Gnacinski, Longley. 1979. Guide to Tracing your Polish ancestry. (FHL book 943.8 D27g.)\nPolish family research. Konrad. 1992 (FHL book 943.8 D27k.)\nMajor genealogical record sources in Poland. Series C #31. 1978. (FHL book 943.8 D27gs.)\nEssentials in Polish genealogical research. Daniel Schlyter. 1993. (FHL book 943.8 D27sd.)\nPoland Research Outline. The Church of Jesus Christ of Latter-day Saints, Item 36386.\nPoland Genealogical Word List. The Church of Jesus Christ of Latter-day Saints, Item 34098.\nDictionary of Surnames. Kazimierz Rymut. Sold by the Polish Genealogy Society of America (PGSA).\nInformator Teleadresowy. Addresses of all current Polish Civil Registraiton Offices on CD and two printed volumes. Available through \"Technika,\" 44-100 Gliwice, ul. Floriańska 51a, Pland. Now available through the same firm, a CD that includes all the parish addresses.\nPo mieczu i po kądzieli. Translates to On the Spear (male) side and the distaff side (female). This is a CD produced by Naczelna Dyrekcja, Archiwów Państwowych, 2001, ul. Dluga 6, skr.poczt. 1005, 00-950 Warszawa. The CD consists of five databases: The Registers of population in Archival Material, the inventory of parish and civil records in the archives, German civil registraiton in Poland, nobility informatin and The Lutherans of Warsaw. Some of this information can be found on their website.\nIn Their Words: a genealogist's translation guide to Polish, German, Latin, and Russian Documents. Jonathan D. Shea and William F. Hoffmann. 2 Volumes. (FHL book 940 D27sj.)\nA translation guide to 19th century Polish-language civil registration documents. Judith R. Frazin. (FHL book 943.8 V27f.)\nPosen Place Name Indexes: Identifying place names using alphabetical and reverse alphabetical indexes. Roger P. Minert. (FHL book 943.84 E5m.)\nFirst Names of the Polish Commonwealth: Origins and Meanings. William F. Hoffman and George W. Helon\nFinding Your Polish Ancestors. Kathleen Ann LaBudie-Szkall and Jan Steven Zaleski\nFollowing the Paper Trail:A Multilingual Translation Guide. Jonathan D. Shea and William F. Hoffman\nPolish Surnames: Origins and Meanings. William F. Hoffman\nSto Lat: A Modern Approach to Polish Genealogy. Ceil Wendt Jensen\n- http://www.sggee.org Society for German Genealogy in Eastern Europe","John and Janet May with some of their children, undated c1900\nStanding from left: Jessie, John, Eliza (Wannie)\nSeated from left: Barbara, John May Snr. Paulina, Janet May, Mary\nLocation of Glenugie in New Zealand\nThe following article was sourced, with permission, from the writings of Murray Henderson, descendant.\nThe May and Henderson family of Peterhead, Scotland immigrated to New Zealand in 1886 and settled at The Halfway, now Glenside. They called their 65 acre farm Glenugie, after the River Ugie and Ugie valley near Peterhead.\nThe homeland in Scotland\nJohn May was the fourth child of nine children from the union of John May and Jane Stephen of Inverallochy, Scotland. His father was an industrious and capable fisherman. In 1838 the family moved to Burnhaven, a small close-knit fishing village not far from Peterhead, Scotland. At the time John was about ten years old. In a few years he would become a competent fisherman and would also extend his skills by taking up trade as a cooper, - a barrel and cask maker.\nJanet was the youngest of six children to George Milne and Janet Williamson who lived on a farm four miles west of Peterhead and to the south of the River Ugie in Scotland.\nOn 2 June 1856 the couple were married at the farm, Hillhead of Cocklaw, near Peterhead.\nFor the next 30 years Janet and John lived in and near Peterhead. Their family bible records that Janet May gave birth to thirteen children. At the time of their marriage John May was a skilled cooper and fish-curer. He set up his own business in Peterhead. He also had a small farm holding on the outskirts of town and Janet kept a little shop nearby where her younger daughters helped her when necessary.\nJohn and Janet May’s eldest daughter Mary-Jane was the first of their family to marry. Her husband was Captain John Henderson and they married at Peterhead on 27 April 1881.\nFor reasons unknown John and Janet May and their immediate family, including son-in-law Captain John Henderson and infant son John, left their home in Peterhead and travelled to London where in late January 1886 they boarded the Shaw Savill & Albion Company steamer Ionic and departed for the long voyage to New Zealand.\nToward the end of February the steamer Ionic berthed at Auckland, New Zealand and John and Janet May and their family landed in their new country after a voyage of several weeks. At this time the family consisted of:\nThe May family\nJohn May, aged 58\nJanet May nee Milne aged 50\nEliza Joan May aged 22\nJessie Williamson May aged 20\nBarbara Henderson May aged 18\nJohn Alexander May aged 16\nPaulina May aged 13\nThe Henderson family\nMary Jane Henderson nee May aged 24\nCaptain John Henderson aged 34,\nJohn Seaborn Henderson aged 3.\nIt would seem that no firm plans had been made about just where the family were to settle in New Zealand. Their first home was in a rented house in Parnell where they stayed for several weeks. A move was then made to Christchurch and then soon after to Blenheim. Whilst there, their daughter Eliza Jane, a qualified teacher, secured a position at the Renwicktown School and taught there for some time. Finally the opportunity came for the Mays to establish themselves with some permanency.\nHeld: Murray Henderson Collection, Glenside Progressive Assn. Inc.\nArrival at The Halfway (Glenside)\nOn 30th July 1886 John May purchased a small farm of 65 acres just north of Johnsonville in an area then known as the Halfway. This property was part of the original Section 24 on the Porirua Road and was brought from Charles Pichoir de Launay who had recently built a house there.\nWith obvious nostalgic reference to their homeland the farm was named Glenugie after the river and valley near Peterhead that had so greatly influenced the lives of their ancestors for several centuries.\nSubsequent family recollections seem to confirm the fact that this was not easy land to farm and that great effort was needed to make it reasonably productive. But at least they owned it and a period of consolidation followed.\nOpportunities also existed for John May to used his other considerable skills as a cooper and fish curer. At this time the small community of Paremata on the shores of the Porirua Harbour a few miles north of Glenugie was developing as a growing inshore fishing base in the Wellington district. Its accessibility was greatly enhanced in the mid 1880’s by the construction and opening of the privately owned Wellington and Manawatu Railway Company’s line and tenancy of small sections of land on the foreshore and reclamations associated with that line in the area were offered to interested parties, some of whom were already “squatters.”\nProbably in the late 1880’s John May with his son John Alexander May as a worthy assistant, built premises on the shorefront at Paremata and started an operation which comprised a cooperage and smoking and curing facilities. They employed local fishermen to provide the catch and very quickly they became firmly established. They were soon joined by Thomson Bruce, a skilled fisherman, who had worked for John May back in Peterhead and who would later marry his daughter Barbara. Their business was known as J. May and Co.\nAs the family settled down to life in New Zealand each member became involved in other pursuits and interests. In the absence of the Congregational Church in the area, John and Janet became loyal and respected members of the Johnsonville Wesleyan Methodist Church and remained so for the rest of their lives. After some fourteen years yet another move was contemplated and effected soon after.\nMove into Johnsonville\nJohn May sold the Glenugie farm to John Collings Moxham on 29th September 1900 and purchased a block of land in the heart of Johnsonville – bounded by the lower end of Trafalger Street and Railway Terrace (now Frankmore Avenue). This section was only metres away from the site on the banks of the Waitohi Stream where in 1841 settler Frank Johnson built a house on his 100 acre Section 11 on the Porirua Road.\nWhen they took up residence in Johnsonville, John and Janet May began a period of relatively quiet retirement. John apparently never became involved in public life but both of them maintained their reputations as very respected and popular members of the community.\nJohn and Janet May celebrated their Golden Wedding at Johnsonville in 1906. John May died on 30 August 1907 aged 78 and Janet May died two years later on 17 July 1909 aged 73. Both are buried in the Wesleyan Methodist Church Cemetery in the heart of Johnsonville.\nHonouring John May\nJohn May’s death was recorded back in his old home town and his obituary printed in the Peterhead Sentinel read thus:\nDeath of the Townsman in New Zealand\n\"The death took place at Johnsonville, Wellington, New Zealand, on 30 August 1907 of Mr John May late of Peterhead, at the advanced age of 78. Mr May was well known and greatly respected in the community for nearly half a century, and many will remember the surprise evinced at the time when he, with a grown-up family, emigrated to New Zealand over twenty years ago. He was very strong and consistent in church matters and very soon he was as highly respected in the land of his adoption, as he was in the land of his birth. He was buried in Johnsonville cemetery on 1st September and the funeral was one of the largest ever seen in the district being attended by all in the neighbourhood and for many miles around. At the grave the officiating minister in an address to a gathering of most of the inhabitants of the township, pointed out the sterling qualities of the deceased who set a splendid example to all who knew him and came in contact with him; he took no part in public affairs, rather obscuring himself but he led an active and useful life. He is survived by a grown-up family.”\nThe Glenugie Farm was bought by the Moxham family, followed by the Hodge family and the Pender family. The Pender's sold to the Wrightson company, and the homestead was subsequently pulled down in about 1979. The homestead block was separated from the main farm by the Westchester link road and is named \"Waitakaro\". The Reedy family own this land and the main farm, which is on the north side of the Westchester link road.\n“Few if any in the area will now remember John and Janet May, their family and the Glenugie farm. However to us descendents the attractive little Glen will remain a tangible, lasting local reminder of long ago and the lands of the Ugie on the other side of the world from whence it gained its name.” The words of descendant Murray Henderson (1928 - 2008) in the book From Glen to Glen.\nFrom Glen to Glen The Story of John and Janet May, Their ancestors and descendants. Privately published family history.\nCaptain John Henderson 1852-1924 His ancestors and descendants. Privately published family history."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:f4d70cf9-bddb-4c92-94c3-70c0a34e0e93>","<urn:uuid:7365c0d9-4144-4598-8782-89556818ecb0>"],"error":null}
{"question":"Could you compare and contrast Churchill's 'soft underbelly of Europe' strategy with Mussolini's expansionist ambitions in the Mediterranean region? Please detail both their objectives and outcomes.","answer":"Churchill's 'soft underbelly of Europe' strategy involved first pacifying North Africa in 1942 through Operation Torch, targeting Morocco and Algeria to cut German supply lines in the Mediterranean. This strategy proved partially successful, leading to the eventual Allied victory in Tunisia by mid-May 1943 and allowing for the invasion of Sicily. In contrast, Mussolini's Mediterranean ambitions were more expansive but less successful, including multiple invasions aimed at building an empire. He invaded Albania in 1939 to control the Adriatic, attempted to invade Greece in October 1940 (which failed and required German intervention), and launched unsuccessful campaigns in Egypt. While Churchill's strategy was part of a larger Allied plan that eventually succeeded, Mussolini's imperial ambitions resulted in multiple military failures and ultimately contributed to Italy's wartime difficulties.","context":["Both Winston Churchill and Franklin Roosevelt knew that they had to make some tangible moves against the Germans in 1942. And despite Josef Stalin’s insistence that western allies open a second front, Churchill knew that would end in disaster.\nSo the powers decided that they’d first pacify North Africa, where the British Eighth Army and the German Afrika Korps had been fighting back and forth since 1940. After much disagreement, it was decided to invade Morocco and Algeria and establish a base where the supply lines for the Germans in the Mediterranean could be cut. This would open as Mr. Churchill called it the “soft underbelly of Europe.” But this first foray for the Americans into the war against Nazi Germany was a victory, not so much militarily but politically as the allies were treading on a slippery slope dealing with the Free French as well as Vichy and the inexperienced Americans.\nPresident Roosevelt had wanted to execute “Operation Sledgehammer”, the joint Allied invasion of Western Europe into France, but Field Marshal Rommel’s attack in Egypt had come with 120 miles of Alexandria. General Marshall and Admiral King of the US had argued that the British didn’t want to invade France or Belgium in either 1942 or 1943. But they were ordered by the President to go along, one of only two times during the war years that he so invoked that privilege.\nThe Plan: The Allies decided on the operation to be done with three separate task forces. The overall commander was General Eisenhower with his deputy of General Mark Clark. Clark would come ashore by submarine early and in a bit of cloak and dagger, try to convince the French not to fight.\nThe Western Task Force under General George Patton consisted of the 2nd Armored Division, and the 3rd and 9th Infantry Divisions. Patton’s forces would land in Spanish Morocco at Fedala outside of Casablanca, Safi, and Mehdia outside of Port Lyautey. He’d have 35,000 troops and 100 ships under his command.\nThe Central Task Force was commanded by General Lloyd Fredendall and consisted of the 1st Armored Division and the 1st Infantry Division as well as the 509th Parachute Infantry. The would land in Western Algeria at Oran and at two landing sites on either side of it. They totaled 18,500 total troops.\nThe Eastern Task Force was commanded by Lieutenant General Kenneth Anderson but once the troops hit the ground, they’d be led by General Charles Ryder commander of the 34 Infantry Division. They would also have a brigade from the British 78th Division and two British Commando Units (1 and 6 Commando). They totaled 20,000 troops and would land around Algiers.\nThe Allies organized the three amphibious task forces to simultaneously seize the key ports and airports in Morocco and Algeria, targeting Casablanca, Oran, and Algiers. Successful completion of these operations was to be followed by an eastwards advance into Tunisia. This would cut off the German retreat as they were being pushed westward by the British Eighth Army.\nThe Battle: Patton, never one to mince words told the Naval commanders, that their plans on landing the troops would “break down in the first five minutes,” and then in typical Patton fashion told the navy this: “Never in the history of warfare has a navy landed an army at the planned time and place. But if you land us within fifty miles of Fedala and within one week of D-Day, I’ll go ahead and win.”\nHis Western task force landed without naval bombardment because it was hoped that the French wouldn’t resist. This decision would prove costly to the Americans. The green American troops were pinned down by a surprisingly light amount of French troops.At Safi, the plan was to land about 50 Sherman tanks there and to block any reinforcements from the strong French garrison at Marrakech. The coastal batteries opened up and the American naval bombardment silenced them. But by the afternoon of November 8th, D-Day, they had control of Safi. Unloading the tanks was a slow process, the American 2nd Armored didn’t finish unloading until the 10th, these were the learning curves that would pay dividends in 1944.\nAt Port-Lyautey, the landing troops were delayed. This gave the French defenders time to organize resistance, and the remaining landings were conducted under artillery bombardment. However, with the assistance of air support from the carriers, the troops pushed ahead, and the objectives were captured.\nAfter the landings at Fedala, the port of Casablanca was surrounded. It was the principal French Atlantic naval base. The naval engagement resulted from a sortie of French cruisers, destroyers, and submarines opposing the landings. A cruiser, six destroyers, and six submarines were destroyed by American gunfire and aircraft. The incomplete French battleship Jean Bart—which was docked and immobile—fired on the landing force and the battleship USS Massachusetts with her one working gun turret until she was knocked out of action by the Massachusetts’ 16-inch guns, the first such heavy-caliber shells fired by the U.S. Navy anywhere in World War II. Two U.S. destroyers were damaged.\nAt Oran in the Central Task Force, the opposition was much tougher but was quickly brought under control due to superior planning on the part of the British Navy and Terry Allen, Commander of the US 1st Infantry Division. Allen’s troops landed on target and on time and they swept aside any resistance and captured the port and city in a double envelopment.\nThe U.S. 1st Ranger Battalion landed east of Oran and quickly captured the shore battery at Arzew. A bold attempt was made to land U.S. infantry at the harbor directly, in order to quickly prevent the destruction of the port facilities and scuttling of ships. The operation failed, as two sloops were destroyed by crossfire from the French vessels there. The Vichy naval force tried to break out from the harbor and attack the Allied invasion fleet but its ships were all sunk or driven ashore.\nOperation Torch was the first major airborne assault carried out by the United States. The 2nd Battalion, 509th Parachute Infantry Regiment flew all the way from Britain, over Spain, intending to drop near Oran and capture airfields at Tafraoui and La Sénia, respectively 15 miles (24 km) and 5 miles (8 km) south of Oran.The operation was hampered by weather, navigational and communication problems. Poor weather caused the formation to scatter and forced thirty of the 37 aircraft to land in the dry salt lake to the west of the objective.The few drops that did occur were wildly scattered. However, the 509th captured both airfields.\nOne interesting footnote of the airborne operation concerned Pvt John Thomas (Tommy) Mackall. Mackall was assigned to Company E, 2nd Battalion, 509th Parachute Infantry Regiment. During the airborne segment of Operation Torch, he was mortally wounded in an attack by French Vichy aircraft on his aircraft as the aircraft landed near Oran. Seven paratroopers died on the C-47 and several were wounded, including Mackall. He was evacuated by air to a British hospital at Gibraltar where he died on November 12, 1942.\nThe Special Forces Training Facility in North Carolina now sports Mackall’s name. During WWII Camp Mackall was a huge airborne training base preparing paratroopers for combat duty.\nAt Algiers, there was a coup staged by nearly 400 members of the Jewish Resistance Fighters kicked off. They seized key targets, including the telephone exchange, radio station, governor’s house and the headquarters of 19th Corps.\nThe landings took place on three beaches, two west of Algiers and one east. Although some landings of the 34th Infantry Division took place on the wrong beaches, they quickly pushed inland due to the paucity of the French resistance. The coastal artillery batteries had been put out of action by the Jewish Resistance Fighters. On another beach, there was no resistance as the French commander welcomed the Americans as they landed on shore. Two British destroyers boldly raced into the harbor to unload 250 American Rangers who were tasked with seizing the facilities before they could be scuttled. One destroyer unloaded the Rangers, the other was forced back by heavy gunfire. General Juin, Commander of the Vichy French troops, surrendered the city at 1800 hrs on November 8.\nThe Germans Respond: Due to the lack of Vichy French resistance to the Allies landing in North Africa, the Germans didn’t trust the French any longer. As a result, the Germans overran the remainder of Southern France which had been left under Vichy control after the French surrender of 1940.\nThe German raced to the port of Toulon where the French had a sizable fleet there, to take control of those ships. But the French scuttled the fleet in the harbor, denying the Germans the use of those, which turned out to be a significant loss.\nThe Americans and British drive on Tunisia but the Germans, retreating from Montgomery’s Eighth Army, reached there first. Later in the spring of 1943, Rommel would decisively rout the American II Corps under Fredendall at the Kasserine Pass. That would move Eisenhower to replace him with Patton. It wasn’t until mid-May 1943 that the last of the Germans surrendered in Tunisia. The Allies would invade Sicily in mid-July, Churchill’s so-called “soft underbelly” of Europe.\nThe amphibious landings didn’t go well, but the green Americans would learn the hard lessons that would serve them well before they finally invaded the French coast on June 6, 1944. That experience and the enhanced cooperation with the naval forces would make the largest invasion force in history less than two years later.\nPhotos Courtesy: Wikipedia","From the moment it was unified in the mid-19th century, Italy began to harbor dreams of empire. Under the fascist dictator Mussolini, these dreams were backed by an ideology of racism and national power. And so Italy began a series of invasions to expand its fledgling empire.\nIn 1923, an Italian general was assassinated in Greece. At the time, he was involved in negotiations between Greece and Albania over the island of Corfu.\nMussolini used the incident to stir up nationalist feelings in Italy. He then made extreme demands for recompense from the Greeks, who refused. Using this to depict Italy as the injured party, Mussolini bombarded and invaded Corfu in an attempt to strengthen his strategic position in the region.\nNegotiations followed, with Britain and France pushing for an Italian withdrawal. The Greeks eventually gave in on harsh terms, making a large payment and displays of grief for the dead Italian general. Italy withdrew from Corfu, having proved the weakness of the League of Nations and gained status and wealth.\nItaly already occupied part of Somaliland. In 1935, a border clash there provided an excuse to build up troops on the Ethiopian border and then launch an invasion.\nOnce again, the League of Nations proved unable to resolve the situation politically or curb Italian aggression. Italian use of chemical weapons caused outrage but drew little practical response from the international community. Britain and France were too afraid of turning Italy into Germany’s ally to stand against Mussolini.\nBy the end of the next year, the invasion was complete and Ethiopia would remain an Italian possession until well into World War Two.\nAlbania had both strategic and symbolic importance for Italy. It controlled the head of the Adriatic, and had strategically important ports there, as well as providing access to the Balkans. As territory that had once been part of the Roman Empire, it fitted into Mussolini’s schemes to rebuild that empire.\nHitler’s occupation of Austria and western Czechoslovakia made Mussolini realise that he was being left behind by his German ally. In April 1939, he invaded Albania, occupying the country in only a week. A puppet government was installed.\nWhen Germany invaded France in 1940, Italy was poorly prepared to take part in the war. Not even a factor in Hitler’s planning, the Italians sat on the sidelines, not invited by their allies.\nOnce again, Mussolini saw that he was missing out on the opportunities that Hitler was seizing, and so on the 10th of June, he declared war on France. Italian forces launched a small and ineffective attack, losing 642 men in a conflict that cost over 100,000 lives. France was divided between a German occupied zone and the theoretically free Vichy, with only a small part going to appease Italy. This area became a haven for French Jews, as Italian officers refused to hand them over to German authorities to be sent to the concentration camps.\nOn the 13th of September, 1940, Italian forces crossed the border from Libya into Egypt. This was a chance to gain control of the strategically vital Suez Canal, secure the eastern end of the Mediterranean, and gain access to the oil beyond.\nIn Egypt, they faced a British army far inferior in numbers – 36,000 British and Commonwealth troops against 236,000 Italians. But General Graziani, leading the Italian forces, was not up to the opportunity. Fighting as if in a colonial war rather than against a European power, Graziani and his men were held up by the British.\nIn December 1940, Australian, British, and Indian troops swept around the Italian 10th Army in Operation Compass. The 10th Army was cut off and 130,000 Italians surrendered. The rest were driven out of Egypt by Operation Crusader.\nThe arrival of the German Afrika Korps under Rommel gave the Axis the edge again, and Italian troops participated in a second invasion of Egypt. But they, along with the Germans, were driven out once more.\nControl of the Balkans was important to Mussolini’s dreams of empire. But both Greece and Yugoslavia were more friendly towards Hitler than him, and there was a risk that they would become part of the German sphere of influence.\nOn the 28th of October, 1940, Mussolini began a campaign meant to solve this problem – an invasion of Greece. But the Greeks had far more troops experienced serving in mountainous terrain and so were able to contain the Italians, before driving them back into Albania.\nBritish troops then arrived in Greece, including bombers that could reach the Rumanian oilfields on which Germany relied. And so Hitler came to Mussolini’s rescue once more. But there would be one more invasion before the Germans reached Greece.\nOn the 6th of April, 1941, Germany invaded both Greece and Yugoslavia, whose pro-fascist government had been overthrown by one hostile to the Axis. Italy joined in on both invasions, as Mussolini struggled not to be relegated to the position of Hitler’s junior partner. Within two weeks, Yugoslavia surrendered, the Italians having played their now familiar small part.\nTogether, the fascist armies swept on into Greece, which fell by the end of April.\nIn late 1942, the Allies began a decisive fight back in North Africa called Operation Torch. As part of this, they moved into Tunisia, held by Vichy French forces, to attack the Germans and Italians from the west. In response, Rommel also launched an attack into Tunisia, and once again Italian forces participated. As the French fell apart, the two invading forces fought each other in a six-month campaign that ended in defeat for the Italians.\nBritish Somaliland, Kenya, and Sudan\nFascist Italy’s most successful invasion was launched in east Africa in August 1940. Advancing in several columns, the Italians drove back British forces from British Somaliland as well as adjacent parts of Kenya and Sudan. The British commander lost his nerve and withdrew, with relatively few casualties suffered on either side. It was the most peaceful, and most successful, of all Mussolini’s invasions, and fulfilled Italian dreams of an empire and of revenge on the British for past humiliations."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:41c04db3-990f-4342-94a0-0c0e12df64ae>","<urn:uuid:aa1114d9-ad13-404d-8339-56948e74a061>"],"error":null}
{"question":"What are the key differences between human observation and computer-based tracking systems in laboratory animal behavior studies?","answer":"Computer-based tracking systems offer several advantages over human observation. Traditional human observation is lengthy and painstaking, subject to variations in classification due to tiredness and different observers. In contrast, automated systems like ETHOVISION and MARS eliminate these human frailties. MARS can analyze an hour of video in just 2-3 hours, while human annotation typically takes 4-5 hours per hour of video. Additionally, automated systems provide standardization across different labs - MARS ensures 'apples-to-apples comparison between different groups,' whereas human annotators vary in how they identify behaviors.","context":["Recording and classifying the behaviour of laboratory rodents is a vital part of a wide range of studies ranging from the discovery of new drugs and detection of harmful side-effects to the biological control of agricultural pests. Until now, it has been a lengthy and painstaking task, requiring human observers to judge, count and record. But a new computerised system developed with EUREKAs help has done away with the need for human observers, revolutionising the way labs work around the world.\nOne of the key issues in the biological control of agricultural pests is to find the right natural enemy for a particular pest, for example, parasitic wasps attack pest insects like caterpillars, beetles, aphids, etc. ETHOVISION allows researchers to automate the observation process in the exploratory phase. It measures aspects of the insects behaviour in the laboratory (e.g. walking and flight speed, turning rate, time distribution of different areas in space) that have a predictive value for its performance in the field.\nA video tracking linked to a computerised image analysis system automatically records and classifies the spatial orientation and movement of an animal, taking away all-too-human frailties such as variation in classification caused by tiredness or different observers.\nNicola Vatthauer | alfa\nUT professor develops algorithm to improve online mapping of disaster areas\n29.11.2016 | University of Tennessee at Knoxville\nNew standard helps optical trackers follow moving objects precisely\n23.11.2016 | National Institute of Standards and Technology (NIST)\nA multi-institutional research collaboration has created a novel approach for fabricating three-dimensional micro-optics through the shape-defined formation of porous silicon (PSi), with broad impacts in integrated optoelectronics, imaging, and photovoltaics.\nWorking with colleagues at Stanford and The Dow Chemical Company, researchers at the University of Illinois at Urbana-Champaign fabricated 3-D birefringent...\nIn experiments with magnetic atoms conducted at extremely low temperatures, scientists have demonstrated a unique phase of matter: The atoms form a new type of quantum liquid or quantum droplet state. These so called quantum droplets may preserve their form in absence of external confinement because of quantum effects. The joint team of experimental physicists from Innsbruck and theoretical physicists from Hannover report on their findings in the journal Physical Review X.\n“Our Quantum droplets are in the gas phase but they still drop like a rock,” explains experimental physicist Francesca Ferlaino when talking about the...\nThe Max Planck Institute for Physics (MPP) is opening up a new research field. A workshop from November 21 - 22, 2016 will mark the start of activities for an innovative axion experiment. Axions are still only purely hypothetical particles. Their detection could solve two fundamental problems in particle physics: What dark matter consists of and why it has not yet been possible to directly observe a CP violation for the strong interaction.\nThe “MADMAX” project is the MPP’s commitment to axion research. Axions are so far only a theoretical prediction and are difficult to detect: on the one hand,...\nBroadband rotational spectroscopy unravels structural reshaping of isolated molecules in the gas phase to accommodate water\nIn two recent publications in the Journal of Chemical Physics and in the Journal of Physical Chemistry Letters, researchers around Melanie Schnell from the Max...\nThe efficiency of power electronic systems is not solely dependent on electrical efficiency but also on weight, for example, in mobile systems. When the weight of relevant components and devices in airplanes, for instance, is reduced, fuel savings can be achieved and correspondingly greenhouse gas emissions decreased. New materials and components based on gallium nitride (GaN) can help to reduce weight and increase the efficiency. With these new materials, power electronic switches can be operated at higher switching frequency, resulting in higher power density and lower material costs.\nResearchers at the Fraunhofer Institute for Solar Energy Systems ISE together with partners have investigated how these materials can be used to make power...\n16.11.2016 | Event News\n01.11.2016 | Event News\n14.10.2016 | Event News\n02.12.2016 | Medical Engineering\n02.12.2016 | Agricultural and Forestry Science\n02.12.2016 | Physics and Astronomy","New software uses artificial intelligence to automatically identify and quantify certain types of mouse social behavior from videos of mice interacting in a cage — even animals with cables implanted to monitor their brain activity.\nThe tool, called the Mouse Action Recognition System (MARS), could accelerate research on how autism-linked genetic mutations or drug treatments impact the behavior of mice, says co-lead investigator Ann Kennedy, assistant professor of neuroscience at Northwestern University in Chicago, Illinois. It could also standardize how different labs characterize behaviors, as different researchers may identify the same behavior differently, she says.\nMARS is part of a recent effort to develop software that can automatically analyze video of mouse behavior. In most labs, researchers annotate behaviors by hand, which can take four to five hours for every hour of video, according to Kennedy. MARS can analyze an hour of video in just two to three hours, running in the background and leaving researchers free to do other work.\nThe software processes footage from an overhead monochrome video camera with a lens adjusted to capture infrared wavelengths. (The experimental setup is illuminated only with red light because mice are active at night.) The software tracks seven key points on the rodents’ bodies to calculate the relative postures of two mice. From this information, the software can determine if the two animals are investigating, attacking or mounting each other, so long as the mice have different coat colors. Researchers described the system in November in eLife.\nThe researchers trained the software on nearly seven hours of video, including about four hours of mice undergoing a standard assay in which a lone mouse in a cage is introduced to a foreign intruder mouse. In some of the footage, at least one of the mice had a fiber optic cable or an endoscope attached to its skull, a setup often used to control or record the activity of neurons.\nThe team used the crowdsourcing service Amazon Mechanical Turk to recruit people to manually flag the animals’ body parts in each frame of the videos. The software learned to read the rodents’ poses based on these key points. The researchers then ran MARS on an additional seven hours of video that had not been annotated and allowed the software to derive the animals’ postures on its own.\nFinally, the researchers fed MARS the same footage, more than14 hours in total, this time with individual behaviors coded by one of the researchers on the team. MARS learned how to translate the animals’ poses into specific interactions: mounting, attacking or investigating.\nTested on about two hours of video of resident-intruder interactions, MARS was as accurate as the team members were at flagging the important key points on the mice and identifying attack and investigation; it was only about 3 percentage points worse at identifying mounting.\nThe researchers also unleashed the software on 45 hours of video capturing interactions involving mice with mutations in genes linked to autism: CHD8, CUL3 and NLGN3. The software confirmed previous results; for example, CHD8 mice showed more aggression than controls.\nThe software also found that BTBR mice, an asocial inbred strain that lacks a corpus callosum, spend less time investigating intruder mice than control mice do, matching previous results. And MARS was further able to identify which region of the intruder mouse the resident mouse was interacting with: BTBR mice spend less time inspecting the intruder’s face and genitals than controls do. The BTBR mice may miss pheromonal clues, Kennedy says.\nThe software includes a user interface called BENTO that enables researchers to sync MARS-processed videos with other kinds of data captured during the rodents’ interactions, such as neuronal activity and audio. This feature revealed that a subset of 28 neurons in a male mouse’s hypothalamus became active only during the first moments of the mouse mounting a female intruder. The BENTO interface allows researchers to notice such significant moments in mouse behavior that they might otherwise miss, Kennedy says.\nHuman annotators varied in how they identified behaviors, the team found, which could create problems when labs compare results, Kennedy says. Using software such as MARS creates a standard so that “you can make a real apples-to-apples comparison between different groups,” she says.\nThe software is available for download on GitHub. Labs can run the trained software as is, or they can train it on new key points and behaviors. Kennedy and her colleagues next plan to explore software that uses ‘unsupervised learning’ to make its own classifications based on raw data, rather than being trained.\nCite this article: https://doi.org/10.53053/NNFZ8503"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:06ed661a-b440-4c9d-af7b-2241ec21a0ba>","<urn:uuid:d0ca9608-e316-4b1e-b2f0-8b40a10aa5ad>"],"error":null}
{"question":"When did Antarctica's major glaciation begin and what caused it?","answer":"Major expansion of Antarctic glaciations started around 35 to 40 million years ago. This was likely a response to declining atmospheric CO2 levels from their peak in the Cretaceous period (approximately 100 million years ago).","context":["6.3 The Pre-Quaternary Climates\n6.3.1 What is the Relationship Between Carbon Dioxide and Temperature in this Time Period?\nPre-Quaternary climates prior to 2.6 Ma (e.g., Figure 6.1) were mostly warmer than today and associated with higher CO2 levels. In that sense, they have certain similarities with the anticipated future climate change (although the global biology and geography were increasingly different further back in time). In general, they verify that warmer climates are to be expected with increased greenhouse gas concentrations. Looking back in time beyond the reach of ice cores, that is, prior to about 1 Ma, data on greenhouse gas concentrations in the atmosphere become much more uncertain. However, there are ongoing efforts to obtain quantitative reconstructions of the warm climates over the past 65 Myr and the following subsections discuss two particularly relevant climate events of this period.\nHow accurately is the relationship between CO2 and temperature known? There are four primary proxies used for pre-Quaternary CO2 levels (Jasper and Hayes, 1990; Royer et al., 2001; Royer, 2003). Two proxies apply the fact that biological entities in soils and seawater have carbon isotope ratios that are distinct from the atmosphere (Cerling, 1991; Freeman and Hayes, 1992; Yapp and Poths, 1992; Pagani et al., 2005). The third proxy uses the ratio of boron isotopes (Pearson and Palmer, 2000), while the fourth uses the empirical relationship between stomatal pores on tree leaves and atmospheric CO2 content (McElwain and Chaloner, 1995; Royer, 2003). As shown in Figure 6.1 (bottom panel), while there is a wide range of reconstructed CO2 values, magnitudes are generally higher than the interglacial, pre-industrial values seen in ice core data. Changes in CO2 on these long time scales are thought to be driven by changes in tectonic processes (e.g., volcanic activity source and silicate weathering drawdown; e.g., Ruddiman, 1997). Temperature reconstructions, such as that shown in Figure 6.1 (middle panel), are derived from O isotopes (corrected for variations in the global ice volume), as well as Mg/Ca in forams and alkenones. Indicators for the presence of continental ice on Earth show that the planet was mostly ice-free during geologic history, another indication of the general warmth. Major expansion of antarctic glaciations starting around 35 to 40 Ma was likely a response, in part, to declining atmospheric CO2 levels from their peak in the Cretaceous (~100 Ma) (DeConto and Pollard, 2003). The relationship between CO2 and temperature can be traced further back in time as indicated in Figure 6.1 (top panel), which shows that the warmth of the Mesozoic Era (230–65 Ma) was likely associated with high levels of CO2 and that the major glaciations around 300 Ma likely coincided with low CO2 concentrations relative to surrounding periods.\nFigure 6.1. (Top) Atmospheric CO2 and continental glaciation 400 Ma to present. Vertical blue bars mark the timing and palaeolatitudinal extent of ice sheets (after Crowley, 1998). Plotted CO2 records represent five-point running averages from each of the four major proxies (see Royer, 2006 for details of compilation). Also plotted are the plausible ranges of CO2 from the geochemical carbon cycle model GEOCARB III (Berner and Kothavala, 2001). All data have been adjusted to the Gradstein et al. (2004) time scale. (Middle) Global compilation of deep-sea benthic foraminifera 18O isotope records from 40 Deep Sea Drilling Program and Ocean Drilling Program sites (Zachos et al., 2001) updated with high-resolution records for the Eocene through Miocene interval (Billups et al., 2002; Bohaty and Zachos, 2003; Lear et al., 2004). Most data were derived from analyses of two common and long-lived benthic taxa, Cibicidoides and Nuttallides. To correct for genus-specific isotope vital effects, the 18O values were adjusted by +0.64 and +0.4 (Shackleton et al., 1984), respectively. The ages are relative to the geomagnetic polarity time scale of Berggren et al. (1995). The raw data were smoothed using a five-point running mean, and curve-fitted with a locally weighted mean. The 18O temperature values assume an ice-free ocean (–1.0‰ Standard Mean Ocean Water), and thus only apply to the time preceding large-scale antarctic glaciation (~35 Ma). After the early Oligocene much of the variability (~70%) in the 18O record reflects changes in antarctic and Northern Hemisphere ice volume, which is represented by light blue horizontal bars (e.g., Hambrey et al., 1991; Wise et al., 1991; Ehrmann and Mackensen, 1992). Where the bars are dashed, they represent periods of ephemeral ice or ice sheets smaller than present, while the solid bars represent ice sheets of modern or greater size. The evolution and stability of the West Antarctic Ice Sheet (e.g., Lemasurier and Rocchi, 2005) remains an important area of uncertainty that could affect estimates of future sea level rise. (Bottom) Detailed record of CO2 for the last 65 Myr. Individual records of CO2 and associated errors are colour-coded by proxy method; when possible, records are based on replicate samples (see Royer, 2006 for details and data references). Dating errors are typically less than ±1 Myr. The range of error for each CO2 proxy varies considerably, with estimates based on soil nodules yielding the greatest uncertainty. Also plotted are the plausible ranges of CO2 from three geochemical carbon cycle models."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:e0f18eed-e30f-40da-9df9-8e010a67f92e>"],"error":null}
{"question":"Hello! I am curious about performances with large choirs. How does the size of choir used in Handel's oratorios historically compare with the GSU Singers performing Carmina Burana?","answer":"During Handel's lifetime, his oratorios were performed by relatively small ensembles with just a few dozen professional singers (men, boys and perhaps a few women). However, after his death, performances grew to include hundreds or even thousands of singers. In contrast, the Georgia State University Singers, who are performing Carmina Burana, is described as the university's premier vocal ensemble selected by competitive audition, comprising both music majors and non-majors, undergraduate and graduate students, representing the diverse population of Georgia State University.","context":["Learn about the Music for Atlanta Ballet’s Carmina Burana + Video of the GSU Singers Rehearsal\nLearn About the Music for Atlanta Ballet's Production of Carmina Burana\nThe Carl Orff score is one of the most recognized pieces of music, and you may not even realize that you already know it! Many films and television shows have used or incorporated the melody of \"O Fortuna\" (opening and closing movement) from Carl Orff’s Camina Burana into their soundtracks. Some of these films include Glory (1989), Hunt for Red October (1990), Natural Born Killers (1994), and Cheaper By the Dozen (2003). TV shows include Friends, The Office (US), The Simpsons, Glee, The Tonight Show with Jay Leno, and Late Show with David Letterman.\nClick on the image below to watch the Georgia State University Singers rehearse \"O Fortuna\" for the upcoming performance of David Bintley's Carmina Burana. See if you recognize the music!\nGeorgia State University Singers perform \"O Fortuna\" in Carmina Burana written by Carl Orff; video by Brian Wallenberg.\nAtlanta Ballet's production of Carmina Burana by David Bintley will be reminiscent of an arena-sized concert with not only a live orchestra but also a full-sized chorus and three professional soloists! Learn about the musical artists who will be bringing this dazzling, modern interpretation and North American premiere to life April 12-14. Get your tickets today by clicking here!\nscore to life for all Atlanta Ballet performances of David Bintley's Carmina Burana!\nBrendan Daly (Tenor Soloist), an Atlanta native, finished the 2011|2012 season with critically noted lead roles in Le 66 by Offenbach, Trial by Jury by G&S, and The Mighty Casey by Schuman (Opera Saratoga). Recent supporting credits include La Bohème (Atlanta Opera), Die Fledermaus (Saratoga), Kurt Weil’s Mahagonny (Opera Boston), Haydn’s Creation, Handel’s Messiah, and the Magnificat and St. Matthew Passion of Bach. Brendan apprenticed two seasons with Opera Colorado, appearing in Tales of Hoffmann by Nathanaël and the Barber of Seville (Almaviva). He is in residency at Boston University’s Opera Institute, recently appearing in stage works of Massenet, Poulenc, Britten, and Jake Heggie.\nAngela Gilbert (Soprano Soloist), a South African born soprano, is an accomplished international interpreter of the Bel Canto repertoire. She has performed the title role in Donizetti’s Lucia di Lammermoor and Maria Stuarda for San Diego Opera under the batons of Richard Bonynge and Edoardo Müller, respectively. The title role in Lucia has also taken her to the Anna Livia International Opera Festival in Dublin, Ireland, Cape Town Opera in South Africa, Connecticut Grand Opera, Kentucky Opera, and Palm Beach Opera; and she has covered the role for Natalie Dessay at the San Francisco Opera. She has also performed Norina in Don Pasquale with Cape Town Opera and Wolf Trap Opera, Adina in L’Elisir d’Amore with the Bar Harbor Festival, and Inez in La Favorita for Opera Orchestra of New York at Carnegie Hall. Additional engagements with OONY include covering the title role in Adelia and Elena in Rossini’s La Donna del Lago. An alumna of the Lindemann Young Artist Development Program at the Metropolitan Opera, Angela is a versatile performer relishing her ongoing relationship with Mozart and Verdi.\nGabriel Preisser (Baritone Soloist), praised for his \"rich and powerful voice,\" has performed over 30 operatic and musical theatre roles with companies such as Des Moines Metro Opera, Utah Festival Opera, Pensacola Opera, and Kentucky Opera. He has also appeared as a soloist with the Minnesota Orchestra, Orlando Philharmonic, Ars Lyrica, Mercury Baroque, and others. Recently, he reprised his role as Lt. Gordon in the Pulitzer Prize winning Silent Night with the Opera Company of Philadelphia, a role he created with Minnesota Opera last year. A district winner in the 2010 Metropolitan Opera National Council Competition and winner of the American finals of the International Lirico Concorso Competition in 2011, he has earned performance degrees from Florida State University and the University of Houston.\nGEORGIA STATE UNIVERSITY SINGERS UNDER THE DIRECTION OF DR. DEANNA JOSEPH\nDr. Deanna Joseph (Conductor, Georgia State University Singers) is director of choral activities at the Georgia State University School of Music, where she conducts the University Singers and the Women’s Chorus, teaches conducting and choral literature, and supervises the master’s program in choral conducting. She is an active guest conductor and clinician who has conducted all-state and honor choirs in eight states. Dr. Joseph is a frequent conductor of choral-orchestral repertoire and has led performances of pieces such as Mendelssohn’s Elijah, Beethoven‘s Mass in C, Mozart’s Requiem, Haydn’s Creation and Lord Nelson Mass, Schubert’s Mass in A-flat, and Bruckner’s Mass in D Minor. Dr. Joseph holds a BS in music education from Duquesne University and both the MM and the DMA in conducting from the Eastman School of Music. At Eastman, she taught conducting and served as the assistant conductor of the Eastman Chorale and the Eastman-Rochester Chorus and was awarded the Walter Hagen Conducting Prize. Dr. Joseph has also been a conducting fellow at the Oregon Bach Festival. Prior to her appointment at Georgia State University, Dr. Joseph served on the faculties at Smith College (2004-2007), the University of Massachusetts at Amherst (2007-2008), and Hobart and William Smith Colleges (2008-2010) and served for three summers as a conductor and teacher on the artist faculty of the New York State Summer School for the Arts - School of Choral Studies (2007-2009).\nGeorgia State University Singers (Choir), under the direction of Dr. Deanna Joseph, is the Georgia State University School of Music’s premier vocal ensemble. Selected by competitive audition, the choir is comprised of both music majors and non-majors, undergraduate and graduate students, while representing the diverse population of Georgia State University. The ensemble’s annual performances have included appearances before the Georgia Music Educators Association, American Choral Directors Association, and at the Georgia Music Hall of Fame Awards. The Singers’ tours have taken them throughout much of the United States, including Carnegie Hall on two occasions, and six international tours with stops in France, Belgium, Italy, Yugoslavia, Finland, Russian, Estonia, Canada, and Great Britain. The University Singers is honored to have been selected to represent the United States in the 2013 Florilège Vocal de Tours International Choral Song Competition this May. Click here and select the 'Music' tab for the Georgia State University Singers listing.\nATLANTA BALLET ORCHESTRA WITH GUEST CONDUCTOR\nBeatrice Affron (Conductor) was born and raised in New York City. She joined Pennsylvania Ballet in 1993 as the assistant conductor and was promoted to music director and conductor in 1997. A graduate of Yale University, Beatrice studied conducting with Robert Spano and Pascal Verrot at New England Conservatory. At Pennsylvania Ballet, Beatrice has conducted many Balanchine ballets as well as other classics such as The Sleeping Beauty and Romeo and Juliet. In 2004, she conducted the world premiere of Christopher Wheeldon’s Swan Lake. Other dance credits include Les Sylphides, Moor’s Pavane, and Dark Elegies, all of which Beatrice led at the Boston Conservatory. Outside of dance, Beatrice is heard in a large and varied repertoire that encompasses works from Handel to Donizetti to Philip Glass. In 2002, she received international attention when she led the world premiere performances of Philip Glass and Mary Zimmerman’s Galileo Galilei at Chicago’s\nGoodman Theater and subsequently on a tour to London’s Barbican Theatre. In 2005, Beatrice made her debut with the Glimmerglass Opera conducting Donizetti’s Lucie de Lammermoor. Other guest conducting appearances include Opera Theatre St. Louis, the Pro Arte Chamber Orchestra, the Landmarks Orchestra, and New England Conservatory. Beatrice lives in Boston with her husband and daughter. Click here for the Atlanta Ballet Orchestra listing.","George Frideric Handel (1685-1759) is best known to the general public today as a composer of oratorios. But the German composer originally established his reputation as a composer of Italian opera, first in Rome and later in London.\nDuring the 1730s Handel realized that his operatic style was losing popularity among London audiences. He therefore turned to a new type of composition—the oratorio in English—which could be produced at less expense (no sets or costumes were required), and which could be enjoyed by those who had never felt comfortable with the aristocratic entertainment of Italian opera.\nFollowing the examples of earlier oratorios, Handel’s works are essentially operatic in style, and based on stories from the “Old Testament.” Handel broke from his predecessors, however, in his preference for the English language and his dramatic use of the chorus, setting it on an equal footing with the solo roles. Handel’s oratorios thus succeeded in portraying the drama of great biblical stories to Londoners in a language they could understand. Furthermore, in their glowing portrayal of the heroes and populace of ancient Israel, Handel’s oratorios were among the rare works of art that portrayed Jews in a favorable light. And London’s Jews (only 6,000 strong) responded with enthusiasm.\nComposed in just one month between 1 October and 1 November 1738, Israel in Egypt premiered at London’s King’s Theatre in the Haymarket on April 4, 1739. The first performance was not received well by its audience, so Handel immediately revised the work, and it has subsequently become a favorite among choral societies the world over.\nWhile most of Handel’s oratorios are loosely based on “Old Testament” stories, Israel in Egypt and Messiah are the only two that are drawn directly and exclusively from the biblical text, with no paraphrases, interpolations or interpretations. It is not known whether Handel chose the biblical passages himself, or whether he consulted his collaborator Charles Jennens. In any event, the libretto is taken from the book of Exodus and a few passages from Psalms 105 and 106, telling the story of the Israelites’ slavery in Egypt, the advent of Moses the liberator, the plagues upon the Egyptians, the crossing of the Sea of Reeds, and the subsequent exultant song of praise. The plagues seem to have inspired Handel to create some of his most colorful “word painting.” The listener can easily hear the hopping of the frogs, the buzzing of the flies, the pounding of the fiery hail, the eerie darkness and so much more.\nIsrael in Egypt is also unique in its abundance of choruses and double choruses, and its paucity of solo arias. The usual format of Handel’s oratorios is the sequence: recitative+aria+chorus. But in this oratorio there are twenty-six choruses (eighteen of which are for double chorus), and only four recitatives, five arias, and three duets. Most of the arias are found in Part Two, which was actually composed before the first part.\nFurthermore, this oratorio holds the record for the greatest amount of musical plagiarism. But perhaps plagiarism is too harsh a word. Composers in that era freely borrowed material and modified it for their own needs; copyright protection was virtually unknown. For Israel in Egypt Handel adapted music from his own pen, as well as from those of his colleagues, Alessandro Stradella, Johann Caspar Kerl and Don Dionigi Erba. But in each case Handel revised and greatly improved the source material. It’s hard to believe that the chorus “He Gave Them Hailstones” could have been composed to any other text, yet the source material is a sinfonia and bass aria from Stradella’s Serenata.\nDuring Handel’s lifetime, his oratorios were performed by relatively small ensembles—a chorus of a few dozen professional singers (men, boys and perhaps a few women) and an equal number of instrumentalists. But with the increasing popularity of these oratorios came a growing desire on the part of amateur musicians to perform them. Shortly after the composer’s death performances featured hundreds (and later, thousands) of singers and players. In fact, the first community choruses arose in England at that time, specifically for the purpose of performing Handel’s oratorios. Fortunately, these works are great enough to stand up to various modes of interpretation. Our performance involves a chorus of more than one hundred amateur adult male and female singers and an orchestra of thirty three players using modern instruments. For practical reasons we have dropped five of the choral movements. Bostonian audiences generally want to hear “early music” performed as authentically as possible. But our approach mirrors the performance practice of the early nineteenth century rather than that of 1739. To quote conductor Leonard Van Camp, “Even the most learned scholar-performers of our day cannot duplicate the conditions of Handel’s day and recapture the exact way in which he performed. The audience was different, their knowledge of the Bible was different, the instruments were different, the feeling of the time was different, and so on.” We hope that our performance conveys the drama of Handel’s music in a manner of which the great composer would have approved.\n– Joshua Jacobson"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:a557901d-caaa-46eb-afb3-fd44bb7fca4a>","<urn:uuid:91e7f25b-ba72-45aa-b2cd-f0148c15d1d9>"],"error":null}
{"question":"Do cooked fish and general leftovers have the same refrigeration time?","answer":"Yes, both cooked fish and general leftovers can be safely stored in the refrigerator for 3 to 4 days.","context":["Although most people employ the \"sniff test\" to determine if their food is still good, this method can be misleading and dangerous. Many organisms that cause food borne illnesses do not create any odor or visual evidence of their presence. Use these brief guidelines to help determine how long food should be stored for maximum freshness and safety. Leftovers\nLeftovers may be the most susceptible to pathogens\nbecause they often spend an elongated amount of time in the temperature danger zone (between 40-140 degrees Fahrenheit) as they cool. Although bacteria is usually killed during the cooking process, it is quickly reintroduced from the environment after cooking. Leftovers should be placed in the refrigerator (below 40 degrees Fahrenheit) as soon as possible after cooking. Once refrigerated, leftovers should be kept for only 3 to 4 days. If promptly frozen, leftovers can be stored for 3 to 4 months. Fresh, Uncooked Meats\nFresh, uncooked meat usually contains a fair amount of bacteria and should only be stored for a short time in the refrigerator before cooking. Fresh poultry and ground meats (hamburger or fresh sausages) should only be kept in the refrigerator for 1 to 2 days. Solid cuts of beef, pork, or lamb can be kept refrigerated for 3 to 5 days prior to cooking. Cured meats, such as ham, can be kept a little longer or for 5 to 7 days. Eggs\nEggs should always be stored refrigerated below\n40 degrees Fahrenheit. Storing eggs in the main compartment of the refrigerator, rather than storage compartments on the inside of the door, will help ensure that they stay at the proper temperature. When stored properly, eggs can be kept for 3 to 5 weeks past the \"sell by\" date. If your eggs take on an undesirable or sulfur like smell, discard them. Canned Goods\nCanned goods can be divided into two categories as far as storage times: high acid and low acid. High acid canned foods, such as tomato products and pineapple, have a shorter shelf life of about one and a half years. Low acid canned foods, like most vegetables and meats, have a longer shelf life of about 5 years. If you cannot remember when the product was purchased, most cans are labeled with a \"Best if Used By\" date that can be used as a guide. If at any time you find a can that is dented, damaged, or bulging, discard it immediately. Damaged cans can have microscopic cracks which can allow bacteria entry. Frozen Foods\nPackaged frozen foods that have remained unopened should stay palatable for up to 3 months. Although freezing does not kill bacteria, it slows its growth significantly. Expiration dates on frozen foods are usually a guide to best quality rather than spoilage. Prolonged freezing can dry foods, cause ice crystals, and other common characteristics of \"freezer burn.\" Opened packages can expose food to bacteria, air, and rogue smells. Once opened, frozen foods should only be kept 1 to 2 months in the freezer.","Raw fish and shellfish should be kept in the refrigerator (40 °F/4.4 °C or less) only 1 or 2 days before cooking or freezing. After cooking, store seafood in the refrigerator 3 to 4 days. Any frozen fish or shellfish will be safe indefinitely; however, the flavor and texture will lessen after lengthy storage.\nHow long can I keep raw fish in the fridge?\nIn general, raw fish should be kept in the fridge 1 or 2 days maximum. If you are not going to eat the fish immediately, you can freeze it. It is best to freeze fish immediately to preserve freshness.\nCan you eat fish that has been in the fridge for a week?\nCook fresh fish within two days. When stored properly in the refrigerator, fresh fish should be cooked within two days, up to three at most, from the time it was purchased. Shelf life does vary from species to species, with some lasting slightly longer. Two days is a good rule of thumb to follow.\nHow long can thawed fish stay in the fridge?\nThawing fish in hot water is not recommended — this can cause the superficial meat to begin to cook while the inside is still frozen. When it is completely thawed, keep the fish in a refrigerator for no more than two days before eating it.\nHow do you know if fish has gone bad?\nSome common traits of bad fish are a slimy, milky flesh (a thick, slippery coating) and a fishy smell. This is hard because fish is smelly and slimy by nature, but these traits become much more pronounced when fish has gone bad. Fresh fillets should glisten like they came out of water.\nHow do you store raw fish in the fridge?\nRefrigerate the Fish Before refrigerating a fish, wash it in cold water and dry it with a clean cloth or paper towels. Then wrap the clean fish in waxed paper, plastic wrap or aluminum foil, and store it on ice or in the refrigerator. You can usually store a fish in the refrigerator for up to two days.\nHow do you keep fish fresh in the refrigerator?\nTo properly store the fish, seal the fish fillets in a plastic bag and squeeze out the air. Then place the bag in a bowl filled with ice. Generally, fish can be stored in the fridge for up to two days if it is to be used immediately after purchase.\nWhat happens when you eat old fish?\nThere are two types of food poisoning you can get from eating fish. They are ciguatera poisoning and scombroid poisoning. Ciguatera poisoning symptoms include abdominal cramps, nausea, vomiting, and diarrhea. Symptoms can progress to headache, muscle aches, and itchy, tingly, or numbness of the skin.\nCan you eat cooked fish after 5 days?\nCooked fish and other seafood can be safely stored in the refrigerator 3 to 4 days. Refrigeration slows but does not prevent bacterial growth. Therefore, it’s important to use food within recommended time before it spoils or becomes dangerous.\nWhat happens if you eat expired fish?\n“If you do eat a food past the expiration date [and the food] is spoiled, you could develop symptoms of food poisoning,” said registered dietitian nutritionist Summer Yule, MS. The symptoms of foodborne illness can include fever, chills, stomach cramps, diarrhea, nausea, and vomiting.\nCan I refreeze fish after thawing?\nIf you thawed your meat, poultry, and fish properly in the refrigerator, then you can refreeze it without cooking. However, there may be some loss of quality because of the moisture loss through thawing. After cooking the meat, poultry, and fish that was refrozen, you can also refreeze it.\nHow long can you keep raw cod in the fridge?\nCOD – FRESH, RAW After cod is purchased, it may be refrigerated for 1 to 2 days – the “sell-by” date on the package may expire during that storage period, but the cod will remain safe to use after the sell by date if it has been properly stored.\nHow do you defrost fish in the fridge?\nOption one – in the fridge Do not remove fish from packaging. Place fish in a bowl. Place bowl at the bottom of the fridge. Leave until fully defrosted. Defrost time is typically six to eight hours per lb.\nIs it safe to eat smelly fish?\n“Fishy” odors begin to develop in fish immediately after they are caught and killed, as bacteria on the surface break down the compound trimethylamine oxide into stinky trimethylamine. As long as the flesh is still firm and the skin is shiny rather than slimy, this fish is still fine to cook and eat.\nCan you eat fish 4 days out of date?\nYou should never take any chances when it comes to your meat and fish. While smoked fish, like salmon or kippers, can last up to three days in the fridge after the “use-by” date, fresh fish should be thrown away before 24 hours.\nHow long before fish goes bad?\nAccording to Stephanie Harris-Uyidi, chef and cookbook author, fish can be stored in the fridge for up to two days if it will be used immediately after purchase. The FDA also recommends you keep fresh fish, shrimp, scallops, and squid for just one to two days in the fridge.\nCan I freeze fresh fish?\nFresh, and the emphasis is on ‘fresh’, (store bought or fresh catch) fish freeze well for up to six months if stored in an airtight method (fatty fish like salmon and trout; only three months). Keep the fish as cool as possible (on ice, or in the shade).\nHow long can you keep Ungutted fish?\nIf you bleed ungutted fish and then store them on ice or in the refrigerator, they can be kept for 24-48 hours without quality problems. However, it’s essential to keep fish cool for this. If you don’t keep them cool, you only have 6-12 hours before ungutted fish goes bad.\nHow long can you freeze fresh fish?\nWhen frozen in an at-home refrigerator, a fatty fish like tuna or salmon will last two to three months. A leaner fish like cod will last up to six months. When vacuum-sealed and properly stored in the freezer, fish can last for as long as two years.\nHow do you keep fish fresh for a week?\nHow to store fish so it stays fresher for longer Wash it. Wash fresh fish with water and dry thoroughly with a paper towel. Use an airtight container. Fresh fish can cause a stink in the refrigerator if it is not properly sealed. Keep it cool. Fresh fish needs to be kept very cool to make sure it doesn’t rot. Prioritise it."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:044e898e-8376-4cf8-992c-ed10156790b2>","<urn:uuid:2f1fc12e-12c7-42a7-82a6-fedd76f63535>"],"error":null}
{"question":"What are the recommended training principles for boxing conditioning, and what injury risks should be monitored?","answer":"For conditioning, boxouts should be short and spirited with no sitting down during workouts. Roadwork must be done six days weekly, including sprints and uphill climbs, with running being the most essential exercise regardless of weather. Skill tasks should be done first before fatigue sets in, with conditioning last. Regarding injury risks, boxers must monitor for various conditions including cuts, nosebleeds, bruises (especially in the rib cage area), concussions (which can cause disorientation and memory loss), and shoulder dislocations. It's crucial to never disregard any injury, even slight ones, and to maintain proper hydration by always having sufficient water available. Regular stretching exercises focusing on specific muscles like hamstrings, quadriceps, and shoulders are essential to prevent muscle strains and sprains.","context":["1. Listen to your body and take it slow and easy when you are loosening up or doing your warm-ups. Never, ever, disregard an injury, no matter how slight.\n2. Dress appropriately by always wearing loose, comfortable clothing and the proper shoes—sneakers for running and boxing shoes for sparring.\n3. You do your roadwork six days a week, taking one day off and include intervals of sprints and uphill climbs. If you only have time for one exercise, make that exercise running. You must run no matter what the weather is like.\n4. If you start an exercise, you must complete it! You can lighten up or slow down but you never quit. Once that bell sounds there is no quitting.\n5. Each workout needs to be goal oriented.\n6. Skill tasks should be done first, don’t let fatigue interfere with learning. In other words you do your conditioning last.\n7. Take the extra time to insure that you wrap your hands properly.\n8. Shadow box for form using the mirror – it’s the best coach in the gym.\n9. You first work on your stance, which means chin down, hands up, elbows in, knees bent, weight on the balls of your feet and maintain the triangle.\n10. Always keep in mind that speed and form are the most important considerations.\n11. Workouts should be short and spirited. You never sit down during a workout – keep moving.\n12. The use of the heavy bag is for working on combinations and developing power.\n13. Supervised sparring should only be done when you’re fresh and can learn.\n14. You spar with smaller men for speed, and the bigger men for power.\n15. Always use the large gloves for training and sparring (16 ounce).\n16. Always put Vaseline on your face before each sparring session.\n17. There is a good reason for sparring for 3 minute intervals. It gives your mind an opportunity to develop a 3 minute mental clock, the same time period they use for rounds in real competition.\n18. Avoid dehydration by always having a sufficient supply of water on hand.\n19. Never give in to your body, remembering that your mind is a million times stronger.\n20. As quick as you throw a punch at your target, you quickly bring it back to the on-guard position.\n21. Why they say your jab is so important: 1) it measures the distance between you and your opponent, 2) it’s used to set up other punches and 3) you can score with it as a solid blow.\n22. Since the Hook is the most difficult punch to throw properly, it’s important you perfect the jab and right hand first. The power of this punch is generated by body torque and turning the punch over. It’s thrown as if you are hitting your opponent with your shoulder.\n23. You never make the uppercut the last punch of a combination. Likewise, you always follow the right with a hook and the left with a straight right to close you up defensively.\n24. A good boxer moves their head, comes in and out, as well as circles an opponent, recalling that old adage, a moving target is always harder to hit.\n25. Good footwork means your feet coincide with the movement and placement of punches. What you want to do is control the punching distance and keep your chin in the shoulder of the hand you just punched with.\n26. Abdominal exercises should be done in every workout.\n27. Always cool down and stretch after a training session.\n28. Keep things consistent: sleep (a minimum of 8 hours), regular meals, and exercise, which excludes any use of drugs or alcohol.\n29. Never lose weight unnaturally e.g. with pills or supplements. Make your diet a way of life.\n30. After learning all the angles, all the tricks from as many coaches as possible, you then move on to the coach that makes you feel the most comfortable and you can truly trust.\nBy: Jim Wyatt – Sport of Boxing","Boxing is a full contact, combat sport in which players often face a high risk of sustaining injuries. These can occur most frequently during training and it will make everyday tasks a bit more difficult.\nTherefore, it’s essential that you take the right measures to prevent injuries from occurring as much as you can.\nTypes of Boxing Injuries\nBefore you can learn how to prevent injuries while boxing, you must know the common boxing injuries. This will help you to take extra precautions.\n- Cuts or Lacerations: These occur more frequently during professional fights rather than during training or sparring, though they can still happen. During a bout, cuts are treated by cleaning the wound and applying petroleum jelly on it to prevent bleeding.\n- Nosebleeds: This is one of the most common boxing injuries, and are caused by small lacerations inside the nose.\n- Bruises: When boxers sustain a high impact hit, they usually suffer from bruises. Bruises occur when blood vessels beneath the skin are damaged, such as a “black eye.” The soft tissue of the rib cage can get easily bruised by body shots. Applying a cold compress on bruises can reduce inflammation and pain.\n- Fractures: Boxers often have fractured bones, usually in the nose, wrist, hand, jaws, and rib regions. Fractures involving the metacarpal bones are quite common among boxers and are referred to as a “Boxers Fracture“. Fractures require immediate and extended treatment.\n- Concussion: Heavy impact to the head can shake the brain and lead to a loss of consciousness, vomiting, disorientation, short term memory loss, dizziness, and headaches. It is important to consult a neurologist when you suffer from a concussion.\n- Shoulder Dislocation: As a result of a heavy blow to the body or due to improper hand movement, the humorous bone of the arm can get detached from the shoulder blade or scapula. This is referred to as a shoulder dislocation. It is extremely painful and requires immediate hospitalization.\n- Sprains: During bouts and training, frequent rapid movements can result in muscle and ligament sprains. Boxers are more susceptible to straining muscles in their back, shoulders, arms, knees, and ankles.\nHow to Prevent Injuries in 10 Ways\n1. Wear the Proper Protective Gear\nDuring sparring, you should always wear the proper protective gear. Even if it’s just light sparring, because it’s easy to sustain injuries such as cuts within the mouth. Here are some precautions that must follow while using protective gear.\n- Head Guard: Make sure that you your head guard is properly cushioned, feels comfortable, easily breathable and easy to see out of.\n- Boxing Gloves for Sparring: If you’re below 147lbs, you and your sparring partner’s gloves should be at least 14 ounces. If you weigh more, you should opt for at least 16 ounces. Sparring gloves have extra padding in comparison to training gloves, so ensure that you have the right type. You can find the 10 best rated boxing gloves here.\n- Boxing Gloves for Training: You may want to get a separate pair of gloves for the heavy bag and other types of bag work. You’ll often be hitting hard and frequent on the bags which requires more protection, so bigger gloves are recommended.\n- Groin Guard: For obvious reasons, get a bigger groin guard with more padding and that’s comfortable.\n- Mouth Guard: This is definitely a must for sparring. You should never enter the ring without a custom fitted mouth guard. Cheap ones usually don’t give you the proper mold, so get one that has a good reputation and name behind it. Top only is fine, but there’s also an option to have top and bottom if you prefer.\n- Hand Wraps: These are also are must no matter if you’re sparring or just doing bag work. Ensure that they’re 180in so that they’re long enough to properly wrap around your hands to give proper protection to your hands. Preferably, you should go for a semi-elastic type. You can find the 5 best boxing hand wraps here.\n2. Ensure Your Hands are Wrapped Properly\nAlways use the proper hand wrapping technique. There are many videos on the Internet that show various techniques to properly wrap your hands. Whatever method you choose, ensure that there is adequate padding on your knuckles and wrist.\nAlways start wrapping with your hand stretched out fully, so when to make a fist, it tightens up, but make sure that you don’t wrap it too tight otherwise it’ll reduce blood flow and will be extremely uncomfortable.\nWrapping between the fingers will provide good support and prevent hand injuries better. To find out how to properly wrap your hands, click here.\n3. Do Stretching Exercises Regularly\nBoxers face a high risk of muscle strain and injury. When you do regular stretching exercises your muscles and ligaments become longer, and hence your range of movement increases. This decreases your risk of muscle sprains and strains.\nYou should concentrate on stretching exercises aimed at specific muscles, such as hamstring, quadriceps, and shoulder muscles. Also, don’t forget to do your warm up exercises before sparring, which your trainer should make it mandatory.\nResistance bands are a great way of loosening, stretching and strengthening your muscles. I highly recommend Bodylastics Resistance Bands for their outstanding construction and materials.\n4. Use Moisturizers to Prevent Nose Bleeds\nWhen the skin inside the nose is dry and brittle, it is more susceptible to cuts and lacerations. Steam inhalations, saline water nose drops, and natural moisturizing nose sprays such as Aloe Vera nose sprays can effective methods of conditioning the skin inside the nose. By moisturizing the skin inside your nose before sparring, you can make yourself less vulnerable to nosebleeds.\n5. Learn the Correct Punching Techniques\nYour hands are the most precious tools but they’re also the most susceptible to injury. To minimize damage to your wrists and fingers, learn how to throw a punch correctly. Make sure that you turn fist when punching so you’ve aligned your wrist correctly.\nAlso, when striking, ensure that you’re aiming for the knuckle of your middle finger to make contact first. Many times, fighters injure their thumbs because of the way they throw their punches, which often causes fractures and broken bones.\nTo learn how to properly throw punches, check out the How To Box In 10 Days course, which takes you through boxing fundamentals step-by-step.\n6. Apply Petroleum Jelly on Impact Sites\nApply a thin coat of petroleum jelly on your face, which is often the target of jabs. This will make the skin slippery, supple, and elastic thus reducing the probability of cuts and bruises from punches.\nIt’s most useful if you’re fighting in the professional game where no head guard is allowed, but facial injuries are known to occur during sparring also.\n7. Improve Your Fitness Level\nDefending yourself from blows is essential to minimizing injuries. You must have excellent stamina and endurance to be able to withstand intense training procedures.\nIf you have high level of physical conditioning, then you will be able to go through the bouts with a clear head and defend yourself by maintaining quick footwork and agile reflexes. If you’re tired, it’s difficult to move around, but remember to keep your guard up at all times.\n8. Follow an Effective Diet\nAll athletes need to have a nutritious diet that helps their body to heal and remain strong. Your daily diet must include high levels of calcium, protein, and Vitamin D. Regular calcium intake will strengthen your bones. This will help in reducing the risk of fractures and help the bones to heal faster in the event of a fracture.\nIt is also important to drink plenty of fluids to keep your body hydrated at all times. In between bouts and during training, boxers should take sports drinks to replenish the electrolytes and water lost through sweating.\nIf you fail to do this, your body will become dehydrated and you will feel fatigued, resulting in a higher likelihood of head injuries such as concussions. The 30 Day Fighter’s Diet guide has helped amateur and pro fighters to manage their weight effectively.\n9. Consult a Doctor When in Pain\nToo often, fighters ignore a pain is until the point where it gets really bad, when it could’ve been prevented just by consulting a doctor.\nIf for any reason you’re under no circumstance to visit a doctor, then do your own research on the Internet because more than likely, someone else would’ve experienced the same pain as you. They can offer you advice and how to make it better or even cure it altogether.\n10. Let Your Body Rest\nIt’s fine to train hard and push yourself to the limit, but if you feel any sharp pains anywhere during training, then stop to find out what the problem is.\nIt may be a serious injury or could lead to one if you’re not careful. Let it heal before resuming your training.\nWhen you do push yourself, usually you’ll feel the aches the next morning. It’s a good sign because you know that you’ve trained hard, but just remember that if you are going to doing any form of exercise (if you can), go easy and then your muscles will recover much faster.\nHone Your Defensive Skills\nThe best way to prevent injury during sparring or competition is to know your game well enough to avoid getting hit too much. Spend a lot of time on improving your defensive skills and drill good habits into you so that it slipping, parrying, blocking and ducking punches become subconscious.\nWritten by: Seema Misra\nTo get the most out of your training, I highly recommend the following articles:\n► How to Increase Punching Power\n► 10 Tips to Improve Boxing Footwork\n► Boxing Basics\n► Top 10 Best Heavy Punching Bags\n► Top 10 Best Boxing Gloves"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:8713f427-3e73-4618-ab15-9eb009bb34c2>","<urn:uuid:b1990ea1-0862-4996-bda1-47cdf5cad206>"],"error":null}
{"question":"What's the connection between Open Content licenses and FCW, and how do commercial restrictions affect their compatibility?","answer":"Open Content licenses, like those used in JUSLINE's Open Law Commentaries, provide comprehensive rights of use while imposing certain obligations. These licenses protect both the licensor and public against usage restrictions through the 'copyleft-effect.' Regarding Free Cultural Works (FCW) compatibility, only two Creative Commons licenses meet the requirements: Attribution (CC BY) and Attribution share-alike (CC BY-SA). Licenses containing Non-commercial (NC) restrictions do not qualify as FCW. This commercial restriction issue has sparked debate, with some citing UN Human Rights principles supporting the right to earn a living as reason to avoid NC restrictions, while others argue for NC inclusion to prevent commercial exploitation. The OER Foundation maintains that share-alike provisions combined with open file format requirements sufficiently protect against commercial exploitation while preserving earning rights.","context":["Why commenting law?\nJUSLINE´s Open Law Commentaries provide the opportunity to make a contribution to the general public (\"Open Content\") with a minimal investment of time and to call attention of experts and persons seeking legal assistance.\nYou can actively participate in the legal development!\nMany authors analyse certain judgements or laws in order to criticise or to promote the legal development, in any case to influence it. Another ambition is to advance your own career and to call attention of experts or potential clients.\nThe professional reputation of an author is expressed by the number of readers or how often the contribution is cited in other articles. Empirical studies show that Open Access considerably increases the frequency of the reading and citing of an article (for example \"The Open Citation Project\", a bibliography of American studies). One reason for this development is the fast linking and distribution via \"Blogs\" respectively \"blawgs\".\nFor this reason Open Law Commentaries are the ideal platform for specialised legal publications, especially for lawyers, jurists and juridical interested people who don't have the chance to contribute to a printed law commentary due to their limited time budget or the \"closed-shop-character\" of traditional publishing houses.\nThis project also aims to overcome the frustration of the fast obsolescence of traditional law commentaries caught between two printed editions. New judgements and doctrines can only be incorporated after many years.\nWho should contribute?\nUsually the collaboration on Legal Commentaries is reserved to a small group of authors. As a result of the small number of specialised publishing houses there exist only few commentaries on laws and consequently only a small number of authors.\nThis is regrettable because a large part of the available potential of creativity, experience and knowledge gets lost:\nMany jurists or judges give innovative judgements which receive no public attention because they are not rendered by court of ultimate resort.\nStatements of lawyers questioning accepted theories are not adopted by courts or not taken into account by legal publications.\n(Young) lawyers shape up new perspectives for which they can't find an appropriate platform and which are ignored by leading commentators.\nEverybody can contribute to the Open Law Commentaries! Judges, lawyers, administrative jurists, inhouse counsels, lecturers, students at Law Schools as well as retired lawyers may join the Net-community to collaborate voluntarily on this joint project.\nBut you don't have to be legal practitioner to contribute to the Open Law Commentaries. If you receive for example a judgement which throws a new light on a legal provision you can write a contribution as well as a person who browses the Internet for judgements or other legal information with the aim to incorporate them into an Open Law Commentary.\nFrequently people external to the subject are those who formulate questions unconventionally and initiate new theoretical developments. Albert Einstein was seeking the contact with young students who confronted him with - at first view - simple questions, whereas the answers opened on occasion unexpected and in this respect even for the celebrated scholar advanced perspectives.\nThe \"social control\" by the JUSLINE-community which carefully examines, discusses and if necessary modifies contributions finally provides a favourable result for everybody. Furthermore all former versions of the commentary are saved and made accessible as to enable the users to control each contribution and its modifications.\nOpen Content are texts, pictures, data bases and other contents for which an author can claim protection of intellectual property (in particular copyright), but which are freely accessible via Internet and may be copied and distributed and partly modified by everybody. The rules of use are summarised in Open Content Licenses which base on licenses originally made for the free circulation of software (Open Source Software). For the simple use of a creation, for example reading a text, there is no license necessary, this authorization results from legal provisions.\nThe beginning of the Open Content movement was characterised by the altruistic idea that software should circulate freely as expression of opinion. Open Content projects are also characterised by the wish to facilitate the exchange of knowledge. The distribution of information which is important for society but not state-aided should be made available free of charge in the framework of voluntary cooperations. The content of those data-bases is regularly updated through contributions of third persons.\nOpen Access characterises the aim to make scientific literature and materials free accessible (free of charge and without license restrictions) in the world wide web. Valuable sources are made freely available by their authors on servers of free internet-journals, specialised servers or at their own homepages. Thereby state-aided results of research of universities is made freely accessible instead of being sold costly.\nA milestone in the Open Access movement was the \"Berlin Declaration on Open Access to Knowledge in the Sciences and Humanities\" from October 2003. Many other international organizations as OSI, SPARC and CERN joined this appeal.\nOpen Law Commentaries as Open Content\nOpen Law Commentaries are provided by JUSLINE as Open Content. Open Content is characterized by the granting of comprehensive rights of use but also by assumption of obligations. Who acquires rights by writing or modifying a contribution has to submit these rights under the Free JUSLINE License which means that he has to permit third persons the use of the new version according to the provisions of the JUSLINE License. The Open Content License protects the licensor and the general public against a subsequent restriction of use by third persons. This is provided by the so-called \"copyleft-effect\" which ensures that a creation (including all modifications) subordinated under an Open Content License may be only used according to the provisions of the license.\nDirectly linked to the right of modification granted to third persons is the right of authors and holders of the exclusive rights of use on naming. An Open Content License aims generally to protect the interests of authors and holders of rights as far as possible. The naming of authors and holders of exclusive rights is compulsory, partly already in the heading, partly in the chronology.\nThe Free JUSLINE License\nThe contents of JUSLINE's Open Law Commentaries are subject to the Free JUSLINE License which follows the provisions of the GNU Free Documentation License which was developed for free software respectively manuals for free software. This means that everybody may freely copy, distribute and modify the content of the Open Law Commentaries stating the origins and the individual authors and administrators. Texts derived from the Open Law Commentaries have to be free in the same manner.\nIntention of the Free JUSLINE License is to make the Open Law Commentaries freely accessible i.e. to allow everybody to copy and to distribute them with or without modifications. The license is addressed to people who want to make available their achievements without the requirement of obtaining the permission for use or modifications. Thereby the Free JUSLINE License provides the drafting and distribution of Legal Commentaries by any number of persons who don't have to be connected institutionally.\nThe interests of authors of contributions to Open Law Commentaries are protected by the Free JUSLINE License and it is intention of this license to properly protect and adequately appreciate the creative work of authors and other ancillary copyright legitimated people. The author should be associated with his contribution by naming him or - in case that his contribution was modified by other persons - adding a notice to him in the chronology. Thereby it is assured that authors and administrators are gaining compliment for their creation without being liable for modifications of others.\nBasic Information on Open Content and Open Access Projects\nBerlin Declaration on Open Access to Knowledge in the Sciences and Humanities\nBjörk, Bo-Christer, Open access to scientific publications - an analysis of the barriers to change. Information Research, January 2004\nDoherty, Sean: The Law and Open Source Software\nGomulkiewicz, Robert W.: How Copyleft Uses License Rights to Succeed in the Open Source Software Revolution and the Implications of Art. 2 B\nLaurent, Andrew M. St.: Understanding Open Source and Free Software Licensing\nMcGowan, David: Legal Implications of Open-Source Software\nMoglen, Eben: SCO Scuttles Sense, Claiming GPL Invalidity\nSédallian, Valérie: Garanties et responsabilités dans les logiciels libres\nSim, Deborah; Clayton, Monifa; Boyer, Brian: Legal Research on Open Source Software\nOther Links to Open Access\nScholarly Electronic Publishing Bibliography, by Charles W. Bailey, Jr.\nSPARC Open Access Newsletter & Forum\nAmerican Scientist Open Access Forum\nOpen Access News by Peter Suber\nOpen Content Licenses\nFree JUSLINE License\nGNU Free Documentation License\nOpen Publication License\nCreative Commons Licenses","FCW approved licenses\n|Course dashboard for #OCL4Ed|\n|The right license||Video signpost - Frances Ferreira | Introduction | The essential freedoms | Free cultural works | FCW approved licenses | Technology issues | E-Activity - 3rd Learning reflection|\nIn a digital OER world, many of these problems may be avoided by shifting from a default culture of restrictions to a proactive culture of giving permissions in advance. Creative Commons provides the legal framework to refine copyright by providing the necessary permissions to support the freedom to use and adapt educational materials in advance. This is an effective way to encourage and support educational freedom of choice.\nObtaining the 4R permissions (i.e., reuse, revise, remix, redistribute) in advance contributes to the sustainability of education. OER projects like the WikiEducator community do not incorporate all-rights reserved copyright material into the wiki. Every time a contributor makes an edit on WikiEducator, he/she confirms that the contribution is original work (to be shared under a free cultural works approved license) or is sourced from the public domain or similar free (libre) resources.\nFree content licenses\nThe freedom \"paradox\"\nThere is a healthy debate in the Open Education Resource community regarding the implementation of the essential freedoms for OER.\nThe Creative Commons licenses are reasonably well known in the education community and there is a strong association with the use of this license and the sharing of content. However, only two of the six generic Creative Commons licenses meet the requirements of the free cultural works definition.\nSome advocates of the libre community suggest that this statement misleads the general public because there are configurations of the Creative Commons license that don't meet the requirements of the free cultural works definition. However, Creative Commons international has made a very clear distinction between the license alternatives which are free and those which are \"non-free\".\nThe counter argument is one of freedom of choice, namely that individuals should have the freedom to choose among the different license alternatives, including those configurations that restrict the use of the resource in a way that the resource would not qualify as free content under the requirements of the free cultural works definition. Supporters of this view contend that the public is provided with unrestricted access to tools, information and tutorials on what each of the license alternatives mean. It is the resource owners' responsibility to use the materials to inform their decision as to which license to choose for their resource.\nTo avoid ambiguity, the two Creative Commons licenses which meet the requirements of the free cultural works definition are:\n- Attribution (CC BY)\n- Attribution share-alike (CC BY-SA)\nA Creative Commons license which contains either or both of the following restrictions does not meet the requirements of the free cultural works definition:\n- No derivative works (ND)\n- Non commercial (NC)\nThe right to earn a living?\nA topical debate in the OER arena relates to the question of the non-commercial (NC) restriction. The free cultural works definition does not permit the inclusion of the non-commercial restriction.\nMany supporters of the free culture cite the principles of free speech (Article 19) and the rights to just and favourable remuneration (Article 23) of the United Nations Universal Declaration of Human Rights as a reason not to exclude the rights to earn a living from OER. Other free learning proponents argue that the phenomena of conversion and enclosure warrant the inclusion of the non-commercial restriction (see for example Downes 2011). Conversion refers to the appropriation of free and open content and resources by commercial providers for commercial gain, while enclosure refers to the practice of using technological and other means to restrict access to the original no-cost alternative.\nThe OER Foundation holds the view that the share-alike provision combined with the requirement to store digital artifacts using open and free file formats is sufficient to legally protect OER from risks of commercial exploitation without compromising the rights of individuals to earn a living.\nDebating whether OER should permit commercial use\n- The Definition of Free Cultural Works provides a useful grid comparing different licenses for further reference.\n- Creative Commons\n- Reasons why not to use the NC restriction\n- Downes, S. 2011. The OER Debate, In Full. Retrieved 29 December 2011"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"}],"document_ids":["<urn:uuid:31d09f8b-eb9d-4be1-8219-333b825476bc>","<urn:uuid:8c2c4b3f-3a24-4c2e-854c-dea1474a45cf>"],"error":null}
{"question":"How is remission determined using the RAID score in rheumatoid arthritis?","answer":"Remission using the RAID score is determined by the following cut-off values: A RAID score of ≤3 indicates remission, >3 to ≤4 indicates low impact of disease, >4 to ≤6 indicates moderate impact of disease, and >6 indicates high impact of disease. Additionally, a Patient Acceptable Symptom State (PASS) is defined as a maximum score of 2.","context":["Objective To evaluate the responsiveness of the Rheumatoid Arthritis Impact of Disease (RAID) score compared with other patient-reported outcome measures (PROMs), inflammatory markers and clinical disease activity measures in patients with early rheumatoid arthritis (RA).\nMethods Disease-modifying antirheumatic drug–naïve patients with RA with short disease duration were included in the treat-to-target ARCTIC trial and followed for 24 months. The responsiveness of the RAID score was evaluated using standardised response mean (SRM) and relative efficiency (RE) with respect to tender joints by Ritchie Articular Index (RAI). SRMs and REs were also calculated for other PROMs, inflammatory markers and clinical outcome measures. An SRM with value above 0.80 was considered high.\nResults 230 patients with RA were included. The mean±SD symptom duration was 7.1±5.4 months and the baseline mean±SD RAID score was 4.49±2.14. At 3 months of follow-up, the mean±SD change score for RAID was −2.25±1.98 and the SRM (95% CI) −1.13 (−1.33 to −0.96). The RAID score showed high responsiveness both at 3 and 6 months (SRM≥0.80) and was more sensitive in detecting change than the reference, tender joints assessed by RAI.\nConclusions The RAID score proved to be highly responsive to change in patients with RA with short disease duration who followed a treat-to-target strategy. The RAID score was more efficient in detecting change than the reference (RAI) as well as most other PROMs.\n- disease activity\n- early rheumatoid arthritis\n- outcomes research\n- patient perspective\n- rheumatoid arthritis\nThis is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0\nStatistics from Altmetric.com\nWhat is known about this subject?\nResponsiveness is an important quality in patient-reported outcome measures.\nFurther validation of the responsiveness of the Rheumatoid Arthritis Impact of Disease (RAID) score has been suggested.\nWhat does this study add?\nThe RAID score showed high responsiveness to change compared with conventional disease activity measures and other patient-reported outcome measures.\nHow might this impact on clinical practice?\nThe RAID score should be considered for use in clinical rheumatoid arthritis trials.\nPatient-reported outcome measures (PROMs) provide valuable information about the impact of disease from a patient perspective and are considered as important as conventional disease activity and clinical outcome measures. They support patient-centred care and shared decision-making between patient and rheumatologist regarding treatment, in alignment with European League Against Rheumatism (EULAR) recommendations.1–3\nEfforts have been put into development and validation of rheumatoid arthritis (RA) PROMs in order to achieve valid outcomes.4–9 A prior EULAR initiative developed a patient-derived composite response index for RA for use in clinical trials, called the Rheumatoid Arthritis Impact of Disease (RAID) score.5 The RAID score includes the domains sleep disturbances, fatigue, coping and physical and emotional well-being, in addition to pain and physical disability, which are traditionally assessed. Further validation of the responsiveness of the RAID score has been suggested.6 10\nThe objective of this study was to assess the changes in the RAID score in patients with early RA within the first 6 months of intensive disease-modifying antirheumatic drug (DMARD) treatment, and to evaluate the responsiveness of RAID after 3 and 6 months, compared with other PROMs and conventional disease activity measures.\nPatients and study design\nThis study used data from the ARCTIC trial (ClinicalTrials.gov identifier: NCT01205854).11 All patients fulfilled the American College of Rheumatology (ACR)/EULAR classification criteria for RA, had symptom duration less than 2 years and were DMARD naïve. Patients were randomised 1:1 to a treat-to-target strategy with or without the use of ultrasound examination. All patients received treatment according to the same escalating DMARD treatment algorithm, in accordance with current EULAR treatment recommendations.2 11 Results from the ARCTIC trial showed no significant differences in clinical and radiographic outcomes between the two groups and both treatment groups were merged in the current analyses.\nPatients were assessed at 13 visits within 24 months. PROMs included the RAID score, the Patient-Reported Outcomes Measurement Information System 20-item Physical Function short form (PROMIS PF-20, range 20–100), the 36-item Short Form Health Survey (SF-36, 0–100) with calculations of physical and mental component summaries (PCS and MCS), fatigue Visual Analogue Scale (VAS, 0–100 mm) and joint pain VAS. Other assessments included swollen joint count (0–44), tender joint count (Ritchie Articular Index (RAI) with a graded (0–3) assessment of the tenderness of 26 joints (0–78)), erythrocyte sedimentation rate (ESR, mm/hour), C reactive protein (CRP, mg/L) and patient and physician global assessment of disease activity VAS. Disease Activity Score (DAS, 0–10) was also assessed, a four-variable composite score of 44-swollen joint count, RAI, ESR and patient global assessment.\nThe RAID score assesses the impact of disease on seven domains. Each RAID domain is measured on a simple numeric rating scale from 0 (best) to 10 (worst) and is assigned a weight in the sum score. Pain is weighted 21%, functional disability 16%, fatigue 15% and sleep disturbance, physical and emotional well-being as well as coping all 12%.5 6 An absolute and relative Minimal Clinically Important Improvement (MCII) of at least 3 points or more than 50% has been proposed, along with a Patient Acceptable Symptom State (PASS) of maximum 2.10 Suggested cut-off values for levels of impact of disease are RAID ≤3 (remission), RAID >3 and ≤4 (low impact of disease), RAID >4 and ≤6 (moderate impact of disease), and RAID >6 (high impact of disease).12\nTo evaluate the responsiveness of the different outcome measures, standardised response mean (SRM) was calculated as the ratio between the mean change score and the SD of the mean change score, expressed as at 3 and 6 months of follow-up.13 Bootstrapping techniques (5000 replications) were applied to calculate the 95% CI of the SRMs. The threshold values for effect size suggested by Jacob Cohen were used to interpret the magnitude of the SRM and values above 0.20, 0.50 and 0.80 represent small, moderate and large responsiveness, respectively.14 The relative efficiencies (REs) with SE were calculated with respect to tender joints (RAI) at 3 months from baseline. RE equals the square of the ratio between the SRM of the outcome and the SRM of RAI and is given by the formula .15 16 An RE >1 suggests that a measure is more efficient in detecting change than the RAI.15 Tender joints, in this case by RAI, is an outcome measure which reflects inflammation and disease activity and based on these capacities it was selected as anchor for the RE analyses.\nBaseline data were examined for floor effect, which can occur when more than 15% of the patients achieve the lowest possible score. The percentage of missing data was small and no imputation was performed.\nStatistical analyses were performed using IBM SPSS Statistics V.24 and R V.3.0.2.\nBaseline demographics, clinical characteristics and PROMs including the seven RAID domains from the 230 included patients are presented in table 1. At baseline, the mean±SD DAS and RAID scores were 3.46±1.17 and 4.49±2.14, respectively, indicating a moderate disease activity in this cohort. One patient (0.4%) reported a RAID score of 0 at baseline. No floor effect was identified.\nThe mean change scores and SRM values of the outcome measures after 3 and 6 months are shown in table 2. After 3 months, there was a marked treatment response in all measures, and the same tendency was observed at 6 months. The −1.95±1.09 points improvement in the DAS at 6 months led to a mean±SD DAS of 1.52±0.89, which indicates an average change from moderate disease activity to remission.11 17 The percentage of patients in DAS remission was 48 and 62 at 3 and 6 months of follow-up, equivalent of 99 and 131 patients, respectively.\nThe mean±SD change of the RAID score at 3 and 6 months was −2.25±1.98 and −2.39±1.98, respectively, which led to mean±SD scores of 2.28±1.84 and 2.08±1.78 at 3 and 6 months, respectively, which reflects that the group on average achieved a level of remission according to the suggested cut-off values. At 3 and 6 months, 34% and 40% of the patients had reached the suggested absolute MCII of 3 or more and 56% and 58% the relative MCII of 50% or more. Moreover, 53% and 56% of the patients reported a RAID score of 2 or less at 3 and 6 months, which is the suggested PASS.\nDAS, RAID, RAI, PROMIS PF-20, joint pain, SF-36 PCS, physician and patient global assessment and swollen joint count all showed high responsiveness to change (SRM ≥0.80). ESR and CRP showed moderate responsiveness to change (SRM >0.5) while fatigue VAS and SF-36 MCS showed low responsiveness (SRM <0.5) (table 2).\nThe RE in relation to tender joints (RAI) after 3 and 6 months are illustrated in figure 1. DAS, physician global assessment and swollen joint count showed the highest efficiencies in detecting change. After 6 months, the RE of the RAID score increased slightly, which led to a slightly better performance than patient global assessment and joint pain VAS. The least efficient outcomes were ESR, CRP, fatigue VAS and SF-36 MCS.\nOur study of patients with RA with short disease duration and followed by treat-to-target strategy found the RAID score to be highly responsive to change and efficient in detecting change compared with several other PROMs.\nAt 3 and 6 months, more than half of the patients reported a RAID score of 2 or less, which is the suggested PASS and also indicates remission as proposed by Salaffi et al.12 In comparison, 48% and 62% of the ARCTIC population achieved DAS remission at 3 and 6 months of follow-up.\nMore than half of the patients in the ARCTIC population achieved the suggested relative MCII of 50% or more after 3 months while a smaller proportion had an absolute improvement of 3 points or more. An absolute change of 3 points or more in an individual or a population with moderate disease activity level at baseline and short symptom duration, such as in the ARCTIC trial, might not be realistic to achieve.\nThe outcome with the highest relative sensitivity to change was DAS. Three of the DAS components, swollen joints, patient global assessment and joint pain, were highly responsive as single domains. The outcomes with the highest relative responsiveness all reflect physical aspects of the disease, whereas the RAID score includes emotional well-being and coping and still seems to show a high efficiency in detecting change.\nPatient global assessment (PGA) and RAID are both global patient-reported indexes and both measures are equally responsive to change, according to this study. PGA is already incorporated in the EULAR/ACR core set of outcome measures for RA. The question whether the RAID score could replace the patient global assessment has been raised.6 Some considerations in this regard would be that the PGA is less time consuming to perform compared with the RAID score. If a global assessment with no differentiation is satisfying, then the PGA should be sufficient. However, RAID provides more specific details about the impact of disease.\nThe data imply that the RAID score was more efficient in detecting change than the other multidimensional PROMs, SF-36 PCS and MCS and PROMIS physical function after 6 months. Compared with these outcomes, the RAID score separates itself in the sense that it incorporates the traditional health-related domains as well as sleep, fatigue, well-being and coping that patients with RA perceive as important.18–20 Furthermore, the RAID score distinguishes itself as a disease-specific outcome compared with the generic SF-36 and PROMIS physical function.\nFor an outcome to be able to detect treatment effect or any change over time, it needs to be responsive. There are a variety of statistical approaches to measuring responsiveness and there is no consensus yet about which approach is the best.16 21 22 Measuring the magnitude of change detected by an instrument is one approach and multiple effect size indices are applied for this purpose. There is some evidence to suggest that using the SD of the change score (SRM) rather than the SD of the baseline score (ES) is more informative because it includes the variety of the change scores,13 which is why we chose to use SRM and not ES. It was as well a factor that SRM had been used to measure the responsiveness in the finalisation and validation study of the RAID score and we wanted to be able to compare the results.\nIn conclusion, this early RA intervention study provides support for the responsiveness of the RAID score. According to the EULAR/ACR recommendations for reporting results in clinical trials, assessing changes is important.23 The changes in the RAID score corresponded well with the changes in the DAS with regard to the proportion of patients in remission after 6 months. The RAID score was more efficient in detecting change than the reference (RAI) as well as other PROMs. The RAID score is a highly responsive patient-reported composite index which, with the suggested cut-off values, MCII and PASS should be considered for intervention studies in patients with RA. Further research should assess the responsiveness to change of the RAID score regarding the performance in RA flares.\nThe authors wish to thank the patients for participating in this study and the ARCTIC investigators: Hallvard Fremstad, Tor Magne Madland, Åse Stavland Lexberg, Hilde Haukeland, Erik Rødevand, Christian Høili, Hilde Stray, Anne Lindter Noraas, Dag Magnar Soldal and Gunnstein Bakland. Parts of the work from this manuscript have been presented at the EULAR Congress 2018; Annals of the Rheumatic Diseases, volume 77, year 2018, page 1824.\nA-BA and EAH are shared last authors.\nContributors KH designed the current study, analysed and interpreted data, and wrote the report. JS analysed and interpreted data, and reviewed the manuscript. TKK designed the ARCTIC study, contributed to the current study design, interpreted data and reviewed the manuscript. A-BA and EAH designed the current study and the ARCTIC study, recruited and enrolled participants, collected, analysed and interpreted data, and reviewed the manuscript. All authors have approved the final draft and vouch for the accuracy and completeness of the data and analyses.\nFunding The ARCTIC study has received grants from the Norwegian Research Council, the South-East Health Region in Norway, the Norwegian Rheumatism Association and investigator-initiated research grants from AbbVie, Pfizer, MSD, Roche and UCB.\nCompeting interests KH: none. JS: none. TKK has received consultancy honorariums from AbbVie, Bristol-Myers Squibb, Celltrion, Epirus, Hospira, Merck-Serono, MSD, Orion Pharma, Pfizer, Roche and UCB. A-BA has received consultancy honorariums from UCB, AbbVie, Eli Lilly and Pfizer. EAH has received research funding from Pfizer, UCB, Roche, MSD and AbbVie for the submitted work; honorariums as a speaker from Pfizer, UCB, Roche and AbbVie; honorariums for development of educational material from Pfizer; and has sat on advisory boards for Pfizer, Eli Lilly and Celgene.\nPatient consent Not required.\nEthics approval REK Sør-Øst C.\nProvenance and peer review Not commissioned; externally peer reviewed.\nData sharing statement No additional data are available.\nIf you wish to reuse any or all of this article please use the link below which will take you to the Copyright Clearance Center’s RightsLink service. You will be able to get a quick price and instant permission to reuse the content in many different ways."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:448370d0-fa5a-440c-89ec-5bfdab8b933b>"],"error":null}
{"question":"What are AED usage rates and psychological impacts in cardiac arrest survivors?","answer":"Despite AEDs being proven safe and effective, they are only used by the public in approximately 4% of out-of-hospital cardiac arrests. This contrasts with the psychological impacts on survivors - particularly those who experience consciousness during cardiac arrest, who often show positive long-term transformational changes by two years post-event, including greater empathy, increased family involvement, and reduced fear of death compared to survivors without conscious experiences during the arrest.","context":["AWARE Study Abstract\nA number of recent studies have indicated that 10% of cardiac arrest survivors report memories and thought processes from their period of resuscitation. A small proportion of survivors have also described the ability to “see” and “hear” details of their cardiac arrest. Even though the significance and mechanisms that lead to these experiences are not fully understood, nevertheless their occurrence may have significant implications for establishing clinical markers1 of improved brain resuscitation, as well as long term psychological support of cardiac arrest survivors2. The occurrence of cognitive3 function during cardiac arrest also raises the possibility that patients may have received improved “cerebral resuscitation” leading to consciousness and the activity of the mind. Furthermore, the occurrence of such experiences in cardiac arrest survivors has also been shown to lead to long-term positive life enhancing effects.4\nThrough a variety of psychological5 and physiological tests as well as cerebral monitoring techniques6, we aim to conduct the first comprehensive study examining the relationship between the human mind, consciousness and brain during cardiac arrest. Specifically, we aim to study the relationship between consciousness and the quality of cerebral resuscitation (as measured through non-invasive monitoring of cerebral perfusion)6 and its outcome on neurological, emotional and cognitive morbidity7. Patients’ experiences and cognition will also be examined qualitatively immediately after their cardiac arrest as well as at regular intervals for a period of two years.\nThe tests of consciousness include the use of independent markers8 designed to objectively examine the validity of survivor’s claims of being able to “see” and “hear” during cardiac arrest as well as their underlying association with socio-cultural9 and cognitive parameters. We will also examine the relationship between cognitive function during cardiac arrest with clinical and physiological markers, the severity of cardiac arrest, as well as markers of the relative effectiveness of resuscitation. An understanding of the nature of human consciousness and mental processes during cardiac arrest and its relationship with brain perfusion may have significant implications for improving the acute management of cardiac arrest resuscitation as well as the long term psychological care of survivors.\n1. In other words these experiences may serve as indices (markers) for improved brain resuscitation meaning that those patients having had these experiences may have had better cardio-pulmonary resuscitation, leading to a better brain blood perfusion (hence more oxygen) during their cardiac arrest. For example, in one study comparing physiological parameters such as arterial oxygen and carbon dioxide levels during cardiac arrest, it was observed that patients with cognitive function had higher oxygen levels, possibly due to improved ventilation during resuscitation.\n2. It has been well demonstrated that the occurrence of cognitive states during cardiac arrest is associated with long term psychological benefits, hence the occurrence of these states could serve as a predictor for improved long term cognitive outcomes.\n3. Cognitive: refers to the mental processes of knowing, formulating judgments, reasoning, perceiving and being aware.\n4. Survivors who had experienced memories and consciousness during cardiac arrest have been observed to develop a positive transformational change in behavior by two years, as characterized by greater empathy and understanding for others, involvement in the family and less fear of death compared to cardiac arrest survivors without the experience (Parnia S, et al.; Resuscitation Feb 2001 48, 149-156).\n5. Psychological testing: for example testing for the occurrence of depression and anxiety.\n6. This can be done by using devices of cerebral oximetry. This device works by non-invasively transmitting and detecting harmless near infrared light through sensors that are placed on a patient's forehead. Just as with the commonly used pulse oximetry devices, which measure changes in the saturation of oxygen in peripheral blood, cerebral oximetry monitors changes in the saturation of oxygen within the cerebral cortex. This device thus has the potential to provide a real time indicator of cerebral oxygen levels and hence cerebral perfusion. To date there have only been limited studies of cerebral oximetry during cardiac arrest, which have indicated that this technique can provide a useful measure of cerebral oxygenation during cardiac arrest. Real time brain monitoring using cerebral oximetry may potentially provide an important and invaluable tool to guide physicians and nurses regarding the effectiveness of their resuscitation efforts as well as an independent clinical marker of improved mortality and outcomes.\n7. It is important to understand that lack of oxygen during a cardiac arrest may lead to irreversible brain damage (hypoxic brain injury), which often leads to cognitive and emotional impairments as characterised by short and long term memory disorders as well as depression and posttraumatic stress disorder (PTSD).\n8. The verification of memories relating to the resuscitation events or “veridical perception” includes the use of hidden objects that are normally not visible from a patient’s or their caregiver’s perspective unless viewed from a vantage point above. Typically these are images placed on a support hanging from the ceiling in a hospital ward, in a way that the images face upward, towards the ceiling. These objects will provide an independent objective marker of the claims of being able to “see” during cardiac arrest because they will only be visible by “someone” observing them from above.\n9. Association: the sociocultural background may influence what the patient claims to have “heard” or “seen”.","Bystander CPR is a critical link in the chain of survival. It has been shown to more than double a victim’s chance of surviving an out-of-hospital cardiac arrest (OHCA).1 Using an automated external defibrillator (AED) in addition to performing bystander CPR further improves the chances of survival.2 Yet, both bystander CPR and AEDs are not provided in a majority of OHCA events.1,2\nBecause time is so critical in cardiac arrest, immediate bystander action (calling 9-1-1, performing CPR, and early defibrillation) is the cornerstone of maximizing the effectiveness of subsequent EMS and hospital interventions and ultimately survival. This is especially true in rural and congested urban areas with prolonged response times.\nBystander CPR lengthens the duration of ventricular fibrillation (VF) and provides critical blood flow to the heart and brain during cardiac arrest.3 This improves the likelihood of shock success, return of spontaneous circulation (ROSC), survival, and the chance of a good functional outcome.3,4 The combination of quickly calling 9-1-1, immediately doing chest compressions and applying an AED as soon as possible works synergistically to increase survival. Each of the successive links in the chain of survival depends on the preceding links—the whole is greater than the sum of the parts.\nBecause of this, EMS (in fact, our entire healthcare system) has a vested interest in the delivery of care before the arrival of professional rescuers on scene. Everything EMS does to improve the readiness of lay rescuers (training, public awareness, 9-1-1 pre-arrival instruction, assistance locating AEDs, etc.) will pay heavy dividends in an increased survival rate in our communities.\nThere is wide and unacceptable variability in cardiac arrest outcomes between communities,5 which likely results from differences in implementation and performance of important interventions such as 9-1-1 pre-arrival CPR instructions, bystander CPR and early defibrillation. Continuously measuring these interventions and analyzing their impact is the only way to know specifically what needs improvement and whether a system is functioning as intended.\nCurrent registries exist to help communities measure their cardiac arrest incidence and outcomes. The CARES (Cardiac Arrest Registry to Enhance Survival; https://mycares.net) registry is a national data collection system for OHCA. This registry includes data collection on OHCA incidence and process of care, including bystander CPR, AED use and, recently added, data for 9-1-1 pre-arrival CPR instructions.\nThe need to take this a step further and systematically track data from 9-1-1 centers has come about due to the realization that the quality of telephone CPR instructions has a significant impact on survival. Details such as whether the cardiac arrest was correctly identified, whether CPR instructions were provided, how long into the 9-1-1 call before CPR was started, and what type of CPR was given can make the difference between life and death. There is growing interest in pre-arrival CPR metrics and the need to quantify this critical intervention. To illustrate the point: If the 9-1-1 system provides pre-arrival CPR instructions at eight minutes into a call, it will obviously have much less impact on survival than if the instructions were provided one minute into the call. And yet both callers received “pre-arrival CPR instructions.”\nThe state of Arizona and King County, Wash., have piloted a data collection tool and reporting system for suspected cardiac arrest dispatch calls, which is integrated into their OHCA registries and linked to EMS care, hospital care and patient outcomes. In Arizona, the 9-1-1 pre-arrival CPR program is part of the Save Hearts in Arizona Registry and Education (SHARE) Program, a collaboration between the Arizona Department of Health Services and the University of Arizona (see http://azdhs.gov/azshare/911/index.htm). The Arizona and King County, Wash., models have now been incorporated into CARES to help dispatch and EMS systems across the country.\nWhy You Need an AED Registry\nLike bystander CPR data, AED information is a critical component of an ongoing cardiac resuscitation system of care. When various data points along the continuum of care (bystander CPR, 9-1-1 data, AED placement/use, and outcomes) are integrated into a standardized registry, such as CARES, an entire system can be measured and improved over time.\nAED information needs to be integrated into registries in order to know where AEDs are placed, if they are checked for maintenance (pads, batteries), if potential users are trained on-site, when they are used, and the ultimate patient outcome. Event data should include the location of the arrest, who did CPR, what kind of CPR was performed, who applied the AED, and whether a shock was delivered. Detailed data after an AED is used should be made available to other healthcare providers such as emergency physicians and cardiologists.\nWhat follows is a closer examination of why you need an AED registry:\n• You can’t use them if you don’t know where they are: We know AEDs are extremely safe and effective.2 We also know they are only used by the public in approximately 4% of OHCAs.6 Knowing where AEDs are located and if they are being used is important information. For example, if AEDs are placed in a certain area of town but they aren’t being used in cardiac emergencies, likely more public education is needed. In contrast, if cardiac arrest is occurring more frequently in a certain location where few AEDs are available, then more attention should be given to acquiring and placing additional AEDs throughout that community.\n• You can’t use them if they’re not maintained: Just as an AED that is not found cannot save a life, neither will an AED that is not properly maintained. Maintenance includes making sure expired pads and batteries are replaced and software upgrades are installed. A Web-based AED registry can assist in ensuring the functionality of AEDs by sending maintenance reminders. Just as fire departments check fire extinguishers in a community, it makes sense that you need to have a system to ensure that all AEDs are maintained in a ready-to-use state.\n• You can’t use them if they’re not there:\nAnother reason for having an AED registry is the fact that the information can be useful in the submission of grants for the deployment of additional AEDs. To secure and receive either private foundation or government grants, a Public Access to Defibrillation (PAD) program needs accurate data—both utilization and patient outcome information. AED grants can come from both private foundations and government. An example of a private foundation offering grants is The Ramsey Social Justice Foundation (http://ramseyjusticefoundation.org\n), which has donated AEDs to communities participating in the SHARE Program in Arizona. An example of a government AED grant is the one offered through the U.S. Department of Health and Human Services’ Rural Health program.\nFinding AEDs with Social Software\nKeeping tabs on the locations of existing AEDs has been a challenge. There have been several large-scale efforts to locate AEDs within communities. One such program in Philadelphia used a crowdsourcing approach. In 2012, the MyHeartMap Challenge (www.med.upenn.edu/myheartmap\n) set up a competition and offered monetary awards for those submitting the most AED locations. Using a smartphone application, participants photographed and recorded GPS coordinates for AEDs they found throughout the city.\nAlso using mobile phone technology, the PulsePoint App (http://pulsepoint.org) takes locating AEDs one step further—tying the location of the AEDs directly to nearby cardiac arrest incidents through the community’s 9-1-1 system. The mobile app (iPhone and Android) sends real-time AED location information to those within a certain radius of a suspected cardiac arrest with the goal of increasing both bystander CPR and the use of the life-saving devices.\nPotential lay rescuers must normally witness an arrest to take action. PulsePoint seeks to improve the efficiency of both CPR-trained citizens and publicly available AEDs by making bystander rescuers aware of cardiac events occurring nearby so they can retrieve an AED and begin CPR while paramedics are making their way to the scene. No one is in a better position to make a difference in the first few minutes of an OHCA than a nearby CPR/AED-trained individual. PulsePoint has been successfully implemented in many U.S. cities.\nDisparity Issues: Location of Arrests\nThe location of a cardiac arrest has a significant influence on patient survival. Patients who arrest in public have a higher probability of having their arrest witnessed, receiving bystander CPR, and receiving defibrillation with an AED—all of which strongly increase the chance of survival.2\nNational data on bystander CPR and PAD programs have uncovered large and unacceptable disparities. For example, using the CARES registry, Sasson and colleagues found that in low-income black neighborhoods the odds of receiving bystander-initiated CPR was approximately 50% lower than in high-income non-black neighborhoods.7 Their study showed that both the racial composition and the median income of a neighborhood have a significant effect on the likelihood of receiving bystander CPR. Studies like this help identify where to concentrate public training and education efforts.\nIn Arizona, Dr. Sungwoo Moon (a visiting professor from Korea University) found OHCA victims in mainly Hispanic neighborhoods received bystander CPR less frequently and had worse neurologic outcomes than those in mainly white, non-Hispanic neighborhoods.8\nUsing Geographic Information System (GIS) technology and SHARE Program OHCA event data, Dr. Moon was also able to identify the areas where OHCAs occurred most frequently but where AEDs were lacking. This is a great example of how important it is to have both cardiac arrest event and AED location data.9\nA Variety of AED Registries\nAED registries can take different shapes. Most states require reporting of AED locations to local EMS and/or dispatch centers. However, it varies widely as to how agencies capture and actually use this information.\nArizona’s SHARE Program AED registry is voluntary; however, it fulfills the statutory requirement that AED owners enter into an agreement with a physician to oversee a PAD program. In the SHARE registry, medical direction is free of charge to those complying with the training and reporting requirements. The registry uses a Web-based data entry system.\nAED owners must keep their units functioning and registries can play an important role in helping to ensure that AEDs are always in a ready-to-use state. A Web-based AED registry can send general reminders to registrants or targeted reminders based on expiration dates entered into the system. Several companies offer subscription services to assist with this.\nThe Future of AEDs\nTracking AEDs that are placed in static locations is one thing; however, tracking the location of AEDs that are mobile, such as those used during high school athletic events, requires a higher level of sophistication. Also, many AEDs are moved from one “permanent” location to another. In the future, AEDs will include technology (perhaps GPS, WiFi, Bluetooth, or other methods) that will allow tracking in real time, thereby allowing more efficient monitoring of the units’ placement and readiness. This technology will likely be integrated into CAD systems in the future, aiding dispatchers in locating AEDs and relaying that information to callers, in an effort to increase AED use. And of course, more AED use and more bystander CPR will translate into more lives saved.\n1. Sasson C, Rogers MA, Dahl J, et al. Predictors of survival from out-of-hospital cardiac arrest: A systematic review and meta-analysis. Circ Cardiovasc Qual Outcomes. 2010;3:63–81.\n2. Hallstrom AP, Ornato JP, Weisfeldt M, et al. Public-access defibrillation and survival after out-of-hospital cardiac arrest. N Engl J Med. 2004;351:637–646.\n3. Eftestol T, Wik L, Sunde K, et al. Effects of cardiopulmonary resuscitation on predictors of ventricular fibrillation defibrillation success during out-of-hospital cardiac arrest. Circulation. 2004;110:10–15.\n4. Bobrow BJ, Spaite DW, Berg RA, et al. Chest compression-only cpr by lay rescuers and survival from out-of-hospital cardiac arrest. JAMA. 2010;304:1447-1454.\n5. Nichol G, Thomas E, Callaway CW, et al. Regional variation in out-of-hospital cardiac arrest incidence and outcome. JAMA. 2008;300:1423–1431.\n6. Weisfeldt ML, Sitlani CM, Ornato JP, et al. Survival after application of automatic external defibrillators before arrival of the emergency medical system: Evaluation in the resuscitation outcomes consortium population of 21 million. J Am Coll Cardiol. 2010;55:1713-–1720.\n7. Sasson C, Magid DJ, Chan P, et al. Association of neighborhood characteristics with bystander-initiated cpr. N Engl J Med. 2012;367:1607–1615.\n8. Moon S, Kortuem W, Kisakye M, et al. Disparities in Bystander CPR and Neurologic Outcomes from Cardiac Arrest According to Neighborhood Ethnicity Characteristics in Arizona. Poster presentation to the American Heart Association, Resuscitation Science Symposium, Scientific Sessions in Dallas, Texas. November 2013. Circulation; in press.\n9. Moon S, Kortuem W, Kisakye M, et al. Analysis of Out-of-Hospital Cardiac Arrest Location and Public Access Defibrillator Placement in Metro Phoenix, Arizona. Poster presentation to the American Heart Association, Resuscitation Science Symposium, Scientific Sessions in Dallas, Texas. November 2013. Circulation; in press."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:d63fff67-95e4-43a3-8816-c16a48a0adde>","<urn:uuid:a1d47dbc-12bf-484a-b2c1-905ed432158b>"],"error":null}
{"question":"Is the multi-stakeholder approach emphasized in the Global Governance Futures program similar to the collaboration principles outlined in the California Global Education Project?","answer":"Yes, both frameworks emphasize multi-stakeholder engagement but approach it differently. The GGF program demonstrates this through practical experience, bringing together professionals from diverse backgrounds (law, business, civil society, etc.) to create policy recommendations, showing how challenging but necessary it is to work with multiple stakeholders. The California framework similarly values collaboration but formalizes it through specific competencies like 'working with others,' 'finding common ground,' and 'utilizing community assets,' while emphasizing that global education requires partnership between educators, students, parents/guardians, and community partners.","context":["Shaping the Future with a Multi-Stakeholder Approach\nGlobal Governance Futures is a program under which 25 young professionals from five countries are asked to develop concrete policy recommendations for the effective and accountable governance of three issues that are likely to be of crucial importance in 10 years’ time. The Tokyo Foundation, in partnership with the Global Public Policy Institute of Germany, hosted the Tokyo round of the program in 2014–15. Masahiko Haraguchi, a PhD student at Columbia University, was one of five fellows from Japan and wrote the following report.\nWhy I Joined GGF 2025\nI joined the Global Governance Futures program because I expected that I could produce policy recommendations with talented young professionals. Therefore, before GGF 2025 began, I was hoping that creating policy proposals with young professionals from other countries would be an enjoyable experience. Because I was to participate in the working group on geoengineering, I prepared for the first meeting by reading relevant technical books to acquire the specialized, scientific knowledge that I thought I would need. Then, I traveled to Berlin for the first round believing that I was well prepared for the discussion based on natural science.\nHowever, it did not take long for me to discover that my expectations were way off the mark. Once discussions began, I found that participants were approaching the issue not just from the perspective of natural science but also from those of business, international law, and civil society. I had also expected our discussions to be friendly, since the fellows were interested in global governance, and therefore they were presumably adept at discussing in a friendly manner.\nThe debates, though, were heated; some fellows argued furiously, got upset, and left the room. The atmosphere was the complete opposite of what I had expected. Based on these initial observations, I became very anxious about our subsequent meetings over the coming year, and I was no longer sure how we could collaborate to make effective proposals for global governance.\nAnother reason why I joined the GGF program was that I wanted to learn whether I had overcome the challenges that I had previously encountered while participating in a similar multinational program called the Global Youth Exchange program. The GYE was organized by the Japanese Ministry of Foreign Affairs and invited youths from 30 countries around the world. Through the GYE program, the fellows produced actionable recommendations on global challenges, such as extreme poverty and justice in a globalizing world.\nBecause I realized from my GYE experience that I lacked debating skills, English proficiency, and technical expertise, I had decided to go study and work in the United States to cultivate these skills. Therefore, through GGF 2025, I wanted to know whether my capabilities had become sufficient enough to discuss global governance issues with professionals from around the world. Below, I would like to share my thoughts on the meaning of global governance and the skills required to discuss governance policy recommendations. I also share my views regarding what Japan should do to more actively engage in shaping the global order.\nGeoengineering Working Group\nI belonged to the working group that focused on geoengineering. (The other two groups focused on Internet governance and global arms control.) The group was so diverse: the team had a lawyer at the United Nations, a management consultant, a staff member at an environmental NGO, a public policy think tanker, and a researcher in geoengineering. We decided to focus on solar radiation management (SRM) and created two scenarios using a scenario planning method. Our final policy recommendations were: (1) The Intergovernmental Panel on Climate Change should produce a special report about SRM; (2) an SRM advisory body should be established within the United Nations; and (3) a negotiation process should be created under the UN Framework Convention on Climate Change.\nIn addition, our report discusses the possibility that geoengineering could create a moral hazard by discouraging current and future efforts to mitigate greenhouse gas emissions and adapt to climate change.\nBefore arriving at our conclusions, we faced many challenges. Debates were heated, and during the Tokyo round we literally discussed the issues from the morning to midnight. The main reason for the heated debate was the diverse backgrounds of the participating fellows. There was only one expert in geoengineering, and the other eight members had little in common. The scenario planning methodology enabled us to incorporate various stakeholders’ viewpoints, but it was a great challenge to pull all the views together into a coherent policy proposal.\nI now believe, however, that this challenging process was necessary to create an effective proposal for global governance. Global governance, after all, is precisely about working with multiple stakeholders from a variety of backgrounds, cultures, and interests to craft common rules and frameworks.\nThe Need for Toughness\nThe social gatherings after the official program played an important role in helping foster a deeper understanding among participants with diverse backgrounds. It was very important to reestablish friendly ties after our heated discussions with other fellows. Therefore, we needed to be physically tough to join these social gatherings after a full-day program.\nMental toughness was an important quality too. We needed to argue our point tenaciously and be ready to defend our positions when someone disagreed with us.\nWe needed intellectual toughness as well. We needed to not only argue passionately but also to explain our reasoning very logically so that even non-experts could understand. Coming from an engineering background, I also needed to acquaint myself with the viewpoints of business, international law, and civil society.\nJapan’s Involvement in Global Governance\nHow do policymakers and experts in each country perceive what global governance entails? During the GGF process, I realized that perception gaps exist between Japan and other countries. Policymakers in other countries tend to actively engage in designing “how global governance should be,” while those in Japan are inclined to think “what global governance will be.” I do not mean to attribute this to the Japanese government’s lack of international influence. Rather, this is an issue that anyone even slightly involved in global governance should address at the individual level.\nThrough my participation in GGF, I have come to think that physical, mental, and intellectual toughness, as well as the engagement of multiple stakeholders, are crucial to leading the discussion on designing global governance. Just taking the small step of involving many stakeholders could lead to improving global governance. As such, individuals play a large role in shaping the way the world is governed; relying only on politicians or bureaucrats will not solve our problems. Each individual must take steps to improve conditions around them, and the building up of small steps can lead to an overall improvement in global governance.\nBirth of a Policy Network\nThe GGF 2025 program has engendered a policy network among the fellows and collaborators. For example, thanks to a German fellow in the geoengineering working group, Stefan Schaefer, I was invited to join the Climate Engineering Conference in August 2014 in Berlin. I was consequently able to learn the latest developments in geoengineering at the meeting and to apply what I learned to the GGF discussions. I also got an opportunity to interact with Japanese geoengineering researchers. Because I am now studying in the United States, this was a valuable experience that familiarized me with the current status of geoengineering research in Japan. We even collaborated on writing up a symposium report.\nAfter the first GGF 2025 round in Berlin, I was at a loss as to how we could proceed to create proposals for global governance, as our discussion was so heated. Now that we have finished producing our policy recommendations after five sessions of GGF 2025, I would say that global governance is essentially a process of rule-making that involves a variety of stakeholders.\nWhat are the skills required to contribute creatively to global governance? Language proficiency, debating skills, and a certain amount of expert knowledge are of course necessary. But I now feel that these are not sufficient. Even more critical are such “cross-border” skills as the ability to overcome differences in culture, nationality, and areas of specialization; physical, mental, and intellectual toughness; and the ability to get a large pool of stakeholders involved.\nNow that GGF 2025 is finished, I may not be as actively involved in contributing to global governance in my daily work and research. However, the experience is still very much alive, tangibly providing me with precious ties to young professionals all over the world as well as the “guts” to take a step forward and try to make a difference. Preparations are now moving forward for GGF 2027. I wish it great success and hope that the next group of fellows will have as rewarding an experience as I did!","Global Competence Framework\npresented by the California Global Education Project\nGlobal Competence is the disposition and knowledge to understand and act on issues of global significance (CCSSO & Asia Society). Those issues are identified in the Sustainable Development Goals adopted by countries to end poverty, protect the planet, and ensure prosperity for all (United Nations). Globally competent individuals are life-long learners who understand these issues and have an appreciation for cultural differences, an ability to understand and consider multiple perspectives, use critical and comparative thinking skills as well as problem-solving abilities, and are comfortable with ambiguity and change (World Savvy).\nWhat is Global Competence?\nThe California Global Education Project (CGEP) has adopted the four domains, or capacities, for global competence presented by CCSSO & Asia Society (2011) to foster awareness and curiosity about how the world works, which is informed by disciplinary and interdisciplinary insights. CGEP agrees that globally competent students are able to:\nInvestigate the world beyond their immediate environment, framing significant problems and conducting well-crafted and age-appropriate research.\nRecognize perspectives, others’ and their own, articulating and explaining such perspectives thoughtfully and respectfully.\nCommunicate ideas effectively with diverse audiences, bridging geographic, linguistic, ideological, and cultural barriers.\nTake action to improve conditions, viewing themselves as players in the world and participating reflectively.\nHow can we develop Global Competence?\nCGEP identifies the following specific indicators, or competencies, within these four domains for educators, students, parents/guardians, and community partners to use for themselves and for instructional purposes in developing global competence.\nINVESTIGATE THE WORLD\nPose questions to better understand issues and perspectives\nIdentify and suspend assumptions and judgements\nRecognize the value of each person in a global community\nExplore the world with curiosity\nKeep an open mind\nEmpathize with others\nIdentify my personal perspectives and influences\nExamine the perspectives and influences of others\nConsider multiple perspectives and opinions\nAnalyze cultural influences, connections, and contexts\nShare ideas and context with diverse audiences\nActively listen to others\nEngage in civil discourse\nConsider the audience and communicate appropriately\nUse evidence and values to guide plans\nAssess options and consider the potential impact of planned actions\nApply creative thinking and solve problems\nCapitalize on available resources and partnerships\nPersist through challenges\nAct and reflect individually and collaboratively\nAct with respect for individual dignity, differences, and human rights\nContribute to a better world\nCombined with the Sustainable Development Goals, these global competence indicators guide the work of CGEP in supporting global education in PK-12 programs in California. The rationale and core philosophy described below provide the underpinnings for that work.\nWhy develop Global Competence?\nWhy focus our work with educators and students’ attention to the global competence indicators identified above? These are some of the reasons and positive outcomes for global competence at three levels – personal (self), community (family, local or regional, groups or organizations), and world (global):\nINVESTIGATE THE WORLD\nPersonal: ● motivate and inspire yourself ● understand yourself & others ● develop empathy ● remain curious ● be a life-long learner\nCommunity: ● relate to and participate in a community ● understand and learn from others’ experiences ● inspire community\nWorld: ● see commonalities and patterns among and across communities ● see yourself in the bigger picture and feel connected ● be informed and inspired ● learn how others address common human challenges and opportunities\nPersonal: ● be reflective ● value personal contributions ● practice agency ● engage yourself and others in civic responsibilities ● apply empathy\nCommunity: ● build understanding and connections in the community ● decipher the common good ● value the insights and experiences of others ● better understand your community ● develop awareness of how power dynamics influence narratives\nWorld: ● understand commonalities and differences among people and environments ● learn from others ● appreciate differing ideas, practices, lifestyles, and beliefs\nPersonal: ● identify and discuss important issues ● develop listening, speaking, reading, writing, and viewing skills ● form your thoughts and opinions, share with others, and reflect on feedback ● take risks ● develop and share your own understanding of the common good\nCommunity: ● bring attention to important issues with a purpose ● be inclusive and value the ideas of others ● practice civil discourse ● generate discussion about issues that affect the community\nWorld: ● promote progress ● engage in a global learning community ● help others solve problems and allow others to help you solve problems\nPersonal: ● transform your thoughts and opinions into action ● make your voice count ● practice empathy ● manage time and other resources ● use confidence, commitment, and authenticity to sustain your actions\nCommunity: ● work with others ● find common ground ● identify and utilize community assets ● acknowledge your privilege within the community ● persist in times of adversity ● develop creative solutions ● raise collective awareness for a greater impact\nWorld: ● interact with others as a global citizen ● work in unique circumstances, manage deadlines, collaborate with others, and produce results ● use your privilege in benefitting others ● move beyond your immediate communities ● contribute to a better world\nWhat drives this work?\nCGEP is an organization with a core philosophy for global education, which serves as a foundation for these global competence indicators. The following beliefs form a core philosophy and serve as the underpinnings of our work to develop global competence:\n1. Identity: An examination of self and one’s identities is critical in the ability to develop one’s own global competence. For students, this examination requires research and reflection about multiple facets of identity – racial, ethnic, gender, religious, socioeconomic, age, family, and other cultural factors. For educators, this examination helps to inform how global competence is framed and fostered in their students. In other words, educators must develop global competence themselves before and while supporting student development of global competence.\n2. Diversity: We value multicultural and multilingual societies and celebrate the benefits of living in a diverse community and world.\n3. Equity: Global education is for all students. Every student has important and valuable contributions to make in a global community as well as in a global studies program. Each student deserves the opportunities and the benefits of a global education. In our increasingly interconnected world, a global education is essential for people to navigate the world in which they live and have equal access to opportunities.\n4. Perspectives: Global issues are complex, interconnected, interdependent, and are informed and influenced by historical, geographic, political, cultural, and economic forces.\n5. Foundations: Understanding and appreciation of world history, geography, cultures, and belief systems provide a basis to developing global competence.\n6. Collaboration: California educators have an opportunity to empower their students to address local and global problems identified in the United Nations Sustainable Development Goals.\n7. Interdisciplinary: The work to foster global competencies in students is interdisciplinary and aligned with existing state frameworks, standards, and initiatives that guide our work and to which educators are accountable:\nHistory-Social Science Framework\nEnglish Language Arts/English Language Development Framework\nCalifornia Science Framework\nCommon Core State Standards for Mathematics\nCalifornia World Language Standards\nCalifornia Health Framework\nCalifornia Visual and Performing Arts Framework\nPartnership for 21st Century Framework\nA Blueprint for Environmental Literacy\nCareer Technical Education Standards\n8. Access: Fostering global competencies in students occurs across grades PK-12 and requires developmentally appropriate learning experiences.\n9. Engagement: Globally competent citizens are inspired to advocate for themselves, their communities, the common good, and a better world.\n10. Inclusion: Global education can occur in many courses and programs, and is not isolated to social studies, world languages, or special programs (e.g., International Baccalaureate). Travel abroad and language learning are important aspects of global education, but are not the goals or markers of global competence.\n11. Empowerment: Global education is intended to prepare students to become active citizens in an ever-changing world. It is not designed for students to feel guilt, sadness, sorrow, or helplessness about the conditions of others. While students should learn about their own identities and the cultures of others, global education is not simply a parade of food, festivals, and flags. In developing global competence, students consider cultures, values, and contexts while suspending assumptions and judgements. They ask questions and conduct research to better understand situations before communicating ideas and taking actions that are solution-oriented. Students realize that fundraising and giving items to others may provide temporary relief, but is rarely a long-term solution to a complex problem. While taking some actions may make people feel better in the short term, globally competent students realize that the best course of action to a complex problem is one that sheds light on issues in order to promote change and improve the conditions of people, plant and animal species, and the environment for the health of the planet.\n12. Action: Globally competent active citizens are aware of how power and justice play out in the actions they take. While students are taking action to advance their communities, they are listening closely to those most affected by whatever challenge they are aiming to help mitigate. Students are looking at themselves as actors, and considering their place in the process of taking action for sustained change. Globally competent students use a systems approach before taking action to ensure that unintended negative consequences are minimized. After taking action, students engage in an iterative process of reflection that prepares them to leverage their strengths as globally competent individuals to make sustained contributions to their local and global community over the course of their lifetime.\nHow can we monitor progress toward global competence?\nASCD has developed a Globally Competent Learning Continuum (2017) for educators to use as a tool for reflection and growth.\nThe California Global Education Network (2017) has developed benchmarks using the CGEP Global Competence Indicators for use with K-12 students. These benchmarks are intended to guide greater understanding of global competence among educators, parents, community partners, and students, and support the implementation of global education programs in K-12 classrooms, after-school programs, and informal education settings.\nWe recognize the value of these indicators and benchmarks as tools to engage parents, guardians, and business/community partners in building global citizenship together with educators. However, we want to hear how you are using them in your work and how we can support you to develop global citizens in your classroom, school, and district. Please share with us your questions, comments, ideas, and suggestions here.\nAs the work of CGEN and the California Subject Matter Projects (CSMP) continues, these indicators and benchmarks will be used in communications, forums, professional learning, and resource development for the benefit of K-12 global education in California. Stay connected to CGEN, CGEP, California World Language Project, and other CSMPs for forthcoming information and opportunities."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:99304f67-be65-4177-8d81-56b331d43b94>","<urn:uuid:c2896b8e-b063-4ee2-b5b5-74375d7d3ebc>"],"error":null}
{"question":"What are the unique properties of umbilical cord tissue as a stem cell source, and how does current regulation affect its therapeutic use in different countries?","answer":"Umbilical cord tissue is a rich source of mesenchymal stem cells (MSCs), particularly from Wharton's jelly. These MSCs can differentiate into various cell types including bone, cartilage, fat, skeletal muscle, cardiac muscle, neurons, and cells of the kidney, liver and pancreas. They possess anti-inflammatory, immune-modulating, antimicrobial, and anti-tumorigenic properties, and can target injury sites while recruiting local cells for repair. The cord blood also contains hematopoietic CD34+ stem cells and the protein TIMP-2, which improves memory and learning. Regarding regulation, the legal framework varies across countries. In the US, cultured stem cell products are considered drugs and are under FDA review, while adult stem cell therapy is permitted for certain conditions. In Europe, regulations differ by country - for instance, Germany heavily restricts embryonic stem cell research, while the UK allows it under proper licensing.","context":["Stem Cell Therapy\nWhile stem cell therapies may seem to have appeared overnight, they have been practiced for decades. The most recent developments in stem cell science have brought exciting new opportunities for improving patient outcomes – especially over the long term.\nWhat are stem cells?\nStem cells are primitive cells in our body serving as a reservoir, able to replenish itself and differentiate into a wide range of specialized cells, in order to replace damaged cells and regenerate tissue. They have innate intelligence, able to home in to injured areas, secrete bioactive molecules that exert local and systemic effects, reduce inflammation, and recruit local cells to assist in the healing process.\nEvery cell in our body can trace its origin to the ultimate stem cell – a fertilized egg. Each cell division moves the cells down a path to their final cell type such as cells of muscle, nerve, or liver. All along this journey cells make commitments that are typically irreversible. This implies that any tissue in our body may require stem cells for regeneration. Properly harnessed, stem cells have the potential to repair or reverse an incredibly broad range of conditions, such as musculoskeletal injuries, autoimmune diseases, wounds, and lung conditions.\nWhere are these stem cells?\nStem cells exist in varying forms in numerous places throughout the body, although with a tendency to decline in number and quality throughout our life cycle. Adult stem cells are most abundant in bone marrow, fat tissue, and blood; it is from these sources the body often recruits stem cells when they are needed. Bone marrow transplant has been a routine treatment for decades.\nStem cells are especially abundant at birth, in umbilical cord and placenta, which is why many parents choose to privately store umbilical cord blood/tissue when their babies are born. Membranes from placenta have been used to treat burns and other wounds for over a century.\nAdult Tissue as Stem Cell Source\nMore recently, stem cells from a patient’s own fat, bone marrow, and circulating blood have been used to treat a variety of common conditions. For example, in the case of joint problems that require replacement or repair of cartilage, concentrated and directed doses of one’s own stem cells have been shown to be more effective and long-lasting than widely practiced alternatives using PRP (platelet rich plasma) or cortisol injections.\nAcquiring stem cells from an adult’s blood requires many sessions and expensive processing, to harvest a useful number of therapeutic cells. Using bone marrow increases yield and requires only one session. Harvesting stem cells from fat has exciting applications and has shown efficacy for treating a variety of conditions.\nHowever, adult stem cells from a patient’s old body are as old and as diseased as the patient himself, thus affecting their therapeutic potential, leading to inconsistent treatment results.\nBirth Tissue as Stem Cell Source\nStem cells of birth tissue origin have another unique advantage: These cells are young and have been shown to be therapeutically more active. While we do not yet know all of the mechanisms by which stem cells promote healing, we do know that these cells produce cytokines and growth factors, and recruit local cells to perform work of repair and regeneration. When birth tissue stem cells are compared to adult stem cells, they demonstrate higher level of secretion of cytokines and growth factors, higher speed of differentiation, slower cellular aging, stronger anti-inflammatory effects, and higher number of future cell divisions before eventual cell death. Also, studies have shown that umbilical cord stem cells have greater neuroprotective and neurorestorative properties compared to adult bone marrow stem cells.\nYet, it may not simply be the cells that are exerting therapeutic benefits. Recent study out of Stanford University showed that umbilical cord blood contains an abundant supply of a valuable protein called TIMP-2, which has shown to improve memory and learning, through improving hippocampal function.\n1. Amniotic Membrane\nAmniotic membrane products have been rapidly advancing in quality and popularity in the last few years. They show greater long-term efficacy over PRP (platelet rich plasma) or cortisol injections. Using these products does not require matching, because while the chorionic (maternally facing) membrane presents HLA markers, the fetal-facing membrane (amnion) is immune-privileged and can be used in allogeneic applications (transplantation into a different individual).\n2. Umbilical Cord\nUmbilical cord tissue is a dense source of MSC’s, mainly from a gelatinous material surrounding the blood vessels of the cord, called Wharton’s jelly (WJ). MSC’s (mesenchymal stem cells) were shown to have the capacity to differentiate into bone, cartilage, fat, skeletal muscle, cardiac muscle, and even neurons, or cells of the kidney, liver and pancreas. MSC’s from umbilical cords are more primitive than MSC’s derived from more mature tissue sources, and have intermediate properties between embryonic and adult stem cells. They have anti-inflammatory, immune-modulating, antimicrobial and anti-tumorigenic properties, are able to home in to sites of injury, and send out signals to recruit local cells to participate in rescue and repair. MSC’s from WJ may also be particularly helpful in the treatment of neurodegenerative conditions.\nUmbilical cord blood contains hematopoietic CD34+ stem cells, which for decades have been used to treat the same panel of conditions for which bone marrow transplants were used for. Hematopoietic stem cells also help with angiogenesis (generating blood vessels) thus help ensure blood supply to the repaired tissue. There is also evidence, that a more naïve progenitor cell is present exclusively in cord blood. Recently, a valuable protein TIMP-2 was found to be abundant in the umbilical cord blood, and TIMP-2 was shown ng and hippocampal health.\nAdvantages of Birth Tissue-Derived Products\nAlthough autologous stem cell transplantation (using a person’s own stem cells) is currently the most utilized form of stem cell therapy, as it avoids the risk of graft vs. host immune response, this method has significant drawbacks in the aging and chronically ill populations. Besides requiring invasive procedures to harvest the cells, in the older and chronically ill population, both the number and quality of stem cells have declined, limiting their regenerative capabilities.\nEven among the young and healthy adult population, stem cells obtained from a person’s bone marrow or adipose tissue still produce less cytokines/growth factors, with lower anti-inflammatory potentials, lower rate of growth & differentiation, shorter telomeres (end sequences that protects the chromosomes), more rapid cellular aging, and less remaining generations of offsprings, when compared to the stem cells of birth tissue origin.","The term stem cell research gleans different reactions from people, both in the medical community and the wider public. Still an emerging science, stem cell research is shrouded by many myths and misconceptions. Here, we take on some of the most predominant myths to discuss the misconceptions and clarify the facts regarding this fast-growing branch of medicine.\nStem cell myths\nMyth #1: Stem cells only come from embryos.\nFACT: False. Stem cells exist in all bodies, from embryos to adults.\nEmbryonic stem cells come from the early embryo, and have the potential to produce all the specialized cells of the body. Because of this, they hold great promise for studying and potentially treating disease and injuries. Tissue or “adult” stem cells are found in the body throughout our lives. These cells maintain and repair many tissues in the body. Examples of these cells include blood stem cells, muscle stem cells, bone marrow stem cells, adipose tissue (fat) stem cells and skin stem cells. Some of these adult stem cells are used in established medical and aesthetic treatments.\nMyth #2: Induced pluripotent stem cells (iPSCs) eliminate the need for embryonic cells\nFACT: False. Research is needed on all types of cells because it is not clear which cells will be most useful for which types of application. For the foreseeable future, side-by-side research on both embryonic and induced pluripotent stem cells is needed. Global Stem Cell Group’s research and treatment products use no embryonic stem cells.\nMyth #3: Stem cell research leads to cloning humans.\nFACT: False. Most countries prohibit this type of cloning.\nIn most countries, even attempting to clone a human being is illegal. Some countries do allow something called “therapeutic cloning” for the purposes of studying a disease. In this procedure, scientists isolate embryonic stem cells from a cloned blastocyst (early stage embryo) but do not transfer the blastocyst into a womb. In therapeutic cloning, the blastocyst is not transferred to a womb. Instead, embryonic stem cells are isolated from the cloned blastocyst. These stem cells are genetically matched to the donor organism for studying genetic disease. For example, stem cells could be generated using the nuclear transfer process described above, with the donor adult cell coming from a patient with diabetes or Alzheimer’s. The stem cells could be studied in the laboratory to help researchers understand what goes wrong in diseases like these.\nTherapeutic cloning also could be used to generate cells that are genetically identical to a patient’s. A patient transplanted with these cells would not suffer the problems associated with transplant rejection. To date, no human embryonic stem cell lines have been derived using therapeutic cloning.\nMyth #4: Adult stem cells are only found in adults\nFACT: False. There are three different types of stem cells: embryonic stem cells, induced pluripotent stem cells and tissue specific stem cells. It’s the tissue stem cells that are often called “adult” stem cells, but these “adult” stem cells are found in people of all ages. (See myth #1).\nStem cell myths: research\nMyth #5: Embryonic stem cell research is banned in Europe.\nFACT: False. The laws vary across the EU.\nEU member states have diverging regulatory positions on human embryonic stem cell research. For instance, in Germany, the use of embryos for research is heavily restricted under the Embryo Protection Act (Embryonenschutzgesetz) of 1991, which makes the derivation\nof embryonic stem cell lines a criminal offense. But in the UK, embryonic stem cell research is allowed, subject to licensing from the Human Fertilization and Embryology Authority (HFEA). Click here for country by country overviews for more details. Under the previous two European Framework programs (FP6 and F7), as well as the current program, Horizon 2020, human embryonic stem cell research can be funded, provided that the work is permitted by law in the country where it is to take place.\nMyth #6: Stem cell research and treatment is against the law in the US.\nFACT: False. The FDA does not regulate the practice of medicine, but rather drugs and medical devices and which of these can be marketed in the US. Under federal law, cultured (grown) stem cell products are considered a drug, but are not illegal. Adult stem cells, however, are not cultured—they exist in our bodies throughout our organs, blood, skin, teeth, fat, bone marrow and other places.\nAdult stem cell therapy is currently used in the United States to treat conditions such as leukemia and other illnesses. Bone marrow consists of stem cells which have been transplanted for years in the US.\nGlobal Stem Cells Group offers stem cell treatments in countries where stem cell therapy is approved and regulated with no appreciable difference in safety record.. Stem cell therapy technology is still under review by the FDA.\nStem cell myths: therapies\nMyth #7: Bone marrow is the best source of stem cells.\nFACT: False. Bone marrow is just one source of stem cells. Bone marrow stem cells have been studied for decades, and have been used to treat certain types of cancer. A great deal of research has been dedicated to understanding this source of stem cells and their potential. Bone marrow contains a number of different kinds of stem cells, one of which is mesenchymal stem cells. However, mesanchymal stem cells can also be found in adipose (fat) tissue at nearly 2000 times the frequency of bone marrow.\nMesenchymal cells have the capability to become different types of tissues (blood vessels, muscle tissue, etc.) and are capable of communicating with other cells. In combination with other proteins, molecules and regenerative cells found in adipose tissue, they also have the ability to reduce inflammation, regenerate damaged tissue, and grow new blood vessels, a process known as angiogenesis. Stem cells from adipose tissue are more accessible and abundant. They can be processed immediately and reintroduced into the body right away.\nMyth #8: There is a risk of rejection with stem cell therapy.\nFACT: False. When a patient’s stem cells are derived from his or her own body (such as fat tissue), there is no risk of rejection. In fact, studies thus far have indicated no safety issues with fat-derived autologous (from self) stem cells. Since these stem cells come from your own body, the risk of rejection is eliminated."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:52859410-89fb-4430-8026-25d77fae5af2>","<urn:uuid:8e372956-10d0-48a9-a8db-25207b8beb96>"],"error":null}
{"question":"What roles do Caribbean medical professionals play in HIV response, and what neurological complications do they need to address?","answer":"Caribbean medical professionals, such as Dr. Nikkiah Forbes from the Bahamas, serve as directors of national HIV/AIDS programs and provide clinical care as infectious disease consultants. They must address AIDS Dementia Complex, a neurological disorder characterized by disabling cognitive impairment, motor dysfunction, and behavioral changes. This condition requires careful diagnosis through neurological examination, brain scans, and lumbar punctures, as it can be complicated by various factors including opportunistic infections, cerebral lymphoma, direct HIV effects, and drug treatment toxicity.","context":["Who are the PANCAP Champions for Change?Get to know the people behind the causes.\nPANCAP relaunched the Champions for Change initiative after an eleven-year hiatus. The two-day event was be held from Tuesday, September 12 to Wednesday, September 13 at the Guyana Marriott Hotel, Georgetown, Guyana. The keynote speaker was the Rt. Hon. Sir Charles Michael Dennis Byron, President of the Caribbean Court of Justice.\nBelow are profiles of each of the new Champions.\nSandra Marie Granger, First Lady of Guyana\nGuyana’s First Lady was recognized for outstanding leadership and championing of the ‘Every Caribbean Woman Every Caribbean Child’ Initiative and stellar work in improving the lives of children and women in Guyana.\nSandra Marie Granger is the First Lady of the Cooperative Republic of Guyana. Since becoming First Lady, she has immersed herself in activities aimed at improving the lives of the most vulnerable sectors of the Guyanese population. She is a member of the Caribbean Community (CARICOM) Forum of First Ladies and Spouses of Heads of Government, which focusses on reducing adolescent pregnancy, cervical cancer, mother-to-child transmission of HIV, and domestic violence in the Caribbean. She is a Champion of the Every Caribbean Woman Every Caribbean Child Initiative and the United Nations Food and Agriculture Organisation’s School Feeding Programme. She holds two Bachelor of Arts Degrees in English Literature and in Portuguese, respectively, from the University of Guyana.\nDr Allyson Leacock\nDr Allyson Leacock was recognized for leadership as Executive Director of LIVE UP: The Caribbean Media Alliance and championing the HIV response in the Caribbean.\nDr Allyson Leacock is the Executive Director of LIVE UP: The Caribbean Media Alliance. She has 34 years of experience in executive management and has been involved in all aspects of broadcast media for 40 years. For the past 10 years, Dr Leacock has led a coalition of 112 Media Houses in 24 Caribbean countries as part of the LIVE UP Campaign, training over 2000 Caribbean broadcasters. She is currently on the Executive Board of the Global Media AIDS Initiative (GMAI) and served 4 years as Chairman of the Global Steering Committee for the World AIDS Campaign. Her professional training includes both Masters and Ph.D. Degrees in Educational Technology from Concordia University, Canada.\nDr Arif Bulkan\nDr Arif Bulkan was recognised for leadership in advancing the University Rights Advocacy Project and creating a safe space for LGBT students at The University of the West Indies.\nDr Arif Bulkan is an attorney-at-law who formerly practiced law in Guyana as a prosecutor and then criminal defence lawyer. He has a PhD in Law from Osgoode Hall Law School in Toronto, Canada, and currently lectures constitutional law and human rights law in the Faculty of Law of the St Augustine Campus of The University of the West Indies. As a consultant for PANCAP, Arif Bulkan produced a National Assessment on laws and policies impacting on HIV and AIDS in Guyana. He is a co-founder of The University of the West Indies Rights Advocacy Project [U-RAP], which aims to promote human rights, equality and social justice in the Caribbean through litigation and advocacy. He was conferred with the Anthony N. Sabga Award for Public and Civic Contributions in 2017.\nCanon Garth Minott\nCanon Garth Minott was recognized for significant work and advocacy towards greater involvement of the faith community in national and regional HIV responses.\nCanon Garth Minott is the Canon of the Cathedral in the Diocese of Jamaica and the Cayman Islands, a member of the Religious Groups Steering Committee of the Jamaica Council of Churches and Chair of the board of directors of the Jamaica AIDS Support for Life and the Regional Faith Based Organisation Steering Committee to end AIDS by 2030. He lectures in the field of Practical Theology at the United Theological College of the West Indies, where he served as Deputy President for a two-year term. A graduate of the University of the West Indies and McGill University, Canon Minott has published articles in the Journal of Caribbean History, Groundings, and, the Journal for the Network of African Theological Institutions. His most recent publication was titled “Living by faith in challenging times: A Caribbean view on what it means to say ‘God will take care of us.” He is the recipient of the CIBC RBC Bank Unsung Hero Award for his work in the area of HIV and AIDS.\nDr Frank Anthony\nDr Frank Anthony was recognized for outstanding work in public health and demonstrated understanding of the critical role that parliamentarians can play in ending AIDS.\nDr Frank Anthony is a Member of Parliament and serves on the parliamentary management committee and the parliamentary standing committee on constitutional reform in Guyana. He has worked in the public health sector from 1993 to 2006 as a physician, epidemiologist and Executive Director of the Health Sector Development Unit, Ministry of Health, Guyana. Dr Anthony was the Minister of Culture, Youth and Sports a position he held from 2006 to 2015. He is currently in private medical practice. He is also an adjunct professor in epidemiology at the University of Guyana and a member of the Guyana Medical Council. Dr Anthony received has a Medical Degree from the Russian Peoples Friendship University and a Masters in Public Health from the Hebrew University, Israel.\nDwayne Gutzmer was recognised for leadership of the CARICOM Youth Ambassador Corps and youth advocacy.\nDwayne Gutzmer is the Chief Executive Officer of the Institute of Law & Economics (ILE) with direct responsibilities for the Business Entrepreneurial Empowerment Programme (BEEP) & the Urban Lab for Youth Innovation Projects. He has served as President of the Junior Chamber International, Jamaica and Dean of the CARICOM Youth Ambassador Programme. Dwayne is the co-author of the “Caribbean Youth Advocacy Guide, A Road to Development”. He holds a Bachelor of Science Degree in Computing and Information Technology from the University of Technology, Jamaica, and a Masters in Business Administration with special focus in Finance from the University of Wales, UK.\nJoel Simpson was recognised for advocacy work against sexual orientation discrimination in Guyana and regionally.\nJoel Simpson is the founder and Managing Director of the Society Against Sexual Orientation Discrimination (SASOD) in Guyana. He has served as the UNESCO Human Rights Researcher at the HIV Education Unit at the University of the West Indies (UWI) St. Augustine Campus in Trinidad and Human Rights Associate at the United Nations Development Programme (UNDP) country office in Guyana. He currently serves as the secretariat of the Caribbean Forum for Liberation of Genders and Sexualities (CariFLAGS). He holds a Bachelor of Laws Degree from the University of Guyana and is a Chevening scholar with a Master of Laws Degree in Human Rights Law from the University of Nottingham in the United Kingdom.\nKenita Placide was recognised for advocacy and work in the LGBT community nationally, regionally and globally.\nKenita Placide is a founding member and current Executive Director of the Eastern Caribbean Alliance for Diversity and Equality (ECADE). She is also the Caribbean Advisor for New York-based OutRight Action International. In 2009, she submitted the first written and oral presentation by United and Strong to Saint Lucia’s Constitution Reform Commission and followed with a submission to the Universal Periodic Review process at the United Nations in 2010. Kenita was instrumental in organising the first OECS regional security and human rights training for LGBT and sexual rights defenders in 2011 and a regional documentation training in 2013. She helped make history when United and Strong hosted an International Dialogue on Human Rights in 2012 with ARC International; the first of its kind in the Caribbean.\nLaura Tucker-Longsworth, MSN. RN. O.B.E.\nLaura Tucker-Longsworth was recognised for leadership in the HIV response and demonstrated understanding of the critical role that parliamentarians can play in ending AIDS.\nLaura Tucker-Longsworth is the speaker of the National Assembly of Belize and Chairperson of the National AIDS Commission. She is an entrepreneur and owner of Nursing & Healthcare Services (NHS) Consultants Ltd. She is the Chairperson of the Disciplinary Committee for the Nurses and Midwives Council of Belize. She is the co-author of the evidenced-based paper entitled Harmonizing Nursing Education: Theory and Practice. She holds a Master’s of Science Degree in nursing from the Marcella Niehoff School of Nursing, Loyola University Chicago. She was honoured with the Most Excellent Order of the British Empire (OBE) for her contribution to Nursing and Community Service.\nLucien Govaard was recognised for advocacy on LGBTI issues both nationally and regionally.\nLucien Govaard is the Chair of the Caribbean Forum for Liberation and Acceptance of Genders and Sexualities (CariFLAGS). He serves as the representative of this organization on the PANCAP Executive board, the Regional Coordinating Mechanism as well as other PANCAP sub-structures. As a Surinamese national, he is active in several local organizations in the fields of youth development, HIV and the wellbeing of elderly people and LGBTI+ community in particular. Advocate, youth leader and active member of the Caribbean community are some of the capacities in which he dedicates time and energy to the achievement of change. Lucien is a freelance consultant in health communication and youth development\nNicolette Fernandes was recognised for utilizing her platform as a sports personality for advocacy regionally and internationally.\nNicolette Fernandes is a professional squash player who represented Guyana. She won the only gold medal for Guyana at the 2006 Central American and Caribbean Games in Colombia. She was named Guyanese Sportswoman of the year for the year 2009 by the Guyanese National Sports Commission (NSC). She also appears in the WISPA 2010 calendar, which features the top WISPA squash players. She reached a career-high world ranking of World No. 19 in October 2013.\nDr Nigel Taylor\nDr Nigel Taylor was recognised for significant work and advocacy towards greater involvement of the faith community in national and regional HIV responses.\nDr Nigel Taylor is the Minister in Charge of the Calvary Evangelical Church. He holds Doctoral Degrees in the disciplines of Theology and Psychology. He is also the President of the Barbados Evangelical Association and former Vice President of the Evangelical Association of the Caribbean. He served as Chairman of the National HIV/AIDS Commission of Barbados and engaged the denominations in the country to get involved in the response to HIV and AIDS. Dr Taylor was also part of the Barbados Delegation to The UN General Assembly Special Session on Drugs (UNGASS) and a Barbados’ representative to the 2012 AIDS Conference in Washington.\nDr Nikkiah Forbes\nDr Nikkiah Forbes was recognised for contributions as an Infectious Disease and Clinical Care Physician and contributions to the response to ending AIDS.\nDr Nikkiah Forbes is the Director of the National HIV/AIDS and Infectious Disease Programme at the Bahamas Ministry of Health. She is a Consultant in Infectious Disease at the Princess Margaret Hospital and Doctors Hospital and an Associate Lecturer at The University of the West Indies, School of Clinical Medicine and Research (SCMR), Bahamas. She graduated with honours from The University of the West Indies in surgery and was the first recipient of the SCMR’s Cecil Bethel Award as the top graduate in her class in 2002. She is actively engaged in medical research and presents her work at national, regional and international scientific meetings including the Infectious Disease Society of America of which she is a member.\nHonourable Terrence Deyalsingh\nHonourable Terrence Deyalsingh was recognised for leadership as a member of parliament advocating for the end of AIDS.\nHonourable Terrence Deyalsingh is the Minister of Health and the Member of Parliament for St. Joseph, in the Republic of Trinidad & Tobago. Before his stint in politics, the Hon. Terrence Deyalsingh started his career as a lecturer in the Institute of Training and Development (INTAD). From 2003-2006 he was a member of the Cabinet -appointed Committee on Labour Market Reform and chaired the sub-committee on Labour Market Information, all of which derived from his passion for business management. Subsequently, Minister Deyalsingh entered the realm of politics, where he served as a Temporary Opposition Senator during the 10th Republican Parliament. He was appointed a Senator on November 2, 2010 and served until October 14, 2013, when he accepted the nomination to contest the St. Joseph constituency. During this tenure in the Parliament of Trinidad and Tobago, he has served on the Standing Orders Committee of the Senate, as well as on the Finance Committee.\nVolderine Hackett was recognised for advocacy and significant contributions to championing the HIV response in the Caribbean.\nVolderine Hackett is the Deputy Programme Manager within the Communications Unit at the CARICOM Secretariat. She is a Communications Specialist with more than eighteen years’ experience in the field of information and communications; half of which has been integrally linked to the Caribbean’s response to the HIV epidemic through PANCAP. She has served as Technical Coordinator of the Inaugural Champions for Change Conference on reducing HIV and AIDS stigma and discrimination. From 2004-2010, she spearheaded the operational aspects of Champions for Change. She has served as Head of Strategic Information and Communication within the PANCAP Coordinating Unit. In addition to a Masters in Communications from the University of Leicester, she holds a Bachelor of Science in Management and a Post-Graduate Diploma in International Relations from the University of Guyana.\nRev. Winston Mansingh\nRev. Winston Mansingh was recognised for significant work and advocacy towards greater involvement of the faith community in national and regional HIV responses.\nRev. Winston Mansingh is currently the Senior Pastor of The Poonah Open Bible Miracle Centre (POBMC). He is a graduate of the Community Bible Institute, Brooklyn, New York, Open Bible Institute of Theology Trinidad & Tobago as well as the Haggai Christian Leadership & World Missions Training Institute, Maui, Hawaii. He is the President of The Faith-Based Network of Trinidad and Tobago and an Internationally Certified Educator on HIV and AIDS.\nVanessa Uziely Rosario Brito\nVanessa Uziely Rosario Brito was recognised for advocacy in human rights and facilitation of key populations access to justice in the Dominican Republic and regionally.\nMs Brito joins 16 PANCAP Champions who received their awards from Hon. Nicolette Henry, Minister of Education (Guyana) and Dr Douglas Slater, Assistant Secretary-General, Human and Social Development, CARICOM Secretariat, during the opening ceremony on Tuesday, September 12. Ms Brito was presented with her award by UNAIDS and PANCAP Advisor, Dr Edward Greene who referred to her many interventions for vulnerable groups including women and children; the Lesbian, Gay, Bisexual and Transgender (LGBT) community and persons living with or affected by HIV and AIDS. She has a Law Degree from the Catholic University of Santo Domingo, Dominican Republic and a Masters in Corporate Law from the Antonio de Nebrija University, Madrid, Spain. She is the Chairperson of the COIN Board and co-researcher on French Legislation in the field of HIV and AIDS for the University Hospital Center (CHU), Pointe-a-Pitre, Guadalupe. She is a Defense Lawyer on human rights and access to justice of vulnerable groups at the Human Rights Observatory for Vulnerable Groups of the Dominican Republic (ODHGV). Ms Brito has studied best practices in holistic education on sexuality, sexual health and Human Rights at the Cuban National Center for Sexual Education (CENESEX). She is also the Chief Executive Officer and Founder of the Foundation for Savings, Loans and Multiple Services in Primary Health Care. She has defended the right of access by the public to government information as the officer responsible in the Office of the Free Access to Public Information (National Office of Public Defense, Dominican Republic). In addition to her full-time occupation as Operations Manager in the Center of Orientation and Holistic Research (COIN), she works as an independent legal consultant.\nPANCAP extends congratulations to all the new Champions and anticipates collaborating on issues related to protecting vulnerable groups and creating an enabling environment for access to prevention, care and treatment without the fear of stigma and discrimination.\nVisit the official Champions for Change web page here.","Individual differences |\nMethods | Statistics | Clinical | Educational | Industrial | Professional items | World psychology |\nAIDS dementia complex (ADC; also known as HIV dementia, HIV encephalopathy and HIV-associated dementia) has become a common neurological disorder associated with HIV infection and AIDS. It is is a metabolic encephalopathy induced by HIV infection and fueled by immune activation of brain macrophages and microglia. These cells are actively infected with HIV and secrete neurotoxins of both host and viral origin. The essential features of ADC are disabling cognitive impairment accompanied by motor dysfunction, speech problems and behavioural change. Cognitive impairment is characterised by mental slowness, trouble with memory and poor concentration. Motor symptoms include a loss of fine motor control leading to clumsiness, poor balance and tremors. Behavioural changes may include apathy, lethargy and diminished emotional responses and spontaneity. Histopathologically, it is identified by the infiltration of monocytes and macrophages into the central nervous system (CNS), gliosis, pallor of myelin sheaths, abnormalities of dendritic processes and neuronal apoptosis.\nADC typically occurs after years of HIV infection and is associated with low CD4+ T cell levels and high plasma viral loads. It is sometimes seen as the first sign of the onset of AIDS. Prevalence is between 10-20% in Western countries and has only been seen in 1-2% of India based infections. With the advent of highly active antiretroviral therapy (HAART), the frequency of ADC has declined in developed countries. HAART may not only prevent or delay the onset of ADC in people with HIV infection, it can also improve mental function in people who already have ADC.\nDementia only exists when neurocognitive impairment in the patient is severe enough to interfere markedly with day-to-day function. That is, the patient is typically unable to work and may not be able to take care of him or herself. Before this, the patient is said to have a mild neurocognitive disorder.\n- Marked acquired impairment of at least two ability domains of cognitive function (e.g. memory, attention): typically, the impairment is in multiple domains, especially in learning, information processing and concentration/attention. The cognitive impairment is ascertained by medical history, mental status examination or neuropsychological testing.\n- Cognitive impairments identified in 1. interfere markedly with day-to-day functioning.\n- Cognitive impairments identified in 1. are present for at least one month.\n- Cognitive impairments identified in 1. do not meet the criteria for delirium, or if delirium is present, dementia was diagnosed when delirium was not present.\n- No evidence of another, pre-existing aetiology that could explain the dementia (e.g. another CNS infection, CNS neoplasm, cerebrovascular disease, pre-existing neurological disease, severe substance abuse compatible with CNS disorder.\nWhile the progression of dysfunction is variable, it is regarded as a serious complication and, untreated, can progress to a fatal outcome. Diagnosis is made by neurologists who carefully rule out alternative diagnoses. This routinely requires a careful neurological examination, brain scans (MRI or CT scan) and a lumbar puncture to evaluate the cerebrospinal fluid. No single test is available to confirm the diagnosis, but the constellation of history, laboratory findings, and examination can reliably establish the diagnosis when performed by experienced clinicians. The amount of virus in the brain does not correlate well with the degree of dementia, suggesting that secondary mechanisms are also important in the manifestation of ADC.\nAIDS Dementia Complex (ADC) is not a true opportunistic infection. It is one of the few conditions caused directly by HIV itself. But it is not quite as simple as that because the central nervous system can be damaged by a number of other causes:\n- opportunistic infections - there are many\n- Primary cerebral lymphoma or metastasis of other AIDS-related cancers\n- direct effects of HIV in the brain\n- toxic effects of drug treatments\nMany researchers believe that HIV damages the vital brain cells, neurons, indirectly. According to one theory, HIV either infects or activates cells that nurture and maintain the brain, known as macrophages and microglia. These cells then produce toxins that can set off a series of reactions that instruct neurons to kill themselves. The infected macrophages and microglia also appear to produce additional factors chemokines and cytokines - that can affect neurons as well as other brain cells known as astrocytes. The affected astrocytes, which normally nurture and protect neurons, also may now end up harming neurons. Researchers hope that new drugs under investigation will interfere with the detrimental cycle and prevent neuron death.\nADC stage characteristicsEdit\n- Stage 0 (Normal) Normal Mental and Motor Function\n- Stage 0.5 (Subclinical) Minimal symptoms of cognitive or motor dysfunction characteristic of ADC, or mild signs (snout response, slowed extremity movements), but without impairment of work or capacity to perform activities of daily living (ADL). Gait and strength are normal.\n- Stage 1 (Mild) Evidence of functional intellectual or motor impairment characteristic of ADC, but able to perform all but the more demanding aspects of work or ADL. Can walk without assistance.\n- Stage 2 (Moderate) Cannot work or maintain the more demanding aspects of daily life, but able to perform basic activities of self care. Ambulatory, but may require a single prop.\n- Stage 3 (Severe) Major intellectual incapacity - cannot follow news or personal events, cannot sustain complex conversation, considerable slowing of all output. And/or motor disability - cannot walk unassisted, requiring walker or personal support, usually with slowing and clumsiness of arms as well.\n- Stage 4 (End Stage) Nearly vegetative. Intellectual and social comprehension and responses are at a rudimentary level. Nearly or absolutely mute. Paraparetic or paraplegic with double incontinence.\nReferences and notesEdit\n- ↑ 1.0 1.1 Gray, F., Adle-Biassette, H., Chrétien, F., Lorin de la Grandmaison, G., Force, G., Keohane, C. (2001). Neuropathology and neurodegeneration in human immunodeficiency virus infection. Pathogenesis of HIV-induced lesions of the brain, correlations with HIV-associated disorders and modifications according to treatments. Clin. Neuropathol. 20 (4): 146-155. PMID 11495003.\n- ↑ Adle-Biassette, H., Lévy, Y., Colombel, M., Poron, F., Natchev, S., Keohane, C. and Gray, F. (1995). Neuronal apoptosis in HIV infection in adults. Neuropathol. Appl. Neurobiol. 21 (3): 218-227. PMID 7477730.\n- ↑ Grant, I., Sacktor, H., and McArthur, J. (2005). \"HIV neurocognitive disorders\" H. E. Gendelman, I. Grant, I. Everall, S. A. Lipton, and S. Swindells. (ed.) The Neurology of AIDS, 2nd, 357-373, London, U.K.: Oxford University Press. ISBN 0-19-852610-5.\n- ↑ Satishchandra, P., Nalini, A., Gourie-Devi, M., Khanna, N., Santosh, V., Ravi, V., Desai, A., Chandramuki, A., Jayakumar, P. N., and Shankar, S. K. (2000). Profile of neurologic disorders associated with HIV/AIDS from Bangalore, south India (1989-96). Indian J. Med. Res. 11: 14-23. PMID 10793489.\n- ↑ Wadia, R. S., Pujari, S. N., Kothari, S., Udhar, M., Kulkarni, S., Bhagat, S., and Nanivadekar, A. (2001). Neurological manifestations of HIV disease. J. Assoc. Physicians India 49: 343-348. PMID 11291974.\n- ↑ Grant, I., Atkinson, J. (1995). \"Psychiatric aspects of acquired immune deficiency syndrome.\" Kaplan, H.I. and Sadock, B.J. (ed.) Comprehensive textbook of psychiatry, VI, (Vol.2, Sect. 29.2) 1644-1669, Baltimore, MD: Williams and Wilkins. ISBN 0-683-04532-6.\n- Price, R.W. (1998). AIDS Dementia Complex. University of California San Francisco. URL accessed on 2006-04-06.\nHIV/AIDS related topics\nHIV · AIDS · HIV structure and genome · HIV test · CDC Classification System for HIV Infection · HIV disease progression rates · HIV vaccine · WHO Disease Staging System for HIV Infection and Disease · AIDS dementia complex · Antiretroviral drug · Tuberculosis (coinfection)\nInternational AIDS Conference · International AIDS Society · World AIDS Day · Treatment Action Campaign · UNAIDS · PEPFAR · NAMES Project AIDS Memorial Quilt · HIV and AIDS misconceptions · List of HIV-positive people · People With AIDS Self-Empowerment Movement · HIV–positive fictional characters\n|AIDS pandemic in||\nSub-Saharan Africa (in South Africa • Uganda) · Asia (in China • India • Myanmar • Pakistan • Taiwan • Japan) · in Latin America (in Brazil) · Caribbean · Eastern Europe and Central Asia (in Russia) · Western Europe · United States · List of countries by HIV/AIDS adult prevalence rate\n|This page uses Creative Commons Licensed content from Wikipedia (view authors).|"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:ee65c1a2-d672-416a-a746-8444bcade8e3>","<urn:uuid:1445395c-cf41-409b-90ef-df413d437161>"],"error":null}
{"question":"How does meditation impact brain structure and emotional regulation, and how does Jonathan Finlayson's music incorporate both structured composition and emotional expression?","answer":"Meditation causes significant changes in brain structure, including increased folding of the cortex (gyrification), higher axon density, and increased myelin formation. It also impacts emotional regulation by decreasing activity in the amygdala (stress center) while increasing memory and cognitive abilities. Studies show meditation can decrease anxiety and depression, with changes visible in just eight weeks. As for musical structure and emotion, Finlayson's music is tightly composed with intersecting themes, drawing inspiration from counterpoint and Bach, while maintaining emotional depth. His compositions feature independent moving parts and careful attention to variation, as demonstrated in pieces like 'Ruy Lopez' which translates chess moves into musical conversation between instruments.","context":["Jonathan Finlayson: The Chess Player\nTrumpeter takes no prisoners on his highly anticipated debut\nAnyone who’s heard Steve Coleman and Five Elements in the past dozen years has come to grips with trumpeter Jonathan Finlayson, a player with studious poise and formidable chops. From Alternate Dimension Series I and Resistance Is Futile, his earliest Five Elements dates, to the sustained brilliance of Coleman’s 2013 Pi release, Functional Arrhythmias, Finlayson has proved indispensable to one of music’s most rhythmically demanding ensembles. In recent years he’s also been called upon for Steve Lehman’s quintet and octet, Tomas Fujiwara’s the Hook Up, Mary Halvorson’s quintet (now septet as well) and other influential units.\nBut with Moment and the Message (Pi), Finlayson, 31, has at last debuted as a leader. Sicilian Defense, his quintet, takes its name from a maneuver in chess. The track “Ruy Lopez,” also named for a chess opening, assigns rhythmic values to the game pieces and translates their movements into music. “It’s kind of a prototype,” Finlayson says. “The improvisation shows the conversation of the black and white pieces. So when [guitarist] Miles [Okazaki] starts and then I play, I’m playing the black pieces and he’s playing the white pieces. At the very end of the form we switch. Same thing for the piano and bass.”\nOkazaki, a colleague in Five Elements who shares Finlayson’s passion for chess, remarks, “Jonathan’s chess game has the same balance as his musical personality, in my opinion. When I play him I think everything is going well until I realize he has a subtle strategy that is ultimately crushing. When I hear playbacks from recordings and gigs with him, it’s kind of similar—things he did in the moment went through under the radar, but upon closer listening you realize he made some very slick moves.”\nTweaking instrumentation over the years, Finlayson arrived at his current lineup with\nOkazaki on guitar, David Virelles on piano, Keith Witty on upright bass and Damion Reid on drums. The music is tightly composed, grooving and supple, with intersecting themes and solos supported by counterpoint more often than by comping in the ordinary sense. “I think about counterpoint all the time because I hate things that move together,” Finlayson declares. “I like variation, I like things to be independent. I’m a huge fan of Bach. I remember the first time I recognized ‘imitation’ in a piece. I thought, ‘That’s how I want my music to move.’ The spirit of that is there at least, if not in such a strict format.”\nA native of Oakland, Calif., Finlayson arrived at a new school in fifth grade and showed zero interest in his required music classes. “A class or two went by and they were like, ‘Mr. Finlayson, you need to choose an instrument or we’re going to have to call your parents.’ I was like, ‘Oh my goodness. Music. Ugh.’ What was presented to me was the trumpet or the choir. Well, that’s a no-brainer. This instrument has three keys. I thought, ‘This is going to be easy. Look at this thing!’”\nNeedless to say he was wrong, and yet Finlayson found himself drawn in. He performed in a district-wide concert and met Ambrose Akinmusire, now a famed fellow trumpeter, who’d also go on to work with Steve Coleman. During a youth workshop with saxophonist Jessica Jones, the 13-year-old trumpet pals had a chance to observe a Coleman rehearsal up close. “We were sitting there, not having a clue what was going on,” Finlayson says. “No clue. None at all.”\nAt least one more youthful encounter with Coleman didn’t light a spark, but trumpet lessons with local veteran Robert Porter began to make all the difference. “Ambrose and I really got into acquiring vinyl through him,” Finlayson remembers. “Part of the education was looking for the vinyl, seeking it out, appreciating it and then learning about the music, the history.” Finlayson still shops for vinyl in thrift stores on the Upper West Side, near his home in Harlem. He arrived at our interview with a stack of Pierre Boulez LPs, a lucky haul.\nBy the time Coleman held a clinic at Berkeley High School in 2000, Finlayson and Akinmusire were ready. Coleman writes via e-mail: “I had gone there with [bassist] Anthony Tidd and [drummer] Dafnis Prieto. We asked if any students wanted to sit in, and Jonathan and Ambrose jumped up. I was impressed with their playing, considering their ages , and so I invited them over to my house to talk about music. … I’m looking for people who are serious and have the potential to make a contribution to this music. I’m also looking to learn from these people.”\nComing east to attend the New School in September 2000, Finlayson just as quickly left: He’d been hired by Coleman for a series of gigs at the Chicago World Music Festival. (He graduated from the New School in 2005.) “[Pianist] Vijay Iyer was my roommate in Chicago,” Finlayson says, “and he helped a lot with writing out melodies and so on. At that point everybody had things memorized, so there wasn’t a lot of [sheet] music going around. And if there was, Steve wasn’t going to give it to you. Chicago is also where I met [late tenor saxophonist] Von Freeman. I played with him, went to his session at the Apartment Lounge. That kind of set the tone for how things would be.”\nThese experiences have pushed Finlayson to seek a personal voice, informed by deep and wide-ranging interests. While “Ruy Lopez” is the only chess-related work on Moment and the Message, there’s a Phoenician theme running through “Tyre” and “Carthage,” a debt to Nabokov in “Lo Haze” (short for Dolores Haze in Lolita), an Iliad reference with “Scaean Gates” and even a Buckminster Fuller neologism (via Carlos Castaneda), “Tensegrity,” the beautiful acoustic guitar track.\nFor all its heated competitive lore, Okazaki describes chess as “a creative construction between two people,” and that ethos prevails in Finlayson’s band without doubt. But there’s also a whiff of battle: “It’s going to be a fight if you see [the Sicilian Defense] played,” Finlayson remarks. “I like that, because as black you are at a disadvantage when you play the game. You’re a tempo behind white, so you’re defending. The Sicilian is almost like, ‘I’m fighting right out the block. Instead of passively waiting to equalize, I’m fighting right now.’ I really like that attitude.”\nOriginally published in October 2013","A previous post in March 2012, Meditation and Neuroplasticity, outlined research about meditation causing changes in the brain, including new brain cells, axons, dendrites and synapses. These studies showed dramatic brain alterations for all of the major traditions of meditation. A brief summary of that previous research follows.\nThis post will look at the most recent studies that continue to show new effects of meditation on the brain, as well as new applications.\nSome of the information summarized in the previous post appeared in a recent review article in the journal Nature Neuroscience. This article additionally describes that severe stress causes increase in some of the regions of the amygdala, (emotional center related to fear) and decrease in regions of the hippocampus (memory and learning), and pre frontal cortex (decision-making). It notes that meditation counteracts these stress related brain changes. Meditation decreases anxiety and fear, and increases memory and cognitive abilities.\nThis Neuroscience review reported additionally that compassion meditation (summarized in previous post and below) increased gamma oscillations and synchrony, as well as increased activity in brain regions related to empathy. It also emphasized that changes in the brain from mindfulness meditation can occur in just eight weeks.\nThe article raised the question whether meditation research is complicated by the fact that changes in the brain could also be from daydreaming, and self-reflection. Daydreaming has been recently linked to creativity (see research and discussion below) and self-reflection might also cause brain changes. Social learning in children, including self-reflection, significantly helped academic achievement.\nBrief Summary of Previous Meditation Post\nThe previously described brain changes for three major types of meditation are:\nCompassion: In meditation emphasizing a focus on compassion and “loving-kindness” there was increased concentration. There was also increased activity in frontal brain regions (positive emotions and self control) and thalamus (filters sensory- motor signals), and a decrease in the parietal region (visual and spatial).\nMindfulness: Mindfulness meditation showed increased neurons and connections in right frontal cortex, (concentration), insula (emotions) and right parietal and temporal (sight and sound). It showed a decrease in amygdala (stress), and increase in hippocampus (memory)\nTranscendental: Transcendental meditation showed more activity in frontal and parietal (attention), and decrease in thalamus, (sensory) and basal ganglia (choosing actions). The brain waves showed increased coherence and more synchronous oscillations throughout the brain.\nDefault Network: In all types of meditation a very important finding was that the Default Mode Network (DMN) was changed, briefly in novice meditators and permanently in experienced meditators. The DMN is the part of the brain that operates with non-focused internal thought and daydreaming (memories, future planning, wondering, thinking about others). This new default network caused by meditation now included new brain centers (dorsal anterior cingulate and dorsolateral prefrontal cortex) and was associated with increased control of behavior and thought.\nBasically, meditation of all types increased focus and self-monitoring of thought and emotion.\nWide Range of New Research\nAs the research into meditation has expanded, there are new findings in brain connectivity, neuroplasticity (brain changes and brain region growth), multitasking, and emotional monitoring. Other research has focused on the specific uses of meditation in cancer, cardiovascular disease, depression, and war related stress.\nAs these new results are incorporated into brain science, a broad question arises about the relation of meditation, daydreaming, sleep, physical exercise and creativity. These are discussed below.\nGeneral Brain Changes with Meditation\nGyri in the cortex are the folded regions of the cortex that allow for increased complexity and increased connectivity of the neurons. A recent study showed that with all of the different meditation techniques there are increased folding of the cortex, that is, increased “gyrification.” Significantly, the longer people had practiced the various forms of meditation, the more this effect of increased cortical surface area was evident. This correlates with increase brain effectiveness.\nIncreased Axon Density and Myelin\nA study using advanced diffusion tensor fMRI showed that one month of Chinese mindfulness training, called IBMT (Integrative body-mind training) increased the density of axons, which means more ability to signal and more connectivity (see post on Connectivity). These changes in the neurons of the anterior cingulate, a center for focus, attention, concentration, and self-regulation, also included an increase in myelin (myelin surrounds mature neurons and increases the speed of transmission of the signal). The increase in axons occurred after two weeks, and the increased myelin in one month. In early development axons also develop first, followed later by myelin.\nThis study of Chinese mindfulness meditation also found decrease in stress, measured by hormones in the blood. Other findings included less anxiety, depression, anger and fatigue. There was an increase in blood flow for the cingulate cortex after five days of 20 minutes meditation. The subjects had lower heart rates, decreased skin conductance, decreased breathing rates with increased belly breathing.\nStudy groups of meditators and non-meditators were given questions with multiple answers (for example, “Name one of the seasons”), then one of the correct answers was flashed on a screen either in a way that could be seen consciously or for only 16 milliseconds, a rate that is too fast to be consciously seen. The meditation group was able to see the subliminal, unconscious, words better. Either they were aware of unconscious material or their concentration was better.\nNew research with mindfulness meditation shows an improved ability to multitask after the meditation session. The study included simultaneous work with emails, calendars, instant messaging, telephone and word-processing tools to perform common office tasks. They measured speed, accuracy and the extent of switching between tasks. The meditation group showed an ability to stay focused on a task longer with less distraction. They were able to concentrate better, and switch less. They also had decreased stress, increased memory and equal or better productivity\nMeditation and Disease\nMeditation has now been used to help treat a variety of medical problems. The recent studies include anxiety from cancer, cardiovascular risk in teens, and depression.\nAn analysis of 22 studies involving 1400 patients from Denmark showed that cancer patients had less anxiety and depression with mindfulness meditation. The result lasted at least six months after the study period.\nCardiovascular Risk in Teens\nIn a study of 62 black teens with high blood pressure, meditation showed positive effects on their heart. With fifteen minutes of transcendental meditation a day, their heart’s left ventricle became smaller (an enlarged heart is a sign of weakness with an extra workload from the higher blood pressure). The deep rest of the sympathetic nervous system during meditation lowered blood pressure and heart size.\nAnxiety and Depression\nA new study shows meditation has long-term effects on emotional stability, and decreased anxiety and depression. As in previous studies there was a change in the default network related to daydreaming and self-oriented thought with long-term meditators. This new study of experienced and novice meditators showed weaker synchronization between two regions of the medial prefrontal cortex – the dorsal (cognitive) and the ventral (emotion, self evaluation). This correlates with improvement in depression, because depressed people have hyper connectivity between these two areas. There was also a greater synchronization to the right parietal lobe, which is related to attention. Consequently, research seems to suggest that when meditation is practiced alongside regular trips to one of the many mental health facilities out there for mental health treatments, then the symptoms of anxiety and depression can be improved.\nPhysical Exercise, Meditation, Sleep, Daydreaming, and Creativity\nThe complex relationships between physical exercise, meditation, sleep, and creativity are not yet fully understood, but are intriguing. Physical exercise and meditation are both noted to increase brain regions and increase new learning. Sleep is noted to increase learning and memory as well as creativity. Meditation is also shown to increase creativity. Are these similar or different mechanisms?\nPrevious studies have shown that sleep during the time of slow waves stimulates increased memory for learned material. This learning could include athletic skills. When exposed to sound and odor cues during sleep the memory of specific locations was increased. Sleeping and dreaming are also correlated with increased creativity. Just recently a tune was played to musicians during slow wave sleep and this enhanced their ability to play the tune when they awoke.\nDaydreaming and the Wandering Mind\nDaydreaming is important because it allows us to imagine future events, to flesh out ideas, and to create.\nA recent study asked subjects to list as many uses as possible for everyday objects such as toothpicks, clothes hangers and bricks. One group then did an undemanding task that encouraged daydreaming. Other groups did focused work, or nothing. The daydreaming group did much better on the next round of creative questioning.\nOther studies show that when a person’s mind is wandering they perform better in creativity, association and insight tasks. These include imagination games, original thinking and invention. A recent study showed that people report a wandering mind 47 percent of the time.\nTop Athletes, Musicians and Managers\nIncreased brain coherence is noted in meditation, but is also demonstrated in elite managers, musicians and athletes.\nTo measure exceptional performances with high brain integration a variety of measures are used. One measure of brain performance is increased coherence of brain waves measured by EEG (see post on Brain Oscillations). This measures how different parts of the brain are in sync with each other and work together. Another EEG measure, that of alpha waves, is related to alertness. The third is a measure of how efficient and effective the brain operates.\nBy these measures high-level managers, as well as elite professional and amateur musicians showed much more brain integration than less qualified managers and musicians. The most recent study shows that elite athletes also have this high brain integration by the three measures. They also shared a cluster of subjective experienced often referred to as “peak experience,” which includes inner calm, effortlessness, extreme wakefulness, ease of functioning, absence of fear, and a sense of perfection. Some athletes and musicians refer to this feeling as a performance “high”.\nIt remains for future studies to relate this “peak experience” to meditation states\nIn Elderly Tai Chi Increases Brain Size, Improves Cognition\nTai Chi is a meditative physical exercise, which is less aerobic than other forms of exercise. Research has already shown that exercise increases brain growth factors to make new cells. Seniors who engaged in Tai Chi three times a week for eight months had increases in brain volume, and better memory and thinking. One of the control groups that used lively discussions instead of the Tai Chi, showed some increase in brain size but less cognitive improvement. The other control group with no intervention had brain shrinkage. Previous trials showed increases in brain with exercise (new brain cells for new learning), increase in memory, but not as much cognitive improvement.\nNeuroscience, Meditation, Yoga, and Performance in War\nJust as the great American Indian warrior Crazy Horse did many years ago, the new soldier is learning to concentrate his mind for battle using meditative techniques. Martial arts, such as Tai Chi, Karate, and Kung Fu, have always used meditative techniques for superior focus, balance, power and muscular coordination.\nYoga and meditation are now being used in the military to help soldiers become calmer and better decision-makers in order to avoid trauma. Meditation is used before mock training that attempts to simulate the chaos of war scenes. While most military research has been related to brain injury and post traumatic stress, new brain studies, including brain imaging and blood tests for stress markers before and after simulated combat, are being done at the Warfighter Performance Lab to determine stress affects decision-making. Meditation techniques including breathing exercises are being applied to help the soldiers regain a state where good decisions can be made.\nThe psychological terms used in these military studies include “resiliency”, “psychological hardiness” or “mental toughness”. The new training called Comprehensive Soldier Fitness program increasingly includes these emotional, and psychological elements. Most soldiers have signs of stress, but only 20% have great difficulty in dealing with it. Training in elite forces, like the SEALS, simulate severe states such as near drowning to see who can tolerate this very high level of stress.\nThe most elite group remaining after very grueling SEAL training shows more activation in the insula, an area related to self-awareness, pain and emotion. The insula also helps relieve stress with awareness.\nOne early study, called the Trojan Warrior Project, included 10 days of meditation, yoga, and martial arts. After these sessions, soldiers performed much better in biofeedback tests of muscular and neurological reactions to stress. They were also able to learn a foreign language faster, learn complex technical weapons systems better and were better marksman.\nCurrently, SEALs are using meditation in training, based upon neuroscience data of increased gray matter volume and better synapses in the pre frontal cortex. These brain changes lead to improved ability to have attention control triggers of the amygdala fear responses. The Mindfulness Based Stress Reduction program showed decreased stress, and improvement in concentration, memory, performance of complex tasks, and regaining focus after stress.\nAnother meditation study for eight weeks, using fMRI, blood markers and saliva markers, showed a better recovery from stress. After the study period soldier’s brains were more likely to resemble the brains of elite SEALS and Olympians.\nPrevious posts have focused on how attention, and suggestion, as well as meditation, change the brain. The recent understanding is that the brain is much more “plastic” or changeable than previously thought and will change in any way that we choose to exercise it.\nIn normal function any mental event creates rapid changes in neurons, including building and rebuilding very complex structures almost instantly. (see post).\nMeditation is a specific training that builds a “muscle” of mental concentration with increased memory, creativity and cognitive abilities. These new abilities include being able to control the effects of severe stress and include a variety of different subjective internal states.\nAs mechanisms of these changes are elucidated in the future, hopefully the details of subjective meditative states can be correlated with molecular changes in the brain."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:c16f5d2f-76ef-4105-be98-0d46463f5301>","<urn:uuid:425237aa-1a9b-43ba-8f34-1c263437e374>"],"error":null}
{"question":"Can you compare how rural tourism and regional tourism contribute to economic development?","answer":"Both rural tourism and regional tourism contribute to economic development in different ways. Rural tourism's economic benefits largely stay within the surrounding community, with a focus on local residents providing services and creating income through activities like farming, food production, and cultural experiences. It has evolved from mainly domestic, inexpensive family vacations to attracting international travelers with comfortable incomes. Regional tourism, on the other hand, serves as an important source of revenue for developing countries more broadly, enhancing employment opportunities and increasing government revenue. It acts as an important development tool that provides economic, social, and political development in the region, particularly helping to eliminate economic imbalances in rural or underdeveloped areas.","context":["In Bulgaria, the owners of Deshka House create a very welcoming atmosphere. Lubomir Popiordanov\nAn Interview with Klaus Ehrlich, General Secretary of EuroGites\nIs Rural Tourism the same as Agro-Tourism? Rural Tourism refers to all kinds of tourism services offered in rural areas, provided by local residents. The intention is that the economic benefits largely stay in the surrounding community. Agro-Tourism is part of this kind of vacationing, usually offered on a working farm (at least part-time farming). In all cases, the client may anticipate a personal welcome by his host family, an experience of a real countryside and rural culture, tasty home-made food featuring local products, and comfortable but not necessarily luxurious accommodations.\nFood at a country inn in northern Greece tastes as good as it looks. Guest Inn Greece\nWho is interested in taking a rural vacation today? Some years back, rural and agro-tourism vacations were clearly domestic, that is most people who took them were residents of the country itself. It focussed on inexpensive vacations for families with children, but this has changed considerably in the past decade.\nWith most of us now living in cities all over the world, there is a significant interest in searching out undisturbed nature, peaceful surroundings, good tasting fresh food, open-air activities, and genuine local cultures. People are taking short-breaks too or spending a few days in different villages or on different farms instead of staying in only one place for an entire vacation.\nA country experience in Neudegghof, Austria is delivered with gracious hospitality by the owners. Farm Holidays in Austria\nThere is an increasing international demand as well, mostly from experienced travellers with a comfortable income. This is already creating new and interesting tourist products based on the specific assets of each region and village. Older travellers now make up one-third of rural tourism clients, and with this market looking to increase, EuroGites is focusing more product development and member training on meeting the needs and interests of the mature traveller.\nCountry walking is inspiring while staying near Watermouth, Devon in the UK. FarmStayUK\nWhat kinds of activities can visitors do during a rural stay? The great advantage of rural accommodations over any other kind of tourist lodging is the personal contact between the client and his host, who knows all about the characteristics and possibilities in his region. This allows for activities and action almost “on the go”.\nVisitors may join in cultural day celebrations like this one in Lithuania. Lietuvos Kaimo Turizmo Asociacija\nVisitors cycle through Belgian villages like Mohiville. H. Roland\nMost frequently in demand are light sports (hiking, biking, horseback riding) or simply exploring the region by car, relaxing in the garden, at a pool, or sipping a wine on the terrace of a local bar. Health and wellness travel is another area that is developing in some regions, especially where there are natural hot springs. The visitor may also learn about local recipes, original food products, and may participate in cultural events such as local celebrations or festivities. While this list is common all over Europe, it is precisely the local variations that make rural tourism so attractive. Which country or region in Europe is the best organised for rural tourism? Rural tourism was traditionally based on domestic demand. As a result, very different concepts and approaches developed in parallel all over Europe, and only a few countries have so far made a serious attempt to present themselves specifically to the international market. At a national or regional level, strong organisations specializing in rural or agro-tourism exist in France, Germany, Austria, and the United Kingdom. Italy also has an excellent agro-tourism framework. The new EU member countries have made great efforts … good examples are Romania and Bulgaria with similar methods of making visitors welcome throughout the country, and Latvia where development has been strongly combined with a business understanding of the activity.\nA wheat festival celebration in Alba, Romania provides memorable photo opportunities. Cristian-Alexandru Catana\nWhat encounters are most memorable during a rural stay? Urban visitors spending more than just a week-end in some rural accommodation are sure to have a story to tell when they return home. This starts with tasting unknown food or often homemade drinks. But probably the most impressive experience is to see in reality where the food products, only known as packed units in the supermarket shelve, really originate: oranges or almonds on the trees, real cows and how they are milked, sheep with wool and how it is sheered or transformed into clothing, cheese or wine production, to name a few.\nA meal at Deshka House in Bulgaria is served family-style. Lubomir Popiordanov\nOther stories to tell will be based on cultural differences: time has another meaning in rural areas, mobile phone or internet access may not exist, personal conversation is still at the heart of human relations instead of electronic communication. And for sure, almost all visitors from urban background will be surprised by the open and heartily welcome they receive from anybody in the local village or at the farm.\nInterior of a countryside villa in Spain. Red Andaluza de Alojamientos Rurales\nArtemios Guest House on the Greek Island of Santorini. Guest Inn Greece\nEuroGites or European Federation of Rural Tourism, www.eurogites.org, is a professional organization representing 36 associations from 29 countries across geographical Europe and Israel. With an overall number of more than 100,000 establishments, it represents about 15% of European tourism overall. This ranges from the rural Bed & Breakfast and self-catering in private homes or farms to small family-run rural hotels and guesthouses.\nAs a professional organization, EuroGites participates actively in all discussions and structures within Europe that relate to tourism. It is also responsible for the European Congress on Rural Tourism, a bi-annual event first launched in 2003.\nCurrent member countries are Austria, Belarus, Belgium, Bosnia-Herzegovina, Bulgaria, Croatia, Cyprus, Czech Republic, Estonia, France, Georgia, Greece, Hungary, Italy, Israel, Latvia, Lithuania, Norway, Poland, Portugal, Romania, Russian Federation, Serbia, Slovakia, Slovenia, Spain, Switzerland, and United Kingdom.\nImage above: Can a farm stay in the Logar Valley of Slovenia’s Kamnik Alps get any more spectacular than this? Assn of Tourist Farms of Slovenia","What is regional tourism?\nRegional tourism is tourism concentrated in a region. … A regional tourist is a tourist visiting a region or province other than in which she/he has a normal residence but with a defined geographic region as a modification of the Wiki.com definition.\nWhat is Examples regional tourism?\nSome of the more famous tourism regions based on historical or current administrative regions include Tuscany in Italy and Yucatán in Mexico. Famous examples of regions created by a government or tourism bureau include the United Kingdom’s Lake District and California’s Wine Country in the United States.\nWhat is Regional Tourism Organization?\nRegional tourism organizations are independent, not-for-profit organizations, led by the tourism sector. They play an important role in supporting competitive and viable tourism regions. Each of these organizations provides coordination and provides the required regional leadership.\nWhy is regional tourism important?\nRegional tourism is becoming an important source of revenue for many developing countries. Through such tourism, countries can enhance their employment opportunities and increase their government revenue.\nWhat is regional level of tourism planning?\nRegional level planning is more specific than national level . and development tourism development areas. In some regions sub regional level or local level planning is required. This is more specific than regional level and it is also called as zonal level planning.\nWhat is the meaning of rural tourism?\nAny form of tourism that showcases the rural life, art, culture, and heritage at rural locations, thereby benefiting the local community economically and socially as well as enabling interaction between the tourists and the locals for a more enriching tourism experience can be termed as rural tourism.\nWhat are the role of national and regional tourism organization?\nNational Tourism Organisations (NTO) are responsible for marketing a country to tourists. … Regional Tourism Organisations (RTO) are responsible for marketing their own regions domestically and internationally and are also government funded bodies.\nWhat are the classification of tourism on the basis of region of tourism?\nThere are three basic forms of tourism: domestic tourism, inbound tourism, and outbound tourism.\nWhat are two types of tourist regions?\nTourist destinations can be classified to six main categories: urban destinations, seaside destinations, rural destinations, Alpine destinations, authentic third world, unique-exotic-exclusive destinations (Buhalis 2000).\nWhat is the difference between national and regional tourist boards?\nAs their titles suggest, the national board cares for tourist information within the entire country. On the other hand, the regional tourist board shares information about specific provinces, states, or regions within the country. It might include things like the climate, local attractions, and common customs.\nWhat are the 3 classification of tourism organization?\nThe types of travel and tourism organisations can be broadly separated into one of three categories: private, public and voluntary.\nWhat is an example of international tourism?\nInternational tourism is tourism that crosses national borders. … The World Tourism Organization defines tourists as people “traveling to and staying in places outside their usual environment for not more than one consecutive year for leisure, business and other purposes”.\nWhat is tourism and regional development?\nTourism is a sector with positive effects on regional development. It is an important development tool that provides economic, social and political development in the region. … Thus, development in a region of tourism in rural or underdeveloped areas, can help eliminate economic imbalances.\nWhat do u mean by regional development?\nRegional development. Regional development is the provision of aid and other assistance to regions which are less economically developed. Regional development may be domestic or international in nature.\nWhat are the various factors influencing the growth of tourism in a region?\nThe growth of tourism\n- leisure time – there has been an increase in the amount of paid leave days.\n- greater awareness – television travel programems have raised people’s expectations.\n- increased life expectancy – there are a greater number of older people travelling.\n- greater affluence – people have more spending money."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:29861085-d5fe-4ba7-acf6-27590258b045>","<urn:uuid:d7559860-951e-45d9-baa0-be75d9111ae8>"],"error":null}
{"question":"How did the Qin Dynasty and early Islamic calligraphers differ in their approach to using written text for political control?","answer":"The Qin Dynasty and early Islamic calligraphers had contrasting approaches to written text control. The Qin Dynasty, under Emperor Qin Shi Huang Di, enforced strict standardization through the Xiao Zhuan script and ordered the burning of all unauthorized texts to suppress philosophical diversity and maintain political control. In contrast, early Islamic calligraphy developed as an art form due to religious restrictions on pictorial representation, focusing on preserving and beautifying the Quran through various scripts like Kufic and Naskh, without evidence of political suppression of texts.","context":["In the beginnings of Islam, the Quran was mostly recorded in the memory of the Huffaz. After witnessing the unreliability of such a form of transmission, mostly because of the untimely death of many of those Huffaz in battle, it was decided to record it in written form.\nGiven the sacred nature of the word of Allah, the book would be made with great attention to quality and readability. Given Islam's taboo against pictural representation, however, drawings could not be used to enjolivate the book, as was done in the Christian world. Neither was it allowed to decorate mosques, for that matter. Thus, the art of calligraphy became very important in the Muslim world, and still today it is a major art; calligraphers are held in great esteem. The aesthetic of their art, which allows for the teaching of the Quran, is an unifying aspect of Islam.\nAfter the definitive fixing of the arabic script around 786, by Khalil ibn Ahmad al Farahidi, many styles were developped, both for the writing down of the Quran and other books, and for inscriptions on monuments as decoration.\nThe first of those to gain popularity was known as the Kufic script; it was angular, made of square and short vertical strokes, long horizontals, and bold, compacts circles. It would be the main script used to copy the Quran for three centuries; its static aspect made it fit for monumental inscriptions, too. It would develop many serifs, small decorations added to each character.\nMore often used for casual writing was the cursive Naskh script, with rounder letters and thin lines; with perfectionning of its writing techniques it would come to be preferred to Kufic for copying the Quran.\nDevelopped later, the Thuluth would take on from the 13th century the ornamental role devoted to the Kufic script. Thuluth meaning one third, it is based on the principle that one third of each letter slides downward. As such it has a strong cursive aspect and is usually written in ample curves.\nAs Islam extended farther east, it converted the Persians, who took to use arabic script for their own language; and they contributed to arabic calligraphy the Taliq and Nastaliq styles. The later is extremely cursive, with exageratedly long horizontal strokes; one of its particularities is that vertical strokes lean to the right rather than the more common left, making Nastaliq writing particularly well flowing.\nFinally the most commonly used script for everyday use is Riqa, simple and easy to write, its movements are small, without much amplitude. It is the one most commonly seen.\nThe traditional instrument of the Arabic calligrapher is the qalam, a pen made of dried reed; the ink is often in color, and chosen such that its intensity can vary greatly, so that the greater strokes of the compositions can be very dynamic in their effect.\nIndeed, Arabic calligraphy hasn't fallen out of use as in the western world; the\nArabic script, cursive by nature unlike the latin alphabet, is used to write down a verse of the Quran, a Hadith, or simply a proverb, in a spectacular composition that is often undecipherable. The composition is often abstract, but sometimes the writing is shaped into an actual form such as that of an animal. One of the current masters of the genre is Hassan Massoudy.\nWeb references and examples :\nhttp://www.arabiccalligraphy.com/resources.htm - examples of arabic scripts.\nhttp://perso.wanadoo.fr/hassan.massoudy/ - Modern calligraphies.","History of Chinese Calligraphy – The Origins of Calligraphy in Ancient China: The Unification of China and a Common Script in Qin Dynasty\nThe Qin Dynasty (秦朝/Qin Chao, Ch’in Ch’ao)\nIn 221 BCE, the state of Qin finally conquered the remaining states that had made up the Warring States and proclaimed the formation of a new dynasty under a centralized government. This essentially began the Imperial period of Chinese history, with the first Emperor Qin Shi Huang Di (秦始皇帝/Ch’in Shih Huang Di) effectively controlling the entirety of China.\nUnlike the Warring States or the Zhou that came before, the state was maintained not by a feudal system of lords, but by a more direct, and in many cases repressive, hierarchical system that fed directly back to the Imperial throne. China was for the first time unified under a single ruler who maintained direct control over almost every facet of society.\nInscriptions on Qin Stelae\nOne of the Emperor’s first official acts was the erection of stelae at important points throughout the China. A stele is essentially and inscribed stone monument. The Qin stelae were inscribed with politico-religious proclamations designed to cement the Emperor and the clan of Qin as the rightful rulers of all China. Although the Qin Emperor could clearly not be present in every corner of the Empire, claims of his legitimacy could be fixed permanently throughout his realm. Indeed, the written word had such force in early China that the simple acts of inscribing and installing these stelae were in and of themselves a cogent claim of legitimacy. Almost all Qin Stelae have been lost over time, and are available only as rubbings made in later dynasties.\nStandardization of Script and the Emergence of the Xiao Zhuan Calligraphy Script\nIn the Zhou and Warring States, textual variation was very common. Scribes in the various regions adopted different graphs for the same word, separated as they were by vast distances and, often, strict political border. The first Emperor knew that a single writing system would be needed if his unified empire was to be maintained. Imperial edicts and laws would need to be legible to officials in all corners of China. The result is what we now call Xiao Zhuan (小篆/Hsiao Chuan), or small seal script. For the first time, the entirety of China was provided with a single set of characters from which all written works were to be written.\nPolitical Control Through Words\nOf course, this tendency toward far greater standardization in the characters themselves was not without its dark side. The Warring States was a period of incredible philosophical and religious diversity, known for its Hundred Schools and the emergence of Taoism, Confucianism and Legalism. The emergence of technologies needed for the creation and maintenance of a considerable literary corpus allowed an incredible diversity of ideas to flourish within the independent states. The first Emperor believed that these texts could easily challenge the legitimacy of his reign. His own political, ritual, metaphysical and philosophical framework, based on Legalism could not be challenged. In order to quash dissent, Qin Shi Huang Di decreed that all written works not on a prescribed list be summarily burnt. It is only due to the concealment of many works, either by political dissidents or those lying in graves, as was the common practice, that archaeologists have been able to piece together the vast complexity of the literary tradition before the Imperial period."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:e5420646-af19-429c-9249-85ddbeb0c90c>","<urn:uuid:f9f3f422-724c-42fe-bc8f-c059866f0b2f>"],"error":null}
{"question":"Hi! Could you please explain the complete step-by-step process of winterizing a boat's engine and fuel system? I want to make sure I don't miss any critical steps.","answer":"The winterization process for a boat's engine and fuel system involves several key steps: First, run the engine and check the timing and basic motor operations. Then, drain the lower unit gear lube while it's still hot and refill with manufacturer's recommended lube. Next, preserve both the fuel tank and fuel by adding fuel stabilizer for the upcoming seasons. Inspect the steering, throttle, and shift cables for wear and binding, applying anti-corrosion grease. Inspect the water pump housing, holes, and impeller. Drain water from the block and use marine grade antifreeze to prevent freezing, rust, and corrosion. Drain oil from the motor, replace the marine oil filter, and refill with recommended oil. For 4-stroke engines, change the oil filter and refill with recommended 4-stroke oil. Replace the water separator filter, grease all steering cables, linkages and fittings with marine-grade grease. Finally, fog the engine block and cylinders, drain the fuel lines, and check all hoses, belts, and the general condition of the engine, drive, and lower unit.","context":["US Marine Services\nAlaska , Arizona\nCalifornia , Colorado , Connecticut\nIdaho , Illinois , Indiana , Iowa\nKansas , Kentucky, Louisiana\nMaine , Maryland , Massachusetts , Michigan , Minnesota , Mississippi , Missouri , Montana\n& Storage - Tools, materials and procedures\nWinterizing,teach you the professional methods for preparing a boat for winter storage\n- \"How to winterize\" your Boat\nWinterization Process is more than just taking care of the Favorite Boat it's very important maintenance, this process can be a scene once a year or multiple times(should be looked at as regular maintenance) per year and It depends\nhow you use the boat and your location. If the first time winterize your boat, set aside some extra time for the job.\nIf it is done professionally , very little work will be required\nto get the vessel really ready for the salt or fresh water in the\nExp. Proper winterization More Extends the boat and engine life by protecting its parts and components from bad corrosion, clogging or freezing, and lying idle for long winter time.But makes all the difference as to whether your vessel comes through the cold winter months & cold season fit as the proverbial fiddle or demands minor/major boat repairs in the spring.\nHow to Winterization. Winterization includes addressing the filters and oil,hoses and belts.\nGenerator blocks(they can be cracked due to winter icing ), valves and pistons, drive unit and engine, boat interior and exterior..or boat outboard exterior care & maintenance.\nIf you keep your vessel or boat on a lift, it too needs both to be ready for the\ncold season. Removing boat covers, greasing fittings and pulleys and repairing damage are all Important part of winterizing.\nI well remember- ensure that the boat's fuel tank is full! If NOT you run the risk of condensation (need to prevent condensation in the tank) forming within the boat tank which can lead to clogging and tank corrosion. In short, a lot can go wrong on a boat during cold weather - Hot water boat tanks can burst. Also Winterization Work is so Important.\nThe following aspects that we think is a helpful to boat winterization.\nSee Guide to winterization:\nAt first Run the engine and Check the timing and basic motor operations.\nThe Second Step is: inspect or Drain the lower unit gear lube and\nrefill(while the old is still hot) with it manufacturer's recommended lube-gear\nNext Step is to preserve both the fuel tank and the fuel with add.fuel stabilizer\nfor the upcoming seasons, winter and spring.Inspect the steering,throttle, and shift boat cables for wear and binding and apply anti-corrosion(anti rust lubricant) grease. Now Inspect the boat water pump housing,holes, and impeller,it\nif necessary More to see pressure-check and lower-unit seals, Drain water from the block and/or use a quality marine grade antifreeze, this are engeneered to prevent not only freezing, but also rust and corrosion, Drain oil from the boat motor, replace the marine oil filter, Racor ot other, and refill with recommended mfs. oil\nNote: On 4s troke engine models, change the oil filter and refill with recommended manufacturers 4 stroke oil.Replace water separator filter - Fuel/water separator filters should be checked often. Grease all steering cables,linkages and other fittings with grease - marine-grade and lnspect. Noe Fog the boat engine block,the cylinders, carburetors, and drain the the fuel lines, and Check all hoses, belts, and the general condition of\nthe engine, drive, and lower unit.\nwinterization - Fuel Tank and Stabilizer\nWhen fuel is being stored for a long period the chemical structure\ndown and fuel in Boat Tanks gets old and and be a problem to use - it will burn inconsistently and clog up the boat motor, But you have option:Use Fuel Stabilizer or treat the fuel with a fuel stabilizer , other option is to Removing the fuel, but Leaving a fuel tank empty might be a problem for winter storage! - Most people opt for treating the fuel. Removing the fuel would mean getting all the fuel out of the tank and lines to leave the fuel tank empty. Leaving a fuel tank empty might or might not be a problem(depending it is made from and the material type),\ncondensation built up inside can build up in the tank GeneRally you must Leave the fuel tank filled with fuel, but treated!\nIf you plan on leaving your vessel for longlength of winter time.\nWinterizing Boat Water Systems\nObviously, you must protect your boat water system require little\nmaintenance with some sort of anti freeze agent.If your Boat have\na portable water tank clean it with a bleach solution and best way\nis to put it away for the coldest season of the year.Boat Sinks-\nIf it's plumbed to a through hull and you are storing your boat\non land, You must be sure the drain line is empty and the seacock.If\nyour boat store in the water most important to add antifreeze-Agent\nto the drain line Water Systems and allow some antifreeze to drain\nthrough to ensure that the drain line\nRequire more work for complex boat water systems,practice is to drain the water tank,add several liters of antifreeze agent so that it replaces all the water that remains in this w.system.Pump out from the freshwater tank and add antifreeze.Starting pump with the one farthest from the tank and working your way back until it comes out of every outlet. Remember if you have one holding tank, tank must be pumped. After it's pumped, add antifreeze to the head, sure it gets through all the head hoses and don't skimp on antifreeze agent.\nSeveral non-toxic antifreeze products and brands are now available for winterizing your boat freshwater system. All winter time Leaving holding tank, even if there is antifreeze in it, that stuff sitting in isn't good idea.\nat last - Don't forget to put antifreeze in the hot water heater, AC cooling loop , shower and any sea strainers in Water Systems.\nWhether your boat is 10 or 80 feet,outboard or inboard, open or cabin-equipped, Winterize Projects is the perfect guide to keeping boat reliable safe, and running from season to season.\nWinterizing a Boat Before the Big Freeze\nExplaining how to Winterize a Boat during the fall break. Hopefully your million dollar boat will not look like this yacht caught in the freezing rain a few years back. Planning well ahead to winterize your boat and motor will save you a great deal of money, imagine having to winterize a frozen hard boat during a cold windy day of autumn.\nDepending on the size of your boat, you will either have a professional company take care of it, or you will want to save the money and do it yourself. The size of the boat would dictate your willingness to take care of such a project.\nTips on Winterizing your Boat\nPower wash Boat before Winterizing While it may look like a unwanted task to do at the end of a beautiful summer, winterizing your boat is the time to take care of those repairs you have been putting aside for so long.\nJust think of all those times you had the pleasure of going out on the water with friends or family and just have a really nice afternoon. Now looking back on those times, don't you how it to your boat a little love and attention? OK, enough with all that sentimental stuff, here is my way of getting the job done before winter comes around.\n1. A good scrub, from bow to stern, (here is a site for those of you that are still struggling with the boat terms) it is the perfect time to lift your boat out of the water and really give it a scrub, cleaning the barnacles, seaweed and other gunk that was stuck to the hull all summer long.\nHere are the products I use to clean and wax my boat: Star brite Instant Boat Hull Cleaner and Meguiar's Flagship Premium Marine Wax, just two outstanding products that really does a great job on the boats hull.\nStar brite Instant Boat Hull Cleaner-1 Gallon + Meguiar's Flagship\nPremium Marine Wax - 32 oz.Buy from Amazon.com.\nDiagnose or prevent moisture problems: How to Prevent Mold During Winter Storage, tips & advice."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:a6adfdcd-1987-459d-a71e-cb3b25a9e5ac>"],"error":null}
{"question":"How to test if water is hard at home?","answer":"There is a simple test you can perform: 1. Fill a clear, clean, empty bottle one-third full of tap water 2. Add a few drops of pure liquid soap 3. Tightly screw the cap on and shake vigorously for a few seconds. If there are few bubbles and the water appears cloudy, your water is hard. If there are many bubbles and the water below the bubbles is clear, the water is soft.","context":["Most Calgary residents are familiar with the white crystalline buildup in the showerhead and the kettle over time.\nThis is hard water buildup (sometimes called “limescale”) and it’s a natural consequence of the water here in Calgary.\nHard water is water with high mineral content. Most homes in Calgary receive their water from the Bow and Elbow Rivers to the west of the city.\nThis water is high in calcium and magnesium content, the water percolating through the limestone rocks before being treated and reaching our homes. So, hard water has always been part of life for Calgary residents.\nSoft water contains less than 75mg per litre of calcium carbonate\nMedium-hard water contains 75-150mg per litre\nHard water contains 150-300mg per litre\nVery hard water contains 300mg or more per litre\nMost homes in Calgary have hard to very hard water but it varies with location and season (the lowest levels are usually during the spring snowmelt season).\nThis mineral content builds up in taps, boilers, showers, dishwashers, washing machines, kettles, and other water-based appliances around the home.\nSome homeowners wait until the hard water has ruined a few appliances to do anything about it. Installing a softener will break down the mineral deposits and prevent your water from doing any damage in the future.\nHigh calcium and magnesium content in the water is not associated with any known adverse health effects but it can create other problems around the home: for instance, it can cause clothing to lose colour after washing and increase energy bills due to harder-working appliances.\nA good example is water heaters. They generally operate better with soft water as hard water can force water to run at higher temperatures. That means higher energy bills.\nIn summary, a water softener can help with the following:\nEnhance the efficiency of household appliances\nProtect your plumbing network from avoidable problems\nSave on soap/detergent\nReduce the damage to your favourite clothing when washing\nLeave your skin and hair feeling softer\nHow do you know if you have hard or soft water?\nIf you live in Calgary, assume that you have hard water in your home unless you have a softener installed.\nThere is a simple at-home test you can perform to test water hardness:\nFill a clear, clean, empty bottle one-third full of tap water\nAdd a few drops of pure liquid soap\nMake sure that the cap is tightly screwed on and shake it vigorously for a few seconds.\nIf there are few bubbles and the water appears cloudy, your water is hard\nIf there are many bubbles and the water below the bubbles is clear, the water is soft\nMore advanced tests may involve water test strips and a colour chart to help you identify the precise hardness of the water but for most Calgary homeowners it won’t be necessary.\nWhich type of water softener do you need?\nWater softeners use salts to break down the calcified deposits in pipes and appliances in your home and attack the problem before it even starts.\nSometimes called “descalers”, water softeners are either packaged or mechanical systems.\nWith packaged water softeners, softening materials called resins (baking soda or borax) are added to accessible areas or appliances to remove the calcium and magnesium buildup. You simply add them as required.\nMechanical water softeners are separate units installed in your home. They vary in cost but are mainly affordable and durable systems that work using ion-exchange, whereby the calcium and magnesium ions are replaced with sodium ions.\nSome systems can “partition” the water supply in your home, creating soft water in some parts of the home while allowing the water to remain hard in others.\nDoes a water softener affect drinking water?\nThe tap water in Calgary is safe to drink, as it is treated by the City.\nInstalling a water softener may add sodium content to the drinking water supply but this is generally a tiny amount that will not cause any negative impact on your health. The sodium content of many foods and beverages is far higher.\nThose on a low-sodium diet may prefer to avoid softened water but, for everyone else, the water is perfectly safe to drink.\nCan you install a water softener with a septic system?\nA properly installed, high-quality water softener will not adversely affect the performance of the septic system in your home.\nA small amount of sodium-rich wastewater may be discharged into your septic tank by the water softening system but this is not disruptive to the performance of either system.\nThe key is to choose a high-quality system and get it professionally installed.\nSix signs you need a water softener\nLet’s finish up by summarizing the signs that you need a water softener in your home:\nScale buildup in your appliances\nFrequent plumbing problems\nClimbing energy (and water) bills – for no apparent reason\nDryness of the skin and hair\nStains on sinks and bathtubs\nFaded clothing after washing\nInstalling a water softener should solve these problems. It should extend the life of your appliances and plumbing pipes, as well as your favourite clothing. It may even reduce energy bills as fixtures work more efficiently when limescale is removed.\nThere is a small initial investment but it will save you in the long run."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"}],"document_ids":["<urn:uuid:4a7eda2c-3d53-4c9a-8989-a346ab78785c>"],"error":null}
{"question":"How do Chef and AWS Cloud Control API differ in their approach to cloud resource automation?","answer":"Chef focuses on configuration management through cookbooks and requires client installation for managing cloud services like Azure and AWS OpsWorks, while AWS Cloud Control API provides a more direct, standardized set of CRUDL operations for managing cloud infrastructure. AWS Cloud Control API offers immediate access to new AWS features typically on launch day and supports third-party resource management, whereas Chef requires specific cookbook implementations and separate setups for different cloud providers.","context":["With this course, students will learn how to deploy, configure, and administer Platform as a Service (PaaS) and Infrastructure as a Service (IaaS) solutions as well as manage security and compliance in cloud solutions. Students will also be able to execute a phased cloud migration and explore virtual machines.\n- Describe cloud operations.\n- Plan cloud services Implementation.\n- Deploy a cloud application with Digital Ocean.\n- Deploy a cloud application with Heroku.\n- Deploy websites with Microsoft Azure.\n- Implement Azure Cloud Services and virtual machines.\n- Manage Azure applications with Visual Studio.\n- Deploy applications to Opscode Chef.\n- Manage server state with Puppet.\n- Implement Rackspace Cloud Servers.\n- Import and export data from cloud services.\n- Manage security and compliance in cloud solutions.\n- Plan and execute a phased cloud migration.\nLesson 1: Overview of Cloud Operations\n- Topic A: Overview of Cloud Computing Technologies and Roles\n- Topic B: IT Administration Requirements for Cloud Services\n- Topic C: Business Requirements for Cloud Service Administration\nLesson 2: Planning Cloud Service Implementation\n- Topic A: Determine Hardware, Software, and Network Requirements\n- Topic B: Assess Risks of a Cloud Deployment\n- Topic C: Coordinate with End Users and Business Stakeholders\n- Topic D: Plan Automation and Configuration Management\n- Topic E: Determine Cloud Service Support Resources\nLesson 3: Deploying a Cloud Application with DigitalOcean\n- Topic A: Determine Cloud Application Implementation Requirements\n- Topic B: Deploy a Droplet on DigitalOcean\nLesson 4: Deploying a Cloud Application with Heroku\n- Topic A: Identify Cloud Application Features of Heroku\n- Topic B: Deploy a Heroku App\n- Topic C: Scale and Update Applications on Heroku\n- Topic D: Secure Heroku Applications with Git Bash\nLesson 5: Deploying Websites and Apps with Microsoft Azure\n- Topic A: Overview of Microsoft Azure\n- Topic B: Deploy Websites and Apps in Microsoft Azure\n- Topic C: Manage Data and Storage in Microsoft Azure\nLesson 6: Implementing Azure Cloud Services and Virtual Machines\n- Topic A: Implement Azure Cloud Services\n- Topic B: Implement Azure Virtual Machines\n- Topic C: Manage Microsoft Azure Cloud Services\nLesson 7: Managing Azure Applications with Visual Studio\n- Topic A: Publish Applications to Azure with Visual Studio\n- Topic B: Migrate .NET Applications to Azure with Visual Studio\nLesson 8: Introduction to AWS\n- Topic A: AWS Components\n- Topic B: AWS Deployment\nLesson 9: Deploying Applications to Opscode Chef\n- Topic A: Overview of Opscode Chef\n- Topic B: Install the Chef Client\n- Topic C: Implement Chef Cookbooks\nLesson 10: Managing Cloud Services with Chef\n- Topic A: Manage Azure Services with Chef\n- Topic B: Manage AWS with OpsWorks\nLesson 11: Introduction to Puppet\n- Topic A: Determine How Puppet Can Streamline Cloud Management\n- Topic B: Explore Components of Puppet\nLesson 12: Implementing Rackspace Cloud Servers\n- Topic A: Overview of OpenStack\n- Topic B: Overview of Rackspace Cloud Services\n- Topic C: Deploy a Rackspace Cloud Server\n- Topic D: Manage QoS\nLesson 13: Importing and Exporting Data from Cloud Services\n- Topic A: Determine Requirements for Cloud Data Import and Export\n- Topic B: Import Data to and Export Data from a Cloud Network\n- Lesson 14: Managing Security and Compliance in Cloud Solutions\n- Topic A: Secure Cloud Solutions\n- Topic B: Manage Compliance for Cloud Solutions\nLesson 14: Planning and Executing a Phased Cloud Migration\n- Topic A: Plan a Phased Migration\n- Topic B: Execute Phase 1: Cloud Assessment\n- Topic C: Execute Phase 2: Deploy a Proof of Concept\n- Topic D: Execute Phase 3: Data Migration\n- Topic E: Execute Phase 4: Application Migration\n- Topic F: Execute Phase 5: Implement Cloud Features\n- Topic G: Execute Phase 6: Optimize Cloud Implementations\n- Designed for system administrators or cloud technologists who need to develop their skills on evaluation, deployment, and administration of cloud services. This includes evaluating and selecting Platform as a Service (PaaS) solutions and deployment applications to the cloud, as well as maintain, securing and optimizing cloud solutions to achieve the best Total Cost of Ownership (TCO) and Return on Investment (ROI)\n- Basic network and server administration, as well as a strong understanding of cloud Technologies. Besides, the student should be familiar with evaluating, selecting and implementing Software as Service (SaaS) solutions. This type of knowledge can be obtained by taking the NCTA Cloud Technologies.","AWS Cloud Control APIs give developers the ability to use a set of standardized CRUDL APIs to manage services in an intuitive and descriptive way.\nAWS Cloud Control API gives developers standardized APIs that work with AWS and third-party cloud resources listed in the AWS CloudFormation Public Registry.\nAWS Cloud Control API provides partners with the ability to programmatically expose new AWS features and services, typically on the day they launch.\nHow it works\nAWS Cloud Control API is a set of common application programming interfaces (APIs) that make it easy for developers and partners to manage the lifecycle of AWS and third-party services. Cloud Control API provides five operations for developers to create, read, update, delete, and list (CRUDL) their cloud infrastructure.\nCreate, read, update, delete, and list AWS and third-party resources\nAWS Cloud Control API makes it easy for developers to consistently manage hundreds of AWS resources as well as third-party resources using standardized APIs. As an example, you can use Cloud Control API to create any supported cloud resource using a common CreateResource API.\nExpose new AWS resources to customers automatically\nAWS Cloud Control API remains up-to-date with the latest AWS resources, enabling Amazon partners to integrate their own solutions with Cloud Control API just once, and then automatically access the new AWS services and features without assuming additional integration work.\nProvision resources with third-party infrastructure tools\nCloud Control API provides developers with the ability to provision AWS resources with partner infrastructure tools such as HashiCorp Terraform and Pulumi.\nHashiCorp provides cloud infrastructure automation software that enables organizations to provision, secure, connect, and run any infrastructure for any application.\n“AWS Cloud Control API makes it easier for our teams to build solutions to integrate with new and existing AWS services. HashiCorp’s foundational technologies solve the core challenges around infrastructure so that teams can focus on business-critical tasks. Integrating HashiCorp Terraform with AWS Cloud Control API means developers are able to use new AWS features and services as soon as they are available in Cloud Control API, typically on the day of launch.”\nJames Bayer, EVP Product - HashiCorp\n“Pulumi’s new AWS Native Provider, powered by the AWS Cloud Control API, gives Pulumi’s users faster access to the latest AWS innovations, typically the day they launch, without any need for us to manually implement support. The full surface area of AWS resources provided by AWS Cloud Control API can now be automated from familiar languages like Python, TypeScript, .NET, and Go, with standard IDEs, package managers, and test frameworks, with high fidelity and great quality. Using this new provider, developers and infrastructure teams can develop and ship modern AWS applications and infrastructure faster and with more confidence than ever before.”\nJoe Duffy, CEO - Pulumi\nAnsible Automation Platform makes it easier to provision and configure cloud infrastructure, streamlining and operationalizing activities across clouds and cloud-native services.\n“Ansible cloud automation provides a common framework using Certified Ansible Content designed to support process automation for operationalizing cloud infrastructure and services. The AWS Cloud Control API helps produce an improved cloud automation experience supporting AWS infrastructure consisting of hundreds of services and features. It allows Ansible to quickly develop content for the automation of new AWS services and the implementation of new features. The uniform access that AWS Cloud Control API provides contributes to a faster and more efficient, and flexible foundation on which to build and deploy automation that helps businesses accelerate, orchestrate, and innovate on AWS.”\nTom Anderson, VP Ansible Business Unit - Red Hat"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:41045801-294a-4ed9-a307-d000e200f5c8>","<urn:uuid:0b4029c4-8386-43bb-a060-65653bd808c5>"],"error":null}
{"question":"How do the Peaceful Bamboo Family's localized approach to cultural integration and INBAR's international development strategy demonstrate different scales of implementing sustainable development in the Global South?","answer":"The Peaceful Bamboo Family demonstrates a localized approach by intentionally embedding their practices within Vietnamese cultural context, incorporating Buddhist and Confucian traditions, and adapting their community structure to local customs and moon cycles, while avoiding imposed foreign values. In contrast, INBAR operates on an international scale with 44 member countries and regional offices in multiple countries, promoting South-South cooperation and implementing broader sustainable development initiatives. While working at different scales, both organizations share the goal of supporting sustainable development in the Global South, with the Peaceful Bamboo Family focusing on community-level implementation and INBAR coordinating larger policy initiatives and knowledge sharing across nations.","context":["In 2009, Eurasia created the Peaceful Bamboo Family (Tinh Truc Gia), in Hue, Vietnam, a vocational training centre and living community for young adults living with disabilities. The community is based on humanistic values offering a healthy environment that facilitates the wellbeing of each member. TTG embodies an ecological lifestyle and develops biodynamic agriculture, it aims to be a practical training centre for social therapy and biodynamic gardening. Community life is central to the integration of the person living with disabilities.\nTTG provides a rich social and cultural life, and welcomes more and more visitors and volunteers each year. In 2012 Tinh Truc Gia joined the international Camphill network.\nThe Center offers each resident a vocational training, enabling them to be integrated in professional life and to become as autonomous as possible. Various vocational training workshops enable the youngsters to learn a profession and promote income generating activities.\nThe Gross National Happiness Framework applied in a Camphill Community in Vietnam\nWhen we created the Peaceful Bamboo Family community in Hue, Central Vietnam, our fundamental intention was not focused on caring for young people with intellectual disability, but rather on creating a conducive environment that would allow these young people to unfold their full potential in a way that would enable them to make a positive contribution to society. And these contributions have been manifold.\nWhen we started our community, it was not yet possible for NGOs in Vietnam to buy land and to run a privately owned Centre. Due to the many years of work in the field of special education, the local government had confidence in our Foundation and granted us an exception so that we could create the first private and free centre entirely based on our values and principles inspired by the Camphill Movement and later by the GNH framework.\nThe Four Pillars of GNH in the Peaceful Bamboo Family\nIn Vietnam, as in many developing countries the so-called modernization of agriculture has created a lot of damage to the environment and even to the health of the population due to the misuse of pesticides and fertilizers. Especially among young parents, there is a growing concern of the negative effect of harmful food on the health of their children. Our community started the first biodynamic organic horticulture garden in Vietnam, which became rapidly a pilot project where students of the local agricultural college could come to learn about a different way to take care of the earth and produce healthy food. School classes also come to our garden to learn about ecology, gardening and they work alongside people living with disabilities, thus appreciating how people with special needs not only contribute to society, but can even be their teachers in a specific area.\nOur own community eats mainly our own organic, locally grown vegetables.\nAs a community, we are trying to reduce as much as possible our ecological footprint; we have solar panels for warm water and electricity, our own water source and the means to collect rainwater. Our next project is to become a zero waste community and to recycle human waste into compost and biogas.\n2. Fair and sustainable\nOur aim is to become economically and financially sustainable and to generate enough income to gradually become autonomous. Our community is also a vocational training centre and the young people who have graduated and want to remain in the community are hired as co-workers. Our current focus is to develop social entrepreneurship in partnership with other like-minded companies. We process tropical fruits from our garden into delicious jam, juice and ice cream, we have a bakery and produce several types of cookies, and we sell these products through a partnership with an online health food store from Saigon.\nOur lacquer-ware workshop combines traditional techniques with spontaneous creativity allowing the young people to express themselves freely while learning age-old Vietnamese handicrafts. We organize exhibitions and auctions to sell the paintings, and it is very moving to experience how proud the youngsters can be when they realize that people actually appreciate their creations and are willing to buy them. We also have an incense workshop producing high quality incense made of natural organic medicinal plants according to an ancient recipe.\nWe have opened a teahouse in our front-yard with a beautiful flower and rock garden; this gives us the opportunity to sell some of the products of the workshops and the garden, including our own organic green tea. Likewise, it is also an opportunity for the youngsters to learn the skills of service industry, and to practice useful abilities such as counting, reading and writing, speaking in an appropriate way with strangers.\nAll these projects have a dual purpose, creating situations where young people living with an intellectual disability can learn useful skills and train for a job, thus contributing to society, and also generating income for the centre. This year, the centre was able to generate over 50% of its running costs through these activities. But of course such a centre will always need some financial support to be able to develop further and flourish.\nWhen we started the Peaceful Bamboo Family, we were inspired by the ideals of the Camphill Movement, but we wanted to create a community that was completely embedded in the Vietnamese context. We did not want to import foreign values and cultural practices in a country that has suffered too much and for too long from destructive foreign influence, whether from French colonialism or American imperialism.\nAt the same time, we knew from our experience in the Camphill community of Perceval the importance of spiritual and cultural practices to structure the life and cycles of time of a community. So our challenge was to find the essence of the practices that we had experienced in a Western, largely Christian context located in a temperate climate zone, and to recreate comparable forms and rituals born out the Vietnamese, largely Buddhist and Confucian, tropical context. I explicitly mention the climate zone because most religious festivals are related to the season: Christmas near the Winter Solstice, Easter at the Spring Equinox, St John at the Summer Solstice and Michaelmas at the Autumn Equinox.\nSo we structured our yearly cycle around traditional Vietnamese and Buddhist festivals that are connected to the moon cycle rather than the sun cycle; including ancestor and Earth-spirit worshiping ceremonies which are held on New and Full Moon.\nLikewise, we organized the weekly rhythm with a day of Mindfulness and an evening called ‘Sharing from the Heart’ where each member of the community has an opportunity to share how they feel, what makes them happy or worries them and heard in an atmosphere of respect and non-judgemental listening.\nWe also hold regular seminars and workshops for both co-workers and youngsters in a spirit of lifelong learning for all, and we have created the ‘Eurasia Learning Institute for Happiness and Wellbeing’ (ELI) to share our experience well beyond our limited field. As an example, we have started a training programme for forty university professors from Saigon who want to implement a ‘Mindfulness Based Compassion and Happiness programme’ with their students. We are also working with the Education Department of Hue province and have implemented a mindfulness and compassion educational programme: “A call to Care” in primary schools in Hue.\nThese are just some of the many examples of the way we have consciously included the spiritual and cultural dimensions in the community life and how it can spread beyond our community.\n4. Good governance\nOf course our community has a leadership structure that is responsible and accountable, but our effort is to create a participatory leadership-style that includes everyone, long-term co-workers, volunteers, and the residents alike and we regularly hold seminars to redefine and co-create a common vision and mission that is shared by all. When new projects emerge, the whole community is consulted so that they can voice their ideas or doubts. For instance, in the recent past, we have created an inclusive kindergarten, a sector for young teenagers with behavioural challenges and we are designing an ambitious zero waste programme. All these projects were discussed and designed with the entire community at many open meetings. Beyond the Four Pillars, we have also used the nine domains of GNH as an assessment tool to pilot and improve the functioning of our community.","PROMOTING THE USE OF BAMBOO AND RATTAN FOR SUSTAINABLE DEVELOPMENT\nThe International Bamboo and Rattan Organisation （INBAR） is a multilateral development organisation which promotes environmentally sustainable development using bamboo and rattan. It has 44 Members. In addition to its Secretariat headquarters in China, INBAR has regional offices in India, Ghana, Ethiopia, and Ecuador.\nIts unique set-up makes INBAR an important representative for Members. With over 40 of its members from the Global South, INBAR has played an especially strong role in promoting South-South cooperation for the last 20 years. Since its founding in 1997, it has been making a real difference to the lives of millions of people and environments around the world, with achievements in areas such as: raising standards; promoting safe, resilient bamboo construction; restoring degraded land; capacity-building; and informing green policy and Sustainable Development Goal objectives.\nSUPPORTING THE SUSTAINABLE DEVELOPMENT GOALS\nGuided by its 2015-2030 strategic plan, INBAR’s priority is to work with countries to focus the use of bamboo and rattan as strategic resources that support sustainable development and their green economy action plans. Its strategy and performance contribute directly to six sustainable development goals （SDGs）:\n- SDG 1:End poverty in all its forms\n- SDG 7:Provide affordable, sustainable and reliable modern energy services for all\n- SDG 11:Access to adequate and affordable housing\n- SDG 12:Efficient use of natural resources\n- SDG 13:Address climate change\n- SDG 15:Protect and restore terrestrial ecosystems.\nSTRATEGIC PLAN 2015-2030\nINBAR’s priorities, defined under the Strategic Plan 2015-2030, are to promote the promise of bamboo and rattan as practical and sustainable solutions, to the producers and users of these plants. You can read in more detail about INBAR’s Strategic Plan here.\nTo do this, INBAR targets its support to countries in four priority areas:\n- Policy shaping\nto provide affordable, sustainable and reliable modern energy services for all\n- Representation and advocacy\nto coordinate inputs on bamboo and rattan from a growing global network of members and partners, and to represent Members; needs in the global policy arena\n- Knowledge sharing and learning\nto exchange and communicate lessons learned widely, providing training and raising awareness of the relevance of bamboo and rattan as strategic resources and commodities that directly support a number of the Sustainable Development Goals, Aichi Targets, REDD+ and other global, regional or national frameworks\n- Action research and country support\nto promote adaptive research and on-the-ground innovation by promoting pilot best-practice case studies, and supporting the upscaling of best practices and innovations across INBAR Member states and with others\nWHY BAMBOO AND RATTAN?\nBamboo and rattan are astounding resources with unique potential to combat poverty and natural resource challenges. They grow locally to some of the world’s poorest communities in the tropics and subtropics, and have many uses, providing a vast range of sustainable products, livelihood options and ecosystem services. If we can harness the potential of bamboo and rattan the Global South will be closer to achieving its ambitious development, climate and environmental aims, including the Sustainable Development Goals, green growth, REDD+ targets, the Paris Agreement commitments, and the Aichi Biodiversity Targets."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:219e0e60-4cf9-45f9-8b4a-272ae0ffb228>","<urn:uuid:2f31ebea-a894-468c-9093-57146a292b8a>"],"error":null}
{"question":"Hey! Both the Pantheon and Theatre of Marcellus are in Rome's Region IX - what's the connection? 🗺️","answer":"Both structures are indeed located in Region IX (Circus Flaminius) of ancient Rome. The Theatre of Marcellus is explicitly stated to be in Regione IX Circus Flaminius, while the Pantheon's location is also mentioned to be in Regione IX or the Circus Flaminius. The area got its nickname from its major landmarks, as that was how areas in ancient Rome acquired their names.","context":["Theatre of Marcellus\n|Theatre of Marcellus|\nTheater of Marcellus (above)\n|Location||Regione IX Circus Flaminius|\n|Built in||13 BC|\n|Built by/for||Julius Caesar Augustus Caesar / Marcus Marcellus|\n|Type of structure||Roman theatre (structure)|\n|Related||List of ancient monuments\nThe Theatre of Marcellus (Latin: Theatrum Marcelli, Italian: Teatro di Marcello) is an ancient open-air theatre in Rome, Italy, built in the closing years of the Roman Republic. At the theatre, locals and visitors alike were able to watch performances of drama and song. Today its ancient edifice in the rione of Sant'Angelo, Rome, once again provides one of the city's many popular spectacles or tourist sites.\nIt was named after Marcus Marcellus, Emperor Augustus's nephew, who died five years before its completion. Space for the theatre was cleared by Julius Caesar, who was murdered before its construction could begin; the theatre was so far advanced by 17 BC that part of the celebration of the ludi saeculares took place within the theatre; it was completed in 13 BC and formally inaugurated in 12 BC by Augustus.\nThe theatre was 111 m in diameter and was the largest and most important theatre in Ancient Rome; it could originally hold between 11,000 and 20,000 spectators. It was an impressive example of what was to become one of the most pervasive urban architectural forms of the Roman world. The theatre was built mainly of tuff, and concrete faced with stones in the pattern known as opus reticulatum, completely sheathed in white travertine. The network of arches, corridors, tunnels and ramps that gave access to the interiors of such Roman theaters were normally ornamented with a screen of engaged columns in Greek orders: Doric at the base, Ionic in the middle. It is believed that Corinthian columns were used for the upper level but this is uncertain as the theater was reconstructed in the Middle Ages, removing the top tier of seating and the columns.\nLike other Roman theaters in suitable locations, it had openings through which the natural setting could be seen, in this case the Tiber Island to the southwest. The permanent setting, the scaena, also rose to the top of the cavea as in other Roman theaters.\nThe theatre fell out of use in the early 4th century and the structure served as quarry for e.g. the Pons Cestius in 370 AD. However, the statues located inside the building were restored by Petronius Maximus in 421 and the remaining structure still housed small residential buildings. In the Early Middle Ages the theatre was used as a fortress of the Fabii and then at the end of the 11th century (when it was known as templum Marcelli), by Pier Leoni and later his heirs (the Pierleoni). This saved the complex from further destruction. The Savelli held it in the 13th century. Later, in the 16th century, the residence of the Orsini, designed by Baldassare Peruzzi, was built atop the ruins of the ancient theatre.\nNow the upper portion is divided into multiple apartments, and its surroundings are used as a venue for small summer concerts; the Portico d'Ottavia lies to the north west leading to the Roman Ghetto and the Tiber to the south west.\nIn the 17th century, the renowned English architect Sir Christopher Wren explicitly acknowledged that his design for the Sheldonian Theatre in Oxford was influenced by Serlio's engraving of the Theatre of Marcellus.\n- Leland M. Roth 1993 Understanding Architecture: Its Elements, History and Meaning (Westview Press: Boulder, CO ISBN 0-06-430158-3 and Cassius Dio 53.30.5., pp 230-31\n- Cartwright, Mark. \"Theatre of Marcellus\". Ancient History Encyclopedia. Ancient History Encyclopedia Limited. Retrieved 5 November 2013.","|The Pantheon is one of the best-preserved buildings of Ancient Rome.|\nIt’s a short walk from Piazza Venezia through cobblestone alleys to this next must-see spot in the Eternal City. If you feel lost, worry not for tourists fill the city streets day in and out and the movement from one major attraction to another is pretty much like a pilgrimage. “Ride the tide” so to speak, and you’ll arrive with them at the next ancient marvel. Or, you can ask for directions, whatever makes you feel more secure.\n|You might chance upon this piazza heading to the Pantheon– the Basilica di Santa Maria sopra Minerva & the Pulcino della Minerva, the famous elephant sculpture by Bernini & Ercole Ferrata, making the base of one of Rome’s eleven Egyptian obelisks.|\n|If you can’t find your way around, go ask directions from these guys.|\nThe Pantheon is one of Rome’s must-see spot that can be accessed by foot from Capitoline Hill, Trajan’s Forum and Vittorio Emanuele II Monument cutting through charming small streets that lead to the square called Piazza della Rotunda, which features a fountain at its center, the Fontana del Pantheon. The area is called Regione IX or the Circus Flaminius referring to how the areas in ancient Rome acquire their nicknames—by the regions’ major landmarks.\n|The Fontana del Pantheon that features a six-meter obelisk.|\n|The fountain base. Designed by Giacomo Della Porta in 1575 and sculpted out of marble by Leonardo Sormani.|\nThis landmark is one of the best-preserved buildings of Ancient Rome. Built during the reign of Augustus (27 BC – 14 AD), along with the Baths of Agrippa, the Basilica of Neptune, the Pantheon was a part of Marcus Agrippa’s building program after the Battle of Actium (the decisive confrontation of the Last War of the Roman Republic). The structure suffered devastations by fire in its lifetime but was rebuilt by emperors, Domitian and Hadrian, during their respective reigns. Preserved well during its history, the Pantheon has been in continuous use from the time it was built to its present use as a Christian Church dedicated to St. Mary and the Martyrs when the ruling emperor gave the building to Pope Boniface IV in the 7th century. The conversion saved it from abandonment and destruction during the early medieval period when the worst of the spoliation that happened to the majority of ancient Rome’s edifices.\nArchitecturally, the building’s design is impressive— under the pediment of the portico are massive Corinthian columns (16 columns weighing 60 tons each) made of granite quarried from the eastern mountains of Egypt (imagine the logistics required to transport it to Rome during the ancient times). The porch is attached to the main circular structure consisting of the vast rotunda under the concrete dome designed with sunken panels called coffers and at its apex, the oculus, the dome’s central opening to the sky that serves as the interior’s source of natural light and ventilation system.\n|16 columns under a pediment weighing 60 tons each made of granite quarried from the eastern mountains of Egypt.|\nHere’s something to ponder on—the designer was able to create the dome with the height of the oculus (floor to apex) equal to the diameter of the dome’s interior circle (think: a 142-feet sphere will fit under this building’s dome). This architectural feature is still the world’s largest unreinforced concrete dome two thousand years (almost) after it was built.\n|Cross set ion of the Pantheon. The height of the oculus is equal to the diameter of the dome’s interior circle. (wikipedia image)|\nOf course, as the users change the interior gets modified. From the original design to honor the divinities, it was pillaged during the medieval times. It was converted to a Catholic Church and the high altars and apses, niches and chapels were added, and since the Renaissance, the Pantheon were adorned with paintings and has been used as a tomb (prominent Italians are buried here including 2 kings and a queen).\nThe Pantheon is a popular destination for us as tourists, so it is for the locals. It’s a place to pray and be at on important Catholic days of obligation, or perhaps get married in. Now, wouldn’t that be a dream wedding.\n|A family that tours together. The Asistidos at the Pantheon.|\nPublished in the Sun.Star Davao newspaper on June 05, 2014."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:c175969a-8f0b-40ee-ab4c-3d9ea3e7695c>","<urn:uuid:bf73efd8-b3d2-43d4-82af-1cf7d5a6a9e3>"],"error":null}
{"question":"Hi! I'm curious about how football referee authority compares with captain responsibilities, and what fundamental skills players need to master. Could you provide details on both aspects?","answer":"The referee serves as the game's moderator with complete control - they start and end the game, keep players in check, and make final decisions to ensure fair play. While team captains interact with referees, they don't have special privileges for complaints and actually have more duties than rights, being responsible for team behavior. As for essential player skills, they must master several techniques: passing the ball (including long passes, short passes, through passes, and back passes), shooting the ball with appropriate force to score, crossing the ball from beside the 18-yard box, heading/nodding the ball for passing or shooting, and dribbling to get past opponents using skills like nutmeg and shot feint.","context":["In many team sports, a team captain , also a game captain , team captain or captain, is a player who occupies an outstanding position in the game. Formally, this primarily concerns the ability to speak to the referee during the game . Usually the captain is elected by the team members or determined by the coach.\nHe represents the interests of the players in his team vis-à-vis the club, the coach and the referee, but is also often seen as the coach's extended arm on the field.\nIn cricket , the team captain plays a central role in the game. According to the rules, he is particularly responsible for ensuring that his team adheres to the rules and the spirit of the game and fair play . He can also be punished for misconduct by the team. In addition to the official tasks, such as representing his team at the toss of a coin and declaring an innings to be completed, the captain also makes decisive tactical decisions, such as the line-up of players or the order of his bowlers .\nIn ice hockey , in addition to the captain, there are two assistants who are allowed to exercise the captain's rights. The captain needs as well as his two assistants before the game in the score sheet have been noted. The function of captain or assistant may only be performed by field players, not by the goalkeeper. In ice hockey, only the captain and his assistants have the right to talk to the referee during the interruption of the game, whereby he must already be on the ice as a player for such a conversation, i.e. not be allowed to come off the bench as an additional player. The captain can be recognized by the letter C on the player's jersey or, in Russian-speaking countries, partly by the Cyrillic K (К). The assistants wear an A on their jerseys.\nIn football , the captain / captain can be recognized by the arm band. Before the start of the game, he greets the team of referees (in lower-class games, only the referee because there are no assistant referees ) and the opposing captain and takes part in the selection of sides . When winning a competition, it is also customary for the captain to receive the trophy.\nOften the captain's position in relation to the referee is misrepresented. The rules do not give the captain any more rights - e.g. B. Complaints - a, as his teammate. On the contrary, he has more duties. So he is the contact person for the referee if the situation requires it, e.g. B. to remedy a misconduct of his team or the trailer. Quotation from the DFB football rules 2018/2019: \"The captain / captain has neither special status nor privileges, but bears a certain responsibility for the behavior of his team.\"\nIf he is eliminated during the game (substitution, injury, expulsion), another player must be appointed team captain, which is formally sealed by putting on the arm band.\nUntil the rule changes on August 1, 2005, there was also a handball captain who was identified by an armband. The only task of the captain was the choice or draw before the start of the game (choice of side and throw-off). This can now be observed before the game by an official or any other eligible player.\n- Football rules 2018/2019 (PDF file; 8.5 MB)","Brief introduction of Football\n- Football is a game loved by many and these include people who have the ability to play and people who just love the sport and have passion for the sport. Football is also known as soccer and it is a game that involves two teams systematically kicking a ball which is usually spherical till they can get it into a goal post. This sport is the world's most popular sport and this can be said because this singular sport is played in over 200 countries and played by over 250 million people. Many people usually change the rules of the game to suit their needs but some set of rules still apply and they never change.\n- Football as a sport can be played professionally and this occurs in a placed called a pitch. The pitch is rectangular in shape. The pitch starts and ends with a goal post thus a pitch has two goal posts, each for each team. As earlier stated the aim of this sport is to move and kick the ball using different skills and techniques until you can get it in a goal post across the goal line. When this action is successfully carried out, it is called a goal. The team with the highest number of goals wins the game.\nThings required to play Football game\nThe following are some of the major requirements:\n- Two Teams Of An Equal Number Of Players\nTo play this game, you must have two teams and they must have an equal number of players. If it is a standard football match, the standard numbers of players in one team is 11 and these include a goalkeeper and 10players. If it is a game played just for fun, then we can have any number depending on the size of the pitch the individuals wish to use.\n- A Pitch\nThe football match has to be played in a pitch. A standard pitch is a rectangle and the pitch has a goalpost that has its size specifications. Professional pitch sizes differ but there is a minimum size of the pitch before it is qualified to be called a standard pitch and before professional matches can be played on such pitch.\n- A Ball\nThis is very important. This is the heart of the game. This is a spherical object containing air.\n- A Referee\nThis is the moderator of the game. The referee controls the game and makes sure the game is played fair and also keeping the players in check. He starts the game, he ends the game and he make the final decisions in the game.\n- A Pair Of Boots\nThis is only very important when it is a professional or serious match. If it is a match played for fun you can play without your boot. However professional football must be played with a boot as a matter of fact teams like India national team has been disqualified in the past for wanting to play a game of football without boots.\nThis is the distinguishing factor of the teams. Each team must have its players put on the same type and pattern of jersey with the name written on the jersey if possible. These jerseys are made in such ways that there is no way a player from the opposing team will mistake an opponent for a teammate. Each team is allowed two jersey types. One for when they play at home and the other when they play away from home. Both jerseys must not be similar so that if another team has a similar jersey color to theirs, the away team jersey would contrast.\n- Hand Gloves\nThis is mainly for the goalkeeper. He has to wear these to make sure he doesn't injure his hand and stress any bones or muscles causing pain as the ball can be very heavy sometimes especially during a rainy match. However, Hand gloves are only very important in professional and serious games. When football is played for fun, having a hand glove is not really a necessity.\nThis is one of the most important aspects of football. If there are no goal post players will just run and run and play the ball around with no real aim. A goalpost must be present because it determines who wins and who loses. It determines what direction to play and somewhere to aim.\nRequired skills to play Football\nThere are certain skills you need to have in mind and master before you enter the game of football. It is important that you know that the aim of the game is shooting the ball into the goal post. It takes certain skills to do this effectively and not depending on luck. The skills requires includes:\n- Passing The Ball\nPassing the ball is a skill where you play the ball to another teammate. It is not always possible for one person to run with the ball all by themselves past 11 players and score a goal, the ball must be passed around to players who are in better positions to pass the ball to other players who are in a better position or to shoot the ball into the goal post. There are different kind of passes one needs to master, they are, long passes, short passes, through passes, back passes, etc.\n- Shooting The Ball\nThis is another important skill to learn. There is a popular saying that if you don't shoot, you don't score, and if scoring is the aim of the game, this should tell how important this skill is. This is the act of kicking the ball with a good amount of force with the aim to put it in the back of the net.\nThis is the act of playing the ball across the goal from beside the part of the pitch called the 18-yard box.\n- Heading Or Nodding\nThis is the act of using one head to hit the ball. This action can be aimed at passing, shooting, or defending one's goal.\nThis is a process where one player gets past or round another player or sets of players using a certain skill set. Some of these skills include, the nutmeg, shot feint, etc.\nHow to play Football?\nTo play the game of football, you must make sure you have the above requirements and the set of players have the right skills listed above.\nThese are the steps you need to enjoy a game of soccer.\n- Get your pitch ready. It must be a conducive pitch.\n- Get your players ready. Put them in two teams, each team having the same number of players. A standard team is made of 11 players.\n- Get your goal post ready. Both goalposts of each team must be of the same size.\n- Get your ball ready. It must have enough air in it.\n- Bet a referee to moderate the game.\nSome important rules of Football\nJust like any life endeavor. There are rules that govern the football game. This include but not limited to the following:\n- The team with the highest goal wins the game\n- You must not pick the ball with your hand, or move your hand in a motion that will disrupt the ball movement. Don't keep your hand in a position in which it can touch the ball\n- You must not tackle a player roughly\n- Yellow card is awarded for bad play and two yellow cards makes a red card thus the player has to leave the pitch.\n- An opposing player cannot be the last player to the goalkeeper while the ball is passes to such player as this is called offside\n- Two balls must not be on the pitch at the same time.\n- More than 11 players must not be on the pitch at the same time in a standard football match.\nOn the final note, the above requirements, rules and skill sets are what is required to be an efficient football player.\nShare This Page On..."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:e1a32dd4-c95d-4851-8d5d-6d2a747f5487>","<urn:uuid:5fc09302-7694-4f04-a7b3-f17e2462911e>"],"error":null}
{"question":"How do extreme weather events affect healthcare facilities, and what building adaptations can protect against these impacts?","answer":"Extreme weather events can severely impact healthcare facilities by affecting their power and basic equipment, which hampers their ability to provide services. Additionally, climate change increases patient numbers, straining healthcare delivery systems and impacting quality of care due to limited resources. To protect against these impacts, buildings can implement several adaptation strategies including: high-performance building envelopes to maintain indoor temperatures during power outages, elevated mechanical and electrical equipment to avoid flood damage, distributed cooling and heating systems, and backup power generators for critical systems. These measures help maintain essential operations during and after weather emergencies.","context":["Policy Brief on Climate Change Name Institution Instructor Course Date Policy Brief on Climate Change Background Information Climate is one of the major factors that affect the health of all individuals across the globe\nPolicy Brief on Climate Change\nPolicy Brief on Climate Change\nClimate is one of the major factors that affect the health of all individuals across the globe. Climate can be described as the weather patterns in a given area, which have been identified over a long time (Burch, Harris, & University of Toronto Press, 2016). Different parts of the continent have different types of climate. When climate changes to the extreme, it will affect the human health, as extreme heat will increase the transmission of certain diseases while extreme cold will also affect the human health negatively (Burch, Harris, & University of Toronto Press, 2016). Some of the consequences of climate change include flooding and drought, which all will affect individual’s health negatively. Climate change also affects the basic needs necessary for the well-being of all individuals, which may include food, water, and the air which are important for the daily survival of all living creatures (Burch, Harris, ; University of Toronto Press, 2016).\nWhen these basic needs are affected, the human health also bears the consequences (Black, 2013). The issue of climate change must be considered and addressed due to the negative impacts it has on all humans across the globe. Climate change is a health issue that every nation should be keen to address and measures to protect the environment from a climate change should be implemented (Black, 2013). The major cause of climate change is human activities and all government and authorities should put measures to protect the environment from human activities that may have negative effects on the weather (Black, 2013). The populations that will bear the most burden of climate change are the elderly and the young children due to their weak immune systems and the poor who are unable to put mitigation strategies to protect themselves from the negative effects of climate change (Black, 2013).\nThe extreme weather changes may even lead to death or injury for the poor population, as they are unable to protect themselves from the events that may be caused by extreme weather changes (Burch, Harris, ; University of Toronto Press, 2016). The United States has enacted measures at the national, state, and local levels to address the issue of climate change in the country. This will ensure that the nation addresses any arising threats to the climate at all levels by ensuring coordination and support between the levels (Burch, Harris, ; University of Toronto Press, 2016).\nPolicies are made for all levels considering the risks at the specific levels and mitigation strategies are implemented to prevent any negative human activities that may lead to the negative effects of climate change (Black, 2013). This is important as state and local representatives are allowed to participate and air their opinions, as they are the ones responsible in enforcing and implementing any policies regarding climate protection (Black, 2013). The constituencies and the states are diverse and have different weather patterns and so it is necessary to involve them in policy making for the betterment of the nation (Black, 2013).\nClimate change has affected the whole globe with rising temperatures which are negatively affecting all population across the globe and this is due to human activities which pollute the environment affecting its normal functioning and this has led to disasters in some parts of the world that are unable to implement preventive strategies to protect their citizens (Hanusch, 2018). Following these negative effects caused by climate change, all nations should put protective policies on their resources to prevent human activities from exploiting these resources, which has led to the troubles related to climate change (Hanusch, 2018). These human activities have led to the degrading of certain regions exposing them to the negative effects of extreme weather effects. These negative effects have affected the human health and this has a negative outcome for any country as it tries to reverse the negative side effects caused by these extreme weather changes (Hanusch, 2018).\nMost governments spend a large part of their budget in solving these negative situations and addressing the health issues of its citizens caused by the climate changes (Hanusch, 2018). Climate change also has a negative impact on agriculture, which is important for any country as agriculture provides food for its citizens, and if this is affected, the health status of all individuals will be impacted as well as the motion’s economic budget in its provision of the basic need to its citizens. Due to this, nations must address the issue of climate change at all levels to ensure that the world is stable from any negative effects of climate change (Hanusch, 2018).\nSuggestions for Addressing the Issue (Solutions) – (a) Including Necessary Stakeholders (Government Officials, Administrator); and (b) Include Budget or Funding Considerations, If Applicable\nClimate change can be addressed by educating the public about the negative effects of climate change, which are caused by human activities (Reid, 2014). Education and training programs should be planned and implemented across all countries across the globe since climate change is a global concern and a single nation cannot be successful in mitigating the issue alone (Reid, 2014). These programs will help the public to be aware of their activities and be on the watch out for any activities that may lead to the negative effects (Reid, 2014).\nThe United States government should help its citizens in adapting to new weather changes and strategies to help the nation in times of disasters should be planned (Reid, 2014). Weather changes should be monitored to avoid unexpected weather changes, which can negatively impact a nation (Reid, 2014). The government and administrators should implement strict measures on environment protection against pollution, which largely contributes to climate change (Reid, 2014). A budget should also be planned to address emergencies and to support organizations, which help protect the environment and enforcing policies and laws regarding environment protection (Reid, 2014).\nImpact of climate change on the Health Care Delivery System\nThe health care system aims at providing quality healthcare to the citizens of the United States (Maslin, 2014). With the negative effects of climate change, the number of patients will increase impacting the healthcare delivery system negatively as it has to provide health care services to its population regardless the number and this will negatively impact the quality of healthcare services due to the limited resources in healthcare facilities (Maslin, 2014). Due to the climate change affecting food and water security, health care delivery system will have more diverse issues, which will involve patients without food and other basic needs, which will affect the goals and objectives of the health care delivery system of bettering the health status of the citizens of the country (Maslin, 2014).\nNegative effects that occur due to climate change, which may include floods and storms, may affect healthcare facilities affecting their power and other basic equipment, which can worsen the situation due to the difficult of administering healthcare services to the citizens (Maslin, 2014). Due to this, health care facilities need to put more resources in their preparation for natural disasters brought about by climate changes and educate health care practitioners on what procedures to undertake in times of disasters (Maslin, 2014).\nBlack, B. (2013). Climate change: An encyclopedia of science and history. Santa Barbara, California: ABC-CLIO.\nBurch, R. W., Harris, S. E., & University of Toronto Press. (2016). Understanding climate change: Science, policy, and practice. Toronto: University of Toronto Press.\nHanusch, F. (2018). Democracy and climate change. London: Routledge, Taylor, & Francis Group.\nMaslin, M. (2014). Climate change: A very short introduction. Oxford, United Kingdom: Oxford University Press.\nReid, H. (2014). Climate change and human development. London: Zed Books.","As areas affected by recent hurricanes and earthquakes struggle to recover from the damage, demand for resilient multifamily housing capable of resisting natural and man-made disasters is expected to climb in coming years.\nGiven the power and magnitude of the quakes and storms, boosting multifamily building resilience in the Caribbean, Mexico and along the U.S. Gulf and Atlantic coasts is not an extravagance, but a necessity.\nToward a More Resilient Latin America and Caribbean\nFrom 1990 to 2011, natural disasters cost the housing sector in 16 Latin American counties and the Caribbean at least $53 billion, according to a global assessment report published in 2013 by the United Nations Office for Disaster Risk Reduction.\nLack of access to safer, affordable housing alternatives has forced 25 percent of the region’s population to live in substandard housing and informally built homes that are much more vulnerable to natural hazards. Public and private housing efforts traditionally have focused on quantity rather than quality, endorsing new housing construction and purchase subsidies while neglecting improvements to existing housing.\nIn March last year, The World Bank gathered international experts and housing authorities from 14 countries—among them the U.S., Chile, Argentina, Colombia, Peru, Honduras, Mexico and Jamaica—in Washington, D.C., to discuss how to improve housing affordability and resilience in order to mitigate increasing climate and disaster risks. They came up with several recommendations:\n- Align structural retrofitting efforts with better incentives for home/building owners.\n- Proactively engage finance institutions to increase affordability and improve building resilience.\n- Link housing policies and improvement efforts to both affordability and energy efficiency.\nDesigning for Multifamily Building Resilience\nResilient multifamily housing calls for innovative design approaches and construction methods that can tackle both acute shocks (hazard events) and the chronic stresses that stem from the gradual and perpetual disruptions that reduce a community’s ability to recover from disaster.\nAffordable housing and community development advocate Enterprise Community Partners recently published a collection of strategies for making affordable multifamily housing more resilient against the effects of extreme weather events. Based on the advice of 50 technical experts, the manual—“Ready to Respond: Strategies for Multifamily Building Resilience”—is a guide for building owners on retrofit strategies to help adapt and protect their properties against a variety of climate hazards.\nImproving multifamily building resilience poses significant design, cost and safety challenges, but the costs associated with disaster recovery—response, repairs, reconstruction, etc.—can be as disastrous as the natural hazards themselves. The old adage stands true: better safe than sorry.\nTHE COSTS ASSOCIATED WITH DISASTER RECOVERY CAN BE AS DISASTROUS AS THE NATURAL HAZARDS THEMSELVES. THE OLD ADAGE STANDS TRUE: BETTER SAFE THAN SORRY.\nStrategies for Resilient Multifamily Housing\nNot every housing unit or development is the same nor does it requires the same design and construction approach. Following are some the strategies designers and builders can use to improve multifamily building resilience.\nProtection strategies to reduce a building’s vulnerability to extreme weather.\n1. Wet Floodproofing\nAllows unoccupied portions of a building to be flooded during a storm by letting water flow through the building in a controlled way.\n2. Dry Floodproofing\nSeals buildings to keep water out and prevent damage to critical systems and mechanical equipment, reduce recovery time and deter mold growth. There are two types of dry floodproofing: active and permanent. Active measures require removable elements to be put into place before an anticipated flood. Permanent measures are fixtures and systems integrated into the structure itself that do not need to be manually deployed in the event of an emergency.\n3. Site Perimeter Floodproofing\nDeploying temporary (sandbags, water-inflated tube systems) or permanent (floodwalls, berms) physical barriers to prevent floodwaters from reaching a building. Does not require modifications to the building structure.\n4. Resilient Elevators\nElevators are often the only way residents have to reach higher floors, making them a critical building system. They are vulnerable to flood damage because elevator pits typically extend well below the lowest floor. Several techniques can make them more resilient.\n5. Backwater Valves\nSewage backflow occurs when storm water backs up into a building basement because of sewer line blockage or storm drain overflow due to flooding. A backwater valve is a relatively inexpensive retrofit that can prevent significant problems from sewer line failure by blocking reverse flow from entering the building through wastewater pipes.\n6. Sump Pumps\nThese remove water that accumulates in the low points in a building, typically the basement. They are an effective and affordable way to reduce costly flood damages.\nAdaptation strategies to improve a building’s ability to adapt to changing climate conditions.\n1. Envelope efficiency\nA high-performance envelope is very valuable during a power outage because indoor temperatures change more slowly, increasing a building’s “passive survivability.” The thermal performance of a building envelope depends on its insulation value, air leakage and thermal bridges.\n2. Elevated Equipment\nWith more extreme weather events causing coastal flooding, elevating or relocating mechanical and electrical equipment out of flood-prone basements and lower floors increases building resilience. Critical equipment can be elevated in place or moved to higher floors, the roof or an outdoor platform.\n3. Elevated Living Space\nAbandoning floors below the design flood elevation or using them for a non-residential purpose can limit damage to critical equipment or living space during a flood. By eliminating living spaces and mechanical systems below the base flood elevation and incorporating wet floodproofing measures, buildings may become eligible for lower insurance rates.\n4. Surface Stormwater Management\nStormwater is a major cause of urban flooding, especially in cities with combined sewer and stormwater systems. Most water treatment systems cannot handle additional volume during a large storm. Infiltrating water into the ground on-site reduces the need for large infrastructure projects and can ease flooding, speed recovery after a storm and reduce sewer backups.\n5. Window Shading\nExterior or interior window treatments that shade rooms can lessen solar heating in the summer and insulate against heat loss in winter.\n6. Distributed Cooling and Heating\nDecentralized and high-efficiency heating and cooling systems distributed throughout a building can help avoid flood damage while lowering operating costs. Distributed systems are most effective in buildings with high-performance windows and well-insulated, airtight envelopes.\nBackup strategies that provide critical needs for when a building loses power or other services.\n1. Maintaining Backup Power to Critical Systems\nDuring a power outage, backup power is vital to continue building operations and make repairs during and after a storm event. Consider the needs of your site when selecting a backup power generator, including the location where it will be installed, fuel storage issues, the amount of emissions it will produce and your budget.\n2. Emergency Lighting\nBuilding codes generally require only 90 minutes of emergency illumination. Different lighting strategies—such as natural light, battery- and solar-powered emergency lighting—are necessary to keep buildings operating safely during and after emergencies.\n3. Access to Potable Water\nA reliable source of potable water is essential if a building is to remain livable during a power loss. Taller multifamily buildings typically use rooftop water tanks, rainwater storage tanks, pressure-booster pumps, critical load circuits (for the water pump and power generator) and water efficiency measures to keep the water flowing.\nOther strategies that can improve multifamily building resilience include sea walls, elevated post-tension concrete design, missile-impact glass and subterranean concrete pilings.\nSources: The World Bank, Enterprise Green Communities, Resilient Design Institute."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:59855dfe-fbad-4e8d-b422-86a7bb9ce2eb>","<urn:uuid:ab67aee7-00d9-4d77-9232-0672226623f7>"],"error":null}
{"question":"What's the difference between jam and jelly? Need specifics on texture and preparation.","answer":"Jam and jelly differ in both preparation method and texture. Jellies are clear because the fruit is mashed and strained, using only the juice with no visible fruit pieces remaining. Jams, on the other hand, are made from puréed fruit and will have small pieces of fruit still visible in the final product. Additionally, jams are less firmly set than jellies.","context":["Jam is a sweet, thick spread made from preserved fruit.\nGetting jam to set depends on pectin. Pectin, combined with the acid in the fruit and the sugar you add, makes the jam gel. Pectin needs to be added both for fruits that are very ripe (because they will have lost most of their pectin), and for fruits that never contain any great amount of pectin, such as strawberries.\nFreezer jam generally needs no cooking. While many people dismiss it as not being real jam, others say that the fruit retains a more fruity, bright, true-to-itself flavour because it doesn’t go through a boiling process.\nJam differs from jelly in that jellies are clear — to make a jelly, the fruit is mashed and strained, so that just the juice is used, with no apparent bits of fruit remaining, whereas jam are are made from puréed fruit, and so will have small pieces of the fruit still visible. Jams are also less firmly set than jellies.\nJam differs from fruit preserves in that fruit preserves will have much larger pieces of fruit available, and fruit preserves may or may not use pectin — the fruit preserve may aim to be spoonable as a dessert, rather than spreadable like a topping, as jam is.\nJams can be made with or without added pectin.\nA popular commercial brand in North America and the UK is “Certo”, though it’s actually two separate products now.\nOther popular brands include Ball and Bernardin.\nSome jams such as apricot and strawberry would be pourable rather than thick and gel-like without the added pectin.\nWhen you’re not using pectin, you definitely want to try to be using some unripe fruit, about ¼ of the fruit that you are using, as unripe fruit has more pectin and will help to give a firmer set. If you have a fruit with high enough pectin in it, such as apples, blackberries, crab apples, cranberries, gooseberries, grapes, plums, red currants or quinces, you can easily make a jam with no added pectin. Basically just mash the fruit, and measure the mashed fruit: add an equal amount of sugar, and simmer, stirring frequently, until it thickens into a jam. (Remember, it will thicken even more when removed from the heat and allow to cool.)\nIf you want to swap in honey for some of the sugar, swap no more than ¼ of the sugar for honey — honey’s more pronounced taste can make your jam taste less like the fruit it is made from, and too much honey will inhibit the jam from setting because it does add additional liquid.\nDon’t double a jam recipe, unless the commercial pectin you are using clearly says it is okay to. It’s much harder to get it to boil properly; and can affect how it sets. The cooking pot should be half full.\nIf a jar of jam develops some mould, always throw the jar out — don’t just remove the mouldy part and keep on eating the rest. Some moulds can produce potentially harmful toxins, and even if only a small part of the jam has got mouldy, there may be invisible spores not germinated yet in other parts of the Jam.\nForms of jam have been made for millennia — it just depends on how finely you want to slice the definitions of jams, jellies and preserves. The Roman writer, Apicius, has recipes for fruit preserves.\nCertainly, though, it wasn’t until the modern availability of affordable cane sugar that nams really took off.\nSmuckers Jam began with Jerome M. Smucker’s cider operation in Orrville, Ohio, in 1897. He later branched out into apple butter, and then into jam.\nThe most famous brand in North America of Grape Jam is Welch’s. Welch’s, which already existed as a grape juice company since 1869 (see entry for Concord Grapes), got their patent for the jam in 1917; they called it “Grapelade”. The government purchased every bottle he made and shipped it off to soldiers. The troops came home with a taste for it, and created an instant market for what would become Welch’s Grape Jam and Welch’s Grape Jelly.\nWhen the Titanic went down it was carrying 1,120 pounds of jams and preserves.\nJam on bread provided a cheap meal for many working people in the first half of the 1900s, thanks to cheap sugar:\n“Jam was a staple food in pre [World War Two] Britain, and remained so throughout the war. It may seem an odd foodstuff to single out, but it had a significance way beyond its modern role. In the 19th century, sugar had become a cheap commodity. So cheap, in fact, that it became a working class staple. The energy that can be obtained from small amounts of sugar is great: it moves quickly into the bloodstream, giving a very noticeable lift. Cheap sugar had led to cheap jam, much cheaper than dripping. The working classes of Britain had long survived largely on bread, and a smear of jam made it both more palatable and significantly raised its calorific content. At the outbreak of World War II, bread and jam, also known as “a piece”, was still the cheapest meal available and one that many city dwellers, in particular, regularly had to make do with. A farmer may have been lucky enough to have a wedge of cheese or a slice of ham in his lunchtime sandwiches, but if money was tight, then it was back to jam.” — Ruth Goodman. In: Ginn, Peter et al. Wartime Farm. London, England: Mitchell Beazley. 2012. Page 126-127.\nIn 1940, the US Food and Drug Administration set a legal definition of what a jam is.\nIn February 2009, Marks and Spencers announced that it would sell jam sandwiches as a recession special. Called “Simply…Strawberry Jam Sandwich”, it went on the market at 79p. Marks and Spencers said that a jam sandwich is “one of the greatest simple pleasures of life.”\n“Marks & Spencer to sell jam sandwiches.” London: Daily Telegraph. 18 February 2009."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"}],"document_ids":["<urn:uuid:eed154b3-b3c9-4238-915e-79e8012b6af6>"],"error":null}
{"question":"What are the benefits of zirconia in dental work vs its drawbacks as implant material?","answer":"Zirconia offers several benefits in dental work - it is biocompatible, translucent, and exceptionally strong when used in frameworks. As an all-ceramic material, it allows light to shine through restorations like natural teeth and shows no dark metal edges at the gum line. However, as an implant material, zirconia has some significant drawbacks - it is more brittle than titanium, typically comes as one piece which makes angle corrections difficult, and crowns tend to come off more easily due to limited customization options. While it has good biocompatibility with no local or systemic effects, zirconia implants can fracture and the broken pieces can be difficult to remove from the jaw. Additionally, they have about 5% lower success rates compared to titanium implants, though newer research shows improving outcomes.","context":["Dr Christiaan Vorster: Prosthodontist BChD, MChD (Prosthodontics)\nThe damage or loss of even a single tooth can have considerable impact on any patients’ everyday life and self-esteem. Restoring and replacing teeth has been the mainstay of modern dentistry for many years. But it is only recently after the advent of dental implants and all-ceramics prosthetic teeth that patients have been able to enjoy restorations that feel, function and look like natural teeth.\nAll ceramic materials stand out for their highly aesthetic and natural appearance, long lasting quality, variety of colours and biocompatibility with the human body. All-ceramic restorations do not have a metal core therefor light can shine through the restorations as it does with natural teeth. In addition, the adjoining gum will show no dark metal edges.\nCeramic material is colourfast and wear-resistant. If a tooth is only damaged to some extent e.g. due to caries, a filling will normally be sufficient. An alternative to a conventional filling is a ceramic inlay or onlay. An inlay is a resistant ceramic filling, which is used for smaller defects or decay and is difficult to distinguish from the natural tooth structure.\nFractured, discoloured or slightly malpositioned teeth can also be easily and quickly treated with veneers. Veneers are thin laminates made of ceramic, which are bonded to the tooth without having to sacrifice a lot of your own tooth structure and do not cover the entire tooth. In certain instances, no tooth preparation is required for the veneers to be placed. The completed restoration is as true-to-nature in appearance as your neighbouring teeth.\nTeeth, which demonstrate extensive damage, can be restored or optically enhanced with all-ceramic crowns. Older restorations that are unsightly can also be given a natural and unobtrusive appearance. When teeth are missing, bridges supported by teeth or implants can also be manufactured from all-ceramics without a dark metal core or margin. Zirconium oxide is the material of choice for frameworks, as zirconium oxide is biocompatible, translucent and exceptionally strong.\nThese days, prosthodontists and dentists are seeing patients with tooth structure loss as a result of acid erosion and grinding due to a stressful and demanding life. This in turn leads to severe damage to the teeth that affect the overall aesthetics of a patients’ smile as well as optimal masticatory function and speech. All-ceramic materials and techniques make replacing lost tooth structure less invasive and much more pleasant while providing far better aesthetic results than a few years ago.\nAnother important aspect in daily practice is that people lose their teeth for a number of reasons; from accident and illness to deficient care. Whatever the reason, the immediate consequences can have a negative impact on their quality of life. People may no longer eat many of the foods they once enjoyed. Self-conscious about their physical appearance, they stop laughing and smiling spontaneously.\nDental implants are widely recognized to be the most successful method of tooth replacement used today. Planned by specially trained clinicians like prosthodontists, implants and modern prosthetics are hard to differentiate from your natural teeth. The colour, shape and contour of replacement teeth can be adapted to match that of your natural teeth with all ceramic restorations. With dental implants, healthy teeth do not have to be compromised.\nMissing teeth can and should be replaced. This is because each and every gap in your mouth poses potential problems for long-term dental health. Adjacent teeth can collapse into the gaps, while teeth in the opposing jaw can grow into the gap. Long-term missing teeth also cause the bone to be resorbed. This weakens the adjacent teeth until they can also be lost. In fact, even one missing tooth can lead to the loss of additional teeth and ultimately a permanent change in your facial appearance.\nMaintaining your natural bone if one of the most important advantages of dental implants. With missing teeth, the bone begins to resorb over time. Significant bone loss can shrink the contours of the jawbones, causing wrinkled lips and a sunken mouth and chin. Dental implants can help counteract that by preventing resorption of the jawbone, stimulating bone growth and stopping bone loss.\nThere are a wide variety of prosthetics and implant solutions available. Crowns, bridges or full arch prosthetics are securely anchored to integrated dental implants. The stable retention of prosthetic solutions and implant supported tooth replacements offer strength, reliability and durability similar to that of natural teeth.\nProstheses fixed on implants are also more stable, more comfortable and more functional than conventional dentures. This eliminates some of the main problems of conventional dentures like poor fit, gum irritation, pressure points, speech and taste impairment. The result is an aesthetically comfortable, reliable and stress-free solution. With proper care and good oral hygiene, a prosthetic solution will last for many years.\nAll-ceramic cosmetic dentistry and implants all fall under the field of prosthodontics. Most people have never heard of a prosthodontist. Some have called prosthodontists ‘The Best Kept Secret in Dentistry’. Prosthodontists have rigorous training and experience that gives them an in-depth understanding of the dynamics of the smile, the preservation of a healthy mouth and creation of dental replacements.\nProsthodontists specialise in the restoration of oral function and aesthetics and are frequently called upon to treat aesthetically demanding cases and full mouth rehabilitations on teeth or implants. A prosthodontist may be considered as the ‘architect’ of a restorative dental treatment plan and will be with you every step of the way, restoring proper function and aesthetics of your mouth, face and jaw.\nProsthodontists are also expert in diagnostic and treatment planning and deal with complex dental problems on a daily basis. They normally work in a team to achieve aesthetically pleasing, optimal long-term dental health. Close co-operation exists within the team, consisting of general dentists, maxillo-facial and oral surgeons, periodontists, orthodontists and dental technicians.\nModern dentistry is undergoing a rapid advancement of solutions and products to satisfy all patient requirements, improving daily chewing function and restoring personal appearance. With today’s latest technologies and materials, individual teeth or even a full complement of teeth can be replaced for natural-looking appearance and optimal function. Modern all-ceramic dental restorations help thousands of people improve their lives. Advancements in technology utilising smile designing software allow you not only to virtually see how great your smile can look before any treatment begins, but also to better predict what material option would best suit your treatment needs.","What are zirconia dental implants?\nZirconia dental implants are similar to titanium dental implants except they are made from a zirconia ceramic instead of a titanium alloy.\nWho can get zirconia dental implants?\nWell anyone can get a zirconia dental implant but the real question is who should get a zirconia dental implant. The answer depends on who you ask. The most likely candidate has one of several conditions or concerns. The most likely candidate is someone who has concern about the health or allergy issues of titanium dental implants. Another candidate is someone who has a high smile line, which means they show their gums when they smile, and they have thin tissue biotype, which means you can see through their gums.\nSuccess rates of zirconia dental implants\nTraditionally we find the success rate of zirconia dental implants v titanium dental implants is lower by about 5% Elnayef JOMI 2017. However, newer research is showing success rates similar to titanium. One of the main reasons for this is the decrease in fracture rates of the zirconia dental implants Roehling COIR 2018. Zirconia implants are almost always better for the soft tissue in research articles no matter how we traumatize the gums Roehling JOMI 2019. There are reasons to believe that zirconia is better in regards to peri-implantitis Siddiqui J Perio 2019.\nTitanium allergy and zirconia dental implants\nAlthough extremely rare the use and exposure of individuals to titanium will likely result in more people developing sensitivities if not outright allergies to the metal. A recent review of the literature indicates that titanium can induce hypersensitivity in susceptible patients and could play a critical role in implant failure. Siddiqi COIR 2011 An allergy to titanium was found in .6% of patients by Sicilia in COIR 2008. We currently believe zirconia, on the other hand, to be highly biocompatible, with no local or systemic effects.\nHow much do zirconia dental implants cost?\nWe have an entire post on the cost of zirconia dental implants. However, in brief form we can say that zirconia dental implants cost is typically slightly higher than titanium dental implants. The slight increase in fee is often because the doctor has taken on additional risk of failure if there is any kind of guarantee of the dental implant.\nWhat exactly do we make zirconia dental implants out of?\nA zirconia dental implant is a ceramic dental implant. The exact name of the material is yttria-tetragonal zirconia polycrystals (Y-TZP). On the positive side of things Y-TZP is white, highly bio-compatible, has great wear and corrosion resistance, and has low thermal conductivity. On the negative side of things Y-TZP has low temperature degradation, is brittle, and there are manufacturing and surface treatment imperfections.\nProblems with zirconia dental implants\nThere are several problems with zirconia dental implants that make them difficult to deal with for dentists and dental laboratories.\nFirst of all zirconia dental implants are often one piece.\nTitanium implants come with an implant body portion and then we later add an abutment that attaches to a crown. This allows for us to correct issues with depth and angle of existing bone. A one piece implant means that your bone and our placement need to be perfect for us to get a crown on the dental implant.\nThe crowns we do get on come off more easily.\nThis is primary due to the fact the implants are one piece. Since the top is stock, there is no customization to make ideal. Therefore if someone needs to prepare or cut the top back to fit a crown, they are also reducing what little we have to grab onto. This issue is seen below where the the dentist had to adjust the abutment portion of the zirconia implant and now the crown comes off more easily.\nZirconia dental implants lack the the history and research of titanium.\nZirconia dental implants do not have anywhere close to the amount of history and research that titanium dental implants do Afrashtehfar JPD 2020. Perhaps we do not know all the downsides to zirconia long term in the mouth yet.\nZirconia fractures more easily.\nThe reason why we make zirconia implants in one piece is because they are too fragile to handle forces the way titanium dental implants can. Zirconia fractures and when it does it can be difficult to remove the remaining pieces from your jaw."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:a0603fdb-d18a-4b54-aea7-c6c7e74fb8c7>","<urn:uuid:e89d9e72-ef00-4cf0-9843-5bf22b3d2ba1>"],"error":null}
{"question":"How do London's Transport for London (TfL) and San Antonio's 311SA differ in their approaches to data integration and user engagement?","answer":"TfL focuses on integrating transport data from various sources (TfL networks, mytaxi, Uber) to optimize journey planning and potentially generate profit through platform access for businesses. Their system aims to provide personalized routing options based on factors like speed, reliability, and environmental impact. In contrast, San Antonio's 311SA platform integrates with the city's customer relationship management system to handle service requests and builds community engagement through social media features. The 311SA app allows residents to propose new problem categories, build followings, and track issues shared by neighbors, achieving a 93% resolution rate for reported problems.","context":["Creating the smart cities of the future is high on the agenda for national governments, local councils, and innovative tech companies alike.\nTake London as an example. In the summer of 2018, Mayor Sadiq Khan launched Smarter London Together, a plan to make London “the smartest city in the world.” Smarter travel is set to be a huge part of this – and when you consider how much data Transport for London (TfL), mytaxi, Uber, and others hold about both their own networks and the movements of almost 2 billion annual passengers, it’s clear there are some exciting opportunities to be had.\nSome strides towards smarter travel have already been made. The TfL route planner, for example, allows users to optimize their journey with features like accessibility requirements or walking preferences in mind. Others, such as CityPlanner or Transit, do something similar, often via TfL’s APIs. But this could be pushed a lot further, and in ways that benefit not just travelers, but businesses, the environment, and transport providers’ profitability, too.\nComplicating matters further, a recent King’s College study showed Oxford Street to be the most polluted street in Europe, and a DEFRA report demonstrated that much of the pollution in central London is due to buses. And as for last-leg transportation (for those in a hurry or with luggage, or for the elderly and children), it isn’t always delivered by TfL; it’s often filled by Uber, taxis, and so on.\nSo, with all this in mind, what does a smarter future for London’s transport really look like – and what tools are needed to make this vision a reality?\nGreater choice and better flow for travelers\nThe tools users currently have to navigate London’s transport system are functional enough, but far from optimal. End users seem to be concerned with the obvious: price, accessibility, speed. But they are also interested in things like avoiding busy areas or traffic, not contributing to pollution, enjoying the weather, and aligning travel with their fitness goals.\nA holistic transport provider could crunch data on a cloud platform and develop truly intelligent route-mapping applications – and give users choice. The application could extend the purview of that journey to include the micro-journeys that can arise: a taxi back from the supermarket or a bus to take you directly to a large office. A new view of the journey starts to arise: a multi-modal one, where the passenger or traveler isn’t tied up with complexities about finding the nearest taxi stand or ensuring they have mobile signal to command an Uber.\nThere are multiple ways to answer: “What’s the best route for my journey?” Shortest in time, for sure. Most reliable or least traffic could be more useful for important journeys like hospital trips. An insurer might want to incentivize you to consider the least risky route, while your conscience might prefer the one that causes the least pollution. In all cases, it’d be nice to know what these answers are if we want to make informed decisions about our own travel.\nThis level of personalization and journey aggregation wouldn’t only create a better experience of moving through London, it would also improve traveler flow, facilitating smarter journeys with recommended stops along the way. This would benefit everyone from the tourist who wants the most scenic route back to their hotel to the office worker who needs to swing by a flower shop on their way home.\nCreating a greener, smarter city\nIn 2018, London hit its legal air pollution limit just one month into the new year. This figure speaks for itself, but as anybody who’s ever witnessed a horde of near-empty buses creep their way down Oxford Street will know, the city’s transport system is far from optimized. Having a robust platform in place to better analyze the flow of travel could play an invaluable part in minimizing unnecessary transport pollution and helping planners figure out exactly where and when the majority of people need to travel.\nAlthough the mayor has already introduced measures like charges for dirty vehicles entering the city, a smart-city platform could contribute further – both by optimizing public transport schedules to reduce needless journeys and by directing travelers to green transport alternatives, like Santander Cycles.\nAn opportunity for profit\nConsider the number of people traveling in and out of London each day – by plane, train, or tube. Providing seamless, end-to-end journeys on trips that start outside London isn’t easy, and given that travelers don’t have a great deal of choice, there’s relatively little impetus for providers to invest in a platform that can assist with this. But as the city’s population and numbers of visitors grow, access to this platform’s insights could be a hugely valuable resource for various private businesses and individuals. Which means a smart travel platform could actually generate profit for an organization like TfL.\nAirlines are a prime example of this. Passengers arriving into Heathrow may have planned to get the tube into the city. But a business professional who needs to make calls and get ready for a meeting during their journey into London may be left scrambling to find another route. Through integration with a smart platform, the airlines could offer push notifications through their apps with the opportunity to book a taxi or access shared minibus services – impressing their customers, improving their service, and smoothing the onward journey in one fell swoop. For the passenger, it’d be great to be able to miss out the taxi queue at T5 and jump straight into their pre-booked black cab or Uber car. No standing around in the cold. No hour spent underground without mobile signal. No issues trying to find a cashpoint.\nEqually, there’s sometimes little support for Londoners’ use of their own city. One of the more frenetic taxi stands in the city is at the Sainsbury’s in Angel, with people pilling into cabs, their arms bulging with purchases, as there is little or no other alternative for the many elderly in Islington who want to do their own shopping and take it home. It seems a pity that this kind of journey can’t be paid for by Oyster cards.\nAccess to the platform could even be bought by supermarkets, food chains, and restaurants around key transport hubs, allowing them to predict footfall and adjust their strategies accordingly. This kind of deal would be a significant commercial opportunity for ticketing providers such as TfL, so it’s certainly worth exploring. There’s also the possibility for providing subsidized local transport to job seekers and the homeless.\nEqually, such a strategy might help London re-evaluate the potential of river craft (especially for Canary Wharf / City journeys), incentivize cycle usage; and enable better timings and placings of services within and around stations.\nBuilding London’s smart future\nLondon’s smart-city future is a compelling prospect, and more intelligent travel should play a significant role in this. Because whether you’re a tourist, a commuter or an infrequent visitor to London, everybody ultimately wants the same thing: the most seamless end-to-end journey. Increasingly, as journeys are streamlined, it will be necessary for this platform to become more dynamic and responsive to real-time situations. “Take me home without a traffic jam” might become an interesting option on Waze or Google Maps.\nBut to deliver this, transport-providing organizations need to do more to invest in travel and transportation technologies that can help them build the relevant applications, whether that’s intelligent route mapping or a platform to provide data access for partner businesses. Without this innovation, London’s plans to become the world’s smartest city may well falter before they truly begin.\nFor more on smart-city technology, see How Future Cities Can Engage Citizens.","Emily Royall, Smart City Coordinator for the City of the San Antonio, spoke with Managing Editor Laura Benold about the city’s Smart 50 Award-winning project, 311SA, and what it means to be “smart”.\nLB: Let’s start off with the basics. Can you tell me about the 311SA project itself?\nER: 311SA transforms how the public connects with each other and the City of San Antonio on municipal services in our community. The platform shapes a new generation of discussion and action to resolve daily challenges related to the maintenance and care of our urban fabric.\n311SA is a radical departure from other 311 applications because it not only allows residents to flag and document issues, it also builds community around the resolution of those issues by allowing residents to propose new categories of problems, build a following through the social media environment, and track the issues their friends, neighbors and other residents share on a people-centric mobile interface. The application was built by a local technology company, CityFlag, and procured with the support of the city’s 311 department and the office of innovation.\nLB: How is the city kept accountable for request submitted through the app, and what prevents residents from being digitally neglected or ignored?\nER: The mobile app requests are not treated any differently than those that are processed when residents call the 311 customer service office. The mobile app is fully integrated with the city’s customer relationship management (CRM) system which serves as the intake system for services requests. The mobile app requests get submitted through the CRM system which then sends the request to the department to get addressed. The mobile app requests are not treated differently than requests coming in from the 311 call center or through the city’s website.\nLB: What themes have you noticed from engaged users? Are they demographically similar or different? Do they share common concerns?\nER: Since launch in August 2018, the focus has been mostly focused on responding to the issues identified by residents. Although we don’t collect personal information of users, we will be releasing aggregated 311 data to our entrepreneurial community to develop further insight and analysis through our CivTechSA initiative.\nLB: You have a resolution rate of 93%. What falls in the remaining 7%?\nER: The remaining 7% are issues that are still open and under investigation. The remaining items aren’t necessarily different from the 93%. Because the app is integrated with our CRM system, the cases remain open until they are closed. The status of the app is real time.\nLB: Was it simply the size of San Antonio at 1.5 million residents that prompted you to create this service, or was there something else that brought about your interest in reaching the community in this way?\nER: It’s true that San Antonio is a large, ever growing city. However, the spirit of this service is that we find innovative ways to connect to our public. 311SA is fun to use, it’s engaging, and it builds bridges between citizens and government.\nLB: What do you think San Antonio is currently known for? What do you want the city to be known for?\nER: “Puro” San Antonio is known for its rich history and cultural diversity. We are a city built by the confluence of many people along an ancient water source, the dynamics of which continue to play out in how our city grows physically and culturally.\nWe want our city to be known for celebrating that diversity and complexity by protecting, nurturing, and maintaining our urban landscape and the quality of life for our residents. We want to be known for pioneering a “community-first” smart city strategy, always keeping in focus how people actually live in our city.\nLB: How did you engage the community to the extent that they would adopt and use 311SA? What work are you still doing to educate the public?\nER: Our partner CityFlag helped get the word out about the application. At the official launch of 311SA, staff was on hand to train residents with how to use the application. The application is designed to be intuitive and user-friendly, which may have contributed to its wide popularity.\nLB: What does it mean to you to win a Smart 50 Award?\nER: It’s a huge honor for our smart cities team, our office, our partners CityFlag, and the 311 department at the City of San Antonio. For us, it means that we are on the right track with our smart city strategy that focuses on how to work collaboratively with our local entrepreneurship ecosystem to innovate smart city technologies that actually meet the needs of our residents. We’re so excited to continue developing our strategy in this space.\nLB: What’s next for the Department of Innovation in San Antonio?\nER: In 2019, with our SmartSA Partners (a consortium of local utilities and universities) we will launch our first round of RFPs in our three innovation zones — designated areas for prototyping smart city technologies. We will continue to evaluate the success of those prototypes hand-in-hand with our citizens, which will continue to rely on for feedback, ideas, and direction.\nWe will also be embarking on our third year of the CivTechSA program, that focuses on developing local technology talent by connecting entrepreneurs and students with city projects and challenges, in 2020. We will also be kickstarting the research and development arm of our office, that will support both internal and external process improvements. Finally, through our Metrolab partnership with local University of Texas at San Antonio (UTSA), we will focus on bringing to bear new research and solutions that bridge our city’s digital divide, among several other projects."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:18215f2f-a11d-40c6-8fff-643bacbd6ba9>","<urn:uuid:d4d9601c-5604-41d1-a392-6edd304ff704>"],"error":null}
{"question":"How do CRM Software and Human Resource Information Systems compare in terms of their data management capabilities?","answer":"CRM Software and HRIS both serve as database systems but handle different types of information. CRM Software consolidates customer documents and information into a single database for user access and management, automating workflow processes like alerts and calendars related to customer service. In contrast, HRIS is a systematic way of storing data and information for individual employees to aid planning, decision making, and submitting reports to external agencies. Both systems aim to improve organizational efficiency through centralized data management, but they focus on different stakeholder groups - customers versus employees.","context":["The first and most essential step of customer relationship management (CRM) is to understand what it means. It is defined as the strategies, practices, and technologies adopted by a company or an organization in the management and analysis of the customer interactions and the relevant data all across the customer life cycle (Tandon, Sharma, & Bhulal 2017, p. 59). The goals of CRM in an organization include improving the relationship between the company and the customers since it directly addresses the concerns of the customers. In doing this, it assists in improving the business relationship with the customers of the company. The resulting impact is a driven growth of sales for the company.\nIn most cases, CRM is designed with the aim of compiling information from customers’ organization channels. In other words, Fogleman (2013) donates that it is a point of contact between the company and the customers through direct emails, social media, websites, live chat, and marketing materials among others. CRM is adopted in three primary systems which include CRM Software, CRM Technology Market, and Cloud Solution.\nCRM Software- CRM software helps in consolidating the documents and information from the customers into a single database to enable users’ to access and manage the information. It is essential for the automation of various workflow processes within the organization such as alerts, calendars, and relevant tasks that are essential to customer service. It thus gives the management the ability to track performance as well as productivity by the customer information that has been logged into the system\nCloud-Solution-It is a cloud-based system that is adopted as a CRM to provide real-time customer or company data or information to sales agents both in the office. It becomes effective as long as the devices used are internet connected i.e. laptops, smartphones, tablets, etc. However, if the company faces off/goes out of business, the access of the information can be compromised.\nCRM Technology Market- Adopts the use of salesforce.com, SAP, Oracle, and Microsoft as the main vendors preferred by many companies. The technology unites the administration, security, maintenance, and control functions of the database and the company information. However, it resides on the server of the organization and adopts the use of cloud computing hence allowing access to information in a remote place.\nIn the adoption of CRM, there are many challenges experienced by the companies. Some of them include;\n- Difficulty in developing a ‘single view customer’ when different data sets are organized in a single dashboard.\n- Reduced customer experience as a result of poor handling of technical support and long wait times on phone calls\n- Duplicate or outdated information slows down the data processing.\nAdopting CRM in the organization has many benefits i.e. enables easy management of customer information, improves business relationship with the customers, and enables a company to retain the existing customers. Namhee and McLean (2014) also denote that adopting proper CRM in a company increases sales due to increase in the customers through better services\nEffective and satisfactory customer service requires an organization to adopt proper customer service strategy. CRM enables the company to have a proper management of customer service and provide information in an easy way that can be interpreted and understood by the company workforce and the customers. Studying this topic is hence essential in gaining the relevant skills and knowledge in effective customer service management.\nFogleman, D 2013, 'Customer Service', Training, 50, 2, pp. 44-45, Business Source Premier, EBSCOhost, viewed 14 August 2017.\nNamhee, K, & McLean, G 2014, 'Customer Service Behaviours in Korea and Implications for Training: Lessons from an Exploratory Critical Incidents Study of Customer and Employee Service Encounters', Asia Pacific Business Review, 13, 1, pp. 1-20, Business Source Premier, EBSCOhost, viewed 14 August 2017.\nTandon, M, Sharma, N, & Bhulal, V 2017, 'The Impact of Customer Relationship Management and its Significant Relationship to Customers' Satisfaction in Cooperative Banking: (A Case Study of Kangra Central Co-operative Bank)', Global Journal Of Enterprise Information System, 9, 2, pp. 59-66, Business Source Premier, EBSCOhost, viewed 14 August 2017.","Human resource development hris human resource information system executive summary: human resource is the part of the organization dealing with the employees it starts with selecting the employees, recruiting the employees, training the new joiners and engaging the existing employees in a continuous process of training and knowledge gaining. Android mobile using human resources system information technology essay chapter – 1: introduction topic of the system after observing the existing situation under project background, it is being aimed to do develop a mobile application for an organization. Human resource information system (hris) is a systematic way of storing data and information for each individual employee to aid planning, decision making, and submitting of returns and reports to the external agencies. Human resource information systems - introduction human resource information systems (hris) can provide an organization a wide variety of functionalities that improve the productivity of the hr department while supporting the desires and requirements of the rest of the organization. The human resource information systems information technology essay the human resource information systems is introduced by presenting the various definitions, development, costs and benefits, as well as their functions and relationship with hrm.\nThe rapidly transforming business landscape means that there are currently many human resource management challenges which will continue to evolve for years to come. Human resource information system (hris): important and emerging opportunities and challenges in the business horizons suggest that ,”it is not technology . A human resource management system or human resource information system (hris) or hr system is the systems and processes between human resource management (hrm) and information technology (it) hrm is a discipline which blends its basic hr functions and processes with the information technology. Impact of information technology in human resources management dr seyni mamoudou, phd management’s support of the hr information systems application,.\nToday, the field of human resource management (hr) is experiencing numerous pressures for change shifts in the economy, globalization, domestic diversity, and technology have created new demands for organizations, and propelled the field in some completely new directions. Human resource management essay of technology generated challenges correspondent to the pay levels of staff as well as within the information transformation . Explain what a human resources information system (hris) does, and identify its main components chapter 3 human resources management and technology 51.\nResource planning (erp) systems erp systems are an information technology (it) infrastructure that facilitate the flow of information between all supply chain processes in. The human resource information system (hris) is a software or online solution for the data entry, data tracking, and data information needs of the human resources, payroll, management, and accounting functions within a business. The emerging challenges in hrm human resource information system that they can overcome information technology challenges 7 proper performance evaluation . Essay # 1 meaning of human resources: by the term human resources we mean the size of population of a country along-with its efficiency, educational qualities, productivity, organisational abilities and farsightedness.\nDescribe the various challenges that or human resource information system, is a solution for the challenges of information technology in management the human- side of leadership | switch & shift. Some of the common types of management information systems include process control systems, human resource management systems, sales and marketing systems, inventory control systems, office automation systems, enterprise resource planning systems, accounting and finance systems and management reporting systems. Providing employee training on how to secure data and prevent privacy breaches to keep business information secure are challenges human resources faces in this area.\nA study of issues & challenges of implementation of information technology 437 4 literature review 41 the paradigm shift information technology has greatly impacted the human resource management. This paper will highlight on how a hr manager can meet the challenges of workplace diversity, how to motivate employees through gain-sharing and executive information system through proper planning, organizing, leading and controlling their human resources. Human resource information systems the purpose of this paper is to identify other companies who have faced similar human resources issues in regards to information technology through benchmarking different companies, we can learn how other companies have handled certain human resources issues related to information technology, information .\nChallenges to human resource management since the 1990’s many public sector managers have begun to address the daunting issue of upgrading their legacy human resource information systems to. The human resource management review (hrmr) is a quarterly academic journal devoted to the publication of scholarly conceptual/theoretical articles. Impact of globalization on human resource management need to take advantage of technology and data analytics to build a global human resource information system . Human resource information systems (hriss) have the potential to improve organizational efficiency and effectiveness by facilitating workforce planning ."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:2ec5ba2b-6f74-4026-84eb-85be1c105cf1>","<urn:uuid:eb424396-03ce-4483-8f6c-9f1bb7cba41d>"],"error":null}
{"question":"What's the transformation process like for converting old industrial spaces into cultural venues, and what technical challenges come up with soundproofing these renovated buildings?","answer":"The transformation of industrial spaces into cultural venues involves multiple stages. In Beijing's case, it started with clearing unauthorized buildings and reorganizing spaces to create multi-layered courtyards. The process involves preserving historical elements while adding modern features - like exposing original brick walls while incorporating new materials such as weathering steel and reinforced concrete. For soundproofing challenges, as demonstrated in Pearl Street Warehouse's case, it requires extensive technical planning including noise spectrum modeling, specialized wall and ceiling constructions, and careful consideration of sound transmission through building materials. The acoustical design must account for both interior sound quality and noise impact on surrounding spaces. This involves computer modeling to determine optimal acoustical treatment placement and materials, while ensuring compliance with various noise regulations.","context":["- Architect In Charge : Li Ji\n- Design Team : Zhang Hui, Lian Hui, Wang Jing\n- City : Beijing\n- Country : China\nText description provided by the architects. Different from the grand factories of elite German descent in 798, Beijing Offset Printing Factory, nestling in the backstreet of Art Gallery, is more like an industrialized courtyard with a scent of civil life in Beijing Hutongs. Built in 1960s, 1970s and 1990s respectively, the industrial buildings have different histories. They look nothing special except the higher storey height. But once upon a time, there was a secluded yard boxed in the enclosures.\nUnfortunately during half century of trials and hardships, the original industries declined and shut down one after another; the factories were also dilapidated day by day almost beyond all recognition. The pipe lines are now aging and bare; the idle workshops are separated and rent disorderly. The unordered addition jams the whole factory area and makes it a genuine warren. The integral reformation combining drama culture and functional replacement is in the hope of bringing a new vitality to the waste urban body.\nRespecting for the specific historical emotions of the courtyard, the hitting-point of the transformation strategy is to extend the accumulation of various industrial cultures, awake and arouse its inner vitality.\nStarting with targeted local excision, the addition part which causes the overall blocking will be cleared: in the east, eliminate the unauthorized temporary buildings and remove the disorder parking to make room for a quiet front yard; in the west, demolish the crude tin room attached between the two major structures to form a backyard; further clean up the blocked Hutongs on both sides and link them up from back to front, thus a multi-layered courtyard space and alleys will be brought to light again.\nActivation/ Development/ 3-D\nStreets Breaking through the shackles of original structures, a unique space traveling system is leading the free and stereoscopic flowing growth of the initial traditional yards and alleys: some climb up circuitously from the ground courtyard to the roof garden; some fly crosswise from one house to another to form an air corridor; some straightly break into the room or underground and bring the sunshine, the air and the refreshing nature inside. There will not be only route any more. Traffic moving lines will evolve into irregular three-dimensional garden trails, which brought along interaction between indoor and outdoor space and scenery.\nThe unreachable and isolated inactive roofs in the factory are totally activated by the verandas and becoming well-proportioned floating hanging gardens. The different heights, landscape experiences and arrival patterns of each garden form a flow of scenery in the stereoscopic alleys. Making up the shortfall of the limited ground space, the hanging gardens everywhere provide opportunity of closing to the nature for every internal unit. Moreover, the communication place for relax and encounter will bring creative inspirations. After breaking the rigid space, the diversity of environmental settlement will grow into the most suitable place for the ecological development of cultural creativity.\nMost of the plants were initiated in the early 1970s. After repeated temporary renewal paintings, the true features of the walls had been covered layer upon layer. Now being polished layer by layer, the decorative cover is carefully removed. Thus the buried historical truth is able to come to light again. Built in the Cultural Revolution period, the brick walls are now exposed with their uneven texture and coarse construction. Meanwhile the flavor and memory of the special times are transmitted frankly. Although not very perfect, the antiques have it all over the fake decorated forgeries and deserve respects for their dignity.\nOn the old walls, a series of interventions are exposed deliberately without any dissimulation in people’s sight. Being renovated with different techniques, some holes have sharp cutting marks and others are rough and unfinished with the remaining trail of chisels. Old brick walls of different ages with scrapes and marks, reinforced concrete walls processed by clinging and casting, embedded steel beams, simple and clean glasses, all these crafts and materials of different eras are distinctively combined together. Just like the steel nails used in staple china art, the new and old are combined to manifest the change of times.\nContrary to the current architectural concept which is becoming finer day by day, materials and techniques with low precision and more direct construction methods are adopted during the renovation. Preserving the original shape and specification of steels, removing all unnecessary processes and decorations, the integrality and independence of every piece of material can be protected. The joint constructions are made as simple and direct as possible to reveal the beauty of power and essence. The weathering steel, naturally mottled and rusted as time goes on, is now talking with the surrounding old brick walls in a whisper. The new buildings have become integrated with the overall historical atmosphere. Therefore the deep industrial temperament of the factory can be further strengthened with its cohesion power.\nIf the veranda system can be considered as the artery of the garden, then the warehouse theatre is the garden’s heart, the fountain of vitality and charm. The theatre is newly constructed on the former address of dilapidated buildings. Adopting the architectural structure of industrial warehouse, massive I-column steel and Corten steel panel, the massive industrial space of the warehouse strongly contrasts the fashion and living drama scenes. When the night falls, when a shocking scene opens, the warehouse theatre walls toward the courtyard will be hung up slowly with the internal lightening and popularity gushed out.\nThe drama and cultural life are no longer limited in a fixed space. Vitality is spreading everywhere in the garden. The front yard becomes an outdoor theatre without boundary; the alleys become joint channels; the roofs and verandas are changed to air stages and stands; the terraces on the old brick houses become boxes… The gap between actors and audiences is eliminated; the estrangement between culture and life is vanishing. The whole garden becomes an omnipresent open theatre and then integrated with the comprehensive city life.","Pearl Street Warehouse is a live music venue located at District Wharf in Washington, D.C. In the design phase of the project, there were many aspects of its proposed use that needed to be considered. Not only did the interior environment need to be suitable for live music, but also noise impact upon the adjacent uses needed to be controlled. Located directly above the music venue is a hotel and across the alley way are condominium units. Additionally, there is commercial tenant space located adjacent to the venue.\nRegarding its impact upon surrounding properties, this project needed to achieve compliance with the noise and vibration requirements within the lease language as well as with the District of Columbia Municipal Regulations (DCMR) and Alcoholic Beverage Regulation Administration (ABRA). Achieving compliance with all three regulatory bodies increases the difficulty of the design and the associated cost of the project.\nPhoenix Noise & Vibration’s involvement with the project began at the design phase, as the building in which Pearl Street Warehouse is located was still under construction. The client’s vision for the venue was discussed to determine the type of music environment that would be suitable for its use. With an understanding of the intended use of the space, we were able to propose design solutions appropriate for the venue’s application.\nOne of the first steps was to determine the level of mitigation required by the venue’s demising wall and ceiling partitions to provide compliance with the regulatory requirements. This was completed by using noise spectrum data from multiple music noise sources and modeling the sound transmission loss data of various wall and ceiling constructions to determine the resulting level of noise reduction within the adjacent spaces. Based upon the modeled noise levels within the adjacent spaces, specialized wall partition and ceiling construction techniques were specified for the venue. The construction incorporated acoustical products that are not commonly found in typical partition construction.\nRecommendations were also provided for the exterior of the venue, as part of the design was to have large glass garage doors that open to the alley walkway located between the two buildings.\nAs noted above, the building was under construction at the time of the design. Therefore, critical reverberation time (RT) measurements could not be made within the venue’s proposed space. Alternatively, to determine the amount of acoustical treatment required within the space for a live music environment, a computer model was developed to simulate the Pearl Street Warehouse’s surfaces, architectural features, and resulting acoustical environment.\nThe model started with the “as designed” condition which included acoustical treatment in the drawings and specifications. The computer model determined that the specified amount of treatment was actually more than necessary, resulting in a materials cost savings. The model also determined that some of the treatment would be more effective if it were redistributed on other surfaces. Multiple factors must be considered when applying acoustical treatment to a space, which requires an understanding of the space’s use and its occupants. Phoenix Noise & Vibration used all of this information in combination with the acoustical modeling to produce an optimized acoustical design.\nPearl Street Warehouse is currently hosting a variety of music acts with frequent nightly performances. The venue is one of the more popular attractions in the District Wharf waterfront area. Due to design considerations in the early phase of the project, the venue has been able to operate as intended for both Warehouse patrons and Warehouse neighbors. Properly planning for all acoustic considerations, not only within the space but also to the surrounding spaces, provides an acoustic environment appropriate for the space’s use and helps minimize future risks associated with operation."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"sensitive"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:3381b6d1-947b-4721-bce2-a357aff58b68>","<urn:uuid:b3f3d60f-7e46-43df-a090-99907df5172a>"],"error":null}
{"question":"What's the scoring system like in figure skating competitions, and how do physical fitness levels impact a skater's artistic scores? ⛸️","answer":"The scoring system, called the International Judging System (IJS), evaluates both technical elements and program components. Technical elements have base values according to difficulty levels, while program components assess artistic qualities like skating skills, transitions, performance, composition, and interpretation. Studies have shown that skaters who supplement their artistic training with strength and conditioning programs, thereby improving their fitness levels, score significantly higher in aesthetic competency assessments and generally perform at higher competitive levels. The improved fitness helps them better display controlled movements, spatial skills, accuracy, technique, timing, and overall performance quality.","context":["Axel: A forward-facing jump invented by Norwegian Axel Paulson in 1882. The Axel is the only jump in which skaters take off from a forward outside edge. The skater rotates one-and-a-half times in the air – two-and-a-half times for a double, and so on – before landing on the back outside edge of the opposite foot from which they took off.\nBase Value: Every element has a certain base value according to its level of difficulty. These values are listed in a table called the Scale of Values (SOV). Base values for jumps are straightforward and pre-determined based on the difficulty of the jump and number of revolutions. For example, a triple Axel (8.5 points) is worth more than the less difficult double Axel (3.3 points). Non-jump elements, such as spins and step sequences are assigned a level – between one and four – based on their difficulty. Level one elements receive a lower base value than level four elements.\nBiellmann Spin: A variety of upright spin named for former Swiss skater Denise Biellmann, this spin requires exceptional flexibility of the back and legs, and is performed almost exclusively by women. (Yuzuru Hanyu is one notable exception.) Standing in an upright position, the skater reaches behind his/her shoulders and grabs onto the skate blade of the free leg. The free leg then reaches up towards the ceiling, so the skater rotates while standing upright in a kind of reverse split position.\nCamel Spin: The skater spins on one leg with the free leg extended in the air, parallel to the ice.\nChoreographic sequence: The choreographic sequence consists of any kind of movements such as steps, turns, spirals, arabesques, spread eagles, Ina Bauers, hydroblading, transitional (unlisted) jumps, spinning movements, etc. The pattern is not restricted, but the sequence must fully utilize the ice surface and is a required element of the free skate in men's and ladies' singles.\nCode of Points: The \"code\" is the set of technical regulations for skaters detailing how much certain elements and variations of elements are worth (see \"Scale of Values\").\nCombination Spin: The skater changes positions while maintaining speed and a continuous spin (may or may not include a change of foot).\nComposition: One of the five program components; defined as: an intentional, developed and/or original arrangement of all types of movements according to the principals of proportion, unity, space, pattern, structure and phrasing.\nConnecting Steps: Skating moves such as turns, spirals, arabesques, spread eagles, Ina Bauers and any other flowing steps with strong edges can be characterized as connecting steps.\nCostume: Figure skaters select outfits that match the style of their programs and the mood of their music. Ladies can wear a skirt or pants and men must wear full-length trousers, but not tights. Accessories, props and apparel that gives \"the effect of excessive nudity\" are not allowed.\nCrossovers: Foot movement in which the skater crosses one foot over the other in order to gain speed and turn corners. This step can be done forwards and backwards.\nDeath Spiral: A pair spin in which the man stands as the anchor in a pivot position while holding his partner's hand as she spins, body extended low and parallel to the ice, around him.\nDeduction: Points subtracted from the total score. Deductions can be applied for a time violation, an extra/illegal element, a costume/prop violation, or a fall, among other things.\nDouble Jump: A jump in which the skater completes two revolutions in the air (except in the case of the double Axel, in which the skater actually completes two-and-a-half revolutions).\nDraw: The starting order for each event in a figure skating competition is determined by a lottery or “draw.” Either the referee or chair of the competition conducts the process in the presence of other judges (closed draw) or in an open setting where the athletes actually draw a number from a pouch (open draw).\nEdge: The two edges of the skate blade are on either side of the grooved center. The inside edge is the one on the inner side of the leg and the outside edge is on the outside of the leg.\nEdge Jump: In an edge jump, a skater takes off from the entry edge of the skating (takeoff) foot without bringing the free foot into contact with the ice to assist the takeoff. The three edge jumps are the Axel, loop and Salchow.\nFall: Under the current rules, a fall is defined as the “loss of control by a skater with the result that the majority of his/her own body weight is on the ice supported by any other part of the body other than the blades, e.g. hand(s), knee(s), back, buttock(s) or any part of the arm.”\nFlip: A toe-assisted jump in which the skater takes off from the back inside edge of one foot and lands on the back outside edge of the opposite foot.\nFlutz: \"Flutz\" is an unofficial term for a common mistake made by skaters attempting the Lutz jump. A Lutz is \"flutzed\" when a skater switches from a back outside edge to an inside edge right before takeoff.\nFlying Spin: A spin with a jumping entry. For example, in a flying sit spin, the skater leaps upwards and assumes a sitting position at the peak of the jump before landing in a similar sitting position on the ice and performing a sit spin.\nFootwork: See \"step sequence.\"\nFree Dance: The second of the two phases of an ice dancing competition is the free dance. Relatively unrestricted, the skaters select the mood and tempo of their music and are allowed four minutes (plus or minus 10 seconds) to display their full range of technical skills, interpretation and inventiveness.\nFree Skate: Skated after the short program, the free skate is the second and final segment of the singles and pairs events. The ladies’ free skate lasts between 3:50 – 4:10 minutes; the men’s and pairs’ free skates last between 4:20 – 4:40 minutes. Also known informally as the long program.\nGrade of Execution (GOE): The score, ranging from -3 to +3, that each member of the judging panel awards for each technical element performed by the skater(s).\nInternational Judging System (IJS): Also referred to as the \"Code of Points,\" the current judging system replaced the old 6.0 judging system with a cumulative points system. Ordinals and the ranking of skaters against each other was eliminated in this system. It was first implemented on the Grand Prix circuit for the 2003-04 season, and was used at all ISU championship events during the 2004-05 season. 2006 marked the first time the Olympic Games used the Code of Points system.\nInternational Skating Union (ISU): The official governing body of figure skating. The ISU is responsible for the training and certification of judges and determines the rules of competition.\nInterpretation: One of the five program components; defined as: the personal and creative translation of the music to movement on ice.\nJudging Panel: Judges are the officials who award grades of execution (GOEs) for each element, as well as scores for the five program components. The judging panel consists of nine judges and a referee (in charge of the judges). In any given competition segment, seven of the nine judges’ scores are selected to count towards the result.\nJump Combination: Two jumps performed in an immediate and consecutive order. In a jump combination, the second jump takes off from the same foot on which the first jump was landed. The skater must not change feet or turn between the two jumps.\nJump Sequence: A jump sequence is a series of two or more jumps linked by hops, unlisted jumps, steps and turns immediately following each other; the jumps are connected more loosely than the jumps in a jump combination. There cannot be more than one revolution on the ice between any hop or jump. The sequence must have a constant rhythm and must not contain crossovers.\nLayback Spin: Usually performed by women, the skater spins in an upright position. As the speed of the spin increases, she drops her head and shoulders backwards, arching her back. Skaters often display a few different arm and free leg positions during the layback.\nLevel: Non-jump elements, such as spins and step sequences are assigned a level – between one and four – based on their difficulty. Level one elements receive a lower base value than level four elements.\nLift: Some of the most exciting elements in pairs and ice dance, lifts involve the hoisting of the female partner above the head of the male partner. There are several different types of lifts, differentiated according to style of entry and the position and hand holds of the pair during the lift.\nLine: A skater's carriage and position relative to the ice. The term also is used in ballet and dance.\nLong Program: See “free skate.”\nLoop: A jump in which skaters take off of a back outside edge and land on the same edge of the same foot.\nLutz: This toe-pick-assisted jump is named after its Austrian inventor, Alois Lutz, who first performed it in 1913. Skating backwards on an expansive curve, the athletes take off from a back outside edge, anchoring the toe pick into the ice and rotating in the opposite direction of the curve before landing on the back outside edge of the foot opposite to the launching foot.\nMirror Skating: Opposite movements performed by pair skaters in close proximity to one another.\nPerformance: One of the five program components; defined as: the involvement of the skater/couple/teams physically, emotionally and intellectually as they translate the intent of the music and choreography.\nProgram Components: The components that represent the overall presentation and artistic quality of a skating performance are known as the program components. There are five program components: skating skills, transitions, performance, composition and interpretation.\nProgram Components Score (PCS): The scores (between 0.25 and 10) for each of the five program components are each multiplied by a factor and then summed. The result is the program components score, which is more precisely referred to as the factored program components score. Also known informally as the second mark.\nQuadruple Jump: A jump in which the skater completes four revolutions in the air. The two \"quads\" that men most frequently attempt are the quadruple toe loop and the quadruple Salchow – these were the only two that were attempted at the last Olympics. Now, every quad except the Axel has been done successfully. The only quadruple jump ever landed successfully by a woman in international competition is the quad Salchow.\nReferee: The referee manages the judging panel and is in charge of the overall event. Among the referee's responsibilities: conducting the draw, timing the skating performances, determining certain deductions (including music violations), monitoring ice conditions and supervising the conduct of the competitors.\nSalchow: Edge jump named after Sweden’s Ulrich Salchow, 10-time world champion from 1901 through 1911. Skaters take off from the back inside edge of one foot and land on the back outside edge of the opposite foot.\nScratch Spin: A type of upright spin, the scratch spin begins on a back inside edge. The free leg is extended in front of the body with the thigh raised, and the arms are up and out to the side. Bringing the free leg down and drawing the arms closer to the body accelerates the spin. Skaters achieve the highest number of revolutions per minute in the scratch spin.\nShadow Skating: Identical movements performed by pairs skaters in close proximity to one another.\nShort Dance: The first segment of the ice dance event. Running two minutes and 50 seconds (plus or minus ten seconds), the couple must perform a predesignated pattern dance as well as skate to a predesignated rhythm (although they select the music).\nShort Program: The first segment of the singles’ and pairs’ events. Running two minutes and 40 seconds (plus or minus 10 seconds), during which skaters must execute seven required elements. The free skate follows.\nSide-by-Side Jumps: Side-by-side jumps (also sometimes referred to as solo jumps) are a pairs element in which the partners perform a jump, jump combination or jump sequence, in unison, next to each other.\nSingle Jump: A jump in which the skater completes one revolution in the air (except in the case of the single Axel, in which the skater actually completes one-and-a-half revolutions).\nSit Spin: A spin performed in a sitting position. Low to the ice, the skater spins with one leg bent and the other leg extended beside it.\nSkating Skills: One of the five program components; defined as overall skating quality: edge control and flow over the ice surface demonstrated by a command of the skating vocabulary (edges, steps, turns, etc.), the clarity of technique and the use of effortless power to accelerate and vary speed.\nSpiral: A move in which the skater extends his or her free leg behind him or her during a long glide to demonstrate both flexibility and fluidity, often included in the choreographic sequence of a program.\nStarting Order: The result of the draw, the starting order lists the sequence in which skaters will compete and the groups they will warm up with prior to competition.\nStep Sequence: A choreographed series of steps in sync with the music, performed across the ice in straight, circular or serpentine movements to demonstrate a skater's precision and agility. Also known as “footwork.”\nStroking: A maneuver used to gain speed. Skaters push forward from one inside edge to the other inside edge.\nTechnical Controller: The technical controller is the leader of the technical panel. This official supports the technical specialist and ensures that any potential mistakes in the \"calling\" process are corrected immediately.\nTechnical Elements: Any specific, definable skill, such as a jump, spin, lift or throw, is a technical element.\nTechnical Panel: The technical panel consists of five officials - the technical controller, the technical specialist, the assistant technical specialist, the data operator and the video replay operator - who run the judging system at a competition. The technical panel is responsible for identifying all elements and levels during a program.\nTechnical Specialist: The technical specialist is the official who identifies, or \"calls\" the elements that a skater performs.\nThrow Jump: A maneuver in pair skating in which the male throws his partner in the air, and she lands unassisted on a backward outside edge.\nToe Jump: Skaters use their free foot to \"pick\" into the ice and help propel themselves upwards. The three toe jumps are the flip, Lutz and toe loop.\nToe Loop: A toe-assisted jump in which the skater takes off and lands on the same back edge of the skate.\nToe Pick: The teeth-like ridge at the front of the blade used for spinning and jumping.\nTotal Element Score (TES): The sum of the judging panel's scores for each individual element performed during a program is the total element score.\nTotal Segment Score (TSS): A skater, pair or couple's total score for one particular segment of competition (e.g. short program, free skate) is referred to as the total segment score. The total segment score is determined by adding the total element score (TES) to the factored program component score (PCS) and subtracting any deductions.\nTransitions: One of the five program components; defined as: the varied and or intricate footwork, positions, movements and holds that link all elements. This also includes the entrances and exits of technical elements.\nTriple Jump: A jump in which the skater completes three revolutions in the air (except in the case of the triple Axel, in which the skater actually completes three-and-a-half revolutions).\nTwist Lift: A maneuver in pair skating in which the male throws his partner into the air and catches her after she has performed one, two, three, or four revolutions. He then places her back onto the ice.\nTwizzle: This is one of the most easily identifiable moves in ice dancing. Twizzles are a series of turns on one foot. The skaters perform the rotations quickly with a continuous action, side by side, preferably close to each other on the ice (though not touching). The weight remains on the skating foot, with the free foot in any position during the turn.\nUpright Spin: This spin can be performed forwards or backwards. The skater spins in an upright (standing) position with the free foot positioned next to the skating foot.\nWaltz Jump: From an outside edge, the skater takes off and completes a half-revolution in the air. He or she lands on the back outside edge of the opposite foot. This jump is not usually performed in competition.","Why strength & conditioning is important for artistic athletesSeptember 28, 2018 | by Jermaine John-Archer, Strength & Conditioning Coach and ArtisticSTRONG Coordinator\nArtistic athletes compete in sports that are subjectively judged in technical skills and sport specific creative elements (e.g., dancers, figure skaters, synchronized swimmers, artistic gymnastics, etc.). At the elite level, artistic athletes may train multiple hours a day, 5-7 days a week, all year round to stay competitive in their sport.\nWhy is adding a strength & conditioning practice important? Here are three topics for clubs, coaches, parents, and artistic athletes to discuss when considering the importance of strength & conditioning.\nEARLY SPORT SPECIALIZATION\nEarly sport specialization is focusing all efforts on a single sport from a young age. Research has shown that this can pose many risks for youth athletes including injury, social pressure, anxiety, burnout, and more.\nBeing exposed to various activities helps young athletes develop fundamental movement skills and physical literacy (the motivation, confidence, and physical competence across a wide range of activities). Sport diversification also exposes our youth to different and fun activities that can boost psychological morale and social interaction.\nWith such strong evidence promoting sport diversification, why is early sport specialization so prevalent? In all fairness, some sports don’t have the luxury to wait. Artistic sports may require early specialization because peak performance can occur before full physical maturation3.\nFor example, Alina Zagitova won Olympic gold at this past Pyeongchang Winter 2018 Games at 15 years old and began skating at the age of 4.\nHow then do artistic sports manage their athletes for both excellence in performance and longevity in sport?\nWith proper guidance from a qualified strength & conditioning coach, athletes can limit the negative effects of early sport specialization. Coaches can create customized training plans that take into account an athlete’s age, maturity, and sport needs. This is accomplished through regular testing, following a sport-specific Long-Term Athlete Development (LTAD) plan, using training periodization, and by tracking development and growth trends.\nSPECIFIC ATHLETIC DEMANDS\nThere are a number of sport demands, physically and mentally, that are unique to the artistic athlete. A proper strength & conditioning program can support an athlete in meeting these demands, to optimize performance and reduce injury risk.\n1. Biomechanical demands: Spinning & Jumping\nArtistic athletes are expected to perform unique movements that put a large degree of stress on the body. A number of coordinated muscle groups (i.e., hips, legs, arms, and core) control extreme spins and jumps at high velocities 4,10. Spins and jump rotations also add up to 2-300 pounds of centrifugal force when holding the arms and legs in position4.\nSubsequently, the landing force from a jump can be 8-14 times an athlete’s body weight4.\nSpins and jumps are complex movements that require coordination, control, strength, speed, and power. With regular performance testing to guide programming, coaches will teach movement coordination and control, help athletes build foundational positional strength, and expose artistic athletes to tools that will enhance their ability to drive into the air and land while attenuating extreme forces.\n2. Energy Systems\nArtistic athletes use their bodies as “instruments of expression” and most movements and technical skills require enhanced fitness levels as well as artistry1. A vaulting gymnast may explode from the floor and vault in a single bout, using energy requirements similar to a 100-meter sprinter. A figure skater will be quite different, using supramaximal effort in a cold environment with energy demands equivalent to an 800-meter runner4.\nDuring a 4-minute program, fatigue levels of elite figure skaters can be similar to those of a post-race long distance runner4. What about the demands of a dancer during an hour-long performance?\nWith varying performance durations come multiple energy system exchanges. Energy systems do not simply take turns. Instead, all systems will simultaneously function, and as one system predominates, the others participate to varying degrees5. Incorporating exercise physiology testing into a strength & conditioning plan will help evaluate an athlete’s energy needs and correlate them with the demands of their artistic sport. Knowing when to peak which energy system at what time, based on the periodized Yearly Training Plan (YTP), proves purposeful when training athletes for specific performances and competitions.\n3. Artistic Competency\nAesthetic competence is as an artistic athlete’s ability to display controlled movements, spatial skills, accuracy of movements, technique, dynamics, timing, rhythmic accuracy, performance qualities, and overall performance.\nBy addressing variance and competency in supplemental training, better programs are designed to challenge athletes that promote injury prevention without adversely affecting sport specific movements and artistry. Studies have shown that artistic athletes that supplement their artistic training with strength & conditioning programs, and have subsequently improved their fitness levels, scored significantly higher in aesthetic competency assessments and generally perform and compete at higher levels10.\n4. Psychology & Body Image\nAs a past dancer and current exercise physiologist & strength coach, I’ve experienced and seen the varying aesthetic needs of artistic athletes. The constant worry about body image is an awful and overbearing threat to an artistic athlete’s health, both physically and psychologically.\nAs it pertains to strength & conditioning, the myth that supplemental training will make an artistic athlete “bulky” is well inflated. There are countless training platforms, each one yielding different neurological and physiological adaptations.\nAn exercise physiologist and/or strength & conditioning coach will specifically program to the desired adaption (e.g., strength, speed, power, etc.), which may or may not include lean muscle mass goals depending on sport needs. They will work with the athlete, coach, sport organization, and parents to communicate mutual interests and to involve everyone in the decision making process.\n5. Joint Integrity: Mobility and Stability\nArtistic athletes can be known for their extreme ranges of motion. Having supple muscles gives athletes that specific aesthetic stretch needed for artistic presentation.\nWhen having difficulty reaching the end range of some of these positions, artistic athletes might choose movement strategies that are not ideal for joint health. Strength and conditioning sessions will incorporate proper mobility and stability work to improve end range of motion strength and joint integrity, all while preventing injuries and keeping the aesthetic nature of artistic sports.\nAs mentioned above, injury risk is typically higher in early specialized sports, such as most artistic sports. Participating in a single sport for more than eight months per year appears to be an important factor in the increased injury risk observed in highly specialized athletes.\nThere are a few causes for this phenomenon:\n- Practicing one sport generally leads to one way of moving on the same surface – this stresses the same tissues repetitively and can lead to micro trauma over time\n- Repetitive tissue loading in high volumes creates high demands on joints in a young changing body (i.e., during puberty) – this can lead to a breakdown of tissues\nA quick tip in preventing overuse injuries: listen to the warning signs and be assessed by an exercise physiologist or strength & conditioning coach (or see an allied health professional if you’re already in pain).\nWork with a qualified exercise specialist to incorporate movement variations at an appropriate time in your YTP; test regularly, track growth and development, use a “coach’s eye” to assess daily movement quality, and expose artistic athletes to fundamental movements skills (especially outside of the repetitive movements they may be familiar with).\nWith longevity at its core, part of a structured supplemental training program should also involve recovery strategies to prime the body and energy systems for the following days’ practice/rehearsal, performance, or competition. Exercise physiologists and strength & conditioning coaches will strategically structure an athlete’s YTP to include (but are not limited to):\n- aerobic conditioning within a targeted heart rate zone for a purposeful cool-down\n- planned de-load weeks between blocks of training that include general preparatory exercises and circuits to prevent staleness and overtraining\n- contralateral circuits to prime movements and energy systems for greater performance outcomes in the following week\n- breathing techniques, mindfulness, and meditation\n- corrective exercises to balance full-body locomotion and mobility-stability deficits\n- re-lengthening through dynamic and/or static stretching and SMR (self-myofascial release)\nIMPORTANT TRAINING CONSIDERATIONS\nWhen seeking supplementary strength & conditioning programs, it’s important to work with a certified exercise physiologist and/or a strength & conditioning specialist, preferably with a background in artistic sports performance. The design of any resistance training program must be specific to the artistic sport.\nAthletes are much more likely to be passionate about their training if they understand why they are training and what the expected outcomes may be. Motivation to keep training comes from educating athletes about the importance of strength & conditioning. Education should be given in reference to injury prevention and improved performance to create longevity within their athletic career, as well as for an active life after sport.\nThe ArtisticSTRONG program at Fortius Sport & Health complements sport specific training along a developing athlete model to improve performance, prevent injuries, and boost motivation through movement competency and confidence.\n1. Anioi, M. (2014) Fitter Dancers Dance Better – The Effects of Supplementary Fitness Training in Contemporary Dance. The IADMS Bulletin for Dancers and Teachers. 5(1): 7-8\n2. Behncke, L. (2004) Mental Skills Training for Sports: A Brief Review. Athletic Insight – The Online Journal of Sports Psychology. 6(1): 1-19\n3. Brenner, J.S. and AAP Council on Sports Medicine and Fitness (2016) Sport Specialization and Intensive Training in Young Athletes. Pediatrics. 138 (3):e20162148\n4. Grant, E.C. (2006). Specific Athletic Demands of Figure Skaters. Retrieved from http://iceskatingresources.org/SpecificAthleticDemands.pdf\n5. Gropper, S.S., Smith, J.L., and Groff, J.L. (2005) Advanced Nutrition and Human Metabolism, 4th ed. Belmont, CA: Thompson Wadsworth.\n6. Jayanthi,N., Pinkham, C., Dugas, L., Patrick, B., and LaBella, C. (2012) Sport Specialization in Young Athletes: Evidence-Based Recommendations. Sports Health. 5(3): 251-257\n7. Jordan, M. (2014) Assessing Movement Competencies in Elite Sport: Beyond the Movement Screen. Perspectives in Exercise, Health & Fitness. Calgary, AB.\n8. Jordan, M. (2014) Strength & Power Training in Endurance Sports. Perspectives in Exercise, Health & Fitness. Calgary, AB.\n9. Kanmani, R., and Dalpana, D. (2016) Burnout Syndrome – Overtraining and Burnout in Young Athletes. Indian Journal of Applied Research. 6(5): 484-486\n10. King, D.L. (2005) Performing Triple and Quadruple Figure Skating Jumps: Implications for Training. Can. J. Appl. Physiol. 30(6): 743-753\n11. Mountjoy, M., Sundgot-Borgen, J., Burke, L., Carter, S., Constantini, N., Lebrun, C., Meyer, N., Sherman, R., Steffen, K., Budgett, R., and Ljungqvist, A. (2014) The IOC Consensus Statement: Beyond the Female Athlete Traid—Relative Energy Deficiency in Sport (RED-S). Br J Sports Med 48: 491-497\n12. Mountjoy, M., Sundgot-Borgen, J., Burke, L., Carter, S., Constantini, N., Lebrun, C., Meyer, N., Sherman, R., Steffen, K., Budgett, R., and Ljungqvist, A. (2015) Authors’ 2015 additions to the IOC consensus statement: Relative Energy Deficiency in Sport (RED-S). Br J Sports Med 49(7): 417-420\n13. Myer, G. D., Jayanthi, N., Difiori, J. P., Faigenbaum, A. D., Kiefer, A. W., Logerstedt, D., & Micheli, L. J. (2015). Sport Specialization, Part I: Does Early Sports Specialization Increase Negative Outcomes and Reduce the Opportunity for Success in Young Athletes? Sports Health, 7(5), 437–442.\n14. Relative Energy Deficiency in Sport (RED-S). (2015) Br J Sports Med. 49: 421-423\n15. Sands, W.A., Kimmel, W.L. McNeal, J.R., Murray, S.R., and Stone, M.H. (2012) A Comparison of Pairs Figure Skaters in Repeated Jumps. Journal of Sports Science and Medicine. 11, 102-108\n16. Seiler, S. and Tonnessen, E. Intervals, Thresholds, and Long Slow Distance: The Role of Intensity and Duration in Endurance Training. Sportscience. 13, 32-53\n17. Thrift, N. (2004) Movement-Space: The Changing Domain of Thinking Resulting from the Development of New Kinds of Spatial Awareness. Economy and Socitey. 33(4): 582-604\n18. Van Dyke, M. (2015) Advanced Triphasic Training Methods. Retrieved from http://vandykestrength.com/files/Applying_Triphasic_Training_Methods_for_CSCCa_Final.pdf"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:4ff5f924-15c4-416b-a4b9-cf38a57803d3>","<urn:uuid:2dd70f84-4b2c-4820-bc06-b8b9c6269968>"],"error":null}
{"question":"Could you explain how green building materials contribute to cost savings, and what challenges do architects face in implementing sustainable solutions in the US market?","answer":"Green building materials contribute to cost savings in several ways - businesses that invest an additional 2% in green materials can recover up to seven times that cost long-term. Materials like bamboo flooring can save $58 per square foot over 20 years, and sustainable materials generally have lower maintenance and repair costs. They also enhance the cost-saving effects of sustainable energy technology. However, architects face significant challenges implementing these solutions in the US market. As noted by industry experts, abundant natural resources in the US remove cost-driven pressure to seek alternatives, allowing inefficiency to persist. Additionally, sustainable products often struggle to reach price points that attract mainstream markets, making widespread adoption difficult despite their long-term benefits.","context":["“I love the idea of biomimicry,” says architect Allison Ewing of design inspired by nature. It’s the next step, she says, in designing and delivering sustainable buildings, a progression that started for her working with green pioneers Renzo Piano and William McDonough and continues today in an architectural practice with her husband, Chris Hays, in Charlottesville, Va. “It’s very much an emerging technology.”\nTo maintain a sharp eye on its evolution, Ewing routinely checks in with cutting-edge sustainable materials sources such as Material ConneXion, and she recently used Cambia, a wood-based decking product that is thermally modified to more effectively resist natural forces. “It’s a kind of fossilization process that changes the cellular structure of the wood,” she says, a process that mimics (if occurs far faster than) petrified wood in nature.\nShe’s also tracking a curtainwall system for buildings in desert climates that sheds sand like a lizard, but the product is not yet in her toolbox. “I need to see it work in the market before I design with it, especially if it has to do with the building envelope,” she says. “A failure there has a huge impact on overall performance.”\nShe’s similarly intrigued by Greensulate, a fungi-based rigid insulation panel and packaging material that purportedly rivals the performance of polyiso. The material elicits a naturally occurring binder during its organic formulation process, then is dried to a desired dimension—a manufacturing cycle that uses one-tenth of the energy needed to produce a conventional rigid foam panel. It’s also completely biodegradable once removed from application. “It is the essence of biomimicry,” says Ewing.\nIt’s also a multitasking product (insulation and substrate) that helps improve and simplify the first line of sustainable building: a high-performance envelope. “That’s where you need to spend a clients money first, to tighten up the house,” she says.\nMeanwhile, Ewing is resolved to spec what she calls “state of the shelf” sustainable solutions, like Cambia, which has been used in Europe for a decade. “There are a lot of fascinating products out there that never gain traction,” she says, in large part because they never get to a price point to attract a mainstream market. “It continues to be a challenge.”\nShe points to the U.S. market’s abundant natural resources, at least compared with other developed countries, as a major hurdle. “There’s no cost-driven pressure to look for alternatives,” she says. “We’re allowed to be inefficient.”\nBut the biggest spur for sustainable product demand, she thinks, is production housing, where the green-building nut has the most potential but is the hardest to crack. To that end, she encourages large-volume builders to engage local or regional green building certification programs such as EarthCraft to get their feet wet and educate themselves and their buyers about the practices and benefits of sustainable housing.\n“Most of those programs are less stringent than LEED and are therefore likely more affordable,” she says. “Once they see these programs are accessible and offer a financial benefit, they’ll put them into practice.”\nTo builder and developer clients more concerned about the impact of green building on sales than the environment, Ewing frames her pitch around the concepts of lower ongoing costs, greater functionality, and creating a competitive advantage.\nThose principles are proving out with a 10-unit sustainable-modern infill project designed and developed by Hays & Ewing Design Studio that’s outselling everything in an otherwise slow Charlottesville housing market. “Its appeal is sustainability,” she says. “There’s an unserved market out there.”","Sustainable building designs offer businesses several advantages. Increasingly, companies are using green building materials to magnify the cost-saving effect of sustainable energy technology. Environmentally minded companies enjoy the financial benefits of being green.\nBig-name companies are going green\nEnvironmental Leader recently reported that Whole Foods and Google are now using a building material called Ecor in their business locations. Ecor, developed by Noble Environmental Technologies in Serbia, is made from 100 percent recycled material.\nInterestingly, Ecor was created in partnership with the United States Department of Agriculture and is used by cabinet and furniture makers, designers and architects alike. It can replace materials that are typically made from cardboard, plastic, aluminum, fiberboard and traditional wood panels. Ecor is also free of toxins and highly practical, according to the news source.\nSustainable materials such as Ecor offer businesses the same durability and use as other trusted building materials, but they also save money for companies due to the less expensive maintenance and repair costs. Ecor is one of many options available to those who want to incorporate greener materials in their corporate properties.\nSustainable techniques keep costs down during winter\nAs winter settles in, the topic of insulation becomes relevant with regard to energy efficiency. Homeowners commonly reduce their heating costs by applying window treatments and using programmable thermostats. On the business side, there are similar methods that can be employed to keep costs down.\nMike Schoenecker, vice president at Winkelman Building Corp., recently wrote an article on LinkedIn that outlines how green building saves money. Schoenecker said that the financial benefit of sustainable energy like solar power and geothermal technology is compounded by installing green materials such as energy-efficient windows and roofing. In the same way that a homeowner insulates his or her attic as an easy way to keep heat from escaping the house, companies – some of which have already started using renewable energy sources – can select building materials that conserve energy and keep costs down.\nSchoenecker suggested using bamboo instead of hardwood as a way to make positive changes without sacrificing durability or style. An investment of $4 per square foot now, he argued, will yield $58 of savings per square foot over a 20-year period. In his article on LinkedIn, Schoenecker also suggested using recycled glass, drywall and steel in buildings because of the money saved and benefit to the environment. Like Ecor, costs will be kept to a minimum without sacrificing product efficiency.\nWhat successful implementation looks like\nIn the example of big-name companies, Whole Food uses Ecor for their signage, while Google uses it for their wavy interior panels. Ecor, according to Environmental Leader, is reportedly 75 percent lighter than conventional panel products and can also be shaped into any form – such as waves or spheres. While the manufacturing cost of Ecor started out at $3 to $4 per square foot, the current cost is approximately 29 cents per square foot. The dramatic drop in the cost of production signifies that with green building materials there is always room for growth. It is impressive that such a versatile product can be this affordable, which speaks to the strength of green building materials.\nSchoenecker highlighted what many experts have said – businesses that invest an additional 2 percent in overhead for green materials, instead of traditional building materials, on average, will recover up to seven times of that cost in the long run.\nAdditionally, it is worth noting that there are government incentives for sustainable business practices. Schoenecker mentioned rebates and tax credits offered to businesses that commit to sustainable energy like solar, wind and geothermal technology. The U.S. Department of Energy provides a database that details all of these federal incentives. As green building materials become more widespread, partly due to their ability to accentuate the savings from sustainable energy technology, the government may soon offer additional discounts. Products like Ecor, bamboo flooring panels and recycled glass windows are already priced competitively with respect to traditional materials. It is likely that the costs benefits of green materials will keep getting better."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:4ec7dc14-af2f-4f4d-9e92-212f030532ae>","<urn:uuid:f8ab789c-8bd6-4c62-a695-3a8448a6a25e>"],"error":null}
{"question":"Could you explain how swap rates and futures contracts differ in their approach to risk management?","answer":"Swap rates and futures contracts manage risk differently. Swap rates are calculated based on specific factors including trading positions, interest rate differences, duration of open positions, and broker commission rates, with a precise formula: Swap rate = (contract * [interest rate difference + commission] /100) * (price / number of days in a year). Futures contracts, on the other hand, manage risk by allowing investors to lock in prices for future transactions, protecting against price volatility, though they can be high risk as the contract can lose all value and trade at $0 when it expires. While both serve as hedging tools, futures provide highly liquid markets and access to commodities, whereas swaps focus more on exchanging cash flows between parties.","context":["The basic meaning of swap is exchanging one thing for another.\nIn finance, a swap is a contract between two parties where they exchange cash flows of two different financial instruments over a specified period. One cash flow is fixed while the other cash flow can change based on factors such as interest rates, commodity prices among others. Interest rates, currencies, and commodities are some examples of financial instruments that are exchanged.\nSwaps are traded over the counter. Over the counter is where trading of financial instruments is done directly between two entities without the involvement of a central exchange. Some participants in the swap market are financial institutions and companies.\nReasons for Using Swaps\nSwaps are used to minimise risks. For example, commodity swaps mitigate the risk of changes in commodity prices while currency swaps protect against risk in case of fluctuations in the currency exchange rates. Since swaps are traded over the counter, a company may gain access to new markets, and parties outside the central exchange willing to trade swaps with them. Consequently, this may lead to the company gaining financial benefits.\nAlso known as FX swaps, these swaps are traded when the financial flows of two different currencies are exchanged by the parties involved. The purpose of this swap is to hedge against potential loss associated with changes in currency exchange rates. Currency swaps are used by companies with operations in different countries. The types of currency swaps include;\n- Fixed for fixed swap – This is exchanging fixed interest payments in one currency for fixed interest payments in a different currency.\n- Fixed for float swap – This is exchanging fixed interest payments in one currency for floating interest payments in another currency.\nThese are contracts where the parties involved exchange the floating cash flows for the fixed cash flows (that are dependent on the commodity price) with one another. Commodity swaps enable a company to control the risks associated with changes in the commodity price. Examples of commodities are crude oil, gold, and silver.\nInterest Rate Swaps\nA fixed interest rate is a rate on a financial instrument that does not change during the period of the contract. The floating interest rate on the other hand changes during the period.\nThe Islamic swap is also known as a swap-free. The Islamic swap is one where receiving or paying interest on a financial instrument is prohibited. This is because according to Islamic law, Muslims are forbidden from receiving or paying interest in their transactions. For example, in Islamic Forex accounts, when you open a trading position and keep it open overnight, you will not be subject to rollover fees. A rollover fee is an interest payment made when a trader holds a position overnight to the next trading day.\nSwaps in Forex Trading\nA swap in Forex trading is an overnight interest that you either pay or receive for a trade that you hold open overnight. Swaps apply only when a position is held until the following trading day. Swaps do not apply when a trade is opened and closed within a day. There are two types of Forex trading swaps and they are long swaps and short swaps.\n- Long swaps. This is where a trader opens a buy position and leaves it open overnight.\n- Short swaps. This is where a trader opens a sell position and keeps it open overnight.\nThe difference in interest rates between the 2 currencies in the currency pair and the position taken whether to buy or sell determines whether the trader will pay or earn the interest fee.\nTrader paying the interest fee\nIf the interest rate of the currency you’re buying is lower than the interest rate of the currency you’re selling, then you will pay the fee. For example, if a trader enters a long position on GBP/USD. If the interest rate of GBP is lower than that of USD, the trader will be charged the interest fee for holding the position overnight.\nTrader earning the interest fee\nWhen the interest rate of the currency bought is higher than that of the currency sold, the trader has a chance to earn the interest fee. For example, if a buy position on EUR/JPY is opened. If the interest rate of EUR is higher than that of JPY, the trader will potentially receive the interest.\nFactors Influencing the Swap Rate\nThe amount of interest that a trader can earn or pay is influenced by the factors listed below;\n- The trading positions entered: either buy or sell position.\n- The interest rate differences of the financial instruments involved.\n- How long (days) the trading position has been kept open.\n- The commission rates charged by brokers.\nHow to Calculate the Swap Rate\nSwap rate=(contract * [interest rate difference + commission] /100) * (price / number of days in a year)\nFor example; A trader sells 1 lot of GBP/USD trading at 1.2400. Let’s assume the GBP interest rate is 4% and for USD is 2.5%. The interest rate difference is 1.5 and the broker’s commission is 0.25%. The commission is added in the formula since the interest rate of the currency sold (GBP) is higher than the one of the currency bought (USD).\nSwap rate=(100000 * [1.5 + 0.25] /100) * (1.2400 / 365)= USD 5.95\nWhen this trade is kept open overnight to the next trading day, the trader will be charged USD 5.95 from his/her account.\nLet us use the previous example as a buy position. A trader buys 1 lot GBP/USD at 1.2400. GBP=4% and USD=2.5%. This time, the commission will be subtracted from the formula since the interest rate of the currency sold (USD) is lower than that of the currency bought (GBP).\nSwap rate=(contract * [interest rate difference – commission] /100) * (price / number of days in a year)\n=(100000 * [1.5 – 0.25] /100) * (1.2400 / 365)= USD 4.25\nHere, if the trade is kept open to the next trading day, the trader will earn the USD 4.25 interest into his/her account.\nWhen applied effectively, swaps serve as an important strategy for companies to manage their risks and obtain financial benefits from their transactions.\nLooking for more Forex Education? Click here to keep reading.","Futures contracts are a type of financial derivative that investors use to speculate on the price of a security at a forthcoming date. These typically trade on separate futures exchanges, which allow for higher volumes of trading.\nRecommended: A Guide to Derivatives Trading\nWhat Is a Futures Contract?\nFutures contracts, or futures, are legal agreements to either buy or sell a given security, commodity, or asset at a specific time in the future, for a previously agreed-upon price. For investors, they offer access to commodities and other markets they might not be able to access otherwise. They can also act as a way to protect against volatility.\nOne important feature of a future contract is that both buyers and sellers can execute the contract regardless of the current market price of the underlying asset when the contract expires.\nInvestors use futures contracts when they believe that the underlying security will go up or down by a certain amount of time over a fixed period of time. The futures contract buyer enters a legal agreement to buy the underlying asset at the contract’s expiration date. On the other side of the trade, the futures contract seller agrees to deliver the underlying security at the agreed-upon price, when the contract expires.\nThe majority of futures contracts on a futures exchange are standardized by date and price, to allow for higher trading volumes and simpler transactions.\nInvestors can buy futures contracts to make money – or to hedge against losses – resulting from the price increases or decreases in stocks and commodities like oil, as well as other financial instruments.\nRecommended: Perpetual Futures and Swaps in Crypto & Investing\nHow Do Futures Contracts Work?\nIn a futures contract, the purchaser gets to buy a given asset at a predetermined price. That can help protect against big price swings up or down, making them popular not only with investors, but with companies that rely on commodities that experience sudden price changes.\nExample of a Futures Contract\nAn airline, for example, might buy an oil futures contract to lock in the price of the oil that it will need to buy in order to get its jets off the ground in the coming months. Purchasing the futures contract allows the airline to guard against the financial harm of a sudden rise in the price of fuel. The risk to the airline, however, is that oil prices will go down – in which case, it will miss out on those lower prices.\nOn the other side of this hypothetical transaction is a fuel distributor, which has millions of gallons of oil in its inventory. It would sell the oil futures contract as a way of maintaining a steady market for its oil in the coming months. That’s because the airline buying the futures contract must buy the fuel at the agreed-upon price on the dates specified in the contract. That removes some risk for the oil distributor, but it also creates a risk if oil prices climb before the futures contract expires. Should that happen, the oil distributor will still have to sell the oil at the lower price specified in the futures contract.\nTo stay with this example, in the futures contract, the airline and the oil distributor will set and agree upon the terms, specifically the price of the oil and the expiration date upon which the contract expires. In this contract, the distributor agrees to sell 1,000 barrels of oil at $50 per barrel, in exactly 90 days. If the price of oil in 90 days is $75 per barrel, then the airline will have gotten a good deal. If a barrel of oil falls to $35, then the oil supplier will have protected itself against the price declines.\nWhat’s the Difference Between Futures and Options?\nFutures and options are both derivative contracts. However, futures contracts oblige the buyer or seller to complete the deal at the contract’s expiration, while options contracts give traders the right but not always the obligation to execute the contract when it expires.\nRecommended: 10 Important Options Trading Strategies\nBoth futures and options share some of the same trading terminology. For example, both investors in both types of derivatives will need to consider it’s bid-ask price. The bid price is the highest price a buyer will pay for the contract, while the ask price is what the seller will accept.\nInvestors can also purchase options on future contracts. In a call option on a future, the buyer has the right to buy a futures contract at a specific price at a specific future date. In a put option, the buyer has the right to sell the futures contract at a specific price at a specific date.\nRecommended: Call vs Put Options: What’s the Difference?\nFutures Contracts Pros & Cons\nFutures trading can be a profitable strategy, but it also has some drawbacks that investors should consider.\nBenefits of Futures Contracts\n• Futures contracts act as a hedge against the risks related to price volatility.\n• Most futures markets are highly liquid, allowing traders to buy and sell when they want.\n• Futures may give investors access to commodities, and other markets not normally accessible to everyday investors.\n• Futures contract pricing is determined by adding the cost of carrying the underlying asset to its spot price.\nDownsides of Futures Contracts\n• Futures contracts can be a high risk investment. In some cases, a futures contract can lose all of its value and trade at $0 when it expires.\n• Futures contracts can reduce or eliminate potential gains from price swings in the underlying securities or assets.\n• Futures contracts themselves are often highly volatile, with their prices fluctuating wildly.\n• You may have to pay high commission charges on high-volume trades.\nHow Investors Use Futures Contracts\nBut not everyone who buys an oil futures contract plans to take delivery of the oil it represents. Retail investors also use futures as a way to protect their investments against volatility. Those futures investors who buy and sell the contracts to make money off the price changes that the contracts themselves undergo.\nTo go back to the example of an oil futures contract, an investor owns a contract, and the price of oil rises, allowing the contract owner to buy oil for less than the market price. The investor will be able to sell that contract for more than they purchased it for. The investor will then sell the contract on the futures market.\nOther investors use futures contracts related to other commodities, including corn, soybeans and wheat. But there are also futures markets where investors can buy futures contracts that offer them the ability to bet on the future of currencies, individual stocks or stock indices like the S&P 500 or 10-year Treasury bills. Investors may choose to buy futures, rather than the securities themselves, to reduce their volatility exposure.\nHow to Trade Futures Contracts\nThere are several steps to trading futures contracts.\n1. Open a brokerage account\nTo trade futures contracts, the first thing you’ll need is a brokerage account. You may also need your broker to give approval for margin and options privileges in your account.\n2. Set a trading strategy\nBefore jumping into the futures market, develop a strategy. That strategy could involve technical analysis based on market data, or fundamental analysis based on the investment’s underlying economic and financial trends.\nSome investors even try out their strategy using hypothetical trades before they start trading with real money. This allows you to understand the risks of potential trades without actually losing money.\n3. Research trades that make sense for your investment strategy\nMost brokerages that offer futures trading have an online platform you can use to research specific securities and see futures contracts available to buy or sell.\n4. Double-check the terms\nMake sure that the contracts will do what you think. That means confirming the selling and purchase price of the contract, the expiration, and the fees.\n5. Develop your skills\nWhether doing it on paper, or with real money, you’ll want to refine your strategy over time. You may find that you make more profitable trades in a specific sector, for example, or need to work on staying calm as security prices rise and fall. Practice will allow you to improve, and get more out of the futures strategy you’ve developed.\nFutures contracts are a type of investment that can offer access to commodities markets, as well as a way to protect against volatility. They can be a helpful tool to some investors, but they’re also risky and can be an expensive way to invest.\nWhile SoFi does not offer futures contracts, it does provide a great way for investors to get started building a portfolio. The SoFi Invest brokerage platform offers an active investing solution that allows you to choose stocks and exchange-traded funds without paying commissions. SoFi Invest also offers an automated investing solution that invests your money for you based on your goals and risk, with no Sofi management fee.\nPhoto credit: iStock/fizkes\nThe information provided is not meant to provide investment or financial advice. Investment decisions should be based on an individual’s specific financial needs, goals and risk profile. SoFi can’t guarantee future financial performance. Advisory services offered through SoFi Wealth, LLC. SoFi Securities, LLC, member FINRA / SIPC . SoFi Invest refers to the three investment and trading platforms operated by Social Finance, Inc. and its affiliates (described below). Individual customer accounts may be subject to the terms applicable to one or more of the platforms below.\n1) Automated Investing—The Automated Investing platform is owned by SoFi Wealth LLC, an SEC Registered Investment Advisor (“Sofi Wealth“). Brokerage services are provided to SoFi Wealth LLC by SoFi Securities LLC, an affiliated SEC registered broker dealer and member FINRA/SIPC, (“Sofi Securities).\n2) Active Investing—The Active Investing platform is owned by SoFi Securities LLC. Clearing and custody of all securities are provided by APEX Clearing Corporation.\n3) Cryptocurrency is offered by SoFi Digital Assets, LLC, a FinCEN registered Money Service Business.\nFor additional disclosures related to the SoFi Invest platforms described above, including state licensure of Sofi Digital Assets, LLC, please visit www.sofi.com/legal. Neither the Investment Advisor Representatives of SoFi Wealth, nor the Registered Representatives of SoFi Securities are compensated for the sale of any product or service sold through any SoFi Invest platform. Information related to lending products contained herein should not be construed as an offer or pre-qualification for any loan product offered by SoFi Lending Corp and/or its affiliates.\nOptions involve risks, including substantial risk of loss and the possibility an investor may lose the entire amount invested in a short period of time. Before an investor begins trading options they should familiarize themselves with the Characteristics and Risks of Standardized Options . Tax considerations with options transactions are unique, investors should consult with their tax advisor to understand the impact to their taxes."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:0f2e5c17-ebd9-4c02-9d53-920b5eb5c621>","<urn:uuid:52c61f27-3604-407b-b97e-09def4818610>"],"error":null}
{"question":"Can you explain what Java nio really is and why it matters for security - like, how does the non-blocking I/O thing work and what's the connection with buffer overflow risks?","answer":"Java nio (new I/O) is a file I/O mechanism introduced in Java 5 that enables non-blocking input/output operations. In non-blocking I/O, when performing file operations, a new thread is created to handle the I/O task while the main thread continues executing other tasks in parallel. This contrasts with traditional blocking I/O where the thread gets blocked until the operation completes. However, when dealing with I/O operations, security considerations become crucial, particularly regarding buffer overflows. Buffer overflows occur when input exceeds allocated space, which is especially risky in C/C++ programs but can affect Java applications when they interact with native code or pass variables to other programs. Even though Java uses dynamic memory management making it less vulnerable, it's important to check input lengths to prevent buffer overflow attacks that could lead to malicious code execution or system compromise.","context":["Java nio Tutorial with Examples\nThis, an interesting, file I/O mechanism, introduced in Java 5, brings many important features to provide something very new and to address few, I may not call those as issues, but requirements of File I/O. This is called Java file nio. In this java nio tutorial, we try to explore what all is there as part of this new package by understanding the concepts behind and writing code examples to use the features. It contains many high level APIs that can be used to perform different I/O operations.\nIn this discussion, we try to get overview of what is nio, what is rational behind introducing different features in this API and few code examples.\nWhy is It Called nio?\nThis can be a basic question in any Java nio tutorial. One can say that it includes APIs that can be used to perform non-blocking I/O that is why it is called nio. But actually it is simpler than that. It is just new I/O, hence nio.\nWhat is Exactly Non-Blocking I/O?\nLet us understand through this java nio tutorial, what gets blocked when it is blocking I/O. In old file I/O, while performing read or write to a file, the working thread gets blocked until the operation is completed. Means, it does only reading or writing to file and does not execute next statements in program until those operations are done. What is impact of it? First question, what if the program does not wants to wait for file operation to complete, i.e. it can continue doing something else in parallel? Existing I/O does not permit this. Second, file I/O time does not only depend on the Java code performance, but it has to do with the network and underlying OS as well. Then why Java program performance is impacted just because we don’t have feature to do something else?\nIf the thread can continue executing next statements instead of waiting for completion of the I/O operation started, it is not blocking. Hence it is called non-blocking. Obviously, you must be thinking, how does the file read/write continuation and completion will be handled? It is left to programmer, if we want non-blocking behavior then we also need to ensure completion of the parallel running tasks. May appear complex here, but we can take this with and example in asynchronous file operation below.\nHow does Non-Blocking I/O Work?\nIt is an important concept to explain in a java nio tutorial. Very simple to understand, just read non-blocking as parallel for a moment and you will get the clue. If we want to the file operations to run in parallel mode, what is solution in Java? Threads, correct? This is exactly how it works. Another thread is spawn for the file operation and it continues doing the job we initiated, while main thread goes ahead doing next tasks.\nWe can look at this asynchronous file write call example. Here the main thread continues executing next statement by assigning file write to a new thread. As a developer we have to write a logic that checks if the read/write operation is completed or not. Print statements of this example can give us exact thread details.\nWhat are Contents of nio Package?\nBelow are the important classes grouped under different categories. These groups are primary based on what is use of these classes from a developer point of view. Actual packages under nio package group these classes differently.\nLet us understand these groups and important classes in these groups.\nThe philosophy behind this grouping is the level of interaction or representation with/of file system. We group the classes from broader level of representation and usage to finer level and helper classes in the end. Time to dive deep into details.\nPath and File System Representation\nWe have a generic class java.nio.Paths, which gives methods that can be used to get representation of a file system object using URI or String path.\nSimilarly, we have FileSystem and FileSystems classes which are designed to encapsulate underlying file system to represent in some way or other.\nIn non-nio APIs, we had used java.io.File class to represent a file or folder. In nio, we use java.nio.file.Path to represent anything that can be called as “path”, it can be a file or a path mapping to directory or file. It is definitely more than just the name change. Path is more powerful than the File class.\nIt is not independent of the underlying OS. If we want to compare a Path representing a file on Unix with a Path representing a file on Windows, it won’t be a direct comparison. You can be bold to say that this class is not platform independent, and it is correct also, as it is representing something very native to OS, a file/directory/symbolic link.\nAnother important thing that Path supports now is symbolic links. Path can be used to represent symbolic links.\nIn addition to this, we have more objects such as Files that provides methods to operate on Path. Also, there are classes to interface underlying OS events. These events are the events occurring on certain Path representation.\nFile Operation and File Data Operations\nTo enhance non-blocking I/O support, nio package provides classes that allow access to file data in different asynchronous way.\nChannels can represent different (file) data streams or buffers more appropriately. Examples can be FileChannel, AsynchronousFileChannel, AsynchronousSocketChannel etc. These channels can be configured to receive buffered data from underlying sources.\nSelectors allow a thread to select a Channel from such registered multiple channels and read/process data provided by such a channel in a non-blocking way.\nJust try to visualize that there are multiple sources of data, each source is mapped through an appropriate Channel. Channels are registered to a Selector. A thread can select a desired Channel from Selector and read/write data using this channel to a source/target. Thread does not need to wait until the data is read by the Channel. Instead it can continue doing other work. This is non-blocking I/O, we have discussed it above.\nClasses Supporting File Operations\nThese are basically supporting classes required while performing core operations using nio. If you look at names, and attributes, you can see what is use of those.\nJava nio Tutorial Code Examples:\nUsing these concepts, below are few code examples that can help programmers while writing code using nio package classes.\nWill keep on linking more Java nio code examples to this java nio tutorial in future.","Buffer-overflow vulnerabilities are back in the news. Buffer overflows, as this tip from InformIT explains, usually...\nBy submitting your personal information, you agree that TechTarget and its partners may contact you regarding relevant content, products and special offers.\ntarget poorly constructed C/C++ code. Elfriede Dustin, Douglas McDiarmid and Jeff Rashka, the writers of this article, provide some tests to see if your system is susceptible to a buffer overflow.\nOne common security hole exploited on Web systems is the buffer overflow, used mostly against compiled executables, particularly operating system tools and utilities. A buffer overflow occurs when the length of a program or a function input exceeds the space allocated to store it. C/C++ programs are particularly vulnerable to this kind of attack, as developers often declare variables that reside on the program's stack. For example, consider the following C/C++ code:\nvoid createFullName(char* firstName, char* lastName)\nstrcat(fullName, \" \");\nThis C++ code simply takes the supplied first and last names and puts them together, separated by a space. Of particular importance is the fullName variable. The way it is declared causes it to reside on the stack. The problem is that this variable can easily exceed 1,024 characters whenever firstName or lastName or both values are too long.\nIn most cases, this situation will simply cause a program crash as the stack is corrupted by the strcpy or strcat function calls. However, if these arguments are carefully crafted, they can in fact be used to send malicious code to the program, embedded in the first- and last-name arguments. If the arguments manage to overflow the fullName stack variable, they can cause the execution of this code by manipulating the return address, which also resides on the stack.\nThe return address is a hidden piece of data that resides on the stack with the rest of the variables passed to a function. Depending on the specific language, compiled programs place this data on the stack prior to calling the function. That way, the program knows where to go when the function is finished.\nBy overflowing one of the variables on the stack, a malicious input can overwrite the return address, as it exists on the stack as well. In the example of createFullName, by overflowing the firstName or lastName inputs with precisely the correct number of characters, the return address can be overwritten and made to point back to a specific place in the data that was supplied in the firstName or lastName inputs. With a little creativity, this data can be executable program code, with malicious intent. Because the return address is simply a pointer to code, the return address is pulled off the stack when the function completes and is used as the place to start executing the next sequence of instructions. Unfortunately, the next sequence of instructions is code written by the attacker and will be blindly executed by the server.\nOnce the malicious program argument has been submitted and the input buffer has been successfully overflowed, the attacker effectively has his or her own code executing on the site's Web server machine. Depending on the buffer size, a lot of bad things can happen. The code could read the contents of the password file, e-mail the file, make changes to configuration files, start up a TELNET session, or even connect to another Web server and download a larger, more damaging program, such as a Trojan horse.\nPreventing buffer overflows consists mainly of checking the length of user-supplied input variables. In the previous example, limiting the size of the firstName and the lastName inputs to 511 bytes would protect against overflows (511*2 = 1,022, plus one for the space and one for the terminating \"null\" totals 1,024). In addition, using the strncpy and the strncat functions instead of strcpy and strcat is also advised, as the former two functions limit the number of characters copied into the buffer. Keep in mind that it is not realistic to restrict the input on the Web page or form, as a malicious user could simply alter the page on his or her local disk and remove the length restrictions on the form fields or simply access the URL of the form action directly, without using the form itself. The only sure way to prevent buffer overflows is to examine and to reject excessively long inputs in all Web system components.\nAgain, the most common source of buffer overflows is C/C++ code, particularly when string manipulation is involved. Scripting languages, such as Perl and Java code are less of a risk, as they use dynamic memory management to allocate space for variables. This does not mean that input lengths should be ignored when using scripting languages or Java. It is still possible that these variables could be passed to other programs that are susceptible to buffer overflows.\nSometimes, variables are simply \"passed through\" a program. For example, a Perl script could be created that takes a form input, such as a customer name, and simply hands it off to another program, possibly one written in C++ or one that came with the operating system that was probably also written in C or C++. The second program in the chain may be susceptible to buffer overflows, so the attacker could still cause damage. It just wouldn't affect the Perl script, as it is passing it through. Therefore, it's important to always check input lengths regardless of language, function and so on.\nTesting for buffer overflows\nMuch like testing component inputs for dangerous metacharacters, testing buffer overflows requires that the component actively check the lengths of all inputs. Component inputs are either HTML form fields or name/value pairs. A name/value pair is a field name and a value, separated by = on the URL line and is formatted as a name/value pair. A sample set of input might look something like name=Norma, orderID=12345.\nWhen an input string that exceeds the maximum length is detected, the component should return a predetermined error page. The successful display of the error page represents a successful test result. The security test procedure is concerned with verifying that an overflow condition cannot be created, by supplying long inputs to the component. The error message produced is simply a way to confirm that the component has properly detected the invalid input and then aborted the activity.\n- The list of Web system components should be augmented with the maximum length of each input that the component will accept. If the engineering techniques described in Chapter 2 are used, these lengths should be documented in the interface use case descriptions. If the input length exceeds this value, the component must return the predetermined error page. If the error page is not returned, a security flaw exists.\n- For each input to the component, supply an input string that exceeds the maximum size by one character. This should return the predetermined error page. Also try the test with an input string that is exactly equal to the maximum size of the field and watch the behavior of the component with this input. Boundary conditions often cause problems when dealing with buffers and string operations. Any printable character is acceptable as input, as long as it is within the valid set of characters that the component is willing to process. A long string of A characters will usually suffice.\nTypically this type of test must be performed either by saving the HTML page to disk and manually editing the value attribute of an input field or by using an automated testing tool to send in the data. As with metacharacter testing, make sure that each field is tested one at a time so any problematic fields can be isolated.\nRead more of this article at InformIT. Registration is required, but it's free."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:84123db6-6f55-4a7f-b93b-2613a1759d93>","<urn:uuid:ff7a58c9-2ab7-4279-ae73-c225e59065d1>"],"error":null}
{"question":"Could you please explain the key difference between making regular quilt binding and bias binding for button-loops - specifically in terms of how they are cut from the fabric?","answer":"The key difference is that quilt binding is typically cut across the fabric from selvage to selvage, while bias binding for button-loops must be cut on the bias (diagonal) of the fabric. This is because bias-cut binding can stretch and give, making it ideal for button-loops that need to bend smoothly, while quilt binding doesn't require this stretch since it's mainly used for straight edges and corners of quilts. When making button-loops, the bias cut allows the fabric to fold and loop nicely without distortion.","context":["What is Quilt Binding?\nQuilt binding is the finishing touch to a quilt.\nIt is the fabric used cover the outer edges of a quilt and keeps the edges intact and adds a wonderful finish to the quilt’s design. Sewing binding around a quilt’s edges is one of the final steps in quilt making.\nQuilt binding can be constructed from a fabric that’s already been used in the design, or with any other fabric that works with the layout. Binding can be made from a single layer of fabric, but two layers (called double-fold binding) are much more durable.\nTo make the binding, measure the length and width of the runner/ hanger and add them together and then multiply by two and add an extra 10” for corners.\nCut strips of fabric to make up this length (ideally the fabric should be cut across the piece: selvage to selvage for the best binding finish.\nFor a peeper binding you will require 2 different fabrics, one that will “peep” out from the binding to add contrast and one for the binding itself. We’ve cut the peeper at 1 ¾” wide and the outer binding colour at 1 ½” wide.\nThe cutting widths are totally variable to what you desire but there does need to be a ¼” difference between the 2 strips. The finished width we have used will provide a generous ½” binding on the edge.\nJOINING STRIPS – Lay your fabric strips right sides together as shown. Sew a diagonal seam from corner to corner (45 degree angle), trim the corner, and repeat until all the binding strips are sewn together into one long strip.\nPress your joined fabric as you go to ensure this remains flat for your binding and eliminates bulk.\nRepeat the steps above for the other strip of fabric.\nTo make up the peeper binding strip, lay right sides together and stitch exactly ¼” from the edge trying to keep this stitching as straight and even as possible.\nWith an iron (working on the right side of the fabric as it’s much easier) press the closed seam allowance to the side from the peeper fabric. Press the whole length.\nWith wrong sides together fold widthways and press the peeper edge keeping the raw edges as even as possible.\nPressed binding should look like this.\nThe peeper binding is stitched onto the underside of the runner/ hanger and then folded around to the topside and stitched into position. To ensure perfect corners we suggest you mark the ¼” seam intersections on the 4 corners of the runner/ hanger.\nCreate a 45 degree angle at the beginning of your binding by flipping the end across to the side of the binding, as in the photo below. This will give a smooth finish when finally joining the 2 ends together. Our peeper side of the binding is facing up.\nOPTION: this can also be done with the binding folded instead of being opened out.\nThen press the whole long strip in half, wrong sides together and iron down.\nMatch the raw edges of the hanger and the peeper binding to the desired starting location (With your quilt wrong side up, start about halfway along one side).\nA – Using a ruler, mark 1 inch down from the end of the strip. Mark with a pin.\nB – Then using a ruler, mark 2 inches down from the 1-inch mark. Mark with a pin.\nUsing a ¼ inch seam, stitch 1 inch of the open fold onto the runner/ hanger and stop stitching when you get to the 1-inch mark.\nThen leave a 2 inch gap (this will provide an opening for the end of the binding fabric at the end) and then start stitching again at the 2 inch mark.\nContinue sewing until you reach the first corner and stop stitching 0.65cm (1/4”) from the end but keep your needle down. Lift your foot and turn your runner/ hanger (with your needle still down). Continue stitching to the corner.\nLift the binding strip over pulling against that angled stitch that we just made, forming a diagonal fold. Then pull the binding strip back down creating a fold at the top. Pin and start stitching again until you reach the side of the runner/ hanger that you started on, mitring the corners as you go.\nStop stitching when you get 2 inches from the starting point.\nTo work out how much excess fabric we need to leave, measure from the finishing point and the start of the second stitch line (it should be about 5 inches). You can use a pin or pen to mark the location. Then cut your excess fabric. You should have about 5 inches of fabric left to tuck into the little pocket of the binding.\nBefore we tuck the end of the strip into the pocket, we need to trim a little bit of fabric off the raw edge. This will just help the strip to sit flatter in the pocket.\nPlace the end of the binding fabric into the pocket created at the start of the binding process. Pin in place.\nContinue to stitch the seam until binding is completely sewn on.\nNow we need to iron the binding. Fold the binding over the border towards the front and iron the seam flat.\nNow turn the runner/ hanger over so you are working on the front.\nWe started at the corners of the quilt. Fold in one side of the corner JUST past the stitching and iron well. Pin in place. This will help with getting the nice pointed corner. Repeat for the other side of the corner meeting up with the first fold creating a nice pointed corner. Repeat for all four corners of the runner/ hanger.\nThen continue folding and pinning the remaining binding to the front of the runner/ hanger, JUST past the stitching. Once folded, iron well.\nStart stitching anywhere on the front of the runner/ hanger, between the peeper and outer layer of the binding. When you get to the corner, simply just leave your needle down and lift the foot and rotate the runner/ hanger. Put your foot down and continue stitching in this fashion until you are right around the runner/ hanger.\nIron the binding and enjoy!\nThese pictures are our Stained Glass Blocks design.\nIf you would like to learn more about In The Hoop (ITH) Machine Embroidery we have some wonderful tutorials, online groups and a ITH Machine Embroidery course available.\nOur Online Embroidery Groups are a wonderful way to stay in touch with like minded ITH Enthusiasts, gain inspiration, share projects and get crafty in the hoop.\nWe have a wonderful ITH Machine Embroidery Course for those looking to learn a wonderful new hobby or gain a greater knowledge and further their techniques in the hoop.","March 01, 2021 4 Comments on How to Make Bias Binding & Button-Loops\nby Cynthia Anderson\nLearning how to make bias tape for binding is a liberating skill and one every sewist should have in their arsenal. Understanding all the possibilities available to you when faced with any task, gives you not only more options, but added confidence. In this blog you will learn how easy it is to make your own bias tape and how to use it to create a neat and clean finish to any raw fabric edge. You will then learn how to apply this same technique to make a front button-loop closure.\nBias tape can be used to cleanly finish the raw edge of fabric. The raw edge of the fabric is sandwiched between a strip of folded bias tape and stitched together to keep the fabric from unraveling and to create a finished edge. The bias tape is cut on the bias to allow it to slightly stretch and give, making it easy to smoothly go around curved edges. This is extremely important when binding a neckline or armhole. This finishing technique is used in any number of applications, like luggage and handbag construction... but most commonly used in making quilts and clothing.\nThere are a number of Folkwear patterns that incorporate bias tape binding! For this purpose of this blog, the Folkwear 108 Turkish Dancer pattern is featured. This pattern includes three easy to make and wear basic garments, an Entari (robe), vest, and cropped jacket. All three garments incorporate finishing edges using bias tape. And the Entari and vest both have a front closure made of button loops, using the same bias tape technique. Learning to make bias tape will open up a whole new world of sewing possibilities, and the 108 Turkish Dancer Entari is the perfect piece to entice and inspire you!\nYou can always purchase bias tape binding. However making your own is not hard, and it saves money, and helps give your scraps new purpose. And your creativity has no bounds!\nMaking Bias Tape\nThere are endless schools-of-thought, when it comes to making bias tape. However, the technique used in this video is ingenious and well worth learning, especially if you require copious amounts of binding and have a limited amount of yardage. This technique is also perfect for using up the scraps in your cabbage bin. The discouraging part of making your own seam binding often comes from the toil it takes to create one continuous strip that is long enough to meet the requirements of your project. While making bias binding is not hard, it can be bothersome to not have enough. This video is is a game changer!\nUsing a Bias Tape Maker\nOnce a long continuous strip of bias tape is cut to the width you plan to work with, the easiest and quickest way to make bias tape is to use a Bias Tape Maker. This handy tool is easily found where sewing notions are sold and are available in five different sizes; 1/4\"(6mm), 1/2\"(12mm), 3/4\"(18mm), 1\"(25mm), and 2\"(50mm). We have three commonly used sizes in our shop.\nIt is important to predetermine the size (width) of binding you intend on using, before you cut any strips. Typically, the pattern will provide you with a recommended width and length. In order for your bias maker to make neat and tidy folded edges, you need to use a strip of fabric that is appropriate size for the size of maker you are using. The width of the small end of the maker is the width your bias tape will be. This small end is half the width of the large end. Therefore, the width of your bias fabric strip should be double the width of the final results. For example, I am making a 1/2-inch (12mm) binding and my strip is 1-inch (25mm) wide. There is a little bit of wiggle room in the width of the strip you use in the bias tape maker tool. It is preferable to have just a hair too much than too less. The idea is for the folded edges to be as even as possible and for the folds edges to barely touch in the middle. If your fabric strips are too wide or too narrow it will not work so well.\nI am using a bias strip that is 1-inch wide. Insert the bias strip into the widest end of the the Bias Tape Maker, using a straight pin in the slot on the top of the tool, ease and pull the fabric strip through the small end. See the photos below to see how to get started feeding the bias strip through a Bias Tape Maker.\nKeep the strip evenly fed through the wide end. This will help in keeping the folded edges even as the strip comes out the other end. Pull slowly, using the folding handle on the the Bias Tape Maker, pressing with a stream iron, as the folded tape comes out the end. Use the steam of the iron as you go to set the folds of the strip. The Bias Tape Maker folding handle ensures your fingers are as far from the steam of the iron as possible.\nThe following photos illustrate how to use the Bias Tape Maker in tandem with a steam iron. Of course, you can make your own bias tape, by meticulously measuring, folding the sides toward the middle, and trying to avoid singeing your fingers, but it is not recommended.\nNext fold the folded strip in half length-wise and press again to set the fold. This creates the binding, and makes it a \"double fold bias tape\". Take your time to ensure a nice fold. Ideally, you want to fold and press so that the top edge is ever so slightly shorter than the bottom edge. The idea is that the underneath edge is wider, so that when sewing the binding from the top, the bottom edge gets caught in the stitching. See the photo below.\nIf required, trim the excess seam allowance according to pattern instructions. In this case, I trimmed leaving 1/8-inch seam allowance before attaching the binding.\nSandwich the raw edge of your fabric in the fold of the bias tape and secure in place using as many pins as needed to hold everything neatly together. Be sure to leave a bias tape tail of a few inches at the beginning and end of the edges you are working on (see third photo below). The tails will get trimmed and turned under in the end.\nUsing matching thread set the stitch length and tension so it is not too short or tight and not too long either. On my machine the this setting is around 3. Using a regular straight stitch presser foot on your sewing machine, place your work securely under the foot so that the fabric has good contact with the feed dogs. Use the edge of the foot as your stitching guide. In the photo below, you can see I am using the inner left edge of the presser foot as a guide. Position the needle so it aligns as close as possible to the inner edge of the bias tape, but not too close as to not catch the bias tape in the stitching. It might take a little fiddling to figure out what alignment configuration works best for you.\nOnce you are ready to stitch, take your time and stitch slowly to keep the stitches as aligned and evenly spaced with the edge of the bias tape as humanly possible. The idea, and sometimes the trick, is to catch the underneath edge of the bias tape in your stitching (this is why the tape is folded unevenly, as mentioned above). Often this is easier said than done. In part because you can not see the underneath of the fabric and the margin of error is hard to control. Do the best you can, knowing that it is highly likely that the underneath edge of the bias tape may have not gotten ALL caught in the stitching. It is ok. Simply enjoy a little hand stitching to secure the spots that were missed. You want to make the top of your bias tape stitching as neat as possible. This is the side that shows and therefore the only side that really matters. Remember, perfection can take the pleasure out of sewing.\nTo finish the raw ends of the bias tape edge, trim away any excess, leaving enough turn under the edges of the bias tape according to the pattern instructions (usually 1/4-inch). Using your fingers or pins to hold the folded under edge in place, use a simple hand whip stitch to secure neatly into place. There are times when only hand stitching gives you the control you need. Below is a photo showing the pointed edge of the Entari sleeve hand stitched to finish. Notice how the binding is turned under and meets at a neat finish.\nThat's it bias tape made and edges beautifully finished.\nNeck line edge finished.\nSleeve edge finished.\nMaking the Front Button-Loop Closure\nThis same easy bias tape technique is used to make the front button-loop closure for the Entari (robe) and vest featured in this pattern. These techniques are not exclusive to this pattern, but can be used on any garment that needs an interesting closure or a simple finishing detail. Not only is this perfect as a front closure, but works beautifully for a front or back neckline detail, a sleeve or cuff closure, a vent detail, or anything else you can dream up.\nBias Button-Loops Tips and Techniques\nWhen making binding and loops the only rule is to avoid fabrics that want to unravel. Depending on your experience level and bravery, you may want to avoid fabrics that are too slippery or heavy to start with. Lighter-weight stable fabrics are much preferred when first attempting to make button-loops out of bias binding.\nWhen making your own binding for button loops, consider how large or small button-loops need to be. This will in part depend on the size of the buttons, how many buttons, and spacing of the buttons and loops. Logically... small buttons will function and look better with small loops. Large buttons will need larger loops and more space.\nAesthetics and personal preference plays a part as well. The pairing of buttons and button-loops is an opportunity to get creative. Consider how much you want this detailing to stand out or fall back. Make the most of of the details in anyway that you choose.\nAs before, the fabric will need to be cut on the bias, in a fabric with a weight that will allow the fabric to nicely fold in on itself... just like we did with the edge binding. The bias cut will also allow your button-loops to bend and loop smoothly. By keeping your binding and button-loop fabric choice relatively light-weight will help avoid bulk and ensure ease of making, especially if you are working relatively small, as I am with this project.\nMake the binding tape as you have already learned to. Fold the tape evenly, with the edges matching this time, and press to create clean edges. Pin to hold the fold securely in place with as many pins as deemed necessary. See the photos below illustrating these instructions.\nStitch as close to the edge as possible, being sure the top and bottom edges are caught in the stitching. See the photos below.\nNow, that the binding tape is sew together, cut out the number of loops you need in the length needed, or according to the pattern instructions. You need to determine what buttons to use and their spacing out ahead of time.\nMake a loop out of each cut strip, keeping the stitched edge turned to the inside of the loop. This detail simply makes for a cleaner looking loop. Be sure that all the loops have the stitched edge situated in the inside of the loop.\nWith each stitched inner edge of the loop touching, machine stitch each loop together approximately 1/2-inch (12mm) in from the raw edges. Sewing the loops together now will eliminate fiddling with trying to place them later.\nGive the loops a bit of a study and take notice of what is the the right and wrong side of each loop. The loops in the photos pictured so far, are all right-side up. The scoop-shape of the loop will cradle the buttons and create a secure closure.\nTurn each each button-loop wrong side up, as pictured below, and this time secure the loops again a little further up toward the loop. Instead of using the machine this time, simple use two or three whip stiches to secure. The idea is to close each loop up just a bit more, without the stitching showing on the front side.\nSet the loop making aside for now. It is time to make the strips that the button-loops and buttons will be sewn to, creating the front closure to the 108 Turkish Dancer Entari pattern.\nThe button-loops and buttons need a platform or base that is both stable and strong. The closure point of any garment is considered a stress point, because of all the wear and tear this area inevitably experiences. So, this time the two strips will be cut on the straight grain and not the bias. Remember, bias stretches and gives. Therefore, not the stability and strength needed this time.\nCut two strips of fabric on the straight grain according to the pattern instructions. Again use the Bias Tape Maker to make strips with neat folded edges. Turn under the top and bottom edge 1/4\" (6mm) and press.\nWith wrong sides together, pin and then stitch the button-loop strip to the right front, sewing around all edges to secure. Be sure the button-loops point toward the center front.\nEven if you use a heavier weight fabric for the garment, the binding and loops could be made of a lighter weight fabric. It is perfectly fine to mix fabrics - just be sure to launder before cutting!\nNow, sew the buttons to the left front so they correspond to the loop placement. You may find that a button with a shank works the best when using small loops.\nSeptember 15, 2023 6 Comments on How to Make Bias Binding & Button-Loops"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:8e681a6f-9f55-4f38-80c4-86ae1507ae7b>","<urn:uuid:3a23fc3a-95a9-4500-850b-159142efd73e>"],"error":null}
{"question":"What's the main benefit of using animal classifications in scientific studies? 🤔","answer":"Animal classifications make the identification and study of animals easier, as they group animals based on certain characteristics that each class has in common.","context":["Topic or Unit of Study Animal Classifications\nGrade/Level Grade 3\nWith the completion of the Animal Classifications lesson, students will understand and know the following: 1. Students will know what classification means. Classification is the arrangement of objects, ideas or information into groups. 2. Students will understand that the objects or members of a particular classification have one or more characteristics or behaviors in common. 3. Students will understand that classifications are made throughout our society in many different ways. 4. Students will understand that classifications are made in science, with the classifications of animals and plants. 5. Students will understand that scientific classifications of animals are made on the basis of certain characteristics each class have in common. 6. Students will understand that the identification and study of animals is made easier with the use of animal classifications. 7. Students will be able to identify the seven major animal classifications, and why animals are in the same class or in a different class.\nThe Animal Classifications Lesson will require students to use critical thinking skills and higher level thinking when learning the meaning of classification and how our surroundings are grouped and classified in different ways. Students will gain knowledge on the many characteristics of different types of animals. Students will learn how animal characteristics relate and differ from one another in order to form a class. Students will gain knowledge on the importance of grouping and classifying in the study of animals, science and everyday life.\nThis lesson gives students the opportunity and motivation to discuss and learn different classification schemes and how classifications are determined in science with different types of animals and also in the world around them. Through learning about different types of animals, students will learn to make observations and knowledgeable decisions about the similarities and differences amongst animals and how these relate to classifying animals.\n1. Begin this lesson by introducing the term classification to the students in discussion. Using the Smartboard, write the word \"Classification\" on the Smartboard Notebook, so the students can visually see the word. Write out the definition (for the sake of this lesson) underneath the word \"Classification\": \"The arrangement of objects, ideas or information into groups.\" 2. Encourage discussion amongst the classroom by asking students \"What are some things that we classify in our daily lives?\" Provide some examples to start off discussion: tools, food, clothing, furniture, etc. Continue discussion by explaining and pointing out to the students why things around us are classified. Explain to students the similar characteristics between each classification. Also, explain to students the differences between the characteristics of different classes of objects. 3. Ask students \"Why are things in our surroundings classified?\", \"Does classifying make our daily lives easier and more convenient?\" Use these questions to encourage students' curiosity, understanding and learning of classifications in our daily lives. Ask students \"Do you think that the study of science in animals and plants would be better with the use of animal classifications?\" Use informal assessment to take notice of the understanding and comprehension of “Classification” and how classification is used in our daily lives and how it is important to the study of plants and animals in science. 4. Bring the students attention to the Smartboard, bringing the short discussion on classification to a close momentarily. Through the Smartboard, show the Powerpoint presentation on the background of Animal Classifications. Click the..."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:30b50e80-cb76-4f7a-9c59-17e9e0e9de70>"],"error":null}
{"question":"I'm interested in the ancient history of the Inyo Mountains. What are the rules regarding archeological artifacts found in this area?","answer":"All archeological resources in the Inyo Mountains Wilderness are protected by law. It is not permitted to collect or damage prehistoric or historic artifacts, or damage prehistoric or historic sites. Historic cabins and the historic salt tram within the wilderness are also protected by law and should be visited with care, leaving everything in place for others to enjoy.","context":["The Inyo Mountains Wilderness is part of the 110 million acre National Wilderness Preservation System. This System of lands provides clean air, water, and habitat critical for rare and endangered plants and animals. In wilderness, you can enjoy challenging recreational activities like hiking, backpacking, climbing, kayaking, canoeing, rafting, horse packing, bird watching, stargazing, and extraordinary opportunities for solitude. You play an important role in helping to \"secure for the American people of present and future generations the benefits of an enduring resource of wilderness\"\nas called for by the Congress of the United States through the Wilderness Act of 1964\n. Please follow the requirements outlined below and use Leave No Trace techniques\nwhen visiting the Inyo Mountains Wilderness to ensure protection of this unique area.\nBureau of Land Management Information\nThe BLM portions of the Inyo Mountains Wilderness are managed under the same general wilderness prohibitions as the US Forest Service-managed land, consistent with the provisions of the Wilderness Act of 1964.\nCommercial use, organized group activity, competitive events and vending on all public land managed by the BLM requires a Special Recreation Permit. Commercial services are generally prohibited in wilderness areas. Section 4(d)(6)of the Wilderness Act allows those commercial services necessary for activities that are proper for realizing the recreational or other wilderness purposes of the areas. Special recreation permits will only be considered for the Inyo Mountains Wilderness area if the managing agency determines it is consistent with BLM management policies for wilderness and the Inyo Mountains Wilderness, and the requirements of the Wilderness Act. Please contact the Bishop Field Office for questions about activities on BLM land on the west side of the Inyo Mountains and the Ridgecrest Field Office for questions about activities on BLM land on the east side of the Inyo Mountains.\nMechanized vehicles are not permitted in any designated wilderness. Bicycles, off-highway vehicles, and other types of motorized vehicles are all forms of mechanized transport. Vehicles are permitted on the \"cherry-stemmed\" Cerro Gordo- Swansea Road only. Other former travel routes in the Inyo Mountains Wilderness are being restored to a natural condition. Please support the restoration efforts and do not drive off road.\nThe Cerro Gordo-Swansea Road was not included within the wilderness and remains open to vehicles. The road is very rough and is prone to washouts, particularly in areas where it travels through drainages. The road is classified as four-wheel drive technical and is recommended for high-clearance, short wheel base, four wheel drive vehicles only.\n2,220 acres that includes 1,200 acres of bristlecone pine, Pinus longaeva, on the Inyo Crest are designated as the Keynot Peak Area of Critical Environmental Concern (ACEC). The Keynot Peak ACEC is located entirely within the Inyo Mountains Wilderness and was designated to protect the scientific and aesthetic values of the bristlecone pine-limber pine stands. Campfires are prohibited in this area. Wood removal is allowed under permit only. Please contact the Bishop Field Office for further information.\nPeople have lived and traveled in the Inyo Mountains for thousands of years. All archeological resources in the Inyo Mountains Wilderness are protected by law. Do not collect or damage prehistoric or historic artifacts. Do not damage prehistoric or historic sites. The historic cabins and historic salt tram located within the Inyo Mountains Wilderness are protected by law. Please visit these areas with care and leave what you find for others to enjoy.\nForest Service Information\nGeneral Wilderness Prohibitions\nMotorized equipment and equipment used for mechanical transport is generally prohibited on all federal lands designated as wilderness. This includes the use of motor vehicles, motorboats, motorized equipment, bicycles, hang gliders, wagons, carts, portage wheels, and the landing of aircraft including helicopters, unless provided for in specific legislation.\nIn a few areas some exceptions allowing the use of motorized equipment or mechanical transport are described in the special regulations in effect for a specific area. Contact the Forest Service office\nor visit the websites listed\nfor more specific information.\nThese general prohibitions have been implemented for all national forest wildernesses in order to implement the provisions of the Wilderness Act of 1964. The Wilderness Act requires management of human-caused impacts and protection of the area's wilderness character to insure that it is \"unimpaired for the future use and enjoyment as wilderness.\" Use of the equipment listed as prohibited in wilderness is inconsistent with the provision in the Wilderness Act which mandates opportunities for solitude or primitive recreation and that wilderness is a place that is in contrast with areas where people and their works are dominant.\nWilderness managers often need to take action to limit the impacts caused by visitor activities in order to protect the natural conditions of wilderness as required by the Wilderness Act of 1964. Managers typically implement 'indirect' types of actions such as information and education measures before selecting more restrictive measures. When regulations are necessary, they are implemented with the specific intent of balancing the need to preserve the character of the wilderness while providing for the use and enjoyment of wilderness.\nThe following wilderness regulations are in effect for this area. Not all regulations are in effect for every wilderness. Contact the Forest Service office\nor visit the websites listed\nfor more specific information about the regulations listed.\nMaximum party size is 15 persons and 25 head of pack or saddle stock.\nFood and refuse must be stored in a container designed to prevent access by bears, or counter-balanced at least 15 feet above the ground and 10 feet horizontally from a tree trunk.\nCamping is prohibited within 1/4 mile of springs with surface water.\nDo not deposit bodily waste within 100 feet of streams or trails. Do not discharge soap waste within 100 feet of surface water.\nDo not leave any debris, garbage, or refuse within the wilderness.\nStoring of equipment or supplies for more than 24 hours is prohibited.\nYou may not discharge a firearm, except for emergencies or hunting in accordance with state law.\nLearn more about why regulations may be necessary in wilderness"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:1fb18b61-e4fe-45c9-95e1-db420825cf33>"],"error":null}
{"question":"Does classroom teaching or ongoing training offer more flexibility?","answer":"Ongoing training offers more flexibility than classroom teaching. While teaching typically takes place in a fixed classroom setting with students seated in front of a teacher at a podium, training can be conducted in various environments and formats, including one-on-one sessions, group workshops, or online courses. Additionally, ongoing training allows agents to self-select skills they want to develop and participate in cross-training opportunities, making it more adaptable to individual needs and organizational requirements.","context":["Teaching usually takes place in a classroom setting, while training can be done in a variety of ways, including one-on-one sessions, group workshops, or online courses.\nThe major goal of training is to help people learn the skills they need to do their jobs better. However, teaching can also include training components, such as when a teacher provides students with exercises that will help them improve their skills.\nWhat does teaching mean?\nTeaching is the process of transferring knowledge and skills from one person to another.\nIt can involve formal education in a classroom setting, or it can be informal, such as when a parent teaches their child how to ride a bike.\nGood teachers are patient and skilled at explaining difficult concepts in a way that students can understand.\nThey also need to be able to adapt their teaching methods to different students and situations. The best teachers are passionate about their subject matter and enjoy helping others learn.\nWhat does training mean?\nTraining means the acquisition of knowledge, skills, or abilities through experience, education, or by being taught. It can also refer to the process of teaching someone how to do something.\nIn business, training is often provided to employees in order to improve their skills and help them be more productive.\nThe biggest benefit of training is that it can help employees learn new techniques and become more efficient in their work.\nIn general, training makes employees more valuable to their employer, which can lead to better job security and opportunities for advancement.\nTeaching vs Training\nOne of the biggest differences between teaching and training is that teaching is more formal.\nA teacher has a set curriculum that he or she must follow, whereas a trainer can tailor the lesson plan to meet the specific needs of the students.\nTeaching also involves more interaction with students, while training typically takes place in a more hands-off environment.\nMost importantly, teaching is about passing on knowledge, whereas training is about teaching people how to use that knowledge.\nImportant differences between teaching and training include –\nThe key difference between teaching and training is that the two terms have different purposes.\nTeaching is the process of transferring knowledge and skills from one person to another, with the goal of educating students.\nTraining, on the other hand, is the acquisition of knowledge, skills, or abilities through experience, education, or being taught with the goal of improving performance in a particular task or activity.\nAnother important difference between teaching and training is the process involved.\nTeaching involves explaining difficult concepts in a way that students can understand, and adapting teaching methods to different students and situations.\nTraining, on the other hand, generally involves practicing a particular skill or activity until it becomes automatic.\nThe subject matter of teaching is usually broader than that of training. Teachers need to be familiar with a wide range of topics in order to educate their students.\nTrainers, on the other hand, typically specialize in one particular area, such as carpentry or first aid.\nFor example, in business, training may be given on specific software applications, while teaching may cover the use of computers in general.\nThe duration of teaching is usually longer than that of training.\nTeaching generally takes place over the course of many years, as students progress through different levels of education.\nTraining, on the other hand, is often shorter in duration and may only last for a few days or weeks.\nWhile there may be some exceptions, this is generally true across different fields. This is another reason why teaching is often seen as a more involved process than training.\nThe motivation for teaching is usually to help students learn and achieve their potential.\nTeachers want their students to be successful in their academic pursuits and beyond. The motivation for training, on the other hand, is often more practical.\nTrainers want their students to be able to perform well in a particular task or activity.\nFor example, a football coach is not typically motivated by helping students learn, but by helping them win games.\nOne of the key differences between teaching and training is the approach that is taken.\nTeaching typically involves giving students information and allowing them to ask questions.\nIt is a more passive process than training, which often involves instruction followed by practice.\nThis difference can be seen in the way that teachers and trainers interact with their students.\nTeachers encourage questioning and debate, while trainers typically give instructions and then monitor students as they practice.\nThe environment in which teaching and training take place can also be different.\nTeaching often takes place in a classroom setting, where students are seated in front of a teacher who is standing at a podium.\nTraining, on the other hand, may take place in a variety of environments, such as a factory floor or an office.\nThis is because the focus of teaching is on transferring knowledge, while the focus of training is on practicing a particular skill or activity.\nAre teaching and training similar?\nDespite the different contexts in which teaching and training can take place, the main similarity between the two is that they both involve transferring knowledge or skills from one person to another.\nTheir similarities also extend to the goals of each activity – good teachers and trainers want their students or trainees to learn as much as possible.\nWhat are the 3 types of teaching?\nThere are three main types of teaching:\n- Direct Instruction\n- Delegate Teaching Style\n- Discussion Method\nDirect instruction is where the teacher stands in front of the class and delivers a lesson.\nThe delegate teaching style is where the teacher delegates tasks to students who then teach each other.\nDiscuss teaching style is where the teacher and students discuss concepts and ideas together.\nThe 3 styles can be used together to create a more varied and effective learning environment.\nWhy training is important?\nTraining is important because it helps people learn the skills they need to do their jobs effectively.\nIt can also help them improve their performance and become more productive.\nTraining can also increase safety awareness and help people stay up-to-date on new technology or procedures.\nWhat is effective training?\nThe term “effective training” can mean different things in different contexts.\nHowever, some key elements of effective training include providing learners with a clear overview of what they will learn and why it is important; breaking down information into manageable chunks; using a variety of teaching methods to keep learners engaged; and providing opportunities for learners to practice what they have learned.\nEffective training also takes into account the needs of different types of learners and provides appropriate support and feedback.","Create an Ongoing Agent Training Program\nOngoing training is designed to provide the knowledge, skills, and attitudes (KSA) needed to do the current job better and plant the seeds for jobs in the future. Training never stops. Most companies never get past the new hire training because they are too busy putting out new hire classes.\nExperienced agents receive an average of six training days per year. The best companies in the world recognize that training is not a single event but an ongoing process.\nWhen you invest in your current workforce today it will pay out big dividends when expansion and growth occur later. Your current workforce needs to grow and expand right along with the contact center. A best practice is to provide recurring refresher courses and cross-training opportunities for existing employees.\n– Refresher Courses\n– New product and services\n– Systems; applications and best practices\n– Personal and Professional development\nBasics Training – the Refresher Course\nThe best athletes know the power of practicing the basics. That’s all ballplayers do at spring training – practice the basics. Olympians spend years developing and practicing the basics. What agent skills, knowledge and attitudes should be reinforced?\nNothing is more basic than product training. Most companies are good at training employees on their products. For agents to be truly credible with customers they need to be thoroughly fluent in your product knowledge. Not just what products and services you sell but what those products do, how customers use them and how customers benefit. What issues do customers experience and why? This includes keeping up with new products and services. Agents can become product authorities when they have used the products, even if in a lab or classroom setting. When agents believe in your products and convey this belief with confidence, customers respect agents more and gain the trust needed to resolved calls on the first call.\nSystems & Applications\nNew hires are always rushed through new hire training; forced to learn new products, systems and proprietary applications. Bring them back after 90 days to review application best practices. Have your power users submit more efficient and effective ways to use the applications. They have figured out short cuts, tips and tricks. Cross-pollenate the knowledge. This can reduce your call times, improve first call resolution, reduce transfers and when you make the job easier you improve the morale and tenure.\nin a contact center the more flexible agents can be, the more resourceful the site can be to the changing marketplace.\nCross-training agents allows them to “fill-in” when the site is short-handed for whatever reason. Many times, one product line queue is busier than others and being able to shift agents who are already trained reduces costs by leveraging internal talent. No contact center can afford to have agents sitting idle because they only know how to do one function. The more your agents know the more valuable they become. The more flexible and responsible the site is to callers.\nCross-trained agents become a hiring pool for promotions, special projects and management. The more in-depth technical knowledge an agent has the more valuable he becomes to the site. Agents are motivated to stick around when the company invests in their career development. The company sends the message that it is genuinely interested in the agent’s career growth. Perhaps you allow the most motivated and driven agents to self-select the cross-training opportunities and you sit back and watch the rising stars.\nCross-trained agents smooth out the ebb and flow of productivity when agents are out due to illness, emergency, injuries and other unavoidable absences. Team members can easily cover for an absent team member when they already are skilled in the absent team member’s key tasks, products and system applications.\nCross training eliminates skills’ gaps keeping your site up and running and always productive. It motivates agents, keeps them engaged and constantly growing and evolving and you raise the skill level of your entire workforce.\nINDUSTRY SERVICE TIPS\n1. You are the Example. What continuous self-improvement program have you completed lately? How can you share what you learned with your team? What is one thing you can implement because of training?\n2. Cross Training – let agents self-select what skills, knowledge and attitudes they choose to develop. Watch the rising stars and groom them for management.\nOngoing agent skill development and training raises the level of knowledge, skills and attitudes for the entire workforce therefore making the contact center more productive, competitive and self-reliant. The most successful companies never stop after the new hiring training. They continue with refresher courses on products, services, system application, soft skills and technical skills.\nCross-training agents makes agents more valuable; they can fill in at a moment’s notice. Agents who have been cross-trained to do everyone’s job inside out and backwards become a go-to-person. Many times, these people are highly driven and motivated and become rising stars for promotions. Invest in your people and they will invest in the company with tenure.\nDon’t forget the compliance training and figure out how to make it fun! It is a vital part of the education and training plan and is usually the most dreaded to complete. Get the most out of the compliance training by making it more meaningful, applicable and engaging. You will not only meet the compliance requirement but employees will know how to apply regulations with complete knowledge integration.\nOngoing training is how the best keep getting better. Run to the finish line and collect the gold!\nCompliance training is essential to educate employees about the industry and governmental laws and regulations that pertain to their tasks and duties in the workplace. Compliance training is the most important training an organization can do and yet it can be an after thought and put on the back burner for a rainy day.\nWithout proper training, the company may be at risk of lawsuits and penalties. To avoid potential risk, conduct on-going compliance training to educates the workforce on current and new regulations. If your industry is highly regulated, you know that regulations rarely stand still and to avoid penalties ongoing compliance training is a must.\nCompliance training keeps agents updated on any regulation changes and how it impacts their jobs. The traditional “read and sign” compliance format is simple to implement but misses true knowledge integration. Many employees read the content and manage to pass the quiz at the end but are unable to apply it to their jobs. They fail to understand the regulations when asked about them. Regulatory auditors are seeing through the “read and sign” and are beginning to interview workers. The workforce must be prepared for compliance interrogation or jeopardize their entire operation.\nMaking compliance training as important as new hire and management training starts with a mindset shift. Compliance training doesn’t have to be painfully boring! The best compliance training courses are not only conducted in January but are integrated into your core business and reinforced throughout the year.\nNext step is changing the mindset of the instructional design team. They need to approach compliance training as problem solvers; creating learning that is timely, relevant, meaningful and actionable. Create engaging compliance courses that facilitate the application of the regulations for true knowledge integration. Bring legalese topics into the real world to provide context and meaningful applications. Instructional designers need to step it up and make compliance more fun.\nHolding training sessions helps employees understand the best practice standards and how to preform tasks more appropriately and efficiently. You develop a culture of compliance and how the culture values the laws, regulations, polices and procedures that it lives by.\nBuild your compliance training program around what laws and regulations affect job performance. What policies and procedures affect job performance? You can always layer in the “nice-to-know” material after the “need-to-know” has been mastered.\nVIDEO FROM OUR EXPERTS\nNETWORKING FOR CONTACT CENTER PROFESSIONALS\nNACSMA brings together like-minded professionals focused on advancing the customer contact industry and creating career growth.\nManagement of a best-in-class contact center sites require the continuous review of Agent Sourcing Models, Organizational Training and Management Development Programs.\nNACSMA is a professional, non-profit association whose members represent customer contact organizations and the vendors who support them.\nWhen a contact center organization expands to an additional site or requires new space, the steps to properly implement are unique to each organization but do have standard phases."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:09e96af1-d9f9-4e11-a72d-ea9e112f2ae3>","<urn:uuid:9c429c83-e0af-4526-8286-a0b0bc4652bd>"],"error":null}
{"question":"Hey wat are d differences between physical n financial elder abuse signs? Need 2 compare both typa abuse","answer":"Physical elder abuse signs include bruises, broken bones, scratches, blisters, torn clothing, poor hygiene, bedsores, and injuries that reflect object outlines. These signs are often visible on the body. Financial elder abuse signs include unusual bank activity, signatures that don't match, unpaid bills despite having a caretaker, unusual spending habits, lack of personal amenities, and the sudden appearance of strangers handling finances. While physical abuse typically leaves visible marks, financial abuse can be harder to detect as it involves monetary and documentation patterns rather than bodily harm.","context":["What are the elder abuse laws in SC?\nThere are few things more terrifying than suspecting that a caregiver is abusing your elderly mother, father, grandparent, or other loved one in a care facility or even in their home. When a caregiver who is entrusted with protecting a vulnerable adult instead takes advantage of or hurts them, the caregiver and their employer may be liable criminally and civilly.\nIn this article, we will discuss elder abuse laws in SC, including:\n- The SC Omnibus Adult Protection Act,\n- Criminal charges and civil lawsuits for elder abuse,\n- Types of elder abuse,\n- Warning signs of elder abuse, and\n- What to do if you suspect elder abuse.\nElder Abuse Laws in SC\nSC’s “Omnibus Adult Protection Act,” found at SC Code § 43-35-5, is intended to protect vulnerable adults in our state. A “vulnerable adult” could include any adult who has a physical or mental condition that limits their ability to care for themselves, including a person of advanced age or a resident of a care facility.\nSC law on elder abuse provides criminal penalties under some circumstances, but the caregiver or facility is also liable for damages for negligence or intentional abuse in the civil courts.\nBecause abusers often are not charged criminally, filing suit against the responsible parties and making them pay the maximum compensation allowable under SC law and the facts of your case is the primary way that we can hold abusers responsible for their conduct and prevent future cases of elder abuse.\nCriminal Charges & Civil Actions for Elder Abuse in SC\nSC Code Section 43-35-85 makes it a felony criminal offense to knowingly and willfully abuse, neglect, or exploit a vulnerable adult.\nIn civil court, we must prove either negligence or intentional conduct that resulted in harm to the elderly person. To be charged in criminal court, the state must prove intentional or willful conduct, which is a different standard of proof.\nAlthough a criminal conviction may be indisputable evidence of liability in your civil case, the abuser doesn’t need to be charged with a crime before we file suit or take action to protect your loved one.\nThe potential penalties for the criminal offense of elder abuse or neglect include:\n- Up to five years in prison for knowingly and willfully abusing, neglecting, or exploiting a vulnerable adult,\n- Up to 15 years in prison for knowingly and willfully abusing or neglecting a vulnerable adult when it results in great bodily injury, and\n- Up to 30 years in prison for knowingly and willfully abusing or neglecting a vulnerable adult when it results in death.\nTypes of Elder Abuse Under SC Law\nThere are many ways that a caregiver, neighbor, family member, or another person can hurt a vulnerable adult.\nBecause not all abuse results in visible injuries, the victim does not always report the abuse, and the abuser may be working to cover up the abuse, many cases of elder abuse go unreported, and the abuse continues undetected.\nThe types of elder abuse that family members should be on the lookout for include:\n- Physical abuse: including slapping, hitting, pushing, or any physical actions that result in bodily harm to the elderly person,\n- Psychological or emotional abuse: threatening, yelling, belittling, humiliating, or isolating the vulnerable adult,\n- Sexual abuse: any unwanted sexual contact with an elderly person or any sexual contact with an elderly person who is unable to consent due to their mental state or disability,\n- Neglect: failure to provide for the vulnerable adult’s personal needs, including bathing, hygiene, needed supervision, or access to medications, and\n- Financial exploitation: forging checks, use of credit cards or bank cards without authorization, misuse of a power of attorney, or taking a vulnerable adult’s funds or resources through trickery or coercion.\nSigns of Elder Abuse\nHow do you know if your loved one is being abused or neglected?\nBecause the abuser will most likely take actions to conceal their misconduct and medical issues like dementia or Alzheimer’s may call into question your loved one’s reports, it is necessary to investigate before filing a lawsuit or charging a caregiver with a crime.\nThere are many warning signs, however, that may justify taking further action. Some examples include:\n- Poor hygiene: Unwashed hair, dirty clothes, body odor, and other signs that a vulnerable adult’s personal hygiene needs are not being looked after is a red flag that may indicate neglect,\n- Bruises, broken bones, or other unexplained injuries: Unexplained falls that result in broken bones, scratches on the arms or face, or other unexplained injuries could indicate physical abuse or defensive wounds,\n- Bedsores: Bedsores could be an indication that caregivers are failing to turn a patient, assist them to a chair, or walk with them as needed, and this is another form of neglect,\n- Unexplained anxiety, fear, or emotional response: If your loved one suddenly begins to panic when you are leaving them, it could be a red flag that they are afraid of someone or something at the facility,\n- Unexplained financial activity: Unauthorized ATM withdrawals, unexplained credit card purchases, or a lack of funds to pay bills could be a red flag indicating financial exploitation.\nWhat to do if You Suspect Elder Abuse\nIf you suspect elder abuse, you should ask questions and investigate further. If you are a mandated reporter, you must report the abuse if you “have reason to believe” that the abuse has occurred or is occurring.\nIf you are not a mandated reporter, you must still report elder abuse if you have “actual knowledge that a vulnerable adult has been abused, neglected, or exploited.”\nMandated reporters listed in SC Code Section 43-35-25 include a “physician, nurse, dentist, optometrist, medical examiner, coroner, other medical, mental health or allied health professional, Christian Science practitioner, religious healer, school teacher, counselor, psychologist, mental health or intellectual disability specialist, social or public assistance worker, caregiver, staff or volunteer of an adult day care center or of a facility, or law enforcement officer.”\nFailing to report elder abuse is a misdemeanor criminal offense that is punishable by up to a year in prison.\nQuestions About Elder Abuse Laws in SC?\nIf you suspect that your loved one is being abused at a nursing home, elder care facility, or in their home, your SC elder abuse lawyer can help you to investigate, take steps to protect your loved one, and file a lawsuit for compensation on their behalf.\nCall the Law Office of Nicholas G. Callas, P.A. at 803-369-3968 or contact us through our website for a free consultation.\nReady To Speak With An Attorney?\nLet’s discuss the details of your case and see if we can help.","Legal Issues and Resources For Seniors\nSeniors may have unique or different legal needs and issues from their younger friends and family. The information here is not meant to provide a comprehensive guide to these issues, but rather provide a useful starting point for seniors and their families. A great site for more information is the California Department of Aging, which offers a wide variety of programs and services. For specific legal issues relating to seniors, you might also want to check out the State Bar of California’s Seniors and the Law.\nIn addition to the information on this page, you might also want to see our pages on:\nElder abuse can be physical and it can also be financial. Elder abuse is a problem and it is a crime. That’s why the Attorney General has a Bureau of Medi-Cal Fraud and Elder Abuse. A copy of the Bureau’s Citizen’s Guide To Preventing and Reporting Elder Abuse is available here. To find out more about preventing elder abuse or if you suspect someone you know is being abused, go the Bureau’s website.\nAdditional information is also available from the California Department of Social Services Adult Protective Services. You may also contact your county adult protective services office or 24-hour abuse hotline.\nSigns of elder abuse\nUnfortunately, much elder abuse comes not from strangers, but from family members and caretakers. Below are some of the signs to look out for, but the presence of one or more of these does not necessarily mean abuse has occurred. Rather, it means that diligent attention to your loved ones or further investigation may be necessary.\n- Uncombed or matted hair\n- Poor skin condition or hygiene\n- Unkempt appearance\n- Patches of missing hair or bleeding scalp\n- Untreated medical conditions\n- Malnutrition or dehydration\n- Torn or bloody clothing\n- Scratches, blisters, lacerations, or pinch marks\n- Unexplained bruises, welts, burns, or injuries that reflect the outline of an object\n- Any injury that comes with an unacceptable or unbelievable explanation\nWhile physical abuse will often leave physical scars, elder financial abuse may be more difficult to spot. Here are some things to look for:\n- Unusual bank account activity\n- Signatures on checks and other documents that do not resemble the senior’s signature\n- Lack of personal amenities, like appropriate clothing and grooming items\n- Numerous unpaid bills when there is a caretaker supposed to be taking care of these\n- Unusual or different spending habits, such as purchasing things the elder doesn’t need or can’t use\n- The appearance of a stranger who is now handling the senior’s finances\nAbusers will sometimes use isolation to maintain control. Here are some signs to look out for:\n- The caretaker, which could include a family member, has isolated the senior from contact with others including family, visitors, medical care providers, spiritual advisers and clergy, or friends\n- The senior is not allowed to speak freely or have contact with others without the caretaker being present\nIf you suspect elder abuse call 800-722-0432 or file an Online Complaint Form.\nSCAMS DIRECTED AT SENIORS\nSeniors are likely to be the targets of scams designed to take advantage of them. Scam artists target seniors because they believe they may be more trusting, more easily scared, or more likely to be confused, even though these assumptions are not true of all or even most seniors. They are also targeted because scam artists believe, often correctly, that they are likely to have money and property for the taking. Unfortunately, the number and types of scams are numerous and consistently changing. That is why it’s important to always investigate fully before giving your money to a stranger or even someone on the other side of the phone claiming to be a family relative.\nWhile there are some scams directly aimed at seniors, seniors, like others, can be victims of any of the scams out there. Visit our Common Scams page for more information\nGrandma I’m in Jail – You get a phone call from someone saying, “This is your grandson, I’m traveling, and I’ve been arrested. Help, I need $500 for bail. Go to Walmart and send the money to the following….” Don’t panic. First ask questions to determine if it really is your grandchild. If they called you “Grandma” don’t say “Is this Michael,” ask “Who is this?” Ask him the name of his parents. Check with your son or daughter to find out if your grandchild is even traveling. Ask where the child is being held and confirm the information on the internet.\nThis is Medicare calling – It’s not hard for a scam artist to guess what health insurance a senior has. So you might get a call from “Medicare” about your coverage. They may try to sell you bogus additional insurance or just try to get your personal information so that they can steal your identity or bill Medicare for services you’ve never received. If you have any doubts about whether it is Medicare really calling, get their information and contact Medicare yourself. Monitor your Medicare account and contact it about charges for services you didn’t receive. You can also set up an online Medicare account at MyMedicare.gov.\nWe’ve got a great deal on your prescription - You should never assume that prescription drugs you buy on the internet are what you should be taking. They may be sugar pills. They may be something much more dangerous. If you’re unable to pay for your prescriptions, you may be eligible for assistance from the drug manufacturer. You may also contact the California’s Health Insurance Counseling and Advocacy Program (HICAP) to find out if there is a program to help you.\nWe’re so sorry for your loss (1) – Scam artists will attend a stranger’s funeral and seek out the surviving spouse and claim that the deceased owed the scam artist money.\nWe’re so sorry for your loss (2) – Unscrupulous funeral homes may try to take advantage of your grief by selling you burial items and other services that are unnecessary or inappropriate to your financial condition. Consider making arrangements for yourself and your loved ones before death. Don’t be ashamed to shop around and look for the best services for the best price. But make sure that the service provider is licensed by California’s Cemetery and Funeral Bureau. Check out the Bureau’s consumer page at http://www.cfb.ca.gov/consumer/funeral.shtml.\nHave I got a deal for you - If you get a telemarketing call, don’t make the purchase over the phone. Ask them to send you the information so you can review it. Get the company’s full name and address. Ask friends and family for advice. And never give out your credit card or financial information to strangers who call you!\nYou’ve won - If someone calls and says you’ve won a prize or a lottery, and all you need to do is pay the taxes or shipping and handling, don’t believe it. You shouldn’t have to pay money to receive something you’ve legitimately won. Ask for details in writing and check it out carefully.\nWe’ll pay you to live in your house – If you’re over 62 and own your own home, you may be eligible for a “Reverse Mortgage.” Reverse mortgages are designed to allow senior homeowners to convert the equity in their home into income to supplement other sources of income. There are situations when a reverse mortgage may fit your needs, but you should proceed cautiously. As with any financial product, there can be significant costs and significant disadvantages. Check them out carefully, shop around, and make sure you understand all of the risks and conditions involved. You don’t want to buy a product that might not pay off for decades or could put your family on the street. If you are considering a reverse mortgage, consult with trusted resources, such as family, your attorney, and your financial advisor, before making any significant investment decision. A helpful guide on reverse mortgages is available from the Consumer Financial Protection Bureau."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:269de100-6516-41c9-bd11-561d72f93755>","<urn:uuid:ab439b3e-d2f7-424d-b34a-fe1f80496b5e>"],"error":null}
{"question":"What are the main differences between Kaizen's team-based approach and Lean Six Sigma's collaborative methodology in process improvement?","answer":"Kaizen and Lean Six Sigma have different approaches to team collaboration in process improvement. Kaizen explicitly denies individual work and requires all activities to be done through team work, with teams typically consisting of two to four persons working on different topics simultaneously. The philosophy emphasizes that every employee must participate in continuous improvement, regardless of their role or title. In contrast, Lean Six Sigma relies on collaboration among team members with specific expertise, particularly recommending that organizations start with the Lean approach for general efficiency improvements, and then apply more technical Six Sigma statistical tools through a team of specialists when persistent process problems arise. Both approaches aim for quality improvement but differ in their team structure and implementation methodology.","context":["The philosophy of working and self-improvement is called Kaizen, so that we can always do better with the desire to achieve perfection.\nFeeded by Japanese traditions, Kaizen was developed according to lifestyle and adapted to the business world and then spread all over the world. The improvement in Kaizen’s philosophy focuses not on the outcome. Kaizen offers small but steady steps to achieve better. This results in long-term results. However, the business world of the West focuses on moving fast and getting quick results. Increasing competition, especially with globalization, rapidly changing technology and increasing customer expectations require faster action.\nAlthough Kaizen is not a result-oriented process, it should be kept in mind that improvements in the process will affect the outcome. Considering the continuity of process-oriented improvement, we can accept that this improvement will be permanent and effective. In this way, the employees can see and understand the effects of the work they are doing and the process they carry out on the result more clearly. This increases participation and motivates employees. Continuous Improvement: Kaizen\nKaizen’s main objective is to enable companies to do better, faster and more costly work. All problems that hinder access to these objectives should be found and eliminated. Therefore, the first Kaizen principle to be acquired is to recognize that there are problems. Problems are not to live, but to unravel. In other words, there can be no improvement in the place where there is no problem. The first step in solving problems is to accept them and make them visible. However, the process is not completed by solving the problem. It is necessary to take the necessary measures to ensure that the solution is reinforced and standardized and not to happen again.\nSince Kaizen is an improvement approach, the changes that require very large investments and that require everything from the beginning do not take place in this process. Therefore, studies such as great breakthroughs, inventions or the application of technological innovations are not addressed in Kaizen’s philosophy. Instead, it is necessary to target developments that will be achieved with less costly, demanding, pluralistic participation.\nIn Kaizen philosophy, man is very important. First of all, the human being is defined as the element that will solve the problem, not as one of the causes of the problem. People are expected to contribute to the solution of the problem rather than blaming each other, regardless of their duties and titles. Continuous improvement is the task of all employees, not only of the quality circle members. First, people should take care of their problems and find solutions to these problems in order to address organizational problems. If there are internal problems, it should be assumed that the existing problems are everyone’s problem and everyone is responsible for the problem. In this respect, it is not an issue in a company managed with the principles of Kaizen, which is unclear because everyone will have the problem.\nKaizen is human oriented, but should not be a, super odak employee who thinks, plans and implements these improvements. Kaizen denies individual work, underlining that all activities must be done with a team work. The team’s understanding of the Kaizen philosophy and the use of techniques makes it possible for everyone to gain the ability to solve problems after a while.\nKaizen application process consists of four main steps;\n- In this step the goals of recovery are determined. When determining a target, economic gains should not be targeted. Keep in mind that the goal is not more profit, but more quality.\n- The choice should be made as simple as possible, with little investment.\n- A team should be formed. Kaizen teams may be between two and four persons depending on the size of the targets. More than one team at the same time the company is expected to work on different topics.\n- Metrics are then determined for the measurements that should be improved. It is not possible to say that the problems have been solved or improvement has been made without the necessary measurements. Continuous Improvement: Kaizen\n- The resources needed for the team created for Kaizen should be provided.\n- The team analyzes the current situation using different analysis methods (such as five causes, cause and effect diagram, brain storming, pareto analysis), finds the root cause of the problem and plans improvements to be made.\n- In the planning phase, improvement works are implemented.\n- The plan needs to be fully implemented.\n- Data is collected at every step taken.\n- If the planned improvement works cannot be carried out, the planning phase is returned.\n- Kaizen team is following the application results to determine how much the targets have been reached and whether there is any deviation.\n- Deviations between the target and the occurrence must be within the pre-defined limits. If the deviation is too much, the planning phase is returned.\n- The recovered amount must be reported to the top management\n- Make sure that the improvement is permanent.\n- Therefore, the measures taken should be standardized and applied to the entire company. To achieve this, every employee in the company must be trained and informed to ensure that they are fully performed.\n- If necessary, checkpoints can be added to the process to ensure continuity of improvement.","Lean Six Sigma and a sample application\nLean Six Sigma is a concept that aims to improve process performance by minimizing waste and reducing variations. It is a method that combines Lean Manufacturing, Lean Enterprise and Six Sigma principles to eliminate waste and improve quality.\nThe origins of Lean Six Sigma can be traced back to 1986 when Motorola came up with strategies to compete with higher quality Japanese products. Japan used the Kaizen approach (continuous improvement) in product development to produce world-class products of high quality.\nIn the 1990’s, an American businessman called Larry Bossidy introduced Six Sigma in Manufacturing and soon after he was engaged to introduce the concept in GE.\nIn early 2000’s the two concepts of Lean Manufacturing (Reduction of waste) and Six Sigma (higher process quality leading to reduced variability) came together as a single concept called Lean Six Sigma. The concept then found acceptance in other industries such as Healthcare, Finance, Retail and Supply chain etc.\nLean focusses on eight kinds of waste (Muda is Japanese word for waste) inherent in processes;\nSix Sigma focuses on improving the quality of process outputs by identifying and removing the causes of defects and minimising variability in processes.\nLean Six Sigma aims to achieve continuous flow of quality outcomes, by exposing constraints between process steps and reducing variability between and within the process steps through a cycle of iterative improvements. Lean Six Sigma uses the DMAIC (Define, Measure, Analyse, Improve and Control) phases similar to Six Sigma.\nBasic Concepts of Six Sigma\nSix Sigma quality is a statistical term used to indicate how well a process is controlled in terms of its variability from the mean. It is a fundamental nature of any process that over time and scale, variations will creep in due to a variety of reasons or factors. The aim of Six Sigma is to keep the process running within acceptable limits from a mean (or arithmetic average of a process data set).\nThe word Sigma ( σ ) is the standard deviation or the spread around the mean or central tendency. In simple terms, Six Sigma quality performance means 3.4 defects per million opportunities. It is important to note that not all processes, products or systems need to function at Six Sigma quality level. Other than for critical processes involving high safety requirements, such as healthcare, pharmaceuticals, airplanes, manufacturing, etc. it is enough for most processes to function at 3 Sigma or 4 Sigma. The trade-off between achieving Six Sigma or lower levels of Sigma is simply cost and often it is not practical or cost-effective to aim for a high level of Sigma. The table below illustrates the number of defects per million opportunities (DMPO) at various levels of Sigma. It is easily evident as to how efficient processes need to be at Six Sigma level.\nSigma Level DMPO\n2 σ 308,537\n3 σ 66,807\n4 σ 6,210\n5 σ 233\n6 σ 3.4\nLean Six Sigma Case Study\nThe objective of this case study is to illustrate how to apply Six Sigma thinking and concepts to organizational problems and processes.\nImagine a retail organization that uses disparate core systems such as CRM (Customer relationship management), ERP (Enterprise Resource Planning), Analytics and Financial Accounting to run its business. This organization has 100,000 unique Customer master records that are regularly referenced in sales, order management, delivery, invoicing and accounts receivable transactions. Each Customer master record has 10 attributes associated with it as shown below;\nCustomer Master Records (100,000 unique records)\nCustomer Pricing Code\nThis structure implies that there are 1 million elements associated with Customer master data.\nThese Customer master records are created, referenced and updated separately by different individuals, in different departments and business units, depending on their role and function. For example, the Finance Department may manage elements of Customer master data relating to invoicing and accounts receivable. The Sales team may manage elements relating to Customer orders. As is typical in many organizations and situations, disparate systems and independent work functions cause the following issues with Master data;\nDuplicated master data across systems that are out of sync\nWasted effort in data maintenance\nErrors that get accumulated over time because of data changes made in multiple systems\nBusiness risk arising from poor governance, etc.\nDMAIC Approach to improve the process of data management\nThe DMAIC (Define, Measure, Analyse, Improve and Control) concept can be applied to the above case problem, as follows;\nDefine (The Problem)\nMaster Data, maintained separately in multiple business systems, has been observed to contain an unacceptable level of errors (defects) causing unnecessary manual intervention (extra processing) that is costing the organization money, business responsiveness and customer satisfaction.\nMeasure (The Process parameters and Sigma)\nAn important step in Six Sigma Analysis is to measure the key operating parameters of the process in consideration to understand current levels of Sigma (Standard Deviation from mean). The table below shows the impact of errors (Defects per million elements) in terms of cost and time. An error can be broadly defined as any situation relating to any Customer master data element that requires changes to data arising from any non-business driven reason. Sigma (standard deviation) can be determined by sampling in a specific section or department or the entire organization at data element levels or entire Customer Master record levels.\nIt has been assumed that it takes an average of 10 minutes to fix an error at a cost of $50/hour. These assumptions can be validated in the Analysis stage by end users or by Six Sigma experts.\nLet us assume that sampling shows there are likely to be 200,000 errors (20% of the total volume of Customer Master data elements). From the table, we can see that the current process of managing customer master data reveals a Sigma between 2 and 3, implying it is costing the organization at least $556,725 in remediating these process errors. It is useful to note that data volume may also grow at 20% year on year and with growth in master data volume there is also an increase in DMPO.\nAnalysis (Why are there errors in the process?)\nThe errors in the process may be occurring due to one or a combination of the following reasons;\nAsynchronous editing of Customer master data elements in different systems\nLack of a concept of Master data and downstream systems for data leading to uncontrolled changes\nLack of formal data governance policies and procedures defining how Master data is created and edited\nImprove (How can the process be improved?)\nThe process for managing Customer master data and its elements can be improved through several options;\nNominating one of the systems (CRM or ERP or Financial or Analytics systems) as the Master system for Customer data and setting up integrations between that designated Master system to propagate changes\nImplementing a centralized, organization-wide Master Data Management (MDM) system to manage and control all Customer master data. This MDM system will then propagate all changes to master data to all other systems referencing that data through integrations (This may be a costlier option but improve process accuracy the most and help achieve 4 σ or 5 σ efficiencies)\nSetting up a manual governance process to manage changes to Master data in all systems in a coordinated way (This may be the cheapest option but may not improve process accuracy significantly and in a sustained manner)\nControl (How can the process be controlled?)\nRegardless of which option is chosen to improve the process efficiencies, it is important to ensure that process parameters are regularly measured and action taken to remediate. This is done by implementing good data governance initiatives.\nLean Six Sigma is a concept that aims to improve process performance and efficiencies by reducing waste and eliminating errors. It relies on collaboration amongst team members to achieve that. Lean Six Sigma uses the DMAIC (Define, Measure, Analyse, Improve and Control) phases to reduce errors. As such it is a evidence-based, data driven approach to improvement that focuses on defect prevention. Lean Six Sigma initiatives improve customer satisfaction and profitability by reducing variation, waste and cycle time while promoting work standardisation and flow.\nIt is recommended that organizations new to the Lean Six Sigma begin by implementing the Lean approach to make the workplace as effective and efficient as possible, reducing waste and using value stream mapping to improve throughput. When process problems persist, the more technical Six Sigma statistical tools can be applied by a team of specialists in various areas of the overall process."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:12e4cff0-f671-45c8-8ad4-de1a6b2cb220>","<urn:uuid:02bb5903-0b04-4b5d-bf7f-7f6c52131372>"],"error":null}
{"question":"What are the contrasting approaches to labor market efficiency between developed and developing economies, particularly regarding employment mobility and market frictions?","answer":"Developed and developing economies show significant contrasts in their labor market efficiency. In developed economies, labor market frictions are primarily characterized by separation rates (job loss) and job-finding rates, with unemployment often being frictional (2-3%) due to people changing jobs. However, underdeveloped countries face more severe challenges due to market imperfections, transport bottlenecks, ignorance, and personal attachment factors, making labor significantly less mobile. While developed economies can focus on managing natural unemployment levels and maintaining NAIRU, underdeveloped countries must deal with chronic unemployment, disguised unemployment, and under-employment. These fundamental differences make the classical assumptions of perfect labor mobility within regions particularly unsuitable for underdeveloped countries.","context":["Reasons for Non-Conformance of Conditions of Foreign Trade in Underdeveloped Countries!\n1. The underdeveloped countries cannot afford to have free trade policy:\nThe Ricardian principle of “comparative costs” favours free trade for efficient production.\nIt is simply an extension of the theory of laissez faire to international exchange of commodities. The theory implies that trade between different countries should not be subject to any artificial restrictions in the interest of complementary benefits resulting from international specialisation. The theory may be correct in the case of trading countries which are equally advanced so that specialisation along the lines of comparative advantage may, of course, confer benefits on them.\nBut when applied to an underdeveloped country, the doctrine of comparative costs appears to be logically untenable and fallacious. Under free trade, there may be evils of cut throat competition, dumping, depreciation of currencies which may smash down the complementary character of international trade as assumed by the classicists.\nConsequently, free trade between an advanced country and an underdeveloped country may make the poor country poorer rather than give it any benefit. Moreover, the infant industries of a poor country have to be protected by tariffs otherwise they cannot survive in the growing competition from abroad under free trade.\nFurther, poor countries are basically primary-producing countries; in bargaining with the industrially advanced countries for the export of primary products against the import of manufactured goods, they always suffer adverse terms of trade.\nThe comparative costs theory deals with only the production aspect of international trade. It seeks to explain how total world production can be maximised through international specialisation on the basis of comparative costs advantage. But it fails to consider the distribution aspect of international welfare emerging through international specialisation.\nFree world trade will lead to unequal distribution of income and gain in favour of the industrially advanced countries. Thus, under free international trade, a rich nation always benefits at the cost of a poor nation. Therefore, if the tenets of the classical theory of comparative costs are to be strictly followed, the poor countries would remain poor forever.\n2. A developing poor country is not a static economy:\nThe doctrine of comparative costs assumes a static economy, where the supply of factors is fixed. In a developing economy, where new resources are being developed, this does not hold good; eventually the theory become inapplicable.\nThe fundamental problem of a developing country is not just the optimum allocation of resources on the basis of cost advantage and specialisation but that of uplifting the production possibility frontier by improving and developing the resources so that growth may be perpetuated.\n3. A poor country suffers from the problem of chronic unemployment and disguised unemployment:\nThe principle of comparative costs rests on the assumption of full employment equilibrium condition for each of the trading countries. This is far from being a reality in any country of the present world. Moreover, a poor country is characterised by chronic unemployment, under-employment and “disguised” unemployment.\n4. In a planned developing economy there is a regulation on market mechanism and free competition:\nThe principle of comparative costs assumes perfect competition. This is, of course, an unrealistic phenomenon throughout the world. In a developing economy, where planning is adopted, a further blow is struck at the freely working price mechanism as assumed by the doctrine.\n5. A poor country has not perfect mobility of labour due to market imperfections:\nFurther, the Ricardian theory assumes that labour is perfectly mobile within a region. This is not true for any region whether it is developed or underdeveloped. However, due to market imperfections, transport bottlenecks, ignorance, personal attachment and such other factors, labour is relatively less mobile in an underdeveloped country than in a developed country. As such, the theory has least applicability to poor countries.\n6. Poor countries have to be more and more self-sufficient:\nMany poor countries also face foreign exchange crises and adverse balance of payments; hence regulation of foreign trade (specially imports) becomes an economic necessity for them and as such they cannot accept in toto the doctrine of comparative costs.\nThese countries have to be more and more self-sufficient, self-reliant and resort to import substitution rather than specialising merely in the production of primary products according to the comparative costs advantage principle.","What is Full Employment?\nFull employment refers to the state when every individual in the economy who is willing and able to work is employed. The employed workforce does not include senior citizens and students, as they are not willing to work. It may also exclude the personnel that are not physically fit to work.\nIt can also be understood as a situation where there is no involuntary unemployment. Under full employment, all resources in the economy are fully utilised. Efficient use of resources would enable the economy to reach the maximum level of output attainable by it.\nHowever, According to Keynes, full employment refers to that state when an increase in aggregate demand does not lead to a rise in the level of employment and output. Keynes also states that there would ideally never be full employment in the economy, due to a certain level of voluntary unemployment always being present in it.\nA full employment scenario occurs when the economy functions on the Production Possibility Curve and not below it. Every point on the PPF curve represents an efficient production level, where the resources are fully utilised.\nHow do economies reach full employment?\nFull employment is not a situation that can be practically observed. There always exists some level of unemployment in the economy. There can be many reasons for an economy to have unemployment. Based on these reasons, unemployment can be classified into the following types:\n- Frictional Unemployment: Frictional unemployment occurs due to the working population shifting jobs. When employed individuals want a change in their career, they might take a sabbatical from work, or stay at home to look for a new job.\n- Cyclical Unemployment: This type of unemployment occurs during the economic downturns in the business cycle. It might become severe during a recession, and it declines during a period of economic growth.\n- Structural Unemployment: It occurs due to technological changes which might lead to specific manual jobs becoming obsolete. As newer technology arrives in the market, people might lose out on their jobs.\n- Institutional Unemployment: It can occur because of unfavourable government policies, labour market phenomena and other institutional decisions that might lead to individuals losing their jobs.\nMany of these unemployment types are caused by external factors that are beyond the control of individuals. External factors like government policies, technological developments, and business cycle downturns end up hurting the availability of jobs in the market. Even if all the elements in the economy are favourable, individuals might be in between jobs, making them frictionally unemployed.\nIt becomes difficult to break down which type of unemployment might be prevalent if there are no clear market indicators. It is safe to say that most of these factors are hard to avoid or eliminate. However, once the government realises that there is unemployment in the economy, they can provide relief packages to unemployed people.\nFull employment can be understood as the “optimal level” of employment when unemployment is not 0, but there are no involuntarily unemployed people. Frictional unemployment may cause the unemployment rate to stay at around 2-3%. Thus, an unemployment rate of less than 3% is targeted by many economies to establish full employment in the economy.\nWhat is meant by NAIRU?\nNAIRU refers to the Non-Accelerating Inflation of Unemployment, which is the threshold to measure the level of unemployment. It is calculated by taking the historical relationship between the unemployment rate and any changes in inflation.\nIf the unemployment is maintained below the NAIRU, then there exists full employment. If unemployment exceeds NAIRU, then there are too many workers who are out of jobs. An indication of the economy at full employment implies that the wages must increase.\nNAIRU is also essential for central banks as it must be maintained while setting up interest rates. Central banks lower interest rates when unemployment is high and then increases the interest rates when unemployment is low. Full employment might also see an increase in inflation due to lack of supply of more labour felt by businesses. At the NAIRU level of unemployment, inflation is constant.\nWhat is meant by Full Employment GDP?\nFull employment GDP can be understood as a hypothetical level of GDP attained at the full employment level. It is the maximum output that a country can produce given its resources and their efficient use.\nThe natural level of GDP is different from the full employment level of GDP. Natural GDP corresponds to the natural level of unemployment in the economy.\nThere are frictions in the labour market because of two broad reasons: frictions in the separation rate and frictions in the job-finding rate. Separation rate can be understood as the rate at which an employee loses his job. When the conditions in the labour market are strong, the separation rate would be significantly lower. However, in the real-world scenario, separation rates can get relatively high due to various factors like imperfect information, asymmetric information, ill-defined labour contracts, etc.\nThe Job finding rate refers to the rate at which an average employee might find a job. An ideal situation would see workers finding jobs immediately. However, in the real-world scenario, it may take up a very long time for an employee to find a job that he/she likes. Because of this, real-world job finding rates can be extremely low."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"}],"document_ids":["<urn:uuid:8b13e8aa-a420-43d2-a5cf-a7318ae4065a>","<urn:uuid:720190e9-0f44-4f9b-803e-5e580868e361>"],"error":null}
{"question":"what r causes n treatments for hearing loss in construction workers and older adults?","answer":"Hearing loss has multiple causes in both construction workers and older adults. For construction workers, the main cause is exposure to hazardous noise exceeding 90 decibels, particularly from heavy machinery, jackhammers, and demolition work. For older adults, causes include medications (like aminoglycosides, chemotherapy drugs, and antiepileptic drugs), medical conditions (diabetes, renal failure, atherosclerosis), and exposure to industrial chemicals. Treatment options include prevention through proper hearing protection (both passive and active types), hearing aids that amplify sound, and cochlear implants for severe cases. Additionally, for older adults, auditory training programs and music listening can help, though the long-term benefits of training programs are controversial. Importantly, once the microscopic hair cells of the inner ear are destroyed, they cannot be regenerated through any known medical means, making prevention crucial.","context":["Rule Out Hearing Loss\nBoth experts emphasize that psychiatrists should be suspicious of potential hearing loss when treating an older adult who is showing signs of depression, anxiety, or cognitive impairment.\nThe quiet office room in which a psychiatrist typically sees patients will not yield the necessary information. “The worst place to test a person’s hearing is the office because this is usually not where the problem occurs. Rather, it takes place in groups of people or other settings where there is background noise,” Dr Blazer pointed out.\nPatients who require hearing tests should be referred to audiologists, who are the “entry point for people with hearing impairments,” he said.\nNevertheless, a simple screening test administered in the office can provide useful information. The Hearing Handicap Inventory for the Elderly–Screening Version can be a helpful way to start.11\nPatients who are already aware of a hearing impairment and even those already wearing hearing aids should still be referred for an evaluation of their hearing prior to determining whether they have a mood disorder or cognitive impairment because their hearing may not be sufficiently corrected by these devices, Dr. Frisina added.\nRisk Factors for Hearing Loss\nBecoming aware of risk factors for hearing loss may raise a clinician’s level of suspicion that the condition is affecting his or her patient.\nSeveral classes of medications are implicated in hearing impairments or hearing loss. Ototoxic medications include aminoglycosides and macrolides, certain cancer chemotherapy drugs (eg, cisplatin), and loop diuretics.12 Long-term use of nonsteroidal anti-inflammatory drugs and acetaminophen is also associated with hearing loss.13 Some evidence suggests that salicylates, progestin, and sildenafil also increase the risk.11\nAntiepileptic drugs (eg, carbamazepine, phenytoin, valproate, lamotrigine, gabapentin, vigabatrin, and oxcarbazepine) can cause auditory and vestibular toxicities, so monitoring of patients taking these agents who are at high risk for audio-vestibular manifestations is necessary for appropriate preventive and therapeutic measures.14\nAdditional risk factors include male sex, exposure to loud noises, medical conditions (eg, diabetes mellitus, renal failure, atherosclerosis, immunosuppression, and head injury), industrial chemicals (eg, toluene and styrene), and tobacco use.11\nTips for Psychiatrists Treating Hearing-Impaired Older Patients\nProvide education. An important role that a psychiatrist can play in working with hearing-impaired older patients is to educate their families, Dr Frisina said.\n“Tell the family that granddad isn’t ignoring you and doesn’t have dementia, but rather has a hearing loss that should be treated with hearing aids,” he suggested.\nFamily members should be made aware that speaking louder does not help and, in fact, often creates auditory distortion. “It is better to speak more clearly and more slowly, and to allow the person to see the face, get facial cues, and read lips,” Dr Frisina advised.\nEducating the patient about his or her condition and what can and cannot be realistically expected from hearing aids and other interventions is also key. The NIDCC provides helpful fact sheets that can be given to the patient.1\nRefer patients to audiologists. “Audiologists do not just prescribe hearing aids,” Dr Blazer pointed out. “They offer many techniques to help people cope better with hearing loss.” They can also be active in helping patients deal with tinnitus, which is a common and extremely challenging problem.\nHe added that many hearing instrument specialists who fit people with hearing aids can also provide the patient with useful tips for adapting to hearing loss.\nRefer patients to auditory training programs. “The literature underlying auditory plasticity following placement of sensory devices suggests that additional auditory training may be needed for reorganization of the brain to occur and optimal performance from devices to be obtained.”15 Certain programs can also be accessed using web-based formats and smartphone technology.15\nAuditory training programs are often offered by audiology centers that specialize in the elderly. “A university or good hospital with an audiology department would be a good place to start if you want to refer patients for auditory training,” Dr Frisina said.\nDr Frisina warned that the long-term success of these programs in improving hearing is “controversial.”\n“We know they can make improvements while the person is in the program, but it is unclear if there are lasting benefits after the training program ends.”\nStill, he added, “It won’t hurt and it will help while the patient is in the program.”\nEncourage patients to listen to music. Music has shown effectiveness in providing neuroprotection.16 Dr Frisina called music “a special stimulus,” noting that in people with dementia and even advanced Alzheimer’s disease, “the last meaningful auditory stimulus is music. Some patients who are unable to understand commands can still dance or sing with the music.” He cautioned that music should not be too loud, which could cause further hearing damage.\nAs the baby boomers continue to age, the prevalence of hearing impairments in older adults will continue to rise. It is essential for psychiatrists to be aware of the interplay between hearing loss and mood disorders and to address the hearing loss before reaching a diagnostic conclusion or treatment plan.\n1. National Institute on Deafness and Other Communication Disorders (NIDCD). Hearing Loss and Older Adults. Available at: https://www.nidcd.nih.gov/health/hearing-loss-older-adults. Updated July 17, 2018. Accessed August 31, 2017.\n2. Packer L. The complex link between depression and hearing loss. Healthy Hearing. Available at: http://www.healthyhearing.com/report/52437-The-complex-link-between-depression-and-hearing-loss. July 27, 2017. Accessed September 4, 2019.\n3. Li CM, Zhang X, Hoffman HJ, Cotch MF, Themann CL, Wilson MR. Hearing impairment associated with depression in US adults, National Health and Nutrition Examination Survey 2005-2010. JAMA Otolaryngol Head Neck Surg. 2014;140(4):293-302.\n4. Monzani D, Galeazzi G, Genovese E, Marrara A, Martini A. Psychological profile and social behaviour of working adults with mild or moderate hearing loss. Acta Otorhinolaryngol Ital. 2008;28(2):61-66.\n5. Lin VYW, Black SE. Linking deafness and dementia: challenges and opportunities. Otol Neurotol. 2017;38(8):e237-e239.\n6. Davidson JGS, Guthrie DM. Older adults with a combination of vision and hearing impairment experience higher rates of cognitive impairment, functional dependence, and worse outcomes across a set of quality indicators. J Aging Health. 2019;31(1):85-108.\n7. Genther DJ, Frick KD, Chen D, Betz J, Lin FR. Association of hearing loss with hospitalization and burden of disease in older adults. JAMA. 2013;309(22):2322-2324.\n8. Iwagami M, Kobayashi Y, Tsukazaki E, et al. Associations between self-reported hearing loss and outdoor activity limitations, psychological distress and self-reported memory loss among older people: analysis of the 2016 Comprehensive Survey of Living Conditions in Japan. Geriatr Gerontol Int. 2019;19(8):747-754.\n9. Frisina RD. Age-related hearing loss: ear and brain mechanisms. Ann N Y Acad Sci. 2009;1170:708-717.\n10. Choi JS, Betz J, Li L, et al. Association of using hearing aids or cochlear implants with changes in depressive symptoms in older adults. JAMA Otolaryngol Head Neck Surg. 2016;142(7):652-657.\n11. Walling AD, Dickson GM. Hearing loss in older adults. Am Fam Physician. 2012;85(12):1150-1156.\n12. Landier W. Ototoxicity and cancer therapy. Cancer. 2016;122(11):1647-1658.\n13. Lin BM, Curhan SG, Wang M, Eavey R, Stankovic KM, Curhan GC. Duration of analgesic use and risk of hearing loss in women. Am J Epidemiol. 2017;185(1):40-47.\n14. Hamed SA. The auditory and vestibular toxicities induced by antiepileptic drugs. Expert Opin Drug Saf. 2017;16:1281-1294.\n15. Olson AD. Options for auditory training for adults with hearing loss. Semin Hear. 2015;36(4):284-295.\n16. Kraus N, Zatorre RJ, Strait DL. Editors’ introduction to Hearing Research special issue: music: a window into the hearing brain. Hear Res. 2014;308:1.\nThis article originally appeared on Psychiatry Advisor","When considering construction worker injuries many people think of examples of injuries caused by physical accidents from impacts such as a fall from a ladder or scaffolding. However, there are many other types of injuries that occur in addition to those that occur from strictly physical accidents. In fact, one of the most common injuries suffered by construction workers is hearing loss.\nConstruction workers are often exposed to loud noises which make them especially susceptible to the loss of hearing. According to Audicus, there are around 30 million workers in the U.S. who are exposed to hazardous noise on the job.\nHazardous noise is defined as noise which exceeds 90bD (decibels) for an extended period of time. There is a 60 percent chance of construction workers losing their hearing if they are exposed to hazardous noise throughout their career.\nCompared to a 9 percent risk factor for no noise exposure, and a 30 percent risk in manufacturing, construction, along with mining, remain the top two high-risk professions in industry.\nThe Main Causes of Hearing Loss on a Job Site\nThe most common cause of hearing loss on a job site is intuitive: a lack of use of protective hearing equipment, which is required by law. There may be one of two common reasons why construction workers do not use hearing equipment.\nFirst, the employer may not make them aware of the risks of working in an environment with hazardous noise and may not provide them with appropriate hearing protection. Secondly, the worker may choose not to wear protective hearing equipment.\nA third, often overlooked, reason is that existing hearing protection may be insufficient. When hearing protection does not prevent hazardous noise from reaching the ear, or fails to do so effectively, the worker may be unknowingly exposed to excessive noise.\nLack of equipment to control noise can be a contributing factor to hearing loss as can failing to take breaks when working in an area containing hazardous noise. Finally, a lack of training about how to wear hearing protection can contribute to the risk of overexposure and hearing loss.\nWhere Hearing Loss Occurs\nHearing loss typically occurs in areas where noise levels exceed 90bD – the established noise level that is deemed “hazardous” to workers’ hearing. Job sites where workers are exposed to, or must use or interact with, heavy machinery, jackhammers, sledgehammers, nail and bolt drivers, electrical saws, and constant noise from demolition pose the most serious risk.\nWhen Hearing Loss Occurs\nHearing loss usually does not occur upon a single overexposure, although if the noise is loud enough, it may permanently or temporarily cause hearing loss. Permanent hearing loss occurs over time when repeated overexposure is experienced by the worker. Workers who reach the age of 50, and have been working in construction for at least several years prior, are the most likely to experience hearing loss.\nWorkers who start young, and enjoy a lifetime of work in construction, may be at an increased risk for hearing loss, particularly if their exposure levels exceeded the maximum threshold during most workdays.\nHow Hearing Loss Occurs\nHearing loss happens in one of two ways.\nConductive Hearing Loss:\n- Sound energy is blocked before it can reach the inner ear. This typically occurs because of an obstruction like earwax or a tumor is blocking sound from getting to the ear. This is typically not associated with damage caused by overexposure to noise or sound on a construction site, but it must be ruled out by a physician.\nSensorineural Hearing Loss:\n- Sensorineural hearing loss is a type of hearing loss which occurs because of some type of damage to the ear. Damage may occur to the inner ear or the nerves that are responsible for hearing (auditory nerves). Damage can also occur to the tympanic membrane (ear drum) which will prevent hearing.\nWith repeated overexposure to hazardous noise, construction workers are most likely to be exposed to sensorineural hearing loss at some point during their lives. Hearing does not immediate disappear. Rather, as damage accumulates, hearing gradually fades away.\nOver time, the individual may notice this manifesting as various symptoms. Symptoms of hearing loss include:\n- Muffled or distorted hearing;\n- Difficulty hearing high-pitched noises, like birds singing;\n- Difficulty hearing soft noises like crickets chirping;\n- Difficulty hearing alarm clocks, watch alarms, telephones, or doorbells;\n- Difficulty understanding telephone conversations while in public or where background noise is present; and,\n- Ringing in the ear, also called tinnitus, after overexposure;\nHearing loss can be mild, moderate, or severe. Mild hearing loss is usually associated with the inability to hear soft sounds or difficulty understanding speech in noisy environments. Moderate hearing loss occurs when workers are unable to hear soft and moderately loud sounds and have considerable difficulty understanding speech, especially background noises.\nSevere hearing loss occurs when some loud sounds are inaudible and communication is impossible or extremely difficult without a hearing aid.\nPrevention and Treatment\nPrevention is the best treatment. Loud noises are dangerous to human ears, and the impact they can have can be devastating. Noise levels of just 100dB for 15 minutes are enough to cause damage to the inner ear. 100dB is the “loudness” of a typical MP3 player at full volume.\nWorking in environments where construction is going on represent an inherent danger, because the noise level often exceeds the 100dB level. Once destroyed, the microscopic hair cells of the inner ear don’t grow back. They also cannot be artificially recreated by any known medical means. Once destroyed or damaged, permanent hearing loss occurs.\nTinnitus is just one symptom that results from the damage and destruction of those hair cells.\nIn addition to hearing loss, workers may experience nervousness, a reduced ability to concentrate, a reduction in the quality of sleep, an inability to get to sleep in a timely or efficient manner, reduced productivity, and an increased risk of work-related accidents.\nWorkers who lose their hearing are also more susceptible to feeling isolated and may have trouble communicating with co-workers.\nFor these reasons, workers should always wear specially-designed ear protection that is rated for the construction job and site they are working on. Hearing protection comes in two versions: passive and active.\nPassive protective devices or uniform-attenuating protectors use mechanical blocks or means to filter sounds to provide equal attenuation across the audible frequency range. Attenuation refers to the general reduction in strength of a signal. In the context of noise, it means the reduction of noise or sound. Attenuation is expressed in dB.\nThe sounds heard with passive protection in place are more natural, clearer and less distorted than protection provided by low-quality alternative or conventional hearing protectors. Workers who are continually exposed to loud noises benefit the most from this type of hearing protection. When communication is secondary to work, this type of hearing protection may be ideal.\nFor passive hearing devices to work, however, they must be properly fitted and used. As workers get hearing protection without distortion or muffling, they feel less isolated on the job site. If possible, the hearing protection device should be custom-fitted for the individual, and considerable time should be spent explaining the importance of always wearing hearing protection.\nSome workers may have the tendency to only wear hearing protection when they are currently working, but may not wear the protection when they have finished the job but are still on the construction site in an area where hazardous noise exists. Workers must wear their passive hearing protection until they are clear of hazardous noise areas.\nActive hearing protection or “level dependent” hearing protectors block sound and also use electronic means to transmit low-level sounds through the hearing protector.\nThe electric signal amplifies incoming sounds up to a specific level. Anything that exceeds that level is automatically reduced, thus preserving the wearer’s hearing through limiting and preventing overexposure.\nThese devices also employ amplifiers for background noise. Rather than providing equal attenuation, they provide it selectively. Loud noises, even sudden loud noises, are reduced to comfortable levels, while low dB noises are not muted or attenuated. The result is that the worker can carry on a conversation with another co-worker without the need for special communication equipment and without removing the protective gear, risking overexposure.\nElectronic devices also allow users control over the attenuation of hazardous noise, essentially allowing customization of hearing. These provide the best hearing protection in environments where hazardous noise occurs, but where communication is still important, even critical.\nAnother benefit of these devices is that special FM or infrared (wireless) capabilities can be integrated into the device to provide one or two-way communication. This allows workers to communicate with each other without risking overexposure to hazardous noise levels in situations where they are spaced apart and cannot effectively communicate by other means.\nAgain, for these devices to work, they must be properly fitted and worn during times when hazardous noise threatens the individual. Like the passive device, it should be custom-fitted and tested prior to use. Because it’s electronic, it should be inspected prior to each use to make sure that the power is on, or that the device is properly charged and functioning normally.\nPeriodic replacement and maintenance is necessary with these types of ear protectors, which makes them a more expensive option.\nHearing Aids, Implants and Resources\nOnce hearing loss occurs, options for treatment are limited. There is no official cure for hearing loss, but there are some treatments which may improve hearing or augment it. While cochlear implants are an available technology, they are still relatively expensive and full hearing restoration is not guaranteed. A second option is a hearing aid, which does not restore lost hearing, but rather amplifies sound, making hearing easier.\nGetting A Cochlear Implant\nCochlear implants have been approved by the Food and Drug Administration for children and adults who are deaf or severely hard-of-hearing. As of December 2012, there have been roughly 324,000 individuals worldwide who have had the procedure and received implants.\nIn the U.S., only 58,000 implants have been done. Some adults who have lost their hearing completely may be candidates for implants. For these individuals, they must relearn how to hear after the procedure and full hearing restoration is never guaranteed. Patients must learn to associate the signal provided by an implant with sounds they remember.\nHealth insurance may cover the procedure, but not always.\nThe implant itself consists of a microphone, which is capable of picking up sounds from the environment. A speech processor arranges sounds that are captured by the mic. A transmitter receives signals from the speech processor and then converts them into electrical impulses. Finally, an electrode array collects and transmits the impulses from the stimulator to various regions of the auditory nerve.\nThe implant will not restore normal hearing. Instead, it gives deaf or hard-of-hearing individuals useful representations of sounds in the environment. It can also help the individual better understand speech.\nA hearing aid is a device that is fitted into the ear which effectively amplifies sound. Hearing aides are commonly used by older adults or individuals who are hard-of-hearing. They do not replace the human ear, and are not a replacement for cochlear implants.\nInstead, they capture the sounds of the environment and convert them into electrical signals. The hearing aid amplifier increases the strength of the signal. Then, the aid converts the signal back into sound and sends it into the inner ear.\nThe brain hears and understands the sound just as it would unaided. The technology requires that the patients still have basic functional hearing and that the ear drum assembly, inner, middle, and outer ear are structurally intact. The labyrinth system of the ear must also be normal or at least not so abnormal that hearing becomes physically impossible.\nWhat Should You Do If Your Hearing Is Already Affected?\nIf you feel that the risks that you’re being asked to take are unreasonable, you’ve suffered hearing damage on the job, or if you’ve been injured in some other way on a construction site, don’t hesitate to speak with an attorney. You have rights, and you shouldn’t be afraid to assert them."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:28f98333-b6ad-4154-a263-22797d9e8f79>","<urn:uuid:21c43838-3700-4391-abaa-4c1da88fd373>"],"error":null}
{"question":"How do the fundamental challenges of implementing AI in enterprise settings compare between data-related issues and organizational integration concerns? Could you explain the key differences?","answer":"There are distinct challenges between data-related issues and organizational integration in AI implementation. On the data side, deep learning requires vast amounts of labeled training data to effectively train neural networks, making the sourcing and curation of high-quality datasets a critical challenge. Additionally, the models are computationally intensive, requiring significant resources. On the organizational integration side, AI technologies are relatively new to the business world, with few managers and enterprise technology professionals understanding these techniques. For successful implementation, AI practitioners and their methods need to be fully integrated into the enterprise fabric, requiring managers to have a basic understanding of AI/ML science, techniques, and success metrics. This integration demands different skill sets and approaches compared to traditional software products.","context":["Deep learning is an advanced subset of machine learning, a current and ever-evolving field of technology that has the potential to revolutionize the way we interact with and understand the world around us. In recent years, deep learning has gained significant traction, becoming a widely discussed and utilized technology in a variety of industries and applications.\nAt its core, deep learning is a complex algorithmic approach to building and training artificial neural network architectures. These networks are inspired by the structure and function of the human brain, with interconnected nodes, or neurons, that work together to process and interpret data patterns. Through the use of these neural networks, deep learning algorithms can autonomously learn to identify and extract features from large datasets, enabling them to recognize and understand complex patterns and make accurate predictions or decisions.\nOne of the key strengths of deep learning lies in its ability to handle unstructured data, such as images, videos, and natural language. This makes it particularly well-suited for applications like image recognition, speech recognition, natural language processing, and even autonomous vehicles. For example, deep learning algorithms powering self-driving cars can process visual input from cameras and sensors to quickly and accurately identify objects, pedestrians, and potential hazards in real-time, enabling the vehicle to make split-second decisions to ensure safety.\nThe breadth of potential applications for deep learning is vast and diverse. In healthcare, deep learning algorithms can be used to analyze medical images, diagnose diseases, and predict patient outcomes. In finance, they can help detect fraudulent transactions and make investment recommendations. In marketing, they can analyze customer behavior and preferences to personalize product recommendations. In manufacturing, they can optimize production processes and predict equipment failures. The possibilities are virtually endless, and as the technology continues to mature, we can expect to see even more innovative and impactful applications emerge.\nOne of the most significant recent developments in the field of deep learning is the use of generative adversarial networks (GANs). GANs are a type of neural network architecture consisting of two networks – a generator and a discriminator – that work together to produce realistic synthetic data. This has huge implications for tasks like image and video synthesis, where GANs can be used to create lifelike images of non-existent people, places, or objects, or even produce deepfake videos that are nearly indistinguishable from real footage. While the ethical considerations of this technology are complex, it’s an exciting testament to the power and potential of deep learning.\nIn addition to its practical applications, deep learning also presents a number of challenges and considerations. One of the most significant challenges is the need for vast amounts of labeled training data to effectively train deep neural networks. As a result, sourcing and curating high-quality datasets is a critical step in the deep learning process. Additionally, deep learning models are often large and computationally intensive, requiring significant computational resources to train and deploy. This can be a barrier for smaller organizations or research groups with limited resources.\nPrivacy and security are also major concerns when it comes to the widespread adoption of deep learning. As deep learning algorithms become more adept at processing and interpreting personal data, there is an increased risk of privacy breaches and misuse. It’s essential for organizations to implement robust data protection measures and ensure transparency in their use of AI-driven technologies to maintain user trust and compliance with regulations.\nDespite these challenges, the continued growth and advancement of deep learning hold immense promise for the future of technology and society as a whole. With ongoing research and innovation, we can expect to see even more sophisticated deep learning models that push the boundaries of what is possible and drive new breakthroughs in fields like healthcare, finance, education, and beyond.\nIn conclusion, deep learning is a foundational technology with far-reaching implications. Its ability to process, analyze, and interpret complex data is driving significant advancements in a wide range of industries and applications. As the technology continues to evolve, it’s important for organizations and researchers to remain mindful of the ethical and practical considerations that come with harnessing the power of deep learning.\nRecent news in the field of deep learning includes the release of OpenAI’s GPT-3, the third generation of their groundbreaking language prediction model. GPT-3 represents a significant leap forward in natural language processing and understanding, with the ability to generate human-like text and perform a wide range of language-based tasks, such as writing essays, answering questions, and even writing code. While the technology has generated excitement and intrigue, it has also sparked discussions around responsible AI use and the potential consequences of highly advanced language models in the wrong hands.\nThis recent development serves as a testament to the rapid pace of advancement in deep learning and the potential for profound impacts on how we communicate and interact with technology. As deep learning continues to progress, it’s critical for researchers, developers, and policymakers to collaborate on establishing ethical guidelines and standards for the responsible development and deployment of AI technologies. By doing so, we can ensure that the potential of deep learning is harnessed for the collective benefit of society, while minimizing risks and vulnerabilities.","Continue reading or Download a free copy of the complete e-book\nArtificial intelligence (AI) and machine learning (ML) are important emerging technologies that have the potential to transform organizations. Exponential increases in computational capacity, the emergence of cloud computing, and innovations in algorithms have resulted in tremendous advances in the application of AI. Leveraging AI and ML techniques, organizations can unlock tremendous value through improved customer service, streamlined operations, and the realization of new business models.\nDespite tremendous advances in the field over the last decade, AI remains very much the domain of expert data scientists. AI technologies are a complex subject and are relatively new to the business world; few managers and enterprise technology professionals have an understanding of these techniques. Furthermore, implementing AI techniques within the enterprise requires different skill sets and approaches from traditional software products.\nIn order for organizations to truly unlock value from AI, its practitioners and their methods need to be fully integrated into the fabric of the enterprise. This integration requires that managers have a basic understanding of the science behind AI/ML, the techniques leveraged, and the metrics used to measure success.\nManagers who are well-versed in the complexities of leading AI/ML efforts will be able to capture the most value from these new technologies. These managers will be able to select the best AI use cases, effectively collaborate and problem-solve with data scientists during prototyping phases, support the transition of algorithms into production use, and design the right business processes and change management activities to capture value for the organization. In order to achieve this, managers need a “field guide” to AI and ML techniques.\nAs we have designed, developed, and implemented AI techniques and AI-enabled enterprise applications at organizations across the world over the past decade, it has become clear to us that such a field guide does not exist. Most books and articles are either too technical, and focused on machine learning practitioners, or are too managerial without encapsulating sufficient mathematical and machine learning knowledge.\nThis online resource attempts to provide such a managerial field guide. It captures essential information about the practical application of enterprise AI/ML techniques, gathered from our extensive experience at C3 AI, across a wide range of industries and business problems. It also captures our experience with AI/ML teams – recruiting, organizing, and managing high-performance teams.\nLogic-based algorithms represent the core of traditional programming. For decades, computer scientists were trained to think of algorithms as a logical series of steps or processes that can be translated into machine-understandable instructions and used to solve problems. Traditional algorithmic thinking is quite powerful and can be used to solve a range of computer science problems, including data management, networking, and search.\nTraditional logic-based algorithms effectively handle many different problems and tasks. But they are often not effective at addressing tasks that are quite easy for humans to do. Consider a basic task such as identifying an image of a cat. Writing a traditional computer program to do this correctly would involve developing a methodology to encode and parameterize all variations of cats – different sizes, breeds, and colors as well as their orientation and location within the image field. While a program like this would be enormously complex, a two-year-old child can effortlessly recognize the image of a cat.\nML algorithms take a different approach from traditional logic-based approaches. ML algorithms are based on the idea that, rather than code a computer program to perform a task, it can instead be designed to learn directly from data. So instead of being written explicitly to identify pictures of cats, the computer program learns to identify cats using an ML algorithm that is derived by observing a large number of different cat images. In essence, the algorithm infers what an image of a cat is by analyzing many examples of such images, much as a human learns.\nAI algorithms enable new classes of problems to be solved by computational approaches faster, with less code, and more effectively than traditional programming approaches. Image classification tasks, for example, can be completed with over 98% less code when developed using machine learning versus traditional programming."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:0d08b97a-a0bf-4297-bb0e-9d390a06a8b5>","<urn:uuid:84ae65ad-4dcc-45dc-9304-366316d614bf>"],"error":null}
{"question":"Hi there! I'm curious about how our early life experiences shape taste preferences, and how genetics might influence our responses to food cues. Could you explain this relationship?","answer":"Taste preferences begin before birth, with the amniotic fluid containing various nutrients being our first food exposure. Maternal eating habits during pregnancy and nursing can influence children's taste preferences, as shown by studies where mothers' consumption of specific foods led to offspring preferring those items. On the genetic side, research has found that certain genetic variants are associated with increased appetite and food responses - particularly variants in genes like MC4R and FTO. The MC4R variant is linked to greater intake of high-calorie foods, while the FTO variant is associated with lower self-regulation of food intake. These genetic differences may make certain populations more susceptible to obesity by affecting how they interact with food cues in their environment.","context":["Obesity is complex but certain factors are simple. Obese people prefer calorie-dense foods because they taste better. That’s how we become obese. That raises an interesting question. Why do the least healthy foods taste so good? Rich, sugary, fatty foods aren’t good for anyone. Yet, everybody loves them. Why is that? Aren’t our taste buds supposed to be a protective mechanism? And, of course, why do overeaters seem to like calorie-dense foods more than normal eaters? As it turns out there’s more to taste than meets the tongue. Also, what meets the tongue in normal eaters and overeaters is very different. More importantly, these differences are a key part of the obesogenic puzzle.\nOrigins of Taste\nTaste appeared over 500 million years ago as a way of avoiding toxins and finding nutrients. All vertebrates have taste. Taste was so important to humans it changed our history; the European’s pursuit of spices launched the age of exploration.\nPersonal taste preferences begin before birth. In utero, amniotic fluid, which contains glucose, fructose, amino and fatty acids, is our first food. Humans also have an innate taste for sugar because newborns prefer the sweet taste of breast milk. However, maternal eating habits during pregnancy and nursing can influence children’s taste preferences. A study showed pregnant and nursing women who consumed anise, carrots, mint, vanilla, and blue cheese conveyed a taste preference for these items to their offspring. It’s basic survival. When a child begins eating solid food, eating what the mother ate is a safe bet. The taste preferences that start in the womb endure for a lifetime.\nThe Physiology of Taste\nWhen I think taste, I think tongue. So let’s begin there. There are four types of papillae (filiform, fungiform, foliate, and circumvallate) that give the tongue its rough surface. The filiform papillae only determine texture, but the fungiform, foliate, and circumvallate contain five different types of taste receptors (taste buds). Each taste receptor is densely packed with taste cells, which are capped with sensors. When these sensors receive taste signals, various neural pathways swing into action, saliva production increases, and stomach secretions activate. Five taste receptors correspond with the five known tastes: sweet, sour, salty, umami, and bitter. When I read that I thought, what, there are more than five tastes left on my fingers from my last meal. However, though they are often misused interchangeably, taste, taste perception, and flavor are not the same.\nTaste is a chemical process: Sweetness sensors react to sugar molecules. This relates to food with high caloric energy value. Sourness measures pH because humans have an aversion to acidic foods because they could be spoiled. Saltinessmeasures positive ions in alkali metals, in particular sodium, because of our need for mineral salt. Umami, the savory meaty taste, is detected by a receptor for glutamate. This detects protein. Bitterness is poorly defined. It may be an umbrella term for various chemical reactions that are toxic, because many dangerous compounds are bitter, although not all bitter foods are toxic.\nHot and astringent oral sensations are important, though not classified as taste or texture. When you eat a chili pepper, the capsicum molecule dissolves in your saliva. The trigeminal nerve triggers a burning sensation. This nerve also detects heat, cold, and pain. Although spicy is not classifiably a taste, it is a trigeminal sensation, like pepper, garlic, ginger, and menthol.\nTaste and the Other Senses\nI used to think taste was the only sense involved in enjoying food—not true. Actually, gustatory enjoyment is not taste, but taste perception. Taste perception involves taste, sight, hearing, touch, and smell. Besides taste, smell is the sense most engaged in the enjoyment of food. The olfactory epithelium detects aromas by interacting with odor molecules entering via the nose or the back of the mouth. It has millions of neurons, with specific receptors that combine odor molecules and subsequently produce an electrical impulse. This in turn transmits a signal to the olfactory bulb, then to the cortex and simultaneously to the limbic system, where human emotions and memories are stored. Also, smell is the only sensory input that is not first processed through the thalamus, the brain’s clearinghouse for sensory information. This direct connection to the limbic system is why smells can spark deep memories and very emotional responses.\nSmell is also more complex than taste. We have five receptors for taste. Taste occurs when molecules bind to these five receptors on the tongue. From there, signals travel to specific brain regions. We have 350 different types of receptors that can perceive over 10,000 different odors. When odor molecules bind to nasal receptors smell occurs and goes to certain brain regions. Chewing releases volatile molecules that go from the back of the mouth to receptors in the lining of the nasal passages. Odors traveling through the back of the throat while tasting are perceived differently in the brain. When taste and smell arrive simultaneously in the insula, the insula creates flavor because taste and smell have distinct overlapping pathways in the insula. This allows us to identify the combination of sensations that lead to flavor, which bears little resemblance to actual taste. That’s why food “tastes funny” when you have a cold. The taste is not missing, but the flavor is. You can determine, sweet, sour, salty, bitter, or umami, but not the flavor. For flavor, you need smell. It is the endless possible combinations of taste and odor that create our wide variety of recognizable flavors.\nVision is also essential to taste perception. We evaluate the aesthetics of food and then determine if it looks okay to eat. EEG studies have shown, compared to low-calorie foods, calorie-dense foods cause stronger cortical activity in the bilateral insula and frontal operculum. Pleasant changes in taste were correlated with medial orbitofrontal cortex activation. Even shape can affect taste perception. In one study, after subjects completed an unrelated task involving geometric figures, the taste perception of pointed pieces of cheese was sharper than rounded pieces of cheese.\nSound also affects taste perception, e.g., the sound of a crisp apple or potato chip. Studies have shown playing crisp audio cues, while apples are being eaten, enhances their taste perception.\nTouch is another marker for differentiating taste perception, e.g., a fresh juicy ripe peach compared to a mealy dry peach, or a very hard unripe peach. Nerve endings on the taste buds provide consistency and texture information about food. This is especially true of fats, e.g., the creamy feel of ice cream or the texture of a well marbled grilled steak, compared to a very lean cut. Dedicated neurons in the orbitofrontal cortex respond specifically to the texture of fat in the mouth. Feel influences taste perception in soda as well. The taste perception of flat beverages is much different than that of fully carbonated beverages.\nOvereating and Decreased Taste Sensitivity\nStudies have shown that the five tastes, except sour, have distinctive regional representations on the gustatory cortex. Those studies also say while bitter and sweet receptors are intermingled on the tongue they are separated by 2.5 millimeters in the brain. This could span hundreds of neurons. The brain is probably wired this way so that bitter resides in a region that drives aversion, and sweetness in an area of attraction. The important thing about this topographical segregation is that the encoding of taste signals can drive aversive and attractive behaviors. This could begin to explain why obese people are more responsive to certain foods.\nTaste receptors are unique. An overpowering sweetness to one tongue may be barely detectable to another. So, differences in satiety would also differ among individuals. This is especially important to overeaters. Conceivably a person’s taste receptors could mitigate taste perception and influence food preferences, eating habits, and subsequently weight management. Obesogenesis is complex, but studies increasingly suggest that taste receptors are a major factor. Continuous studies dating back as far as the 1950’s link a decreased ability to detect sweetness with obesity. So, is it possible that it is a decreased sensitivity to sweetness that actually causes overweight people to eat more sweets than regular eaters? Diminished ability to perceive taste, and subsequently encode flavor and satiation in the brain could be one of the reasons overeaters overeat. In other words obese people are seeking the same satiety levels that all people seek, but we just have a diminished capacity for determining when those levels are achieved because of a signal breach that begins with our taste buds. So, it’s not about liking sweets more, it is about needing more sweets to achieve satiety.\nCertainly, that’s theoretically possible, and according to scientists, probable. The overeater in me is ready to jump on that train—but one problem. I’m not a big sweet eater. I am a grease monkey, and not the kind that fixes your car. Like most obese people, I crave fat more than carbohydrates. “When I die, bury me deep, with a bowl of gravy at my feet, and a platter of deep fried fatty meat in my hand, and I’ll smack my way to the promised-land” has been my spiritual mantra for years. And fat isn’t even one of the basic five tastes. Hmm… looks like this train might not be coming. It’s curious all around. The tongue has receptors for two of the three mandatory macronutrients—sweet for carbohydrates, and umami for protein. It would logically conclude that humans would have some form of taste response for fat, the remaining macronutrient. While fat is not one of the basic tastes, it affects food’s taste perception, appearance, texture, and even smell. Obese people are much less sensitive at detecting fatty acids (the breakdown of fats) than people who are not overweight. This low sensitivity leads to significantly more fat consumption and subsequent weight gain. Predisposition to this can have various causes, beginning with genetics, in utero and neonatal exposure as well as signal breaches in taste sensitivity, flavor construction in the insula, and abnormalities in the orbitofrontal cortex.\nSo the key issues as I see them are the heavy involvement of smell with taste, and decreased sensitivity for detecting the five basic tastes, and fatty acid insensitivity, in achieving satiety. Could this be the reason normal eaters, “get enough” and I just never do when it comes to food? Also,direct communication between smell and the limbic system is a likely factor. Amygdala and hippocampal remodeling, due to adverse early life experience, has been reliably associated with obese populations. This raises the question, if the amygdal-hippocampal complex has undergone restructuring, how does this effect receiving, processing and responding to signals from the olfactory epithelium. That’s all fine and well: the train has arrived and we’re on it. Now for the important question: where is this train going, and more importantly where do we get off?\nThe bad news for chronic overeaters, such as myself, is that our taste detection, driving our taste perception, and subsequent eating habits is impaired and placing us in harm’s way. The good news is we can compensate for these breaches in taste detection insensitivity and change our taste perception. Stay tuned for the next post and we will explore that. Until then, remain fabulous and phenomenal.\nAraujo, I. E. (2003). [Taste representation in the human cortex and the central control of appetite]. Rev Bras Psiquiatr, 25 Suppl 2, 25-28, 77.\nBirch, L. L. (1999). Development of food preferences. Annu Rev Nutr, 19, 41-62.\nBiroh, G. G., & Mylvaganam, A. R. (1976). Evidence for the proximity of sweet and bitter receptor sites. Nature, 260(5552), 632-634.\nCabanac, M., & Duclaux, R. (1970). Obesity: absence of satiety aversion to sucrose. Science, 168(3930), 496-497.\nCarbohydrate taste, appetite, and obesity. (1987). Neurosci Biobehav Rev, 11(2), 131-262.\nChevrot, M., Bernard, A., Ancel, D., Buttet, M., Martin, C., Abdoul-Azize, S., et al. Obesity alters the gustatory perception of lipids in the mouse: plausible involvement of lingual CD36. J Lipid Res, 54(9), 2485-2494.\nCrow, J. M. Obesity: insensitive issue. Nature, 486(7403), S12-13.\nDegrace-Passilly, P., & Besnard, P. CD36 and taste of fat. Curr Opin Clin Nutr Metab Care, 15(2), 107-111.\nDonaldson, L. F., Bennett, L., Baic, S., & Melichar, J. K. (2009). Taste and weight: is there a link? Am J Clin Nutr, 90(3), 800S-803S.\nFrank, S., Kullmann, S., & Veit, R. Food related processes in the insular cortex. Front Hum Neurosci, 7, 499.\nGravitz, L. Food science: taste bud hackers. Nature, 486(7403), S14-15.\nGrinker, J. (1978). Obesity and sweet taste. Am J Clin Nutr, 31(6), 1078-1087.\nHarris, G. (2008). Development of taste and food preferences in children. Curr Opin Clin Nutr Metab Care, 11(3), 315-319.\nHuang, A. L., Chen, X., Hoon, M. A., Chandrashekar, J., Guo, W., Trankner, D., et al. (2006). The cells and logic for mammalian sour taste detection. Nature, 442(7105), 934-938.\nHumphries, C. Cooking: delicious science. Nature, 486(7403), S10-11.\nKane, F., & Law, M. E. (1950). Nerve connexions of taste-buds. Nature, 165(4207), 978.\nKhan, M. A. (1981). Evaluation of food selection patterns and preferences. Crit Rev Food Sci Nutr, 15(2), 129-153.\nMathieu, A., Liebermeister, H., Orlik, P., & Wagner, M. W. (1976). [Differences in taste assessment of sweeteners by normal and overweight persons]. Dtsch Med Wochenschr, 101(18), 703-708.\nMela, D. J. (2001). Determinants of food choice: relationships with obesity and weight control. Obes Res, 9 Suppl 4, 249S-255S.\nNasser, J. (2001). Taste, food intake and obesity. Obes Rev, 2(4), 213-218.\nPasquet, P., Frelut, M. L., Simmen, B., Hladik, C. M., & Monneuse, M. O. (2007). Taste perception in massively obese and in non-obese adolescents. Int J Pediatr Obes, 2(4), 242-248.\nSalbe, A. D., DelParigi, A., Pratley, R. E., Drewnowski, A., & Tataranni, P. A. (2004). Taste preferences and body weight changes in an obesity-prone population. Am J Clin Nutr, 79(3), 372-378.\nShepherd, G. M., Getchell, T. V., & Mistretta, C. M. (1986). Neurobiology. Questions of taste and smell. Nature, 324(6092), 17-18.\nSimon, Y. (1994). [Food preferences in obesity]. Rev Med Brux, 15(4), 259-261.\nStalling, R. B., & Sobotowicz, W. (1980). Obesity, compatibility, and a taste preference. Percept Mot Skills, 51(3 Pt 1), 871-877.\nSzalay, C., Aradi, M., Schwarcz, A., Orsi, G., Perlaki, G., Nemeth, L., et al. Gustatory perception alterations in obesity: an fMRI study. Brain Res, 1473, 131-140.\nThompson, D. A., Moskowitz, H. R., & Campbell, R. G. (1977). Taste and olfaction in human obesity. Physiol Behav, 19(2), 335-337.\nTrivedi, B. P. Gustatory system: the finer points of taste. Nature, 486(7403), S2-3.\nTrivedi, B. P. Neuroscience: hardwired for taste. Nature, 486(7403), S7-9.","Researchers identify how food word cues influenced by both stress and genetics can be associated\nwith increased food desire and intake\nFOR IMMEDIATE RELEASE\nNovember 3, 2015\nJohns Hopkins University:\nEkaterina Pesheva (Child and Adolescent Psychiatry): email@example.com, 410-502-9433\nSarah Weber (Global Obesity Research Center): firstname.lastname@example.org, 410-502-3332\nThe Obesity Society: Mollie Turner, email@example.com\nLOS ANGELES, CA: New research shows that brain responses to written food words differ between lean individuals and those with obesity, and suggests that both stress and genetics could influence excess eating.\nThe pair of studies led by Susan Carnell, PhD, member of The Obesity Society (TOS) and Assistant Professor of Psychiatry and Behavioral Sciences at Johns Hopkins University School of Medicine, reinforces the need to better understand how the external food environment interacts with our biology, and may aid the development of behavioral interventions to help individuals with obesity or those at high risk for the disease. The findings will be unveiled today during an oral presentation, and a poster presentation on Wednesday, Nov. 4, at The Obesity Society Annual Meeting at ObesityWeekSM 2015 in Los Angeles, CA.\nIn recent years, obesity researchers have greatly enhanced our understanding of “food cues,” which are internal or external environmental factors that influence the desire to eat. They come in many forms including emotions, images, smells, tastes and even food words. Food words could be considered a relatively minimal food cue compared with images or smells; however, because they are ubiquitous in advertising and other contexts they have significant potential to impact eating behavior.\nIn one study, the research team found that individuals with obesity were more likely to consume energy-dense foods (foods high in calories per unit of weight) compared to those of normal weight after experiencing stress. As seen in brain imaging scans, neural responses to high-calorie compared with low-calorie food words was also increased for individuals with obesity under both stressed and non-stressed conditions. To conduct the study, seventeen participants with obesity and 12 at normal weight underwent a functional magnetic resonance imaging (fMRI) scan during which they viewed words describing high-calorie foods, low-calorie foods and non-foods, and rated how much they wanted to eat each food item.\n“Our study found that individuals with obesity had a stronger response to words associated with high-calorie foods - such as chocolate spread and chicken wings - in a widespread neural circuit spanning multiple areas of the brain,” said Dr. Carnell. “When we subjected individuals to a combined social and physiological stressor, both individuals with obesity and those of normal weight showed slightly altered responses to high-calorie food words, but only those with obesity ate more at a subsequent meal. This suggests that people with obesity show a consistently different response to mere words describing foods than lean individuals. This could contribute to excess intake of energy-dense foods in both stressful and non-stressful environments.”\nIn the second study, the research team identified an association between higher genetic obesity risk in teenagers based on several known obesity-associated genetic variants and subjective responses to food words. In addition, one specific genetic variant, MC4R, was associated with greater intake of high-calorie foods during a laboratory test meal, while another, FTO, was associated with lower scores on a questionnaire measuring self-regulation of food intake.\nA genetic variant is a genetic difference that makes one individual or population different from another.\n“We all have tiny differences in our genome that affect how we interact with the surrounding environment,” says Carnell. “While some of the genetic variants we see may have helped people maintain a healthy body weight in the past, they could now be working against us, making certain populations more susceptible to obesity and diabetes.”\nTo conduct the study, the research team genotyped 35 adolescents between 14 and 19 years old with varying familial risk for obesity. Subjective appetite responses to food and non-food words were measured using a computer paradigm, and food consumption was measured in a laboratory meal that followed. Participants also filled out a questionnaire measuring habitual self-regulation of intake.\n“While we know that certain genetic variants are tied to obesity, our study provides additional insight into how these particular obesity-associated genetic variants may be working – by increasing appetite and food intake,” said Leora Benson, MS, research coordinator for the study. “The fact that many of these genetic variants act through eating behavior is exciting because behavior can be changed,” adds Carnell. “This research tells us that there may be ways we can help prevent individuals with these variants from developing obesity.”\nThe new understandings gleaned from these two studies could help the clinical research community identify behavioral treatment strategies based on reducing the impact of food cues, particularly for those at high risk for obesity.\n“It may be possible to train our brains to react differently to certain food cues,” said Martin Binks, PhD, FTOS, Secretary Treasurer of and spokesperson for The Obesity Society. “This research is a step toward better understanding how food words – relatively minimal food cues – may influence food consumption and how other common experiences like stress may interact with associated food cues to influence eating behavior. These types of studies may eventually lead to more effective behavioral strategies.”\nThe Obesity Society calls for more research into neurohormonal regulation of eating behavior.\nBoth abstracts are available below.\n# # #\nThis press release can be published in full or in part with attribution to The Obesity Society.\nSusan Carnell, PhD, Johns Hopkins University School of Medicine\nNeural Responses to Food Words in Obese and Lean Individuals Under Stressed and Non-Stressed Conditions\nObese individuals may show heightened responses to environmental food cues, and stress has been associated with greater intake and weight. We aimed to study neural responses to minimal food cues (written words) under normal conditions and following a stressor in obese vs. lean individuals.\nWe recruited 12 lean and 17 obese participants. On two separate days, participants underwent an fMRI scan during which they viewed words representing high energy-density [ED] foods, low-ED foods, and non-foods and rated how much they wanted to eat each food item. On one day, the scan was preceded by a Socially-Evaluated Cold Pressor Test [SECPT] (stress); on the other (counter-balanced) by a warm water task (control). A multi-item ad libitum meal followed each scan.\nWanting scores were highest for the high-ED foods under both conditions (p<0.001), and obese, but not lean, individuals consumed more calories during the stress (vs. control) condition (p=0.018). Imaging analyses for the non-stress condition revealed that obese (vs. lean) individuals showed increased responses to food (vs. non-food) cues and high-ED (vs. low-ED) food words in multiple cortical and sub-cortical brain regions including the caudate, dlPFC, cingulate, sensorimotor cortex, SMA and brainstem. In comparisons of the stress vs. control condition, both obese and lean individuals showed increased food vs. non-food and high-ED vs. low-ED responses in distinct but overlapping neural circuits.\nOur results suggest that obese vs. lean adults show heightened neural responses to minimal food vs. non-food and high-ED vs. low-ED food word cues under normal, non-stressed conditions. Both obese and lean adults showed some evidence for increased neural food cue responses following a stress manipulation, but only obese individuals consumed more at a subsequent ad libitum meal. Heightened neurobehavioral responses to food cues in both stressed and non-stressed conditions could contribute to excessive intake and weight gain.\nCarnell S. Johns Hopkins University School of Medicine. Poster abstract presentation at: The Obesity Society Annual Meeting at ObesityWeekSM 2015; November 2-6, 2015; Los Angeles, CA. www.obesityweek.com.\nLeora Benson, MS, Johns Hopkins University School of Medicine\nGenetic obesity risk and appetite in adolescents\nCommon obesity-associated genetic variants have been identified via genome-wide association studies, and many of the genes involved are expressed in the brain. However, relatively little is understood about the behavioral mechanisms by which these variants influence body weight.\nWe genotyped weight-associated SNPs in FTO (rs9939609), MC4R (rs17782313), NEGR1 (rs2815752) and TMEM18 (rs6548238) in 35 adolescents between 14 and 19 y old (20 F; 15 M), with a mean BMI percentile of 64 ± 28 (range: 12-99), recruited for varying familial (i.e. both genetic and environmental) obesity risk based on maternal weight. We assessed subjective appetitive responses to food and non-food words using a novel computer paradigm, as well as ad libitum intake in a laboratory meal. Participants also completed the Satter Eating Competence Inventory, a questionnaire measuring habitual self-regulation of intake.\nHigher genetic risk scores based on the number of risk alleles in all four variants were associated with greater ‘wanting’ responses to food words compared with non-food words in the computer paradigm (r=0.37; p=0.030). Analyses of individual variants revealed that the FTO risk allele was associated with lower scores on questionnaire measures of intake self-regulation (p=0.044); and the MC4R risk allele was associated with greater ad libitum intake of high energy-density foods (p=0.036).\nOur results suggest that common obesity-associated genetic variants influence weight via multiple appetitive endophenotypes, including a heightened subjective desire to eat when exposed to simple food word cues. This genetic effect on appetite was evident even in this small sample. Targeted behavioral and environmental interventions may help to limit the impact of increased appetitive responses and diminished self-regulation of intake in those at raised familial/genetic obesity risk.\nBenson L. Johns Hopkins University School of Medicine. Poster abstract presentation at: The Obesity Society Annual Meeting at ObesityWeekSM 2015; November 2-6, 2015; Los Angeles, CA. www.obesityweek.com.\nAbout The Obesity Society\nThe Obesity Society (TOS) is the leading professional society dedicated to better understanding, preventing and treating obesity. Through research, education and advocacy, TOS is committed to improving the lives of those affected by the disease. For more information visit: www.Obesity.org. Connect with us on social media: Facebook, Twitter and LinkedIn. Find TOS disclosures here.\nAbout ObesityWeek 2015\nObesityWeek is the premier, international event focused on the basic science, clinical application, prevention and treatment of obesity. TOS and the American Society for Metabolic and Bariatric Surgery (ASMBS) host the world’s pre-eminent conference on obesity, ObesityWeek 2015, Nov. 2-6, at the Los Angeles Convention Center in Los Angeles, California. For the third year, both organizations hold their respective annual scientific meetings under one roof to unveil exciting new research, discuss emerging treatment and prevention options, and network and present. Connect and share with ObesityWeek on Twitter and Facebook, or by using #OW2015."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:141ee6df-a589-4273-87b1-204995b20cb6>","<urn:uuid:74369d0f-ba83-43a8-bb46-d58f996324f6>"],"error":null}
{"question":"What happens to babies with ichthyosis regarding water loss?","answer":"They can experience high levels of transepidermal water loss with resultant hypernatremia.","context":["ICTIOSIS CONGENITA PDF\nIchthyosis is a family of rare genetic skin disorders characterized by dry, thickened, scaly skin. There are more than 20 types of ichthyosis which range in severity. Las ictiosis congénitas autosómicas recesivas (ICAR) son trastornos infrecuentes de la queratinización que se engloban en las formas no sindrómicas de. Describimos el caso de un paciente de 32 años de edad que desde el nacimiento presentaba dermatosis ictiosiforme generalizada, queratodermia.\n|Published (Last):||2 May 2015|\n|PDF File Size:||2.48 Mb|\n|ePub File Size:||20.49 Mb|\n|Price:||Free* [*Free Regsitration Required]|\nAutosomal recessive congenital ichthyosis ARCI encompasses several forms of nonsyndromic ichthyosis. Disease or Syndrome T Mutations in ichthyin associated with specific structural abnormalities in the granular layer of epidermis.\nOrphanet: Ictiosis congenita tipo arlequin\nAplasia cutis congenita Amniotic band syndrome Branchial cyst Cavernous venous malformation Accessory nail of the fifth toe Bronchogenic cyst Congenital cartilaginous rest of the neck Congenital hypertrophy of the lateral fold of the hallux Congenital lip pit Congenital malformations of the dermatoglyphs Congenital preauricular fistula Congenital smooth muscle hamartoma Cystic lymphatic malformation Median raphe cyst Melanotic neuroectodermal tumor of infancy Mongolian spot Nasolacrimal duct cyst Omphalomesenteric duct cyst Poland anomaly Rapidly involuting congenital hemangioma Rosenthal—Kloepfer syndrome Skin dimple Superficial lymphatic malformation Thyroglossal duct cyst Verrucous vascular malformation Birthmark.\nPrenatal diagnosis of Harlequin ichthyosis ictiosid as distal arthrogryposis using three-dimensional ultrasound. It is an autosomal dominant inherited or acquired disorder characterized by scaling and desquamation of the skin. TGM1 pathogenic variants include missensenonsenseand splice site variants. Health care resources for this disease Expert centres 74 Diagnostic tests 21 Patient organisations conggenita Orphan drug s 4.\nAm J Hum Genet. They subsequently develop erythroderma generalized redness of the skin and fine, white semi-adherent scales. Affected mothers are at no specific disease-related risks during pregnancy. Only comments seeking to improve the quality and accuracy of information on the Orphanet website are accepted. Regular physical examination for evidence of infection and control of skin involvement is appropriate; frequency depends on the severity. In adults, regular surveillance for skin cancer is appropriate cases with atypical melanocytic nevi, malignant melanoma, squamous cell carcinoma, and basal cell carcinoma have been reported [ Fernandes et alNatsuga et al ].\n504 Gateway Time-out\nFacial features are distorted due congeniha extreme ectropion, conjonctival edema, eclabium and broadened nose. They also have palmoplantar keratoderma, often with painful fissures and digital contractures [ Fischer et al ].\nPermission is hereby granted to reproduce, distribute, and translate copies of content materials for noncommercial research purposes only, provided that i credit for source http: Meleda clngenita Keratosis pilaris ATP2A2 Darier’s disease Dyskeratosis congenita Lelis syndrome Dyskeratosis congenita Keratolytic winter erythema Keratosis follicularis spinulosa decalvans Keratosis linearis with ichthyosis congenita and sclerosing keratoderma syndrome Keratosis pilaris atrophicans faciei Keratosis pilaris.\nCheck this box if you wish to receive a congeita of your message. WNT10A mutations congemita a frequent cause of a broad spectrum of ectodermal dysplasias with sex-biased manifestation pattern in heterozygotes. Gaucher diseasean autosomal recessive inborn error in glucosylceramidase, has a wide spectrum of clinical presentation.\nThe mildest outcome with features of CIE or LI was observed in individuals with harlequin ichthyosis who had at least one pathogenic missense variant. They can experience high levels of transepidermal water loss with resultant hypernatremia.\nAll pathogenic variants congeinta the severe harlequin phenotype are predicted to have a deleterious effect because they completely destroy the production or function of the transporter protein encoded for by ABCA The skin at birth is erythrodermic, swollen, and massively thickened with a vernix-like appearance.\nMissense mutations in GJB2 encoding connexin cause the ectodermal dysplasia keratitis-ichthyosis-deafness syndrome. Assignment of the locus for ichthyosis prematurity syndrome to chromosome 9q Mutations in ichthyin a new gene on chromosome 5q33 in a new form of autosomal recessive congenital ichthyosis.\nTreatment of Manifestations For neonates, providing a moist environment in an isolette, congenira infection by hygienic handling, and treating infection are paramount. Orphanet J Rare Dis.\nIn some cases, scales are so thick that they resemble armored plate. Molecular analysis, if available, reveals ABCA12 mutations. J Am Acad Dermatol.\nMost pathogenic variants are distributed in the first two thirds of the gene. LI and CIE are seemingly distinct phenotypes:"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:af16b095-92bf-45e3-93f4-2fea3671a4a7>"],"error":null}
{"question":"What are the main differences between using plant identification apps and participating in geocaching when it comes to outdoor exploration and learning?","answer":"Plant identification apps like PictureThis and FlowerChecker use visual recognition software to help users identify various species of plants, moss, fungus and lichens through photos, enabling ongoing observation of plant growth. Geocaching, in contrast, uses GPS technology and online coordinates to guide users in searching for hidden caches containing trinkets, requiring them to search specific locations and possibly go off-trail. While plant identification apps focus on natural education and understanding local flora, geocaching emphasizes the excitement of treasure hunting and exploration. Both activities use technology to enhance outdoor experiences, but serve different learning purposes - botanical knowledge versus navigation and search skills.","context":["by Asta Mail\nSource: Island Parent Magazine\nOriginally Published: March 2019\nAfter a long, wet winter, most adults can’t wait to get outside to observe the blossoming of a new season. Kids, however, might have a tougher time coming out of hibernation. Video games, good books and screen time can be hard to get away from, but spring is a great time to start spending more quality time outdoors. It’s also a great time to learn and bond together as a family.\nYou can make almost any seasonal change into an engaging and exciting way to learn and discover the natural world. All it takes is a little curiosity and the willingness to dive into a project together as a team. Here are some great ways that you and your family can engage your own curiosity and enjoy the beauty of this glorious spring to its fullest.\nGeocaching is an activity that turns any hike or outdoor walk into an exciting search for hidden treasure.\nHow to do it: Download the Geocaching app on your smartphone to get started, or go to geocache.com to create a free account. Once completed, open the app and input your location. The app will guide you to the GPS location of hundreds of hidden “caches” located all over Vancouver Island. The caches vary by size and difficulty, so prepare yourself to search high and low around the given coordinates—and maybe even get a little dirty!\nTips and tricks: This activity is great for group and family outings. Have the kids alternate on the responsibility of guiding the group to the cache location using the phone or GPS. Once there, everyone in your group should participate in searching for the cache. Once you find it, don’t forget to sign the logbook, search through the swag, and perhaps add a piece of your own swag for the next family to find. One special note, caches are sometimes located off trail and some parks and Nature Sanctuaries (like Swan Lake) ask that you remain on the trails to protect the ecosystem. Please do respect these rules.\nPlastic pollution is one of the most pressing environmental issues our society faces today. A great way to teach children about this issue is by conducting a trash tally.\nAs a family, collect pieces of garbage and plastic from your local park, playground or beach. Record the number of pieces, sizes and types of plastic found. You could also take part in a beach clean-up, like the ones conducted monthly by organizations like the Surfrider Foundation.\nObserving how and why plastics end up in our public spaces can help kids understand the seriousness of plastic pollution, and allows them to contribute towards keeping their own communities cleaner and healthier.\nWhat you need: It’s a good idea to bring bags to put your trash in, as well as rubber gloves or trash pickers to get at some of the more tricky pieces. Bring along a notebook and pencil to keep track of what you find. Make sure you find a safe way to dispose of what you find once you’re finished.\nTips and Tricks: Not everyone gets excited about the idea of picking up trash, but if you frame it like a treasure hunt, kids can usually get pretty excited about it. Plus, nothing feels better than knowing that you did something truly heroic for the natural spaces around you. A short talk on safety is important too and may vary depending on the age of the children involved in your activity. A rule of thumb is that if it looks unsafe, ask an adult before picking up.\nFlower Power in your Pocket\nYou’ve probably heard “What’s that, Mom/Dad?” more times than you’d care to remember, and been stumped by the question more than you’d care to admit. Plants can be especially tricky to identify at first glance unless you’ve got a background in botany.\nThe next time this question comes up, try enlisting the help of Apps like PictureThis, FlowerChecker or Plantify. These apps allow you to snap a photo and use it to identify most species of plants, moss, fungus and even lichens using a visual recognition software. Using this App, you and the family can start learning to ID the plants growing in your own backyard and neighbourhood.\nTips and Tricks: Once you’ve identified a couple of common plants, start tracking their growth process. Ask kids to take a picture of the same outdoor plants each day, or plant some seeds at home and track their progress daily. This is a great way to get kids to think about what factors might affect the growth of plants.\nYou don’t have a PhD to contribute to the world of real research. In fact, there are plenty of local organizations that are actively looking for young or budding scientists to help them collect and analyze real world data. The best part is, you won’t even need any fancy scientific equipment to take part!\nOceans Network Canada has a citizen science program called Digital Fishers which allows young scientists to analyze footage from underwater webcams, identify animals and describe environmental conditions. Nature Kids BC also runs a Pollinator Citizen Science Program in which kids are asked to conduct an outdoor pollinator survey. The program also teaches young scientists about how to become active stewards of the pollinator’s environment.\nTips and Tricks: The most important parts of a scientist’s job are to be curious and to make observations. You can stoke your child’s curiosity for science by recording their nature questions, making regular observations of the plants and animals around you, and measuring how these observations change over time. These projects require committed time and effort, but the results are well worth it. Keep following your child’s line of inquiry, and you may end up raising a future scientist!\nSpring is a great season to observe birds at Swan Lake and elsewhere in our region. Not only are water birds using the lake as a stopover in their return migrations up north, many birds are attracting mates, and preparing nests to house their young. Grab a pair of binoculars and your hiking boots, hop on the trails, and see how many different species you can identify.\nTips and Tricks: If your birding skills are limited, you’re welcome to join Swan Lake’s Sunday morning Bird Walk (9:00-10:30 am), led by volunteers from the Victoria Natural History Society. The group meets at the parking lot, and children are welcome. There is also a Swan Lake birding checklist, available online and at the Nature House.\nAll of us Swan Lake Christmas Hill Nature Sanctuary wish you an active and exhilarating spring.\nAsta Mail is a Program Naturalist at Swan Lake Christmas Hill Nature Sanctuary. She loves seeing kids and families exploring the natural environment.\n|Submitted by: |\nIsland Parent Magazine\nIf you find an article you think we'll enjoy, share it with us.\nJust remember to give proper credit to the author, and to provide a link to the site where you found it.\nWe all want to respect copyright.\n|<< prev. month||next month >>|\nSign up now to start receiving the Island Parent Newsletter. It only takes a minute.\nEnter now for your chance to win some exciting prizes in our Island Parent Contest! We have new contests often, so check back regularly!","This is an excerpt from Geocaching for Schools and Communities by J. Kevin Taylor,DuAnn Kremer,Katherine Pebworth & Peter Werner.\nA geocache, pronounced \"geo-cash,\" is a hidden store of trinkets. The word geocache comes from geo, meaning \"of the earth,\" and cache, which is French for hiding place or hidden store. Simply stated, geocaching involves someone hiding a box of trinkets and posting the coordinates of the box's location on the Internet; other people reference the coordinates and then go hunting for the trinkets. People who go geocaching are called geocachers (often abbreviated to cachers). If you want to go geocaching, you look up the coordinates of a cache, plug them into your GPS unit, and try to find the cache. A cache is normally well hidden so that people who are not actually looking for it don't find it by mistake; therefore, along with the coordinates, the person who hid the cache will usually post a short clue to help people locate the cache once they are within a few feet of the location.\nSo, you track down the location using your GPS and the posted coordinates, you solve the clue that was posted, and you find the cache. Now what? At a traditional geocache, most geocachers like to swap a trinket—that is, they take something from the cache and leave something in its place. Trinkets can be any small item worth no more than $2. Some creative cachers leave the same trinket every time, and this becomes a calling card of sorts. After finding a cache, most geocachers will log their cache online. They will also track the number of caches they have found. You don't have to log your cache if you prefer not to; some dedicated geocachers simply enjoy the thrill of hunting for a cache. Those who do log their find also sometimes leave comments for the person who set the cache. Geocachers may leave comments to thank the person for setting the cache, to compliment the person on a well-hidden cache, or to report any problems with the cache. An example of a reported problem might be that the cache wasn't properly hidden after the last find. When reporting this problem, the geocacher may include a request for future geocachers to be careful in rehiding the cache more thoroughly. More details on the intricacies of geocaching are covered throughout the book.\nAlthough more than one Web site is available for looking up and logging a geocache, the most popular site by far is www.geocaching.com. To use the geocaching.com Web site, you set up an account with a user name and password of your choice. A basic account is free and gives you everything needed to start caching. Frequent reference will be made to this Web site as we explore the many intricacies and complexities that have been added to the basic concept of geocaching. Throughout this text, any further mention of logging a cache or looking up a cache on the Internet refers to the geocaching.com Web site unless stated otherwise."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:9315c458-bc61-4178-99fc-7fdd9d01b791>","<urn:uuid:cc6c6e28-2989-435c-8706-0db74b65eec9>"],"error":null}
{"question":"What's the deal with that abandoned piece of El Camino Real near UC San Diego? Anyone tried getting there?! 😮","answer":"A forgotten segment of the original El Camino Real's roadbed lies in a deep canyon north of the Geisel Library at UC San Diego. The stretch, measuring between 50 and 200 feet long, still shows visible white lane markings and hasn't been driven on since before the university's construction in the 1960s. However, accessing this historic piece is extremely challenging due to its location at the bottom of an 80-foot canyon with walls sloping at 35 degrees, surrounded by hazards including rattlesnakes, Africanized bee nests, and dense cacti. The road segment was originally part of the Rose Canyon Highway, paved in 1930 over the old stagecoach road before being renamed Pacific Highway. Modern attempts to reach it have proven unsuccessful due to dead-end trails and thick vegetation that obscures dangerous drop-offs.","context":["It’s right in front of us — a forgotten chunk of the original El Camino Real’s roadbed.\nWell, it’s not right in front of us. It’s at the bottom of a deep canyon, north of the Geisel Library at UC San Diego, that’s surrounded by 80-foot walls sloping 35 degrees downward and mined with rattlesnakes, Africanized bee nests, cacti and things that are even less fun than that.\nSomewhere between 50 and 200 feet long, this roadbed has not felt a car tire since before the university was plopped all around it in the ‘60s. Yet its white lane markings are still clearly visible.\n“You and me are taking a selfie on that!” enthuses my companion on this mission, Edie Littlefield Sundby, the La Jollan who published a 2017 book, “The Mission Walker” (Harper Collins), about her experience walking every one of El Camino Real’s 1,600 miles from deep in Mexico up to Sonoma in 2016.\n“This should be a cakewalk compared to Loreto,” she says. “Human beings were just not meant to be there.”\nOn her El Camino Real route through La Jolla, Littlefield Sundby took currently functioning surface streets. But that’s only because, she says, “I had no idea about this.”\nEl Camino 101\nPopularly, El Camino Real (the Royal Highway) refers to the path taken by Franciscan friars between the 21 missions, two pueblos and four presidios established in the 500 miles and 55 years between the founding of the first Alta California mission in San Diego in 1769 and the last one in Sonoma in 1824 — back when our state belonged to Mexico, and Mexico to Spain.\nThe missions were spaced so that each was within a day’s walk (or about 30 miles) of the next. According to the August 1914 issue of “The Journal of the American Institute of Architects,” the plan was “to establish a cordon of missions a day’s journey apart,” which “led to the development of a road, following, in all probability, previously established crude trails, and which … became the recognized highway of official travel.”\nMost of the missions were built by Father Junipero Serra and 16 other priests from Mexico City’s College of San Fernando, who arrived in Loreto in Spring 1768. Their intention was to establish Catholicism as the region’s dominant religion, and to convert Native Americans to a European way of life.\nAs a 1/8 Choctaw who was raised Christian in rural Oklahoma, Littlefield Sundby could be expected to harbor conflicting emotions about these goals. But, she says, it’s a waste of time imposing modern values on people who were trying to do good according to the rules of their time.\n“You can talk about what happened 250 years ago, or you can put your eyes on what’s happening today and say never again,” she says. “That’s one thing Junipero Serra used to say: ‘Always forward, never back.’”\nAnd that’s exactly what we’re trying to figure out as we stare in the distance at the former El Camino Real — how to move forward towards it. A feature of the directly surrounding canyon walls are cliff-like drop-offs at the bottom that we need to avoid. The easiest way would be to split up so that one of us can direct the other down from across the canyon.“No,” Littlefield Sundby says. “We’re taking that selfie together.”\nTo the north of us, El Camino Real picked up again at the canyon bottom parallel to the I-5, on the other side of the landfill wall that completed Genesee Avenue’s on-ramp. But that path is long obliterated, as was the path El Camino Real took through Sorrento Valley connecting it to the road that, in Del Mar right up to the entrance to Mission San Luis Rey in Oceanside, is still called El Camino Real.\nOf course, the road we’re staring at in the distance didn’t meet its demise as El Camino Real. It was part of the Rose Canyon Highway that was paved in 1930 over the old stagecoach road and renamed Pacific Highway shortly thereafter. The I-5 was built over most of that highway, but not this part.\nAn 1889 survey map of San Diego shows the stagecoach road, which ran to Los Angeles since before the Civil War. (There was no coast route yet, as the map shows, and no cars to take it if there were.) Still, it’s impossible to know for certain the location of a Native American footpath so long ago without a map from the time.\n“To have a semblance of authority, you'd need to find something pre-1849,” said Barry Ruderman of Barry Lawrence Ruderman Antique Maps, “but I know of no maps with the requisite scale from this period.”\nHowever, Ruderman points out that the route north would have been dictated by the fastest route northward from San Diego to Oceanside. “This would have been as straight a line as the missionaries could have found,” he said.\nEver wonder why the train tracks cut a five-mile east-west horseshoe shape through University City and Sorrento Valley while traveling north-south? It’s because, prior to the construction of the I-5’s gravity-defying bridgery in 1964, there was no straight line possible to take through Rose Canyon. The ascent was too steep — as it would have been for Franciscans and their mules and caretas (the traditional freight wagons of colonial Mexico).\n“After a short time, we ascended a hill well covered with grass,” wrote Father Juan Crespi in his diary on July 17, 1769. “Our road then took us across mesa lands, some open pasture and others covered with groves of scrub oaks, wild rosemary, and to us unknown bushes.”\nThe Franciscan and his small padre cadre were in the midst of what historians regard as the first voyage of Europeans through California.\nSo the Franciscans were led, by their Native American guides, up a less-steep trail, west of Rose Canyon, that led up to a mesa. That this trail was probably what became Gilman Drive was not lost on the El Camino Real Association, which placed one of its Mission Bells, a series of markers celebrating the original route, by what is now the entrance to the Residence Inn by Marriott at 8901 Gilman Drive in the early 1900s.\n“We should have brought gloves!” Littlefield Sundby yells from behind me. “Also a hiking pole and a machete!”\nIncidentally, about half of the sentences Littlefield Sundby utters today start with “we should have.” The other half start with “be careful of the.” The most recent of the latter sentences ended with “prickly pear.”\nBut it arrived too late to prevent a thicket of thorns from slowly stabbing into my pants and even my Timberlands. I will survive, although the other hardships we will face today include being buzzed by a black military helicopter filled with angry-looking officers wondering what we’re doing, and receiving a UCSD citation for parking in a space that I clearly displayed a permit for. (Have I mentioned that I’m more of an indoorsman?)\nThe Camino: Real or mythical?\nAfter all this, there may have never even been a real El Camino Real after all. I feel I should at least mention this possibility, since historians vigorously debate it.\n“The idea of a continuous road that connected all the missions as part of this concrete plan — I wouldn’t be surprised if someone said this would be a great idea, but as far as evidence of what was on the ground, which really begins to come to us only in the era of roadbuilding, there was nothing there,” said Matthew Roth, historian at the Automobile Club of Southern California Archives.\n“From Santa Barbara to the Mexican border, it’s a little over 240 miles,” Roth explained. “That was the first stretch of the Pacific Coast Highway to open in 1928. There were literally hundreds of bridges necessary. There were no bridges across these drainages. So any notion of continuous road that doesn’t include these stream crossings is ridiculous.\n“Maybe they crossed by bridges that left no archeological evidence,” Roth continued, “but during this period, the way to travel north and south was by coastal vessel. There’s ample evidence of that.”\nThe placement of the mission bells — an idea dreamed up by Los Angeles writer and activist Harrie Forbes and backed by the California Federation of Women's Clubs, which funded the one on Gilman — were partly responsible for what Roth calls this “booster myth.” They were an early 1900s marketing effort to refashion El Camino Real into a tourist highway to attract commerce.\n\"El Camino Real was a product of the same impulse that gave us the Spanish Colonial Revival in architecture — imparting an exotic hue to the region as a way to attract more tourists and settlers,\" Roth said.\n“Nonsense!” Littlefield Sundby snaps. “That’s a lie and you and I both know it. There was totally an El Camino Real.”\nThis is not an argument that can be settled by a newspaper article. But one thing is becoming abundantly clear today … There is no trail down to this abandoned stretch of El Camino Real that Littlefield Sundby and I can locate. We’re on our fourth attempt to descend the canyon, but every trail we think we find dead-ends into ever-thickening sagebrush, yerba santa and assorted tall and prickly plants that I can’t identify but that obscure the drop-offs.\nAs much as I want to make contact with the original El Camino Real, cracking my skull on it is not what I had in mind. But Littlefield Sundby tells me she actually wouldn’t mind dying today.\n“It’s better than dying in bed,” she says.\nThe big reveal\nLittlefield Sundby was diagnosed with gallbladder cancer and given a three-month life expectancy … back in 2007.\n“It was in eight organs,” she says, “my colon, my liver, my bile ducts. Because it was Stage 4, it spread all over the place. There was no operating.”\nI probably should have dropped this bombshell earlier, but then you would have thought of this as an article about cancer, and Littlefield Sundby as someone who is disabled by it. And neither is true.\n“Walking is how I’m still alive,” she says, reporting that it helped her endure 79 rounds of chemotherapy and four major surgeries at Stanford Cancer Center. “The only way I could withstand the chemo was to walk.”\nIt was while walking the canyons around Stanford that Littlefield Sundby discovered what became the purpose of her life’s final years.\n“Every time I walked, I’d see these mission bells and I’d get really curious about it,” she says. “There are mission bells every mile up there. It’s almost as if they were beckoning me to this mystery — what is this all about?”\nI hear the cough because I’m listening for it. But it’s only there when Littlefield Sundby sits or stands perfectly still — not when she walks or hikes. The cancer has returned in her left lung, the one that wasn’t removed by surgeons.\n“So what if I die?” she asks. “Everybody’s dying.”\nFor the third time today, I lose my footing and slide into a plant that saves me from sliding or tumbling. In this case, it’s NOT a patch prickly pear (thank goodness), but I’ve had enough. I’m not ready to die today, and I convince Littlefield Sundby to turn back.\nThe padres didn’t succeed either — at least on their first mission.\n“There were some native peoples that welcomed them with open arms, and there were some that were shooting arrows and screaming with remarks the padres couldn’t understand but they knew it was not a welcoming gesture,” said Tony Falcon, archivist at Mission San Diego, who estimates that “only 10 percent” of the native peoples converted or even accepted the padres and their strange culture.\n“They were not that welcome, I guess,” he said.\nAs Littlefield Sundby and I beat a retreat, she promises that we will return — “with the proper tools” — and take that selfie on the original El Camino Real one day.\nThat’s a question of faith, on many levels, and I can’t think of a more appropriate note upon which to end this mission.","It’s right in front of us — a forgotten chunk of the original El Camino Real’s roadbed.\nWell, it’s not right in front of us. It’s at the bottom of a deep canyon, north of the Geisel Library at UC San Diego, that’s surrounded by 80-foot walls sloping 35 degrees downward and mined with rattlesnakes, Africanized bee nests, cacti and things that are even less fun than that.\nSomewhere between 50 and 200 feet long, this roadbed has not felt a car tire since before the university was plopped all around it in the ‘60s. Yet its white lane markings are still clearly visible.\n“You and me are taking a selfie on that!” enthuses my companion on this mission, Edie Littlefield Sundby, the La Jollan who published a 2017 book, “The Mission Walker” (Harper Collins), about her experience walking every one of El Camino Real’s 1,600 miles from deep in Mexico up to Sonoma in 2016.\n“This should be a cakewalk compared to Loreto,” she says. “Human beings were just not meant to be there.”\nOn her El Camino Real route through La Jolla, Littlefield Sundby took currently functioning surface streets. But that’s only because, she says, “I had no idea about this.”\nEl Camino 101\nPopularly, El Camino Real (the Royal Highway) refers to the path taken by Franciscan friars between the 21 missions, two pueblos and four presidios established in the 500 miles and 55 years between the founding of the first Alta California mission in San Diego in 1769 and the last one in Sonoma in 1824 — back when our state belonged to Mexico, and Mexico to Spain.\nThe missions were spaced so that each was within a day’s walk (or about 30 miles) of the next. According to the August 1914 issue of “The Journal of the American Institute of Architects,” the plan was “to establish a cordon of missions a day’s journey apart,” which “led to the development of a road, following, in all probability, previously established crude trails, and which … became the recognized highway of official travel.”\nMost of the missions were built by Father Junipero Serra and 16 other priests from Mexico City’s College of San Fernando, who arrived in Loreto in Spring 1768. Their intention was to establish Catholicism as the region’s dominant religion, and to convert Native Americans to a European way of life.\nAs a 1/8 Choctaw who was raised Christian in rural Oklahoma, Littlefield Sundby could be expected to harbor conflicting emotions about these goals. But, she says, it’s a waste of time imposing modern values on people who were trying to do good according to the rules of their time.\n“You can talk about what happened 250 years ago, or you can put your eyes on what’s happening today and say never again,” she says. “That’s one thing Junipero Serra used to say: ‘Always forward, never back.’”\nAnd that’s exactly what we’re trying to figure out as we stare in the distance at the former El Camino Real — how to move forward towards it. A feature of the directly surrounding canyon walls are cliff-like drop-offs at the bottom that we need to avoid. The easiest way would be to split up so that one of us can direct the other down from across the canyon.“No,” Littlefield Sundby says. “We’re taking that selfie together.”\nTo the north of us, El Camino Real picked up again at the canyon bottom parallel to the I-5, on the other side of the landfill wall that completed Genesee Avenue’s on-ramp. But that path is long obliterated, as was the path El Camino Real took through Sorrento Valley connecting it to the road that, in Del Mar right up to the entrance to Mission San Luis Rey in Oceanside, is still called El Camino Real.\nOf course, the road we’re staring at in the distance didn’t meet its demise as El Camino Real. It was part of the Rose Canyon Highway that was paved in 1930 over the old stagecoach road and renamed Pacific Highway shortly thereafter. The I-5 was built over most of that highway, but not this part.\nAn 1889 survey map of San Diego shows the stagecoach road, which ran to Los Angeles since before the Civil War. (There was no coast route yet, as the map shows, and no cars to take it if there were.) Still, it’s impossible to know for certain the location of a Native American footpath so long ago without a map from the time.\n“To have a semblance of authority, you'd need to find something pre-1849,” said Barry Ruderman of Barry Lawrence Ruderman Antique Maps, “but I know of no maps with the requisite scale from this period.”\nHowever, Ruderman points out that the route north would have been dictated by the fastest route northward from San Diego to Oceanside. “This would have been as straight a line as the missionaries could have found,” he said.\nEver wonder why the train tracks cut a five-mile east-west horseshoe shape through University City and Sorrento Valley while traveling north-south? It’s because, prior to the construction of the I-5’s gravity-defying bridgery in 1964, there was no straight line possible to take through Rose Canyon. The ascent was too steep — as it would have been for Franciscans and their mules and caretas (the traditional freight wagons of colonial Mexico).\n“After a short time, we ascended a hill well covered with grass,” wrote Father Juan Crespi in his diary on July 17, 1769. “Our road then took us across mesa lands, some open pasture and others covered with groves of scrub oaks, wild rosemary, and to us unknown bushes.”\nThe Franciscan and his small padre cadre were in the midst of what historians regard as the first voyage of Europeans through California.\nSo the Franciscans were led, by their Native American guides, up a less-steep trail, west of Rose Canyon, that led up to a mesa. That this trail was probably what became Gilman Drive was not lost on the El Camino Real Association, which placed one of its Mission Bells, a series of markers celebrating the original route, by what is now the entrance to the Residence Inn by Marriott at 8901 Gilman Drive in the early 1900s.\n“We should have brought gloves!” Littlefield Sundby yells from behind me. “Also a hiking pole and a machete!”\nIncidentally, about half of the sentences Littlefield Sundby utters today start with “we should have.” The other half start with “be careful of the.” The most recent of the latter sentences ended with “prickly pear.”\nBut it arrived too late to prevent a thicket of thorns from slowly stabbing into my pants and even my Timberlands. I will survive, although the other hardships we will face today include being buzzed by a black military helicopter filled with angry-looking officers wondering what we’re doing, and receiving a UCSD citation for parking in a space that I clearly displayed a permit for. (Have I mentioned that I’m more of an indoorsman?)\nThe Camino: Real or mythical?\nAfter all this, there may have never even been a real El Camino Real after all. I feel I should at least mention this possibility, since historians vigorously debate it.\n“The idea of a continuous road that connected all the missions as part of this concrete plan — I wouldn’t be surprised if someone said this would be a great idea, but as far as evidence of what was on the ground, which really begins to come to us only in the era of roadbuilding, there was nothing there,” said Matthew Roth, historian at the Automobile Club of Southern California Archives.\n“From Santa Barbara to the Mexican border, it’s a little over 240 miles,” Roth explained. “That was the first stretch of the Pacific Coast Highway to open in 1928. There were literally hundreds of bridges necessary. There were no bridges across these drainages. So any notion of continuous road that doesn’t include these stream crossings is ridiculous.\n“Maybe they crossed by bridges that left no archeological evidence,” Roth continued, “but during this period, the way to travel north and south was by coastal vessel. There’s ample evidence of that.”\nThe placement of the mission bells — an idea dreamed up by Los Angeles writer and activist Harrie Forbes and backed by the California Federation of Women's Clubs, which funded the one on Gilman — were partly responsible for what Roth calls this “booster myth.” They were an early 1900s marketing effort to refashion El Camino Real into a tourist highway to attract commerce.\n\"El Camino Real was a product of the same impulse that gave us the Spanish Colonial Revival in architecture — imparting an exotic hue to the region as a way to attract more tourists and settlers,\" Roth said.\n“Nonsense!” Littlefield Sundby snaps. “That’s a lie and you and I both know it. There was totally an El Camino Real.”\nThis is not an argument that can be settled by a newspaper article. But one thing is becoming abundantly clear today … There is no trail down to this abandoned stretch of El Camino Real that Littlefield Sundby and I can locate. We’re on our fourth attempt to descend the canyon, but every trail we think we find dead-ends into ever-thickening sagebrush, yerba santa and assorted tall and prickly plants that I can’t identify but that obscure the drop-offs.\nAs much as I want to make contact with the original El Camino Real, cracking my skull on it is not what I had in mind. But Littlefield Sundby tells me she actually wouldn’t mind dying today.\n“It’s better than dying in bed,” she says.\nThe big reveal\nLittlefield Sundby was diagnosed with gallbladder cancer and given a three-month life expectancy … back in 2007.\n“It was in eight organs,” she says, “my colon, my liver, my bile ducts. Because it was Stage 4, it spread all over the place. There was no operating.”\nI probably should have dropped this bombshell earlier, but then you would have thought of this as an article about cancer, and Littlefield Sundby as someone who is disabled by it. And neither is true.\n“Walking is how I’m still alive,” she says, reporting that it helped her endure 79 rounds of chemotherapy and four major surgeries at Stanford Cancer Center. “The only way I could withstand the chemo was to walk.”\nIt was while walking the canyons around Stanford that Littlefield Sundby discovered what became the purpose of her life’s final years.\n“Every time I walked, I’d see these mission bells and I’d get really curious about it,” she says. “There are mission bells every mile up there. It’s almost as if they were beckoning me to this mystery — what is this all about?”\nI hear the cough because I’m listening for it. But it’s only there when Littlefield Sundby sits or stands perfectly still — not when she walks or hikes. The cancer has returned in her left lung, the one that wasn’t removed by surgeons.\n“So what if I die?” she asks. “Everybody’s dying.”\nFor the third time today, I lose my footing and slide into a plant that saves me from sliding or tumbling. In this case, it’s NOT a patch prickly pear (thank goodness), but I’ve had enough. I’m not ready to die today, and I convince Littlefield Sundby to turn back.\nThe padres didn’t succeed either — at least on their first mission.\n“There were some native peoples that welcomed them with open arms, and there were some that were shooting arrows and screaming with remarks the padres couldn’t understand but they knew it was not a welcoming gesture,” said Tony Falcon, archivist at Mission San Diego, who estimates that “only 10 percent” of the native peoples converted or even accepted the padres and their strange culture.\n“They were not that welcome, I guess,” he said.\nAs Littlefield Sundby and I beat a retreat, she promises that we will return — “with the proper tools” — and take that selfie on the original El Camino Real one day.\nThat’s a question of faith, on many levels, and I can’t think of a more appropriate note upon which to end this mission."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"}],"document_ids":["<urn:uuid:8b01905d-35f2-4683-bc04-86fed63d35af>","<urn:uuid:8b01905d-35f2-4683-bc04-86fed63d35af>"],"error":null}
{"question":"Could you explain how the fashion industry combines traditional craftsmanship with sustainable practices, and what environmental challenges does fast fashion pose to the industry?","answer":"Traditional craftsmanship in fashion is exemplified by designers like Bernard Chandran and Jas Sehmbi, who maintain high-quality production with fair working conditions. They emphasize quality, good cut, and skilled craftsmanship, training their workers extensively. However, the fashion industry faces severe environmental challenges from fast fashion, including excessive water usage (2700 liters for one cotton shirt), massive textile waste (92 million tonnes annually), and significant carbon emissions. Currently, 84% of clothing ends up in landfills or incinerators, with textile waste projected to reach 134 million tonnes by 2030.","context":["Once upon a time an aspiring fashion designer called Christian Dior dreamed of ladies with silhouettes like flower petals. Using around 50 metres of fabric to create skirts that accentuated the waistline, he made his dream come true. How dare he waste fabric so recklessly, cried the outraged establishment of the post war austerity era, but women across the world fell in love with this new look and so, an icon was born.\nDior’s ‘New Look’ remains as iconic today as it was 60 years ago but the fashion industry landscape is vastly different. The eccentricity of designers such as Dior and the craftsmanship that turned his visions into reality, providing much of couture’s cachet, is in danger of extinction. We often hear insiders lament the demise of les petites mains (literally ‘little hands’). At the same time, the mass exodus of brands – both luxury and high street - to the Far East in the name of cutting costs has put the issue of labour on the agenda: miserable working conditions in third world factories and the ensuing rise of the Fairtrade movement are all well documented.\nAnd yet there are a number of London-based designers whose oeuvre combines craftsmanship with Fairtrade: garments made in their own factories with good working conditions, where staff are trained and supervised by the designers themselves. These are independent designers with sizable production, who have redefined the concept of couture fashion into their own brand of artisan clothes-making, creating a niche between high street and the high fashion of Paris and Milan in the process. With their originality, not only have they been able to claim space on London’s catwalks but they have also become part of the phenomenal talent that has staked London’s claim to being the most cutting-edge of the fashion capitals.\nBernard Chandran hails from Malaysia, where he launched his career and built up an impressive client base (including royals from Malaysia and Brunei) before heading to London. Despite being a complete unknown when he arrived, within a few seasons he made his mark by reinterpreting traditional Malay garb for a modern, fashionable audience. Thanks to his quirky vision, he became part of the tapestry that makes London so innovative, and includes pop royalty in the guise of Lady Gaga and Tori Amos among his fans. Garments are made in Bernard’s atelier in Kuala Lumpur, where he manages a technical and creative team of 70 people, comprised of both local and foreign workers (mainly from India). Every member of staff goes through rigorous training before they are, in Bernard’s words, ‘allowed to touch the real stuff.’ ‘I have always believed in quality craftsmanship,’ he adds. ‘I believe that’s our strength even though ours is a ready-to-wear presentation. We emphasise quality, good cut and craftsmanship.’ All materials for the collections are sourced from reputable suppliers.\nOne of the greatest challenges for Bernard is to find staff with the potential to develop their skills and be up to the creative challenges of the prêt-à-porter market. For those with a ‘passion for excellence’, the rewards are great: fair working conditions, wages commensurate with commitment, paid annual leave and equal treatment of local and foreign workers – in a nutshell, the opposite of the horror stories about sweatshops in developing countries. The most talented even get the opportunity to work on the catwalk show in London, including Fazlur Rahman who arrived from India four years ago without qualifications and in search of employment. Chandran gave him a chance and unearthed an artisan, whose beadwork is the equal of anything produced by a Parisian petites mains.\nAnother ethical designer currently making it big is homegrown talent, Jas Sehmbi. His biggest claim to fame is the ‘DJ bag’. Radical when he first made it, it responded to the needs of the culturally dominant 90s dance scene and soon became ubiquitous as the music itself. The kudos that came from an authentic association with street culture carried over when Jas set up his label, Jas MB in 2000. Unlike the music industry where success is measured in terms of whether or not you make it in the States, in fashion, you get real cred if you make it in Japan. With over 300 Japanese outlets, a standalone store in Fukuoka and a new flagship opening in Tokyo this November, Jas is very cool indeed.\nSo what’s the secret of his appeal? The answer is that it’s all made in Britain. Everything is produced in east London, albeit using Italian leather (‘the best’), zips from Switzerland and cotton for linings sourced from a green supplier in Taiwan. His colourful team - including workers from the local community, über cool graduates from Central Saint Martin’s, interns from local colleges and family members – is symbiotic with the label’s cosmopolitan, British feel, so sought after around the world. Given that Sehmbi lives and works in the city that’s home to some of the world’s best fashion schools, you could be forgiven for thinking that usable skills come as standard but paradoxically, he is facing the same problems as Chandran when looking for colleagues. ‘Colleges create talent but there is no craftsmanship to help production wise. A craftsman is someone who’s broken their hands to learn and put together a product. You got to feel how to twist and turn leather, how to manipulate it… We lost that craft. In this country, we have no ateliers and factories left.’\nThe high cost of production in the UK means that as a rule, the moment designers reach a critical mass of interest, they are pressured to move their production abroad in order to respond to demand from the international fashion buyers’ market. Big London Fashion Week names who developed organically, including Ashish and KTZ (the duo Pejoski/Bezovski), have their ateliers in India and Indonesia, respectively. Like Chandran, they have trained their staff but are forced to regularly shuttle backwards and forwards when production starts. When the catwalk action kicks off tomorrow, the media focus will be overwhelmingly on the glamour of the catwalk with little insight into how precarious it is to be an independent designer and how much passion and dedication goes into sustaining a business. Unless something is done and done fast to reclaim our crafts, London as a source of cutting-edge innovation is at risk of becoming a fairy tale for the future generations.\nLida Hujic is the author of The First to Know: How Hipsters and Mavericks Shape the Zeitgeist (www.thefirsttoknow.info), available from select independent bookshops including Artwords, Foyles, Magma, Muswell Hill Bookshop, Pages of Hackney, Rough Trade and galleries including The ICA and The Serpentine.\nFashion special Safia Minney: fashion’s impact on the earth\nIn an exclusive extract from her new book - Naked Fashion - the People Tree founder looks at the environmental damage caused by modern fashion – and sketches out a radical new way forward\nFashion special The Ecologist guide to Estethica\nLondon’s environmental fashion initiative celebrates its fifth birthday this year and this season looks set to be the best yet. Ruth Styles takes a closer look\n|HOW TO MAKE A DIFFERENCE\nFashion special Inside the London College of Fashion's eco-hub\nFashionable ideas get an ethical makeover at the Centre for Sustainable Fashion. Matilda Lee reports\nFashion special The fashion industry has the potential to be a real force for good\nYes there have been scandals, and yes, there is more to do, but the fashion industry is working hard to become greener and more ethical. It’s time to start supporting these efforts, argues Green Living Editor Ruth Styles\nFashion special Naked Fashion: The New Sustainable Fashion Revolution\nShowing fashion at its worst while providing upbeat solutions is a tough call but Safia Minney has achieved it with Naked Fashion, says Ruth Styles","As we all know fast fashion industry focuses on excessive production, overcomplicated supply chains, and mindless consumption to make huge profits. Naturally, adopting such an attitude would bring about severe consequences in the form of environmental, economic, and social impacts.\nFrom an environmental perspective, excessive use of water, water pollution, textiles waste, and carbon emissions are among the critical impacts that have to be taken into consideration. Producing one cotton shirt needs 2700 liters of water which is enough to meet the average person’s drinking needs for 2.5 years; contaminated water with toxins, heavy metals, and synthetic materials due to fabric dyeing and treatment ends up in seas and oceans which would surely be a danger to marine creatures and the underwater ecosystem; 92 million tones of textile waste are created each year and it is estimated that this number will reach 134 million tones by 2030. Nowadays, 84% of clothing still ends up in landfills or incinerators.\nNear one garbage truck of textiles per second is produced, and greenhouse gas emissions which lead to global warming and natural disasters are some of the marked effects of fast fashion on our planet.\nBesides, putting profits ahead of human welfare has its consequences in terms of labor conditions, health, child labor, and wages. So, an immediate change that is thoughtful, intentional, and holistic to benefit the planet and all people is needed. Such movements like sustainable fashion and slow fashion are reactions to fast fashion’s hazardous consequences.\nSlow Fashion vs Sustainable Fashion\nSlow fashion is the opposite of fast fashion literally. Slow fashion focuses on brand practices and consumer’s shopping habits. Its aim is specifically targeted at reducing consumption and production. Whereas, sustainable fashion utilizes the most sustainable methods and materials possible in all stages of a product’s life cycle.\nThe term slow fashion was first coined by Kate Fletcher. The naming was inspired by the similar slow food movement that was in itself a response to the fast-food industry. Much in the same way Fletcher felt the need for a slower-paced fashion movement that does not encourage mindless consumption. This attitude towards fashion could potentially help reduce our environmental footprint via adopting a non-consumer mentality and shift shopping habits to a more beneficial one for our planet and the people who inhabit it. The slow fashion movement aims to reduce our textile wastes which have been overburdening our landfills through speedy production schedules, large-scale production, and creating an excessive amount of waste. They encourage customers to keep a minimalistic wardrobe and invest in garments that they could keep for the duration of their lifespan. Consequently, the material used in the production of clothes gains importance as clothing made to last longer should have a sturdy enough fabric such as linen, organic cotton, or Tencel.\nSome Slow Fashion Characteristics:\n- Having high quality and sustainable materials\n- Being timeless in their designs\n- Producing and sourcing in-house or local places\n- Selling in local stores\n- Having few and specific styles per collection, or permanent seasonless collection\n- Being made-to-order to reduce unnecessary production\nSustainable fashion, as can be inferred from its name, uses sustainable methods to produce and market wearables such as clothes, shoes, and accessories that are both environmentally and socio-economically conscious. This fashion practice considers all stages of the product’s life cycle, from design, raw material production, manufacturing, transport, storage, marketing, and final sale, to use, reuse, repair, recycling, and upcycling. It is aimed to be environmentally friendly and to minimize any undesirable environmental effects by:\n- Using natural resources such as water, energy, land, soil, plants, etc. carefully and efficiently\n- Selecting renewable energy sources like wind and solar power at every stage\n- Indulging in eco-friendly practices like repair, remake, reuse, recycling, and upcycling\nSustainable fashion companies should encourage people to adopt more sustainable consumption patterns like buying less, using longer, upcycling, repairing, etc., and do sustainable caring and washing practices.\nFrom a socio-economic perspective, working conditions should be improved for workers in terms of welfare, wages, safety, transportation chain, insurance policies, etc.\nThere are several noteworthy approaches to sustainable fashion like circular fashion, slow fashion, eco or green fashion, cradle to cradle, ethical fashion, fair-trade fashion, organic fashion, minimalistic wardrobe, etc."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:668d577c-07b8-4792-97f7-94f3b0247be3>","<urn:uuid:848dea19-3d0c-4b7f-82e1-0ef80dc23b94>"],"error":null}
{"question":"What are the detailed storage requirements for virus samples, and how long can they be preserved before they become compromised?","answer":"Virus samples should be transported and stored at 2°C-8°C and submitted for inspection immediately. The sample transport and storage time should not exceed 48 hours. When virus samples (including A-type H1N1 and H3N2 virus suspensions with virus titer of 1x106) are stored in VTM solution, they can be successfully isolated within 48 hours, whether stored at 2-8°C or room temperature. The VTM solution itself can be stored at 5-25°C with a 12-month expiration date. It's important to note that inappropriate temperature storage will affect the final results, and if the sampling solution turns yellow or turbid, the sample should be recollected for testing.","context":["Viral Transport Medium\nViral Transport Medium(VTM)\nViral Transport Medium\n20 servings / box\nCollection, storage and transportation of human nasopharyngeal virus samples\nThe virus sampling kit is based on Hank's solution. The solution contains inorganic salts, amino acids, and protein-stable ingredients. The virus sampling kit has a stable osmotic pressure, which provides a stable transport and storage environment for nasopharyngeal swab samples. Samples are sent to the laboratory for follow-up testing to determine whether the collected samples are infected with the virus.\n|Sample tube||1 sampling tube with 3.5ml sampling solution||1 sampling tube with 3.5ml sampling solution|\nSampling tube: 100mmx16mm 120mmx16mm\nsodium chloride: 0.8%,\n|Sampling swab||1 sampling swabs||2 sampling swabs|\n1. In 2006, virus preservation solution was Hank's solution.\nIn 2010, upgrade to VTM, with a higher PCR test positive rate and shorter test time.VTM is recommended by the World Health Organization and the National Influenza Center of China.\nBased on Hank ’s, VTM adds HEPES, amino acids, glycerin and other ingredients, with higher PCR positive rate.\n1.A type H3N2 virus (virus titer is greater than 1e6), diluted 10 times, 100 times, 1000 times and 10,000 times\nwith VTM and Hank ’s.\n1. No matter whether it is stored at low temperature or room temperature, VTM has a lower CT value than Hank ’s\nat different virus dilution, which means shorter detection time.\n2.In real work, almost every laboratory will have a positive PCR test, but the virus cannot be isolated.\nThe reason is that virus isolation is performed after the positive PCR result, time difference is the main reason for this problem.\n1. The A-type H1N1 virus and H3N2 virus suspensions (the virus titer is 1x106, which is equivalent to the virus level while the actual sampling conditions are not good) are stored in VTM solution.\nRegardless of the virus is stored in VTM at 2-8 ° C or room temperature, the virus can be isolated within 48 hours.\n3.The virus sample collected in the swab can only be detected by PCR and separated from the virus if it is successfully released into the sampling solution.\nThe release rate of the swab greatly affected the positive rate of PCR detection and virus isolation.\nIn order to increase the swab release rate, we innovatively add specially treated glass elution beads to the sampling solution.\nExperiments have shown that the sample release rate has increased 3 times.\nThe used sample collection tube should be placed on an oscillator.\nThe vortex generated is shaken to drive the elution beads to hit the sampling swab, so that the cells and virus particles adhered to the swab are released into the virus sampling solution.\nThe number of virus particles eluted into the sampling solution can be accurately calculated by using immunofluorescence method and observing live fluorescent particles labeled with green fluorescent protein (GFP) under the fluorescent inverted\nThe sample release rate has increased 3 times.\n4.Mold contaminationafter sample collection is a problem for the laboratory to prepare sampling liquid or other brands of sampling tubes.\nIn order to inhibit bacteria in the early sampling solution, penicillin (inhibiting bacteria) and amphotericin B (inhibiting mold) are added.\nRelatively, penicillin is still stable at normal temperature, while amphotericin B is stable only at -20 ° C. The activity of amphotericin B decreases rapidly at room temperature until it disappears.\nThat is the main reason why most of the sampling tubes cannot be stored at room temperature.\nAs a company specializing in cell culture and virus isolation, Yocon Biology replacespenicillin with stable gentamicin at room temperature.\nNot only solves the problem of allergies to penicillin in some people, but also raises normal temperature Antibacterial effect of the stored sampling solution on bacteria.\nThe amphotericin Bwas replaced with a normal-temperature stable fungal antibiotic, which solved the problem of mold contamination after sampling and saved the sample solution at room temperature.\nStorage: 5-25℃ Expiration date: 12 months\nPlease refer to the outer box for the production date and expiration date.\nThe collected nasopharyngeal swab samples should be transported at 2°C-8°C and submitted for inspection immediately. Sample transport and storage time should be no later than 48h.\n1. Before sampling, mark the relevant sample information on the label of the sampling tube.\n2. Use a sampling swab to sample at the nasopharynx up to different sampling requirements.\n3. Sampling methods are below:\na. Nasal swab: Gently insert the swab head into the nasal condyle of the nasal passage, stay for a while and then slowly turn it out. Wipe the other nostril with another swab, immerse the swab head in the sampling solution, and discard the tail.\nb. Pharyngeal swab: Wipe the bilateral pharyngeal tonsils and posterior pharyngeal wall with the swab, immerse the swab head in the sampling solution, and discard the tail.\n4. Quickly place the swab into the sampling tube.\n5. Break the sampling swab above the sampling tube, and tighten the tube cap.\n6. Freshly collected clinical specimens should be delivered to the laboratory within 2 hours at 2°C-8°C.\n[Interpretation of results]\nIf the collected sampling solution turns yellow or turbid, the sample should be re-sampled for testing.\n1. Contaminated samples after collection will affect the final results.\n2. Store samples at inappropriate temperature will affect the final results.\n2.1 Sampling solution\nClear pink liquid.\nNot less than the indicated amount (3.5mL).\n7.0-7.6 at 20°C-25°C\n2.1.4 Freezing point osmotic pressure\n2.2 Sampling swab\n2.3 glass bead\n2.4 Sample preservation effect\nThe virus samples are stored in the virus sampling kit at 2℃-8℃ for 48h, and the RT-PCR nucleic acid test\n2.5 Difference between batches\nThree consecutive batches of products should meet the requirements of 2.1, 2.2, 2.3\n1. This product is for in vitro diagnostic use only.\n2. This product is intended for use by trained laboratory personnel only.\n3. Gloves and masks should be worn for protection while using the product.\n4. Discarded specimen collection liquid should be treated by moist heat sterilization.\n5. Prohibited use when solution is out of date, the sampling solution turns yellow, leakage.\n6.The BSA in the export VTM is replaced by a kind of amino acid that isolated from E coli. fermentation product to meet the requirements of the local laws and regulations.\nRegistrant / Manufacturer Name: YOCON Biology Technology Company\nResidence: 304, Third Floor, A Building, No.7 Fengxian Middle Road, Haidian Beijing\nContact information: Zip code:100094 Phone: 010-58711655\nFax: 010-58711656 Website: www.yocon.com.cn\nProduction address: 303-304, Third Floor, A Building,105, First Floor B Building No.7 Fengxian Middle Road,\nProduction license number: 20180033\n[Medical device registration number / product technical requirement number]\n[Specification approval date and modification date] September 01, 2020\n- No album download"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:6b562acc-35f4-41af-9421-fe8217130bdc>"],"error":null}
{"question":"Which plant has more impressive blooming characteristics - the beach-dwelling Guettarda speciosa or the Cardinal Candy Viburnum?","answer":"Guettarda speciosa features fragrant white flowers that are 2.5-3 cm long with 4-9 lobes, blooming from October to May, followed by sweet-smelling globular hard fruit. Cardinal Candy Viburnum produces small fragrant creamy white flowers in large, rounded clusters in late spring, followed by bright red fruits in showy clusters that persist through winter until spring. While both have fragrant flowers, they have distinctly different blooming patterns and fruit characteristics.","context":["Guettarda speciosa, with common names sea randa, or zebra wood, is a species of shrub in the family Rubiaceae found in coastal habitats in tropical areas around the Pacific Ocean, including the coastline of central and northern Queensland and Northern Territory in Australia, and Pacific Islands, including Micronesia, French Polynesia and Fiji, Malaysia and Indonesia and the east coast of Africa. It reaches 6 m in height, has fragrant white flowers, and large green prominently-veined leaves. It grows in sand above the high tide mark.\n|Guettarda speciosa (artist John Lindley)|\n|Occurrence data from GBIF|\nTaxonomy and namingEdit\nIt was originally described by Carl Linnaeus. The genus was named in honour of the 18th century French naturalist Jean-Étienne Guettard, while the specific epithet is derived from the Latin speciosus 'showy'.\nIt is a perennial shrub or small tree 2–6 m (6.6–19.7 ft) tall by 1–3 m (3.3–9.8 ft) wide with smooth creamy grey bark. The large oval-shaped leaves are 15–23 cm (6–9 in) long by 10–18 cm (4–7 in) wide. Dark green and smooth above with prominent paler veins, they are finely hairy underneath. Flowering is from October to May, the fragrant white flowers are 2.5–3 cm (1–1 1⁄4 in) long with 4–9 lobes. These are followed by sweet-smelling globular hard fruit, measuring 2.5 cm–2.8 cm × 2.2 cm–2.5 cm (0.98 in–1.10 in × 0.87 in–0.98 in), which mature September to March.\nDistribution and habitatEdit\nGuettarda speciosa is found in coastal habitats in tropical areas around the Pacific Ocean, including the coastline of central and northern Queensland and Northern Territory in Australia, and Pacific Islands, including Micronesia, French Polynesia and Fiji, Malaysia and Indonesia and the east coast of Africa. As its name suggests, the beach gardenia grows on beaches and sandy places above the high tide level.\nUse by indigenous culturesEdit\nThe large leaves were used in various ways by the indigenous people of northern Australia; they could hold food, and when heated, they were given to relieve headaches and aches in limbs. The stems could be used to make Macassan pipes. The flowers were used to scent coconut oil on the Cook Islands, and the wood for dwellings and canoes.\nA very useful plant for seaside planting in tropical climates, it needs a sunny aspect and well-drained soil. It has proven difficult to propagate, as this must be done by seed which may take months to germinate.\n- Guettarda speciosa GBIF.org (28th November 2018) GBIF Occurrence Download https://doi.org/10.15468/dl.ncywcn\n- \"Guettarda speciosa\". Germplasm Resources Information Network (GRIN). Agricultural Research Service (ARS), United States Department of Agriculture (USDA). Retrieved 21 November 2014.\n- Guettarda speciosa Australian Tropical Rainforest Plants Retrieved 28 November 2018.\n- McCormack G (2007). \"Guettarda speciosa\". Bishop Museum: Cook Islands Biodiversity Database. Bishop Museum. Retrieved 2008-06-01.\n- Simpson DP (1979). Cassell's Latin Dictionary (5th ed.). London: Cassell Ltd. p. 883. ISBN 0-304-52257-0.\n- Elliot, Rodger W.; Jones, David L.; Blake, Trevor (1990). Encyclopaedia of Australian Plants Suitable for Cultivation: Vol. 5. Port Melbourne: Lothian Press. p. 162. ISBN 0-85091-285-7.\n- Brock, John (2001) . Native plants of northern Australia. Frenchs Forest, New South Wales: New Holland Press. p. 211. ISBN 1-876334-67-3.\n- Levitt, Dulcie (1981). Plants and People: Aboriginal Uses of Plants on Groote Eylandt. Canberra: Australian Institute of Aboriginal Studies. ISBN 0-391-02205-9.","Fifteen native plants have been planted in our neighborhood native plant and pollinator garden. Here are photos and descriptions of each of these. If you are interested in adding any of these to your garden, Colesville Nursery in Mechanicsville carries most of these; plants may also be available on-line from various sources.\nJoe Pye Weed, Eutrochium purpureum is late-blooming perennial native to much of the U.S. It is a wildflower and an herb that was used as an herbal remedy to lower fevers and other maladies. In some plants, the leaves and flowers can give off a vanilla-like scent. Joe Pye Weed attracts butterflies and birds.\nAgastache, Agastache a member of the mint family (lamiaceae); a perennial plant with flower spires that bloom all season long. The Agastache flower is commonly found in purple to lavender but may also bloom in pink, rose, blue, white and orange. Also called hyssop or hummingbird mint. It is a favorite plant for attracting hummingbirds and butterflies to your garden and is known as a nectar plant.\nBee balm, Monarda. The bee balm plant is a North American native. Bee balm is very attractive to bees, butterflies and hummingbirds. The bee balm flower has an open, daisy-like shape, with tubular petals in shades of red, pink, purple and white. Bee balm plants are perennial, coming back year after year.\nYarrow, Achillea millefolium. Despite their tendency to spread, yarrow plant varieties offer a host of flower colors and can fill a multitude of roles in the garden. Yarrow plants are probably one of the easier perennials to grow. Plants are generally pest-free, and they’re not picky about soil or demanding when it comes to care. The blossoms of all yarrow plants attract all kinds of pollinators — butterflies, beneficial insects, hummingbirds and different kinds of bees and wasps flock to yarrow flowers. Yarrow plants can spread somewhat aggressively in the garden. They self-sow readily and spread by underground stems.\nGarden phlox, Phlox paniculata is a hardy, long-lived perennial. From midsummer to early fall, the plants are topped with large clusters of fragrant flowers that come in a range of colors including white, pink, fuchsia, red, lavender, purple and orange as well as dozens of bi-colors. The sweet-smelling, nectar-rich blossoms attract butterflies and hummingbirds and are beautiful in summer flower arrangements.\nCatmint, Nepeta. Related to catnip, but much showier, catmints are easy to grow perennials that have flowers in shades of purple-blue, pink and white, as well as gray-green foliage that remains attractive throughout the growing season as well. All are great plants for attracting bees and butterflies.\nButterfly weed, Asclepias tuberosa L. This bushy, 1-1/2 to 2 ft. high perennial has large, flat-topped clusters of bright-orange flowers. The brilliant flowers attract butterflies. Because its tough root was chewed by the Indians as a cure for pleurisy and other pulmonary ailments, Butterfly Weed was given its other common name, Pleurisy Root.\nGoldenrod, Solidago, is a genus of 100 to 120 species of flowering in the aster family, Asteraceae. Goldenrod often is inaccurately said to cause hay fever allergies in humans. The pollen causing this allergic reaction is produced mainly by ragweed (Ambrosia sp.), blooming at the same time as the goldenrod and pollinated by wind. Goldenrod pollen is too heavy and sticky to be blown far from the flowers, and is pollinated mainly by insects. Frequent handling of goldenrod and other flowers, however, can cause allergic reactions, sometimes irritating enough to force florists to change occupation. Goldenrods are attractive sources of nectar for bees, flies, wasps, and butterflies.\nRussian sage, neither truly Russian nor a sage, Perovskia atriplicifolia is a trustworthy, drought-tolerant shrub. In 1995, Russian sage received the Perennial Plant of the Year award. Russian sage, due to its fragrance, is resistant to deer, rabbits, and other smaller creatures. Russian sage attracts butterflies and bees and is dramatic as a cut flower.\nLittle bluestem grass, Schizachyrium scoparium. These grasses are most commonly called Little Bluestem, but can go by “bunch grass,” “beard grass,” or “creeping bluestem.” It will grow in a variety of soils, thriving in those that are well-drained, medium to dry, and infertile. It gives food and shelter to wildlife and attracts birds and pollinators. According to the USDA, it’s one of the best grasses for nesting and roosting habitat. The plant produces seeds which can be blown from the main plant and sprout.\nDogwood tree, Cornus florida, “Cherokee Brave.” Cherokee Brave Flowering Dogwood features showy clusters of crimson flowers with white centers held atop the branches in mid spring. It has forest green foliage which turns burgundy in spring and brick red in the fall. It produces red berries from early to late fall and is a good choice for attracting birds.\nFringe tree, Chionanthus virginicus. Fringe tree usually is ignored in favor of dogwood, saucer magnolia, flowering cherry, Bradford pear and numerous other choices for spring-flowering trees. Indigenous to the eastern U.S., it grows from Canada all the way down to the Gulf Coast. It’s tougher than dogwood, more dependable than saucer magnolia, longer-lived than cherry, and smells better than Bradford. Fringe tree gets its name from its clouds of fleecy white, softly fragrant flowers that hang from the branches in late spring and early summer. Trees can be either male or female. Males sport larger, showier blooms, but females form blackish-blue fruits that birds like.\nArrowwood viburnum, Viburnum dentatum. Arrowwood viburnum is an upright, rounded, multi-stemmed, deciduous shrub which typically matures to 6-10′ tall with a similar spread. Non-fragrant white flowers up to 4″ diameter appear in late spring. Flowers later give way to blue-black, berry-like fruits that are attractive to birds and wildlife. Variable fall color ranges from drab yellow to attractive shades of orange and red.\nViburnum, Dilatatum, “Cardinal Candy.” Cardinal Candy typically matures to 4 to 5 feet tall and as wide. This is a dense, free-branching, bushy, upright-rounded, deciduous shrub that is distinguished by its multi-season ornamental interest and excellent winter hardiness. Small fragrant creamy white flowers in showy, large, rounded clusters form in late spring. Flowers give way to bright red fruits in showy clusters. Fruits mature in late summer to early fall but persist through winter until spring. Fruit is attractive to birds.\nEuropean Snowball Viburnum, Viburnum opulus ‘Roseum.’ A large rounded shrub reaching 10 to 12 feet. Considered to be an heirloom plant, which is why it is the most commonly known viburnum to the public. Blooms profusely with large, double 3-inch flowers in “snowballs” in mid-May. Flowers are first apple green, changing to pure white for an extended period. In high demand by the floral industry as a cut flower for arrangements. All of the flowers are sterile so there is no fruit. Fall color is shades of reds and yellows."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:34d61034-c24d-49f7-be29-909a55530029>","<urn:uuid:8cb1963f-57e0-4490-9c7e-6d42e24aeba8>"],"error":null}
{"question":"How does climate change affect Arctic shipping routes, and what are the main economic challenges facing these maritime passages today?","answer":"Climate change is causing Arctic ice to recede, potentially opening up shipping routes that were historically impassable. The Northwest Passage could soon be accessible due to global warming, potentially reducing the crossing distance from Atlantic to Pacific by thousands of miles. However, contrary to popular belief, summer sea ice extent plays only a minor role in determining the routes' popularity. The main challenges are economic: reduced bunker fuel prices have made shortcuts less economically attractive, while falling commodity prices have decreased the value-to-weight ratio of transported goods. This makes it more cost-effective to use larger vessels, which are difficult to operate in Arctic conditions. Additionally, ice-hardened vessels capable of operating in these routes are smaller, and regular vessels requiring icebreaker escorts must follow size and draft restrictions.","context":["Searching the Arctic for What Wasn't There\nIt Took Centuries to Find the Northwest Passage\nText by James Breig\nPhotos by Dave Doody\nA long-wished-for northern water route from Atlantic to Pacific promised greatly shortened voyages to trade for riches from the East. The Arctic yielded no ready access till recent summer melting of the polar cap.\nGerard Mercator’s late sixteenth-century map of the Arctic and surrounding lands records attempts by explorers Frobisher and Davis to find the Northwest Passage. It was believed an inland lake or rivers allowed passage across the American continent.\nSeen in part in this satellite photo and winding its way from the Atlantic through archipelagoes of the Canadian Arctic and on to the Bering Strait between Alaska and Russia, the Northwest Passage remained unnavigable because of ice until recent thawing.\nIn 1745, readers of the Virginia Gazette, a weekly newspaper published in Williamsburg, learned that back in England Parliament “had resolved to bring in a Bill to grant a Sum of Money to any Person or Persons who shall discover the N. West Passage.” Seven years later, the Gazette informed its audience that “an Officer of the Marine who has been twice or thrice at Greenland” had given “Reasons for supposing there is an open North West Passage into the South Seas.” After fifteen more years had passed, the newspaper said, “Great discoveries have been made relative to the North West passage.” After five additional years, subscribers saw that “the Government is preparing to send out Major Rogers . . . in Pursuit of the North West Passage.” Two decades later, the Gazette reported that the empress of Russia had dispatched three ships to attempt “the Discovery of the north west Passage to China.” A year later, two British ships were sailing “at the End of Spring . . . to discover a Northern Passage to the South Sea”—as the Pacific was called. When spring arrived, the paper said two French frigates were “fitting out at Brest . . . to attempt the north west passage” ahead of the British explorers.\nThroughout the eighteenth century, explorers from Great Britain, Denmark, France, and Russia tried and failed to find the Northwest Passage, that is, a practical route from the Atlantic seaboard of America to the Pacific that would shorten the trade route between Europe and the Far East. All failed, but they were in storied company. Long before and long after their ventures, sailors and trailblazers tried to find the passage. In the twenty-first century, nature may be opening the way. The New York Times reported in October 2007, “The Arctic ice cap shrank so much this summer that waves briefly lapped along two long-imagined Arctic shipping routes, the Northwest Passage over Canada and the Northern Sea Route over Russia.”\nFor at least four centuries, finding the Northwest Passage was a dream like finding the golden fleece, the Holy Grail, the fountain of youth, and cities of gold. Uncovering a route from Europe to the Far East by sailing west inspired explorers, churchmen, businessmen, and governments seeking an easier path to glory, converts, goods, and power. John Logan Allen, author of Lewis and Clark and the Image of the American Northwest, wrote that the quest endured so long because the desire for such a route trumped its nonexistence. By the way, Lewis and Clark were looking to find an all-water route to the Pacific, too.\n“A lot of geographical ideas,” Allen said, “are born out of desire: If you want something to be organized in a certain way, it will be—in your head. If you have a strong geographical imperative, you can say, ‘I don’t want to be confused by geographical facts.’\n“The desire in this case belonged to European powers and businesses that were eager for a way to get their goods cheaply and quickly to the East, and return just as quickly and cheaply with Asian supplies.” Europeans “knew it was a rich area from the reports of Marco Polo and other travelers,” Allen said. “With the increase in agricultural production and population in the thirteenth to fifteenth centuries, Europe was looking for a source of raw materials, like lumber, and new markets.”\nThe sources included China, Japan, and Indonesia. The lure of the passage was that it offered a means “of getting the riches of the Orient for the markets of western Europe” and vice versa, said historian James Ronda. The western route seemed to guarantee “wealth and imperial power. Those are strong motives and enormously influential forces.”\nIn the late fifteenth century, the search motivated such navigators as Christopher Columbus and John Cabot. Cabot was attempting to find a simple way to the East when he ran into a 3,000-mile-wide obstacle: North America. The sixteenth and seventeenth centuries saw efforts by Martin Frobisher, Francis Drake, John Davis, Henry Hudson, William Baffin, and others who probed the eastern and western edges of the New World to find a waterway that connected the oceans.\nIn the seventeenth century, England established Jamestown in part to “gain the rich trade of the East India, and so cause it to be driven through the Continent of Virginia, part by Land and part by Water, and in a most gainfull way and safe, and far lesse expenceful and dangerous than now it is,” in the words of the 1649 Perfect Description of Virginia. Many of the Northwest Passage explorers would focus on the northern regions of North America in the belief that a polar passageway existed. Belief in it was so common that cartographers put it on their maps and named it the Strait of Anian.\nThe phrase “northwest passage” first appeared in print in the reports of Richard Hakluyt, a geographer who published Voyages in Search of the North-West Passage in 1587. He sought to prove there was a passage through America “to go to Cathay and the East Indies.” Cathay was another name for China. Citing Plato and Aristotle in support of his argument, Hakluyt said that learned men of the past “would never have so constantly affirmed” such a passage “if they had not had great good cause and many probable reasons to have led them thereunto.”\nAs the eighteenth century dawned, the long-sought-for route was as elusive as ever. In the Age of Reason, with its emphasis on scientific evidence and provable facts, the idea that the passage might be wishful thinking seemed to have occurred to few. A Spanish admiral recorded in his diary that the passage had “no other foundation than the madness or ignorance of someone devoid of all knowledge of either navigation or geography.” But he was an exception to what Ronda termed “the tenacity of illusion” and “the geography of hope,” which posited, “Because you want it to be there, it will be there.” And people wanted it to be there.\nScholar Philip V. Allingham said that “the matter of a direct sea route to Asia was always foremost in the minds of those controlling British naval exploration. . . . As Britain acquired colonial possessions in the Pacific and the former thirteen colonies became a national rival to British power on the North American continent, Britain’s discovery of a viable Northwest Passage loomed even larger in the minds of government officials.”\nIn the 1700s, adventurers, scientists, and military leaders had a couple of notions of what the passage was, John Allen said. “By the 1770s, it evolved into a configuration which includes either a large lake or inland sea in the middle of the continent, or a large river navigable to the interior,” where a pyramidal rise in the land would lead to another river rushing to the Pacific. With that notion and others in their minds, eighteenth-century explorers headed into terra incognita:\n- In 1753, the Pennsylvania Gazette reported that Captain Charles Swaine had returned from his search for the passage with the news that “there is no communication with Hudson’s Bay through Labrador where one had here to fore imagined.”\n- In 1778, Captain James Cook was ordered to “explore such rivers or inlets as may appear to be of a considerable extent and pointing towards Hudson Bay or Baffin Bay.”\n- In 1789, Alexander Mackenzie set off on a trek across Canada in an attempt to find a combination of rivers, straits, and other waterways that would unlock the doors to Asia. He failed, but he did not give up.\n- In 1781, J. Carver wrote in Travels through the Interior Parts of North America in the Years 1766, 1767, and 1768 that “a Northwest Passage, or a communication between Hudson’s Bay and the Pacific Ocean” could be found and result in “many useful discoveries.”\n- In 1793, Mackenzie made it to the Pacific with a handful of Indian guides and fellow voyageurs. He painted his name on a rock to prove his arrival, but he had proved something else: how torturous the journey was, involving many portages and much walking, impediments to swift trade.\nColonial Williamsburg’s Willie Balderson as Meriwether Lewis discusses with Bill Barker’s Thomas Jefferson the proposed Lewis and Clark expedition to find, among other things, a usable water route through the continent to the Pacific. They did not find it.\nThe search for the Northwest Passage, so fascinating to explorers, has intrigued authors and filmmakers, too. Allingham said, “Polar exploration captured the British imagination, as the opening of Conrad’s Heart of Darkness suggests. Dickens’s The Frozen Deep also attests to popular fascination with polar exploration.”\nThe search motivated Walt Whitman to pen an epic poem, “Passage to India,” a celebration of exploration and global unity. The mention in the Virginia Gazette of the real Major Robert Rogers undertaking a search for the passage has a fictional counterpart in Northwest Passage, a popular novel of the 1930s by Kenneth Roberts. When it was made into a 1940 movie starring Spencer Tracy as Rogers, the search for a passage was lost in a tale about the French and Indian War.\nAmong the books the Lewis and Clark expedition inspired was 1996’s Undaunted Courage by Stephen Ambrose. In 1997, Ken Burns, a documentary filmmaker, produced Lewis and Clark: The Journey of the Corps of Discovery. The duo’s trek got a fictionalized Hollywood treatment in The Far Horizons, a 1955 film starring Fred MacMurray and Charlton Heston as the explorers.\nThe Founding Fathers were not immune to passage-mania. George Washington believed that the Potomac, which flowed past Mount Vernon, was the beginning of a series of rivers that would transport goods a long distance. A Frenchman assured Washington that “it is less difficult to discover the Northwest Passage than to create a people, as you have done.” Thomas Jefferson told James Madison that “the Ohio, and its branches which head up against the Patowmac, affords the shortest water communication by 500 miles of any which can ever be got between the Western waters and Atlantic.” Jefferson had a long-standing curiosity about the western expanses that began at Virginia’s border, a curiosity perhaps inherited from his father, Peter, who had surveyed the Old Dominion’s interior and sought land grants beyond the Allegheny Mountains. In 1793, the year Mackenzie moved toward the setting sun, Jefferson financially supported a French botanist’s plan, eventually aborted, to “find the shortest & most convenient route of communication between the U.S. & the Pacific Ocean.”\nAs the eighteenth century gave way to the nineteenth, President Jefferson launched a search for the passage by commissioning Meriwether Lewis and William Clark and their Corps of Discovery to walk, ride, portage, row, and sail from the middle of the United States to the Pacific and back. The purpose of the expedition, Jefferson wrote, was\nto explore the Missouri River, and such principal streams of it, as, by its course and communication with the waters of the Pacific Ocean, whether the Columbia, Oregan, Colrado, or any other river, may offer the most direct and practicable water-communication across the continent, for the purposes of commerce.\nFor all of its successes in charting rivers, establishing contacts with Native Americans, chronicling flora and fauna, and reaching the Pacific, the expedition failed in its main goal. With the jagged, jutting Rockies blocking the way and meandering, rapids-riddled rivers not connecting with one another, Lewis and Clark did not find a simple way to get across the continent.\nNevertheless, fascination with the Northwest Passage did not wane. Much of the exploration was in the Canadian Arctic, a region that had shorter latitudes and was dotted with a watery maze of islands through which ships could pass when the ice receded. One of the most elaborate attempts was Sir John Franklin’s 1845 expedition with more than 120 men on two ships, Erebus and Terror. The vessels were laden with three years’ supplies, including nearly five tons of chocolate and 2,400 books. The crew disappeared, and rescue missions found only traces of them. Some historians believe ice death-gripped the ships for two years.\nAs the twentieth century began, the search captivated Norwegian explorer Roald Amundsen, who admired Franklin but opted for an approach that was the polar opposite. To traverse the Arctic, Amundsen took a handful of men aboard a small boat, Gjoa, with relatively few supplies. His notion was to eliminate the need for enormous crafts loaded with tons of goods; instead, the explorers would forage for food and build shelters, as the native Inuits did. In 1905, two years after he left Oslo, Amundsen encountered an American whaler, confirming that he had crossed from the Atlantic to the Pacific.\nThat led some people to declare that he had discovered the Northwest Passage; but, if the passage is defined as an easy, practical, and repeatable route, Amundsen fell short.\nWith the invention of submarines came another method of making the passage: instead of fighting against the implacable ice, a craft could slide underneath it. The United States sub Nautilus did just that in the 1950s when it reached the North Pole. Still, a simple route had not been charted.\nIt is a debatable point whether the Northwest Passage has been found. Looked at another way, however, it has been discovered several times. James Ronda said, “There are different kinds of passages, and they have changed dramatically from the fifteenth century to our own time. There have been trails, rails, and the interstate highway system. Each of these takes objects from the Atlantic to the Pacific. The idea is still very much alive. It’s one of the most enduring ideas—and illusions—in the history of American geography.”\nJohn Allen said the transcontinental railroad in the middle of the 1800s was “the penultimate gasp of the Northwest Passage idea, with the completion of the interstate highway system” as the idea’s twentieth-century finale.\nIn these efforts through the centuries, Philip Allingham finds recognition that nature could be a powerful enemy. “The third-generation Romantics, including Tennyson and Dickens,” he said, “reluctantly acknowledged that Nature was not the benign deity she seemed in the south of England and the Lake District. Rather, as the Franklin Expedition’s members and the various search parties learned through excruciating experience, she was terrible, fearsome, and utterly inimical to European intrusion.\n“In the North, no trees grew, ice retreated for only a month, towering ice floes could crush European vessels as if they were match-sticks, and only the aboriginals, superbly adapted to such a harsh environment by generations of experience, could survive temperatures below what had been the theoretical minimum of zero Fahrenheit. The creation and maintenance of Empire, the British realized, required an heroic endurance and sacrifice that were, as in the case of the Franklin Expedition, sometimes quite pointless.\n“Perhaps, then, the greatest contribution of the Northwest Passage was undermining the popular appreciation of imperialism” as incapable of defeat and failure.\nIn the end, nature may uncover what man could not. After thwarting explorers for centuries, nature may be opening the Northwest Passage. Because of global warming, whether caused by human activity or the cycles of weather, Arctic ice is receding. Some scientists say the route westward could be open within a few years and slice the crossing from Atlantic to Pacific by thousands of miles.\nWith that possibility in mind, Prime Minister Stephen Harper of Canada preemptively told the United States in 2006 that his nation owned something that had previously been a chimera: the long-sought Northwest Passage.\nView a clip about the Northwest Passage from Colonial Williamsburg's 2005 Electronic Field Trip \"Jefferson's West.\"\nSmall - Quicktime (912kb\nSmall - Windows Media Player (900kb)\nLarge - Quicktime (1.5Mb)\nLarge - Windows Media Player (1.7Mb)\nJames Breig, is an Albany-based writer who contributed to the Holiday 2007 journal an article on Williamsburg weddings.\nSuggestions for further reading:\n- John Logan Allen, Lewis and Clark and the Image of the American Northwest (Urbana, IL, 1975).\n- Harold B. Gill and Joanne Young, eds., Searching for the Franklin Expedition: The Arctic Journal of Robert Randolph Carter (Annapolis, MD, 1998).\n- Glyn Williams, Voyages of Delusion: The Quest for the Northwest Passage (New Haven, CT, 2003).","BODO, Norway – Economic factors, such as reduced bunker fuel prices and slowing demand for commodities, are the primary reasons for reduced shipping traffic along Russia’s Northern Sea Route, according to research presented by Arctic shipping experts at Bodo’s High North Dialogue conference. Higher amounts of summer sea ice during 2014 and 2015, on the other hand, play only a minor role. What does this mean for the future prospects of Arctic shipping?\nInterest in the commercial use of Arctic shipping routes first emerged following the rapid decline in summer sea ice in 2007. If the Arctic Ocean were to become ice-free during the summer months in the near future, the thinking went, it could serve as a shortcut for vessels travelling between Europe and Asia. The Northern Sea Route (NSR), as well as its less popular Canadian cousin the Northwest Passage (NWP), can cut the distance on popular routes, such as Rotterdam (the Netherlands) to Shanghai (China), by up to 35 percent potentially offering significant time and fuel cost savings.\nShipping traffic on the NSR steadily increased since the first non-Russian-flagged voyages in 2009 and reached 71 transits carrying 1.35 million tons of cargo in 2013. However, since then shipping volumes on the route have declined sharply, falling to a low of just 18 transits and 40,000 tons in 2015. Have the prospects of Arctic shipping been oversold? And what explains the lack of interest in utilizing the NSR since 2013?\nArctic Shipping Sensitive to Global Economy\nFelix Tschudi, chairman and owner of the Tschudi Group, a shipping and investment company based in Oslo, identifies the fallen bunker fuel prices as a key reason for the decline in Arctic shipping. As fuel expenditures have decreased sharply, the cost of transportation has become less significant for shipping operators and with that shortcuts have become less economically attractive.\n“The economic calculations have changed since 2013 and the benefits of the NSR as a shortcut have largely been lost,” said Tschudi. “The value of the time saved is much less compared to 2013.”\nIn addition, commodity prices of raw materials have fallen sharply, in part due to declining demand, especially in Asia. As a result the value-to-weight ratio of transported goods has decreased, placing larger emphasis on economies of scale. Simply put, when prices are low it becomes more important to ship commodities on larger vessels because it reduces the relative cost of transportation. Ice-hardened vessels capable of operating on the NSR are much smaller and regular vessels requiring icebreaker escorts have to abide by size and draft restrictions.\n“At the current price levels, commodities are no longer able to carry the transportation costs on the NSR,” Tschudi said.\nReduced Availability of Icebreakers\nAn additional factor, according to Tschudi, is the reduced availability of icebreaker escorts from Rosatomflot, the world’s only company maintaining a fleet of nuclear-powered icebreakers. While Atomflot was keen to provide icebreaker escort services in previous years, the ongoing and growing construction of the Yamal LNG gas project and the Port of Sabetta have tied up capacity, reducing the company’s ability to escort and assist commercial shipping operations.\nIce Extent Variability Minor Factor\nContrary to popular belief, the extent of summer sea ice in the Arctic Ocean only plays a minor role in determining the popularity of the region’s shipping routes. Laurence Smith, professor and chair of the geography department at the University of California Los Angeles, emphasized that ice-extent variations over the past few years, together with projected variability in the future, make up one of many factors. “Ice-extent variability under different climate forcings factors little into the overall economic equation of Arctic shipping,” Smith said, during a talk at the university in which he presented research on the impact of climate model variability on future Arctic shipping.\nSmith and his coauthor Scott Stephenson, professor at the University of Connecticut, used data from dozens of existing climate models and “translated” it with the use of a geographic information system (GIS) to devise an Arctic Transportation Accessibility Model (ATAM).\nTheir model shows a simulated future of sea-ice extent based on climate models and then calculates the fastest routes through the Arctic Ocean. Based on this research, the NSR is highly likely to remain the preferred Arctic shipping route, with only some outlier models predicting the NWP as a significant transport route.\nIn the second part of the 21st century, a more direct transpolar sea route outside the Russian Exclusive Economic Zone closer to the North Pole may also become feasible.\nArctic Shipping Remains a Complex Equation\nThe economic complexities described by Tschudi and Smith surrounding the viability of Arctic shipping were also the subject of research published by the Copenhagen Business School earlier this year. The study identified more than a dozen variables, ranging from ship hull design and fuel prices to cargo types and routes served, as key determinants of cost on the NSR. It concluded that summer ice extent and length of navigability on the NSR are just one of many variables.\n“The fall in oil prices has lowered the incentive of using the Arctic routes despite the reduced sailing distances. Low oil prices diminish the large distance benefits on the Northern Sea Route as fuel costs decline throughout the shipping industry,” said Peter Gronsedt, lead author of the study and researcher at CBS.\nWhile forecasts of a rapid increase of traffic on the NSR may have proven overly optimistic, the current slump is merely temporary, said Tschudi. Transit traffic may be down but a lot of internal and destination traffic is still going on, delivering infrastructure supplies into the Arctic and carrying hydrocarbon resources out of it. Thus, Tschudi said: “Arctic shipping is not dead, but it’s been put on ice temporarily.”\nThe views expressed in this article belong to the author and do not necessarily reflect the editorial policy of Arctic Deeply."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:bc85e00b-d0d2-48d8-9fe3-e63149d1f9b9>","<urn:uuid:862e60cc-295d-432e-ac17-efdf00bf00ae>"],"error":null}
{"question":"Hey history buffs! I'm curious about military bugle calls - what's the real difference between 'Taps' in the US and 'The Last Post' in British tradition? How did they each come about? 🎺","answer":"Both Taps and The Last Post are among the most recognized military bugle calls in the world and share similar functions. The Last Post originated in British military tradition as part of the evening Tattoo routine in the 17th century, marking the completion of the duty officer's final rounds. It was first referenced in J. Hyde's 'Preceptor for the Bugle' in 1818. Taps, on the other hand, was adapted by Union Army General Daniel Butterfield in July 1862 during the Civil War as a revision of the 'Extinguish Lights' signal. Both calls serve dual purposes - marking the end of the day and being played at military funerals and memorial services. While similar musically, The Last Post uses the low C note and is typically performed in Bb concert pitch, while Taps can be sounded in Bb, G, and sometimes F. There is a false story claiming Taps originated from a Union Captain finding his dead Confederate son, but this has been debunked by military historians.","context":["The “Taps” Military Bugle Tune Came From a Confederate Soldier Whose Body was Discovered By His Father, a Union Soldier in the Civil War–Fiction!\nSummary of eRumor:\nA Union Captain in the Civil War named Robert Ellicombe hears the moan of a soldier in the distance one night near Harrison’s Landing in Virginia. He decides to investigate and discovers that the solider, who is wearing a Confederate uniform, has died. By the light of his lamp, he realizes to his surprise and horror that the dead solider is his own son. The son had studied music in the South and without telling his father, had enlisted in the Confederate army. The grief-stricken father requests a military burial for his son, complete with an army band. His superiors decline, however, because his son was an enemy soldier, but give him the choice of one musician. The caption chooses a bugler and using a short piece of music he found in his son’s uniform, the tune for “Taps” comes into being and has been used ever since for military funerals.\nAccording a researcher at West Point, there is no historical evidence that anyone named Robert Ellicombe even existed in the Union army. Master Sergeant Jari Villanueva is a part of the United States Air Force Band and is not only a historian about the tune “Taps,” but is working on an exhibit for Arlington National Cemetery about bugle calls. Both he and Kathryn Shenkle, Historian for Arlington National Cemetery, agree that “Taps” came from Brig. General Daniel Butterfield at Harrison’s Landing in Virginia in 1862. Sgt. Villanueva has found correspondence from both General Butterfield and a bugler which confirm the origins, although there are some minor discrepancies in their letters.\nFor more information:\nIt all began in 1862 during the Civil War, when Union Army Captain Robert Ellicombe was with his men near Harrison’s Landing in Virginia.\nThe Confederate Army was on the other side of the narrow strip of land.\nDuring the night, Captain Ellicombe heard the moan of a soldier who lay mortally wounded on the field.\nNot knowing if it was a Union or Confederate soldier, the captain decided to risk his life and bring the stricken man back for medical attention.\nCrawling on his stomach through the gunfire, the captain reached the stricken soldier and began pulling him toward his encampment.\nWhen the captain finally reached his own lines, he discovered it was actually a Confederate soldier, but the soldier was dead.\nThe captain lit a lantern.\nSuddenly, he caught his breath and went numb with shock.\nIn the dim light, he saw the face of the soldier.\nIt was his son.\nThe boy had been studying music in the South when the war broke out.\nWithout telling his father, he enlisted in the Confederate Army.\nThe following morning, heartbroken, the father asked permission of his superiors to give his son a full military burial despite his enemy status.\nHis request was partially granted.\nThe captain had asked if he could have a group of Army band members play a funeral dirge for the son at the funeral.\nThat request was turned down since the soldier was a Confederate.\nOut of respect for the father, they did say they could give him one musician.\nThe captain chose a bugler.\nHe asked the bugler to play a series of musical notes he had found on a piece of paper in the pocket of his dead son’s uniform.\nThis music was the haunting melody we now know as “Taps” that is used at all military funerals.\nThese are the words to “Taps”:\n“Day is done,\nGone the sun,\nFrom the lakes,\nFrom the hills,\nFrom the sky.\nAll is well.\nGod is nigh.”","Taps Vs. The Last Post\nA look at two iconic bugle calls\nOf all the bugle signals sounded in the world, the two that stand out as music of remembrance are the American bugle call Taps and its Commonwealth counterpart The Last Post. With the exception of a few, most bugle calls are only a few bars long and are not usually recognized by the general population. To be sure there are calls like Reveille, First Call (heard at Race Tracks), Charge (heard at Baseball games) and the almost recognizable calls for Retreat and To The Color that are sounded to mark the end of the military duty day. But Taps and The Last Post are among the most recognized melodies in the world. Both calls share a similar function in that there are both sounded at the end of the day and for funerals and memorial services.\nTwo good books on the history of the calls can be found in “Twenty-Four Notes That Tap Deep Emotions-The Story of America’s Most Famous Bugle Call” by Jari Villanueva and “The Last Post-Music, Remembrance and the Great War” by Alwyn W. Turner. (Both available though Amazon)\nThe Last Post is one of a number of bugle calls in British military tradition which mark the phases of the day. Where Reveille signaled the start of a soldier’s day, the Last Post signaled its end. It is believed originally to have been part of a more elaborate routine, known in the British Army as Tattoo that had its origins in the 17th century. During the evening, a duty officer had to do the rounds of his unit’s position, checking that the sentry posts were manned and rounding up the off-duty soldiers and packing them off to their beds or billets. He would be accompanied by one or more musicians. The “first post” was sounded when the duty officer started his rounds and, as the party proceeded from post to post, a drum was beat. The drum beats told off-duty soldiers it was time to rest – if the soldiers were billeted in a town, the beats told them it was time to quit the pubs. Tattoo is a derivation of “doe den tap toe”, Dutch for “turn off the taps”, a call which is said to have followed the drum beats in many a Dutch pub while English armies were campaigning through Holland and Flanders in the 1690s. Another bugle call was sounded when the party completed their rounds, when they reached the “last post”: this signaled the night sentries were alert at their posts and gave one last warning to any soldiers still at large that it was time to return to the garrison. One of the first references to the call can be found in the “Preceptor for the Bugle” by J. Hyde published in 1818. It is titled 2nd Post and is written for two buglers. The call is performed as a solo today.\nThe Last Post was incorporated into funeral and memorial services by the late 19th century in England as a final farewell symbolizing that the duty of the dead is over and that they can rest in peace. At funerals and memorial services, The Last Post is followed by the call The Rouse (Reveille). The idea of having a “wake up” call following a somber sounding dates back many years. Stephen Graham wrote two centuries ago, “The Last Post” is the Nunc Dimittis [the promise of salvation as found in Luke 2: 29-32] of the dead soldier. It is the last bugle call…but it gives promise of reveille…\nBy the time the First World War broke out in 1914, The Last Post was part of the British national culture. Mostly it was still associated with soldiers, but increasingly it was also being played at the funerals of civilians such as Wallace Hartley, the bandmaster of the Titanic. During the war, it was sounded countless times at funerals at the front. With mass enlistment and then conscription, the walls that had long existed in Britain between the civilian and the soldier broke down completely, and a piece of music that had once belonged exclusively to military culture was adopted by a wider society. HG Wells said this was “a people’s war”, and the Last Post became the people’s anthem. As memorials were constructed following the war, most notably The Cenotaph and the Unknown Warrior, The Last Post became an integral part of ceremonies honoring those who died in the Great War.\nThe call is sounded every evening at the Menin Gate in Ypres, Belgium. You can read about that here:\nIn the United States, bugle signals dated back to the revolution. Like the British military, American bugle calls were found in printed military tactics manuals around the start of the 19th century. Taps began as a revision for the signal of Extinguish Lights (Lights Out) at the end of the day. Up until the Civil War, the infantry call for Extinguish Lights was printed in the Infantry tactics manuals with the bugle signals taken from the French. The music for Taps was adapted by Army General Daniel Butterfield for his brigade in July, 1862. As the story goes, General Butterfield was not pleased with the call for Extinguish Lights, feeling that the call was too formal to signal the days end. With the help of his brigade bugler, Oliver Willcox Norton (1839-1920), Butterfield wrote Taps to honor his men while in camp at Harrison’s Landing, Virginia, following the Seven Days battle in June, 1862. The new call, first sounded that night in July, 1862, soon spread to other units of the Union Army and was reportedly also used by the Confederates. Taps was made an official bugle call after the war.\nThe highly romantic account of how Butterfield composed the call surfaced in 1898 following a magazine article called “The Trumpet in Camp and Battle,” by Gustav Kobbe, (1857-1918) a music historian and critic. Both Norton and Butterfield responded to the magazine article with their versions on how the call originated.\nMore on the history of Taps can be found at: https://www.tapsbugler.com/an-excerpt-from-twenty-four-notes-that-tap-deep-emotions-the-story-of-americas-most-famous-bugle-call/\nThe original purpose for Taps was to signal Lights out for soldiers. It was called at first Extinguish Lights although it was commonly referred to as Taps (for the three tap beats on a drum to signal lights out). During the Civil War Taps was sounded at a funeral, a practice that was to continue on in an unofficial capacity until 1891 when Taps was formally recognized in the Army manual in name and as the call sounded at funerals. It has been used since at funerals, wreath ceremonies and memorial services.\nBoth calls share things in common. Both are sounded at military funerals and in the evening to mark the end of the day. Both encompass the overtone range of the bugle, although The Last Post uses the low C. Both were written to be sounded on a bugle but are commonly performed on trumpets or cornets. While The Last Post is performed in Bb (concert), Taps is sounded in Bb, G, and sometimes F. Both calls have a dual purpose-to end the day and as an honors piece of music at funerals and memorial services.\nWhile Taps has had many sets of lyrics written to the music, most notably “Day Is Done, Gone The Sun”, there are no official words to the call. The Last Post by its very nature of being a longer call has very few lyrics set. Here is one I’ve found.\nCome home! Come home!\nThe last post is sounding for you to hear.\nAll good soldiers know very well there is nothing to fear while they do what is right, and forget all the worries they have met in their duties through the year. A soldier cannot always be great, but he can be a gentleman and he can be a right good pal to his comrades in his squad.So all you soldiers listen to this – Deal fair by all and you’ll never be amiss.\nBe Brave! Be Just! Be Honest and True Men!\nThe origin of both Taps and The Last Post cannot be traced to any composer. The first reference to the musical notes of Taps are found in the 1835 Infantry Manual prepared by Major General Winfield Scott. Taps is found in the last part of the call The Tattoo. This has been commonly referred to as the Scott Tattoo although General Scott probably did not compose the music. The Last Post can be traced to the “Preceptor for the Bugle” by J. (John) Hyde published in 1818 under the title 2nd Post. Hyde was a trumpeter in the King’s Theatre Orchestra and a fine keyed bugler who was also credited with inventing the English Slide Trumpet. It is not known whether he composed the calls or arranged them. He may have had a hand in both.\nOn November 11, 1918 World War I came to and end with the Armistice that took effect at 11 am. Thus was born the phrase: “The 11th hour of the 11th day of the 11th month.” As the war came to an end bugles were sounded including a rendition of Taps that General John “Black Jack” Pershing ordered performed by his bugler Hartley Edwards. Edwards (known as “Hot Lips”) stood next to a rail car in the Forest of Compiègne and did as he was told. Later, Edwards learned that he blew the call that signified the end of the Great War. He later repeated the call under the Arc de Triomphe in a parade in 1919 as part of the first of many Armistice Day celebrations.\nThere is some disagreement with Edwards’ story as pointed out here:\nIt is not known if The Last Post was sounded at 1100 on November 11, 1918. Certainly buglers would have sounded Stand Fast or Cease Fire. I know of no specific British Bugler that day sounding the calls at 1100. However a French Bugler, Bugle Corporal Pierre Sellier is said to have sounded the call (presumably French) Cease Fire at 1100. According to Time Magazine “the bugle which stopped the World War” was deposited at Les Invalides, the great Paris War Museum. The bugle was donated to Indiana’s War Memorial Museum in 1949 where it is on display today.\nOn a daily basis Taps and The Last Post are sounded at military funerals and memorials services in the United States and the United Kingdom. For 100 nights during the summer Taps is sounded at the Gettysburg National Cemetery in Gettysburg Pennsylvania where Abraham Lincoln delivered his famous address in 1863. At the Menin Gate in Ypres, Belgium Last Post is sounded every evening in a ceremony.\nOn November 11, 2018 thousands of buglers around the world sounded their call of remembrance to mark the centennial of the Armistice.\nYou can download music to Taps, The Last Post and The Rouse by clicking here: Taps Last Post Rouse\nHere are videos of Taps and The Last Post"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:ac60cfc6-6410-4518-bb5e-227e91a845da>","<urn:uuid:77763871-5c21-427c-87d9-21f851b93eda>"],"error":null}
{"question":"Could you compare how the Art Professional Ethics survey findings relate to the historical pattern of artwork removals in museums?","answer":"The Arts Professional Ethics survey revealed that over 70% of arts organization employees feel their employers are at reputational risk through association with controversial sponsors, yet only about a quarter of organizations have ethical decision-making policies in place. This contemporary concern is reflected in the historical pattern of artwork removals, where artists have frequently used the removal of their work as a form of protest against institutional decisions and associations. These removals have become a significant form of political gesture spanning many decades, demonstrating that ethical concerns about institutional associations have been a long-standing issue in the art world.","context":["Michelle writes for Charities Management magazine\nArts charities and fundraising ethics\nFundraising is hard enough without having to turn down sponsors who want to give charities money. Yet, according to the recent Arts Professional Ethics survey, more than 70% of arts organisation employees feel that their employer is at reputational risk through association with a sponsor or major donor whose own reputation is subject to criticism.\nThey’re not exaggerating. This year, we’ve seen several high profile cases such as the sponsorship of the Great Exhibition of the North which was brought to a rapid close and the furore in relation to Sackler Trust’s funding of several major arts organisations due to its wealth being created by Purdue Pharm.\nEven more recently, the outrage surrounding the Design Museum’s decision to host a private event for the defence contractor Leonardo as part of the Farnborough International arms fair put its temporary exhibition “Hope to Nope” in the spotlight for all the wrong reasons.\nWhen thirty artists and designers demanded their work be removed from display, the sentiment behind Design Museum’s exhibition, which celebrates political protest, seemed hypocritical at best and, to some, an example of exploiting the political spirit without respecting the art itself.\nUnsurprisingly, there is a high degree of nervousness from arts charities about what’s appropriate when soliciting funding. Sponsorship must be “defensible”, i.e. it must align with the values of a charity and help them to further their aims. But we also need to support our fundraisers to be able to actively raise funds from as wide a variety of sources as possible.\nFundraising is a difficult job at the best of the times and if we create too narrow a view of what makes an appropriate source of funding then we are putting potential sponsors in an impossible situation. We mustn’t make art too difficult to fund.\nSo what is a “defensible” policy and how can an arts charity avoid backlash, without ignoring vital fundraising opportunities? Is it possible for organisations to be sensitive to their stakeholders’ views without impacting the commercial success of the organisation? And does due diligence require a thorough review of a potential sponsors’ own stakeholders? If a brand that is funding a charity has links through a parent company or subsidiary to an unfavourable business, does this disqualify it as a sponsor?\nConversations about what constitutes a good sponsor aren’t straight forward and it’s important that there is a structure to any discussion, linking to an agreed upon policy so that individuals who are making decisions can reference the charity’s developed policy and justify their decisions. Opinions run high from a personal perspective when we talk about ethics, and it’s important to remember that as far as possible we should come to an organisational consensus as to what’s appropriate as opposed to an individual one.\nA charity needs to invest time to consider their position. The first step could be to develop an ethical policy that outlines which associations are acceptable or not. This activity should be led by the charity’s trustees. It’s disappointing to learn that only a little over a quarter of respondents to the Arts Professional survey said that their organisation has a policy in place to help them make ethical decisions.\nThe policy shouldn’t be a “nice to have” and needs to be fully debated throughout the organisation. Decisions and policies need to be reviewed regularly. Opinions change, reputations change, and we need to make sure that our views are up to date.\nThe policy is there to help charities make ethical decisions and shouldn’t be prohibitive. Against a backdrop of the continued threat of more public funding cuts, it seems that trustees and leaders of arts organisations are getting more risk-averse. Amidst a range of worries, the last thing that an organisation needs is attention drawn to it through controversy. There is also an underlying fear that taking the wrong sort of private money could impact funding agreements with public bodies such as Arts Council England.\nAudiences can be cynical. Many believe that sponsorship of the arts is just an excuse for major corporations to cleanse their reputations. And with this in mind, we absolutely need to understand the position that an organisation represents. The sponsor reports to private interest, and the charitable arts organisation to the interests of the public. Sponsorship isn’t philanthropy, it’s a business exchange, and in this context, if a sponsorship can’t work for both parties then it shouldn’t be entered into.\nLondon 2012 gave us much to think about in relation to ethical sponsorship. Sainsburys received mostly good press for their sponsorship of the Paralympics which played to their core values and gave them the chance to build on existing programmes such as Active Kids. In contrast, critics saw Atos sponsorship as lacking on moral grounds due to the view that they had treated disabled people unfairly in delivering the “fit to work” programme.\nAnd this is key when we debate the ethics of sponsorship. We have to focus on values. The bottom line is that the trustees of arts organisations need to decide whether taking on a sponsorship will help further the artistic or charitable cause, but also whether the association can genuinely align with core values.\nThe starting point with developing ethical fundraising has to be that each organisation feels comfortable with its decision-making. An arts organisation needs to have a clear line and understand its core principles long before negotiations with a sponsor start. The buck stops with the charity’s trustees and leadership. It is their job to talk to donors and the public to gather opinions about what’s right, and to rely on their own instincts about whether a practice is ethical or not.\nA well run board will actively engage in the ethical debate and will continue to return to the issue even after a set of ethical guidelines has been agreed upon. Raising money at any cost is not acceptable and waiting to see whether the sponsorship will be noticed outside the organisation, and if so what the public reaction could be, is a risky business.","Artists removing work from an exhibition (or having it removed for them) is a pointed and often political gesture—and part of a lineage covering many decades to the present. Last year, eight artists called for their work to be removed from the Whitney Biennial in protest of the chair of the museum’s board. Since then, Phil Collins and Ali Yass pulled out of a MoMA PS1 show about the Gulf Wars, and a group of artists removed their art from the Aichi Triennale in Japan over claims of censorship. Meanwhile, a video by Xandra Ibarra was removed from a show of Chicanx performance art in Texas earlier this year after local politicians deemed it “obscene.”\nRemovals such as these have historical precedents. Below is a guide to some of the most notable artworks that have been removed—either by force or by choice—over the past 50 or so years.\nTakis pulls work from Museum of Modern Art (1969)\n“The Machine as Seen at the End of the Mechanical Age,” Pontus Hultén’s 1968 group show at MoMA, has been considered a landmark exhibition for its interest in technology. But the show is also major for what happened around it—the removal of an artwork by the Greek artist Takis. Toward the end of the show’s run, Takis picked up a sculpture of his that was on view in the exhibition, claiming that the museum had not consulted him before installing it, and moved it into MoMA’s courtyard. He described the removal as a symbolic action intended to open up conversation between artists and upper-ranking museum staff. After discussion with MoMA’s director, the work was officially taken out of the exhibition for good.\nRobert Morris closes show at the Whitney Museum (1970)\nRobert Morris removed not just one artwork but an entire show as debate surrounding the Vietnam War raged in America. Many in the New York art scene tried to figure out what role artists could play in protest, and Morris became the leader of an antiwar movement that swept the city’s art world—and even resulted in a widespread strike that saw museums and galleries close. As part of his efforts, Morris shuttered his solo exhibition at the Whitney in an gesture, he said at the time, meant “to underscore the need I and others feel to shift priorities at this time from an making and viewing to unified action within the art community against the intensifying conditions of repression, war and racism in this country.”\nDaniel Buren sculpture taken down at the Guggenheim (1971)\nMany artists have dramatically transformed the rotunda of the Guggenheim Museum in New York, but none has courted so much scandal as Daniel Buren. His artistic intervention in the space—a striped drape titled Around the Corner that hung from the ceiling and extended almost all the way down—didn’t seem controversial. But some artists who were exhibiting in its midst (in a now-defunct recurring survey known as the Guggenheim International) felt differently. In an effort led by Dan Flavin and Donald Judd, five artists claimed that Buren’s art obstructed views of Frank Lloyd Wright’s sloping architecture—and their own work. They called for it to be deinstalled, and after they got what they wanted, feted art historian Douglas Crimp (then a curator at the museum) resigned because of the fracas.\nUlay moves Hitler’s favorite painting (1976)\nSometimes removal can be both a form of protest and an artwork in itself. For a “protest action” titled Irritation – There is a Criminal Touch to Art, performance artist Ulay seized his attention on the 1837 Carl Spitzweg painting The Poor Poet: a quaint image of a writer counting out the meters of his verse in a cramped attic that was also Adolf Hitler’s favorite artwork (he even owned a copy of it). Ulay chose not to let Germany forget that fact by marching into the Neue Nationalgalerie in Berlin, taking the work of the wall, and bringing it to the home of a Turkish immigrant elsewhere in the city. Ulay returned the painting 30 hours later, and the temporary theft was documented by his partner Marina Abramović.\nRichard Serra’s Tilted Arc deinstalled (1989)\nFrom its initial installation in 1981, Richard Serra’s Tilted Arc—a 120-foot-long arc crafted with Corten steel in Lower Manhattan’s Foley Plaza—was meant to lead to an intriguing reorientation of a viewer’s understanding of a picturesque location. Not everyone saw it that way, however—and after howls from the public, a jury voted in favor of taking down the enormous mass of 73 tons of steel that were unceremoniously hauled away to a government-owned parking lot in Brooklyn.\nAdrian Piper pulls out of Conceptualism survey in L.A. (1995)\nIn 1995, the Museum of Contemporary Art Los Angeles staged “1965–1975: Reconsidering the Object of Art,” a major survey focused loosely on the evolution of Conceptualism. But the proceedings were marred by controversy when one of the sponsors was revealed: Philip Morris, the cigarette company that owns Marlboro. The artists in the show claimed not to have been notified in advance, and Adrian Piper asked MOCA to pull her work from the show and replace it with Ashes to Ashes (1995), a piece focused on her parents’ struggles with—and, ultimately, deaths from—cancer that may have been caused by smoking. When the museum declined, she withdrew from the show entirely.\nTania Bruguera installation shuttered at the Havana Biennial (2000)\nTania Bruguera is no stranger to controversy, having regularly staged boundary-pushing performances that have raised the ire of officials in her home country of Cuba. Originally staged in a fortress used to house political prisoners in the 1950s, her installation Untitled (Havana, 2000) was a darkened space in which viewers could see barely visible nude performers who appeared to be slapping their bodies and video footage of Fidel Castro as they walked across a mat of sugarcane. Brugerua’s consideration of the state of the body under oppressive regimes was closed by authorities hours after opening. Since then, it has been acquired by MoMA, which restaged it in 2018.\nAdrian Piper yanks video from black performance art exhibition (2013)\nEighteen years after her MOCA removal, Piper pulled work from “Radical Presence: Black Performance in Contemporary Art,” an exhibition spread across NYU’s Grey Art Gallery and the Studio Museum in Harlem. Piper’s work appeared in the NYU part, where she was presenting documentation of her past performances as the Mythic Being—a male alter ego she assumed to test gender and racial norms. Piper said she felt limited by the show’s purview and suggested that curator Valerie Cassel Oliver organize “multi-ethnic exhibitions that give American audiences the rare opportunity to measure directly the groundbreaking achievements of African American artists against those of their peers in ‘the art world at large.’”\nYams Collective drops out of the Whitney Biennial (2014)\nAmid outrage over a work by the white male artist Joe Scanlan, who got black female performers to play a fictional character known as Donelle Woolford, the Yams Collective (also known by the name HOWDOYOUSAYYAMINAFRICAN?) pulled their work from the Whitney Biennial in 2014. “We felt that the representation of an established academic white man posing as a privileged African-American woman is problematic, even if he tries to hide it in an avatar’s mystique,” one of the collective’s members told Hyperallergic at the time.\nShanghai officials strike Ai Weiwei from survey (2014)\nAi Weiwei has frequently accused governments and museum figures of censorship in ways that have affected his standing in his home country of China. In 2014, days before the government-operated Power Station of Art in Shanghai was to stage an exhibition devoted to the winners of collector Uli Sigg’s Chinese Contemporary Art Award, officials in the city yanked Ai’s work—including his famed Sunflower Seeds installation—and dropped his name from the artist list. At the time, Sigg said, “We don’t understand but we must accept that his works will not be in there.”\nAnimals pulled from Chinese art show in New York (2017)\nThe Guggenheim Museum faced a widespread outcry when several historically important artworks featuring live animals went on view in a survey of Chinese art. The controversial pieces included Huang Yong Ping’s Theater of the World, featuring a see-through case in which insects and amphibians preyed upon one another; photo documentation of Xu Bing’s A Case Study of Transference, in which pigs were inked with Chinese characters; and a Sun Yuan and Peng Yu video that involved dogs on treadmills. Animal-rights groups widely decried the works, and after an online petition garnered tens of thousands of signatures, the museum pulled them—leading some to wonder whether the protesters properly understood the cultural context for the art on view.\nOlu Oguibe obelisk taken down in Germany (2018)\nA giant obelisk dedicated to immigrants by Nigerian-born Olu Oguibe was one of the most celebrated offerings at the 2017 edition of Documenta—it even won the artist the exhibition’s top prize. But after the city of Kassel formalized plans to install the work, the work, titled Monument to Strangers and Refugees, was targeted by right-wing politicians who raised doubts about its pro-refugee message and the price of its installation. The monument was removed—but then, just two weeks later, reinstated.\n10 artists pull out of the Aichi Triennale in Japan (2019)\nAlmost from its beginning, the Aichi Triennale began generating controversy when officials made the decision to remove a show-within-a-show titled “After ‘Freedom of Expression?’” That exhibition featured a sculpture by Kim Seo-kyung and Kim Eun-sung that referred to the history of ianfu—Asian women who were forced into sexual slavery by the Japanese Imperial Army. And when it was taken off view, 10 artists—including Pedro Reyes, Tania Bruguera, Minouk Lim, and Claudia Martínez Garay—pulled their own works from the triennial, claiming that the removal of the ianfu piece was a violation of its makers’ freedom of expression. Ultimately, officials relented—and the ianfu work was reinstated along with all the other works that been taken away."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:15934e9b-43d4-4733-8417-69fb5cb2c6a5>","<urn:uuid:cc16aeae-74be-4067-a420-547fd9acf0a3>"],"error":null}
{"question":"How to differentiate between black box and white box testing methodologies?","answer":"Black box testing identifies bugs only by examining software malfunctioning through erroneous outputs, disregarding internal calculation paths when outputs are correct. In contrast, white box testing (also called glass box testing) examines internal calculation paths to identify bugs. White box testing enables data processing correctness tests, software qualification tests, and maintainability tests. While black box testing can perform output correctness tests and most testing classes, it cannot perform internal processing verification like white box testing can. However, black box testing offers unique testing capabilities that white box testing cannot provide.","context":["Software testing is a formal process carried out by aspecialized testing team in which a softwareunit, several integrated software units or anentiresoftware package are examined by running theprograms on a computer. All the associated tests areperformed according to approved test procedures onapproved test cases.\nSoftware testing (or “testing”) was the first softwarequality assurance tool applied to control the softwareproduct’s quality before its shipment or installation atthe customer’s premises.\n0 At first, testing was confined to the final stage of development, after the entire package had been completed.0 Later, as the importance of early detection of software defects penetrated quality assurance concepts, SQA professionals were encouraged to extend testing to the partial in-process products of coding, which led to software module (unit) testing and integration testing.0 Common to all testing activities is their application through the direct running of code, free of review of development documents. Some authors tend to broaden the scope of testing even further and consider all software life cycle quality assurance activities as types of testing activities.\nSoftware Testing Strategies0 Big bang testing : test the software in its entirety, once the completed package is available;0 Unit Test : test the software piecemeal, in modules, as they are completed0 Integration tests : test groups of tested modules integrated with newly completed modules ().0 Incremental testing : This process continues until all the package modules have been tested. Once this phase is completed, the entire package is tested as a whole (system test).\nIncremental Testing0 In top-down testing, the first module tested is the main module, the highest level module in the software structure; the last modules to be tested are the lowest level modules.0 In bottom-up testing, the order of testing is reversed: the lowest level modules are tested first, with the main module tested last.\nSoftware Test ClasificationsClassification according to testing concept:0 Black box (functionality) testing. Identifies bugs only according to software malfunctioning as they are revealed in its erroneous outputs. In cases that the outputs are found to be correct, black box testing disregards the internal path of calculations and processing performed.0 White box (structural) testing. Examines internal calculation paths in order to identify bugs. Although the term “white” is meant to emphasize the contrast between this method and black box testing, the method’s other name – “glass box testing” – better expresses its basic characteristic, that of investigating the correctness of code structure.\nWHITE BOX TESTING0 White box testing enables performance of data processing and calculations correctness tests, software qualification tests, maintainability tests and reusability tests.0 In order to perform data processing and calculation correctness tests (“white box correctness test”), every computational operation in the sequence of operations created by each test case (“path”) must be examined.\nData processing andcalculation correctness testsApplying the concept of white box testing, which is based onchecking the data processing for each test case, immediatelyraises the question of coverage of a vast number of possibleprocessing paths and the multitudes of lines of code. Twoalternative approaches have emerged:0 “Path coverage” – to plan our test to cover all the possible paths, where coverage is measured by percentage of paths covered.0 “Line coverage” – to plan our tests to cover all the program code lines, where coverage is measured by percentage of lines covered.\nCorrectness tests and path coverageDifferent paths in a software module are created by thechoice in conditional statements, such as IF–THEN–ELSE or DO WHILE or DO UNTIL. Path testing ismotivated by the aspiration to achieve completecoverage of a program by testing all its possible paths.\nCorrectness tests and line coverageThe line coverage concept requires that, for full linecoverage, every line of code be executed at least onceduring the process of testing. The line coverage metricsfor completeness of a line-testing (“basic path testing”)plan are defined as the percentage of lines indeedexecuted – that is, covered – during the tests.\nBlack Box Testing0 Black box testing allows us to perform output correctness tests and most classes of tests. Apart from output correctness tests (if you are prepared to pay the extra costs, these could be performed by white box data processing and calculation correctness tests) and maintainability tests (that could be performed by white box tests), most of the other testing classes are unique to black box testing."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:43466faa-c9da-4943-aebe-a11c599daa15>"],"error":null}
{"question":"How does English language proficiency affect academic achievement in bilingual children with ASD compared to bilingual Thai children in English-based schools?","answer":"For children with ASD, research indicates that bilingualism does not have a detrimental effect on academic achievement, as monolingual and bilingual children with ASD perform similarly on standardized measures. However, for Thai children learning English in English-based schools, studies show they may face academic difficulties for up to 6.5 years while developing English proficiency. These children often struggle with learning academic content while simultaneously learning English, and this process could take even longer in Thailand where the local language is Thai, compared to English-speaking countries.","context":["Profiles of Academic Achievement in Children with Autism Spectrum Disorders with Monolingual and Bilingual Language Experience\nAlthough research has shown that children with ASD with can demonstrate comparable academic skills with their typically developing peers (Mayes & Calhoun, 2008), no research to date has assessed the impact of diverse experiences on academic achievement in children with ASD. Research with typically developing bilingual children find that although English-language learners may lag behind their monolingual peers on measures of academic achievement (Han, 2012), these gaps can be minimized with bilingual programs (Rolstad, Mahoney, & Glass, 2005). Despite these studies on academic achievement in children with ASD and bilingual children, it is unclear whether these patterns will hold for bilingual children with ASD.\nThe present study aims to clarify the impact of diverse language experiences on academic achievement in diverse children with ASD.\nThe current study is part of a larger study evaluating developmental profiles of diverse children with ASD who visited a developmental disabilities clinic located in an urban city in the United States. Clinic records of children between 3 and 12 years of age with clinical diagnoses or educational classifications of an Autism Spectrum Disorder were reviewed. Information about demographics, language experiences, nonverbal IQ, and subtest scores for Wechsler Individual Achievement Test (WIAT; Wechsler, 2001) were extracted from the clinic records. Children were grouped by their language use as monolingual or bilingual based on clinician observations, parent-report of language use in the home and school and language use reported in children’s IEP reports.\nCases were included in the current analyses if children with ASD had data available for at least three WIAT subtests: Word Reading, Numerical Operations, and Spelling. Preliminary analyses included 17 monolingual children and 11 bilingual children. No differences were found in age, age of first diagnosis, and nonverbal IQ (all p’s > .05) between groups. Additionally, the two language groups were comparable in the proportion of males and percentage receiving public aid, see Table 1. To examine academic achievement profiles of monolingual and bilingual children with ASD, a repeated measures ANOVA was conducted with WIAT subtests (Word Reading, Numerical Operations, Spelling) as a within subjects variable, and Language Group as a between subjects variable. These analyses found a significant WIAT subtest X Language Group interaction, F(2, 52) = 3.62, p = .034, partial η2 = 0.12. The results of the significant interaction are displayed in Figure 1. Follow-up t-tests found no significant differences between monolingual and bilingual children with ASD on individual WIAT subtests (all p’s > .05).\nAlthough the preliminary results found a significant interaction between language group and WIAT subtests, follow-up tests revealed no differences between groups. However, the results also indicate that monolingual and bilingual children perform similarly on standardized measures of academic achievement, indicating that learning two languages may not have a detrimental effect on the cognitive development of children with ASD. These results provide initial evidence on the impact of language experience on academic achievement, adding to the limited literature on bilingual language development in ASD.","The Surprising Link Between English Proficiency And Academic Performance: What This Could Mean For Thai Children In English-Based Schools\nSome bilingual children learn both of their languages from birth, whereas other children learn a second language well after their first. In Thailand, local families speak Thai at home, so children are usually first exposed to English once they attend an English-based school. Children who learn English during their school years face the challenge of learning a new language while trying to keep up with academic content. Some content is likely to be missed during this process . It is commonly assumed that after some time and English exposure, these children just “catch-up”, however, in Thailand where the local language is Thai, this is not necessarily the case.\nThere are several studies which have looked at how learning English at school can impact a child’s performance at school. The findings will surprise you...\nHow long does it take a child to become proficient in English?\nStudies have shown that it can take a child anywhere between 1- 6.5 years of exposure to English to become proficient in English . This is also influenced by other factors such as family, education, social and individual factors [3.]\nHow does English proficiency impact a child’s academic performance?\nAn Australian study published last year found that school-aged children who are not yet proficient in English are likely to face academic difficulties compared to their peers . This study also found that children who had better English proficiency when starting school achieved higher academic outcomes overall towards the completion of primary school .\nWhat do these findings mean?\nThese findings suggest that children who first learn English through exposure at an English-based school, could struggle with learning academic content at school for up to 6.5. years. These findings were based on populations living in countries such as Australia and the US, where the main language is English to begin with. However, in a country like Thailand, where the local language spoken is Thai, this could take even longer.\nAs a result, it is likely that local Thai children might be over-identified as requiring Speech Therapy during their school years. I often find myself teaching children concepts in English which I then realize during the session that they already have sound knowledge of in Thai (e.g. ‘past’ and ‘future’ tense). In these cases, the child’s underlying difficulty is not language, but specifically English. Thus, an ESL program is often more suitable for these children.\nHow can we use this evidence practically?\nChildren who are learning English at school would benefit from the use of strategies such as modeling, repetition and emphasis in the classroom. These strategies will help support their understanding of instructions and material presented in class. Once their understanding is supported, their performance when completing tasks will likely improve.\nSeveral children who learn English at school require individualized programs to be tailored to support their learning and performance at school. Before a program can be recommended, there needs to be a strong understanding of the child’s Thai language skills. If the child has adequate Thai language skills, then they can be enrolled in an ESL program. However, if a child is having difficulty with both Thai and English, Speech Language Therapy is recommended, as there is likely to be underlying language impairment.\nThere is a greater need for spreading information about the benefits of being bilingual as well as the difficulties a child is likely to face if they are expected to learn English while at school. This might encourage local parents to expose their children to both Thai and English from a young age if they intend to send them to an English-based school in the future.\nAttending day-care or pre-nursery is a fantastic way for children to become exposed to English from a young age. Attending playgroups or arranging play-dates with other English-speaking children will also help.\nLocal Thai children who first learn English at school are likely to face difficulties keeping up with academic content. Increasing exposure to English from a young age is likely to help with this. Certain classroom modifications and programs such as ESL can be provided for these children during their school years.\n1. Macswan, J., & Pray, L. (2005). Learning English bilingually: Age of onset of exposure and rate of acquisition among English language learners in bilingual education program. Bilingual Research Journal, 29, 653-678.\n2. Brinkman, S. et al. (2009). Population monitoring of language and cognitive development in Australia: The Australian early development index. International Journal of Speech Language Pathology, 11, 419-430.\n3. Halle, T. et al. (2012). Predictors and outcomes of early versus later English language proficiency among English language learners. Early Childhood Research Quarterly, 27, 1-20.\n4. Dennaoui, K., Nicholls, R. J., O’Connor, M., et al. (2016). The English proficiency and academic language skills of Australian bilingual children during the primary school years. International Journal of Speech-Language Pathology, 18: 157-165.\nWelcome to my blog!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:10e23f86-e382-4f39-bf4b-a76258ebb424>","<urn:uuid:efc51235-e3e6-4e42-9cca-e2bb4fcf0429>"],"error":null}
{"question":"Can copper sulfate treatment for tree roots actually kill my trees?! Really worried!","answer":"No, copper sulfate will not kill the tree. The tree roots will simply avoid the copper-tainted soil and find other sources of water and nutrients elsewhere. Copper is a natural biocide, and tree roots will avoid the copper-saturated soil while continuing to grow in untreated areas.","context":["Sewer Lines and Tree Roots\nTree Roots Sewer Line Tips\n- Poison soil surrounding the sewer line with copper sulfate\n- Install 1.5-inch PVC vertical pipes in the ground above the sewer line\n- Use a 2-inch hand auger to drill holes into the soil\n- Pour copper sulfate crystals into the pipe and add hot water\n- CLICK HERE to subscribe to Tim's FREE & Funny Newsletter\n\"The root control/elimination products that flush down a toilet do little to solve the problem in my opinion...... The chemicals often only burn those portions of the roots that actually contact the water flow.\"\nDEAR TIM: The sewer line in my house recently backed up. The plumber who cleaned out the line discovered tree roots were the problem. I've seen products that you flush down the toilet to solve this problem.\nAre they effective? Is there a better, more long-term solution? I really don't have the money to install a new sewer line. Chuck S., St. Cloud, MN\nDEAR CHUCK: Tree roots in sewer lines are probably one of the top ten plumbing problems, especially in older homes. Mother Nature has equipped many trees with sophisticated sensing capabilities.\nFree & Fast Bids\nWhy Do Tree Roots Enter Sewer Pipes?\nThe trees send out feeder roots in all directions in a search for both nutrients and water. The trenches that contain sewer lines rarely contained compacted soil. Roots are naturally drawn to this disturbed soil.\nHow do Tree Roots Enter Sewer Pipes?\nTree roots enter sewer pipes through small cracks in the joints between individual pieces of pipe. Old clay pipes often had the joints packed with mortar.\nThis mortar shrinks as it hardens allowing a tiny micro-crack to develop in the female hub of the old sewer pipe.\nIf tiny feeder roots discover these cracks they enter the pipe and continue their search for moisture and food. Once inside the pipe the roots enlarge and gorge themselves on the plentiful supply of water and food. I have actually taken out grotesque roots that have been over ten feet long and nearly one inch thick in diameter.\nDoes RootX Kill the Tree Roots?\nRootX and other liquid products you pour into your toilet, in my opinion, treat the symptoms to a small degree, but they do NOT SOLVE the problem.\nWater flow in a typical sewer pipe only fills a small percentage of the bottom cross section of the pipe. The chemicals often only burn those portions of the roots that actually contact the water flow.\nSome of the chemicals are drawn into the root system but not enough, in my past experience, to completely wipe out the roots. The tree continues to grow and send roots out to take advantage of the underground oasis.\nHow Can You Stop the Roots From Entering the Sewer Pipe?\nYou stop tree roots from entering the sewer pipe by poisoning the soil on the outside of the sewer pipe. The tree roots will not enter this soil and thus can't get into the sewer pipe.\nI've solved this problem for customers and at an old house, I used to own. You need to install a series of small vertical pipes above the sewer line that resemble miniature oil wells.\nCopper sulfate crystals are put into the pipes along with hot water. The hot water dissolves the copper sulfate and this solution enters the soil above and around the sewer pipes.\nCopper is a natural biocide and tree roots, algae, moss, or any living thing will avoid the copper-saturated soil.\nWill the Copper Sulfate Kill the Tree?\nNo, the copper sulfate will not kill the tree. The tree roots will just avoid the copper-tainted soil and go find other water and nutrients.\nHow Do You Locate the Sewer Line?\nYour best chances of success will happen if you can find a company that sends a small camera into the sewer line. By looking at a video monitor, the best camera operators can pinpoint the exact location outside where the roots are entering the pipe.\nWhat's more, with electronic sensing equipment the professional can tell you the depth and path of the sewer pipe below the surface of the ground at this location. Armed with this data, you can permanently solve the problem.\nHow Do You Drill the Holes for the Small Vertical Pipes?\nUsing a simple earth auger or large drill, you will drill a vertical hole down towards the sewer pipe.\nA 2 or 2.5-inch diameter hole works best as it provides plenty of room to insert a standard schedule 40 1.5 inch PVC pipe into the hole.\nStop drilling when the hole is about 24 to 30 inches above the top of the sewer pipe. Slide the pipe into the hole and glue a threaded female adapter equipped with a plug onto the end of the pipe at the surface. Make sure this is flush with the soil so that lawn mowers do not cut it off.\nCan I Use City Records to Locate the Sewer Line?\nYes, you can use city records to locate the sewer line that runs between your house and the city sewer in the street or alley.\nThe records often will show you where the sewer tap was installed as it entered your property. You should be able to determine where the sewer line leaves your home. The plumber who installed the sewer line usually tries to install it in a straight line.\nIf you can't find a company with a sewer camera, use municipal sewer records to locate your sewer tap and try to estimate where the sewer line might be. Insert a number of PVC pipes in your yard hoping that you spot them above and near the sewer line.\nHow Much Copper Sulfate Should be Used?\nTry to fill the vertical pipe halfway with the copper sulfate crystals. You can have the copper sulfate delivered to your home. CLICK HERE to order some. You'll need one or two 50-pound bags for sure.\nSome home centers may carry them. Immediately pour hot water into the pipe until it flows out the top. The hot water will begin to dissolve the copper sulfate and then this solution will begin to seep into the soil above and around the sewer pipe. Tree roots do not like soil that has been treated with copper sulfate and they will avoid it completely. Add crystals as needed and pour hot water into the pipe every four months or so to stop those pesky sewer backups!"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:5f17ca68-2f62-46f9-a3de-e5ca14082624>"],"error":null}
{"question":"What contrasts exist between the historical photographic documentation of Mexican geological features in the early 1900s and modern basalt construction applications?","answer":"The early 1900s photographic collections focused on documenting Mexico's natural landscapes, including geological features like volcanoes, as seen in the 1906-1909 glass negatives from highland central Mexico. In contrast, modern basalt applications are heavily industrial - the stone is now primarily valued for its construction properties, being used for concrete aggregate, road base materials, building blocks, and processed into innovative materials like basalt fiber composites that feature low water absorption and electrical non-conductivity. This shows an evolution from purely documentary interest to practical industrial utilization.","context":["Subject Source: Library of Congress Subject Headings\nFound in 60 Collections and/or Records:\nCollection — Box 1 - 20\nIdentifier: Image Archive-Collection 01\nScope and Contents 1965-1985. The Abbye A. Gorin Collection includes photographs of people, city and country scenes, architecture, archaeological sites and pre-Columbian art in Spain, Mexico, Guatemala, Peru and the Museum of Mankind in England, taken during the years between 1965 and 1985. Gorin used two cameras in shooting the photographs in the collection: a Rolleiflex (purchased in 1954) with a fixed 3.5/75mm lens, and a Leica M-3 (purchased in 1963) with Leica Summicron 50mm, Summicron 35mm, and Elmarit...\nIdentifier: Image Archive-Collection 38-(9)\nScope and Contents c. 1938. 3 black and white photographs. One shows an informal pose of Mexican artist Frida Kahlo taken in Coyoacán Mexico, by Emmy Lou Packard; the second is an image of Isaac Berliner and Rose; and third is a snapshot of Berliner and his granddaughter.\nDates: c. 1938\nIdentifier: Image Archive-Collection 18\nScope and Contents 1910-1920s. 300 photographs (and negatives) relating to two disparate themes. One is of seals and other wildlife living along the Baja California coast. The second is of Guatemala and its native populations and the city of Tegucigalpa, Honduras. Included in the collection are papers, passport, and obituary of Anthony, a noted naturalist.\nIdentifier: Image Archive-Collection 22\nScope and Contents 1985. 48 photographs of Franciscan churches in Yucatán described by Father Alonso Ponce in 1588 and revisited by Wulfing in 1985. Some of the churches photographed are in modern-day Campeche, which seceded from Yucatán in 1867 and formed its own separate state. The collection also contains Wulfing's 29-page descriptive paper.\nIdentifier: Image Archive-Collection 39-(07)\nScope and Contents 1915-1916. Postcards published by Kavanaugh's War Postals depicting scenes from the U.S.-Mexico border conflict, with some action shots of both sides including troops of Pancho Villa.\nIdentifier: Image Archive-Album-033\nScope and Contents c.1908. An album of 211 gelatin silver prints. The images were taken from across Mexico including the cities of Pachuca, Puebla, Jalapa, Toluca, Morelia, Guadalajara, Guanajuato, San Luis Potosí, Zacatecas, and Aguas Calientes. The album provides images of urban and rural life including street scenes, churches, mining operations, markets, bullfights in Guadalajara, roads, trains, architecture, and indigenous people.\nDates: c. 1908\nCollection — Box 1, Box: 2\nIdentifier: Image Archive-Collection 17\nScope and Contents 1940s-1960s. 500 amateur photographs of Bolivia, Brazil, Costa Rica, Mexico, Guatemala, and Peru. Included are 100 postcards of images taken by Martín Chambi. The work of other photographers like Robert González, Jiménez, Mateo Nieva, and Villavicencio are also included. Contained in the collection are three miniature commercial albums of Brazil.\nIdentifier: Image Archive-Collection 38-(20)\nScope and Contents 1950-2000. 3 color photographs (11\" x 14\") of structures at the archaeological site of Chichén Itzá in northern Yucatán, Mexico. The structures include the main pyramid called \"El Castillo\", the Templo de los Guerreros, and the third image is a shot of the Chacmol statue at the entrance of the Templo de los Guerreros.\nFile — Box 1, Folder: 1\nIdentifier: Image Archive-Collection 40-(1)\nScope and Contents c.1900. Gelatin silver print mounted on a cabinet card (17.5 x 10 cm) taken by F. Parker of El Paso, Texas. Appears to be part of a numbered series. Printed in the lower left, \"61 Chihuahua, Mex.\"\nIdentifier: Image Archive-Collection 26\nScope and Contents 1977. Three sets of black and white prints with negatives and three sets of Ektachrome color slides taken by Betsy Swanson of this Mixtec pictorial manuscript; also includes an older black and white and color set of prints.\nIdentifier: Image Archive-Collection 50\nScope and Contents 1906-1909. Glass negatives of cities and towns from across highland central Mexico including Mexico City, Querétaro, Puebla, Cuernavaca, Morelia, Guadalajara, Tampico and others all showing landscapes, trees, volcanoes, churches, houses, and people. Contact prints made from the negatives are available for consultation. with contact prints of each exposure. 246 negatives with contact prints.\nIdentifier: Image Archive-Photograph Collection 53\nCollection — Box 1\nIdentifier: Image Archive-Collection 28\nScope and Contents c. 1904. 25 printed out paper photographs taken by C.B. Waite throughout Mexico. Numerous views of railroads, parks, archaeological sites, architecture, and a hacienda.\nDates: c. 1904\nIdentifier: Image Archive-Collection 39-(08)\nIdentifier: Image Archive-Collection 38-(21)\nScope and Contents c. 1950. 5 black and white promotion photographs (8\" x 10\") of the Hall of Science at the University of Mexico, downtown Mexico City, Acapulco, granaries, and a singing group. One photograph is attributed to Pan American World Airways.\nDates: c. 1950\nIdentifier: Image Archive-Collection 38-(22)\nScope and Contents 1970. 2 photographs and 1 postcard providing views of an exposure of columnar basalt, 20 miles north of Pachuca, Mexico. It is a natural wonder known to have once visited been visited by Alexander von Humboldt (1769-1859).\nIdentifier: Image Archive-Collection 05\nScope and Contents 1924-1927. 197 photographs taken during three Carnegie Institution expeditions to archaeological sites in Mexico and Guatemala. Three photographs in the collection are attributed to Teobert Maler.\nIdentifier: Manuscripts-Collection 68\nScope and Contents 1940-1980. Collection of personal and business papers, published works, drafts, research and field notes, and texts of Nahuatl plays and stories focusing on modern Nahuatl language and people, with a 19th century Atlixco manuscript and material on the dance of Moros and Cristianos. 6,200 pieces and 2,300 cards.The Fernando Horcasitas Papers reflect the interest and dedication of a man devoted for many years to various aspects of Mexican ethnohistory and linguistics, focusing...\nIdentifier: Image Archive-Collection 24\nScope and Contents 1940s. 45 black and white photographs (10 1/2\" x 13\") of city and country scenes, indigenous people, workers, famous personages, archaeological sites and architecture of Mexico. See also the companion book, Mexico: 64 photographs, by Fritz Henle, which included this passage on the origin of the photographs: \"In 1936, Henle saw Mexico for the first time and, impressed by the paradoxical countray with its centuries-old cultures and its...\nIdentifier: Manuscripts-Collection 151\nScope and Contents 1913-1959. Extensive collection of personal and political papers of General Rafael E. Melgar (1887-1959) who fought in Mexico’s Revolution (1910-1920) and then entered politics to serve in various offices including congressional representative from Oaxaca, campaign manager for Lázaro Cárdenas, governor of the Territory of Quintana Roo, Senator from Oaxaca, and as the Mexican ambassador to Holland. 42 linear feet.A finding aid, ...\nFile — Box 2: Series LAL03_153_02, Folder: 2\nScope and Contents c.1940s. Richly colored double trifold travel brochure for Guadalajara, Mexico produced by the Comisión Nacional de Turismo. The texts are printed in English to target Anglophone tourists, likely from the United States. The introductory text gives a brief history and description of the city of Guadalajara. The body of the brochure contains brief texts and graphic illustrations under the headings of: Principal Attractions, Location and Climate, Hotels, Excursions from Guadalajara, Chapala,...\nCollection — Box 1, Box: 2\nIdentifier: Image Archive-Collection 27\nScope and Contents A collection of 173 photoprints of glass plates taken by Pedro Guerra Jordán in Mérida and elsewhere in Yucatán. Among the images are those of social and work settings, machinery, and Maya archaeological sites.\nDates: c. 1900\nIdentifier: Image Archive-Photograph Collection 57\nFile — Box 1, Folder: 4\nIdentifier: Image Archive-Photograph Collection 80-(4)\nScope and Contents 1900-1910. Set of colored, photomechanical stereocards published by the Sonora News Company. Includes the original box and label. This series contains urban images from the major cities in northern Mexico (Zacatecas, Monterrey, Chihuahua, San Luis Potosí, Aguas Calientes, Veracruz, and Mexico City). Railroads is a second common theme among the images. 40 pieces\nDates: Publication: 1900-1910\nIdentifier: Photograph Collection-39-(18)\nIdentifier: Manuscripts-Collection 86\nScope and Contents December 30, 1927-August 5, 1928. Frans Blom diaries and records written during the 1928 Gray Memorial Expedition to Chiapas, Mexico and Guatemala. Also includes the diary of expedition medic Louis Bristow and Blom's calendar notes, archaeological notes, and notes on plant names. 20 pieces. The collection consists of diaries, notes, records, and photographs made during the Gray Memorial Expedition to Chiapas, Mexico and Guatemala. This was Tulane's 4th expedition to Middle America and was...\nIdentifier: Image Archive-Album-017\nScope and Contents 1877-1898. A photograph album of 32 leaves containing 116 albumen and gelatin silver prints taken by Captain Joshua W. Reynolds. The images document different voyages taken by Captain Reynolds in the Gulf of Mexico and the Caribbean. Most are of Veracruz, Tampico, Havana, and Mexico City. The album includes an early 1877 photograph of the cathedral of Mexico, which includes the Aztec calendar stone. Most of the photographs are identified in Reynolds' own hand.\nDates: 1877 - 1898\nFile — Box 1, Folder: 6\nIdentifier: Manuscripts-Collection 49-(6)\nScope and Contents 1577-1660. Collection of documents in Nahuat and Spanish concerning land tenure from the area of Tulancingo and Chimalhuacan or Sayula, consisting of wills and records of land sales. They relate particularly to Miguel Alejandrino, Gobernador of Tulancingo, his son Diego, Diego de Peredo Suarez, Agata de Santa Ana, and Andrés Tohcuiltecatl who mentions land belonging to Martín Cortés. The original 16th century documents in Nahuatl have 17th century translations into Spanish made by Nicolás de...\nIdentifier: Image Archive-Album-004\nIdentifier: Photograph Collection-39-(13)","10 Types of Stones Used for Building Constructions\nWhat is basalt stone?\nwhat is importance of basalt in construction industry ...\nApr 23, 2019 Basalt fiber features low water absorption, important in construction and pipe applications. Basalt fiber is electrically non-conductive. As a naturally occurring material, it is also inherently more recyclable than other reinforcing fibers, a factor that automotive and other industries take into consideration.\nthe use of basalt rock as a construction material\nPlio ‐ Quaternary Basalt (B)3.56 Мб The columns belong to four different rock types, namely pre‐Tertiary meta‐ophiolites, Eocene limestones, Miocene limestones and Plio‐Quaternary basalts.The most remarkable feature of these build‐ ing is the use of basaltic rocks as construction material.\nThe still-promised potential of basalt fiber composites ...\nApr 23, 2019 · Basalt fiber features low water absorption, important in construction and pipe applications. Basalt fiber is electrically non-conductive. As a naturally occurring material, it is also inherently more recyclable than other reinforcing fibers, a factor that automotive and other industries take into consideration.\nThe many uses of Basalt include the following - Basalt Guru\nJun 12, 2014 · Chopped Basalt fibers, non-woven Basalt needled mats (lined or not with BCF fabrics) find their place in the construction of car and bike exhaust mufflers and of ovens. They are used for the heat insulation of gas turbines, including in nuclear plant locations, as basalt is known to resist to degradation caused by radiations, unlike synthesized materials as glasses.\nWhat is Basalt? - Definition, Uses & Composition - Video ...\nBasalt is a typically dark-colored, extrusive igneous rock, and igneous means that it formed from rapidly-cooled lava on the earth's surface. Remember that extrusive means it hardens at the ...\nBasalt Rock Properties and Uses - Science Struck\nThe tensile strength of basalt is very high, much greater than carbon fiber or fiberglass. Therefore, melted composites of the rock are used for manufacturing pipes and rebars that are used in the construction of wind turbine blades. Ophitic basalt is often used in the medical industry for orthopedic purposes. Industrial Manufacture\nMinerals, Rocks and Stones used in Building Construction in ...\nBASALT: An igneous volcanic rock, dark gray to black, it is the volcanic equivalent of plutonic gabbro and is rich in ferromagnesian minerals. Basalt can be used in aggregate. SCHIST: A metamorphic uneven-granular, medium to coarse grained, crystalline with prominent parallel mineral orientation.\nGlobal Basalt Fiber Market Size, Trends | Industry Analysis ...\nBasalt fiber has not been widely used, unlike Glass Fiber-reinforced polymer (GFRP) and carbon fiber-reinforced polymer (CFRP) materials, Chopped basalt fibers have also been introduced as an additive to concrete mixes to produce fiber reinforced concrete (FRC). The basalt fiber market can be segmented into continuous and discrete.\nBasalt: Igneous Rock - Pictures, Definition, Uses & More\nUses of Basalt. Basalt is used for a wide variety of purposes. It is most commonly crushed for use as an aggregate in construction projects. Crushed basalt is used for road base, concrete aggregate, asphalt pavement aggregate, railroad ballast, filter stone in drain fields, and may other purposes. Basalt is also cut into dimension stone.\nimportance of basalt - Brainly.ph\nAnswer: Basalt is used for a wide variety of purposes. It is most commonly crushed for use as an aggregate in construction projects. Crushed basalt is used for road base, concrete aggregate, asphalt pavement aggregate, railroad ballast, filter stone in drain fields, and may other purposes.\nBasalt Rock | Formation, Properties, Composition, Uses\nUses of Basalt. Basalt is used in construction (e.g. as building blocks or in the groundwork), making cobblestones (from columnar basalt) and in making statues. Heating and extruding basalt yields stone wool, said to be an excellent thermal insulator.\nApplications & Uses of Stones | Uses of Building Stone in ...\nBasalt: It is quarried and crushed as \"Blue Metal\" which is used as a road-base, and in reinforced concrete as aggregate. Although wood, straw and mud is used for houses in some parts of the world, most buildings are preferred to be built of stones.\nTrap Rock: Dark igneous rocks used to make crushed stone\nTrap rock is a name used in the construction industry for any dark-colored igneous rock that is used to produce crushed stone. Basalt, gabbro, diabase, and peridotite are the most common rock types referred to as trap rock. \"Trap rock\" is not a geological term that you are likely to learn about in a ...\nBasalt For Civil Construction\nBasalt rock fibres have new range of material in building construction, road construction, concrete industry and agriculture field. The basalt fibre rebar having full resistance against corrosion may be good alternative for the reinforcement of concrete structures, like RC bridge girders subjected to an environmental attack.\nThe importance of the Code of Hammurabi\nSep 19, 2020 · The Importance of the Code of Hammurabi September 19, 2020 by Konstantina Sakellariou Leave a Comment In one of the central halls of the National Museum of Iran in Tehran, there stands the familiar index-finger-shaped, basalt stele that contains the articles of what is known as the Code of Hammurabi .\nWhat Are the Uses of Basalt Rock? - Reference.com\nApr 15, 2020 · Basalt is most commonly used during construction projects. It can be used as aggregate in asphalt and concrete pavements. It is also used as a road base, railroad ballast and cobblestone pavement. Basalt may be cut into thin slabs and used as monuments, building veneers or floor tiles.\nBasalt fiber - Technobasalt\nBecause of this basalt fibre has several advantages of using it in different applications. Basalt fiber is an innovative and multifunctional material, which can be used in different areas such as the engineering, construction sector, the automotive sector, chemical and oil processing industry, the electronic sector, etc.\nBasalt Fiber Rebar | Monolithic Dome Institute\nMar 03, 2011 · The construction industry is becoming aware of the existence of reinforcing bars made from fiber-reinforced plastic. Fiberglass rebar has been on the market for some time, making inroads where steel rebar doesn’t work well. There is now a new entry into this field, rebar made from basalt continuous filaments.\nBasalt - Wikipedia\nBasalt Igneous rock Composition Mafic: plagioclase, amphibole, and pyroxene, sometimes feldspathoids, or olivine. Basalt is a mafic extrusive igneous rock formed from the rapid cooling of lava rich in magnesium and iron exposed at or very near the surface of a terrestrial planet or a moon. More than 90% of all volcanic rock on Earth is basalt, and the eruption of basalt lava is observed by ..."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:c2ddf52c-c5c2-4a5d-a268-eb12760e7a66>","<urn:uuid:dd532cd3-8fc8-4331-a856-deca11f52261>"],"error":null}
{"question":"How do indoor and outdoor LED installations differ, and what safety considerations apply to each? ⚡","answer":"For indoor LED installations, fixtures should be UL approved, airtight, and IC rated for recessed ceiling lights when there's unconditioned space above. They should be used for ceiling and wall-mounted fixtures that operate more than 2 hours daily. For outdoor installation, LED fixtures require special consideration - 120V fixtures can be wired directly to home electricity, while 12V low-voltage landscape lighting needs a transformer to step down from 120V to 12V. Outdoor installations must use waterproof connections, GFCI-protected outlets, and proper burial of cables 3-6 inches deep, with cables potentially encased in PVC pipe for protection.","context":["Energy-efficient indoor and outdoor lighting design\nIndoor Lighting Design\nWhen designing indoor lighting for energy efficiency, consider some basic design principles and methods.\nEnergy-efficient lighting design principles include the following:\n- More light is not necessarily better: light quality is as important as quantity\n- Match the amount and quality of light to the performed function\n- Install task lights where needed and reduce ambient light elsewhere\n- Use energy-efficient lighting components, controls, and systems\n- Maximize the use of daylighting.\nHere are some basic methods for achieving energy-efficient indoor lighting:\n- Install fluorescent or LED light fixtures for all ceiling- and wall-mounted fixtures that will be on for more than 2 hours each day, such as kitchen and living room, bathroom, hallway, and other higher-demand locations.\n- Consider installing fluorescent or LED fixtures, rather than using fluorescent or LED replacement lamps in incandescent fixtures.\n- Use CFLs or LEDs in portable lighting fixtures that are operated for more than 2 hours a day.\n- Use occupancy sensors for automatically turning on and off your lights as needed.\n- Consider light wall colors to minimize the need for artificial lighting.\n- If you are using recessed lights in a ceiling with an unconditioned space above it, use only Underwriters Laboratory (UL) approved fixtures that are airtight, are IC (insulation contact) rated, and meet ASTM E283 requirements.\nOutdoor Lighting Design\nWhen designing outdoor lighting, consider the purpose of the lighting along with basic methods for achieving energy efficiency.\nOutdoor lighting for homes generally serves one or more of three purposes:\n- Aesthetics: Illuminate the exterior of the house and landscape\n- Security: Illuminate the grounds near the house or driveway\n- Utility: Illuminate the porch and driveway to help people navigate safely to and from the house.\nHere are some basic methods for achieving energy-efficient outdoor lighting:\n- Security and utility lighting does not need to be bright to be effective.\n- Use LED or fluorescent lights unless incandescent lights are automatically controlled to be on for just a few minutes each day.\n- Consider flood lights with combined photo sensors and motion sensors in the place of other security lighting options.\n- Make sure outdoor light fixtures have reflectors, deflectors, or covers to make more efficient use of the light source and help reduce light pollution.\n- Use timers and other controls to turn decorative lighting on and off.\n- Use outdoor solar lighting where applicable.\nThe light-emitting diode (LED) is one of today’s most energy-efficient and rapidly-developing lighting technologies. Quality LED light bulbs last longer, are more durable, and offer comparable or better light quality than other types of lighting\nLED is a highly energy efficient lighting technology, and has the potential to fundamentally change the future of lighting in the United States. Residential LEDs — especially ENERGY STAR rated products — use at least 75% less energy, and last 25 times longer, than incandescent lighting.\nWidespread use of LED lighting has the greatest potential impact on energy savings in the United States. By 2027, widespread use of LEDs could save about 348 TWh (compared to no LED use) of electricity: This is the equivalent annual electrical output of 44 large electric power plants (1000 megawatts each), and a total savings of more than $30 billion at today’s electricity prices.\nHow LEDs are Different\nLED lighting is very different from other lighting sources such as incandescent bulbs and CFLs. Key differences include the following:\n- Light Source: LEDs are the size of a fleck of pepper, and a mix of red, green, and blue LEDs is typically used to make white light.\n- Direction: LEDs emit light in a specific direction, reducing the need for reflectors and diffusers that can trap light. This feature makes LEDs more efficient for many uses such as recessed downlights and task lighting. With other types of lighting, the light must be reflected to the desired direction and more than half of the light may never leave the fixture.\n- Heat: LEDs emit very little heat. In comparison, incandescent bulbs release 90% of their energy as heat and CFLs release about 80% of their energy as heat.\nInfo: Originally Energy Saver is the U.S. Department of Energy’s (DOE) consumer resource on saving energy and using renewable energy technologies at home. Learn more about the Energy Saver Mission.","Landscape Lighting Design Guid\nA little knowledge and planning will help you attain landscape lighting that looks like it was done by a professional. Landscape lighting should include pathways, decks, patios, doorways, drives and other beautifully enhanced features to create a visible picturesque scene of your home. If you are rather unfamiliar with this topic, you may not feel too comfortable with handling the job yourself. You may even feel the need to hire a professional landscape lighting designer. To help you overcome this obstacle, this landscape lighting design guide will offer up some basic information and tips you can apply. Once you are finished reading it, you can shop our online catalog of outdoor light fixtures and buy from us with confidence.\nBenefits of Landscape Lighting\n- Enhances and reveals the beauty of your home and landscape after dusk.\n- Extends the amount of time spent together with loved ones while enjoying outdoor activities, relaxing, breathing fresh air and smelling the roses.\n- Adds dramatic lighting effects to a landscape.\n- Creates a heightened artistic scenic view with high and low points of interest.\n- Increases security and wards off intruders looking for an easy target.\n- Minimizes accidents by lighting up stairs, paths, drives and other traffic areas.\n- Polished and beautifully created landscape lighting escalates the financial value of a home.\nDesigning and Planning your Landscape Lighting\n- Don't over light your yard like a stadium with exterior lighting.\n- Create high and low areas of interest with high and low intensity lighting variations. Overall there should be more low focal points of light than high.\n- Incorporate different types of lighting fixtures into your landscape lighting as they will have different lighting effects and your landscape will be more interesting to look at.\n- Decorative outdoor lights have artistic flair and are designed to bejewel and adorn a landscape and home. Ideally decorative lighting fixtures should be placed more prominently. Other types of outdoor lighting, such as low voltage well lights and spot lights, are best concealed as their purpose is to create interesting lighting effects and the light fixture itself is not designed to draw attention.\n- Don't aim lights directly at windows, including your neighbor's.\n- Place decorative lights in and around pathways, doorways and other activity areas.\n- Pay extra special attention to the front entrance of your home, the welcoming place, which should be one of your high focal points of interest. The type of landscape lighting design you employ here is very important.\nCommon Landscape Lighting Techniques\n- Up Lighting - Light is aimed upwards for dramatic effect. Used commonly to light up a tree, sculpture, or walls. Lighting from below or upfront creates interesting shadows against surfaces behind the lighted objects.\n- Down Lighting - Casts light down and may create interesting effects by way of shadowing. Especially useful in lighting up very dark areas to heighten security and safety.\n- Moonlighting - Simulates moonlight by positioning light fixtures very high above trees and larger plants or objects to create enchanting shadow effects.\n- Accent Lighting - An intense beam, or spotlight, creates high focal points in your landscape. When the light is aimed at the leaves of shrubs, plants or flowers it can create a fantastic glittering effect.\n- Grazing - Placing the light fixture close to a surface to achieve the effect of the light traveling and enhancing the lighted area. Grazing is done against textured walls or beautiful wood. It's also used to highlight a very rough texture of a wider tree.\n- Backlighting - Silhouettes a sculpture, tree or plants.\n- Cross Lighting - Enhances a three-dimensional view of a voluminous plant, tree or object.\nTypes of Lighting Fixtures\nAlways choose quality lighting fixtures and you will never be disappointed. Quality lighting fixtures are time tested for durability and reliability. Their timeless designs and illumination will create a luxurious landscape.\n- Outdoor Lanterns and Wall Lights and Sconces – An excellent choice for doorways, garages, and windows. Used to enhance walled areas or square pillars.\n- Outdoor Ceiling Fixtures – Perfect for porches, patios, breezeways, and covered areas or walkways.\n- Post Lights – Majestically light up ponds, lakes, pools of water, main driveways and walkways. Create a picturesque scene by placing in a garden near outdoor benches. Some cast interesting light patterns.\n- Diffusers and Spreads – Low voltage lighting fixtures that give off a softer light and are used to outline borders.\n- Cylinders, Square and Bullet Shaped Lights – These are designed to focus a beam of light.\n- Well Lights – Hidden from view, they flush with the ground. Mostly used for up lighting on plants, trees and walls. On highly textured surfaces they give interesting shadow effects.\n- Accent Lighting– Very versatile fixtures that are used for up lighting, moonlighting, accent lighting, grazing, and down lighting.\nTypes of Energy Efficient Landscape Lighting\nAlways choose quality outdoor lighting fixtures and you will never be disappointed. Quality lighting fixtures are time-tested for durability and reliability. Their timeless designs and illumination will create a luxurious landscape lighting design that you can be proud of.\n- Outdoor Lanterns and Wall Lights and Sconces - These exterior light fixtures are an excellent choice for doorways, garages, and windows. Used to enhance walled areas or square pillars.\n- Outdoor Ceiling Fixtures - Perfect for porches, patios, breezeways, and covered areas or walkways.\n- Post Lights - Majestically light up ponds, lakes, pools of water, main driveways and walkways. Create a picturesque scene by placing in a garden near outdoor benches. Some cast interesting light patterns.\n- Diffusers and Spreads - Low voltage lighting fixtures that give off a softer light and are used to outline borders.\n- Cylinders, Square and Bullet Shaped Lights - These are designed to focus a beam of light.\n- Well Lights - Hidden from view, they are flush with the ground. Mostly used for up lighting on plants, trees and walls. On highly textured surfaces they give interesting shadow effects.\n- Accent Lighting- Very versatile fixtures that are used for up lighting, moonlighting, accent lighting, grazing, and down lighting.\nLandscape Lighting Easy Installation\nLandscape lighting is easy to install for the do it yourselfers. There are two types of voltage for landscape lighting: 12 volt and 120 volt. Landscape lighting fixtures that are 120v can be wired or plugged into your home’s existing electrical supply. Outdoor fluorescent lighting fixtures come equipped with a ballast which limits the current to its proper value and thus can be wired directly to your home wiring. Twelve volt (12-volt), low voltage landscape lighting requires an outdoor lighting transformer to step down the volts. Low voltage lighting is easy and safe to install and you do not need to be an electrician. Most landscape lighting designs include both line and low voltage landscape lighting.\nOutdoor Lighting Installation\nOutdoor lights that are 120 volts do not require a landscape lighting transformer and can be directly plugged into an outdoor electrical outlet. Low voltage landscape lighting and LED requires the use of an outdoor lighting transformer to step down the current from a house of 120 volts to a safe 12 volts. Do not hook up a 12 volt lighting fixture directly into an outside electrical unit, as homes are typically equipped with 120 volts.\n- If you require a lighting transformer, calculate the total amount of wattage by summing up the watts found on the bulbs that will be used for each light fixture. Purchase an outdoor lighting transformer that supports the summed wattage of the landscape lighting plus add an additional watt for every 10 feet of power cord. We recommend you buy a lighting transformer that supports more wattage to anticipate future changes and additions. However, for optimal performance use at least half of the transformer’s wattage rating.\n- Plug the transformer into a GFCI-protected outdoor electrical outlet that has a protective plastic box covering the power cord. For safe and convenient operation, the transformer should be mounted at least 1.5’ above the ground.\n- Lay out where the cord will run and allow extra cord to give you flexibility in moving the wires around. A #12-2 cable is recommended for low voltage landscape lights. It is recommended that the cable runs do not exceed 100 feet. If you have a very large area you may install more than one transformer and run cable between them or separate from each other.\n- It is not recommended that you put more than 100 watts on one line. If the wattage exceeds 100 watts make a t-connection. You may mix wattages as long as they don’t exceed the wattage of the light transformer. Read about the types of low voltage cable layouts below.\n- Connect the light fixtures to the cable. Be sure not to place light fixtures where they may be easily damaged. Use a Direct Burial (DBr) splice connector to connect the light fixtures to the cable. They are the highest quality. Direct Burial Connections are tightly sealed and prevent moisture invasion, minimizing future repairs and corrosion. All low voltage connections must be waterproof and tightly sealed.\n- Test your voltage and spacing and direction of lights. Stand at different angles and distances to be sure that you have properly spaced and placed your lights.\n- Between the light fixtures, where the cord will run dig a trench three to six inches deep and bury the cord. You may encase the cables in PVC pipe to minimize accidental damage.\n- Seal any loose ends with electrical tape.\nLow Voltage Cable Layouts\nLow Voltage lighting cable is available in #12-2, #10-2, and #8-2, the lower the number the thicker the cable. A thicker cable will reduce the amount of voltage drop.\n- Straight Installation – The lighting fixtures are sequentially run in one line from the transformer with only one end connected to the transformer. This is the easiest to install and requires the least amount of effort.\n- Star or Split Load Installation – More than one cord is run directly from the transformer, and run in different directions, hence a \"star\" formation which lends to the name.\n- Loop Installation – Minimizes the drop of voltage and outputs more uniform light among the light fixtures. Connect both wire ends to the transformer. Low voltage polarity is maintained by connecting the same wire leads to the proper transformer terminals. Mark on one side of the cable to note the ridge and help you make the proper connections.\n- T Installation – Two cords are run from a heavier gauge cord, (use either #8 or #10 gauge), that is directly run from the transformer and forms a “T”."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:3d2067a8-fd2b-4323-8f97-1e437d5009b0>","<urn:uuid:7fc4907d-f5c0-4c26-a43c-a28a0ba9c0c2>"],"error":null}
{"question":"What's so special about Verdi's I Due Foscari's high notes and its dramatic storyline? 🎭","answer":"I Due Foscari features exceptional high notes in a replacement cabaletta 'Sì lo sento, Iddio mi chiama', which was discovered in the Bibliothèque nationale de France. Verdi wrote this specifically to showcase the extremely high range of tenor Mario, Count of Candia, including two top E flats. As for the dramatic storyline, it centers on Jacopo Foscari, who is unjustly condemned for murder by the Council of Ten due to a plot by Jacopo Loredano. Despite his father Francesco Foscari being the Doge of Venice and believing in his innocence, he must sign his son's exile decree. The story ends tragically with Jacopo dying of despair and his father being forced to step down before collapsing lifeless.","context":["Giuseppe VERDI (1813-1901)\nSimon Boccanegra - Preludio [2:26]\nErnani - Recitativo ed Aria: ‘Odi il voto’, atto\nAttila - Oh dolore! Atto III [3:37]\nScena lirica per due tenori ed orchestra: ‘Io la vidi’,\nI Due Foscari - Scene ed cavatina: ‘Dal più remoto\nesilio’, atto I [5:07]\nCabaletta di Jacopo: ‘Sì lo sento, Iddio mi chiama’,\natto I [4:14]\nLes vêpres siciliennes - Nouvelle romance pour M. Villaret:\n‘Ô toi que j'ai chérie’, atto IV [3:54]\nAida - Sinfonia [11:02]\nLuciano Pavarotti (tenor)\nAntonio Savastano (tenor: Scena, Foscari scene),\nGiuseppe Morresi (baritone: Ernani), Alfredo Giacometti\nOrchestra del Teatro alla Scala/Claudio Abbado\nrec. January 1978 and April 1980, CTC Studios, Milan, Italy\nWARNER CLASSICS 2564 64653-8 [42:47]\nI had this all-Verdi recording when it first came\nout on vinyl in 1981 on CBS Masterworks 74037. At that stage it was\nentitled Pavarotti Premieres. Now it has been reissued on Warner\nClassics and renamed Giuseppe Verdi Rarities. At the time it\nwas marketed as the first recording of rare Verdi arias. This is a reissue\nfor which I have been waiting anxiously mainly owing to the amazing\nhigh notes Pavarotti achieves in a rarely heard cabaletta from\nI Due Foscari.\nVerdi was very conscious of the demands of great tenors of his day who\nwith their popular following could make or break an opera première.\nIn view of this Verdi wrote a number of additional or alternative arias\nespecially for the star tenors. Some of these were being recorded here\nfor the first time after being rediscovered in various archives.\nThe recitative and aria ‘Odi il voto’ from act 2\nof Ernani,part of the aria con cori, was commissioned\nby Rossini for Russian tenor Nikolai Ivanov. Here Pavarotti as the bandit\nErnani is joined by baritone Giuseppe Morresi as Iago and bass Alfredo\nGiacometti as Silva. Displaying impeccable control Pavarotti’s\nsweet, fluid tone is a treat to hear. For my money he was peerless in\nNext is the aria ‘Oh dolore!’from act 3 of\nAttila, an Adagio that Verdi composed for the tenor Napoleone\nMaoriani. As the knight Foresto, Pavarotti has much work in his rich\nlower register; this he displays to splendid advantage.\nA very early work from 1833, the scena lirica ‘Io la\nvidi’ for two tenors and orchestra was written by Verdi to\na text by Calisto Bassi. It seems that ‘Io la vidi’\nis a fragment thought to be from an opera that Verdi never completed.\nUnless I’m mistaken the notes to this reissue have incorrectly\nput the work under the heading of the opera Attila. For ‘Io\nla vidi’ Pavarotti is joined by tenor Antonio Savastano.\nIn the scene and cavatina ‘Dal più remoto esilio’\nfrom act I of I Due Foscari Pavarotti’s voice, accompanied\nby tenor Antonio Savastano, is clearly in exceptionally fine condition.\nFollowing straight on is Jacopo’s cabaletta ‘Sì\nlo sento, Iddio mi chiama’, a replacement for the normal aria\nwhich was discovered in the Bibliothèque nationale de France\nin Paris. Verdi had written the cabaletta especially to demonstrate\nthe extremely high range of the high tenor Mario, Count of Candia. In\nthis curiously attractive work Pavarotti is twice called to soar rapidly\ninto falsetto. There are two top E flats before we plummet into more\nnatural terrain. Full of dark mystery Jacopo’s cavatina\nand cabaletta impressively display the qualities of Pavarotti’s\nFrom act 4 of the grand opera Les vêpres siciliennes the\nnouvelle romance ‘Ô toi que j'ai chérie’\nis an alternative aria to ‘O jour de peine’.\nOne of the highlights of this release, the Largo was tailor-made\nfor the voice of French tenor François-Pierre Villaret.\nCommencing and ending this reissue are a pair of overtures that were\nnot included in the final edition of each opera. Verdi consigned them\nto a drawer. The Preludio is from the first version of Simon\nBoccanegra. The Sinfonia was intended for the first performance\nof Aida. To set the scenes for the action to follow each overture\nquickly establishes and maintains that special contrast of drama and\nSet down some 35 years ago the sound engineers have provided a satisfyingly\nclear and well balanced recording. I notice that it has been re-astered\nbefore release. As I loved every minute of this reissue I will make\nan exception for its short playing time. It is good to hear Pavarotti\nsinging rare Verdi repertoire to which he seems so well suited. As one\nmight expect under maestro Abbado the Orchestra del Teatro alla Scala\ndi Milano is totally at home in this repertoire.","- Composer:Giuseppe Verdi\n- Librettist:Francesco Maria Piave\n- Creation date:1844\n- Creation place:Italy\n- Acts number:3\n- Original language:Italian\n- Opera House of original production:Teatro Argentina\nComposed during the summer of 1844, I Due Foscari belongs to that famous period of intense work that Verdi called his “difficult years”, ten years that saw the creation of sixteen operas. After the dazzling success of Nabucco in 1842, every opera director was clamouring for a work from the Maestro, who had finally won over the public. For his debut in Rome, Verdi returned to a project he had first envisioned for Venice but then abandoned in favour of Ernani. Lord Byron’s The Two Foscari, in which Verdi saw a “lovely subject, sensitive and moving”, offered up such a cruel portrait of the famous Venetian doges that it was better to save it for the Romans! Turning again to Piave, the librettist of Ernani, the composer, as was his wont, took an active part in adapting this political and family drama blending vengeance and great patriotic fervour, spirit of sacrifice and loves thwarted by the State. The work met with success, then was gradually eclipsed by the popularity of other great works by Verdi until it was revived in the 1960s, associated mainly with the magnificent role of Francesco Foscari, doge of Venice, that attracted the greatest baritones, starting with the famous Piero Cappucilli, and more recently Leo Nucci. And yet the charm of I Due Foscari, which Verdi himself deemed rather uniform in its sadness, is not limited to the astonishing beauty of the baritone and tenor roles. The orchestral richness and the dramatic intensity of the choirs are immediately seductive. The use of instrumental themes to characterise the characters is used by Verdi for the first time, creating an atmosphere of intimate melancholy that contributes to tightening the boundaries of this poignant struggle between State interests and feelings that presage the heartbreak of Simon Boccanegra.\nJacopo Foscari, son of the doge of Venice Francesco Foscari, is to be judged by the Council of Ten for a crime of which he claims to be innocent. A sworn enemy of the Foscari family, the vindictive Jacopo Loredano, traitorously manages to get him sentenced to exile. Despite the pleading of Lucrezia, Jacopo’s wife, the unfortunate father is forced to sign the decree banishing his son, even though convinced of his innocence. The young man dies of despair just before the real murderer is revealed. Loredano ensures Francesco Foscari’s removal from office; Foscari collapses, lifeless.\nIn 1457, in Venice, Jacopo, son of Doge Francesco Foscari, is sentenced by the Council of Ten for a murder he did not commit. Condemned to exile, he knows he is the victim of a plot carried out by Jacopo Loredano, a wretched pretender to the throne currently occupied by his father, Francesco Foscari. But his father is pondering this power, the reality of which is illusory. Quite rightly, Lucrezia Contarini, Jacopo Foscari’s wife, is revolted by the obvious injustice of his sentence. She cannot understand why his father, although convinced of his innocence, does not intercede in his son’s behalf.\nAlone in prison, Jacopo laments and raves. Lucrezia encourages him to keep hope. His father comes to say goodbye. Loredano, who considers both Foscaris responsible for the death of his father and uncle, joins them to savour his vengeance. Before the Council, he states his desire to see the sentence carried out as quickly as possible and objects firmly to Lucrezia and his children accompanying Jacopo into exile.\nAs a regatta is celebrated by the delighted people of Venice in St Mark’s Square, Jacopo must say goodbye to Lucrezia. The Doge learns too late that the real murderer has confessed on his deathbed. The unjustly sentenced Jacopo has already died from grief as he was boarding the boat that was to take him far from Venice. The Council of Ten now demands that the father step down; he rebels, resists and finally gives in. The bells of St Mark’s ring out to celebrate his successor’s election. Francesco Foscari collapses and dies. The unyielding Loredano notes in his diary: “I have been paid.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:f5b367c5-c922-4fb5-85cc-c3621e802624>","<urn:uuid:23bc75e8-3b50-45f2-8c05-246c44736223>"],"error":null}
{"question":"How do warrior burials in Russia's Caucasus mountains compare to the Griffin Warrior tomb in Greece in terms of valuable grave goods?","answer":"Both tombs contained extremely valuable grave goods indicating high-status individuals. The Russian warrior's tomb contained numerous golden artifacts, iron chain mail, weaponry including a 36-inch iron sword, bronze helmets, and remains of animals important to his culture. The Griffin Warrior's tomb was even richer, containing gold cups, a gold chain necklace, bronze mirror with ivory handle, about 50 sealstones, over 1,000 beads of various precious materials, weapons including a sword with gold pommel and hilt, and four rare gold signet rings. Both tombs were approximately undisturbed, though the Russian site showed signs of looting outside the grave while the Griffin Warrior's tomb was completely untouched.","context":["Interpreting burial status is a difficult thing, however some burials are clearly different from their peers. Often the warrior designation is given to adult males burials found with large amounts of weaponry and exotic goods. This doesn’t necessarily indicate a warrior status or that they themselves fought in battle. In some cultures there are obvious examples of males who were too young to be actually warriors found with ‘warrior’ level artifacts. The status may be something inherited from their parents or conferred upon adulthood. It may be related to one’s status, where all individuals at a certain social level are given warrior like burials whether or not they actually were in battle. However, in many societies it must be earned through hard work.\nArchaeological excavations in Russia have revealed a necropolis hidden in the Caucasus mountains. Within it were the remains of an adult male. He was found with numerous golden artifacts, iron chain mail, and a large amount of weaponry. Most impressive was a 36 inch iron sword found between his legs. The whole site is approximately 2,000 years old. Outside of the necropolis there were two bronze helmets, one with relief carvings of curled sheep horns and one with geometric shapes. Remains of three horses, a cow and wild boar were also found at the site, and have been interpreted as signs of his status as they were important to his culture. They argue that based on the artifacts, necropolis and signs of a funerary feast it is likely that this individual is a chieftain. Oddly enough, the site appears to have been looted even though the grave itself was untouched. (For a full list of artifacts see this post by the History Blog)\nAn archaeological investigation in Japan revealed a 1,400 year old Kofun-period warrior. His status as a warrior was determined by the fact that he was still dressed in his lamellar suit of armor. Based on his size and armor design, he would have belonged to an elite warrior class or was a local ruler. It is the first time that a warrior has been found wearing one of these suits of armor. Traditionally the armor is buried next to the individual. However, it is thought that the warrior died during a volcanic eruption that has been referred to as the ‘Pompeii of Japan’. The fact that he was found face down means he likely fell while running from the eruption. The presence of an infant means he may have been trying to escape with his child.\nSometimes though we get lucky and already know the identity of the warrior. Recently the body of the Renaissance warrior Giovanni de’ Medici was exhumed. It was assumed that he had died from an improper amputation, but bioarchaeologists argue instead he died from infection. Giovanni of the Black Bands was a known warrior, and had a reputation of being invincible. However, he died at only 28 after being hit by a cannon ball, in a battle in Lombardy on Nov. 25, 1526.Vertebral hernias were found on the skeleton, which they argue to be evidence of wearing heavy armor in battle. He was buried in a zinc coffin in a Medici tomb in Florence. A statue picturing him in armor with a sword stands in the Uffizi Gallery in Florence.\nOwen 2013. Treasure-Filled Warrior’s Grave Found in Russia. LiveScience. http://www.livescience.com/27275-ancient-treasure-warrior-grave.html\nLorenzi 2013. Famed Warrior Medici Died From Gangrene. Discovery News. http://news.discovery.com/history/archaeology/mystery-over-renaissance-warriors-amputation-solved-130116.htm\nTorres 2012. Japanese archaeologists find 1,400 year old Kofun-period warrior still in armor.","The tomb of the Griffin Warrior is one of the richest found on mainland Greece in recent years. This Bronze Age burial belongs to the transitional period in European prehistory when the Minoan culture of island Crete gave way to that of the Mycenaeans on the mainland, and its lavish grave goods are not only some of the most spectacular to have been recovered in the last few years, but are also providing important new information about the emergence of mainland Europe’s earliest civilisation.\nThe grave sits on a hilltop in Messenia, near the village of Chora, overlooking the south-west coast of the Peloponnese. It was here, in 1939, that Carl Blegen of the University of Cincinnati and Konstantinos Kourouniotis, director of the National Archaeological Museum of Athens, discovered a Bronze Age palace – and though they were not to know it at the time, the palace turned out to be one of the finest and best-preserved examples of such a site in the whole of Greece.\nThey were searching for the palace of the legendary king Nestor, a wise old counsellor mentioned in both Homer’s Odyssey and his Iliad. However, the eve of the Second World War was not a good time to start an archaeological project, and as Europe erupted into conflict, investigations at the Palace of Nestor were suspended. Finally, in 1952, Blegen returned, and over the following 15 years, he and his team uncovered the fabulous remains of one of the most magnificent Mycenaean palaces on the Greek mainland. Destroyed by fire and abandoned in about 1200 BC, it had lain undisturbed for three millennia beneath an olive grove.\nBlegen knew he had found the palace he was looking for on the first day of excavation, when he uncovered a collection of clay tablets baked – and thus preserved – in the final conflagration. The tablets were inscribed with Linear B script, the earliest form of written Greek, which descends from the as-yet undeciphered Linear A script famously found by Arthur Evans at the Minoan site of Knossos on Crete. Some of these tablets refer to the palace as belonging to the wanax (king) of Pylos, who controlled the surrounding region.\nThough what we see at Pylos today reflects only the final phase of the palace’s existence, subsequent study of the stratigraphy uncovered by Blegen and his team revealed an unbroken sequence of deposits dating back to about 1900 BC. But, significantly, the results also provided evidence of strong influences from the more advanced Minoan civilisation that flourished on Crete: not only in the type of artefacts, but also in the construction techniques that employed cut-stone limestone blocks, and the use of Cretan-style masons’ marks.\nDuring those early excavations, the team uncovered several beehive-shaped tombs, the most impressive of which is a large round monument called Tholos IV. Situated about 100m north-east of the palace, this tomb was built about 1650 BC, making it one of the earliest of its kind yet found in Greece. Though it had been robbed in antiquity, Blegen’s team recovered high-status grave goods missed by the thieves, including a gold signet ring, a gold seal, several gold cut-outs in the form of an owl, and beads made of imported semi-precious stones.\nSuch grave goods suggest this distinctive beehive-shaped monument was a royal tomb, the designated burial place of the high-ranking members of the palatial community. They also found evidence to suggest it accommodated multiple burials over a period of about 250 years. So it was with some surprise that, investigating the area in the adjacent field in 2015, we and our team from the University of Cincinnati made one of the most significant prehistoric discoveries on mainland Greece in more than half a century.\n‘We’ve found bronze’\nAs we surveyed the area, we noticed several stones visible on the ground surface in a section of a field between the North-east Gateway of the palace and the dromos of Tholos IV. Our team opened up a test trench, and within a few days had traced the entire outline of a small rectangular structure. Could this be a tomb? If so, it was very different from Tholos IV and the other beehive-shaped tombs associated with the Palace of Nestor.\nExcitement grew as the dig continued, for it swiftly became apparent that not only was this indeed a grave, it was one that had lain undisturbed by would-be tomb robbers since the deceased was interred. The subterranean stone-built chamber, which lay on a north-west/south-east axis, was constructed using well-dressed limestone slabs, some as much as 60cm high, with eight courses of dry-stone rubble masonry above. A few fragments of pottery and tiny pieces of bronze were recovered from the upper levels, but nothing to suggest that this was a burial of any significance. Until, that is, the tenth morning of excavation.\nWe were alerted by an urgent call from trench supervisor Alison Fields: ‘You’d better come quick,’ she called, ‘we’ve found bronze.’ This was the moment we knew we had discovered that rare phenomenon: an unplundered Mycenaean tomb.\nAs the day progressed, the team exposed several bronze artefacts, including a large basin and a spouted bowl, along with what appeared to be the remains of wooden planks that ran the length of the grave.\nExcavation was impeded by two large chunks of rock. One of the grave’s cover stones that had lain across the top of the tomb had broken in two. Unsupported by the walls of the chamber and held in place only by the surrounding earth, the pieces had fallen into the grave at some point. It was too risky to move the larger of the two slabs, for fear of destroying whatever lay around it, so for the time being it was secured in place and excavation concentrated on the less-obstructed parts of the tomb.\nWe could see that grave goods had once been placed on top of a wooden coffin. However, as the wood decayed, the weight of the soil that had accumulated in the grave after the slab fell had caused the top of the coffin to collapse and the grave goods to fall inside, onto the human remains, damaging the skull and upper spinal column.\nDigging in the tight confines of the grave was also hampered by the sheer number of grave goods that constituted the 60cm-deep deposit. Not only was there an impressive number of artefacts, but the wealth of the collection signalled to the team that this burial must belong to a person of high status. The grave goods include a bronze mirror with an ivory handle, two gold cups, a large granulated gold bead, and a stunning 80cm-long gold chain necklace. Our team also painstakingly recovered bronze fragments that probably belonged to a suit of armour, along with pieces of a helmet made of boar’s tusks – the first clues that this might be the burial of a warrior.\nMany of the smaller items were found in a bronze basin that had rested on the top of the coffin before it collapsed onto the deceased’s chest. Beneath the wood of the coffin lid, we recovered large quantities of precious grave goods: gold, silver, and bronze vessels; about 50 sealstones; more than 1,000 beads of amber, amethyst, carnelian, glass, and gold; weapons; and four intricately decorated gold signet rings.\nThe depiction of a griffin on one of the sealstones and another carved on an ivory plaque gave the individual his nickname ‘Griffin Warrior’.\nIt is rare to find so many gold rings in a single burial, and, interestingly, all four were found on the warrior’s right side, in close proximity to the beads and seals. On his left side were his weapons, including a bronze spear, a bronze battle-knife with a terminal ring, and a sword with a gold pommel and hilt. This sword was another surprise: the gold of the pommel and hilt was worked using a rare technique known as gold embroidery, a method that so far has been found at only two other sites in Greece, Dendra and Mycenae. Interestingly, a gold and silver vessel recovered from the grave also has parallels at Dendra.\nThe Griffin Warrior had been placed on his back, with his legs extended and his arms by his side. He lay in a wooden coffin that rested on a prepared earthen floor on top of bedrock within a stone-lined shaft just over 1.5m deep. He was about 30-35 years old when he died, a robust individual who would have stood about 1.7m tall – though post-burial damage to his lower limbs make it difficult to make an exact measurement.\nThe poor condition of the skeletal remains also make it difficult to assess how he died, so investigations are ongoing. However, do we have some idea of what he looked like: though his skull was crushed beneath the deposition of heavy metal vessels, Tobias Houlton and Lynne Schepartz from the University of the Witwatersrand were able to make a facial reconstruction, while examination of contemporary Minoan and Mycenaean iconography gives us a pretty clear idea of his style of hair.\nThe damage caused by the collapsed cover stone and the subsequent displacement of artefacts also complicates our picture of precisely how the grave goods were arranged at the time of burial. However, it appears that there was a deliberate zoning of types of offerings. Bronze vessels and body armour were placed on banks of earth around the coffin, while all the weapons and artefacts associated with combat were arranged on his left-hand side, with the most valuable having been put in the grave first.\nRings, the necklace, and sealstones were placed on the warrior’s right-hand side. Again, it is interesting to note that neither signet rings nor sealstones were used as seals during this period, yet they had been placed in close proximity to each other, suggesting their purpose and function were understood to be similar and their grouping together a deliberate act.\nDates obtained from pottery fragments found in the building trenches and fill around and beneath the coffin show that the burial took place in the first part of the 15th century BC, probably about 1450 BC. It is interesting to note that no complete ceramic vessels of any sort were found in the grave, only bronze, silver, and gold. Such a conspicuous display of riches is a typical feature only of the wealthiest graves during the Early Mycenaean period, suggesting the warrior enjoyed high social status during his life. But this leads to another intriguing mystery: single burials are unusual during this Late Helladic era, and it is probable that Tholos IV was still being reopened and used for burials during this period, so why was the Griffin Warrior not buried in the royal tomb nearby?\nThe answer may lie in the nature of the grave goods. The rings, in particular, are interesting and might offer the strongest clues to the identity of the Griffin Warrior.\nGold signet rings are scarce in the Aegean world, and it is exceedingly rare to find more than one or two rings of such quality in a single burial, but here we have four. During his entire excavation in the 1950s and 1960s, Blegen’s team recovered a single gold signet ring (from Tholos IV); the only other from this area was the famous Ring of Nestor – purchased by Arthur Evans, famous for his excavations at Knossos on Crete – which was supposedly found to the north of Pylos, on the western coast of the Peloponnese.\nAll four of the warrior’s rings are made of several sheets of gold welded together over a central core, and three have identical trapezoidal sections. This method of metalwork is typical of rings made on Crete during the Minoan period. Significantly, too, the iconography of all four reflect Minoan stylistic forms.\nThe biggest, and perhaps the most impressive, of the four rings depicts five elaborately dressed female figures: they stand, two on one side and three on the other, either side of a seaside shrine flanked by date palms. Their distinctive costumes have parallels in Minoan art, and possibly represent a Minoan cultic scene of a goddess and two singers accompanied by two acolytes.\nAnother ring, the first to be found, depicts a bull-leaping scene, reminiscent of the famous wall painting discovered by Arthur Evans at the Minoan palace at Knossos. The third ring shows a goddess, accompanied by two long-tailed birds, holding a long staff topped by ornamental bull’s horns. This clearly defined staff-head resembles a similarly styled bronze bull’s head, also with prominent horns, that was found in the warrior grave and which also would have capped a wooden staff – a recognised symbol of authority.\nThe fourth ring depicts a seated goddess holding a long-handled mirror that bears an uncanny resemblance to the mirror found with the warrior’s remains. Mirrors are more common in female burials than male, yet when associated with a male, it is almost exclusively a warrior burial. It, surely, is no coincidence that a ring with such an image should be placed within a burial with an example of the luxury item itself, and therefore whoever placed these grave goods in the Griffin Warrior’s tomb was making a conscious connection between them, and recognised their symbolic significance.\nSo, who was the Griffin Warrior? We can only speculate. Perhaps he was an outsider, someone who excelled in combat, and who married into the royal family, taking up his position in the community as a prince of Pylos. When he died, perhaps in battle, he was buried not in the royal tholos – designated for the wanax and his heirs – but in a single grave close by, with a funeral ceremony that recognised his honoured status, and accompanied by funerary gifts that reflected his origins.\nThis rich cache of artefacts gives us a unique insight into the mindset of the people of Pylos at a critical moment in the development of their society. The parallels between the grave goods and the representational elements on the rings that illustrate aspects of Minoan cult-practice and belief, show that the mainlanders at Pylos at the start of the Late Bronze Age attached symbolic meaning to the rings. Yet it does not necessarily follow that they interpreted the iconography in the same way as did the people on Crete. What we can say is that Minoan works of art were being imported into mainland Greece during this period, but once here, they were recontextualised – as in the grave of the Griffin Warrior – as foundations for the emergent Mycenaean civilisation that was destined to take over.\nJack L Davis and Sharon R Stocker, University of Cincinnati, and co-directors of the University of Cincinnati Pylos Excavations.\nALL images: Department of Classics, University of Cincinnati, unless otherwise stated."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:41f1a915-3d28-43cb-8891-39c544ff678d>","<urn:uuid:5909fc13-8239-4ea9-9707-1d6308c69121>"],"error":null}
{"question":"What are /ubu Editions' main publication types, and what key preservation concerns affect digital archives?","answer":"The /ubu Editions series includes diverse publication types such as poetry, prose, opera librettos, critical theory, and manifestos, with works both in English and in translation. Regarding digital preservation concerns, key issues include the short lifespan of digital storage media compared to traditional formats, rapid obsolescence of retrieval and playback technologies, absence of established preservation standards and protocols, and challenges in maintaining authenticity and reliability of electronic records. Additionally, digital preservation requires continuous financial commitment for maintaining access, as well as technical expertise to handle various document formats and their associated hardware/software requirements.","context":["Follow Harriet on Twitter\n/ubu Editions, Third Series: 12 New Titles\nUbuWeb is pleased to present our occasional but substantial ongoing series of full-length e-books, called /ubu Editions. Titles for this series include works by Steve Benson, Maurice Blanchot, Mairéad Byrne, Terence Gower & Mónica de la Torre, Dick Higgins, Bernard Nöel, Severo Sarduy, Claude Simon, Rosemarie Waldrop, Robert Wilson, and Monique Wittig. This new series of /ubu editions presents eleven out-of-print works from 1957 to 1994 – and also includes three newer titles (1999-2007). Of the historical republications, there are three works of poetry, three works of prose, one opera libretto, one work of critical theory, and one manifesto – though each piece blurs these genres. Seven were written in English, four appear in translation, and one is bilingual. Two authors could be considered language poets, two are associated with Tel Quel, one arguably initiated Fluxus, another arguably initiated the new novel. Four are women, nine are men. One title was changed for its /ubu publication. Series editor: Danny Snelson. All e-books are entirely free.\nFull descriptions, links, and list of titles below the fold…\nBruce Andrews “Divestiture – A” (1994)\nThe choice: to be a catalog, or a cataloguer. Such examples can be multiplied. I only collect money, America is more astonishing. Husk. Cataloging phrasal fragments and reconfiguring verbal shells, Divestiture—A continues Andrews’ method of anasemantic editorial composition begun in the mid-eighties: a montage of heterogeneous constellations of words culled from vast collections of textual material jotted down over time. We see only the feet of the dancers, the de-socializing of language, never their whole bodies. As editing is the reading moment: the multimplication of material in Divestiture—A yields a thresholding surplus, a hyper-trophy of enjoyments: its post-personalizing thrill bursting from an energizing strangeness of interferences, interruptions, and diastrophic collisions. Now, even the lacunae are eloquent—plausible verbal models are quite easy to formulate. The unlikely pairing of radically disjunctive contexts and syntactically coherent prose (preminiscent of spambot computational processing) is formed precisely in the affirmation of rupture & divestiture. To understand too much is to destroy: the containers are distorters inevitably. The horizon-value of Divestiture—A emphasizes a political economy of full textual dissemination: Andrews cedes the original contexts of the collected material and relinquishes authorial control over illusory semantic value—in its place: the ecstatic pleasures of egalitarian exchange and productive reader-editor dialogue. The sounds are not enough—’no address,’ ‘in distress.’ Language speaks for itself. … I hate dealing with messages that may not have been intentionally transmitted delicacies of randomness.\nSteve Benson “The Ball // 30 Times in 2 Days” (2005)\nSaturday and Sunday, April 23 and 24, 2005, every hour on the hour, when my wristwatch alarm sounded, I wrote five minutes in a brown book Lyn gave me several years ago, as well as I could. This is the transcript, completed two weeks later.\nMaurice Blanchot “The Last Man” (1957)\nWe can dream about the last writer, with whom would disappear, without anyone noticing it, the little mystery of writing. A dense, dream-like exploration of the extreme limits of this mystery, written some ten years prior to the Death of the Author, (though unpublished in English until thirty years later) Maurice Blanchot’s The Last Man (Le Dernier Homme, 1957) could be considered a narrative follow-up to The Space of Literature (L’Espace littéraire, 1955) or a fictional companion to the critical essays composing The Book to Come (Le Livre à venir, 1959). One can imagine an infinite conversation between these works: drifting wearily across abyssal alterities—the echo, in advance, of what has not been said and will never be said. But this sumptuous récit alone demands the reader’s full attention—marvelously, Blanchot writes what cannot be written without losing it as un-writable by writing it (Hans-Yost Frey, YFS, 1998). Narrating at the threshold of this impossible writing, The Last Man weaves a blurring of several prosopopetic characters towards a radical revision of the subject and the text. The prose itself never crystallizes into an unambiguous statement—Blanchot’s trangressive philosophy peculiar in the tantalizingly pleasurable suspension of the never-fulfilled promise of understanding. Reading happens in this continual absence of comprehension: instead, dense knots of delightfully paradoxical propositions and stupefying catachreses drive the reader on in the unconditional acceptance of the text that pierces, like a look that is too direct, the indeterminate prose, and makes all relations, and especially our relationship to time, absolutely precarious\nMairéad Byrne “SOS Poetry” (2007)\nWithin hours of its release SOS POETRY was wreaking havoc with readers’ sleep. Cathy Wagner checked her email just before bed & though she was completely wiped, eyeballs like raisins, read SOS POETRY straight through & laughed a lot & nodded a lot & went to bed with her eyeballs like GRAPES. The author’s daughter said: “ok i need to go to sleep so im going to stop reading the book now. let me tell you though…it is great. im sitting here laughing and crying at the same time. i love you so much.” Joseph Massey was more restrained: “This is wonderful. I’m perusing it now, as I type, while drinking some sort of mint tea — pleasurable.” Evie Shockley said: “you are totally on crack. : ) i’m laughing and cheering through my sleepless haze… .” And – proving that the effect lasted well into next day – Dodo said: “I spent a good part of the morning reading the book (When I should have been doing other things, but I was entranced).”\nTerence Gower & Mónica de la Torre “Appendices, Illustrations & Notes” (1999)\nThis surreal and funny artist’s book is a collaboration between conceptual artist Terence Gower and writer Mónica de la Torre, who have created an anthology of meaningless book-marketing blurbs, reviews of dubious exhibitions, evil-spirited notes by editors, and obsessional letters addressed to a psychiatrist. Presented as an appendix of ancillary material to a fictitious book, the texts take referentiality to a level of Borgesian absurdity. The humor is dry and understated, and it is only upon rereading that the uncanny thread uniting the seemingly found and disjointed fragments becomes apparent. For anyone whose day-to-day encounters with discourse include texts riddled with jargon and psychoanalytical babble, Appendices, Illustrations & Notes offers the opportunity for sweet revenge.\nDick Higgins “Horizons” (1984)\nIn 1984, Southern Illinois University Press published two books as part of its “Poetics of the New” series: The L=A=N=G=U=A=G=E Book, ed. Charles Bernstein and Bruce Andrews and Dick Higgins’ Horizons: The Poetics and Theory of the Intermedia. It should be noted that this title has been charged with “false advertising”—the essays composing this collection better understood as aesthetic manifestoes or reports from the front rather than a cohesive poetics or theory of the intermedia (Poetics Today, 1984). This indispensable collection includes writing on a wide swath of innovative work: from free metaphorical application of Gadamer’s “fusion of horizons” to exacting taxonomic configurations of experimental art across media up to and including Higgins’ serious reconfiguration of his monumental essay “Intermedia” (1965) from the vantage of 1981. Of particular note are inspiring chapters on visual poetry, music without catharsis, postmodern performance, and a charming “Child’s History of Fluxus.” Interestingly, the unifying strain of argumentation among these fragments, letters, and essays culled from small magazine publication in the late 70s and early 80s is a polemic against an increasingly capitalized Theory; throughout the work this rhetoric testifies to the unique alienation of Higgins’ milieu to the dominant currents of academic criticism. The principle value of Horizons, however (perhaps in spite of this polemic), is Higgins’ characteristic candor, taxonomic rigor, and prescient perceptions of cutting-edge, genre-blurring work.\nBernard Nöel “The Outrage Against Words” (1978)\nBernard Noël’s pamphlet The Outrage Against Words (as it’s translated in 1978) has seen a multiplicity of afterlives. Originally written in 1975 following the infamous attempted censorship of his spectacular Le Château de Cène, the manifesto asks: How can one turn their language against them when one finds oneself censored by one’s own language? First appearing in Paul Buck’s remarkable Curtains magazine before being picked up by the parallel political effort in the L=A=N=G=U=A=G=E journal, the work was appended to the Atlas Press translation of The Castle of Communion in 1993, and most recently surfaced in Jed Rasula and Steve McCaffery’s UbuWeb-like tome Imagining Language (2001)—each reading changes it, according, of course, to the immediate state of the reader and his social context, but equally according to the relationship of these components with those which exist at the moment of the book’s composition. In every instance, the writing opens paradoxically: Screams. They begin again. I hear them. Yet I hear nothing. A meditation on the politics of erasure and potential of expression introduced through the impossible figure of the written cry. Perhaps one writes to erase? Noël struggles against bourgeois silencing—the encyclopedic ‘outrage against words’ that acts both through words and against them. The police are even in our mouths. A penetrating defense of polysemia, The Outrage Against Words is essential reading for the state of language and the politics of play.\nSevero Sarduy “Big Bang “(1973)\nCuban émigré Severo Sarduy (1937-1993) is one of the most daring and brilliant writers of the 20th century. By the publication of Big Bang, Sarduy had become director of the Latin American collection of Editions du Seuil, a regular contributor to the influential Tel Quel magazine, and an important theoretician of the neo-baroque. /ubu is excited to reintroduce this resplendent cosmological poetry cycle in the original bilingual version printed by Fata Morgana in 1973. Sarduy’s interest in cosmology stems from a Foucauldian attention to shifts in the cosmological episteme made explicit by formal aspects of literature and the arts. Just as the development of the baroque ellipse was born of the confrontation of Kepler’s elliptical orbit with Galileo’s circular order in the 17th century, the modern theory of the expanding universe (in 1973, rooted in the discovery of the cosmic microwave background) introduces the polymorphic and movable center essential to modern literature. The theory of the empty center, the topology of the empty center, is going to reverberate in literature exactly as the theory of the ellipse resounded at a certain moment in the structure of the Gorgorine metaphor. Hijacking astronomical argot from “white dwarves” to “red giants,” Big Bang explodes from this empty center with an elliptic circumscription of parodic pseudo-charts and de-functionalized cosmological notions. The unique arc of Sarduy’s radial phenotext does not lead us to a pure and simple meaning, but rather, through a series of ellipses, of zig-zags, of détours, carries with it only a floating signifier—empty and polyvalent.\nClaude Simon “Properties of Several Geometric or Non-Geometric Figures (1971)”\nOriginally published in 1971 as Les Corps Conducteurs, Claude has repeatedly noted that the real title (“abandoned for absurd commercial considerations”) of this work has always been Properties of Several Geometric or Non-Geometric Figures (see ‘interview’ in Diacritics, 1977). An unseemly title for Simon’s combine-novel, perhaps, but vastly more interesting considering its architectural arrangement: crisscrossing citations occurring and reoccurring, encoding and recoding each image in a Euclidean field of semantic reproduction. A sign for the particular sort of systematicity ruling the prose might be read from its partial publication in Tel Quel as The Properties of Rectangles. These changes in title mark the work more as a decentered network of passages inscribing a kaleidoscopic welter of images than as a polymorphic circumvolution of words as ‘conducting bodies’—the difference erected by the change in title is exactly that between Simon’s geometric composition and Silliman’s spiraling Tjanting. Instead, Simon weaves wandering sets of hesitations, fragmented documents, and unfinished conversations through rectilinear woofs. Here, the reader is obliged to consider (in a geometric sense) a grid of verbal events charted by a Lawrence Sterne-like constellation of ‘associations, contrasts, sideslips and oppositions.’\nRosemarie Waldrop “Shorter American Memory” (1988)\nAll Americans are also ambiguous. In 1937, Henry Beston assembled and edited an anthology of various historic sources titled American Memory: Being a Mirror of the Stirring and Picturesque Past of Americans and the American Nation. The gist: to weave historical documents together to ‘evoke the emotions and motives of those who made our memory.’ From this commonplace histrionic babble, Rosmarie Waldrop crafts her delicious comic critique, Shorter American Memory. Originally published in 1988 by paradigm press (a year after The Reproduction of Profiles, Waldrop’s stunning reworking of Wittgenstein’s Philosophical Investigations) Shorter American Memory applies a playful array of abbreviating manipulations to Beston’s collection. Unlike Waldrop’s more familiar signature of mixed original composition and embedded citation, Shorter American Memory is strict detournement‹the entire work consists of politically subverted, procedurally reprocessed fragments from the hegemonic narrative of American Memory. The twenty-two prose-poem revisions fall between disjunctive textual synthesis and nuanced hypotactic collage. Hear Waldrop read selections of Shorter American Memory at PENNsound here, or enjoy a small sample: We holler these trysts to be self exiled that all manatees are credited equi distant, that they are endured by their Creditor with cervical unanswerable rims, that among these are lightning, lice, and the pushcart of harakiri.\nRobert Wilson “A Letter For Queen Victoria: An Opera” (1974)\nThe staggering Schizo-Culture issue of semiotext(e) (no. 2, 1978)—punctuated by Christopher Knowles’ patterned typings and childlike scribblings—features a brief interview of Bob Wilson by Sylvère Lotringer. Lotringer: How did you arrive at a theatre which is not based upon language? Wilson: I never liked theatre… Later I added words, but words weren’t used to tell a story. They were used more architecturally: for the length of the word of the sentence, for the sound. They were constructed like music. Wilson wrote the opera libretto for A Letter to Queen Victoria in 1974, two years before Einstein on the Beach. Most of the text is derived from a mechanical rehearsal process of performance and improvisation in “supportive dialogue” with Knowles’ spontaneously organized pseudo-geometric speech patterns. L: It seems to be very logically, even mathematically ordered although it may be futile to try to understand what that order actually is. W: Then I became more fascinated with him and what he was doing with language. He would take ordinary, everyday words and destroy them. They became like molecules that were always changing, breaking apart all the time, many-faceted words, not just a dead language, a rock breaking apart… Originally performed with scream songs, contrapuntal shouts, and heteroglossic murmurs—far removed and formally inscribed, this outstanding libretto still reads with the distinct verbivocovisual pleasure of anarchic verbal destruction and architectonic musical reconstruction.\nMonique Wittig Les Guérillères (1969)\nThey say that in the first place the vocabulary of every language is to be examined, modified, turned upside down, that every word must be screened. /ubu is very pleased to present this sharp new edition of Monique Wittig’s ‘delectable epic of sex warfare.’ Originally published in 1969, Les Guérillères remains one of the most important experimental novels of the century. Concurrent with Wittig’s foundational role in the MLF and the birth of radical feminism, the significance of this work is momentous. A precursor of the Language maxim ‘to change ones language is to change one’s world,’ Les Guérillères functions doubly as politicized SF explosive and gender-neutering disarming device. One should remember that where David Le Vay writes “the women” (1971) Wittig wrote elles, not les femmes: significant in difference to the gendered pronoun, elles is without English equivalent. Here, every word is deployed in Wittig’s battle against the mark of gender. Linguistic shrapnel and fantastic invention, the delicious writing of Les Guérillères enacts a change to the language of the book, as they say, the world. Or, as Wittig has it: ALL ACTION IS OVERTHROW.\n__ /ubu Editions __\n*** UbuWeb is entirely free. ***\n__ U B U W E B __","Digital preservation can be defined as the process and activities which stabilize and protect digital records and publications in forms which are retrievable, readable and usable over time. Digital preservation could also be defined as a set of processes and activities that ensure continued access to information and all kinds of records, scientific and cultural heritage existing in digital formats. This includes the preservation of materials resulting from digital reformatting but particularly information that is born-digital and has no analog counterpart. Digital preservation is an ongoing process of managing data for continued access and use.\nThe adoption of Information Communication Technologies (ICTs) has revolutionized the conduct of business and has greatly enhanced information accessibility. In particular, organizations are not only able to store large amounts of information but can also have quick access to it. This has improved service delivery and has ensured that policy makers react rapidly to social and economic developments. Further, the general public can also access information in remote areas. ICT has enabled archivists, records managers and librarians to carry out their mandate: that of information capture, preservation and dissemination. While use of ICT has occasioned these many benefits it has also brought challenges that have to be addressed. Principally, this new development has led to the generation of information in digital form which has to be managed. In spite of the benefits accruable, the technology has presented tremendous challenges which information professionals should be concerned with.\nThe purpose of preservation is to ensure protection of information of enduring value for access by present and future generations (Conway, 1990: 206). Libraries and archives have served as the central institutional focus for preservation, and both types of institutions include preservation as one of their core functions. In recent decades, many major libraries and archives have established formal preservation programs for traditional materials which include regular allocation of resources for preservation, preventive measures to arrest deterioration of materials, remedial measures to restore the usability of selected materials, and the incorporation of preservation needs and requirements into overall program planning.\nCHALLENGES OF DIGITAL PRESERVATION\nAn African perspective on preservation ought not to be different from other perspectives. However, digital preservation is often discussed in terms of technology, infrastructure and practices. Africa is largely composed of developing nations and thus has peculiar problems.\nIn African institutions these factors are attributed to:\nMost African countries have no policies on handling information be they in print; let alone in electronic format. In some African countries, years after independence they are still struggling with enacting a libraries act and as a result most institutions operate within a no policy framework. An enabling policy framework would allow institutions to implement various preservation strategies that are in line with their own parent institutions but operate within the overall country policy framework. These policy frameworks are essential especially if they can feed into broader continental policies such as the NEPAD initiative (The New Partnership for Africa’s Development which is a VISION and STRATEGIC Framework for Africa’s renewal). The NEPAD initiative itself is very silent on the preservation of Africa’s knowledge resources although it places prominence on the improvement of information and communication infrastructure (ICT). The improvement of ICT infrastructure will do well if there are policy frameworks at the country level that support the preservation and permanent storage of African knowledge resources wherever they might be found and in whatever format they might in.\nAfrica’s infrastructure is still lacking in handling large preservation of knowledge resources, especially resources that are in electronic form. Access to ICT facilities is a daily struggle for most institutions that are just barely managing to maintain access to print resources to be able to meet the daily requirement for academic learning in higher educational institutions.\nPreservation of knowledge resources is a continuous process not just a one off issue. To implement an effective and efficient preservation policy, there is need for commitment at both the institutional and national levels that preservation of the knowledge resources will be an incremental process that will be carried on from one generation to another. This effort entails that financial resources be committed to such a venture over long periods of time. This trend in funding has affected all areas of library operations including money that could be allocated for preservation of scholarly information materials. Financial commitments would also be needed to purchase and preserve the digital knowledge resources to permanently make them accessible to users, now and in the future.\nFinancial resources available for libraries and archives continue to decrease and will likely do so for the near future. The argument for preserving digital information has not effectively made it into public policy. There is little enthusiasm for spending resources on preservation at the best of times and without a concerted effort to bring the issues into the public eye, the preservation of digital information will remain a cloistered issue. The importance of libraries has been diminished in the popular press as the pressures from industry encourage consumers to see libraries as anachronistic while the Internet and electronic products such as Microsoft Encarta are promoted as inevitable replacements. Until this situation changes, libraries and archives will continue to be asked to do more with less both in terms of providing traditional library services, as well as new digital library services: preservation will have to encompass both kinds of collections.\nTechnical knowledge on the digital elements of electronic documents is largely lacking among staff that are in preservation departments. The presence of preservation departments in most of the libraries and information centers is really in name only as most of them concentrate on book and journal binding. This is coupled with the lack of preservation training. This lack of knowledge extends to deficient know-how on the equipment and software that is required for the preservation of digital information resources.\nDigital Technology Challenges\nDigital technology poses several challenges in the preservation of digital information resources. These are among others; technology comes in different formats, the cost of maintaining international standards of digital formats is expensive as it is often based on paying for upgrades to match the technology both the hardware and software. These come with subscriptions costs; so in essence a library/information center/archival center would have to subscribe to hardware; software and then to the electronic journal. This is unlike the paper format which has relatively changed very little since it was discovered as papyrus in Egypt 3000 BC. The electronic document is fairly new and has changed forms since then. If it is not the document changing from MS Word, PDF, html XML etc; it is the software requirement to be able to open and read the document. For example, if the document is in PDF you will need a PDF reader; JPEG would require a JPEG; just as a TIFF formatted document would require a Tiff reader. This means that institutions are always forced to change the facilities so they can meet various requirements such as software and hardware. Digital preservation presumes that there should be constant and continuous learning on the part of preservation staff both in software knowledge as well as hardware. This is because digital preservation methods are always changing depending on the nature of the hardware and software applied.\nDigitization of information requires obtaining copyright permission from various publishers to be able to duplicate anything in large quantities. However, most licensing agreements for journals or books produced by major publishers prohibit duplication of electronic documents or local storage of the document. What is allowed when one has a subscription is usually the online access to the particular journal for instance, without the subscribing institution having permanent access to content of the journal. Once subscription ends, access to the electronic content of journal is not possible. It is unlike in the print subscription model where once one has subscribed to the journal, the institution will have permanent access to the journal because the journal will be physically present the libraries own space.\nRecording media for digital materials are vulnerable to deterioration and catastrophic loss, and even under ideal conditions they are short lived relative to traditional format materials. Although librarians/archivists have been battling acid-based papers, thermo-fax, nitrate film, and other fragile media for decades, the threat posed by magnetic and optical media is qualitatively different. They are the first reusable media and they can deteriorate rapidly, making the time frame for decisions and actions to prevent loss is a matter of years, not decades. While acid paper is prone to deterioration, becoming brittle and yellowing with age, the deterioration may not become apparent for some decades and progresses slowly. It remains possible to retrieve information without loss once deterioration is noticed. Digital data recording media may deteriorate more rapidly and once the deterioration starts, in most cases there may already be data loss. This characteristic of digital forms leaves a very short time frame for preservation decisions and actions.\nMore insidious and challenging than media deterioration is the problem of obsolescence in retrieval and playback technologies. Information technologies are essentially obsolete every 18 months. Innovation in the computer hardware, storage, and software industries continues at a rapid pace, usually yielding greater storage and processing capacities at lower cost. Devices, processes, and software for recording and storing information are being replaced with new products and methods on a regular three- to five-year cycle, driven primarily by market forces. This dynamic creates an unstable and unpredictable environment for the continuance of hardware and software over a long period of time and represents a greater challenge than the deterioration of the physical medium. Many technologies and devices disappear as the companies that provide them move on to new product lines, often without backwards compatibility and ability to handle older technologies, or the companies themselves disappear. Records created in digital form in the first instance and those converted retrospectively from paper or microfilm to digital form is equally vulnerable to technological obsolescence.\nAnother challenge is the absence of established standards, protocols, and proven methods for preserving digital information. With few exceptions, digital library research has focused on architectures and systems for information organization and retrieval, presentation and visualization, and administration of intellectual property rights (Levy and Marshall). The critical role of digital libraries and archives in ensuring the future accessibility of information with enduring value has taken a back seat to enhancing access to current and actively used materials. As a consequence, digital preservation remains largely experimental and replete with the risks associated with untested methods; and digital preservation requirements have not been factored into the architecture, resource allocation, or planning for digital libraries.\nProliferation of document and media formats\nThere is a proliferation of document and media formats, each one potentially carrying their own hardware and software dependencies. Copying these formats from one storage device to another is simple. However, merely copying bits is not sufficient for preservation purposes: if the software for making sense of the bits (that is for retrieving, displaying, or printing) is not available, then the information will be, for all practical purposes, lost. Libraries will have to contend with this wide variety of digital formats. Many digital library collections will not have originated in digital form but come from materials that were digitized for particular purposes. Those digital resources which come to libraries from creators or other content providers will be wildly heterogeneous in their storage media, retrieval technologies and data formats. Libraries which seek out materials on the Internet will quickly discover the complexity of maintaining the integrity of links and dealing with dynamic documents that have multimedia contents, back-end script support, and embedded objects and programming.\nConcerns of authenticity and reliability\nThe authenticity and reliability of electronic records are often questioned because of possible changes to content or structure. Authenticity can be defined as the ability of the records to be reliable over time and act as evidence of organizational transactions. Reliability on the other hand, refers to a record’s authority and trustworthiness, and this is tied to the ability of a record to stand for a fact it is about. A number of authors among them, Hoffman and MacNeil, have argued that there are no guarantees of authenticity and reliability in the electronic environment, as records can be deleted or changed at any time. It is, therefore, important that electronic records are managed to ensure that they remain authentic and reliable as evidence. Perhaps in the paper environment, one can say that this is more straightforward, as records are physical objects, and this makes identification of their characteristics easier than it is in the virtual world. The records provide evidence of actions, but the computer systems may fail to capture the necessary information about the context of the creation and the use of records.\nAccess to electronic records and concerns of privacy\nThe use of computers has enabled organizations to create databases that now handle huge amounts of data on-line, which is made accessible anywhere and anytime. This has raised concerns that if the information is not properly managed, it may be made available too easily, resulting in lack of protection for the citizen’s individual rights. Further, the vast amount of information maintained about individuals by both government and private organizations threatens their privacy. Ojedokum has highlighted some of the privacy infringement as unauthorized acquisition of data, unauthorized penetration into computer networks. Computers allow fast and inexpensive communication of information and the collection and storage of large amounts of data. At the same time, these capabilities allow individuals and organizations to access information.\nPower cuts and backup strategies\nPower cuts and irregular electricity supplies are a major barrier. In most African countries there are limited power distribution networks which do not even reach rural areas where the majority of the population lives. African cities with higher population that have been experiencing power cuts include but are not limited to Accra, Dares Salaam, Lagos, Gaborone, Nairobi, Harare etc. These power cuts have disrupted business operations. Increased dependence on computers and their services for data processing also means increased reliance on the power supplies that keep the systems operating. Power failure means that organizations may lose valuable information and time. It is estimated that 50-70% of businesses that lose their data due to power cuts never recover it, and some go out of business. There is a need, therefore, for systems that will maintain quality power supply and protect electronic systems.\nInternet Bandwidth (Digital Divide)\nThe digital divide is still a major hindrance. In many parts of Africa there is little access to computers and the Internet. In those parts where there is Internet access, the resources, such as bandwidth, are severely limited or extremely expensive. Some digital preservation systems, such as LOCKSS, have questionable applicability. In the case of LOCKSS, a group of sites collaboratively maintain the integrity of collections. LOCKSS, however, does not cater for unstable and irregular bandwidth availability – its algorithms will not make the most efficient use of bandwidth and may exacerbate problems at sites with poor bandwidth. All online archives need to make use of bandwidth in a way that is both minimal and cognizant of the differences among sites.\nSkills and Education\nLibrarians, archivists and information professionals in African institutions are arguably not as technically skilled as their counterparts in other parts of the world. The availability of computer systems in some parts of the continent has the effect that curators of information do not receive sufficient training in electronic systems. Digital media is not the norm for many forms of communication and information storage. The level of education of the general population in many African countries also is a problem. The number of literate individuals, as well as the number of individuals with access to a computer and the Internet is lower than elsewhere in the world. This creates a challenge for digital preservation both in terms of collection building, especially for end-user submissions, and dissemination. Novel solutions are needed for both these problems to make digital archives effective.\nDigital collections facilitate access, but do not facilitate preservation. Being digital means being ephemeral. Digital places greater emphasis on the here-and-now rather than the long-term, just-in-time information rather than just-in-case. The research program for digital preservation has only recently been initiated to develop strategies, guidelines, and standards. The challenges to digital preservation are considerable and will require a concerted effort on the part of librarians and archivists to rise up to these challenges and assert in public forums the importance of protecting a fragile digital heritage.\n1. Douwe Drijfhout. 2006. Challenges in terms of Digital Preservation. LIASA Conference 2006.\nwww.nlsa.ac.za/...preservation.../Drijfhout.Challenges%20in%20terms %20of%20Digital%20P reservation.pdf\n2. Christine W. Kanyengo. 2006. Managing Digital Information Resources in Africa: Preserving the Integrity of Scholarship\n3. Hussein Suleman. An African Perspective on Digital Preservation\n4. Margret Hedstrom. Digital Preservation: A Time Bomb for Digital Libraries www.eric.ed.gov/ERICWebPortal/recordDetail?accno=EJ586788\n5. Margret Hedstrom. Digital Preservation: Problems and Prospects\n6. Terry Kuny. 1997. A Digital Dark Ages? Challenges in the Preservation of Electronic Information. 63rd IFLA Council and General Conference"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:d4e8290b-8f41-40b5-b2b1-a64ae447109f>","<urn:uuid:ee408182-9bc7-4f44-994d-f50aa7dea141>"],"error":null}
{"question":"I am confused - which missile system has better range - the 9K38 Igla or China's DF-21D? Please explain!","answer":"The Chinese DF-21D has a vastly superior range compared to the Igla missile system. The DF-21D anti-ship ballistic missile has a range of approximately 1,450 kilometers, while the 9K38 Igla surface-to-air missile system has a maximum range of only 5.2 kilometers. This massive difference exists because the DF-21D is a medium-range ballistic missile system designed to target ships at great distances, while the Igla is a man-portable air defense system (MANPADS) meant for short-range air defense.","context":["There is growing concern over China’s ability to further exploit the First Island Chain\nBY PETER KNOTT\nThis feature appeared in the March-April 2020 issue of ADBR\nAnyone who has a passing interest in China’s military development would have heard of the term, ‘Anti-Access Area Denial’, or A2AD for short.\nA2AD is an increasingly popular term for layered defence strategies. In China’s case, it is the overarching strategy in its defence posture, and what it is seeking to achieve from the massive military modernisation program it has undertaken in the past 15 to 20 years.\nSimply described, A2AD is what the Pentagon’s annual report into China’s military power calls the ability for China to “dissuade, deter, or, if required, defeat third-party intervention against a large-scale, theater-wide campaign” mounted by China’s People’s Liberation Army, such as a Taiwan contingency.\nKey to Chinese A2AD efforts would be the so called First Island Chain, a string of islands stretching from Russia’s Sakhalin in the north, down through Japan, Taiwan, the Philippines, and Borneo, encompassing everything in between, that provides a series of natural maritime chokepoints surrounding China.\nThis has always been seen by China as a natural means for adversaries to contain its wider ambitions to be a Pacific and global player in a geopolitical sense, with a series of carefully placed American and allied military bases designed to hem China in.\nBut the barrier effect of the First Island Chain can work both ways. In recent years China’s massive military modernisation effort and investment in A2AD has turned the waters inside the chain into an area where China’s adversaries will find it more and more difficult to operate freely.\nIndeed, there is now a growing worry that China – should it see an open conflict as inevitable or necessary – has acquired enough capability to conduct a massive pre-emptive strike against key military facilities and targets throughout the First Island Chain, and even beyond into the Second Island Chain comprised of a line stretching from Japan’s Bonin Islands, down through the Mariana Islands including Guam, and on to West Papua.\nSuch a strike could potentially cripple a US military response to any regional crisis, and the A2AD capabilities could prevent follow-on forces from Hawaii and the US mainland from intervening.\nThe Pentagon report mentioned above echoes this, noting in its 2019 iteration that the PLA’s “A2AD capabilities are currently most robust within the First Island Chain, though China aims to strengthen its capabilities to extend farther into the Pacific Ocean”.\nIn a similar vein, an article by former US Navy submariner Thomas Shugart in the War on the Rocks website notes that satellite photos of missile test ranges in China suggests that it has conducted trial missile attacks – believed to be made using short or medium-range ballistic missiles – on mockups shaped to look like US air and naval bases in Japan. This would indicate that China has seen such an action as possible enough to test the viability of its missiles for such an eventuality.\nAN A2AD SENSOR NET\nThe DoD report also said that China has robust Integrated Air Defence System (IADS) architecture over land areas, and out to 550km from its coast, that relies on an extensive early warning radar network, fighter aircraft, and a variety of SAM systems. China is also placing radars and air defence weapons on its man-made island outposts in the South China Sea, further extending its IADS.\nThe IADS includes early warning radars that are designed to spot inbound targets, ranging from bomber aircraft to cruise missiles, and even ballistic missiles. These include four large phased array radars for possible ballistic missile tracking similar to the American Pave PAWS system, although there is also a possibility these could be associated with anti-ship ballistic missile (ASBM) targeting. China has also developed and put into service high-frequency (HF) over the horizon radars at several locations throughout China that claim to be able to detect stealthy aircraft.\nThese include both OTH Backscatter (OTH-B), similar to Australia’s Jindalee Operational Radar Network (JORN) and the less complex OTH Surface Wave (OTH-SW) radars, and include one set of the latter at some of the islands in the South China Sea. Chinese analysts claim that these have a range of up to 400km, although the Center for Strategic and International Studies’ Asia Maritime Transparency Initiative (CSIS-AMTI) estimates that the smaller sets in the South China Sea islands are not able to extend their coverage that far.\nThese ground-based sensors are backed by an increasing number of space-based sensors. The US-based Union of Concerned Scientists says that, as of 2016, China had 192 satellites in orbit (second only to the US which has 593). That number has since increased, with nearly all of these belonging to organisations or companies with close ties to the government and many with dual civilian and military utility.\nThese satellites include the Yaogan Weixing (remote sensing) family of approximately 40 satellites whose functions are officially civilian in nature, such as crop yield studies or scientific research. However, several of these are almost certainly used for military purposes with payloads such as electro-optical sensors, synthetic aperture radar, and electronic intelligence (ELINT). There are also constellations of Naval Ocean Surveillance System (NOSS) satellites providing persistent coverage of the waters surrounding China.\nAll of the above could, and almost certainly are used to support ASBM targeting and other naval purposes. With sufficient numbers and integration, they can potentially provide real time target triangulation data to build up a robust picture of the location of a target to generate a targeting solution (see below).\nChina is also said to be developing and trialling an underwater sensor network – similar to the US’s SOSUS (Sound Surveillance System) in the North Atlantic – as part of its anti-submarine warfare efforts. Like many things about PLA developments, there is little solid information about such efforts. While the Pentagon report acknowledges the development of such a network, it adds that the PLA continues to lack a robust deep-water anti-submarine warfare capability.\nIt also adds that it is unclear whether the PLA can “collect accurate targeting information and pass it to launch platforms in time for successful strikes in sea areas beyond the First Island Chain”. It is this writer’s opinion that this capability is not so pressing, and the priority for the PLA is to be able to do so effectively within, but not yet beyond, the First Island Chain.\nThe PLA’s fighters typically employ short and medium-range air-to-air missiles of indigenous design in addition to Russian types such as the Vympel NPO R-77 (AA-12 Adder) for its Russian-built Sukhoi Su-30/35 Flankers, but is also developing an ultra-long range air-to-air missile. Expected to be used to target an adversary’s high value airborne assets such as AEW&C or tanker aircraft, the missile has been given the temporary designation the PL-XX, although observers believe that the eventual in-service designation will be PL-20 (see ‘Savage Skies’ in ADBR Jan-Feb 2020).\nThe new missile has been observed being carried on the Shenyang J-16 multi-role fighter and Xi’an JH-7 fighter-bomber. Comparing the known sizes of the parent aircraft and its hardpoints, has been estimated to measure roughly 5.8 metres in length and about 300mm in diameter. Four rear-mounted fins provide manoeuvrability and control for the missile.\nBy comparison, the RAAF’s longest ranged air-to-air missile, the AIM-120C-7 AMRAAM, measures 3.7 metres long and has a diameter of 180mm. There is little verifiable information about the PL-20’s performance, however a schematic of how it would be used has been leaked to the internet, showing the ramjet or solid-fuel powered missile with a range of 300km.\nAfter launch, the missile will fly a parabolic trajectory to its target, attaining an altitude of about 100,000ft from a launch altitude of 50,000ft, before diving down onto its target. Missile guidance is expected be achieved by a mixture of GPS, INS, and space-based sensors providing launch and mid-course guidance, before an active electronically scanned array (AESA) radar takes over in the terminal phase.\nThat the launch platform can be a relatively limited aircraft like the JH-7 lends further credence that the missile does not rely on its launch aircraft for early targeting data, with an AEW&C platform also likely to be a source of launch parameters. It is not known if China’s stealthy Chengdu J-20 interceptor can carry the missile, but it would need to be carried externally as the J-20’s internal weapons bays are not long enough to carry the missile internally.\nThe airborne shooters are backed up by a network of ground-based long-range air defence systems. Similarly to what it has done across its other defence domains, China has put a lot of effort in improving and modifying Russian systems for its own needs, and in recent years has developed its own line of indigenous ground-based air defence systems.\nThe longest ranged system is the HQ-9, a development of the Russian S-300PMU (SA-20) system that China acquired from Russia. Starting with the original HQ-9, China has since improved the system with the HQ-9A and HQ-9B introduced at the turn of the century and in the mid-2000s respectively, leveraging on improvements in technology in microelectronics and signal processing to introduce dual seekers in the latter.\nThe range of the HQ-9B is said to be in excess of 300km with an altitude ceiling of 134,000ft. To maximize the flexibility of the system, the HQ-9 can employ a wide range of radars, both the search/surveillance/acquisition radar and the tracking/engagement/fire control radar (FCR), however the primary FCR is the dedicated HT-233 that can also double as a search and acquisition radar if required.\nLike the HQ-9 the FCR is also mobile, being mounted on a 10×10 wheeled transporter and is said to operate on the C-band at 300MHz. Performance-wise the HQ-9/HT-233 is said to be closer to the AN/MPQ-53 of the American Patriot missile system than the Russian 30N6 (Flap Lid) that supports the S-300 which is limited by its narrow beam coverage, even in search mode.\nThe HQ-9 has also made its way into the PLA Navy’s ships, with the navalised HHQ-9 being standard fit on board China’s Type 052C, 052D and 055 destroyers. China has also acquired the Russian S-400 Truimf (SA-21) long-range SAM system, although given past history it is likely to be seeking to reverse-engineer it for its own purposes rather than having any intentions of integrating it into its own IADS.\nGiven that the objectives of China’s A2AD strategy is to keep not only aircraft but an adversary’s ships away from its shores, it is also of no surprise that China has also pursued its anti-shipping options in the form of a variety of anti-ship missiles.\nThe most talked about of these weapons is the ASBM. As the name suggests, these are long-range, conventionally armed ballistic missiles used for attacking moving ships at sea, most notably the US Navy’s showpiece nuclear-powered aircraft carriers. The theory being that a missile speeding down to sea level on a ballistic trajectory at speeds of Mach 5 or higher would prove to be an extremely difficult capability to counter.\nThe DF-21D is a road-mobile ASBM system that is mounted on a wheeled transporter erector launcher (TEL) to improve survivability against possible enemy counter-strikes. Said to have a range of about 1,450km, the DF-21D is derived from the DF-21 family of two-stage, solid-fuel rocket, single-warhead conventional or nuclear-warhead medium-range ballistic missile (MRBM) in use by the PLA Rocket Forces (PLARF).\nThe US DoD suggests the DF-21D reached IOC with the PLARF in 2010. The system is thought to employ manoeuvrable re-entry vehicles (MaRVs) with terminal guidance systems assisted by China’s network of satellites such as the Jianbing-5/YaoGan-1 and Jianbing-6/YaoGan-2 that provide targeting data in the form of radar and visual imaging respectively.\nThere are however still questions remaining about the utility of the ASBMs. China has reportedly tested the DF-21D against fixed land targets, but it is not known to have conducted similar tests against a moving target. This makes it difficult to accurately judge the capability – particularly from the maturity and efficacy of China’s sensor net for its kill chain in generating the kind of real time, highly precise data required to enable the DF-21D, and the newer 4,000km-range DF-26 – to accurately target an aircraft carrier making 30 knots in the expanses of the western Pacific.\nThere is however the possibility of using ASBMs and their sensor net to keep watch and/or provide deterrence on the maritime chokepoints presented by the First Island Chain, including the Miyako Straits between Okinawa and Taiwan, and Bashi Channel between Taiwan and the Philippines. This would theoretically reduce the demand on a less-than-mature sensor net and kill chain to limited geographic areas where potential targets will have to navigate.\nConsidering the limited combat radius of carrier-borne aircraft without large scale tanker support, the ability to keep an American carrier battle group at arm’s length may be all that China’s A2AD capability needs.\nBut if required, an attack with ASBMs can be used in conjunction with air and surface-launched anti-ship missiles (ASMs), timed to arrive at the target at the same time to saturate its defences.\nThese attacks could be mounted from longer-ranged ASMs such as the YJ-12 and YJ-18. Both are Chinese improvements of Russian designs, derived from the Kh-31 air-to-surface missile and the 3M54 Klub cruise missile. Both are capable of supersonic speeds, with the anti-ship YJ-18A variant attaining its maximum speed of around Mach 2 in its terminal phase following a subsonic cruise, while the YJ-12 can fly at speeds of between Mach 2 and 4 depending on its launch and cruise altitudes.\nBoth are also very long ranged, with the YJ-12 believed to be between 200 and 400km, while the YJ-18 is believed to possess a range of 540km. The YJ-12 can be launched from wheeled TELs, from vertical launch cells on ships such as the Type 052D or 055 destroyers, or aircraft such as the Xi’an H-6 bomber, JH-7 fighter bomber and possibly the Shenyang J-11/15/16.\nMeanwhile, the anti-ship variants of the YJ-18 can be launched from ships, submarines or land-based mobile TELs, offering flexibility in targeting adversary ships. There are also land attack versions of the YJ-18, which would theoretically mean that US bases such as Guam and even Hawaii could be threatened in times of conflict. The former is also within range of the DF-26 – colloquially known as the ‘Guam killer’ on account of its range.\nChina also has other conventional attack weapons for targeting an adversary’s land targets. These include the CJ-10 and the CJ-20 cruise missiles which can be launched from H-6 bombers and the PLAN’s newer destroyer classes, and can carry a 1,000lb conventional or nuclear warhead over 1,500 km.\nOne area of weapons development China is reportedly more advanced than the West is in the field of hypersonics. China became the first country in the world to officially field an operational hypersonic weapon when it unveiled the DF-17 hypersonic glide vehicle (HGV) during its 2019 National Day parade. The DF-17 has its HGV mounted on the rocket booster of the DF-16 short-range ballistic missile and its TEL, simplifying the development cycle.\nTesting of DF-17 prototypes was underway by 2014 with at least nine test flights reportedly occurring between January 2014 and November 2017. The HGV is known as the DF-ZF and adopts a very different flight profile from normal ballistic missiles by suppressing its trajectory and accelerating to reach speeds of around Mach 5 in its terminal phase.\nDue to its extreme speed and suppressed/lower altitude trajectory, intercepting the glide vehicle becomes more complex than that of a conventional re-entry vehicle – already a difficult undertaking. The high-speed glide profile means the DF-ZF is more manoeuvrable with the bonus of extending its range. In a November 2017 test the HGV reportedly managed to glide at a depressed altitude of around 60km following the DF-17 booster’s ballistic and re-entry phase 1,400km downrange.\nWriting in the in-house blog of the International Institute of Strategic Studies (IISS), Senior Fellow for Military Aerospace Douglas Barrie pointed out that there is always a risk of using shorthand phrases such as A2AD, and conflating the term with drawing weapons range circles on a map and declaring anywhere within those circles as a ‘no-go area’.\nThis is a valid point in assessing the efficacy of an A2AD ‘bubble’. For all of China’s military advancements, the waters of the East and South China Seas and the airspace above will certainly not become no go areas for the US and allied navies, even in a ‘hot’ conflict. But, where it once was a permissive environment, it will undeniably become contested space and become increasingly more so the deeper one ventures into the ‘bubble’.\nWhile the sensors and shooters inside that bubble look impressive on paper, questions remain about their level of integration. Integration of the PLA’s various services has been acknowledged to be China’s weak spot in the past. But recent military reforms such as the consolidation of military regions from seven to five, and the formation of the PLA’s Strategic Support Forces seems to be a step in the direction of creating a truly joint force.\nAt the end of the day, the dearth of verifiable information coming out of China is a stumbling block to assessing how effective or how far-reaching such integration efforts are. But given that these reforms only started in 2016, these are still early days, and a true picture of how effective these efforts will be is still years away.","Igla missile and launch tube.\n|Type||Man-portable air-defense systems (MANPADS)|\n|Place of origin||Soviet Union|\n|Used by||See Operators|\n|Manufacturer||KB Mashinostroyeniya – developer of the system|\n|Weight||10.8 kg (24 lb)|\n|Length||1.574 m (5.16 ft)|\n|Warhead||1.17 kg (2.6 lb) with 390 g (14 oz) explosive|\n|contact and grazing fuzes|\n|Engine||solid fuel rocket motor|\n|5.2 km (3.2 mi)|\n|Flight ceiling||3.5 km (11,000 ft)|\n|Speed||570m/s (peak), about Mach 1.9|\n|dual waveband infra-red (S-version)|\nThe 9K38 Igla (Russian: Игла́, \"needle\") is a Russian/Soviet man-portable infrared homing surface-to-air missile (SAM). \"9K38\" is the Russian GRAU designation of the system. Its US DoD designation is SA-18 and its NATO reporting name is Grouse; a simplified, earlier version is known as the 9K310 Igla-1, or SA-16 Gimlet. The latest variant is the 9K338 Igla-S, with NATO reporting name SA-24 Grinch. It has been fielded by the Russian Army since 2004.\nThere is also a two-barrel 9K38 missile launcher called Djigit.\nThe development of the Igla short-range man-portable air defense system (MANPADS) began in the Kolomna OKB in 1972. Contrary to what is commonly reported, the Igla is not an improved version of the earlier Strela family (Strela-2 and Strela-3), but an all new project. The main goals were to create a missile with better resistance to countermeasures and wider engagement envelope than the earlier Strela series MANPADS systems.\nTechnical difficulties in the development quickly made it obvious that the development would take far longer than anticipated, however, and in 1978 the program split in two: while the development of the full-capability Igla would continue, a simplified version (Igla-1) with a simpler IR seeker based on that of the earlier Strela-3 would be developed to enter service earlier than the full-capability version could be finished.\nThe 9K310 Igla-1 system and its 9M313 missile were accepted into service in the Soviet army on 11 March 1981. The main differences from the Strela-3 included an optional Identification Friend or Foe system to prevent firing on friendly aircraft, an automatic lead and super elevation to simplify shooting and reduce minimum firing range, a slightly larger rocket, reduced drag and better guidance system extend maximum range and improve performance against fast and maneuverable targets, an improved lethality on target achieved by a combination of delayed impact fuzing, terminal maneuver to hit the fuselage rather than jet nozzle, an additional charge to set off the remaining rocket fuel (if any) on impact, an improved resistance to infrared countermeasures (both decoy flares and ALQ-144 series jamming emitters), and slightly improved seeker sensitivity.\nThe seeker has two detectors – a cooled MWIR InSb detector for detection of the target and uncooled PbS SWIR detector for detection of IR decoys (flares). The built-in logic determines whether the detected object is a target or a decoy. The latest version (Igla-S) is reported to have additional detectors around the main seeker to provide further resistance against pulsed IRCM devices commonly used on helicopters.\nThe 9M313 missile features an aerospike mounted on a tripod (Igla's 9M39 missile has aerospike attached directly to the seeker dome), which reduces a shock wave, thus providing less dome heating and greater range. The name Igla is derived from these devices.\nLike many other MANPADS, Igla-1 and Igla feature so-called rolling airframe missiles. These missiles roll in flight (900 – 1200 rpm) so steering the missile requires just a single pair of control surfaces, unlike roll-stabilized missiles, which require separate control surfaces for pitch and yaw. Both 9M313 and 9M39 missiles contain a gas generator, which drives a small gas turbine to provide electrical power, and the pistons, which move the canards used to steer the missile in a bang-bang mode. In addition to that, two exhaust tubes of the gas generator are placed perpendicular to the steering canards to provide maneuverability immediately after launch when the missile airspeed is too low for canards to be effective. Later versions of Igla are reported to use proportional control to drive the canards, which enables greater precision and less oscillation of the flightpath.\nAccording to the manufacturer, South African tests have shown the Igla's superiority over the contemporary (1982 service entry) but smaller and lighter American FIM-92A Stinger missile. However, other tests in Croatia did not support any clear superiority, but effectively equal seeker performance and only marginally shorter time of flight and longer range for the Igla.\nAccording to Kolomna OKB, the Igla-1 has a Pk (probability of kill) of 0.30 to 0.48 against unprotected targets which is reduced to 0.24 in the presence of decoy flares and jamming. In another report, the manufacturer claimed a Pk of 0.59 against an approaching and 0.44 against receding F-4 Phantom II fighter not employing infrared countermeasures or evasive maneuvers.\nThe full-capability 9K38 Igla with its 9M39 missile was finally accepted into service in the Soviet Army in 1983. The main improvements over the Igla-1 included much improved resistance against flares and jamming, a more sensitive seeker, expanding forward-hemisphere engagement capability to include straight-approaching fighters (all-aspect capability) under favourable circumstances, a slightly longer range, a higher-impulse, shorter-burning rocket with higher peak velocity (but approximately same time of flight to maximum range).\nThe naval variant of 9K38 Igla has the NATO reporting name SA-N-10 Grouse.\nThe Igla–1M missile consists of a Ground Power Supply Source (GPSS), Launching Tube, Launching Mechanism & Missile (9M 313–1).\nThe Igla is being replaced in Russian service by the 9K333 Verba (Willow) MANPADS. The Verba's primary feature is its multispectral optical seeker, using three sensors as opposed to the Igla-S' two. Cross-checking sensors against one another better discriminates between relevant targets and decoys, and decreases the chance of disruption from countermeasures, including lasers that attempt to blind missiles.\nThe first combat use of the Igla-1E was during the Gulf War. On 17 January 1991, a Panavia Tornado bomber of the British Royal Air Force was shot down by an Iraqi MANPADS that may have been an Igla-1E (or Strela-3) after an unsuccessful bombing mission. The crew, Flt Lts J G Peters and A J Nichol, were both captured and held as prisoners of war (POWs) until the cessation of hostilities. \nIt is uncertain if an AC-130H lost was hit by a 'Strela' missile or a more recent Igla since Iraq had SA-7, SA-14 and SA-16 missiles at the time, according to the SIPRI database.\nDuring the Iraq War, American and coalition forces suffered a relevant number of helicopter losses. Around a third of them, around 40 aircraft were due to hostile fire, including losses to small arms fire, Anti Aircraft guns, Rocket-propelled grenades and MANPADS; any kind of combat helicopter was shot down from small observation helicopters to armoured Apache gunships. Among the losses to MANPADS, some were reported as losses to older Strela-2 (SA-7) or Strela-3 (SA-14) while others were due to more modern Igla-1E (SA-16) missiles.\nPrivate intelligence company Stratfor asserts that Igla-1E missiles were used in the 1994 shoot down of a Rwandan government flight, killing the presidents of Rwanda and Burundi and sparking the Rwandan Genocide.\nA Peruvian Air Force Mi-25 attack helicopter was shot down on 7 February 1995 around Base del Sur, killing the 3 crewmen, while an Ecuadorian Air Force A-37 Dragonfly was hit but managed to land on 11 February. Hits on additional Ecuadorian aircraft were claimed but could not be confirmed.\nDuring Operation Deliberate Force, on 30 August 1995; a French Mirage 2000D was shot down over Pale by an Igla fired by air defence units of the Army of Republika Srpska. The pilots, Lt. Jose-Manuel Souvignet (pilot) and Capt. Frederic Chiffot (back-seater), were captured and freed in December 1995.\nThe 2002 Khankala Mi-26 crash occurred on 19 August 2002 when a team of Chechen separatists brought down a Russian Mil Mi-26 helicopter in a minefield with an Igla; this resulted in the death of 127 Russian soldiers in the greatest loss of life in the history of helicopter aviation. It was also the most deadly aviation disaster ever suffered by the Russian armed forces, as well as their worst loss of life in a single day since 1999.\nOn 26 January 2014, the militant group Ansar Bait al-Maqdis shot down an Egyptian Mi-17 over the northern Sinai peninsula using a suspected Igla-1E or Igla. How the group came to obtain the weapon is currently unknown.\nDuring the 2011 military intervention in Libya, Libyan loyalist forces engaged coalition aircraft with a certain number of Igla-S. Three Igla-S were fired against British Apache attack helicopters of the 656 Squadron Army Air Corps operating from the HMS Ocean amphibious assault ship. According to the squadron commander at the time, they were all dodged by insistent use of decoy flares by the gunships who in exchange successfully engaged the shooters.\nOn 23 March 2015, a Libya Dawn-operated MiG-23UB was shot down with an Igla-S (reportedly a truck-mounted Strelets variant) while bombing Al Watiya airbase (near Zintan), controlled by forces from the internationally recognized Council of Deputies. Both pilots were killed.\nVideo has surfaced showing rebels using an Igla-1E on a Syrian government helicopter. Such weapons were believed to have been looted from a Syrian army base in Aleppo in February 2013. In 2014, a member of the rebel group Harakat Hazm was filmed aiming an Igla-1E into the air on the same day that the group was filmed operating BGM-71 TOW missiles. Whether these weapons were raided from regime stockpiles or supplied via overseas is unknown.\nOn 14 June 2014, rebel forces near Luhansk International Airport in Eastern Ukraine shot down an IL-76 of the Ukrainian Airforce probably using an Igla MANPADS, killing all 49 Ukrainian service personnel on board.\nOn 12 November 2014, Azerbaijani forces shot down an Armenian Army Mi-24 of a formation of two which were flying near the Azerbaijani border. All three on board died when the helicopter crashed while flying at low altitude and was hit by an Igla-S MANPADS fired by Azerbaijani soldiers.\nOn 13 May 2016, PKK militants shot down a Turkish Army Bell AH-1W SuperCobra attack helicopter using 9K38 Igla (SA-18 Grouse) version of this missile system. The missile severed the tail section from the rest of the helicopter, causing it to fragment in midair and crash, killing the two pilots on board. The Turkish government first claimed that it fell due to technical failure before it became clear that it was shot down. The PKK later released video footage of the rocket being fired and striking the helicopter.\nSeveral variants of the Igla were developed for specific applications:\n|9K34 Strela-3 /SA-14||9K38 Igla /SA-18||9K310 Igla-1 /SA-16||9K338 Igla-S /SA-24||FIM-92C Stinger||Grom||Starstreak|\nready to shoot\n|16.0 kg (35.3 lb)||17.9 kg (39 lb)||17.9 kg (39 lb)||19 kg (42 lb)||14.3 kg (32 lb)||16.5 kg (36 lb)||20.00 kg (44.09 lb)|\n|Weight, missile||10.3 kg (23 lb)||10.8 kg (24 lb)||10.8 kg (24 lb)||11.7 kg (26 lb)||10.1 kg (22 lb)||10.5 kg (23 lb)||14.00 kg (30.86 lb)|\n|Weight, warhead||1.17 kg (2.6 lb),\n390 g (14 oz) HMX\n|1.17 kg (2.6 lb),\n390 g (14 oz) HMX\n|1.17 kg (2.6 lb),\n390 g (14 oz) HMX\n|5.5 lb (2.5 kg),\n20.6 oz (585 g) HMX\n|6.6 lb (3 kg) HE||1.27 kg (2.8 lb)||3x0.90 kg (2.0 lb) tungsten alloy darts,\n3x450 g (16 oz) PBX-98\n|Annular blast fragmentation||Directed-energy||Directed-energy|\n|Fuze type||Impact and grazing fuze.||Delayed impact,\nmagnetic and grazing.\nmagnetic and grazing.\nmagnetic and grazing.\n|Delayed impact.||Impact.||Delayed impact, armour-piercing.|\n|Flight speed, average / peak||470 m/s (1,100 mph) sustained||600 m/s (1,300 mph)\n/ 800 m/s (1,800 mph)\n|570 m/s (1,300 mph) sustained\n(in + temperature)\n|?||700 m/s (1,600 mph)\n/ 750 m/s (1,700 mph)\n|580 m/s (1,300 mph)\n/ 650 m/s (1,500 mph)\n|1,190 m/s (2,700 mph)\n/ 1,360 m/s (3,000 mph)\n|Maximum range||4,100 m (13,500 ft)||5,200 m (17,100 ft)||5,000 m (16,000 ft)||6,000 m (20,000 ft)||4,500 m (14,800 ft)||5,500 m (18,000 ft)||7,000 m (23,000 ft)+|\n|Maximum target speed, receding||260 m/s (580 mph)||360 m/s (810 mph)||360 m/s (810 mph)||400 m/s (890 mph)||?||320 m/s (720 mph)||?|\n|Maximum target speed, approaching||310 m/s (690 mph)||320 m/s (720 mph)||320 m/s (720 mph)||320 m/s (720 mph)||?||360 m/s (810 mph)||?|\n|Seeker head type||Nitrogen-cooled,\nlead sulfide (PbS)\nIndium antimonide (InSb)\nuncooled lead sulfide (PbS)\nIndium antimonide (InSb)\nIndium antimonide (InSb)\n|?||SACLOS and SALH|\n|Seeker scanning||FM-modulated||FM-modulated||FM-modulated||FM-modulated||FM-modulated||FM-modulated||Low intensity modulated-laser-homing darts|\n|Seeker notes||Aerospike to reduce\nsupersonic wave drag\nto reduce supersonic wave drag\n|Low laser beam energy levels ensuring no\nwarning to target\nOn 12 August 2003, as a result of a sting operation arranged as a result of cooperation between the American, British and Russian intelligence agencies, Hemant Lakhani, a British national, was intercepted attempting to bring what he had thought was an older-generation Igla into the United States. He is said to have intended the missile to be used in an attack on Air Force One, the American presidential plane, or on a commercial US airliner, and is understood to have planned to buy 50 more of these weapons.\nAfter the Federalnaya Sluzhba Bezopasnosti (FSB) detected the dealer in Russia, he was approached by US undercover agents posing as terrorists wanting to shoot down a commercial plane. He was then provided with an inert Igla by undercover Russian agents, and arrested in Newark, New Jersey, when making the delivery to the undercover US agent. An Indian citizen residing in Malaysia, Moinuddeen Ahmed Hameed and an American Yehuda Abraham who allegedly provided money to buy the missile were also arrested. Yehuda Abraham is President and CEO of Ambuy Gem Corp. Lakhani was convicted by jury in April 2005, and was sentenced to 47 years in prison.\nIgla and Igla-1 SAMs have been exported from the former Soviet Union to over 30 countries, including Angola, Bosnia and Herzegovina, Botswana, Brazil, Bulgaria (former producer), Croatia, Cuba, East Germany, Egypt, Ecuador, Eritrea, Finland, Hungary, India, Iran, Iraq, the Republic of Macedonia, Malaysia, Mexico, Morocco, North Korea, Peru, Poland, Serbia, Singapore, Slovakia, Slovenia, South Korea, Sri Lanka, Syria, Thailand, Turkey, United Arab Emirates, Vietnam and Zimbabwe. Several guerrilla and terrorist organizations are also known to have Iglas. Alleged Operatives of the Liberation Tigers of Tamil Eelam a rebel organization fighting for a homeland for Tamils in the island of Sri Lanka were arrested in August 2006 by undercover agents of the FBI posing as arms dealers, while trying to purchase the Igla. In 2003 the unit cost was approximately US$60,000–80,000.\n|Wikimedia Commons has media related to 9K38 Igla.|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:fadb9048-555a-4629-9748-440eb9325940>","<urn:uuid:8f927b77-1a03-4f41-aba5-b5855779eac8>"],"error":null}
{"question":"What's the main difference between PPE inspection requirements for standard safety equipment vs chemical containers in workplaces?","answer":"PPE and chemical containers have different inspection requirements. For standard PPE like harnesses and protective gear, workers need to inspect for damage and ensure proper fit, especially after contact with hazardous materials, but no specific inspection frequency is mandated. In contrast, chemical containers require more rigorous inspection schedules - they must be inspected at least annually, with certain substances like peroxide-forming compounds requiring checks every three months minimum. Chemical container inspections involve examining bottles for safety issues like discoloration, bulging caps, corrosion signs, and checking expiration dates.","context":["When you imagine a construction worker’s daily uniform, typical things that may come to mind are the safety glasses, the reflective vest, and the classic hard hat. While they might appear to be just part of a uniform, all of these accessories are essential to conducting workplace safety and are some of the main items worn as a part of a construction worker’s personal protective equipment. Personal protective equipment is crucial to safety on the job site, so below we’ll fill you in on what it is, why it’s worn, and how you can use it to better improve safety for your workers.\nWhat is Personal Protective Equipment\nIt’s a no-brainer that personal protective equipment is designed to protect oneself from the dangers they may encounter during work in their field, but what exactly is it defined as? Personal protective equipment (PPE) is a general term for wearable equipment and gear that’s meant to protect the wearer from hazards and dangers on the job site. Although construction is one of the largest industries utilizing personal protective equipment, it is used in many other fields too, like the military, the police, and firefighting.\nIn the construction industry, workers use all kinds of equipment and materials. Because of this, there is an abundance of protective gear available to protect against the possible dangers a worker can encounter on site. Below are the main areas of the body requiring protective gear and items used to protect each region:\nThe head > includes hard hats to protect against falling objects and blows to the head.\nThe eyes > includes safety glasses, face shields, and chemical splash goggles to protect against particles from getting into the eyes when working in certain areas like welding or handling hazardous materials.\nThe ears > includes ear plugs and ear muffs to protect against loud noise that can occur on site.\nThe back > includes support belts to protect against muscle strains that can come from lifting heavy objects.\nThe hands and feet > includes snug, insulated gloves and puncture-resistant, steel-toed boots to protect against shocks from working with electrical wires or objects from crushing the feet..\nPersonal protective equipment includes more than just protective clothing. There are three other important categories including fall protection, respiratory protection, and visibility. Falling is one of the leading causes of death on construction sites, so using appropriate protective gear like a safety harness is one way to prevent this danger. Protecting the lungs is also important, so using respirators to prevent the inhalation of hazardous gases, vapors, and particles is another way to practice good safety. The visibility of your workers is also important on construction sites, so enforcing the usage of high visibility vests keeps workers easy to spot, ensuring the ability to quickly find anyone in case of an emergency.\nThe Risks Involved\nDue to the many potential dangers that workers can face in the construction industry, wearing personal protection equipment is necessary. Depending on the job site, workers can face a number of risks including falling, electrical shocks, blunt trauma, and getting caught in between objects, all of which can cause death in serious cases. Construction workers can experience a number of serious nonfatal injuries too, like chemical burns, broken bones, and severed fingers. Due to the severity of these risks, companies can suffer huge fines for the non-usage of safety equipment, and in some cases can face massive legal trouble.\nImproving Construction Site Safety\nConstruction site safety should be a priority for employers, so it’s important to practice good safety procedures through the usage of personal protective equipment. One way to practice this is to make sure your employees understand how to use their equipment, what it protects them from, and even more important: what it does not protect them from. Personal protective equipment has to fit properly to ensure its maximum protective ability, and proper care and maintenance are also equally important in practicing good safety measures. Workers also need to know when to replace equipment, especially when it comes in contact with hazardous materials, or gets damaged as this reduces its maximum protective ability.\nUnderstanding why PPE needs to be worn is important as big fines, legal trouble, serious injuries, and even death can occur from a lack of or improper usage. Ultimately, personal protective equipment improves construction site safety which is why it’s important to promote a safe working environment with fit testing and ensuring all occupational and health safety requirements are met.","While chemical safety includes many individual elements, ranging from right-to-know training, to personal protective equipment (PPE), to material safety data sheets (MSDS), these elements should be part of a larger, overall system. This system's aim is to protect all employees from chemical hazards they may encounter at work.\nChemical safety is a system of standard operating procedures that receives, transports, stores, uses and disposes of chemicals in a safe and prudent manner. This process actually begins before a chemical is even ordered, and it doesn't end until the substance is properly disposed of.\nThe system is a living system, growing, changing and adapting to the potential dangers of the substances that are being used. It is also a partnership - one between labor and management designed to produce what all parties want: a safe work environment.\nLet's look at the some of the operating procedures involved in a chemical safety program.\n1) Prior to orderingBefore a chemical is ordered, the person requesting the material should attempt to substitute a less hazardous substance. In some facilities, prior approval from management and the safety department is needed if the desired chemical is a known or probable human carcinogen, acutely toxic substance, or presents a pronounced physical hazard, such as an explosion.\nAn MSDS for the substance should be on hand before the chemical is received. After reviewing this document you can decide if additional/specialized engineering controls, PPE, storage facilities and spill control measures are needed.\nAlso, having the MSDS prior to receipt of the chemical allows time for employee training in the safe handling and use of the material.\n2) Receipt and transportAll packages containing chemicals, including gas cylinders, must be inspected for leaks and damage before being transported to the assigned storage site. The personnel that inspect these packages should be wearing the appropriate level of PPE: safety glasses and chemical-resistant gloves at a minimum. Things to look for:\n- physical damage: dents, tears, scrapes, dirt, paint/ink from other containers;\n- evidence of tampering;\n- signs of leaks or spills: discoloration, odor, wet packaging, powder coming from the container.\nIf there are any indications of a spill or leak, evacuate the immediate area and call for aid.\nIf there are no signs of damage or leaks, the material may be transported to its assigned storage area. If the material is a particularly hazardous substance, notify the safety department and the person requesting the material. If a chemical requires refrigeration or freezing, and transport to the designated storage site is delayed, make arrangements for proper preservation of the compound.\nDo not hand carry chemical packages. Packages containing chemicals should be transported to the appropriate storage site on a cart that has raised sides. If the package has been opened, place the substance in a secondary containment vessel and then on the cart.\n3) Storage/inventoryChemicals are stored according to properties. Acids are stored separate from bases, flammables are stored in special cabinets, oxidizers are stored away from organics, and so on. After storing according to chemical properties, then and only then may chemicals be sorted alphabetically.\nRefrigerators/freezers used for chemical storage must be labeled to that effect. Food or beverages must be kept out unless they are being used for testing; they should bear a prominent label that states they are not for human consumption. Refrigerators/freezers being used for storing flammable chemicals should be explosion-proof.\nThe chemical inventory in a stock room or other storage area must be inspected at least once a year. During these inspections, examine each bottle to see if the chemical is still safe to use and that the container hasn't been breached. (See \"Warning Signs\" sidebar.)\nCertain classes of chemicals must be checked more frequently. Peroxide-forming compounds that have been opened should be checked every three months at a minimum. Visual inspection of the container and contents using a non-hazardous light, such as a flashlight, can detect the presence of very high levels of peroxides in organic solvents stored in glass bottles. Check to see if the clear solvents contain: suspended wisp-like structures, crystal formation, cloudiness or gross contamination. Contact your safety department or hazardous waste contractor immediately if they do.\nIf none of these conditions exist, the solvent may be tested using a commercially available test strip. These strips can measure up to 100 mg/L peroxide as H2O2. Some experts recommend that this concentration be used as the maximum safe concentration and that solutions containing higher values than this be disposed of.\n4) Point of useWherever chemicals are used, measures must be taken to reduce personnel exposure. Among these measures are engineering controls, including: fume hoods, glove boxes, local exhaust systems and robotic equipment.\nThese systems need to be inspected and tested on a regular basis, with the date of the last inspection being posted on the device. When working with a particularly hazardous substance, have the device tested immediately prior to use.\nAnother safety requirement is the posting of appropriate safety signage. Additionally, in areas where carcinogens, reproductive toxins, and chemicals of high toxicity are used, access to the area should be limited to only those people who need to be there.\n5) DisposalChemical disposal must conform to the local hazardous waste regulations. Most regulations require secondary containment and storage in a secure area. Only authorized personnel should be allowed into this part of the facility. Spill equipment should be stored outside the secured area to allow easy and safe access in case of an emergency.\nAn empty container is not truly empty. Until it has been cleaned, there will always be chemical residue inside it. PPE should always be worn when handling these \"empties\" until decontamination/cleaning has taken place.\nSIDEBAR: Warning SignsWhat to look for when inspecting your chemical inventory:\n- Is the label discolored? Something in the cabinet may have leaked.\n- Are there crystals around the cap? For some chemicals, such as potassium chloride solutions, this is not abnormal.\n- Is the container or cap bulging?\n- Is the cap cracked?\n- Does the container have a \"sucked in\" look or show signs of corrosion?\n- Is there a film on the container?\n- Is the bottle warm to the touch?\n- Is there a precipitate in an otherwise clear reagent?\n- Has the reagent turned color? This is normal in the case of open nitric acid bottles but a danger sign for most other reagents.\n- Is there obvious contamination, such as discoloration or specks in the substance?\n- Is the chemical past the expiration date assigned by the manufacturer?\n- Is the substance giving off a strange odor? If so, initiate a spill response."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"}],"document_ids":["<urn:uuid:0f74e8e6-fd9c-42c9-8a94-b4c3edb30984>","<urn:uuid:c976c5fe-ee49-41e5-b956-4c093cf7f0aa>"],"error":null}
{"question":"What's the main difference between how corporate compliance departments and Meena Krenek approach design innovation? Really curious about this! 💡","answer":"Corporate compliance departments typically take either a conservative or progressive approach to design innovation, with some erring on the side of legal protection at the cost of customer experience. In contrast, Meena Krenek approaches innovation through research and ideation, believing that questioning everything and exploring possibilities is key. While compliance departments focus on regulatory boundaries, Krenek emphasizes being bold and never accepting that something can't be done or built, actively seeking clients who want to disregard normalcy and embrace risk-taking in design solutions.","context":["Most designers look at regulations the way that Don Quixote looked at windmills – as an adversary that must be defeated or circumvented.\nIn fact, regulations are just one of several boundaries on any designer of business communications. Designs are also restricted by:\n- Corporate Identity Guidelines\n- Postal Regulations\n- Production Processes\nAnd just as windmills are not giants, boundaries don’t need to be the designer’s enemy. In fact, identifying these factors in advance can help to focus attention on the goals of the design and also apply a filter to the process of finding solutions. The ability to understand and design for these constraints can actually become a strategic advantage for the designer.\nDo you need to be an expert on every regulation? Cam Shapansky, Partner at Canada-based marketing agency Blue ID says “I don’t think the designer should become the regulatory expert, but we’ve always tried to view the regulators as a friend.” At the end of the day, compliance departments and corporate counsel exist for a reason – they are the legal experts. What is critical is that designers understand when they are working with a communication that is subject to regulatory compliance and that they engage the appropriate experts as early in the process as possible. Some designers may be tempted to simply lift-out the regulatory language that is currently used. This is a problem for several reasons; first, the product or business changes that were the catalyst for redesign might have negated the need for specific disclosures. Second the regulations (or cited regulatory agencies) may have changed or be pending change – recent examples include the renamed FINRA (replacing NASD in the footnotes of your U.S. brokerage statements) and the newly formed Consumer Financial Protection Bureau or CFPB. Third, the company’s “compliance culture” or interpretation of the regulations may have shifted since the last time the document was updated. Some companies take a very conservative approach, erring on the side of legal protection to the corporation at the cost of customer experience. This can have a major impact on the design process as well as the design itself.\nAnother way that companies differ in their interpretation of regulations is in the placement of compliance messaging according to Michael Ellison. As the president of Corporate Insight, an analyst firm that uses live accounts at leading financial firms to benchmark communications across all major channels, Ellison reviews a lot of statements. “Some firms dump several paragraphs of legalese onto one page in very small type, creating a dense, uninviting reading experience that adds no value to the relationship. Others sprinkle the required language throughout the document. While still dense legal-speak, the language is at least a little easier to understand since it’s presented in proper context. A third – and in our view, optimal – approach transforms regulatory disclosures into readable, plain language, presenting this required text in a way that is not distracting to the reader.” .\nProgressive companies combine “point of need” messaging with plain language disclosures to minimize complex legal language and make sure that key information is placed where it is most useful to the reader. Some language may still be clustered in one area of the statement if it is general information that is not frequently referenced. According to Shapansky, “We consider the meeting with corporate counsel to be one of the most important meetings we have with any client. You know within the first 30 seconds what type of regulatory interpretation the company is going to follow and whether they are progressive or not. “\nWorking directly with a firm’s compliance expert provides a much-needed opportunity to advocate for innovations that make the language and positioning more customer-friendly. Sometimes the boundaries need to be pushed and interpretations need to be challenged for the benefit of the customer – and ultimately the corporation as well. Often in challenging specific compliance “rules” it is determined that they are not rules at all but simply “guidelines” defined by some long-retired employee of years gone by.\nIn designing business communications, you must have a strategy for dealing with the boundary conditions you face. Will the design process be based on rigid instructions or will there be a dialogue? Will the process lean toward the customer or toward a bureaucratic norm? Will you color well within the lines or will you color right up to the outside edge of the line?\nKeys to Success:\n- Understand the current interpretation. Why was the regulatory language handled in this particular way? Has the corporate or regulatory climate changed?\n- Understand the corporate culture. Do they take a conservative position or a progressive position? Do they actually have a position or are they just doing what they’ve always done?\n- Make your case for any requested changes. Will your approach have a significant positive impact on customer experience, cost or risk exposure? Can you back your claims up with competitive benchmarks or research?\n- Provide several options. There may be more than one way to make improvements. Don’t end up with the status quo, legalese interpretation because you weren’t willing to compromise.\n- Engage with compliance representatives in person (and have your corporate sponsor on board with your recommendations first.) Remember, it’s easy to say “no” in an email. It’s much harder face-to-face.\n- Document the discussions and factors that drove the decision to take a particular approach. This will help to make the decision stick and avoid revisiting issues multiple times when and if new people join the project.\nMost importantly, remember that regulations are intended to inform and protect the customer. They also protect the corporation from potential liability. Regulations are not the enemy of design, they don’t need to be defeated or circumvented. They need to be understood and implemented in a way that serves the intended purpose – and the same could be said of any portion of content in any information design project. Once you learn enough to color inside the regulatory lines you’re much more likely to be able to influence where those lines are drawn.\nElizabeth Gooding is the President of Gooding Communications Group and editor of the Insight Forums blog. She writes, presents and provides training on trends and opportunities for business communications professionals within regulated vertical industries.\nThis labelling news was spotted at The Digital Nirvana\nGet the full story direct from source..","Meena Krenek uses design to tell stories and craft culture: Focus on Leadership - Oct 2017\nInterview by Kemp Harr\nLess than two decades into her career, Meena Krenek already has a lot under her belt. She currently serves as design director for Gensler’s Atlanta office. Prior to that, she was interior design director for Perkins+Will’s New York City location. With her hands-on approach, Meena believes that design has the capability not just to complement but also to transform company culture, and she loves clients who are willing to push the boundaries of experiential and experimental design.\nQ: How did you decide that architecture and interior design was the right career focus for you?\nA: I always knew. I played with Legos as a child and was fascinated with houses, buildings and books with great graphics. Also, I loved to draw. I had a wild imagination as a child, and I don’t think that has changed.\nQ: What mentors helped shepherd your career?\nA: Mentorship is the true foundation of our industry. I’ve been very fortunate to have had and to continue to have incredible coaches and colleagues in my career. I had a professor in college, Tracy Moir-McClean, who taught me how words can be expressed through architecture and space. In her class, we studied poetry and learned to interpret prose and translate the meaning into architectural sketches and collages. In my experience, our design concepts start with a vocabulary derived from the clients’ drivers and specific needs; then we turn the verbal language into a visual one, creating truly meaningful environments. Tracy provided me a unique perspective in design thinking that is fully integrated into my process, as well as a level of confidence that allowed me to evolve as a designer.\nQ: What are your thoughts about the open office environment? Does it always enhance productivity? Where does it go from here?\nA: Open office design does not work for every office. It is important to truly understand the organization as well as how to create a workplace that supports its business goals and culture, providing spaces that enable employees to do their best work every day. The idea is to provide the correct balance of open and closed spaces that accommodate different tasks, work styles and personalities. The future of the workplace is a big question for everyone. We are continuously seeking and exploring ways to integrate flexibility and multi-use into the design to support future proofing.\nQ: How do you get your clients comfortable with trusting and investing in your designs?\nA: I build mutual trust with my clients so that together we can explore new design possibilities that positively transform all aspects of their businesses. I’m always looking to partner with clients who want to be expressive and bold-pushing design to places that were previously unthinkable. It’s a partnership with a capital P. It’s finding an emotional connection with clients and connecting with them in ways that build an alignment with their mission and aspirations.\nQ: Do you try to integrate biomimicry and outdoor spaces into your designs? Does tying in with nature and fresh air make for a better work environment?\nA: Yes. First and foremost, natural light is essential to workplace design, and creating spaces that allow all users to experience natural light is essential. Of course, outdoor spaces are a wonderful amenity for the workplace. When this is not feasible, providing views to the exterior and a connection to natural light is a must. As a designer, it’s important to educate clients about aspects of wellness in the workplace. All our clients are now seeking height-adjustable workstations, areas to encourage stand-up meetings, group treadmills in the meeting spaces, wellness rooms, active design and healthy food choices.\nQ: Which project has given you the most satisfaction, and why?\nA: I really love each project for a different reason. My most satisfying projects are those within which a client wants to do something big-opting to disregard normalcy and embrace risk-taking.\nQ: How important is the flooring decision to the overall function of any given space?\nA: As a designer, the flooring is a part of the immersive experience of creating impactful spaces. The flooring, wall treatment and ceiling all must come together as a holistic experience.\nFlooring is where most non-designer’s eyes go while experiencing an environment. When I’m selecting flooring, I think about how to use the flooring to define the diverse parts of the space, and it becomes the foundation for wayfinding.\nQ: What is your go-to resource for questions about flooring?\nA: We are lucky to have a strong A&D community in our industry. Our reps are an incredible resource, sharing case studies and new product information. The flooring solution is typically a response to our design concept and supportive of the type of spaces we are creating.\nQ: Why are we seeing more polished concrete in the workplace? Aren’t there acoustic and comfort barriers that must be overcome to make this “cool” look really work?\nA: Sure, exposed concrete floors and exposed slab in the ceiling are very authentic ways of expressing the rawness of a space. But we must balance the space with flooring that absorbs sound, like carpet tiles, or add acoustic clouds in the ceiling to damper sound in the space.\nExpressing the right look and feel is a science and an exercise in balance. But “cool” comes in many forms, and the key is finding the right “cool” for each client.\nQ: What do you do to sharpen your way-to become better informed-so that you can offer the client the best solution available?\nA: I have always been with firms that are thought leaders in the industry. Research and ideation are the keys to innovation. Every day at Gensler, we are solving ideas for the future and exploring new topics in design. It never stops. With this mindset, great design solutions are born.\nQ: You worked first in Atlanta, then in New York, and now you’re back in Atlanta. How are these cities different from both a client and design perspective?\nA: This is a great question. Atlanta and New York are very different in size, culture and lifestyle. I believe every designer needs to spend time working in New York City. There is nowhere in the world like Manhattan. But when it comes down to clients and design perspectives, by working for global firms I have been fortunate to work across the nation and world with some of the most sophisticated clients and minds.\nI believe that to be a successful designer in our society today, you must serve the world and express design through your unique lens. You can’t have simply a regional point of view. Regardless of what city you’re in, finding clients that believe design is a business tool and value the creativity that design yields is crucial to being a world-class designer.\nQ: What advice do you have for recent graduates who want to follow in your footsteps?\nA: Find your personal brand and embrace your passions. You will attract clients that align with your values this way. Never stop listening. Being able to emotionally connect with clients and co-workers is a beautiful thing. Listen between the words-there is so much to gain. Never let someone tell you something can’t be done or built. Question everything and explore possibilities. Be bold.\nQ: How have your roots in the South helped you be successful?\nA: I adore the South and have enjoyed both being a part of Atlanta’s growth and watching it mature. And I appreciate all the businesses that have made Atlanta their home. The individuals and clients I have met in the South have helped me in my career. It’s all about the people that have trusted me to transform their workplace and the colleagues that have worked beside me to produce award-winning projects.\nCopyright 2017 Floor Focus"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:76c20cb5-bfe1-4598-baf7-e8a175ac8c09>","<urn:uuid:a507354c-4e28-44a8-a02d-a1652ae98256>"],"error":null}
{"question":"How do both the Minor in Consciousness and the Africana Studies programs address the intersection of psychology and cultural experiences in their curricula?","answer":"Both programs incorporate psychological perspectives but with different focuses. The Consciousness Minor explores psychological aspects through courses like BCONSC 321, which studies dreams, intuition, and contemplative practices, and BBIO 310, which examines the biological basis of human behavior. The Africana Studies program addresses psychology through courses like Psychology 2420 (Psychology of the Black Experience), which specifically examines cultural differences from a psychological perspective, covering topics such as intelligence, racial identity, and psycholinguistics.","context":["The Minor in Consciousness at the University of Washington Bothell is the first of its kind at a public university in the world. It offers students and faculty the opportunity to explore big questions and bigger mysteries that have drawn the attention of some of the most brilliant scientists, scholars, and creative minds throughout the centuries.\nConsciousness is a multidisciplinary inquiry into the nature, dynamics, and functions of the mind. It comprises new insights about the ontology of mind that are informed by depth psychology, neuroscience, quantum physics, and contemplative practices. The integral study of consciousness emphasizes broad and intellectually rigorous approaches to the mind and the exploration of cutting-edge and controversial issues. These include the nature of consciousness, the intersection of mind and matter, and ways of exploring levels of awareness that span disciplines, cultures, and history. It also includes a variety of experiential practices that have been demonstrated to heighten mental clarity, enhance creativity, and promote psychological and physical well-being.\nThe Minor's seven permanent courses provide students the opportunity to engage the emerging field of Consciousness within a context grounded in scientific method, empirical inquiry, and philosophical reflection. The Minor consists of a minimum of 25 credits from A and B:\nA. Core Requirements- 10 credits\n- BCONSC 321: Consciousness Studies - The Farther Reaches of Human Nature (5 cr): Introduces the field of consciousness studies. Explores the interaction of mind and body through scientific studies of dreams, intuition, intention, and anomalous phenomena. Includes the role of meditation and contemplative practices in physiological and psychological well-being.\n- BCONSC 322: Exploration of Consciousness (5 cr): Deeper inquiry into the nature of consciousness and the interaction of mind and body. Topics include the biology of compassion and belief, attention and intention in neuroplasticity, experimental studies of meditation and mental training in promoting psychological, physical health; and the emergence of an integral scientific paradigm. Prerequisite: BCONSC 321.\nB. Elective Requirements- 15 credits (Chosen from this list)\n- BCONSC 323: The Psychology and Science of Dreams (5 cr): Explores the psychology and science of dreams. Topics include the history and theories of dreams, modern experimental studies of dreaming and dream content, lucid dreams, contribution of dreams to scientific creativity, and dream incubation and interpretation techniques.\n- BCONSC 424: Consciousness and the Natural World (5 cr): Explores emerging models of consciousness in the natural world. Topics include scientific and shamanic research about animal and plant consciousness and the ethical implications of this inquiry for human interaction with other species. Prerequisite: BCONSC 322\n- BPHYS 305: The Cosmos: Provides a conceptual introduction to the foundation and current theories of cosmology. Studies black holes, time travel, the Big Bang, and dark matter.\n- BBIO 310: Brain and Behavior (5 cr): Interdisciplinary exploration of the biological basis of human behavior, including altruism, aggression, learning, communication, and mating. Draws on neuroanatomy, neuroscience, endocrinology, ethology, genetics, and sociobiology to examine how the brain influences, and is influenced by, behavior. Readings include primary literature as well as popular publications.\n- BCONSC 425: Consciousness and Well-Being (5 cr): Focuses on understanding the non-local dynamics of human consciousness. Topics include entanglement and attunement as underlying principles of psychological and physical reality, experimental and phenomenological studies of shared consciousness with humans and other species, and contemplative practices that promote individual and societal health and well-being. Prerequisite: BCONSC 322.\nC. Optional Undergraduate Research – 5 credits\n- BCONSC 499: Undergraduate Research: After completing the minor, students will be eligible to participate in undergraduate research (1-5 cr). Undergraduate research can be supervised by any interested faculty member.\nThe Consciousness Minor offers students at all three UW campuses a coherent opportunity to explore big questions and bigger mysteries that have drawn the attention of some of the most brilliant scientists, scholars, and creative minds throughout the centuries. By emphasizing broad and rigorous approaches to the study of consciousness, the minor brings together a variety of scientific and contemplative disciplines to speak to the following goals:\n- Understand the ways in which contemporary scientists and contemplative scholars are collaborating to investigate the psychology, biology, phenomenology, and physics of consciousness.\n- Analyze complex models of consciousness from scientific, philosophical, historical, and contemplative perspectives.\n- Consider the role of different states of consciousness in facilitating creative processes, inventions, and scientific discoveries as well as psychological, physical, and societal well-being.\n- Examine the influence and limits of scientific paradigms, as well as their ethical implications.\n- Comprehend the ways in which thoughts, emotions, and contemplative practices change the anatomical and physiological structure and functioning of the brain.\n- Explore the role of meditation and contemplative practices in expanding our knowledge about the nature and scope of consciousness.\n- Offer students opportunities to participate in research at the leading edge of an emerging field.\n- Provide a platform for students to explore their own consciousness, heighten mental clarity, and improve individual and collective well-being.\nAs a result of completing the minor, students will be prepared to explore the complex relationships among mind, brain, and body with scientific rigor and open minds. They will be able to converse about the relationship of mind and matter with contemporary scientists and contemplative scholars, comparing and contrasting different approaches, and assessing their strengths and limitations. They will learn contemplative practices that have been proven to help them concentrate, increase their motivation and persistence, enhance their higher order thinking skills, and achieve a greater sense of equanimity. These skills will help them cope with the increasingly complex problems of the contemporary world and contribute creatively to their solutions. Students will be encouraged to become more reflective, compassionate, insightful, and resilient, to cultivate their self-awareness, and to consider carefully the consciousness and needs of other species and the biosphere. As a result, students will gain a greater sense of meaning and purpose, an enhanced capacity to draw upon and integrate different forms of knowledge, and a heightened ability to utilize inner resources to live mindfully at home, at work, and in their communities.","What will I study?As an interdisciplinary minor, you will take a range of courses covering all aspects of issues relating to people of African descent. In order to insure that you complete a well-rounded curriculum, there are certain required courses as well as a large range of electives. As you progress through the curriculum you will develop an understanding of the history, culture, and experiences of peoples of color from Africa, to the Americas, and beyond.\nNote: Presently the majority of courses are at the 300/400 level, thus students enrolling in the minor will generally be at the sophomore credit level or higher.\nMinority studies (3 hours)\nThese classes are designed to help students with strong foundation in minority issues before progressing onto other areas. These courses thus provide students with a general understanding of diversity, and the psychology of race. The classes do not only cover those of African descent, rather they deal with the entire experience of minorities often from a global perspective.\n- Psychology 2420: Psychology of the Black Experience. STEPHENS/COTHRAN. Fall semester. Covers the impact of cultural differences from a psychological perspective. Topics include intelligence, racial identity, and psycholinguistics.\n- Sociology 3050: Minorities in American Life. Fall & spring semesters. The course covers the character and role of racial, religious, and ethnic minorities in the US; the interplay of historical and current sociocultural processes on attitudes and behavior for both dominant and minority groups; and minority-related social problems and their possibilities of solution.\n- Sociology 3450: Social Inequality. MEDLEY/ BUCHANAN. Fall & spring semesters. An introduction to the study of inequality focusing on the distribution of resources in the US, and the social barriers that keep groups and individuals apart.\n- Criminal Justice 3170: Minorities and Criminal Justice. BUMPHUS/ILES. Every semester.This course involves a critical analysis of multicultural, intergroup relations in the United States. It is intended to help students gain increased understanding of how race, ethnicity, gender, social status, age, occupation, etc., are related to the myriad of problems confronting social relations and the workings of the criminal justice system.\n- Political Science 3220: Civil Liberties. FOWLER . Spring semester. Case studies of key Supreme Court decisions affecting the rights and freedoms of the individual in American society.\nAfrican Studies (3 hours)\nNo Africana curriculum would be complete without a beginning. These courses are intended to introduce students to the study of the Africa continent in all its wonder and complexities. The courses taken here are intended to force students to rethink some of the ingrained cultural stereotypes about the African continent, both in history and in the contemporary world. Students will be able to choose from a range of classes that include history, culture, literature, and film.\n- Anthropology 3320: Peoples and Cultures of Sub-Saharan Africa. Every 4th semester. Social and ethnological study of peoples and cultures of Africa. Traditions and modernization analyzed in light of the contract with Western cultures. Similarities and differences among societies in Africa. African cultures compared and contrasted with the West.\n- English 3160: African Literature. KIZZA. Fall or spring semesters, alternate years. A study of selections from the literature of Africa. Emphasis on historical fiction and the oral traditions.\n- History 3710: Sub-Saharan Africa to 1880. Fall semester. The partition of Africa; ideological underpinnings of imperialism; growth of colonial systems and the African reaction; colonial development and independence; apartheid; the European colonial legacy; response of traditional African social and political structures to technological modernity; nature of African cultural trends and developments.\n- History 3720: Sub-Saharan Africa since 1880. Spring semester. A study of the development of Modern Africa from the its partition; ideological underpinnings of imperialism; growth of colonial systems and the African reaction; colonial devolution and independence; apartheid; the European colonial legacy; response of traditional African social and political structures to technological modernity, nature of modern African cultural trends and developments.\n- University Honors 2190: Africa through Its Literature. KIZZA. Fall or spring once a year (limited to University Honors Program students or with approval of instructor). A study of the sociocultural, historical, and political dynamics of the continent and its peoples through reading, discussion, and analysis of African literary works by and about Africans.\nHopefully students will complete the curriculum in the order suggested. This will allow students to enter these additional classes with a firm foundation in cultural studies, allowing for a better understanding of the courses that will complete their studies. The courses in this category will also allow students to find a distinct path through the minor, whether they are interested in cultural studies, or race and gender, or even Latin American Studies.\n- Communications 3240: Race, Gender, and the Media. GAILEY. Fall and spring semesters. An upper-level course in which students investigate how the mass media helps construct popular notions about race and gender in American society.\n- English 2190: African American Literature. BRAGGS. Every semester. An examination of the development of African-American literature from the 1850s to the present.\n- English 3350: African American Slave Narrative Tradition. KIZZA. Fall semester. A study of slave narratives and the literature that influenced them.\n- History 3460: Afro-American History. Spring semester. An historical survey of Black Americans with some attention to African backgrounds; emphasis on their reactions to experiences in the New World.\n- History 3750: Colonial Latin America. ALTHOUSE. Fall semester, ever other year. Survey of Latin America beginning with contact with Spain in the 16th century until the movements for Latin American Independence in the first quarter of the 19th century.\n- History 3760: Latin America from Independence to the Present. ALTHOUSE. Spring semester, every other year. Survey of Latin American history from the movement for independence from Spain and Portugal until the present. Specific topics will include the colonial heritage of Latin America, and 20th century politics (particularly instances of dictatorship.)\n- History 4170: History of the Blues. Fall semester, every other year. Origins of the blues in the US; emphasis on historical antecedents and the social as well as economic conditions which shaped the nature and content of the music; patterns of musical migration; emphasis on various styles including Delta, Piedmont, Texas, Chicago, and West Coast Blues.\n- History 4230: Black Popular Culture. Fall semester, every other year. Presentation and inclusion of African-Americans in mainstream (Anglo-American) popular culture from 1800 to present-day: emphasis on social purpose of racial stereotyping and its importance in transmitting attitudes and social values; and critical evaluation of progression of African-Americans into mainstream culture.\n- Music 3170: Survey of Jazz. BRELAND. Fall semester. An introductory survey course in jazz from its ethnic origins, through its chronological development, to its current styles.\nThere are a number of courses taught at the university that are also appropriate for addition to the minor but, for various reasons, are not yet listed. For a course to be considered for inclusion under the minor it must contain at least 1/3 African-American content or 2/3 minority content. The intent of this rationale is to ensure that any courses included in the Minor provide an appropriate amount of material that supports the spirit of our aims as a program.\nStudents wishing to take classes that are not officially listed under the minor will need to submit a petition the records department to have these courses added.\nCourses include (but are not limited to)\n- Archeology 3280: The Archeology of Latin America. On Demand. This course is designed to familiarize students with the prehistory of their Latin American neighbors, highlighting some of the major cultural groups of Mexico, Guatemala, and Belize, including the Olmec, Maya, Zapotec, and Aztec. It will provide the foundation needed to understand contemporary Latin America, highlighting continuities between the region’s prehistoric cultures and today’s indigenous groups.\n- Art 4990: African-American Art. LINDSAY. Fall semesters. The history of African-American art from the 17th century to the present will be the focus of the course. Select artists and themes in African-American Art, as well as different approaches scholars have taken on the subject will be considered. The cultural and historical circumstances surrounding the production of African-American art - traditional and contemporary art forms - will be introduced.\n- Geography 2010: Geography of Africa. TYM. On Demand. A geographical survey of the continent of Africa by region 1) North Africa, the Sahara, and the Transition Zone; 2) West Africa; 3) Equatorial Africa; 4) East Africa; 5) Southern Africa. Physical geography (climate, landforms, biodiversity), political geography (tribal conflicts, dictators, kingdoms, colonialism), cultural and social geography (tribalism, population growth, slavery, AIDS0, economic geography (plantation agriculture, periodic markets, fossil fuel and mineral extraction) will be examined by region.\n- History 4990: Black Women’s History. Fall semester, every other year. An upper-level course, providing a foundation for understanding the central role of African American women in the history, culture and politics in the United States. We will focus on the major role that black women played in the foundation of America, through history, sociology, and popular culture.\n- Humanities 2300: Contemporary Francophone Cinema. STEINBERG. On demand. An overview of recent African films from former French colonies with attention to issues of identity, heritage, and former colonial status.\n- Music 3200: African-American Music: An Introduction. CARTER. On demand. An overview of vocal and instrumental genres rooted in the African-American experience, spotlighting African American contributions from slavery to the present."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:eacce5fc-c46d-45e5-ae8b-7829bcc81c89>","<urn:uuid:e2970a1b-e79e-4eb1-ac22-8f727bd46271>"],"error":null}
{"question":"What are the differences in alcohol content between Bell's Cherry Stout and Kessel Blond?","answer":"Bell's Cherry Stout has an alcohol content of 7.0% ABV, while Kessel Blond has a slightly higher alcohol content at 7.5% ABV. Both are relatively strong beers, with Bell's Cherry Stout being at the top of its style range for American Stouts.","context":["Do you consider a Fruit Beer to be a ‘real’ beer? Ever tried a Cherry Stout or an Apricot Wheat? Read on to find out…\n- 20. Fruit Beer\nFirst we will cover the history of the category, then take a look at the specifications of each style highlighting the similarities and differences. We then sample commercial examples of each style.\nFruits have been used in beers to provide additional aromas, flavors and as a source of fermentable sugars for centuries. Some beers that contain fruit include Fruit Lambics and are covered under specific BJCP beer styles.\nFor some fruit beers the fruit is added in the mash, or to the boil, whilst in other beers the fruit may be added to the secondary fermentation to impart different characteristics to the beer e.g. whilst ageing in oak barrels. Certain fruit beers are produced seasonally depending on when the crop of the specific fruit is ready for harvesting.\nAccording to Jamil Zainasheff in his book, Brewing Classic Styles, this should be a beer with the distinctive flavor and aroma of fruit well integrated with the beer character.\nThe following table* shows the characteristics of one style of Fruit Beer:\n|Original Gravity:||Varies with base style|\n|Final Gravity:||Varies with base style|\n|ABV (alcohol %):||Varies with base style|\n|IBU’s (bitterness):||Varies with base style|\n|SRM (color):||Varies with base style|\nThe above table shows that there are no specific guidelines as to a Fruit Beer’s characteristics more that those of the underlying style apply to the beer e.g. Ithaca Apricot Wheat is based upon an American Wheat so the characteristics of an American Wheat should be applied to this beer.\nIn the following sections we will look in more detail at each of the above Beer Styles.\nCommercial examples of this style include New Glarus Belgian Red and Raspberry Tart, Dogfish Head Aprihop, Great Divide Wild Raspberry Ale, Founders Rübæus, Ebulum Elderberry Black Ale, Stiegl Radler, Weyerbacher Raspberry Imperial Stout, Abita Purple Haze, Melbourne Apricot Beer and Strawberry Beer, Saxer Lemon Lager, Magic Hat #9, Grozet Gooseberry and Wheat Ale, Pyramid Apricot Ale, and Dogfish Head Fort. We decided to sample Bell’s Cherry Stout and Ithaca Apricot Wheat.\nBell’s Cherry Stout has the following characteristic which using the assumption that the base beer is an American Stout then it is at the top of the style for alcohol content:\n- ABV = 7.0%\nThis beer is opaque black in color with a tan head that does not last. A cocoa cherry aroma. An alcohol and tart cherry flavor with a bitter cocoa after-taste. Low carbonation with a slick mouth-feel.\nIthaca Apricot Wheat has the following characteristic which using the assumption that the base beer is an American Wheat is within style for alcohol content:\n- ABV = 4.9%\nThis beer is light golden in color with a white head. Apricot fruit aroma and flavor. Moderate carbonation with a clean dry finish.\nOur next article will look at BJCP Category 21, ‘Spice, Herb, or Vegetable Beer‘, where we will examine the two styles making up this category.\nIf you have any questions or comments about this article, please do not hesitate to contribute to the discussion below.\n* Beer Styles’ data is courtesy of BJCP.org.","Kessel Blond and Kessel 69 are produced throughout the year.\nThe three aperitif beers are always available as well.\nIn addition, a seasonal beer is brewed each season: the so-called specials. In spring, we produce the Holsbeekse Lentetripel/Spring Triple; in the summer you can try our Caroussel special; and finally, you can light up your dark winters with our Xmas special.\nThe original location Kessel-Lo still lends its name to our two standard beers. The names of our more recent beer types are connected to the current location of the brewery or to one of the several partners we have worked with to create our unique beers.\nOur aperitif beers (Gulden Delle - Ferme Framboos and Brut) are a nod to vine culture, similar to what medium dry, rosé and brut are for sparkling wine, cava or champagne.\nThe original location of De Vlier in Kessel-Lo still lends its name to this beer. Kessel Blond is a clear straw-coloured beer of high fermentation (7.5% ABV) with a thick veil and a huge white head, somewhat adhesive. The aroma is fresh, with hops, apple and citrus. After a neutral start, a fruity, sparkly taste with a hint of honey and an aftertaste of light hops hits. With taste evolution, unfiltered and unpasteurized.\nKessel 69 is an amber coloured beer of 6.9% ABV Cloudy with an adhesive white head.\nIt has a malty aftertaste and a pleasant bitterness. Taste evolution, unfiltered and unpasteurized.\nThis beer was brewed for the 40th anniversary of the association \"Men of 1969\". Leuven has a long held the peculiar tradition of forming groups around a certain year, always called \"Men of ...\". On the eve of their 40th birthday, men of Leuven unite on the base of a common birth year, regardless of religious, political or any other beliefs, creed or origin. From their 40th birthday on they are active for ten years, with congregations and participation in various activities wherein friendship and fun in life are the central value. After ten years, one passes to the \"Abraham\"-groups, to take it easy.\n(Holsbeek Spring Triple)\nTo regain strength after an exhausting winter, Brewery De Vlier provides this multigrain spring triple. This beer, made from barley, wheat and oats, has a specific aroma and a hoppy aftertaste. With taste evolution, unfiltered and unpasteurized.\nCarrousel beer was brewed for the first time at the request of cultural centre 30CC (Leuven) to celebrate the unique folk festival in Kessel-Lo on Saturday, May 14, 2011. Master brewer Marc selected four grains and some hops varieties to create a unique lager with a distinctive fresh and fruity character. The beer is made with spelt malt which adds a slight acidity to the beer. We use a new hops variety, CITRA, which gives this beer its refreshing citrus character. With taste evolution, unfiltered and unpasteurized.\nBrut is De Vlier's festive beer. Perfect as an aperitif and on festive occasions. This beer has lovely fresh acidity through a complex fermentation process. The secondary fermentation with champagne yeast creates strong carbonic bubbles and a full flavour. With taste evolution, unfiltered and unpasteurized. The excellent companion to a festive event. You are looking for an alternative to cava, crémant or champagne? Look no further, you found it!\nGulden Delle is a delicious aperitif beer. Made sour-sweet by a complex fermentation process. Made fruity by using the incredible perfume of elderberry blossoms captured in homemade elderflower syrup which is carefully united with the beer. With taste evolution, unfiltered and unpasteurized. An ideal refreshment on a hot summer day, or an excellent companion at the start of a meal. This beer is the medium dry appetizer of our three beers.\nTwo local products unite to create this unique aperitif beer! De Ferme Framboos is a farm in Sint-Agatha Rode that produces juice from its own ecologically grown raspberries, which gives this beer its distinctive flavour and colour consistency. Brewery De Vlier uses a sour-sweet beer as a base, which is gained through a complex fermentation process. Combined with the delicious raspberry juice, this results in a divine drink! The rosé-aperitif beer is the last of the brewery's trio of aperitif beers. With taste evolution, unfiltered and unpasteurized."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:a7a6760d-127c-4bee-923f-248303e93bf0>","<urn:uuid:3222201d-a65e-4e13-9c09-231c392fa440>"],"error":null}
{"question":"what consent rules do gdpr and ccpa have abt marketing cookies?","answer":"Under GDPR, any data collection including marketing cookies requires valid consent that must be specific and unambiguous through an affirmative action - implied consent is not acceptable. This applies to both new and existing users after May 25. The CCPA regulations focus more on giving consumers the right to opt-out of the sale of their personal information, requiring businesses to provide clear opt-out methods and notices, particularly through a mandatory 'Do Not Sell My Personal Information' link on their websites. Both regulations require businesses to be transparent about their data collection practices in their privacy policies.","context":["What is the General Data Protection Regulation?\nIn legal terms, the GDPR is a European Union law intended to strengthen and unify data protection rules and rights for the benefit of EU citizens. Put in other words, to give control of personal data back to the user. While great news for individuals, it presents complex problems for companies.\nThe new rules apply to all organizations (of any size) that provide goods and services to the EU or that utilize tracking technologies (like cookies or tracking pixels) to monitor EU users’ behavior.\nWhile simple in theory, the law is dense and complex and requires a comprehensive understanding of the data you collect, whether it's personal or not, how you store and use it, and how you expose or remove data upon request. To do so, you must look at every single process and line of software code to outline your data processes.\nIn most cases, your data collection will require valid consent following May 25 - not just going forward, but also from all your existing users. Under the GDPR, consent can't be implied or inferred from someone's actions. Instead, valid consent must be specific to the data being collected, by an affirmative action that is unambiguous.\nLearn more about the General Data Protection Regulation (GDPR)\n1. Personal Information - What we collect and why\nWe offer certain site features, services, applications, and tools that are available only through the use of the following tracking technologies. You are always free to block, delete, or disable these technologies if your browser, installed application, or device so permits. However, if you decline cookies or other similar technologies, you may not be able to take advantage of certain site features, services, applications, or tools.\nGenerally, these technologies allow our sites, services, applications, and tools to store relevant information in your browser or device and later read that information in order to identify you to our servers or internal systems. Where applicable, we protect our cookies and other similar technologies to help ensure that only we and/or our authorized service providers can interpret them by assigning them a unique identifier that is designed for interpretation only by us.\nThis website collects and uses personal information for the following reasons:\n1.1. Google Analytics\nLike most websites, this site uses Google Analytics (GA) to track user interaction. We use this data to determine the number of people using our site, to better understand how they find and use our web pages and to see their journey through the website.\nAlthough GA records data such as your geographical location, device, internet browser and operating system, none of this information personally identifies you to us. GA also records your computer’s IP address which could be used to personally identify you but Google do not grant us access to this. We consider Google to be a third party data processor (see section 2 below).\nDisabling cookies on your internet browser will stop GA from tracking any part of your visit to pages within this website.\nLearn more about Google Analytics.\n1.2. Google Tag Manager\nWe are constantly trying to improve the customer experience on our website by providing visitors with more personalized and targeted campaigns and offerings. To do so, we use Google Tag Manager (GTM).\nGTM is a little snippet of code that helps us track user behavior across our sites and then pushes the data to our Google Analytics account. Then, all the data is perfectly organized and ready for us to assess and review for potential site improvements and remarketing campaigns.\nWe consider Google to be a third party data processor (see section 2 below).\nLearn more about Google Tag Manager.\n1.3. Contact, signup and download forms etc.\nShould you choose to contact us using i.e. the contact/signup form on our pages or download gated content from our website, your information will be stored in our backend and collated into an email and sent to us over the Simple Mail Transfer Protocol (SMTP).\n1.4. E-mail newsletter\nOn the website of Migatronic A/S, users are given the opportunity to subscribe to our enterprise's newsletter. A confirmation e-mail will be sent to the e-mail address registered by a data subject for the first time for newsletter shipping, for legal reasons, in the double opt-in procedure. This confirmation e-mail is used to prove whether the owner of the e-mail address as the data subject is authorized to receive the newsletter.\nThe personal data collected as part of a registration for the newsletter will only be used to send our newsletter. In addition, subscribers to the newsletter may be informed by e-mail, as long as this is necessary for the operation of the newsletter service or a registration in question, as this could be the case in the event of modifications to the newsletter offer, or in the event of a change in technical circumstances.\nThe subscription to our newsletter may be terminated by the data subject at any time. The consent to the storage of personal data, which the data subject has given for shipping the newsletter, may be revoked at any time. For the purpose of revocation of consent, a corresponding link is found in each newsletter. It is also possible to unsubscribe from the newsletter at any time by contacting us.\nThe newsletter of Migatronic A/S contains so-called tracking pixels. A tracking pixel is a miniature graphic embedded in such e-mails, which are sent in HTML format to enable log file recording and analysis. This allows a statistical analysis of the success or failure of online marketing campaigns. Based on the embedded tracking pixel, Migatronic A/S may see if and when an e-mail was opened by a data subject, and which links in the e-mail were called up by data subjects.\nSuch personal data collected in the tracking pixels contained in the newsletters are stored and analyzed by the controller in order to optimize the shipping of the newsletter, as well as to adapt the content of future newsletters even better to the interests of the data subject. These personal data will not be passed on to third parties. Data subjects are at any time entitled to revoke the respective separate declaration of consent issued by means of the double-opt-in procedure. After a revocation, these personal data will be deleted by the controller. Migatronic A/S automatically regards a withdrawal from the receipt of the newsletter as a revocation.\n1.5. Website cookies\n- In connection with log-in information: \"DW_Extranet\" (only if the solution contains Extranet)\n”DW_Extranet” is a ”persistent cookie”. It contains encrypted information about username and password to the extent you are using a log-in function on the Website. The lifespan of the cookie is one month, and it will therefore be deleted one month after the last time you have used the Website's log-in function. This cookie is used to remember you when you return to the Website, so that you won't have to log in again.\n- In connection with the date of your last visit: ”Dynamicweb.VisitDate”\n”Dynamicweb.VisitDate” is a persistent cookie. it contains information about the date of your last visit to the Website and is used in connection with statistics. The cookie has a one year lifespan and it is therefore deleted one year after your last visit to the Website.\n- In connection with previous visits: ”Dynamicweb.VisitorID”\n”Dynamicweb.VisitorID” is a persistent cookie. It contains a unique ID which you have been given upon your visiting the Website. It is used in connection with statistics. The cookie has a one year lifespan and it is therefore deleted one year after your last visit to the Website.\n- In connection with current session: ”Dynamicweb.SessionVisitor”\n\"Dynamicweb.SessionVisitor\" is a session based cookie. It preserves users states across page requests.\n- In connection with each session: \"ASP.NET_SessionID\"\nThis cookie preserves the visitor's session state across page requests.\n- In conncection with statistics: \"_ga\"\n\"_ga\" is a 2 year HTTP cookie. Registers a unique ID that is used to generate statistical data on how the visitor uses the website.\n- In conncection with each session: \"_gat\"\n\"_gat\" is a session cookie, used by Google Analytics to throttle request rate.\n- In connection with statistics: \"_gid\"\n\"_gid\" is a session cookie. Registers a unique ID that is used to generate statistical data on how the visitor uses the website.\n- In connection with marketing: \"ads/ga-audiences\"\n\"ads/ga-audiences\" is a session cookie. Used by Google AdWords to re-engage visitors that are likely to convert to costumers based on the visitor's online behaviour across websites.\n- In connection with marketing: \"fr\"\n\"fr\" is a HTTP cookie stored for 3 months. Used by Facebook to deliver a series of advertisement products such as real time bidding from third party advertisers.\n- In connection with marketing: \"tr\"\n\"tr\" is a session based tracking pixel. It tracks the actions that users take on the website using both standard events and custom events.\n2. Our Third Party Data Processors\nWe use a number of third parties to process personal data on our behalf. These third parties have been carefully chosen and all of them comply with the legislation set out in the EU General Data Protection Regulation 2018 (GDPR).\n- Microsoft Office 365 (Privacy Statement)\n- Microsoft Dynamics 365 (Security and Compliance)\n3. How Long do We Store Your Information\nWe will retain your personal information for the period necessary to fulfill the purposes outlined on our 'Consent page'. You can always contact us, if you want your personal data 'erased' from our databases (see Section 6). We will respond without undue delay (and in any event within one month, although this can be extended in difficult cases).\n4. Data Breaches\nWe will report any unlawful data breach of this website’s database or the database(s) of any of our third party data processors to any and all relevant persons and authorities within 72 hours of the breach if it is apparent that personal data stored in an identifiable manner has been stolen.\n5. Data Controller\nThe data controller of this website is: Svejsemaskinefabrikken Migatronic A/S, with company number (CVR): 34485216 whose registered office is:\nPhone: +45 96 500 600\n6. Right to Access and To Be Forgotten\nPlease contact us, if you want to request access to your personal information stored in our databases, or if you want your personal data 'erased' from our databases. We will respond without undue delay (and in any event within one month from receiving your request, although this can be extended in difficult cases).\nPhone: +45 96 500 600\n7. Privacy Questions\nPhone: +45 96 500 600\nWhen a privacy question or access/download request is received we have a dedicated team which triages the contacts and seeks to address the specific concern or query which you are seeking to raise. Where your issue may be more substantive in nature, more information may be sought from you.","California’s landmark privacy regulation now has teeth\nANALYSIS Regulations to apply the game-changing California Consumer Privacy Act of 2018 (CCPA) have come into effect, granting consumers an extensive set of new privacy rights in the process.\nThe regulations fundamentally alter the privacy landscape in the US by giving consumers an extensive set of new privacy rights.\nThe CCPA went into effect on January 1, 2020, and enforcement of the law commenced on July 1, 2020.\nRecently, the finalized version of the CCPA regulations were approved by the California Office of Administrative Law.\nThese regulations, which came into immediate effect, solidify the obligation of covered organizations to ensure strict compliance with the CCPA’s statutory text and its corresponding rules.\nOverall, the final CCPA regulations parallel the original version issued by the California Attorney General (AG) in early 2020, with several notable modifications:\nOpt-Out Link Language: The finalized regulations eliminate the option to use abbreviated “Do Not Sell My Info” language in CCPA-mandated opt-out website links. Instead, businesses will need to use the lengthier “Do Not Sell My Personal Information” language in providing consumers with a link to opt-out of the sale of their personal information.\nAdditional Notice and Consent Before Using Data for a “Materially Different Purpose”: The finalized regulations eliminate the requirement that companies provide notice and obtain explicit consent before using a consumer’s personal data for a “materially different purpose” than those stated in the entity’s “Notice at Collection”.\nOffline “Do Not Sell” Notices: The finalized regulations eliminate the requirement that entities which “substantially interact with consumers offline” provide consumers with a notice of their right to opt-out via an offline method.\nStandards for Opt-Out Methods: The finalized regulations eliminate the requirement that covered entities provide an easy opt-out method for consumers that requires minimal steps to complete, as well as the corresponding prohibition on using methods that would impair a consumer’s ability to opt-out.\nDenials of Certain Requests From Authorized Agents:The finalized regulations eliminate the ability of covered entities to deny requests from authorized agents where the agent is unable to provide proof of his or her authorization to act on the consumer’s behalf.\nEnforcement of the CCPA by the California AG commenced on July 1, with a retrospective period extending to the statute’s January 1, 2020, effective date.\nNow, the CCPA regulations are also fully in effect at this time – meaning that the AG has the ability to pursue enforcement actions under both the CCPA’s statutory language itself, as well as under the regulations.\nApproval of the regulations means they are now an active obligation that must be strictly satisfied by all companies that fall under the scope of California’s consumer privacy law.\nIn particular, companies should consider the following:\n- “Do Not Sell” Links: The California AG’s office has indicated that enforcement notices have already been issued as of July 9, 2020. These are believed to relate to the CCPA’s “Do Not Sell” requirements. As such, companies that sell the data of California consumers must ensure they have active “Do Not Sell My Personal Information” links on their sites.\n- Opt-Out Notices: Companies that sell California consumers’ data should also ensure they have operational Opt-Out Notices that satisfy the requirements of the finalized Regulations.\n- Privacy Policies: In conjunction with its early enforcement actions, the California AG’s office has also been examining covered entities’ privacy policies to ensure compliance with all notice and disclosure requirements mandated by the law. Consequently, companies should review their privacy policies to ensure they satisfy the criteria set forth in the CCPA Regulations.\n- Notices at Collection: At the same time, covered entities should ensure they have operational Notices at Collection in place to provide consumers with the mandatory information specified by the finalized Regulations at all points where consumer personal information is collected.\nWith the final regulations in place, it is expected that the California AG’s office will focus its efforts on enforcement of both violations of the statutory text, as well as the finalized regulations.\nTherefore, full and ongoing compliance with the CCPA is critical."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:991c2fe9-1627-484b-9ccd-be7bab67b8ae>","<urn:uuid:0640b644-a142-4881-8b45-8af4e944cd34>"],"error":null}
{"question":"What communication challenges affected naval operations at Pearl Harbor in 1941 versus the Australian response to the I-124 submarine in 1942?","answer":"At Pearl Harbor, major communication breakdowns among several branches of the U.S. armed services and government departments contributed to the success of the surprise Japanese attack. In contrast, during the engagement with the Japanese submarine I-124 near Darwin, the Australian Navy demonstrated effective communication and coordination, responding promptly to an unsuccessful attack on a U.S. oil tanker by sending three corvettes to the scene, which successfully located and sank the Japanese submarine.","context":["Pearl Harbor is a lagoon harbor on the island of Oahu, Hawaii, west of Honolulu. Much of the harbor and surrounding lands is a United States Navy deep-water naval base. It is also the headquarters of the United States Pacific Fleet. The U.S. government first obtained exclusive use of the inlet and the right to maintain a repair and coaling station for ships here in 1887. The attack on Pearl Harbor by the Empire of Japan on December 7, 1941 was the immediate cause of the United States' entry into World War II.\nPearl Harbor was originally an extensive shallow embayment called Wai Momi (meaning, “Waters of Pearl”) or Puʻuloa (meaning, “long hill”) by the Hawaiians. Puʻuloa was regarded as the home of the shark goddess, Kaʻahupahau, and her brother (or son), Kahiʻuka, in Hawaiian legends. According to tradition, Keaunui, the head of the powerful Ewa chiefs, is credited with cutting a navigable channel near the present Puʻuloa saltworks, by which he made the estuary, known as \"Pearl River,\" accessible to navigation. Making due allowance for legendary amplification, the estuary already had an outlet for its waters where the present gap is; but Keaunui is typically given the credit for widening and deepening it.\nDuring the early 19th century, Pearl Harbor was not used for large ships due to its shallow entrance. The interest of United States in the Hawaiian Islands grew as a result of its whaling, shipping and trading activity in the Pacific. As early as 1820, an \"Agent of the United States for Commerce and Seamen\" was appointed to look after American business in the Port of Honolulu. These commercial ties to the American continent were accompanied by the work of the American Board of Commissioners for Foreign Missions. American missionaries and their families became an integral part of the Hawaiian political body.\nThroughout the 1820s and 1830s, many American warships visited Honolulu. In most cases, the commanding officers carried letters from the U.S. Government giving advice on governmental affairs and of the relations of the island nation with foreign powers. In 1841, the newspaper Polynesian, printed in Honolulu, advocated that the U.S. establish a naval base in Hawaii for protection of American citizens engaged in the whaling industry. The British Hawaiian Minister of Foreign Affairs Robert Crichton Wyllie, remarked in 1840 that \"... my opinion is that the tide of events rushes on to annexation to the United States.\"\nFrom the conclusion of the Civil War, to the purchase of Alaska, the increased importance of the Pacific states, the projected trade with the Orient, and the desire for a duty-free market for Hawaiian staples, Hawaiian trade expanded. In 1865, the North Pacific Squadron was formed to embrace the western coast and Hawaii. Lackawanna in the following year was assigned to cruise among the islands, \"a locality of great and increasing interest and importance.\" This vessel surveyed the Northwestern Hawaiian Islands toward Japan. As a result, the United States claimed Midway Island. The Secretary of the Navy was able to write in his annual report of 1868, that in November 1867, 42 American flags flew over whaleships and merchant vessels in Honolulu to only six of other nations. This increased activity caused the permanent assignment of at least one warship to Hawaiian waters. It also praised Midway Island as possessing a harbor surpassing Honolulu's. In the following year, Congress approved an appropriation of $50,000 on March 1, 1869, to deepen the approaches to this harbor.\nAfter 1868, when the Commander of the Pacific Fleet visited the islands to look after American interests, naval officers played an important role in internal affairs. They served as arbitrators in business disputes, negotiators of trade agreements and defenders of law and order. Periodic voyages among the islands and to the mainland aboard U.S. warships were arranged for members of the Hawaiian royal family and important island government officials. When King Lunalilo died in 1873, negotiations were underway for the cessation of Pearl Harbor as a port for the duty-free export of sugar to the U.S. With the election of King Kalākaua in March 1874, riots prompted landing of sailors from USS Tuscarora and Portsmouth. The British warship, HMS Tenedos, also landed a token force. During the reign of King Kalākaua the United States was granted exclusive rights to enter Pearl Harbor and to establish \"a coaling and repair station.\"\nAlthough this treaty continued in force until August 1898, the U.S. did not fortify Pearl Harbor as a naval base. The shallow entrance constituted a formidable barrier against the use of the deep protected waters of the inner harbor as it had for 60 years.\nThe United States and the Hawaiian Kingdom signed the Reciprocity Treaty of 1875 as supplemented by Convention on December 6, 1884, the Reciprocity Treaty was made by James Carter and ratified it in 1887. On January 20, 1887, the United States Senate allowed the Navy to exclusive right to maintain a coaling and repair station at Pearl Harbor. (The US took possession on November 9 that year). The Spanish–American War of 1898 and the desire for the United States to have a permanent presence in the Pacific both contributed to the decision.\nFollowing the overthrow of the Hawaiian Kingdom, the United States Navy established a base on the island in 1899. On December 7, 1941, the base was attacked by the Imperial Japanese Navy airplanes and midget submarines, causing the American entry into World War II. One of the main reasons that Pearl Harbor happened was because the United States had major communication breakdowns among several branches of the U.S. armed services and departments of the U.S. government. This led to the surprise Japanese attack at the Hawaiian air base. Even if American army and navy forces had not been surprised by the Japanese attack against Pearl Harbor on December 7, 1941, they would have been defeated just as decisively. There was no meaningful plan for the air defense of Hawaii, for American commanders had no understanding of the capabilities and proper employment of air power. As it was, had the Pacific Fleet acted on the war warnings it undoubtedly would have sortied and been at sea on December 7, where the major ships would have been sunk in deep water, making salvage impossible. Shortly after the devastating Japanese surprise attack at Pearl Harbor two American military commanders, Lt. Gen. Walter Short and Adm. Husband Kimmel were demoted of their full ranks. The two American commanders are now seeking to restore their reputations and full ranks.\nOver the years, Pearl Harbor remained a main base for the US Pacific Fleet after World War II along with Naval Base San Diego. In 2010, the Navy and the Air Force merged their two nearby bases; Pearl Harbor joined with Hickam Air Force Base to create Joint Base Pearl Harbor-Hickam.\n- Funk and Wagnalls (2014). \"Pearl Harbor\". Funk and Wagnalls new world encyclopedia: 1.\n- FDR Pearl Harbor Speech. December 8, 1941. Retrieved 2011-02-05.\nDecember 7th, 1941, a day that will live in infamy.\n- Apple, Russell A.; Benjamin Levy (February 8, 1974). \"Pearl Harbor\" (pdf). National Register of Historic Places - Nomination and Inventory. National Park Service. Retrieved 25 May 2012.\n- \"Pearl Harbor\" (pdf). Photographs. National Park Service. Retrieved 25 May 2012.\n- \"Places - The History of Pearl Harbor\". National Park Service, U.S. Department of the Interior. Retrieved Dec 22, 2014.\n- Cold Spots - Pearl Harbor\n- Burtness, Paul; Warren, Ober (2013). \"Communication Lapses Leading to the Pearl Harbor Disaster\" 75 (4). p. 20.\n- Smith, Dale (1997). \"Pearl Harbor: A lesson in air power\" 44 (1). pp. 46–53.\n- \"Remember Pearl Harbor\". Christian Science Monitor: 2. January 6, 1996.\n|Wikimedia Commons has media related to Pearl Harbor.|\n|Wikisource has the text of the 1921 Collier's Encyclopedia article Pearl Harbor.|\n- British Pathé Online archive of Pearl Harbor and related footage\n- Pearl Harbor at DMOZ\n- Pearl Harbor on The History Channel","Video: Australia Completes 3D Survey of WWII Japanese Submarine\nAustralia completed its first 3D survey of a wreck in deep waters off the coast near Darwin. It is hoped that the unique project which took three years to complete will provide critical new details about a WWII-era Japanese submarine sunk by the Australians and will also provide information for the preservation of the site which is recognized as a war grave by both the Australians and the Japanese.\nIt was January 1942, during some of the darkest days of World War II. The Japanese submarine I-124, which had been built in the 1920s, was deployed off the northwest coast of Australia laying underwater mines. The submarine was part of an Imperial Japanese Navy squadron that had been waging covert operations against Australia’s north, laying mines in waters near Darwin in a bid to intercept allied vessels and close the port.\nThe Australian Navy responded to an unsuccessful attack on a U.S. oil tanker in the region by one of the Japanese submarines by sending three corvettes to the scene. The I-124 fired a torpedo at the first ship to arrive, the HMAS Deloraine, which in turn detonated dozens of depth chargers in a sustained attack that sank the Japanese submarine. All 80 crew members died on board, with the vessel sinking between Darwin and Bathurst Island. Only weeks after the I-124 was sunk, 236 people were killed in the bombing of Darwin.\nEight decades after the corvettes deployed by the Royal Australian Navy sunk the Japanese Navy submarine I-124 on January 20, 1942, a team of researchers completed a 3D survey using specialized cameras mounted to underwater scooters. According to Northern Territory senior heritage officer and maritime archaeologist Dr. David Steinberg, a remote location, strong rides, murky waters, and depth all presented hurdles that had prevented them from previously completing surveys of the site.\nThe archeological mapping marks the first-time divers have descended 50 meters (164 feet) at the Beagle Gulf, northwest of Darwin in a bid to capture a deeper understanding of the vessel to inform future research and site management. Previous surveys have been restricted to remote sensing which provides valuable data but was limited in comparison to diving to the site.\nThe submarine was the first wreck in Australia to be protected under the Commonwealth Historic Shipwrecks Act 1976 which has since been replaced by the Underwater Cultural Heritage Act 2018. Access to the site by the public is by permit only. In 2018, former Japanese prime minister Shinzo Abe visited Darwin, and earlier this year a plaque bearing the names of the 80 submariners was unveiled at Darwin's Dripstone Cliffs as part of the measures to preserve the historical significance of the battle both to the Australian and Japanese people.\n“By sending experts down to the wreck, we give ourselves the best chance to get the most accurate picture of what happened 80 years ago, and the condition of the wreck today,” said Chansey Paech, the Northern Territory Minister for Arts, Culture and Heritage.\nHe added that the expedition is critical in understanding the role that the Northern Territory played in the defense of Australia during WWII, and will help inform how it protects and maintains the important historic site. They also hope to add to the understanding of the submarine and modifications made by the Japanese during World War II. While it was one of four vessels in a class built to lay mines, three were destroyed during the war.\nAccording to David Steinberg who led a team of archaeologists, technical divers, a filmmaker, and a cultural liaison officer on the expedition aboard Paspaley Pearls’ research vessel Marilynne, the 3D survey was able to capture accurate details on the state of the submarine and the surrounding area. He said it would provide a baseline for future study.\nThe team was also able to understand how quickly the site is deteriorating, and whether there are ways to preserve the war grave. “The level of accuracy and detail that's been captured is just remarkable with these new technologies and new advances in maritime shipwreck mapping,\" Steinberg told News Corp Australia.\n“The wreckage of the I-124 submarine is an iconic reminder of our history and this expedition will hopefully provide new information about how we can care for this site,” said Tanya Plibersek, Commonwealth Minister for the Environment and Water.\nFindings of the survey have been shared with the Japanese authorities and a container of sand from the seabed was to be shared with the families of the crew. Plans call for a documentary revealing the findings from the survey to be released next year on the anniversary of the bombing."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:ca91e1ef-3450-40a3-b7a5-72c3f288e7cf>","<urn:uuid:3e1ebf6d-8e14-4509-9ae7-a72f006cc79c>"],"error":null}
{"question":"What's the significance of bread in Persian weddings and how does air pollution affect respiratory health?","answer":"In Persian weddings, bread (nooné sangak) plays a symbolic role representing prosperity. It is specially baked in coal ovens and arranged ornately, often with congratulatory messages etched into it. It's displayed on the sofreyé aghd (ceremonial tablecloth) and shared with guests. As for respiratory health, air pollution can cause both immediate and long-term problems. Short-term effects include wheezing, chest pain, and dry throat, while long-term effects include decreased lung function, asthma, bronchitis, emphysema, and cancer. Acute respiratory infections are particularly dangerous for children, being the largest single disease category in India and enhanced by exposure to urban air pollutants.","context":["The wedding is one of the most important occasions in the Persian tradition- it is an event in which all are invited, no expenses are spared, and much feasting and merry-making takes place.\nThere are many customs and rituals observed in the Persian Ceremony Incredibly, most of the traditions of Persian weddings originated in Zoroastrian times (Zoroastrianism is an ancient Iranian religion, the first monotheistic religion in the world dating back to the 2nd millennium BCE), and have changed very little up to modern times.\nThe ceremony begins with the groom seated on a bench in front of the guests. In front of them is the sofreyé aghd, a table which contains several highly symbolic items. Above his head is a canopy held by female family members or female members of the bridal party. The bride walks into the ceremony wearing a veil. She is preceded by someone burning a special incense which is said in Persian tradition to ward off the evil eye. The bride takes a seat to the left of the groom with the groom seated on her right hand- this designates a place of respect.\nThe tablecloth in Persian ceremony is very important, it contains many symbolic elements and it is cold Sofré\nThe tablecloth is normally either on the floor on a rug to prevent slippage in an indoor wedding, or constructed on wood raised from the ground about 6-8 inches in an outdoor wedding. It is usually covered by either a simple cloth, or an elaborate cloth. Usually the bride’s mother spends several months before the wedding gathering elements of the sofré- these elements are both objects that are near and dear to the hearts of the bride and groom, and elements that contain imagery and symbolism relating to their impending union. They include the following:\nThis is the most important and most iconic part of the sofré. The mirror and candlesticks will become a part of the couple’s home as a memento of their wedding ceremony. Traditionally, the mirror and candlesticks were gold dipped or made of silver, but modern couples often opt for other materials. The mirror symbolizes eternity and the candlesticks reference Zoroastrianism, in which light and fire play an extremely important part. In this context, the fire and light represent the brightness of the future and eternal passion. The mirror and candlesticks are situated in front of the bride and groom during the ceremony, with the mirror facing the couple and away from the audience. After the bride sits on the stool beside the groom, she lifts her veil, and the groom sees her for the first time in the mirror.\nNooné sangak is a certain type of flatbread baked in a coal oven on top of coals and stones. On the sofreyé aghd, the bread is usually ornately arranged, either into a shape like flowers, or with the word mobarak (celebrate/congratulations) etched into it. The bread represents prosperity for feasts and the couple’s life thereafter.\nIn addition to this decorative bread, there is generally a tray of bread, feta cheese, and fresh herbs that are intended to be shared with the guests after the ceremony.\nThe Basket of decorated eggs- often beaded or painted gold, and various nuts such as almonds, walnuts and hazelnuts, also painted gold. These represent fertility.\nThe bowl made out of crystallized sugar often also contains more crystallized sugar (also known as rock candy) inside it. This represents sweetness in the couple’s life.\nThese are pretty self explanatory- they represent future financial prosperity for the couple.\nA basket of fruit is included- usually either anār (pomegranates) or seeb (apples), depending on the season, to represent a joyous and fruitful future for the couple.\nThis is a well designed part of the table- a tray in which seven spices of seven different colors are laid out in order to represent prosperity and spiciness of life. Each of the spices generally have a specific meaning and significance.\nDuring the ceremony, someone will walk in front of the bride holding an incent called esfand, which will then be placed on top of the sofré. Esfand is a very important element in Iranian tradition, because it has been used for thousands of years to ward away the ‘evil eye’.\nAs the bride and groom are seated before the guests, a canopy is held above their heads by several unmarried women, traditionally family members, but in modern weddings, by the bride’s wedding party. Until the 19th century, the canopy was green, the favorite color of Zoroastrians, but in recent years, it is a white piece of cloth to blend more with Western culture.\nAs the ceremony is taking place, happily married members of the family take turns grinding two sugar cones together so that the sugar granules fall into the canopy, symbolically showering the couple in sweetness.\nFlowers are used in Persian weddings to decorate the sofré, but they are also used as a symbolic sign of life, spring, and beauty.\nRosewater is extremely important in Persian culture, and it is used as perfume as well as for cooking. In this case, the rosewater is intended to perfume the air during the ceremony.\nFor religious couples, the quran is placed on the table, open to a verse about the importance of marriage. Secular couples, on the other hand, will usually display a book of poetry by one of the great Persian poets, or another book that holds a significant place in their relationship.","Sunday, 26 January 2014\nAIR POLLUTION AND HEALTH PROBLEMS\nAir is the mixture of gases that surround earth due to its gravitational pull. It is colourless, odourless and tasteless mixture that forms earth’s atmosphere. It contains Nitrogen (79.1%), Oxygen (20.0%), Carbon dioxide (0.03%) and traces of inert gases like argon, krypton, xenon, neon, helium, ammonia, ozone, water vapour and suspended particles (0.07%).\nWe need air to perform certain vital life functions. All human beings and animals breathe in Oxygen and breathe out Carbon dioxide. Plants breathe in Carbon dioxide and breathe out oxygen in the day time to manufacture their own food through Photosynthesis. But they follow the pattern of animals at the night. Without Air there would be no transmission of sound and radiation waves, no burning of fire and cycle of seasons.\nWhen the natural composition of air is altered to such an extent, so as to make it harmful for living creatures primarily due to human activities, air is said to be ‘polluted’. Any substance that causes pollution is called pollutant. Pollutants can be solid, liquid or gaseous substance.\nAir is polluted by natural ways of volcanic eruptions, forest fires, pollen from plants etc. However, nature has a way of balancing itself. Our concern here is man caused pollution which is looming largely as a threat to modern civilization. Pollution can be INDOOR as well as OUTDOOR:\nINDOOR AIR POLLUTION refers to the physical, chemical, and biological characteristics of air in the indoor environment within a home, building, or an institution or commercial facility. Indoor air pollution is a concern in the developed countries, where energy efficiency improvements sometimes make houses relatively airtight, reducing ventilation and raising pollutant levels. Indoor air problems can be subtle and do not always produce easily recognized impacts on health. Tobacco smoke, cooking and heating appliances, and vapors from building materials, paints, furniture, etc. cause pollution inside buildings.\nVolatile organic compounds originate mainly from solvents and the main indoor sources are perfumes, hair sprays, furniture polish, glues, air fresheners, moth repellents, wood preservatives, and many other products used in the house. Their main health effect is the imitation of the eye, nose and throat. In more severe cases there may be headaches, nausea and loss of coordination. In the long term, some of the pollutants are suspected to damage to the liver and other parts of the body.\nTobacco smoke generates a wide range of harmful chemicals and is known to cause cancer. It is well known that passive smoking causes a wide range of problems to the passive smoker (the person who is in the same room with a smoker and is not himself/herself a smoker) ranging from burning eyes, nose, and throat irritation to cancer, bronchitis, severe asthma, and a decrease in lung function.\nBiological pollutants include pollen from plants, mite, hair from pets, fungi, parasites, and some bacteria. Most of them are allergens and can cause asthma, hay fever, and other allergic diseases.\nFormaldehyde is a gas that comes mainly from carpets, particle boards, and insulation foam. It causes irritation to the eyes and nose and may cause allergies in some people.\nAsbestos is mainly a concern because it is suspected to cause cancer.\nRadon is a gas that is emitted naturally by the soil. Due to modern houses having poor ventilation, it is confined inside the house causing harm to the dwellers.\nOUTDOOR AIR POLLUTION is the pollution that occurs outside homes through automobiles, industrial emissions etc.\nMAIN AIR POLLUTANTS AND THEIR IMPACT ON HEALTH\n1) Oxides of sulphur 2) Oxides of Nitrogen 3) Suspended Particulate Matter 4) Carbon Monoxide 5) Lead 6) Benzene 7) Hydrocarbons\nHealth impacts of air pollution depend on pollutant type, its concentration in air, interaction with other pollutants, and length of exposure and individual vulnerability.\nAir Pollution has both acute and chronic effects on Human health. It has both long term and short term effects. It may range from minor irritation to most chronic respiratory problems.\nIMMEDIATE HEALTH PROBLEMS FROM AIR POLLUTION\nØ Aggravated cardiovascular and respiratory problems\nØ Burden on heart and lungs, causing them to work harder to supply the body with oxygen\nØ Damage the cells in respiratory organs\nØ Damage to deeper portions of lungs, even after symptoms of coughing or sore throat disappear\nØ Wheezing, chest pain, dry throat, headache or nausea\nØ Increased reactivity to allergens and particles\nØ Eye irritation\nØ Reduced body immunity to infection and increased fatigue\nLONG TERM EFFECTS OF AIR POLLUTION AS PERMANENT HEALTH PROBLEMS:\nØ Accelerated ageing of lungs and loss of lung capacity\nØ Decreased lung function\nØ Diseases like, asthma, bronchitis, emphysema and cancer\nØ Is a potential cause of human mortality\n1. Acute respiratory infections (ARI) in children: ARI in children under 5 years in\ncause: 13% of deaths; 11% of NBD; 24% of NBD for children under 5 years\n(NBD- National Burden of Disease) India\nARI is the largest single disease category for\n, accounting for about\none-ninth of the national burden. For the world as a whole, ARI is\nalso the largest category, accounting for about 8.5% of the global\nAcute respiratory infections as pneumonia, is one of the chief killers of children in Developed Countries. It is well known to be enhanced by exposure to urban air pollutants and indoor environmental tobacco smoke at levels of pollution that are some 10-30 times less than that typically found in villages.\nA recent study of 642 infants conducted in urban slums of\n. The incidence of acute respiratory\ninfection was more in highly polluted areas than less polluted areas. In New Delhi , children\nhave to bear the double the burden of diseases that have persisted for\ngenerations as well as of new diseases caused by various environmental factors. India\nAsthma: Asthma causes: 0.2% of deaths; 0.5% of NBD in\nAlthough Asthma rates are officially low in India , there is some recent\nevidence that the true prevalence is higher than previously thought.\nAssociated with urban outdoor pollution and ETS (Environmental Tobacco smoke),\ntypical solid-fuel indoor smoke exposures are much higher.\nUndoubtedly, the rates of Asthamatic patients have been increasing; it might be\ndue to increase in the environmental pollution.\n2. Chronic obstructive pulmonary disease: Today in developed countries, nearly all cases of COPD are attributable to tobacco smoking. Undoubtedly, smoking is also a significant factor in COPD incidence among LDC (Less Developed Countries) men. In\n, even though\nrelatively few rural women smoked during the past decades, COPD in\nrural women today is not uncommon. Chronic obstructive lung disease, for which\ntobacco smoking is the major risk factor remaining in the developing countries\nis known to be an outcome of excessive exposure to air pollution. India\n3. Cancer: There are many chemicals in biomass smoke, which are carcinogenic in nature. In recent study in Japan on the other hand, found that women aged 30 years old cooking with wood fuel have an 80% increased chance of having lung cancer in later life.\nhas a larger\nfraction of its national burden of disease attributable to TB than any other\nregion, although the actual risk per person is less than that in\nSub-Saharan Africa. A large scale survey in India reported that women using bio\nfuels were three times more likely to have tuberculosis than women using\ncleaner fuels. India\nhas a larger burden of\nblindness than any other major region of the world. Indeed, globally, one out\nof three cataracts occurs in India where they are responsible\nfor 80% of blindness in the country. One case-control study in India found an excess\ncataract risk of about 80% among people using biomass fuel. Delhi\nThe Health Information of India reports show that environmental reasons are increasingly responsible for increased mortality in women and children (see graphs: What kills India’s children). According to the report, 55 percent of child mortality in\nis due to conditions originating in the prenatal period. A significant\nproportion of the tables are strongly related to environmental causes. India"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"}],"document_ids":["<urn:uuid:aa19b316-0f64-45a6-a1fc-98f33d2cc330>","<urn:uuid:942ceabb-30d0-410d-a36e-2802ecd24954>"],"error":null}
{"question":"How do the propagation strategies of waterlilies compare to those of Pilea Peperomioides in terms of their environmental triggers?","answer":"Waterlilies and Pilea Peperomioides show distinct responses to environmental conditions during propagation. Waterlilies can propagate through both sexual reproduction (pollination) and various forms of vegetative propagation, with some species like Nymphaea micrantha producing plantlets from leaf centers. The formation of these plantlets in tropical hybrids can be triggered by leaf decay or removal from the parent plant. In contrast, Pilea Peperomioides' propagation is strongly influenced by temperature and seasonal changes. It grows most vigorously during hot months (spring to fall) with temperatures between 65-75 degrees Fahrenheit, while its growth significantly slows during cold months. Both plants require specific light conditions - waterlily plantlets need proper growing conditions and light for development, while Pilea requires bright, indirect light to avoid burning and withering of the cuttings.","context":["Life will find a way, as Jeff Goldblum’s character in Jurassic Park famously said. The need to reproduce is a basic motivation that drives all life on Earth, and modern aquatic plants have demonstrated this better than most of Earth’s other creatures. In fact, they have found several ways, which I’ll shine a light on here with a couple of examples of plants for which even two reproductive strategies are not enough.\nThe two forms of reproduction used by most aquatic plants are classic sexual reproduction, or pollination, and one or many forms of vegetative propagation. Vegetative propagation is a broad category describing various forms of asexual reproduction, resulting in the creation of clones of the parent plants.\nThe most common forms of natural vegetative propagation that we see in the pond trade involve the formation of tubers, (e.g., Nelumbo, tropical Nymphaea) stolons and runners (e.g., Nymphoides) and rhizomes (e.g., hardy Nymphaea, iris and Typha).\nSexual reproduction is a superior method of propagation, because the population benefits from the exchange of genetic material. Greater genetic diversity leads to greater resistance to disease and adaptability to changes in the environment. Conversely, most forms of vegetative propagation simply produce clones of the parent plant. This offers the plant a faster strategy to colonize an area with good growing conditions and allows it to produce fewer but larger offspring with a higher likelihood of reaching maturity than seedlings. But, this comes at the cost of possibly reducing the genetic diversity of the overall population. By taking advantage of both sexual and vegetative methods, plants can establish themselves quickly in a particular area, maintain genetic diversity and extend their range to new areas.\nFor those who produce cultivars of waterlilies or lotuses with very specific characteristics, vegetative propagation is a major key to maintaining the purity of a cultivar. Another vegetative strategy we growers may exploit is a fascinating process known as vivipary. There is more than one definition of vivipary in the world of botany. The narrower definition describes true vivipary as a form of sexual reproduction whereby germination takes place while the seeds are still attached to the parent plant; pseudo-vivipary, on the other hand, is the formation of plantlets in place of sexual reproductive structures. The wider definition, which I will focus on in this article, includes any scenario in which plantlets are formed while still attached to the parent plant.\nIn addition to the production of tubers or rhizomes, some species of waterlily also create fully formed plantlets from either the leaves or the flower.\nNymphaea micrantha is an African waterlily species that produces plantlets from the center of the leaves. These plantlets start from a small, gelatinous nub at the center of the leaf. N. micrantha utilizes this strategy to such a degree that the plantlets even produce plantlets of their own while still attached to the parent plant.\nMore than 30 tropical waterlily hybrids employ this method of propagation to a lesser or greater degree, and all those are descendents of N. micrantha. Some popular examples are N. ‘Lindsey Woods’, N. Panama Pacific, N. ‘Daubenyana’ and N. ‘Margaret Mary.’\nIn hybrids, production of these plantlets seems to be triggered by the decaying of the parent leaf. Plantlet formation can even be induced by removing the leaf from the parent plant. With the right growing conditions, this can be used as a viable way of propagating certain hybrids. Sean Stevens describes a method where the leaves are removed from the parent plant and placed on the bottom of a 35-gallon propagation tank under artificial lights. He reports that the plantlets started developing within days, and in just a few weeks’ time, they were large enough to be transferred to individual pots.\nSome hardy waterlily cultivars display a form of vegetative propagation that more closely resembles pseudo-vivipary. These plants produce plantlets directly from the flower. Two slightly different forms of this have been observed.\nIn the first form, the plantlet grows from the side of the flower bud. In this case, the plantlet starts to form before the parent flower even opens. What I have found in observing this behavior in N. ‘Colorado’ is that these plantlets often form blooms of their own before they form roots or leaves. The parent flower’s ability to produce pollen and seed does not appear to be inhibited.\nIn the second form, the plantlet grows from the center of the bloom. In this case, the reproductive parts of the flower are modified, and the development of the plantlet replaces the flower’s ability to produce pollen or seed.\nMany of the hardy hybrids that use this strategy can be directly or indirectly linked to Nymphaea mexicana. N. mexicana has been observed to produce plantlets off the flower, but it is very rare. The hybrids that don’t have a clear link to N. mexicana are descendants of N. ‘Colonel A.J. Welch’ or N. ‘Perry’s Fire Opal.’ Unfortunately, according to the Water Gardeners International (WGI) list of names, both of these varieties have gaps in their genealogy.\nSome examples of hybrids that have exhibited this behavior are N. ‘Barbara Dobbins’, N. ‘Cherokee’, N. ‘Georgia Peach’, N. ‘Innerlight’ and N. ‘Colorado.’\nThe Big Question\nSo, what triggers this behavior? Can it be induced, as it is in tropical hybrids? It is not commonly observed in any naturally occurring species of the subgenus Nymphaea. The one species that this has been recorded in appears to exhibit this behavior far less frequently than the descendant hybrids. This is the opposite with N. micrantha, which propagate from the leaves more readily than its descendants. This could mean that the formation of plantlets from the flowers in hardy waterlilies is more of an artifact of hybridization than a naturally developed strategy.\nThis is not to say that this strategy doesn’t occur in the wild. Pseudo-vivipary off the flowers in waterlilies has been observed in N. lasiophylla and N. prolifera; however, these tropical species are in the subgenus Hydrocallis and are not known to have been used in propagation. In both N. lasiophylla and N. prolifera, this vegetative propagation replaces sexual reproduction to the point where these plants in the wild rarely produce seed. Instead, they produce several generations of clones without leaving the parent plant.\nWithout knowing what triggers vivipary in hardy lilies, it is less likely to be a reliable propagation method for growers. I am currently experimenting with some N. ‘Colorado’ plantlets that were removed from the parent plant at different levels of development. These plantlets don’t seem to develop any substantial roots while still attached to the parent plant, so because of this, they don’t get established as easily. One curious thing that I’ve noted is that the first flower of the plantlet often doesn’t look like N. ‘Colorado.’\nSeveral species of the sedge family (Cyperaceae) also exhibit alternate propagation strategies where new plantlets are grown from the base of the inflorescence or from the stems.\nUmbrella palms Cyperus alternifolius and C. involucratus, Dwarf Papyrus (Cyperus isocladus) and Giant Papyrus (Cyperus papyrus) will produce new growth from the base of the inflorescence. This occurs mainly when the inflorescence is brought in contact with water. It’s not necessary to remove the stem from the parent plant to trigger this behavior. In C. isocladus, I have even seen it occur when the stem was merely bent down without actually touching the water.\nA different member of the Cyperaceae family uses a slightly different strategy. Dwarf Bamboo (Dulichium arundinaceum) creates plantlets along the stem when floated in water. The plantlet will sprout from between the segments of the stem.\nTo encourage this behavior, simply bend the stems downward so that at least part of the stem is floating horizontally. Once the new plantlets have formed, the parent stem can be cut off and pushed gently or slightly submerged into wet soil.\nSeveral species of the genus Nymphoides are also known to propagate viviparously by production of plantlets from leaves separated from the parent plant. This is part of why N. peltata (floating heart) can be so invasive and difficult to remove in earth-bottom ponds. The native water snowflake (N. cordata) also exhibits this behavior.\nThese propagation strategies allow aquatic plants to multiply quickly and take advantage of good growing conditions. It is not surprising that these plants have gotten so creative. In a natural environment, good growing conditions can be limited by many factors, such as water depth, clarity, temperature, sunlight, nutrients and predation. Plants are constantly jockeying for position, especially at the water’s edge, and they use these vegetative propagation strategies to try to outcompete their neighbors. As growers we can use these behaviors to our advantage, and we may even enhance or inhibit them through hybridization.","How To Propagate Pilea Peperomiodes\nPilea Peperomioides, commonly known as the Chinese money plant, is a houseplant known for its medicinal properties. As an erect plant that requires little maintenance, its ideal growing season spans from spring to fall.\nMost people grow it as a houseplant for its visually appealing coined-shaped leaves, measuring up to 4 inches in diameter. The plant has its roots in China’s George Forest, which surrounds Cangsgan mountain (with altitudes ranging from 5,000 to 10,000 feet.\nWith the easy-to-follow tips discussed in this guide, you can get yourself started with pilea propagation.\nAs a succulent, evergreen, and perennial plant, the Pilea Peperomioides grows up to 12 inches in height with the ability to expand its width. The plant thrives in temperate and tropical regions across the globe.\nIt is part of the Urticaceae family, which includes about 600 to 715 flowering plants mostly grown as houseplants.\nConditions Required to Propagate Pileas\nSince they require minimal watering, pilea plants can thrive and continuously grow new leaves in hot months.\nWhen the cold months approach, their growth significantly slows down. It’s advisable to propagate the plant in containers before the spring season reaches. All you need for pilea propagation is the stem cuttings.\nWith relatively brittle stems, pileas are easy to propagate. Use the tips of new branches when propagating for a more compact, bushy plant. Observe the following conditions for the cuttings to thrive:\nUse a moderately rich, well-draining mix to propagate your pilea cuttings. A mix designed for African violets or a pear moss potting mix combined with perlite and leaf mold may be ideal. Soggy soil may lead to root decay and kill the cuttings.\nBright, indirect light is ideal for pilea propagation. The cuttings may burn and wither when exposed to direct sunlight. Rotate the container twice or thrice a week to allow the shoots to receive adequate light.\nThough the plant can survive under dimly-lit conditions, its foliage may become leggy and turn a darker green.\nTemperature and Humidity\nPilea plants grow well in temperatures above 50 degrees Fahrenheit. Since Frost is detrimental to the plant, the indoor temperatures for pilea propagation should range from 65 to 75 degrees Fahrenheit.\nGrow the cuttings away from the vents, which tend to blow hot or cold air. Pileas thrive in moderate to high humidity conditions.\nWater the plants when the first inch of the potting mix completely dries out. If the leaves start dropping, it may be a sign that the plants require watering. Water more often in hot weather since the soil tends to lose moisture faster.\nThough watering isn’t necessary during winter, you should always check signs of moisture loss in the soil.\nOverwatering may weaken the stems or make the plant droop. These signs may also show when the soil completely lacks water.\nAerate the soil before watering to allow it to breathe and make it easier for moisture to evaporate. Loosen up the soil particles using a stick as a way of aerating them.\nYou won’t need fertilizer when propagating pileas outdoors. However, you have to propagate them in the ideal growing zones for this exception to work in your favor.\nUse a specialized liquid fertilizer when propagating the cuttings in containers. Apply the compound at half strength and mix it correctly with the soil.\nBesides knowing the conditions for pilea propagation, it’s also important to understand the different pilea varieties. These varieties differ based on the size and shape of the leaves and their ability to spread. They include:\n- Pilea Microphylla – Also known as gunpowder plant, artillery plant, or rockweed, this plant features light green foliage with relatively tiny leaves.\n- Pilea Mollis – Also known as the “moon valley pilea,” this variety features sawtooth-edged chartreuse leaves. Their leaves have a deep texture that resembles the valleys and craters on the moon.\n- Pilea Nummularifolia (also known as creeping Charlie) – This pilea variety spreads fast and has medicinal benefits.\n- Pilea Cadierei – Commonly known as watermelon pilea or the aluminum plant, this variety has dark green, oval-shaped leaves with silver patches that give it a metallic look.\n- Pilea Peperomiodes – The Chinese money plant has round, coin-shaped, and dark green leaves on erect stems.\n- Locate Small Offsets\nYou’ll need small offsets for pilea propagation. Locate them at the base of the houseplant or below the central stalk.\nIf you can’t find any, give the plant some time to grow them. It usually takes two to three weeks for new offsets to sprout up from the base.\n- Cut an Offset from the Base\nOnce you locate the offsets, use a sterile blade to cut them at the base. Contaminated razors may transfer disease-causing organisms to the mother plant, leaving it vulnerable to withering or dying.\nLeave the mother plant with at least two offsets. If the blade gets stained, sanitize it before using it again.\n- Place the Cuttings in Water\nImmerse the cuttings in a jar or glass of water after extracting them from the mother plant. Place the shoot or stem in water leaving the leaves to hang freely in the air. Leaves tend to rot when submerged in water.\n- Give the Offsets Adequate Time to Grow\nStore the submerged offsets in an area with indirect bright light. Changing the positioning twice or thrice a week will help keep it fresh and the roots will start to sprout after two weeks.\n- Transfer the Plants in a Small Pot\nPlease wait until the plants’ roots grow to about an inch in length before transferring them to a small pot.\nThe pot should have fresh well-draining soil to support the young plants. Water the soil for a few weeks until shoots start appearing.\nThe Bottom Line\nSince they’re easy and quick to propagate, pileas are a great addition to every office or home. You’ll need a place with indirect bright light and well-draining potting soil for pilea propagation.\nIt’s also important to water the young plants moderately to avoid root rot. Keep fully grown pilea plants from small children and pets to avoid poisoning.\nPhoto by Markus Spiske on Unsplash"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:31a07eae-a315-4777-9b32-2742e2164250>","<urn:uuid:df661730-2019-4cec-b3df-40798f3d119d>"],"error":null}
{"question":"What are the requirements for registering as an external company in South Africa, and how can SEO optimization help promote such a business?","answer":"An external company must register with the South African Companies Register in Pretoria and appoint a South African resident authorized to accept communications, a registered local auditor, and establish a head office in South Africa. For SEO optimization, the business needs to focus on three key areas: On-Site SEO (ensuring relevant content with proper keywords and formatting), Off-Site SEO (building quality backlinks from reputable sources), and Technical SEO (maintaining website usability, speed, and mobile compatibility). The website must be properly coded to allow search engines to crawl it effectively and recognize it as a legitimate business.","context":["Let`s say this right away: there is no such thing as a “better” business structure. Branches of foreign companies are covered by the Companies Act 1973 and must be registered as “external companies” with the South African Companies Register in Pretoria. An external company is not required to appoint a local board of directors, but must appoint a South African resident authorized to accept litigation services and communications provided to the company. It must also appoint a registered local auditor and establish a head office in South Africa. If you are not a South African citizen, you can still register a business. Take a look at the following blog post we did: Foreigners in South Africa This can be done online through the Companies and Intellectual Property Commission (CPIC) and requires you to create a client account and deposit ZAR 400 into the CIPC bank account, then complete and submit several forms and a copy of the company`s incorporation documents (founding judgment, etc.). Other documents include: a certified copy of the applicant, a certified copy of identity or passport of all founders, directors and representatives, and a power of attorney (if applicable). The company must be registered with the South African Companies Register through the Companies and Intellectual Property Commission (CIPC) within 21 days of the company being incorporated. A company is constituted by the filing of a certificate of incorporation (CoR 14.1) and a deed of incorporation (CoR 15.1 A-E) and, where appropriate, other supporting documents depending on the company. These forms can be downloaded from the CPIC website. You need to determine which business structure is best suited to your company`s establishment and goals.\nRegistering a business in South Africa has become so easy – the need to leave your home and queue endlessly has long since disappeared in our technologically advanced world. Below, we`ve outlined a step-by-step tinkering on how to easily register your business through the Companies and Intellectual Property Commission (CPIC) website portal www.cipc.co.za. Public companies must have at least three directors. Only listed companies can be listed on the Johannesburg Securities Exchange. Public limited companies must be audited and prepare audited financial statements, which are presented annually to their shareholders. Depending on the size of the listed company, the company may also be required to have an audit committee and a social and ethics committee. However, there is a business structure that would be most beneficial for your specific business. A foreign company that does not wish to establish a subsidiary in South Africa may want to set up a representative office or branch instead. While there are important differences between these types, there is no appropriate distinction between the registration of a representative office and that of a branch. Thus, both would have the same basic steps. 5. Private companies: They are similar to what used to be called tight companies.\nChanges to private companies include fewer disclosure and transparency requirements, which are no longer limited to 50 shareholders, and a board of directors that must consist of at least one director. The name of a private company must end with the term “Proprietary Limited” or “(Pty) Ltd”. When you register a company on the CPIC website portal, you have the option to create a standard incorporation protocol (MOI) or a custom incorporation protocol. The MOI contains the “rules” of the company, how decisions are made and how the company is structured. For the purposes of this article, we will only deal with the registration of a company with the standard MOI. 1. Not-for-profit corporations: A corporation incorporated for charitable purposes or any other purpose related to one or more cultural or social activities or community or group interests. First, your business should have a name. Choosing a clear and powerful name also requires huge marketing and branding efforts. A name that shows the relevance of what is offered or provided should also be kept in mind – if you simply call your IT business “Sparkle & Shine”, customers could be terribly confused as to the services your business offers! ICPC and Interior exchange information.\nOnce an identification number is added to the site, the person`s first and last name will be displayed. If the person was recently married, the maiden name will likely still be displayed, as CPIC and Home Affairs may take some time to update their systems. The married person must have requested the new ID, received the new ID (not a temporary ID), and then you can submit the check-in. It will be on the old last name, but then you can request a change of director to solve this problem. Alternatively, you can wait for the last name to play properly, we have found that it takes some time and you will not be notified. Home Affairs also “says” cipc if a person is blacklisted, he will not be able to be an administrator during a company registration if this is the case, the system will not allow you to click Next. Yes, it`s as simple as that. Our management consultant also reminds you of important dates and extensions.\nYour business registration must be renewed one year after your first registration (through annual reports) – this is required by law by the South African government and we can help you through this simple process. State-owned enterprises are corporations like municipalities, public companies are large corporations that want to sell their shares to the public on the stock exchange, and personal liability companies only apply to very specific professionals such as doctors, lawyers, engineers, accountants, etc. A joint-stock company can only be registered by e-mail. Therefore, this step is optional, but still recommended. For this process, a proposed name is reviewed, approved and reserved. This procedure verifies that the proposed name is not already entered in the register of names. Whether you`re making a profit or you`re the size of your business, there are advantages to registering your business in South Africa. These include company name protection, tax incentives, financial support and corporate compliance. Note: The transfer of the reserved name does not result in an extension of the validity period of the reserved name (the initial validity period only applies to another customer code) or a change of company name. Although our research revealed that many sources were talking about this step and the registration requirement, there was no information on registration costs and processing time. This is probably because the process will depend entirely on the local district council. Domain name registration should be part of your trademark protection process.\nIn short, SEO refers to how you make it easier for Google to identify your website. This makes it easier for Google to see when your site is relevant to the specific services or products that users are looking for. All members, signatories and/or any other person who may act on behalf of the private company must provide the same information and documents as indicated above, as well as written confirmation that they are authorized to act on behalf of the CC. If you`d like to speak to a professional who will guide you through the process of registering your business, you can join Startwise. Startwise is an online consulting platform designed exclusively for South African SMEs to have access to experts in their field to help you in all aspects of starting your own business. Yes. Under CPIC, a corporation may be registered under the Companies Act, 2008, with or without a company name. A registered company without a reserved name will continue to receive a registration number, which automatically becomes the name of the company. For foreigners who want to do business in South Africa, there are a number of types of businesses, including branches and subsidiaries. Representative offices or outsourced non-revenue-generating operations are not part of a formal process and therefore effectively fall under the same process as a branch, but with lower tax obligations. Once you`ve decided which business structure is best for you and what your new business name will look like, the next step is to reserve your business name.","Search Engine Optimization (SEO). What is it and why is it important? At its most basic, SEO is the process of ensuring the content on your website is relevant to the people you want to visit your site.\nIf we dig a bit deeper, it’s about optimizing all content on a website, evaluating all sources that lead to a website, and ensuring an overall positive website experience. These are known as On-Site SEO, Off-Site SEO, and Technical SEO, respectively. Optimizing these aspects of your website improves the website’s relevance as evaluated by search engines. Because the goal is for search engines (Google being the most common) to send people to your website, SEO helps ensure the search engine’s algorithms view your website as worthy of traffic. For the purposes of the examples below let’s assume you are a food blogger.\nOn-Site SEO is the tactic that is familiar to most people. Write content, use some keywords, get traffic. Right? Years ago this would have sufficed. As tech gets more sophisticated and our digital needs evolve, algorithms are constantly changing to dig much deeper. The words you use are still important but how you use them, how you stack up compared to other websites using the same terms, and how you apply that content to your website has become increasingly important.\nLet’s say you, the food blogger, and a competitor both wrote similar articles about the pros and cons of cooking in cast iron. You made sure to use the term “cast iron” in your page title, you’ve used additional relevant context in your header tag, and your article is comprehensive but formatted for easy reading (not too long, not too short) and you’ve used rich images that each have clear descriptions. Your competitor has a catchy but ultimately irrelevant page title, forgot to include a header tag, utilized low-quality images, and their article veered off-topic multiple times. When a search engine reviews both articles, it will easily be able to put your article into context and understand what to show to a prospective viewer. Your page will show up higher on the search results page when someone searches for cast iron because you optimized your content.\nOff-Site SEO is the evaluation of what other websites are sending traffic to your website; these are called backlinks and they have become increasingly important as it has become easier to buy links and traffic.\nFor example, let’s say the magazine Bon Appétit loves your mashed potatoes recipe and publishes a link to your blog in a “Thanksgiving Favorites” online article. That website is highly relevant, produces a lot of original content, and Bon Appétit has a high SEO ranking. That traffic will increase the amount of confidence that a search engine has in your website. On the other hand, have you ever clicked on a recipe link on Facebook only to be brought to a website where you need to click on yet another link to get to the actual recipe? These are considered link farms and are not highly regarded; they fall more into the spam (no food pun intended) realm. Having too much traffic coming from spammy sources can lower your authority in the eyes of a search engine. There are a variety of off-site tactics that SEO experts use, both to increase links from reputable sources as well as disavow links from sketchy sources.\nTechnical SEO is all about ensuring a website is usable. In this fast-paced world, your website needs to load quickly, provide a good user experience on a cell phone, be secure, and be seen by search engines. These are just a few of the many aspects of technical SEO. This is the tedious work that gets overlooked too often.\nHow much authority would you have as a food blogger if you published a recipe for chocolate chip cookies and didn’t include chocolate chips? How successful would your website be if you didn’t categorize the recipes by type or include a table of contents menu? That’s how search engines evaluate a website. Your website needs code that tells search engines that your website is open for business. When search engines crawl your website, they need to be able to see that your website is user-friendly, organized coherently, and has active pages associated that don’t contain error messages.\nSEO efforts are an integral part of any comprehensive marketing strategy but can often get overlooked and underestimated because SEO does not require any actual paid media. It’s also a long play and a constantly moving target. In a world where digital marketing strategies can produce instant results, it can be difficult to wait months to see the results of optimization only to have Google make a big algorithm shift. Those algorithm shifts, however frustrating, are why employing an agency with SEO expertise should always be part of any marketing strategy."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"}],"document_ids":["<urn:uuid:1cd7265a-370f-4170-95b6-51a359b8dfd6>","<urn:uuid:87ffd34b-2036-497f-afb9-1d805b4a4405>"],"error":null}
{"question":"What's the seasonal diving conditions like in Phuket vs Maldives' Noonu Atoll?","answer":"In Phuket, diving is year-round but varies by season: November-February has cooler weather and is the main tourist season; March-May is hottest with flat seas and big fish sightings; June-August has more wind and rain; September-October are the wettest months. In Noonu Atoll, diving is also possible year-round, but the calmest conditions occur during the northeast monsoon from January to May. Water temperature in Noonu Atoll stays between 27-30°C with visibility between 10-20 meters.","context":["How to dive Phuket\nLast week we convinced you why to dive in Phuket. Now lets get down to details.\nWhen to dive Phuket\nPhuket is an all year round destination and local diving day trips run 365 days of the year.\nThat being said there are different seasons:\nPhuket diving seasons:\nNovember to February: North east winds provide cooler (but still hot) weather. Dry and sunny days. This is the main tourist season, especially around Christmas and New Year.\nMarch to May: These are the hottest months, it gets really humid. But there is no wind and the sea is flat so it’s great weather to be on the dive boat. This is typically the time of year when the most big fish are sighted, like manta rays and whale sharks. The weather is mostly dry. The rainy season can start from about mid April on, but normally just short tropical downpours that bring relief from the heat. Similan / Surin Island diving is possible until mid May, the national parks close to tourists on the 15th.\nJune to August: As the monsoon changes from north east to south west we get more find and rain in Phuket. The weather is cooler. The gentle ripples on Phuket’s west coast beaches are replaced by breakers just big enough to surf on. At this time of year the diving can be awesome, but you can also be unlucky and get a week of bad weather. The big advantage is fewer boats, and fewer divers on the boats. Hotel rooms can also be found at bargain prices.\nSeptember to October: These are the wettest months. You might get lucky with great weather. But you might not. The wind normally starts to change back around from the north east by mid October. The Similan and Surin Islands national parks open again on October 15th.\nWhere to stay in Phuket\nYou could stay at any Phuket hotel and still dive Phuket’s local dive sites. By local dive sites we mean the trips that depart from Chalong pier to the Racha Islands, Phi Phi Islands, Shark Point, King Cruiser Wreck and Koh Doc Mai.\nHowever many people do not realize that Phuket is quite a big and developed island with some serious traffic issues, so if you stay in north Phuket it could take you an hour to drive down to Chalong pier in the south, and there will be an extra charge for the service.\nFor convenience it’s best to at one of Phuket’s southern beaches like Kata or Naiharn. Chalong bay is ideal if you will be diving for multiple days, then you can just walk to the pier each morning. Chalong bay has plenty of nice bars and restaurants for evening dining and entertainment. It’s also the hub for dive centres and scuba equipment retailers. What Chalong lacks is a nice beach so if you are just planning a couple of days diving and want to spend the rest of your holiday on the beach then you would be better staying elsewhere.\nThe exception to the above is if you choose to do diving day trips to the Similan Islands and Koh Bon. These trips depart from Khao Lak so it’s a long transfer in the morning from Phuket. The further north on Phuket island you stay, the less time you will spend sat in a minibus. If possible we recommend diving the Similan and Surin Islands by liveaboard, it’s an all round better experience.\nPhuket day trip diving itinerary\nDay trips are full days with 2 to 3 dives per day. Breakfast and lunch is served on board.\nThe say starts with pick up by air conditioned minivan from your hotel reception. For trips departing from Chalong these are the approximate pick up times from hotels around the island:\nPick Up Times\nMai Khao/Nai Yang 06:30 am\nBang Tao/Laguna 06:45 am\nKamala/Phuket Town 07:00 am\nPatong 07:15 am\nKaron 07:30 am\nKata 07:40 am\nRawai/Nai Harn/Chalong 07:50 am\nIf you have your own transport you can also make your own way to the pier and meet there.\nWhen all guests are at the pier your guide will direct you onto the shuttle bus that will transfer you to the end of the pier where you will board the boat.\nThen it’s time for the briefings. There will be a boat and safety briefing as well as crew introductions. The dive briefing comes later, when you are closer to the dive site.\nPhuket dive sites are around 1 – 2.5 hours boat ride from Chalong pier. Dive boats cruise at 8-10 knots, they are comfortable with shaded areas, sun bathing areas, a saloon, toilets and fresh water showers.\nOn the journey out to the dive site you have time to set up your dive gear and chat with your divemaster and fellow instructors. You are expected to set up your own dive gear, we like to see if you know how. But if you need any help you will get it. A light breakfast is provided in case you missed it at your hotel. Tea and coffee are also available.\nAbout 20 minutes from the dive site there will be a dive briefing. The first briefing of the day is the longest as it will include all the boat and safety procedures, signals and so on. The briefing may be conducted by your guide to just your group, or the tour leader to the boat as a whole.\nThen it’s time to kit up and do buddy checks. By the time you’ve done that you’ll be at the dive site.\nAll Phuket dives are guided by qualified divemasters. Dive groups are 4 divers per 1 divemaster and divers are grouped based on experience.\nEntry into the water from the boat is by giant stride off the large rear platform.\nIn normal conditions your DM will wait until all divers are together on the surface and give the signal for descent. Occasionally if the sea is choppy or currents are strong it may be necessary to descent more quickly, your guide will give full instructions.\nMost descents are free descents without a line. Ascents at the end of the dive are also free ascents. All diving is no decompression diving within recreational limits. All dives end with a safety stop at 5 metres. Divemasters use a safety balloon to signal their position so it’s best to ascent close to them.\nEntry back onto the boat is at the rear platform. There are large ladders making it pretty easy and the crew are there to help. You will take your tank back to it’s location and secure it in place. You do not need to change your tank to a fresh one, there is a compressor on board and crew will fill the tanks during the surface interval. Make sure to keep all your bits together, like your fins and weighbelt. There are fresh water rinse tanks for cameras.\nSurface intervals are at least one hour. Normally the boat will be cruising to the next dive site during that time. Time to relax , check the fish ID books and fill in log books. Lunch will be served between dives, either after the first or second dive depending on the day.\nThe second and third dives follow a similar routine. After the final dive you have plenty of time to rinse your gear and back it away (the staff will take care of rental gear). There are fresh water showers on board.\nBy now the beer should be nicely chilled, time to crack open a cold one for the cruise back to Chalong pier. Or find a place to snooze, diving takes it out of you.\nOnce at the pier the morning routine is reversed. Pier shuttle to minivan to hotel to dinner to bed. Then start it all again the next day.","Liveaboard Diving in Noonu Atoll\nWhat To Expect On A Noonu Atoll Liveaboard\nA liveaboard to Noonu Atoll, which lies at the south end of a long atoll group that crowns the north of the Maldives, will usually be running a Northern or Central Atolls itinerary. Noonu is joined with Shaviyani Atoll, above which lies the Maldives' new frontier of Haa Alifu and Haa Dhalu (the Far Northern Atolls). Noonu's location puts it in the center of the Northern Atolls action, and being connected to the far north gives it a bit extra: sharks. Sharks can't often be seen in most of the Northern Atolls, but Noonu is an exception.\nNoonu Atoll Underwater\nMaldives liveaboard diving in Noonu Atoll offers colorful thilas with plenty of soft coral, black coral, and gorgonian fans, some hard coral gardens, and grey reef or blacktip reef sharks. Like its Northern Atolls neighbors, Noonu enjoys great variety and volume of reef fish, hunted by larger predators like tuna and barracuda. The Northern Atolls topography of overhangs and caverns is present in Noonu dive sites, along with some particularly memorable and unique formations, described below.\nDive Sites Of Noonu Atoll\nFor sharks, dive cruises visit Orimas Thila, where a particular channel hosts swarms of grey reef sharks numbering in the twenties or higher. Sharks frequent this kandu to take advantage of the spa services offered by small cleaner wrasse, which they allow inside their gills and mouths to remove parasites and detritus. Expect your dive guide to bring you to a resting point just down-current, where you can kneel in comfort without disturbing the inhabitants. This dive site is ideal for checking out a whole community of sharks doing their thing, from small juveniles to adults over three meters long.\nChristmas Tree Rock is also a must-do for most Noonu Atoll dive tours. The topography here consists of large shelves of life-encrusted rock that divers can peer under and swim through to search for big and small reef inhabitants. Adding to the Christmas tree imagery, small dancing fish of vibrant pink, yellow, and blue ornament the different levels of the ìtreeî with their bright colors. Reef sharks and rays rest in the dark, and large pelagics like tuna stream through the blue water off the sides. With a hard coral garden at the top, Christmas Tree Rock is often cited by divers as one of their favorite Northern Atolls dive sites, as well as a Maldives diving favorite in general.\nDive sites abound in Noonu Atoll, and if your dive dhoni ventures off the beaten track, local dive sites offer plenty to discover. Fairy Meadow, The Dome, and Golden Caves are just a few of the many where healthy, varied fish life, overhangs, and colorful soft corals entrance divers year after year.\nTop Tips for Divers\nIn the Maldives, a new Green Tax of 6 USD per person per night applies for every tourist in the country. The official language is Maldivian, also called Dhivehi.\nGear to bring includes your own mask, booties, fins, and dive computer. These are personalized pieces of equipment which we donít recommend renting. An ill-fitting mask or pair of fins can make diving virtually impossible, and a dive computer is your most-important piece of safety equipment.\nGetting To Noonu Atoll\nLike anywhere in the Maldives, Noonu Atoll is best dived by liveaboard; in no other way can you access so many dive sites, often near uninhabited islands or far from land altogether. The length of liveaboard itineraries that include Noonu Atoll is usually 10 or 11 nights, with a budget of around 350 euros per night. Liveaboards often combine Noonu Atoll with Baa, Raa, Lhaviyani, and potentially the Far Northern Atolls. Sometimes, itineraries also add in the Central Atolls.\nMale is one of the Maldives liveaboard departure locations for Noonu Atoll liveaboards, accessible by direct flights from Dubai, Singapore, and Colombo. On liveaboards combining Noonu with the Far Northern Atolls, however, Hanimadhoo or Dharavandhoo may be the port of departure. These destinations can be reached by domestic sea plane from Male. To get to Male from Europe, America, China, India, and Australia, flights often connect through the nearer airports mentioned above.\nDiving Noonu Atoll is possible all year round, but the northeast monsoon from January to May allows the calmest surface conditions. The water temperature usually stays between 27 and 30 C, and visibility between 10 and 20 meters.\nNoonu Atoll Diving Reviews\n- 7.2 Good\n- 1 Verified Reviews"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:33b5520c-52e2-47f5-87c5-f7136f0c34f4>","<urn:uuid:374459bc-a39b-483d-aae4-47dd58d9d7e1>"],"error":null}
{"question":"How much did South Korea invest in the Pyeongchang Olympics and what major infrastructure was built?","answer":"South Korea invested around $13 billion in the Pyeongchang Olympics. Major investments included new hotels in Gangneung, housing projects, venues, and transportation projects, including a high-speed rail link connecting Seoul to Pyeongchang's remote venues.","context":["(The Conversation is an independent and nonprofit source of news, analysis and commentary from academic experts.)\nWhen preparing a bid to host the Olympics, organizers typically promote economic growth, jobs, housing and infrastructure improvements. But as a landscape architect and urban designer who worked on both the Atlanta and London Olympics, I’ve been able to see how these lofty visions don’t always mesh with reality.\nSo is Pyeongchang in a good position to become a winter sports hub that will fuel economic growth and tourism for years to come? Or will the country’s long-term fiscal health be damaged, leaving a financial burden for future generations?\nUltimately, the legacy of the Pyeongchang Games will depend on the answers to these questions.\nBy looking at what’s worked – and what hasn’t – in the planning and execution of the games in previous host cities, we can see whether South Korea is poised to benefit from its considerable investment.\nCreative planning can transform a city\nWith good planning, the Olympics can be an economic boon, while spurring some exciting changes to the urban fabric of a city.\nThe 1984 Los Angeles Summer Olympics turned a profit, generating a US$225 million surplus that has been used to support American Olympic efforts and local youth sports organizations over the decades. After the 1996 Summer Games in Atlanta, the athletes’ village was converted into new dormitories for a local university.\nWhen planning the 2012 London Olympics, organizers took the long view – perhaps more than any other previous host city. They were able to transform an underdeveloped industrial part of the city into a thriving community that includes public open space, infrastructure improvements and affordable housing. Every venue was designed to be retrofitted once the games were completed. For example, the Copper Box Arena, which hosted handball and other events, is now used for an array of indoor sports.\nParis and Los Angeles were chosen to host the Olympic Games in 2024 and 2028, in large part because both cities have hosted the games in the past and have existing venues in place. Planners for Los Angeles Games project that they’ll cost about $5 billion to stage and will generate a surplus. (By comparison, the Rio Games cost $13 billion.)\nLos Angeles does plan to build an expensive new stadium for the opening ceremonies. However, this stadium will eventually become the home for the city’s two National Football League teams, the Rams and the Chargers, and the stadium has already been designated the host of the 2021 Super Bowl.\nIt’s all about the bottom line\nFor the organizers of the Los Angeles and Paris Games, the financial burden of being a host city is a primary concern.\nThis is probably because spiraling costs have crippled previous host cities. From 1968 to 2012, every single Olympic Games ended up costing more than originally estimated, with 1976 Montreal and 1984 Sarajevo each costing 10 times the original estimate. It took Montreal 30 years to pay off its debts after the 1976 Olympics.\nAnd despite bold plans to repurpose Olympic buildings, past host cities have been left with vacant, decaying sports complexes that are referred to as “white elephants.”\nBeijing’s iconic “Bird’s Nest” stadium has rarely been used since 2008. The Olympic Aquatic Center in Athens has sat vacant since the 2004 Summer Olympics, and many blame Greece’s economic collapse on debts associated with the Olympics.\nNearly two years after the 2016 Rio Olympic Games, most venues are closed or underused. The Rio Olympic stadium has been abandoned and closed to tourists due to a dispute over $1 million in unpaid electricity bills and management fees.\nCan Pyeongchang become a winter sports hub?\nSouth Korea hosted the Summer Olympic Games in 1988, and many credit these games for sparking the country’s transformation into an economic powerhouse and a global leader in consumer electronics.\nIn the case of the Pyeongchang Games, one of country’s stated goals was to help the country become a top winter sports hub in Asia.\nThere were two main sites chosen for 2018 Winter Olympics: the mountain resort Alpensia and the coastal city of Gangneung. The Alpensia resort was prominently featured during the 2018 games, with downhill and cross-country skiing, snowboarding, ski jumping and biathlon taking place at the site. The city of Gangneung included new stadiums for curling, ice hockey, speed skating and figure skating events.\nSouth Korea ended up investing around $13 billion for the Pyeongchang Olympics. Although this is significantly less than Russia’s record $55 billion tab for the 2014 Sochi Winter Olympics, it still exceeded what the country had budgeted. A major portion of that has gone to new hotels in Gangneung, housing projects, venues and transportation projects, like a high-speed rail that links Seoul to Pyeongchang’s remote venues. This rail would provide access to the ski resorts and help further South Korea’s vision for creating an Asian winter sports hub.\nYet anyone who watched the games on TV couldn’t help noticing that many events were poorly attended. There could be a number of explanations, including a Chinese travel ban that prevented Chinese fans from attending, the country’s distance from Europe and North America, a lack of local interest in alpine sports, and early morning starting times.\nHowever, it does make you wonder if South Korea’s vision for a major Asian winter sports hub is viable. Many global economists predict that a major increase in regional tourism and economic growth is unlikely.\nNonetheless, organizers seem to have learned from the successes and failures of previous host cities, from Atlanta to Athens.\nFor example, South Korea built a complex of eight 15-story apartment buildings in Pyeongchang to house the Olympic athletes. All of the apartments have already been sold, with most going to domestic buyers.\nAnd to avoid “white elephants,” organizers in South Korea are planning to demolish some of the new venues after the games, deeming that it would be too impractical to try to repurpose them. For example, the new Olympic stadium cost $109 million to build and seats 35,000 people. But there are currently only 40,000 people living in the region. So the stadium will go by way of the wrecking ball once the games conclude.\nSouth Korea’s vision of creating a top winter sports hub might be in doubt. But South Korea did use the Olympics to flaunt its technological prowess, showcasing cutting-edge technologies such as a 5G mobile network and self-driving buses.\nSo perhaps the legacy of Pyeongchang will be that it encouraged further expansion of the country’s technology sector, just as the 1988 Seoul Games helped transform South Korea into an electronics powerhouse.\nAs with all cities that takes the gambit of hosting Olympic games, time will tell.\nThis article was originally published on The Conversation. Read the original article here: http://theconversation.com/will-pyeongchang-be-able-to-avoid-a-post-olympics-day-of-reckoning-92238."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"}],"document_ids":["<urn:uuid:e3e165bb-13ed-4637-a1e3-1d8f332d74b0>"],"error":null}
{"question":"Could you compare the effectiveness of hand washing alone versus using disposable gloves in preventing foodborne illnesses?","answer":"While hand washing is important, it alone is not sufficient to prevent foodborne illness since routine hand washing does not remove all bacteria, and even a small amount can make someone sick. An additional barrier, such as disposable gloves, is needed. However, wearing gloves is not a substitute for proper hand washing - employees must wash their hands before donning gloves to work with food, as gloves can fail and allow bacteria and viruses through. Workers must wash hands after activities like using the restroom, handling raw meats, smoking, eating, drinking, coughing, sneezing, or touching body parts, and gloves should be changed when damaged or soiled, after 4 hours of wear, or after handling raw foods.","context":["A. Employee Health: Personnel with Infections Restricted Critical Violation\nSick food workers suffering from an illness that can be transmitted through food must be restricted from handling food and clean equipment and utensils. Workers with gastrointestinal illnesses, such as diarrhea, fever, vomiting, or with bad colds accompanied by heavy nasal discharge, persistent coughing, or sneezing, can transmit the disease-causing agent they have into the foods they are handling and on to individuals that consume the food product.\nB. Employee Health: Wounds Properly Covered Critical Violation\nCuts or burns on a food worker's hands are a direct threat for introducing disease-causing bacteria, such as Staphylococcus aureus, into food. A water-tight barrier is required to cover cuts and burns on workers' hands and wrists. Cuts or burns on the arms are less of a concern when usual food preparation practices are employed; therefore, no barrier is required.\nHowever, if the food preparation practices involve contact of the exposed portions of the arms with food, a barrier equivalent to that required for the hands and wrist is necessary. Bandages worn over cuts and burns are not considered adequate covers. Bandages must be covered with a water-tight barrier to prevent leakage from the cut or burn through the bandage into the food.\nC. Employee Health: Hands Washed, as Needed Critical Violation\nThe hands are particularly important in terms of transmitting foodborne disease-causing organisms. Food employees with dirty hands and/or fingernails may contaminate the food being prepared. Therefore, any activity which may contaminate the hands must be followed by thorough hand washing. Even seemingly healthy employees may serve as reservoirs for disease-causing microorganisms that are transmissible through food. Staphylococci bacteria, for example, can be found on the skin and in the mouth, throat, and nose of many healthy employees. The hands of employees can be contaminated by touching the nose, mouth, hair, or other body parts.\nHands must be washed after:\nUsing the restroom\nHandling raw meats, poultry, and fish\nSmoking, eating, or drinking\nCoughing or sneezing\nTouching head, hair, mouth, cuts, burns, or other sores\nHandling dirty dishes, utensils, and equipment\nD. Hygienic Practices Critical Violation\nGood hygienic practices must be followed by all food workers to prevent the introduction of contaminants into food and to prevent the possibility of transmission of disease through food. Workers must wash their hands after touching their hair, face, nose, or other body parts. Fingernails must be kept trimmed and clean. Hands must be free of an excess number of rings where disease-causing bacteria can collect and contaminate food. Food workers must not use common towels or aprons to wipe or dry their hands. Towels used over and over again become contaminated, and each time workers wipe their hands on a common towel, their hands also become contaminated.\nE. Hygienic Practices: Smoking, Eating, Drinking Critical Violation\nThe use of tobacco products or eating or drinking during food preparation is prohibited. The hand-to-mouth contact that occurs during these activities results in the contamination of workers' hands and food.\nF. Demonstration of Knowledge: Training Needed Critical Violation\nFood workers must have a basic understanding of food safety as it relates to the job or task they are doing. Dishwashers must know how the dish machine they operate sanitizes and when they should be washing their hands. Cooks that reheat foods must know the temperature requirements for reheating. Employees who are required to cool foods must know what the temperature requirements are for cooling. The more knowledgeable the food handler is, the safer the food-handling practices in the establishment will be.\nG. No Bare-hand Contact Critical Violation\nFood must be prepared with minimal manual contact by using suitable utensils or single-use gloves. Employees should not touch ready-to-eat foods with their bare hands.","Foodborne illness. No restaurant operator wants those words associated with their establishment. To ensure their food is safe, many hours are devoted to employee education and ongoing training. Hand hygiene and disposable gloves are an important part of safe food handling.\nRestroom Germs and Cross-Contamination\nA critical component to safe food handling is proper gloving and hand hygiene. “Restroom germs” such as E. coli, Staphylococcus, Giardia, Hepatitis A, Norovirus, and Shigella can be transmitted from hands to food. Cross-contamination can also occur, transferring pathogens such as salmonella. Restaurants offering gluten-free foods have the added concern of gluten being accidentally transferred.\nThe problem of foodborne illness has real consequences – both for customers and food service establishments. In 2009, a McDonald’s location in Illinois was linked to a hepatitis A outbreak that resulted in a class-action lawsuit. And in New York City alone, dining out was linked to 3,500 hospitalizations in 2008 for food-borne illnesses and some 1,300 cases of salmonella.\nBut even if employees were always diligent about washing their hands, hand washing alone is not enough to prevent food-borne illness. Routine hand washing does not remove all bacteria, and it only takes a small amount to make someone sick. An additional barrier, such as a disposable glove, is needed.\nFDA Food Code 2009\nTo help make food safer, the Food and Drug Administration (FDA) released an updated Food Code in 2009. Here are some of the food handling rules:\n- Employees may not touch ready-to-eat foods with bare hands, except when washing fruits and vegetables, or when otherwise approved. They must use a barrier, such as deli tissue, spatulas, tongs or gloves.\n- Wearing gloves is not a substitute for proper hand washing. Gloves can fail, and allow bacteria and viruses through, so employees must wash their hands before donning gloves to work with food.\n- Gloves should be changed often. Gloves should be changed when they become damaged or soiled, after 4 hours of wear, or after handling raw foods.\n- Glove should be worn for a single task. A food service employee should never handle money, take out the trash or perform other tasks and return to handling ready-to-eat food without changing their gloves.\nGluten-Free Food Handling\nRestaurants such as Subway that are starting to offer gluten-free foods are giving special attention to hand hygiene and proper gloving and food handling. And rightly so. An employee that handles regular gluten-containing bread and then handles gluten-free bead without changing gloves has just cross-contaminated the food. While this may not affect a customer with a non-celiac gluten intolerance, it spells real trouble for a customer with true Celiac Disease.\nGlove Selection Considerations\nRestaurant operators or managers selecting gloves for employees are necessarily concerned with cost. But the cheapest gloves may not be the best choice. Considering the following criteria will help ensure the right glove is purchased for the right job.\n- Proper Fit – For the safety of the employee, properly fitted gloves are essential. Gloves that are too loose can result in serious bodily injury. Glove that are too tight lead to hand strain.\n- Proper Material – Consider the dexterity needed for the tasks the employee is performing. While a poly glove may be suitable for assembling a sandwich, a more form fitting nitrile glove is better suited for tasks like slicing and chopping.\n- Comfort – A comfortable glove that provides adequate grip and tactile sense will increase employee compliance and safety.\n- Allergens – Allergens and chemical sensitivities should be considered. Employees concerned about latex sensitization should be offered a non-latex alternative, like nitrile gloves. Please note that some individuals may be sensitive to the chemicals commonly found in non-latex gloves. If this is the case, accelerator-free nitrile gloves like FreeStyle1100 are now available.\nBy carefully educating employees about hand hygiene and providing gloves that are suitable to the task and comfortable to wear, restaurant operators can be confident they are doing their part to reduce the risk of food-borne illness."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:2fd88e3b-d681-4513-bcda-32d9f6d7c8f5>","<urn:uuid:b1179725-6564-4f7f-9e00-74e3872daad9>"],"error":null}
{"question":"Could you explain how public health education prepares students for future careers, and what strategies these professionals should use to prevent burnout in demanding roles?","answer":"Public health education prepares students through a multidisciplinary approach that combines various disciplines and provides opportunities for practical experience through internships, research programs, and study abroad. Graduates can work in academic settings, government agencies, or nonprofit organizations, focusing on areas like environmental monitoring, health communication, and intervention programs. They may also pursue advanced degrees in specializations such as biostatistics, epidemiology, or global health. To prevent burnout in these demanding roles, professionals should engage in self-care activities including physical strategies (exercise, hiking), relational strategies (spending time with peers, seeking supervision), and cognitive strategies (using music or movies for distraction). They should also maintain work-life balance, take advantage of vacation days, and prioritize their health through adequate sleep and stress management activities like meditation.","context":["As the world becomes more interconnected, our communities and populations face increasingly complex health challenges emerging through the interaction of individual vulnerability and behavior, cultural and social factors, environmental and geographic influences as well as economic and political dynamics. Addressing these public health challenges requires innovative approaches arising from multiple disciplines.\nThe Undergraduate Certificate in Public Health encourages students to extend the breadth of their undergraduate education to include elements of public health. Students are encouraged to take courses from a variety of participating departments to develop an appreciation of the interdisciplinary nature of public health.\nPublic health curriculum at the undergraduate level is relatively new. As a result, we are only beginning to track post-graduate opportunities for individuals who participate in the certificate program. While the vast majority of entry-level positions available to graduates do not specifically require a public health background, incorporating public health curriculum into their studies will provide graduates an advantage when faced with an increasingly complex and multidisciplinary workplace. Graduates of the certificate program will also have a solid foundational knowledge to continue their studies at a School of Public Health or other graduate programs working towards an advanced graduate degree. Graduates of the certificate program also continue their studies in medical school, nursing school, pharmacy school and other health-related professional programs.\nGraduates of the certificate program will find numerous opportunities for advanced study in public health and related disciplines. Graduate study at a School of Public Health may include specialization in biostatistics, environmental health, epidemiology, health administration and management, global health, maternal and child health, nutrition, public health policy as well as social and behavioral science.\nGraduates with a public health background who do not seek advanced degrees may work in academic settings, government agencies or nonprofit and advocacy organizations. The nature of the work may entail environmental and occupational monitoring, health communication and marketing as well as intervention programs developed at the city, state, federal or international level. Additionally, graduates of the certificate program suitably prepared for serving in the Peace Corps or AmeriCorps.\nGaining educational experiences outside of the classroom is a valuable asset to any undergraduate curriculum, especially in the field of public health. First, offered through the CU Boulder campus, many departments participating in the certificate offer for-credit internships that could be tailored towards public health interests and be conducted locally, regionally, nationally or internationally. There are also opportunities through the CU in DC program could be tailored to provide valuable experiential education in health policy and health economics. Further, study abroad programs offered through the CU Boulder Office of International Education (OIE) would provide outstanding opportunities that complement the public health curriculum on the CU Boulder campus. Additionally, there are numerous internship opportunities that would be ideal for undergraduate students working towards a certificate in public health. These are often available during the summer and include regional internships such as volunteering for the Boulder County AIDS Project and national internships at the Centers for Disease Control and Prevention (CDC), Environmental Protection Agency (EPA), Kaiser Family Foundation (KFF), the National Institutes of Health (NIH) and US Public Health Service (USPHS). Students are encouraged to leverage these opportunities to serve as for-credit internships or faculty sponsored independent study (for credit) through their home (major) department. Finally, students may participate in the Undergraduate Research Opportunities Program (UROP) to explore public health interests outside of the classroom with faculty conducting research relevant to public health. Please visit the Public Health Program website for additional details.","Given the emotional and demanding nature of social work, burnout is a significant problem among social workers.\nAs burnout often results in negative emotional and occupational repercussions, it is essential for social workers to recognize the warning signs, practice prevention, and engage in adequate self-care.\nThis article will delve into these topics, while also describing helpful resources from PositivePsychology.com. In doing so, it will provide social workers with the tools and information needed to carry out their invaluable work.\nBefore you start reading, we thought you might like to download our three Stress & Burnout Prevention Exercises (PDF) for free. These science-based exercises will equip you and those you work with, with tools to manage stress better and find a healthier balance in your life.\nThis Article Contains:\nBurnout in Social Work Explained\nSocial work is a noble profession. It is often entered into by those who wish to help vulnerable populations to achieve justice and receive vital support and services.\nGiven the nature of the job, social workers are often exposed to various aspects of human cruelty (e.g., abused or neglected children, domestic violence, etc.). As such, social work requires a high level of empathy and compassion.\nAdditionally, a career in social work is generally highly demanding, with large caseloads and minimal compensation. Imagine, for example, performing a job in which your caseload outweighs your time, your clients are victims of chronic abuse, and you barely earn enough money to pay your mortgage.\nYou may also have a supervisor who is overworked and cannot recognize your accomplishments or needs. This situation may cause compassion fatigue, which involves stress and emotional fatigue that results from the chronic use of empathy to help those suffering from trauma (Figley, 1995).\nThe concept of social work burnout is well exemplified in an article by Smullens (2012, p. 1), who noted how her social work supervisor often came home from work exhausted, telling his wife “They [his clients] feel better, but I surely do not.” This experience has also been referred to as ‘secondary or vicarious trauma,’ which occurs when social workers take on their clients’ stress and vulnerabilities (Wilson, 2016).\nOf course, those who enter helping professions are often highly empathetic, caring individuals. As such, being exposed to their clients’ chronic challenges and health disparities becomes emotionally and physically taxing. This is especially likely when workloads and resources are mismatched to the degree that making a meaningful change is unlikely.\nWhen this happens, social workers are at a heightened risk for feeling frustrated, depleted, and, ultimately, burned out. Indeed, the research literature supports a connection between high levels of burnout and stress among social workers relative to other occupations (Lloyd, King, & Chenoweth, 2002).\nIndeed, in a study including 751 social workers, three-quarters of participants experienced burnout during their careers (Siebert, 2005). Considering these correlations, it is essential that social workers know the warning signs of burnout and take necessary steps toward preventing it.\n16 Warning Signs of Burnout in Social Workers\nIf you’re a social worker who is concerned about potential burnout, here are several research studies that have identified warning signs to keep in mind:\n- Lack of enthusiasm about work\n- Reduced compassion or empathy for clients\n- Mismatch between job rewards (e.g., compensation and recognition) and performance\n- A non-collaborative workplace\n- Feeling a lack of job control, which minimizes autonomy\n- Depression symptoms\n- Job cynicism\n- Sense of resignation about work\n- Quick-temperedness with colleagues or family\n- Self-medicating behavior\nKim, Ji, and Kao (2011)\n- Role ambiguity\n- High work challenges\n- Lack of autonomy\n- High role conflict\nSchaufeli, Leiter, and Maslach (2009)\n- Poor fit between values of the social worker and those of the organization\n- Workload responsibilities out of balance with the social worker’s needs and priorities\nOverall, if you find you dread going to work each day and are exhausted when you return home, you may be suffering from burnout. If this is a concern, it may be helpful to ask yourself the following questions as outlined by the Mayo Clinic (2021):\n- Are you feeling disillusioned about your career?\n- Are you having difficulty concentrating?\n- Do you no longer find satisfaction in your achievements?\n- Are you having trouble sleeping?\n- Are you trying to numb or distract yourself from your feelings?\n- Are you irritable with clients or coworkers?\n- Are you experiencing physical symptoms such as headaches or digestive problems?\nAlong with recognizing the red flags above, it also is important to remember that increased burnout is associated with fewer years of social work practice (Weekes, 2011).\nTherefore, if you are dedicated to social work, but new to the job, hang in there. As long as you know the warning signs and practice plenty of self-care, you will probably feel better as you accumulate experience and confidence in your role.\nPreventing Burnout: The Importance of Self-Care\nHave patience with all things. But, first of all, with yourself.\nFrancis de Sales\nEngaging in adequate self-care is essential among social workers, as it helps to protect against the stress that accompanies repeated exposure to traumatized populations.\nAccording to Salloum, Kondrat, Johnco, and Olson (2015, p. 54), trauma-informed self-care (TISC) involves “being aware of one’s own emotional experience in response to exposure to traumatized clients and planning/engaging in positive coping strategies.”\nBy engaging in TISC, social workers benefit from coping strategies that help to moderate the negative impact of working with highly vulnerable clients (Salloum et al., 2015). Research has indicated that TISC is related to higher levels of compassion satisfaction and reduced burnout among child welfare case managers (Salloum et al., 2015).\nSimilarly, Weekes (2011) assessed 185 members of the National Association of Social Workers for both burnout and self-care. The results showed that depersonalization and emotional exhaustion were significantly lower among those who engaged in higher levels of self-care.\nEngaging in self-care represents an important way for social service workers to experience greater job satisfaction with a diminished likelihood of burnout.\n30 Self-Care Activities for Social Workers\nAs important as it is to have a plan for doing work, it is perhaps more important to have a plan for rest, relaxation, self-care, and sleep.\nResearchers investigating the role of self-care in preventing the likelihood of burnout among social workers have reported many effective self-care approaches, with over 30 presented below.\n- Engage in physical or behavioral strategies (e.g., dancing, hiking, sports, deep breathing, etc.)\n- Engage in relational strategies (e.g., spend time with pets; talk about feelings with colleagues, significant others, supervisors, etc.)\n- Engage in cognitive strategies (e.g., distract yourself with music, movies, etc.; avoid exposing yourself to stress or trauma when outside of work, etc.)\nSalloum et al. (2015)\n- Seek supervision\n- Attend trainings on secondary trauma\n- Balance your caseloads\n- Ensure work–life balance\n- Seek continuing education on the effects of trauma\n- Take advantage of agency resources\n- Set realistic goals\n- Attend therapy as needed\n- Engage in stress management activities, such as meditation\n- Be cognizant of your emotional response to traumatized clients\nHere are 17 more self-care suggestions:\n- Don’t bring work home. Home should be your respite from the day’s stress. Keep it that way by avoiding discussions or reminders of work once your shift is over.\n- Take advantage of vacation days. Always, always use your vacation days. It is a wonderful way to restore your emotional wellbeing, along with your connection with significant others. Besides, you earned that time off.\n- Talk to friends and family. Sharing with others is a great way to get a reality check, as well as to generate ideas about how to avoid burnout.\n- Find an artistic release. Whether it’s music, drawing, working with clay, or any other artistic endeavor, engaging in art enhances a sense of flow and happiness.\n- Get plenty of sleep. Adequate sleep is essential to emotional and physical health. Do not skimp on it.\n- Reward yourself. Whether it’s a vacation or simply a cup of tea, take the time to reward yourself for your hard work.\n- Read a good book. Reading is a healthy way to escape from a stressful day. By taking the time to read, you will feel more relaxed and might even sleep better.\n- Avoid self-medicating. If you find yourself craving a drink or some other drug at the end of the workday, this could escalate into a problem. Try to find healthier coping mechanisms, such as exercise or talking to a friend.\n- Get a massage. If you enjoy massages and they are feasible, then go for it. Massage helps with both physical and emotional tension, and it is also a great way to reward yourself.\n- Go on outings. Simply getting away for the day or the weekend is often highly restorative.\n- Make your health a priority. If you are putting your health last, both your work and your health will deteriorate. Always make time for sleep, exercise, doctor visits, and healthy meals.\n- Don’t be too hard on yourself. Social workers deal with terrible trauma. And while they make a huge impact, they can’t save everyone. Know that you aren’t a miracle worker, but are doing the best you can.\n- Spend time in nature. Many people feel invigorated by a hike in the woods, canoeing, bird watching, going to the beach, or being around animals. If you enjoy nature, get outside and reap the rewards.\n- Pamper yourself. Remember: You are performing a highly demanding job that takes a lot out of you. Be kind to yourself.\n- Go for walks. Along with the benefits of exercise, walking may take your mind off of your workday while providing fresh air.\n- Take on a new hobby. Regardless of your skill level or interests, doing something hands-on (e.g., woodworking, knitting, gardening, etc.) is always good for the soul.\n- Ensure that the job is the best fit for you. If you are feeling burned out despite experiencing an adequate work–life balance and engaging in plenty of self-care, it may be time to examine whether you are in the right field. Your job should be rewarding and not leave you emotionally depleted. Remember, there is no shame in exploring other opportunities if you are consistently stressed and dissatisfied.\n15 Minutes a day to prevent burnout – Paul Koeck\nPositivePsychology.com’s Helpful Resources\nWe have many terrific resources here at PositivePsychology.com that help to identify, prevent, and cope with burnout among social workers.\nTo get you started, here are three useful articles from our blog:\n- Warning Signs of Burnout: 13 Reliable Tests & Questionnaires\nIf you are worried that you might be experiencing burnout, this article will help you identify key warning signs. It contains multiple questionnaires, tests, inventories, and checklists to help you recognize the signs and symptoms.\n- Self-Care for Therapists: 12 Strategies for Preventing Practitioner Burnout\nThis article is specifically aimed at promoting self-care among mental health professionals. It contains a background regarding the importance of self-care among this group, along with real-life examples of self-care plans, self-care strategies, helpful books, worksheets, and tips.\n- 12 Social Work Books Every Practitioner Should Read\nSeeing that reading is a good way to relax and escape a stressful day, these 12 books are great suggestions.\n- Strengths-Based Approach in Social Work: 6 Examples & Tools\nThis article is a wonderful read to learn how to focus on the client’s strengths, rather than deficits. A great way for the practitioner to also tap into their own strengths.\nFree Stress & Burnout Prevention Exercises\nFurther, if you’re a social worker looking to avoid burnout, why not show yourself some care with our free Stress & Burnout Prevention Exercises Pack. These exercises can help you identify domains in which you may be at risk of suffering from stress, as well as the potential benefits of stress for growth.\n- Strengthening The Work-Private Life Barrier\nThis exercise aims to help you identify the behaviors, beliefs, and conditions that create metaphorical “holes” in the barrier between work and private life. By completing the exercise, you can better develop a solid barrier between work and private life to help restore a healthy balance between the two.\n- Energy Management Audit\nThis brief, 16-item assessment helps you assess your energy levels across the physical, mental, emotional, and spiritual domains. Upon completion, you will have gained clear insight into your energy strengths and deficits, building awareness of these energy levels’ effects on daily functioning.\n- The Stress-Related Growth Scale\nThis 50-item assessment tool assesses positive outcomes following a stressful event (i.e., stress-related growth). By reflecting on your results, you can consider the positive benefits of challenging experiences for your relationships, thinking, and coping.\nGet access to all three exercises by downloading the exercise pack today.\n17 Stress-Management Tools\nFinally, if you’re looking for more science-based ways to help others manage stress without spending hours on research and session prep, this collection contains 17 validated stress management tools for practitioners. Use them to help others identify signs of burnout and create more balance in their lives.\nA Take-Home Message\nAs social workers well know, “anyone who confronts the system day in and day out will tell you that residual trauma is real” (Barnett, n.d.).\nThe tireless and honorable work of those who give a voice to the vulnerable takes its toll in terms of compassion fatigue and burnout.\nFortunately, by knowing the red flags and engaging in adequate self-care, these outcomes may be avoided or diminished. In doing so, social workers will be better able to experience a rewarding career that is of invaluable benefit to individuals, families, and society as a whole.\nWe hope you enjoyed this article; don’t forget to download our three Stress & Burnout Prevention Exercises for free.\n- Barnett, B. (n.d.). Retrieved on June 30, 2021, from https://www.goodreads.com/quotes/tag/self-care?page=2\n- Brost, A. (n.d.). Retrieved on June 30, 2021, from https://www.goodreads.com/author/quotes/18384561.Akiroq_Brost\n- de Sales, F. (n.d.). Retrieved on June 30, 2021, from https://www.goodreads.com/quotes/842634-have-patience-with-all-things-but-first-with-yourself-never\n- Diaconescu, M. (2015). Burnout, secondary trauma and compassion fatigue in social work. Social Work Review, 14, 57–63.\n- Figley, C. (1995). Compassion fatigue: Coping with secondary traumatic stress disorder. Brunner/Mazel.\n- Freudenberger, H. (1975). The staff burnout syndrome in alternative institutions. Psychotherapy: Theory, Research, Practice, Training, 12(1), 72–83.\n- Kim, H., Ji, J., & Kao, D. (2011). Burnout and physical health among social workers: A three-year longitudinal study. Social Work, 56(3), 258–268.\n- Lloyd, C., King, R., & Chenoweth, L. (2002). Social work, stress and burnout: A review. Journal of Mental Health, 11(3), 255–265.\n- Mayo Clinic, (2021, June 5). Job burnout: How to spot it and take action. Retrieved on June 30, 2021, from https://www.mayoclinic.org/healthy-lifestyle/adult-health/in-depth/burnout/art-20046642\n- Salloum, A., Kondrat, D., Johnco, C., & Olson, K. R. (2015). The role of self-care on compassion satisfaction, burnout and secondary trauma among child welfare workers. Children & Youth Services Review, 49, 54–61.\n- Schaufeli, W., Leiter, M., & Maslach, C. (2009). Burnout: 35 years of research and practice. Career Development International, 14(3), 204–220.\n- Siebert, D. (2005). Personal and occupational factors in burnout among practicing social workers: Implications for researchers, practitioners, and managers. Journal of Social Service Research, 32(2), 25–55.\n- Smullens, S. K. (2012). What I wish I had known: Burnout and self-care in our social work profession. The New Social Worker. Retrieved on June 30, 2021, from https:///www.socialworker.com/feature-articles/field-placement/What_I_Wish_I_Had_Known_Burnout_and_Self-Care_in_Our_Social_Work_Profession/\n- Weekes, J. (2011). The relationship of self-care to burnout among social workers in health care settings (Doctoral dissertation, Walden University).\n- Wilson, F. (2016). Identifying, preventing, and addressing job burnout and vicarious burnout for social work professionals. Journal of Evidence-Informed Social Work, 13(5), 479–483."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:f92076dc-c1c6-401d-a72c-0b937261b432>","<urn:uuid:63fc7856-514d-43df-9f8d-cbf3d04d4aac>"],"error":null}
{"question":"which job needs more skills - surgical tech or lab tech? 🤔","answer":"Medical laboratory technicians require a broader range of skills. While surgical technologists need specific skills like manual dexterity, team coordination, and pressure management, lab technicians must possess numerous technical abilities including chemical analysis, equipment operation, complex problem solving, quality control analysis, scientific knowledge (biology and chemistry), computer skills, mathematical skills, and various physical abilities like arm-hand steadiness, finger dexterity, and near vision capabilities.","context":["Work Activities/Work Locations\n- Surgical technologists sometimes referred to as Operating Room Technicians become an integral member of the surgical team. They provide patient care before, during, and after surgery with a primary responsibility for maintaining the sterile field.\n- They work in an operating room setting, under the direct supervision of registered nurses and surgeons.\nAdvantages and Disadvantages\n- Surgical technologists enjoy their jobs because they are interesting and challenging and they are helping people as well.\n- They should possess manual dexterity and good fine motor coordination, be able to perform accurately and efficiently under pressure, function well as a team member, and possess a strong sense of responsibility.\n- Surgical technologists work in clean, well-lighted, cool environments.\n- They must stand for long periods and remain alert during operations.\n- At times they may be exposed to communicable diseases and unpleasant sights, odors, and materials.\nEducation: 1-2 years\nPatient Interaction: Low\nPhysical Activity: Low\nJob Growth: Medium\nThis is an accordion element with a series of buttons that open and close related content panels.\nHigh School Courses\n- Students should take a college preparatory curriculum.\n- NTC requires one year of high school biology. Other suggested courses would include algebra, anatomy & physiology, chemistry, and medical terminology.\nEducation and Training\n- Individuals may receive training at an accredited technical college.\n- Programs provide classroom education and supervised clinical experience.\n- Northcentral College (NTC) offers a 3-semester Technical Degree Program. Coursework includes classes on oral/interpersonal communication, anatomy & physiology, medical terminology, microbiology, instruction on instrument handling and sterilization, and infection control. Other studies may include the care and safety of patients during surgery, aseptic techniques, and surgical procedures.\n- Students who have successfully completed a formal training program may earn certification as a Certified Surgical Technologist (CST) after passing a national certification exam.\n- Technologists may obtain voluntary professional certification from the Liaison Council on Certification for the Surgical Technologist by graduating from a CAAHEP-accredited program (NTC) and passing a national certification examination. They may then use the Certified Surgical Technologist (CST) designation.\n- Continuing education or reexamination is required to maintain certification, which must be renewed every 4 years.\nChippewa Valley Technical College\nGateway Technical College\nMadison Area Technical College\nMid-State Technical College\nMilwaukee Area Technical College\nMilwaukee Career College\nMoraine Park Technical College – Fond du Lac\nNorthcentral Technical College\nNortheast Wisconsin Technical College\nWaukesha County Technical College\nWestern Technical College\nHospitals with Associated Educational Programs\nMethod of Entry\n- A high school diploma or equivalent is required for entry into training programs.\n- Must complete an accredited program in surgical technology.\n- Entrance into this program at technical colleges is delayed, as there are many applicants. An annual Petition Process has been established to deal with the long waiting lists. Check with the individual colleges for specifics.\nAccreditation Review Council on Education in Surgical Technology and Surgical Assisting\n6 W. Dry Creek Circle, Suite 110\nLittleton, CO, 80120-8031\nAssociation of Surgical Technologists\n6 W. Dry Creek Circle, Suite 200\nLittleton, CO, 80120-8031\n303/694-9130 or 800/637-7433\nCommission on Accreditation of Allied Health Education Programs\n1361 Park St.\nClearwater, FL, 33756\nNational Board of Surgical Technology and Surgical Assisting\n: 6 West Dry Creek Circle, Suite 100\nLittleton, CO, 80120\nNumber Employed in 2014 (Wisconsin): 2,640\nNumber Employed in 2014 (U.S.): 99,800\nExpected Employment in 2024 (U.S.): 114,500\nPercent Employment Growth (2014-2024): 15%\nExpected Annual Openings: 2,460\nMedian Salary in 2014 (Wisconsin): $48,956\nSalary information is located at Career One Stop\nWisconsin AHEC Health Careers Information Center provides the most current salary information available from CareerOneStop. CareerOneStop will have a lapse between when the information is gathered and when it is released.\n- Surgical technologists usually work 40 hours a week.\n- They may work rotating shifts during these times.\n- They may work overtime, nights, weekends, and holidays.\n- Usually, Surgical Technologist must be ready to work anytime while on call.\n- Surgical Technologists usually receive pay raises as they become more experienced.\n- They usually receive more money when they become certified.\n- Potential careers include Scrub Surgical Technologist, Circulating Surgical Technologist, Second Assisting Technologist, and Central Supply Technician.","Medical and Clinical Laboratory Technicians\nThis occupation is expected to grow rapidly.\nPerform routine medical laboratory tests for the diagnosis, treatment, and prevention of disease. May work under the supervision of a medical technologist.\nSample Job Titles\nCertified Clinical Laboratory Technician\nClinical Laboratory Scientist\nClinical Laboratory Technician (Clinical Lab Technician)\nLaboratory Assistant (Lab Assistant)\nMedical Laboratory Technician (MLT)\nMedical Laboratory Technicians (Medical Lab Technician)\nActive Listening - Giving full attention to what other people are saying, taking time to understand the points being made, asking questions as appropriate, and not interrupting at inappropriate times.\nComplex Problem Solving - Identifying complex problems and reviewing related information to develop and evaluate options and implement solutions.\nCritical Thinking - Using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems.\nInstructing - Teaching others how to do something.\nMonitoring - Monitoring/Assessing performance of yourself, other individuals, or organizations to make improvements or take corrective action.\nOperation Monitoring - Watching gauges, dials, or other indicators to make sure a machine is working properly.\nQuality Control Analysis - Conducting tests and inspections of products, services, or processes to evaluate quality or performance.\nReading Comprehension - Understanding written sentences and paragraphs in work related documents.\nScience - Using scientific rules and methods to solve problems.\nSpeaking - Talking to others to convey information effectively.\nArm-Hand Steadiness - The ability to keep your hand and arm steady while moving your arm or while holding your arm and hand in one position.\nCategory Flexibility - The ability to generate or use different sets of rules for combining or grouping things in different ways.\nControl Precision - The ability to quickly and repeatedly adjust the controls of a machine or a vehicle to exact positions.\nFinger Dexterity - The ability to make precisely coordinated movements of the fingers of one or both hands to grasp, manipulate, or assemble very small objects.\nInformation Ordering - The ability to arrange things or actions in a certain order or pattern according to a specific rule or set of rules (e.g., patterns of numbers, letters, words, pictures, mathematical operations).\nNear Vision - The ability to see details at close range (within a few feet of the observer).\nOral Comprehension - The ability to listen to and understand information and ideas presented through spoken words and sentences.\nOral Expression - The ability to communicate information and ideas in speaking so others will understand.\nProblem Sensitivity - The ability to tell when something is wrong or is likely to go wrong. It does not involve solving the problem, only recognizing there is a problem.\nWritten Comprehension - The ability to read and understand information and ideas presented in writing.\nBiology - Knowledge of plant and animal organisms, their tissues, cells, functions, interdependencies, and interactions with each other and the environment.\nChemistry - Knowledge of the chemical composition, structure, and properties of substances and of the chemical processes and transformations that they undergo. This includes uses of chemicals and their interactions, danger signs, production techniques, and disposal methods.\nClerical - Knowledge of administrative and clerical procedures and systems such as word processing, managing files and records, stenography and transcription, designing forms, and other office procedures and terminology.\nComputers and Electronics - Knowledge of circuit boards, processors, chips, electronic equipment, and computer hardware and software, including applications and programming.\nCustomer and Personal Service - Knowledge of principles and processes for providing customer and personal services. This includes customer needs assessment, meeting quality standards for services, and evaluation of customer satisfaction.\nEducation and Training - Knowledge of principles and methods for curriculum and training design, teaching and instruction for individuals and groups, and the measurement of training effects.\nEnglish Language - Knowledge of the structure and content of the English language including the meaning and spelling of words, rules of composition, and grammar.\nMathematics - Knowledge of arithmetic, algebra, geometry, calculus, statistics, and their applications.\nMedicine and Dentistry - Knowledge of the information and techniques needed to diagnose and treat human injuries, diseases, and deformities. This includes symptoms, treatment alternatives, drug properties and interactions, and preventive health-care measures.\nPublic Safety and Security - Knowledge of relevant equipment, policies, procedures, and strategies to promote effective local, state, or national security operations for the protection of people, data, property, and institutions.\nConduct chemical analyses of body fluids, such as blood or urine, using microscope or automatic analyzer to detect abnormalities or diseases and enter findings into computer.\nAnalyze the results of tests or experiments to ensure conformity to specifications, using special mechanical or electrical devices.\nSet up, maintain, calibrate, clean, and test sterility of medical laboratory equipment.\nPrepare standard volumetric solutions or reagents to be combined with samples, following standardized formulas or experimental procedures.\nCollect blood or tissue samples from patients, observing principles of asepsis to obtain blood sample.\nSupervise or instruct other technicians or laboratory assistants.\nConduct blood tests for transfusion purposes and perform blood counts.\nInoculate fertilized eggs, broths, or other bacteriological media with organisms.\nObtain specimens, cultivating, isolating, and identifying microorganisms for analysis.\nExamine cells stained with dye to locate abnormalities.\nCommunicating with Supervisors, Peers, or Subordinates - Providing information to supervisors, co-workers, and subordinates by telephone, in written form, e-mail, or in person.\nDocumenting/Recording Information - Entering, transcribing, recording, storing, or maintaining information in written or electronic/magnetic form.\nEvaluating Information to Determine Compliance with Standards - Using relevant information and individual judgment to determine whether events or processes comply with laws, regulations, or standards.\nGetting Information - Observing, receiving, and otherwise obtaining information from all relevant sources.\nInspecting Equipment, Structures, or Material - Inspecting equipment, structures, or materials to identify the cause of errors or other problems or defects.\nInteracting With Computers - Using computers and computer systems (including hardware and software) to program, write software, set up functions, enter data, or process information.\nMaking Decisions and Solving Problems - Analyzing information and evaluating results to choose the best solution and solve problems.\nMonitor Processes, Materials, or Surroundings - Monitoring and reviewing information from materials, events, or the environment, to detect or assess problems.\nProcessing Information - Compiling, coding, categorizing, calculating, tabulating, auditing, or verifying information or data.\nUpdating and Using Relevant Knowledge - Keeping up-to-date technically and applying new knowledge to your job.\nAdaptability/Flexibility - Job requires being open to change (positive or negative) and to considerable variety in the workplace.\nAnalytical Thinking - Job requires analyzing information and using logic to address work-related issues and problems.\nAttention to Detail - Job requires being careful about detail and thorough in completing work tasks.\nCooperation - Job requires being pleasant with others on the job and displaying a good-natured, cooperative attitude.\nDependability - Job requires being reliable, responsible, and dependable, and fulfilling obligations.\nIndependence - Job requires developing one's own ways of doing things, guiding oneself with little or no supervision, and depending on oneself to get things done.\nInitiative - Job requires a willingness to take on responsibilities and challenges.\nIntegrity - Job requires being honest and ethical.\nSelf Control - Job requires maintaining composure, keeping emotions in check, controlling anger, and avoiding aggressive behavior, even in very difficult situations.\nStress Tolerance - Job requires accepting criticism and dealing calmly and effectively with high stress situations."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"}],"document_ids":["<urn:uuid:3dcbae72-0a51-4393-867b-99884a23be0c>","<urn:uuid:78e6f223-23c6-490d-91f9-5a6f45557002>"],"error":null}
{"question":"Wanna know what's the deal with these two famous churches - San Lorenzo in Florence and St Peter's in Rome. Which big artists worked on them and what'd they do there?","answer":"Both basilicas feature work from renowned Renaissance artists. In San Lorenzo, Brunelleschi designed the church and the Old Sacristy (1421-1426), Donatello created decorations including bronze doors and arabesque designs, and Michelangelo designed the famous stairway at the Biblioteca Medicea Laurenziana. In St Peter's Basilica, Michelangelo significantly modified the church's design, Bernini created the statue of St. Longinus (1639) and the baldachin, and Maderno designed the façade and extended the nave. Other artists who contributed to St Peter's include Andrea Bolgi, Francois Duquesnoy, and Francesco Mochi, who created statues for the dome's supporting piers.","context":["Basilica of San Lorenzo\nThe basilica of San Lorenzo, in the piazza of the same name in the center of town, is one of the oldest churches in Florence. Its thousand-year history is also that of the Florentine Christian community, and is closely connected to the triumphant rise to power of the Medici dynasty that chose it as the family church.\nAt the start of the 1400s, in the original building, there was already a Medici chapel, afterwards called the Sagrestia Vecchia or Old Sacresty, designed by Brunelleschi for Giovanni di Bicci de'Medici, great grandfather of Lorenzo the Magnificent, the most famous member of the dynasty.\nIn 1418, the Medicis decided to being a serious renovation of the church to turn it into a family temple. The project was given to Brunelleschi who died, however, before being able to finish it.\nInside, though, the Brunelleschi touch is obvious: the huge space with its imposing dimensions, is governed by a scheme of controlled proportions and precise mathematical ratios. It can truly be considered a Renaissance architectural manual, both for its use of classical elements derived from ancient architecture, such as the round arches or columns with Corinthian capitols, as well as for the perfect measures of its spaces.\nFrom the transept on the left, you enter Brunelleschi's Sagrestia Vecchia, built from the years 1421 to 1426. This is one of the works that best illustrates Renaissance architectural thought. The conception of space is simple and rigorous: the volume of the chapel is cubical, over which is the hemispheric dome divided into twelve slices. The area of the altar repeats on a smaller scale that of the main space. The contrast between the grey stone and light-colored stucco underlines the schematic design.\nThe decorations, such as the arabesques of blue cherubs and red seraphims, or the large round windows with Cosma and Damian, patron saints of the Medici family, were all done by Donatello. Not to mention the bronze doors – that, by the way, were not appreciated at the time, being thought too modern with their exageratedly expressive and sometimes a trifle too agitated, figures.\nThe famous library of the Biblioteca Medicea Laurenziana is also part of the basilica complex, and the wide stairway at the entrance is one of Michelangelo's most original works. With its outsized, almost overflowing, dimensions, and the ingenious spiral shape of the stairs, it's a typical example of manneristic art and an introduction to Baroque expression.\nThe Library has the most prestigious collection of Italian manuscripts, a collection begun by Cosimo the Elder, one of the great Renaissance princely benefactors, and was later enlarged by Lorenzo the Magnificent. The space destined to hold this precious treasure trove of culture is one of the first examples ever of a library not pertaining to a religious institution.\nGiorgio Vasari and Bartolomeo Ammannati, Medici architects after Michelangelo, completed the construction of the stairway, scrupulously following the Masters design.\nThe church buildings also contain the Medici chapels with their crypt, in which lie the remains of 50 members of the Medici family. Underneath the church are buried both Cosimo the Elder and Donatello.","St Peter's Basilica - Nave - PHOTOGRAPHER COMMENT\nPanorama showing a view down the nave of St Peter's Basilica in Rome. The images were taken balancing the camera on a wooden barrier with long exposures. One of the first times I tried this technique, and the resulting picture gives an impression of the vast size of the church.\nSt Peter's Basilica - Nave - FURTHER INFORMATION\nSt Peter's Basilica - Nave - Rome visitor guide showing a virtual tour of 'St Peter's Basilica - Nave' linked to an interactive map with local and travel information. 360° panoramas from Roma.\nSt Peter's Basilica is a vast building, the most popular tourist attraction for those visiting Rome. It is the largest basilica church in the world, the interior being 211.5m long and the nave 27.5m wide. This vast size dwarfs visitors passing through the massive porticoes. The whole of St Peter's basilica covers over five acres, and the internal size covers 3.75 acres.\nThe first St Peter's was built by Constantine in the 4th century, supposedly on the site where Peter was buried after his crucifixion between AD 64-67. By the 15th century this church had deteriorated beyond repair and needed replacing. Thus began a building programme lasting almost 100 years, going through several redesigns and architects. St Peter's still retains elements of Bramante's plan, but was greatly modified by Michelangelo.\nThe nave was extended by Maderno, who also designed the façade and Confessio. Adding a further 3 bays to the church, it has a number of distinct features. The dimensions differ slightly to the Michelangelo's nave, though it retains the use of huge paired pilasters. The axis is also slightly different to the western end of the basilica, a deliberate move allowing the façade to line up with the obelisk in St Peter's Square.\nFeatures of St Peter's Basilica NaveThe nave of St Peter's has several important monuments and features that are of note when visiting:\n- Along the floor of the nave are markers showing the comparative lengths of other churches, starting from the entrance.\n- Pairs of 2m high cherubs hold Holy Water basins held on the first piers. These were commissioned by Pope Benedict XIII in the 1720's, designed and sculpted by Agostino Cornacchini and Francesco Moderati\n- Medallion Reliefs of the first 38 popes adorn the pilasters of the nave piers.\n- 39 statues of the 'founder saints' of various religious orders stand in niches between the pilasters.\n- Statue of St Peter Enthroned set against the northeast pier of the Dome. One foot is mostly worn away by hundreds of years of pilgrims kissing it. The statue is thought by some to date from the 5th century, though others attribute it to Arnolfo di Cambio of the 13th century.\n- Stairs to the Confessio and Vatican Crottoes allowing popes to get closer to the supposed grave of Peter.\n- The Papal High altar and Bernini's baldachin dominate the far end of the nave.\n- Each of the four piers supporting the Dome have niches containing statues associated with various relics: St. Helena holding the True Cross, by Andrea Bolgi; St. Longinus holding the spear that pierced the side of Jesus, by Bernini (1639); St. Andrew with the St. Andrew's Cross, by Francois Duquesnoy and St. Veronica holding her veil with the image of Jesus' face, by Francesco Mochi.\nDimensions of St Peter's BasilicaSome dimensions of St Peter's Basilica:\n- Total Width - 150m (500 feet)\n- Interior Length - including the vestibule, St Peters is 211.5m (693.8 feet) long.\n- Transept Length, Interior - 137m (451 feet)\n- Nave Width - 27.5m (90.2 feet)\n- Tribune Width 24.0m (78.7 feet)\n- Internal Width at Transepts- 137m (451 feet)\n- Nave Internal Height46.2m (151.5 feet).\n- Total Area of Basilica - 21,095m² (227,070 square feet, >5 acres).\n- Internal Area of St Peter's - 15,160.12m² (163,182.2 square feet, 3.75 acres)\nSt Peter's Basilica\nPiazza San Pietro,\nTRAVEL DIRECTIONS AND GETTING THERE\nMetro: S.Pietro, Ottaviano (A)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:65fc357a-e31e-406d-a797-03ea6527a8c0>","<urn:uuid:a3ff0580-0882-4417-930e-5941ec13bae4>"],"error":null}
{"question":"What exactly is FONDEN and how does Mexico use it for earthquake recovery?","answer":"FONDEN (Fund for Natural Disasters) is Mexico's budgetary mechanism for disaster response. It ensures financing is available for rebuilding infrastructure after disasters by: 1) Using pre-agreed rules across different government levels 2) Maintaining a protected budget line 3) Utilizing reinsurance and catastrophe bonds. When earthquakes occur, FONDEN triggers the release of funds for early infrastructure rebuilding. It also has a catastrophe bond (IBRD/FONDEN 2017) worth $360 million that can be activated to provide additional relief and reconstruction funding.","context":["Hurricanes and an earthquake have caused havoc across the Caribbean and Mexico. Lives, livelihoods, roads, buildings, and infrastructure will need repair. But in the wake of these disasters, there is some surprisingly good news: Millions of dollars of relief finance are already being paid without fuss, social media campaigns, or photo-ops. What is this remarkable “innovation”? The answer is dull: it’s insurance.\nThis year, this hurricane season, we are beginning to see the benefits of pre-arranged disaster response financing.\nOne of the key problems with responding to these disasters traditionally has been that too often there are few incentives to be prepared, or to plan how to respond. There is often ambiguity about “who owns the risk” – who needs to act and who needs to pay for it.\nIn an immediate crisis, governments simply have to respond with what they have to save lives and protect citizens and infrastructure. But soon afterwards, recovery will need to start, and then the question will emerge: who will pay for what: local or national governments, international partners, families or firms? And where will the resources come from?\n\"Who owns the risk?\"\nTypically, without clarity on who will be responsible for what, and what to prioritise, recovery plans are usually just glossy reports on a dusty shelf, and funding arrangements just left for later. In poorer countries, this is about relying on what others give in response to appeals – and that’s typically less than half than what is asked for.\nOnly then, the scramble over these resources begins. This was shown in 2015, when more than $4.1 billion was raised after the earthquake in Nepal for recovery, but it took until seven months after the quake before a political agreement was reached on how to use the recovery fund. In better-off countries, we see squabbles between central and local governments, scrambling to reallocate budgets, and expectations of citizens that government will bail them out. This similarly stifles recovery efforts and their effectiveness.\nPre-agreed financing – such as sovereign parametric insurance, risk pools, or catastrophe bonds – provide incentives to change this: It forces governments to accept the risk, and clarify what they will do and won’t do when disasters strike.\nSome definitions: Sovereign parametric insurance is where a premium is paid beforehand by a government and payouts are obtained based on an objective trigger, or parameter, such as wind speed or the Richter scale for earthquakes. A sovereign risk pool works in the same way, but countries jointly own the insurance company. In a catastrophe bond, capital is paid in by private investors, who get a return each year, but they lose the capital when a disaster strikes, otherwise the capital will be returned after a pre-agreed length of time.\nAs they are based on easily observable features, these products can get resources quickly transferred into the hands of whoever is considered to own the risk in a country, typically the central government.\nMany of the affected countries in the Caribbean as well as Mexico had invested in these kind of products, mostly with clear rules on how to use the funds: paying for insurance forces you to think about what to insure. It gives hope that early recovery can be handled sensibly and effectively, without the usual political and media circus.\nIn Mexico, for example, the Fund for Natural Disasters (FONDEN) operates as a budgetary mechanism that makes sure that finance is in place for rebuilding infrastructure after earthquakes and other disasters, using pre-agreed rules across different layers of government, protected by a budget line, reinsurance, and catastrophe bond.\nThis week’s earthquake will trigger a release of funds by FONDEN, which should make the early rebuilding of key infrastructure possible, without excessive drains on public resources. Early reports suggest that the catastrophe bond (the IBRD/FONDEN 2017) will most likely be triggered too, resulting in a quick release of a large fraction of the $360 million capital to help with further relief and reconstruction.\nIn the Caribbean, the CCRIF, the Caribbean Catastrophe Risk Insurance Facility, set up 10 years ago as a risk pool with 17 member countries, has already announced it will pay out, within a fortnight, $15.6 million to the governments of Antigua and Barbuda, Anguilla and St Kitts and Nevis – providing resources to get public services and infrastructure functioning again.\nOther countries are beginning to see the benefits of entering such schemes as well. For example, after the devastation of typhoon Haiyan, the Philippines has pursued its own sovereign insurance coverage, and only this week it has completed a catastrophe insurance arrangement with international support to provide financial protection to 25 provinces against the cost of relief operations and damage from typhoons and earthquakes. A similar scheme, African Risk Capacity, provides financing related to drought.\nSetting these schemes up well is complicated, while they only really pay off if there are commensurate investments in risk reduction, public financial management, and preparedness, such as social protection plans that can be triggered after disasters.\nSome key donors are recognising that. The UK Department for International Development (DFID), which has been involved in many of these mechanisms, has also just set up a Centre for Global Disaster Protection, along with the World Bank and insurance industry players. The Centre will give fair and unbiased advice to countries on managing risk and responses, as well as evaluating financial instruments.\nNone of these financing arrangements are silver bullets. They can‘t substitute for risk reduction, solid preparedness planning, and informed decision-making.\nBut they can help to provide the glue that holds it all together, making sound planning beforehand worthwhile.\nDull? We hope so.\nHundreds of thousands of readers trust The New Humanitarian each month for quality journalism that contributes to more effective, accountable, and inclusive ways to improve the lives of people affected by crises.\nOur award-winning stories inform policymakers and humanitarians, demand accountability and transparency from those meant to help people in need, and provide a platform for conversation and discussion with and among affected and marginalised people.\nWe’re able to continue doing this thanks to the support of our donors and readers like you who believe in the power of independent journalism. These contributions help keep our journalism free and accessible to all.\nShow your support as we build the future of news media by becoming a member of The New Humanitarian."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:b50ae98a-81e9-43f4-9b64-336795dbd9c4>"],"error":null}
{"question":"Both Roger de Toeni and Pain de Tibetot faced major conflicts in their lives - how did their military engagements and ultimate fates differ?","answer":"Roger de Toeni and Pain de Tibetot had different military careers and fates. Roger engaged primarily in local Norman conflicts - he waged war against Hugh de Chateauneuf in the 1130s, supported Geoffrey of Anjou against the King of France, and was involved in conflicts that led to his capture by Robert of Gloucester in 1136 (though he was later liberated by King Stephen in 1137). He survived these conflicts and died in 1162 as lord of Flamsted. In contrast, Pain de Tibetot was involved in larger scale warfare, particularly the Scottish campaigns. He served in wars against the Scots in 1303 and 1310, and ultimately met his death at the Battle of Bannockburn on June 24, 1314, which was the largest loss of English knights in a single day where Scottish spearmen defeated heavily armored mounted knights.","context":["Family histories with citations for reference and research -- Searching: I use original spellings from various sources. -- \"It is a revered thing to see an ancient castle not in decay; how much more to behold an ancient family which has stood against the waves and weathers of time!\" - Francis Bacon.\nTuesday, November 27, 2012\nG28: 159277172 Toeni-Hainault\n159277172. Sir Roger de Toeni &\n159277173. Ida of Hainault\n8/2/1100, Henry I\ncrowned King of England.\n~1104, Roger born in England, s/o 79958530. Sir Ralph IV de Tony & 79958531. Alice of Northumberland.\n8/3/1108, Louis VI\ncrowned King of France.\n~1110, Ida born in Hainaut, d/o 378220816. Baldwin III Count of Hainaut & 378220817.Yolende of Gueldre.\n1126, Roger’s father died; his mother remarried.\n1129-35, Confirmation of the gifts made by Robert de Brus to\nthe canons of Guisborough, co. York … signatories .. the king, … Roger de\nToeni, … (S) English Historical Review, V34, 1919, P561.\n1130, Roger founded Conches abbey, “Rogerus de Totteneio filius\nRadulphi junioris” made the donation. (S) FMG.\n1130s, Roger de Tosny waged war against his neighbor Hugh de\nChateauneuf who had attacked Nogent.\n1131-33, King Henry I had his forces occupy Conches when Roger\nde Toeny, in association with William Talvas, did not appear before the court.\n(S) History of Normandy, V4, P562.\n1132, Hughes II, son of Gervais, fighting with Roger Tosny\nagainst William Monvoisin, seigneur de Rosny.\nBy 1135, Confirmation of various grant of alms made to the\nmonaster of St. Ouen, Conches, by Roger de Toesni the elder, and others. The\nsignatories are : the king and Queen Adelaide, Hugh archbishop of rouen, Auding\nbishop of Evreux, William earl of Warenne, Amaury count of Everux, Hugh [the\nking’s sewer], … (S) English Historical Review, V34, 1919, P561.\n1135, Roger de Tosny\nsupported Geoffrey of Anjou in his conflict the King of France. (S) Norman\nFrontier, Power, 2004, P382.\ncrowned king of England.\n1135-54, Roger de\nTany a tenant of the honour of Boulogne. (S) Families, Friends, Allies :\nBoulogne, Tanner, 2004, P340.\nde Tosny sized the ducal castle of Vaudreuil, widening the local conflict.\nRoger is driven out by the earl of Mellent. (S) Reign of King Stephen, Longman,\nexcutes reprisals agains the Count of Mellant for the buring of Acuigni the\ncount of Blois, began to prosecute the war against Roger de Tosny ; while\nthe earls of Mellent and Leicester [Beaumont brothers] pillaged his lands. (S)\nReign of King Stephen, Longman, 2000, P61.\n10/1136, Roger de\nConches ravages the diocese of Lisieux, pillaging the abbey of\nCroix-Saint-Leufroi, and burning the church of St. Stephen at Vauvai. Robert\nof Gloucester captured Roger de Tosny.\n5/1137, King Stephen\nof England liberated Roger de Conches.\n8/1/1137, Louis VII\nsucceeded as king of France.\ncount of Hainault, rode 150 miles across northern France to support Roger and\nIda in a war with the Earl of Leicester.\n9/7/1138, Roger de Toeni reduces to ashes the town of Bretueil.\n1138, Roger is reconciled with the earls of Leicester and\nMellent, and with King Stephen. A settlement was made whereby a daughter\n[Margaret] of Earl Robert would marry Roger’s son [Ralph].\n1140, Vincent abbey gives a palfrey to Roger Tosny and two\nounces of gold to Ida, the wife of the latter, in exchange for donations in\nEngland. (S) Prosopographie des Abbes Benedictins, Gazeau, 2007, P71.\n1140, Raoul du Fresne and Girelme, his brother, were witnesses\nto a charter of Roger de Tosny.\nBy 1142, Pont St-Pierre given back to Roger de Tosny\n[previously held by Robert of Leicester].\n1142, Roger made a confirmation to Lyre abbey at Pont\nSt-Pierre. (S) Beaumont Twins, Crouch, 2008, P55.\n1144, Roger de Conches named as a lord in Normandy of the army\nof the Count of Anjou.\n1145, Robert de Mesnil a witness to a charter of Roger de Tosny\nassociated with Mesnil-Vicomte.\n1147, Roger de Tosny, fils de Raoul le Jeune, decharge l’abbe\nVincent de l’obligation de reparer ou de refaire la chaussee de l’etang de\nFontaine. (S) Prosopographie des Abbes Benedictins, Gazeau, 2007, P71.\n12/19/1154, Henry II\ncrowned king of England.\n1155, Roger de Conches granted a charter in case of forteiture\nof the citizens of Plessis-Mahiel; witnessed by Robert de Mesnil.\n1156, Roger gave the abbey of Bernay 5 acres of land and vine\n1157, Rogo de Toeni in Norfolk and Suffolk, ‘in Holcha’. (S)\n1157-62, Roger granted a charter to Bec concerning the Norfolk\nmanor of East Wretham “to all his men either French or Normans and English.”\n9/29/1158, Roger living.\n1160, King Louis VII took possession of Nogent from Roger [but returned it later in the\n1162, Roger de Tony, lord of Flamsted, Herts, died.\n(S) Parochial and Family History of the Parish of Blisland,\nMaclean, 1868, P65. (S) Norman Frontier, Power, 2004, P295. (S) Dictionnaire\nHistorique de Toutes Les Communes, Charpillon, 1868 & 1879. (S) Ecclesiastical History of England, Vitalis,\n·Conches about 4 leagues southwest of Everux.\nChild of Roger and Ida: i. Ralph de Tony (79638586), born ~1130 in England.","1280, Pain born in Nottinghamshire, England, s/o 121691366. Robert de Tibetot & 121691367. Eve de Chaworth.\n~1290, Agnes born in England, d/o 2498748. Lord William de Roos & 2498749. Maud de Vaux.\n3/1/1297, at Bayonne, France. Robert de Tibetot made arrangements for the marriage of his son Payne.\n[––Payn & Agnes––]\n4/25/1298, The king confirmed the marriage agreement by which Robert’s son Payn would marry Anneyse, d/o William de Ros. (S) Yorkshire Inquisitions, 1902, P85.\n5/22/1298, Payn’s father died.\n3/3/1299, The King took at Certeseye the homage of Payne, son and heir of Robert de Tibotot, of the county of Notts., for the manor of Langar, which the said Robert and Eva, his wife, and the said Payne were jointly enfeoffed. (S) Record Series, V31, 1902, P85.\n11/21/1299, The King granted to Eva, widow of Robert Tibotot, the marriage of Payne, Robert’s son and heir, a minor. (S) Yorkshire Inquisitions, 1902, P85.\n8/24/1300, William de ros of Belvoir acknowledges that he owes to Payn de Tybotot £200. (S) CCRs.\n6/1301, Payn served with King Edward when he attacked Scotland and removed the Scot’s ancient coronation stone from Scone [installing it at Westminster.]\n1302-03, Pain de Tybetot held the land late of John de Berners in Streethall of the bishop of Ely for 1 fee. (S) Honors and Knights’ Fees, Farrer, 1923, P216.\n1303, Pain served in the wars against the Scots.\n2/24/1303, An English invasion force, coming by Borthwick castle near Catcune, were decimated by Scotish archers in the third and last skirmish of the battle of Roslin Muir [aka Roslin Glen]. English forces under John de Seagrave and Ralph de Confreys had already been defeated.\n8/1304 at Weymuster, John de Segrave lord of Segrave, and John de Mohun, lord of Dunsterre, agreed that John de Mohun, eldest son of the latter is to marry Christiana, daughter of the former, … Witnesses: Payn Tibetoft, … Nicholas de Segrave, … Stephen de Segrave, knights, … (S) CPRs.\n9/1304, Pain granted letters of protection to accompany Edward, Prince of Wales, across the seas. Prince Edward went to Amiens to do homage to Philip, king of France, for the duchy of Aquitiane.\n12/28/1304, Commission of oyer … By K. at the instance of Payn de Tibotot. (S) CPRs.\n3/5/1306, Robert the Bruce had himself crowned king of Scotland. Although 67 and in bad health, King Edward I marched north with his army.\n1306, Payn de Tibetot, a knight with a retinue, served under Thomas of Lancaster, in Scotland. (S) The English Aristocracy at War, Simpkin, 2008, P146.\n10/18/1306, King Edward ordered the seizure of the lands of the following for withdrawing from Scotland before the war ended: Payn Tybotot, Robert de Tony, Gilbert de Clare, Peter de Gavaston, Walter de Bello Campo, William de Bello Campo, Giles de Argenteym, Roger de Mortuo Mari, John de Haudlo, Ralph Basset, Henry de Bohun, Humphrey de Bohun, Thomas de Verdun, [and others] …\n7/7/1307, Edward II became king on the death of his father.\n8/18/1307, Commitment during pleasure to Payn Tybotot of the office of justice of the forest beyond Trent. (S) CFRs.\n1307-13, Pain summoned to parliament by writ.\n1308, Pain given a letter of protection to accompany the King across the seas. [For the wedding of the king at Boulogne.]\n4/1309, Sir Payn de Tipetoft, a banneret baron, present at the Dunstable tournament in which 235 knights participated in retinues, and 70 independently. Payn bore “argent, a saltire engrailed gules.” [His son John bore the same at the 1334 Dunstable tournament.] (S) Some Feudal Coats of Arms, Foster, 1902, P243.\n1309, Pain wrote a letter with other nobles to the Pope complaining about abuses in the church.\n10/24/1309, Order to all persons of the counties of Chester and Flynt and the cantred of Engelfeld to be intendant to Payn Tybotot, to whom the king has committed the office of justice of Chester and the castles of Chester, Rothelan and Flynt and the county of Flynt. (S) CFRs.\n1310, Pain served in the wars against the Scots.\n1310, King Edward, invading Scotland, would spend a year on the expedition with no major conflicts, using Berwick as his base of operations.\n1310, Sir Ralph Bigod acknowledged a debt of 40 marks to Payn de Typetot. (S) Norfolk Antiquarian Miscellany, 1906, P132.\n1310, Pain supported the appointment of the Lords Ordainer, a group of 8 earls, 7 bishops, and 6 barons to council the King.\n4/14/1311, “Payn Tybotot” granted a market and fair at Epperstone, Nottinghamshire. (S) Gaz. of Markets and Fairs.\nBy 1311, Payn married Agnes.\n9/3/1311, Payn Tybotot [Tiptoft] and Agnes his wife granted a market and fair at Market W8on, Yorkshire. (S) Gaz. of Markets and Fairs.\n1/25/1312, Mandate to Payn Tybotot, late justice of Chester, in consquence of his neglect to obey a former mandate of the king, … to deliver … the office of Chester … to Robert de Holand … (S) CPRs.\n1/17/1313, Prohibition, directed to all earls, barons, knights and men-at-arms, of a tournament at the town of Newmarket. … Payn de Tybotot … under pain of forfeiture … (S) CPRs.\n2/20/1314, Commission of oyer … on complaint by Payn Tibotot that Roger de Scales, … forcibley entered his free warren at Netlestede and Braunfor, co. Suffolk, … (S) CPRs.\n1314, Pain given a letter of protection to accompany the Earl of Gloucester and Queen Isabel across the seas. [Isabella testified in the adultery case in France involving her two sister’s in law Marguerite and Joan.]\n6/24/1314, Pain, knt. of Burwell, Cambridgeshire, 1st Lord Tibetot, slain at the battle of Bannockburn.\n6/24/1314, Battle of Bannockburn, Scotland, a victory for the Scots, unusual in that it lasted for 2 days. The Scots, commanded by Robert Bruce, were laying siege to Stirling castle, held by the English. As the English attacked across the brook, Robert counter-attacked along a 2000-yard front. King Edward attempted to flank the Scot’s left with archers, but they were driven back the Scot cavalry. The English front broke against the Scottish spearmen. It was the largest loss of English knights in a single day. This was the battle in which organized foot-soldiers [primarily pike men] defeated heavily armored mounted knights.\n7/18/1314, IPM of Payn de Tybotot. York: Wighton. … held of the gift of William de Ros of Haumelak to him and Agnes his wife of the king in chief by service of petty serjeanty. John son of the said Payn and Agnes, aged 1 year and 2 months, is his next heir. Nottingham: Eperiston. The manor … held jointly by the said Payn and Agnes his wife … Langar. The manor … held jointly … Suffolk: Nettlistede. The manor … Leicester: Barkeston. The manor … Thorp Edmer. The manor … Essex: Strathale. The manor … Cambridge: Borewelle. A manor … Lincoln: Merseton. A capital messuage … (S) CIsPM.\nAgnes married 2nd Sir Thomas de Vere, s/o Robert, 6th Earl of Oxford. [No children.]\n6/17/1315, Pardon to Thomas de Veer for marrying without licence Agnes late the wife of Payn Tibotot, tenant in chief. (S) CPRs.\n7/12/1316, Licence for Robert de Veer, earl of Oxford, to grant the manor of Swafham Bolebek, co. Cambridge, and the manor of Doddyngherst, co. Essex, … to Thomas de Veer and Agnes his wife … (S) CPRs.\n7/25/1318, The king … sold to Bartholomew de Badelesmere for 1000 makrs … custody … lands and tenements, late of Payn de Typetot, … minority of John son and heir of the said Payn … together with the marriage … Afterwards Thomas de Veer and Agnes his wife, late the wife of the said Payn, … sought to recover … a third part of the manor of Bentele, … which as dower … (S) CPRs.\n4/10/1320, Licence for John de Lancastre to enfeoff Robert de Veer, earl of Oxford, … remainders to Roger de Lancastre for his life, then to Thomas de Veer and Agnes his wife … (S) CPRs.\n12/2/1322, The king learns by inquisition … Gervase de Clifton holds the manor of Clifton of Thomas de Veer and Agnes. (S) CCRs.\n10/10/1327, IPM of Robert de Clifton. Nottingham: Clifton and Wilford. The manors … held for life of Thomas de Veer and Agnes, his wife, as of the right of the said Agnes. (S) CIsPM.\n3/3/1328, Grant, at the request of John de Warenna, earl of Surry, and Roger de Mortuo Mari, to Thomas de Veer and Agnes, his wife, tenants for the life of Agnes of lands which belonged to Robert and Payn Tibetot, … half-yearly instalments of 10 marks … (S) CPRs.\n1329, Thomas died.\n5/12/1329, IPM of Thomas de Veer. (S) CIsPM.\n6/1329, Agnes died.\n7/22/1329, Grant to … the lands which Agnes late the wife of Payn Tibetot, deceased, whom Thomas de Veer took to wife, held in dower or otherwise for life of the inheritance of John, son and heir of the said Payn, a minor in the king's ward. (S) CFRs.\n(S) Magna Carta Ancestry, P821.\nChild of Pain and Agnes:\ni. John de Tibetot (15210572), born 7/20/1313 in England. [Heir]"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"}],"document_ids":["<urn:uuid:d836314d-93c7-4bf5-bc72-5329a0b6217d>","<urn:uuid:0d59e37e-bc15-4a98-b79e-3b43ca6f38c3>"],"error":null}
{"question":"What are the health benefits of urban trees for city residents, and what challenges do these trees face in maintaining their health in urban environments?","answer":"Urban trees provide significant health benefits by removing up to 25% of air pollutants in their vicinity, helping prevent some of the 3 million annual deaths from air pollution-related illnesses. They also combat deadly heat waves by cooling urban environments through their canopies. However, urban trees face severe challenges to their health, including poor soil conditions with 37% lower mycorrhizal associations compared to rural areas, soil compaction, pollution, inadequate pH levels, and lack of oxygen. They also suffer from insufficient soil volumes, dog urination, smog, and bad pruning practices. Due to these harsh conditions, urban trees typically live much shorter lives than their forest counterparts.","context":["We already know that urban trees can help deter crime and prompt us to smile a bit more. We know that they mitigate stormwater runoff, sequester carbon and provide vital habitats to city-dwelling critters while lending invaluable visual appeal to otherwise foliage-starved concrete jungles. No argument here; urban trees are pretty much the best.\nWe also know that the health benefits attached to urban trees extend well beyond their uncanny mood-improving abilities. Urban trees are air scrubbers nonpareil, dutifully sucking up the pollutants that city dwellers release. This, in turn, helps the denizens of major cities breathe a bit easier — or, in more stark terms, breathe at all.\nA comprehensive new study recently released by the Nature Conservancy titled “Planting Healthy Air” takes an eye-opening deep dive into the relationship between urban trees — or lack thereof — and public health, particularly potentially fatal respiratory diseases linked to dirty city air. The takeaway of the study — at 136 pages, there’s a lot to digest — is this: the planting of trees in cities cannot and should not be underestimated as it serves as one of the most cost-effective methods of curbing urban air pollution levels and combating the urban heat island effect. We’ve all taken refuge under the shady canopy of a tree to escape from the sweltering heat at one time or another, looked up and thought to ourselves phew, what a lifesaver. As the Nature Conservancy details, this is one hell of an understatement.\nThe lead authors of “Planting Healthy Air” conclude that by investing just $4 per capita in tree-planting efforts, cities could have a lasting impact on the respiratory health of residents. Additional trees planted in cities could potentially help reverse a truly troubling reality: more than 3 million people across the globe perish each year from air pollution-related illnesses brought on by the inhalation of fine particulate matter released by human activities that involve the burning of fossil fuels. Transportation-borne particulate matter — that is, the deadly air pollution released when firing up the engine of a car — is a biggie here. Trees can remove particulate matter released within their immediate vicinity by as much as a quarter.\nWhat’s more, tens of thousands of city dwellers die each year from devastating heat waves. Given that canopies do a bang-up job of effectively cooling urban environments, their role in preventing heatwave-related deaths is also critical.\n“Trees can have a significant local impact on pollution levels and temperatures,” notes Rob McDonald, the study's primary author and a scientist for global cities at The Nature Conservancy, in a press statement. “Urban trees can save lives and are just as cost-effective as more traditional solutions like putting scrubbers on smokestacks or painting roofs white.”\nGlobally, a “conservative” investment of $10 million in urban tree planting activities could help 68 million people breathe cleaner, less deadly air and provide 77 million urbanites with the peace of mind that the next heat wave won’t be their last. As the study’s authors point out, trees are the only solution that can do both: cool and clean air.\nOf course, certain cities would benefit more from per capita tree-planting efforts than others. Looking at 245 of the world’s largest cities, the study identifies which urban areas would reap the greatest return on investment (ROI) from more trees — and a lot of them. Obviously, densely populated cities that suffer from both high levels of air pollution and are often struck with deadly heat waves top the list.\nA majority of the cities found to have the greatest ROI in terms of both cleaner air and cooling are (somewhat predictably) big, crowded, hot and located in South Asia: Delhi and Mumbai, India; Dhaka, Bangladesh; Karachi, Pakistan; Kathmandu, Nepal, and on. The African cities of Cairo, Dakar and Freetown, Sierra Leone, also make the study’s top-ROI list as does the Haitian capital of Port-au-Prince.\nWhile the study doesn’t provide case studies for all 245 cities taken into consideration, 15 cities across the globe with a desperate and not-so-desperate need for major tree-planting investments are further examined.\nAtlanta, for example, was found to have a low ROI thanks in part to one of the densest urban canopies in North America. With trees covering 47.9 percent of the sprawling southeastern metropolis (the national average for U.S. cities in 27 percent), Atlanta’s “city in the forest” nickname is more than well deserved. However, the study does point out that Atlanta’s densely populated — and only getting denser — downtown neighborhoods could benefit from additional street-side trees, particularly with regard to heat mitigation.\nUrban trees aren't just easy on the eyes. In densely populated cities with high levels of air pollution, they're also a lifesaver. (Photo: Takyua ASADA/flickr)\nDenver, touted as being a success story in combating rampant air pollution that once held the city in a sooty grip, is also noted as having an all-around low ROI that’s largely due to extensive sustainability efforts and a low population density. However, like Atlanta, Denver’s increasingly crowded downtown neighborhoods sport a high ROI.\nAnd there’s Los Angeles. While drought-ravaged, car-dependent L.A.’s citywide ROI is moderate when compared to other major global cities, localized tree-planting action is suggested in denser neighborhoods of central L.A. along with the cities of Santa Monica and Long Beach. The study concludes that an annual investment of $6.4 million in new trees in targeted neighborhoods could bring temperature-decreasing relief (a 2.7-degree Fahrenheit drop) to more than 400,000 Los Angelenos during Southern California’s sweltering summers.\nClick here to view \"Planting Healthy Air\" in full and to see how your city stacks up on the tree-planting ROI scale compared to other cities around the globe. While most North American cities do rank on the extreme low end of the ROI scale compared to let's say, Ho Chi Minh City, there is of course, always room for improvement. After all, a few more trees never hurt anyone.","Are you curious about how to connect technology with nature to bring urban green to life?\nBlogBack to blog\nTalking Trees — Part 2: What are the trees trying to say?\nImage by © Stephen Chambers\nPublished by RA Editions\nIn my new series, Talking Trees, I’m translating findings from my PhD dissertation, called the \"Internet of Nature\", into seedling-sized blogs. My research advances ecological engineering by exploring the potential of novel technologies to monitor urban ecology, particularly urban soils and forests. I believe technology can be a powerful tool—and in this series, I hope to illustrate how digitising our urban ecosystems into useful data can help us build healthier, happier, and more resilient places to live.\nIn Part 1 of Talking Trees (read here if you missed it), we asked: Do city trees talk to each other? In short, they probably don’t talk, and when they do, it’s a whisper. Even when there are tree-mycorrhizal associations, there typically aren’t enough of them to support the tree’s health.\nIn Part 2, I want to unpack why the life of a city tree is so difficult. There is a lot to unpack. For one, Bainard, Klironomos, and Gordon (2011) found mycorrhizal associations to be 37% lower in urban areas, as compared to rural areas . Why? Mycorrhizae are elusive and prefer not to ‘deal’ with urban soil issues like compaction, pollution, nutrient content, pH levels, or a lack of oxygen. For example, if polluting aluminium levels establish in the soil, the pH of the soil may be too low for effective tree–mycorrhizal associations to establish.\nTree-mycorrhizal associations may be the least of our worries, though. Even to apply the term ‘soils’ to the earth I sampled during my fieldwork is to be awfully polite. The urban soils I saw can only be described as highly variable. Often due to soil compaction, the varying contents of organic matter, or the patchy distribution of coarse natural or human-made materials such as coarse gravel or construction waste, as often even the parent material is anthropogenic in origin. In general, urban forest soil health has been little investigated due to the complexity of urban environments (e.g., variations in soil cover, land-use history, pollution, and degradation) and the difficulties of soil monitoring (e.g., limited training in accurate methods, lack of investment, and tedious and time-consuming work). Nevertheless, urban-forest soil health is the primary determinant of urban-forest health, and vice versa.\nAlthough healthy soil is fast becoming a limited commodity in cities, healthy soil, with ample microbes, should provide the foundation for healthy urban forests. However, urban trees face very different growing conditions than do forest trees; as a result, urban trees live for only a fraction of the time forest trees do. Many studies have catalogued the plight of dying urban trees, and inadequate soil quality is an important cause of this premature mortality.\nOnce the healthy-soil foundation has been established, water availability is the next consideration. Everyone knows that trees need water to live: the question is, how much?\nIf a tree has too little water during a period of drought, the tree becomes stressed. It may wilt for a little while and then bounce back—or the tree could permanently wilt. When this happens, the tree has to use more energy to recover—or it may die back completely. Watering newly planted trees is especially important, as the root zone of such a tree is not as large as that of an established tree.\nTrees that get too much water and have ‘wet feet’ for long periods can also be severely damaged. The tree will not be able to access oxygen from the soil, and the roots may begin to rot.\nPhillip Craul, a Harvard landscape ecologist once said: ‘street trees die for many reasons, but the best place to start looking for causes is in the soil.’\nIn cities, trees live fast and die young  for a number of reasons: not only smog, dog urination, insufficient soil volumes, compacted soil, and bad pruning practices, but also the fact that there is no network of fellow trees to share nutrients and information with via their roots, as mentioned above. Tree health is severely impacted by the absence of a network of close family nearby to communicate with and supply nutrients to. Some urban trees are orphans; we must foster these trees. If only we could find a way to hear what the trees had to say...\n Bainard, L. D., Klironomos, J. N., & Gordon, A. M. (2011). Arbuscular mycorrhizal fungi in tree-based intercropping systems: a review of their abundance and diversity. Pedobiologia, 54(2), 57-61.\n Smith, I. A., Dearborn, V. K., & Hutyra, L. R. (2019). Live fast, die young: Accelerated growth, mortality, and turnover in street trees. PloS one, 14(5), e0215846.\nThank you to Stephen Chambers for the beautiful illustrations. My research is made possible by the generous support of the Connecting Nature H2020 project, University College Dublin, Trinity College Dublin, Stichting Fulbright Commission the Netherlands, and MIT Senseable City Lab."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:41d6ef94-6e37-427a-988c-fef0e940e7d8>","<urn:uuid:665ef050-1134-41fa-ba46-7a9acd931efb>"],"error":null}
{"question":"Could you explain how investing in CAD/CAM software for offline programming can improve cutting operations?","answer":"Investing in advanced CAD/CAM software for offline programming can increase cutting machine utilization by eliminating downtime that occurs while waiting for programming on the CNC. Additionally, this investment can increase material utilization, leading to less waste, which is a significant cost in most cutting operations.","context":["Updating or improving your cutting operation can help increase profits by reducing costs, increasing output, or both. Depending on your objectives, you might be able to improve your operation through simple steps such as more operator training or modest software and hardware upgrades. Other enhancements may require a more significant investment in a new cutting technology or cutting machine.\nYou can often identify potential improvement areas by looking for bottlenecks or other hidden costs occurring both upstream and downstream from the cutting operation.\nWhere are the bottlenecks in your fabrication or manufacturing operation?\n- If your hand cutting stations are a bottleneck, you might be able to improve throughput by investing in machines offering faster cut speeds, or by adding automated cutting capability to your operation.\n- If you’ve already automated and your cutting table is the bottleneck, you might be able to increase productivity through software or hardware upgrades, or by moving from a slower process like oxyfuel cutting to a faster process such as HyDefinition® plasma. Moving from online part programming on the CNC to offline programming using a product like ProNest® may significantly increase your actual cutting time and therefore boost throughput. And don’t overlook the importance of operator training, or technology like SureCut™ that embeds expertise into the cutting operation.\n- If you are experiencing bottlenecks (or simply spending too much time and money) on secondary operations, improving cut quality may reduce the need for grinding, secondary beveling, or other downstream steps. There are many ways to improve cut quality – ranging from modest investments in operator training and software, height control, or torch and consumable upgrades, all the way to investing in a new machine with superior motion control.\nYou may also be able to bring some of these other operations, such as beveling or hole cutting, onto your cutting table via software and hardware enhancements; for example, by utilizing Hypertherm’s True Bevel™ or TrueHole® technologies.\nIdentify hidden costs\nInefficiency and waste in the cutting value stream also offer opportunities for improvement. Common sources of waste – and cost – include operator turnover and associated training costs, low utilization of material, poor quality parts that need to be scrapped, excessive material handling, machine downtime, overly complex software, energy inefficiency, sub-optimal consumable utilization, and even outsourcing work that could more cost-effectively be handled in-house.\nLook beyond the cutting machine\nYou might find significant opportunities for improvement both upstream and downstream from your actual cutting machine. For example, by investing in advanced CAD/CAM software used for offline part programming, an upstream activity, you may be able to increase cutting machine utilization by eliminating the downtime that results from waiting for programming on the CNC. That same investment may also increase material utilization, leading to less waste – a huge cost in most cutting operations.\nLooking downstream, you could be spending unnecessary time and money on mechanical tools and labor to prepare parts for welding or painting. Investing in cut quality improvements may reduce the need for secondary operations such as grinding or beveling, allowing you to increase your throughput of finished parts, not just the number of parts coming off your cutting table or robot."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"}],"document_ids":["<urn:uuid:61ae72d4-01b9-445c-a270-63e2c1a98cfa>"],"error":null}