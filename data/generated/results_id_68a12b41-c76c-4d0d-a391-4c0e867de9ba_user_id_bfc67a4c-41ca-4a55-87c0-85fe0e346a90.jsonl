{"question":"¿Qué herramientas tecnológicas existen para mitigar el impacto en aves, y cuáles son las tasas de colisión reportadas en los parques eólicos? 🤔","answer":"The wind industry uses technological tools like the Landscape Assessment Tool (LAT), which is a GIS-based mapping system that helps screen locations for potential wildlife conflicts early in the siting process. AWWI also maintains a Technology Catalog of detection and deterrent technologies for raptors and bats. Regarding collision rates, studies have shown they vary between 0 and more than 50 collisions per turbine per year for both birds and bats. The risk is particularly high near wetlands (where gulls are common victims) and on mountain ridges (where raptors are frequently killed). Notably, collision risk increases with turbine size, though this relationship is not statistically significant.","context":["AWWI drives the implementation of innovative strategies in the conservation and research communities and the wind development field.\nFor more than 20 years, wind energy companies have undertaken studies to assess risk and impacts to wildlife from wind energy projects. Some data are publicly available but other data are privately owned. AWWI is building the American Wind Wildlife Information Center (AWWIC, pronounced ‘a-wic'; formerly know as the Research Information System), a first-of-its kind initiative, which will securely house wind-wildlife data and make it available for scientific analysis. Collection of existing data through the AWWIC is the most promising and efficient way to increase overall understanding of risks and impacts. The scientific analysis of the data in the AWWIC, which will be guided by AWWI, will:\nTo minimize risk, wind project developers and decision makers need cost-effective tools that enable them to screen locations for potential wildlife and habitat conflicts early in the siting process. AWWI and The Nature Conservancy (TNC) built and maintain the Landscape Assessment Tool (LAT), a GIS-based, publicly-available mapping tool that collates and displays biological information that is relevant to wind-energy development. Users can display web-based maps featuring information culled from over 1,000 data layers relevant to the identification of potential wildlife and environmental impacts and to landscape-level screening for potential project sites. The LAT is a currently the only national decision support tool for energy development, with a focus on the data most relevant to wind energy.\nAWWI’s collaborative network offers a unique opportunity to bring biologist together with engineers to explore challenges and opportunities related to technological solutions to wind-wildlife impacts. By creating a forum for this interaction, AWWI serves as a catalyst for new and exciting ideas that have the potential to drastically reduce the impacts of wind energy on sensitive species.\nAWWI conducted a Request for Information (RFI) to gather information from vendors that have technology products available for immediate testing and/or deployment. The results of this RFI are compiled in a Technology Catalog made available to AWWI Partners and Friends.\nAWWI’s Technology Innovation program coordinates testing, evaluation, and verification of available and in-development technologies intended to detect and deter raptor and bat species at wind energy facilities.\nScience for Policy & Practice: Through research and tool development, AWWI provides the science that wind-wildlife stakeholders need to make decisions in the face of uncertainty. More\nInformation Exchange: Through our Partners and Friends and the National Wind Coordinating Collaborative, AWWI provides a forum to share wind-wildlife solutions and ensure that information empowers action that leads to sustainable results. More\nAWWI’s success is based on wide collaboration with all who hold a stake in the success of wind energy and the protection of wildlife and habitat. By working together, we can move toward a common goal. Here is how you can help:\nOffer your input and ideas to build the AWWI collaboration or support AWWI as a partner organization. To learn more about opportunities to engage with AWWI, contact us.\nWind Energy and Wildlife. We need both for a healthy, sustainable planet. Your donation will support AWWI’s work which generates technological innovation, policy-relevant science, and outreach and education.","Impacts on biodiversity of exploitation of renewable energy sources: the example of birds and bats – facts, gaps in knowledge, demands for further research, and ornithological guidelines for the development of renewable energy exploitation.\nThe purpose of this report is to collect and to evaluate the available information on the impacts of exploitation of renewable energy sources on birds and bats. The focus is on wind energy as there is only little information on the impact on birds and bats of other sources of renewable energy. The report aims at better understanding the size of the impact, the potential effects of re-powering (exchanging small old wind turbines by new big turbines), and possible measures to reduce the negative impact on birds by wind turbines. In addition the need for further research is highlighted.\nThe evaluation is based on 127 separate studies (wind farms) in ten countries, most of them in Germany. Most studies were brief (not more than two years) and did not include the preconstruction period. Before-After Control Impact studies that combine data collection before and after, in this case construction of a wind farm, on both the proposed development site and at least one reference site were rare. In only a few cases, would the design of the study and the length of the study period theoretically allow statistically significant effects of wind farms on birds and bats to be found at all. Assessments of impacts, therefore, are usually based on few studies only. This report includes all studies readily available to the authors, irrespective of the length of the study period and the quality of the study design. In order to base the assessments on as many independent samples as possible even rather unsystematic observations were included. The information of the data was reduced to a level that justified the application of sign tests. The compilation of many different individual studies gave the following results:\nThe main potential hazards to birds and bats from wind farms are disturbance leading to displacement or exclusion and collision mortality. Although there is a high degree of agreement among experts that wind farms may have negative impacts on bird populations no statistically significant evidence of negative impacts on populations of breeding birds could be found. There was a tendency waders nesting on open grounds to be displaced by wind farms. Some passerines obviously profited from wind farms. They were probably affected by secondary impacts, e.g. changes in land management or abandonment from agricultural use next to the wind plants.\nThe impact of wind farms on non-breeding birds was stronger. Wind farms had significantly negative effects on local populations of geese, Wigeons, Golden Plovers and Lapwings.\nWith the exceptions of Lapwings, Black-tailed Godwits and Redshanks most bird species used the space close to wind turbines during the breeding season. The minimal distances observed between birds and pylons rarely exceeded 100 m during the breeding season. Some passerines showed a tendency to settle closer to bigger than to smaller wind turbines.\nDuring the non-breeding season many bird species of open landscapes avoided approaching wind parks closer than a few hundred metres. This particularly held true for geese and waders. In accordance with published information disturbance of geese may occur at least up to 500 m from wind turbines. For most species during the non-breeding season, the distances at which disturbance could be noted increased with the size of the wind turbines. For Lapwings this relationship was statistically significant. There was no evidence that birds generally became „habituated“ to wind farms in the years after their construction. The results of the few studies lasting longer than one season revealed about as many cases of birds occurring closer to wind farms (indications for the existence of habituation) over the years as those of birds occurring further away from wind farms (indications for the lack of habituation).\nThe question whether wind farms act as barriers to movement of birds has so far received relatively little systematic scientific attention. Wind farms are thought to be barriers if birds approaching them change their flight direction, both on migration or during other regular flights.\nThere is evidence for the occurrence of a barrier effect in 81 bird species. Geese, Common Cranes, waders and small passerines were affected in particular. However, the extent to which the disturbances due to wind farms of migrating or flying birds influences energy budgets or the timing of migration of birds remains unknown.\nCollision rates (annual number of killed individuals per turbine) have only rarely been studied with appropriate methods (e. g. with controls of scarvenger activities). In particular, such studies are missing for Germany. Collision rates varied between 0 and more than 50 collisions per turbine per year for both birds and bats. Obviously the habitat influenced the number of collisions. Birds were at high risks at wind farms close to wetlands where gulls were the most common victims and at wind farms on mountain ridges (USA, Spain), where many raptors were killed. Wind farms in or close to forests posed high collision risks for bats. For both birds and bats, the collision risk increased with increasing size of the wind turbine. The relationship, however, was not statistically significant.\nGulls and raptors accounted for most of the victims. In Germany the relatively high numbers of White-tailed Eagles (13) and Red Kites (41) killed give cause for concern. Germany hosts about half of the world population of breeding Red Kites and has a particular responsibility for this species. Bird species that were easily disturbed by wind farms (geese, waders) were only rarely found among the victims. Bats were struck by wind turbines mostly in late summer or autumn during the period of migration and dispersal.\nPopulation models created by the software VORTEX revealed that significant decreases in size of bird and bat populations may be caused by relatively small (0,1 %) additive increases in annual mortality rates, provided they are not counter acted by density dependent increases in reproduction rates. Short-lived species with high reproductive rates are more affected than long-lived species with low reproductive rates. The latter, however, are less able to substitute additional mortality by increasing reproductive rates.\nThe effects of „repowering“ (substitution of old, small turbines by new turbines with higher capacity) on birds and bats is assessed by the available data and by simple models. There is no information, however, on the effects of the newest generation of very large wind turbines. According to current knowledge, repowering will reduce negative impacts on birds and bats (disturbance and mortality) if the total capacity of a wind farm is not changed (many small turbines are replaced by few big turbines). In a scenario in which the capacity of a wind farm is increased 1.5 fold, negative impacts start to dominate. In case of a doubling of wind farm capacity, repowering increases the negative impacts of the wind farm. Repowering offers the chance to remove wind farms from sites that are associated with high impacts or risks for birds and bats. New turbines could be constructed on sites that are likely to be less problematic with respect to birds and bats.\nEffective methods of reducing the negative impacts of wind energy use on birds and bats include:\n- choice of the right site for wind farms (avoidance of wetands, woodlands, important sites for sensitive non-breeding birds and mountain ridges with high numbers of raptors and vultures),\n- measures to reduce the attractivness of wind farm sites for potential collision victims,\n- configuration of turbines within wind farms (placement of turbines parallel to and not accross the main migration or flight directions of birds),\n- construction of wind turbines: replacement of lattice towers, wire-cables and overhead power lines.\nMeasures to increase the visibility of wind turbines and to reduce the effects of illumination remain to be studied.\nIn spite of many publications on windfarms and birds there still is a great demand for further research. First of all there is an urgent need for reliable data on collision rates at wind turbines of birds and bats in Germany. This holds true particularly for the new and big turbines which will replace the present generation of wind turbines.\nIt is still unclear whether these big and necessarily illuminated turbines pose a high collision risk to nocturnal migrants which have not yet been greatly affected by smaller turbines. The high collision rates of Red Kites in Germany also merit urgently study. The aim of the research has to be a quick reduction of the collision rates. The sensitivity to wind farms of many other bird species that are of particular nature conservation interest (storks, raptors, Cranes) has not yet been sufficiently studied.\nThere is hardly any information on the impacts of arrays of solar panels on birds and bats. Studies should be initiated as soon as possible."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:1835cb57-0931-402a-b978-e17f8b5cb178>","<urn:uuid:94aae7dd-018c-48dc-b84c-619735491aee>"],"error":null}
{"question":"What factors commonly distract users on websites, and how do these distractions impact bounce rates according to analytics data?","answer":"Common website distractions include pop-up promotions, auto-play videos, floating sidebars, multiple font colors, and animated elements that can frustrate users. Additionally, slow-loading pages, multiple calls-to-action (CTAs), and irrelevant advertisements significantly disrupt user experience. According to analytics data, these distractions contribute to bounce rates, which typically range between 26-70%. Particularly high bounce rates of 90% or above are considered extremely problematic. These distractions cause users to navigate away after viewing only one page, negatively impacting search engine rankings. For e-commerce sites, experts recommend aiming for bounce rates under 60%, though ideal rates vary by industry.","context":["Most Common Digital Design Distractions\nWith just seconds to capture a Web visitor's attention and guide them to complete the task they came to the site to do, Web designers often rely on elements they think will help conversions. All too often, however, these elements do the exact opposite, failing to capture the conversion because they are too distracting to the user.\nWebsite Magazine enlisted the help of 30-plus Web professions to see what common Web design elements are distracting customers, visitors, users, subscribers from completing their tasks on a company's website - and what should a brand do instead. Note, respondents had word-count restrictions or they likely would have elaborated.\n\"The biggest mistake I see business owners making is keeping an outdated site for years and years on end. If you've not got a responsive website that can be used appropriately on any device, you're losing ground against your competition.\"\n+ Travis Bennett, Founder of Studio Digita\n\"As much as metrics may suggest otherwise, websites lose and frustrate users when they continue to barrage with popup lightboxes that block content to subscribe or advertise. This includes the bottom right pop up which impedes on scrolling down.\nSolution: If subscribing is truly the only way the company can convert a customer to purchasing, then add it as a sticky bottom menu. This means it is present all of the time but allows the user to scroll and read content without interruptions.\"\n+ Emma Moore, Owner of Fundamental, LLC\n\"Forms that have a cancel/reset button. If a visitor accidentally clicks that rather than submit they will often leave the site rather than start all over.\"\n+ Stoney G deGeyter, CEO & Project Manager of Pole Position Marketing\n\"Sliders, especially sliders with footer content, are problematic and most Web design experts strongly advise against them. Even more problematic are infinite scroll websites that load the rest automatically once when you get to the bottom of the page as many customers will find it intuitive to have contact info at the bottom of the page if there is no contact info somewhere on top. Instead of sliders, use well-organized dropdown menus whenever possible.\"\n+ Alex Bar, Owner at Third Temple Digital\n\"Avoid any type of 'notify on first visit' entity. With content now so app oriented, websites are increasingly accessed via native app Web-views (e.g., via Twitter, Reddit, etc.), which means no cookies or persistent logins. Ironically, a good example of this mistake is the Euro Cookie notice law - I don’t think they realized those would show so persistently.\"\n+ Peter Holmes, Creative Director at Barefoot Solutions\n\"Many things can get in the way of people completing the intended task – on e-commerce, discount codes can be a big one where customers will see 'discount code' within the checkout and then drop out to hunt one down. Keep a small text link in the basket asking if they have a code which expands out a form field.\"\n+ Ed Baxter, Search Manager at Evoluted\n\"Poor performance is a big point of friction causing customers to leave websites.\nWeb pages have gotten too large, causing them to load slowly and react poorly to user interaction. This creates frustration and customers just leave.\"\n+ Chris Love, Owner of Love2Dev\n\"Social sharing can have a negative impact on a website’s user experience (UX) and conversions, especially on e-commerce product pages. Its inclusion can slow load times, distract users from a page’s central goal and create distrust in content or products if they include counters with low numbers. Social sharing should be used sparingly on key content or after conversions and sales.\"\n+ Sara Novak, Associate Creative Director of Elevate\n\"One of the biggest distractions for new visitors is too many calls-to-action (CTAs). Especially if your website targets very specific users, bombarding them with several CTAs will not be helpful. Instead, have a clear path that the user should take and guide them through your website one page at a time. A good place to start is only one CTA per page.\"\n+ Sacha Ferrandi, Founder and CMO of Source Capital Funding, Inc.\n\"First and foremost, keep it clean. Nothing is more of an eyesore than a clutter of different fonts, widgets, and buttons. Additionally, stay away from stock photos! They look tacky and unprofessional, and won't represent your brand--visitors will immediately leave. Choose colors that evoke your desired emotional response. Finally, stay consistent. It's important that every visual detail aligns with your brand personality in order to create trust and credibility.\"\n+ Laura Casanova, Creative Director of ONTRAPORT\n\"Pop-up promotions are becoming popular on websites and can be counterproductive if the user isn’t interested in what you are promoting. Users can get frustrated and increase your bounce rate. Brands should be cognizant of how large the ad is and how quickly and frequently it pop-up. When done properly pop-up ads can be very effective.\"\n+ Kara Jensen, Creative Principal of Bop Design\n\"Pop-over videos that obscure content and auto-play.\"\n+Stephan Roussan, President of ICVM Group\n\"While there are many website distractions now a days, one that irks me is the floating sidebar box. People often place an ad, a notification, or a signup box that follows you till the end. It comes into action as soon as you scroll the page and often breaks the rhythm of the reader.\"\n+ Sumit Bansal, Founder of Productivity Spot\n\"Some colors just hurt your eyes. For example, neon colors are usually considered as fun and cool, but only from a certain distance. If you have to see the website on your smartphone or on your 32” screen, it just hurts. It creates serious readability concerns and the brightness of the colors distract your users often overpowering your main content.\"\n+ Jitesh Keswani, CEO of e-Intelligence.in\n\"The biggest distraction for a website is a lacking understanding of our users and business goals. Funny right? That’s not a design element at all,yet too often we spend time, money and effort making design choices that don’t provide any value to our customers, nor impact our business goals because we don’t have a clear understanding of either.\"\n+ Zack Naylor, Co-Founder and CEO of Aurelius\n\"You might laugh at this, but the pages themselves. Internet surfers have short attention spans, and if your cart or ordering form is buried more than about two levels deep, they just don't use your service! Cure: reduce average number of clicks from home page (or touch down pages) to your core business pages.\"\n+ Woody Stanford, Owner of Stanford Systems\n\"Value proposition carousels are the worst. If you don’t know what value your company provides, how is a visitor supposed to figure it out? A large hero section with several headlines and calls to action looks impressive, but makes it harder for visitors to understand what your website does - and more importantly, why they should care.\"\n+ Tyler Moore, Marketing Director at App Press\n\"One of worst offenders, a sure-fire way to annoy site visitors, is auto-play video. Visitors make snap judgments about your brand upon their first visit. Auto-play video is annoying (especially if a user's speakers are on and turned up). Plus, forcing your brand on someone smells of desperation. Embedded video and background (masthead video or animation) are equal opportunity offenders.\"\n+ Tony Mariotti, Owner of RubyHome\n\"Carousels or sliders are still overused on newly designed sites. Carousels take up too much space, add distracting motion and provide too many different options for the user. We’ve moved to large Hero images with call-to-action text and a colorful button overlaid. In my experience this converts better.\"\n+ Tim Knol, Director of Digital Marketing at The Mayors Agency LLC\n\"Common distracting elements on websites include multiple font and type colors, too many boxes with contents, complex background textures, wrong alignment of fields, high-contrast colors, barely visible call-to-action buttons and a few others. For getting into the mindsets of the prospects, conversion rate optimization models can be used to help you minimize the barriers to cognition followed by A/B testing.\"\n+ Swapnil Bhagwat, Senior Manager of Design & Digital Media at Orchestrate\n\"The biggest distraction that website visitors face is the overwhelming amount of outbound links on the website they are visiting. Whether the link is through an ad - in the sidebar or in-between paragraphs - or a link in the content itself, these links are taking the visitor off the website they are visiting, removing them from the content they are reading, and leading them to another business’s website. Even if these links open up in a new tab, the chance that the visitor will return to finish reading the article or complete the original website’s call-to-action, is very small.\"\n+ Mindy Iannelli, CEO of Mindy Iannelli, LLC\n\"Your entry point to a website is NOT always your home page. Search engines like Google will display any page of a website in the search results, therefore, a visitor can enter through an inside page. Brands tend to not have the appropriate calls-to-action on their inside pages in order to guide a visitor through their website, to make contact them, or make a sale.\"\n+ Melih Oztalay is CEO of SmartFinds Marketing\n\"The worst distractions of a website design include automatic pop-up windows, and animated characters that launch into a pre-recording welcome message. The unexpected audio of animated greeters scare the user; most sites do not have audio you land on them. Second, the pop-ups and animated figures literally block the user from recovering the information he or she clicked to get from your website.\"\n+ Angela Zade, Digital Marketing Coordinator for Hawaiian Inn\n\"Advertisements are a leading cause of experience disruption on a website. Particularly advertisements that are out of context and unrelated to content that someone is inclined to find. By using them, businesses sacrifice user happiness, engagement, adoption, retention, and task completion at the expense of clicks. Alternatively, consider leveraging digital to deliver effective content and innovate business models.\"\n+ Casey Kaplan, Principal UX Designer at The Nerdery\n\"When everything is competing for attention on your Web page, your Web form needs to be as simple and easy to navigate as possible. In this day and age of distracting content on every inch of your Web page, users with only a few seconds of focus will not be pulled in by a form with a hundred mundane questions. All these questions are distracting from where you're trying to direct them to! By using less questions on your web form, you're getting enough content from them to reach out for follow up and to answer the other questions you'd like to have from them.\"\n+ April Davis, Wwner and Founder of LUMA\n\"Videos that queue automatically on a website are a huge distraction and even a turnoff to site visitors. They require the visitor to proactively turn them off in order for them to view the site and locate the information that they are seeking. If you have auto-queue videos on your site, you are almost certainly lowering your overall conversion rate.\"\n+ Jennifer M. Poole, J.D. at personalinjurylawcal.com\n\"Popups on phones are the bane of everyone's existence. Most of the time you cannot close them, rendering the site unusable—recipe sites are very guilty of this. Instead, a small, unobtrusive, bottom slide-in would let people keep scrolling while still promoting your material. This leads to a better overall user experience (and I actually get to make your recipe).\"\n+ Justin Kalaskey, Web/UX Designer at WebMechanix\n\"Popups can be an effective lead generator if used wisely. I advise to have them appear after a user has been on your site for a specific amount of time, scrolled down on the page, or clicked to view a couple of pages. Always offer something of value in exchange for their contact information.\"\n+ James Sacci, Web Developer at ProWeb Innovations\n\"Probably the worst offender in terms of distraction are email newsletter/deal sign-up forms that pop-up before you've even had a chance to look around the website. Instead, brands should be more restrained in having pop-ups or consider removing them all the same.\"\n+ Ian Wright, Founder of Merchant Machine\n\"If you're trying to capture leads or get a site visitor to complete a certain goal, having too many calls-to-action on a landing page can distract people from clicking the button that leads to your desired conversion/action. Use less enticing text links for other CTA’s or remove them from a page completely, you can display them on a thank-you page once the main goal has been completed.\"\n+ Grace Howlett, Junior Product Manager at Moonfruit\n\"A slow website - if each of your website's pages are not snappy, loading in less than 3 seconds, the slow loading time will get tedious, distracting and eventually drive the user away. This is especially true for users who are not yet familiar with the brand.\"\n+ David Attard, Founder of DART Creations\n\"One element that I find distracting on websites are text link ads. When users normally click on a link they expect to be directed to a page with relevant information. Instead, when they hover over a link, they’re getting a distracting pop-up that leads them nowhere.\"\n+ Chelsey Moter, Digital Analyst at seoWorks\n\"One of the biggest mistakes I see is having too many links pointing from sales pages to non-sales pages. Any time you give a website user something to interact with it is a distraction, and the last thing you want them to do is curiously click a link that sends them away from your sales page. You should eliminate all unnecessary interactive options from the page leaving them with basically one option - to buy.\"\n+ Brandon Howard, Owner of All My Web Needs\n\"As designers we need to be aware of common web design elements which can be distracting for users. Some of these include multiple CTAs, navigation with multiple layers of information and PPC advertising.\nHowever, many of these common elements have important roles when used is the correct way. Brands should recognize the correct use case for common Web design elements.\"\n+ Rohan Woodward, Art Director at Delphic Digital","The bounce rate. You see this stat in Google Analytics, but what exactly does it mean? Well, it’s quite simple actually. It’s the percentage of people that come to your site and then navigate away from it after viewing only one page.\nEvery single time a visitor does this it increases your bounce rate, in turn affecting your search engine rankings a little bit. High bounce rates are bad, but you must understand that every industry has its own average benchmark for bounce rates, so sometimes comparing to other companies is not always the best thing.\nGo Rocket Fuel explains that bounce rates have an even deeper meaning where they include all single interactions such as transactions and single events such as clicks. They explain that the average bounce rate usually sits somewhere in between 26 and 70 percent, but this is a rather large range, so what should you shoot for?\nYou should see what bounce rate you are currently experiencing on your site and set a goal to improve that mark in the coming year. This helps in understanding what your business is capable of doing in terms of benchmarks instead of comparing yourself to other companies.\nJust for fun though, Go Rocket Fuel says that the worst bounce rates are the ones that reach 90 percent and above. However, this is extremely high, so I would recommend shooting for something much lower if you run an e-commerce site.\nMost experts seem to agree that going for a bounce rate under 60 percent is at least a good place to start, but once again, it all depends on the site you run. You might be able to push your site to a 25 percent bounce rate or even just a 70 percent bounce rate.\nSo, the first step is taking a look at Google Analytics, waiting a few months to get some real data and then using this bounce rate to set a goal for the future. That’s all fine and dandy, of course, but a goal without action is simply a dream, so how do you go about pushing your bounce rate down? Let’s take a look.\nTry to Remove Anything That Moves on Your Site\nAlthough some components on your site might help to push sales, it’s important to always evaluate the moving parts to ensure they don’t turn off your visitors. A huge problem with many sites is popup ads that jump out in front of the real meat of your site, trying to get people to sign up for newsletters or other things.\nThese popups and other moving parts such as videos and animated gifs are fun and sometimes engaging, but they often confuse people and take them out of the moment. Many people can’t even figure out how to clear out a popup ad when it comes up, forcing them to leave your site. If you plan on having a distracting video or pop up ad on your homepage, run some split tests to see if they actually work, and consider making them smaller and out of the way.\nEnsure Your Content is Relevant and Attractive\nThis is somewhat of a no brainer, but you’d be surprised how many ecommerce sites forget about revealing relevant content when people land there. This is huge when you create ads online, since people will see an ad and have a clear vision of what they are about to see.\nIf you post an ad on Google about a discount you have on shoes, but then when people click through they land on your homepage, this is a sure fire way to increase your bounce rate. Make things relevant and design a killer homepage to keep people around.\nClean up Your 404 Pages\n404 pages are simply pages that pop up when your users have clicked through a broken link. In short, the page doesn’t exist, so they have to move elsewhere to find the content they need.\nBy default, most 404 pages don’t help the user at all, and they are quite ugly. Create a 404 page that cracks a joke or makes people smile, then give them clear instructions on navigating to the right pages on your site.\nRead more about redirects for eCommerce and when to use them.\nSpeed Up Your Site\nOne of the main reasons eCommerce sites have high bounce rates is because the site runs too slow. If users come to your site excited to purchase an item and they have to sit there and wait for your slow page loads, there is a strong chance they will navigate away.\nPeople don’t have patience to wait around for a slow site, and they often know that there are plenty of alternative options online to get something you sell.\nCheck your site speed on Pingdom and think about improving the speed of your site with an upgraded hosting account. Make sure you optimize your images and use tools like W3 Total Cache to deliver pages a little quicker to your customers.\nCurious to learn more? Read our guide on troubleshooting a slow WooCommerce site.\nGrab Those Accidental Visitors\nHow many people end up on your site accidentally? The number is probably much higher than you think, considering just about every organic visitor is simply browsing around and maybe thinking about purchasing a product you sell.\nAccidental visitors usually come from the search engines or consists of those who accidentally click through on an ad or reference from another site. The problem with accidental visitors is they have no intention of staying. Fortunately for you, there is a huge opportunity to convince these people to stay, get them to pay for an item, and decrease your bounce rate.\nStart by looking at all of the pages on your site. What is your biggest selling point? How do you differentiate yourself from other sites? Do you have a current promotion that is hard for people to pass up?\nAnswer these questions then figure out if these promotions and selling points are visible on every single one of your pages. Utilize your headers and sidebars to show selling points everywhere people go on your site. Then include clear calls-to-action and links to push them through the sales process.\nAnother practical tip — consider enabling live chat so users with questions can ping you for help.\nMake a Clear Path Through Your Checkout Process\nThis typically just involves constant testing and feedback to see if customers get frustrated with your checkout process. Check your abandoned cart rates and use this in correlation with your bounce rate to test your site and figure out why people are dropping out when they have something in their cart.\nKeeping your bounce rate down is all about testing and implementation. It’s definitely a trial and error process, but you shouldn’t let that discourage you. In fact, let that motivate you into pursuing ever greater heights with your website. So go ahead and make a goal and try to reach that goal by implementing a few of the tricks outlined here.\nBe sure to let us know if you have any other tips for keeping your bounce rate down!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:9d9f8734-8371-42dc-a1ed-7996505b5fd0>","<urn:uuid:1e098fe6-2854-4ca9-9624-48a4818df330>"],"error":null}
{"question":"What are the recommended storage requirements for water in an emergency kit, and how does the safety guidance for storing meat products during a power outage differ between various types?","answer":"For water storage in emergency kits, you should store one gallon per person per day (two quarts for drinking, two quarts for food preparation and sanitation) for at least three days. Water should be stored in plastic containers like soft drink bottles, avoiding milk cartons or glass bottles. Regarding meat storage during power outages, different types have varying safety requirements: large, solid pieces of fresh beef or lamb are least susceptible to quick spoilage, while raw chopped meats like hamburger, pork, fish, and poultry spoil quickly and should be disposed of if left in an unpowered refrigerator for 12 hours or more. Uncured sausage is particularly vulnerable and should be kept frozen as long as possible, then cooked before completely thawing.","context":["Emergency Preparedness Kit\nTo prepare your kit\nGather the supplies that are listed. You may need them if your family is confined at home. Place the supplies you’d most likely need for an evacuation in an easy-to-carry container.\nWATER- Store water in plastic containers such as soft drink bottles. Avoid using containers that will decompose or break, such as milk cartons or glass bottles. A normally active person needs to drink at least 2 quarts of water each day. Hot environments and intense physical activity can double that amount. Children, nursing mothers and ill people will need more. Store one gallon of water per person per day. (Two quarts for drinking, two quarts for food preparation and sanitation).Keep at least a three-day supply of water for each person in your household.\nFOOD- Store at least a three-day supply of nonperishable food. Select foods that require no refrigeration, preparation or cooking and little or no water. If you must heat food, pack a can of Sterno. Select food items that are compact and lightweight. Include a selection of the following foods in your Disaster Supplies Kit:\n- Ready-to-eat canned meats, fruits & vegetables.\n- Canned juices, milk, soup (if powdered, store extra water).\n- Staples such as sugar, salt, pepper.\n- High-energy foods - peanut butter, jelly, crackers, granola bars, and trail mix.\n- Foods for infants, elderly person or persons with special diets.\n- Comfort/stress food - cookies, hard candy, sweetened cereal, lollipops, instant coffee, and tea bags\n|Sterile adhesive bandages in assorted sizes.\n2-inch sterile gauze pads (4-6)\n4-inch sterile gauze pads (4-6)\nHypoallergenic adhesive tape\nTriangular bandages (3)\n2-inch sterile roller bandages (3 rolls)\n3-inch sterile roller bandages (3 rolls)\n|Tube of petroleum jelly or other lubricant.\nAssorted sizes of safety pins,\nScissors, Needle, Tweezers\nLatex gloves (2 pairs)\nMoistened towelettes, Antiseptic\nThermometer (medical), Tongue blades (2)\n|Aspirin or non-aspirin pain reliever\nAnti-diarrhea medication, Laxative\n|Antacid (for stomach upset)|\nContact your local American Red Cross Chapter to obtain a basic first-aid manual and training.\nTOOLS and SANITATION\n|Mess kits, or paper cups, plates and utensils\nBattery operated radio & extra batteries\nFlashlight and extra batteries\nCash, traveler’s checks, change\nNon-electric can opener, utility knife\nMap of the area (for locating shelters)\nEmergency Preparedness Manual\nFire extinguisher: small - ABC type\n|Tent, Pliers, Tape (duct)\nCompass Paper, pencil, Signal flare\nWhistle, Plastic sheeting\nMatches in a waterproof container\nPlastic storage containers, bags\nShut-off wrench- to turn off house gas & water\nSewing kit (needles, thread)\n|Toilet paper, towelettes\nSoap, liquid detergent\n|Plastic garbage bags, ties\nPlastic bucket with tight lid\nDisinfectant- chlorine bleach\nCLOTHING and BEDDING\nInclude at least one complete change of clothing and footwear per person including sturdy shoes or work boots, rain gear, blankets or sleeping bags, sunglasses, thermal underwear, hat and gloves.\nRemember family members with special needs, such as infants and elderly or disabled persons.\nFormula, diapers, bottles, medications, powdered milk\nHeart and high blood pressure medication, other prescription drugs, Insulin, extra eye glasses,\ncontact lenses and supplies, denture needs\nIMPORTANT FAMILY DOCUMENTS\nKeep these records in a waterproof, portable container.\nWill, insurance policies, contracts, deeds, stocks and bonds, passports, social security cards, immunization records.\nIf you have pets, include the following items in your kit:\nIdentification collar and rabies tag\nPet carrier or cage\nNewspaper, litter, trash bags for waste\nTwo-week supply of food and water\nVeterinary records (necessary if your pet has to go to a shelter)","Bulletin #9003, Safety of Refrigerated Foods After a Power Outage\nPrepared by Mahmoud El-Begearmi, Extension specialist, nutrition and food safety, University of Maine\nAll chopped meats, poultry, and seafood sandwich fillings should not be left without refrigeration for more than two hours. If you have to leave your home without an ice chest containing ice, take cold ingredients to mix and eat as soon as you arrive. If any is left over, throw it away.\nDo not trust your sense of smell. Food may be unsafe, even if it doesn’t smell bad.\nYou can extend your food supply by cooking all unspoiled meat immediately. Cooked meat needs to be kept above 140 degrees F if it cannot be cooled below 40 degrees F within two hours. A food thermometer will help you check food temperatures.\nHere are some tips on popular perishable foods.\n- Large, solid, unbound pieces of fresh beef or lamb, such as rump roast or leg of lamb, are least susceptible to quick spoilage.\n- Uncured sausage is vulnerable to contamination because it is free of preservatives. Keep it frozen as long as possible, then cook before it completely thaws.\n- Raw chopped meats, like hamburger, spoil quickly. Pork, fish and poultry spoil quickly, too. Dispose of these foods if they have been in a well-insulated, good working refrigerator without power for 12 hours or more. Do not trust your sense of smell. Food may be unsafe, even if it doesn’t smell bad.\n- Hard cheese usually keeps well at room temperatures. Other cheeses, such as cream cheese, opened containers of cheese spreads and cottage cheese, spoil quickly. Throw them out when an off-flavor or unusual mold develops.\n- Milk spoils quickly without refrigeration. Throw out spoiled milk. Soured milk may be used in baking.\n- Custard, gravies, creamed foods, chopped meats, poultry, and seafood sandwich fillings spoil quickly when unrefrigerated. They are ideal growing places for organisms that can make you sick. Dispose of these foods if they have warmed to over 40 degrees or room temperatures. Spoilage is hard to detect since they may not smell or taste bad.\n- Commercially made baked goods with cream fillings are not safe if unrefrigerated. Keep them cold, and eat as quickly as possible.\n- Accidentally frozen canned goods can present health problems. If they are merely swollen—and you are sure the swelling was caused by freezing—the cans may still be usable. Let the can thaw in the refrigerator before opening it. If the product does not look or smell normal, throw it out. Do not taste it! However, if the food does look and smell normal, thoroughly cook it by boiling for 10 to 20 minutes right away. But if the seams have rusted or burst, throw the cans out immediately.\nSource: “Safety of Refrigerated Foods After a Power Failure,” University of Florida Institute of Food and Agricultural Sciences, 1997.\nInformation in this publication is provided purely for educational purposes. No responsibility is assumed for any problems associated with the use of products or services mentioned. No endorsement of products or companies is intended, nor is criticism of unnamed products or companies implied.\n© 1998, 2010\nCall 800.287.0274 (in Maine), or 207.581.3188, for information on publications and program offerings from University of Maine Cooperative Extension, or visit extension.umaine.edu.\nThe University of Maine is an EEO/AA employer, and does not discriminate on the grounds of race, color, religion, sex, sexual orientation, transgender status, gender expression, national origin, citizenship status, age, disability, genetic information or veteran’s status in employment, education, and all other programs and activities. The following person has been designated to handle inquiries regarding non-discrimination policies: Sarah E. Harebo, Director of Equal Opportunity, 101 North Stevens Hall, University of Maine, Orono, ME 04469-5754, 207.581.1226, TTY 711 (Maine Relay System)."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:2808185f-bde0-49b8-94f6-74ac51a9652f>","<urn:uuid:66c3812c-a209-46d4-9e1a-55916ec7e507>"],"error":null}
{"question":"What role do valleys and ridges play in roof design, and how does sustained sun exposure affect these structural elements over time?","answer":"Valleys and ridges serve crucial structural purposes in roof design - valleys form V-shaped junctions between sloping roofs to facilitate water drainage, while the ridge forms the roof's highest point or peak and requires special shingle types. However, sustained sun exposure can compromise these elements over time. The sun's UV radiation causes degradation of roofing materials, leading to problems like split seams and cracking. Dark-colored roofing materials in these areas particularly retain heat even after sunset, continuing to compromise the roof's integrity and potentially affecting the overall structure.","context":["Other than shingles, what else goes into constructing a roof? Prepare for your roofer's visit by looking over and being familiar with the shingle roof diagram.\nWhat are the Common Parts of a Shingle Roof Diagram?\n1. Roof ridge\nRoof Ridge Often referred to as the peak, the roof's highest point may be found here. A roof's hips and ridges need a certain kind of shingle.\n2. Ridge vent\nRidge vent Use our attic ventilation calculator to figure out how much exhaust ventilation you'll need to keep your roof and attic adequately ventilated.\n>>Related Post: How To Measure A Roof For Shingles From The Ground\nTo keep water out, flashing is a metal covering placed over joints, chimneys, and any skylights or dormer windows. Metal stair steps next to a chimney, or side walls of a roof, may be flashing to you.\nIt is the junction of two roof planes that meet to produce a sloped ridge extending from peak to bottom of the roof. They have been mainly built for this particular area of a roof.\n5. Roof deck\nIt is the structural basis of the roof system, where plywood or wood is often used.\n>>Related Post: A Guide to the Installation of Asphalt Shingles\n6. Roofing underlayment\nAn additional layer of protection for the roof deck and the shingles may be found in the form of synthetic or felt underlayment. Underlayment made of synthetic materials helps keep moisture at bay and guards against leaks. It's becoming more fashionable to use synthetic underlayment instead of felting because of its proven water resistance and long-lasting durability.\n7. Roof valley\nA V-shaped junction of two sloping roofs merging at an angle to facilitate water drainage is known as a \"roof valley.\"\n8. Laminated Architectural Shingles\nAs an architectural shingle, it might be called three-dimensional shingles or laminated, depending on the context. Architectural shingles are the antithesis of three-tab shingles, constructed as a single layer of tabs that seem flat or lacking in dimension.\n9. Roof gable\nIt is the triangular piece of the outside wall that is at the pinnacle of the roof and is situated between an inclining roof and an eavespread. Roof gables are also called rakes.\n>>Related Post: Pros And Cons Of Utilizing Solar Shingles For Your Home\n10. Metal drip edge\nThis non-corrosive metal drip edge is utilized at the rake and eave to assist control dripping water and maintaining the wall's underlying portion by aiding runoff.\nA dormer is a portion of a roof that has been elevated. One of the most typical features of dormers is the inclusion of a window that extends vertically through the roof slope.\n12. Ice and water barrier\nSelf-adhered waterproofing material is put along eaves, valleys, side walls, and other susceptible places to prevent ice damage from wind-driven rain.\n13. Roof eaves\nThis part of a roof extends outward from the main body of the structure, and it is often found in the first three feet of a roof.\n14. Undereave vent\nThis kind of vent helps bring cold, dry air into an attic by being situated under the eaves. Again, you can use our ventilation calculator to figure out how much intake ventilation you need to adequately ventilate your attic and roof.","Sunlight Damage on Roof\nSimilar to the effects of the Sun on your skin, it is important to note that commercial roofing systems are also very sensitive to the Sun. Particularly, in certain areas of the United States like the Western parts. The geographical locations are heavily impacted by the amount of Sun they get. For instance, if you reside in the Los Angeles area, the amount of Sun that you will get is about 44% of the time throughout the year. Unfortunately, even though some people may enjoy this warm weather, this amount can wreak havoc on roofing systems, especially because the Sun is composed of both UV radiation and infrared radiation.\nSunlight Damage on Roof\nNegative Domino Effects of Sunlight on Your Roofing\nThere are a number of different negative domino effects that you will most likely see on your roof today. Some of the more commonly known include bumps, cracks as well as other kinds of damages. In fact, as the beams of the Sun break down the roofing material, it causes the chemicals in the seam sealants to split and open prematurely over time. In addition to the seams of the roofing opening up, the damages from the Sun can also adversely affect the fasteners on the roof because of the pulls, tears and the twist that negatively compromises the fasteners. Further damages may be caused by the integrity of the roof, even after the Sun has set in the afternoon. This is because dark coloring on your roofing system will inherently hold onto the heat and will not allow it to cool down. Thereby, causing the heat that remains to continue to compromise the integrity of your roof.\nHidden Damages Exposed When Ultraviolet Radiation Compromises the Roofing\nEven more insidious, you will also discover that the ultraviolet radiation, another part of the sunlight, is not easily detected but imposes a lot of extra damage to the roofing’s overall structure. Therefore, it does not matter what kinds of materials used in your roofing system, the degradation continues in pretty much any type that is installed (i.e. single-ply-membrane, bitumen and others). Also, because this is hidden damage that is being done behind the scene in a more subtle fashion, no one will notice that these problems have been occurring until the rain clouds move in as the Sun goes away. Hence, when you inspect the roofing system on your building, the after effects usually show split seams, cracking, and blistering that will ultimately allow water flows to work their way down inside the building causing all kinds of interior damage.\nDealing with the damages that occur to your roofing system can be a huge issue for you when you are impacted by its effects. Due to the severe damages that the Sun can cause on the roofing materials and the seams in the design, the damages can completely destroy the tops of your building. To avoid these issues and damages, it is important to note that many property owners are turning to a newer innovative solution that is called cool roof systems."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:8b9f3ddd-340d-4478-ac84-95bee59742a3>","<urn:uuid:291efccb-36a3-4d9e-8aa6-d189339caf38>"],"error":null}
{"question":"How has string theory been successfully applied to study graphene, and what does this mean for understanding superconductors?","answer":"Methods inspired by string theory have led to quantitative predictions about the flow of heat and electrical charge in graphene that have been experimentally verified. While graphene is considered a 'less-strange' metal compared to high-temperature superconductors, this success represents one of the best validations of string theory methods in material physics. However, whether these methods will work for high-temperature superconductors remains unproven, as they are more complex systems than graphene.","context":["Taming Superconductors With String Theory\nString theory was devised as a way to unite the laws of quantum mechanics with those of gravity, with the goal of creating the vaunted “theory of everything.”\nSubir Sachdev is taking the “everything” literally. He’s applying the mathematics of string theory to a major problem at the other end of physics — the behavior of a potentially revolutionary class of materials known as high-temperature superconductors.\nThese materials are among the most promising and the most perplexing. Unlike regular superconductors, which need to be cooled almost to absolute zero (–273.15 degrees Celsius) to pass a frictionless current of electricity, high-temperature superconductors yield the same remarkable performance under more accommodating conditions. Since the first high-temperature superconductor was discovered in 1986, physicists have found other materials that exhibit superconductivity at successively higher temperatures, with the current record standing at –70 degrees Celsius.\nThis progress has occurred despite the fact that physicists don’t understand how these superconductors work. Broadly speaking, many condensed-matter physicists study how electrons — the carriers of electrical current — move through a given material. In an ordinary conductor like copper or gold, the electrons flow through a lattice formed by the copper or gold atoms. In an insulator like diamond, electrons tend to stay put. In superconductors, electrons move through the underlying atomic lattice with no energy loss at all. For three decades, physicists have been unable to develop a comprehensive theory that explains how electrons in high-temperature superconductors behave.\nA particularly interesting question is how the behavior of the material changes with temperature — in particular, how conductors transition from ordinary to super as the temperature drops. Scientists call this a “quantum phase change,” with the two phases being the property of the material on either side of the transition temperature.\nSachdev, a condensed-matter physicist at Harvard University, explains that the challenge is one of scale. A typical chunk of material has trillions upon trillions of electrons. When those electrons interact with one another — as they do in superconductors — they become impossible to keep track of. In some phases of matter, physicists have been able to overcome this scale issue by modeling swarms of electrons as “quasiparticles,” quantum excitations that behave a lot like individual particles. But the quasiparticle strategy doesn’t work in high-temperature superconductors, forcing physicists to look for another way to impose collective order on the behavior of electrons in these materials.\nIn 2007 Sachdev had a startling insight: He realized that certain features of string theory correspond to the electron soup found in high-temperature superconductors. In the years since, Sachdev has developed models in string theory that offer ways to think about the electron behavior in high-temperature superconductors. He’s used these ideas to design real-world experiments with materials like graphene — a flat sheet of carbon atoms — which have properties in common with the materials that interest him.\nIn a forthcoming paper in Science, he and his collaborators use methods borrowed from string theory to correctly predict experimental results related to the flow of heat and electrical charge in graphene. Now he hopes to apply his insights to high-temperature superconductors themselves.\nQuanta Magazine spoke with Sachdev about how the electrons in high-temperature superconductors are related to black holes, his recent success with graphene, and why the biggest name in condensed-matter physics is skeptical that the string-theory approach works at all. An edited and condensed version of the interview follows.\nQUANTA MAGAZINE: What’s going on inside a high-temperature superconductor?\nSUBIR SACHDEV: The difference between old materials and the new materials is that in older materials, electrons conduct electricity independent of one another. They obey the exclusion principle, which says electrons can’t occupy the same quantum state at the same time and that they move independently of one another. In the new materials that I, and many others, have been studying, it’s clear that this independent-electron model fails. The general picture is that they move cooperatively and, in particular, they’re entangled — their quantum properties are linked.\nThis entanglement makes high-temperature superconductors much more complicated to model than regular superconductors. How have you been looking at the problem?\nGenerally I approach this through the classification of the quantum phases of matter. Examples of simple quantum phases are simple metals like silver and gold, or simple insulators like diamonds. Many of these phases are well-understood and appear everywhere in our daily lives. Since we discovered high-temperature superconductors, and many other new materials, we’ve been trying to understand the other physical properties that can emerge when you have trillions of electrons obeying quantum principles and also interacting with each other. At the back of my mind is the hope that this broad attack on classifying quantum phases of matter will lead to a deeper understanding of high-temperature superconductors.\nHow far have you gotten?\nThere has been great progress in understanding the theory of quantum phase transitions, which involves taking two phases of quantum matter that are very different from each other and adjusting some parameter — say, pressure on a crystal — and asking what happens when the material goes from one phase to the other. There has been a huge amount of progress for a wide class of quantum phase transitions. We now understand many different kinds of phases we didn’t know existed before.\nBut a full theory of how electrons behave in high-temperature superconductors has been difficult to develop. Why?\nIf you have a single electron moving through a lattice, then you really only need to worry about the different positions that electron can occupy. Even though the number of positions is large, that pretty much is something you can handle on a computer.\nBut once you start talking about many electrons, you have to think about it very differently. One way to think about it is to imagine that each site on the lattice can be either empty or full. With N sites it’s 2N, so the possibilities are unimaginably vast. In this vast set of possibilities, you have to classify what are reasonable things an electron would tend to do. That in a nutshell is why it’s a difficult problem.\nReturning to phase transitions, you’ve spent a lot of time studying what happens to a high-temperature superconductor when it grows too warm. At this point, it becomes a so-called “strange metal.” Why would understanding strange metals help you to understand high-temperature superconductors?\nIf you start with a superconductor and raise the temperature, there’s a critical temperature at which the superconductivity disappears. Right above this temperature you get a type of metal that we call a strange metal because many of its properties are very different from ordinary metals. Now imagine reversing the path, so that the phase of a system is changing from a strange-metal state to a superconducting state as it goes below the critical temperature. If we’re going to determine the temperature at which this happens, we need to compare the energies of the quantum states on either side of the critical temperature. But strange metals look strange in every respect, and we have only the simplest models for their physical properties.\nWhat makes strange metals so different from other unique quantum phases?\nIn certain phases, [quantum] excitations generally behave like new emergent particles. They are quasiparticles. Their inner structure is very complicated, but from the outside they look like ordinary particles. The quasiparticle theory of many-body states pretty much applies to all states we’ve discovered in the older materials.\nStrange metals are one of the most prominent cases we know where quasiparticle theory fails. That’s why it’s so much harder to study them, because this basic tool of many-body theory doesn’t apply.\nYou had the idea that string theory might be useful for understanding quantum phases that lack quasiparticles, like strange metals. How is string theory useful in this setting?\nFrom my point of view, string theory was another powerful mathematical tool for understanding large numbers of quantum-entangled particles. In particular, there are certain phases of string theory in which you can imagine that the ends of strings are sticking to a surface. If you are an ant moving on the surface, you only see the ends of the string. To you, these ends look like particles, but really the particles are connected by a string that goes to an extra dimension. To you, these particles sitting on the surface will appear entangled, and it is the string in the extra dimension which is entangling the particles. It’s a different way of describing entanglement.\nNow you could imagine continuing that process, not just with two electrons, but with four, six, infinitely many electrons, looking at the different entangled states the electrons can form. This is closely connected to the classification of phases of matter. It’s a hierarchical description of entanglement, where each electron finds a partner, and then the pairs entangle with other pairs, and so on. You can build this hierarchical structure using the stringy description. So it is one approach to talking about the entanglement of trillions of electrons.\nThis application of string theory to strange metals has some interesting implications. For instance, it’s led you to draw connections between strange metals and the properties of black holes. How do you get from one to the other?\nIn the string-theory picture, [changing the density of electrons] corresponds to putting a charge on a black hole. Many people have been studying this in the last five years or so — trying to understand things about strange metals from the properties of charged black holes. I have a recent paper in which I actually found a certain artificial model of electrons moving on a lattice where many properties precisely match the properties of charged black holes.\nI’ve read that Philip Anderson, considered by many people to be the most-influential living condensed-matter physicist, is skeptical that string theory is really useful for understanding strange metals. Do you know if that’s true?\nI think that’s correct. He’s told me himself that he doesn’t believe any of this, but, you know, what can I say, he’s a brilliant man with his own point of view. I would say that when we first proposed the idea in 2007, it certainly sounded crazy. A lot of progress has been made since then. I have a new paper with Philip Kim and others where it turns out that with graphene, which is a slightly less-strange metal, many of the methods inspired by string theory have led to quantitative predictions that have been verified by experiments.\nI think that’s been one of the best successes of the string-theory methods so far. It literally works; you can get the numbers right. But graphene is a simple system, and whether these methods are going to work for high-temperature superconductors hasn’t yet been proven.\nCould you say more about why Anderson might be skeptical of the approach you’ve taken?\nIf you go back and actually look at string-theory models, on the surface they look very different from the kinds of models you need for high-temperature superconductors. You look at the stringy models and their constituents, and it appears absurd that these are connected to the constituents of the high-temperature superconductors. But if you take the point of view that, OK, I’m not literally saying this model is going to be found in [high-temperature superconductors], this is just a model that helps me make progress on difficult issues, like how do materials without quasiparticles behave, string theory gives you examples of one of these materials that’s reliably solvable.\nHow literally are you using string theory? Is it a direct application, or are you drawing inspiration from it?\nIt’s closer to the inspiration side of things. Once you’ve solved the model, it gives you a lot of insight into other models that you may not be able to solve. After six or seven years of work closer to the string-theory side, we think we’ve learned a lot. For us the next step appears to be working in more realistic systems using inspiration we got from more solvable models.\nHow might the string-theory models, plus the work on graphene, put you in a position to understand the properties of high-temperature superconductors?\nAs you change the density of electrons in high-temperature superconductors, there’s a much more dramatic change in which the electrons go from a regime where it seems only a few electrons are mobile to one where all electrons are mobile. We’re understanding that there’s a special point called the optimal density where there seems to be a dramatic change in the quantum state of electrons. And right near this point is where the strange metal is also observed. We’re trying to work out microscopic theories of this special point where the quantum state changes, and stringy models can teach us a lot about such quantum-critical points. Once we have the full framework, we’re hopeful and optimistic that we can take many of the insights from graphene and apply them to this more complicated model. That’s where we are.\nThis article was reprinted on ScientificAmerican.com."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:596d2beb-2f73-45b3-9e6e-a9f6482cacab>"],"error":null}
{"question":"How do I participate in the online version of the program and what technical requirements are needed?","answer":"To participate in the online program, you will need to download the Zoom application if not already installed. No Zoom account is required. You'll be asked to register upon connecting to the webinar, but advanced registration is not necessary. For security reasons, attendees won't have video or audio capabilities, and questions will be moderated by Museum staff. Private messaging between participants is not allowed. The program includes automated closed captioning.","context":["Summer Family Program: Rockin' Rhythms\nOnsite & Online Family Program\nLearn about the guitar’s evolution from acoustic to electric as well as its influence on modern music. Experiment with the guitar and learn fundamentals like chords, rhythm, and song structure. We’ll listen to some of the most iconic guitar riffs and discover Texas guitarists who have made musical history, like Stevie Ray Vaughn, Glary Clark Jr., and Jackie Venson. Be prepared to learn and rock out! The program is best suited for ages 5-9. No musical experience is required. Inspiration for this program comes from the Bullock Museum's exhibition, Guitar: The Instrument That Rocked The World, and the Museum's Texas History Galleries.\nRegister for our virtual program as our limited capacity in-person program at the Museum is sold out. The in-person program will follow safety procedures of the Museum. Please review the procedures to ensure that all participants will enjoy a safe, healthy, and engaging experience.\nProgram is FREE to the public.\nYour Support Matters\nHelp us continue to share the story of Texas through free programs with a tax-deductible donation.\nEnjoy discounts, exclusive programs, and free access to exhibitions year-round by becoming a member of the Bullock Museum.\nTwenty years of experience and hundreds of thousands of students have taught us that playing music with others results in stronger proficiency compared to conventional music education. Working toward and experiencing live performance is the core of our curriculum. Our students grow as individuals by taking the stage with others. While our students work with bandmates, they learn broader life skills like collaboration, compromise and courage.\nWe call this revolutionary approach to music education The School of Rock Method™. The School of Rock Method builds musical proficiency through our proprietary Method App, Method Book collection, SongFirst approach, and performance-based music curriculum. Our Method has been awarded a patent making our teaching system available nowhere else.\nFamily programs provide educational and engaging activities for young Texans and their caregivers. Events are designed to bring families together, spark conversations and provide opportunities for growth and development.\nAt the Bullock Museum, programs have been a place for the community to gather and celebrate culture, explore new ideas, and share experiences together. During the COVID-19 pandemic, programs still provide an opportunity to bring the community together, even if we are apart. Please join us through virtual programs and enjoy lessons, discussions and activities with your family, friends and neighbors who are also participating from home.\nThe online portion of this program has automated closed captioning.\nYou will be prompted to download the Zoom application for mobile or desktop if it is not already installed. You do not need a Zoom account to join this livestream. You will be asked to register upon connecting to the webinar. Advanced registration is not required.\nFor security and privacy purposes, attendees will not have video or audio capabilities. Questions will be moderated by Museum staff. Participants will not be allowed to send private messages or media in the livestream.\nGUITAR: The Instrument That Rocked The World is a Touring Exhibition by The National GUITAR Museum.\nThe Bullock Texas State History Museum is a division of the State Preservation Board. Additional support of exhibitions and programs is provided by the Texas State History Museum Foundation."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:5a54299a-7d4e-4092-9a5a-e3f945560416>"],"error":null}
{"question":"How do DNA testing methods differ in their ability to resolve paternity cases between the 1960s Fronczak case and modern RFLP analysis?","answer":"In the 1960s Fronczak case, only basic blood tests were available which could only determine if parentage was 'not inconsistent,' leading to an incorrect identification of a found toddler as Paul Fronczak. In contrast, modern RFLP analysis provides much more definitive results by examining specific DNA sequences and banding patterns. RFLP can clearly establish or exclude paternity by analyzing multiple loci, where matching bands between parent and child must be present at several genetic locations. While a single RFLP locus match could leave some uncertainty, testing multiple RFLP loci makes it highly unlikely for two unrelated individuals to share the same pattern, except in the case of identical twins.","context":["“How do you like the name Jack?” the woman on the phone asked.\nOn April 26, 1964, a nurse came into the hospital room of Dora Fronczak, who had just given birth to her young son, Paul. She told Mrs. Fronczak that it was time to take the baby to the nursery (at that time newborns did not stay in the room with the moms), took the baby, and left. A few hours later, another nurse came into the room to take young Paul to the nursery. It was then that everyone realized a mother’s worst fear: Her infant had been stolen.\nAuthorities were able to determine how the woman left the hospital and that she got into a cab, but they were never able to find the woman. However in 1965, a small toddler-aged boy was found, abandoned outside a store in New Jersey. Blood tests were not inconsistent with him being Paul Fronczak (DNA testing was not available), and there were no other missing children cases in the area that were matches. The little boy was sent to Chicago as Paul Fronczak and the case was closed.\nHowever, as an adult Paul Fronczak, began to suspect that the couple who raised him were not his biological parents, and in 2012 Paul underwent DNA analysis to test his suspicions. The results showed that indeed, he was not the biological son of Dora and Chester Fronczak. His next step was to enlist the help of a genetic genealogist to assist him in finding his true biological parents and his identity.\nBy conducting “familial searches” using commercially available DNA databases like 23andMe and AncestryDNA and many resources, the genealogist’s group found a match to his DNA on the east coast. Further ground work, discovered that this family was indeed Paul’s…now Jack.\nThe knowledge of Jack’s true identity, didn’t bring with it a joyous union of the adoptive family who had raised and loved Jack (as Paul) with the biological family who had pined for him over the years as many might imagine.\nJack’s biological parents and one of his siblings had passed away, and much of his story with them. The story that remains is one of mystery and intrigue. He has a twin sister, and he and his twin sister went mysteriously “missing” around age two. His biological parents told the father’s side of the family that the twins were with the mother’s family, and not to ask questions. Similarly, they told the mother’s side of the family that the twins were with the father’s family and also not to ask questions. The disappearance was never reported. Family albums that had pictures of the twins were altered to remove any evidence that the children ever existed. Jack, does not know what became of his twin sister, Jill.\nJack knows his biological origins, but he doesn’t know why he was abandoned or what happened to his twin sister. The Fronczaks still do not know what happened to Paul Joseph Fronczak, stolen from his mother’s arms that day in 1964. A stolen baby case now cold again. A new mystery and another missing person. At the center of it all lies DNA.\nWhen Answers Yield Questions\nThis story illustrates the power of asking questions to find the truth. It’s what scientists do. Day in. Day out. This story also illustrates what happens when you ask questions to find the truth: Truths can be confusing, sometimes unpleasant and often lead to more questions. Many of us who have pursued training in the sciences relish the messy answers and puzzles. However, many people are not so comfortable with answers that muddy the picture. We are taught in school that questions have answers. We take tests and get things right or wrong. So, it is not surprising that much of the general public enters into DNA testing with an expectation of definitive answers that are clear and actionable.\nJack’s story illustrates the power of DNA familial searches when combined with resources, determination and skill. It is also brings to mind many ethical questions about the accumulation of genetic information in commercial DNA biobanks like those being built by 23andMe and AncestryDNA. Ethical concerns and discussions of guideline development, protections of rights, etc. have swirled around official databases such as CODIS for years. We have even written about how familial searching works and its promise and ethical dilemmas in the criminal forensics environment. However, little discussion has happened around commercial DNA databases and biobanks.\nSuch discussion would include questions about access, protections and informed consent. Who has access to the information in these biobanks for research? How are the individual identities associated with the genomes protected? Can the systems be hacked from outside? What are the guidelines for gaining informed consent when someone mails swab in for testing? How does the business ensure that the sample was collected voluntarily? What obligation do they have to do so? Can a sample be collected by someone with guardianship or power of attorney?\nAlthough these biobanks have noble goals of connecting people with their past or helping people better understand their health risks, there is little protection governing the misuse of the information in these databases. For instance, could insurance companies use these genetic databases to identify populations based on geography or ethnicity that have higher proportions of genetic alleles that are associated with chronic diseases? Then could such information be used to deny people from these populations coverage for these diseases, even though the associations that are known are not cause-effect, may be heavily dependent on environmental influences and the totality of an individual’s genetic background?\nThe technology and information gathering have progressed exponentially, while the understanding of or even the willingness to discuss the risks involved in maintaining such information databases and biobanks have proceeded at a snail’s pace.\nJack’s story is powerful, and like any powerful story, it spurs discussion and imagination. If you are interested in this story and others like it, consider attending the International Symposium on Human Identification, ISHI28 in Seattle, WA, USA this year.\nFurther Reading on the Fronczak Case\nBreakthrough in Paul Fronczak mistaken identity kidnap case, Las Vegas TV report says http://chicago.suntimes.com/news/breakthrough-in-paul-fronczak-mistaken-identity-kidnap-case-las-vegas-tv-report-says/ [accessed 4/20/2017]\nPaul Joseph Fronczak The Charley Project website http://www.charleyproject.org/cases/f/fronczak_paul.html [accessed 4/20/2017]\nVideo news report about the case https://www.youtube.com/watch?v=C8gzjGhyJqY [accessed 4/20/2017]","RFLP (often pronounced \"rif lip\", as if it were a word) is a method used by molecular biologists to follow a particular sequence of DNA as it is passed on to other cells. RFLPs can be used in many different settings to accomplish different objectives. RFLPs can be used in paternity cases or criminal cases to determine the source of a DNA sample. RFLPs can be used determine the disease status of an individual. RFLPs can be used to measure recombination rates which can lead to a genetic map with the distance between RFLP loci measured in centiMorgans.\nOn this web page, you can see how RFLPs are produced and then three examples of applying RFLP analysis: paternity, disease status, and genetic mapping.\nEach organism inherits its DNA from its parents. Since DNA is replicated with each generation, any given sequence can be passed on to the next generation. An RFLP is a sequence of DNA that has a restriction site on each end with a \"target\" sequence in between. A target sequence is any segment of DNA that bind to a probe by forming complementary base pairs. A probe is a sequence of single-stranded DNA that has been tagged with radioactivity or an enzyme so that the probe can be detected. When a probe base pairs to its target, the investigator can detect this binding and know where the target sequence is since the probe is detectable. RFLP produces a series of bands when a Southern blot is performed with a particular combination of restriction enzyme and probe sequence.\nFor example, let's follow a particular RFLP that is defined by the restriction enzyme EcoR I and the target sequence of 20 bases GCATGCATGCATGCATGCAT. EcoR I binds to its recognition seuqence GAATTC and cuts the double-stranded DNA as shown:\nIn the segement of DNA shown below, you can see the elements of an RFLP; a target sequence flanked by a pair of restriction sites. When this segment of DNA is cut by EcoR I, three restriction fragments are produced, but only one contains the target sequence which can be bound by the complementary probe sequence (purple).\nLet's look at two people and the segments of DNA they carry that contain this RFLP (for clarity, we will only see one of the two stands of DNA). Since Jack and Jill are both diploid organisms, they have two copies of this RFLP. When we examine one copy from Jack and one copy from Jill, we see that they are identical:\nJack 1: -GAATTC---(8.2 kb)---GCATGCATGCATGCATGCAT---(4.2 kb)---GAATTC-\nJill 1: -GAATTC---(8.2 kb)---GCATGCATGCATGCATGCAT---(4.2 kb)---GAATTC-\nWhen we examine their second copies of this RFLP, we see that they are not identical. Jack 2 lacks an EcoR I restriction site that Jill has 1.2 kb upstream of the target sequence (difference in italics).\nJack 2: -GAATTC--(1.8 kb)-CCCTTT--(1.2 kb)--GCATGCATGCATGCATGCAT--(1.3\nJill 2: -GAATTC--(1.8 kb)-GAATTC--(1.2 kb)--GCATGCATGCATGCATGCAT--(1.3 kb)-GAATTC-\nTherefore, when Jack and Jill have their DNA subject to RFLP analysis, they will have one band in common and one band that does not match the other's in molecular weight:\nLet's use RFLP technology to determine if Jack is the father of Jill's child named Payle.\nIn this scenario, DNA was extracted from white blood cells from all three individuals and subjected to RFLP analysis. The results are shown below:\nIn this case, it appears that Jack could be the father, since Payle inherited the 12.4 kb fragment from Jill and the 4.3 fragment from Jack. However, it is possible that another man with similar RFLP pattern could be as well.To be certain, several more RFLP loci would be tested. It would be highly unlikely that two men (other than identical twins) would share multiple RFLP patterns and so paternity could be confirmed.\nIn a different scenario, DNA was extracted from white blood cells from all three individuals and subjected to RFLP analysis. The results are shown below:\nThis time, it can be determined that Jack is NOT the father of Payle since Payle has a band of about 6 kb and Jack does not. Therefore, it is very probable that Payle's father is not Jack, though it is possible that Payle carries a new mutation at this locus and a different sized band was produced. What could you do as an investigator to be more certain that Jack was not the father of Payle?\nIn this example, we want to know if a person carries any cystic fibrosis (CF) alleles and if so, how many. Because CF is a recessive disease, anyonne with CF must be homozygous for disease alleles. From pedigree information, we can often determine who in this family is a carrier. However, if a couple comes to a genetic counselor, often an RFLP analysis is performed on the couple's DNA.\nRFLPs are known for CF and so it would be easy to determine if a person were homozygous wild-type (wt), heterozygous \"carrier\", or homozygous disease alleles and thus have CF.\nFor couples expecting a child, it would be simple to test both parents and make a prediction about the eventual disease status of their fetus. For example, if both parents were homozygous wt, then all of their children would also be homozygous wt:\nHowever, if both parents were heterozygous, they could have children with any of the three genotypes, though heterozygous children would be twice as likely as either of the homozygous genotypes.\nWith increasing genomic sequence information, increasing numbers of genetic disease can be predicted from RFLP analyses.\nTo calculate the genetic distance between to loci, you need to be able to observe recombination. Traditionally, this was performed by observing phenotypes but with RFLP analysis, it is possible to measure the genetic distance between two RFLP loci whether they are a part of genes or not.\nLet's look at a simple example in fruit flies. Two RFLP loci with two RFLP bands possible at each locus:\nThese loci are located on the same chromosome for the female (left) and the male (right). The upper locus can produce two different bands called 1 and 3. The lower locus can produce bands called 2 or 4. The male is homozygous for band 1 at the upper locus and 2 for the lower locus. The female is heterozygous at both loci. Thier RFLP banding patterns can be seen on the Southern blot below:\nThe male can only produce one type of gamete (1 and 2) but the female can produce four different gametes. Two of the possible four are called parental because they carry both RFLP bands from the same chromosome; 1 and 2 from the left chromosome or 3 and 4 from the right chromosome. The other two chromosomes are recombinant because recombination has occurred between the two loci and thus the RFLP bands are mixed so that 1 is now linked to 4 and 3 is linked to 2.\nWhen these two flies mate, the frequency of the four possible progeny can be measured and from this information, the genetic distance between the two RFLP loci (upper and lower) can be determined.\nIn this example, 70% of the progeny were produce from parental genotype eggs and 30% were produced by recombinant genotype eggs. Therefore, these two RFLP loci are 30 centiMorgans apart from each other."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:6fee88e3-94f4-4f2d-bd12-222091eced99>","<urn:uuid:df78a5db-4ab7-4b50-b759-6bca8b2dc3a7>"],"error":null}
{"question":"How do you calculate return on advertising spend (ROAS) for higher education marketing campaigns?","answer":"Return on advertising spend (ROAS) is calculated by dividing advertising revenue by advertising cost. Most digital platforms track this metric automatically. The higher the resulting number, the greater the return on your advertising investment.","context":["Like every other industry today, higher education is teeming with data. Colleges and universities collect an extensive amount of information about students before they ever step foot in a classroom. While all of this data can be incredibly valuable in higher education, you can only use it to inform decisions if you’re able to make sense of it.\nHigher education metrics, when tracked over time, can provide meaningful insight into your marketing and admissions — and even your student support efforts. But because there are so many ways to measure performance, it can be easy to devote too much time to digging into numbers that aren’t particularly helpful.\nWhich metrics are most important? While there are numerous measures that are truly key performance indicators (KPIs) you can track to identify whether you’re achieving institutional objectives, make sure the following 14 metrics are helping to inform your strategies.\nAwareness-based KPIs higher education institutions should track\nA very high-funnel metric, impressions represent the total number of times your content (typically an ad) has been displayed. This doesn’t mean that a user interacted with your content, but it does mean they were exposed to it. Stagnant or lagging impressions could indicate you need to establish a stronger brand or adjust your marketing tactics\nUse this metric to: gain a sense of how many users know about your brand.\n2. Website traffic\nThere are a number of website-related metrics you can dig into, but external website traffic is arguably one of the most important. It indicates how many people arrived at your institution’s domain, whether they came from a digital ad, an email, organic search or even by entering the URL directly into their browser. Internal traffic can also be informative, but that metric mostly conveys information relevant to retention and advocacy. While there are technically numerous metrics that convey how much traffic a website receives (pageviews, users, sessions, etc.), it’s important to track at least one of them consistently over time.\nUse this metric to: identify trends and determine how marketing tactics are affecting performance.\n3. Return on advertising spend\nReturn on advertising spend (ROAS), which can be evaluated at the campaign level as well as for total marketing spend, indicates how effective your marketing efforts are. Calculate ROAS by dividing advertising revenue by advertising cost — most digital platforms track this for you. The higher the number, the greater your return.\nUse this metric to: decide whether marketing spend could be better utilized.\nConsideration-related KPIs higher education institutions should track\n4. Inquiry submissions\nThis number represents the total number of prospective students who’ve expressed interest in your institution in some way. In the digital world, this often occurs when a student visits a landing page, fills out a form or registers for a webinar.\nUse this metric to: gauge how interest among prospects is trending.\n5. Cost per inquiry\nThis higher education metric helps in understanding how effectively marketing budget is being spent toward generating interest among prospective students. You can calculate cost per inquiry (CPI) across all your marketing efforts as well as at the campaign level. To determine CPI, divide marketing spend by the total number of inquiries received.\nUse this metric to: identify successful campaigns and areas for improvement.\nClose-phase (or “conversion”) KPIs higher education institutions should track\n6. Visit registration submissions\nA visit registration submission is exactly what it sounds like: a prospective student who has registered to visit your institution. Campus visits (even virtual ones) can be incredibly powerful in helping institutions drive enrollments, because students typically only attend them at the last few schools they’re considering. You can think of visit registration submissions as a precursor to later enrollments.\nUse this metric to: identify quality leads that need to be nurtured.\n7. Application completions\nThis higher education metric indicates how many students have turned in a completed application — not just those who have created an account and started to fill out an application. This distinction is important given some students never follow through on finishing and submitting every application they start.\nUse this metric to: determine how well you’re pacing toward enrollment goals.\n8. Admissions (or “Admits”)\nFor most colleges and universities, not every student is eligible for acceptance. Your total number of admits tells you not just how many students completed the application process, but how many have been officially accepted for admission.\nUse this metric to: gain insight into what enrollments may ultimately be and to determine the quality of leads coming in through marketing and enrollment efforts\nThe total number of enrolled students — enrollments or “enrolls” for short — is how many students have taken all the final steps to begin their studies at your institution, including submitting their deposit and registering for classes. For most institutions, growing enrollment is a consistent goal.\nUse this metric to: determine whether your enrollment goals have been (or likely will be) achieved.\n10. Cost per application\nCost per application (CPA) builds off CPI to encompass all the marketing spend it takes to get a student to submit an application. To calculate CPA, divide marketing spend by the total number of application submissions. It’s inevitable that more prospects will inquire than will apply, so expect this metric’s value to be higher than your CPI.\nUse this metric to: determine the marketing and outreach spend it takes to compel students to apply.\n11. Cost per enrollment\nCost per enrollment (CPE) is the total investment associated with securing a student’s seat at your institution. CPE is calculated quite simply by dividing total marketing spend by the total number of enrollments. Given the additional investment enrolling a student entails, CPE will be higher than both CPA and CPI.\nUse this metric to: measure the effectiveness of your overall marketing and enrollment strategy.\nCompletion-related KPIs higher education institutions should track\n12. Student lifetime value\nThink of student lifetime value (SLV) as the education equivalent of customer lifetime value (CLV): it’s the total monetary worth the average student contributes toward your institution. This metric is a bit more complex to calculate than the others given there are so many qualitative factors involved, but some researchers suggest using the net present value method.\nUse this metric to: understand the total value a student contributes to your institution, even after graduation.\n13. Retention rate\nGenerally speaking, the retention rate refers to the share of students who continue on to the next milestone at your institution. This metric can be defined many different ways — from the first term to the second term, from one year to the next, etc. Individual schools should determine which milestones to focus on when measuring retention.\nUse this metric to: understand whether there’s a need for interventions that help support students.\nThis metric represents the total number of degrees awarded to graduating students. Most institutions, as well as the annual Digest of Education Statistics from the National Center for Education Statistics (NCES), measure conferrals on an annual basis.\nUse this metric to: identify trends within your institution and to see how you compare to other colleges and universities.\nEnsure your higher education metrics signal success\nHigher education metrics can help you gain insight into which campaigns resonate with students, how effectively you’re nurturing leads, whether you’re on track to meet enrollment targets and more. You’ll also likely recognize whether it’s time to adjust your overall marketing strategy.\nPerhaps your institution, like many others, is starting to realize using the same approach to converting prospects into attending students is no longer as effective as it once was. To find out how you can restructure the enrollment funnel to better meet your goals, read “How Colleges Can Reinvent the Enrollment Funnel.” It may just help you determine how to stand out from the crowd in an increasingly digital landscape."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:f56861e1-d2ef-4811-abaa-d4ee18e5b6aa>"],"error":null}
{"question":"What was the historical origin of parol evidence rules vs how does modern blockchain solve traditional record-keeping problems?","answer":"The parol evidence rule is a traditional legal principle that makes evidence of agreements outside written contracts inadmissible in court. In contrast, blockchain technology offers a modern solution to record-keeping by creating an incorruptible digital ledger using a peer-to-peer (P2P) network. Unlike traditional centralized systems, blockchain distributes information across all network nodes, preventing tampering and eliminating the need for powerful intermediaries, while ensuring data integrity through its chain of linked blocks.","context":["What are examples of extrinsic evidence?\n“With reference to a contract, deed, will, or any writing, extraneous evidence is such as is not furnished by the document itself, but is derived from outside sources[.]”1 In this context, “extrinsic evidence” is synonymous with “parol evidence”, “extraneous evidence”, and “evidence aliunde.”2 A common example of …\nWhat is an example of parol evidence?\nFor example, in a dispute over the sale of a home, if the buyer and seller have signed a written contract for the sale of a home and have written down that the sales price is $500,000, the buyer will be barred from introducing evidence of a discussion that he had with the seller where she agreed to sell it to him for …\nWhat do you mean by parol evidence?\nVerbal evidence, such as the testimony of a witness at trial. In the context of contracts, deeds, wills, or other writings, parol evidence refers to extraneous evidence such as an oral agreement (a parol contract), or even a written agreement, that is not included in the relevant written document.\nWhat is meant by extrinsic evidence?\nExtrinsic evidence, as used in the context of contract construction, is evidence relating to a contract but not appearing on the four corners of the contract because it comes from other sources involving the setting in which the parties negotiated the contract.\nWhen can you use extrinsic evidence?\nExtrinsic evidence of a prior inconsistent statement by a witness is admissible if both of the following apply: (1) If the statement is offered solely for the purpose of impeaching the witness, the witness is afforded a prior opportunity to explain or deny the statement and the opposite party is afforded an opportunity …\nWhat is the meaning of the parol?\n1 : executed or made by word of mouth or by a writing not under seal a parol agreement. 2a : given or expressed by word of mouth : oral as distinguished from written. b : relating to matters outside of a writing. History and Etymology for parol. Noun.\nWhen can parol evidence be used?\nThe parol evidence rule is an evidentiary rule in contract disputes which generally makes evidence of agreements outside the parties’ written contract inadmissible. That is, under the parol evidence rule any agreement that is not contained within the written contract is inadmissible in court.\nWhich one of the following will be excluded by the parol evidence rule?\nterms that one party claims should be added to the contract. Does not exclude evidence about the formation of the contract such as its legality, the capacity of the parties, mistakes, duress, undue influence, or fraud. when using a standard form contract ie.\nWhat is extrinsic evidence in criminal law?\nExtrinsic evidence means evidence that would be inad- missible under the common law parole evidence rule or a similar doctrine because the evidence is not contained in the governing instrument to which it relates.\nCan extrinsic evidence be used to impeach a witness?\n(a) Bias. Bias, prejudice, interest, or any motive to misrepresent may be shown to impeach the witness either by examination of the witness or by extrinsic evidence.\nWhat is the origin of parol?\nThe parol is a star-shaped ornament which originated in the Philippines during the Spanish colonisation when Spaniards brought Christianity to the country.","It doesn’t happen often that the appearance of one cutting-edge technology challenges the foundations of so many industries, but Blockchain Technologies have done just that.\nBlockchain seems to have become synonymous of sounding tech-savvy. But is this hype technology really gonna change the way this world operates? Before we can speak about ‘blockchain magic’ and how it has the potential to be the technology that redefines many business processes, it is important to get a grasp of it.\nWhat is Blockchain Technology?\nAccording to the authors of Blockchain Revolution (2016) “the blockchain is an incorruptible digital ledger that can be programmed to record not just financial transactions but virtually everything of value.” Hence, one of the key attributes of Blockchain Technology is its immutability: it permits the data to be distributed, but not copied or changed.\nWhy is it called Blockchain?\nThe name of blockchain comes from the way it stores transaction data: in blocks that are linked together to form a chain.\nWhen a trade is recorded it is checked by the network. The computers in the network (the ‘nodes’) check the details of the trade to make sure it is valid. The records that are accepted become part of a block. Each block contains a unique code called a hash (a digital fingerprint or unique identifier), timestamped batches of recent valid transactions, and the hash of the previous block. The blocks are linked together by the hashes they share, which prevents any block from being altered or a block being inserted between two existing blocks. That is one of the reasons a blockchain is impossible to tamper with: each subsequent block strengthens the verification of the previous one and therefore contributes to the incorruptibility of the whole chain.\nIf someone tries to change the original record, a new hash will be automatically generated for that record. As the next block in the chain still includes the old hash, the changed hash breaks the chain. It would require an enormous amount of computing power to recalculate all the hashes in the chain, which makes hacking a blockchain so hard.\nHow does Blockchain work?\nOne of the bases of Blockchain Technology is the Peer to Peer (P2P) network. P2P network is completely different from the traditional client-server models as there is no central point of storage. In a P2P network, all the participants on the network act as a server: the users utilize and provide the foundation of the network at the same time. All of them are considered equal, none of the nodes has authority over the other, therefore, no single participant can control the network.\nThe information included in a blockchain is constantly recorded and interchanged between all the nodes of the P2P network. As a method of transferring data, this proves to be a huge improvement because the information is not held in one centralized point. This way of storing data comes with a considerable advantage: as long as we have a copy of the blockchain in one of the nodes, all the records will remain intact.\nGiven that all the users of the network have same access and authority, there is no longer a need for powerful intermediates and all the interested parties can deal directly with each other across a secure and decentralized network.\nWhat are the applications of Blockchain technology?\nBlockchain Technologies could have repercussion on various aspects of our daily life. The most promising potential uses are in healthcare, real estate, retail, governmental sector, supply chain management, multinational policy management, finance and banking.\nWhile Bitcoin and cryptocurrency might have become the most famous uses of Blockchain Technologies, there are many other practical examples where we can see blockchain in action. Given its origin, finance and banking might be the most obvious ones. Blockchain Technologies will allow speeding up and simplifying cross-border payments, improve online identity management, spread the use of Smart contracts and make share trading faster and more accurate.\nBlockchain could also mean a much-needed relief for the healthcare industry, as it promises to provide a more efficient and secure system for managing medical records. As for innovations in governing, Blockchain records could create tamper-proof election returns.\nWhen it comes to supply chain management, the use of blockchain will guarantee transparency with a shared record of ownership and location of products in real time. Today’s consumers are more and more conscious about the origin and quality of the product. Using blockchain is a good way to provide proof of provenance for the consumers. In the food industry blockchain can help the companies find out what food might be contaminated and where throughout the supply chain.\nWe also have some examples from the entertainment business. Spotify turned to blockchain to develop a decentralized database that allows to connect better the artists and licensing agreements with the tracks on Spotify’s service.\nThe range of potential uses of Blockchain Technologies is very wide and we promise to go into more detail in our next post.\nWhat are the benefits of Blockchain Technologies?\nAccording to IBM the main benefits of using blockchain are:\n- Greater transparency\n- Enhanced security\n- Improved traceability\n- Increased efficiency and speed\n- Reduced costs\nWhat are the Main Barriers to a wider Application of Blockchain?\nAfter covering all the benefits and possible uses of Blockchain Technologies, we might want to ask why the companies and governments are not taking full advantage of the potential this technology has to offer. One of the most significant bottlenecks restricting a wider application is the lack of professionals with proper education on this groundbreaking technology. Another barrier hindering Blockchain Technology is the lack of general knowledge and the misinformation with most people thinking the technology is limited to cryptocurrencies."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:462eaee9-7e77-42ae-a3f9-9bc4c626cd7e>","<urn:uuid:bac6c151-f3c3-4694-b8a0-12b17752a39b>"],"error":null}
{"question":"Need quick info - can freelancers use bank statements as income proof AND what's the deal with factoring/invoice stuff for small biz cash?","answer":"Bank statements can serve as proof of income for freelancers when they show regular deposits or consistent payments from the same sources. Additionally, factoring and invoice discounting are available financing options where specialist financiers buy or discount invoices drawn on creditworthy customers of the business, providing an alternative way to access funds.","context":["What Is Proof of Income for Freelance Artists?\nFreelance artists like painters and writers are not often paid in the traditional method. There are seldom pay stubs to show and incomes vary from one week or one month to the next. This can be an issue when freelancers apply for loans or credit cards, or whenever proof of income is required. Freelance artists are considered to be a type of small business when it comes to taxes and as such many financial institutions have adjusted their requirements accordingly.\nIncome taxes are always an acceptable form of income proof since they list every dollar made and every expense incurred throughout the year. If you do your own taxes and use general estimates and standard deductions, they may not be precise enough for lenders to accept. The larger the loan the more stringent the approval process in most cases. If you are considering a home purchase or other large ticket item, the more detail in your tax returns the better. Consider using a professional tax service or accountant to file your incomes taxes each year so the records are accurate and there is no doubt about the outcome.\nMany home loan lenders, including the Federal Housing Administration, require detailed financial records to approve any applicant. The requirements are no different for freelancers. Instead of a W2 form or pay stubs, you can submit a 1099 as proof of income if you are paid as an independent contractor. If you make your money on one-off sales of your work or from private parties who hire out your skill, keep documentary proof of every dollar you make throughout the year with detailed receipts. Many landers will be satisfied if you can list your total annual income and point to real proof of that income for a period of two years or more.\nBank account statements are certainly proof of assets but in some cases they can also serve as proof of income. If you receive a regular payment in the form of cash or check, each deposit will be indicated by your account statements. When a lender or other examiner sees that the same amount is deposited on a regular basis or that funds are received from the same source over and over, she may be able to view those deposits as proof of income. The general rule with proving your freelance income is to combine documentary evidence with verbal explanations of where the money comes from and how much you expect to earn from one year to the next and why. Your competence and confidence is almost as important as your financial records in many cases.\nOnline Payment Services\nIf you sell your talents online, odds are you are paid at least in part through an online payment service that receives funds from your employers and deposits it into your bank account. These services offer monthly and yearly rundowns of payments received and issued. These statements can be downloaded, printed and used as proof of all the income earned for the period desired. Although you may not earn all of your money this way, you will be able to prove at least part of your income without dispute.\n- Stockbyte/Stockbyte/Getty Images","Borrowing from friends and relatives, and advance payments from customers are other possible sources. Not all of these finance sources might be appropriate or available in all cases. For example, venture funding might be available only for innovative businesses that can achieve market leadership with their offerings, and command premium prices and profits. And new small businesses might find financing a difficult proposal unless they have some solid collateral security to offer.\nSmall Business Funding Problems\nStartup funding and loans is usually difficult to find because new businesses do not have a track record of past successful operations that can provide confidence among prospective investors and lenders. The main sources of finance for small business will typically be owner’s capital and the money that the owner can raise from friends and relatives.\nLarge businesses are obliged by law to publish a lot of financial information, audited by independent auditors, and investors and lenders will feel greater confidence in these cases. While small businesses are freed of the bother of such disclosure requirements, the non-disclosure itself stands in the way of easier funding.\nBanks consider small and medium enterprises a greater risk not only on the above grounds. Unlike large companies with substantial budgets, SMEs cannot usually afford to hire highly paid talent in such key result areas as marketing.\nOnly those small businesses that can offer collateral security such as owner’s residence or business premises will usually be able to raise bank loans with comparative ease. If their business plan is approved, government small business support agencies might also provide loan guarantees or even outright loans.\nRaising Small Business Capital\nSmall businesses have to be ready with convincing details such as:\n- A complete business plan that describes how they will handle the different aspects such as marketing, technology, staffing and profitability\n- Resumes of their directors and managers showing that these key persons have relevant experience and records of success\n- List of tangible assets that shows the firm will have the facilities needed to run the business and also offer some kind of security for the loans\n- Other information such as the unique prospects of the business owing to an innovative product or business model\nThe very exercise of providing realistic and detailed information is likely to create a good impression in the minds of prospective investors and lenders. The qualification “realistic” is the key issue here. Unless the assumptions, computations and projections appear convincing to the audience, they are unlikely to accept it. And conviction can be generated best if the planner has done the homework to gather relevant facts on the ground and can answer any questions about the realistic nature of the plans.\nFinancing a Business\nA brief look at the different sources of funding businesses can help the entrepreneur generate ideas for financing his or her small business.\n- Own Savings: Any money that the entrepreneur might have accumulated is the primary source of funding business projects\n- Borrowing from Relatives and Friends: Relatives and friends who wish the person well and also have confidence in the person’s ability to run a business might be willing to help\n- Partnerships: The entrepreneur can associate a partner who might be able to invest funds or bring in expertise that makes obtaining finance from other sources easier\n- Leasing and Hire Purchase: Where the business needs a lot of tangible facilities such as premises, equipment or vehicles, the option of obtaining these on lease or hire purchase can be considered\n- Trade Credit: Raw materials and other supplies can be bought on credit, and it might even be possible to convert them into cash (or discountable invoices) by the time payment is due to suppliers\n- Factoring and Invoice Discounting: There are specialist financiers who buy or discount invoices drawn on creditworthy customers of the business\n- Angel Investors: Angel investors are rich individuals who might be interested in funding new entrepreneurs to earn a higher return on their money and/or because they feel good helping new entrepreneurs\n- Venture Capital Companies: These are similar to angel investors except in that they are more professional and business like, and are not likely to be motivated by sentiments like helping newcomers\n- Bank Loans: Bank loans can be fixed amount loans lent for the short or long term, or an overdraft facility under which the borrower can draw funds as needed and also deposit funds coming in to reduce outstanding (and interest bearing) borrowings\n- Government Loans and Grants: Governments might seek to encourage development of backward regions or disaster-struck areas by extending business loans or grants to businesses coming to these regions and areas\n- Internal Generation of Funds: Successful businesses will typically be generating profits and if these are not fully paid out as dividends, will be available for operating and expansion needs\n- Equity Issue: Once a business has grown to a certain size, it might be practicable to go to the securities market and issue equity shares (or even interest-bearing bonds that do not dilute ownership)\n- Sale of Surplus Assets: Where a business has idle or insufficiently productive assets, it can consider selling these to raise funds for expansion or promising new projects\nBusiness funding sources are varied, ranging from owner’s savings through private business investors and banks to trade credit and invoice factoring. Entrepreneurs who take the trouble to prepare a detailed and realistic business proposal can usually find needed business finance."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:7ee55615-f310-4cc7-8266-2badd996601c>","<urn:uuid:e3ce12ab-24a3-4a70-b43d-331eb1f8f8f3>"],"error":null}
{"question":"How do autism spectrum disorders affect social development in children, and what specialized environmental accommodations can support their sensory needs?","answer":"Children with autism spectrum disorders show significant social development challenges - they may have difficulty learning to interact with others, struggle with imitation skills, and have trouble with basic social games like peek-a-boo. Many avoid eye contact, prefer being alone, and find it hard to take turns or share with peers. These social impairments are often accompanied by sensory processing differences. To support their needs, specialized multi-sensory environments can be created with equipment like interactive bubble tubes for cause-and-effect learning, fiber optic strands that provide calming deep pressure input, and vibro-acoustic furniture that allows them to 'feel' music through vibration. These controlled sensory spaces are designed to promote feelings of safety, well-being and can help develop social interaction skills through appropriate sensory stimulation.","context":["As the name \"autism spectrum disorders\" suggests, ASDs cover a wide range of behaviors and abilities. People who have an ASD, like all people, are very different in how they act and what they can do. No two people with ASDs will have the same symptoms.\nPeople with ASDs have serious impairments with social, emotional, and communication skills. They might repeat certain behaviors again and again and might have trouble changing their daily routine. Many people with ASDs also have different ways of learning, paying attention, or reacting to things. ASDs begin before the age of 3 and last throughout a person's life. It is important to note that some people without ASDs might also have some of these symptoms. But for people with ASDs, the impairment is bad enough to make life very challenging.\n- Social Skills\n- Repeated Behaviors and Routines\n- Additional Disabilities and Conditions\n- Associated Features\n- Pattern of Development\n- Possible Red Flags for Autism Spectrum Disorders\n- What can I do if I think my child has an ASD?\nSocial impairments are one of the main problems in all of the autism spectrum disorders (ASDs). People with ASDs do not have merely social “difficulties” like shyness. The social impairments they have are bad enough to cause serious problems in everyday life. These social problems are often combined with the other areas of deficit, such as communication skills and unusual behaviors and interests. For instance, the inability to have a back-and-forth conversation is both a social and a communication problem.\nTypical infants are very interested in the world and people around them. By the first birthday, a typical toddler tries to imitate words, uses simple gestures such as waving “bye bye,” grasps fingers, and smiles at people. But the young child with autism may have a very hard time learning to interact with other people. One way very young children interact with others is by imitating actions—for instance, clapping when mom claps. Children with ASDs may not do this, and they may not show interest in social games like peek-a-boo or pat-a-cake. Although the ability to play pat-a-cake is not an important life skill, the ability to imitate is. We learn all the time by watching others and by doing what they do—especially in new situations and in the use of language.\nPeople with ASDs might not interact with others the way most people do. They might not be interested in other people at all. Some might want friends but have social problems that make those relationships difficult. They might not make eye contact and might just want to be alone. Many children with ASDs have a very hard time learning to take turns and share—much more so than other children. This can make other children unwilling to play with them.\nPeople with ASDs may have problems with expression, so they might have trouble understanding other people's feelings or talking about their own feelings. Many people with ASDs are very sensitive to being touched and might not want to be held or cuddled. Self-stimulatory behaviors, common among people with ASDs, may seem odd to others or make them uncomfortable, causing them to shy away from a person with an ASD.\nSocial issues such as trouble interacting with peers, saying whatever comes to mind even if it’s inappropriate, difficulty adapting to change, and even poor grooming habits can sometimes make it hard for adults with ASDs to get and/or keep a job at their intellectual level. Anxiety and depression, which affect some people with ASDs, can make existing social impairments even harder to manage.\nSocial skills that many people learn by watching others may need to be taught directly to people with ASDs. When deciding what to teach, remember the social value of learning independent living skills such as toilet training and other basic grooming skills (bathing, tooth brushing, dressing appropriately, etc.).\nBecause children and adolescents with ASDs are “different,” and because they are often very literal and sometimes naïve and overly trusting, they are often the target of bullies and might be easily taken advantage of. It is very important to teach all children from a very young age to be tolerant and accepting of differences. It is also important to teach children and adolescents with ASDs about personal safety and tell them to go to a parent, teacher, or other trusted adult if they need help.\nThere are many strategies and curriculum supplements for teaching children and adolescents with and without ASDs about bullying and other personal safety issues. These can be found by visiting a local bookstore, searching an online book seller, or by contacting a publishing company that specializes in disability-specific and/or education publications. Teachers and health care professionals are often good resources for this type of information as well.\nEach person with an ASD has different communication skills. Some people may have relatively good verbal skills, with only a slight language delay with impaired social skills. Others may be not speak at all or have limited ability or interest in communicating and interacting with others. About 40% of children with ASDs do not talk at all. Another 25%–30% of children with autism have some words at 12 to 18 months of age and then lose them. Others may speak, but not until later in childhood.\nPeople with ASDs who do speak may use language in unusual ways. They may not be able to combine words into meaningful sentences. Some people with ASDs speak only single words, while others repeat the same phrases over and over. Some children repeat what others say, a condition called echolalia. The repeated words might be said right away or at a later time. For example, if you ask someone with an ASD, \"Do you want some juice?\" he or she might repeat \"Do you want some juice?\" instead of answering your question. Although many children without ASDs go through a stage where they repeat what they hear, it normally passes by age 3. Some people with ASDs can speak well but may have a hard time listening to what other people say.\nPeople with ASDs may have a hard time using and understanding gestures, body language, or tone of voice. For example, people with ASDs might not understand what it means to wave goodbye. Facial expressions, movements, and gestures may not match what they are saying. For instance, people with ASDs might smile while saying something sad. They might say \"I\" when they mean \"you,\" or vice versa. Their voices might sound flat, robot-like, or high-pitched. People with ASDs might stand too close to the people they are talking to, or might stick with one topic of conversation for too long. They might talk a lot about something they really like, rather than have a back-and-forth conversation with someone. Some children with relatively good language skills speak like little adults, failing to pick up on the “kid-speak” that is common in their peers.\nUnusual behaviors such as repetitive motions may make social interactions difficult.\nRepetitive motions are actions repeated over and over again. They can involve part of the body or the entire body or even an object or toy. For instance, people with ASDs may spend a lot of time repeatedly flapping their arms or rocking from side to side. They might repeatedly turn a light on and off or spin the wheels of a toy car in front of their eyes. These types of activities are known as self-stimulation or “stimming.”\nPeople with ASDs often thrive on routine. A change in the normal pattern of the day—like a stop on the way home from school—can be very upsetting or frustrating to people with ASDs. They may “lose control” and have a “melt down” or tantrum, especially if they’re in a strange place.\nAlso, some people with ASDs develop routines that might seem unusual or unnecessary. For example, a person might try to look in every window he or she walks by in a building or may always want to watch a video in its entirety—from the previews at the beginning through the credits at the end. Not being allowed to do these types of routines may cause severe frustration and tantrums. .\nChildren with an ASD may also have one of several other developmental disabilities such as mental retardation/intellectual impairment, epilepsy, fragile X syndrome, or tuberous sclerosis. A study published by CDC in 2003 found that 62% of the children who had an ASD had at least one additional disability or epilepsy (glossary). Of those children, 68% had mental retardation/intellectual impairment, 8% had epilepsy, 5% had cerebral palsy, 1% had vision impairment, and 1% had hearing loss. Other studies show that 5% to 38% of adults with ASDs have epilepsy. And some people with ASDs may have mental disorders such as depression and anxiety. Although these additional conditions may not be key to the ASD diagnosis, they do add challenges for the person with ASD and his or her family.\nPeople with ASDs might have a range of other behaviors associated with the disorder. These include hyperactivity, short attention span, impulsivity, aggressiveness, self-injury, and temper tantrums. They may have unusual responses to touch, smell, sound, and other sensory input. For example, they may over- or under-react to pain or to a loud noise. They may have abnormal eating habits. For instance, some people with ASDs limit their diet to only a few foods, and others may eat nonfood items like dirt or rocks (this is called pica). They may also have odd sleeping habits. People with ASDs may seem to have abnormal moods or emotional reactions. They may laugh or cry at unusual times or show no emotional response at times you would expect one. They may not be afraid of dangerous things, and they could be fearful of harmless objects. People with ASDs may also have gastrointestinal issues such as chronic constipation or diarrhea.\nIt is important to remember that children with ASDs can get sick or injured just like children without ASDs. Regular medical and dental exams should be part of a child’s intervention plan. Often it is hard to tell if a child’s behavior is related to the ASD or is caused by a separate health problem. For instance, head banging could be a symptom of an ASD, or it could be a sign that the child is having headaches. In those cases, a careful physical exam is important.\nSome children with ASDs show hints of future problems within the first few months of life. In others, symptoms may not show up until 24 months or later. Studies have shown that one third to half of parents of children with ASDs noticed a problem before their child’s first birthday, and nearly 80%–90% saw problems by 24 months. Some children with ASDs seem to develop normally until 18–24 months of age and then they stop gaining new language and social skills, or they lose the skills they had.\nChildren with ASDs develop at different rates in different areas of growth. They may have delays in language, social, and learning skills, while their motor skills are about the same as other children their age. They might be very good at putting puzzles together or solving computer problems, but they might have trouble with social activities like talking or making friends. Children with ASDs might also learn a hard skill before they learn an easy one. For example, a child might be able to read long words but not be able to tell you what sound a \"b\" makes.\nChildren develop at their own pace, so it can be difficult to tell exactly when a child will learn a particular skill. But there are age-specific developmental milestones used to measure a child’s social and emotional progress in the first few years of life. To learn more about developmental milestones, visit “Learn the Signs. Act Early,” a campaign designed by CDC and a coalition of partners to teach parents, health care professionals, and child care providers about early childhood development, including possible ”red flags” for autism spectrum disorders.\nChildren and adults with an autism spectrum disorder might:\nIf you or your doctor thinks there could be a problem, ask for a referral to see a developmental pediatrician or other specialist. You can also call your local early intervention agency (for children under 3) or public school (for children 3 and older). To find out who to speak to in your area, check with the National Dissemination Center for Children with Disabilities.\nToday, the main research-based treatment for ASDs is intensive structured teaching of skills, often called behavioral intervention. It is very important to start this intervention as early as possible to help your child reach his or her full potential. Acting early can make a real difference!\nEven if your child has not been diagnosed with an ASD, he or she may be eligible for early intervention services. The Individuals with Disabilities Education Act (IDEA) says that children under the age of 3 who are at risk of having serious developmental delays may be eligible for services. These services are provided through an early intervention system in your state. Through this system, you can ask for an evaluation. To learn more about early intervention, click here.\nDisclaimer: We have provided a link to these sites because they have information that may be of interest to you. CDC does not necessarily endorse the views or information presented on these sites. Furthermore, CDC does not endorse any commercial products or information that may be presented or advertised on these sites.\n Johnson, C.P. Early Clinical Characteristics of Children with Autism. In: Gupta, V.B. ed: Autistic Spectrum Disorders in Children. New York: Marcel Dekker, Inc., 2004:85-123.\n Tuchman,R., and Rapin, I. Epilepsy in autism. Lancet Neurology 2002; 1(6):352-358.\nCenters for Disease Control and Prevention content is free and public domain.","According to Research Autism: “Multi-sensory Environments or MSE’s are designed to create a feeling of safety and to provide novel and intriguing sensations, which can promotes pleasure and/or feelings of well-being. They can also be utilized as part of the learning or treatment experience or for leisure and relaxation.”\nTypically, a MSE is a dedicated space or room that is designed to stimulate the senses through a controlled environment enhanced with individualized sensory equipment. Some of the goals and benefits of MSE’s include promoting relaxation and a feeling of well-being, focus and attention, understanding of cause/effect and social interaction skills and are often a perfect milieu for those on the autism spectrum. With their adjustable sensory components combining touch, vibration and movement with sight and sound, they offer something for all levels and sensory preferences.\nComponents in a sensory room can vary widely and usually involve selection based on the assessment of the special needs or general population that will be utilizing the space. A collaboration between educators, parents, equipment vendors and other related specialists are helpful when planning an MSE. Here are just a few of the options available that may work well for individuals with autism:\nThe clear plastic water column produces a steady stream of small bubbles which coordinate with changing light colors within the tube. With an interactive Bubble Tube, the user presses a switch or panel which allow the tube to change color and/or speed of vibration of the bubbles so can help promote cause/effect, turn taking and simple visual perception skills. In addition to the light, the hum and vibration of the tube are also often a source of attention and appeal.\nFor an update on a traditional bubble tube, consider the Calming Bubble Wall as a space saver and/or if there are behavior issues that would preclude using a standard tube.\nThese are light sources made of fiber optic strands in a variety of options including hanging curtains, wall or floor carpets, vertical sprays or draped strands over a sitting piece such as a bean bag cushion. In a semi-darkened room, Fiber Optics produce a soft glow that can promote visual focus and tracking. When used in strands (usually grouped in sets of 100 or more) and draped across the body in a seat or in a swing, the weight of the combined strands provides deep touch pressure input on the body which may help promote the relaxation/calming response.\nThese devices are a fun method to project colorful images onto walls, ceilings, floors or a soft space such as a draped parachute. Themed concepts such as shapes, planets, a deep sea environment or even customized pictures are displayed on a projector disc or wheel which gently rotates producing a clear slow moving image across the desired surface. In a semi- darkened room, these oversized rotating images are great for calming, attending and visual focus and tracking.\nThese lounging pieces such as a beanbag, recliner, wedge, pillow or mats have built in speakers which allow the user to “feel” the music through vibration. Classical, drumming and/or even some contemporary new age composers are often good music choices to use with this equipment.\nWhen considering a MSE keep in mind your space. Obstructions such as excess light from windows, wall barriers such as closet doors, cabinets/shelving and/or ventilation (side hvac units etc.) should be covered, moved or minimized as feasible. Additional electrical outlets may need to be installed and lighting should be changed to a rheostat control to allow gradual dimming. Floor and/or wall padding may be needed for comfort and acoustics. If space or budget is limited a Sensory Calming Cocoon or a Portable Sensory Corner may be good options. Visit our website for more sense-ational ideas for sensory rooms!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:c1abfa99-0a28-476e-991c-0ec495de4500>","<urn:uuid:b1b99488-7293-4f33-8012-211cd59ef205>"],"error":null}
{"question":"What is the relationship between personality traits and stress management, and how does chronic stress affect both mental and physical health?","answer":"Neuroticism, one of the Big Five personality traits, is strongly associated with anxiety and reflects a heightened emotional reactivity to threats. People with neurotic traits, particularly perfectionists, are more susceptible to anxiety and depression. When chronic stress occurs, the body becomes overloaded with cortisol, which can lead to serious health consequences including heart attacks, strokes, and the development of mental health problems such as depression or anxiety. Additionally, those who felt insecure in their environment during childhood may develop a more sensitive stress response system, causing them to perceive even simple stimuli like loud noises or strong smells as threats.","context":["What Causes Sudden Onset Of Anxiety\nA sudden onset of anxiety can be triggered by a plethora of thingsfrom a major event, like a death in the family, to everyday stressors, such as work or budget worriesbut sometimes it can be caused by seemingly nothing at all or issues we arent aware of.\nOur brains are designed to monitor for danger and let us know when these signs appear, says Karin Kassab, MA, psychologist and CEO of Clarity Counseling Center. Although it can feel like it at times, anxiety is not your enemy. Its your brain trying to keep you safe. Think about your anxiety as a security system thats just a little too sensitive.\nAbrupt feelings of nervousness and apprehension are often caused by a specific anxiety trigger. It could be a conversation or a place or a smell that triggers anxiety, says Silvi Saxena, MSW, LSW, a licensed therapist at Choosing Therapy. It can be a result of focusing thoughts on something that is stressful and worrisome, something that doesnt have a solution or worrying about worst case scenarios. Major life events can trigger a series of anxiety attacks and it can become easy to get into a pattern of negative thinking, which worsens anxiety. As a result, its crucial to try to understand your anxiety triggers, in order to find ways to manage it.\nWays To Enlist The Help Of Your Spouse Or Partner\nDoes Personality Play A Role In Anxiety\nThere is a type of personality consistently associated with anxietythose who exhibit the trait of neuroticism. One of the so-called Big Five personality traits, it describes a broad tendency to respond to experience with negative emotions and to be roiled by them. In study after study, neuroticism predicts susceptibility to both anxiety and depression and, to a lesser degree, all other mental disorders. Scientists believe that neuroticism reflects emotional reactivity that is especially attuned to threat. Some facets of neuroticism perfectionism stands outare virtually free tickets to anxiety. Perfectionists may seem like theyre on a path to success but in fact they are driven by a desire to avoid failure as a result, much of their mental life is devoted to worrying about mistakes they could possibly make and imagining dire consequences of those mistakes..\nYou May Like: What Anxiety Disorder Do I Have\nIs It In Your Genes\nIf anxiety appears to run in the family, it may be that your genetic inheritance that biological lottery has set you up for some vulnerability to anxiety.\nThat does not necessarily mean your genes are the cause of your problem. The story is far more complicated than that.\nNot every timid, shy and anxious child develops into a fearful adult with anxiety problems.\nLifestyle factors, parenting and other experiences, as well as your manner of dealing with stressors , determine the ultimate outcome.\nYour personal development, and here the development of anxiety, depends on\n- how safe your environment was when you grew up\n- to what extent essential emotional needs were met\n- whether or not you had parents who were overprotective\n- whether or not you had a parent who was always anxious\n- whether or not you were encouraged to become more resilient and deal with, rather than avoid, feared situations at home, with friends and at school\nThese experiences would have shaped your own reactions and general attitude towards stressful situations and life-events.\nBut ultimately, yes, your genes could indeed be the cause of your anxiety.\nSo, what can you do about it?\nYouve always been a nervous type chronically anxious?\nRegardless of whether that is through a genetic predisposition or any of the above, you just need to follow all the steps below to permanently get over that sense of panic.\nUnless you need treatment for trauma, decide to focus only on the here and now from now on.\nYou Have Higher Amounts Of Stress Hormones In The Morning\n“There’s actually a physiological reason why some people experience anxiety in the mornings,” Dr. Saltz says. “For one, it’s when cortisol levels are naturally at their highest.” She explains that cortisol is often called “the stress hormone” because high levels of it can lead to feeling stressed.\n“There’s nothing you can do from stopping cortisol from raising slightly in the morningthat’s biologically what happensbut there are steps you can take to lower your cortisol overall so that it doesn’t peak as high,” Dr. Saltz says.\n2. Coffee can lead to feeling anxious.\nWhat you eat or drink in the morning can also lead to increased feelings of anxiety, according to Dr. Saltz. “The first thing many people do in the morning is drink a cup of coffee. Caffeine, particularly for people who already have anxiety, can definitely worsen the symptoms of that.” She explains that caffeine can lead to feeling jittery and having an increased heart rate. “Then our brain tries to come up with a reason to explain why we feel that way: I’m feeling jittery. I must be worried about X.” Dr. Saltz says this happens so quickly that it can feel like we have the thought first and then the physiological reaction, but it’s actually the other way around.\n3. Sugar is another culprit.\n4. Morning anxiety could also be a sign of having general anxiety disorder.\n5. You’re chronically stressed.\nDon’t Miss: What To Do If You Have Bad Anxiety\nBehavioral Symptoms Of Severe Anxiety\nBehavioral symptoms of severe anxiety often take the form of avoidance. Because severe anxiety symptoms are so terrifying, people will do almost anything to avoid feeling them. This might include:\n- Not going to specific places\n- Not seeing certain people\n- Not having specific experiences\nThese severe symptoms of anxiety can even escalate until the person refuses to leave the house or talk to most people.\nOther severe behavioral symptoms of anxiety include those seen in obsessive-compulsive disorder . People with OCD become obsessed with ideas such as:2\nOnce an obsession takes hold, the person feels an overwhelming urge to perform an action, a compulsion, also known as a ritual. Examples of severe compulsions include:\n- Washing of hands until the skin is raw\n- Picking of skin and hair around the face until there are open wounds\n- Being unable to leave the house due to repeated checking of things related to safety such as turning off the stove\nAnxiety: What It Is What To Do\n- By Francesca Coltrera, Editor, Harvard Health Blog\nWhile anxiety symptoms vary widely, odds are good that at some point youve experienced occasional physical and emotional distress signals such as panicky breathing, your heart pounding in your chest, trouble sleeping, feelings of dread, or even loops of worry. Thats normal.\nExperiencing anxiety is normal, says Dr. Gene Beresin, executive director of the Clay Center for Healthy Young Minds at Massachusetts General Hospital. A certain amount of anxiety can even be helpful. The problem is that sometimes the systems underlying our anxiety responses get dysregulated, so that we overreact or react to the wrong situations.\nRead Also: How To Help With Teenage Anxiety\nStress Hormones And Generalized Anxiety\nIf you are dealing with excessive anxiety in the morning, theres a good chance you may also have generalized anxiety or something researchers call The Cortisol Awakening Response . The stress hormone, cortisol, is released by the adrenal glands in response to fear or stress. Researchers have found that cortisol is highest in the first hour of waking for people with an increased level of anxiety. This helps explain why you may experience an increase in anxiety in the morning.\nWhen you wake up, the body is already in fight or flight at the memory and thought of another anxiety-filled day ahead. Now cue negative thinking before the day has even begun, creating a repeating cycle of early morning dread. Not to mention, the latter part of the night and early part of the morning generally sees a natural increase in both Cortisol and blood pressure as the body prepares to start another day.\nWhy Does Anxiety So Often Occur With Depression\nDepression and anxiety share much in commonthey both derive from overresponsiveness of the negative affect system, the distinguishing feature of the personality trait of neuroticism. People with the trait of neuroticism tend to react to experience most readily and most strongly with negative emotions, such as irritability, anger, and sadness. Many of the same brain regions malfunction in both conditions, most notably the amygdala and prefrontal cortex . But there are important differences. Anxiety is an alarm intended to energize people to avoid possible future danger they sense depression shuts people down when they feel overwhelmed, disinclining them to ongoing activity and focusing their attention on losses and other negative experiences in the past. Stress can trigger both responses. And anxiety itself can lead to depression. In fact, nearly 70 percent of people who suffer from depression also have anxiety, and 50 percent of those with anxiety have clinical depression.\nRead Also: Can Anxiety Cause Shortness Of Breath\nSix Simple Habits That Defeat Anxiety\nDeanne Repich, Director: National Institute of Anxiety and Stress\nIf youre like most anxiety sufferers, you probably spend much of your day wrestling with physical symptoms, feeling afraid, or even hiding your anxious feelings from others. When stressors arise your racing heart, trembling, dizziness, obsessive thoughts and other symptoms take over.\nAnxiety can keep you feeling trapped and once you feel this way, its difficult to know how or if you can ever feel better.\nIf you suffer from anxiety, take heart. Studies show that simple anxiety-reducing habits can go a long way toward improving how you feel.\nHere are six simple habits you can use to defeat anxiety and take back control of your life.\nHow Is Gad Treated\nFirst, talk to your doctor about your symptoms. Your doctor should do an exam and ask you about your health history to make sure that an unrelated physical problem is not causing your symptoms. Your doctor may refer to you a mental health specialist, such as a psychiatrist or psychologist.\nGAD is generally treated with psychotherapy, medication, or both. Talk with your doctor about the best treatment for you.\nDon’t Miss: Can Energy Drinks Cause Anxiety\nGetting Help For Anxiety\nIf you think your worry has gotten out of hand, an expert opinion can help to further clarify this. Meeting with a cliniciana counselor, social worker, psychologist, or psychiatristcan help you to determine if your anxiety issue can be classified as a disorder, and, if so, which one.\nClinicians will use diagnostic criteria for anxiety disorders to determine whether or not your anxiety is excessive. This typically involves an assessment of how persistent your anxiety is, what types of symptoms you experience, how long they last, and how intrusive they are on your ability to get through life on a day-to-day basis.\nGeneralized Anxiety Disorder Discussion Guide\nGet our printable guide to help you ask the right questions at your next doctor’s appointment.\nTreatment For Generalized Anxiety Disorder\nIf youve given self-help a fair shot, but still cant seem to shake your worries and fears, it may be time to see a mental health professional. But remember that professional treatment doesnt replace self-help. In order to control your GAD symptoms, youll still want to make lifestyle changes and look at the ways you think about worrying\nCognitive-behavioral therapy is one type of therapy that is particularly helpful in the treatment of GAD. CBT examines distortions in our ways of looking at the world and ourselves. Your therapist will help you identify automatic negative thoughts that contribute to your anxiety. For example, if you catastrophizealways imagining the worst possible outcome in any given situationyou might challenge this tendency through questions such as, What is the likelihood that this worst-case scenario will actually come true? and What are some positive outcomes that are more likely to happen?.\nThe five components of CBT for anxiety are:\nEducation. CBT involves learning about generalized anxiety disorder. It also teaches you how to distinguish between helpful and unhelpful worry. An increased understanding of your anxiety encourages a more accepting and proactive response to it.\nMonitoring. You learn to monitor your anxiety, including what triggers it, the specific things you worry about, and the severity and length of a particular episode. This helps you get perspective, as well as track your progress.\nRead Also: Can Anxiety Cause Fast Heart Rate\nThere May Be More Than Anxiety At Play\nAnxiety disorders often occur alongside other mental health issues. Depression and anxiety, for instance, frequently go hand in hand. While not everyone who deals with anxiety is also suffering from depression or another mental health disorder, it’s important to consider that someone who’s dealing with anxiety might have other things going on, even if they don’t divulge everything to you all at once.\n“Mental health issues are often co-occurring. A person may have one mental health challenge that they feel more open to talking about, and another that they keep private. Do not assume that you know the full scope of a person’s mental health challenges just because they have told you about one part of it,” says McCullough. It’s also important to note that just because someone has disclosed something to you in the past, it doesn’t mean that it’s always going to be that way. “Mental health is also constantly shifting, so over time, the landscape of a person’s mental health challenges may change,” she explains.\nWhile everyone with anxiety is different and no list is one-size-fits-all, these are good starting points when it comes to relating to those in your life who have an anxiety disorder. Ask them about their experiences, how you can help them, and what they wish people knew about their anxiety. You may be surprised by what you find.\nMore on mental health:\nHow To Ease Anxiety: 5 Ways To Feel Calmer Right Now\nWhen we’re anxious, our breath becomes rapid and shallow. Deep belly breathing helps decrease anxiety by stimulating the bodyâs relaxation response, lowering our heart rate and blood pressure. Itâs a powerful technique that works because we canât breathe deeply and be anxious at the same time. There are many variations to try, including this simple exercise:\nInhale deeply for a count of 4. Hold your breath for a count of 4. Exhale for a count of 4. Repeat several times.\nExercise is one of the best anxiety remedies, immediately and long term. Going for a walk creates a diversion from worries and releases muscle tension. Grab your headphones or earbuds on the way out:studies show that listening to music brings its own calming effects.\nLong term, regular exercise triggers the release of feel-good neurochemicals in the brain, building up resilience against stormy emotions. It boosts confidence and mood, and we donât need to run a marathon to feel the benefits. Washing the car, hiking, gardening, a pick-up game â anything that gets us moving counts. Research shows that 30 minutes, 3 to 5 days a week can help to significantly improve anxiety symptoms, but even 10 minutes can make a difference.\nYou May Like: What Calms Nerves And Anxiety","Stress and its impact\nStress is one of those words that is used very casually. We talk about being stressed when faced with a choice of which dress to buy for an important event or when we canít find the charger for our mobile phone.\nReal stress, however, has a huge impact on our health. If you already have a long term health condition, it is even more important that you learn how to reduce your stress levels.\nSo, what exactly is stress?\nProfessor Stephen Palmer, an expert in stress and stress management, defines it thus: “stress occurs when perceived pressure exceeds your perceived ability to cope”\nWe all need a certain amount of pressure in our lives to make it enjoyable; that thrill when you go on a first date, the nerves as you walk into an exam room, the fun of trying something new. When you are choosing a dress or hunting for the charger, what you are feeling is pressure.\nHowever, if you feel that the pressure has become too much, perhaps your boss is giving you more work than you feel you can cope with or a relationship is going through a bad patch and you are worried your partner will leave you, then your stress responses kick in.\nThe stress response and mechanism behind it\nTo understand the stress response, we have to wander into the world of neuroscience to get a feel for how the brain works. At any given time, your brain is being bombarded with hundreds of pieces of information through your five senses. Your brain processes that information faster than any super computer and it does this by comparing the new information with things that have happened before.\nIf you pick up an apple, your brain will process the information that your eyes, nose and fingers send to it, compare it with what it has learnt before and come back with apple.\nThis happens so fast you are not even aware of it. If you pick up a strange fruit that you have never seen before, the brain takes longer to process it and you will find yourself turning it over in your hands, perhaps smelling it and looking for a sign to tell you what it is. This information processing starts from the moment you are born.\nWhat about if you see a tiger loose in the street? Our brains process this slightly differently. The human brain has been in development for thousands of years.\nFight or flight?\nThe first part to develop was the part at the back of your head just above your spine – called the amygdala. This is the most basic brain form and it’s here that the things you do to stay alive (such as breathing) are controlled. It’s also where the fight or flight response is triggered. This response prepares your body to either fight or flee from the potential danger and it was essential in the days when if you hesitated for a minute, you could end up being eaten!\nBack to the tiger. As soon as you see it, the brain starts running through its processes. A signal is sent along the neural pathways to the areas that control your sight, hearing etc. and to the part of your brain that makes decisions about risk.\nHowever, part of that signal is sent directly to the amygdala. As soon as the amygdala receives the signal, it sends out a flood of hormones into your system. Your heart starts beating faster, your blood vessels constrict except for those supplying your arms, legs and heart, your pupils dilate, your mouth becomes dry and you get that feeling of butterflies in your stomach as your digestive system slows right down.\nThis all happens incredibly quickly, before the rest of your brain has even had time to process that it’s a tiger on the loose. The technical term for the system that does all this is the sympathetic system and as well as the brain, the adrenal glands and pituitary glands are involved. Hormones such as noradrenaline, adrenaline and cortisol are released. Now that this is all in place, you can run away from the tiger as fast as you can - the flight response.\nThe fight response works in exactly the same way. To put it in the relevant context, imagine you are in a traffic jam. Then, someone cuts in front of you all those hormones start rushing around your body and your body gets itself ready for a fight.\nWhen the danger is past, your parasympathetic system then sends out a different hormone so that your heart rate returns to normal, your blood starts flowing again and your stomach gets back to the business of digesting your food. If you are sitting comfortably relaxed in a chair reading this, it’s your parasympathetic system that’s in charge.\nApplication to today’s world\nNow you are probably thinking this is all very interesting but the only tigers you have seen have been safely behind bars in a zoo. What does this have to do with you?\nIn this modern age, we are bombarded with more information than at any other time in human existence. Remember that this information is being gathered from the moment you are born. The human brain takes longer to develop to full maturity than any other animal.\nIn fact, all the connections aren’t complete until you are in your early twenties. The amygdala doesn’t know the difference between a tiger and a maths exam you haven’t studied for. It just processes that it’s scary, so let’s get those hormones flowing.\nIn some people, the flight or fight response is activated way more often than usual, especially if as a child they felt very insecure in their environment. This can mean that even simple things like loud noises or strong smells can be perceived as a threat, setting off the sympathetic system.\nWhy to manage stress\nEventually, your body becomes overloaded with cortisol and things start to go wrong. Some people have heart attacks or strokes; others may use alcohol or drugs to alleviate the stress. In some cases, mental health problems such as depression or anxiety may develop.\nWhen you have a long-term health condition, your body is already under stress from dealing with that. The difficulties you may be having around work, relationships etc. will be adding further to your stress levels.\nHow to manage stress\nSo you can see that learning to manage stress is very important. Each of us is different, so we all react differently in a given situation.\nTake some time out to think about your daily routine and look at the areas where you feel stressed. See if there are ways that you can change or adapt things to make your life easier.\nThere are lots of ways to destress...listening to music, relaxation techniques, going for a walk in nature, mindfulness, yoga, tai chi...The list goes on. Finding what works for you may take some trial and error but it will be worth it.\nSometimes, the biggest cause of stress is the thoughts that we have and how we react to them. If we think, \"I can't cope\", our stress levels soar. If we react badly to things other people say, if we keep wishing that our lives could go back to the way they were in the past or if we feel that we are being a burden to our loved ones, stress will be a constant companion.\nA life coach can help you deal with stress, working with you to change the way you think about things, helping you to find the best stress relief techniques and helping you to see the difference between pressure and stress.\nWhat are your best techniques for dealing with stress? Share them in the comments!\nSilimar articles you might find interesting:\n- What You Didn't Know About Maintaining a Positive Mental Attitude\n- Dealing with Anxiety: The Toll It Takes on Our Wellbeing\n- How to Notice Your Stress Triggers and De-stress?\n Palmer, S and Cooper, G: How to deal with Stress (2007) (Kogan Page)"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:cc1b24cf-87b3-41d6-8c26-29fde16268b8>","<urn:uuid:fc7e9758-9c41-4430-80a4-a4512f026fa5>"],"error":null}
{"question":"What are the two main possibilities that microservices open up for B2B integration?","answer":"Microservices open up two possibilities: 1) customization of current EDI processes to streamline trading partner relationships and account for partner-specific requirements, and 2) formation of bilateral and multilateral exchanges of functionality, either within or outside a formal EDI setting.","context":["Konstantin Emelyanov - Fotolia\nAbout five years ago, IT pros started to realize that microservices offer a better approach to B2B integration. Rather than argue over what electronic data interchange protocol to use, users could instead use microservices to make an entire supply or distribution chain look more like a single, integrated flow without losing essential security and compliance activities.\nMicroservices open up two possibilities. The first is customization of current EDI processes to both streamline trading partner relationships and account for partner-specific requirements. Secondly, microservices can form the basis for bilateral and multilateral exchanges of functionality, either within or outside a formal EDI setting.\nOne of the first uses of microservices for B2B was to reduce the exploding number of separate EDI networks and interfaces created by the need to apply special transactional rules to select trading partners. With the creation of multiple implementations of specific EDI handling features, companies could reduce the number of specialized interfaces needed and simplify their EDI connectivity requirements.\nFor this application, EDI features can abstract behind a broker that selects the proper microservices sequence based on the partner identity. A single decision can then drive a whole string of microservices executions, some generalized for all partners and some that are partner-specific. This process limits the scope of the partner-specific customization needed for each feature and enables a company to create a complete set of handling instructions for each partner in its commercial exchanges.\nA second microservices benefit is the outpost microservices application, which is used to achieve more extensive process integration with partners. One example of this can be found in just-in-time (JIT) delivery scheduling. By integrating a partner microservice into inventory management, a consumer can alter JIT ordering practices to match the inventory level of its suppliers. If supplier inventory levels are falling, ordering might advance to prevent a shortage.\nFor this application, the important microservices feature is token-based security, which ensures that a microservice placed in another business's transaction flow doesn't create security or compliance problems. Microservices can apply ridged security to their APIs and can also create an audit trail, both of which are essential to survive an internal audit by all the businesses involved. Microservices can also enable look-only or selective query restrictions that constrain accessed information to that which actually supports the partner relationships.\nMoving away from EDI\nThese EDI-enhancing applications of microservices helped organizations step away from formal EDI specifications. EDI processes depend on complex sets of data models, designed to support generalized exchanges of business information. For many B2B applications, it's easier, cheaper and more convenient to use outpost microservices that provide a direct portal between business partners.\nOrder management and shipment make up a big part of B2B, and businesses that have a significant trading relationship with a partner could use microservices to integrate their order processes directly with their partner's. It's fairly easy to adapt data formats using microservices, and the key information exchanged should be consistent because of the partner relationship. This consistency eliminates the extra steps of formatting an EDI request, transporting the request, decomposing it and having a partner enter it.\nIt's this movement beyond emulating commercial paper that generated the most interest in the use of microservices for B2B enhancement. Generalized B2B driven by microservices is based on the exchange of microservices APIs among partners. Today, there are exchanges where partners expose microservices APIs to promote tighter business processes integration. These types of exchanges create a third model of microservices support for B2B: an API-based exchange that replaces the older EDI exchanges.\nPer-partner integration strategies\nMicroservices exchanges are a natural extension of per-partner strategies, which aim to reduce the customization burden on trading partners by establishing a fixed set of APIs and services that then serve as the basis for direct process integration -- rather than the EDI strategy of data-coupled integration. Where these exchanges are available, developers in the partner organizations can treat the exchanges as a set of available, reusable microservices so that the impact on software development is minimal.\nAny of these deep integration approaches can bring risks to security, compliance and even to performance, so it's essential that the APIs and microservices implementations take these into account. Stateless, scalable microservices are critical here, and formal API brokerage with access tokens are also important. In addition, it's necessary for the shared microservices and APIs to be available for all parties, which may mean it's best to host them in the cloud. Because of this, we see microservices-integrated B2B as a cloud-hosted function.\nTools and APIs to help\nCompanies like Software AG provide commercial packages that provide the basis for bilateral or multilateral B2B exchanges that use APIs and microservices instead of traditional EDI processes. While these products aren't essential to build microservices-based B2B, they can save you considerable time if you have multiple trading partners.\nYou can also use microservices and APIs to facilitate the integration of exception handling and other partner collaboration processes. Furthermore, many B2B users share the viewpoint that the next critical step in microservices support for B2B is to use microservices to integrate business processes -- not just applications. Work in this area is nascent, with applications and approaches currently more specialized to a specific partner relationship than generalized across the B2B space, but this is changing. There's great promise that microservices -- not EDI -- will ultimately form the basis of B2B going forward."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:42a3b289-8e39-4128-ad33-46a3e83984d5>"],"error":null}
{"question":"What are the benefits of studying long-term forest evolution, and what role do natural disturbances play in forest sustainability?","answer":"Studying long-term forest evolution provides crucial information about how environments have developed over hundreds to thousands of years in response to changes in climate, fire patterns, and human activity. This historical perspective helps inform current environmental management decisions rather than relying solely on current ecological patterns. Regarding natural disturbances, they are key to forest sustainability, as many forest types result from natural disturbances such as fire, storm blowdown, and native tree pests. These disturbances are generally not devastating, and successfully renewing forest elements after disturbance is essential for forest sustainability across landscapes and through time.","context":["Are rainforests as natural as they appear? How best to replant large forest areas destroyed by fire? A new consultancy service providing the data needed to answer these and other questions has been established at the University of Oxford.\nBioGeoSciences for Conservation (BGSC) has been set up to help managers having to make those decisions by providing information about how environments have evolved over long timescales. The consultancy service is backed by a specialist laboratory which uses fossil records such as pollen and charcoal to reconstruct how forests, savannas and other areas developed in response to changes in climate, disturbances by fire and people, and changes in soil fertility and water availability over hundreds to thousands of years.\nDr Kathy Willis, one of three Principals of BGSC, also heads the Oxford Long-term Ecology Laboratory. She said: ‘What is unique about this service is the way in which it links together many techniques to provide information that is not normally accessible to those involved in environmental management who tend to base their decisions simply on knowledge of current ecological patterns. We take a long-term perspective, sometimes over thousands of years, to help manage biodiversity today.\nBarbara Hott | alfa\nUrban growth causes more biodiversity loss outside of cities\n10.12.2019 | Deutsches Zentrum für integrative Biodiversitätsforschung (iDiv) Halle-Jena-Leipzig\nWie ganze Ökosysteme langfristig auf die Erderwärmung reagieren\n10.12.2019 | Universität Wien\nIn a joint experimental and theoretical work performed at the Heidelberg Max Planck Institute for Nuclear Physics, an international team of physicists detected for the first time an orbital crossing in the highly charged ion Pr⁹⁺. Optical spectra were recorded employing an electron beam ion trap and analysed with the aid of atomic structure calculations. A proposed nHz-wide transition has been identified and its energy was determined with high precision. Theory predicts a very high sensitivity to new physics and extremely low susceptibility to external perturbations for this “clock line” making it a unique candidate for proposed precision studies.\nLaser spectroscopy of neutral atoms and singly charged ions has reached astonishing precision by merit of a chain of technological advances during the past...\nThe ability to investigate the dynamics of single particle at the nano-scale and femtosecond level remained an unfathomed dream for years. It was not until the dawn of the 21st century that nanotechnology and femtoscience gradually merged together and the first ultrafast microscopy of individual quantum dots (QDs) and molecules was accomplished.\nUltrafast microscopy studies entirely rely on detecting nanoparticles or single molecules with luminescence techniques, which require efficient emitters to...\nGraphene, a two-dimensional structure made of carbon, is a material with excellent mechanical, electronic and optical properties. However, it did not seem suitable for magnetic applications. Together with international partners, Empa researchers have now succeeded in synthesizing a unique nanographene predicted in the 1970s, which conclusively demonstrates that carbon in very specific forms has magnetic properties that could permit future spintronic applications. The results have just been published in the renowned journal Nature Nanotechnology.\nDepending on the shape and orientation of their edges, graphene nanostructures (also known as nanographenes) can have very different properties – for example,...\nUsing a clever technique that causes unruly crystals of iron selenide to snap into alignment, Rice University physicists have drawn a detailed map that reveals...\nUniversity of Texas and MIT researchers create virtual UAVs that can predict vehicle health, enable autonomous decision-making\nIn the not too distant future, we can expect to see our skies filled with unmanned aerial vehicles (UAVs) delivering packages, maybe even people, from location...\n03.12.2019 | Event News\n15.11.2019 | Event News\n15.11.2019 | Event News\n11.12.2019 | Materials Sciences\n11.12.2019 | Information Technology\n11.12.2019 | Life Sciences","Understanding the Ecological Roles of Natural Disturbance\nThe key to sustaining forests is successfully renewing all their elements after disturbance, across landscapes and through time. NRS scientists are working to strengthen our understanding of the relationships of certain elements of forest communities in stands and forests of different ages, species compositions, and disturbance history and patterns. Many forest types result from natural disturbances such as fire, storm blowdown, and native tree pests. Generally these are not devastating disturbances; those usually result from non-native pests.\nInteractions between Fire, Gaps, and Deer Browsing\nIn eastern deciduous forests, low-intensity understory fires, canopy gaps, and ungulate browsing are generally regarded as the main forces influencing vegetation dynamics. Over the past 100 years, all three of these historic disturbance and herbivory regimes have been altered to some extent (e.g., fire suppression, smaller, less frequent gap formation in 2nd growth forests, and overabundant deer herds) and have been putatively linked to observed changes in regeneration patterns and losses in understory herbaceous diversity.\nFuels and Fire Behavior in Eastern Hardwoods\nAn ability to predict fuel loads and fire behavior are needed to improve prescriptions for prescribed fire and answer questions about smoke emissions and transport and fire effects on flora and fauna. Our fuels and fire behavior research seeks to develop process-based (mechanistic) approaches to predicting fuel characteristics and fire behavior, with particular focus on hardwoods in Appalachian topography.\nEcosystem Management Study: Restoration of Mixed-oak Forests with Prescribed Fire\nHistorically, fire was a frequent disturbance process in the mixed-oak forests of the central hardwoods region. Fire control has altered forest structure and composition. Forests are more dense and the sustainability of oak and hickory dominance is now threatened by an abundance of shade-tolerant and fire sensitive tree species such as red maple, sugar maple, and beech. Prescribed fire has been advocated to promote and sustain open-structured mixed-oak forests and the plants and animals that have adapted to these communities. However, long-term research on fire effects is lacking.\nPlant Diversity in Managed Forests\nThe great majority of plant diversity in forests is contained in the herbaceous layer, comprised of both herbaceous and woody species. We seek a better understanding of how forest management activities affect plant diversity. NRS-2 scientists are investigating the direct and indirect effects of timber harvesting, prescribed burning, herbicide application, and deer browsing (alone and in combination) on plant composition and diversity in mixed oak, Allegheny, and Northern Hardwood forests.\nSite, Stress, Nutrition, and Forest Health Interactions\nA range of stressors including defoliating insects, pathogens, droughts, inadequate soil base cations, and changing climate have interacted to affect the health and regeneration of selected northern and central hardwood forest species. In the 1980s and 1990s sugar maple dieback and mortality was extensive across the unglaciated Allegheny Plateau in northern Pennsylvania.\nFire Effects in Eastern Forests\nUnderstanding fire effects requires consideration of the processes by which the effects occur. We are applying process-based (mechanistic) approaches to modeling fire effects on endangered Indiana bats and fire-caused tree injury and mortality. Fires pose risks for bats but also provide opportunities for improving bat roosting habitat, our project considers both sides of the problem.\nThe Ecology and Silviculture for Restoration of Shortleaf Pine\nThere is renewed interest in restoring shortleaf pine throughout its native range in the Ozark Highlands and elsewhere in the Central Hardwood Forest Region and in the southeastern United States. Restoring shortleaf pine on former pine and oak-pine sites is viewed as a long-term strategy for mitigating chronic oak decline. There also is an increasing interest in restoring native oak-pine woodland communities where they once were abundant.\nThe Role of Fire in Restoration of Woodlands and Savannas\nOur research is focused on understanding the role of fire in sustaining woodland and savanna composition and structure. Our goals are to develop fundamental information about how to manage and regenerate oak and oak-pine woodlands and savannas with timber harvests and prescribed fire and to use this information to develop management guidelines to be applied on both public and private land.\nRestoration of Mixed Oak Forests in Southern Ohio with Prescribed Fire\nIn the eastern U.S., fire suppression has been implicated as a primary factor facilitating shifts in forest composition from oak to other species, often maples. The state of Ohio began suppressing fires in 1923. Oaks are considered well-adapted to a regime of frequent low- to moderate-intensity fires because they possess thick bark, the ability sprout repeatedly after being topkilled, and are intermediate in shade tolerance.\nFire and Fire Surrogate Treatments: The Central Appalachian Plateau Site\nCurrent forests in many fire-dependent ecosystems of the United States are denser and more spatially uniform, have many more small trees and fewer large trees than did their presettlement counterparts. Causes include fire suppression, past livestock grazing and timber harvests, and changes in land use. The results include a general deterioration in forest ecosystem integrity and the threat of losing important, widespread forest types. Such conditions are prevalent nationally, especially in forests with historically short-interval, low- to moderate-severity fire regimes, such as the upland oak forests of the central hardwoods region.\nThe physiology, genetics, and distribution of ponderosa pine species vary with changes in elevation and environmental conditions\nIn the desert southwest, significant variations in moisture and temperature occur along steep gradients in elevation. Notably, the endemic ponderosa pine species vary with changes in elevation and the differences in elevation are repeated throughout the ranges of the species. The long-term goal of the study is to provide a foundation for future regional studies of species range limitations by water or temperature stress.\nDesigning Pest-Resistant Forest Landscapes: The Importance of Spatial Pattern\nDefoliating insects damage millions of acres of forested land annually in the United States. The balance of evidence suggests forest insect outbreaks today are more damaging than ever because of changes in forest composition and structure induced by fire suppression and post-harvest proliferation of tree species intolerant to herbivory. Our central hypothesis is that landscape connectivity of acceptable host types increases defoliator population connectivity, altering the dynamics and spatial structure of defoliator populations, and thus increasing forest susceptibility to insect pest damage.\nCatastrophic Wind Disturbance\nIn eastern forests, severe wind disturbances are common and salvaging occurs after these disturbances. The Allegheny Plateau region alone receives an average of 11 high wind events and one tornado per year (National Climate Data Center) making wind the predominant natural disturbance event. Given the ubiquity of storm damage and salvaging on the Allegheny and elsewhere, there is a surprising paucity of experimental work demonstrating the impact of salvage logging on post-disturbance forest regeneration patterns.\nLong-term Change at Hearts Content and Tionesta Scenic and Research Natural Area\nOur ability to understand how unmanaged forests develop over time through various climatic and environmental changes depends on long-term data from unmanaged forests, especially remnants of the forest that predated European settlement of our region. Impacts of acid deposition, deer overabundance, beech bark disease, recovery of vegetation after windthrow, climate change, invasive plants – all are better understood by examining their effects in forests that have not been directly manipulated by humans, as well as those that have been managed.\nNative Invasive Species\nRecent changes in disturbance and browsing regimes have strongly impacted species composition in forest understories worldwide. In some cases, these changes have led to large increases in the density and cover of a small number of native understory plant species which may then expand to form interfering vegetation layers.\nRegeneration of Northern and Allegheny Hardwoods\nThe Allegheny hardwood forest type is a variant of the northern hardwood type consisting primarily of black cherry, red maple, sugar maple and American beech. Associated species include white ash, yellow‑poplar, black birch, yellow birch, cucumber magnolia and hemlock. Black cherry and the maples usually dominate stands in Pennsylvania and southward; white ash and sugar maple tend to be more important, and red maple less important, in the New York portion of the range.\nAdapting Forests to Climate Change\nClimate models have projected significant increases in temperature over the next century for the Northeast and Midwest. Climate change will also affect rainfall patterns, but scientists cannot yet predict how regional rainfall patterns will change. Growing seasons will lengthen further in both spring and fall. According to the Intergovernmental Panel on Climate Change, there is very high confidence that the vulnerability of North America depends on the effectiveness and timing of adaptation and the distribution of coping capacity, which vary spatially and among sectors. Climate change will constrain North America’s over-allocated water resources, increasing competition among agricultural, municipal, industrial and ecological uses (very high confidence).\nTropical Forest Mycology\nThe Center for Forest Mycology Research (CFMR, part of the Northern Research Station of the US Forest Service) leads critical research on the biology of tropical fungi native to Hawaii, US territories in the Caribbean (Puerto Rico and the US Virgin Islands) and to other countries in the Caribbean Basin.\nFire and Fuels Research at the\nSilas Little Experimental Forest\nThe Silas Little Experimental Forest was reinstated using National Fire Plan funding in 2003 to conduct multi-disciplinary fire and atmospheric science research to provide fire and forest managers with better tools for predicting fire danger, fire risk, air quality, and ecosystem functioning under changing environmental conditions.\nMid-Atlantic Forests and the Chesapeake Bay Watershed\nForest landscapes are changing as a consequence of climate and environmental change. These changes affect people and the forest ecosystems they depend on for clean water, clean air and forest products, and recreation. How can we best manage our forest resources to sustain this array of ecosystem services under increasing environmental stress and a changing climate?\nImpacts of Disturbances and Climate on Carbon Sequestration and Biofuels\nCurrently, U.S. forests and forest products offset about 20% of the nation’s fossil fuel emissions. However, recent findings cast doubt on the sustainability of this offset. First, the strength of the U.S. forest carbon offset may be weakening due to forest ageing, climate variability, and increasing natural disturbances. Second, climate change is expected to further increase frequencies of insect outbreaks and wildfire, and alter species composition in forest ecosystems, consequently influencing forest carbon pools in a significant way. These current and projected forest carbon cycle dynamics need to be considered in strategic forest planning and management decisions in coming decades if the nation’s forests are to provide stable or even increasing ecosystem services.\nPredicting global change effects on forest biomass and composition in south-central Siberia\nMultiple global changes such as timber harvest of previously unexploited areas and climate change will undoubtedly affect the composition and spatial distribution of boreal forests, which will in turn affect the ability of these forests to sequester carbon. To reliably predict future states of the boreal forest it is necessary to understand the complex interactions among forest regenerative processes (succession), natural disturbances (e.g., fire, wind and insects) and anthropogenic disturbances (e.g., timber harvest).\nEffects of Global Atmospheric Change on Forest Insects\nWe are studying seasonal and annual changes in forest insect populations at the Aspen FACE experiment site in northern Wisconsin where trees are growing under both elevated CO2 (+200 ppm above ambient) and ozone (+50% above ambient).\nStudying fire mitigation strategies in multi-ownership landscapes: Balancing management of fire-dependent ecosystems and fire risk.\nFire risk mitigation within multi-owner landscapes containing flammable but fire-dependent ecosystems epitomizes the complexities of managing public lands. The cumulative effects of fire and forest management over the last century have exacerbated fire risk in some regions and threatened fire-dependent systems in many others. The issue is further complicated by the recent encroachment of human homes into fire prone ecosystems that simultaneously increase fire ignitions and increase demands on fire suppression agencies to protect lives and property. Consequently, the balance between forest restoration, human rural development, and fire risk remains an issue of major concern to natural resource agencies.\nEffects of Insect Defoliation on Regional Carbon Dynamics of Forests\nOn an annual basis, insects severely defoliate more than 20 million acres of forested land in the conterminous United States, affecting a larger area and incurring higher economic costs than any other disturbance. However, the long-term costs and ecosystem consequences of insect outbreaks on forest health and productivity are difficult to quantify at the regional scale because of the variety of pests involved, differences in forest types affected, and varying spatial scale and intensity of the impacts. In particular, the effect of insect activity on carbon cycling and sequestration at the annual and decadal scale is poorly characterized.\nThe Working Forest Initiative: Simulating the cumulative effects of the forest management strategies of multiple landowners on landscape pattern and biodiversity\nSustainable forestry involves the extraction of forest products while maintaining ecosystem integrity to conserve biodiversity and to provide other non-commodity benefits to society. Population viability is a function of the combined actions of multiple landowners, which create a dynamic mosaic of forest types, stand structures and age distributions. Consequently, it is necessary to understand how the actions of individual land owners interact with the actions of others to determine the spatial pattern of the landscape mosaic, and therefore its ability to maintain biodiversity.\nModeling silvicultural treatments after natural disturbance\nModeling silviculture after natural disturbance to maintain biodiversity is a popular concept., yet its application remains elusive. We discuss difficulties inherent to this idea, and suggest approaches to facilitate implementation, using longleaf pine (Pinus palustris). In this species, natural disturbances such as lightning, hurricanes, surface fires, and windthrow all lead to similar structures, but at different rates. The outcomes of natural disturbances are inherently different from those of silviculture (for example, harvesting always removes boles) and it is instructive to think of silvicultural disturbances along a gradient in structural outcomes, reflecting degree of disparity with natural disturbance. Interactions of frequency, severity, intensity, seasonality, and spatial pattern define a disturbance regime and these components may not have equal weight in affecting biodiversity and some are easier to emulate with silviculture than are others.\nLast Modified: 03/06/2013"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:676de1ff-4f8b-4df4-9421-4c0830af9e02>","<urn:uuid:39097e82-0611-416c-a91c-a0cd4ed7322a>"],"error":null}
{"question":"在实验室环境中，水冷式冷水机组与高速冷冻离心机的温度控制系统有何异同？请详细说明。","answer":"Both systems require precise temperature control but operate differently. High-speed refrigerated centrifuges maintain temperatures between 0-40°C and feature rapid cooling capabilities to prevent sample denaturation, typically cooling from room temperature to 4°C in about 10 minutes. Water-cooled chillers, on the other hand, operate based on entering condenser water temperature related to ambient wet-bulb temperature. Water-cooled chillers typically maintain coolant temperature around 50°F (10°C) and can operate more efficiently than air-cooled systems since the wet-bulb temperature is always lower than the dry-bulb temperature, allowing for lower refrigerant condensing temperatures and pressures.","context":["High-speed refrigerated centrifuges are conventional laboratory centrifuges, which are widely used in biology, chemistry, medicine, and other scientific research, education, and production departments; due to the high speed, it is recommended that when users buy a centrifuge, except the centrifuge speed, centrifugal force, and rotor capacity. Besides, for meeting the basic experimental needs, special attention should be paid to the safety performance and performance of the centrifuge such as the centrifuge, which is equipped with automatic rotor recognition function, the rotor has biological safety protection function, fast cooling function, explosion-proof safety protection function, etc., To ensure the laboratory personnel in a safe experimental environment, this article will focus on the related introduction.\nHigh-speed refrigerated centrifuges generally have a maximum speed of 10,000 to 30000 RPM, and the separation form is solid-liquid sedimentation separation, generally equipped with various angle rotors, horizontal rotors, zone rotors, vertical rotors, etc.; It has refrigeration system to eliminate the heat generated by the friction between the rotor and the air during high-speed rotation. The temperature of the centrifugal chamber can be adjusted and maintained at 0-40°C. Speed, temperature, and time can be strictly and accurately controlled and displayed, usually used for the separation and purification of microbial cells, cell debris, large organelles, ammonium sulfate precipitates, and immunoprecipitates.\nAt present, high-speed refrigerated centrifuges have relatively strict requirements on the main shaft, motor, rotor, refrigeration, safety performance, etc., so the high-speed refrigerated centrifuge brands frequently selected by users on the market are relatively concentrated, such as Eppendorf, Heraeus, Sigma, Heal Force, etc.\nSo, how to choose a high-speed refrigerated centrifuge with highly comprehensive cost performance? My suggestions are as follows.\nPurchasing Recommendations the Centrifuge\n1. The speed, centrifugal force, and rotor capacity should meet the experimental requirements or expansion requirements.\nThe most basic requirements for choosing a high-speed refrigerated centrifuge are that the rotation speed and centrifugal force must not be lower than the actual requirements required for the experiment, and the centrifuge rotor must meet the needs of various specifications of centrifuge tubes required for the experiment. If conditions permit, it is recommended to purchase a high-speed refrigerated centrifuge that is slightly larger or larger than the specifications required for the current experiment to meet future experimental expansion needs and avoid purchasing again.\nThe core of centrifugal separation is centrifugal force. One of the main factors for the successful separation of experimental samples is centrifugal force; due to different centrifugal radii and other factors, there will be a large difference in centrifugal force at the same speed. The maximum speed of the centrifuge is 23300RPM, but the centrifugal force actually exceeds 50000g, so this centrifuge can basically meet the experimental conditions required for routine scientific research experiments. There are many desktop high-speed refrigerated centrifuges with a speed of 25000RPM or higher. The maximum centrifugal force can only reach about 35000g.\n2.Outstanding centrifugal performance:\nThe main performances of high-speed refrigerated centrifuges include time for speeding up and down, cooling speed, the versatility of centrifuge, humanized operation, etc. Some of them will be selected for a brief introduction;\nTime for speeding up and down: This performance is particularly concerned by users in micro desktop high-speed centrifuges, such as the micro-speed and high-speed centrifuge commonly used in molecular biology. Speed up to 12000RPM, the time required by different brands varies from 12 seconds to 25 seconds, for example, Heal Force Neofuge13R centrifuge takes about 13 seconds (Note: Some experiments require natural speed reduction or slower speed, the better, such as white membrane layer separation);\nRefrigeration speed: General molecular biology experiments require centrifugation at 4°C. Since the centrifuge is placed in the laboratory, the temperature of the chamber of the centrifuge must be stabilized at about 4°C before the sample is placed in the centrifuge to prevent the sample Denaturation and other damages, so it is recommended to choose a centrifuge with pre-cooling function and rapid cooling to reduce the waiting time and provide a stable temperature environment, for example, Heal Force Neofuge13R centrifuge from room temperature 25 ℃ to 4 ℃ only takes 10 minutes.\nCentrifuge versatility: a laboratory may carry out different experiments at the same time. Sometimes, it not only needs 1.5ml centrifuge tubes, but also centrifuge tubes with different specifications such as 50ml, 15ml, and even larger capacity, such as 400ml centrifuge bottles. At this time, it is recommended to buy a desktop high-speed universal centrifuge to meet all the above centrifugal needs, such as the Heal Force Neofuge1600R centrifuge.\n3. Security protection performance\nWhen choosing a centrifuge, in addition to paying attention to the speed, centrifugal force, capacity, and performance, because the rotor of the high-speed centrifuge is running at a very high speed, in case the centrifuge accidentally breaks the shaft or the rotor breaks unexpectedly, It is very important whether the centrifuge can effectively ensure the personal safety of the experiment operators and avoid the occurrence of experimental accidents.\nIn terms of the safety design of high-speed refrigerated centrifuges, it is recommended that you choose a centrifuge with an automatic rotor recognition function to avoid possible safety accidents caused by incorrect operation of the experiment operator when the centrifugal speed value is set to exceed the maximum speed specified by the rotor.\nIf the experiment requires centrifugal separation of samples with pathogenic microorganisms, in order to avoid experimental operators being exposed to possible bioaerosols, it is recommended to choose an air-tight centrifugal rotor with biological safety protection function in a biological safety cabinet The rotor is opened to protect the operator, and at the same time, the rotor can be sterilized at high temperature and humidity.\nThe high-speed refrigerated centrifuge is home to routine laboratory equipment. Due to its high frequency of use, it is particularly important to choose a centrifuge with outstanding performance, high safety protection, and beautiful appearance.\nIt is recommended that when purchasing a centrifuge, in addition to the speed, centrifugal force, rotor capacity and lifting speed meeting the experimental requirements, special attention should be paid to the safety performance and performance of the centrifuge, such as rotor automatic identification function, rotor biological safety protection function, rapid cooling Function, explosion-proof safety protection function, etc., to ensure that the experimenters work in a safe experimental environment, and at the same time ensure the safety of the experimental samples.","What are Chiller Systems?\nCommercial buildings use Heating, Ventilation and Air Conditioning (HVAC) systems to dehumidify and to cool the building. Modern commercial buildings seek efficient HVAC systems and components as part of broader initiatives centered on building performance and sustainability. Building occupants similarly carry great expectations, that the HVAC system will function as intended . . . to create a comfortable interior environment regardless of the conditions external to the building.\nChillers have become an essential HVAC component of a wide variety of commercial facilities, including hotels, restaurants, hospitals, sporting arenas, industrial and manufacturing plants, etc. The industry has long recognized that chiller systems represent the single largest consumer of electrical usage in most facilities. They can easily consume more than 50% of the total electrical usage during seasonal periods. According to the US Department of Energy (DOE), chillers can combine to use approximately 20% of the total electric power generated in North America. Moreover, the DOE estimates that chillers can expend up to 30% in additional energy usage due to various operational inefficiencies. These acknowledged inefficiencies cost companies and building facilities billions of dollars annually.\nIn general, a chiller facilitates the transfer of heat from an internal environment to an external environment. This heat-transfer device relies on the physical state of a refrigerant as it circulates through the chiller system. Certainly, chillers can function as the heart of any central HVAC system.\nHow Does a Chiller Work?\nA chiller works on the principle of vapor compression or vapor absorption. Chillers provide a continuous flow of coolant to the cold side of a process water system at a desired temperature of about 50°F (10°C). The coolant is then pumped through the process, extracting heat out of one area of a facility (e.g., machinery, process equipment, etc.) as it flows back to the return side of the process water system.\nA chiller uses a vapor compression mechanical refrigeration system that connects to the process water system through a device called an evaporator. Refrigerant circulates through an evaporator, compressor, condenser and expansion device of a chiller. A thermodynamic process occurs in each of above components of a chiller. The evaporator functions as a heat exchanger such that heat captured by the process coolant flow transfers to the refrigerant. As the heat-transfer takes place, the refrigerant evaporates, changing from a low-pressure liquid into vapor, while the temperature of the process coolant reduces.\nThe refrigerant then flows to a compressor, which performs multiple functions. First, it removes refrigerant from the evaporator and ensures that the pressure in the evaporator remains low enough to absorb heat at the correct rate. Second, it raises the pressure in outgoing refrigerant vapor to ensure that its temperature remains high enough to release heat when it reaches the condenser. The refrigerant returns to a liquid state at the condenser. The latent heat given up as the refrigerant changes from vapor to liquid is carried away from the environment by a cooling medium (air or water).\nTypes of Chillers:\nAs described, two different cooling mediums (air or water) can facilitate the transfer of the latent heat given up as the refrigerant changes from vapor to liquid. Thus, chillers can use two different types of condensers, air-cooled and water-cooled.\n- Air-cooled condensers resemble the “radiators” that cool automobile engines. They use a motorized blower to force air across a grid of refrigerant lines. Unless they are specially designed for high-ambient conditions, air-cooled condensers require ambient temperatures of 95°F (35°C) or below to operate effectively.\n- Water-cooled condensers perform the same function as air-cooled condensers, but require two steps to complete the heat transfer. First, heat moves from refrigerant vapor into the condenser water. Then, the warm condenser water is pumped to a cooling tower where the process heat is ultimately discharged to the atmosphere.\nWater-cooled chillers feature a water-cooled condenser connected with a cooling tower. They have commonly been used for medium and large installations that have a sufficient water supply. Water-cooled chillers can produce more constant performance for commercial and industrial air conditioning because of the relative independence to fluctuations of the ambient temperature. Water-cooled chillers range in size from small 20-ton capacity models to several thousand-ton models that cool the world’s largest facilities such as airports, shopping malls and other facilities.\nA typical water-cooled chiller uses recirculating condenser water from a cooling tower to condense the refrigerant. A water-cooled chiller contains a refrigerant dependent on the entering condenser water temperature (and flow rate), which functions in relation to the ambient wet-bulb temperature. Since the wet-bulb temperature is always lower than the dry-bulb temperature, the refrigerant condensing temperature (and pressure) in a water-cooled chiller can often operate significantly lower than an air-cooled chiller. Thus, water-cooled chillers can operate more efficiently.\nWater-cooled chillers typically reside indoors in an environment protected from the elements. Hence, water-cooled chiller can offer a longer lifespan. Water-cooled chillers typically represent the only option for larger installations. The additional cooling tower system will require additional installation expense and maintenance as compared to air-cooled chillers.\nAir-cooled chillers rely on a condenser cooled by the environment air. Thus, air-cooled chillers may find common application in smaller or medium installations where space constraints may exist. An air-cooled chiller can represent the most practical choice in scenarios where water represents a scarce resource.\nA typical air-cooled chiller can feature propeller fans or mechanical refrigeration cycles to draw ambient air over a finned coil to condense the refrigerant. The condensation of the refrigerant vapor in the air-cooled condenser enables the transfer of heat to the atmosphere.\nAir-cooled chillers offer the significant advantage of lower installation costs. Simpler maintenance also results due to their relative simplicity as compared to water-cooled chillers. Air-cooled chillers will occupy less space, but will mostly reside outside a facility. Thus, the outdoor elements will compromise their functional lifespan.\nThe all-inclusive nature of air-cooled chillers reduces maintenance costs. Their relative simplicity coupled with reduced space requirements produces great advantages in many types of installations.\nActions to Increase Efficiency of Chiller Systems:\nChiller costs consume a substantial part of your building’s utility bills. What measures should one take to obtain energy savings through maximal efficiency of the chiller system? Let’s examine some possibilities.\nChiller systems will operate more efficiently through proper ongoing maintenance. Most organizations recognize this value and have taken steps as part of their day-to-day facility management best practices. Some common best practices for chiller systems include:\n- Inspect and clean condenser coils. Heat transfer has a large effect on chiller systems and remains fundamental to producing efficient chiller operation. Routine maintenance should inspect condenser coils for clogging and free air passage.\n- Maintain refrigerant charge. A chiller’s cooling quotient depends on proper refrigerant levels in the system. Maintaining proper refrigerant charge can greatly impact energy efficiency by reducing cooling costs by nearly 5-10%.\n- Maintain condenser water: Condenser water loops used with cooling towers must maintain proper water flow as designed. Any debris like sand, erosive solids and contamination materials can affect the condenser water loop. Fouling or scaling can inhibit water flow and greatly impact the chiller operating efficiency.\nArtificial Intelligence (AI) continues to advance in everyday practical applications. Machinery such as chiller systems will benefit from AI algorithms that can detect potential failures before they occur. Predictive maintenance leverages the collection and analysis of chiller system operational data to determine when maintenance actions should be taken prior to catastrophic failure. As chillers systems represent the heart of most modern HVAC systems, the prevention of catastrophic failures that produce significant “downtime” will save on emergency repair costs as well as reputation. The critical role played by a chiller system warrants the increased scrutiny. Big Data and AI will minimize downtime and maximize productivity.\nThe Internet of Things (IoT) provides the data collection tool that can enable AI applications such as predictive maintenance. In fact, the future of HVAC is AI and IoT. IoT enables the collection of real-time data from a chiller to enable continual analysis of its operation. The granular IoT data collected from a chiller will go far beyond that obtained by visual inspection. IoT connects building engineers to real-time visibility of critical HVAC assets, thereby enabling informed monitoring of actual operating conditions.\nChillers operate as part of a complex HVAC system. Water-cooled chillers have greater complexity due to the connection to a cooling tower system. Evaluating overall chiller plant performance will therefore involve an analysis of total power consumption of the compressor, pumps, cooling tower fans, etc. to evaluate comprehensive efficiency measures such as kW/ton.\nOptimization of the overall chiller plant must be performed holistically. Various adjustments focusing on optimal chilled water set points, chiller sequencing and load balancing, peak demand management, cooling tower water management, etc. can only be performed with operational data. IoT can provide the tools for such optimization by providing real-time monitoring of power consumption from each part of the chiller plant, supply/return temperatures from the chiller and cooling tower, water flow rates from the condenser water loop, etc. IoT has found practical application in HVAC to facilitate true optimization.\nChiller operational efficiency will greatly impact your building operating costs. Ongoing routine maintenance represents the minimum from the perspective of facility management. Predictive maintenance and optimization of the chiller system requires real-time operational data. IoT has opened the door to new forms of chiller efficiencies.\nEditor's Note: This post was originally published in November 2017 and has been completely revamped and updated for accuracy and comprehensiveness."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:8b7d8232-dde9-44a0-918e-7f35bed12817>","<urn:uuid:0e282f18-3d8a-49ec-b001-5ee3512f7143>"],"error":null}
{"question":"Hey! 🤔 I'm writing my first research paper and I'm struggling with both the introduction and conclusion. What's the main difference between them, and how do I avoid being too repetitive in the conclusion?","answer":"The introduction and conclusion serve different purposes. The introduction consists of three main elements: description of the goal (like answering a research question or discussing a new phenomenon), introduction to the topic, and description of the structure of the work. The conclusion, while containing some necessary redundancy, is written for a more informed reader who has already read the paper. In the conclusion, you should summarize the main insights without being completely redundant, reflect on whether the goal was achieved, and meet specific requirements like not introducing new information or examples. The conclusion can reference complex concepts more directly since the reader will have learned about them throughout the paper.","context":["A scientific paper deals with a topic that is worked out systematically and logically.\nA scientific paper’s structure is divided into an introduction, the main part, and a conclusion. This is followed by the bibliography and often an affidavit.\nWe’ll show you the most important rules that you should follow when writing academic papers.\nThe introduction to your text consists of\n- The description of the target\n- The introduction to the topic and\n- The description of the structure of your scientific work\nGoal of the scientific work\nYour scientific work can have different goals:\n- A question, e.g., A research question, is answered.\n- A hypothesis, statement, or opinion is confirmed or refuted.\n- A complicated subject is explained.\n- A new phenomenon or a new idea is discussed.\n- A certain prediction is made about a situation.\nIntroduction to the topic\nAs soon as you know your scientific paper goal, you can familiarize yourself with the underlying topic.\nIn the introduction, you present the topic and thereby establish a framework for your scientific work.\nDescription of the structure\nYou describe which sub-topics you will deal with in the individual sections of the scientific work.\nBefore writing the introduction on a scientific paper, create a keyword list for your scientific work’s goal, topic, and subtopic. This makes it easier to structure and describe the structure of your work in the introduction.\nIn the main part of your scientific work, you will develop answers to your question by:\n- Narrow down your topic and explain technical terms\n- Theories and concepts are investigating.\n- Name arguments and structure them.\n- Use research methods if necessary.\n- Your text into sections and paragraphs\nNarrow down the topic and explain technical terms\nIn your main part, give enough background information on your topic.\nDefine all relevant technical terms that are necessary for understanding your scientific work.\nExplore theories and concepts\nDo a literature search to find out which studies on your subject already exist. Provide an overview of the current state of research and present essential theories and concepts.\nMake sure to identify other people’s thoughts by properly citing sources, direct quotations, or paraphrases.\nBuild your argument logically by including information such as:\n- Describing chronologically\n- Organize according to their importance\n- Structured according to sub-topics\n- From different perspectives\nUse research methods\nYou can generate answers to your questions by doing your research. The application of methods is common for theses.\nIf you use research methods in your scientific work, please state:\n- What kind of exam are you doing?\n- How you collect the data\n- What characteristics your data have\n- How to conduct your investigation\n- How to analyze your data\nAlso, make sure that you adhere to quality criteria such as validity and reliability.\nUse sections and paragraphs\nA logical division into sections or chapters and paragraphs is crucial for the structure of your scientific work.\nIf one can break down your scientific work into sub-topics, divide the sub-topics into sub-chapters.\nAt the end, you round off the scientific work by:\n- Summarizes the main insights of your main part\n- Describes whether and how the goal of the work was achieved and\n- Meet important requirements for a happy ending.\nIn the introduction, you described your scientific work’s aim and dealt with the associated topic in the main part.\nIn the end, you reflect on whether and how you have achieved this goal. If you didn’t achieve the goal, reflect on why you did. Also, describe what alternatively you could have done to achieve it.\nRequirements for a happy ending\nTo write a happy ending, you should:\n- Depict how you achieved the goal or reflect on why you did not achieve it\n- Take up important topics from the main part again precisely.\n- Do not mention any new information.\n- Do not interpret results.\n- Relate to facts and quote them correctly\n- Do not give any new examples.\n- Formulate a catchy last sentence\nIn the bibliography, you list all sources that you have cited and used in your scientific work.\nEnter the author, year of publication, title, place of publication, and publisher for each source.\nMake sure that you use a consistent citation style throughout the text.\nDepending on your field of study’s requirements, you may have to insert an affidavit at the end of your scientific work.\nYou declare that you wrote the work yourself and that you only used the sources you specified in the bibliography.","Components of Documents: Conclusion Back to Components of Documents Next Section\nStudents often have difficulty writing the Conclusion of a paper because of concerns with redundancy and about introducing new ideas at the end of the paper. While both are valid concerns, summary and looking forward (or showing future directions for the work done in the paper) are actually functions of the conclusion. The problems then become:\n- how to summarize without being completely redundant\n- how to look beyond the paper without jumping completely in a different direction\nSince the conclusion’s job is to summarize the paper, some redundancy is necessary. However, you are summarizing the paper for a reader who had read the introduction and the body of the report already, and should already have a strong sense of key concepts. Your conclusion, then, is for a more informed reader and should look quite different than the introduction.\nIn a report on bone tissue engineering, your introduction (see Online Handbook / Components of Documents / Introductions\n) and literature review (see Literature Review\n) might discuss osteoporosis, along with current methods of treatment and their limitations at length, since this involves developing context and establishing the gap for your paper. It would even likely form a large part of the literature review. Your conclusion, however, might summarize all of this in one sentence, while identifying itself as summary (by virtue of the “as mentioned previously”):\nAs mentioned previously, current treatments for osteoporosis that attempt to stimulate re-growth of bone are limited because of problems delivering appropriate signaling mechanisms.\nA sentence like this in the introduction would create difficulty for most readers – who would not initially know what signaling mechanisms are or what role the play in process for bone growth. But by time they reach the conclusion, the audience should know what they are, as well as the problems with current mechanisms. The above sentence might not work anywhere else in the paper – since it relies on knowledge developed throughout the paper.\nSimilarly, since you’ve probably spent a fair amount of time and evaluating the solution in the body of the report, a simple reference to the technology is sufficient.\nTechniques involving injecting nanoparticles containing bone growth factors at the relevant areas have been shown to be effective, safe, and stable [1,2, 8-10].\nThis sentence relies on the audience knowing that “effectiveness,” “safety,” and “stability” are the three criteria for a successful delivery method, and also what the terms mean.\nThese two sentences could form the basis of your conclusion: they review the key elements of an engineering paper (see Accurate Documentation / Conducting and Understanding Research in Engineering\n) by going over the situation-problem-solution-evaluation structure very briefly.\nThe summary could be longer. It might, for example, acknowledge the limitations of this method in current research:\nHowever, research on the use of nanoparticles has yet to be conduct in vivo (in any applications) and bone tissue engineering is still in its infancy as a field of science.\nOr, the conclusion might develop any of the above aspects in greater detail. The level of detail you engage in your summary is up to you – a conclusion can be as short as a few sentences and as long as several pages – depending on the length of the paper and the complexity of the subject matter. Prescribing a length for the conclusion is difficult, but it should not exceed 10% of the document itself, and in many cases is significant shorter.\nOne final note on summarizing your own writing: avoid copying and pasting sentences from the introduction or other parts of your paper into the conclusion. They won’t fit together appropriately because they were taken from a different context, and readers have a knack for spotting duplicated sentences.2. Looking Forward:\nThe other role of the conclusion in a scientific paper is, in fact, to introduce new avenues of potential study or to explain the potential impacts of your conclusions. This is almost an expectation in scientific papers. It should not, however, be seen as an opportunity to develop these avenues in significant detail, and should be clearly linked to the work described in your paper. In the above example, one might conclude with the following statement:\nAs researchers conduct more research into nanoparticles for use in drug delivery systems and bone tissue engineering matures as a field, the potential for finding a cure for osteoporosis increases. Specifically, work on matching growth factors with types of nanoparticle compounds and ways of controlling the release of these factors over time should, in the near future, turn bone tissue engineering from a field of research to an actual treatment method.\nThe final sentence should provide a strong take away statement that allows the audience to remember the main point of the paper – in the above example, the potential for a cure for bone disease and the work that needs to be done to achieve it.\nConclusion: In summary, the two main problems students encounter in writing conclusions are related to the two main functions of that component of a document. In summarizing the paper, the conclusion will exhibit some redundancy: the key is to aim this summary at readers who have read your report. In developing other avenues of study or application, the conclusion may have to introduce new ideas: the key here is to clearly relate these new applications or directions to the content of your report. Back to Components of Documents Next Section"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:a720215b-804a-499c-9b90-f957ffe4e90b>","<urn:uuid:1c066cd6-851a-4b21-a295-fcc99a139f67>"],"error":null}
{"question":"What are the key testing procedures for evaluating both thermal stability and product strength in combination drug-device products? 🤔","answer":"Testing procedures involve both thermal stability evaluation and strength assessment. For thermal stability, pilot plant studies expose the product to maximum anticipated thermal and time conditions in the intended container system, followed by accelerated 40°C stability studies for at least three months to verify specification limits are maintained. Regarding product strength, special analytical methods meeting ICH Q2 standards are required to evaluate how the device affects drug strength. The strength measurement can be challenging when the drug is physically or chemically combined with a device. Both aspects must be tested for every lot, with stability-indicating methods needed to understand degradants in the combination product.","context":["Book chapter – Steam Sterilization: A Practitioner’s Guide (Ch.11)\nactivities associated with conducting cycle development studies necessary for a regulatory filing. The activities associated with developing sterilization technology data for a new or modified drug product require the interaction of several disciplines.\n– How Does One Determine Whether the Product Withstands a Thermal Process That Is Encountered in Moist Heat Sterilization?\nGenerally, pilot plant or bench top laboratory studies are conducted, whereby the formulated product in the intended container/closure system is exposed to maximum anticipated thermal and time conditions. At this point, one would have to speculate on what the maximum conditions of the sterilization process would be. Following thermal exposure per the maximum sterilization cycle conditions, the drug product is tested to ensure that the product remains within the specification limits.\nMore than one set of cycle parameters may be evaluated, such as variable times and temperature conditions, to determine whether a heat sensitive product is compatible with a terminal sterilization process. These evaluations could be classified as initial R&D stability studies. Further, thermally exposed products should be placed on accelerated 40°C stability studies for at least three months. If the product stability data demonstrate that the initial product specification release limits cannot be maintained, a case exists for aseptically processing the product. These data would have to be included in the NDA or European regulatory submission.\nDuring the review process, questions may arise regarding whether extractables from the container/closure system influenced the drug or product data. Therefore, the developmental data must show whether the system will meet\nthe USP biological safety testing if the container/closure system is an elastomeric, plastic, or other polymeric material.\nTasks presented in the chapter :\n– Expectations of Regulatory Agencies Concerning Sterilization of the Solution and Cycle Selection on the Basis of Solution Selection—Development Studies That Need to Be Conducted\n– Defining requirements\n– Selection of a moist heat sterilization process\n– Container thermal mapping: determining the slowest-to-heat zone\n– How much lethality is enough?\n– What Is the Purpose of the D- and z-values?\n– Determining the Minimum Microbial Lethality\n– Determination of the Probability of Survival for Bioburden\n– Determination of the required sterilization process time (in minutes of F0) or cycle definition (load probe controlled cycles)\n-Required Sterilization Process Time\n– Cycle Definition (Product Penetration Controlled Cycles, i.e., controlled by Fo values in solution filled containers)\n– The container/closure system\n– True Fo cannot be calculated at closure sites\n– Regulatory expectations for container/Closure challenge data\n– The master solution – biological challenge\n– How does one select the Master Solution?\n– Special considerations related to the design of the subprocess solution challenge\n– Calculation of the required heat history for processes at temperatures other than 121°C\n– Fractional or half-cycle developement approaches\n– Container closure integrity testing\n– The master solution – heat penetration\n– The Master Equipment Challeng\n– What thermal distribution and penetration data are expected? –\n– Heat Penetration (Thermoprobed Product)\n– Temperature Distribution Studies\n– Time windows\n– Cycle Come-Up Time or Heat-Up Time*\n– Exposure Time\n– Calculation of Cooling Times\n– Loading patterns and configurations drying cycles\n– Sterilization and integrity of filters\n– Cooling water evaluations\nDevelopment of an appropriate sterilization cycle is difficult. The development of an efficacious and yet economic sterilization process is one of the most critical phases of a product development process. This chapter is intended to provide some guidance on the topic. However, each site needs to have an established cycle development program that takes into account the facilities and equipment actually used.[…]\nCourtesy of DHI Publications.","As device organizations continue to evolve in the integration of combination products CGMP’s into their business, a holistic approach can prevent many unnecessary delays. This article provides some insights to consider when integrating stability testing into your device Quality System Requirements (QSR) system. It will discuss a number of quality systems that Stability may significantly impact. Part of the holistic approach should be a discussion that looks out to five years from today and defines where does the organization wants to be with regards to the management, development, manufacturing and compliance of their combination products business. The following six combination product requirements should have good quantitative measures for this five-year plan.\n- Packaging/Labeling codes and the expected order fill rate. If you have five codes that are expected to be delivered to customers on a monthly basis, the delivery challenge will be different than coordinating the manufacture of a 100 codes that will be delivered weekly. The impact of drug release testing and approvals can significantly impact your delivery objectives. Drug testing failure investigations may take longer than expected.\n- Safety & Efficacy\n- The drug and combination product complaint and serious complaint (SAE/MDR) profile should be understood. This information should be incorporated into the risk management models.\n- This must be addressed for every lot. Make sure the drug definitions of lot and batch are well understood, this may affect the number of tests to be conducted and the infrastructure required.\n- How the device affects the strength of the drug may require special analytical methods. These analytical methods should meet ICH Q2 Analytical Methods.\n- Identifying all the impurities and degradants for both device and drug will be important. Also any process that can affect the impurities and/or degradants needs to be well understood and a control strategy implemented.\n- Once the drug and the device are combined the combination product quality characteristics must be defined. There can be effects due to storage, environment, contact time between the device and the drug and use.. A useful exercise is to match the critical-to-quality (CQA) characteristics with relevant product complaints. A control strategy that addresses the CQA’s of both product and process characteristics could be a good source of preventative measures.\nIt is important to identify key functions affected by these requirements (i.e. Stability) and assess the functions ability to meet them consistently. Part of the strategy should ensure that these functions have the ability to consistently meet the combination product requirements.\nFigure 1 is a framework that can be used to help organizations do the following:\n- Think about the affected functions, systems and infrastructures needed to manufacture the combination product\n- Develop a plan to prioritize what will be done and when\n- Include in the plan criteria for sustainable solutions to be implemented and monitored\nIntegrating a new set of CGMP’s (21CFR 820) into an organization that is already operating to a well-established set of QSR’s (21 CFR 820) can be disruptive. Often some basic planning and analysis can make a significant difference in the implementation effectiveness. Before beginning to evaluate the organization’s ability to integrate these new combination product 211 CGMPs into your quality system determine the foundation that would be necessary for each CGMP (21 CFR Part 4) you plan to implement. Once you decide what are the systems, personnel and infrastructure needed, then ensure your organizations relevant core competencies can address these needs. Also assess the maturity and consistency of their performance or at what stage of experience they are operating.\nExclusive VIDEO: How to Gather Clinical Evidence for Combination Products | WATCH NOWA good understanding of how the CGMP’s defined in 21 CFR Part 4 can impact the values of the organization can help you proactively address personnel concerns. Device manufacturers have a good understanding of the safety and efficacy of their products; however, these new CGMP’s may lead you to ask questions you did not previously consider (i.e., questions about the control of degradants, stability indicating methods, reserve samples, control of pyrogen). Employees may see these new requirements as a threat to the effective execution of their functional responsibilities. You may find that maintaining your compliance performance is impacted and some support is needed to get compliance to the level at which you are accustomed to operating.\nThe expectation is that these new CGMP’s will long term impact profits; temporarily there may be an impact. This should be defined and discussed early in the process.\nIn particular you may need to change or add facilities and/or new equipment. As you begin to pull together all of these CP CGMP insights that may impact your values, foundation and functions together, you must be specific what is expected of each function. An important aspect of your plan will be to make sure key stakeholders in impacted functions are on board with the approach. Make sure they agree with the need, the plan, what is acceptable and when this level of performance will be in place.\nMany device organizations have chosen the Streamline approach for their compliance with the combination products CGMPs. Specifically, the streamlined approach provides that a device organization manufacturing combination products may meet the requirements of both the drug CGMPs and device QS regulation by designing and implementing a CGMP operating system that is demonstrated to comply with the following:\n(i) 21 CFR 211.84. Testing and approval or rejection of components, drug product containers, and closures\n(ii) 21 CFR 211.103. Calculation of yield\n(iii) 21 CFR 211.132. Tamper-evident packaging requirements for over-the- counter (OTC) human drug products\n(iv) 21 CFR 211.137. Expiration dating\n(v) 21 CFR 211.165. Testing and release for distribution\n(vi) 21 CFR 211.166. Stability testing\n(vii) 21 CFR 211.167. Special testing requirements\n(viii) 21 CFR 211.170. Reserve samples\nA requirement for 211.137 Expiration dating is to have it determined by appropriate stability testing. For single-entity combination products, you will need to define the applicable standard of drug identity, strength, quality and purity. Most device organizations are well prepared for the quality and identity requirements; however, strength and purity can be difficult. How you measure the strength of the drug when it is physically or chemically combined with a device and how you define the specification can be challenging. Another area that has presented some degree of difficulty is purity, particularly understanding the degradant products of the drug and how the processing affects the degradants of the combination product.\nA helpful FDA technical guidance the device community should understand is “INSPECTIONAL TECHNICAL GUIDANCE; Expiration Dating and Stability Testing for Human Drug Products, 10/18/85 Number: 41. The agency provides guidance on key areas of Expiration Dating and Stability Testing. Some of the areas they cover are:\n- Absence of an Expiration Date will result in regulatory action\n- OTC Drug Exemptions\n- Products Intended for Reconstitution ED and Stability requirements.\n- Impact of no Written Stability Testing Program\n- Supportive Stability Data\n- Number and Size of Batches\n- Three Batch rule and changes\n- Number and Size of Batches\n- Accelerated Studies\n- Appropriate use of accelerated studies are discussed and certain uses of accelerated studies that are discouraged\n- Test Intervals\n- Normal interval – Initial, 3,6,9,12,18,24,36\n- Annual Testing\n- Storage Conditions\n- Room Temp defined as 24-250 C. Products liable to degradation by light or moisture, testing at these conditions needs to be evaluated and addressed.\n- Test Methods\n- Although 211,194 is not called out, review its applicability and confirm your record system meets this requirement, particularly Section 211.194 (a) (2) verification under actual conditions of use.. Also will need to have in place stability indicating methods. This will require a good understanding of the degradants in your combination product.\n- Container-Closure Systems\n- When changing the package or unit the drug is stored in, ways to do satisfactory comparison of container-closure systems\n- Container Sizes to be Tested\n- For more guidance also see ICH Q1D Bracketing and Matrixing Designs for Stability Testing of New Drug Substances and Products Preservatives\n- Guidance for products formulated to contain preservatives to inhibit microbial growth\n- Bulk Drug Substances (Bulk Pharmaceutical Chemicals)\n- Guidance for stability testing program for bulk drug substances\n- Sterility Testing\n- Guidance on container-closure system that has demonstrated ability to maintain sterility throughout the expiration dating period and revalidation when other ingredients are added\nTo help you design a stability program you should consult experts on how to incorporate the applicable sections of the ICH Quality guidances into your program:\n- Start with a commitment to gain a working knowledge of all applicable USP General Notices, Monographs & Chapters.\n- At a minimum, perform a thorough review of the following ICH guidances and identify what sections need to be addressed in your stability, expiry dating and reserve sample practices. Sections that do apply but have not been addressed should be discussed with experts in this area:\n- Q1A – Q1F Stability\n- Q2 Analytical Validation\n- Q3A – Q3D Impurities\n- Q4 – Q4B Pharmacopoeias\n- Q6A- Q6B Specifications\n- As you incorporate these guidances into your organization, an in-depth review of your laboratory practices and the labs’ ability to meet the requirements of 211.194 would also be helpful, particularly if your labs are testing drug products.\n- Review FDA’s “Investigating Out-of-Specification (OOS) Test Results for Pharmaceutical Production” Guidance and confirm your laboratory nonconformance practices would be able to meet the practices identified in this guidance.\n- Pay attention to how you manage stability trends, and evaluate historical data for the batch on stability as well as the overall product. When you find an out-of-trend indication, an investigation must take place.\n- If your combination product requires an NDA/ANDA, and you choose to keep your QSR system as the base Quality System, one of the many CGMP systems you will need to understand is the requirements of Annual Product Review.\n- Note for stability testing that the product must be in its final packaging. If this is not the case the FDA should be consulted. There are instances in which the agency has accepted other practices.\n- Have a good rationale for which product codes are included in the annual stability testing, which is particularly important when there are a large number of product codes."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:d9b3d726-1030-4432-b2a2-2d470e530b29>","<urn:uuid:dd0bfe14-1b8c-45cd-942d-0304e5e0561f>"],"error":null}
{"question":"How does multitasking impact cognitive performance and productivity in daily tasks? Please provide a detailed analysis of its effects on memory, attention, and error rates.","answer":"Multitasking actually reduces cognitive performance and productivity in several ways. What people call multitasking is really task-switching, and the brain has a finite amount of attention to distribute. When switching between tasks, there's a 40% loss in productivity because attention is expended on the act of switching gears. The brain can handle two complicated tasks reasonably well using its two lobes, but adding a third task overwhelms the frontal cortex and increases errors. Furthermore, multitasking can impair short-term memory - even brief interruptions to switch focus can disrupt memory retention, particularly in older adults aged 60-80. It also takes longer to complete tasks when multitasking - finishing two projects sequentially is typically faster than jumping back and forth between them.","context":["We all do it: Texting while walking, sending emails during meetings, chatting on the phone while cooking dinner. In today's society, doing just one thing at a time seems downright luxurious, even wasteful.\nBut chances are, you're not doing yourself (or your boss, or your friends and family) any favors by multitasking your way through the day. Research shows that it's not nearly as efficient as we like to believe, and can even be harmful to our health. Here are 12 reasons why you should stop everything you're doing—well, all but one thing—and rethink the way you work, socialize, and live your life.\n|You're Not Really Multitasking|\nWhat you call multitasking is really task-switching, says Guy Winch, PhD, author of Emotional First Aid: Practical Strategies for Treating Failure, Rejection, Guilt and Other Everyday Psychological Injuries. \"When it comes to attention and productivity, our brains have a finite amount,\" he says.\n\"It's like a pie chart, and whatever we're working on is going to take up the majority of that pie. There's not a lot left over for other things, with the exception of automatic behaviors like walking or chewing gum.\" Moving back and forth between several tasks actually wastes productivity, he says, because your attention is expended on the act of switching gears—plus, you never get fully \"in the zone\" for either activity.\n|It's Slowing You Down|\nContrary to popular belief, multitasking doesn't save time. In fact, it will probably take you longer to finish two projects when you're jumping back and forth than it would to finish each one separately. The same is true even for behaviors as seemingly automatic as driving: In a 2008 University of Utah study, drivers took longer to reach their destinations when they chatted on cell phones.\n\"What tends to save the most time is to do things in batches,\" says Winch. \"Pay your bills all at once, then send your emails all at once. Each task requires a specific mindset, and once you get in a groove you should stay there and finish.\"\n|You're Making Mistakes|\nExperts estimate that switching between tasks can cause a 40 percent loss in productivity. It can also cause you to introduce errors into whatever you're working on, especially if one or more of your activities involves a lot of critical thinking.\nA 2010 French study found that the human brain can handle two complicated tasks without too much trouble, because it has two lobes that can divide responsibility equally between the two. Add a third task, however, and it can overwhelm the frontal cortex and increase the number of mistakes you make.\n|It's Stressing You Out|\nWhen University of California Irvine researchers measured the heart rates of employees with and without constant access to office email, they found that those who received a steady stream of messages stayed in a perpetual \"high alert\" mode with higher heart rates. Those without constant email access did less multitasking and were less stressed because of it.\nAnd it's not only the physical act of multitasking that causes stress; it's the consequences, as well, says Winch. \"If you do poorly on an exam because you studied while watching a baseball game on TV, that can certainly trigger a lot of stress—even self-esteem issues and depression.\"\n|You're Missing Out on Life|\nForget seeing the forest for the trees or the glass half full—people who are busy doing two things at once don't even see obvious things right in front of them, according to a 2009 study from Western Washington University.\nSpecifically, 75 percent of college students who walked across a campus square while talking on their cell phones did not notice a clown riding a unicycle nearby. The researchers call this \"inattentional blindness,\" saying that even though the cell-phone talkers were technically looking at their surroundings, none of it was actually registering in their brains.\n|Your Memory May Suffer|\nIt makes sense that if you try to do two things at once—read a book and watch television, for example—that you're going to miss important details of one or both. But even interrupting one task to suddenly focus on another can be enough to disrupt short term memory, according to a 2011 study.\nWhen University of California San Francisco researchers asked participants to study one scene, but then abruptly switched to a different image, people ages 60 to 80 had a harder time than those in their 20s and 30s disengaging from the second picture and remembering details about the first. As the brain ages, researchers say, it has a harder time getting back on track after even a brief detour.\n|It's Hurting Your Relationships|\n\"This is an area where I think multitasking has a much bigger effect than most people realize,\" says Winch. \"A couple is having a serious talk and the wife says 'Oh, let me just check this message.' Then the husband gets mad, and then he decides to check his messages, and communication just shuts down.\"\nOne recent study from the University of Essex even shows that just having a cell phone nearby during personal conversations—even if neither of you are using it—can cause friction and trust issues. \"Do your relationship a favor and pay your partner some exclusive attention for 10 minutes,\" says Winch. \"It can make a big difference.\"\n|It Can Make You Overeat|\nBeing distracted during mealtime can prevent your brain from fully processing what you've eaten, according to a 2013 review of 24 previous studies. Because of that, you won't feel as full, and may be tempted to keep eating—and to eat again a short time later.\nExperts recommend that even people who eat alone should refrain from turning on the television while eating, and to truly pay attention to their food. Eating lunch at your computer? Slow down and take a break from the screen to focus on each bite.\n|You're Not Actually Good at It|\nYes, you. You may think you're a master multitasker, but, according to a 2013 University of Utah study, that probably means you're actually among the worst.\nThe research focused specifically on cell phone use behind the wheel, and it found that people who scored highest on multitasking tests do not frequently engage in simultaneous driving and cell-phone use—probably because they can better focus on one thing at a time. Those who do talk and drive regularly, however, scored worse on the tests, even though most described themselves as having above average multitasking skills.\n|It's Dampening Your Creativity|\nMultitasking requires a lot of what's known as \"working memory,\" or temporary brain storage, in layman's terms. And when working memory's all used up, it can take away from our ability to think creatively, according to research from the University of Illinois at Chicago.\n\"Too much focus can actually harm performance on creative problem-solving tasks,\" the authors wrote in their 2010 study. With so much already going on in their heads, they suggest, multitaskers often find it harder to daydream and generate spontaneous \"a ha moments.\"\n|You Can't OHIO|\nNo, not the state! Psychiatrists and productivity experts often recommend OHIO: Only Handle It Once. \"This is a rule of thumb for many people with ADHD, but it can also be practiced by anyone who wants to be more organized,\" says Winch. \"It basically means if you take something on, don't stop until you've finished it.\"\nThe problem with multitasking, though, is that it makes Only Handling It Once a near impossibility—instead, you're handling it five or six times, says Winch. \"If you're going to stick to this principle, you need to be disciplined and plan out your day so that when a distraction arises or a brilliant idea occurs to you, you know that there will be time for it later.\"\n|It Can Be Dangerous|\nTexting or talking on a cell phone, even with a hands-free device, is as dangerous as driving drunk—yet that doesn't stop many adults from doing it, even while they have their own children in the car.\nIt's not just driving that puts you at risk for the consequences of multitasking, either. Research also shows that people who use mobile devices while walking are less likely to look before stepping into a crosswalk. And in one study, one in five teenagers who went to the emergency room after being hit by a car admitted they were using a smartphone at the time of the accident."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:f052e194-506e-4a12-9da8-44df620330d7>"],"error":null}
{"question":"How do the base stealing achievements of Rickey Henderson and Ty Cobb compare in terms of total career stolen bases?","answer":"Rickey Henderson achieved significantly more stolen bases in his career with 1,406 steals, while Ty Cobb stole 892 bases during his 27-year Major League career. Henderson became the all-time stolen base leader, surpassing even Lou Brock's 938 steals, and became the first and only player to reach the milestone of 1,000 stolen bases.","context":["~ Base Running, Stealing Third ~ Stealing Bases Excites Everyone And Can Reap Great Rewards For The offense That Is Willing To Play Aggressively! ~\nInside the realm of base running, stealing third base is thought by many to be somewhat easier than stealing second.\nSome Possible Reasons\nBase Running ~ Tips From the Dugout\nThings To Look For:\nIn the age of the aluminum bats, stealing bases sometimes is seen as less important.\nMore coaches have taken to an offensive philosophy of station to station baseball, setting back and counting on the big inning to get their runs.\nAttempting to steal and successfully stealing puts a great deal of pressure on the defense. Pressure ultimately leads to defensive mistakes, which become offensive gains.\nThose 25 opportunities occur with varying frequencies, but one thing is certain; none of them have the opportunity to happen until that base runner is standing on third base.\nThe first part of our offensive philosophy is to get a runner to third base with less than two outs. Stealing third base is one weapon within that philosophy.\n\"Attack, Attack - Always Attack\"( Ty Cobb )\nTy Cobb stole 892 bases in his 27 year, Major League career.\nCobbs' phyilosophy was, \"A defensive play was at least 5 times as difficult to make as an offensive play. The potential was there for an unassisted fielder's error, a bad throw, a misplay from a bad hop of the ball, the shielding of the ball by the runner, and a mix up of responsibility between two infielders or two outfielders. On offense you had fewer ways to fail after putting the ball in play. Therefore: attack, with confidence that the odds are with you. Attack, attack - always attack.\"\nAdditional Topics On This Fun, Yet Overlooked Part Of The GameBase Running\nWhat gravy is to Thanksgiving, the running game is to baseball. Home To First\nA full out sprint towards first base; REMEMBER, HUSTLE NEVER HAS A BAD DAY. First To Second\nLook immediately to the person giving the signs. First To Third\nThe runner needs to think \"Coach ~ Base ~ Coach\", for his reads. Second To Third\nThe base runners first and foremost responsibility is to keep track of the baseball. Third To Home\nFor the base runner, this is the exception in leadoffs, as you lead off in foul territory. Stealing Second\nAs you step out into your lead, all these feelings intensify as you lock in on that one movement the pitcher is about to make, a movement that will send you speeding towards second base. Stealing Third\nIt is often easier to steal third base, than second. Delayed Steal\nHere you are using the element of surprise, a great equalizer. Special Plays\nPlays designed to amp up your running game, catching your opponent off guard while creating pressure on the defense. 25 Ways To Score\nThese 25 ways to score from third base are one reason teams work so hard at getting a runner to third base.\nreturn from baserunning stealing third to theoleballgame.com\n[?] Subscribe To This Site","Twenty years ago, one of baseball’s most impressive career milestones was achieved. It was a milestone that had never been reached before and has never been attained since.\nOn May 1, 1992, world-class base stealer Rickey Henderson led off for the A’s by doubling against Detroit and then immediately stealing third base. That swipe was No. 1,000 for Henderson. Yeah, that’s not bad.\nThis is an incredible achievement. Only three others even topped 850 steals, and two of those played before the lively ball era began. Only Lou Brock has even approached 1,000 steals, and he came fairly well short, with 938.\nHenderson? Not only did he get to 1,000, but he blew past it. He ended his career with 1,406 steals. If he’d had just one more, he’d have exactly 50 percent more than runner-up Lou Brock.\nAs for 1,000 steals itself, in the last 20 years only two guys have even topped the 600 stolen base marker, Kenny Lofton and Otis Nixon. Neither made it to 700, let alone 1,000. Among active players, only Juan Pierre is over 500.\nSome achievements get more attention; 500 homers, 300 wins, 3,000 hits come to mind. But those are far easier to attain than 1,000 steals. Actually, that’s one reason they get more attention. A one-man club like 1,000 steals isn’t much of a club. It’s Henderson’s exclusive domain.\nAnd he first made it to that domain 20 years ago today.\nAside from that, many other events celebrate their anniversary or “day-versary” (which is something happening X-thousand days ago) today. Here they are, with the better ones in bold if you’d prefer to just skim the lists.\n1,000 days since Jason Schmidt appears in his final game.\n4,000 days since Barry Bonds smacks three home runs in one game for the second time in his career.\n5,000 days since the Blue Angels air force planes buzz Wrigley Field during a game. Video of the incident is here.\n5,000 days since Barry Bonds hits his 400th home run. His original goal in baseball was to have 400 homers and 400 steals. Now he’s achieved it, and no one cares. He’ll decide to focus on homers from now on.\n5,000 days since Felipe Alou manages his 1,000th game. His record: 521-479.\n8,000 days since Cecil Fielder hits three homers in one game for the second time in his career.\n8,000 days since the Yankees fire manager Bucky Dent.\n9,000 days since Jose Mesa makes his big league debut.\n15,000 days since longtime shortstop Chris Speier plays in his first baseball game.\n20,000 days since Tommy Thevenow, one of the least powerful batters of all-time, dies.\nAlso, at some point today it will be 1,000,000,000 seconds since Charles Finley sells the A’s to Walter and Wally Haas, and Roy Eisenhardt for $12.7 million.\n1878 Way back in the day, May 1 was Opening Day, so a ton of 19th-century players make their big league debut on May 1. In 1878, the following stars debuted: Hall of Famer King Kelly, third baseman Ned Williamson (who will swat 27 homers in a single season in 1884), Charlie Bennett (the best catcher of the 1880s), and slugger Abner Dalrymple.\n1880 King Kelly hits the first home run ever on Opening Day.\n1880 Several more stars make their debut: Roger Connor, who will be the all-time home run king prior to Babe Ruth; Mickey Welch, a 300-game winner; Larry Corcoran, a star pitcher; Fred Dunlap, maybe the best second baseman of the 1880s, Ned Hanlon, a good player who becomes a Hall of Fame manager, and Tom Burns, a solid infielder.\n1882 Fred Pfeffer, infielder, makes his debut.\n1883 The New York Giants play their first ever game. They beat Boston, 7-5. Also debuting, the Philadelphia Phillies play their first game. They lose 4-3 to Providence.\n1884 Gus Schmelz, one of the game’s great innovators, manages his first game. He’ll be at the cutting edge of creating spring training, some coaching drills, and developing the sacrifice bunt.\n1884 Several more players make their big league debut: Pitcher Ed Morris, the all-time complete game king; Adonis Terry, a long-lasting pitcher; Curt Welch, the best defensive outfielder of his day; and Charlie Ferguson, a great pitcher who will die young.\n1886 The NL plays its first game under “sudden death” rules in the ninth. It used to be that both teams batted in the ninth, no matter the score. Now a team won’t bat in the bottom half if they already have won the game. In the first such game, Chicago tops Cincinnati, 4-3.\n1886 Al Atkinson tosses his second no-hitter, and wins 3-2.\n1891 300-game winner John Clarkson surrenders an inside-the-park grand slam to Oyster Burns.\n1901 Chicago White Sox Herm McFarland hits the first grand slam in AL history as Chicago tops Detroit, 19-9. The Tigers commit an even 12 errors in that loss, the AL record.\n1906 The Red Sox release Hall of Famer Jesse Burkett.\n1906 Phillies pitcher Johnny Lush tosses a no-hitter, beating the Dodgers, 6-0. He fans 11 in the process.\n1912 University of Michigan freshman George Sisler fans 20 in seven innings.\n1920 Babe Ruth hits his first home run as a Yankee. It’s career long ball No. 50.\n1924 Hall of Fame centerfielder Max Carey gets hit No. 2,000.\n1924 White Sox base runner Bill Barrett steals home twice in one game versus Cleveland.\n1925 17-year-old Jimmie Foxx makes his big league debut as a catcher for the A’s.\n1926 19-year-old Satchel Paige debuts in the Negro Southern League, leading Chattanooga to a 5-4 win over Birmingham.\n1928 Babe Ruth legs out his 100th career triple.\n1929 Jimmie Foxx enjoys the first of 55 multi-home run games. In that same game, his teammate Al Simmons enjoys the first of eight career five-hit games.\n1930 After playing 1,103 consecutive games, Hall of Fame infielder Joe Sewell misses a contest. He’s only the third man to top 1,000 consecutive games played.\n1933 Pittsburgh shortstop Arky Vaughan hits the first of two career inside-the-park grand slams.\n1934 Burleigh Grimes, the last legal spitball pitcher, wins his 270th and final game.\n1936 Dizzy Dean posts his 100th career victory. He’s 100-53 in his career at this point. He also ties his career high Game Score: 87. His line: 9 IP, 3 H, 0 R, 0 ER, 1 BB, and 7 K.\n1936 The White Sox claim outfielder Dixie Walker off waivers from the Yankees.\n1939 Monty Stratton, a pitcher who lost a leg in an off-season fielding accident, plays in an exhibition game.\n1940 For the only time in his 457 career starts, Lefty Grove allow a leadoff home run.\n1941 It’s the first night game at Griffith Stadium. The Yankees spoil Washington’s big night by winning, 6-5.\n1942 Stan Musial has the first of 37 career games with more than one home run.\n1943 Rubber-armed Bobo Newsom has one of his five career one-hitters. He never does get that no-hitter. Babe Barna gets the sole safety against him. Barna will end the year with 42 hits and a .187 batting average.\n1944 Washington’s George Myatt gets six hits in one game. It’s the first time in franchise history anyone has done that.\n1946 Brooklyn release veteran pitcher Curt Davis. He arguably has the best career by any pitcher who debuted after his 30th birthday.\n1946 Before today’s Cubs-Dodgers game, Chicago’s Len Merullo and Brooklyn’s Dixie Walker have a big fight on the field. The players form a circle so no one can break up the fight.\n1948 The White Sox lose to put their all-time franchise record at .500. They’ll stay under it for the next eight years: 3,547-3,547.\n1949 Ted Williams smashes the ninth of his career 17 grand slams.\n1949 Elmer Valo of the A’s become the first AL player to hit two bases-loaded triples in one game.\n1949 Bobby Shantz makes his big league debut.\n1952 Bob Lemon has the longest outing of his career: 12.1 innings. He loses as Washington tops the Indians, 2-1.\n1955 Bob Feller has his 12th and final career one-hitter. It’s an odd one for him, as there are only two strikeouts and one walk. Sammy West of the Red Sox gets a seventh-inning single.\n1959 Early Wynn has maybe the most dominant game of his career. He tosses a one-hitter, and the hit came with one out in the first inning by Pete Runnels. Wynn fans 14 and walks seven. Oh, and Wynn also belts a home run. Chicago wins 1-0. Yeah, he was pretty damn dominant in that one.\n1959 Dick Stuart hits a nearly 500-foot home run for the Pirates.\n1960 It begins! For the first time, the exploding scoreboard at Comiskey Park goes off. Al Smith hits a homer to launch it for the first time.\n1965 Tommy Davis breaks his ankle sliding into second base for the Dodgers.\n1967 Jimmy Piersall plays in his final career game.\n1968 For only the second time ever, a pitcher is ejected for throwing the spitball. This one is especially interesting, because it isn’t during the game. John Boozer of the Phillies is tossing spitters while warming up against the Mets in Shea Stadium when umpire Ed Vargo rings him up.\n1968 It’s one of the greatest pitchers’ duels of the year as Oakland’s Blue Moon Odom and Cleveland’s Sam McDowell square off. Odom retires the first 15 batters he faces but loses 3-0 to McDowell, who fans 16 batters.\n1969 Hall of Fame skipper Al Lopez manages his last game.\n1969 Houston’s Don Wilson no-hits the Reds. The day before, Cincinnati’s Jim Maloney had no-hit the Astros. Just nine days ago, Wilson faced the Reds and got killed, 14-0. Today, he fans 15 in a 4-0 win.\n1971 For the first time in nine years, an American League game begins with back-to-back homers. Incredibly, the same pitcher who surrendered them in 1962 is on the mound here again, Jim Perry. Boston’s Luis Aparicio and Reggie Smith go deep against the Minnesota star pitcher.\n1973 The Giants beat the Pirates, 8-7, thanks to one of the most incredible comebacks in baseball history. San Francisco scores seven runs in the bottom of the ninth to win the game. The final runs come on a three-run, walk-off double by Bobby Bonds.\n1973 Jim Colborn becomes the last Expos hurler to toss nine innings in relief.\n1974 Pittsburgh pitcher Dock Ellis is looking to send a message to shake things up against the Reds. Boy, does he ever want to send a message. He beans the first three batters of the game and then walks the fourth guy on four would-be bean balls. After two more attempts, he’s yanked from the game.\n1974 Tom Seaver has his all-time highest Game Score of 106. His line: 12 IP, 3 H, 1 R, 1 ER, 2 BB, 16 Ks. As an added bonus, he does it against the Dodgers, who begin the day with a record of 17-6 and will win 102 games all year. Aside from a Steve Garvey homer in the fifth, Seaver doesn’t allow anyone to make it past first base against him until the 12th inning. Alas, Seaver gets a no-decision as the Mets lose in 14 innings, 2-1.\n1975 Hank Aaron breaks Babe Ruth’s RBI record, as he ends the day with 2,211 RBIs to Ruth’s 2,209. Next year, the Records Committee will revise Ruth’s RBI total to 2,204, so officially the record was set on April 18, but no one knew that on May 1, 1975.\n1977 Tony Perez, who steals only 49 bases in 2,777 career games, has two swipes in today’s contest. He’s nearly 35 years old, too.\n1977 According to WPA, this is Carlton Fisk’s best game: 0.790 WPA. He’s 3-for-4 with two homers and five RBIs in a 6-4 Red Sox win over the A’s.\n1978 Jim Bouton begins his unlikely comeback pitching with the Savannah Braves of the Southern League.\n1979 Phil Niekro wins his 200th game. He’s 200-175. Though he’s already 40 years old, he’ll still win 100-plus more games.\n1979 Frank Taveras of the Mets fan five times in one game.\n1979 Roger Freed hits a walk-off grand slam for the Cardinals against Houston. Even by walk-off grand slam standards, it’s unusually dramatic. It’s in the bottom of the 11th with St. Louis trialing, 6-3.\n1980 Bill Madlock receives a 15-game suspension and $5,000 fine for hitting umpire Jerry Crawford in the face with a glove in a recent game.\n1981 Tim Raines hits his first home run, a walk-off shot in the bottom of the 13th inning. He’ll never homer that late in a game again, have just one more walk-off homer in his career.\n1983 Robin Yount hits his 100th home run.\n1985 Jimmy Key becomes the first southpaw starting pitcher to win a game for the Blue Jays in 614 contests.\n1985 Pitcher (and pretty good hockey player) Kirk McCaskill makes his big league debut.\n1987 Tim Raines finally signs with the Montreal Expos. He tried to sign with another team in the offseason free agent market, but collusion slammed the door in his face, so he missed the first month of the year. For that matter, Bob Boone, Ron Guidry, and Bill Campbell all also sign for the first time on this day.\n1988 Andre Dawson hits the last sacrifice hit of his career. It’s the only one he’ll ever have with the Cubs.\n1991 The Brewers and White Sox have a 19-inning contest. It’s the longest AL game in seven years since the same two teams went a league-record 25 innings. Milwaukee wins today’s game, 10-9. Paul Molitor receives three intentional walks along the way.\n1991 Nolan Ryan tosses his seventh career no-hitter. He walks two and fans 16 along the way for a Game Score of 101.\n1991 He is the greatest. Rickey Henderson steals his 939th career base, passing Lou Brock for No. 1 on the list.\n1992 The Dodgers decide to postpone their three-game home series against the Expos due to rioting going on after the jury in the Rodney King beating trial acquits the police.\n1992 Randy Johnson walks 10 batters, his personal most. Since then, five other pitchers have walked 10 in a game, and none have walked more than that in one outing.\n1995 MLB and the umpires reach an agreement, ending the ongoing lockout of the arbitrators. They’ll be back on the field on May 3.\n1996 Gerald Williams of the Yankees gets six hits in a 15-inning contest.\n1998 The Orioles release veteran infielder Ozzie Guillen.\n2000 For the first time, a home run ball lands in McCovey’s Cove in San Francisco. Naturally, Barry Bonds blasts it there.\n2000 Texas purchases the ancient Ruben Sierra from the Mexican League’s Cancun team.\n2000 Todd Helton hits three homers in one game.\n2001 Ramon Martinez appears in his last game.\n2001 Jeff Kent enjoys perhaps the best game of his career. He’s 3-for-4 with a double, homer, walk, and seven RBIs as the Giants top the Pirates, 11-6.\n2002 Rafael Palmeiro bops his 500th career double.\n2003 Baltimore’s B.J. Ryan records a win despite not throwing a single pitch. He enters the game and picks off Omar Infante in the bottom of the seventh to end the frame. The Orioles rally to take the lead in the eighth, and the squad pulls Ryan for a new hurler in the eighth. Baltimore wins, 5-4 over Detroit.\n2004 Barry Bonds gets four intentional walks in a nine-inning game, setting a record for a nine-inning contest. (Andre Dawson had five IBB in a 16-inning game in 1990).\n2004 Frank Catalanotto of the Blue Jays gets six hits in one game, a first in franchise history.\n2005 It’s the end of Johan Santana’s 17-game winning streak as the Angels top Santana and the Twins, 2-1. He allows just two hits in eight innings, but those hits are a pair of solo homers by Vladimir Guerrero and Jose Molina.\n2006 Joel Pineiro becomes the first hurler in a dozen years to pitch nine innings and neither walk nor fan any batters.\n2010 The Mets’ Mike Pelfrey has a scoreless-inning streak end at 27 as the Phillies clobber New York, 10-0. For the Phillies, today is Roy Halladay’s second complete-game shutout in his last three starts."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:510c9399-cf7a-4082-a686-7df6c9843396>","<urn:uuid:f9ac924b-7bf8-4564-9fed-635e373efb88>"],"error":null}
{"question":"Was King Leopold II of Hungary on the throne during the Thirty Years' War, sí o no?","answer":"No. During the Thirty Years' War (1618-1648), Ferdinand II was Holy Roman Emperor and King of Hungary (1618-1625), followed by Ferdinand III. Leopold II became King of Hungary much later, from 1790 to 1792, as part of the Habsburg-Lorraine Dynasty.","context":["Kingdom of Hungary\nKing of Hungary\nÁrpád Dynasty (1000-1301)\n- Saint Stephen I (I. István) (967-1038),Grand Prince of the Hungarians (997–1000) and the first King of Hungary (1000–1038).\n- Andrew III the Venetian (III. András/Endre) (c. 1265-1301),King of Hungary (1290-1301) and Croatia. The last of the Árpád dynasty.\nArms of Árpád dynasty\nArms of Hungary Modern\nKings of different houses (1301-1526)\n- Wenceslaus III Premyslid, (Vencel ), (1289-1306), King of Hungary (1301-1305), King of Bohemia (1305-1306) and King of Poland (1305-1306) .\n- Otto III of , (Béla V ) ( 1261-1312), Duke of Lower Bavaria from 1290 to 1312 and King of Hungary between 1305 and 1307.\n- Charles Iof Anjou, (Károly Róbert) (1288-1342), King of Hungary from 1308 to 1342.\n- Louis the Great, (Nagy Lajos) (1326-1382), King of Hungary, K ing of Croatia from 1342, King of Sicily from 1348, King of Jerusalem from 1348 (By Papal appointment), and King of Poland from 1370.\n- Mary, (I. Mária) (1371-1395), Queen regnant of Hungary from 1382 to 1385 and from 1386 to 1395.\n- Charles the Short or Charles of Durazzo, (Kis Károly) (1345-1386), King of Naples and titular King of Jerusalem from 1382 to 1386 as Charles III, and King of Hungary from 1385 to 1386 as Charles II.\n- Sigismund, (Zsigmond) (1368-1437),Holy Roman Emperor from 1433 until 1437, and the last Emperor of the House of Luxemburg. King of Hungary from 1387 to 1437. King of Bohemia from 1419, of Lombardia from 1431, and of Germany from 1411.\n- Albert II of Habsburg, (1397-1439),King of Germany from 1438. King of Bohemia, King of Hungary, as Albrecht, Duke of Luxembourg and, as Albert V, Archduke of Austria from 1404.\n- Vladislaus III of Varna,( Ulászló I) (1424-1444), King of Poland from 1434, and King of Hungary from 1440. (disputed)\n- Ladislas V,( V. László (Utószülött) (Ladislaus the Posthumous) ( 1440-1457), King of Bohemia from 1453 and King of Hungary and Croatia as Ladislaus IV.\n- Matthias Corvinus, (Hunyadi Mátyás) (1443-1490), King of Hungary and also King of Bohemia.\n- Vladislas II, also known as Ladislaus Jagiellon (II. Ulászló) ( 1456- 1516), King of Bohemia from 1471 and King of Hungary from 1490. Knight of the Order of the Dragon.\n- Louis II,(II. Lajos) ( 1506-1526), King of Hungary and King of Bohemia from 1516 to 1526. Knight of the Golden Fleece.\n- János Szapolyai(Szapolyai János) (1487-1540), V oivode of . King of Hungary from 1526 to 1540. His rule was disputed by Archduke Ferdinand I, who also claimed the title King of Hungary between 1526 and 1540.\nHabsburg Dynasty (1526-1780)\n- Ferdinand I,(I.Ferdinánd) (1503-1564), Holy Roman Emperor from 1558, King of Bohemia and Hungary from 1526.\n- Maximilian II(I. Miksa) ( 1527-1576), King of Bohemia from 1562, King of Hungary from 1563, Holy Roman Emperor from 1564\n- Rudolf II (1552-1612), Holy Roman Emperor as Rudolf II (1576-1612), King of Hungary as Rudolf (1572-1608), King of Bohemia as Rudolf II (1575-1608/1611) and Archduke of Austria as Rudolf V (1576-1608).\n- Matthias(II. Mátyás) (1557-1619), Holy Roman Emperor (1612-1619), King of Hungary (1608-1619) (as Matthias II), King of Bohemia (1611-1619).\n- Ferdinand II(II. Ferdinánd) (1578-1637), Holy Roman Emperor (1619-1637), King of Bohemia (1617-1619, 1620-1637), King of Hungary (1618-1625).\n- Ferdinand III (III. Ferdinánd), (1608-1657), Holy Roman Emperor (1637 – 1657). King of Hungary, King of Bohemia, Archduke of Austria, .\n- Ferdinand IV(IV. Ferdinánd) ( 1633- 1654), King of the Romans (1653-1654), King of Hungary (1647-1654), and King of Bohemia (1646-1654).\n- Leopold I(I. Lipót), (1640-1705), Holy Roman emperor, King of Hungary, King of Bohemia (1657-1705).\n- Joseph I (I. József), (1678-1711), Holy Roman Emperor, King of Bohemia, King of Hungary.\n- Charles III (III. Károly),(1685-1740), Holy Roman Emperor, King of Bohemia, King of Hungary.\n- Maria II Theresa (II. Mária Terézia),(1717-1780), Queen of Hungary, Croatia, Bohemia, Lodomeria and Galicia. Founded the Order of Saint Stephen of Hungary in 1764.\nAlso see House of Habsburg for further arms.\nHabsburg-Lorraine Dynasty (1780-1918)\n- Joseph II, (II. József)(1741-1790), Holy Roman Emperor from 1765 and King of Bohemia, King of Hungary from 1780.\n- Leopold II, (II. Lipót) (1747-1792), Holy Roman Emperor, King of Bohemia, King of Hungary from 1790.\n- Francis II, (I. Ferenc) (1768-1835), the last Holy Roman Emperor from 1792 to 1806 and the first Emperor of Austria from 1804 to 1835.\n- Ferdinand I, (V. Ferdinánd) (1793-1875), Emperor of Austria, King of Hungary from 1835 to 1848.\n- Franz Joseph I, (I. Ferenc József) (1830-1916), Emperor of Austria and King of Bohemia from 1848 to 1916 and King of Hungary from 1867 to 1916.\n- Charles I,(IV. Károly) ( 1887- 1922), The last Emperor of Austria, the last King of Hungary.\nSee House of Habsburg-Lorraine for personal arms.\nKingdom of Hungary after 1867\nKingdom of Hungary after 1900\nKingdom of Hungary 1900 to 1918","Holy Roman Emperor Ferdinand II - 1619-1637\nFerdinand II (9 July 1578 – 15 February 1637), a member of the House of Habsburg, was Holy Roman Emperor (1619–1637), King of Bohemia (1617–1619, 1620–1637), and King of Hungary (1618–1625). His rule coincided with the Thirty Years' War. Ferdinand's aim, as a zealous Catholic, was to restore Catholicism as the only religion in the Empire and suppress Protestantism.\nHe was born at Graz, the son of Charles II, Archduke of Austria, and Maria Anna of Bavaria. He was educated by the Jesuits and later attended the University of Ingolstadt. After completing his studies in 1595, he acceded to his hereditary lands (where his older cousin, Archduke Maximilian III of Austria, had acted as regent between 1593 and 1595) and made a pilgrimage to Loreto and Rome. Shortly afterwards, he began the suppression of Protestantism in his territories.\nWith the Oñate treaty, Ferdinand obtained the support of the Spanish Habsburgs in the succession of his childless cousin Matthias, in exchange for concessions in Alsace and Italy. In 1617, he was elected King of Bohemia by the Bohemian diet, in 1618, King of Hungary by the Hungarian estates, and in 1619, Holy Roman Emperor.\nHis devout Catholicism and negative regard of Protestantism caused immediate turmoil in his non-Catholic subjects, especially in Bohemia. He did not wish to uphold the religious liberties granted by the Letter of Majesty conceded, signed by the previous emperor, Rudolph II, which had guaranteed the freedom of religion to the nobles and the inhabitants of the cities. Additionally, Ferdinand was an absolutist monarch and infringed several historical privileges of the nobles. Given the relatively great number of Protestants in the kingdom, including some of the nobles, the king's unpopularity soon caused the Bohemian Revolt. The Second Defenestration of Prague of 22 May 1618 is considered the first step of the Thirty Years' War.\nIn the following events he remained one of the staunchest backers of the Anti-Protestant Counter Reformation efforts as one of the heads of the German Catholic League. Ferdinand succeeded Matthias as Holy Roman Emperor in 1619. Supported by the Catholic League and the Kings of Spain and the Polish-Lithuanian Commonwealth, Ferdinand decided to reclaim his possession in Bohemia and to quench the rebels. On 8 November 1620 his troops, led by the Flemish general Johann Tserclaes, Count of Tilly, smashed the rebels of Frederick V, who had been elected as rival King in 1619. After Frederick's flight to the Netherlands, Ferdinand ordered a massive effort to bring about re-conversion to Catholicism in Bohemia and Austria, causing Protestantism there to nearly disappear in the following decades, and reduced the Diet's power.\nIn 1625, despite the subsidies received from Spain and the Pope, Ferdinand was in a bad financial situation. In order to muster an imperial army to continue the war, he applied to Albrecht von Wallenstein, one of the richest men in Bohemia: the latter accepted on condition that he could keep total control over the direction of the war, as well as over the booties taken during the operations. Wallenstein was able to recruit some 30,000 men (later expanded up to 100,000), with whom he was able to defeat the Protestants in Silesia, Anhalt and Denmark. In the wake of these Catholic military successes, in 1629 Ferdinand issued the Edict of Restitution, by which all the lands stripped from Catholics after the Peace of Passau of 1552 would be returned.\nHis military success caused the tottering Protestants to call in Gustavus II Adolphus, King of Sweden. Soon, some of Ferdinand's allies began to complain about the excessive power exercised by Wallenstein, as well as the ruthless methods he used to finance his vast army. Ferdinand replied by firing the Bohemian general in 1630. The leadership of the war thenceforth passed to Tilly, who was however unable to stop the Swedish march from northern Germany towards Austria. Some historians directly blame Ferdinand for the large civilian loss of life in the Sack of Magdeburg in 1631: he had instructed Tilly to enforce the edict of Restitution upon the Electorate of Saxony, his orders causing the Belgian general to move the Catholic armies east, ultimately to Leipzig, where they suffered their first substantial defeat at the hands of the Adolphus' Swedes in the First Battle of Breitenfeld (1631).\nTilly died in battle in 1632. Wallenstein was recalled, being able to muster an army in only a week, and expelled the Swedes from Bohemia. However, in November 1632 the Catholics were defeated in the Battle of Lützen (1632), where Gustavus Adolphus was himself killed. A period of minor operations followed, perhaps because of Wallenstein's ambiguous conduct, which ended with his assassination in 1634.\nDespite Wallenstein's fall, the imperial forces recaptured Regensburg and were victorious in the Battle of Nördlingen (1634). The Swedish army was substantially weakened, and the fear that the Habsburg's power would become overwhelming caused France, led by Louis XIII of France and Cardinal Richelieu, to enter the war on the Protestant side. (Louis's father Henry IV of France had once been a Huguenot leader.) In 1635 Ferdinand signed his last important act, the Peace of Prague (1635), yet this did not end the war.\nFerdinand died in 1637, leaving to his son Ferdinand III, Holy Roman Emperor, an empire still engulfed in a war and whose fortunes seemed to be increasingly chaotic. Ferdinand II was buried in his Mausoleum in Graz. His heart was interred in the Herzgruft (heart crypt) of the Augustinian Church, Vienna.\nMarriages and issue\nIn 1600, Ferdinand married Maria Anna of Bavaria (1574-1616), daughter of Duke William V of Bavaria. They had seven children:\nArchduchess Christine (25 May 1601 – 12/21 June 1601)\nArchduke Charles (25 May 1603)\nArchduke John-Charles (1 November 1605 – 26 December 1619)\nFerdinand III (13 July 1608 – 2 April 1657) married:1631 Infanta Maria Anna of Spain\n1648 Maria Leopoldine of Austria\n1651 Eleanor Gonzaga (1630–1686)\nArchduchess Maria Anna of Austria (13 January 1610 – 25 September 1665)\nArchduchess Cecilia Renata of Austria (16 July 1611 – 24 March 1644), who married her cousin W?adys?aw IV Vasa, King of Poland.\nArchduke Leopold Wilhelm of Austria (1614–1662).\nIn 1622, he married Eleonore of Mantua (Gonzaga) (1598–1655), the daughter of Duke Vincenzo I of Mantua and Eleonora de' Medici, at Innsbruck.\nHoly Roman Emperor Ferdinand II - 1619-1637\nTitles of Ferdinand II\nFerdinand II, by the grace of God elected Holy Roman Emperor, forever August, King in Germany, King of Hungary, Bohemia, Dalmatia, Croatia, Slavonia, Rama, Serbia, Galicia, Lodomeria, Cumania, Bulgaria, Archduke of Austria, Duke of Burgundy, Brabant, Styria, Carinthia, Carniola, Margrave of Moravia, Duke of Luxemburg, of the Higher and Lower Silesia, of Württemberg and Teck, Prince of Swabia, Count of Habsburg, Tyrol, Kyburg and Goritia, Marquess of the Holy Roman Empire, Burgovia, the Higher and Lower Lusace, Lord of the Marquisate of Slavonia, of Port Naon and Salines, etc. etc."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:86101127-64f4-46dd-9fc7-ae0fe63a371a>","<urn:uuid:c15214de-2551-4b4f-a757-c0557f2706de>"],"error":null}
{"question":"What specific interaction occurs between Yb3+ and Er3+ ions in phosphate glass that enhances its laser performance?","answer":"The interaction between Yb3+ and Er3+ ions occurs when they are excited at 2F5/2 and 4I11/2 levels respectively, resulting in fast nonradiative multiphonon relaxation from 4I11/2 to 4I13/2. This dramatically reduces reverse energy transfer and conversion losses, improving the laser's performance.","context":["Erbium Glass (Er,Yb:Glass)\nEr,Yb:Glass/Er, Yb, Cr: Glass product, also known as erbium glass (er glass), is a kind of laser glass with good comprehensive performance.\nEr3+, Yb3+ co-doped phosphate glass (Er, Yb: phosphate glass) is a well-known and commonly used active medium. It emits laser microns in the “eye safe” spectral range of 1.5 – 1.6um.\n1540 nm laser is just located at the position of human eye safety and optical fiber communication window. So it leads to laser generation and signal amplification.\n1540 nm laser has been widely used in range finder, radar, target recognition, and other fields.\nPhosphate glass combines the long-lived (~8 ms) laser level on 4I13/2 Er3+ with the low-lived (2-3 ms) 2F5/2 excited state of 4I11/2 Er3+ level resonant with Yb3+.\nThe fast nonradiative multiphonon relaxation from 4I11/2 to 4I13/2 is due to the interaction between Yb3+ and Er3+ ions excited at 2F5/2 and 4I11/2 levels, respectively. That dramatically reduces the reverse energy transfer and conversion losses.\nEr3+/Yb3+ co-doped phosphate glass is an LD pumped 1540 nm eye-safe radiation source. It can emit eye safe 1540 nm laser radiation directly used in laser rangefinders and telecommunications.\nEr, Yb glass laser with 1540 nm wavelength radiation output does not need to add additional components.\nEr3+/Yb3+ co-doped phosphate glass laser is an eye-safe wavelength laser. It has attracted much attention because of its compactness and low cost.\nEat14: Yb3+, Er3+ co-doped phosphate glass, suitable for high repetition rate (1-6Hz) laser diode pumped 1535 nm. High Yb3+ doping can be achieved in this Eat14 glass.\nThe Features of Er Glass:\n- Eye safety\n- High optical quality\n- Long fluorescent life\n- The absorption band is wide\n- The slope of high efficiency\n|The cross section of stimulated emission（10-20cm2）||0.8||0.75|\n|Fluorescence lifetime (milliseconds) *||7.7-8.0||7.7-8.2|\n|Central laser wavelength（nm）||1535||1535|\n|Refractive Index（d 589.3nm）||1.532||1.536|\n|dn / dT（10-6 /℃）（20〜100℃）||-1.72||-3|\n|Transition Temperature (℃)||556||530|\n|Softening Temperature (℃)||605||573|\n|Linear Coefficient of Thermal Expansion (10-7/K) (20〜100℃)||87||82|\n|Linear Coefficient of Thermal Expansion (10-7/K) (100〜300℃)||95||96|\n|Thermal Coefficient of Optical Path Length (10-6/K) (20〜100℃)||2.9||1.4|\n|Thermal Conductivity (25℃) (W/mK)||0.7||0.7|\n|Density g / cm3||3.06||2.83|\n|Chemical Durability (weight loss in 100℃ distilled water)（μg/ hr.cm2）||52||82|\n|Orientation Tolerance||< 0.5°|\n|Thickness/Diameter Tolerance||±0.05 mm|\n|Surface Flatness||<λ/8@632 nm|\n|Wavefront Distortion||<λ/4@632 nm|\n|Biggest Size||dia (3-12.7)×（3-150）mm2|\nAbsorption and Emission Spectra\n| B Y Z A , A M L , A J L , et al. Optical properties of Er 3+ /Yb 3+ co-doped phosphate glass system for NIR lasers and fiber amplifiers[J]. Ceramics International, 2018, 44( 18):22467-22472.|\n| Langar A , Bouzidi C , Elhouichet H , et al. Er–Yb codoped phosphate glasses with improved gain characteristics for an efficient 1.55μm broadband optical amplifiers[J]. Journal of Luminescence, 2014, 148:249-255.|\n| A C B , A T M , B S R D , et al. Sensitizing effect of Yb 3+ ions on photoluminescence properties of Er 3+ ions in lead phosphate glasses: Optical fiber amplifiers[J]. Optical Materials, 2018, 86:256-269.|\n| Ryabtsev G I , Bezyazychnaya T V , Parastchuk V V , et al. Spectral and temporal properties of diode-pumped Er, Yb: glass laser[J]. Optics Communications, 2005, 252(4-6):301-306.|\n| Francini R , Giovenale F , Grassano U M , et al. Spectroscopy of Er and Er–Yb-doped phosphate glasses[J]. Optical Materials, 2000, 13(4):417-425.|\n| Sendova M , JA Jiménez, Honaman C . Rare earth-dependent trend of the glass transition activation energy of doped phosphate glasses: Calorimetric analysis[J]. Journal of Non-Crystalline Solids, 2016, 450:18-22.|\n| Chen C , He R , Tan Y , et al. Optical ridge waveguides in Er3+/Yb3+ co-doped phosphate glass produced by ion irradiation combined with femtosecond laser ablation for guided-wave green and red upconversion emissions[J]. Optical Materials, 2016.|\n| Balaji S , D Ghosh, Biswas K , et al. Insights into Er 3+ Yb 3+ energy transfer dynamics upon infrared ~1550nm excitation in a low phonon fluoro-tellurite glass system[J]. Journal of Luminescence, 2017, 187:441-448.|\n| Feng S , Fei L , Li S , et al. The fractional thermal factor in LD-pumped Yb3+/Er3+ codoped phosphate glass. IEEE, 2009.|\n| Dan G , Mihailov S J , Walker R B , et al. Bragg Gratings Made With a Femtosecond Laser in Heavily Doped Er–Yb Phosphate Glass Fiber[J]. IEEE Photonics Technology Letters, 2007, 19(12):943-945.|\n| Zhu M , Tongzhao G U . Spectroscopic properties of Er3+/Yb3+ co-doped tantalum-niobium phosphate glasses for optical waveguide laser and amplifier[C]// International Conference on Microwave & Millimeter Wave Technology. IEEE Xplore, 2004.|\n| Danger T , Huber G , DeNker B I , et al. Diode-pumped cw laser around 1.54 m using Yb, Er-doped silico-boro-phosphate glass[C]// Conference on Lasers & Electro-optics. IEEE, 1998.|\n| S Jiang, SJ Hamlin, JD Myers,等. High-average-power 1.54-μm Er3+:Yb3+-doped phosphate glass laser. 1996.|\n| Osellame R , Valle G D , Chiodo N , et al. Mode-locked and single-longitudinal-mode waveguide lasers fabricated by femtosecond laser pulses in Er:Yb-doped phosphate glass. IEEE, 2007.|\n| Valles J A , Rebolledo M A , J Cortés. Full characterization of packaged Er-Yb-codoped phosphate glass waveguides[J]. IEEE Journal of Quantum Electronics, 2006, 42(2):152-159.|\n| Aseev V A , Ulyashenko A M , Nikonorov N V , et al. Comparison of highly doped Ytterbium-erbium phosphate and silicate glasses for microchip lasers[C]// International Conference on Advanced Optoelectronics & Lasers. IEEE, 2005.|\n| Qiu T , Li L , Temyanko V , et al. Generation of high power 1535nm light from a short cavity cladding pumped Er:Yb phosphate fiber laser[M]. 2004.|\n| Buchenkov V A , Krylov A A , Mak A A . 12 mJ 10 Hz Diode Pumped A/O Q-switched Yb:Er:Glass Laser[C]// 2018:48-48.|\n| Kalashnikov V L , Shcherbitsky V G , Kuleshov N V , et al. Optimization of passively Q-switched Er:glass laser[C]// Lasers and Electro-Optics, 2002. CLEO ’02. Technical Digest. Summaries of Papers Presented at the. IEEE, 2002.|\n| Simondi-Teisseire B , Viana B , Lejus A M , et al. Room-temperature CW laser operation at ~1.55 μm (eye-safe range) of Yb:Er and Yb:Er:Ce:Ca2Al2SiO7 crystals[J]. IEEE Journal of Quantum Electronics, 1996, 32(11):2004-2009.|\n| Wu R , Hamlin S J , Myers J D , et al. Infrared image studies of diode-pumped Yb3+, Er3+:glass[C]// Conference on Lasers and Electro-Optics. 1996.|\n| Tan F , Yu F , Wang L , et al. Enhancement in Laser Performance of Er3+/Yb3+ Co-doped Phosphate Glass Materials[J]. Journal of Wuhan University of Technology-Mater. Sci. Ed. 2015, 30(3):442-446.|\n| Sattar A , Azzouz I M , Shafik M S , et al. Effect of sensitizers on the optical properties of Er3+ions in erbium glass lasers[C]// Workshop on Photonics & Its Application at Egyptian Engineering Faculties & Institutes. IEEE, 2002.|\n| Kervevan L , Gilles H , Girard S , et al. Self-mixing laser Doppler velocimetry with a dual-polarization Yb:Er glass laser[J]. Applied Physics B, 2007, 86(1):169-176.|\n| Karlsson G , Laurell F , Tellefsen J , et al. Development and characterization of Yb-Er laser glass for high average power laser diode pumping[J]. Applied Physics B, 2002, 75(1):41-46.|\n| Vitkin V , Krylov A , Polishchuk A , et al. 40 Hz 1.3 mJ Q-switched Yb:Er:glass Laser[C]// 2018:50-50.|\n| Bhardwaj A , Agrawal L , Pal S , et al. Optimization of passively Q -switched Er:Yb:Cr:phosphate glass laser: theoretical analysis and experimental results[J]. Applied Physics B, 2007, 86(2):293-301.|\n| Kalashnikov V L , Shcherbitsky V G , Kuleshov N V , et al. Pulse energy optimization of passively Q-switched flash-lamp pumped Er:glass laser[J]. Applied Physics B, 2002, 75(1):35-39.|\n| Summaries of papers presented at the Conference on Lasers and Electro-optics. 1999.|\n| Third Workshop on Photonics and its Application at Egyptian Engineering Faculties and Institutes (Cat. No.02EX509)[C]// Workshop on Photonics & Its Application at Egyptian Engineering Faculties & Institutes. IEEE, 2002.|\nErbium glass (Er Yb Glass)\nEr, Yb:Glass/Er, Yb, Cr: Glass product, also known as erbium glass, is a kind of laser glass with good comprehensive performance.\nProduct SKU: 50\nProduct Brand: Crylink\nRelated product(s) with Er,Yb:Glass:\nIf you are intereted in Erbium Glass (Er,Yb:Glass), please click the button below to enquire or ask for a samplel.\nRelated article(s) with Erbium Glass (Er,Yb:Glass):\nRelated case study with Erbium Glass (Er,Yb:Glass):\nRelated solution(s) with Erbium Glass (Er,Yb:Glass):\nRelated video(s) with Erbium Glass (Er,Yb:Glass):"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:644d381a-bda0-43dc-bec8-93841b749700>"],"error":null}
{"question":"What are treatment limits for industrial fluoride waste and environmental behavior?","answer":"The traditional lime treatment of industrial fluoride waste can reduce concentrated flows (>1500 ppm) to 35-60 ppm range. Using WT-747 allows further reduction. As for environmental behavior, fluorine cannot be destroyed in the environment, only change form. It forms salts with minerals in soil, and fluorides in water and soil form strong associations with sediment particles. Fluorides accumulate in plants and animals, particularly in bones or shells rather than soft tissues. Hydrogen fluoride gas gets absorbed by rain and clouds, forming hydrofluoric acid that falls to the ground.","context":["The treatment of water containing Fluorides, has been traditionally and historically done with Lime in alkaline pH range.\nThe reaction is : Ca(OH)2 + 2 HF = CaF2 + H2O\nThe fundamental problem that exists using this technique, arises from the low solubility of the Calcium Hydroxide (around = 0,07%) that therefore requires an excess of reagent to get a complete precipitation. For against, theoric solubility of the Calcium Fluoride (Ksp = 4*10 exp-8 equivalent to\n17 ppm of CaF2 or 8,3 ppm as F- ) doesn't obtain a complete removal of the Fluorides as required by wastewater discharge Limits or WHO recommendation for drinking water. Furthermore, substantial lowering in Fluoride ion, by such method requires very long contact time\nThe study on the formation of Aluminium complexes with the Fluorine has been developed (Garrison Sposito: The Environmental Chemistry of Aluminium–CRC Press–1989).\nExperimental trials confirmed the ability of absorption of Fluoride ions on the Aluminium Hydroxide matrix due to the dimension of the ion F - that is similar to the ion OH –RELATE INTERTRADE ’s product WT-747 is a mixture of precipitated Aluminium Oxide and re-dissolution of a complex Aluminium salt containing different ligands at pH value < 1\nThe usual treatment with lime in slurry allows to treat concentrated flows (Fluorides > 1500 ppm) rising from washing or process wastewater where Hydrofluoric Acid (or Ammonium Fluoride) has been used. Such treatment obtains residual Fluoride content in the range of 35 – 60 ppm.\nLimpid water from pre-treatment step is treated as follows :\n1. Mixing of WT-747 in a well stirred reactor for a reaction time of 3 – 5 minutes\n2. pH adjustment in a second reactor with Lime slurry until pH value of 7,5 – 7,8\n3. Anionic Polymer solution addition to allow a formation of big flocks\n4. Sedimentation in a final settling tank\nPRELIMINARY LABORATORY METHOD GUIDELINE\nThe wastewater containing Fluorides ( more than 500 ppm) must be treated with the conventional method :\nLime addition until pH 10 – 11\nStirring for a period of 10 – 15 minutes\nAddition of Anionic Polymer (10 – 20 ppm) until a complete flocculation and sedimentation\nBy such way it’s possible to arrive to a final concentration of Fluorides in the range 35 – 50 ppm\nIf residual content of Fluorides is ALREADY in such range, this pre-treatment is not required.\nOn the limpid liquid superficial (containing the above mentioned concentration) :\n1. WT-747 is added : it’s occurs a pH lowering (to maintain the stirring for 2 minutes)\n2. Lime is added until pH 7,5 – 8,5 (to maintain the stirring for 3 minutes)\n3. Anionic polymer is added (10 ppm) to achieve a complete flocculation and sedimentation\nThe optimum WT-747 dosage has to be defined in lab tests.\nUsually, the laboratory test is carried out by additions, with the same procedure, of 500 – 1000 – 1500 – 2000 – 3000 ppm and by reporting in a calibration curve the Fluoride residual concentration.\nBy such way, it’s possible to define the more suitable dosage.\n|スワンチェデイー（พระสุวรรณเจดีย์ 2 องค์）エメラルド寺院 (วัดพระแก้ว) (2)|\n|私は日本語に翻訳してみます。正しい躊躇います。直していただけませんか。お願いします。 ありがとうね (^。^) (1)|\n|私は 又も 発表しなけばなりませんね。 (3)|\nReport this entry\nThe treatment of water containing Fluorides, has been traditionally and historically done with Lime in alkaline pH range. The reaction is : Ca(OH)2 + 2 HF = CaF2 + H2O The fundamental problem that exists using this technique, arises from the low solubility of the Calcium Hydroxide (aro","On This Page\nToxFAQsTM for Fluorides, Hydrogen Fluoride, and Fluorine\nCAS#: Hydrogen Fluoride 7664-39-3; Fluorine 7782-41-4; Sodium Fluoride 7681-49-4\nThis fact sheet answers the most frequently asked health questions about fluoride, hydrogen fluoride, and fluorine. For more information, you may call the ATSDR Information Center at 1-888-422-8737. This fact sheet is one in a series of summaries about hazardous substances and their health effects. This information is important because this substance may harm you. The effects of exposure to any hazardous substance depend on the dose, the duration, how you are exposed, personal traits and habits, and whether other chemicals are present.\nFluorides are naturally occurring compounds. Low levels of fluorides can help prevent dental cavities. At high levels, fluorides can result in tooth and bone damage. Hydrogen fluoride and fluorine are naturally-occurring gases that are very irritating to the skin, eyes, and respiratory tract. These substances have been found in at least 188 of the 1,636 National Priorities List sites identified by the Environmental Protection Agency (EPA).\nWhat are fluoride, hydrogen fluoride, and fluorine?\nFluorides, hydrogen fluoride, and fluorine are chemically related. Fluorine is a naturally-occurring, pale yellow-green gas with a sharp odor. It combines with metals to make fluorides such as sodium fluoride and calcium fluoride, both white solids. Sodium fluoride dissolves easily in water, but calcium fluoride does not. Fluorine also combines with hydrogen to make hydrogen fluoride, a colorless gas. Hydrogen fluoride dissolves in water to form hydrofluoric acid.\nFluorine and hydrogen fluoride are used to make certain chemical compounds. Hydrofluoric acid is used for etching glass. Other fluoride compounds are used in making steel, chemicals, ceramics, lubricants, dyes, plastics, and pesticides. Fluorides are often added to drinking water supplies and to a variety of dental products, including toothpaste and mouth rinses, to prevent dental cavities.\nWhat happens to fluoride, hydrogen fluoride, and fluorine when they enter the environment?\n- Fluorine cannot be destroyed in the environment; it can only change its form. Fluorine forms salts with minerals in soil.\n- Hydrogen fluoride gas will be absorbed by rain and into clouds and fog to form hydrofluoric acid, which will fall to the ground.\n- Fluorides released to the air from volcanoes and industry are carried by wind and rain to nearby water, soil, and food sources.\n- Fluorides in water and soil will form strong associations with sediment or soil particles.\n- Fluorides will accumulate in plants and animals. In animals, the fluoride accumulates primarily in the bones or shell rather than in soft tissues.\nHow might I be exposed to fluoride, hydrogen fluoride, and fluorine?\n- The general population can be exposed to fluorides in\ncontaminated air, food, drinking water and soil.\n- People living in communities with fluoridated water or\nlevels of naturally-occurring fluoride may be exposed to\n- People who work or live near industries where fluoride containing substances are used may be exposed to higher levels.\nHow can fluoride, hydrogen fluoride, and fluorine affect my health?\nSmall amounts of fluoride help prevent tooth cavities, but high levels can harm your health. In adults, exposure to high levels of fluoride can result in denser bones. However, if exposure is high enough, these bones may be more fragile and brittle and there may be a greater risk of breaking the bone. In animals, exposure to extremely high doses of fluoride can result in decreased fertility and sperm and testes damage.\nFluorine and hydrogen fluoride are very irritating to the skin, eyes, and respiratory tract. At high levels, such as may occur through exposure from an industrial accident, hydrogen fluoride may also damage the heart.\nHow likely are fluoride, hydrogen fluoride, and fluorine to cause cancer?\nMost of the studies of people living in areas with fluoridated water or naturally high levels of fluoride in drinking water did not find an association between fluoride and cancer risk. Two animal cancer studies were inconclusive. The international Agency for Research on Cancer (IARC) has determined that the carcinogenicity of fluoride to humans is not classifiable.\nHow does fluoride, hydrogen fluoride, and fluorine affect children?\nWhen used appropriately, fluoride is both safe and effective in preventing and controlling cavities. Drinking or eating excessive fluoride during the time teeth are being formed (before 8 years of age) can cause visible changes in teeth. This condition is called dental fluorosis. At very high concentrations of fluoride, the teeth can become more fragile and sometimes can break.\nNo studies have addressed whether low levels of fluoride will cause birth defects in humans. Birth defects have not been found in most studies of animals.\nHow can families reduce their risk for exposure to fluoride, hydrogen fluoride, and fluorine?\nIn the home, children may be exposed to high levels of fluorides if they swallow dental products containing fluoridated toothpaste, gels, or rinses. Parents should supervise brushing and place at most, a small pea size dab of toothpaste on the brush and teach children not to swallow dental products. People who live in areas with high levels of naturally-occurring fluoride in the water should use alternative sources of dinking water, such as bottled water.\nIs there a medical test to show whether I've been exposed to fluoride, hydrogen fluoride, and fluorine?\nTests are available to measure fluoride levels in urine; these tests can determine if you have been exposed to higher-than normal levels of fluorides. The urine test must be performed soon after exposure because fluoride that is not stored in bones leaves the body within a few days. The test cannot be performed in the doctor's office, but can be done at most laboratories that test for chemical exposure. The urine fluoride test cannot be used to predict the nature or severity of toxic effects. Bone sampling can be done in special cases to measure long-term exposure to fluorides.\nHas the federal government made recommendations to protect human health?\nThe EPA has set a maximum amount of fluoride allowable in drinking water of 4.0 milligrams per liter of water (4.0 mg/L). For the prevention of dental decay, the Public Health Service (PHS) has, since 1962, recommended that public water supplies contain between 0.7 and 1.2 milligrams of fluoride per liter of drinking water.\nThe Occupational Safety and Health Administration (OSHA) has set limits of 0.2 milligrams per cubic meter (0.2 mg/m3) for fluorine, 2.0 mg/m3 for hydrogen fluoride, and 2.5 mg/m3 for fluoride in workroom air to protect workers during an 8-hour shift over a 40-hour work week.\nAgency for Toxic Substances and Disease Registry (ATSDR). 2003. Toxicological Profile for Fluorine, Hydrogen Fluoride, and Fluorides. Atlanta, GA: U.S. Department of Health and Human Services, Public Health Service.\nWhere can I get more information?\nIf you have questions or concerns, please contact your community or state health or environmental quality department or:\nFor more information, contact:\nAgency for Toxic Substances and Disease Registry\nDivision of Toxicology and Human Health Sciences\n1600 Clifton Road NE, Mailstop F-57\nAtlanta, GA 30329-4027\nPhone: 1-800-CDC-INFO · 888-232-6348 (TTY)\nEmail: Contact CDC-INFO\nATSDR can also tell you the location of occupational and environmental health clinics. These clinics specialize in recognizing, evaluating, and treating illnesses resulting from exposure to hazardous substances.\nInformation line and technical assistance:\nTo order toxicological profiles, contact:\nNational Technical Information Service\n5285 Port Royal Road\nSpringfield, VA 22161\nPhone: 800-553-6847 or 703-605-6000\nSome PDF files may be electronic conversions from paper copy or other electronic ASCII text files. This conversion may have resulted in character translation or format errors. Users are referred to the original paper copy of the toxicological profile for the official text, figures, and tables. Original paper copies can be obtained via the directions on the toxicological profile home page, which also contains other important information about the profiles.\nThe information contained here was correct at the time of publication. Please check with the appropriate agency for any changes to the regulations or guidelines cited.\n- Page last reviewed: March 20, 2013\n- Page last updated: May 6, 2014\n- Content source: Agency for Toxic Substances and Disease Registry"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:3371d1f1-1268-4b2b-86a5-de537a576d39>","<urn:uuid:d84046de-aac2-456b-8723-79af4e49b6d2>"],"error":null}
{"question":"What's the connection between workload monitoring in athletes and chronic pain development? Looking at how ACWR impacts injury prevention and how acute pain might transition into chronic conditions!","answer":"The connection between workload monitoring and chronic pain development involves several key aspects. The Acute:Chronic Workload Ratio (ACWR) helps prevent injuries by monitoring the balance between recent workload (3-7 days) and adapted load (3-6 weeks). The 'sweet spot' range of 0.8-1.3 indicates low injury risk, while ratios above 1.5 significantly increase injury risk. When injuries do occur, proper monitoring is crucial because acute pain can transition to chronic pain if not managed properly. While it's commonly believed that 80-90% of acute back pain resolves without treatment within 2-3 months, research shows only 40% of non-specific acute back pain actually resolves in this timeframe. Several factors can cause acute pain to become chronic, including mechanical working conditions, pain-related issues, medical considerations, poor pain response strategies, fear beliefs about the disease, and lack of social or emotional support.","context":["What is the Acute:Chronic Workload Ratio (ACWR)?\nThe use of the acute:chronic workload ratio has received a growing interest in the past couple years to monitor injury risk in a variety of team sports1. This ratio is generally computed using load over 28 days, and has been calculated using either internal (session-rate of perceived exertion) or external (tracking variables) measures of competitive and training load1.\nAcute Phase= athletes most recent workload (state of fatigue)\n- Typically, between 3-7 days in duration (often recommended specific to sport competition schedule). Variance in acute phase typically based on game schedule 2 ; if play once a week = 7 day compared to multiple times a week (3/4 days)2.\nChronic Phase= the load the athlete has adapted to (state of fitness)\n- Typically, between 3 to 6 weeks with the most recent research indicating 21 days is an appropriate chronic time window2.\nWhy is the Acute:Chronic Workload Ratio important?\nThe acute:chronic workload ratio is a greater predictor of injury than either acute or chronic workload separately3.\n- Compared with a low chronic workload, athletes with a high chronic workload are:\n- More resistant to injury with moderate-low to moderate high acute:chronic workload ratios.\n- Less resistant to injury with a very-high acute:chronic workload ratio.\n- The acute:chronic workload ratio in the current week, subsequent week, and as an average over 2 weeks, is associated with increased injury risk in elite rugby league players 3.\nApplication of the ACWR\nIf we take a step back and dive into known research around weekly changes in workload. It’s known that increased workload results in an increased injury risk3,4, however a lack of workload will subsequently result in athletes potentially being under prepared for game demands4. Therefore, finding the right balance is critical to an athlete’s success 4.\n- Small changes in training loads between weeks has shown decreased injury (-5 to 10%)5\n- When training loads are increased >15% injury risk varies between 21-49% 5\nMore recent research suggests analysing short term (acute) in relation to long term (chronic) load as a valid tool to measure an athletes risk of injury3,5,6.\n- The graph below is a good starting point to interpret the ACWR.\n- The green shaded area is the ACWR where injury risk is low. Red indicates when injury risk is high.\n- Exposing athletes to a spike in ACWR of >1.5 increases the risk of injury3,5,7.\nThe “sweet spot” ranging between 0.8 – 1.3 is the zone practitioners should aim to keep their athletes between.\nAthletes still need to be able to perform under the “worst case scenario” in game play. If they are not prepared to do so they are also at an increased injury risk5. It’s been shown that higher chronic loads may reduce injury risk3,7, therefore reductions in workload may not always be the answer.\nWhile 0.8-1.3 is a good guideline, it’s critical to also take into consideration how the athlete got there. For further detail on the ACWR and rehabilitation- Jo Clubb provides a detailed application for an athlete who suffered a groin injury, 8 week rehabilitation program and 3 weeks back into full training, a re-injury in her blog post, Acute:Chronic Workloads and Rehabilitation: A Case Study.\nHow to set up an Acute:Chronic Workload Ratio Chart on OpenField\n1. On OpenField Cloud, click Settings.\n2. Then Teams.\n3. Change the Acute and Chronic Duration for your team.\n4. Click Save Changes.\n5. Right click on a blank tile from your dashboard and select Wizard.\n6. Click on the Acute:Chronic Ratio Chart.\n7. Double click the parameter to view in the ACRW chart.\n8. Once the chart is created- click Settings.\n9. Click Filters > Last Activities from the drop-down menu and add the amount of activities to view.\n10. To view data labels, click Options > Show Data Labels.\n11. Click Series to modify the type, colour and decimal rounding’s of each series.\nAcute Load - Athlete’s most recent workload (between 3-7 days)\nChronic Load - The load the athlete has adapted to (3-6 weeks)\nAcute:Chronic Ratio - Internal and external measure of competitive and training load (Usually 28 days)\nHow to view day-to-day load in a chart side by side with ACWR?\nThe ACRW chart illustrates acute, chronic and ACWR values. However, there is benefit in coupling this visual with a day-day chart of the actual Player Load (or whichever metric you are plotting).\n- Right click on a blank tile from your Dashboard and select Wizard.\n- Click on the Column Chart.\n3. Set parameter and follow prompts to create the day-to-day load chart.\n4. Coupling the ACWR Player Load and Day-to-Day Load Charts.\n- Buchheit M. Applying the acute:chronic workload ratio in elite football: worth the effort? Br J Sports Med 2017;51:1325-1327.\n- Carey DL, et al. Br J Sports Med 2016;0:1–7. doi:10.1136/bjsports-2016-096309\n- Hulin BT, Gabbett TJ, Lawson DW, et alThe acute:chronic workload ratio predicts injury: high chronic workload may decrease injury risk in elite rugby league players Br J Sports Med 2016;50:231-236.\n- Rogalski B, Dawson B, Heasman J, et al. (2013) Training and game loads and injury risk in elite Australian footballers. J Sci Med Sport; 16: 499-503.\n- Gabbett, TJ. (2016) The training-injury paradox: should athletes be training smarter and harder?Br J Sports Med; 2016;50273-280. doi;10.1136/bjsports-2015-095788\n- Blanch P & Gabbett TJ. (2015) Has the athlete trained enough to return to play safely? The acute:chronic workload ratio permits clinicians to quantify a player’s risk of subsequent injury. Br J Sports Med;0:1–5. doi:10.1136/bjsports-2015-095445\n- Hulin BT, Gabbett TJ, Blanch P, et al. (2014) Spikes in acute workload are associated with increased injury risk in elite cricket fast bowlers. Br J Sports Med; 48: 708-12.","Back pain definition\nBack pain may be defined as the pain affecting between the rib margins and the lower folds of buttocks. The amount of physical activities and bad postures influence back pain. Back pain limits movement of the spine. Back pain is frequently found to be a referred pain from other source of pain. Non-specific back pain is not related to fractures, ankylosis, direct trauma or systemic conditions. Specific back pains have specific pathological conditions and have some warning signs. Back pain is a condition that affect so many groups of people. Affected groups of back pain include healthcare professionals, like doctors, nurses, therapists, osteopaths, chiropractors, healthcare administrators, politicians and many more. Among them, 80% of chronic back pain sufferers have one or more elusive etiology. 70–80% of adults of almost all locations of world experience back pain at some point in their lives. The fifth decade is peak point for having back pain. There is drastic increase in incidence of back pain in the past two to three decades. This increase caused an increase in work loss, compensation or sick leave issues, and disability allowances with huge economic cost as its aftermath.\nMyths we know about acute back pain\n- We have a common notion to back pain that prolonged bed rest is needed for this condition.\n- Many also think that patients with acute back pain do not need close follow-up. That is because many say 80–90% of acute back pain completely resolves without treatment within 2–3 months.\nMyths are not true\n- Prolonged bed rest should be discouraged in most cases of acute back pain, as it causes stiffness, osteoporosis, bedsores and other dangerous conditions.\n- Regarding acute pain, it is a responsibility for all to prevent chronic pain. So, patients suffering from acute pain should be followed more closely to ensure that his/her pain does not convert to chronic pain.\n- It is found that only 40% of acute back pain, which are due to non-specific cause completely resolves without treatment within around 2–3 months. So, pathological conditions must be excluded first.\nMyths about Chronic back pain\n- There are myths about chronic back pain. Many of the people think that the people, who show chronic back pain, are faking and doing so for any gains. They give explanation that they have any one sign of Waddell signs. In Waddell sign, there are some tests. In tenderness test, we see superficial and diffuse tenderness rather than deep tenderness, in case of fake ones. Non-anatomic tenderness also shows fake pain. Those have fake pain will feel pain during simulation test. Here, the person feels pain without any movement of said joint. When the person is distracted, the person can score more in tests like straight leg raising test. Those who do not have real pain will have regional weakness or sensory changes, which cannot be explained by anatomical knowledge. Those with false pain, have more exaggerated reaction to any acts. For example they show overreaction of pain while walking.\n- There is myth all around that what doctors can offer only symptomatic treatment in such case, as no organic cause is there.\nMyths can be clarified\n- When Waddell signs are present, we cannot say definitely that this person have non-organic back pain. Back pain may lead a person of organic pain to such behavior. In his book Gordon Waddell said that, presence of more than three of the signs are clinically significant. But, this never exclude organic pain. This is indicative of only magnified clinical expression or magnified pain behavior.\n- Again, Chronic back pain is a problem which cannot be addressed by a single discipline. A multidisciplinary team approach is needed for assessment and proper management of back pain. Therefore, only specific medicine is not the only thing that the disease need. There are many things beyond medication for the back pain patients. However, the patients usually do not think those important.\nClassification of back pain\n- Acute: those back pains having less than 6 weeks\n- Chronic: back pains lasting more than 6 weeks\n(an acute on chronic or sub-acute variety is still in debate)\nThere are sub categories of chronic back pain. They are graded depending on severity.\nGrade 1 is less severe condition where intensity of pain is low and chance of disability is low.\nGrade 2 is mild severe condition where intensity of pain is high but chance of disability is low.\nGrade 3 is moderately severe condition where pain limits daily activity moderately and chance of disability is high.\nGrade 4 is a severe condition where intensity of pain limits daily work severely and chance of disability high.\nAlthough, we cannot say for definite which acute pain goes to chronic, we can try to manage acute pain to prevent chronic pain. There are some factors, which if present back pain may turn chronic. These are\n- Characteristics or working conditions which involve mechanical insult\n- Issues related to pain\n- Medical considerations\n- Bad strategies of response to pain\n- Fear of beliefs about the disease\n- Absence of social or emotional support\nHistory and physical examination in back pain\nBecause of availability of modern imaging systems, many of the centers are not willing to do routine clinical examination in patients with back pain. In many recent researches also concluded that history\nalone correlated well with MRI results could be better approach for back pain. Clinical examination is\nonly considered in those patients who need surgery and we need document of neurological status. However, still many things are there that can only be seen by keen physician during clinical examination and not revealed by MRI.\nHere are some points in favor of clinical examinations\n- MRI is too often picks pathology where there is none. This may be a procedure error.\n- You cannot order MRI in every patient.\n- Sometimes the real diagnosis can only be found on physical examination, e.g. detailed physical examination can point more pin point diagnosis like early cauda equina syndrome (example: the patient may not have noticed asymmetrical saddle sensory loss and reduced anal tone may be the only sign to diagnose it.)\n- From medico-legal point of view, a proper document of the physical examination findings of the patient while visiting you is important. Patient condition may deteriorate suddenly but your findings will defend you in court.\n- If you perform a proper and gentle physical examination, patient will trust you.\n- Finally, routine MRI with the patient in supine position may still miss\nsome pathology that can be picked up only by standing or upright\nThis new open MRI technology is also good because it can be used in patients with claustrophobia.\nManagement of back pain\nThe objective of our management is not to relieve pain only. It should be a holistic approach. We should treat the patient, not the back pain. There are many treatment options. They are explanation about the disease, rest, drugs, traction, spinal manipulation, exercises, acupuncture, infra red therapy, ultrasonic sound therapy, heat and cold therapy and some rehabilitating measures like Work Hardening and Vocational Conditioning, behavioral therapy etc. So, it is a multidisciplinary approach. However, are outlining some basic rules about back pain management.\nAcute back pain:\n- Rule out red flags\n- Stay active\n- Muscle relaxants\nSub-acute or acute on chronic\n- Expectations of patient\n- Regular Re-assessment\n- Active treatments\n- Cognitive behavioral therapy\n- Multidisciplinary approach\n- Occupational program for workers\nChronic back pain\n- Low disability: simple therapies\n- Severe disability: bio-psychosocial therapy"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:ba683f4a-e167-40e8-8ec7-0467dd8c62ff>","<urn:uuid:080557fb-1a32-43d0-b4f2-bcb3b45e1b4d>"],"error":null}
{"question":"What are the primary conservation efforts for coral reefs in the Northern Mariana Islands, and how do recreational activities like snorkeling and diving on Molokai impact marine ecosystems?","answer":"The Northern Mariana Islands implement several conservation efforts for coral reefs, including the U.S. Coral Reef Task Force which regulates pollution, over-fishing, and recreational misuse of marine resources. They also have Marine Protected Areas (MPAs) and the Marianas Trench Marine National Monument that prohibits fishing in certain areas. As for recreational impact, Molokai offers extensive snorkeling and diving activities through various operators like Molokai Fish And Dive and Molokai Snorkeling Adventures, who provide guided access to coral reefs and marine life while following coast guard regulations and professional diving standards to minimize ecosystem impact.","context":["VACATION INFORMATION – Activities – What To Do On Molokai\nSnorkel & Scuba\nMolokai Fish And Dive\nThis local landmark has everything anyone could need for a great time in the tropical sun. You can arrange ocean kayak outings, whale watch tours, snorkel and scuba trips, Kalaupapa tours and more. They also sell or rent fishing equipment, snorkel/dive gear and surf boards and they have a huge selection of unique Molokai T-shirts.\nPurdy’s Natural Macadamia Nut Farm\nVisit a working macadamia nut farm. Crack a few of those delicious nuts yourself and talk story with Tuddie and Kammy, the owners. You can learn everything you ever wanted to know about mac nuts and sample a few roasted or raw. Learn about Hawaiian culture and this island from folks who live Aloha.\nHere’s your chance to land a trophy size Ulua or Marlin or …… Take a deep sea or near-shore fishing trip with Captain Mike aboard the 27′ Ahi. He can also take care of your snorkeling, scuba or whale watching wishes. Need an escort for your racing canoe, he’s the man.\nMolokai Mule Ride\nRide the famous Molokai mules down the world’s highest sea cliffs to the Kalaupapa National Historical Park. Perhaps the most stunningly beautiful and inspirational place in Hawai’i. Even the most seasoned travelers cherish this tour as one of their most memorable island experiences.\nMolokai Outdoor Activities\nThey specialize in car and ocean sports equipment rentals, plus they will organize your land, ocean, hiking, biking, cultural or eco tours. They can also help with your vacation rental needs.\nMolokai Whale Watching Tours\nThey offer outstanding Humpback Whale watching adventures aboard one of their 2 Coast Guard certified vessels. 10,000 – 12,000 Humpback Whales migrate to Hawaii to spend December through April in the warm Hawaiian waters and these folks guarantee you’ll see whales on their tours.\nMolokai Ocean Tours\nBoard the Manu Ele’ele (Black Bird), a 40′ foot power catamaran and tour the fringing reefs of Molokai’s south coast. Join Captain Pete and his crew for whale watching, SNUBA/snorkeling, fishing or an on-board wedding. You can try spearfishing around the reefs or torch fishing in the shallow water. They offer outdoor rentals too.\nAlyce C Sport Fishing\nThe fishing grounds off of Molokai are the best in Hawaii. Let Captain Joe take you on an authentic Hawaiian fishing experience with Alyce C Sportfishing. He specializes in deep-sea fishing charters in Maui County’s “triangle”- south Molokai, Lanai, and the Penguin Banks – and Molokai’s rugged North Shore.\nMolokai Snorkeling Adventures\nProbably the best snorkel adventures available on the island are aboard their coast guard approved dive boats. Certified PADI Dive Masters lead you to spectacular sites that are filled with colorful, tropical fish, sea turtles, stunning corals and other exciting critters.\nScuba Diving Molokai\nMolokai’s only PADI Dive Center offers excursions to more than 40 of Hawaii’s best sites for divers of all skill levels. They also offer “Discover Scuba” and scuba diver certification courses from PADI dive instructors.\nPost-A-Nut Send a coconut postcard to the folks back home. Drive to the small US Post Office in Ho’olehua, where they keep a supply of coconuts and marking pens. Decorate and address your own tropical postcard then hand it to the postmaster to mail. The only expense is the postage. One of the simple delights that make a Molokai vacation unique.\nDewitt Jones, one of our favorite photographers, captured a visiting family creating their post-a-nuts in this Rockwell-like scene.\nFor driving instructions, look for the USPO Ho’olehua on the Molokai Retail Stores Map\nFor The Actively Inclined\n- Ride one of the sure-footed mules down the spectacular Kalaupapa sea cliff trail.\n- Take a sport fishing boat out to catch your dinner.\n- Sail to Lanai for the day to snorkel and laze around on deck.\n- Scuba dive the pristine waters of Hawaii’s only barrier reef.\n- Play a fast nine on the local municipal golf course.\n- If you didn’t bring yours, rent some gear and go snorkeling, surfing or boogie boarding.\n- Expand your cultural awareness by visiting an ancient Hawaiian heiau (temple).\n- Rent a mountain bike and go touring.\n- Learn Hawaiian fishing and hunting techniques, or try kayaking and reef trolling.\n- Visit the rain forest on a hike through Kamakou Preserve.\n- Take a nap.\nFor The Reclined\n- Grab some shade under a palm tree and dive into that new novel you’ve been wanting to read.\n- Take some sun screen and a towel to an empty beach.\n- Visit the Molokai Museum & restored 19th century sugar mill.\n- Don’t miss the spectacular view of Kalaupapa from the lookout.\n- Visit a tropical flower farm and sew your own lei.\n- Visit a macadamia nut farm to learn the secret of getting that delicious nut out of its hard shell.\n- Visit a coffee plantation and enjoy a quiet cup of java or espresso.\n- If it’s December-April, watch for humpback whales.\n- Watch a halau practice hula.\n- Wander around the Kaunakakai shops.\n- Take a nap.","by Lauren Stoneburner\nThe Commonwealth of the Northern Mariana Islands (CNMI) is a tropical marine haven. The region is made up of a string of fourteen small islands, originally formed by underwater volcanoes along the Marianas Trench. These islands make up a commonwealth of the United States, meaning that it has its own constitution and is largely autonomous, but receives economic assistance from the U.S. The coral reef habitats are at the center of each island’s rich ecosystem, establishing the foundation for a highly productive and diverse biological community, both marine and terrestrial. The islands’ isolation from other landmasses has also led to high levels of endemism, making these ecosystems particularly unique and treasured.\nToday, while the northern islands of the CNMI remain largely uninhabited, the larger southern islands of Rota, Tinian, and Saipan carry about 70,000 people (State Wildlife Action Plan 2007). Unfortunately, these more heavily populated southern islands also have the oldest and most developed coral reefs of the CNMI (NOAA’s Coral Reef Information System 2012). Saipan is the island with the greatest diversity of coral reefs and associated habitats, yet its western side is also the most developed. This human activity hugely impacts the local reefs. As a whole, the coral reefs in the CNMI are reasonably healthy, but the condition of each reef is largely determined by its proximity to human population centers. Consequently, there has been a dire need for both remedial and proactive conservation programs.\nBoth the region’s biology and economy are enormously dependent on the coral reefs, so conservation projects within the CNMI focus primarily on protecting marine habitats.\nThe CNMI is also a member of the U.S. Coral Reef Task Force, which is on the CNMI is managed by the Department of Environmental Quality. This organization focuses on regulating land-based sources of pollution, over-fishing, and recreational misuse or overuse of marine resources, as well as increasing public awareness (Coastal Resources Management Office 2012).\nDue to the central role that coral reefs play in supporting biological diversity, this additional effort and attention placed on preserving coral reefs is absolutely warranted. Additionally, regulations that protect coral reefs from pollution and educate the people about the importance of healthy ecosystems may improve activity with regard to other natural habitats. However, the narrow-minded focus on coral reefs leaves other vulnerable habitats defenseless. Plans to preserve coral reefs seek to maintain the ecosystem’s species diversity, but species diversity is only one element of biological diversity. Conservation efforts must also stress ecosystem diversity. This comprehensive approach is arguably the most promising approach to ensuring resilience, for each ecosystem will be impacted variably by changes to come.\nThe CNMI has developed a Coastal Program, which protects a more comprehensive set of habitats against the threats of coastal development. Of the many threats human activity poses on delicate marine ecosystems, the marine environment of the CNMI is most greatly affected by nonpoint source pollution, tourism, and overexploitation of marine resources, as well as sporadic stressors, such as outbreaks of invasive species and coral bleaching (Coastal Resources Management Office 2012; NOAA’s Coral Reef Information System 2012). To remedy these threats, the Coastal Program protects and restores coral reefs, wetlands, mangroves, lagoons, beaches and other coastal resources primarily by issuing development permits, educating the public, monitoring the condition of the reefs; and remediating problem areas (Coastal Resources Management Office 2012).\nThere is one other mechanism that enables the region to implement an ecosystem-oriented conservation strategy. The CNMI has created several marine protected areas (MPAs), which establish strict regulations regarding human activities in specified locations. With this political instrument, the CNMI has the potential to protect a variety of specific and diverse environments. Saipan—the most densely populated island—currently has five active marine protected areas. However, upon taking a closer look, these marine protected areas may seem insufficient.\nThe Bird Island Sanctuary and Forbidden Island Sanctuary both protect marine environments composed of fringing reefs, and they both primarily strive to protect nesting bird sanctuaries (NOAA’s Coral Reef Information System 2009). The other three marine protected areas protect freshwater wetlands (Division of Fish and Wildlife 2012). Though protection of freshwater habitats is extremely important, two of these sites are off-site mitigation areas where developers can purchase credits recognized by the U.S. Fish & Wildlife Service to maintain the protected habitat, in exchange for developing on wetlands elsewhere, meaning these MPAs legitimize the destruction of wetland habitats (Usa 2009).\nThe reasoning behind the site-selection of the CNMI’s MPAs was highly anthropocentric. Second to being a critical foundation to marine ecosystems, coral reefs are likely the focal point of two of the five MPAs because of human demands. Coral reefs are perceived as exotic and contain enormous aesthetic and cultural value, which makes them a desirable attraction for tourists. Thus, the reefs act as a source of revenue and are very central to the local population’s economy. Unlike many other ecosystems vital to the overall health of the island, coral reefs are extremely attractive, both physically and economically, as opposed to mangrove and wetland habitats, which are an essential habitat for many unique and endemic marine and terrestrial species, but a lesser tourist draw.\nEconomic benefits also lie behind the site selection of the three protected wetlands on Saipan. The Susupe Wetland filters runoff in order to ultimately protect the downstream coral reefs from sedimentation (Division of Fish and Wildlife 2012). Thus, the Susupe Wetland was chosen because of the demand for pristine coral reefs. Nevertheless, the wetland site is important for diversifying the ecosystems protected by MPAs, regardless of its selection reasoning.\nThe creation of the Saipan Upland Mitigation Bank is an even more explicit result of economic demand. This freshwater wetland has been dedicated to habitat restoration and the protection and long-term survival of the Nightingale Reed Warbler. With this conservation system in place, developers can buy credits, which signify a contribution to the protection of the Upland Mitigation Bank, in order to proceed with developing on lands where the Reed Warblers are known to exist (Usa 2009). Therefore, unlike the Susupe Wetland site that protects wetland sites to protect not only the designated wetland habitat, but also the coral reef habitat downstream, this mitigation MPA allows for similar habitats—even with critically endangered species such as the Nightingale Reed Warbler—to be destroyed, thus having a neutral, if not negative, impact on habitat preservation.\nThe Costco Park Wetland Mitigation Pond is yet another off-site mitigation project that attempts to make up for the loss of wetland habitat from the Costco Building (Division of Fish and Wildlife 2012). Because two of the five MPA sites on Saipan are chosen because of their economic value, rather than ecological value, and act as an excuse for the destruction of other valuable habitats, the CNMI has not fully safeguarded the dynamic and fragile relationships that connect various ecosystems and will determine the success of conservation efforts in the future.\nFinally, there has been one last important method of establishing conservation areas. At the very end of his presidency in 2009, President George W. Bush authorized the establishment of three marine national monuments surrounding the U.S. Pacific islands, totaling an area of 195,274 square miles of water (Federal Register 2009). Of these three marine national monuments, the Marianas Trench lies within the CNMI’s jurisdiction, and a predominant achievement is the complete prohibition of fishing in the Islands Unit of the Marianas Trench (The White House 2009). These decisions were made using the Antiquities Act, which is a law made in 1906 and gives the U.S. president unilateral powers to designate federal lands (and waters) as national monuments without the intervention of Congress (National Park Service 2013). President Bush used this act to secure his “blue legacy” and perhaps even redeem his otherwise lack of involvement in enacting environmental legislation.\nSome argue that this top-down approach in governance is unsafe when dealing with environmental issues. The first problem is that Congress is not consulted; therefore Congress is excluded from the role of instating national monuments that protect natural resources. Furthermore, the Antiquity Act allows the President to single-handedly designate an area as a national monument in the interest of the federal government, without any regard to the existing laws, procedures, or the sentiment of the local population (Walsh 2009). This disregard for the local population’s existing relationship with the land gives the law the potential to interfere with and even exploit indigenous peoples and their cultural practices, such as fishing practices (Walsh 2009). This is particularly critical to avoid, considering that the CNMI has a remote and largely indigenous population, subject to the legislation of the United States, a distant mainland, both geographically and culturally.\nThose that remain skeptical of the use of the Antiquities Act for enacting environmental legislation argue that the Magnuson-Stevens Act and the National Marine Sanctuaries Act are superior alternatives. These legislative methods for conserving habitats are considered to better balance local cultural and economic interests with the widespread goals of conserving marine environments (Walsh 2009). In the case of president Bush making a last desperate effort to redeem his name in the eyes of environmentalists, this opinion is justified. However, if the Antiquities Act is used correctly, it has the potential to significantly improve the health of oceans, especially around the CNMI.\nIf the Antiquities Act is again to be used in the interest of the environment, one key step that must be taken is the incorporation of science and multiple levels of stakeholders. Scientific findings must confirm the benefits of designating an area as a national monument, especially if human populations are to be affected by the restrictions. Science must also be used to decide what regulations are necessary to protect the ecosystem’s health. Because the people of the CNMI are largely vulnerable to their needs being overridden by federal decisions, there must also be a mechanism in place that mandates consideration of the indigenous culture and other local stakeholders.\nIf the Antiquities Act is able to systematically consider local community concerns and scientific findings—whether it be through mandated assistance from federal agencies or other checks and balances mechanisms—this system may bring about far more positive action with regard to preserving natural resources. Omitting the need for Congress’ approval will expedite the decision-making process, especially because the bipartisan nature of Congress often disables the force from making decisions entirely. Giving the president an alternative means of making rapid, time-sensitive decisions is a quality much needed today as environmental issues quickly accumulate and pose greater and greater threats to humankind.\nIn order to truly achieve the goals of protecting the CNMI’s reliance against the environmental changes and preserve the unique life forms that reside on the isolated islands, the CNMI must implement a more responsible array of conservation mechanisms that does not justify the destruction of critical habitat elsewhere. However, the CNMI has excelled in implementing a myriad of conservation policies to protect an array of habitats. However, some of these protected habitats are a result of negligence, excusing for further critical habitat to be erased from the Earth. An even more extensive matrix of protected lands must be developed in order to allow the protected areas to interact and species to move between protected habitats. These decisions may be made through an assortment of U.S. and Commonwealth policies and with varying degrees of restrictions on human activities.\nHowever, in order to make both the sound and speedy decisions necessary to protect humans and their environment from irreversible damage, it is possible that a top-down governance—along side a mechanism to consider indigenous practices and local communities’ needs—will become a favorable method of circumventing the indecisive nature of Congress and conserving natural areas in the interests of both the local population and greater international community. If the federal government proves to consider local populations in its decision-making, as it did in 2009 under President Bush, then decisions must rise from the people of the CNMI to push for coastal and terrestrial conservation plans that protect the most unique and central habitats to both the people and macro-ecosystem.\nAbout the author: Lauren Stoneburner is a rising junior undergraduate pursuing a B.S. in Environmental Studies and .B.A in Human Evolutionary Biology at the USC Dana and David Dornsife College of Letters, Arts and Sciences. She is interested in conservation biology, and looks forward to gaining experience working in the field during her trip to Guam and Palau this summer.\nEditor’s note: Scientific Research Diving at USC Dornsife is offered as part of an experiential summer program offered to undergraduate students of the USC Dana and David Dornsife College of Letters, Arts and Sciences through the Environmental Studies Program. This course takes place on location at the USC Wrigley Marine Science Center on Catalina Island and throughout Micronesia. Students investigate important environmental issues such as ecologically sustainable development, fisheries management, protected-area planning and assessment, and human health issues. During the course of the program, the student team will dive and collect data to support conservation and management strategies to protect the fragile coral reefs of Guam and Palau in Micronesia.\nInstructors for the course include Jim Haw, Director of the Environmental Studies Program in USC Dornsife, Assistant Professor of Environmental Studies David Ginsburg, Lecturer Kristen Weiss, SCUBA instructor and volunteer in the USC Scientific Diving Program Tom Carr and USC Dive Safety Officer Gerry Smith of the USC Wrigley Institute for Environmental Studies.\nCoastal Resources Management Office. (2012). \"Ocean and Coastal Management in the Commonwealth of the Northern Mariana Islands.\" NOAA Office of Ocean and Coastal Resource Management : My State : Northern Mariana Islands. National Oceanic and Atmospheric Administration.\nDivision of Fish and Wildlife. (2012). \"Commonwealth of the Northern Mariana Islands.\" Wildlife Protected Areas. Division of Fish and Wildlife.\nFederal Register (2009). Establishment of the Marianas Trench Marine National Monument. U.S. Government Printing Office. Presidential Documents. Vol. 74, No. 7, p. 1557.\nThe White House (2009). “Establishment of the Marianas Trench Marine National Monument.” The White House. The White House: President George W. Bush Archives.\nNational Park Service (2013). “Antiquities Act of 1906.” National Park Service. Federal Historic Preservation Laws. p. 5-6\nNOAA's Coral Reef Information System. (2012). \"Commonwealth of the Northern Mariana Islands.\" Coral Ecosystem Publications RSS. National Oceanic and Atmospheric Administration.\nNOAA's Coral Reef Information System. (2009). \"Coral Reef Habitat Assessment for U.S. Marine Protected Areas: Commonwealth of the Northern Mariana Islands.\" NOAA's Coral Reef Information System. National Oceanic and Atmospheric Administration.\nState Wildlife Action Plan. (2007). \"Commonwealth of the Northern Mariana Islands.\" Northern Marianas Wildlife Action Plan. Association of Fish & Wildlife Agencies.\nUsa, Ibp. (2009). Northern Mariana Islands Ecology & Nature Protection Handbook. USA: International Business Publications. p. 35.\nWalsh, James P. (2009). \"Presidential Bans On Commercial Fishing In Pacific Marine Protected Areas: A Politically Popular But Unlawful Regulatory Action?\" Marine Resources Committee Newsletter 12.3: 1-10.\nPreviously in this series:"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:0de14a7e-8c51-4fee-938e-82e9efc15724>","<urn:uuid:03e73330-7f0d-44ac-b565-6a16123e2deb>"],"error":null}
{"question":"Hey there! Which Weekend Edition kit has more parts - the Eduard Bf 110G-4 nightfighter or the Bf 109G-10 Erla? 🤔","answer":"The Eduard Bf 110G-4 nightfighter Weekend Edition has significantly more parts, with 413 pale olive parts and 13 clear parts (total 426), compared to the Bf 109G-10 Erla Weekend Edition which has 196 injection molded parts and 10 clear parts (total 206).","context":["Eduard's hugely popular Bf 110G-4 nightfighter returns as a Weekend Edition. A Weekend Edition? - well, I've no doubt building the kit in two days is just about possible if you lock the doors, disconnect the phone and Internet, and don't worry about such niceties as food and sleep, but don't be fooled by the name; this is a complex kit that warrants care and a fair bit of time spent building it.\nThe sturdy conventional box carries full colour profiles as a painting guide and is stuffed with no less than 11 sprues divided between several resealable bags. The kit comprises:\n413 x pale olive parts\n13 x clear parts\nDecals for a single colour scheme\nNow, that parts count is a little misleading because the kit includes sprues from the earlier DB 601-engined versions. There is a sprue guide in the instructions, but it doesn't show which parts aren't needed, but rest assured there will be a large number of unused parts for the spares box when you're done - you can see clearly in Jean-Luc's review of Eduard's original ProfiPack version\nReturning to Eduard's Bf 110 after a break, the first thing that struck me is just how good the exterior finish is, with finely engraved engraved panel lines and beautifully subtle embossed rivets. The latter really do make many other manufacturers' efforts look more appropriate for a boiler than a fighter. Jean-Luc found a fair amount of flash on the wings in his earlier kit, but there's none there this time. However, I did note a couple of small sink marks on the nose to take care of.\nThis is the first time I've had a chance to look at the 'G-4, so I was interested to see what Eduard have changed from the 'G-2 dayfighter. Obviously, there's radar - with a whole new sprue devoted to a complex array of \"antler\" diploles - and a new nose containing a pair of neatly detailed MG 108s. The gunner's MG 81Z remains, but it's joined by a pair of 20mm cannon in an upward-firing Schräge Musik mounting. Rounding off the main changes are a set of flame-damping exhausts and new rudders with extended trim tabs.\nOne thing I've always liked about Eduard's approach to tackling different versions is that they don't try to \"over-engineer\" a kit with lots of optional sub-assemblies (which often don't fit as well as one might hope in other manufacturers' kits). Instead, they simply provide an entire new main part. In this case it's the fuselage halves featuring a number of small panel detail changes.\nIntriguingly, Eduard have also modified how the wing roots are moulded compared with the earlier Bf 110G-2\n. I presume this was to make for a more positive assembly, but ironically I found the earlier style gives a better fit (although I'm sure a little trimming will probably sort matters out).\nThe nacelles proved a slightly awkward fit on Eduard's first Bf 110 kits, and that's still the case on the 'Gs - on both my kits there's a small gap between the top of the nacelle and the wing. There's been some concern voiced that the rear fuselage is too slender at the tail, so experienced modellers may wish to insert a plastic-card spreader and adjust the fit of the stabilizer accordingly.\nSomething for the weekend?\nEduard's \"Weekend\" kits are simplified re-editions of their existing range, so what do you lose? The obvious thing is the etched fret. For the most part this is not too much of a sacrifice on the Bf 110 because the interior is still very highly detailed with well moulded consoles and instrument panels. It's a shame the decals don't include instrument faces, but I guess you can't have everything. What you will probably miss are the etched seat harnesses, which goes to show just how much we've come to take these \"extras\" for granted in Eduard kits.\nThe other change you'll really notice come painting time is the omission of the canopy masks. I think a substantial chunk of your \"weekend build\" will be lost masking the complex greenhouse canopy neatly!\nInstructions and Decals\nThe instructions are printed in black and white as a neat little A-5 booklet. It's nowhere near as fancy as the glossy colour versions that Eduard are noted for, but I have to admit I prefer it - the diagrams are perfectly clear, and the booklet takes up much less room on the workbench. If you do want the instruction in colour, they can be downloaded from Eduard's website. Painting notes are keyed as usual to Gunze Sangyo acrylics.\nOnly one colour scheme is included taken from the original kit, and Eduard have taken the opportunity to correct the painting instructions for it:\nW.Nr 110087, 4./NJ3, Kjevik, Norway, 1945\nThe decals are thin and glossy with crystal clear carrier film, but the black ink is touch smeared in places and slightly out of register on the sample sheet. There's a nice set of stencil markings includes, plus the engine instruments mounted on the cowlings. The latter look great and make it all the more regrettable that Eduard didn't also include decals for the cockpit instrument panels.\nDespite a couple of niggles, Eduard's Bf 110G-4 will build into a very impressive model of the famous nightfighter. Even in this \"cut down\" form, it's still quite a complex kit and not really suitable for absolute beginners. However, experienced modellers will really appreciate the level of detail and it should prove a really satisfying build. Recommended.\nPlease remember, when contacting retailers or manufacturers, to mention that you saw their products highlighted here - on AEROSCALE","The Messerschmitt Bf 109 was one of the defining combat aircraft of World War II. The Eduard second-generation of 1:48 scale Bf 109 kits is prolific, and it continues to grow. These are also among Eduard’s best 1:48 scale kits, and they feature great overall quality and detail. In this review, we take a look with their Bf 109G-10 Erla Weekend Edition offering.\nThe Bf 109 was one of the two front-line single-seat German fighters of the Second World War. The prototype flew in 1935 and marked the start of a production run of 33,984 airframes spanning dozens of variants and sub-variants. It was a highly advanced fighter for the mid-1930s, featuring all-metal monocoque construction, a closed canopy, and retractable landing gear. Ten years later, in the final days of the World War II, Bf 109s remained deadly opponents. While many other aircraft came and went, late model variants of the Bf 109, technologically speaking, could hold their own even against the most modern Allied opponents. Losses by then were high, however, owing to pilot attrition, as it proved impossible to replace the experienced, veteran, German aviators.\nThe Bf 109G, also known as the Gustav, was an evolutionary development of the Bf 109F-series. The Bf 109G featured stronger wing structures, the windscreen was bulletproofed, and the fuel tanks were surrounded by light armor. Other changes included tweaks to the outer wheel bay shape and the addition of air inlet scoops on both sides of the forward engine cowling for the newest Daimler-Benz engines. Three different manufacturers produced the Bf 109G-10 at three different facilities: Messerschmitt in Regensburg, Wiener Neustädter Flugzeugwerke (WNF) in Ostmark, and the Erla Machine Works in Leipzig. Each facility manufactured slightly different, idiosyncratic versions of what should have been the same aircraft. The first to go into production was the Erla G-10, which was an interim variant. These G-10s were a standard new build Bf 109G airframe paired with the DB 605 D-2 engine that was destined for the Bf 109K. Since, the -K model was not quite ready for production, these engines were fitted into the Erla-built Gs.\nErla-built Bf 109G-10s further differed from other G-10s visually with an aerodynamic bulge of the engine cowl, but only on the left side. They were missing the full, standard wide cowling (which the Germans evidently called the “Horse’s Ass cowling”) riveted to the rest of the fuselage. Also, the bottom of Erla engine cowls had no bulges under the oil pumps unlike the Regensburg and WNF G-10s. Erlas also had the longer gun troughs on the upper engine cowl. The Erla factory produced 1,709 Bf 109G-10s before the end of the war.\nEduard’s Weekend edition of their 1:48 scale Bf 109G-10 Erla consists of 196 injection molded parts on four dark blue-grey sprues (about 70 parts go unused in this version of the kit), 10 clear parts on one clear sprue, and two decal sheets. The decals provide markings for the following four aircraft:\n- Bf 109G-10 WNr. 490617, Uffz. Gerhard Reiher, 8./JG 3, Alperstad, Germany, November 1944\n- Bf 109G-10, KG(J) 27, Kaubeuren, Germany, May 1945\n- Bf 109G-10 WNr. 150816, JG 300, Bad Langensalza, Germany, April 1945\n- Bf 109G-10 WNr. 491407, Capt. Cesare Marchesi, 3a squadriglia, 1o Gruppo Caccia, Aeronautica Nazionale Repubblicana, Lonate Pozzolo, Italy, March 1945\nStrengths: The retooled Eduard Bf 109s are all superlative kits by any standards. They hold their own against the exquisite Tamiya Bf 109 kit. Further, all the good things that I said about their G-6, G-14, and Regensburg-built G-10 and the G-10 WNF kits (see these and related reviews HERE) apply equally in this case as well. Further, Eduard offers a complete trilogy across ProfiPack and Weekend Edition issues of Regensburg, WNF, and Erla Bf 109G-10 kits in 1:48 scale.\nThis is the “no-frills” Weekend Edition of the Eduard Erla Bf 109G-10, and it differs from the earlier ProfiPACK Edition (reviewed HERE) in that it does not include the photoetched metal detail parts or masking set, and it has a different set of markings.\nTo recap: the unique Erla G-10 features described above are well represented here. The attention to sub-variant details impressive. Additionally, the kit has a range of construction options, including the positionable canopy, separate leading edge slats, flaps, ailerons, elevator, rudder, and radiator flaps. Cockpit detail is relatively good, all the way down to the clear-cast fuel pipe. Instrument dial faces are provided on the decal sheet. Exterior surface details, including the recessed panel lines, rivets, and fasteners are all simply sublime. The builder can position the flaps as desired. While the instructions show the separate elevators going straight-in, you can easily modify them if you want them dropped. There is an even larger mounting pin for the rudder, so to deflect the rudder (if that is the look you are going for) just a tiny bit of work hacking off that mounting pin will get the job done.\nOther details include the Erla canopy, standard and tall rudder, long and short tail wheel, optional 20mm underwing cannon pods, alternative propellers, different main wheel hubs, and choices of oil cooler housings, masts, bomb racks, and an optional centerline 300 liter drop tank. These options are extensive and thorough, though again, not all are used in or are appropriate for this version of the kit. The instructions indicate that only external fuel belly tank(s) are used here.\nThe wet-transfer decals are printed by Eduard and look great with excellent color, resolution, and thin, restrained carrier film. The kit comes with rather diverse and very well-researched schemes to choose from (I really like the unusual Italian option, with over-painted German national insignias on the wings). The second, smaller decal sheet contains a complete set of maintenance stencils for the airplane.\nWeaknesses: I cannot offer any substantive critiques of this kit (but of course 109 experts may be aware of minor issues I might not catch). As is customary for an Eduard Weekend Edition kit, instrument faces and seatbelts are provided as decals. Personally, I prefer them as photoetched or 3-D printed parts, but if a builder is happy with these items in decal form, you are all set.\nOnce again, Eduard provides another consistently great 1:48 scale Bf 109G-10 Erla in this Weekend Edition kit. It is aimed at the scale modeler on a budget or the scale modeler looking for a quick, no-frills build. Still, Eduard also produces a very wide range of additional detail sets for further detailing opportunities should the builder seek those as well.\nWe thank everyone at Eduard for the review sample of this kit. You can visit them on the web at http://www.eduard.comand on Facebook at https://www.facebook.com/EduardCompany.\nScale Modeling News & Reviews Editor\nDetail & Scale"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:cfc4ece4-59ac-46ad-8bcc-7279dd11f6d6>","<urn:uuid:ed4f0e78-a7a7-4255-8b6f-abb397e18003>"],"error":null}
{"question":"Hey climate experts! 🌍 Could you break down the different layers of Earth's atmosphere for me? Looking for a clear list from bottom to top with their key features!","answer":"From bottom to top, the five main layers of Earth's atmosphere are: 1. Troposphere (0-12 km): The densest layer where we live, containing 99% of atmospheric water vapor and most weather phenomena. 2. Stratosphere (12-50 km): Contains the ozone layer which absorbs and scatters solar ultraviolet radiation. 3. Mesosphere (50-80 km): The layer where meteors burn up. 4. Thermosphere (80-700 km): Where auroras occur and satellites operate. 5. Exosphere (700-10,000 km): The outermost layer where molecules can escape Earth's gravity into space.","context":["Layers of Earth's Atmosphere\nThe Atmosphere of the Earth\nThe Earth is the only planet in the solar system with an atmosphere that can sustain life. The envelope-like gases that surround the earth provides the air that we breathe and protects us from the blasts of heat and radiation emanating from the sun. It warms the planet by day and cools it by the night time.\nThe Earth's Atmosphere is made up of a very thin layer of gases and these gases are known as air which surrounds the planet Earth and is retained by Earth's gravity. There would be no life on Earth without the atmosphere. The atmosphere protects life by creating pressure allowing water to exist on Earth’s surface and absorbing ultraviolet solar radiation, warming the Earth’s surface through heat retention and reducing temperature extremes between day and night.\nAtmosphere | Earth's Atmosphere for Life | Know Amazing Facts & Information About Atmosphere\nThere are three major constituents of air which are nitrogen, oxygen, and argon.\nEnergy is transferred between the earth’s surface and the atmosphere via conduction, convection, and radiation.\nConduction, Convection and Radiation\nStructure of The Atmosphere\nFrom the highest to the lowest the five main layers are:\n1. Exosphere – the outer layer of the Earth’s atmosphere.\n700 to 10,000 km (440 to 6,200 miles)\nThis is the upper limit of our atmosphere. It extends from the top of the thermosphere to 10,000 km (6,200 mi). The exosphere is the region where the molecules from the atmosphere can overcome the pull of gravity and escape into space.\n2. Thermosphere – the second highest layer of the Earth’s atmosphere.\n80 to 700 km (50 to 440 miles)\nThe thermosphere starts just above the mesosphere. It extends to 600 km (373 mi) high. The Aurora and satellites occur in this area.\n3. Mesosphere – the third highest layer of the Earth’s atmosphere.\n50 to 80 km (31 to 50 miles)\nThe mesosphere starts just above the stratosphere and extends 85 km (53 mi) high. Meteors burn up in this layer.\n4. Stratosphere – the second lowest layer of the Earth’s atmosphere.\n12 to 50 km (7 to 31 miles)\nThe stratosphere starts just above the troposphere and extends to 50 km (31 mi) high. The ozone layer, which absorbs and scatters the solar ultraviolet radiation, is in this layer.\n5. Troposphere – the lowest layer of the Earth’s atmosphere.\n0 to 12 km (0 to 7 miles)\nThe troposphere starts at earth's surface and extends 8 to 14.5 km (5 to 9 mi). We live in this area. This part of the atmosphere is the most dense. Almost all the weather is in this region. Most clouds appear in this area mainly because 99% of the water vapor in the atmosphere is found here in the troposphere.\nLayers of the Atmosphere Photo\nProperties of the Atmosphere\nThere is a thin envelope of air that surrounds our planet and it is a mixture of gases, each with its own physical properties. The mixture is far from evenly divided. Two elements, nitrogen, and oxygen make up 99% of the volume of air. The other 1% is composed of \"trace\" gases, the most prevalent of which is the inert gaseous element argon. The rest of the trace gases, although present in only minute amounts is very important to life on earth. Two, in particular, carbon dioxide and ozone, can have a large impact on atmospheric processes.\nAnother gas, water vapor, also exists in small amounts. It varies in concentration from being almost non-existent over desert regions to about 4% over the oceans. Water vapor is important to weather production since it exists in gaseous, liquid, and solid phases and absorbs radiant energy from the earth.\nProcesses of the Atmosphere\nAs we learned that water is an essential part of the earth’s system. Three-quarters of the earth’s surface are covered by water. It is important in exchanging the heat and the moisture in the atmosphere.\nThe cycles are as follows:\n1. Most of the water vapor in the atmosphere comes from the oceans.\n2. Most of the precipitation falling over the land finds it way back to the oceans.\n3. About two-thirds returns to the atmosphere via the water cycle.\nThe oceans and the atmosphere interact extensively. The oceans act as a moisture source and a heat source for the atmosphere and a sink (storage).\nEarth's Energy Budget Photo\nHeat and Moisture Effects The Atmosphere\nThe heat and moistures profound effects on the atmospherics processes near and over the oceans. The ocean currents play a significant role in transferring this heat poleward. The northward flowing Gulf Stream, which is a major current transport tremendous amounts of heat poleward and also contributes to the development of many types of weather phenomena.\nThe northward Gulf Stream also helps to warm the climate of nearby locations. The cold southward flowing currents, for example, California’s current help to cool the climate of nearby locations.\nAlmost all of the energy that reaches the earth comes from the sun. It is intercepted firstly by the atmosphere. Then a small part of the energy is absorbed by certain gases such as the ozone and water vapor. Some of the energy is reflected back to space by the clouds and the earth’s surface.\nHeat In Clouds Photo\nClimate and Weather\nEarth is able to support a wide variety of living beings because of its diverse regional climates, which range from extreme cold at the poles to tropical heat at the Equator.\nThe global climate has cooled and warmed throughout history.\nClimate and Weather Photo\n© 2017 Elizabeth J Neal"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:72964b01-d58d-4610-9a41-5e89796cc2cc>"],"error":null}
{"question":"How do both the Living Museum's oral history approach and early intervention for behavioral problems share a common focus on community and family involvement?","answer":"Both approaches emphasize the importance of involving the broader community and family systems. The documents show that early intervention for behavioral problems specifically focuses on the family system as a key component. Similarly, the Living Museum's approach heavily emphasizes community participation and family involvement, particularly through their oral history programs where local community members are actively involved in researching and presenting their own history. Both approaches recognize that addressing challenges (whether behavioral or cultural) requires engaging with the broader social context rather than treating issues in isolation.","context":["These findings suggest the need for early intervention focused on the family system. Careers. Its like a teacher waved a magic wand and did the work for me. PubMed Central 8600 Rockville Pike Journal of Youth and Adolescence, 49(1), 311322. These findings indicate that early prevention and intervention efforts to reduce behavior problems may promote a successful start in working life. It may help that person more than you think. Would you like email updates of new search results? New York, NY: Oxford University Press. o Finding 1: made a distinction between what behaviors vs. what parents found distressing. New York, NY: Guildford. Reciprocal relationships between teacher ratings of internalizing and externalizing behaviors in adolescents with different levels of cognitive abilities. The site is secure. Dart, E. H., Arora, P., Collins, T. A., Stark, K., Cook, C. R., Duong, M. T., McCarthy, C. A., & Doll, B. doi: 10.1136/bmjopen-2012-001942. 2,3 Externalizing problems include traits such as hyperactivity . These studies also aim to disentangle the contribution of global (externalizing and internalizing) and specific (hyperactivity/inattention, opposition/defiance, anxiety, depression) behavior problems on the global and specific aspects of student behavioral, emotional, and cognitive engagement. . ), Contemporary psychometrics (pp. Educational Measurement: Issues and Practice, 38(1), 6377. volume49,pages 23272346 (2020)Cite this article. Similar to children who experience externalizing behaviors, children with internalizing behaviors are more likely to be rejected or disliked by both their fellow peers and adults. If youre too externally focused or over internally focused you tip the scales and put yourself out of balance. Olivier, E., Archambault, I., & Dupr, V. (2020). Internalizing Behaviors include (Williams, 2013): Depression Anxiety Social withdrawal Substance abuse Feelings of loneliness or guilt Feelings of sadness Nervousness and irritability Fearfulness Difficulty concentrating Negative self-talk Internalizing behaviors are not always as easy to observe. A weaker, albeit statistically significant prospective positive association was found between co-occurring internalizing and externalizing behavior problems and substance use and internalizing problems in the absence of externalizing problems protected adolescents against cigarette and marijuana use. 2012 Sep 12;12:772. doi: 10.1186/1471-2458-12-772. Epub 2013 Mar 26. Role of temperament in early adolescent pure and co-occurring internalizing and externalizing problems using a bifactor model: Moderation by parenting and gender. Which is better, internalizing or externalizing your success? What are the jumps called in show jumping? Int J Environ Res Public Health. For instance, children are more likely to exhibit internalizing behavior if they have been victims of various types of physical or mental abuse. Maternal Pre-Pregnancy BMI and Gestational Weight Gain Modified the Association between Prenatal Depressive Symptoms and Toddler's Emotional and Behavioral Problems: A Prospective Cohort Study. Salmela-Aro K, Tang X, Symonds J, Upadyaya K. J Res Adolesc. Informant discrepancies in internalizing and externalizing symptoms in an at-risk sample: the role of parenting and school engagement. Try refreshing the page, or contact customer support. You ask her about them and she tells you that she is cutting in order to deal with her emotions. We investigated whether internalizing (depressive, anxious, somatic complaints) and externalizing (aggressive, rule-breaking) behavior problems in childhood and adolescence were associated with sickness absence (SA) and disability pension (DP) in young adulthood. Other more complex methods for treating internalizing problems include counseling and psychotherapy. Ecological model of school engagement and attention-deficit/hyperactivity disorder in school-aged children. The average internalizing behavior score at baseline was 50.4, and there was no significant change in internalizing behavior problems over time (unstandardized slope = 0.35, p = 0.200). An internalizing disorder ( or internalising disorder) is one type of emotional and behavioral disorder, along with externalizing disorders, and low incidence disorders. Sports participation and psychosocial health: a longitudinal observational study in children. Scand J Public Health. Children and adolescents with Autism Spectrum Disorder (ASD) often show comorbid emotional and behavior problems. Before -. Internalizing behavior can lead to isolation and stress. Campbell, S. B., Halperin, J. M., & Sonuga-Barke, E. J. S. (2014). 1 Externalizing behaviors include physical aggression, verbal bullying, relational aggression, defiance, theft, and vandalism. As a member, you'll also get unlimited access to over 84,000 Longitudinal structural equation modeling. Despite higher mean levels of risk exposure in men overall, AUD appears to be a more severe disorder in women characterized by higher levels of adolescent risk factors and a greater magnitude of the AUD consequences among women than men. Afterwards, we pre-sent our intervention, data, measures, and analytic approach in the method- Ethnic stigma, academic anxiety, and intrinsic motivation in middle childhood. Study 1 was conducted among a sample of elementary school students (n = 1036; 3rd to 6th grade; mean age = 9.94 y.o. Using a developmental cascade model as a guiding framework, we conducted a cross-lagged panel modeling on a sample of 2,844 Korean fourth graders (54% boys and 46% girls) followed over 4 years. provided the data and participated to writing the original and revised manuscript. HHS Vulnerability Disclosure, Help Developing a brief behavior rating scale for progress monitoring of depression in school settings. (2009). Results suggested that externalizing symptoms moderated the association between internalizing symptoms and probability of alcohol, but not marijuana use, and developmental models of substance use that incorporate internalizing symptomology should consider the context of externalizing problems and distinguish probability and amount of use. For externalizing problems we employed two subscales: (a) aggression ( = .90), which contains 21 items that describe openly aggressive behaviors, and (b) delinquency ( = .83), with 15 . The authors declare that they have no conflict of interest. 543560). Political Subcultures: Definition & Examples, The White Bear Problem: Ironic Process Theory, How Social Psychology Relates to Online Interactions, Psychological Disorders and Health: Help and Review, Psychological Treatments: Help and Review, Statistics, Tests and Measurement in Psychology: Help and Review, Neurological Treatment for Psychological Issues, MTTC School Counselor (051): Practice & Study Guide, AEPA Early Childhood Education (AZ036): Practice & Study Guide, DSST Substance Abuse: Study Guide & Test Prep, Praxis Principles of Learning and Teaching: Grades K-6 (5622) Prep, TECEP Abnormal Psychology: Study Guide & Test Prep, Indiana Core Assessments Secondary Education: Test Prep & Study Guide, UExcel Cultural Diversity: Study Guide & Test Prep, GACE School Psychology Test I (105): Practice & Study Guide, Phonological Processes: Definition & Goals, Practical Application: Classroom Management Techniques, Practical Application: Managing Learned Helplessness in Children, Practical Application: Developing Effective Classroom Design, Practical Application: Intrinsic & Extrinsic Motivation in Education, Practical Application: Planning Daily Schedules in the Classroom, Practical Application: Creating a Respectful Learning Environment, Practical Application: Identifying Disciplinary Problems in the Classroom, Practical Application: Culturally Responsive Classroom Management Strategies, Inattention & ADHD: Definition & Explanation, What Is a Developmental Disability? Early Education & Development, 24(8), 11121136. Below are just a few examples of what one might experience when attempting to internalize stress, anxiety, fear, etc: As with internalizing behavior, there are also many examples of externalizing behavior that present themselves when an individual is undergoing great anguish. New York, NY: Springer. These symptoms can vary depending on the individual and situation; however, some common signs are as follows: Internalizing behavior can have a variety of effects on individuals, which range from minor effects to simply take note of, all the way to the need to physically restrain and control the person. (pp. Individuals participating in TCHAD were followed regarding SA and DP during 2001-2013 using nationwide registers. Morin, A. J. S., Arens, A. K., Maiano, C., Ciarrochi, J., Tracey, D., Parker, P. D., & Craven, R. G. (2017). They also have collegiate planning and teaching experience from Central Texas College. Oh Y, Greenberg MT, Willoughby MT; Family Life Project Key Investigators. 2017. More severe examples of this type of behavior can include emotional outbursts, aggressive behavior, and even physical violence under some circumstances. Psychometric properties of the French version of the self-report and teacher Strengths and Difficulties Questionnaire (SDQ). (2012). These cookies track visitors across websites and collect information to provide customized ads. Internalizing and Externalizing Problems were collected using the Youth Self-Report (YSR) and the parent-report Child Behavior Checklist (CBCL) at baseline (age 10-12). Handbook of adolescent psychology (pp. Higher levels of anxious and depressive symptoms in childhood and adolescence were associated with DP in early adulthood despite age at assessment, with the highest risk at age 19-20 years [HR 1.31 (95% CI 1.12-1.53)]. Smith, S. R. (2007). Caci, H., Morin, A. J., & Tran, A. Konold, T., Cornell, D., Shukla, K., & Huang, F. (2017). What are examples of externalized behaviors? This research complies with APAs ethical standards in the treatment of human samples and with the highest ethical standards. official website and that any information you provide is encrypted The individual chooses to, in a way, hold all of their stress inside and attempts to deal with it on their own, as opposed to releasing it outward where others may be affected or become aware of the situation. By clicking Accept All, you consent to the use of ALL the cookies. Journal of School Psychology, 44(2), 87104. Internalizing disorder. Bierman, K. L., & Sasser, T. R. (2014). (2018). Internalizing behavior problems are characterized by inward-directed feelings and include symptoms of depression, anxiety, withdrawal, and somatic complaints, whereas externalizing behavior problems refer to acting-out behaviors directed toward others, such as aggressive and rule-breaking behaviors (Achenbach & HHS Vulnerability Disclosure, Help PubMed 2018 Feb 5;172(2):e174363. Homlong L, Rosvold EO, Bruusgaard D, et al. The teacher-student relationship as a developmental context for children with internalizing or externalizing behaviors. Disclaimer, National Library of Medicine Wang, M. T., & Peck, S. C. (2013). Bidirectional Associations Between Child Sleep Problems and Internalizing and Externalizing Difficulties From Preschool to Early Adolescence. Development and Psychopathology, 29(3), 919928. Is there an immigrant paradox in Canadian elementary students behavioral and social adjustment? A child or an adult who exhibits externalizing behaviors engages in behaviors that harm others as opposed to lashing out at the self (which are known as internalizing behaviors). Do needs for competence and relatedness mediate the risk of low engagement of students with behavior and social problem profiles? 2022 Nov 22;19(23):15442. doi: 10.3390/ijerph192315442. In Study 1, global internalizing behaviors were also associated with lower global and specific cognitive engagement, whereas specific anxiety was associated with lower global and specific emotional engagement. Journal of Youth and Adolescence Functional Behavior Assessment & Analysis | Overview & Steps, Compliance in Psychology | Overview, Techniques & Experiments, Creating a Respectful Learning Environment, Worth Publishers Psychology: Online Textbook Help, Psychology 310: Psychology of Personality, Psychology 301: Industrial/Organizational Psychology, ILTS Social Science - Psychology (248): Test Practice and Study Guide, Social Psychology: Homework Help Resource, Research Methods in Psychology: Help and Review, Introduction to Psychology: Homework Help Resource, Abnormal Psychology: Homework Help Resource, Create an account to start this course today. Inevitably, this dichotomy is neither perfect nor complete. 131430/Fonds de Recherche du Qubec-Socit et Culture, 430-2018-00456/Social Sciences and Humanities Research Council of Canada. The present study examined the nature and timing of relationships between internalizing and externalizing problems as well as the mediating effects of negative self-concept on both. J Can Acad Child Adolesc Psychiatry. provided the data and participated to writing the original and revised manuscript; I.A. Child/adolescent behavioral and emotional problems: implications of cross-informant correlations for . Federal government websites often end in .gov or .mil. Qubec, Qc: Ministre de lducation et de lEnseignement suprieur du Qubec. Children (Basel). Adolescent behavioral, affective, and cognitive engagement in school: relationship to dropout. and K.T.-G. Goodness of fit in structural equation models. Internalizing problems are more common among females, while externalizing problems are more common among males. The causes for an individual directly or indirectly choosing to internalize their problems are as wide-ranging as the situations they find themselves in. Findings In this systematic review and meta-analysis of 87 studies (98 independent samples) including 159 425 children 12 years or younger, greater duration of screen time was weakly but significantly correlated with . A sample of 212 preschoolers aged 3-5 years old was included in this study. Wang, M. T., & Eccles, J. S. (2012). Learning & Individual Differences, 78, No pagination specified. Examining Longitudinal Associations between Externalizing and Internalizing Behavior Problems at Within- and Between-Child Levels.","History of the Museum\nHistory of the Museum\nAustralia’s first ecomuseum, Melboune’s Living Museum of the West is a community museum, operating in the western region of Melbourne in the state of Victoria, Australia.\n(An ecomuseum is a museum focused on the identity of a place, largely based on local participation and aiming to enhance the welfare and development of local communities.There are presently about 300 operating ecomuseums in the world; about 200 are in Europe – source: wikipedia)\nThe Living Museum, as it is more commonly known, was set up in 1984 to address what was then seen as a disadvantaged region, geographically flat and rocky, heavily industrialised with a high migrant population.The ecomuseum concept regards the area researched by a museum as part of the museum itself.\nThe western region covers a large geographical area (see map) west of Melbourne which includes industrial suburbs merging into rural areas. Geologically it sits on an extensive basalt plain with low rainfall. Its population is approximately 500,000 people from approximately 70 different countries.\nMore than 30 % of the population were born in another country. It has in fact given rise to a cultural dynamic that challenges more conventional forms of interpretation.The Living Museum is best known for its outreach programs and close involvement with the community it serves.\nArchived website 1997-2007 »\nOriginal LMW logo\nCommunity participation can take the form of involvement as a volunteer, as a participant in the Museum’s research and oral history programs or through more informal contact.\nFor example, many local historical researchers regularly come to share information or talk about their own research. By depositing copies of their research and publications in the Living Museum’s Resource Centre they provide help for other people doing connected research.\nThe first projects looked at the history of work, the contribution of women in the region’s history and the role of migrants in the culture and heritage of the local region. These first projects focussed on oral history in a bid to involve the local community in the research and presentation of their own history.\nThe Museum has since explored the built heritage of the region, the environment, the Aboriginal Heritage and experimented with the involvement of artists in the presentation of culture and heritage. A book titled ‘Your History Mate’, describes the first decade of the Living Museum’s program and outcomes.\nThe Living Museum is currently working to convert its extensive archives into digital form that can be downloaded and accessed by the public. Hundreds of people worked for thirty years researching, photographing and writing about a wide range of topics to do with the unique history and heritage of the western suburbs of Melbourne. They did this largely within the framework of a particular philosophy of collecting local history which will also be explained to some extent on this website. Over this thirty years the people involved with this museum dealt with a thousand specific projects and scores of special programs. The content of this work gives remarkable insights into the nature of this region and the evolution of Melbourne. It will take some time to digitise this work so bear with us while we bring this story to you.\nThe publications chapter of this website will be regularly updated with new additions of information and downloads."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:79cef474-2550-4e57-a862-be419ed33efa>","<urn:uuid:d593ce6b-32a9-4ce4-b429-4b13d79f84c4>"],"error":null}
{"question":"Could you explain how scholars in late antiquity approached religious identities and beliefs when studying both Islamic and Classical texts, considering both methodological challenges and historical context?","answer":"Scholars recognized that religious identities in late antiquity were not clear-cut, but rather fluid and complex. In Islamic studies, this is evidenced by the examination of how Islam had deep roots in Judaism and how Arabs and Jews were allies. In the Classical context, studies of 4th century figures showed that educated individuals often prioritized social status, friendship, and culture over religious affiliations in their personal relationships. The methodological approach involved examining various types of religious references - formulaic, significant, literary, and educational - though these categories often proved difficult to maintain. Scholars also noted that religious attitudes could vary between historical periods, and that while some religious boundaries existed, most educated individuals maintained a more moderate and pragmatic approach to religious matters.","context":["Patricia Crone (March 28, 1945 – July 11, 2015) was a Danish-American author, Orientalist, and historian specializing in early Islamic history. Crone was a member of the Revisionist school of Islamic studies and questioned the historicity of the Islamic traditions about the beginnings of Islam.\n|Died||July 11, 2015 (aged 70)|\nPrinceton, New Jersey, U.S.\n|Main interests||Islamic studies; Quranic (Islamic) studies; scriptural exegesis; scholarship on Islamic origins|\n|Notable works||Hagarism (with M.A. Cook); Meccan Trade and the Rise of Islam|\nLife and careerEdit\nCrone was born in Kyndeløse Sydmark (south of Kyndeløse) 23 km northwest of Roskilde in Roskilde County, Denmark, on March 28, 1945. After taking the forprøve, or preliminary exam, at University of Copenhagen, she went to Paris to learn French, and then to London where she determined to get into a university to become fluent in English. In 1974 she earned her PhD at the University of London, where she was a senior research fellow at the Warburg Institute until 1977. She was accepted as an occasional student at King's College London and followed a course in medieval European history, especially church-state relations. In 1977, Crone became a University Lecturer in Islamic history and a fellow of Jesus College, Oxford. Crone became Assistant University Lecturer in Islamic studies and fellow of Gonville and Gonville and Caius College, Cambridge in 1990 and held several positions at Cambridge. She served as University Lecturer in Islamic studies from 1992 to 1994, and as Reader in Islamic history from 1994-97. In 1997, she was appointed to the Institute for Advanced Study in Princeton, where she was named as Andrew W. Mellon Professor. From 2002 until her death in 2015, she was a member of the Editorial Board of the journal Social Evolution & History.\nShe died on July 11, 2015, aged 70, from cancer.\nThe major theme of Crone's scholarly life was the fundamental questioning of the historicity of Islamic sources about the beginnings of Islam. Crone's two most known works concentrate on this topic: Hagarism and Meccan Trade. Three decades after Hagarism, Fred Donner called Patricia Crone's work a \"milestone\" in the field of Orientalist study of Islam.\nIn their book Hagarism (1977), Crone and her associate Michael Cook, working at the School of Oriental and African Studies, London at the time, provided a new analysis of early Islamic history. They fundamentally questioned the historicity of the Islamic traditions about the beginnings of Islam. They tried to produce the picture of Islam's beginnings only from non-Arabic sources. By studying the only surviving contemporary accounts of the rise of Islam, which were written in Armenian, Greek, Aramaic and Syriac by witnesses, they reconstructed a significantly different story of Islam's beginnings, compared with the story known from the Islamic traditions. Crone and Cook claimed to be able to explain exactly how Islam came into being by the fusion of various near eastern civilizations under Arabic leadership. Later, Patricia Crone refrained from this attempt of a detailed reconstruction of Islam's beginnings. Yet she continued to maintain the basic results of her work:\n- The historicity of Islamic sources on Islam's beginnings has to be fundamentally questioned.\n- Islam has deep roots in Judaism, and Arabs and Jews were allies.\n- Not Mecca but a different place in north-west Arabia was the cradle of Islam.\nIn her book Meccan Trade and the Rise of Islam (1987), Crone argued that the importance of the pre-Islamic Meccan trade had been grossly exaggerated. Furthermore, she found that Mecca was never part of any of the major ancient trade routes. She also suggested that while Muhammad never traveled much beyond the Hijaz, internal evidence in the Qur'an, such as its description of Muhammad's opponents as \"olive growers\", might indicate that the events surrounding the Prophet took place near the Mediterranean region, and not in Mecca.\nBeginning as a scholar of early military and economic history of the Middle East, Crone's later career focused mainly on \"the Qur’an and the cultural and religious traditions of Iraq, Iran, and the formerly Iranian part of Central Asia\".\n- with Michael Cook, Hagarism: The Making of the Islamic World, Cambridge: Cambridge University Press, first published in 1977; ISBN 0-521-21133-6 Free online version at archive.org\n- with Martin Hinds, God's Caliph: Religious Authority in the First Centuries of Islam (first published 1986); ISBN 0-521-54111-5\n- with Shmuel Moreh, The Book of Strangers: Medieval Arabic Graffiti on the Theme of Nostalgia (1999) Princeton Series on the Middle-East; ISBN 978-1558762152\n- with Fritz Zimmermann, The epistle of Sālim ibn Dhakwān (2001) Oxford/New York: Oxford University Press; ISBN 0-19-815265-5.\n- Slaves on Horses: The Evolution of the Islamic Polity (1980); ISBN 0-521-52940-9\n- Meccan Trade and the Rise of Islam (1987); ISBN 1-59333-102-9\n- Roman, Provincial and Islamic Law : The Origins of the Islamic Patronate (1987, Paperback: 2002); ISBN 0-521-52949-2\n- Pre-Industrial Societies: Anatomy of the Pre-Modern World (2003); ISBN 1-85168-311-9\n- God's Rule: Government and Islam - Six Centuries of Medieval Islamic Political Thought (2004). Columbia University Press; ISBN 0-231-13290-5/ISBN 0-231-13291-3.\n- Medieval Islamic Political Thought (2005). Edinburgh University Press; ISBN 0-7486-2194-6\n- From Arabian Tribes to Islamic Empire : Army, State and Society in the Near East c. 600–850 (2008); ISBN 978-0-7546-5925-9\n- The Nativist Prophets of Early Islamic Iran: Rural Revolt and Local Zoroastrianism (2012). Cambridge University Press; ISBN 978-1107018792\n- Patricia Crone, \"How Did the Quranic Pagans Make a Living?\", Bulletin of the School of Oriental and African Studies, University of London, Vol. 68, No. 3 (2005), pp. 387–399\n- Patricia Crone, \"'Jihad': idea and history\", Open Democracy, April 30, 2007.\n- Patricia Crone, \"What do we actually know about Mohammed?\", Open Democracy, June 10, 2008.\n- \"Library of Congress Authorities\". Library of Congress. Retrieved January 24, 2007.\n- Stille, Alexander (2002-03-02). \"Scholars Are Quietly Offering New Theories of the Koran\". The New York Times. ISSN 0362-4331. Retrieved 2017-10-18.\n- Obituary, nytimes.com; accessed July 23, 2015.\n- \"INSTITUTE APPOINTS NEW FACULTY MEMBERS\". Archived from the original on December 8, 2004. Retrieved June 20, 2012. Cite uses deprecated parameter\n|deadurl=(help)CS1 maint: unfit url (link); \"Dr. Crone, who is presently at Cambridge University, will be in residence at the Institute as of the beginning of the fall term in September 1997\".\n- \"Institute for Advanced Study: Faculty and Emeriti\". Institute for Advanced Study. Archived from the original on March 4, 2007. Retrieved January 24, 2007.\nCrone's work has challenged long-held explanations and provided new approaches for the social, economic, legal and religious patterns that transformed Late Antiquity.\n- Social Evolution & History website; accessed July 17, 2015.\n- Profile, Judith Herrin, opendemocracy.net; accessed July 17, 2015.\n-  Middle East Studies Association Bulletin, Vol. 40, No. 2 (December 2006), pp. 197-199\n- Patricia Crone: Hagarism, 1977; pp. 106, 120 ff., and others\n-  Toby Lester: What is the Koran, in: The Atlantic, issue January 1999\n- Patricia Crone: Hagarism, 1977; p. 24\n- \"Patricia Crone\", Institute for Advanced Study\n- Custers, Martin H. (2016). Al-Ibāḍiyya: A Bibliography, Volume 3 (Second revised and enlarged ed.). Hildesheim-London-N.Y.: Olms Publishing. p. 186.\n- Institute for Advanced Study: Faculty and Emeriti: Patricia Crone\n- Review: God's Rule, Columbia University Press\n- Patricia Crone, \"The Rise of Islam\", Meccan Trade and the Rise of Islam, section beginning at page 231, dealing with rise of Islam as reaction to Byzantine and Persian influence in Arabia, hosted at Fordham University.","Bryn Mawr Classical Review 2014.07.41\nRaffaella Cribiore, Libanius the Sophist: Rhetoric, Reality, and Religion in the Fourth Century. Townsend lectures/Cornell studies in classical philology. Ithaca; London: Cornell University Press, 2013. Pp. x, 260. ISBN 9780801452079. $49.95.\nReviewed by Jan R. Stenger, University of Glasgow (firstname.lastname@example.org)\nLibanius of Antioch (314-93 CE), one of the outstanding orators and teachers of the fourth century, has deservedly aroused growing interest among classical scholars in recent years. Many studies focus on Libanius as a historical figure, on his relationship to the Roman emperors, his position in the civic community and his epistolary network. Libanius’ skill as an accomplished author, so highly valued in late antiquity and the Byzantine era, however, remains somewhat neglected. Thus the monograph by Raffaella Cribiore, a distinguished specialist on both Libanius and ancient education, promises to fill this striking gap by exploring the literary nature of the rhetorician’s output. Based on the Townsend Lectures of 2010, the book is meant to complement Cribiore’s previous study of Libanius’ school by turning to his speeches and letters while excluding his school texts from consideration.1 Three themes stand out: the complex interplay of literature and reality, the public dimension of Libanius’ works, and the sophist’s stance on religious matters. Cribiore raises huge and controversial issues that defy definitive answers. Wisely, Cribiore eschews dogmatic pronouncements but rather highlights the complexity of these questions.\nThe four parts of the book are structured around the key themes. The first chapter (pp. 25-75) addresses the relation of literature to historical reality, with special emphasis on Libanius’ autobiographical Or. 1. By comparing the oration with statements in his letters, Cribiore shows how the more ‘private’ epistolary genre, when used as a corrective, sheds light on the tendentious self-fashioning found in the autobiographical account. After the discussion of Or. 1, the book provides a vast overview of autobiographical and hagiographical texts in late antiquity in order to contextualise Libanius’ self-presentation. This section, however, is not especially illuminating, as most of these works, in particular those on philosophical and spiritual leaders, differ widely in nature from the rhetorician’s effort.\nIn the second chapter (pp. 76-131), Cribiore singles out one striking feature of Libanius’ speeches: his use of invective and slander. Again, the question of the public reception of Libanius’ works comes to the fore. Cribiore here maintains that the publication of these works cannot be determined uniformly but, rather, we have to allow for varying degrees of publicity. In analysing sexual abuse in Libanius’ invectives, Cribiore draws attention to the representation and elicitation of emotions, a point that has been largely overlooked. Further, Cribiore underlines these invectives’ theatrical aspects and points to parallels in classical oratory. She thus makes her readers aware of the fact that Libanius’ displays would have also been received and appreciated by his audiences as entertainment—this should make us cautious in assessing the sophist’s malice.\nWith the third chapter (pp. 132-181), Cribiore moves on to the field of religion. Before discussing Libanius’ personal religious practice, she reviews modern concepts of religion, perhaps more extensively than necessary. Her reading of numerous letters sheds light on Libanius’ ‘belief’ and seeks to establish different types of religious references – formulaic, significant, literary and educational—which, when tested, often collapse. Most interestingly, Cribiore finds that Libanius’ attitudes towards religion vary between historical periods. Under Theodosius, for example, Libanius makes surprisingly few direct references to the contemporary religious turmoil, other than in the period immediately after Julian’s death. In order to contextualise Libanius’ moderate stance on religious matters, Cribiore, in a lengthy treatment, reviews a series of conversions and cases of uncertain religious allegiance in the fourth century. Nothing of this is really original or new, as the view that this period was characterised by fluid identities and beliefs has already become a commonplace.\nChapter four (pp. 182-228) continues this investigation, again drawing attention to the religious and social environment in which Libanius was socialised. Cribiore presents some fascinating figures—especially Libanius’ friend Olympius—that emerge from his correspondence and orations. The examination of these figures’ religious affiliations demonstrates that, at least for educated men in the fourth century, issues other than religion—e.g. social status, friendship and culture—often mattered more in personal relationships. In the remaining part of this chapter Cribiore returns to Libanius’ attitude to the traditional gods. Following an extended discussion of pagan monotheism in late antiquity, she reaches the conclusion that we cannot access his personal beliefs; yet it is clear that before the large audience of his hometown Libanius maintained the image of a traditional pagan.\nThe book concludes with a somewhat erratic appendix on Julian’s teaching edict, which treads a well-trodden path. Contrary to Cribiore’s claim, it has already been argued that the emperor, despite the grey areas between religious groups, sought to create coherence among pagans and draw a sharp line towards Christians.2\nCribiore advances three major observations about which any reader of Libanius’ orations and letters needs to be aware. First, while previous scholarship tended to categorise his output into public and private works, she underlines how elusive these seemingly stable categories are when it comes to specific texts. Even though a definite solution can hardly be reached, it is essential to assess what audience the sophist had in mind for each of his works and how ‘public’ their forum of presentation was. Second, and consequently, the works display clear marks of the audience’s awareness and expectations of genre: Libanius had to take into account the conventions with which his addressees were familiar and what they would have wanted to hear. These factors influenced the shape and content of the texts considerably. Third, Cribiore subscribes to the current prevailing view that there were no clear-cut religious identities and thus Libanius, in his belief, was emblematic of this period. Her major finding, therefore, is that the rhetorician’s oeuvre should not be considered a homogeneous body: each work is carefully adapted to its specific occasion. The interaction between the texts and their audiences thus made an enormous impact on the content of both the speeches and letters and can account for their seeming contradictions.\nAs other recent large-scale projects on Libanius indicate,3 it is—after a period of studies on individual aspects of his life—time to bring together the accumulated findings on Libanius’ career, social standing, religious belief, and rhetorical skills. Cribiore’s monograph thus sits squarely within current scholarship on the Antiochene teacher. The author’s familiarity with research on Libanius leaps from every page. That, however, does not prevent her from making the bold claim that her approach to the literary dimension of his works should be regarded as especially innovative; given that in recent years several publications have been drawing attention to Libanius as a literary author, this claim seems exaggerated. A similar observation holds true for Cribiore’s view of Libanius’ religiosity. It has already been argued that the sophist encapsulated the fuzziness of religious identities and the pragmatic approach to this issue that most of the educated elite in the fourth century displayed. Fanatics like the emperor Julian or Firmicus Maternus were rather the exception that proves the rule.\nThe major asset of Cribiore’s book, then, lies in her impressive and magisterial command of the primary texts, especially Libanius’ correspondence. Time and again she brings letters and speeches to life, yielding important insights into Libanius’ thinking, actions, and oratory that have gone largely unnoticed by scholars. Further, Cribiore deserves praise for challenging long-held views on publication and audience: the extent of public circulation and, thus, the potential impact of each text has to be examined individually (although some patterns can be discerned). Related to this finding, the book demonstrates that, in order to judge Libanius’ views and strategies accurately, it is indispensable to consider the wider context of the political, social, religious and cultural landscape during his lifetime. The value of a seemingly unremarkable missive often comes out only if contextualised in its original setting, illuminating its allusions. Further, Cribiore reminds us of the importance of the likely audience response to speeches as well as letters. In order to better understand how the intended audience would have received Libanius’ thoughts and attitudes we must try to recover with what they were familiar and expected regarding, among other things, literary genres and ethical norms. Overall, the strength of this study is that it sheds light on Libanius' adaptability as an author and it highlights the dynamic nature of his oeuvre.\nThis merit notwithstanding, some weaknesses diminish the effectiveness of Cribiore’s argument. As said in the beginning of this review, she raises big questions that cannot be easily settled. That said, it is still unsatisfactory that the chapters repeatedly end without a clear conclusion, leaving the reader wondering how to make sense of their loose ends. Likewise, although Cribiore claims to investigate the literary side of Libanius’ works, she, in fact, engages in an in-depth discussion and close reading of the texts only occasionally. In a similar fashion (as in her previous book) she makes use of the letters and speeches primarily as evidence for social and religious history. This is particularly striking as she aims to illuminate the interaction of texts and audiences. This interplay needed to be shown in the texts more clearly. Further, Cribiore incorporates a vast amount of historical background information and draws in alleged literary parallels which then make only a minor contribution to our understanding of the Antiochene sophist. In some places, lengthy discussions are even out of place, for instance on Cicero and Roman oratory (pp. 91-93, 106-108).\nDespite her wide-ranging reading of secondary literature, Cribiore’s use of scholarship can be patchy, the limits of which emerge particularly in her discussion of religious matters. She singles out one scholar to argue against, without taking notice of other views relevant to the issue. In doing so, she tends to misrepresent differing views, e.g. when she discusses Sandwell’s argument on Libanius’ religious identity (p. 137-138).4 Cribiore’s selective reading cannot lead to really new results. One might also doubt whether she is right in putting so much emphasis on religious aspects. For one thing, Libanius obviously did not attribute utmost significance to the issue of belief throughout his life, as Cribiore herself makes plain (p. 180). So, in this respect, the focus of the book might be misleading. Further, she seems to downplay late antique attempts to erect religious boundaries and establish clear-cut definitions. To be sure, the existence of fluid identities can hardly be explained away, but, as figures such as Julian, Ephraem and Chrysostom show, religious differences and conflicts made at least some people more conscious of their allegiance. This can also be argued for several passages in Libanius’ works. In this context, it is also necessary to consider Hellenism and ethnic identity, a point that Cribiore fails to connect to her discussion. Finally, some readers might not want to follow her into highly problematic speculations, for instance, about the impact of Athanasius and other Christian models on Libanius (p. 74) or the direct influence of Salutius’ treatise (p. 218-219). These points are unwarranted by the evidence.\nDespite these objections, Cribiore’s well-informed book is a welcome addition to Libanius scholarship. Although it does not offer a completely new picture of the sophist, it addresses major research questions and challenges some established opinions.\n1. R. Cribiore, The School of Libanius in Late Antique Antioch, Princeton, NJ, 2007.\n2. See J. Stenger, Hellenische Identität in der Spätantike, Berlin 2009, pp. 101-110.\n3. H.G. Nesselrath, Libanios: Zeuge einer schwindenden Welt, Stuttgart 2011, appeared too late to be considered by Cribiore; as did O. Lagacherie and P.-L. Malosse (eds.), Libanios: Le premiere humaniste, Alessandria 2011. L. Van Hoof will be editing a collection of essays on Libanius’ life and work.\n4. I. Sandwell, Religious Identity in Late Antiquity, Cambridge 2007."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:ba4063db-a437-4d68-a5df-fd16b28a51e5>","<urn:uuid:d32e3ce4-a841-466e-9e09-53927088017d>"],"error":null}
{"question":"Could you explain how the Data Xplorer's marine mammal detection capabilities work, and what research has revealed about whales' sensitivity to underwater acoustic signals?","answer":"The Data Xplorer detects marine mammals by towing an array of passive hydrophones that record underwater sounds, with automated processing to detect whale and dolphin vocalizations. The system includes multiple sensors like a 360-degree camera, weather station, and multibeam echosounder, transmitting data to command centers via satellite or cell phone connection. Research has shown that whales are highly sensitive to underwater acoustic signals - a study in Massachusetts discovered that humpback whales significantly reduced their singing when exposed to low-frequency signals from acoustic monitoring equipment located 120 miles away. This was the first documented case of whales reacting to man-made sounds from such a great distance, raising concerns about the increasing use of underwater acoustic technologies.","context":["High-tech solution in the works for whale protection: Pacific Navy News\nThe welfare of marine mammals is at the forefront of recent Defense Research and Development Canada (DRDC) equipment testing.\nA team of researchers launched the surfboard-shaped Data Xplorer, a solar-powered ocean drone, over the ocean from Cattle Point in Oak Bay on November 23.\nThe technology, developed by Victoria-based Open Ocean Robotics, is a safe, environmentally friendly and economical way to collect ocean data.\nThe goal is to detect marine mammals by towing an array of passive hydrophones and recording or returning data to a command center. If whales are detected, the navy can use the information to suspend, delay or relocate operations to avoid them.\n“The best strategy to reduce the risk of damage to marine mammals is avoidance, as well as the development of new automated technology to improve monitoring of marine life,” said Major Dugald Thomson, an officer with the Royal Canadian Air Force currently on secondment to DRDC as their Air Liaison Officer.\nThe ocean drone spent the day cruising near Chatham Island, Discovery Island, and Trial Island recording underwater sounds. Automated processing in the vehicle detected whines of baleen whales and whistles of Pacific white-sided dolphins; these detections will be checked manually after the test.\nMaj Thomson says the Data Xplorer has the potential to deploy at sea prior to military exercises. The Royal Canadian Navy would not own or operate the drone; instead, it would outsource a pre-exercise sweep of a specified area to Open Ocean Robotics.\nThe potential data the drone can collect is huge, says Ari Robinson, team leader for Open Ocean Robotics. In addition to the passive data from the sonar array, the Data Xplorer has a 360-degree camera; a weather station which collects atmospheric oceanographic information such as wind speed, temperature, barometric pressure; a wave sensor; multibeam echosounder to collect information on the depth and topography of the ocean; and additional sensors that can be equipped.\nâIt’s satisfying to see something we’ve been working on for so long on water and testing,â says Robinson. âGetting the Data Xplorer to work with businesses and government sectors, get feedback and really deliver is a pretty cool thing. “\nSo far, they have built three prototypes capable of transmitting information to their onshore command center via a satellite uplink or cell phone connection.\nOpen Ocean Robotics works closely with JASCO Applied Sciences to develop autonomous patrol capability. DRDC, meanwhile, is tackling the data problem with a decision support application under development. The application would process and integrate data captured from a multitude of sources, including unmanned platforms such as Data Xplorer, and provide decision support to a ship command team to manage the risks of operations at sea. They plan to prototype the application in-house over the next two years, says Maj Thomson.\n“Once we have finished evaluating and developing all of this, we will have a project that we can hand over to the Air Force and Navy so that they can implement it and bring it to market. . “\nBefore this happens, additional tests on the Data Xplorer must be performed. Phase two trials are scheduled for late February or early March 2022 at the Canadian Forces Marine Experimental Testing Fields in Nanoose Bay.\nThe protection of marine mammals is part of the federal government’s Oceans Protection Plan (2016). It specifically focuses on three endangered cetacean species – Southern Resident Killer Whales, St.Lawrence Belugas and Right Wales North Atlantic, which can be affected by anthropogenic noise such as surveys. earthquakes or the active use of sonar.\nThe military is actively working to mitigate their impact on ocean wildlife. The solution is to automate maritime surveillance, says Maj Thomson, and transmit that information to a central location for instant access by the crew of a ship or aircraft.\nâThis research applies advances in passive sonar technology to alert decision makers when whales are nearby,â says Maj Thomson.\nHe hopes the new technology will be a game-changer for military operations.","Pulsing sounds made by technology used to monitor fish stocks may affect how baleen whales communicate, even at great distances.\nMarine biologists working in Massachusetts waters noticed that humpback whales sang less during the fall of 2006, when a low frequency signal showed up in their recordings. They eventually traced the signal to some acoustic sensing equipment that was part of a scientific study off Maine’s coast, about 120 miles from where they were studying seasonal changes in whale songs in Georges Bank.\nThe scientists recorded more frequent whale vocalizations (listen below) during the same time of year in 2008 and 2009, when the study’s Ocean Acoustic Waveguide Remote Sensing equipment was not being used. This suggests the whales reacted to the low-level sounds by silencing their songs.\n“It’s fascinating that we saw this behavioral response over such a large distance,” said Denise Risch, a marine biologist at the National Oceanic and Atmospheric Association and lead author of research published Jan. 11 in PLoS One.\nPrevious research suggests that nearby underwater noise from ships, airguns, underwater explosions and sonar may cause hearing damage and changes in feeding, mating and communication among marine mammals. But this is the first time whales have been reported reacting to man-made sounds from so far away.\nWhales are extremely social creatures with a remarkable ability to play with sounds. When a male humpback starts to sing, it may keep going for weeks at a time, says Christopher Clark, the director of the Bioacoustics Research Program at Cornell University. Clark, who was not involved in the study but has collaborated with the researchers, studies various species of whales in Mexico and Hawaii.\nIn mating grounds, males sing to attract the ladies and show off to other males, but scientists don’t yet know why they sing in feeding grounds like the ones in Georges Bank.\nThat the artificial acoustic signals, which Clark compared to the sound of a penny whistle, changed the singing behavior of these animals was “pretty dramatic” and a cause for concern because underwater technologies that use acoustics to transfer data are becoming more commonplace.\n“It’s important to be concerned about the whales, but it’s also important to get it right,” said mechanical engineer Nicholas Makris, director of the Laboratory for Undersea Remote Sensing at MIT. Makris was monitoring herring on Geroges Bank in the fall of 2006 with the same acoustic sensing equipment Risch’s team detected near Massachusetts.\nThe researchers don’t know how many whales visited Georges Bank in 2006 when they heard the acoustic monitoring pulses, nor in 2008 and 2009, the two years they used for comparison. Whale populations can vary dramatically each year due to weather conditions and the availability of the herring the whales eat, Makris said.\nWhile underwater noise is “not killing the whales or driving them up on beaches,” Clark said, “it’s man-made junk in the water. We haven’t been good neighbors on that front.”\nListen: Song of a humpback whale\nListen: OAWRS signal\nPhoto courtesy of Hiram Rosales Nanduca\nSound courtesy of Denise Risch and NOAA."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:45e9f720-09a2-4d93-9363-0155744c2ff6>","<urn:uuid:5ce406fd-60c9-4d18-8146-ef76cb1e8d27>"],"error":null}
{"question":"What are the main differences between sustainable agriculture and traditional farming methods in terms of carbon management?","answer":"Sustainable agriculture and traditional farming differ significantly in carbon management. Sustainable agricultural practices aim to minimize natural soil resource depletion and focus on preserving carbon in the soil through methods like planting cover crops and reducing tillage to prevent carbon release into the atmosphere. This approach aligns with practices seen in organic farming, where farmers actively work to pull carbon out of the air and store it in soil through techniques like planting cover-crops and green manures, which naturally capture carbon. For example, in forest management associated with sustainable farming, a 44-acre forest can absorb approximately 55,000lbs of carbon per year, demonstrating how these practices contribute to carbon sequestration.","context":["About the Farm\nUpon this handful of soil our survival depends. Husband it, and it will grow our food, our fuel, and our shelter and surround us with beauty. Abuse it and the soil will collapse and die, taking humanity with it.\n-Vedas, sanskrit scripture, 1500 BC\nWe build soil, health, and community.\nAbout the Farmers:\nWe are a multi-generational family, living and farming together at Daisychain Farm. Daisy and Angus Beal are raising their kids here with the help of Angus’ parents, Jean and Jon Beal, as well as Jean’s sister, Sally Bennett. Just down the road are Daisy’s parents, Scott and Cathy Kemper. All contribute to raising kids and food!\nWhat We Grow:\nWe grow certified organic Strawberries, Raspberries and Apples (plus a few pears, plums, peaches, and pumpkins). We are primarily a You-Pick farm, which means you get to be a part of this bucolic piece of coastal Maine.\nHow We Grow\nOur mission is to help people in Maine eat more delicious, nutrient-dense food, grown in Maine, for the long-term. To that end, we pull carbon out of the air and store it in soil, where it belongs.\nWe are bringing idle land into production and building soil. We grow a diversity of plants, we till very rarely (strawberries) or not at all (raspberries, apples). We keep the soil covered with living plants or mulch. We plant cover-crops and green manures-plants that naturally pull Nitrogen and Carbon out of the air and into our soil. We find waste streams of quality materials like chipped up trees and animal manure. Then we compost them and add them to our fields. That compost starts a virtuous cycle whereby thriving plants feed the soil food web. All this adds organic matter to our ground-meaning literally more life in the soil! More earthworms, tiny creatures, and microbes in the soil means healthier plants and more food-not just this year-but for many decades into the future. Oh yeah, and we don’t knock it all out by spraying persistent synthetic pesticides on your food or the soil.\nHolistic Organic Fruit.\nOur systems go beyond organic standards; they are regenerative-improving the agroecology every year. We focus on building plant health with plenty of good soil and water, plus bio-diversity to avoid overwhelming pest outbreaks from the microscopic level up through the orchard companion plants, birds and voles. Our soils are mineral balanced and full of life-not soluble fertilizers. Nutrient dense means flavor dense. Yum!\nBuilding a farm is more than setting up farm roads, an irrigation system, and an equipment collection. It’s building site specific methods, skill sets and connections in the community. We can farm only because of our relationships with those who eat our fruit and the other farmers with whom we collaborate.\nThe ecological community is just as important as the human one. We aim to work with nature by encouraging beneficial critters-from wasps (which hunt apple pest caterpillars) to birds (which hunt voles) and of course our valuable native pollinators. We keep flowers blooming all season long to feed our beneficial insects. We make nesthouses for kestrel, blue birds and bats. We preserve habitat like standing dead trees and work to improve the health of our forest by removing acres of invasive exotic shrubs.\nForest and Stream Management.\nWe own and steward 44 acres of forest in the Little River watershed. We are committed to improving the health of the forest and water quality of the streams here. We have a professional forest management plan that structures our goals for wildlife habitat, tree health improvement, biodiversity enhancement and control of invasive species. Our forest is part of our working landscape but it is also a refuge for wildlife and a carbon sink. A forest this size and type absorbs approximately 55,000lbs of carbon/year. We work to improve the quality of habitat for trout and other fish, myriad birds, beavers, deer, coyotes, bobcats, bald eagles, hawks, herons, snowshoe hares and more.","In essence, organic agriculture is an agricultural technique that sustains, maintains and improves the quality of the ecosystem. Therefore, it is intimately related to sustainable development.\nOrganic agriculturerefers to an agriculture system that maintains and improves ecological balance. In other words, this cultivation system is based on the use of organic inputs for cultivation.\nTraditional agriculture involves the use of chemical fertilizers, toxic pesticides, etc. That drastically damages the ecosystem. Therefore, this type of agriculture is practiced to produce toxic-free food for consumers and, at the same time, maintain soil fertility and contribute to ecological balance. This type of agriculture allows for sustainable and environmentally friendly economic development.\nSustainable agriculture describes agricultural methods and techniques aimed at minimizing the depletion of natural soil resources. Sustainable agricultural practices aim to preserve higher levels of organic matter, reduce erosion and keep more carbon in the soil. These practices improve soil resilience and long-term health and ultimately lead to higher yields. Because organic agriculture prohibits the use of synthetic pesticides, there is little or no risk of contamination of groundwater and surface water with synthetic pesticides.\nHowever, it is important to mention that when organic farmers use manure fertilizers, manure can also reach bodies of water and contribute to dead zones. In addition, since organic farmers do not use artificial fertilizers, they feed their crops indirectly through the soil, for example by applying fertilizer. FAO research shows that organic agriculture is showing that it can produce better yields during periods of drought. Baby food producers use organic products almost exclusively because organic vegetables and fruits don't normally contain pesticide residues.\nSince organic farmers around the world refrain from using harmful agrochemicals and work as far as possible in harmony with nature, it is clear that these heroes can be considered part of the solution. We have recently created flexible sustainable and cultivable leasing, which allows landlords to sign a lease agreement with their current farmer that includes provisions on sustainable agricultural practices. To determine the role of organic agriculture, a research project was launched with the University of Twente. Since organic farmers do not use chemical fertilizers, they feed their plants indirectly through the soil, for example by applying fertilizer.\nTherefore, it really doesn't matter if an organic product is sold at the farmer's market or in a discount store, if it is sold as “organic”, it must be applied to the strict rules set out in the legislation. So, when it comes to protecting our freshwater supplies, organic agriculture is largely part of the solution. In the U.S. In the US, a farm must be managed through organic practices for 3 years before the first “certified organic” harvest.\nSustainable agricultural practices, such as planting cover crops, help to sequester carbon, and reducing tillage helps prevent the release of additional carbon into the atmosphere. Organic agriculture can contribute to significant socio-economic and ecologically sustainable development, especially in the poorest countries. In organic agriculture, producers must learn to maintain nutrient levels in the soil without synthetic fertilizers and to tackle weeds and insects without herbicides or insecticides. ."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:df26aba0-c728-4ff4-996f-901ed85adb9b>","<urn:uuid:55d8fb1c-226f-486a-a31b-12ee3b7e8b22>"],"error":null}
{"question":"Which receives more annual rainfall: the Central Asian region or the Atacama Desert?","answer":"The Central Asian region receives significantly more rainfall than the Atacama Desert. According to the documents, the Dry Asia region, which includes Central Asia, receives between 2.5 cms to 20 cms (25-200 mm) of rainfall annually, while the Atacama Desert receives only 15 mm (0.6 in) of rainfall per year, making it the world's driest non-polar desert.","context":["World Geography Asia\nWorld Geography Physical\nOn the basis of major physical characteristics the earth can be divided into large continuous land masses known as Continents and the surrounding water bodies known as Ocean. Major continents of the world are Asia, Africa, Europe, North America, South America, Antarctica, and Australia.\nAsia is the world largest continent, having an area of 44,444,100 sq km. It covers 8.8% of the Earth’s total surface area with the population of 4.4 billion which is 60 % of the world’s total population. It is a continent of contrast in relief, temperature, vegetation and people also. Asia is to the east of the Suez Canal, the Ural River, and the Ural Mountains, and south of the Caucasus Mountains and the Caspian and Black Seas. It is bounded on the east by the Pacific Ocean, on the south by the Indian Ocean and on the north by the Arctic Ocean.\nRegional DivisionsAsia can be divided into six physiographic divisions:1. Central Asia: Kazakhstan, Kyrgyzstan, Tajikistan, Turkmenistan, Uzbekistan 2. Eastern Asia: China, Hong Kong, Japan, North Korea, South Korea, Macau, Mongolia, Taiwan Northern Asia: Russia3. South-eastern Asia: Brunei, Myanmar, Cambodia,Indonesia, Laos, Malaysia, Philippines, Singapore, Thailand, Timor-Leste, Vietnam. 4. Southern Asia: Afghanistan, Bangladesh, Bhutan, India, Maldives, Nepal, Pakistan, Sri Lanka. 5. Western Asia: Armenia, Azerbaijana, Bahrain, Cyprus, Georgia, Iran, Iraq, Israel, Jordan, Kuwait, Lebanon, Oman, State of Palestine, Qatar, Saudi Arabia, Syria, Turkey, United Arab Emirates, Yemen.\nMajor Physical DivisionsThe major physical divisions of Asian continent are:1. The Northern Lowlands2. The Central Mountains3. The Central and Southern Plateaus4. The Peninsulas, the Deserts5. The Great River Plains, the Island Groups1. The Northern LowlandsThe Northern Lowlands are the extensive plain areas which comprise of several patch of lowlands of this large continent. The major lowlands are:Great Siberian plainIt extends between the Ural Mountains in the west and river Lena in the east. It is the largest lowland in the world covering an area of 1,200,000 square miles approx. Manchurian PlainIt is the area adjoining Amur river and its tributaries of northern part of China with an area of 135,000 square miles approx. Great Plains of ChinaIt is contributed by two major rivers of China, Hwang Ho and Yangtze river which covers an area of 158,000 square miles approx. Tigris-Euphrates plainsThese are formed by river Ganga 984,000 sq. miles approx.2. The Central MountainsThese are the prominent and extensive mountain ranges which covers the parts of Central Asia. They consist of Pamir and Tian Shan ranges, and extending across portions of Afghanistan, China, Kazakhstan, Kyrgyzstan, Tajikistan, and Uzbekistan. These mountain ranges are designated as biodiversity hot spot by Conservation International which covers several montane and alpine ecoregions of Central Asia. It encompasses several habitat types, including montane grasslands and shrublands, temperate coniferous forests, and alpine tundra. A mountain knot is a junction of two or more mountain ranges.\nThe two main mountain knots in Asia are:• The Pamir Knot is the junction of five mountain ranges they are the Sulaiman, the Hindu Kush, the Kunlun, the Karakoram and the Himalayan ranges. Mount Everest, the highest peak in the world in the Himalayan range. • The Armenian Knot is connected to the Pamir Knot by the Elburz and the Zagros Ranges that originate in the Armenian Knot. The Tien Shan and the Altai are other mountain ranges in Asia. 3. The Central and Southern PlateausPlateaus are the land areas having a relatively that surface considerably raised above adjoining land on at least one side, and often cut by deep canyon. 4. Peninsulas DesertsA peninsula is a mass of land surrounded by water, but attached to the mainland. The Deccan plateau region is also a peninsula. The major peninsulas of Arabia, India and Malay are in southern Asia. The Kamchatka peninsula lies in north- eastern Asia. Asia has some big deserts such as the Gobi, the Takla Makan, the Thar, the Kara-kum and the Rub-al-Khali Deserts. 5. (a) Islands of AsiaAsia also has a cluster of islands, also called an archipelago. An archipelago sometimes called an island group or island chain, which are formed close to each other in large clusters. Indonesia, Philippines, Japan, Andaman and Nicobar are some examples of archipelagos. 5. (b) Drainage of AsiaThe drainage of Asia consists of mighty oceans, extensive seas, lengthy rivers and their tributaries and distributaries, major lakes, etc. Oceans: Asian continent is surrounded by three major ocean from three sides such as • The Pacific OceanIt covers the eastern part of Asia where major rivers of eastern Asia drain, such as Menam Mekong, Xi Jiang, Chang Xiang, Huang Ho and Amur. • The Indian OceanIt covers the southern part of Asia and the major rivers flow into Indian Ocean are Tigris, Euprates, the Indus, the Ganga, Brahmaputra, Irrawaddy, Salween. • The Arctic OceanIt covers the Noth east part of Asia and consists of three major rivers such as Ob, Yenisey and Lena. SeasAs the continent is covered by sea from its three sides, It has also characterised by long stretch of bay and gulf. Major seas contributing Asian Drainage are Sea of Galilee, Andaman Sea, Arabian Sea, Banda Sea, Barents Sea, Bering Sea, Black Sea, Caspian Sea, East Siberian Sea, Java Sea, Kara Sea, Laccadive Sea, Sea of Japan, Sea of Okhotsk. South China Sea and Yellow Sea. LakesMajor lakes of Asia are Lake Baikal, Onega, Ladoga, and Peipus in Russia; Lake Akan, Mashu, Biwa, Shikotsu in Japan; Qinghai Lake, Lake Khanka in China; Dal Lake, Chilka, Vembanada, Pullicat and Sukhna in India; Lake Matano and Toba in Indonesia, etc. ClimateAs a land of Contrast Asia is characterized by varied climatic type on the basis of the temperature and rainfall condition. The rainfall across the continent is highly influenced by Monsoon winds the Asia can be divided into three major climatic zones such as: Monsoon ClimateThe Monsoon Asia is the zone including south and south east Asia and east Asia where the effect of monsoon is prominent. Hence the climatic condition varies according to monsoonal wind flow. After the onset the wind starts moving in the north west direction, hence causing rain over the eastern coast of Indian subcontinent, and parts of south east and east Asia. Moreover the summer spell in India is very hot and dry which trigger the occurrence of additional heavy precipitation owing to tropical cyclones. In winters the central land mass of Asia gets cool more rapidly than the surrounding ocean. This climatic phenomenon starts the flow of cold descending air current in the central Asia which results into generation of high pressure in the heart of Asia. The high pressure starts chasing the low pressure zone present over Indian and Pacific Ocean due to comparatively high temperature. This is called as retreating monsoon or season of winter monsoon. As a result of these phenomena of both onset and retreat of monsoon there is marked difference in the climate of Northern and Southern part of Asia. Dry ClimateThe Dry Asia consists of South West Asia, Central Asia and Mongolia. Latitudinally it varies from tropical desert of Arabian Peninsular to subtropical steppe in Afghanistan and further to mid latitude steppe and desert of Mongolia and Northern China. As compared to other parts of the continent the rainfall is also very less, i.e. 2.5 cms to 20 cms and it is very unpredictable throughout the region. Moreover a Mediterannean climate is experienced over the coastal region which receives winter rainfall. Cold ClimateThe Cold Asia is experienced in maximum part of Russia as an influence of sub-arctic climate. The summer is comparatively mild and lasts for only for four month. The rainfall is also less as compared to other parts of the continent. The annual rainfall accounts for only 50 cms in the coastal areas whereas towards interior, it decreases up to 25 cms.Natural VegetationThere are various types of vegetation found in Asia. For examples: TundraThe Tundra extends to 70°N and with further south extensions on high altitudes (Chersk, Verkhoyansk and Kamachatka mountains). The region is covered by cold, treeless plains with permanently frozen subsoil. The TaigaThe Taiga found in south of tundra is a belt of coniferous forests running across whole of Siberia from west to east reaching Pacific and northern part of Japan. The trees have small leaves, deep roots and thick bark. The species (pine, spruce and fir, etc.) are growing successfully in cold and dry environment. Temperate GrasslandsTemperate GrasslandsThese are elongated, unbroken stretch of the Steppes from Ukraine to Manchuria, which further stretches to several thousand miles in southern Siberia. Region gets low precipitation although cold winters with warm summer. High elevated mountains here are covered with forests. Mediterranean Scrubland is an area of dry land with small bushes and trees In this region summers are hot and dry; the winters mild and moist. Thus vegetations grown here are of small size, short leaves, deep roots, and thick barks to retain moisture. It includes countries of Israel, Lebanon, Syria, Iraq, and the plateaus of Turkey and Iran. Desert VegetationDesert Vegetation types are found in the Arabian Peninsula, the deserts of Tibet, Mongolia, and the desert-like steppe-lands bordering the Caspian Sea. The region is sparsely populated by vegetation. Moisture-combating plants, waxy, deep-rooted or thorny shrubs and sporadic stunted trees grow here. Monsoon VegetationMonsoon Region vegetation varies with the amount of annual rainfall each year in this region. The average range of rainfall varies between 40 inches and 80 inches annually. Mostly, tropical deciduous (shedding leaves seasonally) forests, and those which receive less than 40 inches have savanna and steppe-like vegetation are seen. The monsoon lands have been extensively modified by human settlement and put to cultivation, and little trace of the original vegetation survives. Tropical RainforestTropical Rainforest is the region where evergreen, broad- leafed tall and high-crowned trees are found in this region. Several species having a dense canopy above the floor due to the heavy rainfall received all round the year. The savannas and deciduous trees cover the ground, the subequatorial and the areas that lie in the rain shadow on the leeward slopes. Malaysia and Indonesia, southern Sri Lanka and Java have such vegetation. Plantation tea, rubber, coffee, cocoa, etc. are found here.Mountainous VegetationVegetation in the Mountain area is found on southern and eastern Asia. The higher elevated part is snow covered by meadows. Lower parts are covered by broad-leafed deciduous forests, and on higher ground the coniferous trees occur.\nPeaks of Asia\n• Mount Everest (8848 m), Nepal-Tibet, China border• K2 (8,61,1 m), Pakistan-China• Kangchenjunga (8,586 m), Nepal-Sikkim (India).• Lhotse (8,516 m), Nepal-Tibet, China• Makalu (8,462 m), Nepal-Tibet, China• Cho Oyu (8,201 m), Nepal-Tibet, China• Dhaulagiri (8,167 m), Nepal","What is the driest desert in the world? The 10 driest ranked\nDid you know that roughly one-third of the land on Earth is arid or semi-arid? These areas, known as deserts, can reach incredibly high or low temperatures, receive little to no precipitation, and have sparse vegetation. Because of this, there isn't much life there because plants and animals find the environment hostile. You might not be aware that some deserts are drier than others. So what is the driest desert in the world?\nThe arid climate subtype, also called the desert climate, has a significant excess of evaporation over precipitation. These climates typically have bare, rocky, or sandy surfaces that are dry and don't hold much moisture, so any rainfall they do get quickly evaporates. Even though deserts don't get much rain, sporadic downpours can result in flash floods.\nWhat is the driest desert in the world?\nFrom the Atacama in Chile to the Pelican Point in Namibia, the world has its fair share of barren areas. Discover the ten driest deserts in the world, ranking from the driest.\n1. Atacama – Average rainfall: 15 mm (0.6 in) per year\nThe Atacama is the world's driest non-polar desert. It is also the world's largest fog and true hot desert that receives less precipitation than the polar ones.\nSo, why is the Atacama desert so dry? According to the Global Weather & Climate Center, Atacama's astonishingly low precipitation can be attributed to several factors. They include the subtropical high, a double rain shadow, and the cold ocean current running up South America's west coast.\nThe Atacama desert temperatures are comparatively mild throughout the year, with the average temperature being about 63 degrees F (18 degrees C). But is the Atacama drier than Sahara? Yes, it is. The Atacama is the world's driest place, second only to the polar deserts.\n2. Namib – Average rainfall: 10 mm (0.39 in) per year\nThe Namib is the driest desert in Africa and is found in Namibia and southwestern Angola. It stretches 1,200 miles (1,900 km) along Namibia's Atlantic coast, named after this place.\nEgypt's New Administrative Capital has a 93,440-capacity stadium and plans to host the 2030 World Cup And 2032 Olympics\nBut what causes the Namib desert to be so arid? According to the New World Encyclopedia, aridity is caused by the descent of dry, warm air from the east, cooled by the cold Benguela current along the coast. The warm, dry upper layer keeps the cool, humid air from rising and forming clouds.\n3. The Sahara – Average rainfall: 76 mm (3 in) per year\nThe Sahara is the world's largest hot desert, encompassing nearly all of northern Africa and covering an area of approximately 3.3 million square miles (8.6 million sq km).\nWhy doesn't it rain in the Sahara Desert? According to Live Science, the descending air prevents clouds from forming, resulting in very little rain falling on the land below.\n4. The Taklamakan – Average rainfall: 40 mm (1.57 in) per year\nThe Taklamakan desert is China's hottest, driest, and one of the world's most arid and desolate landscapes. According to NASA, parts of the Tarim Basin, surrounded on three sides by mountain ranges and dried by the resulting rain shadow, receive no more than 10 millimetres (0.4 inches) of rain annually.\n5. The Mojave – Average rainfall: 51 to 152 mm (2 to 6 in) per year\nThe Mojave is North America's driest desert. Its dry summers, which create a harsh environment during the hottest months, are a defining feature. The famous landscape, primarily found in southern Nevada and southeastern California, is home to nearly 2,000 unique plants, including the favourite Joshua trees only found in the Mohave.\nWhy is Mojave so dry? According to Blue Planet Biomes, while some rain falls on the mountains, most of it is evaporated by the hot air before reaching the ground. The rain shadow effect causes the Mojave to be one of the world's driest landscapes.\n6. Death Valley Desert – Average rainfall: 55 mm (2.2 in) per year\nDeath Valley is an arid valley in eastern California, bordering the Great Basin Desert in the northern Mojave. During the summer, it is the hottest place on the planet. According to the National Park Service, Death Valley is North America's hottest and driest place.\nOn 10 July 1913, the world's highest air temperature of 134°F (57°C) was recorded at Furnace Creek.\n7. The Arabian Desert – Average rainfall: 100 mm (3.9 in) per year\nThe Arabian is one of the hottest and largest, with sand covering most of its surface. According to Bayut, the Arabian is hot and dry, reaching 133°F (56.1°C). Among the reasons for this hot and dry climate is the Indian summer monsoon season, which affects the regional weather patterns.\n8. Dasht-e Lut (The Lut Desert) – Average rainfall: 100 mm (3.9 in) per year\nDasht-e Lut is a large salt desert in the Iranian provinces of Kerman, Sistan and Baluchestan. Scientists have measured the surface of its sand at temperatures as high as 70.7 °C (159.3 °F), making it one of the world's driest and hottest locations.\nAccording to NASA, seven years of satellite temperature data show that the Lut is the most desirable place on the planet.\n9. The Thar (Great Indian Desert) – Average rainfall: 100 to 500 mm (4 to 20 in) per year\nThe Thar, also known as the Great Indian Desert, is an arid region in the northwestern Indian subcontinent that spans 200,000 square kilometres in India and Pakistan. According to Britannica, the Thar can reach temperatures of up to 123 °F (51 °C) at its hottest, which is hot most of May and June.\nThe arid subtropical climate is caused by its latitude's persistent high pressure and subsidence. The summer monsoon winds that bring rain to be much of the subcontinent tend to bypass the Thar to the east.\n10. The Chalbi – Average rainfall: 150 mm to 350 mm (6 to 13.8 in) per year\nThe Chalbi desert is Kenya's hottest and driest region. It is a rain-shadow landscape with an annual rainfall of between 150 mm to 350 mm. The part has two dry and two rainy seasons, but rain is erratic, and some years the area barely receives any rainfall.\nAccording to Time and Date, average daytime temperatures in the Chalbi range from 109 F (43 C) to 115 F (46 C), while nighttime temperatures drop to around 57-59 F (14 -15 C).\nWhat is the driest place on Earth?\nAccording to Universe Today, the McMurdo Dry Valleys of Antarctica are the driest place on Earth. For nearly 2 million years, there has been no precipitation in the valley. The lack of rain in this area is due to katabatic winds. Gravity pulls these winds down and away from the valleys because they are so heavy with moisture from the mountains.\nFrequently asked questions\n- What are the 2 driest deserts in the world? According to Pedal Chile, The McMurdo Dry Valleys and the Atacama is the world's driest.\n- Where is the driest desert in the world located? It is located in Antarctica (The McMurdo Dry Valleys).\n- What is the name of the driest desert in the world? The Atacama in Chile is the driest non-polar desert in the world.\n- What is the driest desert in the world? The Atacama and The McMurdo Dry Valleys in Antarctica hold the top positions of the aridest land on Earth.\n- Is Death Valley hotter than the Sahara? No, not really. Despite Death Valley having cold winters, it still has recorded higher temperatures in the summer than the Sahara. However, the Sahara has recorded a consistently higher temperature than Death Valley.\n- What are the 2 hottest deserts in the world? The Lut in eastern Iran and The Sahara in Eastern Morocco hold the record of the hottest desert on Earth.\nWhat is the driest desert in the world? The Atacama in Chile is the hottest and driest place on the planet. Other locations that hold the record include the Sahara, Mojave, and the McMurdo Dry Valleys in Antarctica.\nYen.com.gh published an intriguing article about the world's ten most unique underwater statues. These one-of-a-kind underwater statues will blow you away if you think you've seen everything. They are artificial wonders found worldwide, each with its meaning.\nDiscover what these artistic marvels are and where to find them. Also, learn about the artists who created these magnificent sculptures and their reasons for placing them underwater."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:5bec8c06-2c4c-4512-add0-575be880abdd>","<urn:uuid:82d7158b-1235-46de-9b30-f59016ec0339>"],"error":null}
{"question":"What are the main differences between Expert Advisors and Pine Script in terms of their programming limitations and capabilities?","answer":"Expert Advisors and Pine Script have distinct limitations and capabilities. EAs can execute trades automatically, manage multiple take profit levels, and adjust trailing stops on MT4/MT5 platforms. They can analyze countless price factors simultaneously and run multiple EAs on the same terminal, though only one can communicate with the trading server at a time. On the other hand, Pine Script has specific restrictions including a 64-plot limit, 500-character limit for lines and labels, 40 security calls maximum, 1000 variable cap, and runtime limitations of 40 seconds for premium accounts and 20 seconds for basic accounts. Pine Script was intentionally designed to be simpler, focusing specifically on creating custom indicators and strategies, rather than developing into a full-fledged language with high-end coding capabilities.","context":["Expert Advisors (EAs) are mechanical trading systems that are specifically designed to enable trades to be executed automatically on the MetaTrader 4 and MetaTrader 5 platforms. EAs can be programmed to alert you of a potential trading opportunity and execute trades automatically on your behalf, including automatically adjusting take profit levels, trailing stops and stop loss orders.\nEach Expert Advisor is unique in that it follows different rules to enter and exit the market. One of the primary advantages of an EA is that it never trades on emotion, which is one of the easiest ways to damage your forex trading account during live currency trading. Forex Expert Advisors consistently follow a trading system within pre-programmed parameters. This is one of the many factors that make these programs so appealing to investors.\nThere are several different types of MT4 and MT5 Expert Advisors. Some are specifically designed to stay active on a 24-hour basis while others are designed to only trade news events. The goal of EAs is to automate trading operations and generate a profit at the same time.\nExpert Advisors use technical indicators in order to evaluate current market conditions and place trades. For an EA to work effectively it must be attached to an individual chart on the MT4 or MT5 trading platform. EAs can analyze countless price influencing factors simultaneously in order to make a trading decision. This coupled with a complete lack of emotion ultimately leads to a highly successful trading combination.\nHow do Expert Advisors Work?\nThe Expert Advisor program works by calculating the various indicators that it was designed to use. When the market conditions meet the precise criteria as outlined in the EA’s source code, the EA takes action. Numerous conditions can be assigned to an EA for entering and exiting the market. Further still, conditions can be assigned to manage trades for multiple take profit levels and trailing stops.\nHow to Use Expert Advisors\nTo use an Expert Advisor you will need to install it on the MetaTrader 4 or MetaTrader 5 platforms, which is a fairly simple procedure. If your EA comes with any instructions read them thoroughly before proceeding.\nTo install an EA on MT4 or MT5 you will need to follow these steps:\n- Put the EA in a place where the platform will be able to use it. In most installations of MetaTrader the location is C:\\Program Files\\MetaTrader4-5\\experts. The actual EA is a file that ends with .EX4.\n- When the EA is in the correct location on your PC you will need to restart the MT4/MT5 platform.\n- The EA will appear on the navigation menu on the left once MT4/MT5 starts up again.\nOnce you have installed the EA you will need to attach it to the appropriate chart on MT4 or MT5.\nWhat Types of Expert Advisors are Available?\nThere are many different types of Expert Advisors available. Some of the more common types of EAs are outlined below:\n- Breakout Expert Advisor: A breakout EA opens a trade once the price breaks through predetermined resistance and support levels.\n- News Expert Advisor: News EAs take advantage of news, events, announcements and large price shifts that often occur when financial news is released.\n- Hedge Expert Advisor: An EA that trades two opposing and separate positions, and minimizes losses on one position while it facilitates maximum returns on the good trade.\n- Scalper Expert Advisor: A scalper EA aims to secure small profits once they become available.\nCan More than One Expert Advisor Run on the Same Client Terminal?\nYou can run more than one Expert Advisor on the same MT4/MT5 client terminal, provided the EAs are compatible with one another on the same terminal. However, there are some platform limitations. Only one EA can communicate with the trading server at a given time. If you have multiple EAs actively running on one client terminal and more than one EA tries to communicate with the trading server you will receive the message “Trade context busy” in the logs.","TradingView created Pine Script, a custom scripting language. Users can design their own indicators and use them to run on our servers. Pine script was created as a simple language with a single purpose: creating custom indicators and strategies.\nThe majority of the built-in indicators in TradingView were developed in Pine. We make it a point to keep Pine accessible and understandable for as many people as possible.\nWithout any prior coding knowledge, you may learn Pine Script. However, if you have any prior programming experience in (Python), it will help you soar. Pine Script is used to develop unique trading alerts, techniques, and indicators in order to preserve an edge.\nAlso Read: How to Use Leading and Lagging Indicators for Success\n- What Is Pince Script?\n- Understanding The Pine Script Code\n- Troubleshooting Pine Script\n- How Do I Get Started With The Pine Script?\n- Advantages Of Pine Script\n- Limitations Of Pine Script\n- Bottom Line\nWhat Is Pince Script?\nPine Script is a beginner-friendly programming language developed by TradingView that is used to create custom indicators and technical analysis strategies that you can apply to your live trading chart.\nIn the lower panel of your chart, there is a special editor that is only intended for writing and editing all the code. This editor also has an auto-highlight feature that can be used to draw attention to tooltips, functions, and variables.\nIt automatically highlights the language’s built-in elements (variables and functions). It sends hints in the form of pop-up windows that provide more details when you hover your cursor over particular elements.\nHowever, we do not plan to develop Pine into a full-fledged language with high-end coding capabilities for creating extremely complex tools.\nWe must set restrictions in order to fairly distribute the computational resources used by each script among all of our users because each script uses these resources. We make an effort to impose the fewest restrictions while still upholding the most. So that nobody is negatively impacted by scripts that use an excessive amount of resources, we must maintain a stable platform.\nThe imposed restrictions cover things like the volume of data from additional symbols, runtime, memory consumption, and script size. Pine script syntax and semantics are kept simple as well so that it can effectively handle everyday tasks.\nAs Pine’s development community expands and TradingView users are given more robust and practical tools, we will keep enhancing Pine’s documentation and support to ensure that anybody who wants to understand and use Pine may do so.\nUnderstanding The Pine Script Code\nSuppose you want to create a trading system that relies on MACD setups. In that case, you can write a strategy to test it, then turn it into an indicator to produce alerts so you can trade on them at your leisure, or you can send the alerts to a third-party trade execution bot for market transmission. If this is your goal, be sure to have a peek at the PineCoders Backtesting and Trading alerts.\nPine script has a lot of power because it is very specialized. Pine only needs two lines to accomplish what would require hundreds of lines in other languages. It will be challenging to understand Pine code until you are familiar with a few fundamental ideas regarding Pine and its runtime environment. Pine’s specialization, which gives it power, also implies a high abstraction level.\nPine is available in 4 supported versions, numbered 1 through 4. You may determine what version of Pine is used in the script by looking at a compiler directive in the first line. Knowing which code version you’ll use for writing or studying is crucial since programming jargon and keywords can differ significantly depending on different versions.\nCreate Custom Indicators Using Pince Script\nMany resources are available to teach you Pine. These hold the most weight. Even though you won’t start reading the Reference Manual, you should be aware of its location. Start with the Quickstart Guide before moving on to important sections of the User Manual.\nThe Pine v4 Reference Manual and Pine v4 User Manual are the two main resources for information on Pine. Put your first script into action on a chart by following the directions on the User Manual’s Quickstart Guide page. Then, use the links on that page to become familiar with Pine’s main ideas.\nWhen working with Pine Editor, you’re free to Ctrl/-click on any colored language keyword to open the Reference Manual. By choosing Pine Editor “Keyboard Shortcuts” from the “Help menu,” you can access a list of all keyboard shortcuts directly from the editor. You can access v3/v4 documentation and forums where you can discuss Pine using the editor’s Help menu.\nYou can find links to tools and instructional resources in PineCoders’ FAQ & Code and Resources document.\nThe largest online collection of articles about Pine is located at Kodify.net. They thoroughly examine Pine features in over 200 articles relating to Pine programming and provide methods for carrying out typical tasks in Pine. Kodify is the greatest place to start if you’ve never programmed before.\nThe coders at Pine have material on YouTube. There is a section on” Pine Videos” on our Resources page. A few videos can be found by searching for “pine introductory tradingview.”\nThere are also some articles and blogs on Pine at Backtest Rookies. They provide high-quality content depicting many of Pine programmers’ common goals and interests.\nTroubleshooting Pine Script\nHere are a few techniques for resolving problems with pine coding:\n- Tens of thousands of scripts, many with open-source code, are published on the TradingView indicators. You can explore TV scripts from this page or search for TV scripts by visiting TradingView’s home page, choosing Scripts from the dropdown menu to the left of the search field, and entering your search terms.\n- Go to Google. You’ll frequently land on the TV wiki, stackoverflow.com, backtestrookies.com, getsatisfaction.com, or kodify.net. For improved results when searching for multiple indicators and strategies\n- For multiple indicators on TradingView, enter the following into Google: site:tradingview.com intitle: indicator name.\n- Plan a strategy to solve the issue. Try making small, temporary data plots to gauge your progress. It helps you understand what occurs inside the runtime loop. Without plotting anything in your indicator’s space, use a simple plot(var) or plotchar(var, “var description”, “”) to display the value in the indicator values and in the Data Window. A section on debugging methods is available on PineCoders.\n- Plan strategy scripts to solve the issue. Try making small, temporary data plots to gauge your progress. It helps you understand what occurs inside the runtime loop. Without plotting anything in your indicator’s space, use a simple plot(var) or plotchar(var, “var description”, “”) to display the indicator values in the Data Window. A section on debugging methods is also available for PineCoders.\n- Ask questions on StackOverflow or in the TradingView Pine Script chat. When you have a query, take the time to properly and succinctly describe the issue. Your odds of receiving an answer increase as you improve your explanation. You must learn pine script on your own, as we have all done, and the individuals answering your questions in the various groups won’t teach you Pine; however, they can assist you if you get stuck.\nIs There Any Programming Language Similar To Pince Script\nMicrosoft also implemented the ECMA-262 language standard as JScript.NET, which added support for static typing and traditional object-oriented language features like classes, inheritance, interfaces, and namespaces. Syntactically, TypeScript is very similar to JScript.NET.\nHow Do I Get Started With The Pine Script?\nIt’s very straightforward to use a Pine script, no downloads are required. If you’re not registered with TradingView, visit its official website. On top of your screen is a signup box for e-mails. The registration process is simple by clicking here – click here.\nA free TradingView account can be saved to a cloud platform and allows custom pine script indicator customization for your charts. Once you’re signed up for the Charting platform, open it via the menus. The navigation links are provided for each page. Click.\nHow Can We Modify Pine Script Without Code?\nThe cool thing about the Pine script is the ability to create customized input for a specific strategy or indicator. Take an overview of ATR standard indicators from TradingWeb. You can change length and color by clicking the styles icon in this menu. It can also be achieved with Pine’s research and planning script using its input() function.\nThis example of an input function enables the user to modify the percent change from the previous strategy example. Describe some of the variables sent in the input() function. This time, user input is required. It can have values of 5.5% in this case.\nBacktesting Trading Strategies Using Pine Script?\nLet’s examine a moving average cross strategy using PineScript. Suppose you want to do an average cross-over in a second example by adding the additional parameter. We’ll test it again in the TradingView pine script. To develop strategies, we replace indicators declaration with strategic statements.\nThe next step is to create two moveable averages and assign the data to variable values. We also have an RSI indicator used to confirm the exit or the entry form. These strategies run from main tables to avoid using security. Function(). We’re also looking for a specific crossover condition.\nAdvantages Of Pine Script\nPine Script has amassed more than 10 million users on TradingView, making it a very well-liked trading tool. As a result of the increased demand, more novice and experienced programmers are learning how to use this crucial tool.\nAny of the following is possible with Pine Scripts:\n- Less time is needed for screen time.\n- Lessen your worry about skipping setups when you’re busy.\n- Put your setups through a systematized, rule-based process.\n- Dramatically increase the effectiveness and speed of backtesting.\n- With a click of a button, test trading strategies over many trades in a short period of time.\n- Improve or alter current indicators to meet your needs.\n- Find significant volume or ATR spikes (useful for stocks and crypto).\n- Create unique oscillators and indicators.\n- Directly on your chart, draw helpful information like stop losses and take profits.\n- Automate some of your trading logic or analysis processes.\n- Create tools for trade management (e.g. Trailing stop loss calculation tools).\n- Make alerts out of the existing indicators (e.g. Whenever RSI goes overbought).\n- Improve your knowledge of the price action mechanics.\n- Learn more about the operation of automated trading tools.\n- Take solace in the fact that you have a robot by your side.\nBecause obtaining your own data is required for testing strategies or developing indicators in other languages, Pine Script’s built-in data can be very helpful for traders.\nAdditionally, learning Pine script is incredibly simple because its syntax is more readable than that of other programming languages. In addition, TradingView offers a sizable user base and library with open-source code access, which is a great way for new programmers to learn.\nLimitations Of Pine Script\n- Plots are limited to 64: Be aware that depending on how it is written, one plot statement may consume more than one permitted plot. Each time a color other than the “const” form is used in the plot or text, a plot count is added. The alert condition calls now count as one plot as of Pine script version 4. Except for line() calls, which do not count as plots, all plotting functions count for at least one plot. Plotcandle() and other plotting functions count as 4 plots by default and 5 if you use a series color on the body.\n- Each line and label that is created using label.new() and line.new() is limited to 500 characters.\n- The maximum number of security() calls is 40. However, you can retrieve many more values than 40 by using functions that return tuples.\n- There is a 1000 variable cap.\n- The unknown is the maximum number of lines that can be in a script. 50K compiled tokens is the maximum allowed, although they do not match code lines.\n- Runtime limitations apply if your script takes more than 40 seconds to compile on a premium account and 20 seconds on a basic account.\n- Backtest Due to data restrictions, a premium account can have up to 20k history bars, whereas a basic account can only have up to 5k.\nYou’ll have a good idea of what Pine script can do if you’ve followed along with the examples. Despite some of its limitations, Pine script can be used to build multiple-type indicators. Once you’ve mastered the basics, you’ll be able to quickly code up your own strategy.\nIf you want to expand on it and use third-party libraries, you can always take that logic and program it in another language. Both manual traders and automated trading platforms can benefit greatly from custom and innovative features.\nAnother great feature of Pine script is the in-depth statistics provided for strategies. If you want to enhance your ability to code Pine script, TradingView has a number of materials you can use.\nIs Pine script Like Python?\nSo PineScript can help people with new and old trading needs. The software does not utilize specific coding languages but is similar to coding languages such as Python and Kotlin.\nHow Long Does It Take to Learn Pine Script?\nYou could theoretically get Pine Script for a few days without looking elsewhere. I will show you methods for getting a higher limit on your trading account.\nWhat language Is Pine Script Similar to?\nTypography of Script syntax resembles that of JScript. NET is a new Microsoft application based on the ECMA-262 language standard, which provides support for dynamic typing and classic object-oriented languages such as classes, inherited inheritance interfaces, and namespace.\nShould I Learn Pine Script?\nLearn PineScript from the comfort of your home with no programming expertise or experience required. This can help increase your knowledge and confidence even with a few years of programming experience. PineScript creates custom indicator strategies and trading alert systems for investors seeking a competitive advantage. 9. March 2025."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:3f9b1123-6ed8-4564-8ef6-6dc02bdd5f3c>","<urn:uuid:9d7229b9-4b19-48ee-9450-1ce083ac2543>"],"error":null}
{"question":"Could you describe the ideal growing conditions for both wildflowers in Texas and the cold-hardy cacti that thrive in the Panhandle region?","answer":"Wildflowers in Central Texas should be planted during a brief window in fall, optimally in late October through mid-November. For planting, mixing seeds with compost and vermiculite helps with water retention and seed coverage. For cacti in the Panhandle region, they need lean gritty mineralized soil with good drainage and 6-8 hours of sunlight for best blooms. They prefer acidic rainwater over alkaline city water, and require reduced watering in fall and winter. While afternoon shade can be beneficial for cacti, it's not required.","context":["Hurry up! Those wildflowers won't plant themselves. Huh?\nWe're in prime wildflower planting season here in Central Texas. There's a very brief window for planting in the fall. The optimal time is in the late part of October, but any time in October through mid-November will work.\nHere's a little trick I like to use when broadcasting seeds by hand. I mix the seed in a bucket with some compost and vermiculite (you could also use sand). The vermiculite or sand is a lighter color than the soil and will help you see where you have already spread seeds. Vermiculite has the added bonus of retaining water, which helps the seeds along. The compost adds bulk to the process, so I'm not tempted to spread the seeds to densely, and it helps lightly cover the seeds as well.\nEarly in October I had a idea. My poor hubby nearly ran screaming until I told him tractor work was involved. I didn't know it at the time, but he was secretly working on my birthday present out back when I asked him to use the box blade to cut me a wide, lazy S path right through the middle of the meadow. Bless his heart; he just rolled with the punches and helped me with my project. What a guy!\nIn the picture below, the path separates the meadow into 2 parts. In the space to the left of the path, I plan to grow clumping native grasses and wildflowers.\nTo the right of the path, I constructed a low berm. The berm will allow me to grow cactus and other plants which require better drainage. To the right of the berm on the higher ground, I plan to grow small trees, native perennials, and more grasses.\nHere is a close up of the berm. It may not look like it, but I planted 30 - 1 gallon perennials and dozens of 4 inch plants in the berm and surrounding area. The plants included various yucca, big red sage, wine cup, zexmenia, golden rod, and turk's cap among others.\nI planted 6 trees on the high side of the path where the drainage is better; 3 Mexican buckeye (Ungnadia speciosa), a golden leadball (Leucaena retusa), a Mexican bird of paradise (Caesalpinia Mexicana), and the plant pictured below, the Texas olive (Cordia boissieri).\nThe Texas olive, also called the Mexican olive, has beautiful white flowers that develop into a good sized fruit. Though not a true olive, the fruits are relished by birds and wildlife.\nWhile clearing the weeds from the wildflower planting area, I hit a snag. Yep, that's Bermuda. This area was never planted as a lawn, so I'm thinking the grass must have migrated to this spot from the nearby septic field.\nI started trying to remove the Bermuda by hand, but decided I probably didn't have enough wildflower seed to cover the whole space any way. I think the Bermuda will have to be sprayed or solarized next summer. It seems to be isolated to this one space, which I think may contain a seep spring that fed the grass over the years.\nMowing this area has made it tough to tell if any native species are still hanging in there, but I did find these three survivors. The first is a little bush with yellow flowers. This photo doesn't do it justice. It's really adorable. If you recognize it, please let me know.\nThe other two survivors can be seen in the picture below. The grass on the left is a little bluestem and to it's right is an American beautyberry. Both of these plants are native to this area, so I plan to encourage them along.\nThe wildflower seeds and all the plants were installed just in time for a little storm this past Monday. Now all that's left to do is wait until spring.","It's hard to love a plant that's poised for attack. But hold the disparaging remarks about cactus, please. Thrust into harsh environments and graced with some of the world's most beautiful flowers, cacti did what they could to survive. Beneath the spiny, prickly, thorny, bristly and hurtful exterior, on some, spines so thick they looks more like an inverse pincushion, lies the heart of succulence. Cacti are loved world wide and are among the most collected of plants. It is rare to find a plant person without a potted cactus on their windowsill at least part of their life.\nCacti are natives to the Americas, believed to have originated in South America with the majority of the species inhabiting regions north and south of the hot zone, the moist, humid tropics surrounding the equator. A few forest-type cacti inhabit Central America. It is thought that cacti found outside of the Americas have been introduced by birds, wind or collectors over the centuries. However, one genus, Rhipsalis, has been found growing naturally outside the Americas in KwaZulu-Natal and the Eastern Cape of South Africa.\nCactaceae, the cactus family, includes anywhere from 1500 to 1800 species in about 100 to 122 genera, depending on one's source of information. They are extremely diverse in size and appearance, from the tiny button cactus, Epithelantha bokei, found in the Big Bend region to the giant saguaro, Carnegiea gigantea, the indicator plant of the Sonoran Desert. Cacti are home in the America's arid and semi arid areas that have three climatic seasons: the hot and humid season at the beginning of the year, usually February to June, when the cacti grow. The dry and hot season, July to September, when they flower and bear fruit. And the season of rest, corresponding to our fall and winter. During the period of rest, the weather turns cold, even below freezing. They've adapted to these conditions by drying out and shriveling during the dry hot season. Our cultivation of cacti should replicate these conditions for best results.\nIn North America, Mexico contains the largest number of cacti taxa: 563 species and 48 genera, approximately twice the number of taxa as in the United States. Arizona boasts the highest number of the states with 170 taxa (70 species and 60 varieties) and Texas with 136 taxa comprised of 95 species and 41 varieties. Most of our Texas cacti are native to the Trans-Pecos region of the Chihuahuan Desert. As research and exploration continue, these numbers will change.\nIn fact, it is difficult to be absolute when defining and describing cactus as more and more studies are published. For instance, “cacti do not have leaves” – not true, several genus of cacti do have leaves, particularly in the tropical regions. “All cactus are rooted to the ground” – untrue, as there are forest cerei and epiphetic cacti that attach themselves on rocks and trees by their roots, but are not parasitic, they do not obtain food directly from the plant. “All cacti have spines”, again not true, there are spineless cacti, however all cacti have areoles.\nMy favorite misconception, “cacti do not need water since they grow in deserts” is most certainly false. Although found primarily in arid and semi-arid regions, perhaps it is the lack of competition from more water-thirsty plants that left this land free for them to evolve and survive. Cacti are designed to absorb and store water quickly and for long periods of time. Spines congregate moisture from the air for it to drip to the ground to be absorbed by long spread-out, shallow roots, capturing all available drops.\nOne more misconception, “the plural of cactus is cacti.” Yes and no. It is acceptable to use cactus, cacti and cactuses when referring to the plural. Even the above statement about replicating the cactus growing conditions for best results is not totally true! Studies have shown home grown cactus from seeds in other climates, Europe, for instance, where there is great interest in all plants not European, thrived well in rich soil with ample water and humidity.\nNot all succulents are cacti, but all cacti are succulents -- again, not true. There are a few genera within the cactus family that store so little water they are not considered succulent. The succulent stem, either globose or columnar are built for water storage and minimum evaporation, ribbed or tuberculate (with round nodule or small eminence, as in Mammillaria, and our Panhandle native, Coryphantha missouriensis, the nipple cactus). The ribs and tubercles expand and contract with water availability. The more pronounced the grooves and tubercles, the less water the stem is holding. Likewise, the ribs are well rounded with ample moisture.\nSpines, always emerging from areoles (photo right), are modified leaves, providing protection from herbivores. Spines also provide shading from the sun and deflection of wind to reduce evaporation even further. Spines vary greatly in color, size and shape. Spines sometimes appear as woolly hair, offering the added protection against nighttime cold, or in combination with spines found in mostly columnar-shaped cacti found in high altitudes from Peru to Bolivia and Argentina, the Oreocereus genus.\nIf the shape and form doesn't attract, it is certainly their flowers. Cactus have the most beautiful flowers in the world. In some plants, the flowers are even bigger than the plant itself. Cacti flower every year, after reaching maturity, some species several times a year, including the Thelocactus bicolor, var. bicolor, the Glory of Texas native to Presidio, Brewster and Starr counties near Big Bend National Park. One enthusiastic reference mentioned the similarity of the cholla cactus to early roses in appeal – both have thorny canes and a single period of flowering. Driving a stretch of I-40 between Amarillo and Santa Fe one June, I noticed acres of cane cholla, Opuntia imbricata, in full rose-pink bloom – quite a sight.\nGrowing cactus is similar to growing agave, lean gritty mineralized soil with good drainage and 6 to 8 hours of sunlight for the best blooms. Afternoon shade benefits most plants, but is not required. Cacti prefer acidic water to our alkaline city water, rain water is the best. De-chlorinate a 5 gallon pail of city water by letting it sit in the sun for a day or two, adding one tablespoon of white vinegar or citrus acid to lower the pH if rainwater is not available. Spare the water in fall and winter for better survival or mound the plant to increase soil drainage.\nThe large saguaro and organpipe cactus (pictured above right) are not cold hardy in the Texas Panhandle. The largest cacti that are cold hardy this far north are some of the opuntias, prickly pear cacti, the cylindropuntias, tree chollas, and Echinocereus triglochidiatus, claret cup cactus. Sone of the most colorful are the rainbow cactus, both because of their flowers and their succulent stem or column. Unfortunately, our area is too cold for the large barrel cactus. However, two Echinocactus, E. texensis, the horse crippler, and E. horizonthalonius, the Texas blue barrel cactus (pictured at the right) will winter over, but are not true barrel cactus. Ferocactus hamatacanthus var hamatacanthus, a true barrel cactus and native to the Big Bend region is said to inhabit elevations up to 6000 and sometimes 7500 ft. That could qualify survival in the Texas Panhandle, depending on the individual specimen's providence and soil drainage (quite sharp, I'd image).\nBelow is a list of cacti I believe are reliably cold hardy for Amarillo, or down to zero degrees F. Many of these will survive colder temperatures. Populations of Opuntia fragilis grow natively in several locations in Wisconsin on rock outcrops and sandy soils. I am sure this is not a complete list of cold hardy cacti for the Texas Panhandle.\nCoryphantha echinus, sea urchin cactus, tiny orange flowers, native to the Chiso Mountains in SW Texas. (Pictured at right.)\nCoryphantha missouriensis, nipple cactus\nCoryphantha vivipara, pincushion or ball cactus\nCylindropuntia whipplei, dwarf pencil cholla, plateau cholla, greenish yellow flowers in spring. (Pictured at right.)\nEchinocactus horizonthalonius, Texas blue barrel cactus, perhaps only cold hardy to Zone 7, summer blooming, surviving two winters now at Amarillo Botanical Gardens.\nEchinocactus texensis, Horse crippler\nEchinocereus coccineus, Texas claret cup cactus, very showy\nEchinocereus coccineus x dasyacanthus Texas rainbow hedgehog\nEchinicereus engelmannii, Strawberry hedgehop\nEchinocereus fendlerii, Fendler's hedgehog\nEchinocereus fendleri rectispinus, pink flowered Fendler's hedgehog cactus\nEchinocereus melanacanthus, White spined claret cup\nEchinicereus reichenbachii, and E. reichenbachii var. albispinus, lace cactus; white spined lace cactus\nEchinocereus rigidissimus, New Mexico Rainbow cactus\nEchinocereus triglochidiatus, claret cup cactus, large, very showy. spring blooming. (Pictured right.)\nEchinocereus triglochidiatus gonacanthus\nEchinocereus viridiflorus, green pitaya, green flowered hedgehog. Early spring flowering. (Pictured right.)\nEscobaria vivipara, beehive cactus\nMammillaria heyderi, nipple cactus\nMammillaria meiacantha, pincussion cactus, white flowers with a red stripe, spring flowering. (Pictured at right.)\nOpuntia engelmannii, Engelmann's prickly pear\nOpuntia engelmannii var. linguiformis, cow-tongue prickly pear\nOpuntia fragilis, fragile or brittle prickly pear\nOpuntia humifusa, devil's-tongue, a SE US cactus (also called O. compressa).\nOpuntia imbricata, Cane cactus, tree cactus, cholla\nOpuntia kleiniae, candle cholla\nOpuntia leptocaulis, Tasajillo, pencil cactus, pencil like stems, twiggy structure. Red fruits after flowers, pictured at right in Palo Duro Canyon.\nOpuntia macrorhiza, plains prickly pear\nOpuntia phaeacantha major, Santa Fe prickly pear, brown spined prickly pear, pink flowers in spring. (Pictured right.)\nOpuntia polyacantha, Hunger cactus, very spiny\nPediocactus simpsonii, mountain ball cactus\nAngie Hanna, April 24, 2013"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:01deda36-3611-4d81-947c-79af450c0d8a>","<urn:uuid:e854be5c-bd89-4d5c-8c9b-27cfa92b6ea5>"],"error":null}
{"question":"What's the difference between V. vulnificus infection from eating raw oysters vs getting it through a wound?","answer":"V. vulnificus infection presents differently depending on the mode of transmission. When acquired through eating raw oysters, it causes gastroenteritis with symptoms like vomiting, diarrhea, and abdominal pain, typically developing within 16 hours of consumption. Over 70% of infected individuals develop distinctive bulbous skin lesions. In contrast, wound infections occur when open wounds are exposed to warm seawater containing the bacteria, leading to skin breakdown and ulceration. Both routes can lead to bloodstream infection in immunocompromised individuals, but the initial symptoms and progression differ.","context":["This information has been reviewed and adapted for use in South Carolina by D.C. Smith, Seafood Industry Specialist; P.H. Schmutz, HGIC Food Safety Specialist, and E.H. Hoyle, Extension Safety Nutrition Specialist, Clemson University. (New 12/99.)\nThe organism Vibrio vulnificus causes wound infections, gastroenteritis or a serious syndrome known as \"primary septicema.\" V. vulnificus infections are either transmitted to humans through open wounds in contact with seawater or through consumption of certain improperly cooked or raw shellfish. Studies have shown that V. vulnificus is most likely to be present during warm months. In South Carolina, shellfish harvesting (both commercial and recreational) is generally not permitted between April and October. The harvest season will vary depending on environmental conditions.\nThis bacterium has been isolated from water, sediment, plankton and shellfish (oysters, clams and crabs) located in the Gulf of Mexico, the Atlantic Coast as far north as Cape Cod and the entire U.S. West Coast. Cases of illness have also been associated with brackish lakes in New Mexico and Oklahoma.\nWound infections result from contaminating an existing open wound with seawater harboring the organism, or by cutting part of the body on coral, fish, etc., followed by contamination with the organism.\nAll individuals who consume foods contaminated with this organism are susceptible to gastroenteritis, which usually develops within 16 hours of eating the contaminated food. Over 70 percent of infected individuals have distinctive bulbous skin lesions.\nHigh-Risk Factors: Certain health conditions put you at risk for serious illness or death from V. vulnificus infection. In these individuals, the microorganism enters the blood stream, resulting in septic shock, rapidly followed by death in many cases (about 50 percent). These individuals are strongly advised not to consume raw or inadequately cooked seafood. Some of these conditions have no signs or symptoms so you may not know you are at risk. If you are an older adult, you also may be at increased risk because older people more often have these risk conditions than younger people. Check with your doctor if you are unsure of your risk.\nThese high-risk conditions include:\nIF YOU ARE OR THINK YOU MAY BE IN ANY OF THESE RISK CATEGORIES, YOU SHOULD NOT EAT RAW OYSTERS.\nAvoid exposure of recent or healing wounds, cuts, punctures, or burns, to warm seawater. When swimming or wading, temporarily cover wounds with watertight wrap. The V. vulnificus lives naturally in warm seawater, can enter a person’s wound and, in some cases extend to the bloodstream and cause a potentially fatal illness. The highly invasive nature of this bacterium is cause for special concern.\nConsumers in high-risk categories should avoid consumption of raw shellfish, particularly oysters. Oysters are filter-feeding animals that can concentrate Vibrio bacteria from the water into their system. The bacteria are not a result of pollution; so, although oysters should always be obtained from reputable sources, eating oysters from \"clean\" waters or in reputable restaurants with high turnover does not provide protection. Eating raw oysters with hot sauce or while drinking alcohol does not kill the bacteria, either.\nWhen eating shellfish, particularly oysters, be sure they are properly and thoroughly cooked. Thorough cooking kills the Vibrio bacteria and markedly reduces the risk of becoming ill. However, steaming oysters as is done at an oyster roast does not always provide enough heat to kill all the Vibrio bacteria. Additional heating is necessary to impart a noticeable cooked appearance.\nAvoid cross-contamination of previously cooked shellfish with raw shellfish. A common cause of cross-contamination is storing cooked shellfish in the original container used for raw shellfish, or storing raw and cooked shellfish in the same area.\nDrinking Alcoholic Beverages Regularly & Liver Disease: If you drink alcoholic beverages regularly, you may be at risk for liver disease, and, as a result, at risk for serious illness or death from raw oysters. Even drinking two to three drinks each day can cause liver disease, which may have no symptoms. Liver disease will put you at increased risk for V. vulnificus infection from raw oysters. The risk of death is almost 200 times greater in those with liver disease than those without liver disease.\nAt Restaurants: Order oysters fully cooked. Some states display notices for those at risk. Use them as reminders of how to avoid illness.\nCooking at Home:\nIn the Shell: Cook live oysters in boiling water for three to five minutes after shells open. Use small pots to boil or steam oysters. Do not cook too many oysters in the same pot, because the ones in the middle may not get fully cooked. Discard any oysters that do not open during cooking. Steam live oysters four to nine minutes in a steamer that’s already steaming.\nShucked: Boil or simmer for at least three minutes or until edges curl. Fry in oil for at least three minutes at 375 °F. Broil 3 inches from heat for three minutes. Bake (as in Oysters Rockefeller) for 10 minutes at 450 °F.\nThe culturing of the organism from wounds, diarrheic stools or blood is used to diagnose the illness. The infective dose for gastrointestinal symptoms in healthy individuals is unknown, but for predisposed persons, septicemia can occur with doses of less than 100 total organisms.\nRare! No major outbreaks of illness have been attributed to this organism. Sporadic cases have occurred in South Carolina, becoming more prevalent during the warmer months. To date no fatalities have been related to eating oysters harvested in S.C. waters. Most healthy individuals are not troubled by V. vulnificus infections from water or food. Also, extensive federal and state regulatory programs monitor the production and marketing of raw shellfish to assure product safety. Thus, the V. vulnificus problem is primarily restricted to individuals in the risk categories. These individuals are advised not to eat raw shellfish.\nPage maintained by: Home & Garden Information Center\nThis information is supplied with the understanding that no discrimination is intended and no endorsement of brand names or registered trademarks by the Clemson University Cooperative Extension Service is implied, nor is any discrimination intended by the exclusion of products or manufacturers not named. All recommendations are for South Carolina conditions and may not apply to other areas. Use pesticides only according to the directions on the label. All recommendations for pesticide use are for South Carolina only and were legal at the time of publication, but the status of registration and use patterns are subject to change by action of state and federal regulatory agencies. Follow all directions, precautions and restrictions that are listed.","What is Vibrio vulnificus?\nVibrio vulnificus is a bacterium in the same family as those that cause cholera. It normally lives in warm seawater and is part of a group of vibrios that are called \"halophilic\" because they require salt.\nWhat type of illness does V. vulnificus cause?\nV. vulnificus can cause disease in those who eat eat contaminated seafood or have an open wound that is exposed to seawater. Among healthy people, ingestion of V. vulnificus can cause vomiting, diarrhoea, and abdominal pain. In immunocompromised persons, particularly those with chronic liver disease, V. vulnificus can infect the bloodstream, causing a severe and life-threatening illness characterised by fever and chills, decreased blood pressure (septic shock), and blistering skin lesions. V. vulnificus bloodstream infections are fatal about 50% of the time.\nV. vulnificus can also cause an infection of the skin when open wounds are exposed to warm seawater; these infections may lead to skin breakdown and ulceration. Persons who are immunocompromised are at higher risk for invasion of the organism into the bloodstream and potentially fatal complications.\nHow common is V. vulnificus infection?\nV. vulnificus is a rare cause of disease, but it is also underreported. Between 1988 and 1995, CDC received reports of over 300 V. vulnificus infections from the Gulf Coast states, where the majority of cases occur. There is no national surveillance system for V. vulnificus, but CDC collaborates with the states of Alabama, Florida, Louisiana, Texas, and Mississippi to monitor the number of cases of V. vulnificus infection in the Gulf Coast region.\nHow do persons get infected with V. vulnificus?\nPersons who are immunocompromised, especially those with chronic liver disease, are at risk for V. vulnificus when they eat raw seafood, particularly oysters. A recent study showed that people with these pre-existing medical conditions were 80 times more likely to develop V. vulnificus bloodstream infections than were healthy people. The bacterium is frequently isolated from oysters and other shellfish in warm coastal waters during the summer months. Since it is naturally found in warm marine waters, people with open wounds can be exposed to V. vulnificus through direct contact with seawater. There is no evidence for person-to-person transmission of V. vulnificus.\nHow can V. vulnificus infection be diagnosed?\nV. vulnificus infection is diagnosed by routine stool, wound, or blood cultures; the laboratory should be notified when this infection is suspected by the physician, since a special growth medium can be used to increase the diagnostic yield. Doctors should have a high suspicion for this organism when patients present with gastrointestinal illness, fever, or shock following the ingestion of raw seafood, especially oysters, or with a wound infection after exposure to seawater.\nHow is V. vulnificus infection treated?\nIf V. vulnificus is suspected, treatment should be initiated immediately because antibiotics improve survival. Aggressive attention should be given to the wound site; amputation of the infected limb is sometimes necessary. Clinical trials for the management of V. vulnificus infection have not been conducted. The antibiotic recommendations below come from documents published by infectious disease experts; they are based on case reports and animal models.\n- Culture of wound or haemorrhagic bullae is recommended, and all V. vulnificus isolates should be forwarded to a public health laboratory\n- Blood cultures are recommended if the patient is febrile, has haemorrhagic bullae, or has any signs of sepsis\n- Antibiotic therapy: - Doxycycline (100 mg PO/IV twice a day for 7-14 days) and a third-generation cephalosporin (e.g.,ceftazidime 1-2 g IV/IM every eight hours) is generally recommended\n- Necrotic tissue should be debrided; severe cases may require fasciotomy or limb amputation\n- A single agent regimen with a fluoroquinolone such as levofloxacin, ciprofloxacin or gatifloxacin, has been reported to be at least as effective in an animal model as combination drug regimens with doxycycline and a cephalosporin\n- Children, in whom doxycycline and fluoroquinolones are contraindicated, can be treated with trimethoprim-sulfamethoxazole plus an aminoglycoside\nAre there long-term consequences of V. vulnificus infection?\nV. vulnificus infection is an acute illness, and those who recover should not expect any long-term consequences.\nWhat can be done to improve the safety of oysters?\nAlthough oysters can be harvested legally only from waters free from faecal contamination, even legally harvested oysters can be contaminated with V. vulnificus because the bacterium is naturally present in marine environments. V. vulnificus does not alter the appearance, taste, or odor of oysters. Timely, voluntary reporting of V. vulnificus infections to CDC and to regional offices of the Food and Drug Administration (FDA) will help collaborative efforts to improve investigation of these infections. Regional FDA specialists with expert knowledge about shellfish assist state officials with tracebacks of shellfish and, when notified rapidly about cases, are able to sample harvest waters to discover possible sources of infection and to close oyster beds when problems are identified. Ongoing research may help us to predict environmental or other factors that increase the chance that oysters carry pathogens.\nSome tips for preventing V. vulnificus infections, particularly among immunocompromised patients, including those with underlying liver disease:\n- Do not eat raw oysters or other raw shellfish\n- Cook shellfish (oysters, clams, mussels) thoroughly:\n- For shellfish in the shell, either a) boil until the shells open and continue boiling for 5 more minutes, or b) steam until the shells open and then continue cooking for 9 more minutes. Do not eat those shellfish that do not open during cooking. Boil shucked oysters at least 3 minutes, or fry them in oil at least 10 minutes at 375°F.\n- Avoid cross-contamination of cooked seafood and other foods with raw seafood and juices from raw seafood.\n- Eat shellfish promptly after cooking and refrigerate leftovers.\n- Avoid exposure of open wounds or broken skin to warm salt or brackish water, or to raw shellfish harvested from such waters.\n- Wear protective clothing (e.g., gloves) when handling raw shellfish."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:6cac2f60-5a31-4864-84da-a5b5d87d21af>","<urn:uuid:a59d5bb7-58d4-43f8-9a6d-3c272809f624>"],"error":null}
{"question":"Could you compare the presence of labialized consonants in the Eggon language versus Northwest Caucasian languages in terms of their phonemic contrast?","answer":"In Eggon language, labial-velar consonants like /ɡ͡b/ contrast with sequences of separate consonants like /bɡ/ and /ɡb/, as seen in minimal pairs like 'ɡ͡bu' (to arrive) versus 'ɡba' (to divide). In Northwest Caucasian languages, labialization is phonemically contrastive as a secondary articulation feature, with the labialization having historically shifted from vowels to consonants, leaving some of these languages with only two phonemic vowels.","context":["|Places of articulation|\nLabial–velar consonants are doubly articulated at the velum and the lips, such as [k͡p]. They are sometimes called \"labiovelar consonants\", a term that can also refer to labialized velars, such as [kʷ] and the approximant [w].\nDoubly articulated labial-velars\nTruly doubly articulated labial–velars occur as stops and nasals in the majority of languages in West and Central Africa (for example in the name of Laurent Gbagbo, former president of Ivory Coast; they are found in many Niger–Congo languages as well as in the Ubangian, Chadic and Central Sudanic families), and are relatively common in the eastern end of New Guinea. They include [k͡p, ɡ͡b, ŋ͡m]. To pronounce these, one must attempt to say the velar consonants, but then close their lips for the bilabial component, and then release the lips. Note that, while 90% of the occlusion overlaps, the onset of the velar occurs slightly before that of the labial, and the release of the labial occurs slightly after that of the velar, so that the preceding vowel sounds as if followed by a velar, while the following vowel sounds as if preceded by a labial. Thus the order of the letters in ⟨k͡p⟩ and ⟨ɡ͡b⟩ is not arbitrary, but is motivated by the phonetic details of these sounds.\nThe Yélî Dnye language of Rossel Island, Papua New Guinea, has both labial–velars and labial–alveolar consonants. Labial–velar stops and nasals also occur in Vietnamese, albeit only at the ends of words.\n|k͡p||voiceless labial–velar stop||Logba||ò-kpàyɔ̀||[ò-k͡pàjɔ̀]||'God'|\n|ɡ͡b||voiced labial–velar stop||Ewe||Ewegbe||[ɛβɛɡ͡be]||'the Ewe language'|\nThese sounds are clearly single consonants rather than consonant clusters. The Eggon language, for example, contrasts these possibilities, with /bɡ/ and /ɡb/ both distinct from /ɡ͡b/. Ignoring tone, we have:\n|Single consonant||Two-consonant sequence|\n|pom||to pound||kba||to dig|\n|abu||a dog||bɡa||to beat, to kill|\n|aku||a room||ak͡pki||a stomach|\n|ɡom||to break||ɡ͡bɡa||to grind|\n|k͡pu||to die||kpu||to kneel|\n|ɡ͡bu||to arrive||ɡba||to divide|\nDoubly articulated labial-velars with approximant release\nSome languages, especially in Papua New Guinea and in Vanuatu, combine these labial–velar consonants with a labial–velar approximant release, hence [k͡pʷ], [ŋ͡mʷ]. The extinct language Volow had a prenasalised labial-velar stop with approximant release [ᵑ͡ᵐɡ͡bʷ].\n|k͡pʷ||voiceless labial–velar stop with approximant release||Dorig||rqa||[rk͡pʷa]||'woman'|\n|ŋ͡mʷ||labial–velar nasal with approximant release||Mwesen||ēm̄||[ɪŋ͡mʷ]||'house'|\n|ᵑ͡ᵐɡ͡bʷ||prenasalized voiced labial–velar stop with approximant release||Volow||n-leq̄evēn||[nlɛᵑᵐɡ͡bʷɛβɪn]||'woman'|\nLabial–velar stops also occur as ejective [k͡pʼ] and implosive [ɠ͡ɓ] (often written ⟨ɡ͡ɓ⟩); Floyd (1981) reports a voiceless implosive [ƙ͜ƥ] from Igbo. There may be labial–velar approximants in languages like Japanese. Bilabial clicks are sometimes considered to be labial–velar consonants as well, though the velar articulation is part of the airstream mechanism.\nFor transcribing these sounds ligatures can occasionally be seen instead of digraphs with a tie bar:\nNote that, although such symbols are readily understood, they are not sanctioned by the IPA, and have no Unicode values. They can, however, be specified as the way an OpenType font displays gb and kp digraphs.\n- See p.116 of: François, Alexandre (2005), \"A typological overview of Mwotlap, an Oceanic language of Vanuatu\", Linguistic Typology 9 (1): 115–146, doi:10.1515/lity.2005.9.1.115.\n- See pp.429-430 of: François, Alexandre (2010), \"Phonotactics and the prestopped velar lateral of Hiw: Resolving the ambiguity of a complex segment\", Phonology 27 (3): 393–434, doi:10.1017/s0952675710000205\n- Ladefoged, Peter; Maddieson, Ian (1996). The Sounds of the World's Languages. Oxford: Blackwell. ISBN 0-631-19814-8.","|Sound change and alternation|\n|Places of articulation|\nLabialization is a secondary articulatory feature of sounds in some languages. Labialized sounds involve the lips while the remainder of the oral cavity produces another sound. The term is normally restricted to consonants. When vowels involve the lips, they are called rounded.\nLabialization may also refer to a type of assimilation process.\n- 1 Occurrence\n- 2 Types\n- 3 Transcription\n- 4 Assimilation\n- 5 Examples\n- 6 See also\n- 7 References\n- 8 Bibliography\nLabialization is the most widespread secondary articulation in the world's languages. It is phonemically contrastive in Northwest Caucasian (e.g. Adyghe), Athabaskan, and Salishan language families, among others. This contrast is reconstructed also for Proto-Indo-European, the common ancestor of the Indo-European languages.\nAmerican English has three degrees of labialization: tight rounded (/w/, initial /r/), slight rounded (/ʃ/, /ʒ/, /tʃ/, /dʒ/, coloring /r/), and unrounded, which in vowels is sometimes called 'spread'. These secondary articulations are not universal. For example, French shares the English slight rounding of /ʃ/, /ʒ/ while Russian does not have slight rounding in its postalveolar fricatives (/ʂ ʐ ɕ ʑ/).\nOut of 706 language inventories surveyed by Ruhlen (1976), labialization occurred most often with velar (42%) and uvular (15%) segments and least often with dental and alveolar segments. With non-dorsal consonants, labialization may include velarization as well. Labialization is not restricted to lip-rounding. The following articulations have either been described as labialization, or been found as allophonic realizations of prototypical labialization:\n- Labial rounding, with or without protrusion of the lips (found in Navajo)\n- Labiodental frication, found in Abkhaz\n- Bilabial frication, found in Ubykh\n- Bilabial trill, found in Ubykh\n- Complete bilabial closure, [d͡b, t͡p, t͡pʼ], found in Abkhaz and Ubykh\n- \"Labialization\" (/w/, /ɡʷ/, and /kʷ/) without noticeable rounding (protrusion) of the lips, found in the Iroquoian languages. It may be that they are compressed.\n- Rounding without velarization, found in Shona and in the Bzyb dialect of Abkhaz.\nEastern Arrernte has labialization at all places and manners of articulation; this derives historically from adjacent rounded vowels, as is also the case of the Northwest Caucasian languages. Marshallese also has labialization at all places of articulation except for coronal obstruents.\nIn North America, languages from a number of families have sounds that sound labialized (and vowels that sound rounded) without participation of the lips. See Tillamook language for an example.\nIn the International Phonetic Alphabet, labialization of velar consonants is indicated with a raised w modifier [ʷ] (Unicode U+02B7), as in /kʷ/. (Elsewhere this diacritic generally indicates simultaneous labialization and velarization.) There are also diacritics, respectively [ɔ̹], [ɔ̜], to indicate greater or lesser degrees of rounding. These are normally used with vowels, but may occur with consonants. For example, in the Athabaskan language Hupa, voiceless velar fricatives distinguish three degrees of labialization, transcribed either /x/, /x̹/, /xʷ/ or /x/, /x̜ʷ/, /xʷ/.\nIf precision is desired, the Abkhaz and Ubykh articulations may be transcribed with the appropriate fricative or trill raised as a diacritic: [tᵛ], [tᵝ], [tʙ], [tᵖ].\nFor simple labialization, Ladefoged & Maddieson (1996) resurrected an old IPA symbol, [ ̫], which would be placed above a letter with a descender such as ɡ. However, their chief example is Shona sv and zv, which they transcribe /s̫/ and /z̫/ but which actually seem to be whistled sibilants, without necessarily being labialized. Another possibility is to use the IPA diacritic for rounding, distinguishing for example the labialization in English soon [s̹] and [sʷ] swoon. The open rounding of English /ʃ/ is also unvelarized.\nLabialization also refers to a specific type of assimilatory process where a given sound become labialized due to the influence of neighboring labial sounds. For example, /k/ may become /kʷ/ in the environment of /o/, or /a/ may become /o/ in the environment of /p/ or /kʷ/.\nIn the Northwest Caucasian languages as well as some Australian languages rounding has shifted from the vowels to the consonants, producing a wide range of labialized consonants and leaving in some cases only two phonemic vowels. This appears to have been the case in Ubykh and Eastern Arrernte, for example. The labial vowel sounds usually still remain, but only as allophones next to the now-labial consonant sounds.\n- labialized voiceless alveolar stop [tʷ] (in Archi, Abkhaz, Lao, Paha, Ubykh)\n- labialized voiced alveolar stop [dʷ] (in Archi, Abkhaz, Ubykh)\n- labialized voiceless velar stop [kʷ] (in Abaza, Abkhaz, Adyghe, Kabardian, Taos, Chipewyan, Hadza, Gwich’in, Tlingit, Akan, Nez Perce, Archi, Cantonese, Wari’, Chaha, Dahalo, Hausa, Igbo, Italian, Lao, Latin, Nahuatl, Paha, Portuguese, Thai, Tigrinya, Hiw, Ubykh)\n- labialized voiced velar stop ( [ɡʷ] (in Abaza, Abkhaz, Adyghe, Akan, Archi, Chaha, Dahalo, Hausa, Oowekyala, Hadza, Igbo, Gwich’in, Kabardian, Paha, Portuguese, Tigrinya, Ubykh)\n- labialized voiceless uvular stop ( [qʷ] (in Abaza, Abkhaz, Adyghe, Kabardian, Paha, Tlingit, Nez Perce, Ubykh)\n- labialized pharyngealized voiceless uvular stop [qˤʷ] (in Archi Ubykh)\n- labialized voiced uvular stop ( [ɢʷ] (in Oowekyala, Kwak'wala, Tsakhur)\n- labialized glottal stop ( [ʔʷ] (in Adyghe, Kabardian, Lao, Tlingit)\n- labialized voiceless bilabial stop ( [pʷ] (in Chaha, Paha)\n- labialized voiced bilabial stop ( [bʷ] (in Chaha, Paha)\n- labialized prenasalized voiced bilabial plosive [ᵐbʷ] (in Tamambo)\n- labialized voiceless labio–velar stop [k͡pʷ] (in Dorig, Mwotlap)\n- labialized prenasalized voiced labial–velar stop [ᵑɡ͡bʷ] (in Volow)\n- Sibilant affricates\n- labialized voiceless alveolar affricate [tsʷ] (in Adyghe, Archi, Lezgian, Tsakhur)\n- labialized voiced alveolar affricate [dzʷ] (in Adyghe, Dahalo)\n- labialized voiceless palato-alveolar affricate [tʃʷ] (in Archi, Abaza, Adyghe, Paha, Aghul, German)\n- labialized voiced palato-alveolar affricate [dʒʷ] (in Abaza, Aghul, Tsakhur, German)\n- labialized voiceless alveolo-palatal affricate [tɕʷ] (in Abkhaz, Akan, Ubykh)\n- labialized voiced alveolo-palatal affricate [dʑʷ] (in Abkhaz, Akan, Ubykh)\n- labialized voiceless velar affricate [kxʷ] (in Navajo)\n- labialized voiceless uvular affricate [qχʷ] (in Kabardian, Lillooet)\n- labialized voiceless alveolar sibilant [sʷ] (in Archi, Lao, Lezgian)\n- labialized voiced alveolar sibilant [zʷ] (in Archi, Tsakhur, Lezgian)\n- labialized voiceless palato-alveolar sibilant [ʃʷ] (in Archi, Abaza, Abkhaz, Adyghe, Paha, Aghul, Ubykh)\n- labialized voiced palato-alveolar sibilant [ʒʷ] (in Archi, Abaza, Abkhaz, Adyghe, Aghul, Ubykh)\n- labialized voiceless retroflex sibilant [ʂʷ] (in Bzhedug)\n- labialized voiced retroflex sibilant [ʐʷ] (in Bzhedug)\n- labialized voiceless alveolo-palatal sibilant [ɕʷ] (in Abkhaz, Ubykh)\n- labialized voiced alveolo-palatal sibilant [ʑʷ] (in Abkhaz, Ubykh)\nCentral non-sibilant fricatives\n- labialized voiceless bilabial fricative [ɸʷ]\n- labialized voiced bilabial fricative [βʷ] (in Tamambo)\n- labialized voiceless labiodental fricative [fʷ] (in Hadza, Chaha)\n- labialized voiced labiodental fricative [vʷ])\n- labialized voiceless dental fricative [θʷ] (in Paha)\n- labialized voiced dental fricative [ðʷ] (in Paha)\n- labialized voiceless palatal fricative [çʷ] (in Akan)\n- labialized voiceless velar fricative [xʷ] (in Abaza, Adyghe, Avestan, Chaha, Kabardian, Oowekyala, Taos, Navajo, Tigrinya, Lillooet, Tlingit)\n- labialized voiced velar fricative [ɣʷ] (in Abaza, Navajo, Lillooet, Gwich’in)\n- labialized voiceless uvular fricative [χʷ] (in Abkhaz, Adyghe, Archi, Kabardian, Lillooet, Tlingit, Wari’, Chipewyan, Oowekyala, Ubykh)\n- labialized pharyngealized voiceless uvular fricative [χˤʷ] (in Abkhaz, Archi, Ubykh)\n- labialized voiced uvular fricative [ʁʷ] (in Abkhaz, Adyghe, Chipewyan, Kabardian, Ubykh)\n- labialized pharyngealized voiced uvular fricative [ʁˤʷ] (in Archi, Ubykh)\n- labialized voiceless pharyngeal fricative [ħʷ] (in Abaza, Abkhaz)\n- labialized voiced pharyngeal fricative [ʕʷ] (in Abaza, Lillooet)\n- labialized voiceless alveolar lateral fricative [ɬʷ] (in Dahalo)\n- labialized voiceless velar lateral fricative [ʟ̝̊ʷ] (in Archi)\n- labialized bilabial nasal [mʷ] (in Chaha, Paha, Tamambo)\n- labialized palatal nasal [ɲʷ] (in Akan)\n- labialized velar nasal [ŋʷ] (in Akan, Avestan, Lao, Hiw)\n- labialized labial-velar nasal [ŋ͡mʷ] (in Dorig, Mwotlap)\n- labialized alveolar lateral approximant [lʷ] (in Lao)\n- labialized palatal approximant [ɥ] [jʷ] (in Abkhaz, Akan, French, Mandarin, Paha)\n- Labio-velar approximant (voiced) [w] (widespread; in every above-mentioned language, as well as e.g. Arabic, English, Korean, Vietnamese)\n- Voiceless labio-velar approximant [ʍ] (in certain dialects of English)\n- nasal labialized velar approximant [w̃]\n- labialized postalveolar approximant [ɹ̠ʷ] (found in many dialects of English)\n- labialized bilabial ejective [pʷʼ] (In Adyghe)\n- labialized alveolar ejective [tʷʼ] (in Abkhaz, Adyghe, Ubykh)\n- labialized velar ejective [kʷʼ] (in Abaza, Abkhaz, Adyghe, Archi, Kabardian, Tlingit, Ubykh)\n- labialized palato-alveolar ejective fricative [ʃʷʼ] (in Adyghe)\n- labialized uvular ejective [qʷʼ] (in Abaza, Abkhaz, Archi, Hakuchi, Tlingit, Ubykh)\n- labialized pharyngealized uvular ejective [qˤʷʼ] (in Archi, Ubykh)\n- labialized alveolar ejective affricate [t͡sʷʼ] (in Archi)\n- labialized palato-alveolar ejective affricate [t͡ʃʷʼ] (in Abaza, Archi)\n- labialized alveolo-palatal ejective affricate [t͡ɕʷʼ] (in Abkhaz, Ubykh)\n- labialized velar lateral ejective affricate [k͡ʟ̝̊ʷʼ] (in Archi)\n- labialized velar ejective fricative [xʷʼ] (in Tlingit)\n- labialized uvular ejective fricative [χʷʼ] (in Tlingit)\n- Labio-palatalization (◌ᶣ)\n- Crowley, Terry. (1997) An Introduction to Historical Linguistics. 3rd edition. Oxford University Press.\n- Ladefoged, Peter; Maddieson, Ian (1996). The Sounds of the World's Languages. Oxford: Blackwell. ISBN 0-631-19814-8.\n- Ruhlen, M. (1976), A Guide to the Languages of the World, Stanford University Press"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:f6e8d6e4-d197-4f5d-9e39-3ec0d3e48018>","<urn:uuid:b6f3b9d5-e9cf-412b-9197-bd735ce05698>"],"error":null}
{"question":"What's the link between iron transport proteins in Rhizopus oryzae and the industrial enzyme market? How do both relate to global microbial applications?","answer":"The iron transport protein rFTR1 is crucial for Rhizopus oryzae growth and virulence, while microorganisms are the most common source of industrial enzymes in the global market. Specifically, rFTR1 is essential for iron uptake in Rhizopus oryzae, which is significant since this organism can produce industrial enzymes commercially. The global industrial enzymes market, valued at US$ 10.6 Billion in 2020, heavily relies on microorganisms as the primary source for enzyme production across various applications including food, biofuel, and specialty industries.","context":["|Ibrahim, Ashraf -|\n|Gebremariam, Teclegiorgis -|\n|Lin, Lin -|\n|Luo, Guanpinksheng -|\n|Husseiny, Mohamed -|\n|Fu, Yue -|\n|French, Samuel -|\n|Edwards, JR., John -|\n|Spellberg, Brad -|\nSubmitted to: Molecular Microbiology\nPublication Type: Peer Reviewed Journal\nPublication Acceptance Date: May 17, 2010\nPublication Date: June 9, 2010\nRepository URL: http://hdl.handle.net/10113/47305\nCitation: Ibrahim, A.S., Gebremariam, T., Lin, L., Husseiny, M.I., Skory, C.D., Fu, Y., French, S.W., Edwards, Jr, J.E., Spellberg, B. 2010. The high affinity iron permease is a key virulence factor required for Rhizopus oryzae pathogenesis. Molecular Microbiology. 77(3):587-604. Interpretive Summary: This research demonstrates the importance of a protein involved in iron uptake in the fungus Rhizopus, which has broad interest to the industrial, agricultural, and medical community. Isolates of this organism have the ability to synthesize enzymes and chemicals (e.g. lactic acid or fumaric) on a commercial scale, but are also responsible for food and agricultural crop spoilage and opportunistic (i.e. will not affect healthy individuals) infections. Rhizopus can only grow if it is able to obtain iron from its surroundings using specific transporters that bring the iron into the cell. Understanding how this process works is critical to controlling growth of the organism. This work focused on a specific transport protein called rFTR1 that appears to be the principal mechanism for importing iron. Deletion of the gene required to make this protein prevented growth of the fungus. Additionally, decreasing the amount of this protein had a direct correlation on the ability to take up iron. The results of this study provide valuable information that will be of interest to clinicians and scientists; and are expected to provide new targets for controlling the growth of this important fungus.\nTechnical Abstract: Rhizopus oryzae is the most common cause of mucormycosis, an angioinvasive fungal infection that causes a >/=50% mortality rate despite first-line therapy. Clinical and animal model data clearly demonstrate that the presence of elevated available serum iron predisposes the host to mucormycosis. The high affinity iron permease gene (rFTR1) is required for R. oryzae iron transport in iron-depleted environments, such as those found in the host during infection. To define its role in R. oryzae virulence, we sought to abrogate the function of rFTR1 by gene disruption or by RNA interference. Here we demonstrate that rFTR1 is required for full virulence of R. oryzae in mice. We show that rFTR1 is expressed during infection in diabetic ketoacidotic (DKA) mice. In addition, rFTR1 could be disrupted by double cross-over homologous recombination, but multinucleated R. oryzae could not be forced to segregate to a homokaryotic null allele, regardless of the availability of extracellular iron. Nevertheless, a reduction in the relative copy number of functional rFTR1 demonstrated that it was indispensible for growth, especially in iron-depleted environments. Reduction of the relative copy number of rFTR1 or inhibition of rFTR1 expression compromised the ability of R. oryzae to acquire iron in vitro and reduced its virulence in DKA mice. Importantly, passive immunization with anti-rFtr1p immune sera significantly protected DKA mice from infection with R. oryzae. Thus rFTR1 is a crucial virulence factor for R. oryzae, and passive immunotherapy against rFtr1p is a promising strategy to improve outcomes of these deadly infections.","Enzymes are biological catalysts; they accelerate a chemical reaction. Globally, enzymes are used in industries like Biofuel, cleaning products/detergents, food, animal feed, textile and speciality. Further, the market for industrial enzymes is continuously rising, owing to the growing need for sustainable solutions. Advancement in biotechnology, especially in protein engineering, has also brought in new probiotic products, driving the industrial enzymes market to the next level. According to Renub Research, the Global Enzymes Market is projected to reach US$ 17.4 Billion by 2027.\nindustrial enzymes market\nCarbohydrases, Amylases, Cellulases, Proteases and Lipases are major variants existing in the global Enzymes Market. By Types, these enzymes are used in numerous industries. For instance, the food industry primarily uses carbohydrases in baking for manufacturing fruit juices, winemaking and cheese manufacturing. Similarly, other applications of Carbohydrases are detergents, textiles & leather, and bioethanol. Carbohydrases also have added advantages to various industrial applications due to their low cost, less time & space consumption, and ease in modifying and optimizing the process. The Industrial Enzymes Market Size was estimated at US$ 10.6 Billion in 2020.\nBesides, protease enzymes are widely used in the Speciality Industries. The Speciality Industry uses protease enzymes in a large quantity in the manufacturing of medicines. Protease enzymes treat multiple diseases such as lungs, heart, eye abnormalities, digestive tract, skin ulcers, and soreness. Thus, the Speciality Industry is expected to fuel the demand for protease enzymes in the foreseeable future. Also, with the help of developing science and technology, protease enzymes are used in the several bio-meditation process and leather treatments.\nFurthermore, the Industrial Enzymes Market in North America is influenced by rising demand for enzymes from the food industry and significantly has a large consumer base by countries in the region. Nonetheless, the market in Asia-Pacific is owing to sound growth opportunities induced by soaring demand for carbohydrase and proteases in the applications of the pharmaceutical and food industry, remarkably in emerging countries such as China, India, and Japan. These countries have started investing in the biotech sector to introduce more effective global enzyme products.\nAdditionally, expanding investment in the food and beverage and pharmaceutical industry is anticipated to stimulate the overall industrial enzymes market. With improving disposable income, customer can now afford expensive food product, which is further expected to increase the demand for industrial enzymes products. As per our analysis, The Industrial Enzymes Industry will likely grow at a CAGR of 7.34% from 2020-2027.\nNevertheless, stringent supervision and controlled temperature & PH levels of enzymes await to restrict the market’s growth to some extent. On the other hand, concerns associated with quality, safety, and consumer perception towards enzymes is the key challenge of this market.\nBy Sources, the Industrial Enzymes Market has been fragmented through microorganisms, plants and animals. The microorganism is the most common source of industrial enzymes holding one of the highest shares in the market.\nBy Application, the Global Enzymes Market has been segregated into Bio-fuel Enzymes, Cleaning Product Enzymes, Food Enzymes, Animal Feed Enzymes, Textile Enzymes and Specialty Enzymes. Amongst the segments, Specialty Enzymes Market holds a significant market existence.\nBy Region, we have covered North America, Asia-Pacific, Europe and the Rest of the World.. Furthermore, the Asia-Pacific region is expected to witness the highest growth in the forecasted period and is anticipated to nurture its dominance in the future years.\nSome major companies operating in the industrial enzymes market are BASF SE, Advanced EnzymeTechnologies, Novozymes, DuPont Danisco, DSM and Kerry Group PLC.\nCOVID-19 Impact on Global Enzymes Market\nThe spread of COVID-19 across the globe has positively impacted the overall Industries. The rising adoption of enzymes in multiple industries such as Cleaning Product, Food, Animal Feeds, and Specialty has to propel the market growth during the COVID-19 pandemic as consumers across the world have become more alert and conscious towards their health and lifestyle.\nHowever, Biofuel and Textile Enzymes Market’s growth has been hampered by the COVID-19 pandemic. The lockdowns, social distances, and the shutdown of production plants globally have impacted the automotive industry, which in turn, negatively influenced the biofuel industry.\nSimilarly, the Textile Enzymes Market is no different; the operations of numerous textile industries had either been temporarily halted or were functioning with a minimal workforce due to enforced lockdowns and imposed restrictions by respective governing bodies. This factor has a significantly negative impact on the revenue growth of the Textile Enzymes Market.\nRenub Research latest report “Industrial Enzymes Market Global Forecast by Types (Carbohydrases, Amylases, Cellulases, Proteases, Lipases), Source (Microorganism, Plant, Animal), Application(Bio fuel, Cleaning Product, Food, Animal Feed, Textile, Specialty), Region (North America, Europe, Asia Pacific, Rest of the World), Company (BASF SE, Advanced Enzyme Technologies, Novozymes, DuPont Danisco, DSM, Kerry Group PLC)” provides a detailed analysis of Enzymes Market.\nRequest a Free Sample Copy of the Report: https://www.renub.com/request-sample-page.php?gturl=industrial-enzymes-market-p.php\nBy Types market has been covered from 5 viewpoints:\nBy Source market has been covered from 3 viewpoints:\nBy Application market has been covered from 6 viewpoints:\n- Bio fuel Enzymes\n- Cleaning Product Enzymes\n- Food Enzymes\n- Animal Feed Enzymes\n- Textile Enzymes\n- Specialty Enzymes\nglobal enzymes market\nBy Regions market has been covered from 4 viewpoints:\n- North America\n• Company Initiatives\n• Sales Analysis\n- BASF SE\n- Advanced Enzyme Technologies\n- DuPont Danisco\n- Kerry Group PLC\nAbout the Company:\nRenub Research is a Market Research and Consulting Company. We have more than 10 years of experience especially in international Business-to-Business Researches, Surveys and Consulting. We provide a wide range of business research solutions that helps companies in making better business decisions. We partner with clients in all sectors and regions to identify their highest-value opportunities, address their most critical challenges, and transform their businesses. Our wide clientele comprises major players in Healthcare, Travel and Tourism, Food & Beverages, Power & Energy, Information Technology, Telecom & Internet, Chemical, Logistics & Automotive, Consumer Goods & Retail, Building and Construction, & Agriculture. Our clients rely on our market analysis and data to make informed knowledgeable decisions. We are regarded as one of the best providers of knowledge. Our pertinent analysis helps consultants, bankers and executives to make informed and correct decisions.\nOur core team is comprised of experienced people holding graduate, postgraduate and PhD degrees in Finance, Marketing, Human Resource, Bio-Technology, Medicine, Information Technology, Environmental Science and many more. Our research helps to make business decisions: on strategy, organization, operations, technology, mergers & acquisitions etc. We support many blue chip companies by providing them with findings and perspectives across a wide range of markets. Our research reports offer a blend of information insight, analysis and forecasting that is essential in today’s ultra-competitive markets."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:584bfeb0-77a3-4b70-9ffb-248239ae074a>","<urn:uuid:8c719086-e8a5-48a2-928d-a1410b39d9bd>"],"error":null}
{"question":"Do coffee grounds help make soil more acidic, and what is their actual effect on soil properties when used for gardening?","answer":"Coffee grounds do not make soil more acidic. Used coffee grounds are neutral with a pH of 6.5 and will not affect soil acid levels. The pH of decomposing coffee grounds can actually range from 4.6 to 8.4, changing over time. When used in gardens, coffee grounds can improve soil structure through earthworm activity, as worms consume and deposit them deep in soil. They contain nitrogen-rich proteins and have an ideal carbon-to-nitrogen ratio for plant nutrition. However, they should be used carefully - in compost, they should be limited to 20% of total volume, and as mulch, they should only be applied in thin layers (less than half an inch) covered by coarser organic material to prevent creating a barrier to moisture and air movement.","context":["- Does lime lower pH in soil?\n- Do coffee grounds make soil more acidic?\n- What happens if plants have too much nitrogen?\n- Why is my soil pH so low?\n- What should be added in the soil when it is too acidic?\n- Does nitrogen raise or lower pH?\n- Does nitrogen affect water pH?\n- What happens when soil pH is too low?\n- What causes a high pH in soil?\n- What is the fastest way to lower pH in soil?\n- What do you do if your soil has high pH?\n- What causes low pH in soil?\n- Is low pH bad for plants?\n- How do you lower pH in potting soil?\n- Does urea increase soil pH?\nDoes lime lower pH in soil?\nWhat is lime.\nLime is a soil amendment made from ground limestone rock, which naturally contains calcium carbonate and magnesium carbonate.\nWhen lime is added to soil, these compounds work to increase the soil’s pH, making soil less acidic and more alkaline..\nDo coffee grounds make soil more acidic?\nUsed coffee grounds are neutral.” If you rinse your used coffee grounds, they will have a near neutral pH of 6.5 and will not affect the acid levels of the soil. To use coffee grounds as fertilizer, work the coffee grounds into the soil around your plants.\nWhat happens if plants have too much nitrogen?\nWhen plants receive too much nitrogen (N), they become more attractive to insects and diseases. It can also cause excessive growth and reduce the strength of the stems.\nWhy is my soil pH so low?\nCOMMON CAUSES FOR LOW SOIL pH In soils, intensive fertilization with ammonium-based fertilizers or ammonium-forming fertilizers (urea) may lower soil pH. … Parent material – type of rocks from which the soil developed. Rainfall – soils under high rainfall conditions are more acid than soils formed under dry conditions.\nWhat should be added in the soil when it is too acidic?\nThe most common way to raise the pH of soil is to add pulverized limestone to the soil. Limestone acts as a soil acid neutralizer and consists of either calcium and magnesium carbonate or calcium carbonate. These are called dolomitic limestone and calcitic limestone respectively.\nDoes nitrogen raise or lower pH?\n– Of all the major fertilizer nutrients, nitrogen is the main nutrient affecting soil pH, and soils can become more acidic or more alkaline depending on the type of nitrogen fertilizer used. … Phosphoric acid is the most acidifying phosphorus fertilizer. – Potassium fertilizers have little or no effect on soil pH.\nDoes nitrogen affect water pH?\nNitrate nitrogen works differently by causing the release a negatively charged OH- or HCO3– anion when it is taken up by the plant root. These negatively charged anions are bases, and when they react with the growing medium, they cause the growing medium pH to increase.\nWhat happens when soil pH is too low?\nA pH level that is too low also liberates aluminum—not a plant nutrient—in amounts that can stunt root growth and interfere with a plant’s uptake of nutrients. At a high pH level, the plant nutrient molybdenum becomes available in toxic amounts.\nWhat causes a high pH in soil?\nSoils may be alkaline due to over-liming acidic soils. … Iron chlorosis in plants, caused by inadequate iron, is a common problem in alkaline soils. Phosphate, a macronutrient, may also be limited in these high pH soils due to its precipitation in the soil solution.\nWhat is the fastest way to lower pH in soil?\nTwo materials commonly used for lowering the soil pH are aluminum sulfate and sulfur. These can be found at a garden supply center. Aluminum sulfate will change the soil pH instantly because the aluminum produces the acidity as soon as it dissolves in the soil.\nWhat do you do if your soil has high pH?\nTreatment of High pH Soil Fertilizers and chelates can be added to soil to increase concentrations of plant nutrients. It is important to note that addition of phosphate fertilizer alone will further reduce the availability of other nutrients. Lowering the pH of alkaline soils, or acidifying the soil, is an option.\nWhat causes low pH in soil?\nSoil pH is affected by land use and management. … These changes are caused by a loss of organic matter, removal of soil minerals when crops are harvested, erosion of the surface layer, and effects of nitrogen and sulfur fertilizers. Addition of nitrogen and sulfur fertilizers can lower soil pH over time.\nIs low pH bad for plants?\nLow pH levels also create mineral levels in the soil that can be toxic, thus harming plants. Low pH can increase the solubility of minerals such as aluminum. Plant growth can be repressed in soils that have severely high levels of aluminum or manganese .\nHow do you lower pH in potting soil?\nSphagnum Peat Moss Adding peat moss to your garden soil can also help to lower the pH of your soil gradually. Peat moss is an excellent soil amendment for acid-loving plants and is easy to incorporate into the soil. Simply add two to three inches to the top of the soil and work it into the layers of topsoil underneath.\nDoes urea increase soil pH?\nWhen anhydrous ammonia (NH3) is applied to the soil, it reacts with water to form ammonium-N and the hydroxide ion, which is basic. This reaction initially raises the pH of the soil. … In soil solution, urea first reacts with water and free H+ ions to form ammonium-N and bicarbonate.","Using Coffee Grounds in the Garden - October 31, 2018\nJeff Schalau, Agent, Agriculture & Natural Resources\nUniversity of Arizona Cooperative Extension, Yavapai County\nDr. Linda Chalker-Scott, Extension Urban Horticulturist and Associate Professor at Washington State University, has taken it upon herself to explore anecdotal gardening “miracle products”. Along the way, she has provided excellent product reviews and dispelled various gardening myths. Chalker-Scott has also written an excellent book called The Informed Gardener. In an article from 2009, she wrote: Coffee Grounds – Will They Perk Up Plants? Below I will share some of her observations about the use of coffee grounds in home gardens and landscapes.\nIncreasing numbers of people are using spent coffee grounds as mulch and these people are claiming they repel cats, kill slugs, prevent weeds, aerate and acidify the soil, provide nitrogen, attract earthworms, and more. There is a body of research about the uses for the byproducts of coffee processing (husks, hulls, and waste water), but little about using actual coffee grounds in gardens and landscapes. Coffee grounds are often available in large quantities from coffee venders and many people use them as mulch (applied to the soil surface), for a direct soil amendment, and add them to their compost.\nCoffee beans are seeds that contain nitrogen-rich proteins needed for germination and growth. Protein comprises over 10% of coffee grounds. In fact, the carbon-to-nitrogen ratio of coffee grounds can be ideal ratio for plant and soil nutrition (as low as 11:1). Since coffee is extracted in water, the compounds that are not water soluble (oils, lipids, triglycerides, and fatty acids) remain in the grounds along with cellulose and indigestible sugars. Lignin, phenolics, and essential oils are also left over from the brewing process and these compounds are reported to have antioxidant and antimicrobial properties.\nSoil-borne bacteria and fungi break down the various chemical components of coffee grounds after several months. Earthworms are also able to use this food source. Earthworms consume coffee grounds and deposit them deep in soil. This may account for noted improvements in soil structure such as increased aggregation. Humic substances, which are important chemical and structural soil components, are ultimately produced through organic matter degradation – this includes degradation of coffee grounds.\nMany gardeners assume that coffee grounds are acidic, but this does not hold true experimentally. The pH of decomposing coffee grounds in these experiments ranged from 4.6 (mildly acidic) to 8.4 (somewhat alkaline). The pH also changes over time and you should not assume that it will always be acidic. As for soil-borne diseases, coffee grounds do appear to suppress some common fungal rots and wilts (Fusarium, Pythium, and Sclerotinia) as well as some bacterial pathogens (E. coli and Staphylococcus). Coffee ground composts and mulches enhanced germination of some seeds while inhibiting germination of others.\nDr. Chalker-Scott has synthesized coffee ground research results to make the following recommendations. In compost, limit coffee ground content to no more than 20% of the total compost volume – more than 30% has often been detrimental. Additions of diverse raw materials to compost should ensure a diversity of microorganisms. Don’t assume coffee grounds will make an acidic compost; pH levels will fluctuate over time.\nIn mulch, since coffee grounds are finely textured and easily compacted, they can create a barrier to moisture and air movement, especially when applied in thick layers. Dr. Chalker-Scott recommends against using pure coffee grounds as mulch. Instead, try using a thin layer (no more than half an inch) of coffee grounds and cover with a thicker (four inches) layer of coarse organic mulch like wood chips.\nThis is not the first time I have referenced Dr. Chalker-Scott’s work in the Backyard Gardener. Visit the Backyard Gardener website and access the on-line version of this column for a link to Dr. Chalker-Scott’s website and a direct link her article: Coffee Grounds – Will They Perk Up Plants? I have also linked other coffee ground articles below.\nFollow the Backyard Gardener on Twitter – use the link on the BYG website. If you have other gardening questions, call the Master Gardener help line in the Camp Verde office at 928-554-8992 or e-mail us at firstname.lastname@example.org and be sure to include your name, address and phone number. Find past Backyard Gardener columns or provide feedback at the Backyard Gardener web site: http://cals.arizona.edu/yavapai/anr/hort/byg/.\nCoffee grounds in worm compost (Penn State Extension).\nCoffee Grounds and Composting\nOregon State University Extension Service\nCoffee as Fertilizer?\nUniversity of Illinois Extension\nRecycling Coffee Grounds in the Garden\nPenn State Cooperative Extension\n| Arizona Cooperative Extension\n840 Rodeo Dr. #C\nPrescott, AZ 86305\nLast Updated: October 23, 2018\nContent Questions/Comments: email@example.com<firstname.lastname@example.org"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:752ee150-4188-4788-a0c8-008b6c338d16>","<urn:uuid:81f5f996-de28-444d-b295-b9906b3f3e1e>"],"error":null}
{"question":"What specific problems did the Missile Defense Agency (MDA) encounter in transferring technology to military services?","answer":"The MDA faced the 'not invented here' problem where external organizations were unwilling to adopt technology they didn't develop. As a result, MDA failed to transfer procurement responsibility for many of its major systems and had to evolve by expanding its responsibilities to handle procurement itself.","context":["An Alternative to the Defense Department’s New, Technology-Focused Organizations\nJanuary 22, 2020\nThe national security community increasingly creates new organizations to manage technology. Just within the Department of Defense (DOD), the past three years have seen the elevation of U.S. Cyber Command and the creation of the Space Force, U.S. Space Command, Space Development Agency, Joint Artificial Intelligence Center, Army Futures Command, and an Under Secretary of Defense for Research and Engineering. Looking to the future, some have even suggested creating a cyber defense agency or a new missile defense agency.\nPolicymakers often create new organizations to prioritize technology. But if new organizations separate technology and missions, they can be counterproductive—and create bureaucratic barriers that instead hurt technology development and fielding. Policymakers, therefore, should be wary of creating new organizations that focus solely on high priority technology. Instead, the national security community should carefully construct new organizations to facilitate technology development and fielding by integrating—rather than separating—technology and missions.\nToday’s Focus on Technology\nMany of today’s new organizations separate technology and missions. The new Joint Artificial Intelligence Center, for instance, was created to “accelerat[e] the delivery of artificial intelligence-enabled capabilities.” DOD’s Artificial Intelligence (AI) Strategy acknowledges, however, that one of the center’s first tasks is to “work with teams across DOD to identify, prioritize, and select new AI mission initiatives”—since, at its establishment, the center apparently lacked missions for its new technology. As it matures, the center will face challenges identifying appropriate missions and transferring the technology it develops to outside organizations that execute those missions.\nThe Space Development Agency also separates technology from missions by developing hundreds of small satellites to execute missions that may already exist in other organizations. Former Secretary of the Air Force Heather Wilson questioned the agency’s creation, writing that “until the Space Development Agency has a uniquely identifiable mission that cannot be accomplished by current organizations, the plan should not move forward.” Additionally, it remains unclear whether the Space Development Agency will procure the small satellites it develops or transfer them to separate acquisition organizations in the Space Force.\nUnfortunately, even the Space Force’s mission remains unclear. To date, the Space Force’s primary goal appears to be increasing advocacy for space-related personnel, training, and equipment (i.e., technology) inside DOD. Separating space-based technology (primarily Air Force satellites) from the other military services is problematic, however, because important components of the end-to-end space architecture—including user terminals and ground systems—are managed by the Army and Navy. Rather than consolidating that end-to-end architecture into a single, mission-focused organization, the current instantiation of the Space Force further separates space-based capabilities from the broader DOD missions they support. Going forward, the Space Force may face challenges bridging organizational divides and providing capabilities that integrate effectively with the other military services.\nU.S. Space Command also separates satellite operations from geographic combatant commanders’ Earth-bound missions. Satellites provide communications, navigation, and missile warning—all of which are critical to combatant commanders and enable their missions. Space Command, therefore, may face challenges prioritizing its support to Earth-bound commanders, defining command and control relationships to govern that support, and overcoming institutional barriers to integrated space and Earth-based operations.\nAlthough more mature than Space Command, U.S. Cyber Command is still working to overcome those barriers today. Like Space Command, former director Admiral Michael Rogers says that “Cyber Command, in many ways, what we do functions to support others. We exist to enable and support the success of others.” To facilitate other commands’ integrated employment of cyber capabilities, Cyber Command—itself a new organization—established additional coordination and planning cells inside the other commands. Although these cells should improve operational integration, they illustrate the effort that is required to bridge organizational divides between technology and missions.\nFinally, policymakers created the new Army Futures Command and Under Secretary of Defense for Research and Engineering to prioritize technology development by separating it from mission operations. Technology developers, however, often benefit from close collaboration with operators. Both organizations, therefore, will need to actively bridge institutional divides and foster collaboration among developers and operators; Army Futures Command, for example, is using cross-functional teams to achieve this effect today. It remains to be seen though, how both organizations will facilitate technology’s transition from development to operations—by ensuring that new capabilities are transferred to outside organizations for procurement.\nAn Alternative Focus on Missions\nClearly, today’s national security community has an affinity for creating new organizations to prioritize technology. But by separating technology from existing institutions whose missions could benefit from it, today’s new organizations create barriers to technology development and fielding. Separation matters in the government since bureaucracies are notoriously stove-piped, and separate organizations often engage in turf wars. The military services are engaged in a continuous battle for resources and influence, for example.\nTurf wars impede interorganizational collaboration and make it harder to break down the stovepipes that are created by separating technology and missions. Furthermore, as I observed in my doctoral research, turf wars hurt technology development by slowing it down and by constraining organizations’ ability to make targeted investments in capabilities that directly contribute to their missions.\nGoing forward, the national security community should think more carefully about the stovepipes and turf wars that are engendered by separating technology and missions. Where possible, policymakers can avoid creating bureaucratic barriers between technology and missions by first prioritizing technology within existing institutions. If this is not preferable, policymakers should create new organizations carefully—by ensuring they are thoughtfully constructed to facilitate technology development and fielding. To achieve this objective, policymakers should define new organizations by the distinct missions they execute, not by the high priority technology they manage.\nMissions Drive Technology Development\nWhen new organizations are defined by missions, policymakers can house both technology development and mission operations in the same institution. The proximity between technology and missions facilitates development by allowing missions to drive the demand for and design of new technology. This ensures that new technology is not developed in a vacuum where engineers have little ability to assess how new capabilities integrate into larger architectures or impact missions. It also facilitates DevOps—a development philosophy where engineers and operators interact—by housing both in the same organization.\nIn addition, mission-defined organizations can manage all of the technical capabilities that contribute to a mission rather than focusing exclusively on one type of technology. This creates more opportunities for engineers to innovate and optimize in pursuit of a mission since their design space is not constrained by their organization’s narrow focus on a single technology.\nFor example, the National Reconnaissance Office’s (NRO) mission is to conduct space-based reconnaissance. To execute that mission, the agency develops and procures intelligence satellites that collect data, communications satellites that transport data, and ground stations that receive data. The organization’s end-to-end approach to technology management gives engineers more flexibility to design an optimal set of technologies to execute their mission.\nNational Security Agency (NSA) engineers similarly benefit from their agency’s end-to-end approach to technology management. By controlling all technology that contributes to its signals intelligence mission, NSA can develop a “coherent architecture” that optimally integrates collection, processing, exploitation, and analysis technologies. Because NSA manages all technologies that contribute to its mission, it empowers its engineers to design holistic architectures to optimally execute that mission.\nBy creating new organizations that focus on high-priority technology, today’s policymakers constructed institutional barriers to the type of end-to-end, mission-focused architecture development that exists in NRO and NSA. Even today’s new, technology-focused combatant commands may disrupt architecture development by complicating command-and-control relationships amongst the various components in an end-to-end architecture. It remains to be seen, therefore, whether these new organizations—all of which separate technologies from the missions they support—will overcome institutional barriers and allow missions to drive the demand for and design of new technology.\nMissions Facilitate Technology Fielding\nHousing technology development and mission operations in the same organization can also facilitate technology fielding. Technology fielding, in this context, refers to a new technology’s transition out of development and into procurement and operations. Organizations that house both development and operations can facilitate technology fielding by managing the entire transition process.\nTechnology transition is a long-standing challenge for DOD. Frequently, new technology fails to bridge the valley of death and transition out of development and into procurement and operations. The Defense Advanced Research Projects Agency (DARPA), for example, encounters “administrative, funding, cultural, and programmatic barriers” that impede its ability to field the technology it develops. When development and procurement are managed by separate organizations—as is the case with DARPA—organizational barriers can impede technology transition as well.\nFor example, the Missile Defense Agency (MDA) was created to develop missile defense technologies that the military services would eventually procure. To date, however, MDA has failed to transfer procurement responsibility for many of its major systems. In this way, MDA suffers from the classic “not invented here” problem—where external organizations are unwilling to adopt technology that they didn’t develop.\nMDA overcame organizational barriers to technology transition by simply expanding its responsibilities and by doing procurement itself. Essentially, MDA has evolved from its original organizational construct—one that separated development and procurement—into an institution that manages the transition process. It remains to be seen whether today’s new organizations—many of which separate development and procurement—will evolve according to MDA’s trajectory or will instead face persistent, organizational barriers to technology transition.\nA Future Focus on Missions\nBy defining new organizations by missions—not technology—policymakers can avoid creating institutional barriers to technology development and fielding. Today’s policymakers, unfortunately, have done the opposite. Ensuring the success of today’s new organizations, therefore, will require strong leadership that is committed to bridging institutional divides and to actively facilitating technology development and fielding.\nTo do this, DOD leaders need to create new mechanisms to link technology with mission operations. They should also provide direction and funding to help technology bridge the “valley of death” between development and procurement—especially when technology transition falls outside of both new and existing organizations’ responsibilities. Finally, policymakers should be willing to revisit how they constructed new organizations in the first place. By reallocating roles, missions, and authority, policymakers can minimize the institutional barriers they generated by constructing new organizations around high priority technology.\nGoing forward though, policymakers should simply avoid creating new organizations that separate technology and missions. Most simply, policymakers can keep technology and missions closely integrated by first prioritizing technology within existing institutions. Alternatively, they can ensure that new organizations are thoughtfully constructed to focus on missions rather than on high priority technology. To truly prioritize technology, the national security community must facilitate its development and fielding—and avoid creating new organizations that generate bureaucratic barriers to both.\nMorgan Dwyer is a fellow in the International Security Program and deputy director for policy analysis in the Defense-Industrial Initiatives Group at the Center for Strategic and International Studies in Washington, D.C.\nCommentary is produced by the Center for Strategic and International Studies (CSIS), a private, tax-exempt institution focusing on international public policy issues. Its research is nonpartisan and nonproprietary. CSIS does not take specific policy positions. Accordingly, all views, positions, and conclusions expressed in this publication should be understood to be solely those of the author(s).\n© 2020 by the Center for Strategic and International Studies. All rights reserved."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:dae082a6-9718-4c91-bdb1-a0946c7acddf>"],"error":null}
{"question":"How do mutational signatures work as a diagnostic tool? Really interested in the practical applications! 👩‍⚕️","answer":"Mutational signatures function as diagnostic tools by serving as unique patterns that identify the underlying causes of DNA damage. These signatures can be detected by analyzing the complete genomic sequence of cancer cells, which provides an archaeological record of all mutational processes that have occurred. Different processes create distinct patterns - for example, UV exposure creates predominantly C-to-T transitions in dipyrimidine contexts, while tobacco smoke leads to G-to-T transversions. These signatures have potential to become diagnostic and prognostic biomarkers, help inform treatment choices, and may even correlate with clinical outcomes. Scientists can use computational methods, such as nonnegative matrix factorization, to separate and identify these distinct mutational signatures from cancer genome data.","context":["- Research highlight\n- Open Access\nCancer mutation signatures, DNA damage mechanisms, and potential clinical implications\nGenome Medicine volume 5, Article number: 87 (2013)\nKnowledge of cancer genomic DNA sequences has created unprecedented opportunities for mutation studies. Computational analyses have begun to decipher mutational signatures that identify underlying causes. A recent analysis encompassing 30 cancer types reported 20 distinct mutation signatures, resulting from ultraviolet light, deficiencies in DNA replication and repair, and unexpectedly large contributions from both spontaneous and APOBEC-catalyzed DNA cytosine deamination. Mutational signatures have the potential to become diagnostic, prognostic, and therapeutic biomarkers as well as factors in therapy development.\nGermline versus somatic mutations\nEvery cancer is distinct. We are all conceived with near equal amounts of genetic information from each parent, and yet the resulting genetic blueprint is different for everyone (except identical twins). During development, copying and partitioning of DNA takes place during cell division such that every daughter cell receives a full genetic complement. Individuals can thus directly inherit mutations (known as germline mutations) that predispose to cancer later in life. Additionally, a variety of factors combine to diminish the fidelity of DNA copying, resulting in DNA alterations, termed somatic mutations, that distinguish a daughter cell from its sister or parent (Figure 1). Because each tumor is derived from a somatic cell, the repertoire of somatic mutations that accumulate in each tumor is distinct for each individual and reflects the underlying processes that contributed to its development.\nDriver versus passenger somatic mutations in cancer\nA major rationale for sequencing large numbers of cancer genomes is to identify commonly mutated genes to inform diagnoses and treatments . The mutations themselves range from simple base substitution to larger-scale aberrations such as translocations and copy number changes. The recurrent involvement of a single gene in cancers of the same type provides strong evidence for a mechanistic contribution at some stage of tumor development. Such genes are considered cancer drivers because their alteration is frequently required for tumor formation. Approximately 140 drivers have been identified and, given the massive amounts of existing data, only a few drivers probably remain uninvestigated .\nAs much as 90% to 99% of all mutations are considered passenger events. These mutations can be silent base substitutions in coding sequences but the majority occur in non-coding sequences. Such mutations are less likely to be biased by selective forces during tumor outgrowth and, therefore, can provide ‘signatures’ reflecting the original source of DNA damage and insights into causal mechanisms.\nGlobal analyses of somatic mutations in cancer\nAlexandrov and colleagues recently reported a comprehensive analysis of mutational signatures, examining nearly 5 million somatic mutations from over 7,000 tumors that represented 30 different cancer types . This study was remarkable in three ways. First, it demonstrated the huge (1,000-fold) range in somatic mutation frequencies in human cancers. Second, computational methods enabled the deduction of over 20 distinct mutational signatures. Third, the mutation pattern of each cancer comprised at least two, and in many instances three or more, distinct mutational signatures and therefore major sources of DNA damage. Some of the DNA damage mechanisms are already established, some can be inferred based on current knowledge, and others will require more work to be fully understood.\nCancer mutation signatures from external sources of DNA damage\nA major external source of DNA damage is ultraviolet (UV) light, which can crosslink adjacent pyrimidine bases (CC, CT, TC and TT)  (Figure 1). If such a pyrimidine dimer is not repaired and becomes a substrate for DNA replication (or local synthesis), then most DNA polymerases will follow the ‘A-rule’ and insert two adenines opposite the dimer. Late repair or another round of replication can then immortalize the original lesion as a C-to-T transition mutation. Thus, the mutational signature of UV light is predominantly C-to-T transitions in dipyrimidine contexts. Other features of UV-induced mutagenesis include the occurrence of adjacent mutations (mostly CC-to-TT) and a nontranscribed strand bias due to preferential repair of the transcribed DNA strand.\nTobacco smoke is another external source of DNA damage (Figure 1), but it leads to a more complex array of DNA damaging agents and lesions than UV does . For instance, polycyclic aromatic hydrocarbons are converted by cellular cytochrome P450 enzymes into activated epoxides, which can then react to form alkylated guanine adducts. These lesions can erroneously base pair with adenine during DNA replication and, if unrepaired, lead to G-to-T transversions (equivalent to C-to-A on the opposing DNA strand), which comprise the most abundant class of mutations in smoking-associated cancers .\nMany chemotherapeutics are DNA-damaging agents and, by definition, external sources of mutation. An effective chemotherapeutic should eradicate a target cancer and leave no trace for downstream analysis by sequencing. The study by Alexandrov and colleagues raises a cautionary note for treatment of glioblastomas and melanomas with the DNA methylating agent temozolomide . The presence of a temozolomide-induced mutational signature in these cancers (G-to-A transition mutations at non-CpG sites) suggests not only that the intended therapy may have been ineffective but also that the drug itself may have increased the tumor mutation rate, and possibly contributed to tumor evolution, therapy resistance, and/or poor outcome. Future studies should consider mutational signatures before and after chemotherapy and strive to minimize potentially adverse outcomes.\nCancer mutation signatures from internal sources of DNA damage\nHydrolytic deamination of cytosine bases, and particularly 5-methyl-cytosine (5meC) bases in a CpG context, appears to be the most prevalent mechanism of mutagenesis  (Figure 1). Deamination of C-to-U or 5meC-to-T and subsequent DNA replication or misrepair results in a C-to-T transition mutation biased to CpG dinucleotide motifs. Interestingly, this is the only mechanism that correlates with age, suggesting it may be the only source of mutagenesis that accrues significantly over a lifetime . Some tumors lack this signature, which suggests that these cancers might have existed for short periods and/or that they employ a mechanism of preferential repair. Other sources of chemical damage, such as oxidation, are less prevalent and may be eclipsed by more dominant mutational mechanisms.\nDefects in DNA repair processes have already been linked to mutagenesis and carcinogenesis, such as in hereditary nonpolyposis colorectal cancer, which is due to inherited defects in mismatch repair . Somatic inactivation and epigenetic silencing can also result in defective mismatch repair. The study by Alexandrov and colleagues confirmed the telltale signature of mismatch repair deficiency: enhanced C-to-T transitions and microsatellite instability . By comparison, elevated frequencies of C-to-A transversions and C-to-T transitions occurred in a specific trinucleotide context in colorectal and uterine tumors with defects in the proofreading domain of DNA polymerase ϵ. In addition, an elevated frequency of insertions and deletions (without enhanced C-to-T mutagenesis) was evident in BRCA1- and BRCA2-mutant tumors, consistent with underlying defects in recombination repair.\nThis study also highlighted the breadth of genomic DNA deamination by members of the apolipoprotein B mRNA catalytic subunit-like (APOBEC)/activation-induced deaminase (AID) family of DNA cytosine deaminases  (Figure 1). These proteins catalyze the conversion of C-to-U in single-stranded DNA, which can be converted by replication into C-to-T transition mutations or by uracil DNA glycosylase into an abasic site. This lesion can then lead to a variety of mutagenic outcomes, including C-to-T transitions, C-to-G transversions, and DNA breaks that can precipitate larger-scale aberrations. Most human cells express up to nine active DNA cytosine deaminases, with one family member (AID) functioning in antibody gene diversification and most family members protecting against virus and transposon replication .\nSixteen different tumor types showed evidence of an APOBEC mutational signature, characterized by both dispersed and clustered C-to-T transitions and C-to-G transversions at TC dinucleotides . Mutation clusters, also called kataegis, implicated extended regions of single-stranded DNA, the preferred substrate of these enzymes. Two B cell cancers had an APOBEC signature and an additional signature consistent with AID activity . Prior studies have converged upon APOBEC proteins, particularly APOBEC3B, as a major source of mutation in several types of cancer [7–9]. Because this mutational signature was similar across all sixteen tumor types, it is likely that APOBEC3B is broadly involved in cancer mutagenesis. However, additional studies are needed to assess whether one or more of the APOBEC family members may also be involved. An additional intriguing possibility, given the innate immune function of APOBEC3B and other family members, is that parasite infection may contribute to their induction and/or aberrant regulation. In terms of overall impact, APOBEC involvement in cancer mutagenesis is second only to spontaneous deamination of cytosine and 5meC .\nEpidemiological, translational, and clinical implications\nEach of the cancers studied by Alexandrov and colleagues appeared to be influenced by two or more sources of DNA damage, as deduced by their mutational signatures . This knowledge has a number of important implications. First, novel signatures, such as the strong C-to-A bias in neuroblastomas and T-to-C bias in glioblastomas, will spur research to determine additional DNA damage sources. The quest to account for all mutational signatures is as much a mechanistic problem as it is epidemiological. If some of the unknown signatures are due to external sources (like UV light and tobacco carcinogens), then measures should be taken to minimize exposures.\nSecond, mutational signatures may act as biomarkers for the underlying mechanisms, and may become diagnostic. They will likely be even more beneficial if the mutational signatures and underlying processes correlate with clinical outcomes or specific treatments, because chemotherapeutic agents may synergize with underlying DNA damage sources (for example, PARP inhibition in BRCA-mutant cells ). Finally, it is important to emphasize that most internal sources of DNA damage are unavoidable and/or due to mistakes in DNA maintenance processes. By contrast, APOBEC/AID mutagenesis is through the aberrant action of normal enzymes, which raises the additional prospect of inhibiting these enzymes to slow down rates of tumor evolution, drug resistance, and metastasis.\nApolipoprotein B mRNA catalytic subunit-like\nLawrence MS, Stojanov P, Polak P, Kryukov GV, Cibulskis K, Sivachenko A, Carter SL, Stewart C, Mermel CH, Roberts SA, Kiezun A, Hammerman PS, McKenna A, Drier Y, Zou L, Ramos AH, Pugh TJ, Stransky N, Helman E, Kim J, Sougnez C, Ambrogio L, Nickerson E, Shefler E, Cortés ML, Auclair D, Saksena G, Voet D, Noble M, DiCara D, et al: Mutational heterogeneity in cancer and the search for new cancer-associated genes. Nature. 2013, 499: 214-218.\nVogelstein B, Papadopoulos N, Velculescu VE, Zhou S, Diaz LA, Kinzler KW: Cancer genome landscapes. Science. 2013, 339: 1546-1558.\nAlexandrov LB, Nik-Zainal S, Wedge DC, Aparicio SA, Behjati S, Biankin AV, Bignell GR, Bolli N, Borg A, Børresen-Dale AL, Boyault S, Burkhardt B, Butler AP, Caldas C, Davies HR, Desmedt C, Eils R, Eyfjörd JE, Foekens JA, Greaves M, Hosoda F, Hutter B, Ilicic T, Imbeaud S, Imielinsk M, Jäger N, Jones DT, Jones D, Knappskog S, Kool M, et al: Signatures of mutational processes in human cancer. Nature. 2013, 500: 415-421.\nCleaver JE, Crowley E: UV damage, DNA repair and skin carcinogenesis. Front Biosci. 2002, 7: d1024-d1043.\nHecht SS: Lung carcinogenesis by tobacco smoke. Int J Cancer. 2012, 131: 2724-2732.\nRefsland EW, Harris RS: The APOBEC3 family of retroelement restriction factors. Curr Top Microbiol Immunol. 2013, 371: 1-27.\nBurns MB, Lackey L, Carpenter MA, Rathore A, Land AM, Leonard B, Refsland EW, Kotandeniya D, Tretyakova N, Nikas JB, Yee D, Temiz NA, Donohue DE, McDougle RM, Brown WL, Law EK, Harris RS: APOBEC3B is an enzymatic source of mutation in breast cancer. Nature. 2013, 494: 366-370.\nBurns MB, Temiz NA, Harris RS: Evidence for APOBEC3B mutagenesis in multiple human cancers. Nat Genet. 2013, 45: 977-983.\nRoberts SA, Lawrence MS, Klimczak LJ, Grimm SA, Fargo D, Stojanov P, Kiezun A, Kryukov GV, Carter SL, Saksena G, Harris S, Shah RR, Resnick MA, Getz G, Gordenin DA: An APOBEC cytidine deaminase mutagenesis pattern is widespread in human cancers. Nat Genet. 2013, 45: 970-976.\nBryant HE, Schultz N, Thomas HD, Parker KM, Flower D, Lopez E, Kyle S, Meuth M, Curtin NJ, Helleday T: Specific killing of BRCA2-deficient tumours with inhibitors of poly(ADP-ribose) polymerase. Nature. 2005, 434: 913-917.\nI thank D Harki for comments and apologize to colleagues whose work could not be cited directly due to bibliography length constraints. The Harris Laboratory is grateful for support from the Minnesota Ovarian Cancer Alliance, V Foundation for Cancer Research, Department of Defense Breast Cancer Research Program (BC121347), and US National Institutes of Health (R01-AI064046 and P01-GM091743).\nRSH is a cofounder of ApoGen Biotechnologies LLC.\nAuthors’ original submitted files for images\nBelow are the links to the authors’ original submitted files for images.\nAbout this article\nCite this article\nHarris, R.S. Cancer mutation signatures, DNA damage mechanisms, and potential clinical implications. Genome Med 5, 87 (2013). https://doi.org/10.1186/gm490\n- Somatic Mutation\n- Mutational Signature\n- Transition Mutation\n- Preferential Repair\n- Defective Mismatch Repair","17 May 2013\nBy Ludmil Alexandrov\nCancer, the most common human genetic disease, is caused by changes to the DNA sequence known as somatic mutations. In turn, these somatic mutations are caused by the mutational processes that are operative in every cell of the human body. Some of these processes are intrinsic (e.g., DNA replication errors) and have been present since the very first division of the fertilized egg. Others become sporadically active throughout our lifetimes and depend on the environment (e.g., living in a house built with asbestos) and lifestyle choices (e.g., cigarette smoking, dietary choices, etc.). The constant operation of mutational processes from within our bodies and intermittent exposure to mutagens from our environment results in the gradual accumulation of somatic mutations in the genome of every cell. Cells counteract damage to their genomes by employing a plethora of DNA repair mechanisms. Nevertheless, the molecular battle for keeping the integrity of the genetic code intact is slowly lost by (at least) some cells, resulting in mutations affecting cellular functionality and occasionally in cancerous cells that divide uncontrollably by evading normal cellular constraints.\nDifferent mutational processes can cause different and unique patterns of mutations, which we call “mutational signatures.” Perhaps, the best-known examples of mutational signatures are the patterns induced by exposures to ultraviolet light and tobacco smoking, respectively resulting in changes to DNA bases; cytosine mutating to thymine during UV exposure and cytosine mutating to adenine in tobacco smoke.\nSequencing the genome of a cancer gives a researcher the complete archeological record of the mutational signatures of all processes that have been operative at one point or another during the cellular lineage between the fertilized egg and the cancer cell. The challenge is to take a set of cancers and identify all the mutational processes present in them. We simplified this problem by examining it as an analogous cocktail party problem, where multiple people attending a party are speaking simultaneously while several microphones placed at different locations are recording the conversations. Each microphone captures a combination of all sounds and the problem is to identify the individual conversations from all the recordings. This becomes possible because each microphone captures each conversation with a different intensity depending on the distance between the microphone and the conversation. Similarly, a cancer genome provides only the final mixture of the signatures of all mutational processes operative in a cancer sample, and the goal is to identify these signatures from a set of available mixtures.\nThis type of a “cocktail party” problem is known as a blind source separation problem and can be solved by applying different mathematical methods. In our study, we used a method called nonnegative matrix factorization. This method is quite powerful as it is able to separate meaningful parts from a large set of data. For example, if one applies nonnegative matrix factorization to passport photos, it will be able to separate eyes, noses, ears, and other meaningful facial features. Similarly, our approach allows separating the biologically meaningful mutational processes present in cancer. The developed computational resource can be leveraged by scientists around the world for characterizing the signatures of mutational processes in cancer samples. We extensively evaluate our framework with simulated and real data, demonstrating that it is applicable to different types of cancer data and that it allows incorporation of a wide variety of different mutation types. Currently, our tool is being applied to genomics data from thousands of patients to reveal the signatures of mutational processes in human cancer.\nAlexandrov, L. B., Nik-Zainal, S., Wedge, D. C., Campbell, P. J. & Stratton, M. R. Deciphering signatures of mutational processes operative in human cancer. Cell Rep 3, 246-259, doi:10.1016/j.celrep.2012.12.008 (2013)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:f63611af-dfef-4c25-9102-294e80d8e054>","<urn:uuid:17182780-e664-4747-89d4-1efa71f47155>"],"error":null}
{"question":"What are the key challenges of integrating data systems during company mergers, and what security measures should be implemented to prevent data leakage in the process?","answer":"Integrating data systems during mergers faces several challenges, including dealing with disparate legacy systems, different workflows, and maintaining data quality in a disconnected environment. Companies must choose between migrating to common systems or integrating different legacy systems, often ending up doing both. To prevent data leakage during this process, organizations should implement comprehensive security measures including physical controls (security cameras, locked cabinets), technical safeguards (encryption, firewalls, two-factor authentication), and employee education about data handling. Additionally, they should use data loss prevention tools, maintain strict access controls, and regularly review security policies and procedures to protect sensitive information during the integration process.","context":["Think about the integration of lives when two people get married. Two existences, residences, and belongings become one, and often, the overlap in possessions means some decisions have to be made if it is to progress into a fully embedded union. Whose home? Which couch? Which set of dinnerware? Do we really need this beer sign collection?\nBusiness mergers and acquisitions reflect a similar commitment toward positive growth, but the amount of things to integrate once the ink dries becomes a whole different ballgame. In fact, integrating two companies into one, and all that entails, is extremely cumbersome and complex, to put it lightly.\nThere are people, buildings, supply chains, financial and legal constraints, sales and fulfillment processes, and a whole host of other considerations to manage, not the least of which is technology. These systems and applications running each company prior to the acquisition presumably were crucial to processes in their previous lives, which leaves some tough decisions to be made.\nIf you’re lucky, you’ll have some of the same enterprise systems in place at both organisations. Even if you do, there’s a good chance you’ve got different workflows and integrations around them, and it’s unlikely they’ll share common patterns.\nYour integration team, then, will be faced with two options:\n- Attempt to migrate to a common set of systems across the new enterprise.\n- Figure out how to integrate the different, disparate legacy systems\nThe reality is, you’re likely end up doing both – picking the best common system where migration is feasible and figuring out how to integrate systems where it is not. Even if you do select the best-in-class workflows for each enterprise system, the likelihood of doing new integrations to bring the systems together to form the optimal business process for the unified enterprise is very high.\nSimilar decisions need to be made around the choice of integration solutions in the new enterprise. Many companies have grown up with a range of integration tools and techniques fit for specific purposes and end up maintaining a disparate set of tools and skill sets to maintain this legacy architecture. Of course, this complexity only gets worse when two companies come together.\nSo how do stakeholders decide the path to proceed in a post-transaction world, where the systems and processes of two companies become one well-oiled machine to continue growing the business? What key considerations support a strategy for deciding which of the dozens of incoming products and services from a variety of vendors – many undoubtedly interspersed throughout the world – will make the cut?\nThe process begins with business and IT units finding common ground and getting on the same page. It’s not uncommon for the business side of organisations to assume the IT folks will just take care of the integration of systems into the post-transaction enterprise. However, an M&A transaction presents a great opportunity for business and IT to come together and determine how technology can best serve the needs of the new organisation.\nThe driving factor for coming to this agreement centres on the importance of data to any organisation, merging or otherwise. Data is the lifeblood of many modern enterprises, and it drives business decisions throughout organisations. In fact, the decision to merge/acquire was, without question, based on data-driven insights that led to decision-makers to pull the trigger on this particular business expansion.\nThe recommended course of action, then, is a single unified integration platform to consolidate and displace old integration technologies, integrate the business systems staying on post-merger, deliver high visibility to IT and business users alike, and support the seamless movement of data inside and outside the organisation. This solution should solve internal and B2B integration, and also accommodate one-off data migrations (for consolidation of existing data) and the ongoing integrations where it wasn’t feasible to choose a single system.\nHere are three considerations for enterprises experiencing technology overload in a post-acquisition organisation and how single-platform integration technology protects the critical exchange of information that will power the business and supply chain going forward.\nConsolidate Systems Applications\nPost-transaction, data quality is at risk in a disconnected environment of disparate, siloed solutions. Duplicate and obsolete records, combined with data inconsistency, lead to poor data quality, and your single greatest asset – data – is in jeopardy if there’s no formalisation of best practices or unified integration.\nThe goals of a smooth transition, then, include harmonised business and data management processes. And that’s where a standardised platform supporting application and B2B integration comes in to help the organisation:\n- Identify common data standards and approaches to sharing data, reducing exposure to costly data loss.\n- Replace outdated applications and systems with more efficient ones with expanded capabilities, including high-speed and large-file transfer.\n- Get rid of workflows that don’t work well in today’s hyper-digital ecosystem.\n- Reduce overlapping business partners and vendors performing services.\n- Adopt or adapt to fit current needs but also the organisation’s future needs.\nA flexible yet unified integration platform streamlines the architecture via expanded managed file transfer, secure file sharing and B2B/EDI processes, while also delivering such modern connectivity needs as application, cloud, and big data integration.\nCleaning out the proverbial IT closet positions the post-transaction enterprise for leaner, more refined communications processes as it faces its brave new world.\nAccelerate the Transaction’s Benefits\nWithout question, merging two companies is a strategic growth move for a greater good, and these two businesses look to gain multiple competitive benefits in the process. Integration is essential to the success of the acquisition, and if critical information flowing among applications, people, and systems is not consistent, realising any business value from the acquisition may be compromised.\nSome of the targeted benefits of a merger or acquisition include:\n- Uniting complementary products or services under one proverbial roof.\n- Increasing market share, customer base, and lines of business.\n- Combining resources to reduce costs, eliminate duplicated facilities or departments, and increase revenue.\n- Accessing new funds, assets, and infrastructure for further product development.\n- Gaining better production, development, or data facilities, which often can be more expensive to build than buy.\nDeploying a robust technology supporting strategic integration allows post-acquisition organisations to:\n- Streamline and automate processes for current customers, exceeding service-level agreements and reducing customer churn.\n- Offer flexible integration patterns, including support for multiple advanced protocols, to say “yes” to new business.\n- Connect to emerging cloud, hybrid, and API technologies to support agile operations and expanded development capabilities.\n- Support enterprise-wide visibility into past, present, and future workflows for data-driven analysis.\n- Increase data quality – from customers, partners, suppliers, etc. – for more accurate returns on big data initiatives.\nAn unintegrated, disjointed business ecosystem can bring processes to a slow crawl, but a fully integrated environment accelerates delivery of the competitive advantages to be gained when two companies join forces.\nDrive Organisational Flexibility\nThe power of a unified integration platform lies not only in the ability to integrate technical systems but also to integrate and empower human resources. Because of the complexity of the transaction, many companies designate integration liaisons to manage specific projects and delegate workloads.\nWhen the heavy lifting is done, however, these project managers fail to hand off some of the IT integration duties. Arming business users with capabilities to deploy easy-to-use, IT-approved systems frees up the IT department down the road from addressing single, tactical workflow problems.\nHowever, this citizen integration functionality, as it is known, only works if the solutions are actually easy to deploy and use. The need for security and governance shouldn’t outweigh the need for ease of use among end users, and an advanced integration platform, with an intuitive interface and strong admin controls, delivers both. The organisation then can move its more capable IT resources onto advanced projects that add business value and drive new revenue.\nThe strategy of enabling citizen integrators helps keep the business from regressing into a pre-transaction scenario where multiple rogue solutions – consumer-grade cloud applications, FTP servers, and more – were introduced only because employees needed something to complete their daily responsibilities. It also inspires confidence in team members when they see a tight data communications workflow and corporate security policy that also charges business users with helping them help themselves.\nWith the increases in technologies, endpoints, employees, vendors, and more coming into an enterprise after a merger, competitive enterprises cannot waste the opportunity to consolidate systems and align resources to build a better business future. A stronger business will emerge when an organisation deploys a single-platform integration solution for all of its application, B2B, cloud, big data, ad-hoc, and citizen integration needs.\nMergers and acquisitions are already massive, complex transactions, but organisations choosing reliable integration technology can protect the integrity of their mission-critical information and enable the efficient flow of business throughout this tumultuous time.\nA single-platform communications solution delivers the migration and integration balance necessary for thriving in a post-acquisition business ecosystem.\nDave Brunswick, vice president of solutions at Cleo (opens in new tab)\nImage source: Shutterstock/Kritchanut","Data leakage can have devastating consequences for businesses of all sizes. To protect your business, you need to be aware of the risks and take steps to prevent data loss.\nThere are many potential sources of data leakage, including employees, third-party vendors, and hackers. The best way to protect your business is to implement physical security controls, technical safeguards, and policies that encourage employees to be vigilant and practice good data hygiene.\nUnderstanding Data Leakage\nWhat is a data leakage? A Data leakage happens when data is transmitted from inside a corporation to an outside source. It usually occurs through email and the web but can also be conducted with USB keys, laptops, and optical media.\nImplement Physical Security Controls:\nOne of the best ways to protect your data is physically securing your premises. This includes installing security cameras, alarm systems, and locked cabinets or rooms where sensitive information is stored. You should also restrict access to your premises to authorized personnel only and require employees to wear ID badges.\nImplement Technical Safeguards:\nTechnical safeguards are another critical layer of protection against data leakage. These include measures such as encrypting data in transit, using firewalls and intrusion detection systems, and implementing access control measures such as password protection and two-factor authentication, making it more difficult for unauthorized individuals to gain access to your systems.\nEncourage Good Data Hygiene:\nWhile it’s necessary to implement technical and physical measures to protect your business, education and awareness are the best way to avoid data leakage. Encourage employees to be vigilant about the handling of sensitive information and make sure that they understand their obligations when it comes to protecting company data, such as not sharing passwords or leaving laptops unsecured in public places.\nConsider the Use of Data Loss Prevention Tools:\nSeveral tools and services available can help prevent data leakage. For example, you may want to consider using data loss prevention software, which monitors what users are doing on their devices and alerts you if they try to access or send sensitive information. You also may want to encrypt all data stored on your company’s servers.\nWork With Third-Party Vendors:\nIf you work with other businesses and vendors, it’s crucial to take steps to protect your data from theft or loss. One way to do this is to use contracts that specifically address data security issues. You may also want to consider performing background checks or audits on third-party vendors before working with them to ensure adequate security measures.\nReview Your Insurance Coverage:\nIf your business suffers from data leakage, you may be able to claim under your insurance policy. It’s important to review your coverage and ensure that you have the right type of insurance to protect your business in a data breach, such as a commercial general liability policy or cyber insurance.\nStay Up-To-Date With Emerging Threats:\nIt’s essential to stay up-to-date with the latest threats and trends related to data leakage. By being proactive and vigilant in protecting your business, you can help to reduce the risk of a costly breach or another incident that could damage your bottom line, reputation, and ability to compete in the marketplace.\nSeek Professional Help:\nSeveral professional services can help you protect your business from data leakage. These services can provide you with expert advice and guidance on the best way to safeguard your data. If you’re concerned about data loss, consider seeking professional help to ensure that your business is as safe as possible from both a physical and cyber standpoint.\nReview Your Policies and Procedures Regularly:\nYou should review your data security policies and procedures regularly to ensure they are up-to-date and effective. Your data security needs will also change as your business changes and grows. Periodically reviewing your policies ensures that your business is always protected, no matter what new threats emerge or how your business evolves.\nTake a Holistic Approach to Data Protection:\nThe best way to protect your business from data leakage is to take a holistic approach that focuses on technical and non-technical safeguards. By implementing measures across all aspects of your organization – including physical security, education and training, and contingency planning – you can help to safeguard your data against theft or loss.\nData leakage can have severe consequences for businesses of all sizes. By taking steps to protect your business, you can help to reduce the risk of a costly data breach and prevent damage to your bottom line. With the suitable precautions in place, you can help to keep your business safe, secure, and prosperous for years to come."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:b05bbb1a-8e7c-433d-ab7a-74dec2ad4ef7>","<urn:uuid:02285b8b-8c2d-4cce-b209-86c50a9379a5>"],"error":null}
{"question":"Could you compare the methods used by the Hubble Space Telescope to study shadows in the Serpens Nebula versus its observations of the Ring Nebula's structure?","answer":"The Hubble Space Telescope used different observational methods for each nebula. For the Serpens Nebula, Hubble used near-infrared vision to capture the 'Bat Shadow' - a shadow cast by a young star's disk that spans 200 times the length of our solar system. This shadow reveals properties of both the small dusty disk and the larger nebula that wouldn't be visible otherwise. For the Ring Nebula, Hubble combined ground-based data with new detailed observations to study its structure, evolution, physical conditions, and motion, revealing that it's shaped like a distorted doughnut with a brightly colored barrel of material and lower density material in its center, forming a rugby ball shape.","context":["Shadows on Earth can be mysterious and foreboding, but when they occur in space, they can convey information we otherwise could not know. In a stellar nursery called the Serpens Nebula, nearly 1,300 light-years away, a young star’s game of shadow play is revealing secrets of its unseen planet-forming disk. The near-infrared vision of NASA’s Hubble Space Telescope captured the shadow cast by the fledgling star’s brilliant light being blocked by this disk.\nNamed HBC 672, this Sun-like star is surrounded by a debris ring of dust, rock and ice — a disk that is too small and too distant to be seen, even by Hubble. But like a little fly that wanders into the beam of a flashlight shining on a wall, its shadow is projected large upon the cloud in which it was born.\nIn this Hubble image, the feature — nicknamed the “Bat Shadow” — spans approximately 200 times the length of our solar system. It is visible in the upper right portion of the picture.\n“This is an analog of what the solar system looked like when it was only 1 or 2 million years old,” explained Klaus Pontoppidan, an astronomer at the Space Telescope Science Institute (STScI) in Baltimore, Maryland. “For all we know, the solar system once created a shadow like this.”\nThe presence of a shadow means that the disk is being viewed nearly edge-on. This is something that could not otherwise be known because of the disk’s great distance from us, which makes it too small to be seen by Hubble.\nThe disk’s shadow is similar to what is produced by a cylindrical lamp shade. Light escapes from the top and bottom of the shade, but along its circumference, dark cones of shadow form. Although the disk that gives rise to the shadow is a common object around young stars, the combination of an edge-on viewing angle and the surrounding nebula is rare.\nScientists can use the shadow to figure out the shape of the disk. For example, they now know that the disk is puffy, which implies that it is full of gas. While most of the shadow is completely opaque, scientists can look for color differences along its edges, where some light gets through. They can use the shape and color of the shadow to determine the size and composition of dust grains suspended in the disk.\n“These shadows are not easily seen in visible light, but the stellar disks and the shadows they project onto the surrounding nebula can be easily detected in infrared light,” said Max Mutchler, a research and instrument scientist at STScI. “This infrared Bat Shadow reveals properties of both the small, dusty disk and the much larger nebula.”\nThe shadow is an example of what the future James Webb Space Telescope will be capable of studying in even greater depth. “Webb’s power lies in its ability to see into the dust and gas of these disks to understand the material that comprises these environments that form planets,” explained scientist Alexandra Lockwood of STScI.\nA similar-looking shadow phenomenon emanates from another young star, at the upper left of the Hubble image. At the lower right, what appears to be a void is likely a part of a foreground cloud. Light from the red, double star inside the void is partially blocked by this cloud.\nThe image will be used with NASA’s Universe of Learning to illustrate how shadows can convey information about phenomena invisible to us. This program creates materials and experiences to enable learners to explore the universe for themselves. NASA’s Universe of Learning materials are based upon work supported by NASA under award number NNX16AC65A.\nThe Hubble Space Telescope is a project of international cooperation between NASA and ESA (European Space Agency). NASA’s Goddard Space Flight Center in Greenbelt, Maryland, manages the telescope. The Space Telescope Science Institute (STScI) in Baltimore, Maryland, conducts Hubble science operations. STScI is operated for NASA by the Association of Universities for Research in Astronomy, in Washington, D.C.","Most detailed observations ever of the Ring Nebula [heic1310]\n23 May 2013The NASA/ESA Hubble Space Telescope has produced the most detailed observations ever of the Ring Nebula (Messier 57). This image reveals intricate structure only hinted at in previous observations, and has allowed scientists to construct a model of the nebula in 3D - showing the true shape of this striking object.\nFormed by a star throwing off its outer layers as it runs out of fuel, the Ring Nebula is an archetypal planetary nebula . It is both relatively close to Earth and fairly bright, and so was first recorded in the late 18th century. As is common with astronomical objects, its precise distance is not known, but it is thought to lie just over 2000 light-years from Earth.\nFrom Earth’s perspective, the nebula looks roughly elliptical. However, astronomers have combined ground-based data with new observations using the NASA/ESA Hubble Space Telescope to observe the nebula again, hunting for clues about its structure, evolution, physical conditions and motion.\nIt turns out that the nebula is shaped like a distorted doughnut. We are gazing almost directly down one of the poles of this structure, with a brightly coloured barrel of material stretching away from us. Although the centre of this doughnut may look empty, it is actually full of lower density material that stretches both towards and away from us, creating a shape similar to a rugby ball slotted into the doughnut’s central gap.\nThe brightest part of this nebula is what we see as the colourful main ring. This is composed of gas thrown off by a dying star at the centre of the nebula. This star is on its way to becoming a white dwarf — a very small, dense, and hot body that is the final evolutionary stage for a star like the Sun.\nThe Ring Nebula is one of the most notable objects in our skies. It was discovered in 1779 by astronomer Antoine Darquier de Pellepoix, and also observed later that same month by Charles Messier, and added to the Messier Catalogue. Both astronomers stumbled upon the nebula when trying to follow the path of a comet through the constellation of Lyra, passing very close to the Ring Nebula .\n Planetary nebulae take their name from their roughly circular appearance through low-magnification telescopes. The phenomenon has nothing to do with planets.\n Messier 57 was not the only object to be discovered during the tracking of this comet, named C/1779 A1. Messier and other astronomers added a handful of other nebulae to the catalogue during this observing period — Messiers 56, 58, 59, 60, and 61.\nThe Hubble Space Telescope is a project of international cooperation between ESA and NASA.\nThe research on Messier 57 is described in a set of three papers, two published in The Astronomical Journal: \"Studies of NGC 6720 with Calibrated HST WFC3 Emission Line Filter Images — I: Structure and Evolution\" and \"Studies of NGC 6720 with Calibrated HST WFC3 Emission Line Filter Images — II: Physical Conditions\" and a third paper that has been accepted for publication in The Astronomical Journal: \"Studies of NGC 6720 with Calibrated HST WFC3 Emission Line Filter Images — III: Tangential Motions using AstroDrizzle Images\".\nThe NASA/ESA Hubble Space Telescope observations used in this image were led by C. R. O’Dell (Vanderbilt University, USA), G. J. Ferland (University of Kentucky, USA), W. J. Henney (Universidad Nacional Autónoma de México, Mexico), and M. Peimbert (Universidad Nacional Autónoma de México, Mexico).\nImage credit: NASA, ESA, and C. Robert O’Dell.\nC. Robert O’Dell\nDepartment of Physics and Astronomy, Vanderbilt University\nGarching bei München, Germany"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:2ab2c7d6-9ad4-4575-8034-5147860ef420>","<urn:uuid:714b00ec-3590-4502-8a05-2e7a6f634e9a>"],"error":null}
{"question":"What was the connection between Brother Elias and the tourism economy in Assisi? Can you explain this historical relationship?","answer":"Brother Elias, despite being twice-excommunicated, was instrumental in establishing Assisi's prosperous tourism economy. He accomplished this by masterminding the hijacking of St. Francis's body, which he then entombed in an elaborate Basilica dedicated to the humble saint. This Basilica, built to house Francis's remains, became a significant tourist attraction in the medieval city of Assisi.","context":["Rue for Ophelia\n(2014) Tell Me A Story, Pocatello, ID. An original one-act physical theatre work utilizing the monologues for Ophelia and Gertrude from Shakespeare's Hamlet.\nDouble Blind Sided: Kafka's German Process\n(2013) Callous Physical Theatre. A “compost modern movement opera” inspired, in part, by Franz Kafka’s The Trial . In post-9/11 security state, through the PATRIOT Act and other concessions, the trials and tribulations of Josef K as imagined by Kafka have gone beyond the realm of metaphoric satire and have become a very real possibility. \"Double Blind Sided\" explores Kafka’s memes that continue to resonate in the 21st century. Creating variations upon the motifs from Mussorgsky’s Pictures at an Exhibition, composer Robert Fruehwald creates emotionally moving music for poet G.B.Waldschmidt’s witty libretto; a non-linear montage of anachronistic scenes connecting Kafka’s novel, Weimar Germany’s slide into Nazism, the Vietnam War, and current economic and political events.\nZaum Etude #7\n(2012) Idaho State University. Zaum is a word used to describe the linguistic experiments in sound symbolism and language creation of Russian Futurist poets such as Velimir Khlebnikov and Aleksei Kruchenykh. (from wikipedia) The ten performers created movement phrases inspired by words associated with \"seven\". These phrases were then divided into sevenths and manipulated by the seven digit sequence of their phone numbers. The \"words\" spoken in the performance are created from the first two letters of each performer's name.\nThe Rule of Life - made for video version\nThe Rule of Life - documentary of video production\nThe Rule of Life - live performance\n(2012) Idaho State University. A meditation upon St. Francis and St. Clare of Assisi and their Orders of Lesser Brothers and Poor Sisters. The prosperous touris economy of the contemporary medieval city of Assisi was made possible by twice-excommunicated Brother Elias, who masterminded the hijacking of Francis' body to entomb it and sanctify the elaborate Basilica dedicated to the humble Saint. Francis, miraculously marked by the Stigmata, is honored as the most Christ-like of all saints. He and his convert Clare's rigourous asceticism and devote dedication to \"Lady Poverty\" was too extreme for all but a few members of their Orders. Video direction by Tom Hallaq, co-directed with Joséphine A. Garibaldi.\nCagevent: Sometimes it Works, Sometimes it Doesn't\n(2012) Kontaining Performance Festival, Helsinki, Finland. Six 15 minute performance events inspired by John Cage. With Joséphine A. Garibaldi and Karri Kokko.\nHome is Where You Are\n(2009) Idaho State University. Text is a revision of a monologue that I wrote for Migrant. Performers were provided with significant words from the text paired with terms from the Elements of Movement (body, space, time and energy) to create movement source material which was manipulated through aleatoric, ABA and other structures derived from music. The text was manipulated by the same structures as the movement.\n(2008) Callous Physical Theatre, Tacoma, WA. Inspired by migrant laborers: the hoboes of the Great Depression, undocumented workers of today, the Chinese “Coolies” that, through the “Tacoma Method”, were forced out of town once the railroads were built. Cast of 6 untrained dancers developed texts from journaling assignments, identified “key words” from the text which were paired with specific aspect the Elements of Dance (body, space, time and energy) to create movement. Music is from Harry Partch’s Barstow, a work whose text comes from eight pieces of graffiti Partch had spotted on a highway railing in Barstow, California.\nTacoma - excerpt from Migrant\nText by G.B. Waldschmidt\n(2009) Callous Physical Theatre, Big Dance/Little Space, Pocatello, ID. Four solos exploring male gendering.\nGrudge Match: ReMatch\n(2006) Callous Physical Theatre, Tacoma, WA. 2nd Holiday show. Co-directed with Joséphine A. Garibaldi\n(2005) Callous Physical Theatre, Tacoma, WA. Christmas show as our antidote to the Nutcracker. Co-directed with Joséphine A. Garibaldi\nIn God We Trust\n(2000) Luther College A year long collaboration between Art, Music, Economics, Theatre and Dance faculty involving over 150 students which culminated in a performance/installation, video, interactive website, and panel discussion of four guest artists which I served as moderator. A ritual for the new religion described in Harvey Cox’s article The Market as God. Music by John Howell Morrison, co-directed by Joséphine A. Garibaldi.\nthe world forgetting by the world forgot\n(1991) UC Irvine. A mourning ritual of AIDs related deaths, the World forgetting by the World forgot was informed by the structure of the Roman Catholic Mass, research of ancient dances of mourning, Greek Mystery Religions, human sacrifice research and the writings of ACT-UP founder, David Wojnarowicz."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:7d1d8fc3-75b3-4e39-ac1c-613f5d4505c5>"],"error":null}
{"question":"What specific neural processing methodology is being developed to assess sports-related concussions in athletes?","answer":"Researchers are analyzing electrical responses in the brain using electrodes applied to the scalp to measure frequency-following response (FFR). This methodology, sponsored by the National Institutes of Health, records electrical response to sound and can play it through a speaker. The FFR is sensitive to experience, and injury reduces its amplitude. Scientists are hoping to use this analysis of electrical responses following concussions to determine when an athlete can safely return to full contact sports without risking additional brain damage. Currently, it's estimated that 300,000 head injuries occur annually during high school and intercollegiate sports.","context":["The level of high school sports participation is at an all-time high.1 Students who play competitive sports enjoy physical and mental benefits. It reduces the rate of obesity, Type 2 diabetes and high blood pressure. It also improves cardiovascular and pulmonary function and increases the potential that young people will go on to stay physically active throughout their life.2\nResearchers also discovered that athletes who regularly play sports are less likely to use drugs and less likely to smoke cigarettes. Female athletes are 80% less likely to become pregnant during high school than their peers who don’t participate in sports. Students playing sports perform better in the classroom with higher grade point averages, better attendance and a greater chance of going to college.\nIn one survey of 75 Fortune 500 companies, researchers found that 95% of the vice presidents played high school sports. One of the risks of playing full contact sports, though, is a head injury, which experts estimate occurs 300,000 times annually during participation in high school and intercollegiate sports.3\nPlaying Sports Develops Mental Fitness and Sound Response\nMany of the benefits of playing sports are related to mental fitness or mental flexibility. Neurobiologists from Northwestern University focus on this in their studies of the brain’s response to sound.4 By hooking a series of electrodes to the scalp they can record the electrical response to sound and play it through a speaker.\nLead researcher Nina Kraus commented that this methodology gives insight into the health of the nervous system. Her team has found that those who are exposed to language and musical stimulation while growing up are less likely to have neural static or the generation of excess electrical activity.\nOn the other hand, growing up in a musically or linguistically limited environment, the brain may be excessively noisy, which interferes with your ability to understand auditory information. Their results suggest that playing sports gives an athlete’s brain greater ability to turn down background noise.5 Kraus explained:6\n“The brain is hungry for information and it actually creates electrical activity when it doesn’t get enough. But it creates random and staticky activity, which in the end is more of a problem because it gets in the way of making sense of sound.”\nThe researchers used a cross-sectional study design involving 988 student athletes. They evaluated the athletes’ auditory processing by measuring the frequency-following response (FFR) using electrodes applied to the scalp.\nThe FFR was used as it is sensitive to experience, and researchers have found that injury reduces the amplitude. They measured the FFR amplitude of the brain’s response, of the background noise and the ratio between these measures, and found athletes had a larger response than nonathletes, and concluded:7\n“These findings suggest that playing sports increases the gain of an auditory signal by turning down the background noise. This mode of enhancement may be tied to the overall fitness level of athletes and/or the heightened need of an athlete to engage with and respond to auditory stimuli during competition.”\nSports May Dampen a Noisy Brain\nKraus believes the ability to hear direction during competitive sports helps “tune the brain to better understand one’s sensory environment.”8 This gives an athlete the advantage of being able to hear their coach yelling from the sidelines above the noise of the spectators by dampening the background noise.\nDr. Richard Isaacson from the Alzheimer’s Prevention Clinic at Weill Cornell Medical College was intrigued with the results.9 He commented that the researchers demonstrated that athletes enjoyed mental fitness from playing sports, and he expressed an interest in further studies to differentiate between noncontact and contact sports.\nThe Northwestern researchers theorized that within a healthy nervous system, athletes may be able to handle injury and other health problems better than non-athletes. Kraus explained that making sense of what is heard may be one of the most difficult functions of the brain. The pitch, timing and harmonics of sound must be meshed with understanding the meaning within microseconds of having heard it.\nThe study is one of the latest in neural processing sponsored by the National Institutes of Health concerning sound in sports concussions. The hope is to use the analyzation of electrical responses following a concussion to determine when an athlete may be ready to return to full contact sports without an increased potential for greater damage to the brain.\nBrain Benefits From Language and Music\nThe researchers also found since head injuries disrupt auditory processes it may be important to understand how this enhancement may reduce potential brain injury. Kraus said playing a musical instrument or learning a new language can help strengthen the brain’s ability to process the signal, yet it does not affect the background noise. In other words:10\n“They all hear the ‘DJ’ better but the musicians hear the ‘DJ’ better because they turn up the ‘DJ,’ whereas athletes can hear the ‘DJ’ better because they can tamp down the ‘static.”\nThe obvious benefit of being bilingual is the ability to communicate with people from around the world. Most people in the U.S. believe learning a second language is valuable, though not necessarily essential. However, as a challenging task for your brain, learning a new language is beneficial.\nWhen evaluated, those who are bilingual have more gray matter involved in cognition and have enhanced cognitive control, greater mental flexibility and a better ability to handle tasks that involve switching and conflict monitoring. In the elderly, this may offer greater advantages since bilingual older adults have a greater cognitive reserve that helps the brain cope with pathology.\nIn those who currently are experiencing a neurological disorder such as Alzheimer’s, the simple act of listening to music can help them reconnect with the world around them. Some of this benefit appears to be rooted in familiarity. Imaging studies show when you listen to"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:3ce5e368-bde5-42da-8388-e567814fc213>"],"error":null}
{"question":"How does a creosote-related chimney odor compare to carbon monoxide in terms of detection by human senses?","answer":"Creosote-related chimney odors, which are especially noticeable in summer after rain, can be detected by smell. In contrast, carbon monoxide is completely undetectable by human senses as it is a colorless, odorless, and tasteless gas. This makes carbon monoxide particularly dangerous since it cannot be detected without special equipment like carbon monoxide detectors.","context":["What are the signs of a chimney fire?\nSome chimney fires will go unnoticed by homeowners and will extinguish themselves after a few seconds or minutes. Other more noticeable fires usually have a popping sound like you would hear with wood burning in a fireplace, only much louder. Additionally, there have been reports of a low, rumbling sound emitting from the chimney during fires. Visually, you may be able to see flames or thick smoke being emitted from your chimney even after the fire in the firebox has already been extinguished. Regardless of which characteristics of a chimney fire become apparent the best course of action to take is to immediately get out of the house and call the fire department. If you can do so safely, it is also a good idea to start spraying down the roof of your home with a garden hose to keep the fire from spreading. After the fire has been completely extinguished it is important to get a chimney inspection as soon as possible to determine if there is any structural damage or to clean out any creosote that may still be left after the fire.\nWhat are the signs of excess Carbon Monoxide?\nCarbon monoxide is a colorless and odorless gas that is the by product of incomplete combustion. Regardless of whether the fuel being burned is wood, natural gas or oil, carbon monoxide can be a serious threat to the occupants of a home. Becuase carbon monoxide cannot be detected by a person until symptoms of poisoning start to set in, the gas can quickly build up in a house without the residents even realizing it. Mild carbon monoxide poisoning symptoms often resemble the flu and could be overlooked as a result. Acute carbon monoxide poisoning will lead too dizziness, headache, nausea, vomiting and death within about three minutes to two hours, depending on the levels. The best defense against carbon monoxide poisoning is a carbon monoxide detector and a chimney inspection to investigate any blockage that may be stopping the proper flow of gases from a home.\nMy chimney smells bad, especially in the summer after it rains. Why?\nChimney odors in the spring and summer months are aggravated by the increased heat and humidity associated with this time of year, specifically just after a rain storm. An odor coming from your chimney typically is either a dead animal or an excess build up of creosote. Regardless of which one it is you should get your chimney inspected as soon as possible in order to identify the odor and eliminate the problem. If the problem is creosote a chimney cleaning may not get rid of the odor entirely. When creosote forms it will absorb into the masonry of the fireplace and is difficult to get out at that point. The next best alternative to eliminating odor in a chimney is to stop it before it comes into your house. A damper located at the throat of the fireplace is an effective impediment to air flowing from a chimney into the rest of a home.","First Aid Treatment for Carbon Monoxide Poisoning\nCarbon monoxide is a colorless, odorless, tasteless, highly toxic gas produced by the combustion of gasoline, wood, and coal, among other fuels. This combustion powers cars, gas stoves, and heating systems, among others.\nThis kind of gas is a silent killer that poisons about 1,500 people every year; up to 200 of them die. Most of the cases could be avoided as they’re mainly due to the misuse of equipment. Either that or the poor operation of gas appliances that are in unsuitable, poorly ventilated environments.\nCarbon monoxide poisoning is a medical emergency that can go unnoticed. Continue reading to find out everything you should know about it and what to do if it happens around you.\nCarbon monoxide poisoning\nPeople accidentally inhale this gas in their homes or during some of their daily activities such as cooking or heating a room. This is because the machines they’re using may either be malfunctioning or haven’t been properly maintained. Similarly, there are times when people use it as a suicide method.\nWhat does carbon monoxide do to our bodies?\nCells called erythrocytes, also known as red blood cells, usually circulate in our blood. These blood cells contain a protein called hemoglobin, responsible for transporting oxygen. This protein is in charge of collecting the oxygen breathed into the lungs and then sending it to the tissues where the blood circulates.\nCarbon monoxide toxicity is due to its higher affinity for hemoglobin than oxygen. Because of this, carbon monoxide binds strongly to hemoglobin and doesn’t allow oxygen to enter the blood. Thus, the tissues run out of oxygen, causing what’s technically referred to as tissue hypoxia.\nYou may be interested in Cerebral Hypoxia: Types and Causes\nSymptoms of carbon monoxide poisoning\nThe severity of the symptoms depends on the amount of carbon monoxide inhaled and the time of exposure. There are two types of carbon monoxide poisoning:\n- Acute poisoning happens when a person inhales this gas in large quantities\n- There’s chronic poisoning when people inhale low concentrations of carbon monoxide continuously\nThe symptoms are caused by a lack of oxygen in the tissues, and these are some of the most common:\n- Nausea and vomiting\n- Chest pain\n- Cardiac arrhythmias\n- Respiratory problems\nIf not treated in time, carbon monoxide poisoning will lead to a coma. Therefore, it’s dangerous for people who are exposed to it, especially while sleeping. This is because they can suffer irreversible brain damage or even die before someone notices there’s a problem.\nThe symptoms may not be so obvious in chronic poisonings and serious long-term damage may occur. These occur in the brain level, and are mainly:\n- Difficulty learning and retaining data in memory\n- Emotional disturbances that could lead to depression\n- Sensory and motor disorders such as difficulty moving and loss of sensation, among others\nIn most cases, these symptoms occur without a person realizing the cause is gas. This is because, as we mentioned above, it’s odorless, colorless, and tasteless.\nYou might like this article Loss of Consciousness: Why it Happens\nWhat to do in case of poisoning\nDo the following if you think you may have been poisoned by carbon monoxide:\n- Leave any room where there’s a gas leak\n- Open doors and windows to get fresh air and allow carbon monoxide to dissipate\n- Turn off stoves, ovens, heaters, and any appliances of this type\nOnce you’re away from the source of the poisoning, contact your nearest emergency room. Medical personnel can perform tests to check the carbon monoxide levels in your blood and suggest treatment immediately.\nTreatment consists of injecting oxygen into the blood system to flush out the carbon monoxide from the hemoglobin and replacing it with O2. They usually administer this oxygen through a mask placed over the nose and mouth. Thanks to this, oxygen reaches the tissues.\nIn some cases, doctors will place an affected person in a hyperbaric chamber. This treatment involves breathing oxygen in a chamber at a much higher pressure than normal. It accelerates the replacement of carbon monoxide with oxygen.\nHow to prevent poisoning\nAccording to the Centers for Disease Control and Prevention, you can take the following precautions:\n- Properly install and maintain all fuel-consuming household appliances\n- Inspect and clean household fireplaces and chimneys every year\n- Get a competent service technician to inspect your ovens, water heaters, and gas dryers annually\n- Only use room heaters that consume fuel but have no ventilation outlet when you’re awake, monitor them and try to maintain proper ventilation\n- You must regularly inspect your vehicle’s exhaust system for defects and blockages, especially during winter\nLastly, and most importantly, you should install a battery-powered carbon monoxide detector in your home. Don’t forget to check the batteries every daylight saving time change — spring and fall. Leave your home and call the emergency services if the detector alarm goes off.\nAll cited sources were thoroughly reviewed by our team to ensure their quality, reliability, currency, and validity. The bibliography of this article was considered reliable and of academic or scientific accuracy.\n- Guía de Prevención, Diagnóstico, Tratamiento y Vigilancia Epidemiológica de las Intoxicaciones por Monóxido de Carbono. (2014).\n- Retrieved April 23, 2020, from https://aetox.es/wp-content/uploads/2009/04/Monoxido-de-carbono.pdf\n- Intoxicación por Monóxido de Carbono: una patología poco valorada en Urgencias. (n.d.). Retrieved April 23, 2020, from http://scielo.isciii.es/scielo.php?script=sci_arttext&pid=S1699-695X2010000300011\n- Monóxido de carbono | Calidad del aire interior | US EPA. (n.d.). Retrieved April 23, 2020, from https://espanol.epa.gov/cai/monoxido-de-carbono\n- CDC – Carbon Monoxide Poisoning – Guías de prevención. (n.d.). Retrieved April 23, 2020, from https://www.cdc.gov/co/es/guidelines.htm"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:98ba6220-a5aa-4189-bb33-7e731e37cbc7>","<urn:uuid:b7d0ef2e-6464-4ce8-8bae-d3fd30d20c20>"],"error":null}
{"question":"I am fascinated by the aesthetic variations in marble. Could you explain why we see those characteristic grey veins running through white marble, and what geological process causes this unique pattern?","answer":"The veining in marble represents different minerals that settled together during the stone's formation process. When stone is formed, heat and pressure fuse various organic materials and minerals together. These materials don't all settle in the same way, which leads to the veining patterns you see. While this veining can range from soft to dramatic in appearance, it's important to note that these variations are purely aesthetic and don't affect the stone's structural integrity.","context":["Have you ever looked over your natural stone tiles and wondered why you see variations in color, shading, veining, or pitting?\nYou are not alone. As natural stone aficionados, we are often asked about the variances in this nature-made material.\nBecause of its organic composition, no two pieces of natural stone are entirely alike, even though they may appear similar at first glance. That individuality is part of the beauty of natural stone!\nToday, we are going to review several natural stone idiosyncrasies so you can better understand the unique characteristics of natural stone that give it its one-of-a-kind charm.\nLet’s get started!\nNatural Stone Aesthetic Variations\nAs we mentioned above, the true beauty of natural stone lies in the fact that no two pieces of stone are identical.\nWhen stone is formed, heat and pressure fuse together a myriad of different organic materials and minerals.\nOver time, these materials eventually settle and form the stone that you see today. However, during this process, not all the materials settle in the same way, which leads to an array of shading, veining, and pitting throughout the stone.\nIt is important to remember that these variations are aesthetic—they have no bearing on the structural integrity of the stone. Rather, they are just an outward manifestation of the multitudes and beauty contained within nature.\nTo start things off, let’s take a look at one of the more common variations—veining.\nHave you ever worked with marble?\nYou may have noticed that the soft white stone has shots of grey, or veining, running throughout it.\nThis veining represents the different minerals that settled together long ago to form the marble and can range from soft to dramatic in appearance.\nAt StoneImpressions, we offer a honed Carrara marble tile body for our unique art designs. While other varieties of Carrara marble feature dramatic or contrasting veining, our honed Carrara tiles feature veining that is subdued and sophisticated.\nBelow is an example of how veining can vary from piece to piece in our tiles:\nSometimes, especially when an artwork design is applied to the marble, veining can be mistaken for ink smudging or smearing. Rest assured that this is most certainly not the case, but rather a reflection of the marble’s unique and complex history.\nColor variation is another common characteristic of natural stone.\nOne stone type that has a variety of colors is Limestone. The most typical style of limestone usually displays an airy mix of white, beige, and cream shades and is perfect for creating elevated interiors. From piece to piece, however, some shades may be more prominent than others.\nFor example, take our tumbled Perle Blanc, a luxurious variant of Limestone, shown below:\nAgain, the aesthetic variations that you observe are simply a byproduct of the exceptional, natural circumstances that led to the formation of this stone.\nNext up, we have pitting variation.\nPitting refers to the small indentations and holes in natural stone. These markings reflect how other elements, like water, interact with the stone over time and the specific mix of minerals that comprise the stone.\nOur tumbled Light Travertine decorative tiles, shown below, offer an attractive, rustic appearance, reminiscent of Old World elegance.\nWith this variety of natural stone, every piece tells its own story. Tumbled Light Travertine, like many other natural stones, offers your interior added dimension, visual interest, and individual character.\nNatural Stone Sensitivities\nWhile natural stone might be solid as a rock, it is sensitive to certain things.\nFor example, when going through manmade manufacturing processes natural stone tiles may end up with small chips, usually seen on the back of the tile.\nContrary to what you may think, these tiny notches are totally normal and a regular occurrence when this type of organic material goes through production.\nAs mentioned earlier, these small chips do not compromise the integrity and strength of the stone and will be filled in or supported by the adhesive during installation.\nMaintenance and Care\nNatural stone also requires special care and maintenance to preserve its distinctive beauty.\nBecause stone is a natural product, it is sensitive to harsh abrasive cleaners or abrasive cleaning tools.\nWhen you need to clean your natural stone tiles use a soft cloth, warm water, and pH neutral cleaner or non-acidic soap. Never use an electric scrubber or buffer!\nAnd always adhere to the sealer maintenance schedule recommended by your sealant manufacturer.\nIf you are ever in doubt as to how to properly care for your stone tiles, review our Frequently Asked Questions.\nThe next time you see natural stone, we hope you will be able to identify and understand some of the variations you may see between pieces.\nAnd remember the age-old adage: Don’t judge a book by its cover. These differences are aesthetic and reflect the remarkable beauty of stone.\nCurious to learn more about natural stone? Discover the importance of nominal sizes for natural stone tiles today!"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:69e177dd-7c9e-4687-a1fe-bd44a08a0ace>"],"error":null}
{"question":"How is astronomy education structured differently in Germany compared to other countries, particularly at the undergraduate level?","answer":"In Germany, astronomy is not offered as an independent bachelor's degree. Students must first complete a general physics bachelor's degree and can only specialize in astronomy or astrophysics during their master's degree or doctorate. In contrast, many other countries offer dedicated bachelor's and master's programs in astronomy and astrophysics from the start, allowing students to specialize earlier and participate in research projects during their undergraduate studies.","context":["Is there life on other planets? What are black holes made of? When and above all how did the universe come about? Astronomy deals with these and many other questions. It is one of the oldest sciences and was already practiced by the ancient Egyptians and the Aztecs. Copernicus, Galileo and Einstein were fascinated by her and turned the world of their contemporaries upside down with their findings.\nAstronomers try to fathom and understand the structure and processes in the universe with the means of natural science .\nSpace exploration: an overview\nThe research of both our stand planetary and solar system as well as the so-called interstellar matter and the space as a whole . In the past, astronomers only had an optical telescope for their observations. Today’s researchers, on the other hand, have highly developed devices that can be used to measure and evaluate electromagnetic signals or gamma radiation.\nProbably the most important part of the field of astronomy, the so-called astrophysics . It deals with the physical research of astronomical relationships . This area is so dominant that the term astrophysics is sometimes used synonymously with the term astronomy. Further sub-areas and subjects within the field of astronomy include planetology , cosmology and astrometry .\nThe subject of astronomy in Germany\nAmazingly, universities and technical colleges in Germany currently do not offer astronomy as an independent bachelor’s or master’s degree . If you want to become an astronomer, you usually have to begin a general bachelor’s degree in physics . It is only possible to focus on the areas of astronomy or astrophysics during the master’s degree or as part of a doctorate.\nA strong interest in physics and mathematics as well as scientific and technical issues is therefore an absolute prerequisite for aspiring astronomers. In the first semesters in particular, the focus is on solid basic training in relevant physics topics such as\n- Quantum mechanics\n- Optics and\n- Particle physics.\nThe subject of astronomy abroad\nUnlike in Germany, the subject of astronomy is not exclusively offered as a focus in physics abroad. In many cases, there are already independent courses in the subjects of astronomy and astrophysics in the Bachelor ‘s and Master’ s area .\nThese courses also usually have a high proportion of physics and mathematics. However, they are clearly geared towards a scientific or practical activity in astronomy from the start . Often, students can already actively participate in research projects in the department during their bachelor’s degree and set their own priorities.\nAdvantages of studying abroad\nThe advantages here are obvious: In Germany, you can only focus on astronomy or astrophysics during your master’s degree. Abroad, on the other hand, you have the opportunity to specialize much earlier and complete a full degree in astronomy. There are also many advantages for those who study in Germany when they spend a semester or two abroad .\nStudying abroad literally opens up new perspectives and a different view of the starry sky. It is possible to take part in excursions to research stations and to work with other technical devices. Some of the research centers are located in extraordinary places like Antarctica.\nThe focus of research is country-specific. In western Australia, for example, there is a chance for German students to get to know the subject of radio astronomy better. This is about the investigation of astronomical objects using the radio waves they emit. In fact, one of the world’s most important research centers in this field is located in Western Australia.\nAt some universities abroad it is also possible to combine astronomy with another subject, such as computer science or engineering . In this way, students acquire a double degree , which is rather unusual in Germany.\nTraditionally, the majority of German astronomers and astrophysicists work in university teaching and research or at university observatories .\nAnother classic field of activity for astronomers is the work at non-university research centers and planetariums . In addition to research, the main focus of activity is the preparation and communication of astronomical knowledge.\nFor some time now, astronomers have also been increasingly active in completely different areas. They work in engineering and IT companies as experts in their field in the development of astronomical equipment or computer programs . Companies in the consulting sector also value astronomers because of their excellent basic training and their analytical skills.\nAccording to Top-Mba-Universities, the labor market for astronomers is global, since national borders are in principle irrelevant in astronomy. For this reason, astronomers have numerous opportunities to work internationally, especially in teaching and research, but also in the private sector .\nStudy Abroad in Astronomy: Professional Benefits\nResearch in the field of astronomy takes place on an international level. Astrophysicists exchange ideas with colleagues from abroad and the research teams are often international . The few large research centers are spread all over the world. Many astrophysicists therefore spend a large part of their professional careers in another country.\nYou should prepare for these requirements at an early stage. Therefore, it makes sense to take one or more semesters abroad during your studies or even to complete the entire course abroad. On the other side of the planet, a completely different view of the starry sky opens up to you. You will expand and perfect your foreign language skills and acquire important intercultural skills . You also have the opportunity to sharpen your scientific profile and make lots of contacts on the side. You can certainly use them for your future international career."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:4a920bcd-df91-4d33-ac68-1ebbc7c20fc5>"],"error":null}
{"question":"How do the roles of design thinking differ between policy innovation and cultural policy development? I'm particularly interested in understanding their implementation approaches! 🤔","answer":"In policy innovation, design thinking is primarily used at the implementation stage through 'policy labs' to co-create policy solutions, though it faces resistance in reaching mainstream policymaking due to cultural differences between professional fields. In cultural policy development, design takes a more comprehensive approach through system-wide cultural districts, focusing on both theoretical constructs and practical implementation, with local governance and capabilities serving as critical factors for success. Both domains require specific tools and techniques, with policy innovation needing specific design training programs for policymakers, while cultural policy design emphasizes practical implementation, sustainability, and ex-post evaluation of projects.","context":["Policy innovation by design: understanding the role of design in the development of innovative public policies\nthesisposted on 21.05.2021, 08:27 authored by Federico VazFederico Vaz\nThis investigation departed from the premise that there is increasing interest in introducing design approaches for public policy innovation worldwide. To date, this has been primarily achieved through the use of design at the policy implementation stage, typically resulting in new public services. Moreover, the introduction of design for policy has been associated with the creation of ad-hoc structures termed ‘policy labs’ in which design thinking is utilised to explore and co-create policy solutions.\nAlthough the literature on policy innovation has recently started to shift, the focus has historically been determined by the novelty of the policy content instead of the process through which policies come into being. In innovation management theory, this is represented by the product vs process innovation perspectives. Design, on the other hand, has been associated with the development of innovative products and services in the private sector. In order to exploit creativity to produce these innovative outcomes, the most successful organisations have integrated design at more levels than just product development. However, this has not been reflected in its integration in the public sector. Thus, this constrains its potential for contributing to policy innovations.\nThe overall purpose of this research is to respond to the primary question concerning the role of design in innovative public policymaking, as the effects and requirements of this role remain mostly unexplored. After building a conceptual framework to provide a rationale for introducing design-led approaches into public policymaking, the inquiry first of all explores the design practices which are currently being utilised in the policymaking process; secondly, it describes how design is instilled in public policymaking; and thirdly, it explains the conditions for the successful integration of design in the policymaking process.\nThe research design adopted for this investigation is based on a pragmatist approach through which qualitative data was obtained by online surveys, participant observations, and in-depth semi-structured interviews with key informants. Three studies which addressed recursively the research aim were implemented in different settings. The first study maps the design activities of policy labs in Europe against the stages of the policymaking cycle. The second study relies on participant observations to explore the introduction of design thinking in policymaking by a UK government team of policy designers. The third and last study consists of a set of interviews with policy analysts, policymakers, and design scholars participating in a project examining the future of governments in the EU. The analysis of the data gathered was primarily conducted through a framework and thematic analysis. Additionally, minor descriptive statistics were used to assist in drawing comparisons within the dataset.\nThe key findings reveal that the introduction of design faces resistance to reach mainstream policymaking due to cultural differences between the two professional fields. To overcome some of these barriers, design is introduced in different guises, often as the operationalisation of the open policy government agenda.\nThe main conclusions drawn from this study are the need for specific design tools and techniques for intervening in the public sector, as well as specific design training programmes to equip policymakers with the appropriate skills and mindsets. The contribution to knowledge of the research presented in this thesis is the provision of a new understanding of the role of design as a mode of inquiry and the part it plays in bringing about policy innovation by participating in either reactive, coactive, or proactive policymaking.\n- Loughborough University London","Cultural policy design: principles and cases\nDoctoral study programme Cultural Heritage Studies\nObjectives and competences\nStudents will be introduced into a comprehensive conceptual framework for cultural policy analysis and design, working at the same time on theoretical constructs and case studies, and learning how to synergize between them. A special emphasis will be placed on the practical implementation and sustainability of projects and on their ex post evaluation.\nNo specific prerequisites for this course.\nh1. I. Alternative paradigms for the relationship between cultural production and economics\n1. Culture 1.0, 2.0, 3.0: basic conceptual framework\n2. Culture 1.0: classical patronage\n3. Culture 1.1: strategic patronage\n4. Culture 1.2: public patronage\n5. The transition between the patronage system and the cultural industry paradigm\n6. Culture 2.0: proto-cultural industry\n7. Culture 2.1: mature cultural industry\n8. Culture 2.2: cultural industry and the subcultural worlds\n9. The transition between the cultural industries and the open platforms paradigm\n10. Culture 3.0: the current scenario\n11. The way ahead: Culture 3.1\n12. Implications for EU cultural strategies\nh1. II. System wide cultural districts: theory and case studies\n1. System wide cultural districts as the theoretical platform for culture-led local development\n2. System wide cultural districts and Culture 1.0, 2.0 and 3.0\n3. The 12 characteristic dimensions: an introduction\n4. The Quality factors for culture-led development\n5. The Attraction factors for culture-led development\n6. The Local Assets factors for culture-led development\n7. The Sociality factors for culture-led development\n8. The Networking factors for culture-led development\n9. Principles of cultural policy design\n10. Analysis of cases: local governance as the critical factor\n11. Analysis of cases: capabilities as the critical factor\n12. Summing up and some considerations about the future of cultural policy design in Europe\nIntended learning outcomes\nAt the end of the course, students will have the elements to analyze and to develop basic examples of cultural policy design with reference to the contexts of their professional interests, also with a view to the EU cultural policy agenda.\nBelfiore, E. & Bennett, O. (2010). Beyond the ‘toolkit approach’: arts impact evaluation research and the realities of cultural policy-making. Journal for Cultural Research 14, 121-142.\nGarcia, B. (2004). Urban regeneration, arts programming and major events. Glasgow 1990, Sydney 2000 and Barcelona 2004. International Journal of Cultural Policy 10, 103-118.\nPeck, J. (2005). Struggling with the creative class. International Journal of Urban and Regional Research 29, 740-770.\nPratt, A. (2010). Creative cities: tensions within and between social, cultural and economic development. A critical reading of the UK experience. City, Culture and Society 1, 13-20.\nSacco, P.L., Ferilli, G. & Tavano Blessi, G. (2011). Culture 3.0: A new perspective for the EU 2014-2020 strucgural funds programming. European Expert Network on Culture, Barcelona.\nSacco, P.L. & Crociata, A. (2013). A conceptual regulatory framework for the design and evaluation of complex, participative cultural planning strategies. International Journal of Urban and Regional Research 37, 1688-1706.\nSacco, P.L., Ferilli, G., Tavano Blessi, G. & Nuccio, M. (2013a). Culture as an engine of local development proceses: System-wide cultural districts. I: Theory. Growth and Change 44, 555-570.\nSacco, P.L., Ferilli, G., Tavano Blessi, G. & Nuccio, M. (2013b). Culture as an engine of local development proceses: System-wide cultural districts. II: Prototype cases. Growth and Change 44, 571-588.\nSacco, P.L., Ferilli, G. & Tavano Blessi, G. (2014). Understanding culture-led local development: A critique of alternative theoretical explanations. Urban Studies 51, 2806-2821.\nSacco, P.L. & Tavano Blessi, G. (2007). European Culture Capitals and local development strategies: Comparing the Genoa and Lille 2004 cases. Homo Oeconomicus 24, 111-141.\nValuation of assignments. Open discussion with professor and students. 50/50\nProf. dr. Pier Luigi Sacco is a professor of Cultural Economics at IULM University, Milan. As of September 2011, he is Dean of the Faculty of Arts, Markets, and Heritage. Pier Luigi teaches Creative Industries at the University of Italian Switzerland (USI), Lugano. He holds a Ph.D. ineconomics from the European University Institute, and he is the author of more than one hundred and fifty papers that have appeared in international journals and edited books with major scientific publishers (i.e. Oxford University Press, Cambridge University Press, Elsevier, Springer, Palgrave, Edward Elgar, Ashgate, Sage) on the topics of economic theory, game theory, cultural economics, cultural and creative industries, and cultural policy design at the urban, regional and national level.\nHe also writes for Il Sole 24 Ore, Saturno and Flash Art. Pier Luigi is the president of the scientific committee of the International Festival of Contemporary Art, Faenza and the president of the Cultural Observatory of Marche Region. He is a member of the scientific committee of the Italian National Library, Florence. He is a research associate at Semeion Research Center, Rome, and a member of the editorial board of the following journals: Creative Industries Journal, Mind and Society, Quality and Quantity, Journal of Marketing at Retail and Economia della Cultura. He acts as a keynote speaker and lecturer internationally and provides extensive consultation and advisory work for governments, local administrations and cultural institutions on the issues of culture-led local development and the European Culture Capitals Programs.\nUniversity course code: 3SKD064\nYear of study: 1. year\n- Lectures: 12 hours\n- Seminar: 8 hours\n- Individual work: 70 hours\nCourse kind: specific elective\nLearning and teaching methods:"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:ef38e694-4420-419a-872b-974e8222b2e6>","<urn:uuid:6acf1415-62c7-4c54-b515-c2e3736d5591>"],"error":null}
{"question":"PSV isolation comparison: rupture disc vs LC/LO setup?","answer":"Rupture discs and LC/LO setups offer different approaches to PSV isolation. Rupture discs provide a one-time use membrane that bursts at a predetermined pressure, offering positive sealing and protection from corrosive media while allowing in-situ PSV testing. The LC/LO setup uses a key-controlled locking mechanism where valves are physically secured in either open or closed positions, requiring proper authorization and permit-to-work systems for status changes. This arrangement is typically managed through control room key access and must be properly registered and audited.","context":["Rupture discs are the second commonly used pressure relief (protection) devices after safety valves (PSV/PRV) in industrial applications. Rupture Disk is basically a non-reclosing type pressure relief safety device that protects equipment or system during overpressure situations or potentially damaging vacuum conditions. A rupture disc is also popular as a pressure safety disc, bursting disc, or burst diaphragm. It consists of\n- a one-time-use membrane that ruptures at a predecided pressure difference between the inlet and outlet of the device (i.e, defined breaking point), either positive or vacuum, thus releasing the pressure\n- and a disc holder.\nThe major objective of the rupture disc (Fig. 1) installation in piping or pipeline systems is to optimally protect and minimize the downtime of the system/plant. As the rupture disc is a one-time-use device. So, it has to be replaced after the burst. Rupture Discs are frequently used for over-pressure protection in chemical, petrochemical, oil & gas,\nand sanitary applications.\nRupture Disk Materials\nRupture disks can be constructed from any materials that the process fluid permits. Industrial rupture disc are normally constructed from following materials:\n- Carbon Steel\n- Stainless Steel\nRupture disks are widely accepted and used in industry and are normally available from 3 mm to 1200 mm sizes.\nAdvantages of Rupture Disc over Pressure Safety valve (PSV)\nThe major advantages of rupture disc comparative to electronic, pneumatic, or spring-loaded safety systems are\n- the failsafe performance of rupture discs.\n- high reliability to prevent unnecessary downtime of the system.\n- simple design with no moving parts.\n- Provide both over pressure protection and depressurizing.\n- leak tightness.\n- Reduced fugitive emissions – no simmering or leakage prior to bursting.\n- react quickly enough to relieve the excess pressure quickly.\n- used for both gas or liquid handling application.\n- no additional maintenance cost for each rupture disc per service.\n- Greater sensitivity to temperature.\n- Protect against rapid pressure rise cased by heat exchanger tube ruptures, run away reactions or internal deflagrations.\nDisadvantages of Rupture Disc\nHowever, there are few drawbacks of rupture disks as well. These are\n- not possible to test before application.\n- can degrade with age or due to corrosion.\n- need replacement every time it ruptures. So, a shutdown may be required to refit.\n- care to be exercised during installation not to damage the rupture disc.\n- improper bolt torque during installation may also affect the disc burst pressure.\n- Greater sensitivity to mechanical damage.\nDesign of Rupture Disc\nRupture Disc of Rupture Disk consist of one or more flat or domed layers and generally, are round or square in shape. The rupture element of the disc is equipped with breaking points that are normally created by means of lasers. These breaking points can be made of simple cuts or even special geometries. A rupture disk are normally actuated thermally or mechanically. A safety factor should be used regardless of the disk design.\nRupture Disc types\nDepending on the applications and suitability, rupture discs can be of different types. They are mostly made of metals or plastics (Inconel, Hastelloy, or Tantalum, plastic liners such as PTFE or FEP.). Domed rupture discs are of two types\n- having the dome towards the process (reverse acting rupture disc) enabling very high operating pressures and operating pressure ratio.\n- or having the dome away from the process (forward acting rupture disc).\n- Forward-acting composite disc\n- Forward-acting solid metal disc\n- Forward-acting scored metal disc\n- Graphite disc\nDifference Between Reverse-Acting Rupture Disc and Forward-Acting Rupture Disc\nThe major differences between the above-mentioned rupture disk types are tabulated below:\n|Reverse-Acting Rupture Disc (Fig. 2)||Forward-Acting Rupture Disc (Fig. 3)|\n|Convex side of the dome faces the process media||concave side of the dome faces the process media|\n|Functions when the pressure creates an instability in the dome, resulting in reversal, or buckling, of the dome. They are designed to act in compression.||Functions when the weakest portion of the disc exceeds its tensile strength. They are designed to act in tension.|\n|Possess longer cycle life and generated stresses are compressive. Hence, less crack propagation.||lower cycle life due to generation of tensile stresses that promotes crack propagation.|\n|Domes are typically supported on the outlet side to prevent movement of the dome prior to reversal.||Normally not supported.|\nA Rupture disc can be installed\n- directly between flanges, or\n- inserted into a rupture disc holder, which is then mounted between flanges.\nRefer to Fig. 4 below that shows one of the standard rupture disc installations.\nHow do you select a Rupture Disc?\nRupture discs are not standardized products. hence, various parameters need to be considered for the optimal selection of the right device. Few of those parameters for proper selection of a rupture disc are:\n- Line operating parameters.\n- Pipe size (The diameter of the rupture discs is specified matching the diameter of pipes or flanges as the nominal pipe size DN or NPS (Nominal Pipe Size).\n- Burst or set pressure (The pressure at which the rupture disc opens. It is selected in such a manner, that the rupture disc opens before there is any system damage. It is normally, above the working pressure during normal operation and below the maximum allowable working pressure) and corresponding temperature.\n- Burst tolerance: Defines the tolerance around the defined burst/set pressure at which the rupture disc opens. For example, If a ruptured disc has a burst tolerance of +/-10%, and the defined burst pressure is 10 bar, the rupture disc will open between 9 bar and 11 bar.\n- Permissible overpressure or vacuum pressure\n- Process medium\n- Vacuum resistance\n- Necessary vent area, or required flow rate\n- Phase Application: Gas only rupture discs should be used for gaseous medium only.\n- Rupture Disc Operating ratio: This is the pressure at which the rupture disk can be operated with a prolonged service life. Depending on the construction method and materials used, Rupture disks have a maximum operating ratio of about 50 to 95%. So, rupture disk selection must consider this ratio for proper working.\nComponents of a Rupture Disc\nThe main components of a rupture disk are:\n- Rupture Disks\n- Rupture Disc Holders\n- Alarm system to transfer the signal for rupture disc opening\n- Heat Shield\n- Baffle Plates\nSizing a Rupture Disc\nRupture Disc Sizing for a particular application is done following the standard methodologies described in ASME Section VIII Div. 1, API RP520, API RP 521, and Crane TP-410. Three basic methodologies are followed for sizing rupture disc devices. They are:\n- Coefficient of Discharge Method (Kd)\n- Resistance to Flow Method (Kr) and\n- Combination Capacity Method\nCo-efficient of Discharge Method of Rupture Disc Sizing\nIn the coefficient of discharge model, The rupture disk is considered as a relief valve and the flow area is estimated using relief valve formulas with a fixed coefficient of discharge, “Kd” of 0.62. In order to use this method for rupture disc sizing, the following four conditions must be met:\n- The rupture disk has to be installed within 8 pipe diameters of the equipment or the overpressure source.\n- The rupture disk discharge pipe should be limited to 5 pipe diameters.\n- The rupture disk discharge should be directly to atmosphere.\n- The inlet and outlet piping is at least the same nominal pipe size as the rupture disk.\nThis is popularly known as “8 and 5 rule”. A typical sketch of the “8 & 5” rule for rupture disc sizing is provided in fig. 5 below:\nThe flow area calculated is known as the Minimum Net Flow Area (MNFA). This is the rupture disk’s minimum cross sectional area needed to meet the required flow. The rupture disc manufacturer publishes the actual Net Flow Area (NFA) for each model and size. For the selected rupture disk the NFA should be greater than or equal to MNFA.\nResistance to Flow Method of Rupture Disc Sizing\nThe Resistance to Flow Method analyzes the flow capacity of the relief piping and accounts the frictional losses of the relief piping and all components. Such losses normally include nozzle entrances and exits, elbows, tees, reducers, valves and the rupture disk. The rupture disk is also considered as a piping component and its contribution to the over all frictional loss is determined.\nA factor Kr that represents the velocity head loss due to the rupture disc device is determined experimentally in flow laboratories by the manufacturer for their line of products and is certified per ASME Section VIII, Division 13. This Kr accounts for the holder and the bursting characteristics of the disk. API RP521 recommends using a Kr of 1.5. However, ASME Section VIII, Division 13 states that a Kr of 2.4 shall be used. ASME PTC25 provides standardized test methods to measure the Kr of rupture disc devices. By quantifying this performance characteristic, rupture disc devices may be selected.\nWhere do you use a Rupture Disc?\nThe following picture (Fig. 6) below shows three main cases of rupture disc applications.\nRupture Disc as Primary Relief\nRupture disc can be used as another pressure relief device to protect a vessel of the piping system from overpressure. In the following cases, they can be preferred as a primary relief option over the pressure relief devices:\n- When the pressure rise is so large and rapid that extremely fast-acting is required to prevent catastrophic failure. A relief valve (PSV/PRV) can still be installed in parallel to protect against other relieving scenarios.\n- When the relieving fluids may impede the proper operation of the pressure relief valve.\n- The use of a rupture disc as primary relief is attractive if the relieving fluids are non-toxic, non-hazardous, and the system stop and the loss of fluids is not an issue.\n- When the vessel has no permanent supply connection, and to protect the vessel against exposure to fire or other sources of heat. This is usually the case with storage vessels for non-refrigerated liquefied compressible gases at ambient temperatures.\nRupture Disc as Secondary Relief Device\n- As stated earlier, rupture discs and pressure relief valves can be used in parallel. In such configuration, the design considers a double jeopardy scenario and gives protection with both the vessel overpressure and the pressure relief valve failure.\n- If the process involves exothermic reactions where abnormally high and uncontrollable pressure conditions arise, parallel installation of Rupture disc and PRV is recommended.\nCombination of a Rupture Disc and Pressure Relief Valve\nThe combined use of a ruptured disc along with a pressure relief valves is becoming more popular within the industries nowadays. There are two potential possibilities:\n- rupture disc upstream (inlet) of the relief valve.\n- rupture disc downstream (outlet) of the relief valve.\nRupture disc at the inlet of Pressure Relief Valve\nThe process benefits of installing a Rupture disc at the upstream of PRV/PSV are the following:\n- It ensures positive sealing of the system.\n- It protects the PSV/PRV from fluids containing solids, that may plug/damage the valve.\n- It provides protection of the valve from corrosion and thus reduce valve maintenance.\n- It allows in-situ testing and calibration of the safety valve.\nRupture Disc at the outlet of the Pressure Relief Valve\nRupture disc can also be installed on the downstream side of the pressure relief valve for the purpose of protecting the valve from the atmospheric of downstream fluids. If the relief fluids vented in the common header vented media can result in either corrosion or polymerization. In such cases, the Rupture disc would isolate the vented media from the relief valve.\nRupture discs can also be used at upstream as well as downstream of Pressure relief devices.\nFew more Resources for you..\nRouting Of Flare And Relief Valve Piping: An article\nVarious types of pressure relieving devices required for individual protection of pressure vessels in process plants\nModeling Relief Valve (Pressure Safety Valve) Thrust force\nStress Analysis of PSV connected Piping Systems Using Caesar II","While dealing with valves, you must have come across the abbreviations LO and LC. In valve terminologies, LO stands for Locked open and LC is an abbreviation of Locked Closed. Both LO and LC can imply various types of valves like Ball Valves, Butterfly Valves, Globe Valves, or others depending on the application. In this article, we will learn the meaning of LO and LC with respect to valves.\nThe use of the terms LO and LC in valves are often correlated with the health of the system. It ensures the valve works during normal operation. The requirements of LO and LC during the design phase are essential in maintaining the safety and integrity of the system.\nControl valves are generally specified to add a locking arrangement as part of the vendor supply. It can be cleat located on the valve body or a plate by drilling a hole in the valve. Process P&IDs must identify such requirements (Refer to Fig. 1) specified in the documentation by mentioning the terms LO and LC as applicable. This locked open and locked closed method ensures there will not be accidental valve operation that enhances system safety. Only the designated responsible professionals can change the valve function from open to close or vice versa.\nRefer to the above figure which shows how the LO and LC valve arrangements are specified in a P&ID. In the above image, it shows as out of two PSVs, the inlet valve of one PSV is kept in LO condition and the other is kept in LC condition. Both the valves in the PSV outlet line are kept in LO condition. In a similar way, LC and LO valve arrangements will be specifically designated in the P&ID drawing.\nLocked Open (LO) Valves\nLocked open valves are a type of isolation valve. A typical example of a locked open valve can be a pressure safety valve mounted on a pressure vessel. The locked open arrangement in this PSV will ensure the release of pressure during an overpressure event, thereby protecting the equipment. Accidental closing can be detrimental in such a scenario and this is because the locked open valve arrangement is usually established to keep the valves in open position throughout the normal operation.\nLocked Closed (LC) Valves\nA locked closed valve arrangement is chosen when the valve is to be kept in the closed position during normal working conditions. A typical example of a Locked Closed (LC) valve could be the closed drain system for maintenance. Throughout normal operating conditions, the entry of hydrocarbon must be avoided and this is because a locked closed valve arrangement should be chosen.\nNote that, the locked open or closed status must be properly registered in the appropriate log. Also, the LO and LC status should be audited to ensure the proper working arrangement. To change any status for LO to LC or vice versa, a proper permit-to-work system must be followed.\nThe locking philosophy usually consists of an integral lock with a key arrangement. The keys are generally kept in the control room and only the authorized person can have the access to those keys. Sometimes, the valve with locked open or locked closed operation is performed in a sequential manner. A typical example is the PIG launcher and receiver where the sequence locking procedure is applied. The Pig launcher and receiver system have a number of valves and a separate designated key is assigned for all those valves."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:67479e6f-039a-491e-ba5e-11f7e8895904>","<urn:uuid:487a0901-3540-4542-a39e-bca90118efcc>"],"error":null}
{"question":"What are the key differences between how feedback is provided in performance evaluations versus disciplinary actions?","answer":"Performance evaluations and disciplinary actions differ in their feedback approaches. Performance evaluation feedback covers multiple aspects including achievement, administration, cooperation, creativity, improvement, interpersonal skills, problem-solving, and productivity. It aims to assess overall performance and development. In contrast, disciplinary action feedback focuses specifically on misconduct and rule violations, typically following a progressive system from verbal warnings to written warnings to termination. The documentation for disciplinary actions must include clear descriptions of infractions, specific consequences, and dates, while performance evaluation feedback takes a broader, more developmental approach to documenting employee progress and capabilities.","context":["In our everyday activities, we are doing so many things that require management of our time and resources. Even in our homes, we are tasked to perform our duties as a mother, father, son, daughter or grandparent. We are so busy during the day trying to accomplish the task and trying to beat the deadlines. But at the end of the day, have you ever considered evaluating your performance? Have you ever assessed your efficiency and effectiveness? Have you ever checked your improvements? Do you even want to be successful? What is success for you then?\nThese thoughts linger on our subconsciousness as we are trying to make our everyday living. It is our challenge to not only survive the day but also achieve or even surpass our objectives. How do we know that we are doing “okay” for that day? Performance evaluation.\nApplying this to the corporate and business world, every organization has its own organizational goal in which every member must help in achieving it. To help the management in assessing whether or not the goal is achieved or the level of performance still needed or required if the target is not yet achieved, there has to be performance evaluation.\nWhat Is Performance Evaluation?\nPerformance evaluation is a systematic way of examining how well an employee is performing in his or her task. The evaluation should be planned and should allow feedback. Performance evaluation should be contained in an evaluation report and may be in a form of an evaluation questionnaire.\nWhy Is Performance Evaluation Important?\n- To encourage positive performance and behavior: It is our mentality to work harder if we know that we are being evaluated at a certain period of time. With this, we are being motivated indirectly to push beyond our limits. Companies usually give rewards to top performers. So naturally, employees would try to do their best to achieve their target.\n- To satisfy employee curiosity as to how well they are performing: When the ratings of the employees are announced in a timely manner, for example, monthly, they will look forward to that same day of the month and become curious of their performance or their improvements. They will as well get intrigued on how well their co-employees performed. Just be careful not to cause unhealthy competitions. Only healthy competitions should be promoted. If you are the employee or the supervisor or one of the key personnel, observe symptoms of unhealthy competitions and encourage your members to compete on their own self and to surpass their limits, rather than comparing their achievements to others. Everyone has their own capacity, but by proper guidance and motivation, everyone can undoubtedly surpass their limits.\n- To develop employee’s potentials: Everyone has potentials stored within them, waiting to be fully unleashed. One might just need a little motivation and inspiration to keep the fire of their goals burning in their hearts. Having the performance of the employees evaluated may help them gauge up to what extent are they working and to how much more they are needing to hit the target.\n- To serve as a basis for incentives, promotions, or disciplinary actions: Companies would commonly offer incentives and promotions to compensate a job that is very well done. This method usually works if properly implemented by the management team and with the help and motivation of the immediate supervisors. For employees who are constantly not hitting the target set by the company, there are corresponding sanctions that await them. Disciplinary actions might be implemented not only to punish the employees who have not reached the quota, but also to remind them as well as to motivate them to exert more effort than what they have given right now.\nDisciplinary actions may be included but are not limited to the following.\n- Verbal warning. Usually, companies would give a verbal statement to an employee violating the rule or company policy examples on the first instance, and usually, the intensity of the offense is not grave.\n- Written warning. After the first warning, usually the verbal warning, a written warning may be sent to the employee violating the company rules. It is a formal notification from the employer extended to the employee, making the latter aware of the violation he or she has committed. This is also usually given if the intensity of the offense is just light to moderate.\n- Suspension. If the sanction of the employee for a violation com a fitted is suspension, it is either he or she has done a serious violation or has committed repeating violations. Different companies have different methods and types and graveness of violations depending on their company policies. Notice of suspension is given to an employee in writing. Suspension may be for a week or two or even a month, depending on the severity of the violation committed.\n- Dismissal. If an employee has committed a violation over again or if he or she has committed a grave offense, it is usually in a company’s code of conduct to sanction such employee, and the worst disciplinary action that an employee might receive is dismissal. An employee may be dismissed or discharged from work if the offense is very severe.\nCompany incentives commonly include the following.\n- Monetary. This is a money-based reward given to an employee when an employee hits the target or exceeds expectations. This may include cash bonuses, profit sharing and other reward that can increase an employee’s compensation.\n- Non-monetary. Contrary to monetary incentives, non-monetary incentives are incentives that do not involve money. This usually includes gifts, gift certificates, office materials, or any other that a superior or the company management might think. Giving incentive is a way of thanking an employee for his or her effort that exceeds the standards set by the company; it also motivates an employee to retain his performance or to do more than what he is doing.\nOn the employee’s shoes, performance evaluation is a way to measure their work for the day or for the month. It is also a motivating factor for them to work more to achieve the objectives set by the upper management. Evaluating the performance of an employee would also help him or her to assess himself or herself on how much more effort he needed to achieve the task. For example, in a sales company, an employee may be tasked to hit a target of $200,000 per day, but as per evaluation, a certain employee hit only $150,000 a day. With this, the employee is informed to do more to have an additional $50,000 sales in order to achieve the target. Why would an employee wanted to reach the target? Then, the incentive would come in the way. It is actually either incentive or disciplinary action for poor performance or negligence of duty.\nOn the other hand, on the employer’s side, the management or employer is looking after each employee to ensure that company goals should be attained. With this, performance evaluation is needed so that employers would know how much more would the group needed to hit the target. If most of the employees are performing poorly, the management would be alarmed, and it may be an indication that the management might have to recalibrate their ways on how to inspire people and to push employees beyond their limits.\nPerformance Evaluation Form Samples\nEmployee Evaluation Form\nExempt Positions Job Evaluation Form\nFieldwork Performance Evaluation Form\nGeneral Performance Evaluation Form\nGoals and Performance Evaluation Form\nPerformance Factor Narrative Form\nPlain Performance Factor Form\nProbationary Employee Performance Evaluation\nSimple Employee Performance Evaluation Form\nStaff Evaluation Form\nStudent Performance Evaluation Form\nHow to Evaluate Performance\n- Compare the target or standards set by the company to the performance of the employee.\n- Seek reviews from the staff, the key personnel or the immediate supervisor.\n- Consider the degree of difficulty of a given task.\n- Judge the output, not the potential of the employee, for potentials are limitless.\n- Constantly review performance for the period.\n- Avoid rating pitfalls: inflated rating because of using a less stringent standard to a professional member, evaluation on the basis of a single performance, inconsistency of rating system, or taking the matter personally on the employee.\nAfter the evaluation of the performance, it should be documented for future purposes like for comparing individual performances whether a certain individual has improved or not. It can be documented either in a soft copy or a hard copy, whichever is preferred by the company. Documentation can also be the basis for feedback.\nFeedback for the Performance Evaluation\nAfter the evaluation has been done, the task of the management does not stop there. In order to assess and make action to the performance of an employee, a feedback must be given and must be in a written form for clarity and to avoid misunderstandings. Some feedback that is common in a performance evaluation is the following.\n- Achievement – The employee is assessed on the level of achievement he has done and on whether he has or has not achieved the target.\n- Administration – This also includes assessing an employee on how well he administers his or her time and how well he or she manages his or her resources including planning for a certain project. Promotion might be given to employees who exceed their supervisory skills.\n- Cooperation – An employee will also be rated on his or her cooperation to the success of the group or his or her individual success.\n- Creativity – Creativeness can be measured by how an employee makes something novel out of the very same thing that he has faced everyday. It is thinking outside the box and having new and unique perceptions to certain things.\n- Improvement – Assessing improvement is better than assessing output. Constant improvement will lead to excellent output. As it is said, we have limitless potentials, so everyone can improve in their own little ways through perseverance.\n- Interpersonal skills – This is an assessment of how an employee communicates to his co-employees and his level of the way of communicating to other people.\n- Problem-solving – An employee is assessed on how he could solve a certain problem and what are the ways on how he handles a problem if he has given such.\n- Productivity – Productivity is a measure of one’s efficiency and effectiveness in his work and is demonstrated on the output by an employee over a given period of time.","In human resources, disciplinary actions are a type of personnel action taken by an employer for their misconduct to correct employee behavior or performance.\nDisciplinary action can range from a verbal warning to termination of employment. The type of disciplinary action taken will depend on the severity of the misconduct and the company's policy.\nWhat is the Definition of Misconduct?\nMisconduct is any behavior not following the company's rules and regulations. Common examples of misconduct include:\nTypes of Disciplinary Actions\nThere are three main types of disciplinary actions:\n1. Verbal Warnings\nVerbal warnings are the most common type of disciplinary action. They are usually given for minor infractions and are meant to warn the employee that their behavior or performance is not up to par.\n2. Written Warnings\nWritten warnings are more serious than verbal warnings and are usually given for more serious offenses. They are a formal way of documenting the employee's infraction and typically include a list of expectations for the employee to improve their behavior or performance.\nTermination is typically reserved for employees who have committed serious offenses or have failed to improve their behavior or performance despite repeated warnings.\nHow are Disciplinary Actions Carried Out?\nWhen an employee is found to have committed misconduct, the first step is usually a verbal warning from their supervisor. If the misconduct is more serious or the employee has been warned before, the next step may be a written warning.\nThe written warning will outline the misconduct and the consequences of continued misconduct.\nIf the employee continues to exhibit misconduct, the next step is usually a suspension. Depending on the company's policy, it may be with or without pay.\nA suspension is usually the last warning before termination, so the employee must be aware of the seriousness of their misconduct.\nOnce an employee has been terminated, are usually not eligible for rehire. It is because termination is considered the most severe form of disciplinary action.\nThe disciplinary action process is essential for maintaining a healthy and productive workplace. It is also vital to ensure that employees are treated fairly and consistently.\nNote that every organization is unique with its own cultures, management styles, expectations, risks, and other factors that influence the disciplinary measures it takes.\nFor example, some organizations will view and treat certain behaviors—such as sexual harassment in the same way as absenteeism, while others may not!\nWho Decides Whether or Not to Take Disciplinary Action?\nIf an employee breaks a company rule, it is generally up to the supervisor to decide whether to take disciplinary action. The supervisor will usually consider the severity of the infraction, the employee's record, and the company's policies.\nFactors that can influence the decision to take disciplinary action include the following:\nThe severity of the infraction: A minor infraction may warrant a verbal warning, while a more serious infraction may warrant a written warning or even termination.\nThe employee's record: If the employee has a history of breaking the rules, this will likely influence the decision to take disciplinary action.\nThe company's policies: Some companies have strict policies that dictate when and how disciplinary action should be taken. Others may be more lenient.\nHuman resources: In some cases, the decision to take disciplinary action may be escalated to human resources. They may be involved in the decision-making process or guide the supervisor.\nHow Disciplinary Actions Should Be Documented?\nDisciplinary actions should be documented in the employee's personnel file and handled consistently and reasonably to avoid legal issues.\nIt is because disciplinary actions can significantly impact an employee's career, and if they are not well-documented, it can be challenging to prove that the actions were justified.\nThere are a few things that should be included in any documentation of disciplinary action –\nFirst, there should be a clear description of the committed infraction. It should include what the employee did wrong and how it violated company policy.\nNext, the documentation should include the consequences that were given to the employee. It could consist of a written warning or a suspension. It is essential to be clear about the consequences, so the employee knows what to expect.\nFinally, the documentation should include the date of the disciplinary action. It is important to track when the action was taken and how long it occurred.\nBy including all the essential information, it will be easier to show that the actions were taken somewhat and as per company policy.\nIf you are an employer, you must consult with an HR professional or attorney to ensure that your disciplinary actions are legally defensible.\nIf you are an employee, you should be aware of your rights and understand the disciplinary process at your workplace. You may have legal recourse if you feel that you have been unfairly disciplined.\nAre there any Alternatives to Disciplinary Actions?\nOne alternative to disciplinary action is to offer counseling or coaching. Counseling can help employees identify the root cause of their rule-breaking behavior and find ways to avoid it. It could be done either in person or via an employee assistance program.\nSome companies choose to offer educational opportunities instead of disciplinary action. It could involve sending the employee to a training course or providing information on the rule they broke.\nThis approach aims to help the employee learn from their mistakes and prevent them from making them again in the future.\nWhich of these alternatives is best depends on the company culture and the severity of the rule violation. Companies may find that a combination of these approaches is most effective."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:61ace8ff-7836-461b-b22d-abcaa0230d73>","<urn:uuid:0dc11c5b-39b0-41dd-9926-f6f9734bbbc6>"],"error":null}
{"question":"Were both the Temple of Apollo in Aegina and the Temple of Athena Nike in Athens constructed using locally sourced stone materials?","answer":"No, they used different stone materials. The Temple of Apollo in Aegina was built using local poros stone, while the Temple of Athena Nike was constructed using Pentelic marble, which was sourced from the Athenian hill of the same name.","context":["Ancient Aegina was an affluent state with considerable power and influence over the entire Mediterranean from Neolithic times all the way through the Classical era. (see Aegina History)\nWhile the temple of Aphaia is the most popular destination of the island, the ancient ruins to the north of Aegina town, at Kolonna, are a testament to the long history of the island.\nThe excavations at Kolona present a complex layer of ruins crowned by the foundations and a lone standing column from the opisthodromos of the Temple of Apollo. While difficult to decipher in its present state, it is a Doric temple, built with 6 columns at the front and back, and 12 columns at the flanks (just like the nearby temple of\nAphaia). The Late Archaic temple was built of local poros stone between 520 and 500 BCE and it crowned the city’s acropolis.\nMany of the badly damaged fragments from the temple’s sculptural decorations are exhibited at the nearby museum of Aegina. The east pediment depicted a battle scene with Heracles and the Aeginetan hero Telamon against the Amazons.\nA great deal of the ruins date from the Helladic (Bronze Age) fortified settlement, intermingled with Archaic structures, and later Roman fortifications. Several Byzantine buildings are also visible; although it would be difficult for the untrained visitor to decipher what era each ruin belongs to, despite the several marble markers that appear near them.\nExcavations of the settlement from the Bronze Age (2500-1600 BCE) unearthed ten levels of occupation, with the fortifications of the fifth level (2200-2050 BCE) being the most impressive with tall walls. This settlement shows evidence of destruction by fire and the next city layer was protected with thicker walls and entrances that were protected by round towers.\nOther ruins of note are the badly damaged Tomb of Phokos, the shrine of Ajax (Aiakeion), and a small temple of Artemis.\nThe ruins are located right next to the sea and most of the unearthed settlements were protected by an encircling wall. Ancient Aegina had two harbors. The commercial harbor was located exactly where the modern harbor is today, and just to the north of it the ruins of the “hidden port” or the harbor where the military vessels were docked can be seen under the surface of the sea. Today’s beach of Aegina coincides with the ancient “hidden port”, and many bathers frolic in the shallow waters unaware that they swim within the confines of the ancient walled harbor.\nThe Archaeological Museum of Aegina is located in the same area as the archaeological site of Kolonna, and it houses numerous artifacts from the island. Unfortunately, the sculptures of the temple of Aphaia pediment are not among them. Fragmented sculptures from the temple of Apollo pediment are located in room 8 of the museum.\nThe museum is divided into eight rooms and each room exhibits artifacts from the different historical eras of Aegina. There are several interesting reconstructions of the Bronze Age city at Kolonna, and a multitude of pottery from the Mycenaean era.\nThe unique highlights of the museum are the large Bronze age storage jars (1900-1800 BCE) in room 3, the Sphinx from the temple of Aphaia in room 5, and the fragmented sculpture from the temple of Apollo. In room 6 there is a delightful jar, with a depiction of Odysseas escaping the cave of the Cyclops under a large ram.\nWhile the artifacts housed in the museum are definitely worth a visit if you are in the area, the building itself is in bad need of repair and renovations.\nThe museum is open from 8:30-15:00 daily (closed on Mondays), and the 3 Euro entrance fee allows admittance to the museum and the Archaeological site of Kolonna. Both can be easily visited in one-hour long leisurely walk. The museum is located ten minutes north from the ferry quay. When you disembark walk to the left.","ALREADY KNOW YOUR NEXT DESTINATION?\nDOWNLOAD YOUR FREE AUDIOGUIDE\nBuilt between 426 and 421 BC, this small temple also formed part of the mammoth project of building the Acropolis of Pericles.\nThe embossing of the frieze and decorative elements offer some clues to the reason for building this temple. They include scenes of battles between Persians and Athenians, such as Plataea, in 479 BC. After the victory of the Greeks over the Persians at the famous battle of Salamis, a decision was made to erect this temple to the goddess Athena Victorious. Pericles kept the project at a standstill until half a century later, although the Athenians were then immersed in a new war, the Peloponnesian. Therefore, some of the friezes show the gods Zeus, Poseidon and Athena helping the Athenians in a clear gesture to boost morale in the city.\nThe temple was designed by the architect Kallikrates, who also took part in the construction of the Parthenon. It was not built from scratch, but was raised on the ruins of buildings from Mycenaean and Archaic times that were also dedicated to the goddess Athena. In the mid-6th century BC, there was first a wooden temple on the site, which was destroyed by a Persian attack in 480 BC. After this, at the time of the governor Kimon, a small limestone temple was erected.\nThe ancient structures and altars were respected when building the classical temple whose ruins are visited today.\nThe building was made of Pentelic marble (from the Athenian hill of the same name), and measures less than nine by six metres. The temple was built on top of a bastion measuring almost ten metres in height, which was especially constructed to cover the previous Mycenaean bastion. It is a small amphiprostyle structure. This is the name given to structures with two colonnaded porticos (at the entrance and at the rear) preceding the main chamber, and that are not aligned with the end of the walls of that chamber but instead are in front of it. The four marble columns of the porticos are Ionic, with scrolled capitals.\nThe main cella or chamber measures barely four by four metres, giving the temple a completely human dimension. Its small size also gives away the fact that there it was not a place of worship that was to house large groups, but instead the celebrations were held outdoors.\nInside the temple was a statue of the goddess Athena personified as Nike, or Victorious. It was, of course, Athena, as she was the patron and protector of the city, and was represented as victorious in reference to the Athenian victory over the Persians. However, a detail that you will love to know is that, although the representation of Athena victorious consisted of a winged goddess, given that it is a symbol of naval victories, in this case she was represented without wings. Furthermore, in his writings Pausanias referred to the temple as Apteros Nike or Wingless Victorious. The reason? Represented in this way, Athena could never leave her city.\nArchitecturally speaking, the parapet of the bastion on which the building is constructed must also be highlighted: a jewel of sculptural relief, most of which are in the British Museum in London and in the Acropolis Museum. The friezes of the bastion, which rise one metre in height, showed scenes of winged victories offering sacrifices and divine figures performing daily activities, a hallmark that is far from the idealization of the original classicism.\nThis place is also the origins of another mythological story. It is believed that King Aegeus threw himself into the sea from the top of the temple, believing that his son Theseus had been the victim of the Minotaur of Crete.\nThe high-up position of the Acropolis and the location of the temple in the grounds also served as a vantage point. This strategic position was used to detect the Ottomans, who in 1686 decided to use the site as an artillery position and made the catastrophic decision for the temple of Athena Nike of completely dismantling it. The Turks used the materials to erect a wall and a defence tower in front of the Propylaea. Fortunately, most of the temple was piled up in the same place, which meant it could be reconstructed between 1834 and 1838.\nThanks to its restoration using original materials, today it is a small building that remains considerably true to the original. A real gem.\nAncient Olympic Stadium (Kallimármaro) (43)\nHadrian's Library (28)\nTemple of Hephaestus (33)\nThe Temple of Olympian Zeus (41)\nMikri Mitrópoli - Panagía Gorgoepíkoös (20)\nPnyx (Pnika) (31)\nThe Acropolis (6)\nTheatre Dionysos (14)\nAgia Dinami (18)\nCentral Cemetery (Proto Nekrotafio) (44)\nKolonaki Square (47)\nNational Gardens (Ethnikos Kipos) (40)\nPsiri - The Psiri neighbourhood by night (26)\nThe Hill of The Muses (Lofos Filopapou) (29)\nAgios Dimítrios Loubardiaris (30)\nCentral Market (Kendriki Agora) (27)\nLykavittos (Lofos Likavitou) (48)\nOmonia Square (17)\nRoman Agora and the Tower of the Winds (22)\nAgios Nikólaos Rangavás (3)\nMonastiráki Flea Market (25)\nSyndagma Square and the Changing of the Guard (39)\nAcropolis Museum (11)\nMuseum of Cycladic Art (37)\nTzistarakis Mosque and Kyriazopoulos Museum of Ceramics (24)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:b374def9-fad7-49db-8f90-9d54bf52fd4a>","<urn:uuid:f9c1d163-aa41-46f3-9248-aa90c3532cc4>"],"error":null}