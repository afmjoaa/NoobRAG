{"question":"作为一个科技爱好者，我很想了解Pixar的动画制作过程和其碳足迹！🤔 能详细说说Pixar的制作流程以及这种数字动画对环境的影响吗？For example, the energy consumption in rendering and computing.","answer":"Pixar's animation process consists of 8 key stages: modeling (creating digital sculptures), rigging (adding virtual skeletons), surfaces (adding color and texture), sets & cameras (designing viewing angles), animation (bringing characters to life), simulation (creating believable movement), lighting (solving lighting challenges), and rendering (producing the final film). This complex digital production process has significant environmental impacts. The computing power required for digital animation contributes to substantial electricity consumption - for comparison, just computer gaming alone accounts for 2.4% of residential electricity use in the United States, with carbon emissions equal to more than 5 million cars. Additionally, the electronics used in animation production carry a heavy carbon footprint, with approximately 2/3 of their carbon emissions coming from manufacturing components like semiconductors and PCB components.","context":["PORTLAND, Ore. – The Science Behind Pixar, an exhibition about the science behind some of the most beloved animated films and their characters, opens February 23 at the Oregon Museum of Science and Industry (OMSI). This hands-on exhibition demonstrates the technology that supports the creativity and artistry of Pixar’s storytellers.\nCreated by the Museum of Science, Boston and Pixar Animation Studios, and featuring more than 50 interactive elements, The Science Behind Pixar showcases the science, technology, engineering, art and math (STEAM) concepts used by the artists and computer scientists who help bring Pixar’s award-winning films to the big screen.\n\"The Science Behind Pixar is an interactive exhibit that offers people a hands-on opportunity to understand how we make our films,\" said Jim Morris, president of Pixar Animation Studios. “At Pixar, we use science, technology, engineering, art and math – along with a significant dash of creativity and fun – and this exhibit is truly a great demonstration of how all those ingredients come together in our filmmaking process.\"\nVisitors of all ages will have the opportunity to engage in and learn about the filmmaking process through hands-on activities inspired by some of Pixar’s most treasured films, from the first-ever computer animated feature film “Toy Story,” which opened over two decades ago, to Pixar’s summer 2018 release, “Incredibles 2.”\n“I’m thrilled we are hosting The Science Behind Pixar at OMSI. This exhibit truly immerses you in the Pixar filmmaking process and explores how computers are used as a tool for Pixar filmmakers,” said Nancy Stueber, president and CEO of OMSI. “Digital animation classes are very popular at OMSI. They are not only fun and engaging, but they emphasize the STEAM skills that go into computer animation.”\nThe exhibition is broken into eight distinct sections, each focusing on a step of the filmmaking process providing visitors with a unique view of the production pipeline and concepts used at Pixar every day:\n• Modeling. Envision how digital sculptures are created based on sketches from artists.\n• Rigging. Showcases how the models are given a virtual skeleton to enable the animators to add movement.\n• Surfaces. Understand the techniques behind adding color and texture to every surface in a film.\n• Sets & Cameras. Discover how a bugs-eye view was achieved for A Bug’s Life, through camera angles and large-set design within the computer.\n• Animation. See how animators bring characters to life, posing them to act out each scene.\n• Simulation. Immerse yourself in computer effects and create believable movement in a virtual school of fish\n• Lighting. Try to solve hands-on lighting challenges similar to what Pixar artists faced in creating animated water with virtual light in Finding Nemo.\n• Rendering. Explore how Pixar animators turn all of the data and programming into the final film you see on screen.\nThe Science Behind Pixar is at OMSI Feb 23 – Sep 2 at OMSI and is made by possible through generous support from local presenting sponsor, US Bank.\nThrough our Community Possible giving and engagement program, we focus on the areas of Work, Home and Play,” said Stacey Dodson, Portland Market President for U.S. Bank. “We especially believe in the power of play and its ability to bring joy, to help develop problem-solving skills, creativity and curiosity and to build interpersonal social and emotional skills. That is why we are so pleased to partner with OMSI on this opportunity to bring The Science Behind Pixar to our community.\"\nTickets to this exhibit, which include general museum admission, are $21 for adults, $14 for youth (ages 3-13), and $17 for seniors (ages 63+). Prices for OMSI Members are $5 for adults, $3 for youth, and $4 for seniors. Guests can purchase tickets online at omsi.edu, via phone at 503.797.4000 or in person at the museum.\nSupport for The Science Behind Pixar\nThe Science Behind Pixar is funded through support by Google, members of the Science Museum Exhibit Collaborative (SMEC), Institute of Museum and Library Services (IMLS) and the National Science Foundation (NSF).\nAbout Pixar Animation Studios\nPixar Animation Studios, a wholly owned subsidiary of The Walt Disney Company, is an Academy Award®-winning film studio with world-renowned technical, creative and production capabilities in the art of computer animation. The Northern California studio has created some of the most successful and beloved animated films of all time, including \"Toy Story,\" \"Monsters, Inc.,\" “Cars,” \"The Incredibles,\" \"Ratatouille,\" \"WALL•E,\" \"Up,\" \"Toy Story 3,” “Brave,” “Inside Out,” and “Coco.” Its movies have won 35 Academy Awards® and have grossed more than $13 billion at the worldwide box office to date. “Toy Story 4,” Pixar’s 21st feature, opens in theaters on June 21, 2019.\nFounded in 1944, the Oregon Museum of Science and Industry (OMSI) is one of the nation’s leading science museums, a world-class tourist attraction, and an award-winning educational resource for the kid in each of us. OMSI operates the largest museum-based outdoor science education program in the country and provides traveling and community outreach programs that bring science learning opportunities to schools and community organizations in every county in Oregon and throughout the region. OMSI is located at 1945 SE Water Avenue, Portland, OR 97214. For general information, call 503.797.4000 or visit omsi.edu.\nThis exhibition was developed by the Museum of Science, Boston in collaboration with Pixar Animation Studios. © Disney/Pixar. All Rights Reserved. Used Under Authorization.","Design Green Design What's the Carbon Footprint of All Our Electronics? By Lloyd Alter Design Editor University of Toronto Lloyd Alter is Design Editor for Treehugger and teaches Sustainable Design at Ryerson University in Toronto. our editorial process Facebook Facebook Twitter Twitter Lloyd Alter Updated April 07, 2020 Video screen capture. Topics covered Share Twitter Pinterest Email Design Tiny Homes Architecture Interior Design Green Design Urban Design It all adds up to a huge amount of electricity consumption and carbon, both embodied and operating. As noted earlier, I have committed to trying to live a 1.5° lifestyle, which means limiting my annual carbon footprint to the equivalent of 2.5 metric tonnes of carbon dioxide emissions, the maximum average emissions per capita based on IPCC research. That works out to 6.85 kilograms per day. One of the problems with trying to live a low-carbon lifestyle is actually figuring out what the carbon footprint of all the different things we do actually is. It is often surprising; my carbon footprint from using the Internet is higher than my footprint from food. To find out more about where our footprint comes from, I had each of my students studying Sustainable Design at Ryerson University look at some aspect of our lives, whether it be our diet, waste, clothing, or electronics. The students who covered electronics did some interesting work, and because the classroom went virtual mid-term, they did their presentations as videos, which I thought I would share with TreeHugger. The students looked at a number of aspects of the carbon footprint of electronics, including Bitcoin, which has been discussed on TreeHugger before. Michelle Lan writes: Bitcoin Bitcoin is a mined coin, which means the mining process creates its token. In this process, Bitcoin miners act as verifiers of the transaction in contrast to real-world miners who have to physically mine for gold. In doing so, Bitcoin miners compete and attempt to solve a puzzle to complete building a block; in other words, a set of transactions. Once a successful miner solves the problem, he or she receives a reward for their service; hence new Bitcoin comes to existence. According to Digiconomist, as of Sunday, March 22nd, 2020, Bitcoin's estimated electricity consumption is 68.5 TWh per year. In essence, this is equivalent to Czech Republic's annual electricity consumption, as well it is sufficient enough to power 6,342,327 American homes. The biggest drawback of the 'proof-of-work' consensus algorithm used by Bitcoin is the misuse of enormous energy. Although the 'proof-of-work' mechanism can effectively deter potential attacks, the concerns for its energy efficiency and sustainable practice are problematic. Alternatives to mining mechanisms that are more energy efficient include proof-of-stake (PoS). PoS reduces the computing power required to effectively mine a block since the system removes competition and works on one problem at a time. In comparison to proof-of-work as it uses many machines to solve one puzzle thus racking up energy consumption. Bitcoin could potentially switch to such a consensus algorithm, which would significantly improve its sustainability. Another solution to Bitcoin's high energy consumption is moving towards solar power and other green energy sources to mine. Gaming I have never been much of a gamer, and was very curious about how big a footprint it had. I had no idea it was so popular, either. Reese-Joan Young writes: It would be a severe understatement to describe the Video Gaming industry as anything but a “big deal”. As per a 2018 inquiry from Reuters, the revenue generated by it was stated to have “eclipsed that of all other major entertainment categories” - surpassing Television, Box Office Film and Digital Music. And looking to recent events, this growth hasn’t seemed to waver in the slightest. Amidst the movements towards self-isolation in global response to the COVID-19 pandemic, now, more than ever, there are more and more individuals stuck at home and gaming to pass the time while digitally interacting with others they would otherwise be unable to interact with. Despite how popular gaming is, there exists an astounding deficit in user understanding of their hobby’s environmental impact. I’ve chosen to analyze specific elements of the gaming industry to contribute to the dialog that aims to answer the question “how does an individual’s gaming hobby contribute to global carbon emissions?”. This issue of power consumption of video gameplay and graphics was mentioned in “Toward Greener Gaming”, published in 2019 by the Computer Games Journal. Computer gaming alone is said to make up “2.4% of all residential electricity in the United States, with carbon emissions equal to more than 5 million cars, adding up to $5 billion spent.\" As for upcoming initiatives, the industry’s focus on \"play anywhere\" experiences for mobile games, is projected to bring a more “increased energy footprint than with regular mobile gaming'' due to necessary energy usage of data centres and cloud networking infrastructure. SOLUTION: Redevelop video game concept generation strategies because an engaging story that addresses a meaningful social issue is very possible. An example of this is the Civilization game series, wherein the idea of a “circular economy” is conveyed and promoted as a core gameplay mechanic with the goal in-game being to establish “resources and production as precisely consumed by what one needs”. As for the relevance of gamification to the big idea of sustainability, it is important to remember that global change requires a shift in every sphere - and this act, as unnecessary as it may seem, provides a platform for such concepts and ideas to circulate within the Gaming Industry and influence society as a whole. How long do our electronics last? What can we do about it? Pooja Patel quotes Greenpeace: \"From its choice of energy to the selection of raw materials, the industry needs to reinvent the way that electronic devices are made and used in society to reverse the ever-increasing environmental impacts driven by the growth of the sector.\" Embodied Carbon Lin Gao explains that \"Embodied Carbon is Carbon generated by producing the materials of the electronics, moving the materials, installing the materials; it is the carbon [taken] to manufacture the electronics up to the delivery of it.\" Electronics are one of the most heavily-imported commodity groups in the North American economy. And shipping by air is the most energy-intensive method of shipping. Transportation as part of the upfront carbon emission adds on a great deal of upfront carbon emission for electronics. As globalization and international trade continue to increase, and the electronics consumption continues to increase, it is likely that electronics will continue to play a dominant role in upfront carbon emission on international trade. The upfront carbon emitted by imported electronic goods in one state is greater than the total amount of direct carbon emission of one state. Approximately 2/3 of the carbon emission of electronics can be traced to upfront carbon emission of it, which is the manufacturing of storage devices, semiconductor, and PCB components. The embodied carbon in the major parts and components that electronic goods used to assemble computer products account for nearly 60% of its total analyzed footprint, and the embodied carbon from various chemical, gases, metallic materials, and other semiconductor materials supplies, accounted for nearly 40% of its total analyzed footprint. What about power consumption? There is something to be said for these virtual presentations; they provide a record, and they can be shared widely. I certainly learned that the impact of our electronics goes far beyond their basic energy consumption, which Mara Caza covers in this talk."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:0f072b3d-fc16-4cd8-93a8-92b8d4817f9c>","<urn:uuid:2f043c1b-b424-499a-a983-be65a2f82d6a>"],"error":null}
{"question":"How can I traveling to Uyuni Salt Flats in Bolivia from other countries? Please explain ways to get there.","answer":"There are several ways to reach the Uyuni Salt Flats. You can enter Bolivia through San Pedro de Atacama desert in Chile or through Quiaca in Argentina, which involves a 2-3 day journey. For a quicker option, you can fly to La Paz or Santa Cruz in Bolivia, then take a short flight to Uyuni town. Within Bolivia, you can also take buses from La Paz or trains from Oruro, though these take longer.","context":["Bolivia Salt Flats Q&A\nThe Bolivia Salt Flats make up the largest and highest salt desert in the world. Situated in the Potosi region in southwest Bolivia (South America), the Bolivia Salt Flats, also known as the Uyuni Salt Flats, attract many visitors for their remarkable topography and otherworldly charm. Here are some answers to the most frequent travel questions.\nWHY SHOULD I VISIT THE BOLIVIA SALT FLATS?\nA Paradise for Photography:\nAt nearly 12,000 square kilometers in size, and an extraordinary flatness, the Bolivia Salt Flats provide an endless horizon, which allows photographers to experiment with perspective and proportion. The results yield very creative and fun pictures that will surely go up on your walls.\nThe endless horizon is perfect for playing with perspective & proportion\nIn addition, during the rainy season, the salt flats are covered with a thin layer of water, which creates an amazing mirror effect for truly breathtaking pictures. The effect is one of floating among the clouds!\nAt over 3,650 meters above seal level (nearly 12,000 ft.), the Bolivia salt flats can prove to be a challenging environment. The journey through the flats requires experienced drivers who also play the role of mechanics, as it is not uncommon for vehicles to break down. Only rugged, mechanical 4×4 vehicles are allowed in the salt desert because of the inhospitable environment. Also, it is very easy to get lost in such an expansive landscape, so it is important to hire good quality guides from a reputable tour company who know their way around. Finally, you can satisfy your inner explorer and visit beautiful caves, lakes and islands in the surroundings.\nSpend the night in a Salt Hotel:\nBelieve it or not, the Bolivia Salt Flats are home to several salt hotels that have sprung in the last few decades to accommodate the growing number of tourists. And they are not as rugged as people might think. Many offer great amenities, such as hot water, spacious rooms and even Internet service. The experience of sleeping in a salt hotel is definitely worth putting on your bucket list.\nWHEN SHOULD I VISIT?\nThe region has two marked seasons: wet and dry. The rainy or wet season usually begins at the end of November and lasts through March. The dry season is typically from April to November. Both seasons offer unique experiences of the Uyuni Salt Flats, so you should plan your trip based on what you want to do.\nDuring the rainy season, the Bolivia salt flats are covered in water. As such, travelers can capture amazing pictures of the Salar’s mirror effect but access to certain areas is limited. In addition, excessive rain may cause some tours to cancel. On the other hand, during the dry season, temperatures drop and the salt ground hardens. As such, visitors can explore the iconic Incahuasi Island, and other areas, usually inaccessible during the wet season.\nHOW DO I GET THERE?\nBecause the Uyuni Salt Flats are located in southwestern Bolivia, travelers can cross the border in Chile and Argentina. They can enter Bolivia through the San Pedro de Atacama desert in Chile or through the town of Quiaca in Argentina. From here, it will be two to three days before you reach the flats, however, the voyage is amazing as you’ll explore colorful high-altitude lakes, geysers, rock valleys and more. The scenery of the Bolivian plateaus are spectacular and a final visit to the Salar will be icing on the cake.\nIf you are looking for a quicker trip to the Bolivia salt flats, simply book a flight to either La Paz or Santa Cruz, Bolivia from where you can take a short flight to the town of Uyuni where the flats are located. In addition, other forms of transportation to Uyuni are available within Bolivia, such as buses (from La Paz) and trains (from Oruro). However, these can take long hours, which leaves less time to visit the country.\nTRAVEL RECOMMENDATIONS FOR THE HIGHLANDS: (La Paz, Tiwanaku, Copacabana, Lake Titicaca, Uyuni)\n- If you are flying to La Paz, we recommend you rest for at least 3 hours; do not eat much, as digesting food might be a bit slow during your first day due to the altitude. Also, you can drink coca tea (except those who suffer from high blood pressure and heart problems).\n- Wear comfortable footwear and clothes (dress in layers).\n- Drink water, wear sunglasses, sunscreen and sun cap.\n- Bring moisturizing cream and a small backpack for excursions.\n- Do not forget a camera or videocamera to capture the amazing places you’ll visit.\n- We recommend bringing abundant contact lens solution or an additional pair of glasses."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:a4afe139-8c46-4591-a303-0f503ee9bad2>"],"error":null}
{"question":"How does poor sleep affect heart health and mental well-being? I need specifics like percentages and symptoms.","answer":"Poor sleep impacts both heart health and mental well-being significantly. For heart health, people with frequent night-time awakening have a 26% higher risk of developing atrial fibrillation, while those diagnosed with insomnia face a 29% higher risk of AFib compared to those without sleep issues. AFib can lead to strokes, heart failure, and other cardiac complications. Regarding mental health, sleep disruptions interfere with neurotransmitters and stress hormones, leading to impaired emotional regulation and thinking. Sleep problems are commonly found as both a prerequisite and ongoing symptom in depression and anxiety disorder patients, and in PTSD patients, sleep disruptions can cause increased retention of negative emotional memories, reducing the effectiveness of fear therapy techniques.","context":["By AMERICAN HEART ASSOCIATION NEWS\nNEW ORLEANS — Disruptions in sleep may be raising your risks of an irregular heartbeat known as atrial fibrillation, according to preliminary research presented at the American Heart Association’s Scientific Sessions 2016.\nObstructive sleep apnea, sleep interrupted by pauses in breathing, is a known risk for atrial fibrillation – an irregular heartbeat that can lead to strokes, heart failure and other heart-related complications. But whether there’s a relationship between disrupted sleep and atrial fibrillation even when there’s no sleep apnea is unclear.\nResearchers at the University of California, San Francisco examined three sources of data to isolate and confirm the effects of poor sleep on atrial fibrillation. Their analyses showed that:\n- disrupted sleep, including insomnia, may be independently associated with atrial fibrillation;\n- people who reported frequent night-time awakening had about a 26 percent higher risk of developing atrial fibrillation compared to those who didn’t wake up a lot; and\n- people diagnosed with insomnia had a 29 percent higher risk of developing atrial fibrillation compared to those who do not have trouble falling asleep, getting enough sleep or sleeping poorly.\n“The idea that these three studies gave us consistent results was exciting,” said lead study author Matt Christensen, a medical student at the University of Michigan in Ann Arbor.\nResearch has shown a link between poor sleep among people who already had AFib, but this study focused on people whose pre-existing sleep disruptions were associated with developing AFib later in life.\nThe data sources included the Health eHeart Study – an internet-based cross-sectional study of more than 4,600 people; the Cardiovascular Health Study – an 11-year longitudinal study of just over 5,700 people, of which almost 1,600 (28 percent) developed atrial fibrillation; and the California Healthcare Cost and Utilization Project, a hospital-based database spanning five years and covering almost 14 million patients.\nIn all three studies, researchers adjusted for the effects of obstructive sleep apnea and AFib risk factors that might also be related to sleep. Some of those factors were age, sex, race, diabetes, high blood pressure, heart failure and smoking.\nIn a separate analysis, the same researchers reviewed a subset of the Cardiovascular Health Study to understand the effect of sleep disruptions during different sleep phases without obstructive sleep apnea on atrial fibrillation risks.\nThe analysis showed that having less rapid-eye movement sleep than other sleep phases during the night is linked to higher chances of developing atrial fibrillation.\n“By examining the actual characteristics of sleep, such as how much REM sleep you get, it points us toward a more plausible mechanism. There could be something particular about how sleep impacts the autonomic nervous system,” Christensen said. The autonomic nervous system plays a major role in controlling heart rate and blood pressure.\nAnother possible explanation for the link between sleep disruptions and atrial fibrillation is that frequent waking puts extra stress on the heart’s chambers, said Christensen. Participants in this analysis were also enrolled in the Sleep Heart Health Study. They had a formal sleep study to objectively measure sleep quality. That’s another element that strengthened the study’s conclusions, Christensen said, as it didn’t rely on self-reported data.\nIn this analysis, 1,131 people (average age 77) participated in a study with almost 10 years of follow-up.\nResearchers measured how long and how well participants slept, how long it took to fall asleep and the patterns of sleep (i.e., how much time was spent in REM sleep versus non-REM sleep). Then they analyzed the sleep disruptions’ effects to control the effects of age, sex, race, smoking, diabetes, high blood pressure and other risk factors.\nStudy authors say the exact link between sleep and how AFib develops is still a mystery, but we are getting closer to a clear picture.\n“Ultimately, even without a clear understanding of the responsible mechanisms, we believe these findings suggest that strategies to enhance sleep quality, such as incorporating known techniques to improve sleep hygiene, may help prevent this important arrhythmia,” said senior author of both abstracts Gregory Marcus, M.D., M.A.S., a cardiologist at the University of California, San Francisco.\nPoor sleep is a known culprit for other heart disease risk factors such as high blood pressure, obesity and stroke.","Sleep. Many of us know that we need to sleep. It’s a way to replenish and renew oneself to continue living and working productive lives. Some can function on only a few hours of sleep while others require extra hours of beauty rest, but sleep is also an impactor on mental health. Scientists have discovered that interruptions during sleep disrupt neurotransmitters and stress hormones. That means there can exist an inability to regulate emotions, and thinking can become impaired. Both of these are considered the most common symptoms of mental disorders.\nMany correlations have been found between sleep disorders and mental irregularities. Sleep issues were found as a prerequisite in many depression and anxiety disorder patients, and these patients also continue to report problems sleeping after being diagnosed. Sleep disruptions in PTSD patients can lead them to retain more negative emotional memories that prevent them from responding to fear therapy techniques as well. There are many other examples of links between sleep irregularities and mental disorders. From being a precursor to a more serious problem to being a symptom of a problem, sleep issues have historically gone hand-in-hand with mental diagnoses.\nIf you are having trouble sleeping and feel that you could be at risk for depression or anxiety disorders or are already diagnosed and think better sleep can help calm symptoms, there are a few things you can try to fall asleep better and sleep longer.\nGive It Up\nWe all know that caffeine is a stimulant used to make us feel more awake and provide a little energy, so it makes sense that it should not be consumed anywhere near bedtime. Alcohol and nicotine are two other examples of things not to be consumed before bedtime. Alcohol does help you to fall asleep, but its effects wear off quickly, causing you to wake up before you should. Nicotine speeds up your heart rate and causes your mind to race. If you cannot give these substances up completely, it is still recommended that you not use them prior to bedtime.\nWork It Out\nExercise is a way to expel energy and make the body tired, which is great for inducing sleep. It will also help the body to stay in deep sleep for longer and wake up fewer times throughout the night.\nCalm It Down\nActivities like yoga, meditation, and breathing exercises are great ways to relax the body and mind and ready for sleep. Taking the time to let the day go and calm the mind is a great way to be ready to lie down and catch some z’s.\nMany experts believe that insomnia is a learned thing and that it can be unlearned. You have the ability to train yourself into sleeping better and practicing “sleep hygiene” as it is sometimes referred to. Good sleep hygiene means creating a consistent sleep schedule of going to bed and waking up at the same hours each and every night and day, using the bedroom to sleep and not for any other activities like watching t.v. and eating, and creating a relaxing, sleep-inducing atmosphere in the bedroom that makes the body think of doing nothing but sleeping. The one exception in bedroom activities is sex.\nBy practicing good sleep hygiene and testing the tips listed above, your sleep quality should improve. By sleeping better you are at a greater risk for reducing mental health side effects and a lower risk of developing mental disorders in the first place."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:876751ab-060f-46c3-a1ed-e52f1c14353d>","<urn:uuid:c4b051b4-9645-4b06-8616-07bb1aecc223>"],"error":null}
{"question":"How did Genghis Khan and Gediminas differ in their treatment of conquered peoples regarding religious and cultural practices?","answer":"Genghis Khan granted religious freedom to his subjects and restructured the feudal system to be based on loyalty rather than ethnicity. However, he was known for massacring populations that resisted his rule. Gediminas, on the other hand, made specific promises to respect local governance customs when conquering territories like Volhynia and Kyiv, pledging not to take away lands from local nobles and to appoint only locals to high offices.","context":["Oleksandr Palii, A History of Ukraine, 20.01.2018\nThe lands of the Lithuanian tribes were separated from the Mongols by dense forests. Lithuanian chieftains acquired military experience as they launched attacks on the lands of the former Kyivan state, Poland and the Teutonic Order. The Belarusian chronicle reported that the Lithuanians were so poor prior to their ascent that they paid tribute to Galician and Volhynian princes in bast and brooms for lack of more valuable goods.\nDuring the rule of the Lithuanian Grand Prince Gediminas (1295–1341), Lithuanian forays turned into a massive onslaught. Noteworthily, his predecessor Prince Butvydas was forced to give Galician and Volhynian princes lands in the center of the Duchy of Lithuania “for the sake of peace”. According to Lithuanian chronicles, the great Lithuanian army invaded Volhynia in 1320, seizing the city of Volodymyr. The boyars made an agreement with Gediminas, acknowledging him their supreme ruler, while he pledged to respect governance customs, not to take away the possessions of the Volhynian nobility and to appoint only locals to offices.\nGediminas attacked the Kyiv principality in 1321 and the Rus’ princes were defeated in a battle on the Irpin River near Kyiv. The Kyivans withstood a siege for a month but then made an agreement with Gediminas acknowledging him as supreme ruler. In exchange, he again promised not to violate the established order, not to take away the lands of the local magnates and to appoint only Rusyns to high offices. Gediminas acquired the title of “the king of the Lithuanians and the Rusyns (another known as Ruthenians)”.\nLithuanian Grand Prince Gediminas (ruled in 1295-1341), engraving, 16th century.\nThe new state began to be called the Grand Duchy of Lithuania, Ruthenia and Samogitia (from the name of a region in northwestern Lithuania). It's interesting that due to there was no written Lithuanian language at that times, the Ruthenian (i.e. Old Ukrainian) language, as the most widely spoken one by almost 80% of population, has been used in the official documents of the Grand Duchy until ... 1697, albeit Latin, German, and later Polish were sometimes used too. Another amazing fact is that only in 1387 Lithuania itself and their princes were finally baptised, being before a true pagan state.\nIt should be noted that Muscovy was under Mongol rule for over 240 years, three times longer than Ukraine. Ivan I Kalita (ruled in 1325–1340), one of the founders of Muscovy, spent most of his time on the throne not in ruling in Moscow but traveling to Saray.\nMuscovy freed itself from the Great Horde as late as in 1480, while tribute was last paid to the descendants of Genghis Khan (ruled in 1206-1227) in the early 18th century. The Mongol-Tatar yoke was denigrating even to the nobility. Contemporaries wrote that Muscovite princes met, on foot, Tatar envoys on Poklonnaya Hill. They would take Tatar horses by the bridle and gave them mare’s milk to drink and if it dripped onto the horse’s mane, they would lick it up. After casting off the Mongol-Tatar yoke, Muscovite princes put an even greater burden on other peoples. In particular, they destroyed, to the last man, the population of Novgorod, which was closely tied to Kyiv by history and religion.\nLithuanian Grand Prince Vytautas the Great (ruled in 1392-1430)\nAround 1362, the decisive battle against the Mongols and Tatars took place at Syni Vody (Blue Waters, according to various versions, on the Syniukha River or the Snyvoda River in Central Ukraine). Ukrainian units made up the bulk of the army of the Grand Duchy of Lithuania. The main enemy forces were crushed and the Mongol-Tatar khans died in action. This victory marked the end of the Horde’s power over the larger portion of the Ukrainian lands. As a result of the victory, the Grand Duchy of Lithuania and Ruthenia extended to the Black Sea coast. The Mongol empire had been expanding until that time, but began to disintegrate starting from the 1360s.\nFortress in Bilhorod-Dnistrovskyi (White town on Dnister river), controlled by the Kyiv principality in late 14th and early 15th centuries.\nFor more than three decades after the battle at Syni Vody the Tatars were practically not seen in Kyivan lands. The country began to revive.\nTO EPISODE 30","Genghis Khan (c. 1167 – August 18, 1227) was a Mongolian ruler who became one of the world's most powerful military leaders, who joined with the Mongol tribes and started the Mongol Empire. He was a Mongol Emperor who was very successful in battles, conquering many other peoples such as the Jin Dynasty. He was a very strong and powerful emperor who occupied much of China and some surrounding countries of China. His children and his grandchildren started the largest empire in the world. Genghis Khan's grandson, Kublai Khan, was the first ever emperor of the Yuan Dynasty (1271–1368) in China.\nGenghis Khan's real name was Temüjin which means iron worker. Because of his military success people referred to him as Genghis, meaning \"Universe ruler\". Many people were killed by his armies and he gained a reputation as a \"brutal monster\". Genghis Khan died in the Liupan Mountains in northwestern China, in Aug. 1227  His burial site is unknown.\nEarly life[change | change source]\nLineage[change | change source]\nTemüjin was related on his father's side to Ambaghai and Qutula Khan who had headed the Mongol confederation. When the Chinese Jin Dynasty switched support from the Mongols to the Tatars in 1161, they destroyed Khabul Khan. Genghis's father, Yesügei (leader of the Borjigin and nephew to Ambaghai and Qutula Khan), emerged as the head of the ruling clan of the Mongols, but this position was contested by the rival Tayichi’ud clan, who descended directly from Ambaghai. When the Tatars grew too powerful after 1161, the Jin switched their support from the Tatars to the Keraits. When Yesügei was poisoned, Temüjin who was only 13, became leader.\nBirth[change | change source]\nBecause of the lack of records, there is very little information about the early life of Temüjin. The few sources that provide insight into this period often conflict.\nTemüjin was born in 1162 into an influential family who were part of a Mongol tribe near Burkhan Khaldun mountain and the Onon and Kherlen Rivers in modern-day Mongolia, not far from the current capital Ulaanbaatar. The Secret History of the Mongols reports that Temüjin was born with a blood clot grasped in his fist, a sign that he was destined to become a great leader. He was the second-oldest son of his father Yesükhei, a minor tribal chief of the Kiyad and an ally of Ong Khan of the Kerait tribe, and the oldest son of his mother Hoelun. According to the Secret History, Temüjin was named after a Tatar chieftain whom his father had just captured. The name also suggests that they may have been descended from a family of blacksmiths.\nYesükhei's clan was called Borjigin (Боржигин), and Hoelun was from the Olkhunut, the sub-lineage of the Onggirat tribe. Like other tribes, they were nomads. Because his father was a chieftain, Temüjin was of a noble background. After his death his third son Ogodei succeeded him. He had four queens, and Ogodei was born from his first wife.\nReputation[change | change source]\nAs a ruler, Genghis lowered taxes and got rid of taxes for doctors, teachers and priests. He created the first international postal system. His empire was not known to be greedy with their loot; instead he would spread the wealth among the conquering Mongolians. Temujin eradicated torture, and held no prisoners; instead he merely killed his enemies. In doing so, he became respected. He completely re-made the feudal system to disregard people’s ethnicity and instead based it on loyalty and accomplishments. He gave his people religious freedom, unlike empires that limited their people to one religion.\nThese benefits were enjoyed by those who surrendered immediately to the Mongol invaders. Those populations that resisted would be massacred as a warning to other towns and cities. These massacres were a method of psychological warfare to terrify those not yet conquered. The terror endured, and helped color the historical portrayal of the Mongols.\nPhysical appearance[change | change source]\nNo accurate portraits of Genghis Khan exist, and any surviving depictions of him are considered to be artistic interpretations. Persian historian Rashid-al-Din recorded in his \"Chronicles\" that the legendary \"glittering\" ancestor of Genghis was tall, long-bearded, red-haired, and green-eyed. Rashid al-Din also described the first meeting of Genghis and Kublai Khan, when Genghis was shocked to find that Kublai had not inherited his red hair. Also according to al-Din, Genghis's Borjigid clan had a legend involving their origins: it began as the result of an affair between Alan-ko and a stranger to her land, a glittering man who happened to have red hair and bluish-green eyes. Modern historian Paul Ratchnevsky has suggested in his Genghis biography that the \"glittering man\" may have been from the Kyrgyz people, who historically displayed these same characteristics. Controversies aside, the closest depiction generally accepted by most historians is the portrait currently in the National Palace Museum in Taipei, Taiwan (see picture above).\nReferences[change | change source]\n- Davis, Richard L. \"Genghis Khan.\" World Book Advanced. World Book, 2013. Web. 27 Feb. 2013.\n- \"Genghis Khan.\" Encyclopedia of World Biography. Detroit: Gale, 1998. Biography In Context. Web. 27 Feb. 2013.\n- Ratchnevsky, Paul (1991). Genghis Khan: His Life and Legacy. Blackwell Publishing. pp. 9–10. ISBN 0-631-16785-4.\n- \"World Book\". www.worldbookonline.com.\n- \"Genghis Khan.\" World History: Ancient and Medieval Eras. ABC-CLIO, 2013. Web. 27 Feb. 2013.\n- Morgan, David (1990). The Mongols (Peoples of Europe). p. 58.\n- Guida Myrl Jackson-Laufer, Guida M. Jackson-Encyclopedia of traditional epics,p. 527\n- Paul Kahn, Francis Woodman Cleaves-The secret history of the Mongols, p.192\n- \"THE MONGOLS — PART I\". Republican China. Retrieved 2008-05-20.\nOther websites[change | change source]\n- \"The History of Genghizcan the Great, First Emperor of the Antient Moguls and Tartars\" is a very old book about Genghis Khan from 1722"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:21df97bf-af3a-49f7-beec-4c98200080a7>","<urn:uuid:b495c599-ef60-44ac-9c4c-f9933e679e78>"],"error":null}
{"question":"How does seasonal gardening differ between Florida's winter birds habitat and northern community gardens?","answer":"Seasonal gardening varies significantly between Florida and northern communities. Florida gardens uniquely support winter bird species, with the highest diversity of wintering land birds found in northern Florida, including Mourning Doves, Northern Cardinals, Blue Jays, and various species that nest during winter months like Bald Eagles and Great Horned Owls. In contrast, northern communities like Holland focus on spring celebrations with specialty tulips and need to get creative during winter months for garden interest. While northern gardens emphasize seasonal flowers and spring blooms, Florida gardens can maintain year-round flowering plants like Wild Poinsettia, which flowers throughout autumn in North Florida and year-round in South Florida, providing continuous support for local wildlife.","context":["Greenery and fragrant plants should be the focus of local gardeners.\nAt tables adorned with the bells of the ball, Tulip Time visitors dined at Haworth Inn and soaked up gardening tips from America in Bloom President Katy Moss Warner.\nNearly 100 participants listened in to the Tuesday, May 9, keynote speaker, who spent 24 years and the Walt Disney World director of horticultural and environmental initiatives.\nThroughout Moss Warner’s career, she has been fighting what she calls “plant blindness,” an inability people have to actively recognize the landscape around them.\n“We are not only plant blind, but also nature beauty blind,” Moss Warner said at the luncheon. “We just don’t see the landscape around us. That’s a pretty scary thought.”\nNow, Moss Warner focuses on proving the power plants have to improve communities.\n“Really well-maintained parks in a community can reduce the crime rate and a canopy of trees overhead slows down traffic,” she said. Familiar to Holland residents, Moss Warner also said quality landscaping and focus on plants can bring significant tourism to communities.\n“There’s no question that quality of landscapes contribute to quality of life,” she said.\nWhile parks and community gardens are a great start to community beautification, there is a responsibility for homeowners to take part, too. Moss Warner said no matter what kind of home someone lives in, residents can help improve their community.\nFor those living in apartments, Moss Warner said to utilize window boxes and planters on balconies.\nResidents with yards have a wider variety of options, and Moss Warner encouraged homeowners to experiment with their gardens.\n“Get away from lawns,” Moss Warner said. “They’re boring and they’re only good for walk-on ground cover. Plus, then you don’t have to mow.”\nMoss Warner said people should first focus on trees, shrubs and ground cover in front yard gardens.\n“The most important thing is to deliver green,” Moss Warner said. “We can create beauty for others to enjoy as they walk, bike and drive by. We can do it all by ourselves.”\nThen, gardeners should focus on seasonal flowers, including how to get creative during winter.\n“You’re lucky, here, that you have something that celebrates spring,” Moss Warner said. “There’s such wonderful surprises in specialty tulips.”\nWhile most people focus on color and height when planting new additions to their gardens, Moss Warner said people should also take note of fragrance levels. Flowering bushes like lilacs and roses are best to plant near front sidewalks, encouraging neighbors and visitors to stop and appreciate the aromatic flowers.\nMoss Warner said backyard gardens are most suitable to lawns, overhead trees, natural shrub fences and low maintenance perennial flowers. Backyards are also the best spot for herbs and produce gardens.\nAs an America in Bloom community, Moss Warner said she was impressed with the gardening and landscaping ideas she sees in Holland.\n“Would I want to live here? After I leave Holland, I always answer yes to that question,” Moss Warner said. “It’s a great community to live in.”\n— Follow this reporter on Twitter @SentinelAudra.","The Audubon Observer, December 2019\nNATIVE PLANTS FOR BIRDS: WILD POINSETTIA\nTo help you create bird friendly habitat in your landscape, we are sharing a native plant every month that is beneficial to birds and pollinators.\nThis month's plant is:\nWild Poinsettia (Poinsettia cyathophora)\nWild poinsettia is a native plant which grows in scattered locations from Florida to California, north to Virginia and across to Minnesota in the Midwest. It has many names, including painted leaf, fire on the mountain, painted spurge, and summer poinsettia among them. It is a relative of the showy Mexican poinsettia which everyone uses at Christmastime. The Mexican poinsettia was first brought to the United States by Joel Poinsett, U.S. Ambassador to Mexico from 1825-1829 as he admired the red and green plant. The rest is history.\nThe wild poinsettia is an erect annual or short-lived perennial which grows 1-2 feet tall. It will grow in full sun to part shade with average moisture. Once established, it will tolerate considerable drought and maintains itself by self-sown seeds. Due to its ease of growth, long flowering season (autumn in North Florida and year round in South Florida), it is a welcome addition to native plant gardens. Please note that like the Mexican poinsettia, it is poisonous so be careful if you have small children or pets who might try to taste it.\nIt attracts butterflies such as the White Peacock; bees will drink the nectar from its tiny flowers, and the seeds are a great favorite of Mourning Doves.\nFor additional information on native plants for birds, check out Audubon's excellent Plants for Birds website: Audubon.org/plantsforbirds.\nFor local sources of native plants, check with the Ixia Chapter of the Florida Native Plant Society. They often have native plants as well as cuttings available at their monthly meetings on the first Tuesday of each month. Check out their Events Calendar for all of their upcoming activities.\n--Jody Willis, President\nDUVAL AUDUBON COMMUNITY OUTREACH\nIn addition to our ambitious field trips and monthly programs schedule, Duval Audubon Society volunteers are active in our community, fulfilling our mission of \"connecting people with nature\" whenever and wherever our busy schedule allows. Here are some of our recent community outreach activities:\nThis fall we sponsored a bird-focused art installation and informational kiosk at Women Writing for (a) Change, Jacksonville, and led two urban bird walks for their group in the Riverside area in conjunction with their BIRDS art show and community conversation events. Their mission is \"to nurture and celebrate the individual voice by facilitating supportive writing circles and by encouraging people to craft more conscious lives through the art of writing and the practices of community.\"\nWe also gave our \"Birding for Beginners\" presentation to Groundwork Jacksonville's CREST (Community Restoration Environmental Stewardship Training) program participants and led a wonderful bird walk for the group at McCoys Creek near Hollybrook Park. Seventeen program participants learned how to use binoculars and spotted twenty bird species during the bird walk, including an unexpected sighting of a Limpkin!\nAccording to Groundwork's Community Engagement Specialist Gloria McNair, the CREST program \"works to build environmental stewardship and empower community leaders in our largely under-served urban core neighborhoods. During community engagement meetings, residents of the McCoys Creek area showed a strong interest in leadership, career, and educational opportunities for youth and adults. In response to this feedback, CREST was conceived and designed to help residents and other stakeholders of the community achieve some of their goals around personal and community growth.\"\nThis fall, chapter volunteers also gave presentations at two local garden clubs about backyard birds in the winter months as well as the best plants (native, of course) to attract and support birds, and led a special bird walk at our Crosby Sanctuary in Orange Park in partnership with the fine folks at the Argyle Forest Wild Birds Unlimited location.\nWe believe that those who appreciate the natural world around us will want to do what they can to preserve and protect it, and we are thankful for the opportunity to share our love of birds and nature with our community.\n--Carol Bailey-White, Vice President\nTIPS TO REDUCE YOUR PLASTIC FOOTPRINT\nIn response to the enormous amount of plastics being dumped into the ocean, landfills, waterways, and streets, and reports that we are constantly ingesting and breathing microplastics, Duval Audubon Society board member Carolyn Antman recently set about to severely reduce the amount of new plastic she uses in her daily life. Here is the first in a new series with ways you can help imperiled birds by reducing your plastic footprint:\n\"It took some effort in the way of research, changes in behavior, and self-restraint, but I am making progress. I hope that these monthly tips will make it easier for you to do the same.\nWe know that we should use reusable grocery bags at check-out, but many of us are still using the plastic bags provided by the grocer to sort our vegetables. Lightweight cloth bags that can be made from old sheets or pillowcases work just as well. They can be made in various sizes and are easily washable when needed. Here's how to make them.\nAlso, I’ve accumulated a lot of the red, stretchy bags (left) that oranges often come in and these are very durable and can be re-used many times for this purpose. However, I won’t buy any more. Some produce, like grapes and berries, are almost impossible to find without plastic containers. The farmers’ market is about the only place I’ve found these loose.\nImagine if every day 10 million people refused two plastic bags (there are almost 330 million people in the US) that would be 20 MILLION bags A DAY not in circulation. That IS a difference, and we can make that difference one person at a time.\nYour actions DO have an impact, so please choose to make your impact a positive one.\"\n--Carolyn Antman, Conservation Chair\nWHAT BIRDS MIGRATE TO FLORIDA IN WINTER?\nWinter brings snowbirds to Florida, and not just of the human species! “The highest diversity of wintering land birds can be found in the northern part of the state. Mourning Doves, Northern Cardinals, Blue Jays, Red-bellied Woodpeckers, Red-winged Blackbirds, and Common Grackles are common feeder birds throughout the state,” claims BirdWatchersDigest.com. Several species are known to nest and raise their young throughout Florida’s winter months, such as Bald Eagles, Great Horned Owls, and Ospreys. How lucky we are that migratory patterns guide everything from warblers to waterfowl and shorebirds to raptors (that suppress rodent populations) through Northeast Florida. Land species such as Eastern Phoebe, Hermit Thrush, Ruby-crowned Kinglet, American Robin, and Cedar Waxwing are common to our area in the winter months as well. To learn more about the types of birds that migrate either through or to Florida for the winter, check out this extensive list at OpticBird.org.\nAs we prepare for family gatherings and feasting this season, don’t forget to provide a delicious meal for our winged friends flying in from the north. According to AllAboutBirds.org, black oil sunflower seeds are high in protein and fats with a thin shell easy enough for most bird beaks to crack. Switch to striped sunflower seeds, which has a thicker shell, if you’re “inundated with species you’d rather not subsidize,” (like House Sparrows and European Starlings). Some seed mix has too much filler and may not be attracting the species you’d like to see in your backyard, so instead try safflower, which has a thick shell that’s hard for some birds to crack open but is a favorite among cardinals and finches.\nAlready feeding the locals and beyond? You’re impacting conservation in a big way, according to a study led by Virginia Tech, Cornell Lab of Ornithology and University of Georgia. “Looking at how humans react to and manage wildlife in their own backyards is very important for the future of wildlife conservation...” Read more at EurekAlert.org and use eBird to assist conservation efforts on a bigger scale.\nHave questions or comments about a species or food type? Connect with us via our social channels or email. Duval Audubon Society is your connection to local and state birding.\nParents! Check out our Kids’ Corner:\nReading Standards for Informational Text (RIT)\nReading Standards: Foundational Skills (FS)\nEarth and Human Activity\n--Cristina Tuckness, Education Chair\nOur 2019/2020 season continues this month with more exciting activities. Please join us for one (or more) of our upcoming field trips or programs.\nPlease, always check our website for any last-minute changes before heading out the door, just in case something has come up. We hope to see you soon!\nBest wishes for a joyous and BIRDY holiday season!\nDuval Audubon Society, Inc."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:aa8399b4-4a08-48c2-85df-c80f440d4a73>","<urn:uuid:59581b1f-1b6c-487f-9cfe-03f45bebb661>"],"error":null}
{"question":"How did DHL start its business and what was their innovative approach to document delivery in the early days?","answer":"DHL started in 1969 by offering free round-trip plane tickets to Hawaii for people willing to carry documents in their luggage. They recruited waiters, secretaries, and professors to transport bills of lading on red-eye flights from San Francisco to Honolulu. Once the documents arrived, local couriers would deliver them to clients. This innovative approach helped businesses avoid the unreliable postal service and ensured timely delivery of critical documents needed for clearing cargo at ports. The system was particularly important during the containerization era when shipping documents needed to arrive quickly to prevent goods from piling up at ports.","context":["Global delivery company DHL started its business by offering free plane tickets to people on the street. For the trouble of giving up their baggage allowances, passengers were handed a free round-trip plane ticket to Hawaii.\nFounded as a courier service in 1969, DHL used the spare capacity in travelers’ luggage to transport high-value documents. To understand why it made sense for DHL to provide free tickets to travelers, it helps to understand the massive changes entailed by the containerization of ocean cargo in the 1960s.\nFirst implemented in the mid-1960s, the ocean container dramatically improved the efficiency of international shipping. But containerization also brought about an unexpected downside: When goods are shipped by sea, a piece of paper known as the “original bill of lading” must serve as title to the merchandise. Created by the manufacturer overseas, this piece of paper must be delivered to the purchaser in the destination country.\nThe massive capacity of containerized ships meant that many more shipments would arrive in ports in a much shorter span of time. That was a problem: The documents necessary to clear cargo arrived much later than the cargo did. Goods started piling up in ports, frustrating importers, truckers and port terminals.\nThat’s where DHL came in. The company offered businesses the chance to transport documents by air. No, it didn’t invest in airplanes then. Instead, it found people who were willing to carry documents in their luggage in exchange for a free plane ticket. Waiters, secretaries and professors were sent on red-eye flights from San Francisco to Honolulu if only they would carry suitcases stuffed with these bills of lading. Once these high-value documents were on the ground, the company’s network of local couriers would take responsibility for delivering them to clients.\nHow DHL scaled\nThe system worked amazingly well. The postal service then was notoriously slow and unreliable. By taking important documents and putting them in suitcases, DHL was able to guarantee timely delivery of critical business documents.\nGiven that it skirted the postal monopoly, you might even refer to DHL’s original model as “smuggling as a service.”\nIt’s no surprise that DHL started with service from San Francisco to Honolulu: It was the most active tradelane of Matson, one of the first shipping lines to adopt standardized ocean containers. Couriers from DHL helped businesses avoid the unreliable postal monopoly so that goods could clear more quickly through the ports. People on the mainland suddenly found that their documents could be delivered before their offices even opened.\nDHL soon expanded to other tradelanes, building a worldwide network that was especially prominent in Asian to U.S. air delivery services. Eventually it became a multibillion-dollar business that was acquired by Deutsche Post, helping to create what is now the largest courier service in the world (and ironically a former postal monopoly, before it was privatized by the German government).\nThat’s how DHL was a pioneer in the sharing economy long before the term was invented. People who wouldn’t otherwise fully use their luggage capacity would trade off that space to people willing to bid for it. Given that it skirted the postal monopoly, you might even refer to DHL’s original model as “smuggling as a service.”\nEventually, DHL caught the attention of the now-defunct Civil Aeronautics Board. The company won these challenges brought by the board in a United States Court of Appeals for the Ninth Circuit ruling. Two FBI agents sent to investigate DHL were convinced that it was a legitimate enterprise—and then promptly became couriers themselves.\nAn industry little changed even now\nDHL developed a brilliant hack to solve an archaic problem. The company found a cheap, scalable solution to deal with obstacles and built a multibillion-dollar business in the process.\nDHL saw that containerization brought a new challenge to importers: They didn’t want to wait for their shipments to clear simply because paperwork took too long to arrive. Nobody likes an obstruction, but having a bureaucratic one is especially galling. Did the unreliability of the postal service mean that everyone had to wait around doing nothing while port charges racked up? Surely we’ve figured out a better way to clear goods today.\nAs it turns out, we really haven’t. Businesses still need an original bill of lading to securely collect goods from port terminals. It’s an incredibly outdated issue—starting with its very name. “Lading” is a British term for “loading” that dates back to the Tyndale Bible of the 16th century. Bills of lading used to be tradable goods in Britain.\nThis was an innovation 400 years ago: You could sell a bill of lading in a marketplace, rather than having to transport the goods there. Little has changed in the last few centuries. When truckers come to pick up goods in the terminal, they still need to present the original bill of lading to get the port to release goods.\nIn a world with the Internet, cryptography and the blockchain, shouldn’t there be a better way to enable the secure release of cargo internationally? Surely technology will solve this problem. Let’s take a moment to appreciate DHL’s innovation and its relevance to conversations about the sharing economy."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:9d9d8acf-0994-471f-911b-58614637802a>"],"error":null}
{"question":"What is the significance of sulfur dioxide in both wine and cider production, focusing on its preservative functions and application timing?","answer":"Sulfur dioxide serves as a critical preservative in both wine and cider production, with multiple important functions. In cidermaking, it inhibits the growth of spoilage yeasts and bacteria while allowing desirable fermenting yeasts to dominate the alcohol conversion. It's typically added before fermentation, with dosage levels dependent on juice pH. In winemaking, SO2 acts as both an antimicrobial agent (killing bacteria and fungi) and an antioxidant (preventing oxidation damage). It can be added at four key stages: during grape arrival, at the start of fermentation, after malolactic fermentation, and before bottling. In both beverages, the goal is to use sulfur dioxide judiciously to preserve the drink's character, flavor, and color while preventing spoilage and unwanted fermentation. The preservative helps stabilize the final product and enables proper aging.","context":["Wood is quite permissible and of course for many years was the only practicable material for fermentation and storage vats. It may be difficult to keep clean and free from bacteria but at least it will not poison anybody! Wood coated with modern polyurethane varnish (e.g. for press racks) is much easier to keep clean than is unsealed wood. For fermentation and storage tanks, food grade stainless steel, plastics, fibreglass and epoxy resins are generally preferable to wood, because they contain no pores where undesirable bacteria and moulds can lurk. Glass is also very satisfactory on a small-scale. If you particularly want to use wooden barrels, make sure that they are well scoured, bleached and rinsed or steamed beforehand. They should also be 'sweetened' with 5% sulphur dioxide solution (see Table) before a final rinse with clean water. It should go without saying that all equipment and containers in contact with juice or cider should be well cleaned (and well rinsed) beforehand. Modern non-foaming sterilising detergents such as 'VWP' are most effective in this role, and should be used according to the instructions given on the packet.\nPreviously we described the composition of the ideal cider fruit in terms of materials such as sugar, acid and tannin. Sugar levels are set largely by the weather - in a good summer we might expect them to be as high as 15%, but in a cool wet summer less than 10% might be achieved. The sugar levels can be measured directly on a drop of juice squeezed out from the fruit, using a hand held refractometer. This equipment is expensive (ca £70), but is often used by grape-growers, who need to measure sugar content daily as harvest approaches. For cider-making, the changes in sugar levels are not so critical and the fruit will usually have been stored for a while to convert all the starch into fermentable sugar anyway. So it is usual to measure the juice 'specific gravity' (S.G.) after pressing, using a hydrometer, which is much cheaper (ca £5). Roughly speaking, 15% sugar corresponds to an SG of 1.070 and a total potential alcohol of 8.5 %; 10% sugar is SG 1.045 and a potential alcohol of 6%. If the juice S.G. is less than 1.045 and you have no sweeter juice for blending, it should be brought up to this level by the addition of sugar or apple juice concentrate. Otherwise the resultant alcohol level may not be sufficient to protect the final cider during storage. To raise the S.G. in 5° steps, dissolve 12 - 15 grams of sugar in each litre of juice and re-test with the hydrometer until the desired level is reached.\nMeasurement of pH has to be done by a dedicated 'pH meter'. These used to be very expensive, costing several hundred pounds, but modern 'chip technology' has now brought them down to the range of £30 or so. However, beware the very cheap pH meters which are sold in garden centres for soil testing - these are not accurate enough for cidermaking because we need to measure to at least the nearest 0.1 pH unit or it is not worth making the measurement at all! Narrow range 'pH papers' (e.g. pH 2.8 to 4.2) are now available cheaply from some home brewing suppliers and are a reasonable substitute although not as accurate. A desirable juice pH range for cider-making is say 3.2 - 3.8. At higher pH the fermentation will be subject to microbial infection and at pH 4.0 or above this can lead to serious flavour problems. Many traditional bittersweet cider apples tend to be high in pH which is why they need blending with more acid fruit, preferably before fermentation. That is one reason why bittersharp apples, such as 'Kingston Black', have been regarded as near perfection in terms of their composition for single-variety cider making.\nIf you cannot measure the acidity or the pH, taste the juice instead. Trying to ignore the sweetness and the tannin, judge whether the juice is insipid, balanced or sharp. If insipid, and you have no other juice for blending, malic acid may have to be added in steps of 1 gram per litre (0.1%) until the balance is improved. If the juice is too acid, and you cannot blend it out, you may have to encourage a malo-lactic fermentation to reduce it (see later), or you can add a little calcium carbonate to neutralise it, in 1 gram per litre steps.\nOther juice parameters, such as tannin, are difficult to measure, but only people using a high proportion of bittersweet fruit are likely to suffer from excessive tannin and this can usually be detected by taste although the juice sugar does tend to mask it. Deficiencies here can be corrected after fermentation, however. The purpose of blending before fermentation is to give a juice as close in composition to the 'ideal' which was described in the previous article. Although this may not always be possible, it is always worth the attempt at least in terms of sugar and acid levels. Blending after fermentation is a worthy and useful art but it cannot correct a gross biochemical imbalance beforehand!\nThe blended juice should now be strained through a coarse plastic mesh into a suitable clean vessel for fermentation. Whatever scale you are working on, you must also have some sort of 'airlock', whch can be fitted before fermentation begins or shortly afterwards, to allow carbon dioxide gas to escape but to prevent air getting in. At this point a number of other additions may be made. If it is important that the final cider should be sparklingly clear, a pectolytic enzyme may be added, which will help to ensure that all the pectin is broken down. Pectin is a sort of natural glue which sticks the apple cells together. Although it is water-soluble it is precipitated by alcohol, so it tends to lead to persistent hazes by the end of fermentation. Dessert fruit, or long-stored fruit, tends to suffer more from pectin release than does bittersweet fruit and will often give a very cloudy cider unless depectinised. Although there are natural enzymes in both apple and yeast which will break down the pectin during fermentation, these enzymes are often rather weak and require some assistance. The dosage rates for the commercial enzymes are given by the suppliers.\nThe next potential addition is that of vitamins and yeast nutrient. These may be bought as such or may be added as thiamine and ammonium sulphate (or phosphate) respectively. The dosage rate is up to 0.2 milligrams per litre of thiamine and up to 300 milligrams per litre of ammonium salt. This is what was meant by 'amino nitrogen' in Table 1 of the previous article, and it is needed by the yeast to make protein and amino acids for its own growth. (This is not unlike human and animal nutrition - the yeast's carbohydrate or energy source is of course the apple sugar which is not in short supply!) Apple juices are generally very low in yeast nutrients (unlike beer worts or grape musts) and so your fermentation rate will probably be much improved if you add these. The fermentation is also much less likely to 'stick' or to grind to a halt before completion. The cider can therefore be racked and bottled sooner, reducing the chances of spoilage in store. On the other hand, it is undeniable that some of the finest ciders are fermented very slowly without the addition of nutrients, but the risks of failure are correspondingly greater. You pays your money and you takes your choice! Traditional cider-makers used to hang a leg of mutton or a side of beef in the fermenting vat to boost the nutrient levels. The meat broke down slowly in the acid juice, releasing soluble amino nitrogen which the yeast could use for growth. The supposed requirement of a few dead rats in every vat is a more colourful manifestation of the same idea!\nIn simple terms what happens is that the sulphur dioxide inhibits the growth of most spoilage yeasts and bacteria, while permitting the desirable fermenting yeasts (such as Saccharomyces cerevisiae or uvarum) to multiply and to dominate the conversion to alcohol. Only small amounts of sulphur dioxide are used, and its effectiveness depends on the pH of the juice. The Table shows the appropriate levels to use when a cultured yeast is being added for the fermentation. Lower levels are needed if a 'wild' Saccharomyces fermentation is required (see below), or there is a danger that all the wild yeast will be killed. In the absence of sulphur dioxide, the fermentation is much less likely to be 'clean' although with care it is possible to do without it. A great deal of the concern about sulphite derives from its excessive use at bottling not during fermentation, and from the fact that a very few people are hypersensitive to it in the free state. However, it must be stressed that no sulphur dioxide remains free by the end of fermentation, since it becomes bound to various intermediate chemicals (principally acetaldehyde) which the yeast produces on its route from sugar to alcohol. I would always advise the beginner to use sulphur dioxide to minimise the risk of taints and infection. Later on, the experienced cidermaker can omit it at his discretion and see what difference it makes.\n|Above 3.8 (insipid)||.....Lower pH to 3.8 with addition of malic acid.....|\n|3.8 - 3.5||150||3|\n|3.5 - 3.3 (balanced)||100||2|\n|3.3 - 3.0||50||1|\n|Below 3.0 (sharp)||None||None|\n1. If a pH meter or test strips are not available, use the taste of the juice as a guide. If you cannot measure pH but you are using dessert fruit, you can assume the pH of your juice will probably be in the range 3.0 - 3.3, so the best plan is to use just 1 Campden tablet per gallon of juice.\n2. To make a 5% stock solution of sulphur dioxide, dissolve around\nof sodium or potassium metabisulphite in 100 ml of water. (The\nmetabisulphite salts contain around 50 - 60% of available SO2 depending\non how they've been stored). Then 1 ml of this per\nof juice (5 ml per gallon) corresponds to 50 ppm (parts per million) of\n3. Campden tablets are formulated with metabisulphite and give the equivalent of 50 ppm sulphur dioxide when each is dissolved in 1 (Imperial) gallon of liquid.\nSmall quantities of branded wine yeasts can be purchased from home winemaking suppliers. On a larger scale, you can buy specific strains of S. cerevisiae, bayanus or uvarumwhich are mostly produced overseas for the wine and fruit wine industries there. Modern dried yeasts are sometimes 'pitched' direct, but often the yeast is rehydrated and grown on overnight as a 'starter' in sterile juice or sugar solution, and then pitched into the main bulk the next day. Sometimes the yeast only needs hydrating for 20 minutes or so. Whatever the case, it is important to follow the yeast supplier's directions. If sulphur dioxide is used, it is also important to wait overnight before adding the yeast culture. This is because the sulphur dioxide needs time to act against the wild organisms, and it will also inhibit the added yeast too strongly if they are all added together. By standing overnight, the free sulphur dioxide largely disappears once its work is done, giving the added yeast a chance to get away without significant inhibition.\nFermentation should commence within 2 or 3 days if an active yeast culture is used. As an alternative, it is possible to rely on the few wild Saccharomycesyeasts which will be present in the juice after sulphiting, and allow them to multiply to sufficient levels to start the fermentation, but this may take up to 2 or 3 weeks. In this case you might prefer to use around half the addition of sulphite given in the Table. This is equivalent to the traditional practice of burning a 'sulphur candle' in the barrel before adding fresh juice. If neither sulphite nor yeast are added, the juice will probably start to ferment within a day, but the wild yeasts which multiply under these conditions cannot be guaranteed to produce desirable flavours. In any case, they will begin to die after a few days as the alcohol level rises, leaving the fermentation at the mercy of any other dominant organism which has been able to establish itself. If you are lucky, this may be a useful Saccharomyces species - if you are unlucky, you have only yourself to blame!\nIn summary, therefore, I recommend the beginner to use a pectolytic enzyme, to use sulphur dioxide and to add a cultured wine yeast after standing the sulphited juice overnight. Later on you can try out a 'wild yeast' fermentation. You can perhaps skip the nutrients unless the fermentation begins to 'stick' or unless you know that your fruit comes from big old trees with very low nutrient levels and you are not prepared to wait a few months. The progress of the fermentation should be monitored every few days with a hydrometer and the fall in S.G. plotted on a graph against time (a fall of one degree S.G. per day is pretty reasonable). This makes it much easier to see whether sticking is occurring, and the nutrient and vitamin can be added then if necessary.\nIf the cider is particularly acid at this stage, the first racking may be delayed for a month or so to encourage the 'malo-lactic fermentation' which is described below. In general, however, it is regarded as bad practice to leave a fully fermented cider on its yeast lees for more than a few weeks.\nThe first racking should be into another clean vessel, trying to leave behind as much yeast as possible and with the minimum of aeration to the cider. This is generally done with a clean plastic syphon tube fixed to a plastic rod so it rests just above the yeast deposit or, on a larger scale, with a suitable pump. The transferred cider should be run gently into the bottom of the new vessel without splashing. Now that there is much less carbon dioxide to protect the cider, it is important to minimise the headspace and to prevent air contact as much as possible. This is partly to keep out any undesirable film yeasts or bacteria, and partly to prevent 'oxidation' which leads to flat dull flavours and a loss of freshness. This is why some people add 50 ppm of sulphur dioxide at every racking, although at the first racking this is probably unnecessary because of the remaining carbon dioxide. Sulphite added at this stage will almost certainly inhibit the malo-lactic fermentation, which may or may not be required (see below).\nThe malo-lactic fermentation is difficult to produce at will although some strains of lactic bacterial cultures are now available commercially for use in the wine industry and can be used in cider. It may definitely be prevented by the additional use of sulphur dioxide at racking. Sometimes it reduces the acidity too far and sometimes the 'wrong' organisms take hold, producing other defects such as 'ropiness' (which will be covered in a later article). But if the original juice pH was no higher than 3.8, the chances are that this fermentation will be beneficial if it happens at all. Even if it does not, the cider will mature for several months as its flavour balance stabilises and the harsher notes are smoothed out by slow chemical and biochemical reactions.\nHowever, ciders do not generally profit by extended ageing and by late spring or early summer the cider will be ready for bottling and drinking, or for a second racking into bulk store. The golden rule at this stage is to minimise air contact whenever the cider is handled - it is a matter of preference whether you wish to add sulphur dioxide (ca 50 ppm) to help with this, but in any case you should not exceed a total addition of 200 ppm SO2 to any cider when all additions at fermentation and bottling are summed up. A dry cider with no added sugar and sufficient alcohol should be quite stable in clean, closed and well-filled bottles, and should stand a minimal risk of any unwanted conversion to vinegar! Glass bottles with crown or screw caps are preferred since they will not allow any air in. PET bottles are air permeable and hence not generally recommended, although some are sold for home brew use with an oygen barrier and these are worth hunting out e.g. Coopers Oxbar brand.\nWe have now looked at the steps in producing a still, dry cider which is the easiest sort to make. In the next article we shall look at variations of this process to produce other types of cider.© Andrew Lea 1997. Lightly updated 2015\nMenu and Home Page\nBack to Part 2\nForward to Part 4","Let me cut to the chase and provide dessert before the entrée: unless you are asthmatic or one of the 1% club of people who have a bone fide sulfite allergy, it is highly unlikely that sulfites are the cause of your hangover or any other ill effects from drinking wine.\nI will make this hypothesis: you like high alcohol wines, you perhaps drink too much wine in one sitting, and/or you tend to mix types of alcohol (including types of wine) in the course of an evening or event. Gotcha! Those choices are the real culprits. Oh yes, and if you think that red wines cause extra problems because of sulfites, you should know that they tend to have lower levels than white or sweet wines. And your theory about European wines having fewer sulfites because you can drink them without ill effects? As a general notion, it’s just not true. Wine made in Tuscany and sold in Italy is the exact same wine that is exported to the U.S. There’s only one difference in the U.S.: the bottle has the required warning “Contains Sulfites” on the back label.\nIntrigued? Read on.\nThis is a complex topic, and I am keen to help simplify it. I cannot be the only reasonably well-educated wine-lover to get confused by the differences among sulfur, sulfur dioxide and sulfites, or about their health effects. Do they matter in the winemaking process? Sure, but why and how? Why is it that sulfites get blamed for many maladies and keep otherwise enthusiastic sippers away from vino?\nFor wine enthusiasts not terribly intrigued by the chemistry of wine, this analysis may be a bit of a rat-hole. But let’s level-set the chemistry backdrop.\nSulfur (or sulphur) is the tenth most abundant chemical element in the universe. Usually found in salt deposits, it is pale yellow, odorless and brittle. Because it existed naturally near volcanoes such as Pompeii, sulfur was known and used as a preservative in the winemaking process in ancient Roman times, but it was not officially named a chemical element until the 1770s.\nSulfur dioxide (SO2) forms when fossil fuels (e.g., coal, oil) are burned or sulfur-rich mineral ores (e.g., copper, zinc, lead, iron) are smelted. It can be deadly in high concentrations. Commercial SO2 is typically used as a bleaching agent, solvent, disinfectant and refrigerant. SO2 is also used to preserve fresh foods and as a preservative ingredient in processed foods such as jam, soda, canned soups and dried fruit.\nSulfite is a class of sulfur compounds. Because SO2 is one of the best known sulfur compounds, the terms “sulfur dioxide” and “sulfite” tend to be used interchangeably (and thus constitute the main source of consumer confusion).\nTo simplify things for the balance of this article, I am going to use primarily the compound name SO2 rather than the class name of sulfites. Please hang on to the truth that they are often used interchangeably (and at times incorrectly) in many references as one and the same.\nWhere does SO2 come from? Two sources: yeast and the winemaker. Some yeast is wild. It may be found in the vineyard on grapes and in the winemaking facility. Most commercial strains of yeast produce 10-30 ppm of SO2 during the normal process of alcoholic fermentation.\nWhy is SO2 added during the winemaking process? SO2 is considered to be the most important additive used in making wine. As author Jamie Goode describes it in the second edition of his book Wine Science, sulfur dioxide is the “chemical custodian” of wine. (I highly recommend this book as an excellent resource for both consumers and professionals, as it is written in a very approachable style.) SO2 acts a preservative in wine just as it does in solid food. It is both antimicrobial (kills bacteria and fungi) and antioxidant (inhibits the damaging effects of oxidation). The degree to which SO2 exists in finished wine is expressed as “parts per million” or ppm for short. (This is the exactly same liquid measure as milligrams per liter, or mg/l.)\nWine is inherently volatile due to many changes that occur from grape to glass. It can easily spoil from bacteria, turn to vinegar, or develop other faults during fermentation and aging. In Roman times, sulfur-based candles were burned in amphorae (aging vessels). This unnamed discovery stabilized and preserved the wines which were so popular two millennia ago. In modern times, winemakers employ a similar burning process, using SO2 to clean barrels. Sulfur dioxide is increasingly used to augment good cellar practices as part of a winery’s “housekeeping” regime to clean hoses, fermentation tanks, valves and other processing hardware.\nWhen is SO2 added? SO2 is often added to protect and preserve the wine’s character, flavor and color. Among other things, it inhibits enzymes that cause browning, controls the balance of bacteria, controls wild yeasts from growing, helps to extract pigment making red wines “redder,” and prevents secondary fermentation in the bottle. The winemaker’s challenge is to use SO2 judiciously.\nSulfur dioxide can be added at four main stages in the winemaking process depending on the condition of the grapes and desired style of the finished wine:\n- Arrival of fresh grapes to control wild yeasts and/or to protect the berries from disease as the surface is broken in the process of destemming and crushing the grapes.\n- Beginning of alcoholic fermentation to prevent browning from oxidation and premature malolactic fermentation (MLF) for fruit-forward wine styles that are not intended to be barrel-aged.\n- After MLF to achieve certain wine styles, and to preserve and stabilize the wine for barrel aging.\n- Prior to bottling to support bottle aging.\nHow much SO2 is added, and why? What factors influence this decision? Two main factors influence how much SO2 should be added at any stage in the winemaking process to achieve antimicrobial and antioxidant goals. The proper conventional dose of SO2 is determined by a technical formula that maximizes the effects of SO2 in the context of alcohol by volume (abv) and pH level.\nAlcohol by volume (abv) is the total percentage of ethanol (the type of alcohol in wine) expected in the finished wine. This measure matters because the higher the abv, the less SO2 protection is required. There is no longer a threat of secondary fermentation in the barrel or bottle, and ethanol enhances the bacteria-killing effects of SO2.\nThe pH scale, which ranges from 0-14, measures acidity (0-6) vs. alkalinity (8-14). Seven is considered neutral. The higher the pH, the more SO2 needs to be added to prevent MLF, Brettanomyces or other bacteria. Acidity (low pH) helps to keep those things under control.\nWhile it may seem counterintuitive, for a quick mnemonic, remember these ratios. It is these ratios that matter.\n- higher pH = lower acidity (which needs more added SO2)\n- lower pH = higher acidity (needs less added SO2)\n- higher alcohol (and drier wine) = less need for SO2\n- lower alcohol (and sweeter wine) = more need for SO2\nWhite wines tend to be higher in acidity than red wines, so applying this ratio, they should require less SO2. But that’s not usually the case. They actually require more SO2 because they are prone to oxidation. The more color in the grape pigment, and the longer the period of maceration (contact with skins and stems), the less added SO2 is needed. In most cases, red wines do not even need to have SO2 added because they contain these natural antioxidants, but conventional winemakers may still add it as a precaution. Additionally, higher pH wines (alkaline) made from very ripe red fruit to enhance youthful drinkability are more susceptible to bacteria, thus may require excessively high levels of added SO2. Wines with higher levels of residual sugar need more SO2 to prevent secondary fermentation. The typical order from most-to-least use of SO2 is as follows: sweet white dessert wines, blush and semi-sweet white wines, dry white wines, and dry red wines.\nWhat happens to SO2 during the winemaking process?\nThe basic formula for sulfur dioxide in wine is this: total SO2 = bound SO2+ free SO2.\nWhen SO2 is added to wine, it is initially “free” to serve intended antimicrobial and antioxidant purposes. Over time, a portion of the SO2 binds (or dissolves) with other components of the wine and is becomes inactive, undetectable to most people except the small percentage who are genuinely sensitive. Some proportion of the SO2 evaporates as gas, but the unbound portion remains “free,” continuing to work as an antimicrobial and antioxidant agent. Of the total SO2 in finished wine, 50-90% tends to be bound. The remaining 10-50% is active, or free. It is the only portion of the original dose of SO2 still actively working in the wine, and is thus the component most likely to have a negative impact on sulfite-sensitive wine drinkers.\nLabeling Laws and Consumer Protection\nIt’s a conundrum. Labels are frankly not helpful. But how would a consumer know any of this?\nAll bottles of wine sold in the U.S. with more than 10 ppm of SO2, regardless of country of origin, must be labeled “Contains Sulfites.” By now you should be quite clear that this information borders on irrelevance. All wines will have at least this level of SO2, whether naturally from yeasts or added by winemakers. It simply isn’t a helpful warning.\nIn the United States, the Food & Drug Administration discovered nearly 30 years ago that about 1% of the population is severely allergic to sulfites, and that about 5-10% of people who have asthma are prone to having adverse effects from sulfites. This prompted the health warning label “Contains Sulfites” starting in 1987.\nWhy you may ask? Other countries do not do this. For example, SO2 limits vary in the European Union according to type of wine, from 160 ppm for red wine to 400 ppm for sweet wine, but the EU does not require this information to be disclosed on bottles sold/purchased in the EU.\nMy recommendation is to create a worldwide standard for sulfite content and labeling requirements that actually achieve the intended goal of health protection and education for the consumer. The warning “Contain Sulfites” is neutered by so many misunderstandings of its meaning.\nThe Bottom Line\nIf you are one of the rare people with a known sulfite allergy, or if you suffer from asthma plus sulfite sensitivities, please be careful. If you are not certain, do check with a physician who understands the nuances of this type of allergy. Sulfite reactions induce symptoms such as hives, itching, swelling, nausea, diarrhea and low blood pressure. Headaches and hangovers are another matter.\nChoosing your wines carefully is another option. If you are particularly sensitive, look for “no sulfites added” on the label. Know your winemaker and his/her practices. (Ask if you aren’t sure – many winemakers can tell you the amount of sulfur dioxide added or the total ppm of SO2 in the finished wine.) Organic wines typically limit SO2 to 110 ppm or less, a good option for people with sulfite sensitivities. Biodynamic wines go a step further, typically building on organic farming and winemaking practices. This class of “natural” wines is an interesting subject unto itself.\nAnd get to know your wine merchant. There’s no substitute for good advice in buying wine.\nFor everybody else? Don’t drink too much, choose wines that have a low-to-moderate alcohol level, and don’t mix too many different types of alcohol. Don’t buy cheap wine that may have been heavily processed unless you know how the wine was made. If SO2 is an aromatic annoyance, decant and chill the wine before serving. Wines served at warmer temperatures tend to release their free SO2 compounds, which can also be mitigated by chilling and decanting.\nIn Pursuit of More Knowledge\nFor another angle on this topic, please read the Vino Ventures blog post from July 2013 “I Can’t Drink Wine. It Gives Me a Headache.” In coming weeks, there will be more posts about natural wine trends, an exploration of various types of wood and toasts used in barrels for aging, and other influences on the overall wine experience.\nThe references used for this post are primarily secondary based on quality original source material.\n- Butzke, Christian. “Use of SO2 in High-pH Wines.” Purdue University Extension. March 2010.\n- Good, Jamie. Wine Science: The Application of Science in Winemaking, Second Edition. Octopus Publishing Group Ltd (Mitchell Beazley), 2014.\n- Henderson, Pat. “Sulfur Dioxide: Science Behind this Anti-microbial, Anti-oxidant, Wine Additive.” Practical Winery & Vineyard Journal. Jan/Feb 2009.\n- Jancou, Pierre. “Sulphites in wine.” http://www.morethanorganic.com. Undated.\n- Miller, Mike. “How SO2 and pH are Linked.” Acuvin.com. Undated.\n- Robinson, Jancis et al. Oxford Companion to Wine.\n- http://www.winefolly.com. “The Bottom Line on Sulfites in Wine.” January 15, 2014."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:1de1694b-afcc-4ed4-8a06-a7190b40c050>","<urn:uuid:934cd7f8-7595-4ab3-b66b-6372b790835b>"],"error":null}
{"question":"Hey! I'm curious - what's the key difference between Gray Birch and Silver Birch when it comes to their bark characteristics? 🤔","answer":"The Gray Birch (Betula populifolia) has chalky to grayish white bark with black triangular patches where branches meet the trunk. While it is smooth and thin, it does not readily exfoliate. In contrast, the Silver Birch (Betula pendula) has bark that starts as golden-brown but turns white, developing papery tissue that peels off in flakes. As Silver Birch ages, its bark thickens and becomes irregular, dark and rugged.","context":["[amazon_link asins=’B0727QD4QT,B072HGJ6KN,B0752TRPM8,B014G8VX3E,B06Y2RM7KT,B073N9MH61,B00RLMH7EM,B00ZE7U1UI,B004ZB32FA’ template=’ProductCarousel’ store=’finmeacur-20′ marketplace=’US’ link_id=’8eaba46f-9d05-11e7-970a-bf1174ae3080′]\n[amazon_link asins=’B00CTXSMAQ,B01D9CBR0M,B00NGZG5OQ,B074DD5QXV,B074RM9X7G,B01D9CBP3G,B00X6CMYBW,B01IHVABP2,B06XDK3155′ template=’ProductCarousel’ store=’finmeacur-20′ marketplace=’US’ link_id=’c642c047-9d05-11e7-8ff8-678ff3e2b93e’]\nBotanical Name: Betula populifolia\nSpecies: B. populifolia\nSynonyms: Betula acuminata, Betula cuspidata Schrad. ex Regel\nCommon Name: Gray Birch\nHabitat: Betula populifolia is native to Eastern N. America – Quebec to Virginia and west to Indiana. It is found on the margins of swamps and ponds, it also commonly grows in dry sandy or gravelly barren soils, growing well in poor almost sterile soils.\nBetula populifolia is a deciduous Tree growing quickly to 20 to 30 feet tall and 15 inch trunk diameter, with an irregular open crown of slender branches. The tree often has multiple trunks branching off of an old stump. The leaves are 5-7.5 cm long by 4–6 cm wide, alternately arranged, ovate, and tapering to an elongated tip. They are dark green and glabrous above and paler below, with a coarsely serrated margin. The bark is chalky to grayish white with black triangular patches where branch meets trunk. It is most easily confused for the paper birch (Betula papyrifera) by means of its bark; it is smooth and thin but does not readily exfoliate like paper birch does.It is in flower in April, and the seeds ripen in September. Bloom Color is brown. It’s form is Pyramidal, Upright or erect. The flowers are wind-pollinated catkins 5–8 cm long, the male catkins pendulous and the female catkins erect. The fruit, maturing in autumn, is composed of many tiny winged seeds packed between the catkin bracts.\nSuitable for: light (sandy), medium (loamy) and heavy (clay) soils, prefers well-drained soil and can grow in heavy clay and nutritionally poor soils. Suitable pH: acid, neutral and basic (alkaline) soils. It cannot grow in the shade. It prefers dry or moist soil. The plant is not wind tolerant.\nCLICK & SEE THE PICTURES\nLandscape Uses:Firewood, Specimen. Succeeds in a well-drained loamy soil in a sunny position. Tolerates most soils doing well on poor ones and on heavy clays. A fast growing tree, though it rarely lives longer than 50 years. It is a pioneer species of abandoned fields, burnt-over lands, cleared woodlands etc. A fairly wind-tolerant plant, but it is shallow-rooted and older trees are often uprooted by winds and heavy snow in the wild. Hybridizes freely with other members of this genus, especially with B. papyrifera. A good plant to grow near the compost heap, aiding the fermentation process. Trees are notably susceptible to honey fungus. Special Features: North American native, Naturalizing, Inconspicuous flowers or blooms.\nSeed – best sown as soon as it is ripe in a light position in a cold frame. Only just cover the seed and place the pot in a sunny position. Spring sown seed should be surface sown in a sunny position in a cold frame. If the germination is poor, raising the temperature by covering the seed with glass can help. When they are large enough to handle, prick the seedlings out into individual pots and grow them on in a cold frame for at least their first winter. Plant them out into their permanent positions in late spring or early summer, after the last expected frosts. If you have sufficient seed, it can be sown in an outdoor seedbed, either as soon as it is ripe or in the early spring – do not cover the spring sown seed. Grow the plants on in the seedbed for 2 years before planting them out into their permanent positions in the winter.\nInner bark – cooked or dried and ground into a meal. The meal can be used as a thickener in soups etc, or be added to flour when making bread, biscuits etc. Inner bark is generally only seen as a famine food, used when other forms of starch are not available or are in short supply. Sap – sweet. Harvested in early spring, before the leaves unfurl, by tapping the trunk. The flow is best on warm days that follow frosty nights. The sap is drunk as a sweet beverage or it can be fermented to make birch beer or vinegar. An old English recipe for the beer is as follows:- “To every Gallon of Birch-water put a quart of Honey, well stirr’d together; then boil it almost an hour with a few Cloves, and a little Limon-peel, keeping it well scumm’d. When it is sufficiently boil’d, and become cold, add to it three or four Spoonfuls of good Ale to make it work…and when the Test begins to settle, bottle it up . . . it is gentle, and very harmless in operation within the body, and exceedingly sharpens the Appetite, being drunk ante pastum.”.\nThe bark is astringent. a decoction has been used to treat bleeding piles. Scrapings of the inner bark have been used to treat swellings in infected cuts. The German Commission E Monographs, a therapeutic guide to herbal medicine, approve Betula species for infections of the urinary tract, kidney and bladder stones, rheumatism .\nCharcoal; Pioneer; Wood.\nA pioneer species, readily invading old fields, burnt-over or cleared land and providing suitable conditions for other woodland trees to become established. It is an excellent crop for very poor soils, where it grows rapidly and affords protection to the seedlings of more valuable and slower-growing trees. Since this species is short-lived and not very shade tolerant, it is eventually out-competed by these other trees. Wood – close-grained, soft, light, weak, not durable. It weighs 36lb per cubic foot. Unimportant commercially, the wood is used locally for making clothes pegs, spools, pulp, charcoal and quite commonly as a fuel.\nKnown Hazards: The aromatic and aliphatic hydrocarbons in birch tar are irritating to the skin. Do not use in patients with oedema or with poor kidney or heart functions.\nDisclaimer : The information presented herein is intended for educational purposes only. Individual results may vary, and before using any supplement, it is always advisable to consult with your own health care provider.","|Silver birch forest, Inari, Finland|\nBetula pendula, commonly known as silver birch or warty birch, is a species of tree in the family Betulaceae, native to Europe and parts of Asia, though in southern Europe it is only found at higher altitudes. Its range extends into Siberia, China and southwest Asia in the mountains of northern Turkey, the Caucasus and northern Iran. It has been introduced into North America, where it is known as the European white birch, and is considered invasive in some states in USA and in parts of Canada.\nThe silver birch is a medium-sized deciduous tree that owes its common name to the white peeling bark on the trunk. The twigs are slender and often pendulous and the leaves are roughly triangular with doubly serrate margins and turn yellow in autumn before they fall. The flowers are catkins and the light, winged seed get widely scattered by the wind. The silver birch is a hardy tree, a pioneer species, and one of the first trees to appear on bare or fire-swept land. Many species of birds and animals are found in birch woodland, the tree supports a wide range of insects and the light shade it casts allows shrubby and other plants to grow beneath its canopy. It is planted decoratively in parks and gardens and is used for forest products such as joinery timber, firewood, tanning, racecourse jumps and brooms. Various parts of the tree are used in traditional medicine and the bark contains triterpenes which have been shown to have medicinal properties.\nThe silver birch is a medium-sized deciduous tree, typically reaching 15 to 25 m (49 to 82 ft) tall (exceptionally up to 31 metres (102 ft)), with a slender trunk usually under 40 cm (16 in) diameter. The bark on the trunk and branches is golden-brown at first, but later this turns to white as a result of papery tissue developing on the surface and peeling off in flakes. The bark remains smooth until the tree gets quite large, but in older trees, the bark thickens, becoming irregular, dark and rugged. Young branches have whitish resin warts and the twigs are slender, hairless and often pendulous. The buds are small and sticky, and development is sympodial, that is to say the terminal bud dies away and growth continues from a lateral bud. Some shoots are long and bear the male catkins at the tip, while others are short and bear female catkins. The immature male catkins are present during the winter but the female catkins develop in the spring, soon after the leaves unfurl.\nThe leaves have short slender stalks and are 3 to 7 cm (1.2 to 2.8 in) long, triangular with broad, untoothed, wedge-shaped bases, slender pointed tips and coarsely double-toothed, serrated margins. They are sticky with resin at first but this dries as they age leaving small white scales. The foliage is a pale to medium green and turns yellow early in the autumn before the leaves fall. In mid-summer, the female catkins mature and the male catkins expand and release pollen, and wind pollination takes place. The small 1 to 2 mm winged seeds ripen in late summer on pendulous, cylindrical catkins 2 to 4 cm (0.8 to 1.6 in) long and 7 mm (0.3 in) broad. The seeds are very numerous and are separated by scales, and when ripe, the whole catkin disintegrates and the seeds are spread widely by the wind.\nDistribution and habitat\nThe silver birch grows naturally from western Europe eastwards to Kazakhstan, the Sakha Republic in Siberia, Mongolia and the Xinjiang province in China, and southwards to the mountains of the Caucasus and northern Iran, Iraq and Turkey. It is also native to northern Morocco and has become naturalised in some other parts of the world. In the southern parts of its range it is mainly found in mountainous regions. Its light seeds are easily blown by the wind and it is a pioneer species, one of the first trees to sprout on bare land or after a forest fire. It needs plenty of light and does best on dry, acid soils and is found on heathland, mountainsides and clinging to crags. Its tolerance to pollution make it suitable for planting in industrial areas and exposed sites. It has been introduced into North America where it is known as the European white birch, and is considered invasive in the states of Kentucky, Maryland, Washington and Wisconsin. It is naturalised and locally invasive in parts of Canada.\nThe closely related Betula platyphylla in northern Asia and Betula szechuanica of central Asia are also treated as varieties of silver birch by some botanists, as B. pendula var. platyphylla and B. pendula var. szechuanica respectively (see birch classification).\nB. pendula is distinguished from the related downy birch (B. pubescens, the other common European birch) in having hairless, warty shoots (hairy and without warts in downy birch), more triangular leaves with double serration on the margins (more ovoid and with single serrations in downy birch), and whiter bark often with scattered black fissures (greyer, less fissured, in downy birch). It is also distinguished cytologically, silver birch being diploid (with two sets of chromosomes), whereas downy birch is tetraploid (four sets of chromosomes). Hybrids between the two are known, but are very rare, and being triploid, are sterile. The two have differences in habitat requirements, with silver birch found mainly on dry, sandy soils, and downy birch more common on wet, poorly drained sites such as clay soils and peat bogs. Silver birch also demands slightly more summer warmth than does downy birch, which is significant in the cooler parts of Europe. Many North American texts treat the two species as conspecific (and cause confusion by combining the downy birch's alternative vernacular name 'white birch', with the scientific name B. pendula of the other species), but they are regarded as distinct species throughout Europe.\nSynonyms include Betula pendula var. carelica (Merckl.) Hämet-Ahti, B. pendula var. laciniata (Wahlenb.) Tidestr., B. pendula var. lapponica (Lindq.) Hämet-Ahti, B. aetnensis Raf., B. montana V.N.Vassil, B. talassica Poljakov, B. verrucosa Ehrh., B. verrucosa var. lapponica Lindq., and B. fontqueri Rothm. The rejected name Betula alba L. also applied in part to B. pendula, though also to B. pubescens.\nThe silver birch has an open canopy which allows plenty of light to reach the ground. This allows a variety of mosses, grasses and flowering plants to grow beneath which in turn attract insects. Flowering plants often found in birch woods include primrose (Primula vulgaris), violet (Viola riviniana), bluebell (Hyacinthoides non-scripta), wood anemone (Anemone nemorosa) and wood sorrel (Oxalis acetosella). Small shrubs that grow on the forest floor include blaeberry (Vaccinium myrtillus) and cowberry (Vaccinium vitis-idaea). Birds found in birch woodland include the chaffinch, tree pipit, willow warbler, nightingale, robin, woodcock, redpoll and green woodpecker.\nThe branches of the silver birch often have tangled masses of twigs known as witch's brooms growing among them, caused by the fungus Taphrina betulina. Old trees are often killed by the decay fungus Piptoporus betulinus and fallen branches rot rapidly on the forest floor. This tree commonly grows with the mycorrhizal fungus Amanita muscaria in a mutualistic relationship. This applies particularly to acidic or nutrient-poor soils. Other mycorrhizal associates include Leccinum scabrum and Cantharellus cibarius. It has been shown that, as well as mycorrhiza, the presence of microfauna in the soil assists the growth of the tree, as it enhances the mobilization of nutrients.\nThe larvae of a large number of species of butterflies, moths and other insects feed on the leaves and other parts of the silver birch. In Germany, almost 500 species of insect have been found on silver and downy birch including 106 beetles and 105 lepidopterans, with 133 insect species feeding almost exclusively on birch. In the United States, the wood is attacked by the bronze birch borer (Agrilus anxius), an insect pest to which it has no natural resistance.\nSilver birch is often planted in parks and gardens, grown for its white bark and gracefully drooping shoots, sometimes even in warmer-than-optimum places such as Los Angeles and Sydney. In Scandinavia and other regions of northern Europe, it is grown for forest products such as lumber and pulp, as well as for aesthetic purposes and ecosystem services. It is sometimes used as a pioneer and nurse tree elsewhere.\nSilver birch wood is pale in colour with no distinct heartwood and is used in making furniture, plywood, veneers, parquet blocks, skis, kitchen utensils and in turnery. It makes a good firewood that produces a good heat when burnt but is quickly consumed by the flames. Slabs of bark are used for making roof shingles and wooden footwear. Historically, the bark was used for tanning. Bark can be heated and the resin collected; the resin is an excellent waterproof glue and useful for starting fires. The thin sheets of bark that peel off young wood contain a waxy resin and are easy to ignite even when wet. The dead twigs are also useful as kindling for outdoor fires.\nBirch brushwood is used for racecourse jumps and besom brooms. In the spring, large quantities of sap rise up the trunk and this can be tapped. It contains around 1% sugars and can be used in a similar way to maple syrup, being drunk fresh, concentrated by evaporation or fermented into a \"wine\". In Sweden, the bark of birch trees was ground up and used to make bark bread, a form of famine food. The removal of bark was at one time so widespread that Carl Linnaeus expressed his concern for the survival of the woodlands.\nSilver birch is used in traditional medicine as a diuretic and is reputed to be useful in the treatment of high blood pressure, high cholesterol, obesity, gout, kidney stones, nephritis, cystitis, digestive disturbances and respiratory diseases. For these purposes, a decoction of the bark or leaves is generally used. Externally silver birch is used to promote healing, relieve pain and treat inflammations and infections of the skin such as eczema and psoriasis.\nThe outer part of the bark contains up to 20% betulin. The main components in the essential oil of the buds are α-copaene (~10%), germacrene D (~15%) and δ-cadinene (~13%). Also present in the bark are other triterpene substances which have been shown to have anti-inflammatory, antiviral and anti-cancer properties.\nSuccessful birch cultivation requires a climate cool enough for at least the occasional winter snowfall. As they are shallow-rooted, they may require water during dry periods. They grow best in full sun planted in deep, well-drained soil.\n- 'Carelica' is called \"curly birch\" in Finland; the wood is hard and decorative and is used in wood-carving.\n- 'Laciniata' agm (commonly misidentified as 'Darlecarlica') has deeply incised leaves and weeping branches.\n- 'Purpurea' has dark purple leaves.\n- 'Tristis' agm has an erect trunk with weeping branchlets.\n- 'Youngii' has dense, twiggy weeping growth with no central leader and requires being grafted onto a standard stem of normal silver birch.\n|Wikimedia Commons has media related to Betula pendula.|\n|Wikispecies has information related to: Betula pendula|\n- Vedel, Helge; Lange, Johan (1960). Trees and Bushes. Methuen. pp. 141–143. ISBN 978-0-416-61780-1.\n- Featherstone, Alan Watson. \"Silver birch, downy birch\". Trees for Life. Retrieved 2014-05-28.\n- \"GRIN Taxonomy for Plants - Betula pendula\". USDA Agricultural Research Service. Retrieved 2014-05-29.\n- \"Silver birch: Betula pendula\". Forestry Commission. Retrieved 2014-05-28.\n- \"European White Birch - Betula pendula\" (PDF). USDA Forest Service. 2006-09-01. Retrieved 2014-05-29.\n- Diamond, Joshua; Browning, Mark; Williams, Andrew; Middleton, John (2003). \"Lack of Evidence for Impact of the European White Birch, Betula pendula, on the Hydrology of Wainfleet Bog, Ontario\". Canadian Field-Naturalist 117 (3).\n- Hunt, D., ed. (1993). Betula. Proceedings of the IDS Betula Symposium 2–4 October 1992. p. 51. International Dendrology Society ISBN 0-9504544-5-1.\n- OECD (2008). Novel Food and Feed Safety SET 1: Safety Assessment of Transgenic Organisms OECD Consensus Documents Volumes 1 and 2. OECD Publishing. p. 58. ISBN 978-92-64-05346-5.\n- Anderberg, Arne (1999-10-14). \"Betula pendula Roth\". Den virtuella floran. Naturhistoriska riksmuseet. Retrieved 2014-05-29.\n- Govaerts, R.; Frodin, D. G. (1998). World Checklist and Bibliography of Fagales. ISBN 1-900347-46-6 online search\n- Govaerts, R. (1996). \"Proposal to reject the name Betula alba (Betulaceae)\". Taxon 45: 697–698. doi:10.2307/1224262.\n- Setälä, Heikki; Huhta, Veikko (1991). \"Soil Fauna Increase Betula pendula Growth: Laboratory Experiments With Coniferous Forest Floor\". Ecology 72 (2): 665–671. JSTOR 2937206.\n- \"HOSTS - a Database of the World's Lepidopteran Hostplants\". Natural History Museum. Retrieved 2014-05-29.\n- Brändle, Martin; Brandl, Roland (2001). \"Species richness of insects and mites on trees: expanding Southwood\". Journal of Animal Ecology 70 (3): 491–504. doi:10.1046/j.1365-2656.2001.00506.x.\n- Cox, Michael O. \"Firewood types: silver birch\". WoodstoveWizard.com. Retrieved 2014-05-29.\n- Julie Lindahl (2011-01-09). \"Bark Bread is back\". Nordic Wellbeing. Retrieved 2011-07-21.\n- \"Betula pendula - Roth.\". Plants for a future. Retrieved 2014-11-05.\n- Demirci, Betül; Paper, Dietrich H.;Demirci, Fatih; Başer, K. Hüsnü Can; Franz, Gerhard (2004). \"Essential Oil of Betula pendula Roth. Buds\". Evidence-Based Complementary and Alternative Medicine 1 (3): 301–303. doi:10.1093/ecam/neh041. PMID 15841263.\n- Kovac-Besović, E. E.; Durić, K.; Kalodera, Z.; Sofić, E (2009). \"Identification and isolation of pharmacologically active triterpenes in Betuale cortex, Betula pendula Roth., Betulaceae\". Bosnian Journal of Basic Medical Sciences 9 (1): 31–38. PMID 19284392.\n- Katriina Anttila (2005). \"Suomen kansallistunnukset (Finland's national emblems)\". Retrieved 2014-05-30.\n- \"Perinteinen saunavihta (Traditional sauna vihta)\". Visit sauna. Retrieved 2014-05-30.\n- Botanica (1999). Botanica's Trees & Shrubs. Laurel Glen Publishing A. p. 139. ISBN 978-1-57145-649-6.\n- \"Betula pendula var. carelica - curly birch\". Arboretum Mustila. Retrieved 2014-11-12.\n- \"RHS Plant Selector - Betula pendula 'Laciniata'\". Royal Horticultural Society. Retrieved 2013-06-14.\n- \"RHS Plant Selector - Betula pendula 'Purpurea'\". Royal Horticultural Society. Retrieved 2014-11-12.\n- \"RHS Plant Selector - Betula pendula 'Tristis'\". Royal Horticultural Society. Retrieved 2013-06-14.\n- \"RHS Plant Selector - Betula pendula 'Youngii'\". Royal Horticultural Society. Retrieved 2014-11-12."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:8dc46de4-321f-4c21-9e3c-0d9856887dec>","<urn:uuid:c14a3e25-bc04-4bd2-8091-147fd20d1271>"],"error":null}
{"question":"What is the significance of December 21, 2012, in Mayan culture from both religious and cultural celebration perspectives?","answer":"December 21, 2012 marks the end of the 13th Bak'tun, a 394-year-long cycle in the Mayan calendar. While some interpreted this as a doomsday prophecy, serious scholars and the Vatican's top astronomer dismissed these apocalyptic claims as 'obviously false.' For contemporary Mayans, particularly in Chicago's Guatemalan and Mexican communities, this date represents a time of celebration and renewal rather than apocalypse. It's viewed as an opportunity for reflection on relationships with nature and planning for the future. The date holds special mathematical and cultural significance, with the number 13 being particularly powerful in Mayan culture.","context":["Edward Pentin began reporting on the Pope and the Vatican with Vatican Radio before moving on to become the Rome correspondent for the National Catholic Register. He has also reported on the Holy See and the Catholic Church for a number of other publications including Newsweek, Newsmax, Zenit, The Catholic Herald, and The Holy Land Review, a Franciscan publication specializing in the Church and the Middle East. Edward is the author of “The Rigging of a Vatican Synod? An Investigation into Alleged Manipulation at the Extraordinary Synod on the Family”, published by Ignatius Press. Follow him on Twitter @edwardpentin\nResponding to the media circus over a possible end of the world on December 21st – a claim that’s circulated for years and even spawned a Hollywood blockbuster – the Vatican's top astronomer has said the scientific basis for such speculation is “not even worth discussing” as it is “obviously false.”\nJesuit Father Jose Funes, director of the Vatican Observatory, wrote in L'Osservatore Romano’s Dec. 12 edition that the perennial question “Where do we come from and where are we going?” is often met with “irrational responses.”\nHe noted that if you search this “prophecy” on Google, it brings up 40 million results.\nThis year’s prediction, which derives from the Mayan calendar, requires verifying the alignment of the planets and the sun with the center of the Milky Way and a reversal of the Earth’s magnetic poles.\n“It’s not worth discussing the scientific basis for these claims (obviously false),” Fr. Funes wrote in the article headed: \"Between pseudo-prophecy, science and faith - The end of the world isn't nigh (at least for now)\"\nHe recalled visiting the Mayan archaeological ruins in Copan, Honduras, in 2003 and said he could appreciate the “great powers of observation of the heavens that these people had.” He was referring to the Classic Mayan civilization (250-900 A.D.), but an estimated 7 million Maya peoples live on today among the Native American people of southern Mexico and northern Central America.\nIn any case, he added, “they didn’t enquire if the Earth or the Sun were at the centre of the universe” but were more interested in finding past repeated patterns that could be reproduced in the future. “In the Mayan culture, time had a cyclical and repetitive dimension,” he said. “Astronomy was developed on the basis of politics and religion, with an obsession for time cycles.”\nFr. Funes then reflected on the fate of the cosmos, arguing that it is continually expanding and will “break away” extremely fast, but “billions and billions of years” from now. He pointed out that according to some cosmologists, the universe may not even have a definitive conclusion but rather a unique set of “multi-ends”, with some parts ending at different times to others.\nFor Christians, however, the universe and history have a meaning, reminded the Argentine Jesuit. “In the depths of the human being is the fundamental belief that death cannot have the last word,” he said. “Cosmology shows us that the universe goes to a final state of cold and darkness; the Christian message teaches us instead that in the final resurrection, the last day, God will reconstitute every man, woman and all the universe.”\n“This future reality,” he continued, “is expressed in the words of the Apocalypse of St. John the Apostle (21:1-3): “Then I saw a new heaven and a new earth…Look! God’s dwelling place is now among the people, and he will dwell with them. They will be his people, and God himself will be with them and be their God.\"\nThe Book of Revelation is a prophetic text, not scientific information on the future of the universe and of man, Fr. Funes explained. “It is a prophecy because it shows us the inner foundation and orientation of history,” he said. “In the historical context in which it was written, the sacred author seeks to encourage the community of Christians who suffer persecution.”\n“Human (and cosmic) history has a meaning that has been given by God-with-us,” Fr. Funes added. “Even if we are not persecuted, we always need encouragement. The Word of God reminds us that we are moving towards a future that is basically good, despite all the crises in which we our lives are immersed. Because we are assured that in Christ there is a future for humanity and the universe.”\nThe idea of cataclysmic events occurring in 2012 have been dismissed by serious scholars, including professional Mayanists. As well as Fr. Funes, astronomers and other scientists have also rejected the theories as “pseudoscience,” and believe they amount to \"a distraction” from more important science concerns.\nPerhaps the best thing to do when confronted with these end-of-the-world claims is simply to refer to this well known verse from Matthew 24:36: “No one knows the day or hour when these things will happen, not even the angels in heaven or the Son himself. Only the Father knows.”","You’ve heard it all: 2012, apocalypse, end of the world, blah blah blah. But for some Guatemalans and Mexicans in Chicago, December 21 is a time of celebration that has nothing to do with doomsday prophecies.\nIn the Mayan tradition December 21 is a major turning of the calendar, the end of an approximately 394-year-long cycle called a Bak’tun. It’s the 13th Bak’tun of the Mayan calendar era, and some say this era will be only 13 Bak’tuns long. Translation: time for a new world.\nBut in reality, December 21 more closely resembles Y2K than the John Cusack movie “2012.” It’s a big, huge renewal with numeric and astrological significance. Only one Mayan text suggests that it’s the end of the world, and people of Mayan descent are more likely to be celebrating than stocking up on bottled water and firearms.\n“This is a time of reflection and to see what we have done with our lives, with mother nature, and how are we going to move forward in this new era,” said Hugo Hun, the Guatemalan consul general of Chicago. He said many Guatemalans will travel to large ceremonies in 13 different cities throughout Guatemala.\nThe Bak’tun events are also a tourist attraction, but some are concerned that the doomsday hullaballoo is commercializing the Mayan culture.\n“The living Mayans are systematically losing the way they used to live and their beliefs as well,” Akaze Yotzin said.\nHe’s the leader of a Chicago group called Nahualli that practices and studies indigenous Mexican traditions. He said poverty and racial stereotypes already endanger Mayan identity in Mexico, and stressed that Mayans are not an ancient people, but a people who are alive today. Nahualli held a ceremony Friday morning at the American Indian Center to celebrate the winter solstice and the turning of the calendar.\nMusic and mathematics\nAncient Mayan culture gave great significance to math and numbers, and the number 13 is considered particularly powerful. The complex numerology of the Mayan calendar system inspired Chicago musician Juan Dies, who produced a song called \"13 Bak'tun\" with his band Sones de Mexico.\n\"13 Bak'tun\" features 13 parts, each carefully planned to highlight numerology. For example, the second part is in 2/4 time and uses two instruments. The thirteenth has 13 instruments playing in 13/8 time. And guess what - the song is 13 minutes long.\nDies said the date is important and also misrepresented. His song is part of an effort to correct that. Sones de Mexico has been together for nearly twenty years studying and reinterpreting traditional Mexican music. The tenth part of \"13 Bak'tun\" features Chicago poet Carlos Mejia performing a poem in Quiche Mayan. According to Dies, Mejia traveled to Guatemala for Dec. 21, 2012 to join the Bak'tun celebrations.\n\"I think the Mayans are seeing it today as a closure of a long cycle, very much as we saw the end of our millenium,\" Dies said. \"Along with that comes an opportunity to renew yourself, to look back at the achievements of the last four hundreds years, and how you may make changes or improvements or a rebirth in the new Bak’tun.\""],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:fc00cda1-aeb2-4feb-8d36-06927d8eaafb>","<urn:uuid:3cfdb59a-b425-439e-bb1c-2681ad178595>"],"error":null}
{"question":"How do hand quilting and Japanese stab stitch binding compare in terms of their stitching techniques and traditional applications? I'm curious about these historical handcraft methods.","answer":"Hand quilting and Japanese stab stitch binding use different stitching approaches for distinct purposes. In hand quilting, the quilter can use three techniques: the stab stitch (one stitch at a time), the rocking stitch (using a thimble with one hand above and one below), or 'loading the needle' (multiple stitches before pulling through). This process binds multiple fabric layers together and is traditionally used for bedding. Japanese stab stitch binding, on the other hand, uses a single continuous thread to bind pages together and is traditionally used for thinner publications like gift books and children's books. While both are handcraft methods with historical significance, hand quilting creates functional textile items while stab stitch binding creates books with a decorative yet robust finish.","context":["There is a common belief that quilting originated for its utility rather than decoration. The origins of this method of craft are thought to be in the Crusades, when soldiers needed warmth as well as protection from the chafing caused by heavy armor. Additionally, there are ancient Egyptian sculptures showing figures which appear to be wearing clothing which is quilted, possibly for warmth in the chilly desert evenings. In the 14th century, the gambeson was a popular form of armour.\nIn American Colonial times most women were busy spinning, weaving and making clothing. Meanwhile women of the wealthier classes prided themselves on their fine quilting of wholecloth quilts with fine needlework. Quilts made during the early 1800s were not constructed of pieced blocks but instead whole cloth quilts. Broderie perse quilts and medallion quilts were made. Some antique quilts made in North America have worn-out blankets or older quilts as the internal batting layer, quilted between new layers of fabric and thereby extending the usefulness of old material.\nDuring American Pioneer days \"paper\" quilting became popular. Paper was used as a pattern and each individual piece of cut fabric was basted around the paper pattern. Paper was a scarce commodity in the early American west and women would save letters from home, newspaper clippings, and catalogs to use as patterns. The paper not only served as a pattern but as an insulator. The paper found between the old quilts has become a primary source about pioneer life. Quilts made without any insulation or batting were referred to as summer quilts. They were not made for warmth, only to keep the chill off on cooler summer evenings. Harriet Powers, a slave-born African American woman, made two famous story quilts. She was just one of the many African American quilters who contributed to the evolution of quilting.\nIn modern times, art quilts have started to become popular for their aesthetic and artistic qualities rather than for functionality (i.e., they are displayed on a wall rather than spread on a bed).\nQuilting types and equipment\nMany types of quilting exist today. The two most widely used are hand-quilting and machine quilting.\nHand Quilting is the process of using a needle and thread to sew a running type stitch by hand across the entire area to be quilted. This binds the layers together. A quilting frame or hoop is often used to assist in holding the piece being quilted, off the quilter's lap. A quilter can make one running stitch at a time; this is called a stab stitch.Another option is called a rocking stitch, where the quilter has one hand, usually with a finger wearing a thimble, on top of the quilt, while the other hand is located beneath the piece to push the needle back up. The third option is called \"loading the needle\" and involves doing four or more stitches before pulling the needle through the cloth. Hand quilting is still practiced by the Amish within the United States, and is enjoying a resurgence worldwide.\nMachine Quilting is the process of using a home sewing machine or a Longarm machine to sew the layers together. With the home sewing machine the layers are tacked together before quilting. This involves laying the top, batting and backing out on a flat surface and either pinning (using large safety pins) or tacking the layers together. Longarm Quilting involves placing the layers to be quilted on a special frame. The frame has bars on which the layers are rolled, keeping these together without the need for basting or pinning. These frames are used with a professional sewing machine mounted on a platform. The platform rides along tracks so that the machine can be moved across the layers on the frame. A Longarm machine is moved across the fabric. In contrast, the fabric is moved through a home sewing machine.\nTying is another technique of fastening the three layers together (and is not a form of quilting at all). This is done primarily on quilts that are made to be used and are needed quickly. The process of tying the quilt is done with yarns or multiple strands of thread. Square knots are used to finish off the ties so that the quilt may be washed and used without fear of the knots coming undone.\nQuilting: Processes and Definitions\nTraditional Quilting Processes Traditional quilting is a six-step process that includes: 1) selecting a pattern, fabrics and batting; 2) measuring and cutting fabrics to the correct size to make blocks from the pattern; 3) piecing (sewing cut pieces of fabric together using a sewing machine or by hand to make blocks) blocks together to make a finished \"top\"; 4) layering the quilt top with batting and backing, to make a \"quilt sandwich\"; 5) quilting by hand or machine through all layers of the quilt sandwich; and 6) squaring up and trimming excess batting from the edges, machine sewing the binding to the front edges of the quilt and then hand-stitching the binding to the quilt backing. Note: If the quilt will be hung on the wall, there is an additional step: making and attaching the hanging sleeve.","SUBSTRATES & FINISH: 7 DIVERSE BINDING METHODS\nBinding, the collective term given for the range of processes which hold and fasten a publication’s pages together, is essential for, well, holding and fastening your publications’ pages together. Whilst on the surface not as compelling a design component as, say, print finishes, a little closer inspection reveals a range of distinct processes which exist for different uses. These binding methods aid function; decisions on binding necessarily affect a printed piece’s robustness, longevity and form. Used creatively, they can even add an aesthetic finishing touch to a piece and help amplify messages and intentions. The closer inspection I mention above, and which binding merits, is what this article’s all about.\nSUBSTRATES & FINISH, ARTICLE 1 OF 3: Diverse Binding Methods\nAlso known as edition binding, case binding is often used in the binding of hardback books, owing to the sturdy, robust qualities inherent in its process. As with perfect binding, pages are gathered and folded into sections, or signatures. These are then sewn together, the spine glued and the book block pressed and trimmed. Covers are prepared with buckram or other hardy material and, once dried, the book block is ‘cased in’ to the covers. If we rewind a few steps to just before the book block is glued and pressed, designers can embellish their books by specifying coloured headbands and ribbon bookmarks to creative effect (see images below).\nA commission for four A3-sized, quarter-bound case bindings from London-based bookbinder © Simon Goode.\nJapanese or Stab Stitch Binding\nInterchangeably known as Japanese, stab and traditional Chinese binding, pages are here sewn together with a single, continuous thread. There are many variations, far too many to cover here, but in recent years Western designers have helped bring some of them back into people’s consciousness. Gift and children’s books are often to be found stab stitch bound, and increasingly design-conscious clients like Onitsuka Tiger, who produced a superb stab stitch-bound 2004–05 trade brochure (an image of which your normally resourceful writer was, alas, unable to obtain) are turning to the process. Best used to bind publications on the thinner side and when wishing to add a tactile dimension to a publication’s design, the effect can look pleasingly delicate, yet is a robust enough binding method.\nThe z-bind, so-called because of the distinctive ‘Z’ shape a z-bound piece forms when viewed from above, is a visually arresting method of binding two publications (or two parts of a single publication) together into one. This can be achieved either with permanence in mind by stitching the two together end-to-end, or as a temporary device, through the use of an elastic band or perforation. Lots of interactivity or ‘relational aesthetics’ as French art curator Nicolas Bourriaud has termed it, can ensue through an encounter with a z-bound project; the publication flipped and turned, separated and re-put back together.\nBeautiful z-bound MA Project ‘Warnings From The Past’ by © Leanne Mallinder. She explains: “‘Warnings From The Past’ is a small collection of five purely typographic speeches each coming with a corresponding poster of a quote from that speech.”\nA bellyband looks much like a portion or strip of a book’s dust jacket, and performs in much the same way. Reasonably versatile, the bellyband can be used functionally to hold a collection of loose leaf pages together or decoratively and as an added layer of protection. When used decoratively as part of a well-designed publication, bellybands seem to lend an air of importance to things and manage to connote the idea of a certain graphical luxury.\nTwo examples of well-designed and -integrated bellybands. Both carry important publication information, the first printed from handset type and the second featuring a subtle black spot varnish. Images supplied by (L>R) © Trip Print Press and © Oliver Rone-Clarke.\nThe humble elastic band is another innovative method of binding both loose leaf sheets (usually with notches die cut into their tops and bottoms) and for making more permanent binds. When not used for holding loose leaf sheet together they are best used for devices like flip-books, less good for binding thicker publications, as the elasticity makes for poor page fall. The intrinsically ephemeral nature of the elastic band can help signify a feel of happy ingenuity and immediacy.\nCharming and intricately bound ‘album to store feathers in’ for a bird-watching friend of © Ruth Bleakley. An exposed spine is visible, over which diagonal, coptic stitching sits housed. Elastic bands at the opposite end act as a clasp to keep it all together.\nA largely recent phenomenon driven by designers and more visionary patrons that has had traditional book binders scratching their heads in befuddlement, exposed spines have become an increasingly common sight on design bookshelves in recent years. Perhaps the most openly decorative entry in this article, an exposed spine is not a method of binding per se, as all that has happened is a publication has been produced, usually perfect-bound and as per usual, and then its covers (and hence spine) left out of things, permitting a view of the exposed signatures and stitching which would typically be hidden away. The effect can be both cheerful and utilitarian, cheerful in that colourful signatures are often used in order to wring the most out of the finish (see project below), and utilitarian in the same way Renzo Piano’s Centre George’s Pompidou in Paris is, with its “exoskeleton” of escalators and scaffolding.\nAs featured in these articles elsewhere, Typehigh and Lieselot Moed’s ‘Bodemweek book’ is a graphic banquet of format design and printed finish. In addition to containing gatefolds and perforations, the publication is also bound sans cover, revealing the colourful spine within.\nLoose Leaf with Slipcase\nThere are several ways of collecting loose-leaf pages and holding them together (see ‘Bellybands’ and ‘Elastic Bands’ above) but few feel as luxurious as a bespoke slipcase. These die cut, quickly assembled gems can be designed to fit the pages within as snugly as a book’s covers. From a functional perspective, nothing can beat loose leaf for pages falling and staying open, as the whole point of them is that they aren’t bound, although the process does imply a certain artisanal decadence; a motorcycle maintenance manual, loose leaf, would be an inappropriate choice due to risks of pages becoming lost, discarded or rearranged out of order.\nStunning self-promotional piece by Leicestershire-based graphic design studio Six. Six, ‘Made by Six 08/09’ is composed of loose leaf sheets that feature credentials, recent client work and selected studio projects, all housed in a subtly embossed slipcase/box. Image courtesy of © SeptemberIndustry.\nAn important, and at times fascinating, design component then, no? As with print finishes and substrates, for best results a method of binding should be decided upon at the start of a project and not at the end. Functional considerations should always be heeded, as the diverse array of binding methods available offer up an equally diverse breadth of differences in longevity and robustness. How easily a publication’s pages fall open should be a prime consideration for the thoughtful graphic designer. From a formal and aesthetic perspective, the myriad materials and sundry levels of intricacy available mean that several of the binding methods covered above may be used as signifiers for all kinds of messages, and, as I hope has been demonstrated, even act as the distinct finishing touch to a project.\n…and it’s not just paper-based substrates that can be bound in visually compelling ways! Image courtesy of © Kate Black."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:4655712e-3f36-4809-a6f6-e79b6fe08ff1>","<urn:uuid:5cfd263a-de2d-4f36-8bca-29feaf2113f8>"],"error":null}
{"question":"How many premature deaths could be prevented by switching to zero-emission vehicles, and what economic benefits would this bring to different income groups?","answer":"Switching to 100% zero-emission vehicles and clean electricity generation by 2050 could prevent approximately 89,300 premature deaths. The economic benefits would be distributed differently across income groups - neighborhoods with poverty rates over 30% would experience almost $700,000 annually in benefits per 100,000 people, while areas with poverty rates of 10% or less would receive about $250,000 annually per 100,000 people. The total public health benefits are estimated at $978 billion nationally.","context":["In the summer of this year the American Lung Association released a report titled, “Driving to Clean Air: Health Benefits of Zero-Emission Cars and Electricity.” Typically a person might not expect that driving personal transportation could result in clean air because gas- and diesel-powered vehicles using internal combustion engines produce unhealthy emissions that are harmful to people and the planet. The report presents a new vision, however, one that foresees an America running on clean, renewable electricity and people driving electric vehicles, meaning all-electric vehicles. This vision is important for a number of reasons, some of which may be surprising to those who are unaware of the harm caused by gas- and diesel-powered vehicle emissions.\nWilliam Barrett, National Senior Director of Advocacy for Clean Air at the American Lung Association, answered some questions about the report for CleanTechnica.\nQ: The report says that switching to 100% zero-emission new passenger vehicles and clean, non-combustion electricity generation by 2050 could result in about 89,300 fewer premature human deaths by reducing air pollution. How did you arrive at that total, and which Americans are most vulnerable to premature death from air pollution exposure?\nA: The report includes a target of 100% zero-emission new passenger vehicle sales by 2035, coupled with non-combustion electricity generation. Cumulatively, the health benefits shown through our modeling of this scenario hit nearly 90,000 premature deaths avoided because the air pollution from these sources will be greatly reduced, though not eliminated fully. We used a series of modeling tools to arrive at these results, and for the health benefits specifically, we used the US EPA’s COBRA model for health benefits analysis.\nQ: The switch to electric vehicles and clean electricity could also provide $978 billion in public health benefits. What are the benefits, and are they distributed across the U.S. or are there areas that will benefit more?\nA: The $978 billion is a national figure, but based in more localized results. For example, the report highlights state-by-state findings that vary depending on local sources of pollution from power plants, refineries or the size of the on-road vehicle populations. Every state shows benefits from this transition to zero-emission technologies. The benefits range from reduced asthma attacks to premature deaths avoided because the air would be cleaner as the result of more non-combustion technologies in the vehicle and power sectors.\nQ: The aforementioned switch could result in 2.2 million fewer asthma attacks. What forms of air pollution linked with gas and diesel-powered vehicles cause asthma attacks? How dangerous are asthma attacks?\nA: Both particle pollution and ozone pollution associated with vehicle exhaust can contribute to asthma attacks. In fact, the Health Effects Institute’s latest comprehensive study on the health harms of transportation pollution re-confirmed the link between the onset of new asthma cases and traffic pollution exposure. Asthma attacks can result in the need for increased medication, emergency department visits, hospitalizations and can be fatal.\nQ: The report also mentions that the switch could result in 10.7 million fewer lost workdays. Why is that the case?\nA: By reducing harmful pollution, workers would be less likely to be too sick to work. Whether that is due to asthma flare ups, cardiovascular illness or other impacts, cleaning the air can remove a significant health risk from people’s daily lives. While not included in the report, there is also a significant benefit in terms of improving children’s health that could mean parents don’t need to stay home from when the child is too ill to attend school, camp or other activities.\nQ: Heart attacks, strokes, and lung cancer can be caused by exposure to air pollution. Is the general public aware of this fact and that the source of the air pollution is combusting fossil fuels such as gasoline, diesel fuel and coal?\nA: The goal for our report is to do just that — to draw attention to the existing health risks posed by the transportation and power sectors. We want people to see the report and make the link to the unacceptable risk posed by fossil fuels in our daily lives, and what the health-related benefits could be through a transition to non-combustion, zero-emission technologies that are healthier, less costly and more efficient in the long run.\nQ: In general, does American air pollution impact people of color more than white people?\nA: Yes, and our State of the Air 2023 report puts a very fine point on this. There are almost 120 million Americans living in a community impacted by unhealthy air, and the majority of those affected are people of color. We found that a person of color in the United States is over 60 percent more likely to live in a community impacted by unhealthy levels of ozone and/or particle pollution than a white person. When we look at the communities with a failing grade in all three of the State of the Air categories, a person of color is 3.7 times more likely than a white person to live with the most unhealthy air. The US EPA has also noted this disparity in that 72 million Americans live in close proximity to a major transportation/freight corridor, and those living along those routes are more exposed to harmful pollution, have lower incomes and are more likely to be people of color.\nA Final Note For Context\n89,300 Americans dying prematurely is quite obviously a huge number of lost lives. The good news is that this enormous loss of life can be prevented. For some context, a little over 58,000 American soldiers lost their lives in the Vietnam War. Air pollution from gas- and diesel-powered vehicles is typically not that visible except for some moments when the vehicles accelerate and it is possible to see a surge of smoke or soot from a vehicle’s tailpipe, bus vertical exhaust pipe, or tractor trailer “smoke stack.” We don’t see most of the tiny, microscopic particulate matter, aka soot, nitrogen oxides, or ozone and so we might not be that aware of it or even think about it. It’s there though, wherever gas and diesel vehicles are being operated, especially in large cities, on and near freeways, and in or near ports. Exposure to toxic exhaust takes quite a toll on human health and results in far too many premature deaths. Eventually, as clean, renewable electricity and electric vehicles replace fossil fuels and the vehicles that use them our nation will be healthier.\nHave a tip for CleanTechnica? Want to advertise? Want to suggest a guest for our CleanTech Talk podcast? Contact us here.\nEV Obsession Daily!\nTesla Sales in 2023, 2024, and 2030\nCleanTechnica uses affiliate links. See our policy here.","Study: Plunge in Emissions During Shutdown Demonstrates Potential For Huge Environmental, Health, and Economic Gains\nRockville, Md. – A new study finds that New York City’s two-month shutdown during COVID-19—while undeniably painful—could point the way toward saving thousands of lives through improved air quality, generating billions of dollars in related economic benefits in the process. Neighborhoods with higher percentages of low-income residents or higher percentages of Black or Latinx residents likely would benefit more from the reduced particulate matter concentrations. The study’s findings are published in the journal Environmental Research.\nDuring the initial shutdown from March 15 to May 15, researchers from Columbia University, Abt Associates, and ZevRoss Spatial Analysis estimated a citywide 23 percent reduction in fine particulate matter (PM2.5 ) concentrations. This was attributable to an estimated 60 percent decline in automobile traffic, as well as declines in air traffic, construction, restaurant operation and electricity generation. They then extrapolated ambient levels of PM2.5 during a five-year period. Using data from the U.S. Environmental Protection Agency, the research team quantified the economic value of estimated avoided cases of air pollution-related illnesses and deaths.\n“We know people are healthier when their air is cleaner, and when they are healthy, they earn more,” said Abt Associates’ David Cooley, a co-author of the report and expert on climate change and air quality. “This study models a scenario that captures not only the health benefits of clean air for children and adults, but the benefits of avoiding the cost of air pollution-related illnesses, and the benefits to people in different economic and racial demographics.”\nThe study itself is innovative because it includes impacts on children and infants, cohorts that are typically left out of health benefits assessments of air pollution control and climate change mitigation strategies. These include:\n- A potential reduction of 2,392 autism spectrum disorder cases, saving up to $7 billion dollars.\n- Eliminating almost 8,000 instances of asthma-related health care, worth almost $185 million dollars in savings.\n- Sixty-six million dollars in savings by reducing pre-term births and low birthweights.\n- A potential savings of $100 million by eliminating 10 infant deaths, and a staggering possible savings of $69.7 billion by avoiding up to 7,791 adult deaths.\nEnvironmental Justice Benefits\nThe results show that low-income, Black, and Latinx neighborhoods would receive a higher share of the total benefits, in part because those neighborhoods already suffer disproportionately high rates of negative health outcomes. Divided solely by income, neighborhoods:\n- With a poverty rate of 10 percent or less would experience a little over $250,000 annually in benefits per 100,000 people.\n- With a poverty rate over 30 percent would experience almost $700,000 annually in benefits per 100,000 people.\nWhen looked at through the prism of race:\n- Neighborhoods comprised of 20 percent or fewer Black or Latinx population would experience slightly less than $350,000 in annual benefits per 100,000 people.\n- Neighborhoods with more than 80 percent Black or Latinx population would experience nearly $550,000 in annual benefits per 100,000 people.\n“The tragedy of COVID-19 has inadvertently given us a look at how we might examine the health benefits of efforts to reduce air pollution and mitigate climate change,” said Cooley. “We’ve conducted many studies on the health and financial impacts of air pollution and climate change, but simulating this scenario demonstrates how improving the environment can address the inequities facing communities of color and eliminate serious—and costly—health issues for adults and children.”The study, produced by Columbia University Mailman School of Public Health, isn’t an estimate of the benefits of the pandemic itself; rather, it identifies aspirational policy goals to reduce emissions. The research was supported by grants from the Environmental Protection Agency and National Institute of Environmental Health Sciences, the John and Wendy Neu Foundation, the John Merck Fund, and New York Community Trust."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:c0f0cc80-7ae0-43e9-b82f-de4b3cea908a>","<urn:uuid:8647fb2c-e784-409e-a94a-b256908a9df1>"],"error":null}
{"question":"How does Fair Trade combat poverty through farmer empowerment, and how does this relate to fighting cultural colonialism?","answer":"Fair Trade combats poverty by helping farmers earn fair prices and additional income, with organizations like Lutheran World Relief and Fair Trade USA enabling projects in over 70 countries that improve business capacity and community infrastructure. For example, in Uganda, they helped 6,000 coffee farmers increase production by 75% in three years. This economic empowerment connects to fighting cultural colonialism, as it gives farmers control over their resources and dignity, resisting the kind of occupation that, as described in colonial contexts, settles in the very center of the individual and attempts to destroy local culture and independence. Fair Trade thus represents both economic and cultural resistance against exploitation.","context":["“It is not the soil that is occupied…colonialism has settled itself in the very center of the…individual, and has undertaken a sustained work of cleanup, of expulsion of self…there is not occupation of territory on the one hand, and independence of persons on the other. It is the country as a whole, its history, its daily pulsation that are contested, disfigured, in the hope of a final destruction. Under these conditions, the individual’s breathing is an observed, an occupied breathing. It is a combat breathing.”\nIraq? Afghanistan? Palestine? No. But it could be. This is Frantz Fanon writing about the French in Algeria, in his book, A Dying Colonialism, 1965.\nSo, someone reading this might say, what does this have to do with Best American Poetry? With poetry at all? Fannon knew what he was speaking about. His books are still read for the clarity of his understanding of colonialism, occupiers and the occupied.\nPoetry can be a rebellion, a refusal to allow occupation of the soul. Rebellion to the occupiers themselves.\nWhen I wrote Vocabulary of Silence, (Red Hen Press, 2011) it was from the stance of a witness-from-afar to the continued US war against Iraq and Afghanistan. I tried to examine in myself how that felt, what it meant to be living in the country that conducted, and took photos of, torture in Abu Ghraib, for instance. Many of poems from Vocabulary of Silence have been translated into Arabic by poet and translator Nizar Sartawi, and have appeared in journals and newspapers throughout the Arab world, an honor to be sure.\nOne must write what one must write. For myself, I couldn’t bear what was going on without “doing” something. Poetry and politics. Political poetry. What seems to be questionable in this country, that is, there seems to always be a challenge to those who write what is termed “political poetry,” in my limited experience of reading poets from the Arab world, particularly Iraq and Palestine, the division isn’t there. The assumption is, I believe, that the poets are the speakers for the people, (and for themselves as individuals) what happens to their country and the world, is matter for their poems -- and the poets are highly revered.\nOf course, Palestinian poet Mahmoud Darwish comes to mind. His poems, “Identity Card” and “State of Seige” propelled him to international fame, and he was considered the voice of the Palestinians for most of his writing career. He exemplifies too, a theme, that for me, runs through so much of modern Arab poetry: the theme of exile. Here are some excerpts from Who Am I, without Exile?\nStranger on the river bank,\nlike the river, water binds me to your name.\nNothing brings me back from this distance\nto the oasis: neither war nor peace.\nNothing grants me entry into the gospels.\nNothing. Nothing shines from the shores\nof ebb and flow between the Tigris and the Nile….\nWhat shall I do? What shall I do without exile\nand the long night of gazing at the water?\nThis displacement and comment upon exile, and colonial occupation, is echoed in this excerpt of Iraqi poet Lateef Helmet’s, The Heart of a Woman:\nThe heart of a woman is the only country\nThat I can enter without a passport,\nWhere no policeman\nAsks me for my card\nOr searches my suitcase\nFull of contraband joys\nAnd delicious sorrows.\nThe heart of a woman is the only country\nThat does not heap up heavy weapons\nNor force its citizens to fight its wars.\nIraqi poet Fawzi Karim circles the question of exile, even in one’s homeland, in his poem,\nWhat Was my Choice??\nOne has learned to allow a tiny space in the head for contingency…\nthen you in one moment peel yourself of whom you love\nand lone, dim-sighted, grope your way home,\nthe light of the street lamps heavier than darkness\n---the burden of exile…memory.\nTantalizing ourselves with hope\nshielding ourselves against…but the question in the middle\nof exiles suddenly…:\n--What have you chosen?\nThe question of hope as both desired and feared, is echoed in Darwish’s famous poem, State of Seige:\nHere, by the downslope of hills, facing the sunset\nand time’s muzzle,\nnear gardens with severed shadows,\nwe do what the prisoners do,\nwhat the unemployed do:\nwe nurture hope\nAnd finally, excerpts from We Are Not Dead, by Iraqi poet Munthir Abdul-Hur:\n…We go, every sunset, to the river\nCarrying the coffins of our day\n…We are not dead…\nWe compose our features,\nBandage our calendars,\nWe return to our hospitals\nLighting lamps of regret\n…Where fold after fold,\nThe sea takes our dreams…\nOur lifetimes are withered leaves\nThat launched an attack on the sun\nAnd fell in flames.\nThe fire now licks at our names,\nSewn together with splinters.\nWhat poetry can do, is to seize back our names, emblazon them on paper, and send poems out like messages in a bottle, or the folded paper boats with candles, set upon the water, in tribute to hope, endurance, peace and poetry.\nMahmoud Darwish, Unfortunately, It Was Paradise, Selected Poems, translated and edited by Minir Akash and Carolyn Forche, with Sinan Antoon and Amira El-Zein, University of California Press.\nMahoud Darwish, The Butterfly’s Burden, translated by Fady Joudah, Copper Canyon Press.\nFanon, Frantz, A Dying Colonialism, Evergreen Press.\nSadek Mohammed, Sohell Najm, Haider Al-Kabi, Dan Vech, editors and translators; Flowers of Flame, Unheard Voices of Iraq, Michigan State University Press, East Lansing.\nSaadi Simawe, editor, Iraqi Poetry Today, Zephyrpress.","Social Enterprise: The Lutheran World Relief and Fair Trade USA Empower Farmers to Fight Poverty\nThe Lutheran World Relief (LWR) is a social enterprise empowering farmers and workers to fight poverty, improve the lives of their families and communities and protect the land on which they work. A strong supporter of Fair Trade, it is collaborating with Fair Trade USA to strengthen Fair Trade coffee cooperatives. It is helping coffee growers to improve quality, increase productivity and improve access to capital—all to become stronger businesses. Fair Trade USA and its partners have helped farmers and workers earn more than $225 million in additional income and enabled projects in more than 70 countries worldwide that improve business capacity, community infrastructure, social investment and environmental protection. Paul Rice, President and CEO of Fair Trade USA says, “We are honoured to partner with Lutheran World Relief to build a stronger foundation for small-scale farmers around the world. We firmly believe that this type of collaboration is essential to helping co-ops remain strong and competitive now and in the future.”\nAt the heart of this social enterprise collaboration is the belief that Fair Trade is part of the solution to eradicate global poverty. LWR through its Fair Trade programs has sold more than 1,300 tons of Fair Trade coffee, tea and cocoa; more than $5 million worth of handcrafts; and $1.5 million worth of Fair Trade chocolate to Lutherans in America. LWR works directly with farmer cooperatives, assisting them in quality improvement and obtaining Fair Trade certification. In Uganda, LWR has helped more than 6,000 coffee farmers increase their production of Fair Trade coffee by almost 75% in just three years, significantly boosting family incomes. In Nicaragua this social enterprise organisation has helped more than 1,760 farmers sell more than $19 million worth of coffee and cocoa over the last five years, and created more than 6,000 permanent jobs.\nBuilding on these successes, LWR and Fair Trade USA are now working in Indonesia. They have collaborated with Progreso with generous funding from the Rabobank Foundation. Together these organisations joined forces earlier in 2012 to partner with eight coffee cooperatives in Aceh, a mountainous region on the island of Sumatra. The coffee here is wonderful, yet due to insufficient business training and limited access to market, these farmers are still struggling to make ends meet.\nBehind most of the items we consume daily are farmers struggling to survive and support their families. Living in poor, rural regions of the world small-scale farmers who produce these products have little ability to negotiate fair prices for their goods. In conventional trade, middlemen take advantage of the small-scale farmer’s weak negotiating power and limited access to market, paying unfair low prices that barely cover the cost of farming. This leaves little money for food, medicine, clothes or even education for their children. This is why partnerships like this based around the ethos of Fair Trade are crucial to the survival of farmers globally, as without them our lives and cupboards would be bare.\nPhoto Credit: Lutheran World Relief"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:36494111-6cbf-4626-b44d-00f746765ca3>","<urn:uuid:d862d9a5-f6bb-4e54-b24d-d2688e1f3fff>"],"error":null}
{"question":"What community support exists for saving these historic theaters?","answer":"Both theaters receive strong community support. For the Uptown Theater, local leaders actively endorsed its preservation, with Mayor Mike McGinn calling SIFF 'one of Seattle's true treasures' and praising their leadership in saving the theater. The Greater Queen Anne Chamber of Commerce endorsed the acquisition, highlighting its value for community businesses and entertainment. For the Brighton Hippodrome, community support is demonstrated through the Brighton Hippodrome Community Interest Company (CIC), which has secured grants for surveys and designs, developed restoration proposals, and commissioned studies showing the theater could benefit the local economy by £10m annually. The Brighton and Hove City Council has also recognized the Hippodrome's heritage importance in its Old Town Conservation Area Management Plan.","context":["The Seattle International Film Festival announced Saturday that it will be revitalizing Lower Queen Anne’s historic Uptown Theater, which shuttered its doors back in November after its partent company AMC opted to close the old theater house rather than invest in updates.\nSIFF plans to reopen the neighborhood theater in October, as it transitions out of its current location in McCaw Hall, in conjunction with the Grand Opening of its own new SIFF Film Center at Seattle Center. SIFF says the new space will provide the organization with increased seating capacity and three additional screens, which will allow it more flexibility for year-round programming.\nWhen the Uptown Theater closed last fall, many in the community were heartbroken to see the longstanding neighborhood cinema house, originally opened in 1926, fall by the wayside. We reached out to SIFF to see if the organization had any interest or intention of taking over the newly vacated space. At the time SIFF representatives told us they were not in a position to take over the theater.\n“It really is unfortunate that Uptown theater is closing. I used to go there many times and even when I was growing up so personally it’s a shame that it is closing,” SIFF representative Tod Steward wrote to Queen Anne View back in November. “Maybe Paul Allen or someone like him would finance it to stay open…just like what he did with Cinerama.”\nFortunately for the Queen Anne community, the tides have changed since last fall. In addition to helping expand its year-round programming, SIFF says the reopening of the theater will give it the opportunity to establish first-class educational programs and solidify the future of the organizations and its programs.\nMayor Mike McGinn came out in support of the deal, stating, “SIFF is one of Seattle’s true treasures not only for the work they do in Film and Education, but for being a leader in our community and saving the Uptown Movie Theatre. The leadership that SIFF is demonstrating should not only be recognized but applauded.”\n“On behalf of the Greater Queen Anne Chamber of Commerce, we are especially pleased to endorse the acquisition of the Uptown Theater by the Seattle International Film Festival,” Chamber vice president Ann Pearce said in a statement. “We applaud their actions in preserving a valuable part of Seattle’s Uptown neighborhood and creating more opportunities for Queen Anne community businesses. Another wonderful forum for unique entertainment will now be available for residents and tourists alike to enjoy for years to come!”\n“We couldn’t have scripted a better opportunity for our organization than to have SIFF Cinema Uptown and the new SIFF Film Center in such close proximity and located in such a vibrant part of the city. Seattle Center and Queen Anne are the perfect locations for us to expand in and we’re excited to be opening our doors in time for Seattle Center’s ‘Next 50’ celebration next year,” SIFF Artistic Director Carl Spence said.\n“We are thrilled to welcome SIFF as a new resident here, and we embrace its move to use the former Uptown Theater space as a SIFF screening venue. What a wonderful means to enlivening the neighborhood and further connecting Seattle Center to the Uptown area,” Seattle Center Director Robert Nellams said.","The UK’s most architecturally significant circus theatre – the finest surviving example of its type in the country.\n- Middle Street, Brighton, East Sussex, BN1 1AL\n- Risk Rating\n- 9 (Community Value: 3. Star Rating: 3. Risk Factor: 3.)\n- Local Authority\n- Brighton and Hove City Council\n- Matsim Properties\n- Frank Matcham\n- Date of Construction\n- Grade II*\n- 1,400 -1,500 (estimated)\n- Database Link\n- View in Theatres Database\nBrighton Hippodrome is the UK’s most architecturally significant circus theatre – the finest surviving example of its type in the country. It is listed Grade II*. The Hippodrome originally opened as an ice skating rink in 1897, designed by Lewis Karslake. In 1901 eminent theatre architect Frank Matcham converted it into a circus. Further adaptations in 1902 by another distinguished theatre architect of the time, Bertie Crewe, saw it modified into a variety theatre. The most spectacular feature is the circular auditorium with its richly decorated ceiling in the form of a panelled tent. The relationship between the stage house, auditorium and circle, as well as the ancillary areas, is significant as a unique example of our past cultural and recreational pursuits.\nWhy is this theatre at risk?\nBrighton Hippodrome has been on the Theatres at Risk Register since 2006 when we started the list.\nIn 2014 Brighton and Hove City Council (BHCC) approved planning applications to convert the Hippodrome into a multiplex cinema. This would have seen the auditorium subdivided, the fly tower demolished and the rear access to the theatre built upon, preventing the building from ever being used as a theatre again. However, in 2015 the proposed cinema operator pulled out. The planning consent has subsequently expired. In the meantime the building remains vacant and in an ever-increasing state of disrepair.\nIn November 2017 the Hippodrome was sold by Academy Music Group to private investor Hippodrome Investments. In January 2019 the new owner released initial images showing its proposals for the building, to include a new hotel and spa complex and serviced apartments on the site and retaining only the auditorium from the theatre building. Full details have yet to be released, however there is grave concern that the scheme proposes a scale of redevelopment both inappropriate to the building’s heritage significance and one that will prevent it from being returned to large-scale theatre use in the future.\nIn 2015 a stakeholder group, including campaign group Brighton Hippodrome Community Interest Company (CIC) and Theatres Trust, commissioned a viability study. This concluded that the building does have a viable future as a large-scale theatre, if the challenge of raising funds can be met.\nBrighton Hippodrome CIC secured grants to complete a valuation, structural surveys, initial designs and costings for the building in 2016. Its proposals include residential and retail development on site to support the phased restoration of the auditorium and stage house. Importantly, the CIC’s proposals are sensitive to the historic significance of the theatre and the needs of a performance venue and will retain both the flytower and access to the get-in and back of house areas. This will allow the Hippodrome to be restored and reopened as a large-scale theatre.\nIn 2018 the group commissioned an economic impact study to assess the effect of a restored and reopened Hippodrome for Brighton. This estimated that, once established, a large-scale receiving theatre could benefit the local economy by about £10m annually. The group also commissioned external validation of its business plan by both an independent arts consultancy and two large-scale regional theatre venues with operating models similar to that proposed for the Hippodrome. The use of the building as a large-scale receiving theatre has also secured the backing of national theatre operators. Theatres Trust has been supporting the group in this work.\nIn November 2018 Brighton and Hove City Council published its Old Town Conservation Area Management Plan, based on a Character Statement funded by Brighton Hippodrome CIC on behalf of the council through Coastal Revival Funding. The plan lists the heritage importance of the Hippodrome within the area and its significance for stimulating regeneration of the conservation area.\nOver this last year the CIC has been working on a strategy for a phased approach to the restoration and reopening of the Hippodrome and associated fundraising plan. Theatres Trust has been supporting the CIC in this work. This alternative proposal is based on reviving the whole of the theatre, with enabling development to part-fund the restoration work. The group has also entered into pre-application discussions with Historic England and will be looking to submit for pre-app with BHCC soon.\nTheatres Trust is clear that any development of the theatre and its surrounding site must be sensitive to the possible future reinstatement of the theatre as a large-scale venue for performance and has continued to lobby BHCC, Historic England and other key organisations to this cause.\nIn May 2020 Brighton Hippodrome CIC was awarded a Theatres at Risk Capacity Building Programme grant of £7,000 to support legal advice to formalise the development partnership and to support fundraising advice.\nIn September Brighton Hippodrome was bought by developer Matsim Properties.\nCampaign video (from 2016)\nImages, Brighton Hippodrome, Theatres Trust, 2017"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:f96bd86e-b9fe-4170-9d71-79044788b344>","<urn:uuid:70fc9df6-1c27-4a2c-a00f-7422ff4c4d7b>"],"error":null}
{"question":"What essential documents do I need for a planning application? Need a quick checklist! 🏠","answer":"A planning application requires five copies of application forms, a signed ownership certificate, a site plan, block plan, elevations of both existing and proposed sites, a Design and Access Statement, and the correct fee.","context":["What documents are required for a planning application?\nWhat Does a Planning Application Include?\n- five copies of application forms.\n- the signed ownership certificate.\n- a site plan, block plan, elevations of both the existing and proposed sites,\n- a Design and Access Statement.\n- the correct fee.\nWhat plans are required for a planning application?\nMost planning applications need you to submit two plans as supporting documents: a location plan, which shows the site and the surrounding area, and a site plan, which shows the proposed development in detail. You can buy both online from one of the Planning Portal's accredited suppliers, listed here.\nWhat happens if you lie on a planning application?\nIf a planning permission is fraudulently obtained no doubt that renders it liable to be revoked. If you have not already done so, you should notify the planning department in writing. You should also find out the names of the councillors on the planning committee and send a copy of the letter to each one.\nCan granted planning permission be revoked?\nOnly the applicant can make an appeal against a granted planning application. ... This means you cannot appeal a planning application decision which you have not submitted yourself.\nCan I do my own planning drawings?\nYou can do your own plans. They don't have to be too fancy for something like a garage, but they do need to have all the important information on them. (Address, name, dimensions, materials etc.)30 มี.ค. 2548\nCan I draw my own plans for building regs?\nYou have to apply for building regs before you start building and you can do one of the following. A building notice can be submitted by your builder but does not involve any working/detailed drawings. ... The other alternative is to have an architectural technician to submit drawings under a full plan application.\nDo I need Building Regs for an extension?\nIf you're planning to extend your home, you will need to comply with the building regulations. This is a legal requirement and, without formal approval and control, your local council could force you open up or re-build sometimes significant aspects of the project. It could even lead to prosecution and unlimited fines.\nDo you get a certificate for building regs?\nThere aren't any building regulations certificates from when we moved in. ... Building regulation requirements do change over the course of the years and with works that were carried out a long time ago, say 20 years, you often find completion certificates were not even issued at that time.\nHow do I apply for building regs?\nFollow these five steps to building regulations approval and getting that all important completion certificate.\n- Choose a building control surveyor. ...\n- Submit your building regulations application. ...\n- Get to work. ...\n- The building control surveyor visit. ...\n- Further information.\nHow much do building regs cost UK?\nHow much does building regulation approval cost? This can vary according to local authority fee rates and the nature of the work undertaken, but as a rule of thumb most conversion, renovation or extension work will cost around £100 to submit full plans and a further £200-400 for inspections.\nHow long do building regs take?\nCan I get building regs after work is done?\nCan I obtain retrospective approval for building work carried out without notification? Yes. The Building Regulations allow you to \"regularise\" unauthorised building work that has begun since 11 November 1985.\nWhat happens after planning permission is granted?\nThe authority grants/refuses planning permission by sending you a letter notifying you of its decision. Planning permission runs with the land. This means that land or buildings can usually be sold or let with the benefit of planning permission.\nDo I need building notice or full plans?\nYou can apply for building regulations approval from your local authority building control service by giving a building notice. Plans are not required with this process so it's quicker and less detailed than the full plans application.\nDo I need Building Control drawings?\nUnlike the Full Plans process, detailed drawings are not always required. However, you must submit the following with your application: • Completed Building Notice form. may be requested to ensure compliance with the Building Regulations.\n- How do you write water conservation?\n- What is the meaning of construction?\n- What are the steps of energy conservation planning?\n- How did construction start?\n- Who started construction?\n- What is the national river conservation plan?\n- What is considered heavy construction?\n- What is pre implementation stage?\n- How can a business save energy?\n- What is framing in art?\nYou will be interested\n- How many years did it take to build the Burj Khalifa?\n- What is garment construction?\n- Who invented the hard hat?\n- Which company will give bonus share in 2021?\n- What is NRCS funding?\n- Who makes more money civil engineer or construction manager?\n- When were construction cranes invented?\n- What does strict construction mean?\n- Who was the first civil engineer in history?\n- What are habitat credits and how do they help endangered species?"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:9099cf4a-8c9e-41da-9197-171c558555c7>"],"error":null}
{"question":"Could you explain how both bladder exstrophy and cleft palate develop during pregnancy, and what are the key developmental differences between these two congenital conditions?","answer":"Both conditions develop due to failures in normal fetal development, but at different stages and through different mechanisms. Bladder exstrophy occurs when the abdominal wall fails to close while the baby grows in the womb, resulting in the bladder being exposed on the outside of the abdomen. In contrast, cleft palate develops when the two sides of the palate fail to join together during early pregnancy, specifically at 8-10 weeks from conception. The palate normally forms from several different pieces that should join together in the center, but sometimes these pieces either don't join at all or stop joining before the palate is fully formed, similar to a half-closed zipper.","context":["Bladder Exstrophy (Pediatric)\nWhat is bladder exstrophy?\nExstrophy is a rare and complex disorder in which the abdominal wall fails to close while a baby grows in the womb. The intestine may be abnormally connected to the bladder, and the urethra and genitals may not be completely formed. Exstrophy must be diagnosed before birth to prepare a multidisciplinary team and surgical plan.\nOur reconstructive surgeons form one of the few medical teams on the East Coast able to treat exstrophy and have trained with world leaders and innovators in the treatment of this disorder.\nCloacal exstrophy usually involves many systems in the body, including the urinary tract, skeletal muscles and bones, and the digestive system. Bladder exstrophy means the bladder is essentially open and exposed on the outside of the abdomen. As a result, urine constantly trickles onto the skin and causes local irritation.\nEpispadias often occurs with bladder exstrophy. Epispadias is when the urethral opening, the hollow tube that drains urine from the bladder to the outside of the body, is in an abnormal location. In males, the urethral opening is usually on the top side of the penis and not the tip. Epispadias differs from hypospadias, where the urethral opening is usually underneath the penis. In females, the urethral opening may be bigger and longer than normal, and positioned further up the urethra, often extending to the bladder.\nWho is affected by bladder exstrophy?\nBladder exstrophy occurs in about one in every 30,000 births. The disorder is more common in males and varies in severity. Its cause is unknown, though some reports show a clustering of bladder exstrophy in families, suggesting an inherited factor. However, the chance for parents to have another child with bladder exstrophy is small (1 percent or less). In many cases, bladder exstrophy is associated with:\n- widened pubic bones\n- outwardly rotated legs and feet\n- triangular defect in the abdomen and visible bladder membrane of a bright pink hue\n- abnormally-shaped abdominal muscles\n- displacement of the umbilicus (belly button), usually above the defect\n- umbilical hernia (a section of intestine protrudes through a weakness in the abdominal muscles)\n- short, small penis with urethral opening along the top (epispadias) or divided penis\n- narrow vaginal opening, wide labia, and short urethra\nHow is bladder exstrophy diagnosed?\nBladder exstrophy is usually diagnosed by fetal ultrasound before an infant is born. After the birth, exstrophy is determined by physical examination. Your child's doctor also may order other diagnostic procedures.\nWhat is the treatment for bladder exstrophy?\nSpecific treatment for bladder exstrophy and epispadias is determined by your child's doctor based on:\n- your child's age, overall health, and medical history\n- extent of the disorder\n- your child's tolerance for specific medications, procedures, or therapies\n- expectations for the course of the disorder\n- your opinion or preference\nAfter a diagnosis is made, your child will be referred to a surgeon. There are usually three stages to the surgical repair process that may start when your child is as young as 48 hours old.\n- Stage 1 involves internalization of the bladder and closing the abdomen.\n- Stage 2 is usually done between ages 1 and 2 to repair the epispadias and other genital abnormalities.\n- Stage 3 is done around age 3 and reconstructs the bladder and other structures of the urinary tract.","A cleft palate is a gap in the roof of the mouth that results when the two sides of the palate do not join together during development.\nWhat is Pediatric Cleft Palate?\nThe palate (mouth) has two main parts – a hard bone portion that is in the front half of the palate and a floppy soft part in the back half of the palate. Run your tongue along the roof of your mouth from your teeth backwards.\n- The front part is hard, because there is bone under this part of the palate.\n- The back part is soft because only small muscles are present within this portion.\nIf there is a cleft of the palate, the result is that the two sides of the palate have a gap between them.\nA patient can have cleft palate alone (isolated cleft palate), with a cleft lip or part of a syndrome. Patients with cleft palate alone have different inheritance patterns and characteristics from patients with cleft lip and palate or cleft lip alone.\nHow common is Pediatric cleft palate?\nCleft palate alone occurs in about 1 in 1,500 children born in the U.S. It occurs more often in girls than in boys. The rates do vary by ethnicity with higher rates (1 in 500) in patients of Asian descent and lower rates (1 in 2,000) in patients of African descent. A cleft lip and palate together is the most common occurrence. It is seen in about 1 in 600 children born in the U.S., occurring more often in boys than girls and more often on the left side than the right side.\nThere are several factors that may increase the risk of having a child with cleft lip and palate. While the inheritance of many genes from either parent and the maternal use of certain medications and substances (maternal smoking, anticonvulsants, alcohol, retinoic acid) are believed to increase the risk of having a child with a cleft, the majority of children born with a cleft of the lip or palate have none of these associated factors.\nThe way that the inheritance of many genes can affect the risk for having cleft of the lip or palate is difficult to understand. A simplified way to think about it is that there are many genes that slightly increase someone’s risk of having a cleft. The more of these genes a person has, the more likely it is that they will have a cleft. However, it is important to understand that in most cases, a family with a parent or child with a cleft still has a low risk of having more children with clefts of the lip and palate.\nThe most common scenario is that a family will have a child born with a cleft and no other history of a person with cleft lip and palate in either parent’s family. The risk of this family’s next child having a cleft is about 5% (1 in 20). If a family has one parent with a cleft but no children with a cleft, the risk of their next child having a cleft is about 5% (1 in 20). If a family has no parent with a cleft but two children born with clefts, the risk of their next child having a cleft is about 10% (1 In 10). If a family has one parent and one child with a cleft, the risk of their next child having a cleft approaches 20% (1 in 5). In other words, a family with one parent and one child born with a cleft has an 80% (4 in 5) chance of their next child NOT being born with a cleft. So even when several family members have had a cleft, the risk is higher than the average person, but still relatively low.\nThere are rare exceptions to this such as Van der Woude syndrome, which demonstrates autosomal dominant inheritance where 50% of a family’s children may be born with a cleft. For this reason, genetic testing should be done when there is a strong family history of clefts\nWhat are the different types of Pediatric Cleft Palate?\nThere are several types of cleft palate, which can affect the type of surgery required.\nComplete cleft palate\nComplete cleft palate occurs when there is a cleft of the hard and soft palate; the gap extends from just behind the front teeth all the way through the back of the palate. All of the bony and soft parts are involved.\nIncomplete cleft palate\nIncomplete cleft palate occurs when there is a cleft of the soft palate only and at least some of the bone portion of the palate is intact. Usually, it is only the soft, floppy back portion of the palate that has the cleft.\nUnilateral cleft lip and palate\nUnilateral cleft lip and palate occurs when a cleft palate is associated with a cleft lip, and there is most often a complete gap from the front to the back, joining with the gap in the gum and lip.\nBilateral cleft lip and palate\nBilateral cleft lip and palate occurs when there is a cleft of the hard and soft palate associated with a bilateral cleft lip on both sides.\nSubmucous cleft palate\nSubmucous cleft palate occurs when the muscles of the soft palate have a gap, but the lining of the palate doesn’t have a gap, so it looks similar to a normal palate. There are often a few signs that something is wrong such as:\n- The uvula, or dangling bit at the very back of the palate, is often in two pieces rather than one.\n- There can be a bluish color to the soft palate.\n- You can feel a notch in the bone at the very back of the hard palate.\nMost children with a submucous cleft palate have no problems from it and need no treatment. Occasionally, there can be speech problems that surgical repair can correct.\nWhat are the causes of Pediatric Cleft Palate?\nCleft palate happens because the palate is formed from several different pieces that normally join together in the center of the palate early in the pregnancy, 8-10 weeks from conception. Occasionally, these pieces do not join at all, or they can start to join but stop before the palate is fully formed, like a half-closed zipper.\nWhile a cleft palate can occur by itself, (isolated cleft palate), it is also common for a cleft palate to develop as part of a syndrome. Syndromes often seen with a cleft palate include:\nHow is Pediatric Cleft Palate treated?\nThere are many types of cleft palate repair, and your surgeon will present the very best options based on your unique case. Cleft palate is important to discover and treat because the palate has two main functions, and is vital for several key areas of a child’s development such as:\nHaving a cleft palate can affect the way these develop, so we consider it essential that a child with a cleft palate is cared for through a multidisciplinary approach from birth to adulthood by a craniofacial team, like the one we offer here at Children’s Health.\nOur care team includes speech-language pathologists (SLPs), including a bilingual SLP to offer special insight into the speech and language development of our Spanish-speaking cleft population."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:24359f2e-1349-430f-b4cf-36cc34ff65e2>","<urn:uuid:d3476166-f4ca-433f-98ed-295c5285cf56>"],"error":null}
{"question":"Is high mount position helpful for maintaining control while reducing the risk of overtraining?","answer":"High mount is beneficial for maintaining control as it reduces opponent's escape options and makes mount maintenance easier for fundamentals students. However, to prevent overtraining while practicing this position, you should incorporate rest days in your training program and ensure proper recovery through adequate sleep, balanced nutrition, and stress management. Signs of overtraining to watch for include muscle soreness, decreased performance, and emotional instability.","context":["There are two facets of top mount control we will discuss. First up is maintenance, where your goal is to remain in mount until an attack or transition opportunity presents itself, then we’ll cover a good secondary option when you are about to lose mount.\nThere are various methods for maintaining mount, but staying mounted is a lot easier if you reduce your opponents options for escape. If your hips are near their hips, you are susceptible to upas and bridging that will knock you off balance and possibly result in reversals. This means once you have your mount, transitioning to a high mount should make it easier to maintain mount. Without going off on a tangent, I’ll note that there are very good ways to maintain mount without going to high mount, however for a fundamentals student, high mount is the simpler option.\nTo get to the high mount, your chief obstacle will be your opponents elbows. They want their elbows just inside your legs, and they are using their elbows as a shield against a high mount. If they do not have their elbows sufficiently inside, a good starting attack is to slide your knee along their ribs with the goal of getting your foot up to their hip. Placing your foot on their hip accomplishes a number of different goals:\n- Reinforcement: Having your foot on their hip and driving your heel into their leg helps prevent them from shoving your legs back down their body\n- Hide escape options: A common escape is to turn on the side and scoop up the attackers foot with the top foot. If your foot is on the hip, this becomes impossible.\n- Feel: having your foot on your opponents hips also helps you predict what they are doing. They need their hips to be mobile for any kind of escape, so your feet act as antennae, feeding your information about the orientation and elevation of your opponents hips. This is valuable information that would be dulled or missing if you just have your feet on the floor.\nSometimes you’ll need to reinforce the knee slide with a grip on the elbow, leaning forward and pulling with your hand and pushing with your knee. Placing your head on the floor is a good way to maintain base while freeing up your hands to consolidate the high mount. Once you have control of the elbows with your knees, you can even do things like push on the shoulders with your hands to help reinforce your high mount.\nOnce you get used to this style of getting to high mount, focus on using your knees and thighs to push the arms together, then you can start to look for all the different attacks that are available from high mount. Another option is to start your attack while in low mount, then finish after pushing towards high mount, like some styles of cross collar chokes utilize to get in position.\nThroughout all of this, staying low is your friend. You don’t want to sit upright unless you already have a high mount, some measure of control of the arms, and are ready to attack with a submission in mind. Otherwise you are elevating your base unnecessarily and risking more kinds of escapes.\nIf you feel like you are about to be reversed, switching to a technical mount is a good plan B. The tricky part here is your foot on the side you are being reversed towards. Your opponent will be trying to control that foot by pinching it between their heel and butt. You need to pop it out of there, then rotate your body 90 degrees and shift your weight back away from the reversal. As you do this, drive your heel into your opponents hip and try to stay behind their back as much as possible. It’s likely that they will have control of your arm, but if you stay low and stay back as much as possible, you can turn the reversal into another good attack position.\nSince we spent a lot of time talking about high mount, this time we are just going to cover the defense/escape against high mount. This technique requires good timing, but when you get the sequencing down, it’s a very effective way to defend against a high mount, both after your opponent gets high mount, as well as when they are trying to get high mount.\nThe most important thing to realize here is that we are using the same style of escape that is common to many different jiu-jitsu escapes. First, you create space, then you use that space to alter the position. In this case, you are popping your opponents weight up, then shoving them down your body with your elbows as your body returns to the ground a split second before theirs does. Even the smallest bump can be enough to start the process, but obviously the further down your body you can get your opponent, the more effective your bump will be, and the easier your shove will be.\nBefore you can even start the bump, it is important to still protect your neck, and fight your elbows to the inside as much as possible. This can get very awkward, but you’ll need this positioning to both protect your neck as well as give you leverage against their legs.\nI can’t overemphasize the timing of the bump-fall-shove sequence. Too often, students try to shove too early or too late. In both cases, you end up working against a lot of friction since your opponents weight is still on you. Giving a very hard bump will momentarily ease the pressure on your body both at the top of the bump, as well as while you are falling back to the mat. This weight transfer away from you is what makes the shove effective.\nHigh mount is your friend. It is easier for fundamentals students to maintain, and it still has plenty of chokes and arm attacks available to it. No matter what, you should be treating mount as a go-to position, and you should never willingly transition to a lesser position. Use the above techniques for controlling high mount, as well as defending against the control techniques. As always, protect your neck, keep your elbows in, and stay aggressive.","How to Prevent Overtraining and Overreaching\nSerious athletes have no time to break from training, right? Wrong. Conditioning for your sport is not all about work, activity and movement. You also have to rest, relax, and recover (or restore, recuperate, and regenerate). Overtraining can lead to a number of serious consequences and set your training back weeks or even months.\nAre you overtraining (pushing your body too far over the course of a training program) or overreaching (going too hard in a single workout or series of workouts)? You've gone too far if you're experiencing any of these symptoms:\n- Sympathetic overtraining syndrome, where your resting heart rate, blood pressure, and metabolic rate are abnormally elevated\n- Parasympathetic overtraining syndrome, where your resting heart rate and blood pressure decrease abnormally\n- Emotional instability like fatigue, apathy, depression or irritability\n- Decreased desire for and enjoyment of training\n- Decline in performance\n- Loss of muscle strength\n- Weight loss and loss of appetite\n- Prolonged recovery from training sessions, which can include tenderness and soreness in muscles and joints\n- Sleep disturbances\n- Gastrointestinal disturbances\nOveruse injuries often result from repeated, abnormal stress applied to a muscle, tendon, ligament or bone—by doing too much, doing too much too soon, or not taking enough time to recover and recuperate (Baechle and Earle, 2008). They can also occur as a result of training errors, faulty technique, decreased flexibility or insufficient strength. Find out if you're overtraining or underrecovering.\nHow to Prevent Overtraining\nAre you guilty of overtraining or overreaching? Start incorporating some of these ideas into your training.\n- Design a good training program that incorporates sound exercise principles, including rest days\n- Design a program that is appropriate for your level of conditioning\n- Use the principles of cross training (variety of activity)\n- Use the principles of interval training (variety of intensities)\n- Learn to control your stress in daily life so your body can recover from exercise sessions\n- Get enough sleep to allow your mind and body to recover from workouts\n- Get a massage periodically\n- Use self-massage tools after a workout or on rest days—e.g., massage stick, foam roll, or small massage balls\n- Use a steam bath, sauna, or whirlpool, as needed\n- Eat a balanced healthy diet so that you replenish fluids and nutrients needed for recovery\n- Take a vacation several times a year to allow your mind and body to recharge; an often overlooked area in training is how your daily life impacts recovery from exercise, workouts, and sports competition\nYou can also prevent overtraining and overreaching by tweaking aspects of your personal life, such as:\n- Cutting back on smart phone time, including texting, web surfing, checking emails, and talking, to give your brain a break\n- Driving slower in your community so that your body is not on overdrive (not to mention that it's safer for you and other people on the road)\n- Keeping your personal finances simple and in order\n- Enjoying time with family and friends\n- Avoiding being a constant weight watcher. Don't micromanage every second of your life\n- Learn to complain less throughout your day\nAmerican College of Sports Medicine (ACSM). ACSM's Resource Manual for Guidelines for Exercise Testing and Prescription, 6th ed. Philadelphia; Wolters Kluwer Lippincott Williams & Wilkins, 2010.\nBaechle TR, Earle RW, eds. Essentials of Strength Training and Conditioning, 3rd ed. Champaign, Ill.: Human Kinetics, 2008.\nKreider RB, Fry AC, O'Toole ML, eds. Overtraining in Sport. Champaign, Ill.: Human Kinetics, 1998.\nRichardson SO, Andersen MB, Morris T. Overtraining Athletes: Personal Journeys in Sport. Champaign, Ill.: Human Kinetics, 2008.\nVerkhoshansky Y, Siff M. Supertraining, 6th ed. Rome, Italy: Verkhoshansky, 2009. www.verkhoshansky.com and www.melsiff.com."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:a352dd37-d80e-4ae8-a59c-21c64dfa03ad>","<urn:uuid:eece625b-c80a-4ab3-9588-c1b3ad4c937a>"],"error":null}
{"question":"How do services from the Tissue Acquisition and Cellular/Molecular Analysis facility compare with modern label-free imaging techniques in terms of analyzing cellular structures?","answer":"The Tissue Acquisition and Cellular/Molecular Analysis facility offers traditional labeled imaging services like immunostaining and fluorescence microscopy, which use specific markers to highlight molecular structures through techniques such as Immunohistochemistry (IHC) and In Situ Hybridization (ISH). In contrast, label-free imaging techniques like coherent Raman scattering microscopy can analyze cellular structures by detecting the characteristic intrinsic vibrational contrast of molecules without the need for stains or labels. While the TACMASR approach allows for specific targeting of structures through validated antibody staining protocols, label-free methods are particularly valuable in situations where labeling might be toxic or impractical, such as when studying very small molecules like metabolites where labels would disturb their natural function.","context":["Tissue Acquisition and Cellular/Molecular Analysis\nPersonalized treatment of cancer is rapidly becoming a standard practice. There are a number of factors that contribute to the uniqueness of a patient that include the individual’s genome, the genome and epigenome of the cancer, disease presentation, gender, exposures, lifestyle, microbiome, and other comorbidities. The identification of specific biomarkers, signaling pathways, immune cell signatures and genetic mutations within tumors underlies molecular targeted therapies and new insights into cancer treatment. The Tissue Acquisition and Cellular/Molecular Analysis Shared Resource (TACMASR) is integrated into the University of Arizona Cancer Center and provides support for studies related to advancing our understanding of the pathogenesis of cancers for the successful prevention, control and therapy of disease.\nThe TACMASR provides support and pathology-related services to UArizona Cancer Center and University of Arizona researchers on a fee-for-service basis. We strive to support investigator research endeavors through customized, cost-effective, and quality-controlled services including tissue acquisition, digital pathology, imaging and microscopy, histology and immunohistochemistry, and organoid culture.\nThis shared resource has a board-certified anatomic pathologist on staff with many years of clinical and experimental research experience.\nTACMASR offers two primary types of services to UArizona Cancer Center and UArizona research investigators that include cellular and molecular analysis, and tissue acquisition and biobanking.\nTo build a project, get a quote, or order a service within iLab:\nStep 1: Select “About Our Core” to learn more about this Shared Resource.\nStep 2: Click here to login or sign up for an iLab account at the University of Arizona. For login help, email iLabemail@example.com.\nStep 3: Once the login step is completed, obtaining prices, services and scheduling is available within the iLab system.\nPlease remember to acknowledge the Cancer Center Support Grant (P30 CA023074) when publishing manuscripts or abstracts that utilized the services of the University of Arizona Cancer Center’s Shared Resources and/or were derived from CCSG pilot funds. Suggested language: \"Research reported in this [publication/press release] was supported by the National Cancer Institute of the National Institutes of Health under award number P30 CA023074.\nThe Tissue Acquisition and Cellular/Molecular Analysis Shared Resource (TACMASR) is a multi-faceted research service facility that offers:\n- Biorepository - procurement, storage, and retrieval of Cancer biorepository specimens as well as assistance with locating sample cohorts and access to other special collections. Contact Carole Kepler.\n- Acquisition and preservation of tissues and body fluids\n- Biospecimen banking and storage\n- Routine Histology - paraffin & frozen samples, routine & special stains, Tissue MicroArrays (TMA). Contact Jocelyn Fimbres and Maga Sanchez.\n- Immunostaining and in situ hybridization - Immunohistochemistry (IHC), In Situ Hybridization (ISH) using validated antibody staining protocols on automated platforms. Contact Jocelyn Fimbres and Maga Sanchez.\n- Pathology - experimental advice, quality control, and scoring.\n- Digital Pathology, Imaging & Microscopy - brightfield slide scanning, brightfield and widefield fluorescence microscopic image capture, Leica SP5 confocal microscope (with live cell imaging capabilities), Nikon spinning disk confocal microscope, Nikon BioPipeline Slide Scanner, Nikon image analysis workstation, as well as assistance in accessing and using other microscopy techniques on campus. Contact Sara Parker.\n- Organoid Generation and Culture. Contact Yana Zavros\nThese services are provided on a fee-for-service basis to members of the University of Arizona Cancer Center and to University of Arizona research investigators.\nUniversity of Arizona Cancer Center, Levy Building\nLab - Room 0917\nOffice – Room 0914\n1515 N. Campbell, Tucson, AZ 85724","Jessica Rowbury looks at the development of new fluorescent proteins and label-free imaging methods, helping scientists probe deeper into tissue\nIn recent years, super-resolution fluorescence microscopy has evolved at a fast pace; scientists can now image at a nanometre scale to observe molecular interactions and dynamic processes.\nOne limitation of fluorescence microscopy, however, is that the red fluorescent probes used for labelling tissue specimens are not very bright or efficient. To solve this, researchers are developing a new group of near-infared fluorescent proteins for enabling greater tissue depths with improved sensitivity.\nMeanwhile, in separate research, scientists are advancing label-free live imaging techniques that, for certain applications, eliminate the drawbacks associated with using fluorophores, such as phototoxicity.\nThe availability of bright fluorescent markers that can highlight molecules and structures specifically and efficiently is central to successful fluorescence microscopy. For live imaging, the green fluorescent protein (GFP) family of markers have become the gold standard, because of their ability to be genetically encoded and expressed in cells, resulting in a fusion construct with the protein of interest.\nThis provides a powerful and versatile technique for labelling live samples. Since its discovery in the 1960s, scientists have worked on optimising marker proteins of the GFP family, and the colour palette has been extended from the blue to the far-red side of the spectrum. It’s safe to say that the green fluorescent protein and its colour-shifted genetic derivatives have revolutionised live cell imaging.\nFar-red emitting fluorescent proteins (FPs) are advantageous as markers for live specimens for multiple reasons. Not only is there less absorption, scattering and autofluorescence in the red part of the spectrum, but red light is less phototoxic, and far-red FPs offer the possibility of realising an additional detection channel for multi-colour imaging.\nHowever, despite the urgent need for far-red FPs, researchers have not yet succeeded in engineering markers that can compete with the performance of GFP. Existing far-red FPs do not go far enough into the infrared to emit a bright enough signal; currently, the most far red-shifted derivatives of the GFP family emit a maximum of 670nm fluorescence and excite at around 610nm. ‘Our erythrocytes contain haemoglobin, which absorbs light below 650nm,’ said Professor Vladislav Verkhusha from the Albert Einstein College of Medicine. ‘To excite and detect fluorescence efficiently in biological tissue we need fluorescence proteins with both excitation and emission spectra above 650nm.’\nSo, although the maximum emission value is 670nm, the excitation is still only 610nm, which isn’t ideal for imaging tissue. ‘They work partially but not perfectly,’ Verkhusha noted. ‘Fluorescence that emits below 650nm will not be visible, because it will be absorbed by haemoglobin in the tissue. There have been many research groups over the last two decades that have tried to improve the excitation and emission in the near-infrared (NIR), but this is the maximum that is achievable now.’\nProfessor Verkhusha and his team at the Albert Einstein College of Medicine have developed a new group of NIR fluorescent proteins based on a different family of proteins, which have excitation spectra up to 700nm and emission up to 720nm.\nDerived from the phytochrome photoreceptor family found in plants, bacteria, and cyanobacteria, these proteins make it possible to image much deeper into mammalian tissue and with a higher signal to autofluorescence background ratio. ‘In our experiments, we can detect NIR fluorescent proteins at a depth of 18mm,’ said Verkhusha. ‘If you compare this depth, the signal to background ratio is 20-fold higher for NIR fluorescent proteins as compared to the most far-red shifted protein from the GFP family. This means a 20-fold better sensitivity, or 20-fold smaller number of cells we can detect.’\nWhereas deep cell imaging of live cells is typically associated with two-photon excitation, the NIR fluorescent proteins can use single-photon excitation techniques because they already absorb in the NIR. Two-photon microscopy is generally chosen for its ability to achieve higher resolutions with less photobleaching than single-photon excitation techniques such as confocal microscopy. Two-photon lasers excite by using near simultaneous absorption of two long wavelength (around 800nm) photons and, because excitation only happens near the focal plane where the laser light is most concentrated, there is little tissue damage to the surrounding areas and a higher signal to background ratio.\nHowever, two-photon microscopy has an imaging depth limit of around several hundred micrometres, according to Verkhusha. So, in order to take advantage of the 18mm depths that these new NIR probes offer, techniques such as structured illumination, single-sheet illumination, adaptive optics microscopy, and photoacoustic imaging can be used. ‘These new imaging techniques will allow users to have high resolution in deep tissue using one-photon NIR excitation. They use lower power than two-photon microscopy, so there is less damage to the tissue. Because of this low level of damage, live tissue imaging is more feasible in one-photon regimes with NIR probes,’ Verkhusha noted.\n‘As a result, I think these imaging techniques will become more popular as biologists adopt these new probes, because two-photon microscopy has existed for about 20 years and, during this time, I have not seen much development,’ Verkhusha continued. ‘These days, wavefront engineering imaging techniques are becoming more and more popular. NIR fluorescent proteins, which we develop, fit well with them.’\nAs well as engineering dyes that are more compatible with live tissue, scientists are improving the methods for imaging live cells without the use of labels.\nWhereas fluorescence microscopy is often the method of choice for observing structures or dynamic processes in biological samples, in some cases, labelling isn’t practical. ‘There are certain situations where you just cannot label – for example, for medical diagnostic applications where the labels could be toxic, or when it is simply too labour-intensive to label and more convenient to image in a label-free fashion,’ explained Dr Chistian Freudiger, vice president of research and development at Invenio Imaging, which develops technology for non-destructive microscopy.\n‘If scientists want to image very small molecules – for example, metabolites such as glucose – the components are a lot smaller than the labels you would need to attach for imaging. If you were to label it, you would really perturb the function of these molecules that you’re trying to study,’ Freudiger said. ‘On occasions where you can’t do it, you need to start looking at label-free methods – the goal is to image in a similar way to fluorescence, but without having to add any dyes or stains.’\nCoherent Raman scattering (CRS) microscopy is a dye-free method that images structures by displaying the characteristic intrinsic vibrational contrast of their molecules. The major benefit of this method is that the sample remains almost unaffected.\nThe technique is based on spontaneous Raman scattering, which has been used in analytical R&D applications for years but typically produces very weak signals, resulting in slow acquisition rates in imaging applications. ‘The big issue with this method is the limited sensitivity – you need to wait a long time before you can get a reliable measurement,’ said Freudiger.\nCRS provides amplification of the weak spontaneous Raman signal to enable high-speed, label-free chemical imaging. ‘With coherent Raman scattering we take the spontaneous signal and we amplify it by many orders of magnitude – i.e. by a factor of 10,000. So, suddenly, we can do this label-free measurement at high enough speeds to use it in microscopy.’\nIn general, coherent Raman scattering refers to two independent, but related, techniques: coherent anti-stokes Raman scattering (CARS) and stimulated Raman scattering (SRS), which both have the speed advantage over spontaneous Raman scattering.\nAs a research assistant and then postdoctoral fellow working with Professor Xiaoling Sunney Xie (developer of CARS) at Harvard University, Freudiger co-invented SRS microscopy with colleagues at the Xie lab. Invenio Imaging was founded in 2012 based on Professor Xie’s research, and over the last two years the company has produced a research-based system that can be operated in a similar way to a confocal or two-photon fluorescence microscope, but obtains an SRS contrast.\nThe mechanism of the contrast, Freudiger explained, is based on the vibrational frequencies of the molecules: ‘If you have two atoms, they are connected with a spring, and they’ll have a resonance frequency determined by how heavy the atoms are and how stiff the spring is in between,’ he said. ‘By looking at where the vibration is coming from, you know what the molecule is.’\nWhat is specific to coherent Raman scattering is that, instead of using a single wavelength laser as with spontaneous Raman scattering, two-wavelength lasers are used. ‘If you fire these two wavelengths into the sample, the intensity that results is the beat frequency – the difference in frequency of the two laser wavelengths,’ explained Freudiger. ‘If you now match this beat frequency to the vibrational frequency then you can “shake” the molecules – so, you very actively drive the vibrations. What you measure in CARS is the emission that then originates from these vibrational frequencies. What one does in SRS is look at the energy transferred to the sample that results from exciting these vibrations.’\nIn an area of crossover between fluorescence and label-free techniques, scientists are working on developing dyes for use with this traditionally label-free approach. Professor Wei Min from Columbia University has invented new types of Raman label, which provide the specificity advantage of labelling, but that are much smaller (a few atoms in size) so eliminate some of the drawbacks of labelling molecules. ‘They are still not as bright as typical fluorophores, but they are less disruptive to the system, because it is just very small molecules that you would add,’ Freudiger remarked. ‘So, there is this overlap region where people do use labels, together with Raman imaging, and the motivation is the same – to perturb the system that they are trying to study the least.’\nMinimising tissue damage\nAlthough label-free imaging leaves the samples largely unaffected, the technique acts more as an alternative for when labelling is not practical, as Freudiger pointed out, rather than as a complete replacement to fluorescence imaging.\nFluorophores are still a vital part of imaging live tissue and, for most fluorescence microscopy techniques, it is almost impossible to eliminate damage to the sample. ‘If you use a lamp, laser or LED there will always be some sample damage – phototoxicity – as well as photobleaching because once fluorophores are hit with light they not only emit fluorescence, but they also lose efficiency to release fluorescence and eventually photobleach,’ said Dr Kavita Aswani, senior applications scientist for life sciences, marketing at light source provider Excelitas. ‘The question is how to minimise photobleaching, because there is no way to truly avoid it.’\nAccording to Aswani, minimising sample damage while imaging live cells ultimately comes down to limiting the sample’s exposure to light, with shutters in the case of lamps, and turning LEDs off when the sample is not being imaged. The use of pulsed lasers or pulsed LEDs may also reduce sample damage, she added. It is thought that this could be due to the ability of the cell to recover from being exposed constantly to light, thereby generating fewer reactive oxygen species. ‘So, you can give the cells time to recover before you blast them again with light, which leads to reduced phototoxicity,’ said Aswani.\nFor advanced microscopy applications, Excelitas has demonstrated that it’s X-Cite XLED1 high-power light source, when operated in live cell mode or pulsed mode, results in lower phototoxicity in live cells when compared to continuous light exposure. In a separate study, the company also found that cell proliferation is higher when a sample is imaged with LED than when imaged with a mercury lamp for the same exposure time, although these have only been initial findings.\nBut although pulsed light is typically associated with less photodamage, the extremely high speeds of multiphoton lasers can also create issues concerning sample damage.\nSince two-photon excitation is a non-linear process, scientists quickly realised that shorter laser pulses at the sample resulted in higher fluorescence signal because of the higher peak power. ‘For this reason, lasers designed for multiphoton microscopy typically have pulse durations between about 50 and 150 femtoseconds,’ said Marco Arrigoni, director of marketing for Coherent’s scientific market segment. ‘However, with some biological specimens, if not properly managed, the shorter pulses also produce the undesirable effect of a higher rate of photobleaching.’\nVery short pulses (i.e. 50-100fs) are more difficult to manage since their larger bandwidth results in a higher material dispersion; by the time the pulses travel through all the microscope optics and reach the sample, their duration may be longer than at the laser output. ‘Because of this, lasers like Coherent’s Chameleon Discovery and Vision incorporate a so-called pre-chirp feature that conditions the laser pulses to have the shortest duration right at the sample plane,’ Arrigoni said, adding that the laser pre-chirp feature can also be used to detune the pulses and make them purposely longer, so that the user can find the optimum pulse duration for different experiments.\nInterestingly, the ideal laser parameters for minimising tissue damage in three-photon imaging, a newer technique that enables greater imaging depths in the brain, are quite different than with two-photon microscopy. Professor Chris Xu and co-workers at Cornell University recently reported that higher energies at lower repetition rates, with correspondingly lower average power, are paramount for minimising thermal sample damage, Arrigoni pointed out. ‘This newer imaging technique is leading to the adoption of lasers, like the Coherent Monaco, which produce a more energetic pulse train at 1MHz repetition rate rather than the 80MHz of more conventional mode-locked lasers,’ commented Arrigoni.\nEarlier this year, UK start-up company IoLight launched a digital microscope powerful enough to observe the structure of plant and animal cells, but that can fit inside a jacket pocket.\nCapable of achieving resolutions of 1µm, it unfolds to record and share 5 megapixel still images and real-time high-definition video at a magnification of x200 on an iPad.\nThere have been digital microscopes available on the market for several years… these use high quality mobile phone lenses and optics to produce a small, low cost microscope that is fine for low magnification applications, such as looking at insects,’ commented IoLight co-founder Andrew Monk. ‘However, these microscopes cannot see smaller subjects, like individual cells, because they are handheld and it is impossible to hold your hand still enough. They can be mounted on a robust stand, but then they are not really portable anymore.’\nTo make the microscope truly portable, IoLight has used these same components, but has added a fixed sample stage, just like a lab microscope would have, which holds the sample securely in front of the head. The optical head folds into the stage so that the package fits into a jacket pocket, and contains the camera and top and bottom illuminators, both of which are adjustable.\nAlthough it’s still early days, the microscope has already been sold into micro-engineering applications such as electronics; microbiology research; universities and science centres, including the Eden Project; animal health; and for home use and education.\n‘IoLight sees its role as developing the portable functionality, giving more people access to better microscopy in more places,’ Monk said. ‘We think that existing microscope manufacturers will continue to make beautifully engineered and expensive microscopes, which will have a place in the lab for the foreseeable future. However, high resolution portable microscopes will add another dimension of flexibility, optimising workflow and image sharing.\n‘There will be applications that go portable very quickly and others that take longer to adapt. We are looking forward to learning what the market wants from a portable microscope.’"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:7233fa42-561b-4f3c-a344-19b37d98ebaf>","<urn:uuid:cbb3f776-7e8c-4fe1-b33a-c53a7f6424c9>"],"error":null}
{"question":"Could you compare the optimal temperature ranges for sprouting seeds versus growing broccoli? I'm interested in understanding the ideal conditions for both cultivation methods.","answer":"For sprouting seeds, the optimal temperature range is 65-80°F (18-27°C). This temperature range ensures good sprouting conditions, though the frequency of rinsing may need to be adjusted based on temperature - more frequent in warmer conditions and less frequent in cooler conditions. For broccoli growth, the optimal temperature range is slightly cooler at 60-70°F (15-21°C). While mature broccoli plants can withstand cold temperatures down to 25°F (-4°C), the crop performs best in cool-season conditions.","context":["The most popular and convenient method for sprouting seeds is in a jar. Almost any seed can be sprouted in a jar, following these basic guidelines.\nINSTRUCTIONS FOR SPROUTING IN A JAR\n1. Choose a jar and lid.\nAny glass jar will do for sprouting, though one with a wide opening is most convenient for rinsing, draining, and removing sprouts. Choose a jar large enough to contain the seeds and sprouts.\nFor smaller seeds, use a quart jar or try this convenient wide-mouth quart sprouting jar with mesh lid.\nFor legumes and grains, the half-gallon sprouting jar with lid makes sprouting large seeds easy.\n2. Rinse Seeds.\nRinse seeds well with cool water (around 70ºF) and drain. Remove any debris, stones, or broken seeds. When sprouting smaller seeds, removing broken seeds is not practical, but do look for any non-seed material and remove at this point, if possible.\n3. Soak Seeds.\nPlace rinsed seeds in a jar and fill about ¾ full with cool water. Cover with a mesh lid or cloth, secured with a rubber band, to allow air flow.\nA general rule is to soak at least 8 hours. Some larger seeds may require a longer soak. Soak until the seeds have doubled in size. Keep in mind that temperature also affects soak time. In warmer temperatures, the soak time is shorter. In cooler temperatures, soak time is longer, and larger seeds like chickpeas or kidney beans may require a 24-hour soak.\n4. Drain Seeds Well.\nIt is important to drain the seeds well, for several hours, while allowing plenty of air circulation. Mesh lids work well for this step, as the jar may be inverted and propped at an angle to drain for long periods.\n5. Rinse, Drain, and Repeat.\nRinse seeds with cool water and repeat draining. Rinse gently to avoid damaging tender new sprouts. Usually 2-3 days of rinsing and draining about 3 times per day is sufficient.\nIn very warm temperatures, rinse more frequently. In cold weather, less frequent rinsing may be fine, but keep in mind that seeds may not sprout as well. A temperature of about 65-80ºF for most seeds is fine.\n6. Final Rinse and Drain\nOnce sprouts are ready to harvest, rinse one final time and remove un-sprouted seeds and seed hulls, if desired. Drain thoroughly one final time before eating or storing sprouts.\nUSING SPROUTED SEEDS\nSprouts are ready to eat at any point after a sprout tail appears. Taste sprouted seeds daily and enjoy once they taste good to you. Many seeds will lose their mild flavor if sprouted too long. In general:\n- Sprout grains just until the sprout tail appears for cooking or dehydrating and grinding to flour\n- Sprout grains in jar just until sprout tail appears, and transfer to soil for growing grass for juicing.\n- Sprout legumes just until the sprout tail appears or before leaves appear.\n- Sprout seeds to desired length, tasting daily.\n- Sprout seeds in jar just until sprout tail appears, and transfer to a tray for growing longer sprouts. Or transfer seeds to a tray with soil for growing microgreens.\nStoring Sprouts and Sprouted Seeds\nSprouts are easy to grow in small batches, staggered, so that there are fresh sprouts to eat daily. However, if storing is necessary, make sure the sprouts have drained completely before storing. Transfer to a glass or plastic container, seal tightly, and store in the refrigerator for a few days.","Broccoli is a cool-season crop. It thrives in temperatures between 60° and 70°F (15-21°C). Mature plants can withstand cold temperatures down to 25°F (-4°).\nBroccoli can be temperamental; if you plant too early plants may produce only small heads—called “buttons.” And if you plant too late—and plants mature in very warm or hot weather—heads may not form at all and plants may simply flower and go to seed.\nTime spring planting so that broccoli will come to harvest before uniformly hot weather arrives. Time late spring or summer planting so that plants mature in cool autumn temperatures.\nBroccoli Sowing and Planting Tips\n- Start broccoli from seed or transplants.\n- Seed is viable for 3 years.\n- For spring crop start seeds indoors 7 to 9 weeks before the average last frost date. For a fall crop, start seed indoors 10 to 12 weeks before the first fall frost.\n- Start seeds in individual pots\n- Sow seed ¼ to ½ (6-8 mm) inch deep in the seed-starting mix.\n- Keep the mix moist but not wet.\n- Seeds should germinate in 5 to 10 days at an optimal temperature of 77°F (25°C) or thereabouts.\n- Transplant seedlings into the garden when they 4 to 6 inches (10-15 cm) tall with 2- to 4-leaves.\n- Grow broccoli in full sun for best yield, but broccoli will tolerate partial shade.\n- Add 3- to 4- inches of compost and well-aged manure into planting bed, before transplanting; broccoli needs friable, moisture-holding soil.\n- Avoid planting where cabbage family crops have grown recently.\n- Space plants 18 to 24 inches (45-60 cm) apart; plants spaced 10 to 12 inches (25-30 cm) apart will yield smaller heads.\n- Space rows 36 inches (.9 m) apart.\n- Protect seedlings from the cold for 2 to 3 weeks after planting covering them with a cloche or plastic tunnel or cold frame.\n- Fertilize with an organic fertilizer such as fish emulsion at half strength.\nInterplanting: Plant with bush beans, beets, carrots, celery, chard, cucumbers, lettuce, and peas. Herbs with a strong fragrance such as dill, sage, rosemary, basil, mint, garlic and thyme are also good companions for broccoli. The strong aroma of these herbs helps to repel pest insects that may attack broccoli.\nContainer Growing: Choose a container with a minimum depth of 20 inches (51 cm).\nBroccoli Planting Calendar\n- 8-6 weeks before the last frost in spring: start seed indoors for transplanting to the garden late.\n- 6-4 weeks before the last frost in spring: direct-sow seed in a plastic tunnel or cold frame.\n- 4-3 weeks before the last frost in spring: direct-sow seed in the garden when the minimum soil temperature is 40°\nFor Fall and Winter Harvest:\n- 17-15 weeks before the first frost in fall: start seed of cold-tolerant varieties indoors for transplanting out at end of summer.\n- 14-12 weeks before the first frost in fall: direct sow seed of cold-tolerant varieties in garden for fall harvest.\n- 12-10 weeks before the first frost in fall: transplant seedlings into the garden.\nMore tips at How to Grow Broccoli.\nBroccoli Recommended Varieties\n- ‘Green Comet’ or ‘Premium Crop’ for spring planting.\n- ‘Gypsy’ is disease resistant and matures early. ‘Arcadia’ is mid- to late-season variety with big heads and cold tolerant.\n- ‘Belstar’ grows in warm winters.\n- ‘Nutribud’ is open-pollinated.\n- ‘Packman’ is an early producer.\n- ‘Small Miracle’ and ‘Munchkin’ are good for containers and small spaces.\n- ‘Waltham 29’ is a favorite for fall harvest.\n- ‘Purple Sprouting’ has small purple heads and comes to harvest in late fall.\nBotanical Name: Brassica oleracea\nBroccoli is a member of the Brassicacea (Cruciferae) or cabbage family."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:775a6ff4-de85-451b-87c5-f618e7c76e5c>","<urn:uuid:bfc61dd7-f4ec-455b-bd8e-33b6d50063b7>"],"error":null}
{"question":"Could you explain the proper technique for initiating a steep turn in an aircraft?","answer":"To properly enter a steep turn, first ensure the aircraft is in straight-and-level flight and check for other aircraft. Then, roll the aircraft gently to the desired bank attitude using coordinated aileron and rudder. When passing through 30 degrees angle of bank, add back pressure and increase power to maintain altitude. Apply appropriate rudder pressure to control any adverse yaw tendency, and use elevator to maintain the correct pitch attitude in relation to the horizon.","context":["Objectives of the lesson\n- What is the steep turn.\n- How to practice steep turn.\n- To avoid another aircraft.\n- To make a canyon turn.\n- To make a steep descend cloud.\n- To develop coordination of all three movements\n- Attitude + Power = Performance\n- What is the rule of thumb for starting your roll out from a turn?\n- As we roll into, or recover from a turn, rudder control is used. What is the reason for this ?\n- You are in a climbing turn to the right, using 30° angle of bank and have been directed to rollout on a heading of 095°. On what heading should you begin to rollout ?\n- What happens to stall speed and load factor as speed increases?\nAngle of bank\n- The greater angle of bank, the greater the amount of lift required to maintain a constant altitude.\n- Increased lift produce increased drag, thus more engine power is required to maintain a constant airspeed.\n- Therefore, the angle of attack that can be sustained in a level turn (disregarding structural limitations) depends on the engine power available.\nForces in turns:\n- When the airplane is in banked attitude, lift acts inward toward the center of the turn, as well as upward.\n- Since the vertical component of lift decreases as the bank angle increases, the angle of attack must be progressively increased to produce sufficient vertical lift to support the airplane’s weight. The fact that the vertical component of lift must be equal to the weight to maintain altitude is an important thing to remember when making constant altitude turns.\n- As the radius of a turn becomes smaller a significant difference develops between the speed of the inside wing, and the outside wing. The wing on the outside of the turn must travel a farther distance in the same amount of time as the inner wing.\n- Thus the outer wing travels faster and creates slightly more lift than the inner wing, and the plane wants to continue rolling into the turn after the controls are neutralized.\n- To correct overbanking, use a small amount of opposite aileron to maintain your desired angle of bank.\nLoad factor in a steep turn\n- On the ground or in straight-and-level non-accelerating cruise flight load factor is one (1G)\n- In a steep turn, load factor is 1G + the amount of centrifugal force acting on the aircraft.\n- In a level turn, with a bank angle greater than 60°, load factor increases dramatically with an increase in bank.2\n- 60° = 2G; 70° = 3G, 80° = 6G\n- To counteract adverse yaw, correct rudder pressure must be applied when initiating a turn.\n- Turns to the right display more adverse yaw than turns to the left because of the natural left turning tendencies our airplane exhibits, the adverse yaw is counteracted a bit more.\nSteep turn entry\n- A steep turn is entered like any other turn, but as the angle of bank is increased beyond the 30 degrees angle you will need extra engine power to maintain altitude.\n- Be sure that the aircraft is in straight-and-level flight.\n- Look around for other aircraft.\n- Roll the aircraft gently to the desired bank attitude with coordinated aileron and rudder.\n- when you pass through 30 degrees Angle of bank add back pressure and increase power to maintain altitude.\n- At the same time, use appropriate rudder pressure to control any tendency for the aircraft to yaw adversely.\n- Use elevator to maintain the aircraft in the correct pitch attitude in relation to the horizon.\n- Maintain look out.\nSteep Turn Recovery\n- Look around.\n- Start to roll the wings level prior to the specified landmark with aileron control, below 30 degrees of bank reduce power to avoid climbing.\n- At the same time, use appropriate rudder pressure to control adverse yaw.\n- Keep wing level.\n- Maintain correct pitch attitude with elevator control.\n- Keep straight.\nRule of Thumb:\n- you start rolling wing level at your half of bank angle.\n- ex: 45 degrees turn, you want to go to 360 degrees heading, you stop your roll at (45:2= 23, 360-23=337) 337 degrees.\n- Look out above, below and on each side to check for aircraft, then:\n- Turn 90 degree to the right/left then come back to your initial heading.\n- Or turn 180 degrees and stay a this heading.\n- WATCH YOU AIRSPEED !!! Stall Speed increases with increased bank angle.\n- Load Factor limitations: check your POH.\nCheck your instruments:\n- Attitude Indicator for bank angle.\n- Vertical Speed Indicator for rate of climb/descent.\n- Airspeed Indicator.\n- Heading Indicator.\nSteep descending turn\n- A steep descending turn can be used to come down through a hole in cloud.\n- Care should be taken in a steep descending turn to maintain safe and constant airspeed and avoid a spiral.\n- be sure to look outside to ensure that the center of the nose does not drop during the turn.\n- What’s the link between angle of bank and lift?\n- Why you need more back pressure as the angle of bank is increased in a turn?\n- Why and when you have to increase power during a steep turn ?\n- What happens to load factor and stall speed as speed increases ?\n- How do we do a look out before we start a steep turn ?"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:77c28058-c031-4ad7-9406-894627706eca>"],"error":null}
{"question":"Which example of prehistoric art is older: the cave paintings at Oxtotitlán in Mexico or the paintings in Chauvet-Pont-d'Arc in France?","answer":"The paintings in Chauvet-Pont-d'Arc in France are significantly older. The non-Olmec rock paintings at Oxtotitlán cave date to the Late Archaic period (around 2000 BC), while the paintings at Chauvet-Pont-d'Arc have been carbon dated to between 30,340 and 32,410 years before 1995, making them approximately 30,000-32,000 years old.","context":["Throughout ancient Mesoamerica, caves were perceived as important features of the sacred landscape (Brady and Prufer 2005). Caves were accompanied by a rich set of images and mythic narratives, detailing acts of creation and the emergence of human beings from the underworld (Heyden 2005). Although the origin of these narratives has often been associated with the cave symbolism present in the Olmec-style art of the Formative period (c. 1500-500 BC) Gulf Coast lowlands (Grove 1973; Scott and Brady 2005), the human use of caves in Mesoamerica extends well into the Archaic period (c. 8,000-2,000 BC) (Smith 2005). Archaic period rock art in Mesoamerica, however, is attested at only a handful of sites: the Cauadzidziqui rock shelter (Guerrero, Mexico), Santa Marta cave (Chiapas, Mexico), Loltun cave (Yucatan, Mexico), the El Gigante rock shelter (Honduras), and the Espirito Santo cave (El Salvador). This identification is based on the presence of hand prints, rudimentary anthropomorphic figures, and the presence of abstract geometric art (Gutiérrez 2008; Gutiérrez and Pye 2008; Haberland 1972; Künne and Strecker 2003; Velázquez Valadez 1980).\nIn this brief report, I present evidence for the existence of cave imagery among some of the non-Olmec, possibly Late Archaic period (c. 2000 BC), rock paintings of Oxtotitlán cave in Guerrero, Mexico (Figure 1). The use of cave symbolism at Oxtotitlán, is comparable to the images of caves found on art works from later periods of Mesoamerican history, suggesting that these rock paintings may be one of the earliest portrayals of this common trope in Mesoamerican art.\nArchaic Period Rock Art and the non-Olmec Rock Paintings of Oxtotitlán Cave\nAs noted previously, there have been relatively few examples of Mesoamerican rock art attributable to the Archaic period (Gutiérrez 2008; Künne and Strecker 2003). Most archaeological work has been concerned with the content and technique of Archaic rock paintings due to the lack of direct chronological measures, and the ambiguity of archaeological associations to cultural materials with established chronologies (Coladán 1995). In eastern Guerrero, however, the situation has been somewhat ameliorated by the recognition of an Olmec-style painted mural superimposed on top of much simpler monochromatic rock paintings at the Cauadzidziqui rock shelter, near the Oaxaca-Guerrero border (Gutiérrez 2007). Since the Olmec-style rock paintings of eastern Guerrero have been dated to the Middle Formative period (900-500 BC), based on iconographic comparisons with the sculptures of La Venta, Tabasco (Grove 1970a, 1970b), it has been convincingly argued that the abstract geometric paintings that were superimposed by the Olmec-style paintings probably date to the Late Archaic period (c. 2000 BC) (Gutiérrez and Pye 2008). Similar monochromatic paintings occur at both Oxtotitlán cave and Juxtlahuaca cave in central Guerrero (Gutiérrez 2008, 80), suggesting that they can be stylistically associated with the Late Archaic rock art of Cauadzidziqui.\nAlthough it is best known for its array of Middle Formative period Olmec-style black paintings and polychromatic murals (Grove 1970a, 1970b; Lambert 2012), Oxtotitlán also boasts a number of red rock paintings in its south grotto that are not as easily attributed to the Formative period. These figures have typically been divided into three panels, known as the Area A, B, and C paintings respectively (Grove 1970a, 1970b). The Area A rock paintings are composed of a number of geometric elements including curvilinear lines, triangles, cruciform motifs, and concentric circles (Figure 2). While it is likely that the majority of these simple red figures date to the Late Archaic period, as do their counterparts at Cauadzidziqui, some of the compositions in this panel, such as Painting A-3, contain elements – e.g. goggle-shaped eyes and protruding fangs – reminiscent of Classic and Post-classic period depictions of rain gods (Grove 1970a, 77, 1970b, 26). Only one of these red cave paintings, Painting A-1, appears to date to the Middle Formative period, and may have served as a tepetl place-sign (Lambert 2013).\nLocated to the right of the Area A rock paintings, the Area B rock paintings appear to consist of a series of zigzag lines, triangles, arrows and other linear elements (Grove 1970a, 75-77, Fig.24) (Figure 3). Very little attention has been paid to these red geometric figures. One exception is the naturalistic portrayal of a deer identified as Painting B-2. The deer in this rock painting is rendered in a leaping stance and is accompanied by a series of red lines forming a box around the head of the deer. To the left of the deer, there appears to be a very weathered human figure. Grove (1970b) claims this scene might have served as the basis for rituals associated with hunting magic.\nSituated to the right of the Area B panel, the Area C rock paintings are found primarily in the crevices near the ceiling of the cave, towards the centre of the south grotto (Grove 1970a, 76-77, Fig.25). This cluster of rock paintings consists of simple geometric designs, such as curvilinear elements, comb-like motifs, and a schematic, possibly avian, figure formed by several triangles (Figure 4).\nThe Cave Imagery in the Area B Rock Paintings of Oxtotitlán\nDespite their apparent randomness, a careful examination of the geometric and zoomorphic designs that comprise the Area B rock paintings reveals that this group of images forms a cohesive picture. Using cave symbolism in later Mesoamerican art works as points of comparison, I suggest that the Area B rock paintings of Oxtotitlán portray the cave as a place of emergence and a source of fertility.\nIn terms of their overall appearance, the Area B rock paintings seem to be organised along two bands of triangular designs (Figure 5). The top band of triangles appear to delimit the relatively flat top of the mountain on which Oxtotitlán is located; while the other band of triangular motifs form a baseline, possibly portraying the cliff face of the cave. Similar bands are found on thrones in Olmec-style art, such as Altar 4 from La Venta, Tabasco, and are used to represent the surface of the earth in relation to cave-like openings in the sculptures (Grove 1973, 131) (Figure 6a). Highly stylized versions of such bands are also observable in the quadripartite depictions of the underworld as a cave in the low-relief carvings of Chalcatzingo. (Figures 6b-c).\nA small semi-circular opening indicating the cave itself, is represented on top of the baseline formed by the lower band of triangular motifs. The negative space representing the opening is bordered by diamond-shaped designs, and features the outline of an anthropomorphic figure in the centre of the space. This manner of representing caves is quite common in ancient Mesoamerican art, and is seen in the quadripartite imagery of Chalcatzingo Monument 9 (Figure 6c). The diamond-shaped designs may also be precursors to portrayals of the earth as a turtle-like zoomorph in Maya art (Stone 1995, 24-27). Among some of the more well-known examples of this trope are the Late Formative monuments designated as Tak’alik Ab’aj Altar 48 (Figure 7a) and Izapa Stela 8 (Figure 7b), as well as Late Classic codex-style polychrome vessels depicting the resurrection of the maize god from a turtle carapace (Quenon and Le Fort 1997, Figs. 12, 27, 28, and 30) (e.g. Figure 7c). Above this putative cave opening, there are a series of diagonal meandering lines and a large conglomeration of red paint. These may represent some of the geological features found near the cave, such as the exposed travertine cliff-face above the cave opening (see Figure 1). Underneath the baseline of triangles, the “slopes” of the mountain leading up to the cave are likewise portrayed in the form of zig-zags and meandering lines. At the bottom of the rock painting, two animal figures are recognizable on these “slopes”, and one appears to have antlers or horns. While more commonly addressed through depictions of foliage in later Mesoamerican art (see Figures 6 and 7), it is possible that the representation of caves as sources of water and food was achieved through the portrayal of fauna during the Late Archaic period at Oxtotitlán.\nConclusions: Oxtotitlán and Cave Imagery in Mesoamerica\nThis paper has argued that the non-Olmec geometric designs found among the Area B rock paintings of the South Grotto of Oxtotitlán represent a Late Archaic period portrayal of a cave. If this interpretation of the imagery in these rock paintings is correct, then the non-Olmec rock art at Oxtotitlán may represent one of the earliest depictions of a cave in Mesoamerican art, and could provide scholars with a better understanding of one of the most potent motifs in Mesoamerican mythology. Previous research on the Mesoamerican cave trope has demonstrated that these geological features were associated with a number of closely related cosmological relationships linking agricultural production, rainfall, and ancestor veneration with important mythological events (e.g. the earth’s creation, the origin of humanity, the residence of the gods, and the origin of the sun and moon) (Heyden 2005). Over time, the meanings linked to Mesoamerican cave imagery were expanded to include references to ancestral rulers and important lineage members, and caves became important places of worship and pilgrimage (Brady and Prufer 2005). This study of the non-Olmec rock paintings from Area B at Oxtotitlán, however, indicates that the portrayal of caves as places of emergence and as sources of food and water may be some of their earliest symbolic associations, and may form the cosmological foundations of later Mesoamerican views of caves.\n- Brady, J.E., and Prufer, K.M. (2005). ‘Introduction: A History of Mesoamerican Cave Interpretation’ in Brady, J.E., and Prufer, K.M. (eds.) In the Maw of the Earth Monster: Mesoamerican Ritual Cave Use. Austin: University of Texas Press, pp. 1 -18.\n- Coladán, E. (1995). La gruta del Espíritu Santo (El Salvador). Tendencias. 3 (45), 40-42.\n- Grove, D.C. (1970a). Los Murales de la Cueva de Oxtotitlán, Acatlán, Guerrero. Informe sobre las investigaciones arqueológicas en Chilapa, Guerrero, noviembre de 1968. Serie Investigaciones, * * * Núm. 23. Mexico: Instituto Nacional de Antropologia e Historia.\n- Grove, D.C. (1970b). The Olmec Paintings of Oxtotitlán Cave, Guerrero, Mexico. Studies in Pre-Columbian Art and Archaeology, No. 6. Washington D.C.: Dumbarton Oaks/Trustees for Harvard University.\n- Grove, D.C. (1973). Olmec Altars and Myths. Archaeology. 26 (3), 94-100.\n- Grove, D.C., and Angulo, J. (1987). ‘Catalog and Description of Chalcatzingo’s Monuments’. In Grove, D.C. (ed.) Ancient Chalcatzingo. Austin: University of Texas Press, pp. 114-131.\n- Gutiérrez, G. (2007). Catálogo de Sitios Arqueológicos de las Regiones Mixteca-Tlapaneca-Nahua y Costa Chica de Guerrero. Mexico: CIESAS.\n- Gutiérrez, G. (2008). ‘Four Thousand Years of Graphic Communication in the Mixteca-Tlapaneca-Nahua Region’. In Jansen, M., and van Broekhoven, L.N.K. (eds.). Mixtec Writing and Society. Amsterdam: KNAW Press, pp. 67-103.\n- Gutiérrez, G., and Pye, M.E. (2008). El graffiti estilo olmeca del abrigo rocoso de Cauadzidziqui, Ocoapa, Guerrero. Oxtotitlán 3, 20-26.\n- Haberland, W. (1972). The Cave of the Holy Ghost. Archaeology 25 (4), 286-291.\n- Heyden, D. (1975). The Cave under the Pyramid of the Sun at Teotihuacan. American Antiquity. 40 (2), 131-147.\n- Heyden, D. (2005). ‘Rites of Passage and Other Ceremonies in Caves’. In Brady, J.E., and Prufer, K.M. (eds.) In the Maw of the Earth Monster: Mesoamerican Ritual Cave Use. Austin: University of Texas Press, pp. 21-34.\n- Lambert, A. (2012). Three New Rock Paintings from Oxtotitlán Cave, Guerrero. Mexicon 34, 20-23.\n- Lambert, A. (2013). A Possible Place-Sign (Toponym) from Oxtotitlán Cave, Guerrero, Mexico. The Post Hole, 27, 17-28.|\n- Norman, V.G. (1973). Izapa Sculpture, Part 1: Album. Papers of the New World Archaeological Foundation, No. 30. Provo, Utah: New World Archaeological Foundation, Brigham Young University.\n- Quenon, M. and Le Fort, G. (1997). ‘Rebirth and Resurrection in Maize God Iconography’. In Kerr, N. and Kerr, J. (eds.). The Maya Vase Book: A Corpus of Rollout Photographs of Maya Vases by Justin Kerr, Volume 5. New York: Kerr Associates, pp. 884-902.\n- Schieber de Lavarreda, C. and Orrego Corzo, M. (2009). ‘El descubrimiento del Altar 48 de Tak´alik´ Ab´aj’. In Laporte, J.P., Arroyo B. and Mejía, H. (eds.). XXII Simposio de Investigaciones Arqueológicas en Guatemala, 2008. Guatemala: Museo Nacional de Arqueología y Etnología, pp. 456-470.\n- Scott, A.M. and Brady, J.E. (2005). ‘Formative Cave Utilization: An Examination of Mesoamerican Ritual Foundations’. In Prowis, T.G. (ed.) New Perspectives on Formative Mesoamerican Cultures. British Archaeological Reports, International Series, No. 1377. Oxford: Archaeopress, pp. 147-158.\n- Smith, B.D. (2005). Reassessing Coxcatlan Cave and the early history of domesticated plants in Mesoamerica. Proceedings of the National Academy of Sciences. 102 (27), 9438-9445.\n- Stone, A.J. (1995). Images from the Underworld: Naj Tunich and the Tradition of Maya Cave Painting. Austin: University of Texas Press.\n- Stone, A.J. and Künne, M. (2003). ‘Rock Art of Central America and Maya Mexico’. In Bahn, P.G. and Fossati, A. (eds.). Rock Art Studies: News of the World 2. Oxford: Oxbow Books, pp. 196-213.\n- Velázquez Valadez, R. (1980). Recent Discoveries in the Cave of Loltun, Yucatán, Mexico. Mexicon, 2, 53-55.","The oldest art: ornamentation\nHumans (Homo sapiens) make art. We do this for many reasons and with whatever technologies are available to us. Recent research suggests that Neanderthals also made art.\nExtremely old, non-representational ornamentation has been found across Africa. The oldest firmly-dated example is a collection of 82,000 year old Nassarius snail shells found in Morocco that are pierced and covered with red ochre. Wear patterns suggest that they may have been strung beads. Nassarius shell beads found in Israel may be more than 100,000 years old and in the Blombos cave in South Africa, pierced shells and small pieces of ochre (red Hematite) etched with simple geometric patterns have been found in a 75,000-year-old layer of sediment.\nThe oldest representational art\nSome of the oldest known representational imagery comes from the Aurignacian culture of the Upper Paleolithic period (Paleolithic means old stone age). Archaeological discoveries across a broad swath of Europe (especially Southern France, Northern Spain, and Swabia, in Germany) include over two hundred caves with spectacular Aurignacian paintings, drawings, and sculpture that are among the earliest undisputed examples of representational image-making. Among the oldest of these is a 2.4-inch tall female figure carved out of mammoth ivory that was found in six fragments in the Hohle Fels cave near Schelklingen in southern Germany. It dates to 35,000 B.C.E.\nThe caves at Chauvet-Pont-d’Arc, Lascaux, Pech Merle, and Altamira contain the best known examples of pre-historic painting and drawing. Here are remarkably evocative renderings of animals and some humans that employ a complex mix of naturalism and abstraction. Archaeologists that study Paleolithic era humans, believe that the paintings discovered in 1994, in the cave at Chauvet-Pont-d’Arc in the Ardéche valley in France, are more than 30,000 years old. The images found at Lascaux and Altamira are more recent, dating to approximately 15,000 B.C.E. The paintings at Pech Merle date to both 25,000 and 15,000 B.C.E. The world’s oldest known cave painting was found in Sulawesi, Indonesia in 2017 and was made at least 45,500 years ago.\nWhat can we really know about the creators of these paintings and what the images originally meant? These are questions that are difficult enough when we study art made only 500 years ago. It is much more perilous to assert meaning for the art of people who shared our anatomy but had not yet developed the cultures or linguistic structures that shaped who we have become. Do the tools of art history even apply? Here is evidence of a visual language that collapses the more than 1,000 generations that separate us, but we must be cautious. This is especially so if we want to understand the people that made this art as a way to understand ourselves. The desire to speculate based on what we see and the physical evidence of the caves is wildly seductive.\nThe cave at Chauvet-Pont-d’Arc is over 1,000 feet in length with two large chambers. Carbon samples date the charcoal used to depict the two head-to-head Rhinoceroses (see the image above, bottom right) to between 30,340 and 32,410 years before 1995 when the samples were taken. The cave’s drawings depict other large animals including horses, mammoths, musk ox, ibex, reindeer, aurochs, megaceros deer, panther, and owl (scholars note that these animals were not then a normal part of people’s diet). Photographs show that the drawing at the top of this essay is very carefully rendered but may be misleading. We see a group of horses, rhinos, and bison and we see them as a group, overlapping and skewed in scale. But the photograph distorts the way these animal figures would have been originally seen. The bright electric lights used by the photographer create a broad flat scope of vision; how different to see each animal emerge from the dark under the flickering light cast by a flame.\nA word of caution\nIn a 2009 presentation at University of California San Diego, Dr. Randell White, Professor of Anthropology at New York University, suggested that the overlapping horses pictured above might represent the same horse over time, running, eating, sleeping, etc. Perhaps these are far more sophisticated representations than we have imagined. There is another drawing at Chauvet-Pont-d’Arc that cautions us against ready assumptions. It has been interpreted as depicting the thighs and genitals of a woman but there is also a drawing of a bison and a lion, and the images are nearly intertwined. In addition to the drawings, the cave is littered with the skulls and bones of cave bear and the track of a wolf. There is also a footprint thought to have been made by an eight-year-old boy."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:628ef390-b488-4365-ab56-f5dfef7d7809>","<urn:uuid:f2ea795e-b75d-450f-b30f-df6484d0216d>"],"error":null}
{"question":"How do stone grinding mills maintain food quality during processing, and what are the critical risk assessment steps for industrial grinding operations?","answer":"Stone grinding mills maintain food quality through several features: they use natural sandstone containing beneficial mineral elements, employ low-speed rotation to ensure low-temperature grinding conditions, and have a sealed wooden lid to keep everything clean between uses. The optimal adaptation of grinder diameter and speed, controlled by a three-phase motor, ensures perfect grinding while preserving food quality. Regarding risk assessment, critical steps include conducting a Job Hazard Analysis (JHA) to identify potential hazards before they occur, reviewing accident history, conducting preliminary job reviews, and listing and ranking hazardous jobs. The assessment should evaluate what can go wrong, potential consequences, contributing factors, and likelihood of hazard occurrence. This systematic approach helps establish proper work procedures and prevent workplace accidents.","context":["Stone Grinding Mills For Grain And Pulses Wheat Corn Etc\nstone flour grinding mills for grain and pulses for the production of high quality flours 0541 infopaglierani.com englishthis ingenious solution lets you grind different types of grain in the same mill while keeping food types completely separate. quiet, clean & easy. As with all komo grinders, cleanup of the classic is minimal and easy, and full access to the milling stones takes just seconds, without tools. sealed wooden lid keeps everything clean between uses.its stone grinding teeth are meticulous, clear and sharp, with longer service life and higher bearing capacity. It is faster, better in grinding raw materials. application of tahini stone grinder machine the tahini stone mill can process soybeans, rice, wheat, sesame paste, peanut butter and other grains, as well as various seasonings. the the engsko vertical stones size 400 and 500 mm diameter are available as special coffee stones for grinding of extra fine coffee. open leaflet. after many hours of production with your engsko AS stonemill, the millstones will display some degree of wear. this will typically be after more than 550 ton of flour has been produced on the mill.\nGrain Mill Flour Mill Grinder Stone Burr Impact\nquality grain mill transforms whole grains into flour, meal or a cereal-grind texture. whether you want a flour mill for common wheat, einkorn, or corn, or a flaker for oatmeal, at pleasant hill grain we offer the worlds best. our mills can grind almost anything, and are available in may 21, 2021 burr mills: they are the most common and consist of two grinding plates, fixed and rotating. burr mills can be stone burrs that crush the grain or the steel burrs that break the grain. impact mills: they consist of two different stainless-steel heads where the grain is dropped into the mill, which crushes the substance into a fine powder.new american stone mills is a collaborative stone mill building project between andrew heyn of elmore mountain bread and fulton forde of boulted bread.sep 22, 2018 surface grinding in a mill with a harbor freight grinder around $999 why risk a good mill. now if you are talking a $399 mini mill drill, that would be different. took passes to get rid of about thou of bannana in a rc part. was using a git aluminum oxide stone\nGrain Mill Australia Buy Home Flour Mills Amp Grain Grinders\nstone grinding mill is capable of milling wheat, rye, oats, spelt, barley, corn millet, durum wheat, round grain rice, long grain rice, buckwheat, chickpeas, linseed, quinoa, amaranth and dried peas. your mill grinder can process grinding mill stone, US pair, power grinder, rajasthan, india, year.source from sharad enterprises on alibaba.com.stirred mills for wet grinding xinhai outotec hand operated corn grain mill grinder useful kitchen tool with big hopper adjustable for corn, coffee. food, wheat, oats, nut, herbs, spices, seeds genergy saving stone grinding mill. e-mail email protected call Us 0086 57383. address. no. 188, KZ street, fushan high-tech industrial stone mill grinder manufacturers, factory, suppliers from china, We never stop improving our technique and quality to keep up with the development trend of this industry and meet your satisfaction well. If you are interested in our products, please contact us freely.\nStone Grinding Mill Gypsum Grinding Mill Calcium\nshanghai clirik is the most prefesional stone grinding mill maunfacture&supplier in china,the main products include stone grinding mill,gypsum grinding mill,calcium carbonate grinding mill,limestone grinding mill,dolomite grinding mill and so on.feb 25, 2021 impact mills tend to be cheaper than burr grinding mills. for the latest price on a good impact mill on amazon, click here. but an even better choice would be to buy an attachment wheat grinder rather than a stand alone impact mill.electric grinder mill grain corn wheat feedflour wet&dry cereal machine. $199.90. free shipping. or best offer. retsel romper stone flour cereal mill grinder hopper. wheat grain vintage. $199.99. $20.00 shipping.the stone mill is finely carved from natural from natural sandstone, which contains a variety of mineral elements that are beneficial to the human body. stone milling flour is truly original ecological health, simulating the traditional grinding method, low speed rotation, to ensure low temperature during the process of grinding condition.\nStone Flour Grinding Mill For Wheat Corn Grain Pulses\nhealthy grinding. the heart of the stone mill is the millstone. the size of the millstone is not decisive for the fineness of the flour. On the contrary, the optimal adaptation of the grinder diameter and the speed, is of great importance, controlled by a three-phase motor. the combination of the rotation speed with the distance between the stones ensures a perfect grinding at a low temperature.this item: schnitzer 1112 manual stone grinding mill grain & seed $134.95. only left in stock order soon. ships from and sold by healthnut alternatives.. great river organic milling, whole grain, hard red spring wheat, organic, 25-pounds $38.21 In stock.1,748 mill stone grinder products are offered for sale by suppliers on alibaba.com, of which mine mill accounts for 23%, flour mill accounts for 10%, and coffee grinders accounts for 1%. wide variety of mill stone grinder options are available to you, there are 958 suppliers who sells mill stone grinder on alibaba.com, mainly located in asia.shanghai clirik machinery Co ltd, located in pudong new area of shanghai, china, is a large professional manufacturer with import & export rights specializing in research, manufacture and sales of crushing machinery, mining equipment, and grinding machines, such as micro powder grinding equipment, ultrafine grinding equipment, stone grinding equipment, mineral grinding machine,\n204 Ancient Stone Hand Mill Grain Photos Free Amp Royalty\nrotary discoid mill stone for hand-grinding a grain into flour. medieval hand-driven millstone grinding wheat. the. ancient quern stone hand mill with grain close up of hand grinding stone or hand grinder or old motor or pestle or grain mills on rough surface still used in shanghai clirik is the largest stone mills manunfacturers of china,the stone mills products included stone grinding machine,stone milling machine,stone processing machine,stone pulverizer and so on.please contact with us and get detail infomation.every stone burr mill we offer has the widest possible texture range; they can produce ultra fine or very fine flour, coarser flour, meal texture, cereal grind, and even cracked grain. the stone burrs in most modern small mills have a synthetic engineered composition for precision, uniformity, efficient grinding, and long burr life.jan 02, 2020 the two primary mechanisms available for the home market are burr mills and impact grinders. burr mills. the oldest grinding models, these are the most common. burrs consist of two grinding plates, either stone or steel.\nNews Stone Mill Stone Grinding Machine Stone Grinder Stone\nthe limestone grinding process includes four parts: feeding, crushing, grinding, and grading. clirik supply high quality limestone grinding mill, contact us to get price:195.the stone grinder mill has the advantages of reasonable structure, beautiful appearance, fine grind, smooth grinding, pure ecology and no pollution. the electric stone grinding mill adopts the axis drive technology to drive the grinding disc, the grinding tooth interaction of the upper and lower grinding discs, the low speed and uniform china stone grinding mill manufacturers select 2021 high quality stone grinding mill products in best price from certified chinese grinding equipment, oil mill suppliers, wholesalers and factory on made-in-china.comgrinder stone machine stone ball mill best factory price fine powder grinder quartz stone grinding machine small ball mill for sale $9,500.00-$10,800.00 set set\nPowder Grinding Mill Grinding Machine Grinding Plant\nIf you want to buy grinder mill equipment, you can contact us! We also provide the whole equipment of powder grinding mill production line. contact us via email:may 08, 2011 raymond mill, mill, grinder, mill machinery, grinding equipment, mining machinery, mill grinding, milling equipment, roller mill, pulverizer company introduction established in 1984, henan wanlong machinery manufacturing Co ltd. is one of the largest exporters of raymond mills in china, integrating research, development, production and sale.","Presentation on theme: \"What is a JHA and How Do I Use It? Presented by Bill Jividan, CSP.\"— Presentation transcript:\nWhat is a JHA and How Do I Use It? Presented by Bill Jividan, CSP\nPurpose To inform safety proponents about a very useful tool that can be used to indentify hazards and to have a plan on how to control or eliminate hazards.\nWhat is a hazard? A hazard is the potential for harm. In practical terms, a hazard often is associated with a condition or activity that, if left uncontrolled, can result in an injury or illness.\nJHA Definition OSHA defines a Job Hazard Analysis as: a technique that focuses on job tasks as a way to identify hazards before they occur. It focuses on the relationship between the worker, the task, the tools, and the work environment. A JHA is on component of the larger commitment of a safety and health management system.\nWhats the difference between JHA and JSAs? A Job Hazard Analysis should be the preliminary step to evaluating hazards associated with any job category or function. The JHA assigns risk while the JSA identifies specific hazards and provides tools to remediate the hazards.\nContinued Performing a JHA prior to a JSA is critical because it allows a company to prioritize the implementation of its workplace safety efforts.\nWhy is a JHA important? One of the best ways to determine and establish proper work procedures is to conduct a JHA. A JHA is one component of the larger commitment of a safety and health management system\nWhat value does a JHA have? JHAs help identify, eliminate and prevent hazards in the workplace. This will likely result in fewer worker injuries and illnesses, safer, more effective work methods and reduced workers compensation costs and increased worker productivity.\nWhat jobs do I use JHA on? Jobs with the highest injury or illness rates. Jobs with the potential to cause severe or disabling injuries or illness, even if there is no history of previous accidents. Jobs in which one simple human error could lead to a severe accident or injury. Jobs that are new to your operation or have undergone changes in processes and procedures. Jobs complex enough to require written instructions.\nOK, Where do I begin? Involve your employees Review your accident history Conduct a preliminary job review List, rank, and set priorities for hazardous jobs. Outline the steps or tasks.\nHow do I identify workplace hazards? What can go wrong? What are the consequences? How could it happen? What are other contributing factors? How likely is it that the hazard will occur?\nGrinding Iron Castings: Job Steps Step 1. Reach into metal box to right of machine, grasp casting, and carry to wheel. Step 2. Push casting against wheel to grind off burr. Step 3. Place finished casting in box to left of machine.\nExample Job Hazard Analysis Form Job Location: Metal ShopAnalyst: Joe Safety Date: Task Description: Worker reaches into metal box to the right of the machine, grasps a 15 pound casting and carries it to grinding wheel. Worker grinds 20 to 30 castings per hour. Hazard Description: Picking up a casting, the employee could drop it onto his foot. The casting's weight and height could seriously injure the worker's foot or toes. Hazard Controls: 1. Remove castings from the box and place them on a table next to the grinder. 2. Wear steel-toe shoes with arch protection. 3. Change protective gloves that allow a better grip. 4. Use a device to pick up castings.\nJob Location: Metal Shop Analyst: Joe Safety Date: Task Description: Worker reaches into metal box to the right of the machine, grasps a 15 pound casting and carries it to grinding wheel. Worker grinds 20 to 30 castings per hour. Hazard Description: Castings have sharp burrs and edges that can cause severe lacerations. Hazard Controls: 1. Use a device such as a clamp to pick up castings. 2. Wear cut-resistant gloves that allow a good grip and fit tightly to minimize the chance that they will get caught in grinding wheel.\nJob Location: Metal ShopAnalyst: Joe SafetyDate: Task Description: Worker reaches into metal box to the right of the machine, grasps a 15 pound casting and carries it to grinding wheel. Worker grinds 20 to 30 castings per hour. Hazard Description: Reaching, twisting, and lifting 15 pound castings from the floor could result in a muscle strain to the lower back. Hazard Controls: 1. Move castings from the ground and place them closer to the work zone to minimize lifting. Ideally, place them at waist height or on an adjustable platform or pallet. 2. Train workers not to twist while lifting and reconfigure work stations to minimize twisting during lifts. Repeat similar forms for each job step.\nSample Job hazard Analysis Form Job Title:Job Location:Analyst:Date: Task #Task Description: Hazard Type:Hazard Description: Consequence:Hazard Controls: Rational or Comment:\nQuestions? Presented by Bill Jividan CSP firstname.lastname@example.org"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:2e85ebd2-cc26-40a5-a1a3-3b882a7ad597>","<urn:uuid:33477bac-b10f-4f57-996a-31137b43edec>"],"error":null}
{"question":"Hey what's better for showing compliance - ISO 14001 or OHSAS 18001? Need to know main benefits","answer":"Both certifications demonstrate different types of compliance. ISO 14001:2015 helps organizations demonstrate compliance with environmental regulatory requirements and shows commitment to environmental protection. It helps achieve financial and operational benefits through environmentally sound practices. OHSAS 18001 demonstrates compliance with legal health and safety requirements, shows commitment to employee protection, and helps reduce insurance premiums and workers' compensation costs. The choice depends on whether environmental or occupational safety compliance is the priority.","context":["ISO 14001:2015 Environmental Management System Certification\nThe current version of ISO 14001 was reviewed and published in 2015. Currently, more than 420,000 organizations around the world are ISO 14001-certified. This number is growing rapidly.\nISO 14001 is an international standard offered by the International Organisation for Standards (ISO). Through the ISO 14001 management system, companies can monitor the impact their products and services have on the environment.\nIt’s primarily for organizations that use natural resources. As a result of their processes that convert natural resources into useful products, the organizations tend to release a lot of wastes that negatively affect the environment. These negative effects need to be recognized and reduced, throughout their lifecycle. Recently, ISO 14001 was updated in 2015, which is why the latest certification in the ISO 14001 family that is available is called ISO 14001:2015.\nISO 14001:2015 - An Introduction\nISO 14001:2015 defines the conditions imposed by a standard Environmental Management System. It includes the guidelines for a company looking to enhance their environmental performance and sustainability policies. Its use is directed towards associations who are looking to manage their liabilities with a planned approach towards sustainability. ISO offers a 35-page implementation guide, curated and overseen by Technical Committee ISO/TC 207/SC 1.\nApplicability of ISO 14001:2015\nAccording to ISO, the Environmental Management System Certification can be applied to any organization. This helps organizations of different sizes, belonging to different industries, get the same advantages of ISO 14001:2015’s application. ISO 14001:2015 eliminates the ‘one size fits all’ approach.\nOne must remember that ISO 14001:2015 is not a scale with which environmental management parameters must be matched to. It’s more like an internationally-authorized guidebook that states how certain operations must be conducted with respect to environmental conservation. The basic fundamentals of ISO 14001:2015 are based on the Plan-Do-Check-Act (PDCA) iterative management method.\nObjectives of ISO 14001:2015\nThe objective of ISO 14001:2015 is to deliver a framework for the applying organization aimed towards the protection of the environment. It consists of policies leveled with socio-economic needs that help create a response plan for dynamic environmental conditions. The certification outlines specific requirements for sustainable development, which include:\n- Mitigation of negative effects caused by an organization on the environment, protecting the environment.\n- Mitigation of possible adverse impacts of the environment on the organization.\n- Enhancing immediate environmental performance.\n- Helping the organization fulfil compliance obligations\n- Demonstration of compliance with the changing regulatory requirements of the certification.\n- Achieving strategic business goals by embedding environmental issues into business management\n- Setting up guidelines for a product’s life cycle, including design, production, curation, distribution, and disposal. This ensures environmental effects are not shifted elsewhere within the product life cycle, unintentionally.\n- Strengthening market position of an organization while achieving operational and financial profits from the implementation of environmentally sound alternatives.\n- Boosting leadership involvement and employee engagement\n- Improvement of confidence in the company and company reputation\n- Clear communication of environmental information to relevant and interested entities.\nAdvantages of ISO 14001:2015 Environmental Management System\nThe advantages an organization taking up ISO 14001:2015 Environmental Management System certification may benefit from are:\n- Boost in customer confidence, recognition for the community, employees, and environmental authorities\n- Improvement of company perception through an internationally-recognized certificate\n- Advantage over competitors, both in business and sustainability\n- Reduced risks of environmental accidents drive down costs of insurance\n- Prevent incidents that may lead to fines and sanctions, catapulted by the lack of environmental protection measures\n- Prevent possible incidents that may lead to sanctions /fines due to lack of environmental protection policies\n- Better alignment to market requirements through sustainable approaches\nSustainable Development Goals\nThrough Intercert’s enriched ISO certifications, organizations will be able to contribute to Sustainable Development Goals (SDG) that the United Nations has prescribed in their ambitious 15-year plan that address crucial issues ailing the world. ISO 14001:2015\nEnvironmental management systems contribute to the following SDG codes:\n- 1: No Poverty\n- 2: Zero Hunger\n- 3: Good Health and Well-being\n- 4: Quality Education\n- 5: Gender Equality\n- 6: Clean Water and Sanitation\n- 7: Affordable and Clean Energy\n- 8: Decent Work and Economic Growth\n- 9: Industry, Innovation, and Infrastructure\n- 12: Responsible Consumption and Production\n- 13: Climate Action\n- 14: Life Below Water\n- 15: Life on Land\nWhy Intercert for ISO 14001:2015 Environmental Management System\nIntertcert serves transparent and impartial services so that your organization realizes every detail advised by ISO 14001:2015 accurately. Our certifications are highly sought-after due to our competitive and cost-effective services. With an experience of over 13 years, we’ve mastered the art of delivering excellence in the form of training and international certifications. We are an accredited management system body with certifications from IAF, IAAC, APAC, and Standard Council of Canada (SCC).","Managing health and safety (OH&S) issues in the workplace represents an enormous challenge due to varying human nature, skills set, process complexity & local culture and have implications for everyone at the workplace. Effectively managing these issues means taking account not only of legal requirements, but also the well-being of your personnel in the organization.\nPurpose of OHSAS 18001\nManagement of health & safety issues for an organization considering all interested parties concern is the main challenge of the business while working with significant hazardous process & risk. Achieving OHS performance with improved well being is the need to assure the regulatory bodies, customers and other stack holders due to high premium cost for any incident.\nCertification to OHSAS 18001 show the commitment to the health and safety of employees, demonstrates your ability to manage risk & hazards associated with the activities and provide assurance to all concerned including customers and management that legal compliance is effectively managed.\nImplementation of OHSAS 18001 policies gives systematic approach to minimizing health and safety risks and provide a framework for an organization to manage its legal compliance and improve occupational health and safety performance, including risk and opportunity identification, analysis, target setting, and measurement.\nOrganizations are improving the health & safety status by implementing the universally valid international standard along with best practices beside their own country specific health & safety legislations. OHSAS 18001 is basic and globally recognized standard for occupational health and safety management systems and is applicable to any organization in any business sector.\nBenefits of OHSAS 18001\nImplementing an effective occupational health and safety management system reduces the risk of harm to your employees and other personnel and reduces overall liability. Effective Management of Health and Safety risks will help:\n- Demonstrate your commitment to the protection of employee, property and plant.\n- Minimize the number of accidents and production time loss due to better control over hazards at the workplace\n- Focus on employee safety results in a satisfied, motivated and highly productive work team.\n- Increase control and reduction of hazards through the setting of objectives, targets and evolved responsibility.\n- Maximize the well-being and productivity of all people working for the organization.\n- Encourage better relationships with contractors and more effective contracted activities.\n- Reduction in insurance premiums & workers compensation\n- Demonstrates an innovative and forward thinking approach\n- Ensuring legal compliance\n- Improve safety culture & your reputation in the eyes of customers, competitors, suppliers, other stakeholders and the wider community.\nMore about OHSAS 18001\nA certificate issued by third party registrar to demonstrates that your business system has been certified against requirements of OHSAS 18001 requirements. Implementation of OHSAS 18001 by setting up of internal processes gives confidence to management, employees & society at large about the protecting the health & safety and managing risk to human being.\nOHSAS 18001 is an international standard for environmental management, applicable to companies of all sizes and types; certification to OHSAS 18001 provides a dynamic mechanism for the development of effective health & safety management system. “Plan-Do-Check-Act” principle based cycle, OHSAS 18001: 2007 specifies the most important requirements to identify, control and monitor the risk & hazards of any organization, and also how to manage and improve the whole system.\nThe OHSAS 18001 (Occupational Health and Safety Assessment Series) certification system is developed by an association of national standard bodies, group of certification bodies/registrars, and specialist of health & safety.\nFeatures of OHSAS 18001\nOHSAS series is designed to help organizations formulate occupational health and safety policies and objectives containing two documents viz. OHSAS 18001 – OHS Requirements & OHSAS 18002 which generally known as guidance document for implementation of OHSAS 18001. It is applicable to any organization, large or small, and within any business sector. OHSAS 18001 is largely aligned with the structure of ISO 14001 and is based on the two concepts of continual improvement and regulatory compliance.\nOHSAS 18001 audit covers following:\n- Policy statement (commitment of top management to improve OHS conditions)\n- Hazard identification, assessment & control (evaluation of risk & its consequence on human being)\n- Legal & other requirements (ensuring stringent compliance to the law of the land)\n- Documented objectives & targets (continual improvement)\n- Resources, Role, Responsibility & Authority (making responsible every one)\n- Competence, awareness & training (ensures availability of right person all the time)\n- Communication, participation & consultation (ensuring every one has to become part of OHS management )\n- Documentation, Control of documents & records (for ensuring compliance)\n- Operational controls(established safe working conditions)\n- Emergency preparedness & response (check your preparation to mitigate any emergency or abnormal situation)\n- Performance measurement & monitoring (ensuring health & safety parameters)\n- Incident, Nonconformity, corrective & preventive action (provides mechanism for improvement)\n- Management review (ensuring organization system is complied)\nEliminating risks and hazards\nOHS hazards & its risk to human being are identified by a team of experts considering extent of application, nature of activity & conditions in which it operates. Identified risk are prioritized by making objective to reduce its significance level by giving a frame work of management programs which identify the resources & approach to achieve the desired goal. Timely review of achieved objective & new process area will direct the organization to set the next goal towards improvement in health & safety status.\nCertification Process for OHSAS 18001\nDQS Certification India appoints a competent & suitable auditor or team of auditors to audit the organization against the standard & scope requested by the clients. Client has to file an application seeking standard for which to be certified. Gap analysis may be performed first to check readiness for the auditee organization which help organization to improve upon. Routine surveillance audits are carried out to evaluate continual improvement in the validity period. A re-certification audit is performed after every three years to maintain continuity of the certification."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:a65457b0-cba5-480f-b63c-9b932d4a4f43>","<urn:uuid:d5f3dda1-8c28-4be4-a1f6-40a3cf34df5a>"],"error":null}
{"question":"What are the physical warning signs of an eating disorder?","answer":"The physical warning signs of an eating disorder include accelerated weight loss, loss or infrequent menstruation in females, decreased energy levels, irregular sleeping patterns, and signs of potential damage due to vomiting (such as swelling of the cheeks or jaws, or corrosion of the teeth).","context":["What is an eating disorder?\nAn eating disorder is a mental illness that goes beyond food and diet, as it encompasses distorted thoughts and behaviours towards food, weight, as well as body image1. According to Statistics Canada, current prevalence rates of eating disorders remain around 3%, as approximately 1 million Canadians meet the diagnostic criteria2. Living with an eating disorder is physically and mentally exhausting, and it is difficult for an individual to accept that they may have one. Multiple factors can contribute to the development of an eating disorder such as media, family environment, socio-cultural values, and personality traits1.\nWhat do you see when you look in the mirror? It’s common for most people to see at least one part of their physical appearance that they may not like. Constant exposure to media may intensify the perception of a physical flaw, which can lead to a fixation of constant negative thoughts. Anorexia nervosa and bulimia nervosa are the two most commonly diagnosed eating disorders. Anorexia nervosa is a life-threatening eating disorder, which is often distinguished by extreme restriction, leading to nutrient deficiencies within the body and a low body weight. Bulimia nervosa is an eating disorder characterized by repeated occurrences of eating, followed by activities to prevent weight gain such as fasting, diuretics, self-induced vomiting, or excessive exercise1. Binge eating disorder is another serious eating disorder that exists when an individual experiences a loss of control while eating an amount of food that would be in larger quantities than most people would eat in similar circumstances, including a similar timeframe1. It’s important to note that disturbances in behaviours occur on a continuum, as harmful behaviours range from as simple as going on and off diets, to extreme behaviours such as restricting fat from the diet1.\nOften times, eating disorders remain invisible depending on weight, as they can exist within many body shapes and sizes. Eating disorders that exist at a young age may cause severe impairment in development and growth, as well as overall mental and social well being1.\nIt is important to understand some of the common physical, physiological, and behavioural warnings and signs of an eating disorder:\nPhysical warning signs3\n- Accelerated loss in weight\n- Loss or infrequent menstruation in females\n- Decreased energy levels\n- Irregular sleeping patterns\n- Signs of potential damage due to vomiting (such as swelling of the cheeks or jaws, or corrosion of the teeth)\nPsychological warning signs3\n- Unhealthy body image\n- Restricting food as self-punishment\n- Experiencing anxiety or irritableness during mealtimes\nBehavioural warning signs3\n- Dieting behaviour (for example, counting calories, fasting, or avoiding macronutrients such as fats or carbohydrates)\n- Eating alone and avoiding group meals\n- Evidence of behaviours of binge eating\n- Evidence of behaviours to prevent weight loss (such as laxatives, self-induced vomiting, or excessive exercise)\n- High sensitivity to comments regarding body-image, eating, weight, and exercise\nIf you feel you have recognized one or more of the signs and symptoms listed above, it is suggested to seek help immediately. If you feel you may have an eating disorder, there are many different treatment plans available which vary depending on your needs.\nHow do I get help for my eating disorder?\nTell someone you trust about your struggles. Accept support from your loved ones. This is not something you need to go through alone. The next step is to see your family physician and share what you have been experiencing. If they do not suggest it first, request a referral to a local eating disorders program.\nOftentimes, individuals may not meet the admittance criteria for a program but that does NOT mean you don’t need or deserve help. In these cases, look for a private practice therapist and dietitian to help support you in your journey to recovery.\nBelow are some resources that may be of assistance as you start to navigate your recovery from an eating disorder.\nNEDIC is a Canadian non-profit organization which aims to support those dealing with eating disorders. If you are unsure if whether or not you have an eating disorder, NEDIC provides a toll-free helpline that is open Monday-Friday from 9AM-9PM EST. The number is 1-866-NEDIC-20. You can also call the helpline for support, resources and treatment options. They list competent providers of eating disorder services across Canada in their Service Provider Directory.\nLocal Support in London, Ontario\nThe Adult Eating Disorders Service (AEDS) is a community based program provided by London Health Sciences Centre and the Canadian Mental Health Association Middlesex. This program delivers treatment to adults living with anorexia nervosa, bulimia nervosa, binge eating disorder and other specified feeding or eating disorders. Programming may be delivered in an outpatient, day treatment or residential setting.\nThe Eating Disorders program is a part of the London Health Sciences Centre Children and Adolescent Mental Health Care Program. This program delivers treatment to children and teens living with anorexia nervosa, bulimia nervosa and other eating concerns such as bingeing, excessive exercising and low body weight. Programming may be delivered in an outpatient, day treatment or inpatient setting.\nHope’s Eating Disorders Support provides support for those with eating disorders and strives to assist individuals on the pathway to recovery. Locations exist within London and Sudbury. Through their programming, they provide a safe and supportive space for individuals to discuss eating disorders.\nchange.creates.change Nutrition Counselling offers services with a Registered Dietitian that specializes in disordered eating and eating disorders. Located in London, change.creates.change offers eating disorder services which include individual and family counselling packages, group education classes, as well as meal support therapy. Our dietitian works with clients in the outpatient setting with treatment focused on recovery and engagement. Patients who are unable to access community and tertiary programs can also benefit from their services. change.creates.change is unique in that they offer evening and weekend appointments and have a short wait time of 1-2 weeks.\n- Thompson J, Manore M, Sheeshka J. Nutrition: A functional approach 3rd edition. Toronto: ON: Pearson; 2014. 768 p.\n- National Eating Disorder Information Centre [Internet]. Toronto, ON: Nedic; 2017 [updated 2017; cited 2018 Apr 21]. Canadian Research on Eating Disorders; [about 16 screens]. Available from: http://nedic.ca/sites/default/files//Canadian%20Research%20on%20Eating%20Disorders%20-%20Formatted.pdf\n- National Eating Disorders Collaboration [Internet]. Australia: Government of Australia; [cited 2018 Apr 21]. Understanding the warning signs; [about 5 screens]. Available from: www.nedc.com.au/recognise-the-warning-signs\n- National Eating Disorder Information Centre [Internet]. Toronto, ON: Nedic; 2018 [cited 2018 Apr 21]. Contact the Helpline; [about 2 screens]. Available from: https://www.nationaleatingdisorders.org/help-support/contact-helpline"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:468956af-e241-4bee-8b63-f163fe678e0b>"],"error":null}
{"question":"What are the main benefits of strategic alliances in manufacturing, and how can 3D printing help address their supply chain challenges?","answer":"Strategic alliances in manufacturing offer several key benefits: they improve product development through collaborative innovation, reduce costs by sharing technology and facilities, and enable easier market entry by leveraging established platforms. Meanwhile, 3D printing can address supply chain challenges in these alliances by eliminating traditional warehousing needs, enabling on-demand production, reducing transport costs through localized printing, and allowing for flexible, customized production. 3D printing also minimizes waste through its additive manufacturing process and can help prolong the useful life of older machines by creating spare parts that may no longer be available through conventional manufacturing.","context":["To remain competitive, today’s manufacturers and automotive companies must produce more at a faster pace. These companies must evolve their production processes — and even their business models — while grappling with costly technological advances and vast labor shortages.\nThis pressure is leading many in the industry to form strategic alliances — sometimes with competitors — to keep pace with heightened customer expectations. Doing so, however, comes with its own set of challenges, making risk management and insurance critical components of these arrangements.\nA Changing Landscape\nManufacturing and automotive companies are facing digital disruptions that have forced them to transform production processes to better meet customer demands, including delivering more product variety and shortening production cycles. Robotics, 3D printing, nanotechnology, and blockchain are just a few of the digital solutions allowing manufacturers to adjust to changing customer needs.\nAutomakers, in particular, have been challenged to adapt. Not only are they expected to go to market with new and improved models at an unprecedented rate, they are now attempting to solve for driverless cars and are fighting for space in the rideshare market to diversify their business. It’s likely that none of this would be possible without 3D prototyping, connected factories, or the tech-driven shared economy fueling the rideshare marketplace.\nAt the same time, technology is increasing competition, creating demand for more skilled labor and presenting evolving privacy, security, and safety issues. Adding to these challenges is the integration of new technology into manufacturing processes, which can be costly and complex; solutions can quickly become outdated, and updating one network or system often requires altering others so they are compatible.\nManufacturers face great risk from what is often deemed the “fourth industrial revolution.” They are susceptible to intellectual property theft by cyber hackers, business interruption from system shutdowns, and financial losses and reputation damage from hefty development costs for products that do not meet revenue expectations.\nTeaming Up for Better Results\nThese mounting risks are leading manufacturers and automotive companies to form strategic alliances, which are formal partnerships whereby two independent companies remain separate entities but share resources or collaborate on projects for their mutual benefit.\nSuch strategic alliances often involve intertwining supply chains, technology, production locations, and/or finances. For instance, some automakers share technology and facilities to develop autonomous driving systems and electric vehicle platforms, while many food and beverage manufacturers share distribution networks and facilities to expand their reach.\nThese alliances can be beneficial, allowing collaborating companies to:\n- Improve product development: Two minds are better than one. When two similar or complementary companies collaborate, they can bring different resources to bear, which can lead to real transformation. Rather than creating “separate but equal” standard products, they can unite to create truly innovative products that will move the needle for both companies.\n- Reduce costs: Innovation is not cheap, but it can cost less in a strategic alliance. The aligned parties can split the cost of procuring or implementing new technology and share facilities, which can reduce redundant capital expenditures for expensive technology and equipment at separate locations, and benefit from economies of scale along their supply chains. Ultimately, if a collaborative project fails, it usually costs less than if the parties were going it alone.\n- Enter new markets and grow more easily: Strategic alliances can speed up research, development, and production of new products and up the momentum on distribution of longstanding products debuting in new markets. Collaborating parties can piggyback off one another’s already established production or distribution platforms in specific locations. As such, companies are able to overcome production barriers and local cultural and operational obstacles that would otherwise hamper speed to market.\nPerforming Your Due Diligence\nUltimately, strategic alliances can produce better outcomes at a lower cost, taking companies from barely surviving to thriving in today’s competitive marketplace. However, such partnerships are not without potential challenges. In fact, not properly managing a strategic alliance could actually increase your risk.\nUnfortunately, strategic alliances often fail. Nearly half of the respondents to a 2014 study on strategic alliances by the CMO Council and Business Performance Innovation Network reported strategic alliance failure rates of 60% or more.\nRecently, two major automakers partnered to trade one’s hybrid technology for the other’s access to a particular geographical territory. Both parties failed to agree upon terms and deliver on their promises. This not only resulted in a failed alliance, but also prompted international arbitration.\nMeanwhile, two large telecommunications manufacturers jointly acquired a portion of another smaller telecom company and made a significant investment in a burgeoning industry. But the industry never took off because consumers were not interested, and the alliance failed within just one year of their agreement.\nThese examples highlight how strategic alliances can be difficult to manage, despite their potential value. However, with adequate due diligence and proper planning, potential partners can avoid common missteps and instead find allies with compatible business cultures, aligned objectives and strategies, and agreeable terms regarding their operational business arrangements and how profit pools will be shared.\nDue diligence should go beyond high-level company culture and business strategy research, taking into account potential partners’ risk management and insurance programs as risk and insurance can become especially murky in strategic alliances. For instance, which company’s insurance responds first in the event of a claim? Even if the answer to that question is straightforward, how will partners manage through the frustration or financial burden if one party seems to shoulder disproportionately more risk?\nWhen considering a strategic alliance, organizations should take the following steps to conduct effective risk and insurance due diligence:\n- Evaluate a potential partner’s approach to risk management, loss control, and claims management.\n- Review insurance policies to identify any gaps in coverage.\n- Determine the extent to which deductibles or retentions will affect the quality of earnings.\n- Assess the adequacy of provisions for self-funded losses on the balance sheet.\n- Examine property schedules and create a risk map to determine if shared equipment, processes, and activities, would occur at inherently risky locations.\n- Identify potential areas of exposure or hidden liabilities.\n- For cross-border alliances, consider any unique in-country risk management and insurance requirements.\n- Assess — qualitatively and quantitatively — a potential partner’s risk profile, including benchmarking insurance programs and reviewing financial security of current and historical insurers.\n- Develop pro-forma insurance cost projections with respect to a partner’s total cost of risk.\n- Quantify historical liabilities (for example, from self-insured programs) and identify any insurance-related one-off costs that could affect an alliance.\nAcquiring such information can be much more manageable with access to data and analytics and modeling tools. Guidance from insurance advisors with expertise in manufacturing, strategic alliances or similar arrangements, and any new geographic territories being explored for an alliance can substantially ease this process. And while it may seem like a significant undertaking, risk and insurance due diligence can reduce uncertainty and help prevent surprises. It can also help obtain a clear picture of the value of the liabilities and assets being shared — potentially enhancing strategic alliance agreements, operational costs, and corporate governance.\nTechnology and digitization continue to disrupt manufacturing and automotive industries. Amidst such industry dynamics, strategic alliances may be one of the few ways manufacturers and automotive companies can keep up with the demands to expand product offerings while shrinking production timelines. And while adapting a strategic alliance business model might involve some growing pains, it can also result in real transformation for the manufacturing and automotive industry, helping these companies thrive in an ever-changing environment.","Supply chain management is a constant juggling act. It must balance overall inventory, local availability, and variations in demand. If managing these factors is already a challenge for new products, then spare parts represent the ‘perfect storm’. Maintenance programs and quantities may be designed into a product life cycle. However, they are not always followed. And who knows when and where breakdowns will occur? And what the need for parts will be from one day to the next?\nFaced with these unknowns, suppliers may have few valid options. They can bulk up on spare part stocks, but inventory costs money. It costs even more when suppliers multiply stocks to maintain them locally for specific customers. If people’s wellbeing or business continuity are in the balance, distributed stocks of spares may be mandatory. The cost then often finds its way onto the invoices for the customers. Otherwise, suppliers may try to duck the issue by holding a smaller quantity of parts centrally or only making them on demand. Costs may go down, but so too does customer satisfaction as delivery times stretch out.\nForecasting and inventory for spare parts are indeed thorny problems. But finding solutions is not the only option. In some cases, you can also simply cancel out the problems. The magic wand for making them disappear is called 3D printing. This is a form of supply that takes traditional warehousing and demand planning out of the equation. The two common ways of making things using 3D printing are as follows.\nThe first way is fused deposition modelling or FDM using plastic. The 3D print head heats the plastic. It then sends it in fine, targeted jets to build up or ‘print’ the object layer by layer. The 3D printer can build solid or hollow forms, as well as convex and concave ones. The second way is selective laser sintering or SLS. In this case, the 3D printer uses a powder form of metal, plastic, ceramic, or other material. A laser beam heats the powder selectively to form the 3D object required. Between these two processes, there is little that cannot be 3D printed, on demand, and wherever a 3D printer is located.\nThese capabilities mean three levels of opportunity using 3D printing for spare parts and supply chains. They range from tactical, short-term advantages to strategic, longer-term improvement.\nOpportunity Level 1 – Tactical and Logistical\n3D printing is software driven. It uses virtual electronic models to print as plastic or metal objects. In this sense, it is like traditional printers that print electronic documents onto paper. Virtual models can be stored in a computer database. There is then no need to store physical objects in a physical warehouse. The only physical item to be stored is the raw material for printing. This is the fusible plastic or packs of small metal beads, for example.\nParts and products can then be 3D-printed on demand. This solves the issues of unpredictability and inventory. Waste is also limited by the efficient manufacturing process. 3D printing is an additive process. It works by building a product precisely, layer by layer. On the other hand, traditional manufacturing is subtractive. It involves the removal of material that often becomes scrap.\nCosts must also be correctly compared, if 3D printing is to justifiably replace traditional manufacturing.\nIn addition, 3D printing offers advantages and options for managing availability. It avoids the delays and expenses of tooling up production lines. As 3D printers come down in price, they can increasingly be located directly where parts are needed. Transport costs fall away. The only item that needs to travel is the virtual model to be printed. This is an electronic file that can be sent over the internet. Building on this idea, a further option is to use third parties to print locally and even to send the file directly to a customer with 3D printing facilities.\nHowever, costs must also be correctly compared, if 3D printing is to justifiably replace traditional manufacturing. The production cost per item in 3D printing may still be higher than that of an optimised standard production line. The speed of production per item may also be slower. 3D printing is not yet a solution for mass production. There may be additional cost factors like the machining, milling or coating of parts from 3D printing.\nThe savings are in the reduced or zero inventory needed. Also, overall lead time is low for making and supplying spare parts. Savings can be made in the reduced downtime of the systems needing the parts. Comparing these pros and cons will be a first step in deciding if or how much 3D printing makes sense.\nOpportunity Level 2 – Spare Part and Product Redesign\nThe ideas above already offer logistical cost reductions and faster time to availability. The next step is to improve performance inside the products and spare parts themselves.\nProducts designed for 3D printing can offer greater strength and lighter weight. Computer design software allows the modelling of any shape or form. This includes models with hollow honeycomb structures inside to reduce the total mass without sacrificing stability. 3D printing allows such structures to be manufactured like any other shape. Parts with overhangs can be made layer by layer too. The printing process then includes a separate phase to create the support for the overhang (the ‘scaffolding’ beneath). After the entire product has been printed, the support can be removed.\nSmarter design can take things further still. One jet engine manufacturer is using 3D printing for engine nozzles. It now prints one part, instead of assembling from many. Reliability and performance are as good as before, if not better. The number of component suppliers goes down. Risk goes down. The operation is more streamlined and life for procurement team becomes easier.\nFor decisions on which products and parts to move to 3D printing will depend on various factors.\nBetter inherent product performance can be made a priority too. Weight reduction lets aircraft use less fuel, saving on CO2 emissions. In certain cases, 3D printing does what traditional production methods like die casting cannot. Designs can then extend offer improved fuel flow and, easier, faster maintenance. 3D printing can help simplify where appropriate. It can also support additional complexity if needed.\nAs a bonus, 3D printing for spare parts can help prolong the useful life of older machines. Spare parts produced conventionally may no longer be available. However, the part can be modelled in software for 3D printing in the material required (metal, plastic, ceramic, resin, and so on).\nDecisions on which products and parts to move to 3D printing will depend on various factors. Product data can be collected from different supply chain and production systems. A product lifecycle management (PLM) system will have technical drawings, manufacturing plans, and information on possible innovation. An ERP system will offer access to quantities, costs, and current suppliers. The return on investment for converting to 3D printing and possibly reengineering can be calculated in each case. Working in other factors such as safety and reliability, the possibilities can be ranked and acted on.\nOpportunity Level 3 – Supply Chain Reengineering\nWhy stop at redesigning the parts that travel through the supply chain? 3D printing also offers the chance to redesign the supply chain itself. 3D-printed parts can be made immediately available in practically any location. One forward looking building company in France built a small house using only 3D printed components. All it takes is two things. First, a 3D printer installed on site. Second, a network connection to download the file with the model to be printed out. From a spares point of view, supply chain operations can reduce or eliminate warehousing and shipping. Demand forecasting becomes a matter of how much fusible plastic (or metal, etc.) to buy. As more parts are 3D-printed, the overall requirements for plastic print material are smoothed. Buffer stocks of print material can be kept low overall. Alternatively, suppliers with proven supply reliability and performance can deliver just in time. The bullwhip effect of huge safety stocks becomes a thing of the past.\nUltimately, 3D printing could transform some supply chains from purely physical to entirely electronic.\nAlso, product supply can become more flexible, more tailored. 3D product and part manufacturing can be profitable at low volumes. A product run of one unit becomes feasible. Enterprises can supply on demand. Their products are no longer stored in warehouse racks, but in a database of electronic models. Where appropriate, models can be adapted to individual requirements. Customer needs, whether at a personal or organisational level, can be met with increased precision. Postponement strategies become more flexible too. The customisation of products can be done later along the supply chain. It can even be done at the end of the delivery chain, with 3D printers in regional distribution centres, not just in a central manufacturing facility.\nUltimately, 3D printing could transform some supply chains from purely physical to entirely electronic. Some customer enterprises already have 3D printers for their own needs, such as making product prototypes. In this case, they could pay for the use of a part or product model that they would then print out directly on their site. Digital licencing techniques already exist for intellectual property of many kinds. 3D spares printing can use the same mechanisms or others to ensure vendors are paid according to the number of spares units printed.\nChallenges of 3D Printing for Supply Chains\nWhile the vision is clear, some real-life issues must still be solved. 3D printing can cross borders in ways that physical products cannot. A computer file sent over the internet is undetectable by customs authorities. While this means part and product delivery in minutes, perhaps also saving on import duties, it also nullifies the watchdog role of customs. It is no longer possible for customs authorities to check for suitability for consumers and safety, for example.\nCounterfeit goods cannot be identified like before. Counterfeiters of electronic product blueprints cannot be pursued in the same way. Yet the 3D printing market is bound to attract copiers and fakers. Manufacturers may seek to protect their blueprints through digital copy protection. Note however, by scanning a product in three dimensions to reverse-engineer a product design, fakers can also make their own blueprints.\nIssues of liability may arise. What happens if a 3D printed product breaks after being printed outside the original manufacturer’s premises? 3D printing service providers will first need to be checked for proper standards of printing and finishing. Customers printing on site will need print installations that comply with manufacturer directives. Alternatively, they might need to waive certain rights or claims. Manufacturers and vendors will also need to keep a tight grip on their product change process. The adaptability of 3D printing can be double-edged. The ease of modifying a product or part and printing it right after could lead to chaos in installed bases otherwise.\n3D printing for spares and products is still a new supply chain concept. It has potential in several ways. It can make spare parts logistics more efficient with faster delivery. It can also turn traditional warehousing and shipping on their heads. 3D printing will become a competitive weapon in supply chains, to a certain degree. That said, some suppliers will continue with traditional parts and products manufacturing and delivery. This may be because some parts are still better made using conventional methods. It may also be because there is a strong service component that lessens the impact of 3D printing. Note also that 3D-printed parts are not automatically greener than their conventional counterparts. Only an assessment of the overall effect on a supply chain and customer use will show if they are better for the planet.\nIn studying the feasibility of 3D printing, organisations should consider other factors too. Laws are still lagging the advances in 3D printing. Changes in regulations could alter the business case for 3D printing. Enterprises will therefore also need to keep an open mind. This applies to opportunities for themselves. It also applies to new forms of competition, whether licit or illicit. In summary, 3D printing with all the aspects described above merits a thorough evaluation and clear thinking. Only then can you be sure that using that extra dimension will bring benefit and not disorder."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:1ff5e8fe-1623-4a81-9e07-2b441bc6f4cc>","<urn:uuid:07a6b902-7c89-4fa4-8331-9a09f0e7987d>"],"error":null}
{"question":"What are the key differences between qualifying for a traditional bank loan and a merchant cash advance in terms of credit requirements and character assessment? Please explain the evaluation criteria for each.","answer":"Bank loans and merchant cash advances have substantially different qualification criteria. Banks evaluate three main factors known as the three 'C's: character, credit, and collateral. For character, they look for community ties like long residence and home ownership. Credit history must be clean - while a few late credit card payments might be acceptable, missing multiple mortgage payments requires explanation. However, merchant cash advances have much simpler qualification criteria - they don't even consider personal credit scores in their funding decisions. Instead, they primarily evaluate the business's credit card sales volume, requiring only 6 months of operation history and minimum monthly credit card sales of $5,000. This makes merchant cash advances more accessible to businesses with poor credit histories, as the funding decision is based on future sales rather than traditional credit metrics.","context":["Web definition for a bank loan is a medium-term form of finance\nobtained from a commercial bank or other similar financial\ninstitution. The loan may be secured on the entity’s assets and\nthe interest charged may be variable.\nA loan from a bank can be of different types. A loan to buy\nconsumer durable goods, such as, a car or furniture is a personal\nloan but also called a bank loan.\nA mortgage from a bank is similarly called a bank loan. Basically\nany borrowing from a bank which is not of a short term nature can\nbe known as a bank loan.\nGetting bank loans\ncan be a tedious, but if you do some quick\nhomework the process becomes much easier – and you can save money\nGetting a Bank Loan\nBankers usually look at what are called the three `c's`:\ncharacter, credit and collateral (a security pledged for the\nrepayment of a loan). Character means more than not having a\ncriminal record. The banker should feel confident that you are not\ngoing to suddenly disappear to some unknown place if the business\nruns into trouble. Specifically bankers like to see ties to the\ncommunity such as long residence, family ties, and home ownership.\nA person taking a loan should have clean credit history. A couple\nof late credit card payments doesn’t matter much, but if a person\nis missing mortgage payments for three months in a row will\nrequire a good explanation. Bankers like, good character and good\ncredit, but they live for solid collateral. (Equipment, buildings\nand trucks--that's the kind of stuff that bankers really like for\ncollateral--) even if the business goes bust these solid value are\nlikely to be worth a lot. Inventory, raw material and goods are\nsecond choices for collateral--they will lose their value more\nquickly than fixed assets but still be worth something.\nBanks usually consider the interest rate, usually described as the\nAnnual Percentage Rate or APR. if you're borrowing a lot of money\nover a long period The differences can be dramatic . The\ndifference between 7% and 10% doesn't look like much on paper, but\nit's likely to make a difference of several hundred pounds to your\nFixed APRs are a good idea, especially at the moment when the\neconomy's worn out. With a fixed APR if the interest rate rises,\nyour payments won't. You can often get bank loans with very low\nvariable APRs but you're taking a big gamble if interest rates\nSome bank loans\ncharge a penalty fee if you repay them early,\nwhile others don't. You can skip three consecutive payments if\ntimes are hard; it's worth having because you don't know what's\nround the corner. Some firms also let you vary your payments, so\nyou can pay more when you're loaded and less when you're broke.\nPrior approaching to bank, you should have all of your key\ndocuments in order, starting with a solid business plan. You will\nalso need to have the most recent financial statements available,\nprojections for the business (this is typically in the business\nplan) and a repayment plan, plus collateral.\nCollateral may include:\n• Hard goods such as equipment\n• Real estate\n• Stocks or bonds\n• other personal assets\n• Personal guarantees","A merchant cash advance is a type of funding that allows businesses to borrow money against future sales. The loan is repaid with a percentage of the business’s daily credit card sales, making it a convenient option for businesses that process a lot of credit card transactions.\nMerchant cash advances can be used for a variety of purposes, such as funding inventory, expanding the business, or covering unexpected expenses. They are a popular option for businesses that may not qualify for traditional bank loans, and they can be approved quickly since they are based on future sales instead of credit history.\nTo qualify for a merchant cash advance, businesses typically need to have been in operation for at least six months and process a minimum of $5,000 in credit card sales per month. The amount that can be borrowed depends on the business’s monthly sales, and the repayment terms vary depending on the lender.\nIf you’re considering a merchant cash advance for your business, it’s important to compare offers from multiple lenders to make sure you’re getting the best deal. Be sure to read the fine print and understand the repayment terms before signing any agreements.\nHow does Merchant Cash Advance Work?\nThe basic idea behind merchant cash advance is simple:\nA business sells a future stream of credit card receivables to an investor in exchange for a lump sum of cash today. The purchase price is based on a multiple of the monthly credit card volume, typically 1.15 to 1.40. In other words, for every $1,000 in monthly credit card sales, the business would receive $1,150 to $1,400 today.\nThe cash advance is repaid over time through a daily or weekly automatic deduction from the business’s bank account, equal to a fixed percentage of that day or week’s credit card receivables (from 2.5% to 10%). The repayment percentage is fixed, so the amount of money deducted each day or week will increase as credit card sales increase.\nFor example, let’s say a business has monthly credit card sales of $100,000 and takes out a merchant cash advance for $115,000 (1.15 x $100,000). The repayment percentage is 5%, so the business would need to repay $5,000 each month (5% x $100,000). If credit card sales increase to $120,000 the following month, the business would need to repay $6,000 that month (5% x $120,000).\nThe repayment schedule is flexible, so if credit card sales decrease, the business would simply repay less that month. This is one of the key advantages of merchant cash advance – it’s a form of funding that can fluctuate with your sales, which is helpful for businesses with seasonal or cyclical sales patterns.\nAnother advantage of merchant cash advance is that it’s easy to qualify for. Since the funding is based on future sales, businesses with bad credit can still qualify. In fact, most merchant cash advance providers don’t even consider personal credit scores when making funding decisions.\nThe downside of merchant cash advance is that it can be expensive. The fees are typically calculated as a multiple of the advance, so a business that takes out a $100,000 cash advance could end up paying back $115,000 to $140,000.\nTo compare the cost of merchant cash advance to other types of funding, it’s helpful to look at the “effective rate”, which takes into account the fees as well as the repayment schedule. For example, a merchant cash advance with an effective rate of 30% would be more expensive than a business loan with an interest rate of 10%, even if the interest rate on the loan is higher.\nThe other key downside of merchant cash advance is that it’s not easy to get out of. Once you’ve signed the agreement, you’re committed to making the repayments – even if sales decline or the business struggles.\nFor these reasons, merchant cash advance is best suited for businesses that are confident they can increase sales in the near future and can afford the high cost of funding."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:b4633e43-67a6-4aef-8d60-afb8ab61a144>","<urn:uuid:f57cbe18-8cbd-46d0-9511-fa5997330bc2>"],"error":null}
{"question":"What are the technical innovations in sustainable farming methods like vertical farming, and how do international carbon pricing mechanisms affect their market competitiveness?","answer":"Vertical farming employs several innovative techniques including hydroponics (growing food in water with mineral solutions), aeroponics (using mist instead of water, inspired by NASA), and aquaponics (combining fish farming with hydroponics). These systems use customized LED lighting and automated control systems, achieving significantly higher yields while using 80% less water. Regarding market competitiveness, the absence of a single international carbon price can create trade distortions. Countries implementing environmental programs can protect these sustainable practices through various mechanisms: cap-and-trade systems, carbon taxes, or border tax adjustments. The WTO framework allows these protective measures to prevent 'carbon leakage' where business might migrate to countries with lower environmental standards, though the challenge lies in quantifying the appropriate level of tax adjustments or tariffs, especially in cap-and-trade systems where prices fluctuate continuously.","context":["| Sourced From Guardian.co.uk |\nLONDON, June 26 (Reuters) – Nothing in international trade law would prevent countries that introduce carbon taxes or cap-and-trade programmes from supplementing them with excise duties, tariffs or other measures on imports from countries that don’t.\nThe absence of a single international carbon price risks causing significant trade distortions as well as undermining the effectiveness of emissions reduction programmes if business migrates from countries with a high carbon price to ones with a low or zero one.\nSo the question of whether control programmes can be buttressed with measures such as tariffs and other restrictions to “level the playing field” and prevent “carbon leakage” is crucial to the success of the system as well as its political acceptability.\nWhile the issue of “greenhouse tariffs” has aroused bitter opposition from developing countries such as India and China, the rules are fairly clear, and the World Trade Organisation (WTO) has helpfully set them out in a joint report on “Trade And Climate Change” [ID:nLQ110798] published in conjunction with the United Nations Environment Programme (http://www.wto.org/english/res_e/booksp_e/trade_climate_change_e.pdf).\nTARIFFS AND TAX ADJUSTMENTS\nMarket-based programmes can be based on either a tax or a cap-and-trade system. In theory, a tax would be the most efficient solution, because it would create a simple, transparent and predictable price. In practice, every country that has implemented or is considering a programme has chosen cap-and-trade to reduce political opposition [ID:nLR468410]. The choice has important implications for trade measures. Governments wanting to level the playing field and prevent carbon leakage have four basic alternatives:\n* Give domestic manufacturers of energy-intensive goods a free allocation of permits to reduce the competitive disadvantage imposed by the scheme.\n* Require importers of energy-intensive goods to purchase carbon allowances in the same cap-and-trade market as domestic manufacturers as a condition of entry.\n* Subject imports to a special “border tax adjustment” offsetting any advantage they gain over domestic firms that have to buy costly cap-and-trade permits. Many countries already use border tax adjustments to ensure importers do not gain an unfair advantage over domestic manufacturers paying special excise duties on items such as cigarettes and alcohol.\n* Levy a “carbon tariff” on imports over and above normal customs tariffs.\nThe first two approaches are straightforward. The problem with the second two (tax adjustments and carbon tariffs) is how to quantify the increased cost of energy/emissions for domestic producers and therefore how large the additional tax adjustment or tariff should be.\nIn a carbon tax system, this would be easy, since there would be a predictable price. But in a cap-and-trade system, the price, and therefore the offsetting tax adjustment or tariff, would be uncertain and change continuously.\nLEGAL FRAMEWORK CLEAR\nWhatever approach governments eventually decide to use, the legal framework for applying tax adjustments, tariffs, or requiring importers to buy emissions allowances is clear.\nSupporters and critics alike portray the WTO as a simple “free trade” agreement. Critics complain it prioritises trade liberalisation over other social objectives (such as labour standards, environmental protection and product safety) and prevents governments and elected parliaments responding to popular demands by taking action in these areas. But this is an unfair caricature.\nArticle XX (General Exceptions) of the General Agreement on Tariffs and Trade (GATT) 1947 (re-enacted as part of the WTO Agreement in 1994) gives governments wide-ranging powers to deviate from the trade-liberalising aspects of the agreement in order to promote other social objectives.\nAmong other things, governments can take action to protect public morals; protect human, animal or plant life or health; conserve exhaustible natural resources; or further an international commodity agreement (http://www.wto.org/english/docs_e/legal_e/gatt47_e.pdf).\nArticle XX therefore provides several “routes” by which WTO members could claim an exemption from normal trade rules to introduce tax adjustments, permit schemes or carbon tariffs:\n* Governments could claim an exemption on the basis that climate change endangers human life and health. In the United States, the Environmental Protection Agency (EPA) has already made a similar “endangerment” finding under the Clean Air Act, enabling it to regulate greenhouse gas emissions from motor vehicles [ID:nLK20098].\n* Governments could claim that either hydrocarbons or clean air is an exhaustible natural resource.\n* Governments could brand an international accord on emissions control or cap-and-trade systems an exempt “commodity agreement”.\nFor Article XX exemptions, the only requirement is that “measures are not applied in a manner which would constitute a means of arbitrary or unjustifiable discrimination between countries where the same conditions prevail, or a disguised restriction on international trade”.\nThere is no reason governments could not introduce tax adjustments, tariffs or permit requirements — provided they were carefully tailored and imposed in a manner that was linked to the danger, consistent and proportionate.\nFORESTALLING A BACKLASH\nPolitically, carbon tariffs or tax adjustments would represent a radical shift for the WTO and its members. For more than 60 years, the GATT/WTO process has been animated by the goal of reducing barriers to trade. While the tax adjustments and carbon tariffs would not violate the letter of the agreements, they would certainly mark a revolutionary shift in the spirit.\nBut the real aim of the report, and those who have pushed for it, is twofold:\n* It seems designed to pre-empt hostility from environmental groups and other activists who are suspicious that WTO rules will prevent effective action on climate issues, and prevent them from mobilising an all-out campaign to dismantle the GATT/WTO framework.\n* It provides developed countries (such as the United States and the European Union) with a source of leverage to secure agreement from emerging markets to adopt their own emissions control and trading framework. If developing countries do not adopt their own carbon taxes or cap-and-trade systems, they risk finding that border tax adjustments or tariffs are used against them. (Editing by David Evans)\nBy John Kemp\n– John Kemp is a Reuters columnist. The views expressed are his own –","As urban populations continue to grow, entrepreneurs are going beyond traditional farming to find new ways to feed everyone while minimising the effect on our land and water resources. Vertical farming is one such method that has been used all around the world. Food crops may be conveniently farmed in urban settings using Vertical Farming by planting in vertically stacked layers to conserve space and require little energy and water for irrigation.\nVertical farming is the process of producing crops in layers that are vertically stacked. Controlled-environment agriculture, which tries to maximise plant development, and soil-less farming techniques such as hydroponics, aquaponics, and aeroponics, are frequently used.\nBuildings, shipping containers, tunnels, and abandoned mine shafts are among popular structures used to host vertical farming systems. There are approximately 30 hectares (74 acres) of functioning vertical farms around the globe as of 2020. Vertical farming, in conjunction with other cutting-edge technology such as customised LED lighting, has resulted in crop yields that are more than ten times greater than those obtained by standard agricultural methods.\nVertical farming is still in its early stages in India, but there are a few entrepreneurs and agri-tech enterprises aiming to revolutionise the area.\nVertical Farming Background and Concept\nGilbert Ellis Bailey originated the phrase “vertical farming” and published a book named “Vertical Farming” in 1915. William Frederick Gerick pioneered hydroponics at the University of California, Berkeley, in the early 1930s.\nke Olsson, a Swedish ecological farmer, devised a spiral-shaped rail system for growing plants in the 1980s and proposed vertical farming as a method of raising vegetables in cities.\nProfessor Dickson Despommier invented the concept of vertical farming in 1999. His idea was to grow food in urban areas, utilising less distance and saving time in transporting food produced in rural regions to cities.\nHe aimed to produce food in urban areas in order to have fresher goods available sooner and at a reduced cost. As a result, vertical farming is defined as the cultivation and production of crops/plants in vertically stacked layers and vertically inclined surfaces.\nThe plants are vertically piled in a tower-like form in the physical arrangement. This reduces the amount of space needed to cultivate plants. Following that, a combination of natural and artificial lighting is employed to ensure an ideal atmosphere for the plants’ effective growth. The third component is the plant’s growth medium. Aeroponic, hydroponic, or aquaponic growth media are employed instead of soil as the growing medium.\nAs the methodology gets more scientific, the process’s efficiency grows, and as a result, vertical farming becomes more sustainable, consuming 95 percent less water than previous agricultural methods.\nAlso Read, Oxagon: The World’s First Floating City in the World\nVertical Farming Techniques\nIt is a method of producing food in water without the use of soil by employing mineral fertiliser solutions.\nThe primary benefit of this strategy is that it lowers soil-related cultivation issues such as soil-borne insects, pests, and illnesses.\nAeroponics was inspired by NASA’s (National Aeronautical and Space Administration, USA) endeavour in the 1990s to develop an effective technique to grow plants in space. There is no growth medium in aeroponics, hence there are no containers for growing crops. Instead of water, mist or nutrient solutions are utilised in aeroponics. Because the plants are attached to a support and the roots are sprayed with nutritional solution, there is very little space, very little water, and no soil required.\nThe name aquaponics is derived from the combination of two words: aquaculture (fish farming) and hydroponics (the process of growing plants without soil in order to develop symbiotic interactions between the plants and the fish). The symbiosis is established by feeding nutrient-rich waste from fish tanks to hydroponic production beds called “fertigate.”\nIn turn, the hydroponic beds act as biofilters, removing gases, acids, and chemicals from the water, such as ammonia, nitrates, and phosphates. Furthermore, the gravel beds serve as a home for nitrifying bacteria, which aid in nutrient cycling and water filtering. As a result, the newly cleansed water may be recirculated back into the fish tanks.\nThe Benefits of Vertical Farming\nVertical farming offers various advantages, making it promising for agriculture’s future. The land need is fairly minimal, water usage is 80% less, water is recycled and stored, pesticides are not used, and in the case of high-tech farms, there is no true reliance on the weather.\nA vertical farm makes farming possible within the constraints of a metropolis. When the farms are close by, the food is delivered swiftly and is always fresh, as opposed to the chilled stuff commonly seen in stores. Transportation reduction minimises the cost of fossil fuels and the accompanying emissions, as well as transportation spoilage. Vertical farming, like anything else, has its limitations. The biggest issue is the initial capital expenses for building the vertical farming system.\nThere are further expenditures associated with building the structures as well as their automation, such as computerised and monitoring systems, remote control systems and software, automated racking and stacking systems, programmable LED lighting systems, temperature control systems, and so on."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:171232ac-c21e-4f5f-bbc1-e5d55eac0261>","<urn:uuid:38abc93f-c15d-442d-abe3-4bcfbd141419>"],"error":null}
{"question":"Can someone explain boron's structural properties and its agricultural remediation techniques? 🌱","answer":"Boron exists in many polymorphs (different crystal lattice structures) and forms stable covalent bonds rather than ionic bonds. For agricultural remediation, two main approaches are used: breeding crops for boron-toxicity tolerance and screening large numbers of crop varieties to find those with natural tolerance to high boron levels. This breeding approach, combined with drought tolerance, has successfully improved productivity in boron-affected soils.","context":["The chemical element boron is classed as a metalloid. It was discovered in 1808 by Joseph L. Gay-Lussac and L. J. Thénard and independently by Sir Humphry Davy.\n|Classification:||Boron is a metalloid|\n|Melting point:||2075 oC, 2348 K|\n|Boiling point:||3727 oC , 4000 K|\n|Neutrons in most abundant isotope:||6|\n|Electron configuration:||1s2 2s2 2p1|\n|Density @ 20oC:||2.34 g/cm3|\nCompounds, Radii, Conductivities\n|Atomic volume:||4.6 cm3/mol|\n|Structure:||rhombohedral; B12 is icosahedral.|\n|Specific heat capacity||1.02 J g-1 K-1|\n|Heat of fusion||50.2 kJ mol-1|\n|Heat of atomization||563 kJ mol-1|\n|Heat of vaporization||480 kJ mol-1|\n|1st ionization energy||800.6 kJ mol-1|\n|2nd ionization energy||2427.1 kJ mol-1|\n|3rd ionization energy||3659.7 kJ mol-1|\n|Electron affinity||26.7 kJ mol-1|\n|Minimum oxidation number||0|\n|Min. common oxidation no.||0|\n|Maximum oxidation number||3|\n|Max. common oxidation no.||3|\n|Electronegativity (Pauling Scale)||2.04|\n|Polarizability volume||3 Å3|\n|Reaction with air||mild, w/ht ⇒ B2O3|\n|Reaction with 15 M HNO3||none|\n|Reaction with 6 M HCl||none|\n|Reaction with 6 M NaOH||none|\n|Hydride(s)||B2H6 and many BxHy|\n|Chloride(s)||BCl3 and many BxCly|\n|Atomic radius||85 pm|\n|Ionic radius (1+ ion)||–|\n|Ionic radius (2+ ion)||–|\n|Ionic radius (3+ ion)||41 pm|\n|Ionic radius (1- ion)||–|\n|Ionic radius (2- ion)||–|\n|Ionic radius (3- ion)||–|\n|Thermal conductivity||27.4 W m-1 K-1|\n|Electrical conductivity||5.0 x10-6 S m-1|\n|Freezing/Melting point:||2075 oC, 2348 K|\nDiscovery of Boron\nBoron compounds such as borax (sodium tetraborate, Na2B4O7·10H2O) were known and used by ancient cultures for thousands of years. Borax’s name comes from the Arabic buraq, meaning “white.”\nBoron was first partially isolated in 1808 by French chemists Joseph L. Gay-Lussac and L. J. Thénard and independently by Sir Humphry Davy in London. Gay-Lussac & Thénard reacted boric acid with magnesium or sodium to yield boron, a gray solid. (1) They believed it shared characteristics with sulfur and phosphorus and named it bore. (2)\nDavy first tried to produce boron by electrolysis of boric acid, but was not satisfied with the results. He enjoyed greater success reacting boric acid with potassium in a hydrogen atmosphere. The result was a powdery substance.\nDavy commented the substance was, “of the darkest shades of olive. It is opake, very friable, and its powder does not scratch glass.” After carrying out a number of chemical reactions to verify the uniqueness of the substance, Davy wrote, “there is strong reason to consider the boracic basis as metallic in nature, and I venture to propose for it the name of boracium.” (2)\nNeither party had, in fact, produced pure boron. Their samples were only about 60% pure.\nIn 1909, American chemist Ezekiel Weintraub produced 99% pure boron, by reducing boron halides with hydrogen.\nAlmost a century later, in 2004, Jiuhua Chen and Vladimir L. Solozhenko produced a new form of boron, but were uncertain of its structure.\nIn 2009, a team led by Artem Oganov was able to demonstrate the new form of boron contains two structures, B12 icosohedra and B2 pairs. (3) Gamma-boron, as it has been called, is almost as hard as diamond and more heat-resistant than diamond.\nTalking about boron’s part metal, part non-metal properties, Oganov said, “Boron is a truly schizophrenic element. It’s an element of complete frustration. It doesn’t know what it wants to do. The outcome is something horribly complicated.” (4)\nInteresting Facts about Boron\n- Boron is a tough element – very hard, and very resistant to heat. In its crystalline form it is the second hardest of all the elements on the mohs scale – only carbon (diamond) is harder. Only 11 elements have higher melting points than boron: these are C, W, Re, Os, Ta, Mo, Nb, Ir, Ru, Hf, and Tc. (As a challenge, how many of these elements can you name without looking them up?)\n- Boron is an essential nutrient for all green plants.\n- Boron in its crystalline form is very unreactive. Amorphous boron is reactive.\n- Unusually, the universe’s atoms of boron were not made by nuclear fusion within stars and were not made in the big bang. They were made by nuclear fusion in cosmic-ray collisions. Most of the universe’s boron was made in this way before the formation of our solar system.\n- Boron is an indispensable element in NIB magnets (Neodymium – Iron – Boron). NIB magnets are very powerful magnets invented in the early 1980s. They are used in computers, cell phones, medical equipment, toys, motors, wind turbines and audio systems.\n- Boron is used to control nuclear reactions. It is an excellent neutron absorber. Alloyed with steel or reacted with carbon, titanium or zirconium, it is used in control rods for nuclear reactors.\n- Pure boron can exist as a mixture of positive and negative boron ions.\nAppearance and Characteristics\nElemental boron is not known to be toxic.\nBoron is a metalloid, intermediate between metals and non-metals. It exists in many polymorphs (different crystal lattice structures), some more metallic than others. Metallic boron is extremely hard and has a very high melting point.\nBoron does not generally make ionic bonds, it forms stable covalent bonds.\nAlthough opaque to visible light, boron can transmit portions of infrared light.\nBoron is a poor room temperature conductor of electricity but its conductivity improves markedly at higher temperatures.\nUses of Boron\nBoron oxide (B2O3) is used in glassmaking and ceramics.\nBorax (Na2B4O7.10H2O) is used in making fiberglass, as a cleansing fluid, a water softener, insecticide, herbicide and disinfectant.\nBoric acid (H3BO3) is used as a mild antiseptic and as a flame retardant.\nBoron Nitride’s hardness is second only to diamond, but it has better thermal and chemical stability, hence boron nitride ceramics are used in high-temperature equipment.\nBoron nitride nanotubes can have a similar structure to carbon nanotubes. BN nanotubes are more thermally and chemically stable than carbon nanotubes and, unlike carbon nanotubes, boron nitride nanotubes are electrical insulators.\nBoron carbide (B4C) is used in tank armor and bullet proof vests.\nAbundance and Isotopes\nAbundance earth’s crust: 10 parts per million by weight, 1 part per million by moles\nAbundance solar system: 2 parts per billion by weight, 0.2 parts per billion by moles\nCost, pure: $1114 per 100g\nCost, bulk: $500 per 100g\nSource: Boron compounds are usually is found in sediments and sedimentary rock formations. The chief sources of boron are Na2B4O6(OH)2.3H2O – known as rasorite or kernite; borax ore (known as tincal); and with calcium in colemanite (CaB3O4(OH)4.H2O). Boron also occurs as orthoboric acid in some volcanic spring waters.\nIsotopes: 11 whose half-lives are known, with mass numbers 7 to 17. Naturally occurring boron is a mixture of its two stable isotopes and they are found in the percentages shown: 10B (19.9%) and 11B (80.1%). 10B is used in nuclear reactors as a neutron-capturing substance.\n- Alaa S. Abd-El-Aziz, Macromolecules Containing Metal and Metal-Like Elements Volume 8 Boron-Containing Polymers., (2007) p2. Wiley-Interscience\n- Walter Channing, John Ware, New-England Journal of Medicine and Surgery, and Collateral Branches of Science., (1812) p220. T. B. Wait and Co. (pdf download 19.8 MB)\n- Artem R. Oganov et al, Ionic high-pressure form of elemental boron., Nature 457, 863-867 (12 February 2009)\n- Kenneth Chang, Theory and Experiment Meet, and a New Form of Boron Is Found., (February 2, 2009) New York Times Online\nCite this Page\nFor online linking, please copy and paste one of the following:\n<a href=\"https://www.chemicool.com/elements/boron.html\">Boron Element Facts</a>\nTo cite this page in an academic document, please use the following MLA compliant citation:\n\"Boron.\" Chemicool Periodic Table. Chemicool.com. 15 Oct. 2012. Web. <https://www.chemicool.com/elements/boron.html>.","Crop-Based Management Opportunities for Sodium- and Boron-Affected Soils.\nManzoor Qadir, International Center for Agricultural Research in the Dry Areas (ICARDA), Aleppo, P.O.Box 5466, Syria, Andrew Noble, International Water Management Institute (IWMI), South East Asia Office, Kasetsart University, Bangkok, P.O.Box 1025, Thailand, Sui-Kwong Yau, American Univ. of Beirut - FAFS, Bliss St., Beirut, 1107-2303, Lebanon, and Ghulam Murtaza, Institute of Soil and Environmental Sciences, University of Agriculture, Faisalabad, 38040, Pakistan.\nWith worldwide occurrence, sodium-affected soils (sodic soils) are characterized by the occurrence of sodium (Na) to levels that result in poor physical properties and fertility problems thereby adversely affecting the growth and yield of most crops. These soils can be ameliorated by providing a soluble source of calcium (Ca) to replace excess Na on the cation exchange complex. Many sodic soils contain inherent or precipitated sources of Ca, i.e. calcite at varying depths within the profile. Unlike other Ca sources used in the amelioration of sodic soils, calcite is not sufficiently soluble to effect the displacement of Na from the exchange complex and hence amelioration. In recent years, phytoremediation — removal of Na by the cultivation of certain plant species tolerant to ambient soil salinity and sodicity levels — has shown promise as a ‘pay-as-you-go' option in the amelioration of calcareous sodic soils. In contrast to phytoremediation of soils contaminated by heavy metals, phytoremediation of sodic soils is achieved by the ability of plant roots to increase the rate of calcite dissolution, thereby resulting in enhanced levels of Ca in soil solution. The process of Na+ removal from calcareous sodic soils through phytoremediation has been found to be driven by the partial pressure of carbon dioxide within the root zone, and the generation of protons by roots of certain plant species at the soil-root interface. Both assist in increasing the dissolution rate of calcite with the added benefit of improved physical properties within the root zone, enhancing the hydraulic conductivity of these soils and allowing the leaching of Na below the effective rooting depth. Although shoot uptake of Na provides a direct source of Na removal from the soil, it is a minor component of sodic soil amelioration. Several plant species of agricultural significance have been found to be effective in the amelioration of calcareous sodic soils. Being common in soils and irrigation waters in dry areas, boron (B) at high levels causes toxicity in plants with subsequent impacts on crop yields. Boron can be leached out of the root zone only in higher rainfall areas or under excessive irrigations. In dry areas or in soils with impermeable sub-soil layers, B concentrations in the root zone can be high, making amelioration extremely difficult. In recent decades, screening of large numbers of accessions or cultivars of different crop species revealed wide variation in B-toxicity tolerance. In few studies, geographical diversity in B-toxicity tolerance among accessions could be attributed to selection over years by the soils of the different regions/countries. Breeding for B-toxicity tolerance has been attempted, and cultivars which give higher yields when grown in boron-affected soils were bred. In dry areas with high soil B, breeding for crop tolerance to B toxicity, in addition to drought tolerance, could make a contribution to improved productivity."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:0c8fa7fc-ed12-4c98-af26-d8e1baea0e90>","<urn:uuid:64ffc8a1-8713-4151-9df9-13405e62a948>"],"error":null}
{"question":"What is the hardness difference between granite and diamonds according to the Mohs scale, and is granite actually harder than steel?","answer":"According to the Mohs hardness scale, diamond is rated as 10 (the hardest), while granite scores 7. This means diamonds are significantly harder than granite. As for the comparison with steel, granite (with a hardness of 7) is indeed harder than stainless steel, which has a hardness of 5.5 on the Mohs scale. This is why granite is highly resistant to scratches and is commonly used as a building material.","context":["Granite is natural stone composed of several minerals tightly packed together. The main components include Feldspar and Quartz (both very hard) with a mix of other minerals including Biotite and Muscovite (soft mica). Feldspar and Quartz, both major components of granite, are harder than steel. That’s why granite is used as a building material by many. Biotite and Muscovite, the minor components of granite, give it that glittery appearance. They are also much softer and are frequently associated with pitting and fissures.\nThe elegance of granite countertops adds value to homes. Heat, scratch, and stain resistant, granite even outlasts the life of the home its installed in. Very little maintenance is required. Because of abundant supply, it’s more affordable than many people think.\nGranite is naturally formed all over the world, but major quarries are found in Brazil, India, Italy, Africa, Norway, Finland, and China. Most granite slabs used for kitchen countertops in the USA come from Brazil, where we get a lot of the slabs we use, and India.\nQuite the opposite. Granite countertops require very little maintenance. Clean them with a mild soap and warm water. Read our maintenance guide for more information.\nGranite withstands very high temperatures. Placing hot pans or kettles won’t cause any damage to the stone’s color or stability. Using trivets is a good idea whenever possible and are an absolute MUST under crockpots which sit on granite for an extended length of time. Long periods of concentrated heat can cause granite to crack.\nKnives can’t scratch true granite. The only thing harder is diamond. For example, diamond is scored 10 on the MOH’s hardness scale and granite is scored 7. Diamond blades are the only thing that can cleanly cut through granite. Other natural stones frequently called granites like Gneiss and Schist do not have a MOH score of 7, and those may be scratched by knives as can areas of softer minerals in granite. So always use a cutting board.\nThe abundant supply of natural granite along with modern technology make counter prices for entry level granite very affordable.\nYes, in most cases chips and cracks can be repaired by a granite fabricator.\nNo, the Center for Disease Control has not found evidence to suggest bacteria grows in or on granite.\nGranite has been tested for Radon emissions and found to emit very insignificant levels. It’s been found to be safe for use in homes without any harmful effects.You can read a more detailed report on this at the website of the Marble Institute of America.\nWe use 1 1⁄4” granite which is sturdy enough to be placed directly on the cabinets.<br />\nIt’s not uncommon to see some small pits on the surface of granite. These pits are formed during the polishing process, when some of the weaker components of granite, like Biotite, flake off from the surface. This happens at the granite processing plants in different countries where the granite is quarried and polished. The pits themselves don’t make it less durable or inferior for use in countertops, but the look and feel of the pits may bother some people. We can’t fill the pits because no compound can adequately or permanently fill these spaces without visually affecting the surface of the stone. The best practice is to discuss imperfections with your fabricator before selecting the stone. If you really hate the pits, ask about granite selections that have no visual imperfections.\nA good number of granite colors that are very beautiful with a variety of colors and veins that flow in different directions, are not truly “granites” in strict geological terms. Though they are commonly called granites, they are actually Gneiss or Schists stones. True granite stones scale between 6 and 7 on MOH’s scale of hardness. By comparison, the MOH’s scale for Gneiss and Schist is less than 6. In order to strengthen these stones to be used as countertops, they undergo a process called resinization, where epoxy resin is used to fill the weak spots. These slabs, with the visually filled lines, don’t break or crack once they are installed, with proper care. If any problems occur, they will happen during fabrication or transportation. Many exotic stones belong in this category. The filled areas are not defects but are required as part of the product.\nThe granite provided by us doesn’t have to be resealed and comes with a warranty against permanent staining under normal use. If staining material, like red wine, is not removed promptly there may be superficial staining which can normally be removed with a poultice.\nGranite slabs that are cut into particular sizes and have one edge that is polished. They are typically fabricated in countries with cheap labor, like China, and if you decide to use these, you will not have a custom fabricated countertop. Don’t expect the same quality of fit and finish with these or the same consistency of shade between pieces. We will not return to site for complaints on these issues.\nThe standard overhang is 1 1⁄2” from the face frame of the cabinets. This gives a good visual appearance because it creates a 3⁄4” overhang from the door fronts. You can compare this to the 1” overhang typical of the laminate countertops you are looking to replace with granite.<br /> The actual overhang may slightly vary depending on how straight the cabinets are installed. Having the cabinets not installed in a straight line is a common problem. Our template professionals discuss these issues with homeowners when they are visible at time of template.<br /> We can usually extend the 3 cm granite countertops up to a maximum of 10” from the cabinets, provided the total unsupported area is no more than 1/3 of the supported area. unsupported. We have to be careful when we install upper bar tops that sit on a 5” knee wall. These overhangs have to be supported by steel braces placed under the countertop and then screwed into the wooden studs in the knee wall. Any granite countertops with more than an 10” overhang should be adequately supported by steel braces. The placement of wood or metal supports that extend from the cabinets, sometimes called corbels, can hit your knees and may not be visually appealing. The ideal solution is to place steel bars, secured adequately, providing a permanent support that is almost invisible and does not hit your knees.\n12” is the ideal overhang for comfortable seating without hitting your knees on the cabinet. However, the overhang does need adequate support.\nDishwashers must be attached to the under surface of the kitchen countertop to prevent tipping the machine forward when the door is opened. The attachment also prevents vibration during the dishwasher’s operation. We attach the dishwasher with a well-designed bracket. This attachment is rigid enough to secure the dishwasher safely, while still allowing you to easily remove it in case you need to repair or replace the dishwasher in the future, without having to call a granite fabricator to do so. Newer dishwashers come with side attachment clips so that the dishwasher can be screwed to the cabinets instead. This should be done by your cabinet installer or remodeling contractor.\nYes. While replacing the existing laminate countertops, customers can choose to keep their current tile backsplash. However, you must consider the following points for better results: The thickness of laminate countertops is 1 1⁄2” and granite, marble, or engineered surfaces, like Silestone, are 1 1⁄4” thick. The replacement causes a visible gap of about 1⁄4” between the new granite countertop and the existing tile.<br /> This scenario applies in cases where the tile goes all the way down to the countertops. You can solve this problem by using one of these methods:<br /> -Plying caulk in the gap with a matching color to the existing grout. The new caulk line will be about a 1⁄4” thickness instead of the tile grout line of about 1/8”.<br /> -If you have kept the grout from the original tile installation, you can use that grout to fill the gap. This is the best case scenario.<br /> -You can purchase and install a trim line from tile supplier that fits between the tile and the granite countertop. This should be done by your tile installer.<br /> -Installation of a 4” back splash of granite over the existing tile is another option.<br /> In case the existing tile goes up to the 4” back splash of laminate countertop, 4” granite back splashes have to be placed between the granite countertops and the existing tile. We will custom measure these at the time of installation and they will minimize the gap between the tile and the backsplash. However, that will require a second visit to install.\nNo, you don’t need to buy full slabs. We consider the cost of actual material used in your project. That is one of the advantages of buying from us. Of course, we do have to make efficient use of the stone and therefore it is a requirement that final seam locations and utilization of the slab is at the discretion of the fabricator. If you decide you want a specific slab layout on a particular slab or slabs which involves more waste, then we can provide you with a price for that.\nAll stone seams can be seen and felt and granite will not match exactly at the seam. They will be around 1/8 of an inch wide. However, the goal of a good granite installation company is to make them as inconspicuous as possible.\nGranite weighs about 16 to 17 pounds per square foot.<br />\nThe stone countertops are places on the cabinets and, after ensuring everything is leveled, a bead of silicon is applied at the intersection of the cabinets and the underside of the stone. This is sufficient to hold the countertops in place in a normal situation. If the cabinets are not leveled, which is not uncommon, we have to place shims underneath the countertops to level them.<br /> To avoid shims the tops should be levelled to within 1/8 of an inch over 10 feet. We can install without this standard being met but will ask you to sign a waiver before we do it.\nNo. If you use 3cm (1 1⁄4”) thick granite, you do not need any special reinforcement. You may need some additional support in the corners of walls that our template specialist will be able to explain to you.\nNo, we do not level your cabinets. You will need the help of your carpenter or your contractor for that.\nWe are a production fabricator and our aim is to keep our costs low and our quality high. We ask that you look at the extensive selection in store and make some preliminary choices there. Then call us to make an appointment and we’ll gladly pull available colors from our inventory to show you. Because of the very wide range of colors available we don’t always have those colors in stock but will be happy to get them in for you to see before you commit.","Moh’s Scale of Hardness\nThere are two methods to measure the hardness of materials: scratch hardness and static load indentation hardness. Scratch hardness, also known as Mohs hardness, is a relative hardness and is rather rough.\nIt uses ten natural minerals as standards. The hardness order does not represent the absolute size of a particular mineral’s hardness, but indicates that a mineral of higher hardness order can scratch a mineral of lower order. The hardness of other minerals is determined by comparison with these standard minerals.\nThe unit of Mohs hardness is kilogram-force per square centimeter (kgf/cm²), denoted as [Pa]. It’s a standard for expressing a mineral’s hardness, first proposed in 1824 by German mineralogist Frederich Mohs. The hardness is represented by the depth of the scratch made on the surface of the tested mineral using the scratch method with a pyramid-shaped diamond needle.\nThe hardness scale is as follows: talc 1 (softest), gypsum 2, calcite 3, fluorite 4, apatite 5, orthoclase (also known as feldspar or periclase) 6, quartz 7, topaz 8, corundum 9, diamond 10 (hardest). Mohs hardness is also used to express the hardness of other solid materials.\nFor a more specific method: one would scratch the mineral to be tested against the standard hardness on the Mohs hardness scale to determine the hardness of the tested mineral.\nFor example, if a mineral can scratch calcite and be scratched by fluorite, then the hardness of that mineral is between 3 and 4. Alternatively, one can use a fingernail (hardness 2-2.5), a coin (hardness 3.5), or a small knife (hardness 5.5) to scratch the mineral in order to broadly determine its hardness.\n|Representative Mineral Names||Common Uses||Hardness Scale|\n|Talc, Graphite||Talc is the softest known mineral, commonly used in the form of talc powder.||1|\n|Skin, Natural Arsenic||1.5|\n|Nails, Amber, Ivory||2.5|\n|Gold, Silver, Aluminum||2.5~3|\n|Calcite, Copper, Pearls||Calcite can be used as carving material and industrial raw material.||3|\n|Fluorite (also known as Fluorspar)||Carving, Metallurgy, Building Materials||4|\n|Phosphorite||Phosphorus is an important component of biological cells; it is used as raw material in feed, fertilizer, and chemical production.||5|\n|Glass, Stainless Steel||5.5|\n|Orthoclase, Tanzanite, Pure Titanium||6|\n|Teeth (outer layer of crown)||The main component is hydroxyapatite.||6~7|\n|Soft Jade – Xinjiang Hetian Jade||6~6.5|\n|Pyrite||It is used as raw material for the production of sulfuric acid; gold refining; and can also be used in medicinal purposes.||6.5|\n|Hard Jade – Burmese Jadeite and Jade||6.5~7|\n|Quartz Glass, Amethyst||7|\n|Electric Stone, Zircon||7.5|\n|Quartz||According to the old hardness scale, quartz is rated as 7.||8|\n|Topaz, Chromium, Tungsten Steel||On the old hardness scale, topaz is rated as 8.||9|\n|Moissanite||Synthetic gems are 2.5 times brighter than diamonds and cost 1/10th of the price.||9.5|\n|Corundum||Corundum is rated as 9 on the old hardness scale. Natural gems such as rubies and sapphires are now considered types of corundum, as is the hardness of synthetic sapphire crystals.||12|\n|Diamond||Diamonds are rated as 10 on the old hardness scale, making them the hardest natural gem on earth.||15|\nWhat is Mohs Hardness?\nMohs Hardness is a standard that indicates the hardness of minerals, first proposed in 1824 by German mineralogist Friedrich Mohs. This standard is established by using a pyramid-shaped diamond drill to scratch the surface of a mineral, with the depth of the scratch indicating the hardness.\nThe hardness of a mineral refers to its ability to resist certain external mechanical forces such as scratching, indentation, or grinding. In mineralogy, the hardness often referred to is Mohs hardness, which is the scratch hardness compared to the Mohs hardness scale.\nThe Mohs hardness scale is based on ten minerals of different hardness, divided into ten levels from low to high: 1. Talc; 2. Gypsum; 3. Calcite; 4. Fluorite; 5. Apatite; 6. Orthoclase; 7. Quartz; 8. Topaz; 9. Corundum; 10. Diamond.\nIn use, standard minerals are scratched against minerals of unknown hardness. If the mineral can be scratched by apatite but not by fluorite, its hardness is determined to be between 4 and 5.\nThis method was established and named by German mineralogy professor Friedrich Mohs (1773-1839). However, accurate measurement of mineral hardness still requires a microhardness tester or hardness tester. Mineral hardness is also one of the physical properties of minerals. Minerals with high hardness have been widely used in industrial technology.\nDiamonds, corundum, and other minerals are not only used in industry, but also become precious gemstones. As gemstones, they usually have a high hardness.\nFor example, the hardness of opal is 5.5-6.5, quartz is 6.5-7, sphalerite is 7.5-8. Tsavorite is 8.5, and the hardness of sapphires and rubies is 9, second only to diamonds. People choose high-hardness minerals as gemstones, probably because they are wear-resistant, symbolizing their timeless value!\nAccording to needs, people have also developed a gem hardness scale to identify the mineral hardness of gemstones, from the softest to the hardest minerals: talc, gypsum, calcite, fluorite, apatite, zircon, corundum, silicon carbide, boron carbide, diamond, etc.\nWhen there is no standard hardness mineral, the simplest way to measure hardness is with a fingernail or a small knife. The hardness of a fingernail is 2.5, a copper coin is 3, and glass and a small knife are both 5. Those above 6 are almost all gemstone-like minerals."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:22f52520-a5e9-4460-b963-ec433be6194f>","<urn:uuid:6f5dff6d-ddef-43d0-937c-cbff7f05f328>"],"error":null}
{"question":"What are the characteristics of wind outflows from black hole Markarian 509? List key components and temperatures.","answer":"The wind outflows from Markarian 509's black hole consist of at least five distinct components. The winds are composed of cold, dense clouds of gas surrounded by hotter, more diffuse gas. The temperature of these components ranges between 20,000 and 1 million degrees Celsius. Most of the gas in these winds originates from regions approximately 15 light years away from the central black hole.","context":["Paris, 29 September 2011\nSupermassive black holes with masses several hundred million times that of the Sun are found at the center of most massive galaxies. Contrary to popular belief, they do not swallow up all the matter (gas and dust) that surrounds them. The gas and dust fall in towards the black hole, usually forming a disk that rotates around it. The infalling matter releases phenomenal amounts of radiation, mainly ultraviolet and X-rays. The emission of this radiation is sometimes so strong that it diverts part of this matter away from the black hole, forming winds that can reach several hundreds of km/s. However, the environment of supermassive black holes is still poorly known. What kind of matter surrounds them? Where and how are the nearby flows of matter formed?\nAn international team of astrophysicists has managed to observe, map and characterize, with hitherto unequalled precision, the environment of one of the brightest supermassive black holes known, located at the center of the distant galaxy Markarian 509. To obtain this unprecedented view of the central regions of Mkn 509, the researchers used five large space telescopes. The highlight of the campaign, carried out in 2009, was the repeated and simultaneous observation over a six week period of the radiation emitted by Mkn 509(3) right across the spectrum from visible to gamma-ray wavelengths, using ESA's XMM-Newton and INTEGRAL spacecraft.\nHot corona as energy converter\nFirst result: this supermassive black hole, whose mass is 300 million times that of the Sun, is surrounded by a disk of gas that emits ultraviolet radiation(4). The researchers observed a very hot gas (with a temperature of several million degrees Celsius) forming a corona hovering above the disk. The corona absorbs the ultraviolet radiation and re-emits it at higher energies, in the region of low-energy X-rays (radiation that is nonetheless several hundreds of times more energetic than visible light). The discovery of the existence of this very hot corona enables researchers to better understand observations performed for other active galaxies (galaxies that harbor supermassive black holes in their center), which were previously difficult to decipher.\nCold, dense gas clouds\nFor the first time, the scientists have shown that the outflow of matter blown away from the heart of Mkn 509 is made up of at least five distinct components, with temperatures ranging between 20 000 and 1 million degrees Celsius. They have also found that most of the gas present in these winds comes from regions located around 15 light years from the central black hole. The winds are made up of cold, dense clouds of gas surrounded by hotter, more diffuse gas.\nSigns of collision between galaxies\nIn addition, the researchers collected data on the interstellar gas of the host galaxy, Mkn 509. This gas is strongly ionized by the emission of X-rays coming from the central X-ray source: the atoms are stripped of most or all their electrons when irradiated by a powerful X-ray source. This has revealed the presence of the gas several hundred thousand light years from the central black hole. Falling towards Mkn 509 at a velocity of several hundred km/s, this gas may result from a past collision with a smaller galaxy, a collision that may have caused Mkn 509's current activity.\nThis consortium brings together 26 astrophysicists from 21 organizations across the world: Jelle Kaastra, Elisa Costantini, Rob Detmers, Jacobo Ebrero, Peter Jonker, Ciro Pinto, Eva Ratti, Cor de Vries from the Netherlands Institute for Space Research (SRON); Pierre-Olivier Petrucci, CNRS researcher at the Institut de Planétologie et Astrophysique de Grenoble (CNRS/Université Joseph Fourier), France; Massimo Cappi, Mauro Dadina (INAF-IASF, Bologna, Italy); Nahum Arav (Virginia Tech, USA); Ehud Behar (Technion, Israel) ; Stefano Bianchi (Roma Tre, Italy); Josh Bloom, Chris Klein (Berkeley, USA); Alex Blustin (University of Cambridge, UK); Graziella Branduardi-Raymont, Missagh Mehdipour, Rebecca Smith (UCL, UK); Jerry Kriss (STSI & Johns Hopkins University, USA); Piotr Lubinski (Torun, Poland); Julien Malzac, CNRS researcher at the Institut de Recherche en Astrophysique et Planétologie (CNRS/Université Paul Sabatier), France; Stéphane Paltani (ISDC, Geneva, Switzerland); Gabriele Ponti (Southampton, UK) and Katrien Steenbrugge (UCN, Chile & University of Oxford, UK).\nGas and dust swirling around a black hole. Although part of this matter is attracted by the black hole and will eventually be swallowed up, another part is blown away, forming winds.\n1 - In France, the two laboratories involved are the Institut de Planétologie et Astrophysique de Grenoble (CNRS/Université Joseph Fourier) and the Institut de Recherche en Astrophysique et Planétologie (CNRS/Université Paul Sabatier). These works were partly funded by CNES. The main INTEGRAL instruments (SPI and ISGRI) used in this campaign were developed by CNES and CEA, which are also involved in their in-flight calibration and monitoring.\n2 - European Space Agency.\n3 - The LETG spectrometer on NASA's Chandra X-ray satellite and the COS spectrometer on the Hubble Space Telescope were used to complete these observations. The Swift X-ray satellite was also used prior to and following these observations in order to monitor the behavior of the source before and after the campaign.\n4 - Radiation that is a little more energetic than visible light, but far less energetic than X-rays.\nThe first results of this campaign will be published as a series of 7 articles in the journal Astronomy & Astrophysics from 29 September 2011. Other papers are in preparation.\nThese seven articles can be downloaded:\nI: View web site\nII: View web site\nIII: View web site\nIV: View web site\nV: View web site\nVI: View web site\nVII: View web site\nLatest press releases"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:0090e14d-d541-4c0f-867e-7039b5910671>"],"error":null}
{"question":"Could you tell me how the rotation rate affects the current in electrochemical experiments with rotating electrodes?","answer":"In electrochemical experiments with rotating electrodes, higher rotation rates lead to higher limiting currents. Under hydrodynamic conditions with laminar flow, the current increases until reaching a limiting value where the rate of the redox reaction equals the rate of mass transport, creating a plateau in the voltammogram. This limiting current value remains constant until the reaction is complete and is directly proportional to the rotation rate of the electrode.","context":["Electrochemical experiments are generally performed in cells with quiescent electrolytes. This means that the motion of molecules and ions is imparted by the natural convection process. However, forced convection is sometimes necessary in electrochemistry. In these situations, the use of rotating working electrodes is beneficial to generate forced convection. With forced convection, hydrodynamic conditions are created where the working electrode and electrolyte are in relative motion.\nWhich applications benefit from using rotating electrodes?\nTo answer this question, we will first take a deeper look at the difference between quiescent solutions and hydrodynamic conditions. Then, after spotting the differences between laminar and turbulent flow, three main rotating electrodes and their suggested applications are highlighted.\nThe current measured at the working electrode is the result of redox reactions between electrons and reactants at the electrode–electrolyte interface. The reactants are brought to this interface by mass transport.\nThe mass transport is created by three processes:\n- Diffusion from concentration differences between the bulk electrolyte and the interface.\n- Migration due to the presence of an electrostatic potential. The migration is usually neglected by adding a supporting electrolyte to the solution which does not participate in the redox reaction but increases the conductivity of the electrolyte.\n- Natural convection from density changes inside the solution. This process occurs in quiescent solutions.\nDuring the electrochemical oxidation of a species in solution, mass transport occurs at a rate higher than the charge transfer rate of oxidation. The charge transfer increases along with the measured current. This phenomenon occurs until the two rates reach equal values, and therefore the current reaches a maximum value. Afterwards, the mass transport is slower than the charge transfer, resulting in a decrease of current.\nThe voltammogram resulting from these phenomena shows a peak in the current.\nFor example, Figure 1 shows the resulting voltammograms of different scan rates during the oxidation of Fe+2 to Fe+3 in a quiescent ferro-ferri solution.\nHere it can be seen that the higher the scan rate is, the higher the peak current.\nIt is possible to force convection in the cell by rotating the working electrode. The rotation induces a swirling motion in the electrolyte. The forced convection increases the mass transport of reactants at the interface and, in parallel, removes the products from the interface.\nDuring an electrochemical reaction under hydrodynamic conditions with laminar flow, the current increases until the mass transport occurs at a rate faster than the reaction rate. The current eventually reaches a limiting value where the rate of the redox reaction and the rate of mass transport are equal, resulting in a plateau in the voltammogram. This limiting value remains constant until the reaction is complete. The limiting current is proportional to the rotation rate of the electrode, as shown in Figure 3, where the oxidation of Fe+2 to Fe+3 under hydrodynamic conditions is investigated.\nIn this case, the higher the rotation rate is, the higher the limiting current.\nThe rotating disk electrode (RDE) is a cylinder with a disk used as the active surface. This disk is composed of a metal, glassy carbon, or an alloy (Figure 5).\nGlassy carbon is used in electrocatalysis since it is an inert electrode for hydrogen reduction and supports catalysts adsorbed or deposited on its surface.\nRDEs are employed to generate laminar flow, and are often used in fundamental electrochemistry experiments to investigate the properties of electrolytes. They are also utilized in electrocatalysis studies to measure the performance of catalysts and in sensors to investigate the detection mechanism.\nThe rotating ring disk electrode (RRDE) is a cylinder with two active surface areas which both act as working electrodes (Figure 6). One working electrode is a disk made of platinum, gold, or glassy carbon. The second working electrode is a ring of platinum.\nLike the RDEs discussed in the previous section, RRDEs are also employed to generate laminar flow. Researchers use RRDEs mainly in electrocatalysis experiments to measure the performances of different catalysts. RRDEs are also used to study reaction mechanisms. For example, the production of hydrogen peroxide during the oxygen reduction reaction is studied by detecting reaction intermediates. The RRDE also plays an important role in the study of electroplating.\nThe rotating cylinder electrode (RCE) is a cylinder with a metallic insert that serves as its active surface (Figure 7).\nRCEs are used mainly in corrosion studies to exploit the turbulent flow generated along the RCE, since there is a similarity between the turbulent flow along the RCE and the turbulent flow inside a pipeline of specific thickness and diameter. For example, one common use of the RCE is in the petrochemical industry to investigate the effect of different corrosion inhibitors on the pipelines, either by using linear polarization (LP) or electrochemical impedance spectroscopy (EIS) techniques.\nElectrochemical studies requiring hydrodynamic conditions can be performed with rotating working electrodes to create forced convection in the measurement cell. Both laminar flow and turbulent flow conditions are able to be created in laboratory settings in order for researchers to perform different studies. The Rotating Disk Electrode (RDE) and Rotating Ring Disk Electrode (RRDE) are suitable for creating laminar flow, while the Rotating Cylinder Electrode (RCE) is the choice for making turbulent flow conditions.\nRDEs are commonly used to study electrolyte properties, catalyst performance, and to investigate the detection mechanism in sensors. RRDEs are also used to study catalyst performance as well as electroplating and reaction mechanisms. RCEs are mostly used in pipeline corrosion studies and for investigating the behavior of protective coatings."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:c2274230-680b-4b5d-933b-d719ddc3ec2e>"],"error":null}
{"question":"Could you please compare the process of diagnosing food allergies through oral food challenges with the standard practices used by Anaphylaxis Canada? I'm interested in understanding how these approaches differ in terms of safety and effectiveness.","answer":"The oral food challenge is considered the current gold standard for diagnosing food allergies, though it carries risks with about 2% of challenges resulting in anaphylaxis. The process involves patients consuming increasing amounts of a suspected allergen over several hours in a controlled setting, either at an allergist's office or hospital. While Anaphylaxis Canada works with medical advisors and allergists across the country to guide their programs and services, they focus primarily on education, support, and advocacy rather than diagnostic procedures. They emphasize prevention through effective ingredient label reading, special food preparation precautions, and proper hand washing to avoid allergic reactions.","context":["Anaphylaxis Canada is a non-profit organization dedicated to helping those at risk for anaphylaxis and those who care for them. We are committed to creating a safer world for people with food allergies through research, education and advocacy.\n- The organization was officially founded in 2001, with the merging of two groups: The Anaphylaxis Network of Canada and The Anaphylaxis Foundation of Canada. Today, Anaphylaxis Canada is the country's leading advocacy and education organization for individuals and families at risk from a severe allergic reaction.\n- With staff in Toronto, Ontario and Kamloops, BC, and volunteers across the country, Anaphylaxis Canada delivers vital information, innovative programs and important services to more than 10,000 individuals per year.\n- Anaphylaxis Canada works closely with medical advisors - allergists from across the country - who help guide the programs and services we offer as well as the advocacy positions we take.\n- We offer a range of educational and allergy management programs and services. For more information on these programs and services go to the Educators section.\nA society that is safe for people living with life threatening allergies through well informed, supportive and responsive communities.\nTo educate, support, and advocate for the needs of individuals and families living with anaphylaxis, as well as to support and participate in research related to anaphylaxis.\n- People-centric - We believe in self-management and we strive to understand the perspectives and realities of people living and dealing with life-threatening allergies.\n- Empowerment - We believe people need to be empowered in order to make positive decisions that reduce the risk of anaphylaxis.\n- Balanced Approach - We believe in a research-based and pragmatic approach to dealing with life-threatening allergies. We look for win-win solutions and avoid \"all or nothing\" approaches.\n- Collaboration - We believe the best approach to creating safer, healthier communities is to partner with other like-minded organizations and individuals.\n- Leadership - We believe in always producing top quality resources. We are also not afraid to make our voice heard and lead on important issues and initiatives.\nAbout Food Allergy and AnaphylaxisKey facts:\n- Food allergy is a growing public health issue in Canada.\n- There is no cure; avoidance of an allergenic food is the only way to prevent an allergic reaction.\n- Approximately 2.5 million Canadians self-report having at least one food allergy.*\n- The incidence is highest amongst young children (under 3) with close to 6% affected by food allergy.\n- Peanut allergy in Canada affects about 2 in 100 children.\n- About 300,000 Canadian children under 18 years have food allergies.\n- According to recent studies in the US, it appears that the incidence of peanut and tree nut allergy among children has tripled (1997 to 2008).\n- One in two Canadians know someone with a serious food allergy.\n- More than 40% of Canadians read food labels looking for allergen information.\n- In 2005, the Government of Ontario passed Sabrina's Law, requiring all school boards in the province to establish and maintain an anaphylaxis policy. Other provinces including Alberta, British Columbia, Manitoba and Newfoundland, have legislation or guidelines similar to Sabrina's Law.\nQ and A\n- What is anaphylaxis?\n- What are the signs of an anaphylactic reaction?\n- What causes an anaphylactic reaction?\n- What are the most common food allergens in Canada?\n- How much of a food allergen does it take to cause a reaction?\n- Can someone have a reaction without ingesting their allergen?\n- Can someone who is allergic to a food have an allergic reaction after kissing someone who has eaten that food?\n- How are allergic reactions avoided?\n- Why does food allergy seem to be on the rise?\nAnaphylaxis (pronounced anna-fill-axis) is a serious allergic reaction that is rapid in onset and may cause death. An allergen is a substance capable of causing an allergic reaction. Upon first exposure, the immune system treats the allergen as something to be rejected and not tolerated. This process is called sensitization. Re-exposure to the same allergen in the now sensitized individual may result in an allergic reaction that, in its most severe form, is called anaphylaxis. (Source: www.allergysafecommunities.ca)Back to Q and A list\nWhat are the signs of an anaphylactic reaction?\nAn anaphylactic reaction can involve any of the following symptoms, which may appear alone or in any combination, regardless of the triggering allergen:\n- Skin system: hives, swelling, itching, warmth, redness, rash\n- Respiratory system (breathing): coughing, wheezing, shortness of breath, chest pain/tightness, throat tightness, hoarse voice, nasal congestion or hay fever-like symptoms (runny itchy nose and watery eyes, sneezing), trouble swallowing\n- Gastrointestinal system (stomach): nausea, pain/cramps, vomiting, diarrhea\n- Cardiovascular system (heart): pale/blue colour, weak pulse, passing out, dizzy/lightheaded, shock\n- Other: anxiety, feeling of \"impending doom\", headache, uterine cramps, metallic taste\nBecause of the unpredictability of reactions, early symptoms should never be ignored, especially if the person has suffered an anaphylactic reaction in the past. It is important to note that anaphylaxis can occur without hives. (Source: www.allergysafecommunities.ca)Back to Q and A list\nWhat causes an anaphylactic reaction?\nFood is one of the most common causes of anaphylaxis, but insect stings, medicine, latex, and exercise can also cause a reaction.Back to Q and A list\nWhat are the most common food allergens in Canada?\nThe most common food allergens are: peanuts, tree nuts, seafood (fish, shellfish, crustaceans), egg, milk, sesame, soy, and wheat. The government considers these \"priority\" allergens for labelling purposes. From August 2012, mustard will be added to this list.Back to Q and A list\nHow much of a food allergen does it take to cause a reaction?\nEven a very small amount 'hidden' in a food or a trace amount of an allergen transferred to a serving utensil has the potential to cause a severe allergic reaction.Back to Q and A list\nCan someone have a reaction without ingesting their allergen?\nInhalation of airborne peanut protein can cause allergic reactions, though usually not systemic anaphylaxis. The odor alone has not been known to cause an anaphylactic reaction. Direct ingestion of an allergy-causing food poses the greatest risk for the sensitized individual.Back to Q and A list\nCan someone who is allergic to a food have an allergic reaction after kissing someone who has eaten that food?\nIndividuals with food allergies are at risk of having a reaction from kissing someone who has recently eaten a food allergen. People at risk need to tell their friends and partners about their food allergies to avoid accidental exposure.Back to Q and A list\nHow are allergic reactions avoided?\nEffective ingredient label reading, special precautions for food preparation, proper hand washing and cleaning go a long way toward reducing the risk of an accidental exposure. An allergic reaction can usually be treated effectively with a prompt injection of epinephrine/adrenaline (e.g., EpiPen® or Allerject).Back to Q and A list\nWhy does food allergy seem to be on the rise?\nOne theory, known as the \"hygiene hypothesis\", suggests that people living in western countries are living in cleaner and more sanitized environments. The immune system - exposed to fewer germs than our bodies are used to dealing with - mistakenly identifies certain foods as harmful. Genetics also play a role in the development of food allergies. For example, if one parent has allergies, their child has a greater risk of developing allergies as well.Back to Q and A list","What's up? The FARE FAITH Challenge\nFood allergies affect up to 32 million Americans, approximately 8% of those younger than 18. Approximately 170 foods have been reported to cause food allergies, of which 9 account for 95% of reactions — eggs, crustacean shellfish, fish, milk, peanuts, seeds (e.g., sesame), soy, tree nuts and wheat.\nDiagnosing food allergy is an imperfect process. Physicians use a combination of patient histories, skin testing, blood testing, and sometimes oral food challenges to diagnose food allergy. The oral food challenge is the gold standard for diagnosing food allergy.\nIt can take families months (even years to depending on the provider), to bubble up to the top of a wait list for an oral food challenge. Then parents may need to take time off from work and children may need to miss a day of school to undergo the challenge which often takes the better part of a day. As a parent, you are also sometimes tasked with preparing the food your child will consume during the challenge.\nSometimes food challenges are conducted at an allergist's office. Sometimes they are conducted in a hospital setting. During a food challenge, a patient is dosed with a known (or suspected) allergen over a period of hours until either a reaction occurs, or not. If a reaction occurs, the patient has 'failed' the challenge and is allergic to the allergen he/she consumed. If no reaction occurs, the patient has 'passed' the challenge and is not allergic to the allergen he/she consumed.\nAbout 2% of oral food challenges result in anaphylaxis: hundreds of thousands of these test are administered annually, meaning thousands of patients experience this adverse, life threatening testing outcome.\nThe food challenge process can be a nail-biting experience for both patients and their families.\nImagine having to repeatedly take small bites of a food that has made you really sick in the past, or that you suspect has made you sick in the past.\nImagine taking small bites again and again over hours, fearing that the next bite will be the one that makes you react, not knowing how serious that reaction might be (a couple hives? vomiting? anaphylaxis?)\nImagine the deep disappointment when the test is discontinued because a reaction occurs. While the patient and their family do gain some clarity about the food allergy (yup, not outgrown! yup, still allergic! yup, still really allergic), the mental and emotional toll can be considerable.\nThe FARE FAITH Challenge is a multi-year competition designed to put an end to oral food challenges and create a new, safe and compassionate method to accurately diagnose patients with food allergies. According to Lisa Gable, Fare's CEO, the \"FAITH Challenge is designed to galvanize the best researchers and innovators in the world to action – alone or in collaboration – to reach a breakthrough solution to the food allergy testing problem.\"\nFARE has built a $3 Million war chest for the research competition with generous donations from corporate and private donors. As per FARE's fact sheet:\nA $1 million cash prize will be awarded to the team – or teams – that successfully designs a new gold standard diagnostic tool for food allergies. Interim diagnostic advancements will also receive interim cash awards from a total FAITH funding pool of $3 million.\nFAITH seeks to bring together the world’s most insightful and creative researchers from food allergy and immunology, biopharma and healthcare. Researchers in adjacent disease research categories are encouraged to join the FAITH Challenge.\nResearch submissions will be reviewed, tracked and appraised by a panel of judges comprising experts in the fields of food allergy and immunology from both academia and the private sector.\nThis competition and the outcome will be one to keep an eye on. Thank you, FARE, for spearheading this initiative!\nMore details are available here.\nAllergy Force seeks to keep the food allergy community updated on research initiatives that have potential — now and in the future — to help them live fully with less fear, less anxiety and more confidence.\nImage Credit: Image compiled from FARE website imagery."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:ce485c26-13b9-45d1-917f-85197229fd1c>","<urn:uuid:3959fa7a-2a9a-464c-861a-09731aaf46b9>"],"error":null}
{"question":"What are the scale lengths of the Fender Pawn Shop Super-Sonic and Gibson L-5 guitars? How do they compare?","answer":"The Fender Pawn Shop Super-Sonic has a shorter scale length of 610mm/24-inch, while the Gibson L-5 has a scale length of 24.9 inches. The Super-Sonic's shorter scale length is borrowed from the Jaguar and is specifically described as string-bend-friendly.","context":["Fender Pawn Shop Super-Sonic\nThe Fender Pawn Shop Super Sonic actually resurrects a short-lived model first seen in 1997 bearing the Squier brand name. Back then, it formed part of the new Vista series and originated from Japan; second time around, it's a fully fledged Fender that's made in Mexico.\nUnlike most other Pawn Shops, this model stays pretty true to its roots, so presumably the original design was deemed adventurous enough, and there can be few arguments on that score.\nAs on the earlier Super-Sonic, the lefty-look, large headstock comes complete with a protruding 'bullet'-style truss rod adjuster, but now only one string guide is considered sufficient. The vintage-style Kluson copy tuners differ to those used on Pawn Shop stablemates such as the Jaguarillo and Offset Special, because the post tops have deeper slots, making restringing an easier job.\nThe nut slots are consistently well cut depth-wise, but uneven spacing puts the strings slightly off-centre down the lightly radius'd rosewood fingerboard. The latter borrows the Jaguar's string-bend-friendly shorter scale length (610mm/24-inch) and a 22-strong fret count. The easy feeling fret ends offer a worn-in feel that's maintained by a C profile maple neck, which is gloss finished in vintage fashion.\n\"High-end access to the fingerboard is good, because most of the neck is clear of the body\"\nClay-like position dots are equally old-time, replacing the earlier version's pearloid markers, while side markers are sited along the fingerboard join in time-honoured manner. As usual, this makes them difficult to see - black dots set in the maple neck would be more practical, echoing some 70s Fenders.\nThe original Super-Sonic employed a basswood body, but these days, Fender seems quite coy about stating specific body timber details. Presumably, this is now alder, as used on the other Pawn Shop models, but it's hidden under a sparkly Sunfire Orange Flake finish.\nMatching the neck, this model's body styling is lifted from the Jaguar and similarly reversed to create the left-handed look, but the overall decreased dimensions contribute to a more compact shape. Unlike some other 'upside- down' designs, high-end access to the fingerboard is good, because most of the neck is clear of the body. As before, a curved heel block serves to accommodate a small, angular neckplate that actually still sports the Squier 'S' logo.\nThe neck extends under the scratchplate to ensure secure anchorage, while one of the four fixing screws doubles as the upper strap-button holder.\nThe off-white scratchplate carries a three-way toggle pickup selector switch plus two Fender Atomic humbuckers, which provide the biggest visual difference between old and new Super-Sonics. Here, both pickups are mounted at a backward angle, not just the bridge pickup as on the original version. In addition, height adjustment is now via three screws rather than two, while the exposed bobbins are black and cream, instead of all black. Controls still sit on a separate metal plate and comprise two volume pots topped with Jaguar-style knobs.\nAdding a Strat ingredient to the mix, the vintage-style vibrato unit is another constant factor, featuring bent steel saddles and a screw-in arm. The feel is responsive, but tuning drift is very apparent after a quick waggle or two with string-bending. A few tweaks will be required here.\n\"This one is undoubtedly intended to be up front and dirt-friendly\"\nThe Atomic humbuckers are very potent components, staying true to their title output-wise, while the tonal character borders on brash and brutal, with an aggressive edge guaranteed to slice through the thickest mix. This comes across very strongly in all three pickup positions, although the both-on option adds some unusual honky overtones.\nThe previous Super-Sonic could be a quite subtle performer, but this one is undoubtedly intended to be up front and dirt-friendly, maintaining impressive definition even under heavy distortion conditions.\nThe volume controls clean up the sound as they should, but a tone control would be handy to tame the rather unremitting attack. Like the original Super- Sonic, the layout reverses normal logic, since the nearest knob governs the bridge humbucker. The pickup selector is equally 'upside down' in operation, and when set to the centre position turning either volume off eliminates output entirely, so it can't function as a kill switch.\nAttention-grabbing appearance. Easy feel.\nPitch return problems. Circuitry quirks.\nThis revives a decidedly original Squier design and adds a few updates to add appeal for the modern market.\nScale Length (Inches)\nNo. of Frets\nVintage-type vibrato, vintage-style tuners\nCountry of Origin\nString Spacing (In)\n2x volume, 3-way selector\nScale Length (mm)\n2x Fender Atomic humbuckers\nReverse offset double-cutaway solidbody electric\nSunfire Orange Flake, Apple Red Flake, Dark Gunmetal Flake","Home / Instruments /Accessories / Ordering / Tips / Friends\nGibson 1928 L-5\nPrice and Status: For pricing and hold status of this instrument, please check here. If this instrument does not appear on the Instruments page it has been sold. To be notified of examples of this or any other model in the future, please email your specific requests to [email protected].\nSerial #: 85578, white oval label.\nBody size at lower bout: 16\". Scale length: 24.9\" Nut Width: 1 3/4\"\nMaterials: Handcarved bookmatched solid spruce top; solid bookmatched tiger flame maple back and sides; solid three piece maple neck with walnut centerstripe; solid ebony fingerboard; mother of pearl script peghead logo and fingerboard inlay, abalone flowerpot peghead inlay; triple bound fingerboard, body, peghead and pickguard.\nHardware: 20's vintage hardware includes engraved gold Waverly 3-on-a-plate tuners with grained ivoroid buttons, compensated Gibson adjustable ebony bridge, gold Gibson trapeze tailpiece. Vintage correct triple bound dark tortoise pickguard.\nNotes: Making it's debut in 1922, the Gibson L-5 was created by the legendary Lloyd Loar, father of the renowned F-5 mandolin. One of the most influential instrument designers of the 20th century, Loar pioneered a number of key innovations, including very early work on the electric guitar. The Gibson L-5 is perhaps his most influential creation, and is widely regarded as the first successful commercially produced archtop guitar. Now in its eighth decade, it remains the most famous jazz guitar of all time.\nOf all model years for the L-5 to date, the year 1928 has been the one most requested here over many years. Instruments built in this year possess a neck profile that is uniquely sought after by players for its graceful light D contour. Distinctly slimmer in depth than Loar era versions, the '28 neck also avoids the harder V shape found in the later 16\" L-5. 1928 is also the last full year for the classic dot fingerboard, with its understated elegance. Finally, the tone of these guitars is simply legendary, with a matchless blend of warmth, clarity and astounding projection.\nBuilt early in the year, this instrument, #85578, would have been one of the last to bear the oval Master Model, a portion of which remains visible inside the bass soundhole. (An additional oval Gibson label is affixed as well, and is stamped with the serial number, presumably from a trip back to the factory in the '30s.) Weighing in at just 5 lb. 1 oz. (2.3kg) the guitar is notably lightweight and well balanced, showing fine tiger maple figure in the back, sides and neck, with a graceful Cremona sunburst finish. Well played and well maintained, the instrument is in fine shape, without pick, buckle, thumb or fingerboard wear. Both soundboard and neck are without cracks of any kind, and a single grainline crack on the back lower treble bout has been soundly resealed. Near the treble foot of the bridge a slight groove in the top is visible from an old DeArmond control box, and the outline of an old jack hole has been immaculately resealed in the side. The finish shows some light older overspray, now showing fine scattered checking of its own.\nThe tuners are 20's vintage Waverlys with grained ivoroid buttons and hand engraved backplates, very similar to the originals, and the gold trapeze tailpiece is of similar vintage. The triple bound dark tortoise pickguard is made from an original template, with thick true nitro stock and grained ivoroid binding. Action is smooth and low over fresh vintage style fretwork, a full 1 3/4\" nut, and a fine recent ebony fingerboard. With its finely carved soundboard played-in for some 80 years, the instrument possesses a depth and resonance uncommon in a 16\" body, with exceptional bass response and a pronounced natural reverb in the treble register. This unique combination of power and refinement demonstrates why these guitars have been so widely imitated, but never improved upon.\nSetup: The frets have been precision leveled, recrowned and polished as necessary; trussrod tension and neck relief adjusted; bridge height adjusted; bridge compensation set; string slots at nut and bridge inspected and recut as necessary; bridge foot contour inspected and fit to top as necessary; bridge radius inspected and recurved as necessary; bridge wheels and tuners lubricated; fingerboard and bridge oiled; body and neck cleaned and hand polished.\nThis instrument is strung with medium gauge bronze strings (.013-.057). The guitar will accommodate lighter or heavier gauge strings, according to preference. String action is set at 5/64\" to 6/64\" at the 12th fret, with moderate relief for acoustic playing with medium strings. The action may be lowered or raised to your requirements with the adjustable bridge.\nCase: Original black Gibson hardshell case."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:2bcb5ca8-1b40-4a4d-bb3f-5d257f3379aa>","<urn:uuid:ed46195c-fe17-4457-acc6-c1bb212cd45d>"],"error":null}
{"question":"Please provide a structured comparison of the advocacy strategies employed by K.C. Boyd versus Melissa Thom for promoting the importance of school libraries.","answer":"K.C. Boyd advocates through high-profile engagement, serving on committees like the 2020 Newbery Awards Selection Committee and maintaining a strong online presence through her blog 'The Audacious Librarian.' Melissa Thom takes a more local and organizational approach, serving as Vice President of the Connecticut Association of School Librarians and actively participating in multiple content area organizations like the Connecticut Reading Association and Geographic Alliance. She emphasizes daily advocacy by regularly sharing library achievements with principals and district leaders.","context":["Public speaking events for K.C. Boyd, Library Media Specialist #KC_SaidIt\nSchool librarian and activist K.C. Boyd on libraries, pandemic and racial justice movement. Collaborating for School and Public Library Partnerships. The Librarian Influencers Podcast: The School Librarian Is an Equity Champion: with K.C. Boyd. The Hidden Figure: Your School Librarian. Black Writers Weekend - Black Librarians Speak Out. Episode 5: K.C. Boyd. Library Love Fest - Door to Door: Discussing Anti-Racism Reads. Librarians Wear Many Hats. BCALA ‘Plant A Book, Grow A Reader 8.16.20. A Virtual Town Hall for #DCPS Library Media Specialists Sponsored by the Washington Teachers Union. #DCPS Library Media Specialist ‘Townhall Meeting’ sponsored by the Washington Teachers’ Union. (27) The Power of Your School Librarian in COVID-19 World: Harnessing Technology, Literacy, and Community.\n(4) Facebook. (4) Facebook. Indiana Connected Educators - Indiana Connected Educators LIVE- K.C. Boyd. Moving Multicultural Collections Online. In the age of COVID-19, how can library workers help students and patrons access diverse collections?\nIn a June 26 session at ALA Virtual, two panelists discussed the challenges and strategies of doing just that. As part of the Ethnic and Multicultural Information Exchange Round Table (EMIERT) Chair’s Program, the session, “Promoting Multicultural Library Services in Virtual Spaces,” was moderated by EMIERT Vice Chair Andrea Jamison, librarian and lecturer at Valparaiso (Ind.) University. In physical spaces, said Jamison, libraries can display books, create signage, and read aloud about different communities and cultures. How can they continue to advocate for diverse groups now that programming and services have moved online during the COVID-19 pandemic?\nBCALA Virtual Summit - Marketing and Branding Your Library Media Cent… EMIERT Chair Program Promoting Multicultural EDI Librarianship in Vir… Not All Heroes Wear Capes. From instructional videos to curated online collections, today’s librarians are forging new pathways to learning and discovery amidst the disruption of a pandemic.\nGUEST COLUMN | by Tina Davis As school districts across the country closed their doors in response to the COVID-19 pandemic, the race was on to find ways to connect teachers and students with as little disruption to learning as possible. The response by most districts was swift: move teaching and learning online. While getting there brought some pain and frustration, many of today’s education professionals are finding new opportunities as they transition to doing school online. And while much of the focus has been on how teachers will deliver curriculum to students from afar, there’s an essential link connecting them: librarians. “Especially in this time of uncertainty, librarians have never been more critical to the nation’s schools,” says Bill Bass, Innovation Coordinator for Parkway School District in Missouri. K.C. Boyd, School Librarian, Answers Our Questions!\nBoyd is a well-known figure in the library world. Some were introduced to her when she was named 2015 Library Journal Mover & Shaker, some from her outstanding blog, The Audacious Librarian, and some when she appeared on the cover of School Library Journal. What quickly becomes clear, however, when exploring K.C. Boyd’s vast online presence is that at its core is an irrepressible dedication to the success of her students; it is obvious that any fame Ms.\nBoyd has achieved is secondary to the work she does on a daily basis to encourage literacy among our youth. Enjoy the interview! Perspectives – K.C. Boyd. Perspectives, an interview series that will highlight the work of librarians in different fields and professional specializations.\nOur series will focus on the experiences of our participants, what they do, what they have learned, and offer advice to those interested in librarianship and various fields. To our readers, our committee hopes this column will highlight the valuable labor these individuals perform on an everyday basis. Our interviews will provide perspective on what labor in these fields entails and current issues that affect librarianship, employment, etc. On behalf of the Communications Committee, we hope you find this new column illuminating, informative, and inspiring! What aspects of your job do you enjoy the most? There are countless things that I enjoy about my job. Can you describe a memorable moment in your career? The most memorable moment in my career was when I served on the 2020 Newbery Awards Selection Committee. What kinds of professional development do you do? (27) Door to Door 6/11/2020: Anti-Racism Reads. (27) AASL Office Hours. (27) Ensuring Equitable Digital Access. School Librarians United with Amy Hermon: My Newbery Experience: K.C. Boyd.\nSchool Librarians United with Amy Hermon: #GoodTrouble and Advocacy. School Librarians United with Amy Hermon: Boss Librarian: K.C. Boyd. (6) Boss Librarian Read Aloud Time #5. (6) Boss Librarian Read Aloud Time #4. (6) Boss Librarian Read Aloud #3 and DC Public Library eBook Catalog Tutorial. (6) Boss Librarian Read Aloud Time #2. (6) Boss Librarian Read Aloud Time #1. Tech-Savvy Librarian Maintains Her Heart for Literature. K.C.\nBoyd is a Library Media Specialist for the District of Columbia Public Schools and is affectionately called “Boss Librarian” by her students—a nickname that grew so much in popularity, it led her to use it as her Twitter handle. Boyd is looking forward to the 2020 Future of Education Technology Conference (FETC) in Miami this coming January, where she will be presenting in the new Library Media Specialist Track. Over 20 years ago, when Boyd was busy pursuing her Master’s degree in Library and Information Science (MLIS), librarians were focused on the literature and curriculum side of the job. But over the last seven to eight years, she has witnessed a movement toward greater and greater incorporation of technology. “It started, at first, with the research databases; now, it’s morphed more deeply into using handheld devices, personalized devices, and into Makerspace communities within a school.”\nAbout K.C. Event Registration. Our popular series returns with all-new presentations, from spreading the word about your library (aka marketing) and makerspace tips from the pros, to the lowdown on grants and how to get them.\nLed by top practitioners in the field, these one-hour free programs will offer practical insight into these hot topics, with implications for schools and libraries. Session 2: Lessons from Model Makerspaces Hands-on, experiential learning has never been more relevant. A core conduit to STEM education and skill development, maker activities can also foster collaboration, persistence, and critical thinking.\nLearn best practices from our stellar panel, including how to design relevant programming to engage everyone in your community.","Teacher Librarian Melissa Thom Roars\nWelcome to Library Lions Roar, celebrating libraries and the outstanding librarians serving youth in schools and public libraries across the U.S. since 2010. Today we welcome Teacher Librarian Melissa Thom for part one of her two-part interview with us. Welcome, Melissa!\nI am extremely grateful to be the Joyful Teacher Librarian at Bristow Middle School in West Hartford, Connecticut.\nOver the previous three years, I have worked hard to build positive relationships with the staff and students to create an open and welcoming environment where all learners can find just what they need when they need it. As one student put it, “there’s something for everyone!” Some areas of our Library and Makerspace include a take apart station, building and creating area, an area that changes based on the current theme of makerspace, a stationary bike where one can ‘Read and Ride’ (http://www.readandride.org/), and a self checkout station where students can search and check out books they want to read.\nPhotos: Take Apart Station. Building and Creating Area\nPhoto: Read and Ride and Makerspace theme area\nOne aspect of my job that I love the most is the connections with students and teachers I make on a daily basis. One the first day of school, my principal, Steve Cook, couldn’t wait to tell me he read 7 books over the summer. Then he thanked me for pushing him to become a more active reader. I am so fortunate to have a supportive principal who believes that the library should be “heartbeat of the school.” He has made sure that my building-based budget has remained constant through all of the financial turmoil our district and state has experienced over the past couple of years and is one of those principals who not only supports my efforts in creating both a schoolwide culture of reading and a vibrant Makerspace, he is also an active participant and promoter of it!\nPhotos: Melissa and principal Steve Cook. And Principal Cook with Solo book\nI love sharing my deep (and at times obsessive) passion for books, authors, and knowledge. This year I am creating and promoting #BristowReads with both staff and students on Twitter and Instagram. I am hoping that it will go viral–both in our school and throughout the greater book community! To get started, I created a #BristowReads bulletin board in the school’s main lobby and have invited all members of the staff to participate. This includes the adults who work in the cafeteria and the office, the custodians, the psychologist, and the interpreter who is there only one period of the day. EVERY adult in the building should be given the opportunity to participate. I have only been working on it for three days and everyone is buzzing about it! In a couple of weeks, I plan to invite students to participate in a similar bulletin board that will be in the library.\nTeachers Favorite Books Bulletin Board\nI love that every day is different in my space and that I have access to all teachers, students, and content areas. I love finding curriculum connections between different topics and grade levels, often acting as a bridge by helping them make connections with the information since classroom teachers can be somewhat isolated in their day-to-day teaching and not have much common planning time. I love sharing lesson ideas, project resources, and both book titles and tech tools. For example, last year, I collaborated with 8th grade Social Studies on National History Day, 7th grade Science on Genius Hour, 6th grade Language Arts on book tastings at the beginning of each genre study, and 6th grade Social Studies on Oral Histories. Visit here for some photos of the suitcases that students created in the Makerspace as a culminating project for their oral history interviews.\nWhen I created the Take Apart station in my Makerspace, I thought it would be a good idea to add a small hammer to the basket of tools. Turns out, that wasn’t such a wise decision. One afternoon about a week into having it, I looked up and saw a student with the hammer held over his head ready to bring it crashing down on the glass top of an old projector. As I sprinted across the library to try to stop him, it felt like everything was happening in slow motion. Thankfully, I stopped him and we avoided a major catastrophe! In the calmest voice I could muster at the time, I reminded the students standing around the table that the goal was to TAKE APART the electronics–not DESTROY them!\nThe moral of the story–I suggest leaving the hammer in the toolbox in your desk! 😉\nA Lion’s Pride of Programs\nOne of my favorite themes in the Makerspace last year was the “Make a Difference” theme in February and March. The main activity that took place was the creation of fleece blankets that were donated to Project Linus. I want to give a shout out to a couple of my favorite teacher librarians, Kristina Holzweiss (https://twitter.com/lieberrian) and Gina Seymour for the inspiration to turn the Bristow Makerspace into a place where students and adults could come to help make positive changes and contributions to the local and global community. This coming year I have received a West Hartford Foundation grant for $740.00 to make and donate more blankets!\nAt the end of last school year, I organized a Bristow Book Swap.\nA Mighty Roar!\nLibraries and certified teacher librarians should be considered a vital ingredient in any recipe that hopes to ‘make’ and develop future ready, media literate, civic-minded, and action-oriented citizens. Our profession has always been so much more than book pushers, and in today’s information saturated world, it is increasingly important that we are called upon by local, state, and national leaders and administrators for help in guiding learners of all ages to make sense of the information overloaded world around them. It is terribly short sighted of school districts to cut librarian positions based on the idea that they will be saving money. Instead, they should be asking themselves what are the longterm negative effects of schools without librarians.\nAdvocacy for our programs and the importance of the wide range of skills and behaviors certified teacher librarians provide should be part of our daily professional lives. It is up to US to make sure those individuals making decisions truly understand what we ‘do’ and how we do it! Share the great things that are happening in your library with the principal and other leaders in the district on a regular basis.\nOne way to stay up to date with current and relevant advocacy efforts is to join local, state, and national organizations. Currently, I am the Vice President of the Connecticut Association of School Librarians and a member of both AASL and ALA . I make an effort to attend conferences (both in person and virtual) in order to stay connected with the experts and leaders in our field because I believe there is power in collaboration, connection, and networking. Being with other professionals who share my passion keeps me motivated and inspired during times I am feeling overwhelmed and bogged down by the negativity surrounding me. Check out some of my favorite library related PD opportunities here.\nAlso, get connected to the professional organizations of other content areas! This is another opportunity to be the bridge between those groups and our libraries. I have been actively involved with the Greater Hartford Area Council for Reading, the Connecticut Reading Association, the Connecticut Geographic Alliance, and the Connecticut Council of Social Studies.\nThank you for the Roar, Melissa. LLR readers. We will post part two of Melissa’s interview covering Student Reviews, Readers Roar, Author Visits, and more! See you then."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:606eaa65-c865-4cf6-b4de-bb8559d93623>","<urn:uuid:29eca8a2-808e-454d-b6b9-69ddfafa82c9>"],"error":null}
{"question":"Could you compare the operational status of Duke Energy's Sutton Plant with Black Fox Furnace - when did each facility cease operations and under what circumstances?","answer":"The Sutton Plant and Black Fox Furnace had different circumstances for ceasing operations. The Sutton Plant's coal units were retired in 2013 after being replaced by a new natural gas-fired plant at the same site, as part of Duke Energy's planned transition to cleaner energy. In contrast, Black Fox Furnace's operations ended abruptly in 1860 due to a tragic boiler explosion that killed two men, William Kortz and Benjamin Kogan. The furnace never produced iron after this incident.","context":["Implosion brings down the last Duke Energy coal plant in Eastern N.C.\nDuke Energy has demolished nearly half of its coal fleet in the Carolinas\nCrews have safely excavated 1 million tons of coal ash from plant basins\nWILMINGTON, N.C. -- The Sutton Steam Plant in Wilmington ended its service with a bang, another significant milestone in Duke Energy's campaign to replace older, less-efficient plants with cleaner energy for its customers.\n- Cape Fear Plant – Moncure, N.C.\n- Cliffside Station Units 1-4 – Mooresboro, N.C.\n- H.F. Lee Plant – Goldsboro, N.C.\n- Robinson Plant – Hartsville, S.C.\n- Sutton Plant – Wilmington, N.C.\n- Weatherspoon Plant – Lumberton, N.C.\nDuke Energy is also in the early stages of demolition at the Buck Steam Station in Salisbury, N.C., and the Riverbend Steam Station in Mount Holly, N.C., and continuing demolition of portions of the W.S. Lee Plant in Belton, S.C.. At many locations, retired coal plants have been replaced by new, highly efficient natural gas plants.\nOnly seven of 16 coal plants remain in operation in the Carolinas.\nTo learn more about the company's coal plant decommissioning program, visit duke-energy.com/coal-decommissioning.\nView a video compilation of Duke Energy's progress imploding power plants across the state here: youtube.com/watch?v=fX8zi1HtxQg&feature=youtu.be\nAbout Sutton Plant\nSutton Plant began commercial service in 1954 and the coal units were retired in 2013 after a new natural gas-fired plant came into service at the site. The new natural gas units generate electricity more efficiently for customers and with lower emissions than the coal plant did during its operation.\nAs part of demolition work at Sutton Plant, crews removed the plant's two iconic red-and-white striped smokestacks in March 2016, using a ring-line platform that allowed the stacks to be removed from the top down.\nView a timelapse video of the smokestack removal here: youtu.be/Nzm88b5zIQ0\nView a historical feature story about this plant here: illumination.duke-energy.com/articles/l-v-sutton-plant:-the-generation-has-changed-but-not-the-dedication.\nSutton Plant ash basin closure continues\nDuke Energy continues to safely excavate and close ash basins at the Sutton Plant. Crews have safely excavated 1 million tons of coal ash from Sutton Plant basins since excavation operations began one year ago. Ash is being transported by rail to a fully lined structural fill at the Brickhaven Mine in Chatham County, N.C.\nApproximately 2 million tons of the 7 million tons of ash at Sutton Plant will be taken to the Brickhaven Mine structural fill, with remaining ash to be stored in a fully lined landfill on Sutton Plant property. Construction of the landfill is beginning now that necessary permits and approvals have been received from the state.\nClosing ash basins at the site is part of the overall effort to retire coal ash operations at the Sutton Plant in ways that protect the public, the environment and costs customers pay.\nFor additional information about ash basin closure at the Sutton Plant, please visit duke-energy.com/sutton.\nAbout Duke Energy\nHeadquartered in Charlotte, N.C., Duke Energy is an S&P 100 Stock Index company traded on the New York Stock Exchange under the symbol DUK. More information about the company is available at duke-energy.com.\nThe Duke Energy News Center serves as a multimedia resource for journalists and features news releases, helpful links, photos and videos. Hosted by Duke Energy, illumination is an online destination for stories about remarkable people, innovations, and community and environmental topics. It also offers glimpses into the past and insights into the future of energy.\nContact: Jeff Brooks | 919.219.9215\nTwitter: @DE_JeffB @DukeEnergy","|Black Fox Furnace & Iron Works:\nLocated on Black Fox Run, 1mi. north of Allegheny\nRiver, near the Village of West Freedom, Perry Twp., Clarion County,\nDate Built: ca. 1844\nDate Out-of-Blast: ca.1860\nOther names Black Fox Furnace was known by:\n|Black Fox Furnace & Iron Works\nA Stone Blast Furnace & Iron Works\nOwners: Lawson & Company (ca.1844)\nWelsh & Company (ca.1844)\nAdams & Varnum Company (ca.1848)\nVernum & Adams Company\nJones & Company\nThompson, Boyd & Company\nPainter & Graff Company (ca.1850)\nJacob Painter & Company (ca.1850-1860)\n|Short History of Black Fox Furnace:\nFrom \"History of Clarion County\" 1887.\nPerry Township Along in the forties a company began the erection of a furnace in the southern part called Red Fox. This company sold to a Welsh firm, who finished the work and called it Black Fox Furnace. This firm sold out to Vernum & Adams, who became involved, and a disputed title threw the property into the sheriff's hands, who sold it, and it was bought by Painter & Graff. This company made iron here till 1859. In the summer of 1860 William Moore tried to start the furnace to use up some stock he had on hand, but in attempting to get up steam, the boiler exploded, killing two men named William Kortz and Benjamin Kogan. Thus it has been truly said that \"Black Fox Furnace blowed out in 1860,\" at least it blew up. It never made iron after that event. In its best days it made from fifteen to twenty tons of charcoal, or cold blast metal daily. (Davis,1887:118)\nBlack Fox Furnace. Located on Black Fox Run, about 1 mile from the Allegheny River in Perry Township. Height 30 feet, 9 foot bosh. Built by Welsh & Company. Bought by Adams & Varnum in 1848. Failed in 1850. Purchased by Jacob Painter, et.al., at Sheriff's sale ca.1850. Samuel Barr was Superintendent. Steam, hot blast. Production in 1845 was 1,000 tons; in 1856 was 2,000 tons. Boiler exploded about 1858, one man killed; several others critically injured. Abandoned following explosion. (Caldwell,1877: )\nFrom: \"A Guide to the Old Stone Blast Furnace in Western\n|Location: From Callensburg, Clarion Co., to locate the Black Fox Furnace Site, proceed west from Callensburg on PA Rt.368 approx. 3.5 mi. to West Freedom. In west Freedom turn right unto PA SR3001, go south on PA SR3001 for 2.4mi.|\n|Black Fox Furnace, Perry Township, Clarion Co.\n1872 Map of Perry Township, Clarion, showing the location of Black Fox Furnace and the settlement around the furnace.\n(from \"Atlas of the County of Lawrence & The State of Pennsylvania,\" Published by G.M.Hopkins & Co., Philadelphia, PA, ca.1872)\n|Bibliographical Sources: This section under construction.|\n|[no pictures are presently available for Black Fox\nFurnace, Clarion Co., Pa.]\nIf you have pictures or know of where pictures of the furnace are located or additional information on Black Fox Furnace, Clarion Co., please contact the Ironmaster\nIf you have additional information or pictures on the Iron\nFurnaces of Clarion County, Pennsylvania\nContact: Ray Washlaski, Web Master\nNeed a web site for your family or organization, The \"Mercers, an Undertakers\" Web Productions, will do it for you at a reasonable cost, contact the \"Mercers, an Undertakers\"\nCopyright 2002, All rights reserved, by Raymond A. Washlaski, Ryan P. Washlaski & The 19th Century Society of Pennsylvania.\nWeb site Design by \"Mercers, an Undertakers\" Web Design Company"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:0b929c74-1c68-4138-a99c-2a4e4c3589cf>","<urn:uuid:5c082aa7-6c9c-4af6-ac52-5522fe8ed57b>"],"error":null}
{"question":"What are the essential components of supplier evaluation, and how should companies approach risk assessment in their supply chains?","answer":"Essential components of supplier evaluation include analyzing both subjective and objective aspects of supplier relationships, weighing factors such as quality, delivery, total cost, supplier diversity, service, design control, and R&D. For risk assessment, companies should classify all potential risks, establish formal evaluation systems to track performance, and implement corrective action policies like three-strike rules or monetary compensation. This should be combined with automated monitoring systems for early detection of issues, clear contingency plans, and ongoing collaboration between departments to ensure all aspects of supplier relationships are considered in the evaluation process.","context":["Identifying and Maintaining a Reliable Supplier Network\nChange is certainly a constant in business, which can make the process of managing a complex supply chain difficult for even the most successful companies. Identifying and managing suppliers that can ensure a superior level of quality, service and innovation is critical to gaining and maintaining a competitive advantage.\nAlong with the resurgence in North American manufacturing has come—in particular for many midsized manufacturers—an increased challenge in funneling increased volume through an existing supplier network. This is true whether you’re dealing with new or established supplier relationships. Too many questions can be left to chance. For instance:\n• Can the supplier meet the turnaround deadline?\n• Does the supplier actually have the ability to meet current and future demand?\n• Does the supplier use conflict materials?\n• Can the supplier match our quality standards based on increased volume?\nCan you really afford to have your production planner or procurement director spending time shopping for and vetting new suppliers when your organization attempts to capitalize on new demand? The answer is, of course not.\nInto the Fryer\n“As a midsized company, we knew we had limited resources and expertise to devote to managing and enhancing our supply chain,” says Bill Collins, general manager of Ultrafryer Systems, San Antonio, TX, a manufacturer of commercial deep fryers for restaurant and commercial installations. “But, we also knew that doing so was critical to our future success.”\nUltrafryer and other Prime Advantage members access the group’s endorsed suppliers through multiple channels, including a private intranet, although the company’s semiannual conference is the primary to reach out to multiple suppliers in a short period of time. These three-day conferences offer networking and strategic-sourcing opportunities for all participants. Collins and his Ultrafryer associates attend the conferences to hold one-on-one private meetings with potential suppliers, to discuss needs and strategies, as well as the suppliers’ ability to fulfill those needs.\nSave Time, Save Money\n“We have found this opportunity to sit down with so many suppliers to be a rigorous process that we would not be able to accomplish for even our top 15 suppliers each year,” says Bart Walker, general manager of Romac Industries, another Prime Advantage member company. Romac, Bellevue, WA, manufactures clamps, flanged couplings, sewer products and other products, and operates a custom fabricated steel-pipe division. “To accomplish this within a three-day period,” Walker continues, “has made our supplier evaluation and selection process much more efficient, and has saved us a ton of money.”\nMeeting with this many suppliers, twice per year, enables members to enhance relationships with key suppliers at an executive level, as well as gain exposure to new supplier capabilities, new trends and even new supply-chain options.\nRisk Analysis and Supplier Performance Analysis\nMost global manufacturers have formalized supplier-evaluation systems in place that enable them to actively manage their supply networks. For example, when a supplier is continuously late with shipments, a spend management professional must identify the infraction, quantify it, communicate it to the supplier and implement corrective action. Corrective action can take the form of a three-strike policy, monetary compensation, a combination of both, as well as other steps.\nYet, few small- to midsized manufacturing companies have formal processes in place to track, evaluate and communicate supplier performance, let alone assess risk within their supply chain. These companies simply lack the resources to create and maintain a documented supplier-evaluation system. Without such a system, companies have a hard time defining if supplier performance is productive or if it should improve. And no company can afford to find out after the fact that a supplier is underperforming—not when businesses are in a growth cycle.\nSuppliers that are true partners want to help customers succeed by improving their own performance. These suppliers value the consistent and measurable feedback that a formal evaluation system provides. The advantages to having a formal evaluation and audit process in place benefits your organization as well as your suppliers’ organizations. Empirical evidence illustrates that firms with supplier-evaluation systems realize improvements such as higher rates of on-time deliveries, fewer defects and quicker response time.\nThat said, most small and midsized firms typically have only enough resources to manage the performance of their top few suppliers, at a basic level. The process requires support of multiple departments such as engineering and operations, as well as senior leadership. Each must work together to determine that all parts of a supplier relationship are being considered in the evaluation process.\nUltrafryer and Romac—and other Prime Advantage members—are able to use two systems in place at Prime Advantage to ensure they work with best-in-class supply partners. Suppliers must complete an audit process to enter the network and attain endorsed status. Then, members provide ongoing feedback through a formal evaluation process. The supplier evaluation process begins with many of the steps followed by the world’s top manufacturers, in which subjective and objective aspects of a supplier relationship are analyzed and weighted. Factors include quality, delivery, total cost, supplier diversity, service, design control and R&D.\nHarry Marcionetti, senior vice president of operations for truck-body manufacturer Knapheide Mfg., Quincy, IL, also appreciates the added support Prime Advantage provides, via an account manager. This dedicated resource helps Knapheide (and other member companies) identify the best supplier options in the group based on needs and supplier capabilities.“Our Prime Advantage account manager has helped us build a bench of quality suppliers across a number of specific material and service categories,” says Marcionetti, “where we previously only had one supplier connection. They have effectively added arms and legs to our team without needing to hire new staff.” MF\nSee also: Prime Advantage\nRelated Enterprise Zones: Other Processes\nHi there, just became aware of your blog through Google, and found that it is really informative. Im going to watch out for brussels. Ill be grateful if you continue this in future. Lots of people will be benefited from your writing. Cheers! fdacfkgeecdebbfg","Supply Chain Risk Management\nWhat is Supply Chain Risk Management?\nSupply Chain Risk Management Definition: Supply chain risk management (SCRM) involves monitoring for and identifying potential threats to the supply chain. Although there is no way to completely eliminate risk, many issues can be avoided and contingency plans can be put into place to minimize or mitigate the impact on operations and/or profitability.\nSupply Chain Risk Management Examples: Generally speaking, there are two types of risk associated with supply chains. There are things that are impossible to predict and plan for, such as natural disasters, epidemics, and acts of terrorism, and there are other things that can be planned for, provided an organization has the data necessary to observe and act on early indicators. This may include:\nThe Role of Software Risk Management in Supply Chain Reliability\nBecause there are many potential issues that can impact the supply chain, executives have the difficult duty of assessing which problems are likely to cause the most harm to operations and profitability. Although cyber security is a core focus, there are numerous ways software can impact the reliability and profitability of a supply chain and not all of them are apparent, even to those in IT. While there is some risk involved in the hacking or insertion of malicious code in software, most issues surround unintentional coding errors, which routinely go undetected. As the infrastructure and architecture grow, these errors can create vulnerabilities and cause unexpected conflicts. By identifying these issues in advance and taking steps to reduce their impact, the risk is effectively managed prior to breakdown of the chain. Bear in mind, these errors can occur at a local level as well as at any stage in the supply chain, which is why it’s important for organizations to work with vendors and companies that have systems and transparency in place.\nSupply Chain Risk Management Best Practices\nAutomation: Supplier risk management (SRM) processes, including the collection, management, and analysis of data, should be automated. Human eyes cannot always detect errors, let alone conflicting codes within a system.\nSupplier Transparency: Performance information from suppliers should be readily available and included in analysis.\nEarly Detection: The supply chain risk management process should make use of automation software detect potential red flags before they become a problem.\nClassification: All potential risks should be identified, classified, and prioritized in order to determine which corrective actions offer the greatest ROI.\nPlans & Contingency Plans: A supply chain risk management plan should be developed and include methods for managing imminent risks as well as for minimizing the impact of issues that cannot be prevented or would be cost-prohibitive to prevent.\nMonitoring: Supply chain risk management tools should be used to identify new triggers, even after an assessment and corrections have been carried out.\nCollaboration: SCRM metrics and information should be available to various departments and heads at the same time for easy collaboration regarding supply chain risk management strategies.\nLeadership: SCRM should be overseen by one leader, even if duties are delegated to a team. Historically, organizations that assign a lead, usually an executive or VP, to handle SCRM see the greatest ROI. These organizations are also the only ones to see in excess of 100% ROI on their SCRM efforts."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:bd91ba7e-5b3d-4e37-8501-eb8581d3704a>","<urn:uuid:08a27c68-0dd9-4293-992b-f4e82c905629>"],"error":null}
{"question":"What are the three main types of contaminants that can clog porous metal filters?","answer":"The three main types of contaminants are: Inorganics (non-carbon containing contaminants such as metals, salts, oxides), Organics (typically petroleum based compounds such as oil, grease, wax, gums, tars and polymers), and Biological (protein based contamination such as bacterial, algae and food or plant material).","context":["Filter cartridges eventually will become blinded by the contaminating particles that are removed from the fluid stream. When properly sized for the application, metal filters can be regenerated to perform at up to 95% of their clean, differential pressure. By following prescribed cleaning methods, it is possible to extend the maximum life of the filters. Water used in these procedures should be filtered to the same micron rating as the final filter used in the process train to avoid recontaminating the filters. Please be sure to wear the appropriate protective clothing, gloves and a face shield when handling chemicals. Consult the Material Safety Data Sheets.\nTypes of Contaminants\nIn order to effectively clean porous metal elements, it is important to identify the types of contaminants that are plugging the filter. By knowing this information, it is possible to determine the most effective cleaning methods. In some instances, it will not be possible to clean the elements and it will be necessary to utilize a commercial cleaning company.\nInorganics: These are considered non-carbon\ncontaining contaminants such as metals, salts, oxides\nOrganic: Typically petroleum based compounds such\nas oil, grease, wax, gums, tars and polymers.\nBiological: Protein based contamination such as\nbacterial, algae and food or plant material.\nSince the contaminants can occur in combination, it may be necessary to utilize more than one cleaning method or cleaning agent.\nFor the cleaning agent, dilute acid such as nitric or phosphoric up to 10%, caustics such as sodium hydroxide up to 15% or commercial detergents such as Alconox or Tergezyme can be utilized. Compatibility should always be verified with the metal as well as the housings if done in a circulation mode. A series of cleaning agents may be required due to the presence of multiple types of contaminants. The effectiveness of the cleaning agent can be improved by increasing the temperature of the solution to 80°C. If doing a static soak, a 4 – 6 hour time period is\nOnce complete, rinse with filtered ambient water for 10 – 30 minutes, in the reverse direction, at a flow rate 1.5 times that of the initial flow rate used on the product filtration. Repeat the cleaning process if necessary if the cartridges do not recover to within 10% of the original DP.\nThis is the simplest cleaning method and should be used routinely to maintain the filter’s condition. In this process, liquid or gas (blowback) is utilized in the reverse direction to remove contaminants from the surface of the filter. Pulsing the liquid in the reverse direction, versus just reverse flow, may provide a more effective result. Be certain to avoid exceeding the recommended reverse pressure rating. Typically, a reverse flow (pulse) at 1.5 to 2 times the typical forward flow or pressure drop is all that is required.\nSoak or Circulation\nThese methods require the introduction of a detergent, acid or caustic as the cleaning agent in either a static or circulation mode. If circulating the cleaning solution, the flow should again be in the reverse direction at 1.5 to 2 times the flow rate/pressure of the forward direction.\nProcedure - All filter housings in a process train must be correctly piped so that they can be isolated, from each other. By installing a valve and tee connection on both the inlet and outlet of the housing, the cleansing chemicals can be brought into and removed from each housing, to drain, without flowing into the previous or next filter housing. The tee and valves should be the same pipe size as the process piping or a size large enough to accommodate a flow rate 1.5 to 2 times that of the process or filtration flow rate. Each filter housing should contain an inlet and outlet valve and pressure gauges upstream and down-stream of the housing. The gauges\nshould be liquid filled and have a face diameter of at least 2.5 inches. The pressure range should be such that each graduation can be easily read and differentiated from the other gauge reading. Accuracy is important.\nDue to the thermal tolerance of porous metal elements, it is possible to burn or volatize the organic or biological contaminants. Temperatures up to 850°F are possible. Since some contaminants may leave ash, additional cleaning methods may need to be employed after the furnace. Developing a cleaning method requires a trial and error approach due to the varying nature of potential contaminants."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:5e38b047-5f0b-4558-ad73-2fcfb080b49c>"],"error":null}
{"question":"How do blood sample collection procedures minimize risk, and what safety measures do instrument cassettes provide in dental settings?","answer":"Blood sample collection follows 6 key steps to minimize risk: applying a tourniquet, cleaning with alcohol solution, inserting a sterile needle, withdrawing blood, applying cotton wool for 2 minutes, and applying dressing. As for instrument cassettes in dental settings, they provide multiple safety features: they reduce the risk of percutaneous sharps exposure by keeping contaminated instruments secured in one unit, include built-in needle recapping devices to prevent needlestick injuries, and allow for organized instrument flow from chairside through cleaning and sterilization. Cassettes also eliminate the need for direct handling of contaminated instruments during cleaning, which substantially reduces potential injuries.","context":["- Created by: _laurenb\n- Created on: 02-12-14 18:49\nWhat are the 6 steps for taking a blood sample?\n1. Apply a torniquet\n2. Clean the area with an alcohol-based solution\n3. Push a sterile needle into the vein\n4. Pull back the syringe attatched to the needle to withdraw blood\n5. Remove and hold cotton wool on the wound for 2 minutes\n6. Apply dressing\nWhat are the 8 steps to creating a blood smear?\n1. Apply a small drop onto the end of the microscope slide\n2. Put the 'spreader' on top\n3. At an angle of 30 degrees, scrape the spreader along to create a smear\n4. Label the slide with the patient's details\n5. Allow the slide to air dry, causing the cells to stick to it\n6. Preserve the cells by adding alcohol to the slide\n7. Stain the slide using a Romanowsky stain or a Leishman's stain\n8. Leave for 2 minutes and then wash off\nHaemocytometers - Red Blood Cells\nA counting chamber for blood cells.\nCan be used to count both red and white blood cells, but they have to be diluted first.\nRED BLOOD CELLS\n- Diluted using blood pipette\n1. fill pipette to 0.5 mark\n2. draw 'Dacie's fluid' into the pipette up to the 101 mark\nA bulge within the pipette contains a bead which shows the blood and Dacie's fluid have mixed together = 1 in 200 dilution.\nTHE DILUTED BLOOD CAN BE PLACED ON THE HAEMOCYTOMETER; RED BLOOD CELLS COUNTED IN THE TRIPLE-LINED SQUARES.\nTHE NORTHWEST RULE IS APPLIED.\nThis states that if a cell lies on the middle of north or west lines, it is counted BUT when on the middle of south or east lines they are not counted.\n- RED BLOOD CELLS\n- Carry oxygen and carbon dioxide\n- Haemoglobin - protein that associates reversibly with oxygen\n- Bioconcave shape = more oxygen carriage\n- No nucleus within mature erythrocytes = more oxygen carriage\n- Small and flexible = flattened against capillary walls = smaller distance for diffusion = faster gas exchange\nWhat are the three types of leucocytes?\n(Leucocyte - white blood cell)\n3. Monocytes --> macrophages\n- Small granules within cytoplasm\n- engulf microorganisms by phagocytosis\n- Large nucleus\n- Thin, clear cytoplasm\nB lymphocytes = antibody production\nT lymphocytes = cell destruction etc.\n- Large, bean-shaped nucleus\n- Spend 2-3 days in the circulatory system, then become...\n- Engulf microorganisms\nAs well as erythrocytes and leucocytes, there are platelets.\nThese are fragments of megakaryocytes - giant cells.\nPlatelets are involved in blood clotting.\nWHEN CALCULATING MAGNIFICATION\nsize of structure in the picture\nreal size of structure\nWHEN CALCULATING REAL SIZE\nsize of the structure in the picture\nSize of structure in the picture is always at the top!\n1. Phospholipids (form basis of membrane)\n2. Proteins (scattered around membrane)\nCarbohydrates and cholesterol may also be present.\nStructure of Phospholipids\nglyerol molecule + phosphate group + fatty acid chains = phospholipid\n- Formed of the phosphate group\n- Hydrophillic (water-loving)\n- Charge = soluble in water\n- Formed of the fatty acid chains\n- Hydrophobic (water-hating)\n- No charge = insoluble in water\n- Phospholipids pack together to form a phospolipid bilayer, with the hydrophilic heads facing the water and the hydrophobic tails facing away from the water.\nProteins Within Plasma Membranes\n1. Intrinsic = in the whole of the bilayer\n2. Extrinsic = on one side of the bilayer only\nGLYCOPROTEIN = carbohydrate chain + protein\n- Involved in cell recognition\n- other molcules join to glycroproteins because of this\n- involved in cell-to-cell signalling\n- involved in cell adhesion\nGLYCOLIPID = carbohydrate chain + glycolipid\n(glyco = carbohydrate chain)\nMembranes In and Around Cells\nAT THE SURFACE\n- membranes help to separate a cell from its surroundings - like plasma or tissue fluid\nWITHIN THE CELL\n- Provide 'compartments' allowing complex processes within the cell to be separated\nEukaryotic = true nucleus\nORGANELLES OF THE ULTRASTRUCTURE OF A TYPICAL EUKARYOTIC CELL:\n1. Cell surface membrane\n3. Nuclear membrane\n5. Nuclear pore\n7. Secretory vesicles\n9. Rough endoplasmic reticulum\n10. Smooth endoplasmic reticulum\n11. Golgi apparatus (body)\nCollaboration of Organelles Within Eukaryotic Cell\nTo perform functions, organelles often have to work together.\nAntibody production is an example of this...\nNucleus holds gene that codes for protein on chromosomes --> messenger molecule takes code to ribosome on rough endoplasmic reticulum --> proteins made --> transported to golgi apparatus in small sacks called vesicles --> proteins are modified and repackaged --> make their way to the cell surface membrane\nTHE ENERGY ENABLING ALL OF THIS TO OCCUR IS PRODUCED BY THE MITOCHONDRIA (ATP)\nThis process involved 7 different organelles.\nComparing Animal and Plant Cells\nnucleus, nucleolus, ribosomes, cell wall, plasma membrane, golgi apparatus, rough endoplasmic reticulum, smooth endoplasmic reticulum, mitochondria, chloroplasts, permanent vacuole, cytoskeleton\n- All are present in plant cells\nalthough chloroplasts are only present in the cells of leaves or of green parts of the plant\n- cell walls, chloroplasts and a permanent vacuole are not present in animal cells\nthe other organelles are","You must be signed in to read the rest of this article.\nRegistration on CDEWorld is free. You may also login to CDEWorld with your DentalAegis.com account.\nClearly written policies, procedures, and guidelines have been advocated and developed by professional organizations and governmental agencies to help ensure consistency, efficiency, and effective coordination of infection control activities.1,2 One occupational risk faced by dental healthcare workers (DHCWs) is the possibility of percutaneous sharps exposure when handling contaminated dental instruments. Minimizing the potential for this mode of transmission is therefore a primary focus for a comprehensive infection control program.\nOne aspect to consider when implementing an infection control program is selecting technologies and products that can maximize a safe and efficient work environment for healthcare personnel and patients. Instrument cassettes represent examples of both a technology and a product that can be integrated into a dental office. When used appropriately, cassettes can increase organization and improve safety and infection control both in the dental operatory and when processing instruments for reuse on patients.\nInstrument Cassette Selection\nInstrument cassettes were first introduced in hospitals to organize instruments into procedure sets. They were later incorporated into dental school clinics, and in recent years have also become increasingly popular in dental offices. One important feature of instrument cassettes is that a single cassette can be used to hold and organize a complete set of instruments for a specific procedure (Figure 1). This convenience eliminates the need to gather multiple packages for a procedure. In addition, cassettes allow for less handling of contaminated instruments during cleanup and reprocessing. This latter attribute can provide additional safety by enhancing instrument flow while saving time. Table 1 summarizes the main advantages of using a cassette system in dental practice. Figure 2 shows an instrument cassette ready for chairside use.\nAs with the selection of any new product, it is important to consider what features cassettes can provide that will meet the needs of a specific dental practice. For example, cassettes are available in a variety of materials, sizes, and shapes (Figure 3). When determining what size(s) will best fit practice needs, one must consider how many instruments and accessories are used for each procedure. The most probable outcome of such a review is that several different sizes of cassettes will be needed due to specialized instrument requirements for certain procedures (eg, operative, hygiene, surgical procedures). When considering cassette size, it is also important to evaluate the size of the practice’s cleaning and sterilization equipment (eg, ultrasonic cleaner, instrument washer, heat sterilizer). Making sure there is adequate processing and storage space should be determined early on, because cassettes will occupy more storage space compared with other types of packaging materials.\nThis type of logistics review logically leads to a consideration of the impact of cassette implementation on practice costs. The answer is that cassettes will incur an initial financial investment. What also needs to be included in the office discussion, however, is what the cost would be to the practice owner when one of the clinical employees incurs an accidental percutaneous exposure when treating a patient. Initial consultations with a licensed medical facility, multiple post-accident serologic tests, and follow-up evaluations can cost hundreds of dollars for each accident that occurs. These do not begin to approach the emotional impact a sharps exposure can have on the employee. When taken as a whole, cassettes make sense.\nVirtually all commercially available cassettes are perforated cassettes; these are preferable to containers that are completely solid. Solid cassettes may not allow steam or chemical vapor to reach the contents for sterilization to occur. Additionally, cassette perforations allow thorough ultrasonic or instrument washer cleaning. Other features to consider would be instrument rails, strips, holders, or racks inside the cassette that are used to hold instruments in place. If these are made of soft material, they may decrease scratching on the instrument surfaces. Also, check to see if the holding devices provide adequate space between instruments to allow easy access during instrument cleaning prior to heat sterilization. A study performed at The Dental Advisor demonstrated that a single instrument washer or ultrasonic unit cleaning cycle was able to completely remove bioburden coated and dried onto instruments and cassette rails.3\nCompartments within the cassette to place accessories such as rubber dam clamps, anesthetic syringes, burs, amalgam wells, and air water syringe tips would be advantageous. The inclusion of important safety features such as a built-in needle recapping device can further reduce the potential for accidental needlestick injuries during patient care.\nEngineering and Work Practice Controls\nAvoiding occupational exposures to blood is the primary way to prevent transmission of blood-borne diseases (eg, hepatitis B virus, hepatitis C virus, human immunodeficiency virus) in healthcare settings. Exposures occur through percutaneous sharps injury (eg, a needlestick or cut with a sharp object) as well as through contact between potentially infectious blood, tissues, or other body fluids and mucous membranes of the eye, nose, and mouth or nonintact skin (eg, exposed skin that is chapped, abraded, or shows signs of dermatitis).\nThe majority of exposures in dentistry are preventable.1 Strategies to reduce the risk of blood contacts and prevent the transmission of blood-borne diseases include the use of the hepatitis B vaccine, standard precautions, use of engineering controls, and modifications of work practices. Usually a combination of these practices is used. These approaches, along with training and education, have contributed to the decrease in percutaneous injuries among dentists in recent years.4-7 To help DHCWs be as safe as possible with regard to sharp exposures, the Occupational Safety and Health Administration (OSHA) requires the use of engineering and work practice controls to eliminate or minimize employee exposure.8\nEngineering controls are often technology based and isolate or remove the hazard from the workplace. Whenever possible, engineering controls should be used as the primary method to reduce exposures to blood and saliva from sharp instruments and needles. Examples of engineering controls include sharps disposal containers, safety needles, and scalpels that isolate or remove the blood-borne pathogen hazards from the workplace.\nWork practice controls are those behavior-based practices that are incorporated into the everyday work routine that reduce the likelihood of exposure by altering the manner in which a task is performed (eg, using one-handed scoop technique or a needle recapping device to recap a needle; not bending or breaking needles before disposal; not passing a syringe with an unsheathed needle). In many cases, engineering and work practice controls are used together to eliminate or minimize workplace hazards. For example, by not recapping a needle with two hands, one is using a work practice control; if one recaps the needle using a needle recapping device, it is an engineering control.\nAn instrument cassette can be considered both an engineering and work practice control. When using instrument cassettes, the instruments are organized in one unit from the chairside procedure through cleaning, rinsing, drying, sterilization, and storage. Sharps injuries can be reduced chairside, because when reaching for instruments during a procedure, it is likely that the instruments will be more organized when using a cassette. As mentioned above, using cassettes can also decrease sharps injuries during cleaning after the procedure because of decreased handling of contaminated instruments. A built-in needle recapping device inside the cassette can also assist with one-handed needle recapping and eliminate the need to purchase a separate device.\nThe goal of instrument reprocessing is to deliver sterile instruments to patients. When cleaning and processing contaminated instruments between patient treatment procedures, the instrument recirculation system should be logical and organized in a manner that will most efficiently accomplish reprocessing and sterilization and minimize procedures that can place employees at risk for percutaneous, sharps exposures, or other hazards. 9-11 Using instrument cassettes streamlines instrument processing by keeping all the instruments for a specific procedure together in one cassette from the chairside procedure through cleaning, rinsing, drying, packaging, sterilization, storage, and delivery to chairside for the next patient. As a result, DHCW can save time and increase processing efficiency, in addition to reducing the potential for sharps injuries. The following sections review steps involved in instrument reprocessing, with an emphasis on how cassettes can improve efficiency and DHCW safety.\nInstrument Preparation at Chairside\nThe practice should designate a central instrument processing area to more easily control quality and ensure safety, instead of performing these procedures in the operatory.1,9,12 Preparation for instrument processing does begin chairside in the dental operatory, however. After completion of patient treatment, appropriate personal protective equipment should be worn when disposable sharp objects (ie, needles, burs) are discarded in sharps containers. All other disposable items, including gauze, cotton rolls, articulating paper, and cotton tip applicators, can be placed in appropriate waste containers when indicated. Closed and secured cassettes containing contaminated instruments can then be transported to the instrument processing area. Instruments should be arranged in an orderly manner when preparing them for the next patient, because they will not be removed from the cassette during instrument processing. OSHA regulations state that reusable sharp instruments should be placed in an appropriate container at the point of use to prevent percutaneous injuries during transport to the instrument processing area.1,12 Although an additional container may be used for this, a cassette readily accomplishes the same goal by having contaminated instruments already secured inside.\nCleaning and Decontamination\nThe basic premise of aseptic technique—clean it first—applies to instrument processing. Cleaning involves the removal of debris as well as organic and inorganic contamination. Because of the potential for injury from sharp instruments, hand scrubbing should be avoided as much as possible.1,9 Most dental offices use automated equipment such as ultrasonic cleaners for cleaning dental instruments. Instrument washers are becoming more popular in dental practices and can streamline the instrument cleaning process. When using perforated instrument cassettes, the cassette can be placed directly into the ultrasonic cleaner or instrument washer (Figure 4). After cleaning is complete, the cassette is removed and allowed to dry before wrapping. Because there isn’t any direct handling of the instruments during cleaning or sorting instruments later, the potential for injury can be substantially reduced.\nThe purpose of packaging is to protect instruments from environmental contamination after removal from the sterilizer and storage. Packaging materials must be compatible and designed for the type of sterilization process being used (eg, steam autoclave, dry heat, unsaturated chemical vapor) and cleared by the Food and Drug Administration (FDA). Packaging materials include bags, wraps, pouches, and wrapped perforated instrument cassettes. Instruments should never be stored unpackaged because an unwrapped item does not have a shelf life.1 Instrument cassettes are very useful and a popular method to package dental instruments, as virtually every US and Canadian dental school uses them to train students.\nIt is important to note that when using cassettes, all instruments for that specific procedure can be pre-arranged inside the cassette, thereby eliminating the need for bringing miscellaneous packages into the operatory. Decreased handling may even allow for a quicker set-up for the next patient. After the instrument cassette is cleaned and dried, the cassette can be opened and any disposable gauze items can be placed inside before sterilization.\nManufacturer’s instructions provide recommendations for cleaning, wrapping, and sterilizing cassettes. Unfortunately, the need to wrap a cassette is sometimes misunderstood, and a number of dental practices are thus not maximizing the benefit of cassette use. If a wrapping material (ie, sterilization wrapper, paper/plastic pouch) is not used to wrap the cassette, the contents will not remain sterile during storage because of the perforations in the cassette. Also, before wrapping the cassette, place an internal chemical indicator inside with the instruments. If an opaque packaging material is used and the internal indicator will not be visible on the outside of the package, place an external indicator on the package.\nIn dentistry, the three most common methods used to sterilize patient care items are steam under pressure (autoclaving), dry heat, or unsaturated chemical vapor. Steam sterilization is a dependable and cost-effective process and is the most widely used method for items that are not sensitive to heat or moisture.1 All sterilization equipment must be cleared by the FDA and used according to manufacturer instructions. Correct loading of the sterilizer chamber is essential. Items to be sterilized should be arranged to allow adequate circulation of the sterilizing agent.\nBecause the size and shape of instrument cassettes vary, it is important to consider the size of the sterilizer chamber when selecting and purchasing both sterilizers and cassettes. They will most likely take up more space than other types of packaging materials. Accessories, such as racks or trays, are usually provided with the sterilizer to help with proper loading procedures. Usually packages should be placed in the chamber on their edges so that the sterilizing agent contacts every surface of every article to be sterilized. Additionally, it is important to ensure that the cassette materials are compatible with the sterilization method being used in the office. Instrument packs should be allowed to dry inside the sterilizer chamber before removing and handling, as wet packs can easily tear. Finally, sterile packs should not be touched until they are cool and dry because hot packs act as wicks, absorbing moisture, and thus can introduce bacteria from hands and the environment.\nStorage of sterilized items should occur in a manner that prevents contamination; package integrity must remain intact until the time of use. Sterile dental items and clean patient care supplies should be stored in a clean and dry enclosed storage area. Closed cabinets limit dust accumulation and inadvertent contact with the sterile items. Because cassettes take up more storage space than instruments in pouches, it is important to also consider the size of storage space. Also, a wrapped cassette can reduce the necessity of repackaging and sterilizing items as a result of sharp or heavy instruments tearing paper or plastic package materials.\nAn important part of the office infection control program is selecting and using technologies and products to develop a safe working environment for patients and staff. Instrument cassettes are an example of a product that can be integrated into a dental office and, when used appropriately, can increase organization and improve safety and infection control both in the dental operatory and when processing instruments for reuse on patients.\nDr. Molinari provides consultation services to Hu-Friedy Manufacturing, Inc.\n1. Centers for Disease Control and Prevention. Guidelines for Infection Control in Dental Health-Care Settings, 2003. Atlanta, GA: Centers for Disease Control and Prevention, US Dept of Health and Human Services; 2003.\n2. Infection control recommendations for the dental office and the dental laboratory. ADA Council on Scientific Affairs and ADA Council on Dental Practice. J Am Dent Assoc. 1996;127(5):672-680.\n3. Molinari JA, Prose J. Cleaning efficacy of Miele washer/disinfector. The Dent Advisor. 2011;39.\n4. Cleveland JL, Gooch BF, Lockwood SA. Occupational blood exposure in dentistry: a decade in review. Infect Control Hosp Epidemiol. 1997;18(10):717-721.\n5. Gruninger SE, Siew C, Chang SB, et al. Human immunodeficiency virus type I. Infection among dentists. J Am Dent Assoc. 1992;123(3):59-64.\n6. Klein RS, Phelan JA, Freeman K, et al. Low occupational risk of human immunodeficiency virus infection among dental professionals. N Engl J Med. 1988;318(2):86-90.\n7. Siew C, Gruninger SE, Miaw CL, Neidle EA. Percutaneous injuries in practicing dentists. A propective study using a 20-day diary. J Am Dent Assoc. 1995;126(9):1227-1234.\n8. Occupational Safety and Health Administration. Occupational Exposure to Bloodborne Pathogens; Needlesticks and Other Sharps Injuries; Final Rule. Washington, DC: United States Dept of Labor; 2001.\n9. Molinari JA, Harte JA. Practice settings: dental office. In: Association for Practitioners in Infection Control and Epidemiology, ed. Infection Control and Applied Epidemiology: Principles and Practice. 3rd ed. Washington, DC: APIC Publishing; 2005; 51.1-51.23.\n10. The Organization for Safety, Asepsis and Prevention Web site. www.osap.org. Accessed May 25, 2013.\n11. Molinari JA, Harte JA. Instrument processing and recirculation. In: Molinari JA, Harte JA, eds. Cottone’s Practical Infection Control in Dentistry. 3rd edition. Philadelphia, PA: Lippincott Williams & Wilkins; 2009: 221-231.\n12. American National Standards Institute. Comprehensive Guide to Steam Sterilization and Sterility Assurance in Health Care Facilities. Arlington, VA: Association for the Advancement of Medical Instrumentation; 2006.\nAbout the Authors\nJohn Molinari, PhD\nDirector of Infection Control\nThe Dental Advisor\nAnn Arbor, Michigan\nJennifer A. Harte, DDS, MS\nMilitary Consultant for Dental Infection Control (Retired)\nAir Force Surgeon General\nPeri Nelson, BS\nResearch Associate, Microbiology & Infection Control\nThe Dental Advisor\nAnn Arbor, Michigan"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:da4f7138-d500-46d0-8e2f-71e2f9185049>","<urn:uuid:5e40940b-4aef-4a87-8be3-2236b367bb35>"],"error":null}
{"question":"What are main sources EMI noise in everyday life? pls explain!","answer":"EMI sources include common electronic devices, vehicles, heavy equipment, cell phones, PCBs, clock circuits, oscillators, digital circuits, processors, and electromechanical devices that switch currents. Cell phones particularly rely on high levels of RF energy and can become sources of unintended EMI to susceptible devices, even while complying with regulations.","context":["EMI problems? Part two: Where does EMI come from?\nBonnie Baker -March 15, 2012\nElectromagnetic interference is a part of our lives. Many people think that the proliferation of electronic products is a good thing because they improve our comfort, safety, and health (Reference 1). These products also bring with them the potential for electronically harmful EMI signals. EMI signals can come from various sources, including the common electronic devices around us, as well as vehicles and heavy equipment. In automotive designs, some of these EMI generators reside in the same cabinet as the vehicles’ sensitive electronic circuits. This proximity affects the audio equipment, automatic door controls, and other equipment.\nEvery electronic device, including cell phones, creates both good and bad characteristics. Cell phones these days offer the convenience of talking to friends, family, and business associates from just about anywhere. However, they also have the potential to produce EMI signals—and those signals are only part of the problem. The evolution of these devices exceeds the basic phone services by including smartphone capabilities.\nNeighboring equipment and circuits do not expect this type of EMI noise. Cell phones rely on high levels of RF energy to do their jobs. Although they comply with regulations, they may become sources of unintended EMI to susceptible devices.\nPCBs, clock circuits, oscillators, digital circuits, and processors also can be sources of EMI in circuits. Electromechanical devices that switch currents produce EMI during make-or-break operations. These EMI signals do not necessarily have a negative effect on other electronic equipment. The spectral content and intensity of an EMI signal determine whether it has the potential for an unexpected response from a susceptible circuit.\nYou can simplify the spectral content of a digital signal to its frequency and rise time. The clock or system frequency establishes a time reference for the circuit, but its edge rates create interfering harmonics. Figure 1 shows the spectral content of a 10-MHz square wave. The 10-MHz signal has an edge rate of 10 nsec. The magnitude of these harmonics decreases with frequency. Generally, the potential EMI for this type of signal spans to the maximum frequency, or 1/(π×tRISE), where tRISE is the rise time, equating to approximately 31.8 MHz for a 10-nsec edge rate.\nThe figure shows that the last significant harmonic occurs at 30 MHz. Meanwhile, the 1-nsec edge rate in Figure 2 equates to a maximum frequency of 318 MHz. The EMI harmonics might cause interference in your circuit if it is susceptible to frequencies within the 318-MHz bandwidth.\nIt is better to stop the interfering signal at its source, rather than allow it to propagate through circuits. As for vehicles, carmakers are constructing more vehicle bodies with plastic, which becomes a problem when you need to find a low-impedance ground or provide shielding.\nOnce the signals are free and roaming about, they stand a chance of entering your sensitive systems and wreaking havoc. Next month’s column will detail how the EMI signal travels through the medium to get to your circuits.\nBonnie Baker is a senior applications engineer at Texas Instruments and author of A Baker’s Dozen: Real Analog Solutions for Digital Designers."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:626b7981-58d2-44c7-896f-89a191a192a3>"],"error":null}
{"question":"What role do incentives and specialization play in military assistance programs and talent retention?","answer":"In military assistance programs, incentives and specialization play complex roles but face significant challenges. The US Army's current incentive structure does not properly reward the train, advise, and assist mission, as advancement prioritizes command time and adaptability over regional specialization. This creates a dilemma where the investment in regional expertise needed for Security Force Assistance missions can actually hurt an officer's career prospects. From a broader talent management perspective, organizations need various incentive strategies for retention, including bonuses, professional development opportunities, and succession planning. However, certain retention incentives like salary increases must be carefully justified to avoid discrimination claims. Additionally, sign-on bonuses can be used for recruitment, typically with minimum employment commitments to protect the organization's investment. The success of these programs ultimately depends on balancing the need for specialized expertise with career advancement opportunities.","context":["The Cipher Brief’s Academic Incubator program partners with colleges and Universities across the country to highlight the voices of the next generation of national security leaders.\nStephen Rodriguez is a Managing Partner at One Defense, Senior Advisor at the Atlantic Council, and Senior Innovation Advisor at the Naval Postgraduate School.\nZachary Shaw is a 1st Lieutenant in the U.S. Army Reserves and a student at Georgetown University’s School of Foreign Service and University Law Center.\nACADEMIC INCUBATOR — To prepare for the next large-scale conflict, the United States (U.S.) and its allies in the first line of defense need to accept their missions, and the U.S. needs to align its Security Force Assistance operations to accomplish those missions. Allied forces on the front line will fight to delay the enemy; until the momentum swings back in their favor, they will fight an insurgency. The U.S. must reorient and harmonize its Security Force Assistance efforts—specifically the Defense Security Cooperation Agency and the Army’s Security Force Assistance Brigades—to best enable partners in their delay and insurgency fights.\nThe next major world conflict will sweep through bordering nations as in previous great power conflicts. As during the fall of Belgium and Luxembourg in World War I and all of Germany’s neighbors in World War II, states bordering China and Russia will succumb quickly against overwhelming force.\nOnce overrun, victors will occupy these states until other great powers come to their aid. Perhaps that occupation will last only for several years, perhaps longer. Taiwan will fare no better in the next large-scale conflict than in 1895. Ukrainians have fought an insurgency for the last six years with no end in sight short of a great power conflict.\nU.S. Security Force Assistance must tailor its aid to these fights—the delay and the insurgency. In a high-intensity war U.S. partners will need to trade space for time initially, and the equipment and training the United States provides should reflect this reality. After this fight, allied forces will need to disrupt their occupiers’ operations. U.S. assistance should match this need to fight an insurgency.\nCurrent U.S. Security Force Assistance efforts to assist critically located allies do not match delay and insurgency mission requirements. The Department of Defense’s 20,000-strong Defense Security Cooperation Agency (DSCA) leads Security Force Assistance efforts to “build capacity of foreign security force to respond to shared challenges.” The U.S. Army extends its global power projection capability through this process by selling interoperable weapons and equipment along with the maintenance and support that they require.\nYet, these sales do not align with the mission sets allied partners will face during a great power conflict. Neither do they match the shallow depth of partners’ pocketbooks. How will 4 Blackhawks, 230 Humvees, 84 strykers and 500 JLTVs hold against a Russian attack? How will 108 Abrams tanks and 66 F-16s help Taiwan delay a Chinese invasion? With long-range precision fires, a great power adversary will quickly destroy the small number of technologically advanced allied armored vehicles and air assets.\nMeanwhile, the U.S. Army developed SFABs to enhance readiness and capabilities of Brigade Combat Teams while maintaining and improving security in allied and partner nations. SFABs focus on the train, advise, and assist role and field specially trained units of non-commissioned and commissioned officer volunteers. By relieving Brigade Combat Teams of these missions, the U.S. Army enables these units to prepare for the next great power conflict. Through the regionalization of SFABs, the Army intends to enable lasting partnerships with allies.\nDespite intentions to apply this strategy to allies on the front of the next great power conflict, SFABs will likely befall a fate similar to Special Forces and struggle to maintain their regional focus throughout the unending War on Terror. The first three SFABs to deploy all supported the Resolution Support Mission in Afghanistan and will likely continue to support missions in the Middle East.\nWhile the U.S. has announced its intent to withdraw from Afghanistan, SFABs will likely need to continue to deploy to the Middle East. As long as central governments remain weak, military challenges will remain unsolvable. Without American domestic support for holistic nation-building, the desired end-state of the SFAB mission in new democracies —a capable military subordinate to civilian authority—is an oxymoron. If SFABs accomplish their mission, by necessity, the weak government of the nation-state will not be able to control the strong military. This outcome risks exacerbating political instability in a partner country.\nIf half of SFAB deployments support the Middle East, the Army cannot enable the consistency and regionalization required to develop partnerships in nations on the front lines of the next large-scale conflict. With rotating deployments, SFABs cannot regionally specialize, and without consistency their presence will fail to synergize with other forms of U.S. aid and relationship-building.\nOther military units foster partnerships with U.S. allies on the front lines, but these units can meet only certain train, advise, and assist requirements of the next great power conflict. Special Operations Forces maintain a consistent presence in many of these partner nations and provide similar assistance to the native commandos. With continued optempo in Afghanistan and budget cuts, Special Operations Forces will struggle to fund these relationships. Even if they prioritize these missions, the training provided primarily enables foreign special operators, not the majority of troops. The Army National Guard’s State Partnership Program cannot hope to fill the remaining gaps in assistance.\nTo shift the strategic balance against its great power competitors, the US must match its assistance to the missions faced by allies. Despite the misalignment of recent efforts, the DSCA’s sales offer a unique opportunity to augment allied military defense strategies. Certain conventional capabilities will slow adversary momentum in World War III, but only if U.S. sales to regional allies optimize to the delay mission. The United States needs to match its Security Force Assistance to that mission. For example, the price of one F-16 ($120M) would buy 80,000 AT4 recoilless rifles ($1500), a powerful weapon in the fight over future megacities the US Army plans to fight in. The US has appeared to take steps in the right direction with recent sales of Javelin missiles to Ukraine, Georgia, Estonia, and Poland, but these partners buy Javelins because of their value in a conventional fight rather than their value during an insurgency.\nThe upcoming deployments to the Pacific, Africa, and Latin America mark a step in the right direction. For future success, train, advise, and assist missions must require regionalization and consistency, and the U.S. Army intends to model SFABs on Special Forces Groups’ regionalization. To do so, the U.S. needs to create an agile feedback loop between the DSCA and units on the ground like SFABs and Special Operations Forces to prepare for a modern large-scale conflict. Creating a realistic delaying strategy and modernized insurgency tactics will require flexibility to experiment. Once they receive the interoperable hardware and learn the procedures required to work with coalition forces, their mission is to stretch those capabilities as far as possible. Similarly, insurgent innovation cells will need to make the most of open-source and off-the-shelf technologies which avoid lengthy government contracts. SFABs will work with those on the ground to constantly diagnose the needs of partners, create interoperable solutions on a budget, ensure the DSCA’s follow-through on providing avenues to those solutions, and then train, advise, and assist partners in the implementation of those solutions. The DSCA must provide clearer budgetary boundaries, more flexibility in the spending of those budgets, and overhead cover to SFABs and regional militaries to discover innovative and scalable solutions.\nThis type of partnership will require that Security Force Assistance take a wider approach in its partnerships – incorporating the private sectors of both the United States and the regional allies. Yes, the United States already has partnerships with many defense companies, and many democratized solutions are open source. Many more, however, belong to small and mid-sized businesses—in both the US and partner nations. Army Futures Command, the Defense Innovation Unit, SOFWERX, and others already have created ecosystems to solve the problems regional partners face, and would jump at the opportunity to integrate into a feedback loop on the front lines of the next great power conflict.\nThe U.S. must also be agile enough to grapple with the adversary it faces, rather than the one it trained against. Iraq taught us this in spades. In order to fully align the US Army’s Multi-Domain operating concept and doctrine with the National Defense Strategy, the SFABs must be employed with a strategic vision for the Geographic Combatant Command they support. This will preclude SFABs becoming “band-aid” solutions for missions the U.S. Army doesn’t want to deploy a Brigade Combat Team for and vice versa. It will also enhance our regional allies in ways that take advantage of their comparative advantages.\nEnhanced Security Force Assistance also faces talent management challenges. The US Army incentive structure currently does not reward the train, advise, and assist mission.\nAdvancement in the Army comes from command time and adaptability to each 3-year rotation, not advising and specialization. The SFAB mission requires an investment into regional expertise which takes individual specialization that can derail an aspirational officer’s career. Unless Security Force Assistance Command can avoid the pitfalls of the AfPak Hands program which hurt the careers of its participants, it will fail to recruit and retain the specialists required for mission success.\nIn addition to individual commitment, the success of an expanded Security Force Assistance Command will require strategic commitment to U.S. allies. SFABs will struggle to gain the long-term support they need to develop relationships with partner nations, the DSCA, and existing Security Force Assistance efforts. If SFABs do not have the staying power to follow through on their commitments, both local and U.S. allied groups will not follow their lead. The State Department, Special Operations Forces, and even Army National Guard partners were on the ground before SFABs existed as a concept and will likely be there long after SFABs leave. Without a demonstrable commitment for an extended period of time, SFABs will have little impact on the direction of security development. U.S. national security will be the casualty.\nThe authors are grateful to Dr. Susan Bryant and LTC Christopher De Ruyter for their editorial advice during the production of this article.\nRead more expert-driven national security insight, perspective and analysis in The Cipher Brief","Recruitment and retention are two human resources functions that require strategic thought and planning. Talent management--an area of human resources which includes recruitment and retention--is extremely important to your organization's growth. Your business' most valuable assets are the talent, expertise and resources of your work force. Recruiting and retaining the best talent can only improve the value of the your assets.\nRecruiting Qualified Applicants\nEmployment specialists who devise creative ways to recruit the most qualified applicants increase their own visibility in professional associations, seminars and other activities that give the employment specialist and your company the greatest exposure. By demonstrating to the community that your organization is an employer of choice, the most qualified applicants will have conducted research on your company to ensure they are spending their time wisely in considering a job with your company. Other ways employment specialists recruit talented and qualified applicants is by organizing a job fair or participating in a job fair that is widely publicized as being a promising event for job seekers. Many job fairs these days attract hundreds of people who show initiative and motivation in their search for the right job. A qualified applicant has the technical skills necessary for a role with your company; however, some of the best applicants are those who craft a thorough and diligent job search. There are also ways to incentivize potential applicants. In times when there are shortages in the work force or in particular occupations, employers will offer sign-on bonuses. The typical sign-on bonus carries with it a commitment to stay with the company for a minimum amount of time--you don't want your investment in a new employee to go down the drain after only six months of employment. Think carefully about your recruitment strategy if you intend to pay premiums for applicants you think you can't do without.\nRetaining Talented Employees\nThis is probably one of the trickiest endeavors upon which a small business can embark because of the type of strategy required in retaining employees who you believe add value to your organization. Developing a retention strategy requires special skills in determining which employees are likely to seek opportunities elsewhere and which of them are most valuable to your business. Retention incentives can range from bonuses to professional development. Succession planning can also play a role in your retention strategy. If your human resources department is constructing a succession plan, identify the most promising employees who show aptitude for climbing your organization's ladder. Salary increases are another retention strategy, although it's a difficult case to make when employee compensation is modified in ways that cannot be justified in case questions arise. Raising the salaries of employees you want to retain--simply because you want them to remain in your employ--can backfire and is not the ideal method of retention. Depending on the employees you intend to retain through salary increases, your business may be unfairly accused of discriminatory employment practices. Consult the U.S. Equal Employment Opportunity Commission for information about the Equal Pay Act of 1963 and the Lilly Ledbetter Fair Pay Act of 2009. Weigh the costs of spending money to retain certain employees against the cost to hire. For employees whom you're unsure about retaining, it may be a better decision to recruit for a replacement and assume the cost to hire.\nTapping In-House Talent\nAgain, your work force, or human capital, is extremely valuable to you and as such, perhaps they can play a role in the recruitment and retention of qualified applicants and talented employees. Establishing an employee referral program is an ideal way of recruiting applicants. Individuals who share similar worth ethics, practices and employment records tend to associate with one another. Ask current employees for recommendations and create an employee referral program that rewards them should the referred applicant eventually become an employee. If you company utilizes a 360 degree performance appraisal system, look closely at feedback provided from peers of the employees you want most to retain. The insight you gain from their peers may be more helpful to you than appraisal information you receive from the employee's manager.\n- help wanted image by Tom Oliveira from Fotolia.com"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:0d4b13d2-b0ca-4d98-8e4d-89229a2c890a>","<urn:uuid:b279aecf-b3c8-4b6e-93ed-91f95e5d8dad>"],"error":null}
{"question":"Can you explain how long preservation can last - comparing the human embryo freezing duration versus suspended animation in yeast/nematodes? Por favor incluir los tiempos máximos.","answer":"For human embryos, they can theoretically remain viable indefinitely when properly frozen in liquid nitrogen at -321°F, with documented successful pregnancies from embryos stored for up to 10 years. However, the total potential storage duration is not fully known since the procedure has only existed since 1983. For yeast and nematodes in suspended animation, the documented survival period is much shorter - the studies only demonstrated survival for 24 hours under cold conditions when protected by anoxia-induced suspended animation, after which they could reanimate and live a normal lifespan once returned to normal conditions.","context":["June 11, 2010\nSuspended Animation Can Protect Against Lethal Hypothermia\nFindings in yeast and worms may have implications for extending preservation of human organs for transplantation\nHow is it that some people who apparently freeze to death, with no heart rate or respiration for extended periods, can be brought back to life with no long-term negative health consequences? New findings from the laboratory of cell biologist Mark B. Roth, Ph.D., of Fred Hutchinson Cancer Research Center, may help explain the mechanics behind this widely documented phenomenon.Reporting online ahead of the July 1 print issue of Molecular Biology of the Cell, Roth, a member of the Hutchinson Center's Basic Sciences Division, and colleagues show that two widely divergent model organisms \"“ yeast and nematodes, or garden worms \"“ can survive hypothermia, or potentially lethal cold, if they are first put into a state of suspended animation by means of anoxia, or extreme oxygen deprivation.\nRoth and colleagues found that under normal conditions, yeast and nematode embryos cannot survive extreme cold. After 24 hours of exposure to temperatures just above freezing, 99 percent of the creatures expire. In contrast, if the organisms are first deprived of oxygen and thus enter a state of anoxia-induced suspended animation, 66 percent of the yeast and 97 percent of the nematode embryos will survive the cold. Once normal growth conditions are resumed \"“ upon rewarming and reintroduction of oxygen \"“ the organisms will reanimate and go on to live a normal lifespan.\nA better understanding of the potentially beneficial, symbiotic relationship between low oxygen and low temperatures may one day lead to the development of improved techniques for extending the shelf life of human organs for transplantation, Roth said.\n\"We have found that extension of survival limits in the cold is possible if oxygen consumption is first diminished,\" he said. \"Our experiments in yeast and nematodes suggest that organs may last longer outside the body if their oxygen consumption is first reduced before they are made cold.\"\nRoth's laboratory studies the potential clinical benefits of metabolic flexibility \"“ from anoxia-induced reversible suspended animation to metabolic hibernation brought on by exposure to agents such as hydrogen sulfide. The ultimate goal of this work is to find ways to temporarily lower metabolism \"“ like dialing down a dimmer switch on a lamp \"“ as a means to \"buy time\" for patients in trauma situations, such as victims of heart attack or blood-loss injury, by reducing their need for oxygen until definitive medical care can be given.\nRoth first got the idea to study the link between anoxia-induced suspended animation and hypothermia from documented cases in which humans have managed to make complete recoveries after apparently freezing to death. Widely publicized cases include Canadian toddler Erica Nordby, who in the winter of 2001 wandered outside clad only in a diaper. Her heart had stopped beating for two hours and her body temperature had plummeted to 61 degrees Fahrenheit before she was discovered, rewarmed and resuscitated. Another incident that made headlines was that of a Japanese man, Mitsutaka Uchikoshi, who in 2006 fell asleep on a snowy mountain and was found by rescuers 23 days later with a core body temperature of 71 degrees Fahrenheit. He, too, was resuscitated and made a full recovery.\n\"There are many examples in the scientific literature of humans who appear frozen to death. They have no heartbeat and are clinically dead. But they can be reanimated. Similarly, the organisms in my lab can be put into a state of reversible suspended animation through oxygen deprivation and other means. They appear dead but are not. We wondered if what was happening with the organisms in my laboratory was also happening in people like the toddler and the Japanese mountain climber. Before they got cold did they somehow manage to decrease their oxygen consumption? Is that what protected them? Our work in nematodes and yeast suggests that this may be the case, and it may bring us a step closer to understanding what happens to people who appear to freeze to death but can be reanimated,\" Roth said.\nThe mechanism by which anoxia-induced suspended animation protects against extreme cold has to do with preventing the cascade of events that lead to biological instability and, ultimately, death. For example, suspended animation preserves the integrity of cell-cycle control by preventing an organism's cells from dividing in an error-prone fashion. During suspended animation, the cell cycle is reversibly halted. Upon reanimation, the cycle resumes as normal.\n\"When an organism is suspended its biological processes cannot do anything wrong,\" Roth said. \"Under conditions of extreme cold, sometimes that is the correct thing to be doing; when you can't do it right, don't do it at all.\"\nThe first author of the paper, Kin Chan, Ph.D., formerly a postdoctoral research associate in the Roth lab, is now with the Laboratory of Molecular Genetics in the National Institute of Environmental Health Sciences at the National Institutes of Health. The NIH and the National Science Foundation funded this research.\nOn the Net:","Embryo freezing is a procedure that allows embryos to be preserved for later use. The first successful pregnancy resulting from freezing a woman’s healthy embryos was in the 1980s. Since then, many embryos have been frozen for later use. The embryos may be stored to enable a future pregnancy, to donate to others, for medical research or for training purposes. The process begins by using hormones and other medications to stimulate the production of potentially fertile eggs. The eggs are then extracted from the woman’s ovaries to either be fertilized in a lab or frozen for later use.\nSuccessful fertilization may lead to at least one healthy embryo, which can then be transferred to the woman’s womb or uterus. Hopefully, the embryo will develop and the woman can carry the developing infant through pregnancy to a live birth. Since fertilization often results in more than one embryo, the remaining embryos can be preserved through freezing.\nWhat is an embryo, and how is one created?\nA human embryo is created when an egg is fertilized. According to the Oxford Living Dictionaries, an embryo is “a human offspring during the period from approximately the second to the eighth week after fertilization.” Before freezing can take place, suitable embryos have to be created. To create an embryo in the laboratory, the eggs must first be harvested and fertilized. First, the woman will be given hormones to make sure she ovulates correctly. She is then given fertility medications to increase the number of eggs she produces.\nIn the hospital, a doctor will extract the eggs, using an ultrasound machine to ensure accuracy. The eggs may be frozen or used at once. If the woman wishes to become pregnant at once, in vitro fertilization (IVF) or intra-cytoplasmic sperm injection (ICSI) may be used to fertilize the egg. During the process of IVF, the eggs are exposed to sperm and the mixture is cultured in a laboratory. Fertilization may take 16 to 20 hours. The fertilized eggs are called embryos.\nAn embryologist will monitor the development of the embryos over the next 6 days, after which a suitable embryo may be chosen for implantation. In ICSI, once the eggs have been extracted, a single sperm is injected directly into an egg. This may be done if there is a problem with the sperm or if past attempts at IVF have been unsuccessful. While one embryo can be used for pregnancy, others may be frozen.\nHow is an embryo frozen?\nThe main goal of embryo freezing is to preserve the embryo for later use. The biggest problem is the water within the cells. When water freezes, crystals can form. This expansion can burst the cell, causing it to die.\nTo prevent this happening, the water in the embryo’s cells is replaced with a protective substance called a cryoprotectant. The embryos are left to incubate in increasing levels of cryoprotectant before they are frozen.\nOnce most of the water has been removed, the embryo is cooled to its preservation state through one of two methods of embryo freezing:\nSlow freezing: This involves protecting the embryos from damage in sealed tubes and then slowly lowering the temperature in the tubes. This prevents the embryo cells from aging and becoming damaged. Embryos can last much longer in their frozen state than in their fresh state. However, slow freezing is time-consuming, and it requires expensive machinery. Vitrification: In this process, the cryoprotected embryos are frozen so quickly that the water molecules in the embryos do not have time to form ice crystals. This helps to protect the embryos and to increase their survival rate during thawing.\nAfter freezing, the embryos are stored in liquid nitrogen until they are needed for future use.\nSuccess rates of thawing frozen embryos\nThe process of thawing an embryo is relatively successful. Some research has indicated that embryos frozen through vitrification have a better chance of survival, both at the freezing stage and during thawing.\nSide effects of embryo freezing\nAny risks and side effects involved in embryo freezing usually happen during the process of extracting the eggs from the woman’s body. Common side effects from extracting embryos for freezing are typically mild and temporary.\n- Cramping or bloating\n- Feelings of fullness\n- Changes in vaginal discharge\n- Overstimulation of the ovaries\nHow long can embryos be frozen for?\nEmbryos are stored in liquid nitrogen\nIn theory, a correctly frozen embryo can remain viable indefinitely. The embryos are held in sealed containers at temperatures of -321ºF. At this temperature, almost no biological processes such as aging can occur.\nThere are examples of successful pregnancies that have resulted from eggs that had been stored for up to 10 years. There is no long-term research into embryo freezing, because this procedure has only been carried out since 1983. Some countries choose to regulate the length of time an embryo can be stored. Freezing and storing embryos is also expensive, and each clinic has its own rules about what happens if a woman can no longer use her own embryos or keep them frozen.\nFrozen or fresh embryos?\nA study posted in the International Journal of Reproductive Medicine looked at the results of over 1,000 cases of embryo transfer using either fresh or frozen embryos. The results found no statistical difference between using fresh and frozen embryos for transfer. The study noted that frozen embryos could also be used for additional embryo transfers in the future while fresh embryos could not.\nOther research suggests that frozen embryo transfer may be better than with fresh embryos. A recent study compared fresh and frozen embryo transfer. The results indicate that frozen embryo transfer is associated with a higher rate of pregnancy, and better outcomes for both the mother and the embryo.\nWho is embryo freezing best for?\nEmbryo freezing can be used by any woman, but there are certain groups who may find it more beneficial than others. These include women with genetic disorders of ovarian sensitivities, those who are due to undergo chemotherapy, and those who take medications that affect fertility. Women who are approaching advanced reproductive age and are not ready for children yet may also benefit from freezing embryos for later use.\nBy Jon Johnson\nBy Suzanne Falck, MD, FACP Knowledge center"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:ee5d6bf7-eb95-4b82-9eb0-cc5f70f5f097>","<urn:uuid:91775b7d-baa7-400f-9a3d-aa0a1621c3c0>"],"error":null}
{"question":"Can anyone explain why the standard first-order kinetic equations are inadequate for modeling E. coli reservoirs on agricultural grasslands? Need specifics for my environmental risk assessment project.","answer":"First-order kinetic equations lead to an underestimation of the observed E. coli land reservoir, even when using site-specific die-off coefficients. The models fail to account for the bacterial growth phase in dung-pats under field conditions, which results in a significant underestimation of faecal bacteria accumulation on grasslands.","context":["|Appears in Collections:||Biological and Environmental Sciences Journal Articles|\n|Peer Review Status:||Refereed|\n|Title:||Re-shaping models of E.coli population dynamics in livestock faeces: Increased bacterial risk to humans?|\nHeathwaite, A Louise\nHaygarth, Philip M\n|Citation:||Oliver D, Page T, Heathwaite AL & Haygarth PM (2010) Re-shaping models of E.coli population dynamics in livestock faeces: Increased bacterial risk to humans?, Environment International, 36 (1), pp. 1-7.|\n|Abstract:||Dung-pats excreted directly on pasture from grazing animals can contribute a significant burden of faecal microbes to agricultural land. The aim of this study was to use a combined field and modelling approach to determine the importance of Escherichia coli growth in dung-pats when predicting faecal bacteria accumulation on grazed grassland. To do this an empirical model was developed to predict the dynamics of an E. coli reservoir within 1 ha plots each grazed by four beef steers for six months. Published first-order die-off coefficients were used within the model to describe the expected decline of E. coli in dung-pats. Modelled estimates using first-order kinetics led to an underestimation of the observed E. coli land reservoir, when using site-specific die-off coefficients. A simultaneous experiment determined the die-off profiles of E. coli within fresh faeces of beef cattle under field relevant conditions and suggested that faecal bacteria may experience growth and re-growth in the period post defecation when exposed to a complex interaction of environmental drivers such as variable temperature, UV radiation and moisture levels. This growth phase in dung-pats is not accounted for in models based on first-order die-off coefficients. When the model was amended to incorporate the growth of E. coli, equivalent to that observed in the field study, the prediction of the E. coli reservoir was improved with respect to the observed data and produced a previously unquantified step-change improvement in model predictions of the accumulation of these faecal bacteria on grasslands. Results from this study suggest that the use of first-order kinetic equations for determining land-based reservoirs of faecal bacteria should be approached with caution and greater emphasis placed on accounting for actual survival patterns observed under field relevant conditions.|\n|Rights:||Published in Environment International by Elsevier. Environment International, Volume 36, Issue 1, January 2010, pp. 1 - 7.; This is the peer reviewed version of this article.; NOTICE: this is the author’s version of a work that was accepted for publication in Environment International. Changes resulting from the publishing process, such as peer review, editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document. Changes may have been made to this work since it was submitted for publication. A definitive version was subsequently published in Environment International, VOL 36, ISSUE 1, (January 2010). DOI 10.1016/j.envint.2009.08.006|\n|Rowden model and growth_Env Int_REVISED AUGUST 2009.pdf||230.52 kB||Adobe PDF||View/Open|\nThis item is protected by original copyright\nItems in the Repository are protected by copyright, with all rights reserved, unless otherwise indicated.\nIf you believe that any material held in STORRE infringes copyright, please contact firstname.lastname@example.org providing details and we will remove the Work from public display in STORRE and investigate your claim."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:888b4d74-5954-46f3-9ecf-db5ed28eac0c>"],"error":null}
{"question":"How do short-term versus long-term considerations differ when using ROI for capital planning?","answer":"Short-term ROI calculations focus simply on initial investment versus immediate returns, while long-term considerations require a more comprehensive analysis. For proper long-term evaluation, facility managers need to consider complete life-cycle costs including design and installation costs, operations and maintenance, utilities, salvage/disposal costs, and environmental impacts. Long-term analysis should also account for factors like escalating energy costs, efficiency changes over time, and intangible benefits like productivity improvements. While simple ROI is useful for quick comparisons, it fails to capture these crucial long-term elements that affect the true return on capital investments.","context":["Right Tools Aid Capital Planning\nPart 1: ROI? NPV? FMs Who Know Which Method to Use Boost Odds of Project Approval\nROI? NPV? FMs Who Know Which Method to Use Boost Odds of Project Approval\nBy Christopher P. Hodges - May 2011 - Facilities Management\nFinance is rarely the favorite subject of a facility manager. In a profession called on every day to solve problems and react to the demands of the workforce, the image of a firefighter often comes to mind, not that of an accountant. However, the demand for financial skills has never been greater. The last several years have shown that doing more with less is a career-long challenge, not just a temporary mindset. Financial skills in facility management are truly a core competency.\nAmidst shrinking operational and capital budgets in facilities, facility managers have been faced with a new challenge over the last several years — financing sustainable initiatives.\nHow do facility managers change the way organizations manage their capital to encourage sustainability in capital purchases? Capital purchases, by definition, involve large sums of money that, from an organizational standpoint, might be perceived as better spent on something other than bricks and mortar. Facilities are an important asset of most organizations, but the people and profits are most often the focus of upper management. Therefore, when making the argument for a large capital purchase, facility managers would do best to link the purchase to positive long-term effects on the productivity and profit-making ability of the organization.\nThat's not an easy link to make. However, using financial tools that lead to the right conclusions about the impact on an organization's greatest assets — its people — will improve the success rate in getting sustainable capital projects underway.\nBeyond Simple Payback\nThe first obstacle to overcome is the use of simple payback period to justify sustainable capital projects. While it is a good technique to make the first cut, it leaves much to be desired from an accounting standpoint. To make a more compelling business case, facility managers should look to the use of net present value and internal rate of return to make the case.\nMost sustainable initiatives in facilities these days are justified on the basis of simple payback period. Simply put, it's the amount of time required to generate enough savings (usually in energy) to pay back the initial investment.\nAlthough simple payback period is easy to estimate, it leaves out important financial considerations. First, it does not account for the time value of money. Second, once the payback period is reached, it ignores the continued monetary savings of the investment —often the most important part.\nConsider a lighting retrofit that has a simple payback period of 18 months. Simple payback period “uses” the energy savings to justify the fact that the initial cash outlay will be returned to the owner in a mere 18 months — not a difficult concept to grasp or defend. However, remember that the fixture and lamp life is about seven to 10 years. The energy savings of the new system does not stop at 18 months. There are at least 66 more months (and possibly 102 more) of savings to account for. That's all positive cash flow.\nFrom an accounting standpoint it is also important to consider some of the risks or potential negative monetary impacts of the retrofit. How about disposal costs at the end of service life? Hazardous materials? Increasing energy costs? Labor costs? These are all elements of life cycle that need consideration in any financial analysis.\nReturn on investment (ROI) is often used to evaluate capital investment and alternative options. ROI suffers the same limitations as simple payback period. Simple ROI is the “savings” generated by the investment over the initial cost, expressed as a percentage. ROI is still a simple calculation (essentially it's the inverse of the simple payback period). ROI uses financial gain to measure the success of the investment, whereas simple payback puts the same calculation into terms of the time required to realize a gain. ROI has several derivative calculations that can put it in line with an organization's financial philosophy. Other ROI derivations — return on assets, return on equity, return on capital employed — are all ratios that can be calculated based on a company's financial statements to evaluate its effectiveness in investing money. Most of these ROI tools require much more detail than can be presented here.\nRegardless of the economic or financial tool chosen for a proper analysis, the facility manager should consider life-cycle costs of all potential options under consideration. By using more comprehensive financial tools and considering life-cycle costs, the facility manager is positioned to make better business cases for sustainable capital investments.\nMaking a Better Business Case\n1. Use simple payback period only as the “first cut” in determining if the magnitude of the payback period for the sustainable project will be palatable to the organization (but do not reject an option until you have looked a bit further).\n2. Evaluate all of the life-cycle costs of sustainable capital purchases. Be sure to include all hard and soft design and installation costs, operations and maintenance costs, utilities, and salvage or disposal costs, including any environmental costs. Net present value calculations have the advantage of accounting for escalating or declining life-cycle costs such as energy (potentially escalating) and efficiency (potentially declining) over the life of the asset.\n3. Determine the organization's financial accounting philosophy and methodology. Get to know the CFO. Speaking the language of finance within the organization will enhance a facility manager's ability to show the long-term effects of capital investments.\n4. Where possible, capture any productivity improvements, operational enhancements and other intangible benefits of sustainable capital purchases. These are most difficult to come by but should not be ignored. The facility manager should have the best handle on the long-term productivity improvements in the workplace. There is starting to be more scientific evidence of productivity enhancements due to better air quality, more effective lighting, more pleasing work settings, better use of technology, and other soft benefits.\nFollowing these steps is no guarantee that a facility manger will improve the success rate of getting projects approved through the capital budgeting process, but not accounting for these basic financial concepts will virtually guarantee that projects will not get a second look.\n— Christopher Hodges\nMike Harris wrote re: ROI? NPV? FMs Who Know Which Method to Use Boost Odds of Project Approval\non 9/6/2011 10:12:46 AM\nGood posting! I have found that \"credibility\" helps a lot in selling business cases. How do you build credibility? You need to monitor approved business cases to show whether they achieved the planned savings. You can then use this information to lend credibility to future requests.","The Return on Investment Ratio Explained\nThe return on investment ratio (ROI), also known as the return on assets ratio, is a profitability measure that evaluates the performance or potential return from a business or investment. The ROI formula looks at the benefit received from an investment, or its gain, divided by the investment's original cost.\nDefining the Ratio\nROI serves as a returns ratio, allowing a business owner to calculate how efficiently the company uses its total asset base to generate sales. Total assets include all current assets such as cash, inventory, and accounts receivable in addition to fixed assets such as the plant buildings and equipment.\nIf an investment doesn't have a good ROI, or if an investor or business owner has other opportunities available with a higher ROI, then calculating the ROI values on the different opportunities can instruct him or her as to which investments to choose for the best return.\nMany analysts and investors like to use the ROI metric because of its versatility and simplicity. Essentially, it works as a quick gauge of an investment’s profitability, and it's very easy to calculate and interpret for a wide variety of investment types.\nCalculating the Return on Investment\nYou can determine ROI in different ways, but the most frequently used method involves dividing net profit into total assets. The return on investment ratio is also called the return on assets ratio because that investment refers to the firm's investment in its assets.\nCalculate the ratio as follows:\nInvestment gain ( Net Income) / Cost of Investment (Total Assets) = ___ percent\nInterpretation of the Results\nTo interpret the ROI percent results, collect appropriate, comparative data such as trend (time series) or industry data on ROI. The business owner can look at the company's ROI across time and also at industry data to see where the company's return on investment ratio lies. The higher the return on investment ratio, the more efficiently the company is using its asset base to generate sales.\nSay that Joe invested $1,000 in his start-up, Joe's Super Computer Repair. He has a buyer for the business for $1,200. The ROI for this equals Joe's profit or $200 divided by his initial investment, $1000, for a 20 percent ROI.\nJoe also invested $1,000 in Sam's New Computer Sales, and a buyer is looking to pay $1,800. The ROI for this equals the $800 profit divided by his investment of $1,000, or 40 percent. From this comparison, selling Sam's New Computer Sales appears to be the wiser move, with 20 percent vs. 40 percent.\nThe Time Factor\nWhat the ROI formula doesn't tell you, and one of the short-comings of the ROI ratio is the time involved. This metric can be used in conjunction with the rate of return on an asset or project, which does consider the period of time.\nYou can also incorporate the net present value (NPV), which accounts for differences in the value of money over time due to inflation, for even more precise ROI calculations. The application of NPV when calculating the rate of return is often called the real rate of return."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:2548713d-11b6-46cc-9b83-20224d1397b0>","<urn:uuid:97695d27-baca-40ce-af9d-0a72ae3b82dd>"],"error":null}
{"question":"What's the meaning of the acronym MAD-Buck in tree identification, and how does it relate to branching patterns?","answer":"MAD-Buck is an acronym that helps remember which trees have opposite branching patterns - it stands for Maple, Ash, Dogwood and Buckeye trees. In opposite branching, two branches arise from the same spot and are opposite each other, unlike alternate branching where branches arise at different points on opposite sides of a limb.","context":["On July 12 last year I wrote a blog about identifying Norway and Sugar Maples in spring and summer: http://blogs.pjstar.com/gardening/page/7/\nThis winter indentification blog will help you determine which Maple trees are Norway and which are Sugar when the samara (the fruiting bodies) and leaves are on the ground covered by snow. And if Norway Maples are invading your forest this will help you identify and perhaps remove some of these beautiful, but invasive, aliens. In winter-identification branches, bark, and buds are the most helpful elements to identify these Maple trees.\nMaples have an opposite branching pattern as do Ash, Dogwood and Buckeye trees. The acronym, “MAD-Buck,” helps you remember these trees with opposite branches. When two branches arise from the same spot and are opposite each other, then this is an opposite pattern of branching. When two branches arise at some distance from each other on the other side of a limb, then this is termed an alternate pattern of branching. I’ve placed small white arrows in the photo below showing examples of the opposite pattern of branching. The branching pattern and bark texture are the first things I check when identifying a tree in the winter. It’s not always easy to tell if a tree has an opposite branching pattern since one of a pair of older branches is often lost over the course of time. Look at the younger, smaller branches and you’ll be able to more quickly identify the opposite or alternate branching pattern of a tree.\nBark appearance is most helpful when identifying larger Sugar and Norway Maple trees; however, when these trees’ trunks are less than ten inches in diameter, their bark can look very similar to each other. Sugar Maples over a foot in diameter develop bark with more texture, e.g., higher ridges and deeper valleys. The bigger the Sugar Maple tree the more exaggerated the texture with ridges, plates and shelves of grey-brown bark. Some Sugar Maples have such shaggy bark that they resemble a huge shagbark hickory from a distance.\nThe immature Norway Maple’s bark is a thin layer in young trees. As the trees reach about three inches in diameter, a pattern of narrow and shallow longitudinal fissures appear. As the tree trunks increase in diameter, the bark matures with ridges gaining thickness and the straight longitudinal fissures gaining in depth. This combination of the narrow, longitudinal, grey-black ridges and narrow, longitudinal fissures give the appearance in my mind of a biological corduroy. And the mature Norway Maple trunk appears very well dressed to me.\nThe Norway Maple’s terminal bud and associated stem is larger than the Sugar Maple’s. Maroon colored scales overlap and form a rounded end on the Norway Maple’s terminal bud. The Sugar Maple’s smaller and more numerous brown scales shingle its firm conical tip which feels sharply pointed when pressed with a finger. Both types of terminal buds are flanked by two smaller accessory buds. When maple trees have no branches within reach, the terminal buds often can be viewed well enough with binoculars to make an identification. Especially in young maple trees, I believe bud identification is the best way to differentiate the Norway from the Sugar Maple in the winter."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:d9dd8440-30ce-438b-b395-a3daf6f28f45>"],"error":null}
{"question":"What's the key difference in voicing between traditional jazz guitar and 8-string guitar approaches? Super curious about the harmonic possibilities! 🎵","answer":"Traditional jazz guitar voicing typically involves using the thumb for octaves to thicken single-note lines, along with chords that are either strummed with the thumb's fleshy part or played fingerstyle. In contrast, 8-string guitar voicing, as taught by Tosin Abasi, offers expanded harmonic possibilities due to the extended range, allowing for bass techniques to be incorporated and enabling piano-like two-handed tapping approaches for more complex chord voicings.","context":["Most jazz styles revolve around the swing feel - a triplet-based interpretation of eighth-note rhythms. This bouncy feel is contrary to the even-eighth notes of traditional rock.\nIn swing jazz, though, although a tune’s lead sheet may appear to have a straight eighth-note melody, its upbeats - the “and” of each beat - are actually felt at a slightly later point than those of standard eighths like the first and last notes of triplets (counted “one-uh-let, two-uh-let, three-uh-let, four-uh-let”).\nAdd an accent on each upbeat and play slightly behind the beat, and you’ll be on your way to swinging.\nTurning Pentatonic Rock and Blues Licks Into Jazz Licks\nYou can translate many pentatonic blues and rock licks into jazz licks simply by changing their feel and adjusting your technique.\nFor example, to tweak the G minor pentatonic (G-Bb-C-D-F) rock lick in Figure 1A into a bop line in Figure 1B, play with a jazzy tone, replace bends with slides and add a swing feel.\nOf key importance to this transformation is the replacement of the rock lick’s 1/4-step bend from Bb (3rd fret, 3rd string) with a legato slide to B (4th fret, 3rd string), the 3rd of the accompanying G7.\nFigures 2A–D illustrate additional rock licks and their jazzy counterparts.\nTechnique Dos and Don'ts\nAs an addendum to the previous section, here’s an overview of the dos and don’ts of straight-ahead jazz playing.\nTypically, jazz guitarists don’t bend their strings much. Don’t be afraid to do it, but note that in the work of top-notch stylists like Charlie Christian, Wes Montgomery and Joe Pass, bends are rare; slides are used in their place.\nIn Figures 3A–D, time-honored blues and rock bends have been replaced with slides. Vibrato-inflected single notes are also uncommon in jazz guitar. If you hear this technique, it’s usually subtle, with the pitch wavering no more than a half the result of side-to-side “violin-style” vibrato.\nOn the contrary, other rock techniques translate to jazz quite nicely. Octaves can effectively thicken up a single-note line.\nFigures 4A–B compare a rock-flavored unison-bend line with a jazzy, octave-fueled variation. Try playing octaves by brushing your strings with the fleshy part of your pick hand’s thumb.\nChords, too, are often strummed in this fashion, or plucked fingerstyle. Using economy or sweep picking for your arpeggios also gets a thumbs-up in jazz.\nSignature Licks Of Jazz Guitar Greats For Further Study\nBy studying the lines of jazz guitar greats, you’ll get an appreciation for the diversity of melodies that exist in ii–V territory. In addition, your vocabulary will grow by leaps and bounds.\nCharlie Christian, who rose to fame as a member of Benny Goodman’s band, was among the first jazz cats to cop horn lines on guitar. The “box” shape in Figure 5A is home for many of Christian’s dominant licks, such as the one in Figure 5B.\nWes Montgomery, who got his professional start playing Christian’s solos note for note, used his thumb instead of a pick, as in Figure 6A.\nJoe Pass upped the bar for technique with double-time lines (playing steady 16ths over a swing-8ths groove) like the ii–V7–i in Figure 6B.\nPat Martino specializes in chromatic approaches within the realm of Dorian [Figure 7A], and Pat Metheny possesses a unique legato touch [Figure 7B].\nThank you for signing up to The Pick. You will receive a verification email shortly.\nThere was a problem. Please refresh the page and try again.","Tosin explains some of the intricacies of the 8 string guitar such as his personal setup and approach to playing.\nTaught by Tosin Abasi in Tosin Abasi Artist Series seriesLength: 7:49Difficulty: 1.0 of 5\nLead guitarist for Animals As Leaders, Tosin Abasi brings his knowledge of extended range guitars to JamPlay.\nAs an introduction to JamPlay, Tosin Abasi provides an interview outlining his playing style, influences and musical background.Length: 14:46 Difficulty: 0.5 Members Only\nTosin explains some of the intricacies of the 8 string guitar such as his personal setup and approach to playing.Length: 7:49 Difficulty: 1.0 Members Only\nTosin Abasi demonstrates how he uses hybrid picking styles in the song \"On Impulse.\"Length: 9:28 Difficulty: 2.0 Members Only\nTosin discusses harmonic and music theory ideas as they relate to the Animals As Leaders song \"On Impulse.\"Length: 8:38 Difficulty: 2.5 Members Only\nTosin discusses and demonstrates economy picking technique.Length: 14:41 Difficulty: 2.5 Members Only\nTosin explains how he achieved some of the sounds in his song \"On Impulse.\"Length: 8:50 Difficulty: 2.5 Members Only\nTosin Abasi explains how bass style thumping and slap techniques can be performed on an 8 string guitar.Length: 15:26 Difficulty: 2.5 Members Only\nTosin Abasi expands further on economy picking.Length: 9:54 Difficulty: 3.0 Members Only\nTosin Abasi covers jazz voicings for the eight string guitar.Length: 8:18 Difficulty: 2.5 Members Only\nTosin discusses how he voices chords on the eight string guitar.Length: 9:15 Difficulty: 2.0 Members Only\nTosin Abasi discusses how bass techniques can be emulated on guitars with extended ranges as well as standard 6 string guitars.Length: 6:53 Difficulty: 2.5 Members Only\nTosin Abasi takes a look at a two handed tapping technique that emulates a piano-like feel.Length: 31:59 Difficulty: 2.5 Members Only\nTosin Abasi discusses a muted tapping techniques he utilizes in his playing.Length: 5:25 Difficulty: 2.5 Members Only\nIn his 14th lesson, Tosin discusses riffing in compound meter over a straight back-beat.Length: 12:30 Difficulty: 3.5 Members Only\nIn this lesson, Tosin demonstrates a few of his favorite licks that utilize the full range of the eight string guitar as well as the economy picking technique.Length: 23:17 Difficulty: 3.0 Members Only\nTosin Abasi discusses how fingerstyle can be adapted for use on an electric guitar. Additionally, he takes a look at some advanced one string tremolo techniques that can mimic non-percussive bass thumping.Length: 13:24 Difficulty: 2.5 Members Only\nIn his 17th lesson, Tosin discusses how he goes about composing for guitar.Length: 5:59 Difficulty: 1.0 Members Only\nIn lesson 18, Tosin discusses how to organize scale patterns on the neck of the guitar using the CAGED system.Length: 24:30 Difficulty: 2.0 Members Only\nIn this lesson, Tosin demonstrates several alternate picking exercises aimed at improving dexterity, speed, and accuracy.Length: 6:12 Difficulty: 2.5 Members Only\nAbout Tosin Abasi\nView Full Biography\nHi. My name is Tosin Abasi. I'm the lead guitarist for Animals as Leaders. I've been playing the guitar for 15 years, and touring professionally on and off for about 6.\nA majority of that time has been spent playing extended range guitar (7 and 8 strings) . I'm primarily self taught but I studied jazz and classical guitar briefly at the Atlanta Institute of Music.\nThe extended range guitar can offer a lot of possibilities for composition. Unfortunately, the resources available to 6 string guitarist don't exist in the same prominence for the seven guitar (especially not the 8 string guitar). Through my compositions I hope to break down my approach to utilizing the 7 and 8 string guitar in both lead and rhythm work. We'll also examine multiple techniques such as Hybrid picking, Sweeping, Tapping and Slapping.\nOur acoustic guitar lessons are taught by qualified instructors with various backgrounds with the instrument.\nPamela brings a cap to her first 13 JamPlay lessons with another original etude inspired by the great Leo Brouwer. This is...Free LessonSeries Details\nIn this lesson, Freebo covers the basics of right hand technique. This lesson is essential for all up and coming bassists.Free LessonSeries Details\nLesson 40 takes a deeper look at slash chords. Mark discusses why they're called slash chords, and how they are formed.Free LessonSeries Details\nMiche introduces several new chord concepts that add color and excitement to any progression.Free LessonSeries Details\nJamPlay welcomes David Isaacs to our teacher roster. With his first lesson Dave explains his approach to playing guitar with...Free LessonSeries Details\nLesson 7 is all about arpeggios. Danny provides discussion and exercises designed to build your right hand skills.Free LessonSeries Details\nHawkeye teaches several Robert Johnson licks in this lesson. These licks are played with a slide in open G tuning.Free LessonSeries Details\nJamPlay is proud to introduce jazz guitarist Peter Einhorn. In this lesson series, Peter will discuss and demonstrate a way...Free LessonSeries Details\nRich Nibbe takes a look at how you can apply the pentatonic scale in the style of John Mayer into your playing.Free LessonSeries Details\nMark Nelson introduces \"'Ulupalakua,\" a song he will be using to teach different skills and techniques. In this lesson, he...Free LessonSeries Details\nOur electric guitar lessons are taught by instructors with an incredible amount of teaching experience.\nBilly starts his artist series off with a lesson on something he gets asked the most to explain: right hand 3 finger technique.Free LessonSeries Details\nJoel Kosche talks about creating and composing a guitar solo. He uses his original song \"Sunrise\" as an example.Free LessonSeries Details\nKnown around the world for his inspirational approach to guitar instruction, Musician's Institute veteran Daniel Gilbert...Free LessonSeries Details\nMark Brennan teaches this classic rock song by Jethro Tull. Released on the album of the same name in 1971, this song features...Free LessonSeries Details\nLearn a variety of essential techniques commonly used in the metal genre, including palm muting, string slides, and chord...Free LessonSeries Details\nBryan Beller of the Aristocrats, Dethklok, and Steve Vai takes you inside his six step method to learning any song by ear....Free LessonSeries Details\nJamPlay is proud to welcome senior professor and Coordinator of Guitar Studies at the University of Colorado at Denver,...Free LessonSeries Details\nTosin explains some of the intricacies of the 8 string guitar such as his personal setup and approach to playing.Free LessonSeries Details\nThis is a crucial lesson that explains tablature, how to read it, and why it's important.Free LessonSeries Details\nAllen shows you the 24 rudiments crucial to developing finger dexterity. This is a short lesson but the exercises here can...Free LessonSeries Details\nTake a minute to compare JamPlay to other traditional and new methods of learning guitar. Our estimates for \"In-Person\" lessons below are based on a weekly face-to-face lesson for $40 per hour.\n|Price Per Lesson||< $0.01||$4 - $5||$30 - $50||Free|\n|Money Back Guarantee||Sometimes||n/a|\n|Number of Instructors||78||1 – 3||1||Zillions|\n|Interaction with Instructors||Daily Webcam Sessions||Weekly|\n|Professional Instructors||Luck of the Draw||Luck of the Draw|\n|Learn Any Style||Sorta|\n|Multiple Camera Angles||Sometimes||-||Sometimes|\n|Learn in Sweatpants||Socially Unacceptable|\n|Gasoline Needed||$0.00||$0.00||~$4 / gallon!||$0.00|\nMike H.\"I feel like a 12 year old kid with a new guitar!\"\nI am 66 years young and I still got it! I would have never known this if it had not been for Jamplay! I feel like a 12 year old kid with a new guitar! Ha! I cannot express enough how great you're website is! It is for beginners and advanced pickers! I am an advanced picker and thought I had lost it but thanks to you all, I found it again! Even though I only play by ear, I have been a member a whopping whole two weeks now and have already got Brent's country shuffle and country blues down and of course with embellishments. Thank you all for your wonderful program!\nGreg J.\"With Jamplay I can fit in a random session when I have time and I can go at my own pace\"\nI'm a fifty eight year old newbie who owns a guitar which has been sitting untouched in a corner for about seven years now. Last weekend I got inspired to pick it up and finally learn how to play after watching an amazing Spanish guitarist on TV. So, here I am. I'm starting at the beginning with Steve Eulberg and I couldn't be happier (except for the sore fingers :) Some day I'm going to play like Steve! I'm self employed with a hectic schedule. With Jamplay I can fit in a random session when I have time and I can go at my own pace, rewinding and replaying the videos until I get it. This is a very enjoyable diversion from my work yet I still feel like I'm accomplishing something worthwhile. Thanks a lot, Greg\nBill\"I believe this is the absolute best site for guitar students.\"\nI am commenting here to tell you and everyone at JamPlay that I believe this is the absolute best site for guitar students. I truly enjoy learning to play the guitar on JamPlay.com. Yes, I said the words, \"\"enjoy learning.\"\" It is by far the best deal for the money."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:b5e5a23d-1cf0-4216-b15a-5ef768b5e942>","<urn:uuid:f3e82b83-9a9b-4ee3-afbc-416598413f03>"],"error":null}
{"question":"How do T-cell cytokines and targeted therapies like vemurafenib interact in treating metastatic melanoma, and how does this compare to the traditional chemotherapy approach with dacarbazine?","answer":"T-cell effector cytokines (IFN and TNF) synergize with vemurafenib to induce cell cycle arrest in melanoma cells, with this combination reducing proliferative capacity beyond single agent treatment specifically in BRAFV600E-mutant melanomas. In contrast, traditional chemotherapy with dacarbazine-based regimens historically showed modest response rates of 15-20%, though some patients can show dramatic responses to chemotherapy even after failing targeted therapies, particularly in cases with specific mutations like ATM that affect DNA repair.","context":["Both targeted inhibition of oncogenic drivers mutations and immune-based therapies show\nBoth targeted inhibition of oncogenic drivers mutations and immune-based therapies show efficacy in treatment of patients with metastatic cancer but responses can be either short-lived or incompletely effective. or adoptively moved cells within tumors. Rather, we noticed that the T-cell effector cytokines IFN and TNF synergized with vemurafenib to BAY 63-2521 straight induce cell routine criminal arrest of SB-3123 most cancers cells The mixture treatment program of vemurafenib and effector cytokines decreased proliferative capability beyond one agent treatment also in individual melanoma-derived cell lines and was limited to malignancies bearing a BRAFV600E mutation. This system hence may not really end up being solely model-specific and could end up being suitable in a wide range of BRAFV600E-mutant most cancers tumors. Mechanistically, molecular profiling of treated SB-3123 indicated that the supply of vemurafenib marketed the sensitization of SB-3123 to the anti-proliferative results of T-cell cytokines. The unforeseen acquiring that resistant cytokines synergize with oncogene inhibitors to induce development detain provides main significance for understanding cancers biology at the intersection of oncogenic and resistant signaling and provides a basis for style of combinatorial healing strategies for sufferers with metastatic cancers. Materials and Strategies Cell lines The SB-3123p cell series was made from automatically developing most cancers in a feminine transgenic mouse. The growth was in the beginning divided into little BAY 63-2521 items and after that incorporated onto C57BT/6 feminine rodents. Developing tumors had been serially incorporated onto C57BT/6 rodents and after the second passing had been minced and seeded under cells tradition circumstances to derive the SB-3123p cell collection. M16 (L-2b) is definitely a BRAF wild-type murine most cancers cell collection and A375 is definitely a BRAFV600E mutant human being most cancers cell collection both acquired from the Country wide Malignancy Company growth database. The BRAFV600E mutant human being most cancers UACC-62 cell collection was a present from Dr. Susan Bates (Medical Oncology Department, Country wide Malignancy Company, Bethesda, MD). MC38 (L-2b) is definitely a digestive tract malignancy murine cell collection acquired from the Country wide Malignancy Company growth database. Mouse Melan-a cells had been a present from Dr. Thomas Hornyak (University or college of Baltimore College of Medication, Baltimore, MD). Patient-derived, pathology-confirmed most cancers cell lines utilized in this research had been generated from individuals with metastatic, pathology-confirmed most cancers getting treatment under institutional review board-approved medical protocols in the Medical procedures Department of the Country wide Malignancy Company. Informed permission was acquired from all topics. Most cancers cell lines grew from enzymatically or mechanically distributed cells or from 1C3 micron growth pieces that had been cultured in 24-well china (Corning 3524, Corning, Ny og brugervenlig), one fragment or 1×106 cells/ml in 2 ml/well of RPMI 1640 BAY 63-2521 moderate (Lonza, Walkersville, MD), supplemented with 10% heat-inactivated fetal bovine serum (Hyclone, Described; Logan, Lace) and 100 U/ml penicillin, BAY 63-2521 100 ug/ml Streptomycin and 10ug/ml Gentamicin (Lonza). The set up cell lines grew as monolayer civilizations. Genomic portrayal of individual made most cancers cell lines was performed through exome sequencing as previously defined (18). SB-3123, A375, T16 and UACC-62 cells had been preserved in lifestyle mass media constructed of DMEM (Lifestyle Technology) with 10% heat-inactivated fetal bovine serum (FBS) (Sigma), 1% GlutaMAX (Lifestyle Technology), 1% (sixth is v/sixth is v) penicillin/streptomycin (Lifestyle Technology), 1% MEM nonessential Amino Acids (Lifestyle Technology), 1% Salt Pyruvate (Lifestyle Technology), 0.1% 2-Mercaptoethanol (55 SRA1 mM) (Lifestyle Technology) in 5% Company2 at a regular temperature (37C) and dampness. Trophic factor-deficient mass media comprised of DMEM supplemented just with 1% GlutaMAX, 1% (sixth is BAY 63-2521 v/sixth is v) penicillin/streptomycin, 1% MEM nonessential Amino Acids, 1% Salt Pyruvate and 0.1% 2-Mercaptoethanol. Melan-a cells had been cultured in RPMI 1640 lifestyle mass media (Lifestyle Technology) with 5% heat-inactivated FBS, 0.1% phorbol 12-myristate 13-acetate (PMA) (Sigma), 1% (v/v) penicillin/streptomycin and 1% GlutaMAX. All cell lines utilized had been verified to end up being mycoplasma-free. No extra acceptance assay was performed. Immunoblot analysis Traditional western mark analysis was performed using regular protocols. Entire cell lysates had been ready using RIPA lysis barrier (Thermo Scientific). Protein had been separated by SDS -Web page, implemented by regular immunoblot evaluation using phosphor-Erk ?, total Erk ?,.","Is there still a role for cytotoxic chemotherapy after targeted therapy and immunotherapy in metastatic melanoma? A case report and literature review\n© The Author(s) 2017\nReceived: 16 February 2016\nAccepted: 30 September 2016\nPublished: 13 January 2017\nMetastatic melanoma has long been considered to have a very poor prognosis and to be chemo-resistant. However, a subgroup of patients with metastatic melanoma presents remarkable responses to chemotherapeutic agents, even in the absence of a response to modern targeted therapies and immunotherapies; accordingly, determining predictive biomarkers of the response to chemotherapies for metastatic melanoma remains a priority to guide treatment in these patients. We report a case study of a patient with B-Raf proto-oncogene serine/threonine kinase-mutated metastatic melanoma harbouring many genetic mutations. The patient did not respond to prior targeted therapies or immunotherapies but experienced a dramatic objective radiological and clinical response to subsequent dacarbazine-based chemotherapy. In the era of targeted therapies and immunotherapies for metastatic melanoma, cytotoxic chemotherapies may still represent an interesting therapeutic weapon in a well-defined subgroup of patients presenting with specific genetic and molecular features.\nKeywordsMetastatic melanoma Chemotherapy Immunotherapy Checkpoint inhibitors Vemurafenib ATM mutation Chemosensitivity\nIn the recent era of emergent targeted therapies and immunotherapies, metastatic melanoma is the first solid tumor to benefit from this therapeutic revolution and has become the pioneer malignancy in these therapeutic areas. The presence of the B-Raf proto-oncogene serine/threonine kinase (BRAF) V600 mutation in 40%–50% of melanomas and its role as a predictive factor of response to BRAF inhibitors in combination with mitogen-activated protein kinase kinase (MEK) inhibitors were crucial in establishing an appropriate therapeutic management algorithm for metastatic melanomas .\nAlthough melanoma has long been considered to be chemo-resistant, cytotoxic chemotherapy represented the only available therapeutic option for metastatic melanoma before the era of targeted therapies and immunotherapies. Many chemotherapy regimens only induced modest response rates; the most common regimens were dacarbazine-based and induced objective response rates (ORRs) ranging from 15% to 20% . An observational study has indicated prolonged remission for 7 years . The combination of dacarbazine with other agents, especially cisplatin, produced better results than dacarbazine alone in terms of ORR and progression-free survival but not overall survival .\nCurrently, in BRAF V600-mutated metastatic melanoma, the combination of BRAF and MEK inhibitors is considered the standard of care, with response rates exceeding 70% for first-line treatment . In BRAF non-mutated metastatic melanoma, immune checkpoint inhibitors have been the standard of care since the approval of ipilimumab in March 2011 , pembrolizumab in September 2014 , and nivolumab in December 2014 as first-line therapies . More recently, the combination of nivolumab and ipilimumab (October 2015) has shown an ORR exceeding 75%, a gain accompanied by higher and more pronounced toxicities than those observed in single-agent immunotherapy trials .\nIn this paper, we report a case of a patient with BRAF-mutated metastatic melanoma harbouring many genetic mutations who did not respond to targeted therapies (BRAF and MEK inhibitors) or to immune checkpoint inhibitors, such as ipilimumab and nivolumab, but presented an impressive and dramatic response to subsequent cytotoxic chemotherapy consisting of dacarbazine and cisplatin. We also discuss the potential role of chemotherapy after BRAF and MEK inhibitor treatment and immunotherapy as well as the potential interest and benefit of chemotherapy in particular subgroups of patients.\nA 56-year-old man with a history of hypercholesterolemia and myocardial infarction presented in December 2013 with a dermatologic lesion in the left lumbar region. The pathologic examination of the excisional biopsy revealed an ulcerated malignant melanoma of 6.5 mm in thickness (Breslow). The type was a superficial spreading melanoma, and the Clark level was 4.\nAfter a wide excision of the lesion with 2 cm margins, the pathologic results of the sentinel lymph nodes showed an invasion of malignant melanoma, requiring a subsequent complete left inguinal lymph node dissection. The pathologic TNM stage was pT4bpN1acM0 according to the 7th edition of the American Joint Committee on Cancer/Union for International Cancer Control (AJCC/UICC) staging system. The primary tumor exhibited the typical BRAF V600E mutation.\nFour months later, in April 2014, the patient presented a locoregional cutaneous and subcutaneous relapse in the lumbar region. First-line treatment consisted of the single-agent BRAF inhibitor vemurafenib, which had to be stopped, despite a clinical response, due to unacceptable toxicities, such as a grade 4 skin rash and a grade 2 daily fever. A shift to dabrafenib in combination with trametinib in a medical need programme was initiated in July 2014 and stopped in December 2014 after clinical progression of the lumbar local relapse and of multiple in-transit metastases.\nBetween January and March 2015, the patient received 4 injections of ipilimumab, a monoclonal anti-cytotoxic T-lymphocyte-associated protein 4 (CTLA4) antibody. The main adverse effect after the fourth injection was excessive fatigue, which was attributed to auto-immune hypophysitis with adrenal and gonadal insufficiencies requiring hormonal substitution of hydrocortisone and topic testosterone, respectively. After 4 doses of ipilimumab, positron emission tomography/computed tomography (PET/CT) unfortunately showed progressive disease and the appearance of lung and lymph node metastases.\nTwo molecular analyses of the tumor, one using OncoDeep (OncoDNA, Gosselies, Belgium) and the other using the TruSeq Illumina Cancer Panel (Illumina Inc., San Diego, CA, USA), were performed after the failure of nivolumab (at the end of August 2015). The results were discordant: the OncoDNA detected only one BRAF V600E mutation, whereas the Illumina Panel (TruSeq Amplicon Cancer Panel) detected BRAF V600E-F-box and WD repeat domain containing 7 R385C mutations (FBXW7), a kinase domain insert receptor Q472H variant (KDR), a V-Ki-ras2 Kirsten rat sarcoma viral oncogene homologue G12D mutation (KRAS), a tumor protein P53 P72R variant (P53), and a polymorphism of Ataxia telangiectasia mutated (ATM) −c.8850 + 60A > G.\nSince September 2015, the patient had received 4 cycles of cytotoxic chemotherapy consisting of intravenous injections of dacarbazine (350 mg/m2) and cisplatin (25 mg/m2) for 3 consecutive days, given every 3–4 weeks. An ongoing, impressive, and dramatic response of all metastases (the sizes decreased by more than 80%) was documented after 3 cycles of chemotherapy (Fig. 1c, d).\nDuring chemotherapy, a second biopsy was performed, and the same mutations were detected, but there was a difference in the percentage of cells with the BRAF V600E mutation (41% in August 2015 and 36% in November 2015).\nAfter the failure of checkpoint inhibitors, an immunological biomarker and microenvironment analysis revealed the absence of PD-1/programmed death-ligand 1 (PD-L1) (Ventana biomarker assay) staining, the absence of CD20 (B cells) staining, and diffuse and weak CD3 (T cells) staining.\nThe particular clinical feature of our case was the presence of multiple genetic mutations in the tumor, which did not respond to targeted therapies or checkpoint inhibitors but exhibited a major response to dacarbazine and cisplatin combination chemotherapy in fifth-line therapy.\nApart from the differences (e.g., depth of coverage, number of genes analyzed, and devices and analysis systems) between the OncoDeep test and Illumina panel, the discordant results (i.e., the greater number of mutations detected using the Illumina panel) may be explained by tumor heterogeneity due to the different origins of the two samples.\nThis rare case raises a number of questions. Is there a subgroup of metastatic melanomas that still benefit from cytotoxic chemotherapy? Are there any predictive factors leading to this response? Should the presence of the observed genetic mutations in metastatic melanoma be considered a predictive factor for chemo-sensitivity? Is there a potential role for immune checkpoint inhibitors that render these tumors more chemo-sensitive by modifying the microenvironment?\nMany hypotheses can be considered with respect to these questions. The first and strongest hypothesis is that the observed response is explained by the presence of an ATM mutation in this tumor. The ATM gene is responsible for the repair of DNA double-strand breaks . The presence of an ATM mutation leads to a dysfunction in the repair process for DNA double-strand breaks and consequently could render the tumor more chemo-sensitive, especially to platinum agents, according to the literature [13, 14]. This process is comparable to breast cancer 1 gene (BRCA1)-mutated breast cancer, which exhibits acceptable sensitivity to platinum agents and/or poly(ADP-ribose) polymerase (PARP) inhibitors. By extrapolation, the use of PARP inhibitors could be considered an interesting therapeutic modality in the progression of chemotherapy.\nA second hypothesis may be the “terra incognita” effect of immunotherapy (anti-CTLA4 and anti-PD-1) on the subsequent response to chemotherapy. Cytotoxic agents seem to enhance the anti-tumor immune response by releasing antigens after cellular destruction [15, 16]. Some basic researches on immunological biomarkers and microenvironments, e.g., studies of intratumoral lymphoid infiltrates with intratumoral PD-L1 expression and the interferon-gamma pathway in tumor tissue, show that these factors can predict the response to immune checkpoint inhibitors [17, 18]. In fact, high expression of PD-L1 and the presence of tumor-infiltrating lymphocytes are associated with better responses to checkpoint inhibitors [19, 20].\nFinally, to answer these questions, a retrospective mutation-based study could be used to evaluate the response rate of metastatic melanomas to different therapeutic modalities according to each individual mutation. Based on the results of this observational study, a randomized trial aimed at comparing chemotherapy to targeted therapies and checkpoint inhibitors based on different mutation profiles should be launched. A similar methodology will be used to confirm or clarify the sustained role of chemotherapy in well-defined subgroups of patients, despite the encouraging and promising results of targeted therapies and/or immunotherapies.\nWe are currently in an exciting era of promising new treatment options for malignant melanoma. Cytotoxic chemotherapy (especially dacarbazine and cisplatin) could nevertheless remain an invaluable therapeutic weapon in specific cases with chemosensitizing mutations.\nSA and KHR initiated the review; SA and KHRS performed the review, wrote the paper, and analysed the data. All authors read and approved the final manuscript.\nThe authors declare that they have no competing interests.\nOpen AccessThis article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.\n- Erdmann F, Lortet-Tieulent J, Schüz J, Zeeb H, Greinert R, et al. International trends in the incidence of malignant melanoma 1953–2008—are recent generations at higher or lower risk? Int J Cancer. 2013;132:385–400.View ArticlePubMedGoogle Scholar\n- Boyle P, Doré JF, Autier P, Ringborg U. Cancer of the skin: a forgotten problem in Europe. Ann Oncol. 2004;15:5–6.View ArticlePubMedGoogle Scholar\n- Long GV, Stroyakovskiy D, Gogas H, Levchenko E, de Braud F, Larkin J, et al. Dabrafenib and trametinib versus dabrafenib and placebo for Val600 BRAF-mutant melanoma: a multicentre, double-blind, phase 3 randomised controlled trial. Lancet. 2015;386:444–51.View ArticlePubMedGoogle Scholar\n- Bhatia S, Tykodi SS, Thompson JA. Treatment of metastatic melanoma: an overview. Oncology (Williston Park). 2009;23:488–96.Google Scholar\n- Ahmann DL, Creagan ET, Hahn RG, Edmonson JH, Bisel HF, Schaid DJ. Complete responses and long-term survivals after systemic chemotherapy for patients with advanced malignant melanoma. Cancer. 1989;63:224–7.View ArticlePubMedGoogle Scholar\n- Lui P, Cashin R, Machado M, Hemels M, Corey-Lisle PK, Einarson TR. Treatments for metastatic melanoma: synthesis of evidence from randomized trials. Cancer Treat Rev. 2007;33:665–80.View ArticlePubMedGoogle Scholar\n- Long GV, Stroyakovskiy D, Gogas H, Levchenko E, de Braud F, Larkin J, et al. Combined BRAF and MEK inhibition versus BRAF inhibition alone in melanoma. N Engl J Med. 2014;371:1877–88.View ArticlePubMedGoogle Scholar\n- Hodi FS, O’Day SJ, McDermott DF, Weber RW, Sosman JA, Haanen JB, et al. Improved survival with ipilimumab in patients with metastatic melanoma. N Engl J Med. 2010;363:711–23.View ArticlePubMedPubMed CentralGoogle Scholar\n- Ribas A, Puzanov I, Dummer R, Schadendorf D, Hamid O, Robert C, et al. Pembrolizumab versus investigator-choice chemotherapy for ipilimumab-refractory melanoma (KEYNOTE-002): a randomised, controlled, phase 2 trial. Lancet. 2015;16:908–18.View ArticlePubMedGoogle Scholar\n- Robert C, Long GV, Brady B, Dutriaux C, Maio M, Mortier L, et al. Nivolumab in previously untreated melanoma without BRAF mutation. N Engl J Med. 2015;372:320–30.View ArticlePubMedGoogle Scholar\n- Larkin J, Chiarion-Sileni V, Gonzalez R, Grob JJ, Cowey CL, Lao CD, et al. Combined nivolumab and ipilimumab or monotherapy in untreated melanoma. N Engl J Med. 2015;373:23–34.View ArticlePubMedGoogle Scholar\n- Lee J-H, Paull TT. Activation and regulation of ATM kinase activity in response to DNA double-strand breaks. Oncogene. 2007;26:7741–8.View ArticlePubMedGoogle Scholar\n- Lavin MF, Kozlov S. ATM activation and DNA damage response. Cell Cycle. 2007;6:931–42.View ArticlePubMedGoogle Scholar\n- Basu A, Krishnamurthy S, Basu A, Krishnamurthy S. Cellular responses to cisplatin-induced DNA Damage, cellular responses to cisplatin-induced DNA damage. J Nucleic Acids. 2010;2010:201367. doi:10.4061/2010/201367 PubMedPubMed CentralGoogle Scholar\n- Weir GM, Liwski RS, Mansour M. Immune modulation by chemotherapy or immunotherapy to enhance cancer vaccines. Cancers. 2011;3:3114–42.View ArticlePubMedPubMed CentralGoogle Scholar\n- Bracci L, Schiavoni G, Sistigu A, Belardelli F. Immune-based mechanisms of cytotoxic chemotherapy: implications for the design of novel and rationale-based combined treatments against cancer. Cell Death Differ. 2014;21:15–25.View ArticlePubMedGoogle Scholar\n- Lee SK, Seo SH, Kim BS, Kim CD, Lee JH, Kang JS, Maeng PJ, Lim JS. IFN-γ regulates the expression of B7-H1 in dermal fibroblast cells. J Dermatol. 2005;40:95–103.Google Scholar\n- Gajewski TF, Louahed J, Brichard VG. Gene signature in melanoma associated with clinical activity: a potential clue to unlock cancer immunotherapy. Cancer J. 2010;16:399–403.View ArticlePubMedGoogle Scholar\n- Loi S, Sirtaine N, Piette F, Salgado R, Viale G, et al. Prognostic and predictive value of tumor-infiltrating lymphocytes in a phase III randomized adjuvant breast cancer trial in node-positive breast cancer comparing the addition of docetaxel to doxorubicin with doxorubicin-based chemotherapy: BIG 02-98. J Clin Oncol. 2013;31:860–7.View ArticlePubMedGoogle Scholar\n- Remon J, Chaput N, Planchard D. Predictive biomarkers for programmed death-1/programmed death ligand immune checkpoint inhibitors in non-small cell lung cancer. Curr Opin Oncol. 2016;28:122–9.View ArticlePubMedGoogle Scholar"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:b77c334b-c1a4-4db8-b091-6811fd719513>","<urn:uuid:ab0c6a57-a409-464b-a359-c31ba234c69d>"],"error":null}
{"question":"What factors influence resistance to both death and organizational change, and what strategies help overcome this resistance?","answer":"Both death and organizational change face resistance due to psychological and social factors. With death, people resist due to the desire for eternal life, fear of the unknown, and anxiety about unfulfilled goals. Similarly, organizational change is resisted due to insecurity, tradition, fear of inadequate skills, and concerns about power/status loss. To overcome resistance in both cases, support and proper communication are essential. For death, this involves allowing people to process through stages of grief and providing emotional support. For organizational change, managers must involve affected individuals, communicate benefits clearly, offer training and resources, and allow adequate time for adjustment. Both situations require understanding that resistance is normal and addressing underlying fears and concerns rather than dismissing them.","context":["Death is an intrinsic part of human life, since it is its biological termination. Understanding of this fact may develop with age, with a propensity for a crisis to emerge in one’s psychological being on the grounds of death’s approaching and the uncertainty that comes afterwards. Religion, in certain cases may alleviate the death moment by presenting it not as a termination, but as a transition. On the other hand, death may not be recognized only as a biological, but also a social phenomenon, since not only individuals can die, but groups of individual can undergo the same stages which are pertinent to death. People may try to ignore death or, on the contrary, to prepare for it. This way or another, whether death is accepted or rejected, the attitude to it will have a profound impact on how individuals lead their lives and in what setting they to find themselves at the end.\nWhat is Death?\nDeath features a certain challenge for people in later modernity, for the reason that tendencies regarding self-identity as well as individual life suggest that mortality tends to come forth as an individual as well as a group ethical problem (Giddens, 1991). This implies that the ever growing secular influence has contributed greatly to the absence of common goal and comprehensions of living and dying. It is contended that people are all the more left to themselves to develop their personal beliefs about death in their lifetime, and there might be an emptiness that people try to deal with by means of the persistent effort to preserve or produce a defined and firm perception of who they happen to be as human beings (Giddens, 1991). If observed in a solely natural aspect, death is comparatively uncomplicated - the stopping of the bodily activities of the living being (Giddens, 1991). Kierkegaard (1846) indicates that, as opposed to natural death, \"subjective death\" is a \"total uncertainness\" - an issue about which we are able to possess no specific comprehension. If we are not able to comprehend \"subjective death\", in that case dying is roughly the adaptation from existence to non- existence, and the anxiety about non-being may result in one of the initial fears of the growing newborn (Moraglia, 2004). Hillman (1990) denies as non-psychological the belief that loss of life cannot be lived through, since while lifeless, people are unable to sense, and while living, we may not be dead.\nWhat is a Death Plan?\nIn getting ready for death, people may think of the location they want to be buried in, the people that they want to be with them when they are on their death bed, the place where they want to die, all the particulars of their burial process (clothes for burial, objects to be put into coffin, etc.) and legal outcomes of their death on the basis of their left will.\nHow is Death Part of Life?\nOn the other hand, death is often encountered as an existential situation and a condition of existence: in dreams as well as psychotic conditions, whilst we go through the process of dying, or even actually sense that we are deceased; in our dreams when we see the deceased; when mates and family members pass away; in the event that we are overpowered by a perception of deprivation and void that can feel like dying; whenever we are in the hold of the anxiety of passing away; and as we desire the loss of life of other people, or our personal one.\n“For some, each separation is death, and parting is dying. There are those who feel cursed, certain their life is an ineluctable progress into doom, a chain of destiny, the last link called suicide. Some may have escaped death in a holocaust or war and not yet have inwardly escaped. . . . Phobias, compulsions, and insomnia may reveal a core of death”. (Hillman, 1990, pp. 64-65)\nWe may die in our spirit on a daily basis, just as we die in the human body. Similarly as body tissues pass away and tend to be regenerated, this way the spirit is reinstated by the death encounter, due to dying to the false impression that death is not able to get to us, and with a new interest in the necessity of life (Moraglia, 2004). For the reason that living and dying are thoroughly connected, they are comprehensible solely with regards to one another (Hillman, 1990). Furthermore, \"if only the living can die, only the dying are really alive\" (Hillman, 1990, p. 59). Additionally, should life along with death be irreversibly related, any activity that rejects and fights against death will harm life at the same time.\nHow Do We Manage Death?\nDevoid of a steady target point, existence is progressively focused on an interest in our personal bodies. On the other hand, the frailty of the individual physique and the inescapable fact of its death suggest that the feeling of steadiness that it offers is naturally conditional, and risks of existential safety turn out to be more evident. Although this is frequently looked at in a disconsolate manner, the concept of reflexive modernity proposes that dying as well as deskilling has effects for emergent life-politics in later modernity, which is indicative of the opportunities for reflexive re-skilling regarding ethical issues (Erikson, 1982). Erikson (1982) identified the substance of wisdom as a separate perception of life brought on by the closeness of dying that could be attained solely in the later phases of human existence. In accordance with Jung (1933), the part that the understanding of mortal condition should perform in our existence is significantly modulated by an individual's age. A youthful individual should be concentrated on completing the assignments that are proper to that point of living: building a strong, properly socialized personality; setting up a family; and getting a spot for oneself in the grown-up world (Jung, 1933). There can be no demand to allow space for thoughts of passing away in the psychological living of the youthful individual. Accordingly, the way youngsters, concentrated on past or death, could betray the necessities of life, an individual beyond their prime time, who rejected to face dying, could be no less out of line with the path of their own life:\n“From the middle of life onward, only he remains vitally alive who is ready to die with life. For in the secret hour of life's midday the parabola is reversed, death is born. The second half of life does not signify ascent, unfolding, increase, exuberance, but death, since the end is its goal. The negation of life's fulfillment is synonymous with the refusal to accept its ending. Both mean not wanting to live, and not wanting to live is identical with not wanting to die”. (Jung, 1934/ 1981, p. 129)\nThe initial phase of managing death is rejection, or the \"no, it just could not be real\" period (Kubler-Ross, 1969). The individual might reject the fact that the disease is actually developing in them and behave as if very little were out of order. After that, the rage phase arrives, wherein the individual goes through profound sensations including anger, disappointment, and bitterness, which usually are aimed at other people. Lastly, there is the negotiating phase, in the course of which the person accepts the disease, yet tries to bargain for more time to participate in preferred events or to finish uncompleted issues. In a way, negotiating is an effort to postpone the unavoidable. After that, depressive symptoms take hold, wherein the individual gets to be despondent, sorrowful, and miserable. Throughout this period, the patient could possibly grieve over issues (such as impaired relations) that are presently forfeited, along with items that may be forfeited afterwards. Ultimately, people arrive at the phase of acknowledgement, where they struggle against the unavoidable no more and get ready for their approaching loss of life. In the course of this period, they likewise encounter a sensation of inside and outside contentment (Kubler-Ross, 1969).\nWhat Do We Do to People When They Die?\nWhen people are dying, it could eb said that there are basically three responses all depending on how well we know the person dying. The responses could be sympathy, rejection or indifference. When a person is sick and dying, it may happen that his or her child may not want to accept this fact and wish to remember his or her parent during their better years and refuse to be near. Others, may most naturally feel sympathetic about the person dying and spend all their free time near the death bed of their close person. Still, others, may simply take the fact of death as granted and will not do anything special about it.\nHow Do We Imagine Death?\nLevinson (1978) held that a consideration for death as the termination of the physical processes in a human body could be identified at any stage of existence, however, he added that it amassed power in the senior years. During each phase of our living, he stated, we are equally young and also aged. At a profound psychological stage, we constantly go through, even though in varying styles and effectiveness, the conflict involving youth, which is the desire for rebirth, creative imagination, and development, and age, which is the feeling of stagnancy and decaying (Levinson ,1978). It takes place in the course of maturity, and most significantly throughout the midlife adaptation that happens at approximately age 40. To put it differently, youth/maturity difference is felt with an increasingly higher power. It is likewise at this point (midlife) that it gets to be obvious that this difference has its basis in the conflict involving the desire for eternal life and the inescapable fact of passing of life. Therefore, Levinson (1978) put the problem of death straight at the heart of the grown-up period and most precisely in the course of the midlife adaptation.In this interval, an individual understands that the better years have ended and that senior age together with death are no more a distant possibility:\n“At 40 a man knows more deeply than ever before that he is going to die. He feels it in his bones, in his dreams, in the marrow of his being. His death is not simply an abstract, hypothetical event. An unpredictable accident or illness could take his life tomorrow. Even another thirty years does not seem so long: more years now lie behind than ahead”. (Levinson, 1978, p. 215)\nThis perspective is strengthened by the initial signs of psychic and physical downfall, the sickness and departure of mates, and the increasing age of parents.\nIndividuals contain a desire for an eternal existence, Levinson (1978) contended. For this reason it is so challenging to be prepared for one's loss of life. For a lot of people, this problem is complicated by the dread that their existence has not meant a lot, that it could have been squandered, that they have never realized themselves, along with that there might not be a sufficient period of time to try to come up with a new start. Signs of hopelessness could possibly engulf an individual close to the conclusion of their existence. In addition, Levinson (1978) identified them significantly sooner than that, and that is at the heart of the midlife adaptation.\nWhat is a Suicide?\nThe perspective that probably most clearly features the suicide as a deliberate taking of one’s life belongs to J. Hillman (1990). We learn his thoughts with regards to dying as they are explained in his work \"Suicide and the Soul\" (1990). In Hillman's perspective, living as well as dying are coherently and consistently connected. One can likewise discover there a pointed resistance to Fromm's (1964) perspectives. In accordance with Fromm (1964), living and dying make up totally antipode realities. Therefore, confrontation with death may not be put off to the latter half of lifespan, just as Hillman (1990) quotes from Jung (1933) to explaine it:\n“The moment I am born I am old enough to die. As I go on living I am dying. Death is entered continuously, not just at the moment of death as legally and medically defined. Each event in my life makes its contribution to my death, and I build my death as I go along day by day. (Hillman, 1990, p. 59)\nW. James (1962) contended that spiritual morals present a lot of individuals the single solution to steer clear from suicide. They function for the sake of this purpose by giving human existence an importance that it would be short of in any other case.\nWhat are the Illegal or Legal Issues Assisting Someone to Die?\nAssisted suicide laws are different in many countries across the globe and even within a country depending on a specific administrative unit. For example, in the USA only Oregon and Washington allow physician assisted suicide. The patient takes action or asks a physician to administer life-terminating measure in case the sufferings are unbearable for a person and there is no objective potential chance for recovery. It will not be a criminal act.\nReligion and Death\nIf a person holds on to certain religious beliefs, it is quite often that his or her religion will not allow the person to terminate his life. What is more, it may be considered a great transgression, like in Christianity, since a person is God’s creation and only He has the privilege of taking life, since He is the one who gave it. Suicide is still a murder, in this case, the only distinction being that the offender and the victim is the same person. Thus, it could be suggested that religion is a substantial preventive factor in terms of suicidal inclinations. What is more, religion in certain cases may alleviate the death moment by presenting it not as a termination, but as a transition\nDeath as Social Rather Than Biological Phenomenon\nZell (2003) evaluates opposition to change in a qualified organization, specifically, the physics division of a major research institution, and points out the similarities between the stages of managing individual death and the stages of an organization’s transformation though change. In other words, the organization had to “die” first to be transformed. This process went through a serious opposition. Confronted with essential adjustments in its setting, the division had to go through required improvements in its key functions of educating as well as researching in order to endure. At first, a lot of educators opposed the adjustments, yet, as time passed, substantial adjustments in the divisional primary activities as well as tactical course ultimately took place.\nAn Examination of interview records gathered from educators throughout a 2-year interval exposed that the division's transformation was strongly similar to dying, recognized by Kubler-Ross (1969) in her research of terminally ailing individuals.\nThe practice of grieving was identified as developing through several specific stages, or stages (Volkan, 1981). The most commonly cited of these types of \"stage hypotheses\" is the one of Kubler-Ross (1969), who discovered that terminally ailing individuals proceed through fiev abovementioned particular phases. Similar to the terminally sick, the division went through intervals of rejection, rage, negotiating, melancholy, and, ultimately, acknowledgement. In line with the phenomenon, Shilling (1993) said:\n“The major marginal situation is the individual confrontation with death, because this can radically undermine and call into question the 'cognitive and normative operating procedures' of day-to-day life” (Shilling 1993:178).\nThe modern understanding of death as well as deskilling is based upon several important perspectives of the way death turns into an unseen and personal issue. One of such perspectives by Aries (1991) states that the unseen manner of contemporary death is a sign of the reduction of social solidarity, and the growing influence of authorities over public and private life. According to a different position, by Elias (1978), the privatization of passing of life may be an outcome of civilizing activities natural for modernity in which psychological existence is vulnerable to high degrees of self-regulation and control. In spite of the distinctions that can be found between these explanations, both propose that contemporary communities and individuals experience troubles in managing loss of life and therefore try to set it aside.\nUltimately, people arrive at the phase of acknowledgement where they struggle against the unavoidable no more and get ready for their approaching loss of life. In the course of this period, they likewise encounter a sensation of inside and outside contentment (Kubler-Ross, 1969).\nLoss of life is considered as an ultimate illustration of the loss of common meanings, or, in other words, deskilling, in contemporary culture, and as a primary life-political matter in the concept of later modernity. Passing away is one of the several inevitabilities that we encounter in life, and it may be asserted that one can assess a society by the approaches whereby it handles death. The way one looks at death has a critical impact on the social existence people develop collectively. This concerns the approach to the acceptability of euthanasia whether it is a rightful thing to do or, on the contrary, considered an unlawful and an immoral practice.","How organizations manage resistance to change\nSevere competitive and economic pressures that organizations face today were unthinkable a few decades ago. In order to shed excess costs and to respond more nimbly to customers and competitors, they are being urged to adopt new organizational forms, tightened inter organizational linkages and improved management practices (cf. Miles and Snow 1980, Johnston and Lawrence, 1988). Any change in organization is followed by a kind of resistance from its employees. In this assignment a few methods that can be used to overcome change in the organization are described.\nTechnology developments, social and demographic shifts, competition of changing market and economic issues, tend an organization to implement change in it as well. The rapid and dynamic change in market has increased consumerism. Whether it is an automobile industry or cosmetic industry or IT industry, consumer today has lots of choices these days that they need not have to wait for longer for any product. This changing market scenario imparts a message to managing bodies that the way of work should also change with the changing market. From managerial point of view a change is referred to as change in work pattern, work routine and work culture inside the working atmosphere. Change is normally a reaction to changing commercial, technological, economical, structural and strategic environment in which the company operates (Barbara Senior, Organizational Change). For example; departmentalization, job redesign, implementation of an international division are the examples of structural changes whereas work processes, methods and equipments are technological changes.\nChange should be welcomed as it can produce positive benefits for the individuals, bring opportunities for personal change and development, reduces boredom of work, provides new challenges and an opportunity to participate and shape the outcome. But unfortunately as change is accompanied by resistance, it is very important that the Change Manager anticipate and plan strategies for dealing with resistance not only at the introduction of change but also for monitoring the change over long term (Ronald, G and Smith, J 1995). It is helpful to understand why people resist change, because understanding this allows us to plan strategies to reduce resistance from the beginning. Kotter and Schlesinger identified the basic reasons of resistance to change are communication gap and inadequate information that creates misunderstanding, sense of insecurity, different assessment of situation and disagreement over advantages and disadvantages. Moreover, individuals are more concerned with the implications for themselves (Management by Robbins and Coulter).\nOrganizations do not change, individuals do. No matter how large is the project you are taking on, the success of project ultimately lies with each employee doing their work differently multiplied across all of employees impacted by the change (Web 1). Individual barriers to change include- tradition and set ways; loyalty to existing relationships; failure to accept the need for change; insecurity; preference for the existing arrangements; break up of work groups; different person ambitions; fear of power; skills and income; inability to perform as well in the new situation as for example, when quality control methods based on statistical models were introduced into manufacturing units, the quality control department have to learn the new methods. Some may fear that they will be unable to do so and may develop negative attitude towards the change or perform poorly if required to use the new methods. Sometimes change is resisted because of failures in the way it is introduced to the employees and the management fails to explain the need for change and its future benefits. Poor employer relations, lack of involvement in process and failure to offer support and training for the introduced change are the other reasons for change resistance (Web 2).\nResisting change takes many forms (Web 3) and the more obvious form is of active resistance, objection and refusal to cooperate with the change occurs. Sometimes, resistance appears to be individual and sometimes it is clearly situational. It may be passive in which colleagues agree to a change but are unwilling or unable to implement something new. This subtle form of resistance is dealt with more difficulty. For example, at a staff meeting everyone agrees to follow a new procedure, but after several weeks it is being discovered that the procedure has not been implemented yet. Another example of this kind is the introduction of new computers at the new place but virtually no one is using them for the purpose for which they are intended, since the staff had their own machines. The employee consents to change by agreeing to it but later he only changes to appear cooperative, but in fact he is doing most things the way he was before the change.\nAt the moment the change program is announced, many employees will employ tactics to protect themselves, their turf, and ultimately their place in the organization.Ã‚Â Some will aggressively challenge the necessity for change. This is a time waster and thus prevents critical objectives from being met. Every person who facilitates the change process must work diligently to build consensus. The employee must be assured that every idea is worth considering. If anyone argues, he or she can be asked to explain why he or she feels the way they do and ask for three or four suggestions for making the process work.Ã‚Â Some managers and members of the leadership team will avoid change by passively refusing the commitment to the process. Often these leaders will resist the change effort by being unavailable for meetings, denying resources, or withholding feedback. “The leadership” is a particularly difficult foe, because change efforts often require the use of resources managed by the leadership, such as time and money. Without these resources change efforts are likely to fail. Accountability with consequences is the primary means for assuring leadership participation. Many employees and organizational leaders search for personal or professional diversions during the change process that will ultimately hinder the effort. A distracted individual can undermine the change effort by not being present physically or mentally when his or her critical input is needed. Not being mindful of change creates an unnecessarily difficult experience for every member of the team. Such carelessness calls to mind the wasted energy expended when one runs against the wind. Change efforts provide an opportunity for every one affected to secure a new place in the organization or make a decision to seek a better fit elsewhere.\nKen Hultman argues that while no-one is a perfect change agent, managers have to be impeccable role models for bringing up a successful change. The essential attributes of such a person include the ability to be a clear thinker who is able to get a view about organizational situation and reach at logical conclusions. Hultman suggests few things in creating the right environment for change to occur. Firstly we must do things to establish a positive climate (p172) and secondly we must attempt to create environmental conditions that encourage an interest in improvement. Managers must demonstrate that how changes will improve employees circumstances and that there are opportunities in the change such as enabling colleagues to increase their knowledge and skills leading to genuine achievements and progress They must cultivate a value for collaborative working among staff and colleagues need each other to complete their tasks, it is easier to develop values of co-operation and mutuality. Whatever are the circumstances management must stay calm. At the heart of HultmanÃ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s analysis is a set of humanistic values along with an assumption that one cannot even hope to influence another colleague without firstly demonstrating that they will have their needs met in some way. It is likely to be counterproductive by getting impatient, exasperated and angry.\nBeing a change manager it is his/her duty to reduce the resistance towards change and towards change and to increase the enthusiasm and level of commitment for the change. While likely to encounter the people who resist change, people who welcome change will also be encountered and by knowing the reasons for their acceptance to change, the communication plan will be better formulated. People will accept change when they see possibility that they will gain something from the change. The gain may be either personal like, money; increased job security; status; self satisfaction; less effort and time and gain in better personal contact or other like it provides new challenges, likeness of the source, reduction in boredom etc.\nIn order to reduce resistance to change, the manager should involve people affected by change, actively seeking their thoughts and reactions to proposed changes. They must develop a proper attitude towards resistance to change and realize that it is neither good nor bad. The best way to minimize resistance to change is to involve those responsible for implementing it and those affected by it. People are more motivated towards successful completion when they feel that they are the valued participants in planning and implementing the change. Also ensure that people from all the levels of organization are involved in planning the change process and they should be listened carefully. In the early stages, manager should not launch into lengthy diatribes justifying the change as people are not interested in that. They want to be heard and have their concerns attended to. They must recognize that it takes time to work through reactions to change. Then people should be engaged in dialogue about the change. They should do this only after understanding the specific concerns of others completely. Change must be realistic, achievable and measurable.\nCommunication and education is helpful method to sort out the things when resistance is due to lack of information or inappropriate information and analysis. Though time consuming, this method provides great employee support if persuaded. When cause of resistance is difficulty in adjustment to changes, management support and facilitation do work at times. This is expensive and still unreliable way to overcome the change. Manipulation of some information is necessary some times in order to avoid negative reactions by the employee. The people that easily accept changes and get adapted to changing atmosphere can set an example for others and hence they follow the suit. Therefore, they should be the first target of change program.\nThree basic steps- planning, implementation, and evaluation of outcomes of both the plan and implementation are involved in the change process. Resistance to change should be dealt ideally with planning and early stages of implementation. For proper planning for change, a manager must consider about how and when the change is needed and the way it should be communicated to the employees for their better support. Managers should pay attention to the focus of change, the amount of change, and the rate of change in order to implement change. Evaluation of outcomes of change is also very important as all the change efforts are result oriented. If change is not monitored, its effectiveness cannot be measured. This can be done by collecting data and comparing the results against original goals.\nTo wind up at the end of an interesting discussion we can conclude that a degree of resistance is normal since change is disruptive and stressful but in general, most people have mixed reactions towards purposed change, so the change agents can be helpful in highlighting the positive aspects in realistic manner. Although most people feel comfortable with minor changes, no one can live and work by yesterdayÃ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s reality. Managers must reduce change in very effective, meaningful and healthy way without hurting the sentiments of the employees. By providing resources to support the changes, allowing enough time and flexibility and with the widespread commitment of people throughout the organization, change efforts will succeed.\n(2) Hultman, K. (1998), Making Change Irresistible: Overcoming resistance to change in your organisation, Davies-Black Publishing, Palo AltoOrder Now"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:9e1eb2d0-7084-48cf-b3e8-d5bc5cf3727a>","<urn:uuid:1a1104dc-49cd-429f-a39e-8094db2177d4>"],"error":null}
{"question":"What are the main structural differences between cantilever wings in early aircraft versus modern aircraft designs?","answer":"Early aircraft wings used light structures braced with wires and struts, similar to truss bridges, which created considerable aerodynamic drag. In contrast, modern cantilever wings use a stronger, heavier design with one or more main spars running through the wing, typically near the leading edge at about 25% of the total chord. While the cantilever design is heavier, it eliminates external bracing and allows faster flight by reducing drag. This transition occurred in the 1920s-1930s when aircraft speeds increased to the point where the drag reduction benefits outweighed the weight penalty of cantilever construction.","context":["A cantilever is a rigid structural element, such as a beam or a plate, anchored at one end to a (usually vertical) support from which it protrudes; this connection could also be perpendicular to a flat, vertical surface such as a wall. Cantilevers can also be constructed with trusses or slabs. When subjected to a structural load, the cantilever carries the load to the support where it is forced against by a moment and shear stress.\nCantilever construction allows overhanging structures without external bracing, in contrast to constructions supported at both ends with loads applied between the supports, such as a simply supported beam found in a post and lintel system.\nIn bridges, towers, and buildings\nCantilevers are widely found in construction, notably in cantilever bridges and balconies (see corbel). In cantilever bridges, the cantilevers are usually built as pairs, with each cantilever used to support one end of a central section. The Forth Bridge in Scotland is an example of a cantilever truss bridge. A cantilever in a traditionally timber framed building is called a jetty or forebay. In the southern United States, a historic barn type is the cantilever barn of log construction.\nTemporary cantilevers are often used in construction. The partially constructed structure creates a cantilever, but the completed structure does not act as a cantilever. This is very helpful when temporary supports, or falsework, cannot be used to support the structure while it is being built (e.g., over a busy roadway or river, or in a deep valley). So some truss arch bridges (see Navajo Bridge) are built from each side as cantilevers until the spans reach each other and are then jacked apart to stress them in compression before finally joining. Nearly all cable-stayed bridges are built using cantilevers as this is one of their chief advantages. Many box girder bridges are built segmentally, or in short pieces. This type of construction lends itself well to balanced cantilever construction where the bridge is built in both directions from a single support.\nThese structures rely heavily on torque and rotational equilibrium for their stability.\nIn an architectural application, Frank Lloyd Wright's Fallingwater used cantilevers to project large balconies. The East Stand at Elland Road Stadium in Leeds was, when completed, the largest cantilever stand in the world holding 17,000 spectators. The roof built over the stands at Old Trafford uses a cantilever so that no supports will block views of the field. The old, now demolished Miami Stadium had a similar roof over the spectator area. The largest cantilevered roof in Europe is located at St James' Park in Newcastle-Upon-Tyne, the home stadium of Newcastle United F.C.\nAnother use of the cantilever is in fixed-wing aircraft design, pioneered by Hugo Junkers in 1915. Early aircraft wings typically bore their loads by using two (or more) wings in a biplane configuration braced with wires and struts. They were similar to truss bridges, having been developed by Octave Chanute, a railroad bridge engineer. The wings were braced with crossed wires so they would stay parallel, as well as front-to-back to resist twisting, running diagonally between adjacent strut anchorages. The cables and struts generated considerable drag, and there was constant experimentation for ways to eliminate them.\nIt was also desirable to build a monoplane aircraft, as the airflow around one wing negatively affects the other in a biplane's airframe design. Early monoplanes used either struts (as do some current light aircraft), or cables like the 1909 Bleriot XI (as do some modern homebuilt aircraft). The advantage of using struts or cables is a reduction in weight for a given strength, but with the penalty of additional drag. This reduces maximum speed and increases fuel consumption.\nHugo Junkers endeavored to eliminate virtually all major external bracing members, only a dozen years after the Wright Brothers' initial flights, to decrease airframe drag in flight, with the result being the Junkers J 1 pioneering all-metal monoplane of late 1915, designed from the start with all-metal cantilever wing panels. About a year after the initial success of the Junkers J 1, Reinhold Platz of Fokker also achieved success with a cantilever-winged sesquiplane built instead with wooden materials, the Fokker V.1.\nThe most common current wing design is the cantilever. A single large beam, called the main spar, runs through the wing, typically nearer the leading edge at about 25 percent of the total chord. In flight, the wings generate lift, and the wing spars are designed to carry this load through the fuselage to the other wing. To resist fore and aft movement, the wing will usually be fitted with a second smaller drag-spar nearer the trailing edge, tied to the main spar with structural elements or a stressed skin. The wing must also resist twisting forces, done either by a monocoque \"D\" tube structure forming the leading edge, or by the aforementioned linking two spars in some form of box beam or lattice girder structure.\nCantilever wings require a much heavier spar than would otherwise be needed in cable-stayed designs. However, as the size of an aircraft increases, the additional weight penalty decreases. Eventually, a line was crossed in the 1920s, and designs increasingly turned to the cantilever design. By the 1940s almost all larger aircraft used the cantilever exclusively, even on smaller surfaces such as the horizontal stabilizer, with the Messerschmitt Bf 109E of 1939–41 being one of the last World War II fighters in frontline service to have bracing struts for its stabilizer.\nIn microelectromechanical systems\nCantilevered beams are the most ubiquitous structures in the field of microelectromechanical systems (MEMS). An early example of a MEMS cantilever is the Resonistor, an electromechanical monolithic resonator. MEMS cantilevers are commonly fabricated from silicon (Si), silicon nitride (Si3N4), or polymers. The fabrication process typically involves undercutting the cantilever structure to release it, often with an anisotropic wet or dry etching technique. Without cantilever transducers, atomic force microscopy would not be possible. A large number of research groups are attempting to develop cantilever arrays as biosensors for medical diagnostic applications. MEMS cantilevers are also finding application as radio frequency filters and resonators. The MEMS cantilevers are commonly made as unimorphs or bimorphs.\nTwo equations are key to understanding the behavior of MEMS cantilevers. The first is Stoney's formula, which relates cantilever end deflection δ to applied stress σ:\nwhere is Poisson's ratio, is Young's modulus, is the beam length and is the cantilever thickness. Very sensitive optical and capacitive methods have been developed to measure changes in the static deflection of cantilever beams used in dc-coupled sensors.\nThe second is the formula relating the cantilever spring constant to the cantilever dimensions and material constants:\nwhere is force and is the cantilever width. The spring constant is related to the cantilever resonance frequency by the usual harmonic oscillator formula . A change in the force applied to a cantilever can shift the resonance frequency. The frequency shift can be measured with exquisite accuracy using heterodyne techniques and is the basis of ac-coupled cantilever sensors.\nThe principal advantage of MEMS cantilevers is their cheapness and ease of fabrication in large arrays. The challenge for their practical application lies in the square and cubic dependences of cantilever performance specifications on dimensions. These superlinear dependences mean that cantilevers are quite sensitive to variation in process parameters, particularly the thickness as this is generally difficult to accurately measure. However, it has been shown that microcantilever thicknesses can be precisely measured and that this variation can be quantified. Controlling residual stress can also be difficult.\nChemical sensor applications\nA chemical sensor can be obtained by coating a recognition receptor layer over the upper side of a microcantilever beam. A typical application is the immunosensor based on an antibody layer that interacts selectively with a particular immunogen and reports about its content in a specimen. In the static mode of operation, the sensor response is represented by the beam bending with respect to a reference microcantilever. Alternatively, microcantilever sensors can be operated in the dynamic mode. In this case, the beam vibrates at its resonance frequency and a variation in this parameter indicates the concentration of the analyte. Recently, microcantilevers have been fabricated that are porous, allowing for a much larger surface area for analyte to bind to, increasing sensitivity by raising the ratio of the analyte mass to the device mass. . Surface stress on microcantilever, due to receptor-target binding, which produces cantilever deflection can be analyzed using optical methods like laser interferometry. Zhao et al., also showed that by changing the attachment protocol of the receptor on the microcantilever surface, the sensitivity can be further improved when the surface stress generated on the microcantilever is taken as the sensor signal.\nIn storage applications\nA cantilever rack is a type of warehouse storage system consisting of the vertical column, the base, the arms, and the horizontal and/or cross-bracing. These components are fabricated from both roll formed and structural steel. The horizontal and/or cross bracing are used to connect two or more columns together. They are commonly found in lumber yards, woodworking shops, and plumbing supply warehouses.\nA folding cantilever tray is a type of stacked shelf that can be unfolded to allow convenient access to items on multiple tiers simultaneously. The shelves can be collapsed when not in use for more compact storage. Because of these properties folding cantilever trays are often used in baggage and toolboxes.\n- Applied mechanics\n- Cantilever bicycle brakes\n- Cantilever bicycle frame\n- Cantilever bridge\n- Cantilever chair\n- Cantilever method\n- Corbel arch\n- Euler–Bernoulli beam theory\n- Glossary of industrial scales and weighing\n- Grand Canyon Skywalk\n- Knudsen force in the context of microcantilevers\n- Moment (physics)\n- Hool, George A.; Johnson, Nathan Clarke (1920). \"Elements of Structural Theory - Definitions\". Handbook of Building Construction (Google Books). vol. 1 (1st ed.). New York: McGraw-Hill. p. 2. Retrieved 2008-10-01.\nA cantilever beam is a beam having one end rigidly fixed and the other end free.\n- \"GMI Construction wins £5.5M Design and Build Contract for Leeds United Football Club's Elland Road East Stand\". Construction News. 6 February 1992. Retrieved 24 September 2012.\n- IStructE The Structural Engineer Volume 77/No 21, 2 November 1999. James's Park a redevelopment challenge\n- The Architects' Journal Existing stadiums: St James' Park, Newcastle. 1 July 2005\n- ELECTROMECHANICAL MONOLITHIC RESONATOR, US Pat.3417249 - Filed April 29, 1966\n- R.J. Wilfinger, P. H. Bardell and D. S. Chhabra: The resonistor a frequency selective device utilizing the mechanical resonance of a silicon substrate, IBM J. 12, 113–118 (1968)\n- P. M. Kosaka, J. Tamayo, J. J. Ruiz, S. Puertas, E. Polo, V. Grazu, J. M. de la Fuente and M. Calleja: Tackling reproducibility in microcantilever biosensors: a statistical approach for sensitive and specific end-point detection of immunoreactions, Analyst 138, 863–872 (2013)\n- A. R. Salmon, M. J. Capener, J. J. Baumberg and S. R. Elliott: Rapid microcantilever-thickness determination by optical interferometry, Measurement Science and Technology 25, 015202 (2014)\n- P. C. Fletcher, Y. Xu, P. Gopinath, J. Williams, B. W. Alphenaar, R. D. Bradshaw, R. S. Keynton, \"Piezoresistive Geometry for Maximizing Microcantilever Array Sensitivity,\" presented at the IEEE Sensors, Lecce, Italy, 2008.\n- Bǎnicǎ, Florinel-Gabriel (2012). Chemical Sensors and Biosensors:Fundamentals and Applications. Chichester, UK: John Wiley & Sons. p. 576. ISBN 9781118354230.\n- Noyce, Steven G.; Vanfleet, Richard R.; Craighead, Harold G.; Davis, Robert C. (1999-02-22). \"High surface-area carbon microcantilevers\". Nanoscale Advances. 1 (3): 1148–1154. doi:10.1039/C8NA00101D. Retrieved 2019-05-29.\n- Yue Zhao,Agnivo Gosai, Pranav Shrotriya : Effect of Receptor Attachment on Sensitivity of Label Free Microcantilever Based Biosensor Using Malachite Green Aptamer https://doi.org/10.1016/j.snb.2019.126963\n- Inglis, Simon: Football Grounds of Britain. CollinsWillow, 1996. page 206.\n- Madou, Marc J (2002). Fundamentals of Microfabrication. Taylor & Francis. ISBN 0-8493-0826-7.\n- Roth, Leland M (1993). Understanding Architecture: Its Elements History and Meaning. Oxford, UK: Westview Press. pp. 23–4. ISBN 0-06-430158-3.\n- Sarid, Dror (1994). Scanning Force Microscopy. Oxford University Press. ISBN 0-19-509204-X.","A cantilever is a rigid structural element that extends horizontally and is supported at only one end. Typically it extends from a flat vertical surface such as a wall, to which it must be firmly attached. Like other structural elements, a cantilever can be formed as a beam, plate, truss, or slab.\nCantilever construction allows overhanging structures without additional support.\nIn bridges, towers, and buildingsEdit\nCantilevers are widely found in construction, notably in cantilever bridges and balconies (see corbel). In cantilever bridges, the cantilevers are usually built as pairs, with each cantilever used to support one end of a central section. The Forth Bridge in Scotland is an example of a cantilever truss bridge. A cantilever in a traditionally timber framed building is called a jetty or forebay. In the southern United States, a historic barn type is the cantilever barn of log construction.\nTemporary cantilevers are often used in construction. The partially constructed structure creates a cantilever, but the completed structure does not act as a cantilever. This is very helpful when temporary supports, or falsework, cannot be used to support the structure while it is being built (e.g., over a busy roadway or river, or in a deep valley). Therefore, some truss arch bridges (see Navajo Bridge) are built from each side as cantilevers until the spans reach each other and are then jacked apart to stress them in compression before finally joining. Nearly all cable-stayed bridges are built using cantilevers as this is one of their chief advantages. Many box girder bridges are built segmentally, or in short pieces. This type of construction lends itself well to balanced cantilever construction where the bridge is built in both directions from a single support.\nThese structures rely heavily on torque and rotational equilibrium for their stability.\nIn an architectural application, Frank Lloyd Wright's Fallingwater used cantilevers to project large balconies. The East Stand at Elland Road Stadium in Leeds was, when completed, the largest cantilever stand in the world holding 17,000 spectators. The roof built over the stands at Old Trafford uses a cantilever so that no supports will block views of the field. The old (now demolished) Miami Stadium had a similar roof over the spectator area. The largest cantilevered roof in Europe is located at St James' Park in Newcastle-Upon-Tyne, the home stadium of Newcastle United F.C.\nThe Forth Bridge, a cantilever truss bridge.\nA cantilevered railroad deck and fence on the Canton Viaduct\nA cantilever barn in rural Tennessee\nCantilever barn at Cades Cove\nCantilever occurring in the game \"Jenga\"\nBusan Cinema Center in Busan, South Korea, with the world's longest cantilever roof.\nThis radiograph of a \"bridge\" dental restoration features a cantilevered crown to the left\nRonan Point: Structural failure of part of floors cantilevered from a central shaft.\nThis section does not cite any sources. (April 2018) (Learn how and when to remove this template message)\nThe cantilever is commonly used in the wings of fixed-wing aircraft. Early aircraft had light structures which were braced with wires and struts. However, these introduced aerodynamic drag which limited performance. While it is heavier, the cantilever avoids this issue and allows the plane to fly faster.\nHugo Junkers pioneered the cantilever wing in 1915. Only a dozen years after the Wright Brothers' initial flights, Junkers endeavored to eliminate virtually all major external bracing members in order to decrease airframe drag in flight. The result of this endeavor was the Junkers J 1 pioneering all-metal monoplane of late 1915, designed from the start with all-metal cantilever wing panels. About a year after the initial success of the Junkers J 1, Reinhold Platz of Fokker also achieved success with a cantilever-winged sesquiplane built instead with wooden materials, the Fokker V.1.\nIn the cantilever wing one or more strong beams, called spars, run along the span of the wing. The end fixed rigidly to the central fuselage is known as the root and the far end as the tip. In flight, the wings generate vertical lift and the spars carry this load through to the fuselage.\nTo resist horizontal shear stresses from either drag or engine thrust, the wing must also form a stiff cantilever in the horizontal plane. A single-spar design will usually be fitted with a second smaller drag-spar nearer the trailing edge, braced to the main spar via additional internal members or a stressed skin. The wing must also resist twisting forces, achieved by cross-bracing or otherwise stiffening the main structure.\nCantilever wings require much stronger and heavier spars than would otherwise be needed in a wire-braced design. However, as the speed of the aircraft increases, the drag of the bracing increases sharply, while the wing structure must be strengthened, typically by increasing the strength of the spars and the thickness of the skinning. At speeds of around 200 miles per hour (320 km/h) the drag of the bracing becomes excessive and the wing strong enough to be made a cantilever without excess weight penalty. Increases in engine power through the late 1920s and early 1930s raised speeds through this zone and by the late 1930s cantilever wings had almost wholly superseded braced ones. Other changes such as enclosed cockpits, retractable undercarriage, landing flaps and stressed-skin construction furthered the design revolution, with the pivotal moment widely acknowledged to be the MacRobertson England-Australia air race of 1934, which was won by a de Havilland DH.88 Comet.\nPresently, cantilever wings are almost universal with bracing only being used for some slower aircraft where a lighter weight is prioritized over speed, such as in the ultralight class.\nIn microelectromechanical systemsEdit\nCantilevered beams are the most ubiquitous structures in the field of microelectromechanical systems (MEMS). An early example of a MEMS cantilever is the Resonistor, an electromechanical monolithic resonator. MEMS cantilevers are commonly fabricated from silicon (Si), silicon nitride (Si3N4), or polymers. The fabrication process typically involves undercutting the cantilever structure to release it, often with an anisotropic wet or dry etching technique. Without cantilever transducers, atomic force microscopy would not be possible. A large number of research groups are attempting to develop cantilever arrays as biosensors for medical diagnostic applications. MEMS cantilevers are also finding application as radio frequency filters and resonators. The MEMS cantilevers are commonly made as unimorphs or bimorphs.\nTwo equations are key to understanding the behavior of MEMS cantilevers. The first is Stoney's formula, which relates cantilever end deflection δ to applied stress σ:\nwhere is Poisson's ratio, is Young's modulus, is the beam length and is the cantilever thickness. Very sensitive optical and capacitive methods have been developed to measure changes in the static deflection of cantilever beams used in dc-coupled sensors.\nThe second is the formula relating the cantilever spring constant to the cantilever dimensions and material constants:\nwhere is force and is the cantilever width. The spring constant is related to the cantilever resonance frequency by the usual harmonic oscillator formula . A change in the force applied to a cantilever can shift the resonance frequency. The frequency shift can be measured with exquisite accuracy using heterodyne techniques and is the basis of ac-coupled cantilever sensors.\nThe principal advantage of MEMS cantilevers is their cheapness and ease of fabrication in large arrays. The challenge for their practical application lies in the square and cubic dependences of cantilever performance specifications on dimensions. These superlinear dependences mean that cantilevers are quite sensitive to variation in process parameters, particularly the thickness as this is generally difficult to accurately measure. However, it has been shown that microcantilever thicknesses can be precisely measured and that this variation can be quantified. Controlling residual stress can also be difficult.\nChemical sensor applicationsEdit\nA chemical sensor can be obtained by coating a recognition receptor layer over the upper side of a microcantilever beam. A typical application is the immunosensor based on an antibody layer that interacts selectively with a particular immunogen and reports about its content in a specimen. In the static mode of operation, the sensor response is represented by the beam bending with respect to a reference microcantilever. Alternatively, microcantilever sensors can be operated in the dynamic mode. In this case, the beam vibrates at its resonance frequency and a variation in this parameter indicates the concentration of the analyte. Recently, microcantilevers have been fabricated that are porous, allowing for a much larger surface area for analyte to bind to, increasing sensitivity by raising the ratio of the analyte mass to the device mass. Surface stress on microcantilever, due to receptor-target binding, which produces cantilever deflection can be analyzed using optical methods like laser interferometry. Zhao et al., also showed that by changing the attachment protocol of the receptor on the microcantilever surface, the sensitivity can be further improved when the surface stress generated on the microcantilever is taken as the sensor signal.\nIn storage applicationsEdit\nA cantilever rack is a type of warehouse storage system consisting of the vertical column, the base, the arms, and the horizontal and/or cross-bracing. These components are fabricated from both roll formed and structural steel. The horizontal and/or cross bracing are used to connect two or more columns together. They are commonly found in lumber yards, woodworking shops, and plumbing supply warehouses.\nA folding cantilever tray is a type of stacked shelf that can be unfolded to allow convenient access to items on multiple tiers simultaneously. The shelves can be collapsed when not in use for more compact storage. Due to these properties, folding cantilever trays are often used in baggage and toolboxes.\n|Wikimedia Commons has media related to Cantilevers.|\n- Hool, George A.; Johnson, Nathan Clarke (1920). \"Elements of Structural Theory - Definitions\". Handbook of Building Construction (Google Books). vol. 1 (1st ed.). New York: McGraw-Hill. p. 2. Retrieved 2008-10-01.\nA cantilever beam is a beam having one end rigidly fixed and the other end free.\n- \"GMI Construction wins £5.5M Design and Build Contract for Leeds United Football Club's Elland Road East Stand\". Construction News. 6 February 1992. Retrieved 24 September 2012.\n- IStructE The Structural Engineer Volume 77/No 21, 2 November 1999. James's Park a redevelopment challenge\n- The Architects' Journal Existing stadiums: St James' Park, Newcastle. 1 July 2005\n- Stevens, James Hay; The Shape of the Aeroplane, Hutchinson, 1953. pp.78 ff.\n- Davy, M.J.B.; Aeronautics – Heavier-Than-Air Aircraft, Part I, Historical Survey, Revised edition, Science Museum/HMSO, December 1949. p.57.\n- ELECTROMECHANICAL MONOLITHIC RESONATOR, US Pat.3417249 - Filed April 29, 1966\n- R.J. Wilfinger, P. H. Bardell and D. S. Chhabra: The resonistor a frequency selective device utilizing the mechanical resonance of a silicon substrate, IBM J. 12, 113–118 (1968)\n- P. M. Kosaka, J. Tamayo, J. J. Ruiz, S. Puertas, E. Polo, V. Grazu, J. M. de la Fuente and M. Calleja: Tackling reproducibility in microcantilever biosensors: a statistical approach for sensitive and specific end-point detection of immunoreactions, Analyst 138, 863–872 (2013)\n- A. R. Salmon, M. J. Capener, J. J. Baumberg and S. R. Elliott: Rapid microcantilever-thickness determination by optical interferometry, Measurement Science and Technology 25, 015202 (2014)\n- P. C. Fletcher, Y. Xu, P. Gopinath, J. Williams, B. W. Alphenaar, R. D. Bradshaw, R. S. Keynton, \"Piezoresistive Geometry for Maximizing Microcantilever Array Sensitivity,\" presented at the IEEE Sensors, Lecce, Italy, 2008.\n- Bǎnicǎ, Florinel-Gabriel (2012). Chemical Sensors and Biosensors:Fundamentals and Applications. Chichester, UK: John Wiley & Sons. p. 576. ISBN 9781118354230.\n- Noyce, Steven G.; Vanfleet, Richard R.; Craighead, Harold G.; Davis, Robert C. (1999-02-22). \"High surface-area carbon microcantilevers\". Nanoscale Advances. 1 (3): 1148–1154. doi:10.1039/C8NA00101D. Retrieved 2019-05-29.\n- Yue Zhao,Agnivo Gosai, Pranav Shrotriya : Effect of Receptor Attachment on Sensitivity of Label Free Microcantilever Based Biosensor Using Malachite Green Aptamer https://doi.org/10.1016/j.snb.2019.126963\n- Inglis, Simon: Football Grounds of Britain. CollinsWillow, 1996. page 206.\n- Madou, Marc J (2002). Fundamentals of Microfabrication. Taylor & Francis. ISBN 0-8493-0826-7.\n- Roth, Leland M (1993). Understanding Architecture: Its Elements History and Meaning. Oxford, UK: Westview Press. pp. 23–4. ISBN 0-06-430158-3.\n- Sarid, Dror (1994). Scanning Force Microscopy. Oxford University Press. ISBN 0-19-509204-X."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:ae6e49d2-e901-4941-a0ed-7c3c55cd7c94>","<urn:uuid:126e3f62-ac08-4efc-925a-2591d1b39f45>"],"error":null}
{"question":"What barriers do refugees with disabilities face in Indonesia compared to other transit countries mentioned in the research?","answer":"Refugees with disabilities face multiple barriers in Indonesia and other transit countries. The documents outline common challenges including affordability issues, bureaucratic obstacles, resource limitations, geographic/physical accessibility problems, communication barriers, and social/cultural stigma. In Indonesia specifically, these challenges are compounded by the country's non-ratification of the Refugee Convention, which means refugees lack legal status and protection. Without formal recognition, refugees with disabilities in Indonesia face additional bureaucratic hurdles in accessing services compared to countries that have ratified the Convention. They must rely entirely on UNHCR processing, which makes the process lengthy and less efficient. The situation is particularly concerning given Indonesia's ranking as one of the least refugee-friendly countries according to Amnesty International.","context":["1. New Paradigms for the Right to Health\n1.1. Changing Global Approaches to Disability\nPersons with disabilities include those who have long-term physical, mental, intellectual or sensory impairments, which in interaction with various barriers may hinder their full and effective participation in society on an equal basis with others.\n1.2. Current Approaches to Disability in Displacement\n2. The International Legal Framework for Health Rights 1\n2.1. The International Human Right to Health\nTake, in accordance with their obligations under international law, including international humanitarian law and international human rights law, all necessary measures to ensure the protection and safety of persons with disabilities in situations of risk, including situations of armed conflict, humanitarian emergencies and the occurrence of natural disasters.\nThe rights to food, housing, work, education, human dignity, life, non-discrimination, equality, the prohibition against torture, privacy, access to information, and the freedoms of association, assembly and movement .(para 3)\nThe right to health embraces a wide range of socio-economic factors that promote conditions in which people can lead a healthy life, and extends to the underlying determinants of health, such as food and nutrition, housing, access to safe and potable water and adequate sanitation, safe and healthy working conditions and a healthy environment .(para 4. See also para 11. See also , article 11, which draws links between health and safe working environments)\nattain and maintain maximum independence, full physical, mental, social and vocational ability, and full inclusion and participation in all aspects of life.(CRPD, art 26(1))\n2.2. Human Rights Legal Frameworks in Six Refugee-Hosting Countries\n3. Rights in Reality: Disability and the Enjoyment of Health in Displacement Settings\n3.1. The Protection of Refugees with Disabilities Project\n3.2. Displacement Contexts\n4. Access to Health Services: Country Comparisons\n4.1. Malaysia and Indonesia\n4.1.1. Health and Disability Overview\n4.2.1. Health and Disability Overview\n4.3.1. Health and Disability Overview\n4.4. Jordan and Turkey\n4.4.1. Health and Disability Overview\n5. Beyond Medical Assistance: Disability and Wellbeing in Displacement\n6. The Highest Attainable Standard? Concluding Reflections on Promoting Article 25 and Beyond\nConflicts of Interest\n- Neumayer, E.; Plumper, T. The gendered nature of natural disasters: The impact of catastrophic events on the Gender Gap in Life Expectancy. Ann. Assoc. Am. Geogr. 2007, 97, 551–566. [Google Scholar] [CrossRef]\n- Aglionby, J. Four times as many women died in tsunami. The Guardian, 26 March 2005. [Google Scholar]\n- Convention Relating to the Status of Refugees, 1951.\n- Protocol Relating to the Status of Refugees, 1967.\n- Crock, M.; Smith-Khan, L.; McCallum, R.; Saul, B. The Legal Protection of Refugees with Disabilities: Forgotten and Invisible; Edward Elgar: Cheltenham, UK; Northampton, MA, USA, 2017. [Google Scholar]\n- International Covenant on Economic, Social and Cultural Rights, 1966.\n- UN Committee on Economic Social and Cultural Rights. General Comment No. 3: The Nature of States Parties’ Obligations (Art. 2, Para. 1, of the Covenant), 1990.\n- UN Committee on Economic Social and Cultural Rights. General Comment No. 4: The Right to Adequate Housing (Art. 11(1) of the Covenant), 1991.\n- UN Committee on Economic Social and Cultural Rights. General Comment No. 12: The Right to Adequate Food (Art. 11), 1999.\n- Hathaway, J.C.; Foster, M. The Law of Refugee Status, 2nd ed.; Cambridge University Press: Cambridge, UK, 2014. [Google Scholar]\n- WHO. The Global Burden of Disease: 2004 Update; WHO: Geneva, Switzerland, 2008. [Google Scholar]\n- World Report on Disability; WHO & World Bank: Geneva, Switzerland, 2011.\n- Convention on the Rights of Persons with Disabilities, 2006.\n- Optional Protocol to the Convention on the Rights of Persons with Disabilities, 2008.\n- Kayess, R.; French, P. Out of Darkness into Light? Introducing the Convention on the Rights of Persons with Disabilities. Hum. Rights Law Rev. 2008, 8, 1–34. [Google Scholar] [CrossRef]\n- HelpAge International; Handicap International. Hidden Victims of the Syrian Crisis: Disabled, Injured and Older Refugees; HelpAge International & Handicap International: London, UK; Lyon, France, 2014. [Google Scholar]\n- UNHCR. Figures at a Glance. Available online: http://www.unhcr.org/en-au/figures-at-a-glance.html (accessed on 1 December 2018).\n- Smith-Khan, L.; Crock, M.; McCallum, R.; Saul, B. ‘Up to now I am suffering’: Justice, Sexual Violence and Disability amongst Refugees in Uganda. Int. J. Migr. Bord. Stud. 2015, 1, 348–371. [Google Scholar] [CrossRef]\n- Crock, M.; Smith-Khan, L. Swift and systematic? Identifying and recording disability in forced migration. In International Measurement of Disability—Purpose, Method and Application; Altman, B., Ed.; Springer: Cham, Switzerland, 2016. [Google Scholar]\n- Crock, M.; Ernst, C.; McCallum, R. Where disability and displacement intersect: Asylum seekers and refugees with disabilities. Int. J. Refug. Law 2012, 24, 735–764. [Google Scholar] [CrossRef]\n- Smith-Khan, L.; Crock, M.; Saul, B.; McCallum, R. To ‘Promote, Protect and Ensure’: Overcoming Obstacles to Identifying Disability in Forced Migration. J. Refug. Stud. 2015, 28, 38–68. [Google Scholar] [CrossRef]\n- Saul, B. Migrating to Australia with Disabilities: Non-Discrimination and the Convention on the Rights of Persons with Disabilities. Aust. J. Hum. Rights 2010, 16, 63–104. [Google Scholar] [CrossRef]\n- Saul, B. Migrant Rights to Social Security and Disability Support in Australia: Lessons from Geneva and South Africa. Univ. Coll. Lond. Hum. Rights Rev. 2010, 3, 72. [Google Scholar]\n- Hathaway, J.C. The Rights of Refugees under International Law; Cambridge University Press: Cambridge, UK, 2005. [Google Scholar]\n- Sen, A. Development as Freedom; Random House: New York, NY, USA, 1999. [Google Scholar]\n- Nussbaum, M.C. Sex and Social Justice; Oxford University Press: Oxford, UK, 1999. [Google Scholar]\n- UN Committee on Economic Social and Cultural Rights. General Comment No. 14: The Right to the Highest Attainable Standard of Health (Art. 12 of the Covenant), 2000.\n- Convention on the Elimination of All Forms of Discrimination against Women, 1979.\n- Keen, D. Refugees: Rationing the Right to Life; Zed Books: London, UK, 1992. [Google Scholar]\n- UN Office of the High Commissioner for Human Rights. Handbook for Parliamentarians on the Convention on the Rights of Persons with Disability: From Exclusion to Equality: Realizing the Rights of Persons with Disabilities; United Nations Department of Economic and Social Affairs (UNDESA): Geneva, Switzerland, 2007. [Google Scholar]\n- Constitution of the Hashemite Kingdom of Jordan, Jordan. 1952.\n- Schulze, M. Understanding the UN Convention on the Rights of Persons with Disabilities: A Handbook on the Human Rights of Persons with Disabilities; Handicap International: New York, NY, USA, 2010. [Google Scholar]\n- UNHCR and Chief Commissioner of Afghan Refugees (CCAR). Population Profiling, Verification and Response Survey of Afghans in Pakistan; UNHCR and Chief Commissioner of Afghan Refugees (CCAR): Islamabad, Pakistan, 2011. [Google Scholar]\n- Smith-Khan, L.; Crock, M.; McCallum, R.; Saul, B. Refugees with Disabilities in Pakistan: An Introductory Report. 2015. Available online: https://data2.unhcr.org/en/documents/download/62361 (accessed on 4 January 2019).\n- UNHCR. Global Focus: Malaysia: 2017 Year-End Report. Available online: http://reporting.unhcr.org/sites/default/files/pdfsummaries/GR2017-Malaysia-eng.pdf (accessed on 4 January 2019).\n- Regulation of the President of the Republic of Indonesia Concerning the Handling of Foreign Refugees, 2016.\n- UNHCR. Global Focus. Indonesia: 2017 Year-End Report. Available online: http://reporting.unhcr.org/sites/default/files/pdfsummaries/GR2017-Indonesia-eng.pdf (accessed on 4 January 2019).\n- UNHCR. Global Focus: Pakistan. Available online: http://reporting.unhcr.org/node/2546 (accessed on 4 January 2019).\n- UNHCR. Refugee Health Strategy 2014–2018 Pakistan. Available online: https://unhcrpk.org//wp-content/uploads/2018/06/Health-strategy.pdf (accessed on 4 March 2019).\n- UNHCR. Operational Update: Uganda. November 2018. Available online: http://reporting.unhcr.org/sites/default/files/UNHCR%20Uganda%20Operational%20Update%20-%20November%202018.pdf (accessed on 4 January 2019).\n- UNHCR. Global Focus. Turkey. Available online: http://reporting.unhcr.org/node/2544 (accessed on 4 January 2019).\n- Chuah, F.; Tan, S.; Yeo, J.; Legido-Quigley, H. The health needs and access barriers among refugees and asylum-seekers in Malaysia: A qualitative study. Int. J. Equity Health 2018, 17, 120. [Google Scholar] [CrossRef] [PubMed]\n- UNHCR. Public Health in Malaysia. Available online: http://www.unhcr.org/en-au/public-health-in-malaysia.html (accessed on 9 March 2018).\n- Ali, M.; Briskman, L.; Fiske, L. Asylum seekers and refugees in Indonesia: Problems and potentials. Cosmop. Civ. Soc. J. 2016, 8, 22–43. [Google Scholar]\n- Khan, F.; Amatya, B.; Sayed, T.M.; Butt, A.W.; Jamil, K.; Iqbal, W.; Elmalik, A.; Rathore, F.A.; Abott, G. World Health Orgnization Global Disablity Action Plan 2014–2021: Challenges and perspectives for physical medicine and rehabilitation in Pakistan. J. Rehabil. Med. 2017, 49, 10–21. [Google Scholar] [CrossRef] [PubMed]\n- Humanity & Inclusion; iMMAP. Removing Barriers—The path towards inclusive access: Disability Assessment among Syrian Refugees in Jordan and Lebanon—Jordan Report, July 2018; Humanity & Inclusion; iMMA: Jordan, 2018. [Google Scholar]\n- UNHCR. Global Focus. Jordan. Available online: http://reporting.unhcr.org/node/2549 (accessed on 4 January 2019).\n- Wells, R.; Steel, Z.; Abo-Hilal, M.; Hassan, A.H.; Lawsin, C. Psychosocial concerns reported by Syrian refugees living in Jordan: Systematic review of unpublished needs asessments. Br. J. Psychiatry 2016, 209, 99–106. [Google Scholar] [CrossRef] [PubMed]\n- UNHCR. UNHCR RSD Procedural Standards—Interpretation in UNHCR RSD Procedures; UNHCR: Geneva, Switzerland, 2016. [Google Scholar]\n- Sivunen, N. An Ethnographic Study of Deaf Refugees Seeking Asylum in Finland. Societies 2019, 9, 2. [Google Scholar] [CrossRef]\n- Pocock, N.S.; Suphanchaimat, R.; Chan, C.K.; Martinez Faller, E.; Harrigan, N.; Pillai, V.; Wickramage, K. Reflections on migrant and refugee health in Malaysia and the ASEAN region. BMC Proc. 2017, 12, 4. [Google Scholar] [CrossRef] [PubMed]\n- Women’s Refugee Commission. Vulnerability- and Resilience-Based Approaches in Response to the Syrian Crisis: Implications for Women, Children and Youth with Disabilities; Women’s Refugee Commission: New York, NY, USA, 2017. [Google Scholar]\nThis section of the paper draws on our work in Chapter 2. See 5. Crock, M.; Smith-Khan, L.; McCallum, R.; Saul, B. The Legal Protection of Refugees with Disabilities: Forgotten and Invisible?; Edward Elgar: Cheltenham, UK; Northampton, USA, 2017.\nMore information about the group and the questions they developed is available on their website: http://www.washingtongroup-disability.com/washington-group-question-sets/short-set-of-disability-questions/.\nSee for example the extensive work in this area by Uganda National Action on Physical Disability https://unapd.org/about-us/.\nFor an extended discussion of the combined impact of migration status and other personal attributes, see Chapter 6, 5. Crock, M.; Smith-Khan, L.; McCallum, R.; Saul, B. The Legal Protection of Refugees with Disabilities: Forgotten and Invisible?; Edward Elgar: Cheltenham, UK; Northampton, USA, 2017.\nFor a depiction of the connections between stressors, needs and experiences among Syrians in Jordan, see ref .\n|Treaty and Article||Description|\n|Convention relating to the status of Refugees 1951|\n|Article 1A(2)||Defines who is a refugee|\n|Articles 20–24||Basic welfare provisions covering refugees’ access to rations, housing, public relief, and social security, etc.|\n|Article 33||Prohibits parties from returning refugees from the country they are fleeing|\n|International Covenant on Economic, Social and Cultural Rights 1966|\n|Article 11||Sets out rights to adequate standard of living (food, clothing and housing)|\n|Article 12||Sets out right to the ‘highest attainable standard of health’|\n|Convention on the Rights of Persons with Disabilities 2006|\n|Article 1||Describes persons with disabilities|\n|Article 5||Requires parties to take measures to ensure equality and overcome discrimination|\n|Article 9||Sets out duties related to accessibility to ensure participation and full enjoyment of rights|\n|Article 11||Provides that Convention on the Rights of Persons with Disabilities (CRPD) applies in conflict/emergency situations|\n|Article 25||Echoes International Covenant on Economic, Social and Cultural Rights (ICESCR) article 12 right to health|\n|Article 26||Sets out right to habilitation and rehabilitation|\n|Refugee Convention and Protocol||No||No||No||27 September 1976||No||30 March 1962|\n31 July 1968\n(with geographic limitations)\n|CRPD||19 July 2010||30 November 2011||5 July 2011||25 September 2008||31 March 2008||28 September 2009|\n|ICESCR||No||23 February 2006||17 April 2008||21 January 1987||28 May 1975||23 September 2003|\n|Barrier||Overall Challenges||Additional Barriers|\n|Affordability||Most commonly identified barrier. Refugee incomes are often well below national poverty lines. In some locations, compounded by limited access to public health services due to non-citizen status, or the unavailability of free specialist care.||Persons with disabilities commonly have less household disposable income.|\nCosts compounded by limited transport options.\nAssistive devices are not provided, even where diagnosis is available (e.g., glasses).\nSpecialist services are less likely to be free.\n|Bureaucratic||Prioritization of ‘urgent’ treatable needs over long-term care.|\nDifficult to obtain travel clearance or access services outside assigned area based on registered address.\nAge-based inclusion criteria problematic in forced migration.\n|Persons with disabilities that are not ‘curable’ or who need ongoing support, e.g., with pain management, may quickly exhaust their allocated assistance.|\nFear around the impact of disclosing disability to refugee agency on refugee status determination and resettlement outcomes.\n|Demand/resources||Public/NGO services are overburdened and cannot meet demand.||Persons with disabilities pushed to the back of queues, experience distress or discomfort over waiting times. Overreliance on private/high fee services.|\nCompetition/limited places available for specialist/secondary services.\n|Geographic/physical||Affordable and/or specialist services are located far from refugee housing.||Limited accessible transport options.|\nRequiring the assistance of a friend/family member to navigate to/access the service.\nPhysical accessibility of buildings: e.g., stairs, inaccessible toilets, etc.\n|Communication||Language barriers between refugees and service providers may impede access to, or limit information about, available services.||Information for refugees may not be shared in accessible formats, and appropriate interpreting assistance is less likely to be available in non-local sign languages|\nIncreased risk of social isolation decreases access to information.\n|Social/cultural||Stigma attached to certain conditions or experiences: e.g., accessing reproductive services for pregnancy/birth or injury resulting from sexual violence.|\nEthnic, religious, age- or nationality-based discrimination.\n|Specific impairments/disabilities attract direct discrimination from the community, family or health service providers and deter disclosure/encourage social isolation.|\n© 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).","Ratification Urgency of the Refugee Convention and its Protocol in Indonesia\nIndonesia has become one of the most sought-after landing-places for refugees and asylum seekers. By the end of January 2012, according to United Nations High Commissioner for Refugees (UNHCR), it was found that there are 3275 asylum seekers and 1052 refugees registered in UNHCR Jakarta. Ironically, the protection and legal status of the asylum seekers and refugees are not yet guaranteed in Indonesia, although it should also be noted that Indonesia is considered a transit destination and had not taken part in Refugees Convention 1951 and its Optional Protocol 1967. According to the Refugees Friendly Index recorded by Amnesty International, among the 27 countries which public acceptance level towards refugees were rated, Indonesia—alongside Russia and Thailand—ranked as one of the countries with the worst reception towards refugees.\nWithout ratifying the Refugee Convention 1951 and its Optional Protocol 1967, the government of Indonesia is unable to give a status for the refugees and asylum seekers. Until then, the task lies in the hands of the UNHCR, which makes the process lengthy thus far less efficient. This causes them to be categorized as illegal immigrants which violates the administration of immigrants as regulated in Law no. 6 of 2011 on Immigration.\nRefugees and asylum seekers have become an international issue. It is due to the reason that Indonesia becomes a haven for these people that the problem becomes a national issue. The determination of the status of the refugees and asylum seekers towards the status of an immigrant is very important to be a priority in regards to prevent illegal immigrants entering and potentially causing a threat to national security. In consideration to this, the government should have ratified the Refugee Convention 1951 and Operational Protocol 1967 a long time ago. Based on Article 11 (2) of the 1945 Constitution and Article 25 (1) of Law no. 37 of 1999 states that the power to give asylum to foreigners lies in the President with the consideration from the Ministers and that the Refugee Convention should not give a negative impact to the people of Indonesia as well as the financial problem of the State in ratifying the convention to become a Presidential Regulation with the notification of the House of Respresentatives. In ratifying the conventions stated, it is obvious that Indonesia will receive certain benefits as well such as reducing the probability of asylum seekers categorized as illegal immigrants which have committed an international crime with the addition of the power of the government in determining the legal status for the refugees as well as making it simple to make decisions regarding the problem. The international community will also help the government in giving aid in regards to the handling of the refugees and asylum seekers so that the government will not handle all the burden. Aside from that, in ratifying the Convention stated, it will increase the rank of Indonesia as a refugee and asylum seeker friendly state. Pancasila also stated the sila of just and civilized humanity and by giving aid to the refugees and asylum seekers, Indonesia implements the values of humanity stated. The government may be sued for restraining the needs of the refugees because Indonesia herself from year to year receives refugees from different neighboring states such as Myanmar as well as from Middle East as another example. If this is not taken into matter correctly, the asylum seekers and refugees will find themselves living in a hostile environment after leaving their state of origin.\nThe government should initiate the ratification of the Refugee Convention 1951 and Operational Protocol 1967 not only so that the refugees and asylum seekers coming to Indonesia are guaranteed protection but also due to the reason that there is a concrete national regulation regarding refugees and asylum seekers. The government will also have their burden lifted in the supervision and decision making to the matter at hand.\n Hukum Online “Indonesia Perlu Ratifikasi Konvensi tentang pengungsi” hukumonline.com http://www.hukumonline.com/berita/baca/lt4f351aacc4a70/indonesia-perlu-ratifikasi-konvensi-tentang-pengungsi (Accessed on 13 March 2017 at 19.08)\n CNN Indonesia “Amnesty : Warga Indonesia paling tak ramah kepada pengungsi” cnnindonesia.com http://www.cnnindonesia.com/internasional/20160520160115-106-132261/amnesty-warga-indonesia-paling-tak-ramah-kepada-pengungsi/ (Accessed on 14 March 2017 at 23.15)\n Hukum Online, Op.Cit\n Pasal 9 ayat (2) UU No. 24 Tahun 2000 tentang Perjanjian Internasional\nUnited Nations High Commissioner for Refugees, “The 1951 Convention relating to the status of refugees and its 1967 Protocol”, http://www.unhcr.org/about-us/background/4ec262df9/1951-convention-relating-status-refugees-its-1967-protocol.html diakses 13 Maret 2017.\nSucahyo Danang, “Ratifikasi perjanjian Internasional menurut undang-undang”, http://danangsucahyo.blogspot.co.id/2013/01/ratifikasi-perjanjian-internasional.html diakses 14 maret 2017.\nTirto.id “Indonesia dan Persimpangan Pengungsi” https://tirto.id/indonesia-dan-persimpangan-para-pengungsi-9jb diakses 13 maret 2017\nCNN Indonesia “Amnesty : Warga Indonesia paling tak ramah kepada pengungsi” http://www.cnnindonesia.com/internasional/20160520160115-106-132261/amnesty-warga-indonesia-paling-tak-ramah-kepada-pengungsi/ diakses 13 maret 2017"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:6ec275c0-d1a3-4721-836b-889c44986572>","<urn:uuid:2dd81e55-9147-4f34-a020-ec30292a5d90>"],"error":null}
{"question":"How much money did the Washington-Baltimore Regional Coalition invest in preparing their Olympic bid, and what was the scope of their proposal?","answer":"The Washington-Baltimore 2012 Regional Coalition invested $9.5 million to craft a 600-page bid. Their proposal projected selling 8.5 million tickets and attracting more than 5 million visitors.","context":["Dan Knise is president and CEO of the Washington-Baltimore… (Lloyd Fox, Baltimore Sun )\nA little more than a decade ago, a group of business executives and civic leaders envisioned a moment when the world's eyes would be riveted by events in the Baltimore-Washington area: the lighting of a cauldron followed by two weeks of elite athletic competition.\nThe group hoped to bring the 2012 Summer Olympics to the region — and with it, billions of dollars in revenue and tens of thousands of new jobs.\nBaltimore would be the scene for soccer, gymnastics, triathlon, cycling and field hockey. The waters near the Naval Academy would be used for the sailing competition. The hills of Patapsco Valley State Park would challenge mountain bikers. University of Maryland dorms would provide a temporary home for athletes.\nAnd, though the organizers had no way of knowing it then, they also might have given Michael Phelps home-field advantage in his final Olympics.\n\"The area had everything in the world to offer the International Olympic Committee,\" recalled John Moag Jr., former chairman of the Maryland Stadium Authority and a leader of the Washington-Baltimore 2012 Regional Coalition. \"We all felt good about it.\"\nBut when the U.S. Olympic Committee picked its candidate in 2002, the region's bid lost to New York, which lost to London three years later, when the International Olympic Committee made its choice.\nThe rejection was not only a blow to local civic pride, but also an economic letdown.\n\"A lot of federal money is secured in the name of the Olympics,\" said Lisa Delpy Neirotti, an associate professor of tourism and sports management at George Washington University. \"We missed out on federal transportation and beautification dollars. The University of Maryland missed out on money to improve its dorms. In the private sector, hotels and restaurants missed out on hospitality dollars.\"\nDan Knise, president and CEO of the coalition, said projects that likely would have received an Olympic-sized financial boost included Baltimore's proposed $2.2 billion Red Line light rail, a new Baltimore arena and upgrades at the University of Maryland, Baltimore County, the field hockey site.\n\"I think there would have been a lot of new things,\" Knise said.\nMany cities have benefited from holding the Olympics. Once-dowdy East London is getting a makeover, with new pedestrian bridges and walkways. After the games, the media center will be converted into an office building and the athletes' village will become apartments and subsidized housing. An expanded railway system will be a boon to commuters.\nIn 2002, Salt Lake City greeted spectators with an expanded airport, upgraded highways and a new light rail system.\n\"The Olympics were good to the city and the region,\" said former Salt Lake City Mayor Rocky Anderson. \"There's a sense of real joy and accomplishment. I don't think there's any question that it was good for civic pride, and that's going to have a lifetime impact.\"\nBut there can also be a downside.\nUntil Los Angeles showed the world how to turn a profit in 1984 by lining up scads of sponsors, holding the Olympics was often a red-ink affair. Denver walked away after securing the 1976 Winter Games when voters rejected a $5 million bond to pay for them. Montreal posted a loss of $1 billion on the 1976 Summer Games.\nWithout the U.S. Olympic Committee quietly forgiving as much as $50 million in debt, organizers of the 1996 Summer Games in Atlanta could not have claimed that they broke even. A post-Olympics economic analysis by Georgia Tech University showed that during the Games, sales were off in Atlanta shops and restaurants, traditional tourism dropped, air travel was down — and taxpayers shelled out millions.\nThat was not the expected scenario for the Baltimore-Washington region.\nA 2000 economic impact study conducted by Richard Clinch of the University of Baltimore and Stephen Fuller of George Mason University projected that the Olympics would cost $2.04 billion to build and run, with a return of $5.32 billion in total economic impact — $6.72 billion in today's dollars. The lead-up to the Summer Games was expected to support the creation of nearly 70,000 jobs.\n\"But to make this work, we needed more of Maryland than just the Washington suburbs,\" Fuller recalled. \"We needed Baltimore. We needed all the hotel rooms, all the venues and all of the attractions. It brought together two economies that weren't normally thought of together. I think it was a good marriage.\"\nSo good, in fact, that a promotional flier at the time shouted: \"This is regionalism brought to life!\"\nThe Washington-Baltimore 2012 Regional Coalition invested three years and $9.5 million to craft a 600-page bid. Organizers lined up financial support from corporations such as Verizon, Legg Mason, Bank of America, Giant, Marriott International and the company then known as Mobil.\nIn the proposal, organizers projected selling 8.5 million tickets and attracting more than 5 million visitors."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:ba36761e-6a7a-459a-b21d-9fa9a60d51fb>"],"error":null}
{"question":"What are the research challenges in studying biological processes in both cancer metastasis and marine ecosystems, considering environmental factors and disease transmission mechanisms?","answer":"Research challenges in both fields involve complex biological interactions and environmental factors. In cancer studies, researchers must track miRNA expression levels and their effects on tumor progression, requiring careful laboratory controls and survival analysis. For marine ecosystems, researchers face challenges studying disease transmission due to multiple environmental threats including wastewater pollution, climate change, and coastal development that can alter biological processes. Disease transmission in both contexts involves host-pathogen interactions - in cancer through metastasis patterns, and in coral reefs through bacterial pathogens that can lead to outbreaks. Both fields must also account for how environmental conditions affect biological processes, with wastewater pollution being a common factor that can alter temperature, pH, and oxygen levels.","context":["Purpose miR-409-3p/-5p is a microRNA expressed by embryonic control cells and its function in cancers metastasis and biology is unidentified. gland activated tumors where the tumors portrayed, Stemness and EMT markers. Intracardiac inoculation (to imitate systemic dissemination) of miR-409-5p inhibitor treated bone fragments metastatic ARCaPM prostate cancers cells in rodents, led to reduced bone fragments metastasis and elevated success likened to control vehicle-treated cells. Bottom line miR-409-3p/-5p has an essential function in prostate cancers biology by assisting growth development, Bone and EMT metastasis. This selecting holds particular translational importance since miR-409-3p/-5p shows up to end up being an appealing biomarker and/or perhaps a healing focus on HMN-214 to deal with bone tissues metastatic prostate cancers. pet research Mouse tumor and tumor xenografts were paraffin-embedded and formalin-fixed. miRNA ISH process was implemented as per producers guidance (Exiqon, Mother). One QD labels was performed as previously talked about (16). Scramble, miR-409-5p or miR-409-3p probes had been tagged with 625 nm QDs (16). Pictures had been used at 40x. L&Y yellowing was performed on following tissues sections. MSKCC dataset analysis The dataset was published by MSKCC team (20) and was acquired from cBioPortal (21). miR-409-3p but not miR-409-5p was analyzed in the ITGAV dataset. For the analysis of miR-409-3p with different Gleason scores, individuals with Gleason score 6 or 7 (in=86) were arranged collectively to compare with those with Gleason score 8 or 9 (in=12). College student capital t test was carried out between the two organizations for analysis of differential appearance of miR-409-3p between two cohorts. For the survival analysis, the appearance levels of miR-409-3p in individuals were compared with the median appearance level of normal individuals. The disease free survival of individuals with miR-409-3p appearance levels higher than normal individual (n=29) was compared with that with lower miR-409-3p expression levels (n=78). Kaplan-Meier survival curve was done by log-rank test between high and low expression groups. Lentiviral transduction ARCaPE or LNCaP PCa cell lines were transduced with miR-409 lentivirus expressing green fluorescent protein (GFP) or control GFP lentivirus and ARCaPM PCa cell lines were transduced with miR-409-5p lentivirus expressing GFP or control GFP lentivirus. Lentiviral preparation and transduction of cell lines were performed as per the manufacturers instructions (System Biosciences). GFP positive cells were FACS sorted and cultured metastasis study Luciferase tagged ARCaPM control and ARCaPM-409-5pi cells were injected intra-cardially as previously mentioned (24) in male SCID/beige mice (Charles River Laboratories) (N=5/group). Mice were imaged for bioluminescence and X-ray detection using IVIS? Lumina Imaging system. Mice were euthanized when they produced large tumors. Mice were given NIR dye (IR783) 48 h before euthanasia, the tumor specific NIR dye was used to detect metastatic tumor HMN-214 in the mice. Statistical analysis Values were expressed as means standard HMN-214 deviation. All experiments were done in triplicates at least two independent times. Statistical analysis was performed using Students t-test. For cells Gleason rating array, the difference between the combined groups were tested by Kruskal-Wallis one way analysis of variance. A post hoc Tukey technique was utilized to allow multiple evaluations between organizations. Ideals of g<0.05 were considered to be significant statistically. Outcomes MicroRNA miR-409-3p/-5p can be overexpressed in bone tissue metastatic EMT versions of human being PCa To understand the regulatory part of microRNAs in EMT and PCa bone tissue metastasis, we performed miRNA profiling of two lineage-related, bone tissue metastatic HMN-214 human being PCa cell lines differentially, ARCaPE (non-metastatic range) and ARCaPM (metastatic range), denoted respectively their epithelial (ARCaPE) and mesenchymal (ARCaPM) phenotype (15, 25) (Supplementary Desk. T2, T3). The differential miRNA appearance of the non-metastatic (ARCaPE) and metastatic PCa cells.\nPurpose miR-409-3p/-5p is a microRNA expressed by embryonic control cells and","Beyond threats associated with climate and ocean change, coral reefs are also affected by various local and regional threats. These threats may occur alone or synergistically with climate change adding to the risks to coral reef systems.\nOverfishing and Destructive Fishing\nUnsustainable fishing has been identified as the most pervasive of all local threats to coral reefs. ref Over 55% of the world’s reefs are threatened by overfishing and/or destructive fishing. Overfishing (i.e., catching more fish than the system can support) leads to declines in fish populations, ecosystem-wide impacts, and impacts on dependent human communities. Destructive fishing is associated with some types of fishing methods including dynamite, gill nets, and beach seines. These harm coral reefs not just through physical impacts but also through by-catch and mortality of non-target species including juveniles. Read more about threats and management strategies in the Reef Fisheries Toolkit.\nTraditionally, impacts from wastewater pollution have been associated with human health, but the detrimental effects of wastewater pollution on marine life – and the indirect impacts they have on people – cannot be overlooked. Wastewater transports pathogens, nutrients, contaminants, and solids into the ocean that can cause coral bleaching and disease and mortality for coral, fish, and shellfish. Wastewater pollution can also alter ocean temperature, pH, salinity, and oxygen levels disrupting biological processes and physical environments essential to marine life.\nOther sources of pollution to coral reef waters include land-based pollution associated with human activities such as agriculture, mining and coastal development leading to the discharge or leaching of harmful sediments, pollutants, and nutrients. Marine-based pollution associated with commercial, recreational, and passenger vessels can also threaten reefs by discharging contaminated bilge water, fuel, raw sewage, and solid waste, and by spreading invasive species. Learn more in the Wastewater Pollution Toolkit or in the Wastewater Pollution Online Course.\nMore than 2.5 billion people (40% of the world’s population) live within 100 km of the coast, ref adding increased pressure to coastal ecosystems. Coastal development linked to human settlements, industry, aquaculture, and infrastructure can cause severe impacts on nearshore ecosystems, particularly coral reefs. Coastal development impacts may be direct (e.g., land filling, dredging, and coral and sand mining for construction) or indirect (e.g., increased runoff of sediment, sewage, and pollutants).\nTourism and Recreational Impacts\nRecreational activities can harm coral reefs through:\n- Breakage of coral colonies and tissue damage with direct contact such as walking, touching, kicking, standing, or gear contact that often happen with SCUBA, snorkelling, and trampling\n- Breakage or overturning of coral colonies and tissue damage from negligent boat anchoring\n- Changes in marine life behavior from feeding or harassment by humans\n- Water pollution by tour boats through the discharge of fuel, human waste, and grey water\n- Invasive species which can be spread through transportation of ballast water, hull fouling of cruise ships, and fouling from recreational boating\n- Trash and debris deposited in the marine environment\nCoral disease is a naturally occurring process on reefs, but certain factors can exacerbate disease and cause outbreaks. Coral disease outbreaks can lead to an overall reduction in live coral cover and reduced colony density. In extreme cases, disease outbreaks can initiate community phase-shifts from coral- to algal-dominated communities. Coral diseases can also result in a restructuring of coral populations.\nDisease involves an interaction between the coral host, a pathogen, and the reef environment. Scientists are learning more about the causes of coral disease, especially in terms of identifying the pathogens involved. To date, the most infectious coral diseases are caused by bacteria. Transmission of coral diseases can be facilitated in areas of high coral cover ref as well as through coral predation, as predators can act as vectors by oral or fecal transmission of pathogens. ref\nThe causes of coral disease outbreaks are complex and not well understood, although research suggests that important drivers of coral disease include climate warming, land-based pollution, sedimentation, overfishing, and physical damage from recreational activities. ref\nOn coral reefs, marine invasive species include some algae, invertebrates, and fishes. Invasive species are species that are not native to a region. However, not all non-native species are invasive. Species become invasive if they cause ecological and/or economic harm by colonizing and becoming dominant in an ecosystem, due to the loss of natural controls on their populations (e.g., predators).\nPathways of introduction of marine invasive species include:\n- Ship traffic, such as ballast water and hull fouling\n- Aquaculture operations (shellfish aquaculture is responsible for the spread of marine invasive species through global transport of oyster shells or other shellfish for consumption)\n- Fishing gear and SCUBA gear (through transport when moving from place to place)\n- Accidental discharge from aquaria through pipes or intentional release\nSargassum are a type of brown, fleshy macroalgae that can have detrimental ecological and economic impacts on coral reefs when overabundant.\nIn the Indo-Pacific, high percent cover of Sargassum is common on degraded coral reefs and often represents a phase-shift from a coral to algae-dominated reef system. ref Their reproductive biology and morphology make them excellent colonizers of free space and particularly resilient to disturbances such as tropical storms. ref When overabundant, they can negatively impact the reef by shading, limiting space available for coral larvae to recruit, and transmitting pathogens. ref\nIn the Atlantic, two species of floating sargassum, S. natans and S. fluitans, are responsible for causing large mats of algae blooms which are particularly harmful and prevalent on the Caribbean and West African coastlines. ref Floating algae mats are naturally prevalent in the Northern Atlantic and provide many ecological benefits such as habitat, food, and nursery grounds to many species of fish, crustaceans and even sea turtles. ref However, in the last ten years, a shift in oceanic currents has led to an algae invasion in coral reef areas, causing reduced sunlight required by corals and anoxic and hypoxic conditions on reefs, as well as poor conditions on beaches that are detrimental to the tourism industry. ref\nCoral predators (or 'corallivores') are naturally occurring organisms that feed on corals for their polyps, tissue, mucus, or a combination of the above. Such predators typically include echinoderms (starfish, sea urchins), mollusks (snails), and some fish.\nCorallivory is a common process that, under normal conditions, allows for natural turnover in the ecosystem. However, when these predators are overly abundant (e.g., outbreak conditions), they can cause significant declines in coral cover.\nCommon coral predators include:\n- Crown-of-Thorns starfish (COTS), which are found throughout the Indo-Pacific region, occurring from the Red Sea and coast of East Africa, across the Pacific and Indian Oceans, to the west coast of Central America. COTS can be a major driver of coral loss in the Indo-Pacific, particularly under outbreak conditions.\n- Drupella snails, which are commonly found living on corals in reefs throughout the Indo-Pacific and Western Indian Ocean.\n- Coralliophila snails, which are often more problematic for Caribbean reefs, although some species are prevalent in the Pacific."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:f68409ec-4c36-47e8-87e8-10b60f935194>","<urn:uuid:6dd87468-19aa-450b-b9cc-46d264a1ee33>"],"error":null}