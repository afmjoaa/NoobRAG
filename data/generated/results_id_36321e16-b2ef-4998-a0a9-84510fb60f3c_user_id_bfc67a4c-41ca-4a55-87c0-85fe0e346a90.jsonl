{"question":"Which is more suitable for creating detailed 2D technical drawings - ASM Creator in Synthagate or the Drawing Workbench in FreeCAD?","answer":"The Drawing Workbench in FreeCAD is more suitable for creating detailed 2D technical drawings. It provides specialized tools for creating and manipulating 2D drawing sheets, displaying views of 3D work in 2D, adding annotations, and exporting to formats like SVG, DXF, and PDF. In contrast, ASM Creator in Synthagate is focused on creating algorithmic state machines (ASMs) as directed connected graphs with operator and conditional vertices, primarily for digital system design rather than technical drawings.","context":["- 1. Design Flow in Synthagate\n- 2. ASM in GUI or SystemC\n- 3. Time in ASM\n- 4. Transformations of ASMs\n- 5. Behavior Synthesis\n- 6. RTL Design\nASM in GUI or SystemC\nASM is the directed connected graph containing an initial vertex (Begin), a final vertex (End) and a finite set of operator and conditional vertices. In ASM, a logical condition is written in each conditional vertex. An operator, containing zero, one, two, three or more microoperations, is written in each operator vertex of ASM. Microoperations written in one operator are implemented simultaneously. Fig. 2 contains two ASMs – Coder (a) and Decoder (b) for some project Codec.\nFigure 1. ASMs Coder and Decoder\nThere are two kinds of micro operations in ASM:\n- Simple micro operation, containing assignments “:=”. We would like to underline here that at the behavior level we don’t have an architecture or Data Path of the designed system. If we write A:=B in the operator vertex, we mean that A is an input of some unit and B is the output of another unit but we don’t know yet how these units will be connected later – directly or through buses (multiplexers). Here we use A and B as variables and connection between them will be constructed automatically and optimal at the design of Data path.\n- Component micro operation (we call it a generalized operator), not containing an assign operator “:=”. In this disclosure they are colored by the yellow color, but the color is not important (see Fig. 1). These operators are sub ASMs and will be included in the upper ASM to get the whole behavior of digital system or one of its modes if we would like to present them separately.\nOperator and micro operations:\n- An operator can be either a set of micro operations, or a generalized operator.\n- A generalized operator always has only one micro operation.\n- The name of generalized operator must be exactly the same in all ASMs, and the same as the file name implementing that generalized operator. These names are case-insensitive – for example, PackData and PACKDATA are the same operators.\n- Microoperations (that are not generalized operators) are always assignments.\n- The source and the destination of an assignment should have the same width (in bits).\n- Registers/counters can be read (assigned) by bits. For example: r1(7-4):=r2(3-0).\n- Registers, counters and flip-flops cannot be read (sources) and assigned (targets) in the same operator.\n- Let m is a memory and m_adr is its address. If memory has address register (m_adr), address should be assign to this register in one of the previous operators. If memory has a bus for address (without register) one of these two assignment should be in the same operator:\nm_adr:=p; m[m_adr]:=r – write the contents of register r into memory cell p;\nm_adr:=p; r:=m[m_adr] – read the contents of memory cell p into register r.\nDesigner can draw ASMs in ASM Creator of Synthagate (Fig. 1). After “build” (special button in ASM Creator) Synthagate immediately compiles this schematic into internal form representation used at the next steps of design.\nFigure 2. Asm Coder and some its generalized operators\nEach generalized operator should be drawn separately. This file must have the same name as the name of generalized operator in the mother’s ASM. The generalized operator can contain generalized operators as well. There are no constraints on the number of generalized operators and the number of levels of such descriptions. Fig. 2 presents ASM Coder (on the left) and some its generalized operators. Coder has generalized operator PackData which has generalized operator PackSegment. The last, in turn, contains three generalized operators etc. Hereby, ASM Coder contains five level of inclusion.\nWhen constructing a very complex digital system, sometimes it is very difficult (really, impossible) to describe its whole behavior by one ASM. In such a case, we can present separate sub behaviors (modes, operations) with ASMs G1 … GQ and then combine them into one combined functional ASM G. As an example here we use a processor with two operations – Coder (Fig. 1a) and Decoder (Fig. 1b). Decoder reads the compressed data from memory M2, decompresses it and writes decoded data into memory M3. Thus, Synthagate supports multilevel top-down behavior descriptions. A designer shouldn’t construct very complex ASMs, maybe not more than 8-10 vertices in one ASM.\nIf designer wouldn’t like to use ASM Schematics (we strongly advise to use it) he can present ASMs as text files in System C (Fig. 3).\nFigure 3. ASM Coder in System C","All workbenches at a glance\nOne of the biggest difficulty for new users of FreeCAD, is to know in which workbench to find a specific tool. The table below will give you an overview of the most important workbenches and their tools. Refer to each workbench page in the FreeCAD documentation for a more complete list.\nFour workbenches are also designed to work in pairs, and one of them is fully included into the other: Arch contains all the Draft tools, and PartDesign all the Sketcher tools. However, for clarity, they are separated below.\nThe Part Workbench provides basic tools for working with solid parts: primitives, such as cube and sphere, and simple geometric operations and boolean operations. Being the main anchor point with OpenCasCade, the Part workbench provides the foundation of FreeCAD's geometry system, and almost all other workbenches produce Part-based geometry.\n|Box||Draws a box||Cone||Draws a cone|\n|Cylinder||Draws a cylinder||Sphere||Draws a sphere|\n|Torus||Draws a torus (ring)||Create Primitives||Creates various other parametric geometric primitives|\n|Shape Builder||Create more complex shapes from primitives||Fuse||Fuses (unions) two objects|\n|Common||Extracts the common (intersection) part of two objects||Cut||Cuts (subtracts) one object from another|\n|Join Connect||Connects interiors of walled objects||Join Embed||Embeds a walled object into another walled object|\n|Join Cutout||Creates a cutout in a wall of an object for another walled object||Extrude||Extrudes planar faces of an object|\n|Fillet||Fillets (rounds) edges of an object||Revolve||Creates a solid by revolving another object (not solid) around an axis|\n|Section||Creates a section by intersecting an object with a section plane||Section Cross||Creates multiple cross sections along an object|\n|Chamfer||Chamfers edges of an object||Mirror||Mirrors the selected object on a given mirror plane|\n|Ruled Surface||Create a ruled surface between selected curves||Sweep||Sweeps one or more profiles along a path|\n|Loft||Lofts from one profile to another||Offset||Creates a scaled copy of the original object|\n|Thickness||Assign a thickness to the faces of a shape|\nThe Draft Workbench provides tools to do basic 2D CAD drafting tasks: lines, circles, etc... and a series of generic handy tools such as move, rotate or scale. It also provides several drawing aids, such as grid and snapping. It is principally meant to draw the guidelines for Arch objects, but also serves as FreeCAD's \"swiss army knife\".\n|Line||Draws a line segment between 2 points||Wire||Draws a line made of multiple line segments (polyline)|\n|Circle||Draws a circle from center and radius||Arc||Draws an arc segment from center, radius, start angle and end angle|\n|Ellipse||Draws an ellipse from two corner points||Polygon||Draws a regular polygon from a center and a radius|\n|Rectangle||Draws a rectangle from 2 opposite points||Text||Draws a multi-line text annotation|\n|Dimension||Draws a dimension annotation||BSpline||Draws a B-Spline from a series of points|\n|Point||Inserts a single point||Shape String||The ShapeString tool inserts a compound shape representing a text string at a given point in the current document|\n|Facebinder||Creates a new object from selected faces on existing objects||Bezier Curve||Draws a Bezier curve from a series of points|\n|Move||Moves or copies objects from one location to another||Rotate||Rotates objects by a certain angle around a point|\n|Offset||Offsets an object to a certain distance||Trimex||Trims, extends or extrudes an object|\n|Upgrade||Turns or joins objects into a higher-level object||Downgrade||Turns or separtes objects into lower-level objects|\n|Scale||Scales objects in relation to a point||Shape2D View||Creates a 2D object which is a flattened view of another object|\n|Draft2Sketch||Converts a Draft object to a Sketch and vice-versa||Array||Creates a polar or rectangular array from an object|\n|PathArray||Creates an array from an object by placing copies along a path||Clone||Creates linked copies of objects|\n|Mirror||Mirrors objects across a line|\nThe Sketcher Workbench contains tools to build and edit complex 2D objects, called sketches. The geometry inside these sketches can be precisely positioned and relationed by the use of constraints. They are meant primarily to be the building blocks of PartDesign geometry, but are useful everywhere in FreeCAD.\n|Point||Draws a point||Line by 2 points||Draws a line segment from 2 points|\n|Arc||Draws an arc segment from center, radius, start angle and end angle||Arc by 3 points||Draws an arc segment from two endpoints and another point on the circumference|\n|Circle||Draws a circle from center and radius||Circle by 3 points||Draws a circle from three points on the circumference|\n|Ellipse by center||Draws an ellipse by center point, major radius point and minor radius point||Ellipse by 3 points||Draws an ellipse by major diameter (2 points) and minor radius point|\n|Arc of ellipse||Draws an arc of ellipse by center point, major radius point, starting point and ending point||Polyline||Draws a line made of multiple line segments. Several drawing modes available|\n|Rectangle||Draws a rectangle from 2 opposite points||Triangle||Draws a regular triangle inscribed in a construction geometry circle|\n|Square||Draws a regular square inscribed in a construction geometry circle||Pentagon||Draws a regular pentagon inscribed in a construction geometry circle|\n|Hexagon||Draws a regular hexagon inscribed in a construction geometry circle||Heptagon||Draws a regular heptagon inscribed in a construction geometry circle|\n|Octagon||Draws a regular octagon inscribed in a construction geometry circle||Slot||Draws an oval by selecting the center of one semicircle and an endpoint of the other semicircle|\n|Fillet||Makes a fillet between two lines joined at one point||Trim||Trims a line, circle or arc with respect to a clicked point|\n|External Geometry||Creates an edge linked to external geometry||Construction Mode||Toggles an element to/from construction mode. A construction object will not be used in a 3D geometry operation and is only visible while editing the Sketch that contains it|\n|Coincident constraint||Affixes a point onto (coincident with) one or more other points.||Point On Object constraint||Affixes a point onto another object such as a line, arc, or axis.|\n|Vertical constraint||Constrains the selected lines or polyline elements to a true vertical orientation. More than one object can be selected before applying this constraint.||Horizontal constraint||Constrains the selected lines or polyline elements to a true horizontal orientation. More than one object can be selected before applying this constraint.|\n|Parallel constraint||Constrains two or more lines parallel to one another.||Perpendicular constraint||Constrains two lines perpendicular to one another, or constrains a line perpendicular to an arc endpoint.|\n|Tangent constraint||Creates a tangent constraint between two selected entities, or a co-linear constraint between two line segments.||Equal Length constraint||Constrains two selected entities equal to one another. If used on circles or arcs their radii will be set equal.|\n|Symmetric constraint||Constrains two points symmetrically about a line, or constrains the first two selected points symmetrically about a third selected point.||Lock constraint||Constrains the selected item by setting vertical and horizontal distances relative to the origin, thereby locking the location of that item|\n|Horizontal Distance constraint||Fixes the horizontal distance between two points or line endpoints. If only one item is selected, the distance is set to the origin.||Vertical Distance constraint||Fixes the vertical distance between 2 points or line endpoints. If only one item is selected, the distance is set to the origin.|\n|Length constraint||Defines the distance of a selected line by constraining its length, or defines the distance between two points by constraining the distance between them.||Radius constraint||Defines the radius of a selected arc or circle by constraining the radius.|\n|Internal Angle constraint||Defines the internal angle between two selected lines.||Snell's Law constraint||Constrains two lines to obey a refraction law to simulate the light going through an interface|\n|Internal Alignment constraint||Aligns selected elements to selected shape (e.g. a line to become major axis of an ellipse)||Map sketch to face||Maps a sketch to the previously selected face of a solid|\n|Merge||Merge two or more sketches||Mirror||Mirrors selected elements of a sketch|\nThe Part Design Workbench contains advanced tools to build solid parts. It also contains all the tools from the sketcher. Since it can only produces solid shapes (the rule number one of Part Design), it is the main workbench to use when designing pieces (parts) to be manufactured or 3D-printed, as you will always obtain a printable object.\n|Pad||Extrudes a solid object from a selected sketch||Creates a pocket from a selected sketch. The sketch must be mapped to an existing solid object's face|\n|Revolution||Creates a solid by revolving a sketch around an axis||Groove||Creates a groove by revolving a sketch around an axis|\n|Fillet||Fillets (rounds) edges of an object||Chamfer||Chamfers edges of an object|\n|Draft||Applies angular draft to faces of an object||Mirrored||Mirrors features on a plane or face|\n|Linear Pattern||Creates a linear pattern of features||Polar Pattern||Creates a polar pattern of features|\n|Scaled||Scales features to a different size||MultiTransform||Allows creating a pattern with any combination of the other transformations|\n|Shaft wizard||Generates a shaft from a table of values and allows to analyze forces and moments||Involute Gear wizard||Allows you to create several types of gears|\nThe Arch Workbench contains tools to work with BIM projects (civil engineering and architecture). It also contains all the tools from the Draft workbench. The main use of the Arch Workbench is to create BIM objects or give BIM attributes to objects built with other workbenches, in order to export them to IFC.\n|Wall||Creates a wall from scratch or using a selected object as a base||Structure||Creates a structural element from scratch or using a selected object as a base|\n|Reinforcement Bar||Creates a reinforcement bar in a selected structural element||Floor||Creates a floor including selected objects|\n|Building||Creates a building including selected objects||Site||Creates a site including selected objects|\n|Window||Creates a window using a selected object as a base||Section Plane||Adds a section plane object to the document|\n|Axes||Adds an axes system to the document||Roof||Creates a sloped roof from a selected face|\n|Space||Creates a space object in the document||Stairs||Creates a stairs object in the document|\n|Panel||Creates a panel object from a selected 2D object||Frame||Creates a frame object from a selected layout|\n|Equipment||Creates an equipment or furniture object||Set Material||Attributes a material to selected objects|\n|Schedule||Creates different types of schedules||Cut Plane||Cut an object according to a plan.|\n|Add Component||Adds objects to a component||Remove Component||Subtracts or removes objects from a component|\n|Survey Mode||Enters or leaves surveying mode|\nThe Drawing Workbench handles the creation and manipulation of 2D drawing sheets, used for displaying views of your 3D work in 2D. These sheets can then be exported to 2D applications in SVG or DXF formats, to a PDF file or printed.\n|New sheet||Creates a new drawing sheet||Insert view||Inserts a view of the selected object in the active drawing sheet|\n|Annotation||Adds an annotation to the current drawing sheet||Clip||Adds a clip group to the current drawing sheet|\n|Browser preview||Opens a preview of the current sheet in the browser||Ortho Views||Automatically creates orthographic views of an object on the current drawing sheet|\n|Symbol||Adds the contents of a SVG file as a symbol on the current drawing sheet||Draft View||Inserts a special Draft view of the selected object in the current drawing sheet|\n|Export||Saves the current sheet as a SVG file|\nOther built-in workbenches\nAlthough the above summarizes the most important tools of FreeCAD, many more workbenches are available, among them:\n- The Mesh Workbench allows to work with polygon meshes. Although meshes are not the preferred type of geometry to work with in FreeCAD, because of their lack of precision and support for curves, meshes still have a lot of uses, and are fully supported in FreeCAD. The Mesh Workbench also offers a number of Part-to-Mesh and Mesh-to-Part tools.\n- The Raytracing Workbench offers tools to interface with external renderers such as povray or luxrender. Right from inside FreeCAD, this workbench allows you to produce high-quality renderings from your models.\n- The Spreadsheet Workbench permits the creation and manipulation of spreadsheet data, that can be extracted from FreeCAD models. Spreadsheet cells can also be referenced in many areas of FreeCAD, allowing to use them as master data structures.\n- The FEM Workbench deals with Finite Elements Analysis, and permits the performing of pre- and post-processing FEM calculations and to display the results graphically.\nA number of other very useful workbenches produced by FreeCAD community members also exist. Although they are not included in a standard FreeCAD installation,they are easy to install as plug-ins. They are all referenced in the FreeCAD-addons repository. Among the most developed are:\n- The Drawing Dimensioning Workbench offers many new tools to work directly on Drawing Sheets and allow you to add dimensions, annotations and other technical symbols with great control over their aspect.\n- The Fasteners Workbench offers a wide range of ready-to-insert fasteners objects like screws, bolts, rods, washers and nuts. Many options and settings are available.\n- The Assembly2 Workbench offers a series of tools to mount and work with assemblies.\n- The complete list of workbenches: http://www.freecadweb.org/wiki/index.php?title=Workbenches\n- The Part Workbench: http://www.freecadweb.org/wiki/index.php?title=Part_Module\n- The Draft Workbench: http://www.freecadweb.org/wiki/index.php?title=Draft_Module\n- The Sketcher and Part Design Workbench: http://www.freecadweb.org/wiki/index.php?title=PartDesign_Workbench\n- The Arch Workbench: http://www.freecadweb.org/wiki/index.php?title=Arch_Module\n- The Drawing Workbench: http://www.freecadweb.org/wiki/index.php?title=Drawing_Module\n- The FEM Workbench: http://www.freecadweb.org/wiki/index.php?title=Fem_Workbench\n- The FreeCAD-addons repository: https://github.com/FreeCAD/FreeCAD-addons"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:3c24de84-b782-40cd-b4c0-d74db4aa315a>","<urn:uuid:9d1641b3-8f80-4e26-8297-869262fc24e9>"],"error":null}
{"question":"Can you compare the sheet lead adjustment techniques for headsails versus mainsail control in terms of available control mechanisms?","answer":"Headsails have several sheet lead adjustment options: sliding blocks on deck tracks, trunnion snap shackle blocks on perforated toerails, towed car systems, running sheet systems, and Barber haulers for deflecting the sheet. In contrast, the mainsail has five primary controls: the mainsheet, traveler, outhaul, cunningham, and mast bend for shaping and controlling the sail.","context":["How to Get the Most Out of Your Headsail\nOptimal sailing performance requires adjusting headsail sheet angles so that the jib, genoa or staysail forms an effective airfoil. Even minor misadjustment of the lead block or tension on sheet, halyard, leech or foot cords can cause a dramatic reduction in performance. Yet it is common for us to sail on boats that have inadequate means of monitoring sheet lead settings or without means to make the proper headsail adjustments.\nReading the flow\nBefore you can adjust the sheet lead, you must be able to read airflow over the sail. Every headsail should have pairs of telltales port and starboard just inboard about 8 to 12 inches off the luff. There should be one pair near the head, another up from the tack that is visible from the helm, and a third pair near the middle of the luff. Large sails may use a fourth or fifth pair. In addition it's helpful to have three or four single telltales located along the leech of the sail.\nTelltales can be bought ready-made (Davis no. 950 Air-Flow Tells -- seven pairs for $5). But our favorites are quarter-inch-wide strips of black or bright-colored three-quarter-ounce spinnaker cloth attached with one-inch squares of sticky-back Dacron. We have found that black actually shows up best, even at night. Most sailmakers have scrap supplies. Your sailmaker might convince you to install telltale windows along the luff of your sail so you can read the airflow on the leeward side as well.\n| When all telltales on the leech and luff stream aft smoothly in the wind the sail|\nis an efficient airfoil.\nIf the luff telltales all flow in the wind but the leech telltales flutter, the sheet lead is too far inboard or the leech cord is overly tight. Sometimes when reaching in heavy air, the leech telltales will flutter in the puffs if the main is eased. This usually indicates that it's time to reef the main.\nIf the windward luff telltales all flutter while the leeward telltales flow, the lead is correct but the sheet is eased too far and the sail needs to come in more.\nIf all the leeward luff telltales flutter but the windward telltales all flow smoothly, the sheet lead is probably correct but the sail is trimmed in too tightly. Slowly let out some sheet and re-check the telltales.\nIf the luff telltales near the top of the sail flutter while the ones near the tack stream correctly, the lead is too far aft.\nIf the luff telltales near the tack flutter before the ones near the head of the sail, the lead is too far forward. The leech telltales will generally curl inboard in this case.\nAdjusting the lead\n|Typical single and double sheet lead cars on spring stop track sliders.|\n|A towed-car system: The blue line is the sheet, while the yellow/green line hauls the car forward and the red line hauls it aft.|\n|A running-sheet system: The red line is the sheet while the yellow/green runner adjusts the lead forward and aft.|\nThe most common method of adjusting sheet angle is with a lead block sliding on a track bolted to the deck. Some boats use trunnion snap shackle blocks on a perforated toerail. Many racing boats have two or more sets of tracks so the athwartships angle can be adjusted as well as the fore-and-aft sheet angle. Headsail sheets can produce very high loads making it difficult to slide a track block. For this reason sliders with tackles hauling the lead blocks fore and aft have become popular on larger boats.\nAn older method of changing the sheet lead moves the sail rather than a lead block. A tackle between the headsail tack and the deck fitting allows raising the entire sail up the headstay. Raising a sail has the same effect as moving a sheet lead forward; lowering a sail moves the lead aft. This method is still viable for boats with hank-on sails.\nAnother method of obtaining a full range of sheet angle to the headsail is the running sheet. Here two blocks are fixed to the deck, one at the farthest forward sheet lead position and one at the farthest aft. The sheet itself passes through the aft deck block to the clew of the sail. A second adjustment line passes through the forward deck block and terminates on a block \"running\" on the sheet. The bitter ends of both sheet and runner are in the cockpit. When the runner is fully released, the sheet is led as far aft as possible. When the runner is two-blocked, the lead is as far forward as possible.\n|This big cruiser has the ultimate in headsail sheet-lead systems, with inboard track, outboard track with 4 to 1 towed car and perforated toerail to attach a Barber hauler.|\nFor sailboats having only a single fixed point for the sheet lead block, or where a track is not long enough to fit all the sails, the solution is a Barber hauler (named after its inventor Merrit Barber). This is a short line with a hook or snatch block on one end to deflect the sheet, much like the running sheet system described above. We carry one with a single block having a cam cleat built in and a snap shackle head that can be attached onto a stout handrail, chainplate or stanchion base. By deflecting the sheet inward, outward or forward, we can achieve a perfect headsail shape.Photos by Kathy Barron","On most boats you have five controls to properly shape and control your mainsail; the mainsheet, traveler, outhaul, cunningham, and mast bend. For this article we are looking at a typical masthead rig with overlapping headsails. In making trimming the main you need to be well aware of what effect changes in trim will have on performance. A flatter sail will cause less heeling and have less drag which means more speed in conditions where you are over powered, making the sail fuller will produce more power when need. A tighter leech will improve pointing (up to the point where the sail is stalled) while a more open leech will improve acceleration and speed. A fuller sail will inherently be tighter leeched than a flat sail which will help pointing.\nIn medium air, usually 7 to 10 knots of wind where you aren’t overpowered, the sail should take its natural shape without much adjustment. This condition is what a typical mainsail should be designed and cut for. You want to use a combination of mainsheet tension and traveler position so that the boom is right on centerline and the top of the sail is twisted just enough so that the back half of the top batten is pointing straight aft, parallel to the centerline of the boat. The traveler will have to be pulled well to weather of the centerline to achieve this. The tell tale on the top batten will be streaming back most of the time but the leech should be tight enough so that the tell tale does stall out now and then. The cunningham should be tensioned just enough to remove wrinkles along the luff and the outhaul so be set so the center of the foot is 2” to 4” away from the boom, a little more if the sea conditions are bumpy.\nAs the wind increases and you start to have more power than you can use flatten the main a little bit. Tighten the outhaul so the foot is pulled up close to the boom and tighten the cunningham a little more if needed to take the wrinkles out along the luff. If you have a bendy rig you should tighten the backstay to increase mast bend and flatten the sail. As you do this the leech will become more open so you will need to tighten the mainsheet enough to keep the leech tight. In this condition the top tell tale should be streaming back most all the time and you want the leech as tight as you can get it before the top tell tale starts to stall. As the wind increases you will have to starting to let the traveler down an inch or two at a time to keep from being over powered.\nBy the time wind gets over 12 knots you want to get the main even flatter. Pull the outhaul all the way tight and bend the mast to flatten the sail even more. If you are consistently overpowered ease the mainsheet an inch or two to let the top twist open a little more. Generally I let it twist just enough so that I’m not over powered in the average wind and then play the traveler up and down in the puffs. Pull the cunningham tight to keep the draft in the sail forward and the leech open. The top tale should be streaming aft all the time.\nIn the 5 to 7 knot range you want the main a little fuller to produce more lift in the under powered conditions. Ease the outhaul off so the foot is 6” to 8” away from the boom and ease the backstay to reduce mast bend. This will also make the headstay looser which will help the genoa shape in light air, making it fuller and the entry rounder. Let the traveler down a few inches so that the boom is a little below the centerline to increase speed. In these conditions you need to point slightly lower to develop speed and increase your apparent wind. Ease the cunningham so that you have a few wrinkles along the luff. You want the sail as soft as possible so that it responds to very slight changes in wind pressure. The tell tale on the top batten will be stalled 50 to 60% of the time.\nIn very light conditions, under 5 knots, you actually want the mainsail to be a little flatter. Too much camber and the flow in light air won’t stay attached. Pull the outhaul out just snug so the foot is up close to the boom and put on enough backstay to slightly bend the mast. This will flatten the sail and open the leech which both help to keep good flow over the sail. The cunningham should be completely loose so you have some wrinkles along the luff.\nBelow is a quick reference summary."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:80ecf787-abb5-44bb-a997-7feb0b027309>","<urn:uuid:12b8a4c4-1d4c-4870-a59a-da763f3cac2c>"],"error":null}
{"question":"What are the potential benefits of nuclear fusion for sustainable energy production, and how does location impact the commercial viability of vertical farming installations?","answer":"Nuclear fusion offers significant benefits as a sustainable energy source, including the potential to provide zero-carbon energy with low radiation levels compared to other technologies. It works by merging atoms to create tremendous amounts of energy, similar to processes in the Sun's core, and could help achieve net-zero emissions by 2050. Recent breakthroughs include sustained fusion reactions lasting 17 minutes at 126 million degrees Fahrenheit in China. As for vertical farming's viability based on location, success depends heavily on factors like proximity to food distribution centers, water scarcity in the region, and local climate conditions. While city centers might seem ideal, locations near distribution hubs on city outskirts often prove more cost-effective. Vertical farms are particularly valuable in regions with water scarcity (like Sub-Saharan Africa and Middle East) or extreme climates (like Scandinavian countries), where they can provide fresh produce while using 95% less water than conventional agriculture.","context":["There's no denying it.\nNuclear fusion has the potential to completely transform the U.S. energy industry, and become a primary source of zero-carbon energy.\nThis is why, in a bid to \"win the 21st-century economy,\" the United States is heavily investing in nuclear fusion technology, according to a March 17 White House summit reported on by Scientific American.\nWhile scientific consensus is firm that we're still not ready to roll out fusion technology for commercial use, the early stages of renewable energy sources like solar, wind, and small modular reactors demand that we double down on reliable backups.\nAnd, in harnessing the same power used by the Sun, nuclear fusion could transform our energy infrastructure, for keeps.\nNuclear fusion can help us achieve net-zero emissions by 2050\nFusion is a process in physics whereby two atoms are pushed into one another until they merge, and create a heavier atom. This releases a tremendous amount of energy — it's the same process happening at the core of every star — and it generates comparably low levels of radiation.\nThat makes it an appealing alternative not only to fossil fuel or coal mining, but potentially every other kind of sustainable energy technology — even solar and wind. But critics among scientific consensus have maintained for decades that, while empirically plausible, the practical realities of implementing fusion technology on a commercial basis are and will remain beyond our reach for decades more.\nGet more updates on this story and more with The Blueprint, our daily newsletter: Sign up here for free.\nBut now, the White House has joined with a group of investors who don't shy away from risk to put forward fusion as a crucial means to building a new economy for the U.S., one that can offer net-zero greenhouse gas emissions by 2050, according to a fact sheet from the White House.\n\"We can lead the world with new energies and innovation and that is exactly what we are doing and why we are gathered here today,\" said Gina McCarthy, the White House's climate advisor, during the summit. \"We have to act on climate change so our country can win the 21st-century economy, and that's what fusion helps to present us with — tremendous opportunities as well as challenges we know.\"\nNuclear fusion deployment by end of the 2020s \"possible\"\nIncredibly, $45 million of the $1.5 trillion appropriations bill from Congress is committed to a new fusion program that will see private firms join forces with the Department of Energy (DOE) — united in a $700-million pursuit of novel fusion energy devices with the DOE's Fusion Energy Sciences program.\nThis multi-pronged effort to coordinate fusion energy research could see \"possible\" deployment by the end of the 2020s, said Jennifer Granholm, the energy secretary, during the summit.\nBut while it's tempting to rush to utopic depictions of a new fusion-powered future, we should definitely keep from expecting too much, according to Granholm. \"We've got to manage expectations,\" he said. \"There's a reason why fusion is hard. So it's going to take time: Even as we are making amazing progress, we have to be careful about overpromising, and we have to be realistic.\"\n🥳Record-breaking 59 megajoules of sustained fusion energy at world-leading UKAEA’s Joint European Torus (JET) facility. Video shows the record pulse in action. Full story https://t.co/iShCGwlV9Y #FusionIsComing #FusionEnergy #STEM #fusion @FusionInCloseUp @iterorg @beisgovuk pic.twitter.com/ancKMaY1V2— UK Atomic Energy Authority (@UKAEAofficial) February 9, 2022\nExtraordinary gains are in store for nuclear fusion this decade\nAlas, considering the scientific obstacles to realizing viable fusion power, she's not wrong. But this isn't to say fusion development is stuck, not by a long shot: A nuclear fusion project in China successfully sustained fusion reactions for 17 minutes at 126 million degrees Fahrenheit — five times the temperature of the Sun.\nIn February, scientists at the Joint European Torus (JET) facility in the United Kingdom's Oxford broke their own 24-year-old record by creating a 59-megajoule sustained fusion reaction. They even released a video of the breakthrough on Twitter.\nSmall moves, big gains - Ultimately, the skeptical attitude is apt when it comes to how soon nuclear fusion power that's viable on commercial scales will come. But with benchmarks and milestones beginning to follow one another like clockwork — from generating more power than is put into a fusion reaction to sustaining that output to more practical durations — we would be foolish to pretend that the 2020s won't be a time of extraordinary growth for nuclear fusion.","Vertical Farming: Location a Key Factor to Success, Says IDTechEx\nVertical farming, the practice of growing crops indoors on vertically stacked layers, has received no small amount of interest over the last few years. Vertical farms commonly tout impressive numbers, such as using 95% less water and providing crop yields 20-30 times that of conventional agriculture. These claims, among many others, have seen many vertical farming start-ups being founded alongside large amounts of industry funding; funding for the industry reached a record high in 2021, with over US$1 billion being raised across the entire industry. The recent IDTechEx report, \"Vertical Farming 2022-2032\", details the economic and technological factors shaping this rapidly growing industry.\nWith crops being grown indoors under controlled environments, a selling point used by multiple vertical farms is that they can grow crops anywhere – even in the heart of a city. This has led to proponents of the industry envisioning \"smart cities\", where vertical farms in city skyscrapers help feed the urban population. While this is achievable in principle, the truth is that the choice of location for vertical farming is much more involved and intricate than it may appear from these claims alone. Choosing an ideal location can be one of the most important factors in determining the success of a vertical farm.\nSome vertical farms may choose to set up their facilities in pre-existing facilities, such as abandoned warehouses. In these cases, identifying the suitability of the venue is the first point of consideration: vertical farms are very energy intensive, and it is important to ensure the facilities chosen can support these energy loads. In addition, the ergonomics of the facility is also important; should the layout not be given proper consideration, this can impede workers and decrease worker efficiency. As labor costs are typically among the largest sources of expenditure for a vertical farm, improving labor efficiency to reduce these costs is of paramount importance.\nWhile growing crops in the center of a city may seem ideal, the reality is that this may be counterproductive. Obtaining and maintaining such a location is expensive and can contribute significantly to the operating expenditure of a vertical farm while presenting logistical challenges in distributing produce; the \"last mile\" of food distribution is often the hardest. Having a farm right next to the consumers themselves may also be less ideal than instead choosing a location near food distribution centers, as this allows for more efficient delivery of produce. As distribution centers are typically located on the outskirts of cities, the cost of land is also much cheaper. This is the approach chosen by UK-based Jones Food Company, which chose Scunthorpe as a location for its vertical farm – this is a relatively low-cost location located near food distribution centers and a network of motorways that could still reach many consumers in a day, even if it isn't right in the middle of the capital city. Vertical farms should carefully consider their place in the supply chain before establishing a base.\nOn a larger scale, vertical farms may prove more profitable in different geographical regions. Vertical farms can reduce water usage significantly over conventional agriculture, and the high degree of control over the growing environment allows them to grow crops in extreme climates – where such crops may not otherwise be able to grow. In return, vertical farms demand more energy to carry out growing operations. To maximize their potential, vertical farms would ideally be located in regions of water scarcity, such as Sub-Saharan Africa and the Middle East, or in areas with extreme climates, such as in Scandinavian countries, where the low amounts of sunlight and high costs of regulating greenhouse environments single out vertical farms as an optimal solution. The amount of agricultural land available is also an important factor – regions looking to increase food security and reduce reliance on imports while facing challenges in acquiring sufficient agricultural land would find vertical farms to be ideal. A particularly prominent example of such a country is Singapore, which has demonstrated much interest in vertical farming over the last few years.\nBeyond the considerations of water scarcity and temperature, the general availability of fresh produce and the distribution networks of given countries should also be considered. Vertical farms use the added freshness and higher quality of their crops as a primary selling point, but these are typically offset by higher prices. Should there already be a large supply of high-quality produce made available at lower costs, vertical farms will find it hard to distinguish their own produce and may struggle to establish a significant market share. The converse would also be true; should a country lack easy access to fresh produce, vertical farms are expected to see much demand for their produce. An example of such a region would be the Middle East: leafy greens typically travel several thousand miles to reach stores, resulting in consumers facing high prices and low-quality products. The high price of conventionally farmed leafy greens, alongside government subsidies, makes it easier for vertically farmed produce to approach price parity while providing much fresher, higher-quality products.\nWhile the choice of location is an important consideration, it is only one of many others that must be given proper thought. Only through proper optimization of growing operations to improve efficiency and reduce costs can vertical farms reach their true potential. In the IDTechEx report, \"Vertical Farming 2022-2032\", many further important factors for consideration are discussed in detail, and the future of vertical farming is evaluated through 10-year market forecasts.\nIDTechEx guides your strategic business decisions through its Research, Subscription and Consultancy products, helping you profit from emerging technologies. For more information, contact research@IDTechEx.com or visit www.IDTechEx.com.\nThis post does not have any comments. Be the first to leave a comment below.\nPost A Comment\nYou must be logged in before you can post a comment. Login now."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:e896b738-2e68-443f-aa84-a96082114d32>","<urn:uuid:98c0eed7-8d91-42cd-b0d1-cc7c105f9a4d>"],"error":null}
{"question":"How do floating structures handle dynamic forces both in coastal engineering and oceanographic applications, and what role does compliance play in their resilience?","answer":"In coastal engineering, floating structures like marinas and bridges use specialized analysis methods to handle dynamic forces from short-crested waves. These structures employ frequency-dependent hydrodynamic coefficients and Monte-Carlo simulation for calculating structural response. The program cgFLOAT specifically analyzes these responses through both frequency and time domain analysis. In oceanographic applications, mooring compliance is crucial for survival in extreme conditions. This compliance can be either geometric (allowing the mooring to change shape like a zig-zag) or elastic (relying on material stretch). Without proper compliance, moorings can break or 'walk' as the anchor gets overloaded by forces, potentially resulting in loss of expensive equipment and valuable data.","context":["marinas, floating breakwaters and floating bridges are long structures made up of pontoons\nwhich are connected between them rigidly or with flexible connectors, and they are\nanchored at the bottom of the sea with mooring lines. They are usually placed in protected\nwater regions. The waves in these regions are short crested waves. The dynamic analysis of\nlong floating structures in short crested waves must take into account the special\ncharacteristics of the short crested wave loading, and the frequency depended load\ncorrelation along the structure.\nstructural modelling using finite element methods does not present any difficulties.\nHowever the part of the analysis which presents special problems is the modelling of the\nloading in a short-crested sea. General purpose finite element programs do not provide\nmethods for calculating the loading in a stochastic, short crested sea, and additional\nroutines should be included in order to do the job. In conclusion the use of general\npurpose finite element programs is - time consuming, uneconomic, and susceptible to\nThe program cgFLOAT has been developed especially for long floating\nstructures in short crested sea loading. The dynamic response can be calculated via a\nfrequency or time domain analysis. Theories and methods for hydrodynamic loading,\nshort-crested waves, directional wave spectra, sea state simulation, and stochastic\ndynamics are included in the calculation routines. The computer code has been optimized\ntaking into account the special characteristics of the structure and the loading. For the\nresponse calculation a Monte-Carlo simulation is used. This method is considered to be\nmore advantageous over the usual frequency domain analysis, which is the only alternative,\nbecause it reduces the computational cost considerably and can be used for frequency and\ntime domain analysis. It is based in simulating sets of nodal load series and calculates\nthe structural response by deterministic dynamic analysis in frequency or time domain. The\nexpected response values are obtained in the end by calculating the ensemble statistics\nbetween the simulated cases. The basis for computing the sets of nodal load series is the\nwave coherence along the structure, which is obtained from the directional wave spectrum.\ncombines fluid, structural, and stochastic process theories in one program. Thus the\nresponse computation of long floating structure is reduced to a routine analysis.\nThe following aspects have been implemented in the program:\n- Modelling of continuous structures and structures with flexible\nconnectors between the pontoons.\n- Eigenvalue solution\n- Frequency domain analysis\n- Time domain analysis\n- Boat wake analysis\n- Short-crested waves defined by a wave spectrum and wave coherence.\n- Monte-Carlo simulation of the wave loading.\n- Statistical evaluation of the results for the simulated response.\n- Frequency dependent hydrodynamic coefficients.\n- Metric or Anglo-American units can be specified.\n- Graphical output, for mode shapes and response values along the\nStructural input data are the characteristics of the pontoons, length, width,\nheight, moments of inertia, shear areas, elasticity modulus, and elastic characteristics\nof moorings. In case of flexible connectors the characteristics of the connectors as\nbending and shear stiffnesses must be described. The geometry of the structure and the\nnodal points are automatically generated by the program after the basic pontoon and\nconnector properties are supplied. In case (as in most cases) of similar pontoons the\ncharacteristics of one pontoon is necessary and the number of pontoons.\nFor pontoons of rectangular cross section the hydrodynamic coefficients (added mass, added\ndumping and hydrodynamic forces) for various frequencies are automatically evaluated by\nthe program. For other cross sections you may input the hydrodynamic coefficients for\ncertain wave frequencies and the program interpolates between them for the necessary\nvalues in the response calculations.\n||The short-crested sea state is\nspecified by the wave spectrum and the wave coherence. Typical wave spectra like\nPierson-Moskowitz, JONSW AP, are computed from their parameters by the program. Other\nkinds of spectra can be used by inputting their f and S(f) values. Wave time series are\nsimulated from the spectra, via various methods, by the program. The wave correlation is\nhandled by specifying the coefficients of an exponentially decayed wave coherence, or by\nspecifying the nodal load correlation directly.\nIn the case of boat wake analysis the speed and characteristics of the boat wake are\nFor the frequency domain analysis, the frequencies for the computation of the frequency\nresponse function can be specified or they are computed by the program after their number\nis specified. For the time domain analysis, participating modes, integration method and\nparameters, accuracy, time interval and time length are specified. The user specifies the\nvarious analysis paths, units, simulation methods and number, and required printed or\nplotted output quantities. For all the cases if general parameters are not specified by\nthe user, default values assigned by the program.\nTime domain response\nThe results from the frequency or time domain analysis is a\nlarge number of values. To be useful they are printed in graphs.\nA typical output of the program contains:\nPrintout of the eigenvalues\nGraphs of mode shapes\nGraphs of the structure response to unit amplitude\nshort crested waves of various frequencies.\nGraphs of ensemble maximum, mean, and standard\ndeviation values, between the simulated responses, for displacements, bending moments, and\nshearing force, along the structure for the three directions of motion (sway, heave and\nThe computations are for frequency domain analysis and for\ntime domain analysis.\n- A printout with all the information of the structure, the wave field,\nassumptions and parameters used.\nFrom the displacements in sway motion the mooring forces can be computed.\n|Please note that these files require you have the Adobe\nAcrobat Reader installed. If you don't have the reader, click here\nto download it. (its free)\n|13) Georgiadis, C. \"CGFLOAT A Computer Program for the Dynamic\nAnalysis of Floating Bridges and Breakwaters \", journal of Advances in\nEngineering Software, Vol. 5, No. 4, October 1983, CML Publication Southampton, England,\n|16) Georgiadis, C. \"Time and Frequency Domain Analysis of Marine\nStructures in Short-Crested sea by Simulating Appropriate Nodal Loads \",\nOffshore Mechanics and Arctic Engineering, proceedings of American Society of Mechanical\nEngineers ASME book I00171, Vol.1, 1984, New York, pp. 177-183.\n|17) Georgiadis, C. \"Modelling\nBoat Wake Loading on Long Floating Structures \", Journal of computers\nand structures, Vol.18,No. 4, 1984, Pergamon Press, London, pp. 575-581.\n|19) Georgiadis, C. \"Finite\nElement Modeling of the Response of Long Floating Structures Under Harmonic Excitation\n\", Transactions of ASME, Journal of Energy Resources Technology, Vol. 107, March\n1985, pp. 48-53.\nThe program is well documented. In addition to the\nuser manual, references 1-6 explain in detail the theoretical aspects behind the\ncomputational and simulation methods as well as the concept of hydrodynamic forces and\nshort-crested waves. Detailed examples are included to show the correct use of the\nThe accuracy of the program has been checked with in situ\nmeasured response values at the Hood-Canal floating bridge and other floating breakwaters\nin the Puget Sound area.(1)\nDownload FREE trial version of\nnovember 01, 2022.","Deep in the Andes Mountains, straddling jagged peaks, sits the 15th century Inca citadel Machu Picchu. It’s a harsh and remote location. To add to this, the ancient site sits on top of fault lines that are prone to earthquakes. But these earthquakes were no match for Incan engineering and architecture. So how did their designs survive earthquakes?\nTheir structures used many-faced blocks in different sizes and shapes. They fit together so precisely that no mortar was needed. When the shaking starts in an earthquake, these blocks can shift and move. But when the shaking stops, they settle right back into place. Lasting hundreds of years, it’s a design that is truly resilient.\nSimilarly, this resilience is needed in oceanographic moorings. When the shaking starts in an extreme ocean storm with wind, waves and currents, surface moorings have to survive severe forces and motions. It’s in these storm conditions that oceanographic mooring survival is possible only through mooring compliance. This mooring compliance must be carefully understood for the design to be successful and last through its deployment. So what is mooring compliance?\nIt’s the give-and-take that prevents things from blowing up\nThere are dynamic and steady forces from the environment. Ocean waves produce dynamic forces and water currents produce steady drag forces. Mooring compliance is the give-and-take in an oceanographic mooring that allows it to absorb the effects and forces of the ocean. So what happens when there’s not enough compliance?\nA broken mooring line can mean a lot of headaches in lost equipment and data\nMooring compliance allows the instruments to ride out the massive waves in severe ocean storms. If there’s not enough mooring compliance, the mooring can break, or it may “walk” as the anchor is overloaded by forces. A resilient mooring design is one that has enough compliance.\nOceanographic moorings have many expensive sensors that make various measurements in the ocean. Sometimes, these measurements may go on for years and years at a time. Often, the data from these sensors can only be retrieved if the mooring is recovered.\nThat data may be gone forever somewhere at the bottom of the sea if the mooring fails. The risk of losing valuable equipment and data is reduced with careful design and understanding of compliance. Usually, moorings may have geometric compliance or elastic compliance, or some combination of the two. Moorings with elastic or geometric compliance can look very different.\nGeometric compliance is the ability of the mooring to change shape\nThe shape of the mooring might look like a zig-zag through the water column, formed with careful placement of floats and weights along the mooring span. The mooring zig-zag then acts like a giant geometric spring that can extend or contract to absorb the dynamic effects of the environment. In comparison, elastic compliance doesn’t rely on the shape of the mooring.\nElastic compliance is when the mooring relies directly on the material stretch\nThe shape of the mooring may be as simple as a straight line from anchor to surface. Some materials can stretch several times their length, much like a rubber band. While geometric compliance relies on the mooring moving through the water, elastic compliance relies on the mooring line to directly stretch out. So when do should use geometric or elastic compliance?\nShallow water moorings are a challenge\nShallow doesn’t always mean near the shoreline. It can be anywhere where the ocean waves are large relative to the water depth. Because the wave effects are so severe, there may not be enough space in the water column to make a geometric shape. This means it’s more likely for the mooring line to be pulled straight and taut, leading to massive tension spikes that can break the mooring. So in shallow water conditions prone to more massive waves, elastic moorings can really shine.\nHow does elastic compliant mooring transmit power and data?\nIt’s true, elastic compliant materials are often highly stretchy synthetic materials. These elastic materials don’t transmit data through electrical or optical signals. So what can be done to provide power and send data through the mooring? One way to do this is with a coil of data and power lines helixed inside the elastic member. They are used in a variety of applications, but one example is in passive acoustic whale monitoring.\nLet’s look at an example of elastic compliance\nOff the east coast of the United States near Cape Cod and Nantucket Island are important Northern Right Whale feeding grounds. It’s at these feeding grounds that at various times of the year these whales concentrate. This concentration increases the chance of vessel strike because of the marine traffic in the area.\nTo guide local marine traffic, warnings are issued by a system that detects the presence of whales by their acoustic signature in the region. The system uses an array of special moored sensors, developed by WHOI and EOM Offshore.\nFaced with the job of monitoring these whales on the continental shelf, the buoys need to be moored in the range of 30-150m water depth. They rely on elastic compliance to survive in the severe Atlantic storms in the region and have been successfully operating for several years. Power from the buoy is transmitted through the conductors helixed within the EOM stretch hoses to the hydrophone that listens for whales. Those same conductors pass the acoustic data from the hydrophone back up to the buoy for transmission to the shore.\nWe’ve covered a few details in understanding mooring compliance, so let’s take a quick review. Only resilient oceanographic mooring designs will survive ocean storms using compliance. Mooring compliance is the give-and-take in the mooring that allows it to absorb the dynamic effects of the environment, such as from ocean waves. Ocean waves can easily break a mooring, resulting in substantial losses in years’ worth of data and expensive sensors to the bottom of the sea, if there isn’t enough compliance.This compliance can be in the form of geometric or elastic compliance. Geometric compliance is the change in shape of the mooring in the water column. In comparison, elastic compliance is a direct stretch of the mooring materials. Often, elastic compliance is better in shallow water. But only detailed dynamic analysis will point out the correct design specifics.\nThe Inca engineers had the right idea\nStructure design allowing movement in the stones is really also a form of compliance, too. The motion of the structural blocks in extreme earthquakes was the give-and-take that prevented catastrophic structural failure. But Inca engineers relied on experience and trial and error in their designs. So how can mooring compliance be tested without a trial and error approach?\nNext step: how to evaluate mooring compliance\nMooring designers use dynamic analysis software to evaluate mooring compliance ahead of deployments. We talked about why mooring compliance is important in this article, but not how to check your own design. Check out this article that outlines a systematic process to do so."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:9a8fb1de-f9e4-423b-81a5-dfd4a3440b1e>","<urn:uuid:ea9a9b1f-e403-442f-be94-af708567dfe3>"],"error":null}
{"question":"How do top-down systemic constraints influence behavior at lower levels, and how does chronic stress similarly affect multiple bodily systems?","answer":"Top-down systemic constraints shape lower-level behavior, as seen in how a computer's structure constrains electron movement in ways that wouldn't occur if the electrons were freely floating in space. This creates new possibilities for complex behavior through the combination of bottom-up and top-down influences. Similarly, chronic stress exhibits top-down effects across multiple bodily systems, causing physical symptoms like increased heart rate and muscle tension, mental health impacts like lack of concentration and motivation, and behavioral changes including social withdrawal and substance abuse. These effects cascade through different levels of human functioning, from molecular to behavioral.","context":["How Does The World Work: Top-Down or Bottom-Up?\nPublished on October 6th, 2013 | by Harmonist staff0\nIn physics what matters are things that produce “effects” — things that cause other things to happen. For the last 400-or-so years it’s been a kind of fundamental assumption that all causes begin at the lowest levels of structure in the universe: electrons, protons, etc. According to this view, the ultimate purpose of science is to discover and understand those most basic levels of our physical universe. Do this and you should be able to wow the world with a Theory of Everything. We’re not there yet and many researchers are skeptical that such a thing even exists.\nThis idea — often called reductionism — tells us that all causes flow from the bottom to the top. Bottom-up causation says that, given an inventory of the smallest stuff and the rules for their interactions, you can explain everything from crystals to cells to your own sweet sense of consciousness. Bottom-up causation is, at this moment in the history of physics, the dominant view.\nGeorge Ellis isn’t buying it.\nIn an essay for the physics website FQXi, Ellis argues for top-down causation. If he’s right, then much of our thinking about what matters would have to be revised.\nTo get an handle on how top-down causation works, Ellis focuses on what’s in front of all us so much of the time: the computer. Computers are structured systems. They are built as a hierarchy of layers, extending from the wires in the transistors all the way up to the fully assembled machine, gleaming metal case and all.\nBecause of this layering, what happens at the uppermost levels — like you hitting the escapekey — flows downward. This action determines the behavior of the lowest levels — like the flow of electrons through the wires — in ways that simply could not be predicted by just knowing the laws of electrons. As Ellis puts it:\nStructured systems such as a computer constrain lower level interactions, and thereby paradoxically create new possibilities of complex behavior.\nEllis likes to emphasize how the hierarchy of structure — from fully assembled machine through logic gates, down to transistors — changes everything for the lowly electrons. In particular, it “breaks the symmetry” of their possible behavior since their movements in the computer hardware are very different from what would occur if they were just floating around in a plasma blob in space.\nBut the hardware, of course, is just one piece of the puzzle. This is where things get interesting. As Ellis explains:\nHardware is only causally effective because of the software which animates it: by itself hardware can do nothing. Both hardware and software are hierarchically structured with the higher level logic driving the lower level events.\nIn other words, it’s software at the top level of structure that determines how the electrons at the bottom level flow. Hitting escape while running Word moves the electrons in the wires in different ways than hitting escape does when running Photoshop. This is causation flowing from top to bottom.\nFor Ellis, anything producing causes is real in the most basic sense of the word. Thus the software, which is not physical like the electrons, is just as real as those electrons. As Ellis puts it:\nHence, although they are the ultimate in algorithmic causation as characterized so precisely by Turing, digital computers embody and demonstrate the causal efficacy of non-physical entities. The physics allows this; it does not control what takes place. Computers exemplify the emergence of new kinds of causation out of the underlying physics, not implied by physics but rather by the logic of higher-level possibilities. … A combination of bottom-up causation and contextual affects (top-down influences) enables their complex functioning.\nThe consequences of this perspective for our view of the mind are straightforward and radical:\nThe mind is not a physical entity, but it certainly is causally effective: proof is the existence of the computer on which you are reading this text. It could not exist if it had not been designed and manufactured according to someone’s plans, thereby proving the causal efficacy of thoughts, which like computer programs and data are not physical entities.\nEllis is arguing for a kind of emergentism whereby new entities and new rules emerge with new levels of structure in the universe (an argument also made by Stuart Kaufmann here at 13.7). But Ellis is going further. He is arguing that the top is always exerting an influence on the bottom.\nThe initial conditions of the cosmos — the configuration of space and time at the Big Bang — constrained the collective behavior of the fundamental quantum entities existing within it. The periodic crystal structure in a metal leads to behavior that allows transistors of different types to exist. The whole, in other words, can shape the behavior of the pieces in ways the pieces alone could never find by themselves.\nEllis puts it all together in a hypothesis at the end of his essay:\nBottom-up emergence by itself is strictly limited in terms of the complexity it can give rise to. Emergence of genuine complexity is characterized by a reversal of information flow from bottom-up to top-down.\nFor myself, I have always been suspicious of reductionism. It remains a kind of article of faith among some scientists. Yet science could do without it and still function quite well (which tells me that it’s more a philosophical stance than a scientific one). For that reason, I find Ellis’ argument exciting and, perhaps, a marker on the path to a fertile new perspective on the world as a whole — a world that includes both electrons and human minds.\nThis article was originally published at npr.org.","How Does Stress Affect The Body: Symptoms And Solutions\nUpdated August 27, 2020\nMedically Reviewed By: Lori Jones, LMHC\nAre you exhausted all the time? Do you have a lot of muscle tension and pain? Is your head or stomach bothering you? It could be stress. There is a long list of symptoms that falls under the question, “How does stress affect the body?” And, learning how to identify the symptoms can help you find the right solution.\nStress levels have been on the rise in Americans over recent years. It’s impacting people of all ages and spans a wide range of worries and concerns.\nThe Impact Of Chronic Stress\nEveryday stress can have a negative impact on multiple areas of your life. However, when the stressful situation passes, you may find that things return to normal even if you didn’t do anything to address your stress. This isn’t the healthiest way to get through stress, but it happens this way for some people.\nHowever, if you’re experiencing chronic stress, it’s not going to just go away. It may not be tied to a specific situation in your life. Instead, it might be the result of poor habits or not knowing how to deal with past trauma. It will not just go away if left untreated.\nThe Effect Of Stress On The Body\nStress can wreak havoc on your body if it’s left unchecked. Not only does occasional stress show up in your body, but chronic stress can also have long-term negative consequences for your physical health. When you are feeling stressed, you may experience:\n- Increased heart rate\n- Rising blood pressure\n- Muscle tension\n- Upset stomach\n- Lack of sexual desire\n- Change in appetite\nAnd these are just a few of the symptoms that you may experience. If you suffer from chronic stress, the symptoms above can start to turn into more serious health consequences.\nChronic stress can lead to health problems such as heart disease, high blood pressure, gastrointestinal problems, heart attack, and strokes, among others. These are clear indicators that allowing chronic stress to continue in your life can be detrimental to your physical health and well-being.\nHow Stress Affects Mental Health\nStress also impacts your mental health and wellness. It can lead to you experiencing many different negatives and difficult emotions such as sadness, anger, frustration, and fear.\nSome of the mental health symptoms that you may notice in your life from stress include:\n- Lack of motivation\n- Irritability and anger\n- Lack of concentration and focus\nThese are serious symptoms that should not be taken lightly. If you experience chronic stress, you may begin to think that these symptoms are just a normal part of life. But, they’re not. All of these symptoms can grow into more serious problems if you don’t work on addressing them.\nHow Stress Affects Behavior\nStress can also impact your behavior. If you look at the symptoms listed above under physical and mental health, it can be easier to understand how stress changes your behavior. If you’re living under constant overwhelm and anxiety and experiencing things like frequent headaches or stomach aches, it can be easy to lose your temper with your loved ones, for example. Here are some of the other behavioral changes that you may experience in your life as a result of stress:\n- Angry outbursts\n- Eating too much or not enough\n- Substance use or abuse\n- Social withdrawal\nThese behaviors can have a negative spiral effect on your life. For example, as your withdrawal from friends and family because of stress, you may find that you struggle even more to cope with stress in your life. This can lead to additional problems which keep you away from a social activity even more. This is why it’s important to learn to recognize and healthily address your stress.\nStress Management Tips To Overcome Chronic Stress\nThankfully there are many things that you can do to address your chronic stress and learn to overcome it. This doesn’t mean that you’ll never experience stress again. Instead, it means that when you do go through stressful situations, you’ll have tips and strategies that you can use to relieve stress and handle it healthily.\nSome of the stress management solutions you may benefit from include:\nLearn to identify your stress triggers\nWhen you start to feel stressed, it can be helpful to take time to identify where the feelings are coming from. This allows you to begin investigating what you can do to make to address it.\nWhile there will be some things causing you to stress that you can’t do anything about, there will be some things that you can address. For example, if a family member’s behavior is causing you to feel stressed, you probably aren’t going to be able to control how they are behaving. But you may be able to establish boundaries in your life that stop the other person’s behavior from having as large of a negative consequence on you.\nThere will be some things that you find are short term stressors. But there also might be habits that you identify that are causing you unnecessary stress. When you learn where the stress is coming from, you can start to take your first steps to address or removing it.\nPractice Deep Breathing\nWhen you’re starting to feel the stress and tension build up within your body, deep breathing can help to break up some of the physical symptoms that you’re experiencing. For example, you may notice that you start to breathe faster as your frustration grows. This can cause your heart to race, as well. And, as your heart beats faster, your blood pressure rises. These physical symptoms can continue to build and even lead to things like full-blown panic attacks.\nDeep breathing can help to stop your physical symptoms from progressing. As you start taking slow, deep breaths in and out, you may notice that it feels like your blood pressure is lowering, and your heart rate is returning to normal.\nYou may also find that deep breathing can help you to slow your thoughts. Your mind will be forced to temporarily shift from your stress and worry to the breathing technique that you’re using. This can help you to regain mental clarity and look for solutions to the stressful situation or problem that you’re facing.\nThere are multiple types of breathing techniques that you can use, so practice a few of them to find what works best for you. It can also help to practice them when you’re not under stress, so when you find your stress starting to build, you will know how to put the breathing exercise to use without too much thought.\nNot getting enough sleep can make it even harder to deal with stress. You may find that you struggle to be patient with others, and you cannot think clearly to look for solutions. If you’re having problems falling asleep or staying asleep due to stress, it’s an important symptom to address.\nMany different things may help improve sleep troubles. A few that you could try include:\n- Keeping a strict sleep schedule\n- Cutting out caffeine\n- Not exercising too close to bedtime.\n- Sleeping in a dark, cool room\n- Using white noise\nHowever, if you’re continuing to struggle, don’t be afraid to talk with your doctor to explore additional options.\nGet More Physical Activity\nPhysical activity and exercise can help you release tension that has built up from chronic stress. It also releases chemicals in your brain that work to boost your mood. But these chemicals also act as natural pain killers, which can help reduce some of the physical symptoms you’re experiencing.\nThere are other ways that physical activity and exercise can help with stress. You may find that you sleep better when you exercise. And, you may experience a boost in your self-esteem as well.\nThe Anxiety and Depression Association of America shares that you may start to experience these positive mental boosts after just five minutes of physical activity. So, if you’re feeling stressed, you don’t need to feel like you have to get in a full workout. Simply getting moving for a few minutes can start to help.\nTalk To Someone\nHaving a trusted person to turn to for support can help when you’re going through stressful situations or experiencing chronic stress. This could be a friend or family member. It could also be a support group. For example, if you’re under stress as a result of losing a loved one, you may benefit from connecting in a group for others experiencing grief from losing someone.\nIf you don’t have anyone to turn to or could use additional support in handling your stress, a licensed therapist is an effective option to consider. Not only can they listen as you talk through the stress in your life, but they also have education on how to help you overcome it. A therapist, like those at BetterHelp, can assist you in finding stress-relieving strategies that work for your specific situation.\nPrevious ArticleHow Stress Can Lead To Emotional Breakdowns And What You Can Do To Avoid It\nNext ArticleAre You Under Too Much Stress? Symptoms, Treatment And Tips\nLearn MoreWhat Is Online Therapy? About Online Counseling\nAbuse ADHD Adolescence Alzheimer's Ambition Anger Anxiety Attachment Attraction Behavior Bipolar Body Dysmorphic Disorder Body Language Bullying Careers Chat Childhood Counseling Dating Defense Mechanisms Dementia Depression Domestic Violence Eating Disorders Family Friendship General Grief Guilt Happiness How To Huntington's Disease Impulse Control Disorder Intimacy Loneliness Love Marriage Medication Memory Menopause MidLife Crisis Mindfulness Monogamy Morality Motivation Neuroticism Optimism Panic Attacks Paranoia Parenting Personality Personality Disorders Persuasion Pessimism Pheromones Phobias Pornography Procrastination Psychiatry Psychologists Psychopathy Psychosis Psychotherapy PTSD Punishment Rejection Relationships Resilience Schizophrenia Self Esteem Sleep Sociopathy Stage Fright Stereotypes Stress Success Stories Synesthesia Teamwork Teenagers Temperament Tests Therapy Time Management Trauma Visualization Willpower Wisdom Worry\nFeeling Overwhelmed? Learn These Stress Management Strategies How To Stop Stressing: 7 Tips To Find Balance And Relax How Stress Can Lead To Emotional Breakdowns And What You Can Do To Avoid It Are You Under Too Much Stress? Symptoms, Treatment And Tips 7 Tips On How To Handle Stressful Situations Stress Management That Works: How To Be Less Stressed"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:da096baa-032f-48b4-9f2e-1b163a2cbb1a>","<urn:uuid:1fe21db8-8096-462d-a9b3-85cbac331785>"],"error":null}
{"question":"How does the brain's memory strengthening process work, particularly for emotional memories?","answer":"Emotional memories are primarily processed in the amygdala region of the brain. Cholinergic neurons, located at the brain's base, deliver acetylcholine to the amygdala. These neurons appear to strengthen emotional memories through cholinergic input to the amygdala. This mechanism works particularly well for emotionally charged experiences, whether positive or negative. These cholinergic neurons are also notably affected early in cognitive decline, though they remain difficult to study as they are few in number and mixed with other types of neurons.","context":["Scientists could fine-tune your brain so as to forget bad memories and remember good ones, Stony Brook research suggests.\nA research team led by Lorna Role, PhD, has taken a step toward the possibility of tuning the strength of memory by manipulating a neurotransmitter called acetylcholine, one of the brain’s natural mechanisms for signaling involved in memory. Their findings are published in the journal Neuron.\nPotential therapeutic uses include strengthening good memories for those suffering from dementia or wiping away bad memories for patients with post-traumatic stress disorder\n“Memories of emotionally charged experiences are particularly strong, whether positive or negative experiences, and the goal of our research is to determine the mechanisms underlying the strengthening of memory,” said Role, Professor and Chair of the Department of Neurobiology and Behavior and Co-Director of the Neurosciences Institute at Stony Brook Medicine.\nBrain mechanisms underlying memory are not well understood, but most scientists believe that the region of the brain most involved in emotional memory is the amygdala. Acetylcholine is delivered to the amygdala by cholinergic neurons that reside in the base of the brain. These same neurons appear to be affected early in cognitive decline. Previous research has suggested that cholinergic input to the amygdala appears to strengthen emotional memories.\nIn the paper, titled “Cholinergic Signaling Controls Conditioned Fear Behaviors and Enhances Plasticity of Cortical-Amygdala Circuits,” Dr. Role and colleagues used a fear-based memory model in mice to test the underlying mechanism of memory because fear is a strong and emotionally charged experience.\nThe team used opto-genetics, a newer research method using light to control cells in living tissue, to stimulate specific populations of cholinergic neurons during the experiments.\nTwo of the team’s findings stand out. First, when they increased acetylcholine release in the amygdala during the formation of a traumatic memory, it greatly strengthened memory making the memory last more than twice as long as normal. Then, when they decreased acetylcholine signaling in the amygdala during a traumatic experience, one that normally produces a fear response, they could actually wipe out memory.\n“This second finding was particularly surprising, as we essentially created fearless mice by manipulating acetylcholine circuits in the brain,” explained Dr. Role. “The findings provide the basis for research examining novel approaches to reverse post-traumatic stress disorder.”\nThe challenge of continued research is that cholinergic neurons remain difficult to study because they are intermingled with other types of neurons and are few in number compared to other types of neurons in the brain.\nBecause acetylcholine is a natural signaling mechanism and seemingly essential for memory, additional research will center on non-pharmacologic ways to manipulate or fine-tune memory.\n“The long-term goal of our research is that we would like to find ways – potentially independent of drug administration – to enhance or diminish the strength of specific memories, the good ones, and diminish the bad ones,” summarized Dr. Role.\nThe research involves faculty and students from the Stony Brook University Departments of Neurobiology and Behavior, and Pharmacological Sciences, as well as the CNS Disorders Center, the Neurosciences Institute, and the Program in Neurosciences. Co-authors include Li Jiang, Srikanya Kunda, James D. Lederman, Gretchen Y. Lopez-Hernandez, Elizabeth C. Ballinger, Shaohua Wang, and David A. Talmage."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:2436590f-448f-49c3-aa24-2b4d86212369>"],"error":null}
{"question":"What are the spiritual beliefs about nature among the Nuer people, and what environmental challenges are affecting their territory?","answer":"The Nuer people have complex spiritual beliefs about nature, including belief in nature spirits called biele (visible as will-o'-the-wisps in bushes and swamps) and various totemic spirits associated with animals and natural objects. They view celestial phenomena as signs of God and believe Spirit exists within or behind natural occurrences. However, their territory now faces significant environmental challenges - climate change is causing decreasing rainfall and increasing temperatures, which affects water availability in the region. These changes particularly impact their semi-arid environment where they practice agriculture and cattle-breeding, and could lead to more droughts and water scarcity issues.","context":["E. Evans-Pritchard (1902-1973) was one of England’s most successful social anthropologists reputed for his work on African cultures, witchcraft, and magic. He conducted fieldwork in South Sudan among the Zande and Nuer people, on whom he produced two books: Witchcraft, Oracles, and Magic Among the Azande (1937) and The Nuer (1940). This entry will be looking at the Nuer people, with special interest in their animistic religious beliefs.\nWho Are the Nuer?\nThe Nuer are a cattle-based culture and pastoral society whose members live a nomadic lifestyle in the semi-arid environment of South Sudan. Regarding the Nuer population and organizational structure at the time of writing, Evans-Pritchard and Fortes say that,\n“Most tribes have a population of over 5,000 and the largest number between 30,000 and 45,000 souls. Each tribe is economically self-sufficient, having its own pastures, water-supplies, and fishing reservations, which its members alone have the right to exploit. It has a name which is the symbol of its distinction. The tribesmen have a sense of patriotism: they are proud to be members of their tribe and they consider it superior to other tribes. Each tribe has within it a dominant clan which furnishes a kinship framework on which the political aggregate is built up. Each also regulates independently its age-set organization… It is not possible to give more than a rough indication of the size of a village population, but it may be said to vary from 50 to several hundred souls….” (1)\nThe Nuer engage in agricultural practice, which means they raise livestock, hunt, and collect wild fruits and roots. Their land is, however, more suited for stock-breeding than for agriculture given its flat, dry, savannah like environment. The land experiences heavy rain fall from June to December which causes nearby rivers to overflow. From around December to June there is little rain and the rivers remain at a low level. During the rainy season, the Nuer live in villages located on knolls, ridges, or slightly elevated grounds that permit agriculture. The land between villages is more or less flooded for the full six months during which the Nuer engage in the cultivation of millet and maize, despite much of the land being unsuitable for habitation, agriculture, or grazing. Food is often limited but there is much sharing in the same village, especially among those in adjacent homesteads and hamlets where villagers eat in one another’s homes at feasts and at daily meals. Food is most abundant from the end of September to the middle of December and it is during this time most ceremonies and dances take place. It is also due to the lack of resources and food supply that members of villages are drawn close to each other. Often hunting, fishing, and agricultural tasks are activities that require cooperative effort.\nGod and Symbols of God\nFor the Nuer, God (or Spirit) is seen in the celestial phenomena of the sky and in the material representations of death and pestilence. God is not believed to actually be any one of these phenomena as they are merely signs or refractions of him. No-one, believe the Nuer, knows what God is like in himself although they find it appropriate to use adjectives to refer to his attributes (i.e. “great” or “good”) or metaphors taken from the world (likening God to the wind or air). This belief is based on a duality between kwoth, Spirit, which is immaterial (rather than supernatural), and cak, creation, the material world known to the senses. Rain, lightning, and pestilences belong to the created world and are seen as instruments of God (nyin kwoth). Evans-Pritchard explains that,\n“[P]estilences, murrains, death, and indeed almost any natural phenomenon significant for men are commonly regarded by Nuer as manifestations from above, activities of divine being. Even the Earthly totems are conned of as a relationship deriving from some singular intervention of Spirit from above in human affairs. It is chiefly by these signs that Nuer have knowledge of God” (2).\nRain and pestilence are symbols for Spirit and in the Nuer context a religious symbol has an intimate association with what it represents. They are what one would “call a medium or manifestation or sign of the divine acuity in relation to men and of significance to them” (3). For example, a bird might be considered a symbol for Spirit but the physical bird itself is not Spirit. Instead, depending on the bird’s actions (perhaps by landing on the crown of a byre or on a hut) it may constitute a spiritual sign (of disaster, perhaps). In these phenomena, whether a bird or the rain, the Nuer believe Spirit to be in some way within, or behind, the object or occurrence.\nHierarchy of Spirits and Totem\nThe Nuer also believe in a hierarchy of spirits; as writes Evans-Pritchard,\n“In other words, there are gradations of the conception of Spirit from pure unattached Spirit to Spirit associated with human, animal, and lifeless objects and more and more closely bound to what it is associated with the farther down the scale one goes” (4).\nThere are the “spirits of the below” called the biele (the nature spirits) and the kulangni (fetish spirits), both of whom are believed to have come from above down to Earth. They are also independent of any material forms. The biele is a visible spirit and is believed to be the will-o’-the-wisps, which are strange and mysterious lights that emerge in bushes and in swamps. The kulangni are fetish spirits that live in small bundles of wood. They are not visible like the will-o’-the-wisps but can be in different wood bundles at the same time.\nFurther, some of the Nuer believe in totemic spirits. A totem is either a natural object or an animal believed to have spiritual significance and is sometimes adopted as a tribe’s emblem. The Nuer have great respect for totems because they represent the spirits associated with them. They even sometimes act towards the totem as if a spirit actually lives within it: “Thus they give some meat of the sacrifice of lion-spirits to lions, and when they sacrifice to the durra-bird-spirit they also address the birds themselves and tell them that the victim is for them” (5). Evan-Pritchard refers to the lou serpent totem he says resembles the Loch Ness monster.\nTwins are Special Creations\nIn Nuer culture, twins hold a sacred place as they are believed to be special creations: they are a person of the sky or of the above, a manifestation of Spirit, and a child of God. For the Nuer, the sky or air are where things that belong to God belong. Twins are believed to be one person and also birds,\n“In addition to being men and women they are of a twin-birth, and a twin-birth is a special revelation of Spirit… twins and birds, though for different reasons, are both associated with Spirit and this makes twins, like birds, ‘people of the above’ and ‘children of God’, and hence a bird a suitable symbol in which to express the special relationship in which a twin stands to God” (6).\nThe Nuer do not believe that twins look like birds in the sense of having feathers, a beak, and wings; rather by saying twins are birds they are referring to the “anima of the twin,” namely of his or her personality and soul. Twins are not one individual but one personality. This reveals a triadic relationship between twins, birds, and God: “In respect to God twins and birds have a similar character” (7). Twins are often given the name of a bird such as Gwong (guineafowl) or Ngec (francolin), which further captures their significance as in Nuer culture it is shameful to kill and eat birds or their eggs. It is also shameful to break the eggs of crocodiles and turtles. When an infant twin dies he is said to have “flown away.” He is then covered in a winnowing-tray or a reed basket and placed in the fork of a tree because birds rest in trees. When adult twins die their souls go up into the sky. An adult twin’s body is buried in a grave so that hyenas do not eat it. Should the hyena devour the body and drink from a pool of water, they might contaminate it and cause the death of men.\nA Complex Culture\nOne of the critiques modern scholars have of several formative theorists in the fields of anthropology, sociology, and religion studies is that these theorists presented cultures such as the Nuer as being “primitives” and “savages” but yet failed to take into account their complexity. These so-called primitive cultures were placed on a cultural hierarchy but always below the superior “civilized men” of the Europeans. For example, the British anthropologist E. B. Tylor claimed that animism was the religion of the “savages” that continued to evolve up until the age of “civilized men”, with civilized men being himself and his fellow countrymen who had appreciated the advancement of science and distanced themselves from savage superstitions. These primitive cultures were simply stuck at a lower rung of cultural evolution.\nBut Evans-Pritchard objects. He concedes that to a western mind “It seems odd, if not absurd, to a European when he is told that a twin is a bird as though it were an obvious fact” (8). Equally, to say that the will-o’-the-wisps are Spirit is strange as “For us the light is [merely] a gas arising from swamp vegetation…” and nothing more than that (9). However, Evans-Pritchard still claims to have uncovered a far greater level of intellectual and artistic elocution than theorists like Tylor and others allowed. Speaking of the Nuer, Evans-Pritchard says that this ability,\n“implies experience on an imaginative level of thought where the mind moves in figures, symbols, metaphors, analogies, and many an elaboration of poetic fancy and language… In all their poems and songs also they play on words and images to such an extent that no European can translate them without commentary from Neur… How Nuer delight in playing with words is also seen in the fun they have in making up tongue-twisters, sentences which are difficult to pronounce without a mistake, and slips of the tongue, usually slips in the presence of mothers-in-law, which turn quite ordinary remarks into obscenities… the imagination of this sensitive people finds its sole expression in ideas, images, and worlds” (10).\n1. Fortes, Meyer., and Evans-Pritchard, Edward. 2015. “The Nuer of Southern Sudan.” In African Political Systems. Abingdon: Routledge.\n2. Evans-Pritchard, Edward Evans. 1940. The Nuer: A Description of the Modes of Livelihood and Political Institutions of a Nilotic People. Oxford: Clarendon Press. p. 124.\n3. Evans-Pritchard, Edward. 1940. Ibid. p. 126\n4. Evans-Pritchard, Edward. 1940. Ibid. p. 139\n5. Evans-Pritchard, Edward. 1940. Ibid. p. 133\n6. Evans-Pritchard, Edward. 1940. Ibid. p. 131-132\n7. Evans-Pritchard, Edward. 1940. Ibid. p. 132.\n8. Evans-Pritchard, Edward. 1940. Ibid. p. 137.\n9. Evans-Pritchard, Edward. 1940. Ibid. p. 137.\n10. Evans-Pritchard, Edward. 1940. Ibid. p. 142-143","Climate change in the region is expected to negatively affect water availability due to decreasing rainfall and increasing temperatures.\nIn light of the growing water demands on both sides and the expected impacts of climate change, Sudan’s current share of Nile waters may no longer suffice or be available in the future.\nIf the allocation of Sudan’s current share of Nile waters becomes more contentious, water allocation conflicts between Sudan and South Sudan could emerge, and might have basin-wide repercussions.\nIn 2005, the government of Sudan and the Sudan People’s Liberation Movement/Army (SPLM/A) signed the Comprehensive Peace Agreement (CPA). The CPA ended a devastating civil war in Sudan, and recognized the right to self-determination of the people of southern Sudan, to be exercised in a referendum in January 2011. The main provisions of the CPA were also reflected in the Interim National Constitution, which contained governance provisions for the 2005-2011 interim period. In July 2011, six months after the referendum, the new state of South Sudan formally came into existence (Salman, 2011b; Salman, 2014). During the interim period, water resources emerged as one of the key issues to be resolved between the north and the south. As water-related issues could not be settled before independence, they now need to be negotiated between two sovereign countries. Today, the most important of these issues concern Nile water allocation, the Jonglei Canal Project, and South Sudan’s role with respect to the Nile Basin Initiative (NBI) and the Cooperative Framework Agreement (CFA). The CFA can be described as an attempt to establish a permanent legal and institutional framework for governing the Nile River Basin. The agreement was opened for signature in 2010, but has not yet entered into force due to inter-riparian disagreements.\nThe role of water during the interim period, 2005-2011\nWater under the CPA and the Interim National Constitution\nThe CPA’s Power Sharing Agreement and the Interim National Constitution granted the government in Khartoum exclusive jurisdiction over the Nile and other transboundary waters, while responsibility for local water resources management was transferred to the government in the south. Despite the fact that 98 percent of southern Sudan was located within the Nile Basin, the SPLM/A refrained from demanding a stronger role in Nile water management during the interim period. Two main reasons help explain this cautious stance (Salman, 2011b). First, the SPLM/A apparently feared that its hard-won right to self-determination could be endangered if it became too involved in Nile politics. Indeed, politics on the Nile had been highly controversial, and especially the Nile Basin Cooperative Framework Agreement (CFA), under negotiation since 1997, divided the riparian states (see: Dispute over Water in the Nile Basin). Egypt and Sudan defended previous agreements concluded in 1929 and 1959, which allocated almost all of the Nile’s total flow (84 billion cubic meters, or BCM) to Egypt (55.5 BCM) and Sudan (18.5 BCM). Other riparian states such as Ethiopia, Kenya, Rwanda and Tanzania rejected those agreements, and requested a more equitable sharing of Nile waters under the CFA. To avoid being perceived as a “…new competitor for the Nile River waters, or at least a complicating factor in an already complex situation” (Salman, 2011b, 161), the SPLM/A apparently chose to take a backseat on Nile water issues. Second, the SPLM/A might have assumed that Sudan’s annual share of 18.5 BCM could rather easily accommodate the south’s water needs, because Sudan had not exhausted its share (using only 14-15 BCM so far); because southern Sudan had no large-scale agricultural projects at the time; and because heavy rains in the south had always been sufficient for maintaining subsistence farming and community livestock herds.\nThe 2009 Southern Sudan Referendum Act\nIn 2009, the Southern Sudan Referendum Act was passed. It listed ten key issues that the north and the south needed to settle. Besides issues such as nationality, currency, public service, and oil contracts, the Act also mentioned water resources as a matter of priority, referring primarily to the sharing and management of the Nile waters between Sudan and the new state of South Sudan. While negotiations on some of these complex outstanding issues had started a few months before the referendum, no agreements could be reached by the time of the referendum (January 2011) or independence (July 2011). Thus, after July 2011, all pending issues – including water resources – had to be negotiated and resolved between two sovereign countries (Salman, 2011b).\nUnresolved water issues post-independence, 2011-present\nSharing the Nile waters\nAfter independence, South Sudan started to demand a share of the annual 18.5 BCM of Nile waters allocated to Sudan under the 1959 water agreement. At first glance, Sudan should be able to accommodate these demands. As noted above, in the past, the country’s water use amounted to no more than 14-15 BCM per year. On closer examination, however, several factors are complicating this situation. Because of the south’s secession, Sudan lost a considerable share of its oil revenue, and now plans to compensate for this loss through irrigated agriculture. The government has also begun to lease large land areas to foreign investors and other countries for growing food crops. Construction of new hydro-electric dams and expansion of existing ones will likewise demand more water (Salman, 2011b; Salman, 2014). South Sudan, for its part, is also claiming a larger share of water in order to rehabilitate agricultural projects, move toward sufficiency in food production, implement plans for hydro-dams, and meet the needs of returning southern Sudanese and internally displaced persons (Mbaku & Smith, 2012; Ngor, 2012; Salman, 2011b; Salman, 2014). In addition to these developments, climate change in the region is expected to lead to decreasing rainfall and increasing air temperatures. These changes are likely to negatively affect water availability due to higher evapotranspiration rates and more droughts (Warner et al., 2015). In light of the growing water demands on both sides and the expected impacts of climate change, the current 18.5 BCM (which in any case are challenged by upstream riparians) may no longer suffice or be available in the future, and water allocation conflicts between Sudan and South Sudan could emerge. Given that water allocation is closely linked to broader Nile Basin politics, such conflicts might have basin-wide repercussions.\nThe Jonglei Canal Project\nIf the allocation of Sudan’s current share of Nile waters becomes more contentious, the government in Khartoum may bring up the issue of water loss in the swamps of South Sudan. Currently, a large amount of water is lost each year in the Sudd and other wetlands due to evaporation and seepage. Plans for a canal to circumvent these wetlands to increase the flow of the White Nile date back to the early 20th century. Although construction of the so-called Jonglei Canal began in 1978, it came to a complete halt in 1984 when the SPLM/A attacked the canal site. Its main criticism was that the project benefitted the north and Egypt, while neglecting or harming living conditions in the south (Salman, 2011b; Sullivan, 2010). From the beginning of the interim period, the SPLM/A asserted itself against reviving the Jonglei Canal or similar water conservation projects. Due to South Sudan’s sovereignty, any resumption or initiation of such projects “…would [now] need the full agreement and cooperation of both the government of South Sudan and the local communities in the area…” (Salman, 2011b, 164). The incentives presented to South Sudan, the positions of affected communities and NGOs, and the fact that the Sudd since 2006 has the status of a Ramsar wetland of international importance are likely to play a role in Juba’s decision-making on the Jonglei Canal. However, the current security situation in the swamps areas, characterized by inter-tribal fighting, food shortages and military clashes, would appear to make a timely resumption of construction activities highly unlikely (Salman, 2011b; Salman, 2014).\nRelationship with the other Nile riparian states\nBeyond bilateral water disputes, it was expected that the new state of South Sudan would come to play a critical role in Nile Basin politics. With respect to the CFA, some predicted that both the CFA’s opponents (Sudan and Egypt) as well as its proponents (Ethiopia, Rwanda, Tanzania, Uganda, Kenya, and Burundi) would do their best to bring – or even pressure – South Sudan to their side (Salman, 2011b). The CFA needs a minimum of six instruments of ratification to enter into force. At the time of South Sudan’s independence, the agreement had been signed by the six proponent states. Between 2013 and 2015, Ethiopia, Rwanda and Tanzania also ratified the CFA (NBI, 2016b). South Sudan’s support for the CFA is seen as crucial by these states, since it “…would provide a cushion in case one of the other six changes its mind or delays its ratification” (Salman, 2011a).\nUN Watercourses Convention\nAs suggested by Salman (2011b; 2014), the UN Watercourses Convention, which entered into force in August 2014, could provide guidance for the allocation of Nile waters between Sudan and South Sudan. Neither country is a party to the Convention, with concerns stemming from the perception that the Convention may not be conducive to certain national interests (Salman, 2007). Nevertheless, many of its provisions, including those on equitable and reasonable utilization, are considered to be part of customary international law. Guided by the principles of international water law, factors to consider in water allocation might include Sudan’s current and planned uses; the expected future uses of South Sudan; the amount of Nile waters crossing from South Sudan into Sudan and Egypt; and rainfall in South Sudan as alternative water sources (Salman, 2014).\nImprovements in water efficiency and water conservation\nImprovements in water efficiency in Sudan, especially in irrigated agriculture, could significantly reduce the country’s present and future water uses. This, in turn, could decrease pressure on the Nile water resources, and possibly relieve tensions over water-sharing with South Sudan. Water conservation projects in South Sudan, especially in the Sudd area, have the potential to enlarge the amount of water to be shared between the two countries. However, such conservation projects have remained highly controversial, and under the current circumstances, their implementation appears relatively unlikely (see below).\nEgypt-South Sudan relations\nDue to its high stakes and dependence on Nile waters, Egypt has become increasingly concerned about post-independence tensions and instability in South Sudan. As long as the country remains politically volatile, resuming work on the Jonglei Canal or similar projects appears unrealistic. Increasing the flow of the White Nile is now a priority for Cairo, especially since Ethiopia has begun construction of its Grand Renaissance Dam on the Blue Nile (International Rivers, 2014; see: Disputes over the Grand Ethiopian Renaissance Dam (GERD)), thereby further intensifying water security concerns in Egypt (see: Security Implications of Growing Water Scarcity in Egypt). Under these circumstances, for Egypt, South Sudan is currently “…the most important Nile Basin country because of the possibility of implementing projects to increase Egypt’s share of the river’s water by harnessing the water currently lost on South Sudanese territory to forests and swamps” (Al Monitor, 2014). As a result, Egypt has stepped up diplomatic efforts vis-à-vis South Sudan, and has also expressed its willingness to engage in bilateral military cooperation or U.N. peacekeeping to improve the security situation. Also, in a nod to South Sudan’s long-standing criticism of the Jonglei Canal, there seems to be growing awareness in Egypt that any water conservation project “…should include developing local communities in South Sudan, not just harnessing lost Nile water for Egypt’s benefit” (Al Monitor, 2014). As another step in a series of “strong political and technical moves [by Egpyt] to earn the trust of South Sudan,” the two countries in November 2014 signed an agreement to increase cooperation on water resources management (Al Monitor, 2015; Sudan Tribune, 2014). Despite these measures, the government of South Sudan maintains its opposition to the Jonglei Canal project, at least until additional studies on environmental and social impacts have been carried out.\nSouth Sudan’s NBI membership\nIn September 2011, only two months after independence, South Sudan announced its intention to join the NBI. According to Mbaku and Smith (2012, 11), “[t]his swift announcement indicates the priority granted to water, especially that from the Nile River, in the new country’s development plans.” South Sudan was admitted to the NBI in July 2012 (NBI, 2016a), and the government subsequently expressed its intention to join the CFA (Al Jazeera, 2013). To date, South Sudan has not yet signed the agreement, and the recent rapprochement with Egypt (which rejects the CFA) might affect the political calculations of the Government of South Sudan. Whether or not South Sudan joins the CFA thus remains to be seen. What seems certain, however, is that this decision will greatly impact not only the domestic political and security situation in South Sudan, but also the broader power dynamics in the Nile Basin."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:37f375fd-8dd4-4ac3-a334-c9a2865788d3>","<urn:uuid:aa63ecb6-200c-433c-a7e7-fed609ef59ae>"],"error":null}
{"question":"Do both desserts require egg whites in their recipes?","answer":"Yes, both desserts use egg whites, but differently. The pastry puffs recipe uses whole eggs (2-3 eggs total, incorporated one at a time into the dough). The Brazilian guava souffle specifically requires 4 large egg whites beaten with cream of tartar until stiff peaks form, without using the egg yolks.","context":["Make the pastry puffs: Preheat the oven to 450 degrees F and line 2 baking sheets with parchment paper. Bring 1 cup water, the butter, granulated sugar and salt to a boil in a medium saucepan. Remove from the heat and sift the flour directly into the pan; stir with a wooden spoon until a paste forms. Return to medium heat and cook, stirring constantly, until the paste is shiny and pulls away from the side of the pan, about 3 minutes.\nTransfer to a stand mixer fitted with the paddle attachment and beat on medium speed to cool slightly, about 2 minutes. Beat in 1 egg until incorporated, then beat in 1 more egg. Whisk the third egg in a small bowl, then beat into the dough, 1 tablespoon at a time, until just smooth and tight. (You may not need all of the third egg.)\nTransfer the dough to a pastry bag fitted with a 1/4-inch round tip. Pipe 1 1/4-inch rounds of dough onto the prepared baking sheets, about 1 inch apart; you should have about 50 puffs. (Alternatively, drop the dough in small mounds onto the baking sheets with a spoon.) Smooth the dough peaks with a dampened finger, then transfer to the oven and bake until puffed, 10 minutes. Reduce the oven temperature to 350 degrees F and continue baking until golden, 5 more minutes. Turn off the oven but leave the puffs inside to dry out, 5 to 7 more minutes. Remove from the oven and pierce a small hole in each puff with a paring knife to let steam escape; transfer to a rack to cool completely.\nMake the filling: Put the white chocolate in a medium heatproof bowl. Bring the heavy cream to a boil in a small saucepan, then pour it over the chocolate. Gently whisk until smooth and cool, about 7 minutes; whisk in the peppermint extract. Stir in the mascarpone until combined. Cover and refrigerate until thick enough to pipe, about 30 minutes. Transfer to a large pastry bag fitted with a 1/4-inch round tip.\nInsert the tip of the pastry bag into the hole in each puff and pipe in the filling. Transfer the filled puffs to a baking sheet; refrigerate at least 30 minutes or up to 2 hours.\nMake the icing: Whisk the confectioners' sugar and milk in a large bowl until smooth. Assemble the croquembouche: Dip the bottom of a puff into the icing, letting the excess drip off. Transfer the puff to a platter, icing-side down. Repeat with more puffs, arranging them side-by-side in a 7-inch circle. Fill in the circle with more puffs to stabilize the base of the tower. Continue building a conical tower of puffs, using the icing to hold them in place. (If the icing becomes too thick, whisk in more milk, 1 teaspoon at a time.)\nDust the croquembouche with confectioners' sugar and sprinkle with crushed candy canes; chill until set, about 15 minutes.\nPhotographs by Johnny Miller\nRecipe courtesy of Food Network Magazine","It can be tough trying to find Latin desserts to replicate in our kitchen when many of the ingredients are not readily available to us. Luckily this recipe for Brazilian Guava Soufflé, or Suflê de Goiabada, calls for guava jam, which can be found in most markets these days. Yes, I said Soufflé. Relax, this recipe calls for 3 ingredients and about 20 minutes of your time.\nAlthough World Cup has now come to an end, we fell in love with Brazil. Brazil is a country bursting with many tropical fruits, and the guava (Goiabada or Guayaba) is king among them. For this dessert, guava jam or a melted guava paste is used to flavor the delicate soufflé. Making a soufflé is easy, making sure it does not deflate before you are ready to eat it can be a little tricky.\nHere’s a quick tip: Use cream of tartar in the whipped egg whites to help stabilize your eggs, increasing their heat tolerance and volume.\nThis recipe calls for smaller 4-6 ounce ramekins. This will help with serving individual portions, and if one falls, then you still have five more! This dessert can also be made in a large baking dish to share, but that can be unpleasant with serving and deflating. Know this: even the best made soufflé will deflate, and you may only have 5-10 minutes before it falls. Every time you hit or bang the baking dish, you risk a flat dessert. So take your time, and plate with care. An easy way to ease the anxiety of presentation is to quickly hand everyone a spoonful of jam or crème anglaise and have them plunge it into the soufflé.\nA quick note on step number four: wrapping your uncooked soufflé in strips of greased parchment is meant to help it rise straight up. You can do this with any straight sided dish, but it is not required for a beautiful Suflê de Goiabada, and it will still collapse anyway.\nBrazilians enjoy guavas and love making their Suflê de Goiabada. The best part is that the elegant and delicate dessert can be put together in minutes and can bake while you are making coffee or serving the port.\nGuava Soufflé (Suflê de Goiabada)\n4 large egg whites\n1/8 teaspoon cream of tartar\n½ cup soft guava jam\n1. Preheat your oven to 350°F. In a stand mixer, beat the egg white and the cream of tartar until stiff peaks form.\n2. Add the guava jam and beat again until stiff, being careful not to overbeat.\n3. Grease and flour 6 ramekins that are between 4-6 ounces. Divide the guava and egg mixture between the ramekins.\n4. This step is optional: cut long strips of parchment paper to wrap around the ramekin. You can spray it with cooking spray to insure clean removal. Use painters tape to hold it tightly closed. This can allow your soufflé to rise straight up, but not required for a beautiful dessert.\n5. Bake at 350°F for 12-15 minutes, until the tops are puffed up and slightly browned. Serve immediately as is or with a spoonful of guava jam or crème anglaise."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:aed267d1-9db1-4a6e-bae2-dbb30ca48861>","<urn:uuid:faa73d65-d75d-4945-af82-fd65867fb632>"],"error":null}
{"question":"How do arbitration and mediation differ in their approach to resolving disputes, and what makes them more appealing than court proceedings?","answer":"Arbitration and mediation differ significantly in their approaches. In arbitration, a neutral third party (arbitrator) makes binding decisions, and there can be multiple arbitrators involved. In mediation, a single mediator facilitates discussion between parties without providing judgment, helping them reach their own agreement. Both methods are more appealing than court proceedings because they offer a less formal environment, privacy protection, and faster resolution. While arbitration results in binding decisions like court proceedings, mediation leads to compromise solutions where neither party feels aggrieved. Both methods avoid the adversarial nature of litigation where one party wins and the other loses, instead promoting solutions that are mutually satisfactory.","context":["METHODS AND ADVANTAGES OF ALTERNATE DISPUTE RESOLUTION (ADR)\nIt is one thing to know the concept of Alternate dispute resolution; it is another to know the right methods to apply or seek in a particular dispute and to know the advantages of Alternate dispute resolution. What then are the methods that one may seek in ADR and what are the advantages of ADR?\nThe main methods of alternative dispute resolution methods available for settling disputes in Nigeria are Negotiation; Mediation; Conciliation and Arbitration.\nNegotiation is a problem-solving process in which the parties to a dispute or an imminent conflict voluntarily come together either personally or by their representatives, to discuss their differences and attempt to reach a joint decision or resolution of the conflict, on their own and without the involvement of a third party. Negotiation is different from other types of alternative dispute resolution mechanisms as no third party is involved.\nMediation is an alternative dispute process in which a neutral and impartial third party called the mediator is invited by the disputing parties to facilitate the resolution of the dispute by the self-determined agreement of the disputants. The mediator facilitates communication, promotes understanding, focuses the parties on their interests, and uses creative problem-solving techniques to enable the parties to reach their own mutual settlement/agreement. The mediator is usually jointly procured by both parties and the process is voluntary as the parties are not under any obligation to accept the suggestions of the mediator.\nConciliation as an alternative dispute method involves a neutral third party who can give an opinion or suggestion. It is a system of ADR where a third party known as the conciliator uses his best endeavours to bring the disputing parties to a voluntary settlement of their dispute. Conciliation is regulated by the Arbitration and Conciliation Act (ACA) Laws of the Federation of Nigeria (LFN) 2004.\nArbitration is the most initiated method of ADR where parties to a dispute submit to a third party called an arbitrator or arbitral tribunal for the resolution of their dispute. The decision of the arbitrator or arbitral panel called an award, is binding on the parties and enforceable by the courts. Arbitration is regulated by the Arbitration and Conciliation Act (ACA) Laws of the Federation of Nigeria (LFN) 2004 and also regulated by the Lagos State Arbitration Law, 2009.\nThe use of ADR is advantageous to litigation in the sense that it is cheaper than litigation. ADR can be more expensive than litigation but in long term, it is cheaper than litigation. In ADR, all the expenses are borne by the parties while in litigation; some of the expenses are not borne by the parties.\nIt is faster as compared to litigation where there is a competition of so many litigants with different cases, but in ADR, the parties' case is likely to be the only one. ADR is less time-consuming unlike instituting a court action which can be time-consuming from factors such as adjournments, the unwillingness of parties, etc.\nThe courtroom where litigation is carried out is usually tense. For the lawyers, it is difficult, there are a lot of rules and procedures which must be followed, and also for the layman, it is extremely difficult. An ADR session is more of a business meeting where coffee can even be served. Hence the layman is likely to prefer such an environment.\nThe parties to the dispute can determine the Coram. This implies that they determine the mediator or arbitrator or conciliator who will preside over their case, but where they fail to agree, there are provisions of the law for such appointments to be done either by the court or an agency.\nADR processes are parties driven. Parties can determine the time, venue, and pace in the ADR process, unlike in litigation where parties are not involved. It is controlled by the court.\nPreservation of the relationship between the parties- Most ADR has a win-win situation on both sides of parties to the dispute, as it preserves the pre-dispute relationship that existed between the parties before the dispute. ADR also helps preserve the privacy of the parties. In litigation, the process must be held in public except under certain conditions thus in private.\nWRITTEN BY: CHAMAN LAW FIRM TEAM\nTEL: 08065553671, 08024230080","|← The Law of Tort and its Implications||Intellectual Property Rights →|\nConflicts, controversies and disputes, have existed in the human history for an extraordinarily long time. This led to the invention as well as development of ways of resolving these conflicts. These methods vary according to the societies and this varies groups of people. Another thing that is common with the methods of conflict resolution is the high rate at which it evolves.\nLitigation refers to a lawful way of resolving conflicts between the various parties such as individuals, businesses, organizations, and governments among others. The traditional litigation system for a long time has been used to resolve conflicts using the civil court system. The key aspects that characterize the traditional litigation system include jury, trial, and discovery, among other aspects encountered in its day to day running. This system often entails the clients hiring attorney’s services in the attempt to seek justice.\nThe primary role of attorneys is to offer the legal advice to their clients and the client’s position in the whole procedure. This procedure happens, and it is usually done to serve justice to two parties that are against one another. During litigation system, the process of discovery is in most cases abused by either one or the both sides. A defiant person can file a lot of objections to detection requirements to deter the whole process. Moreover, the various motions are filed by either party before the trial. These are some reasons why the process of litigations can be protracted expensive and vexatious.\nApart from this classic form of dispute settlement, another method of dispute resolution has come in place. The alternative method is referred to as alternative dispute resolution (ADR). These methods try to solve some of the limitations of the traditional litigation. There are different methods of ADR that are in application today, these include; arbitration, negotiation and mediation. All of these processes are directed towards resolving conflicts.\nOf all the three methods of ADR, arbitration is the most commonly used method. As discussed earlier, traditional methods usually consist of two opposing sides each trying to defend their position, on the other hand, arbitration comprises of people or parties using an unbiased third party to listed and make his decision of the issue. This third party is known as an arbitrator and brings up the decision that is considered binding but some time may be unbinding.\nUnlike arbitration which may have more than one mediator; mediation is presided over by a single mediator whose role is not to provide judgment. The sole role of a mediator is to facilities a discussion that can lead to the conflict being resolved. Mediation has been found to be tremendously effective in conflict resolution and has been credited with reducing the cases that are taken to the courts. In addition, the decision reached is in most times viewed as the compromise between the parties and none feels aggrieved after wards. This occurs in a free environment where all parties can air out their views in from of a mediator who facilitates the reaching of a common ground.\nOne of the advantages of the ADR is the privacy involved. Since both parties are discussing and trying to solve their problem before their own choice of arbitrator, there are few chances that private information may fall into unintended hands. One of the advantages of traditional litigation over ADR is its ability to resole conflicts even when the parties are not willing to meet or discuss.\nMany business and people avoid the traditional method of litigation because of various reasons. One reason that is mostly given by firms and individuals, as to why many of them would not primarily prefer traditional litigation, is the dominant risk people and firms are exposed to in terms of being subjected to scrutiny. The intense scrutiny of an individual, a firm or a product may have negative effects in both the short and the long rung. The scrutiny may make firms suffer monetary loss; in addition, a brand may also suffer reduced demand.\nAnother burden that may make civil trial tedious for many people is the burden of proof. In the ADR, the proof is in most cases not necessary since, the parties are usually willing to come to a dialogue. The burden of proof can be expensive and may work to aggrieve further the aggrieved. For a successful civil trial to take place, the claims done by the plaintiff must be proven and be stronger than the defendants. This makes civil trial lees preferred compared to ADR.\nHowever, for this process to be fair the arbitrators must be neutral, the arbitrators do not have many problems attaining this because of the relaxed nature in which this occurs. This is because the process is informal, on the other hand, if these conditions are not met. The process cannot achieve the desired outcome. One of the major shortcomings of a civil legal process is its adversarial aspects; there always two parties that are defending their position.\nDespite the financial investment, and the time in traditional litigation, one party wins and the other losses at the end. This discourages many people to pursue justice through this process. In contrast, ADR provides a procedure that provides a safe landing for all parties. Mediation processes do not involve winning and losing. The mediator is uses his skills to assist the two parties to come up with a favorable compromise. In this case, both parties usually seek mutually satisfactory settlement for both parties making the final product palatable to all parties.\nIf we consider the costs involved in traditional litigation, it makes it unaffordable to all people. The traditional litigation process has been judged as expensive and time consuming, due to this, many people has resulted in using ADR methods. Among the methods that are preferred most by people are arbitration and mediation. Research shows that arbitration gives the people involved in conflict with smooth and speedy resolution of disagreement."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:f10be73e-a774-46d2-9e45-29355a68ffb6>","<urn:uuid:255de3ff-ecf4-4f59-8a55-53dbd8357fce>"],"error":null}
{"question":"Comparing habitat loss impacts, which species faces a more challenging population recovery - bats or birds - and why?","answer":"Bats face more challenging population recovery compared to birds when dealing with habitat loss. This is primarily because bats typically only have one pup each year, making their population growth inherently slow. In contrast, while bird populations have decreased significantly (2.9 billion birds lost since 1970, a 29% reduction), they can produce multiple offspring in a breeding season. Additionally, bats face specific challenges in finding safe places to roost during the day and raise their young, while birds have more flexibility in habitat adaptation and can utilize various garden features like native plants, water sources, and protective structures for their survival needs.","context":["Garden Lesson Plan: Birds and the Garden Ecosystem\nDownload: Birds and the Garden Ecosystem\nOverview: Birds are important and beneficial members of the garden ecosystem. They eat common garden pests, help with pollination, and aid in seed distribution. This lesson explores ways we can design our gardens to provide a supportive habitat for our feathered friends.\nGrade Level/Range: 6- 8th Grade\n- Learn that birds play an important role in our ecosystem.\n- Discover that bird populations are in decline and need our help to protect and restore their habitats.\n- Explore ways to design and plant bird-friendly habitats.\nTime: 2 hours\n- Interact access\n- Paper and pencils\nFound in a range of colors and sizes, birds fill gardens with song and activity. They are working hard for your garden, too. Birds:\n- Eat insects that we might find garden pests, such as caterpillars chomping on your lettuce or tomato plants and mosquitoes that are feasting on young gardeners.\n- Help with pollination. Birds that feast on nectar, such as hummingbirds, aid in the movement of pollen from flower to flower.\n- Facilitate seed dispersal. Fruit and seeds are a favorite food of birds. Some seeds will actually survive the digestive system of birds when consumed. They get a free flight to a new home and are dropped off surrounded by a “care package” of organic matter. In fact some seeds with hard seed coats will benefit from acid treatment of the digestive process, which will help with their germination. Other seeds hitch a ride on birds by getting stuck on beaks or in their feathers.\nUnfortunately, like many animal and plant species in our environment, bird populations are on the decline. National Geographic recently shared an article published in the journal Science that found bird populations have decreased by 2.9 billion birds since 1970 (which equates to a 29% reduction in the size of the population). They suggest many reasons for the decline. Including\n- loss of habitat\n- exposure to toxic pesticides\n- decrease in insects to consume\n- collisions with glass and vehicles\n- domestic cats\nFrom this list, loss of habitat is considered the top reason for the decline. Fortunately, this is something our gardens can help with. By choosing plants that offer shelter and food sources for local bird populations, we can help our gardens become a safe haven for these garden helpers. The following lesson will guide your class through the process of identifying the birds living in your community and then use that information to help turn your garden into a supportive habitat for them.\nLaying the Groundwork\nAsk students to read the article National Geographic article Three billion birds have been lost in North America since 1970 by Jason Bittel.\nAsk them to answer the following questions about the article:\n- Approximately how many different kinds of birds can be found in the United States and Canada?\nAnswer: 760 bird species\n- What methods did scientists use to discover the decline in bird populations?\nAnswer: population surveys and weather radar data\n- What are some of the reasons they list that have contributed to decreasing populations?\nAnswer: habitat loss, pesticides, decrease in insects, collisions with glass, domestic cat consumption\n- What are some important jobs that birds do in our ecosystem?\nAnswer: decrease insect pests, distribute seeds, eat dead animals, pollinate plants\n- What are some ways they suggest people can help birds?\nAnswer: Plant native plants, minimize impact of windows, keep cats inside\n- The first step in helping your local bird populations is identifying which bird species live in your area. Many birds migrate seasonally as the weather changes, so this is an activity that your students should conduct multiple times during the school year to compare their findings. Also, different bird species are active at different times of day. If possible, conduct one inventory first thing in the morning, and perhaps one mid-day.\n- First ask students to make a list of all the birds they have seen in your area. Next, take the class on a field trip to your garden, schoolyard or a nearby park or natural area to complete a bird checklist or inventory. Before heading outside, remind students to:\n- Respect all life in the garden. Observe living creatures with your eyes, not your hands.\n- Write down or draw as many details as possible. You may also want to bring a digital camera to help record your findings.\nBring a bird identification resource with you to see if you can identify some of the birds as you see them in the field. The Cornell Lab of Ornthology has created an amazing bird identification app called the Merlin Bird ID App. There are also numerous field guides available specifically designed for young observers.\nDepending on the skill level of your students, you can also opt to create ahead of time a pictorial checklist of common birds you may see to aid in the identification process. You may want to check with your local Audubon Society to see if they have regional checklists available for you to use.\nYou may also want to review these tips from the National Audubon Society before you begin.\n- To encourage more detailed exploration, in addition to identifying different types of birds, also have the students record how many of each they find. You can also ask them to take additional notes, such as to describe what they see them doing.\n- Before heading back in, take a look a look at your garden, schoolyard or natural area and complete an inventory of the different habitat elements you find, including plants that provide food, water sources, shelter, etc.\n- When you return to the classroom, begin by completing your identification and make an inventory list of all of the birds you observed.\n- Next, as a large group or in small groups or as an individual activity, research the habitat needs of each of these bird species. What foods do they like to eat? What kind of shelter do they prefer? Where do they like to build their homes? Do they migrate or do they live in your area year-round? What kind of water sources do they prefer?\n- Compare the resources you have available in your garden with the needs of the birds. Does you garden or greenspace currently provide what they need? Is there anything missing? Can you add these missing elements to your space?\n- Create a design to make your space more bird friendly. For example, identify native plants you can add to your garden that would provide food for your native birds. Brainstorm additional features you could add, such as shallow water sources, protective structures or feeders you could use to help provide supplemental winter food sources. If your region experiences freezing temperatures, consider a birdbath with a birdbath heater to ensure a continuous and reliable supply of water.\n- Participate in a local or national bird inventory. Here are a couple events to consider:\nOctober Big Day: https://ebird.org/octoberbigday\nThe Great Backyard Bird Count (February): http://gbbc.birdcount.org/\n- Write stories about the garden from the perspective of one of its newly identified residents.\n- Use your findings to create a field guide specific to your schoolyard garden to share with fellow students and community members.\n- Invite a local naturalist or wildlife expert to give a guest presentation about birds in your area. Based on their own school garden discoveries, have students prepare some questions for the speaker in advance.\nLink to Standards\nMS-LS2 Ecosystems: Interactions, Energy, and Dynamics\nMS-LS2-1. Analyze and interpret data to provide evidence for the effects of resource availability on organisms and populations of organisms in an ecosystem.\nMS-LS2-4. Construct an argument supported by empirical evidence that changes to physical or biological components of an ecosystem affect populations.\nMS-LS2-5. Evaluate competing design solutions for maintaining biodiversity and ecosystem services.\nMS-ESS3 Earth and Human Activity\nMS-ESS3-3. Apply scientific principles to design a method for monitoring and minimizing a human impact on the environment.","Introduction: Bat House\nWhy would anybody want bats in their yard? There are lots of good reasons but my three favorite reasons are \"the three P's\" of Pollination, Poop, and Pests!\nBats are attracted to flower nectar just like bees and (like bees) pollinate as they visit from flower to flower. Since they \"work the night shift,\" bats pollinate all night like bees do all day.\nMy second favorite reason is the guano bats produce. Bat guano (poop) is so incredibly rich in nutrients that wars have been fought over the harvesting rights to it. Bat droppings have an ideal ratio of NPK (nitrogen, phosphorus, and potassium, the elements required for plant growth, )have a high percentage of living organisms making it a natural fungicide that destroys nematode worms, all of which promotes a natural, global ecosystem.\nMy third, but most important, favorite is pest control - bats feast on as many as 1,200 insects each hour and mosquitoes are a major part of their diet. If you’ve ever grown your own garden, you know how difficult it can be to combat bugs, particularly if you are committed to avoiding harmful pesticides. Bats eat the bugs responsible for wreaking havoc on your garden.\nBat houses give females a safe, warm place to raise their young. Because bats typically only have one pup each year, populations are slow to grow. Plus, because of habitat loss, bats are finding it harder to find places to roost during the day and to raise their young.\nBy installing a bat house, you give these pups a chance to survive and for populations to be healthy. And all those healthy bats mean we can use less pesticide on our plants—a win win for everyone.\nWithout bats, humans would be in trouble. Bats help control insect populations, reseed deforested land, and pollinate plants, including many that we eat. Researchers and scientists also learn from bats to improve medicine and technology.\nAs population encroaches on forested areas, loss of habitat has endangered many species of bats. Building a bat house provides a safe place for bats to live and a nursery for their young.\nThere's a lot to know about proper placement of a bat house and thankfully the internet is filled with great sites offering detailed information regarding that. How high off the ground, how close to forest growth, how close to body of water, what color to paint the bat house (to maintain optimum internal temperatures,) compass orientation (for optimum sunlight exposure,) and method of mounting the house are a few of the interesting variables to consider.\nSo, let's get started to make a proper, weather-tight bat house with good ventilation and proper dimensions.\nStep 1: Materials\nYou can use most any wood, but cedar is recommended for its weather resistance and insect repelling properties. I am typically against painting cedar, but a good skin of outdoor water-based latex paint (as good a grade of paint as you are comfortable with) will add years of life to your bat house. You will want to use liberal amounts of yellow carpenter's glue or silicone caulk - or use both to provide as dry an interior as possible.\nOne 3’ foot long 1\" X 8\" (7¼\")\nOne 2’ X 2’ sheet of T-111 exterior siding or rough sided plywood.\nOne 8’ foot long 1\" X 6\" ( 5½\")\nOne 4’ by 4’ sheet ¼” plastic mesh\nOne 6’ foot long 1\" X 4\" (3½\")\n46 - 1 5/8\" #8 galvanized wood screws.\nTwo 3’ foot long 1\" X 1\" (¾\")\nPaint and painting tools\nElectric drill, saw, measuring tools, heavy duty stapler\nStep 2: Carefully Select Lumber and Cut Pieces\nFollowing the excellent (and free) shop plans from http://www.floridabats.org, I dug through the lumber at Home Depot to find 1x boards of cedar. Take your time and dig through the supply of lumber to find boards that are straight and free of defects such as cracks and large knots.\nI brought the wood home, and cut it into the various lengths called for in the plans. Most lumber sources will cut for you - especially helpful with sheet goods.\nFrom the 1X6, cut six 14\" sections for the front and back panels of the bat house.\nFrom the 1X8, cut one 16\" section for the roof and one 14\" section for the back.\nFrom the 1X1’s cut four 17\" sections. These will be used as spacers to secure the partitions.\nFrom the 1X4, cut one additional 14\" section for the back.\nFrom the remaining piece of the 1X4 cut two sections for the sides. One end of each piece will be cut at a 30-degree angle for the roof. This can be done by cutting each piece with a front length of 21½\" and a back length of 23½\".\nFrom the T-111 or plywood sheet, cut a 17\"X12\" section for the back partition, and a 16\"X12\" section for the front partition. If a larger piece of plywood is available, these two pieces can be cut 12½” in width to provide a flush fit at either side.\nI had some ¾” OSB left over from another project, so I saved about $15 on materials; I made the two baffles out of OSB instead of the marine-grade plywood the plans specified. I would normally be concerned about how OSB deteriorates when wet, but since the baffles are inside a rain-tight box, I gave them three heavy coats of paint before assembly and figure they will do just fine.\nThe plans were accurate, so cutting all of the pieces can be done without regrets. Having everything pre-cut helps dry fitting pieces; the dry-fitting process helps visualize how the project comes together.\nStep 3: Glue and Screw\nBefore any assembly, plan your steps so you can anticipate when glue is needed or best time to apply caulk. As pieces come together, it can become difficult to spread glue or apply caulk into tight spaces.\nYou can score the interior pieces (cut a very shallow groove every 1/2\" or so) to give the bats something to climb on/cling to - or you can staple a plastic mesh material to interior surfaces . . . most folks go with the mesh. Just make sure you don't cover up your grooving or the mesh with paint - it renders it unusable by the bats.\nAfter fastening mesh material, everything goes together using construction screws (with star pattern drive.) You can use any type of screw, however, it should be a wood screw, it should be weather resistant, and it should be short enough to avoid poking through to leave exposed screw tips to harm the bats. A construction screw works well - it not only stands up to outdoor conditions, it has a six-pointed star drive which will not spin out during installation (important when using heavy lumber that this project calls for.) Don't have a star drive bit for your drill? No problem - a bit is packed with each and every box of these screws (but check to make the bit it is in the box.)\nPre-drill all holes to prevent splitting wood. Use a drill bit slightly smaller in diameter than your screw. Seat each screw firmly making sure you don't leave any exposed screw tips to harm bats. Spread glue just before screwing; clamping is not necessary if screwed properly, however using clamps sometimes helps hold pieces firmly while you pre-drill holes and install screws.\nAll joints receive a coating of waterproof carpentry glue. When the glue dries, all corners receive a generous bead of silicone caulk; you should plan to do one or the other, but I recommend doing both to ensure a dry interior and extended life.\nStep 4: Construction Steps\n1. Place the two side pieces on a table with the long sides up and 14\" apart (outside to outside). It is recommended that glue or caulking be used as the bat house is assembled to strengthen and weatherproof it. Place one of the 14\" X 6\" pieces on top and align it with the bottom of the two side pieces. Fasten it with two 1-5/8\" wood screws on each side. Drilling 3/32” pilot holes for all screws will help prevent the wood from splitting. Repeat the process with a 6\", 4\", 6\" and 8\" piece, in that order. This will place the 8\" piece at the top of the bat house.\n2. Now turn the bat house over so it is laying on its back. Drill one 5/16\" hole at the top, and one 5/16\" hole bottom. These will be used for mounting the bat house to a post or building - skip these holes if you plan to use a French cleat mounting system. If you do drill the holes, they should be located in the center and 2\" from the edge.\n3. If plastic mesh is being used, cut two sections of plastic mesh the same dimensions as the plywood partitions. Staple the mesh to the plywood using vertical rows of staples about 2-3” apart. The side with the mesh will face the front of the bat house. Cut a section of plastic mesh 12\" wide and 23\" long and place it on the back wall of the bat house. Fasten the mesh with vertical rows of staples about 2-3” apart.\n4. Position the 1X1’s in the left and right-hand corners with the bottom ends located 4½\" from the bottom of the bat house. This will create a 4½\" landing pad. Place the 17\" partition with the rough or mesh covered side up on top of the two 1X1’s already in position. Use three 1-5/8\" wood screws in each; one in the center and the other two about ¾\" from each end. Make sure the top wood screw securely attaches the 1X1 to the 8\" board on the back wall. This will add strength to the bat house\n5. Position the remaining two 1X1’s on each side of the partition directly above the previous two. Place the 16\" partition on top (rough or mesh side up); allowing 1\" of the previous 1X1’s to show at the bottom. This open space makes it easier for bats to crawl into the forward crevices. Now fasten the plywood section and 1X1’s using two 1-5/8\" screws on each side. Locate them about 1½\" from the top and bottom of the plywood partition to avoid the screws underneath.\n6. Place the beveled 14\" X 6\" board at the top of the front, aligning the beveled edge with the 30 degree angle of the two side pieces. Fasten it using two 1-5/8\" screws on each side. Repeat using a second 14\" X 6\" board. Locate the third and final 14\" X 6\" board about ½\" down from the previous one to form a ½\" gap for the vent. This vent is important as it creates different temperature zones inside the bat house - bats will gravitate to different temperatures depending on maternal status, age, etc. and the vent gives them that choice.\n7. Center the roof section such that there is equal overhang on each side. Fasten it to the side pieces using two 1-5/8\" screws on each side. The roof should be caulked where it meets the back wall. Adding roofing material and painting the bat house will greatly extend its life.\nPaint color and texture also regulates bat house temperature. Paint color should be black where average high temperatures in July are less than 85° F, dark colors (such as dark brown or dark gray) where they are 85° to 95° F, medium colors where they are 95° to 100° F and white or light colors where they exceed 100° F. Much depends upon amount of sun exposure; adjust to darker colors for less sun. For the interior, use two coats dark, exterior grade, water-based stain. Apply stain after creating scratches or grooves or prior to stapling plastic mesh. Paint fills grooves, making them unusable. Use exterior-quality, water-based stain or latex paint, and choose flat paint rather than gloss or semi-gloss paint for best solar absorption.\n8. The bat house can be mounted on a 4’X4\" post or the side of a building using the holes drilled in #2 above and three-inch long, 5/16\" lag bolts. Alternately, a \"T\" brace using a cleat for the cross member can be used and anchored to a second cross member using screws in both lower corners. A large galvanized or stainless steel washer (fender washer) is recommended to protect the wood. Mounting on trees is not recommended because they have proven to be the least successful location for bat houses. Bat houses should be located at least ten feet above ground. Experience indicates the higher the bat house is mounted the more likely it will get bats; optimum elevation is between 12 and 20 feet above ground level.\nStep 5: Mounting the Bat House\nThe bat house received several coats of paint (even though cedar weathers quite well) and is ready to mount on a post. I used a 4x4 pressure treated wood post that is 11' above ground level. I attached a brace made of pressure treated 2x4 wood to bring the bat house up to a 12' elevation.\nAll bat houses should be mounted at least 10 feet above ground, and 12 to 20 feet is better. Choose a sunny location on the East or South facing wall of your house or pole-mounted out in the yard. Bat houses work best with at least 6-8 hours of direct sunlight (if only partial day sun is available- morning sun is preferable). Never mount a bat house to a tree or near vegetation - bats need plenty of unobstructed \"air space\" around their house for take offs and landings.\nThe bat house is mounted on a brace (a departure from the plans as regarding mounting instructions) because I wanted to provide extra strength against severe winds and I wanted to be able to take the box down for cleaning and repairs. As it turned out, my choice of mounting method also made it a lot easier to install.\nI used what is known as a “French cleat” on the back of the bat house that mates with an opposing cleat atop the mounting brace. A French cleat will not only hold an enormous weight, it will prevent sagging or loosening over time. Two construction screws secure the bottom of the bat house to the lower cross member of the mounting brace, so it is firmly in place.\nBefore mounting, I gave the post and the brace a couple of coats of outdoor paint. The French cleat made it easy to slip the bat house into place; a construction screw was driven through the bottom corners of the house into the 2x4 brace to anchor it securely. It should stand up to the strongest winds and rain Florida can dish out.\nStep 6: Open for Business\nWe're up and ready for bats. The research suggests it can take as long as a year for bats to adopt a new bat house. Bat houses can be installed at any time of the year, but they are more likely to be used during their\nfirst summer if installed before the bats return in spring. When using bat houses in conjunction with excluding bats from a building, install the bat houses at least two to six weeks before the actual eviction, if possible."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:908dc2f1-732a-4f7c-aba5-4c7538d0527b>","<urn:uuid:642f1a8b-447c-4b24-879c-01b509982f5b>"],"error":null}
{"question":"How did danceGATHERING adapt its 2020 edition in response to COVID-19?","answer":"The 2020 edition of danceGATHERING, originally scheduled for April 6-19, was transformed into a Virtual danceGATHERING held on April 18 and 19 due to COVID-19 public health concerns. Instead of canceling, they created a 5-hour immersive experience featuring over 100 artists, thinkers, administrators, visionaries, healers, technicians, light bearers, and diviners collaborating across 30 cities globally. The virtual edition explored the theme 'THIS IS THE END: THE FUTURE IS BLACK' and examined how artists could work from home while merging home space with work space.","context":["danceGATHERING 2020 | 18/19 APRIL. 2020\nTHIS IS THE END\nTHE FUTURE IS BLACK\ndanceGATHERING Lagos was initiated as an annual get-together, where we are all invited to connect by philosophies and plan for a paradigm shift. The 2020 edition was initially billed to hold from 6 - 19 April, but in the interest of public health and in compliance with local health advisories as regards COVID-19, it became impossible to continue with our plans, but instead of announcing a cancellation, we pushed our thoughts even further; what if we organise an exceptional Virtual danceGATHERING 2020, on our performance weekend, which was the 18 and 19 April, featuring a careful selection out of our danceGATHERING global community + other guest, all engaging with our predefined 2020 theme: THIS IS THE END: THE FUTURE IS BLACK?\nEvery year danceGATHERING examines its conceptual epicenter from myriad perspectives and muses. For 2020 we reflected the time. The world as we knew it ended, but simultaneously, this end time ignited the fire of a new possible future for all to realize that a new world thinking is indispensable, if we wish to reverse the damage that we’ve done to ourselves, to other inhabitants of the planet and to the climate till now. How do we dance together when our bodies are separated? New beginnings ask us to forget and re-examine. As some senses diminish perhaps others will intensify. How do we collectively experiment with the emerging sensitivities that we can predict will begin to manifest to us? Can we enhance this experience together in an intentional way? What if this end never ends ? How does the world breath again? At the time of contacting all the collaborators, almost every artist we know were at home, the object of our reflection was therefore, to examine what working from home meant for many of us, how do we merge the home space with the work space? Defying the dictatorship of social distancing wasn’t what we considered radical at the time, but what we found compelling was how many of us in our different disciplines are going in to collapse the spaces within our own confinements, to investigate how this new reality informs our practices, in a way that incorporates every obstacle that confines us to a place.\nWithin the AFROSPACETIME (which was the theme for danceGATHERING 2019), what really is virtual? does it not encompass everything that takes place outside the realm of what can be considered physical? Including dreamscapes, transcendence, visionscape and other immersive explorations of Yoruba conception of spacio-temporality, which blends the virtual with the spiritual, within a context that unsettles us, and places us as the subject of our own futures, pasts and presents. The digital world is a great space to collapse space and time, to escape and to re-connect, connecting the African dispersed world through creative collaborations and a feeling of presence which defies distance. A Virtual danceGATHERING wasn't an online festival, it isn't a webinar nor an e-conference, in fact, as always, it demanded no deliverables of our collaborators, no one knew what incentive or outcome to make of this experiment, but as systems collapse around us, this was simply be an invitation to allow same to crumble in each of us individually, while seeking new kinds of connections as we rehearse the future together for a paradigm shift.\nThis is the reflection I extended to all the featured collaborators as a prompt, what came out of it is this 5-hour immersive experience with over 100 artists / thinkers / administrators / visionaries / healers /technicians / light bearers / diviners who collaborated across 30 cities globally. Community Building is a creative act, and for me, it is important to build both a collaborative space and a community who have immensely contributed to this vision, which we’ve been imagining and pulling together over the course of the past five years.\nPERFORMER | ARTISTIC DIRECTOR | CURATOR\nWHAT IS danceGATHERING?\nIn 2017 we initiated danceGATHERING, as an annual gathering for creatives coming from diverse backgrounds, a performance lab and anti-disciplinary convention, which takes place in Lagos. It was co-founded in 2017 by Hajarat Alli and Qudus Onikeku, and co-curated in 2018 and 2019 by Qudus Onikeku, dancer, choreographer and artistic director of the QDance Center Lagos, and Onye Ozuzu, the Dean of the School of Arts, University of Florida USA. Operating as a horizontal, co-creation and co-learning space where everyone is an expert in something, where there is freedom of experiment. Here we invite artistes, thinkers, dreamers, healers and other inclassable mutants, who are all radically shifting the boundaries of knowledge in their various fields and localities, to connect by philosophies and practically collaborate together, on ideas that doesn’t necessarily fit into one discipline.\ndanceGATHERING isn't a festival, it isn't a retreat, a conference nor a workshop or seminar. It is a free space devoid of academic rules or marketplace expectations, devoid of professional hustle or cleverness. It is a space of love and laughter, of encounters and imperfections, a space of strength, vulnerability and inter-communal cooperation. A space of free spirit, free sharing and immense generosity, it is an untamed and uncultivated space, which invites us all to shed the layers of inhibition that flaws our capacity for human connectedness in our daily lives. An attempt to strengthen ties across borderlines, across race, across place, across time, across disciplines, across age, across gender and goes straight to the core of our being. A gathering of bodies happy to be together and touch one another, and desire one another, and care for one another, and carry, push, pull and groove with one another regardless of all the differences they emit unto one another.\nA body mind spirit workspace, where we collectively experience the bliss of total surrender to the creative process, where we inquire into what it means to elevate our thinking and culture as creatives, as thinkers and doers, as dreamers and catalysts, by simply being open to others and learning from all kinds of inspiring people from around the globe. It is a gathering where we are invited to plan together for a paradigm shift, where people are curated and not the things they make; here nothing is laid out but deeply felt. On the final weekend, danceGATHERING transforms Broad Street (Lagos historic Business District), into an arena for an elaborate performance, where all the collaborations, the findings and outcomes are shared in open air, with a larger Lagos and international audience. It is an attempt to bring back a religious order to public life.\nWHAT TO EXPECT AT danceGATHERING?\nFor the first week of danceGATHERING, the morning session offers participants an opportunity to take a variety of master classes from what’s available, ranging from traditional dances and drumming, body mind centering, contemporary practice and improvisation, writing and composition, philosophy and history etc., while the afternoon session affords each participant an opportunity to work individually or in small groups.\nThe second week offers a laboratory, where all the participants get an opportunity of collaborating with other collaborators, which further expands the scope of their materials, they experiment together, exchange creative processes and patterns, with the constraint at hand they dive deeper into pertinent questions of innovation, as it pertains to their practices and the current realities, while they develop new collaborative works that engage the creative energy of Lagos and the times.\nOn the final weekend, danceGATHERING transforms Broad Street, Lagos busiest street into an arena for an antidisciplinary performance weekend, where all the collaborations, the findings and outcomes will be shared in open air with thousands of Lagos and international audience."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:7c32f84f-82ce-4803-a4ce-b31c043feaf6>"],"error":null}
{"question":"What are the historical milestones of AI in finance, and what data privacy considerations must be addressed when implementing AI-driven lead generation?","answer":"The key historical milestones of AI in finance include K.C. Chen's 1986 breakthrough predicting an 87-point drop in the Dow Jones through Expert Systems, the 1993 launch of FinCEN's AI system identifying over $1 billion in laundered funds, and the 1998 authorization of high-frequency trading leading to AI handling 56% of NASDAQ trades by 2010. Regarding data privacy in AI-driven lead generation, businesses must comply with GDPR and CCPA regulations by obtaining explicit consent before collecting data, being transparent about data usage, using information only for intended purposes, and implementing secure data storage with encryption and regular security audits.","context":["Furthermore, analysts are expecting financial automation to replace up to 47% of jobs across the industry.2 It’s clear AI will functionally impact all parts of the sector, with increasing importance and relevance to all those participating in the future of the financial industry.\nThere has been a rich history of actualising fintech AI: from the days of Talos defending Crete;3 to the chess-playing Mechanical Turk;4 to playing Go,5 and AI being the best performer on the stock market in 2017.6 With exponential improvements in the price and performance of computing power, storage, and internet bandwidth, AI is being applied to an increasingly broad spectrum of industries to solve a whole host of problems they face.7\nWhat is AI?\nAI is any intelligence demonstrated by machines or computers, in contrast to the natural intelligence displayed by humans and other animals. Specifically in computer science, AI research is defined as the study of “intelligent agents”: any device that perceives its environment and takes actions to maximise its chance of successfully achieving its goals.8\nIn essence, AI consists of two main types: narrow AI and strong AI. Narrow AI is a computer program or learning algorithm designed to solve a very particular problem. For example, IBM Deep Blue beating multi-world champion chess champion Garry Kasparov; and more recently Alphabet (Google’s holding Company) becoming a Go Master in 21 days, winning all 100 of it’s qualifying games.9 In both cases, the AI was designed to compete at chess and Go respectively. If you asked either to perform a task outside of this – such as having a conversation about plants – they’d fail terribly.\nOn the other hand, strong AI refers to machines which are able to reliably pass the Turing Test (initially known as the Imitation Test) – which is to say they are indistinguishable from humans.10 For example, if you were given an instant messenger and told there was either a human or a computer on the other side talking to you, and you were unable to determine which it was – despite active questioning and engagement on a wide range of topics and activities (such as chess, logic arguments and general knowledge tests) – that AI is considered strong AI.\nThis was first (weakly) passed in 2014 by a chatbot called Eugene Goostman who achieved a 30% pass at the 60th anniversary of Turing’s death.11 There is significant debate around if or when it will become possible to achieve a reliable success rate.\nHe further theorises that by 2040, AI will have in excess of all combined human cranial-computing power.12\nThe application of AI to the financial sector sees a clear departure from traditional models of financial innovation. Traditionally, the industry has evolved to market forces and iteratively improved their performance, customer experience, and net efficiency in the delivery of products and services. In contrast, disruptive fintech represents the leap forward that the financial tech industry is taking as a result of new technologies. These are often developed outside of the financial industry and are being applied to the sector. Among others, key technologies include: blockchain/distributed ledger technology, Big Data and AI (including machine learning), smart contracts, crowdfunding, Peer2Peer (P2P) lending and so forth.13\nHistory of AI and finance\nGoing mainstream with high-frequency trading algorithms in 1998, and evolving into the disruptive fintech AI of today with highly customised and user-centric robo advisor services, such as Wealthfront and Betterment, it’s clear the financial sector is seeing rapid and disruptive advancement.14 The underlying technology itself is maturing, able to crunch enormous volumes of financial market data both quickly and intelligently to provide accurate measures of risk and high volumes of time-sensitive trades.\nWhile the application of AI to the fintech development sector often focuses on the investment market, it’s important to note this has been a long process of evolution impacting many areas of the financial industry. To fully appreciate this, we need to cast our minds back to the 1980s.\nThis was the time when countries were mobilising to capture the rapidly growing computer market. Japan was busy investing $400 million in their “Japanese 5th generation Computer Project”,15 the UK’s Alvey Programme had raised £350 million,16 and the US’s Strategic Computing Initiative by Defense Advanced Research Projects Agency had raised over $1 billion,17 for the improvement of technology. This caused rapid growth, and it wasn’t long before the financial industry saw opportunities to leverage this new technology.\nIn 1986, the first real breakthrough was experienced in finance when K.C. Chen from the School of Business at California State University and Ting-peng Lian of the University of Illinois were able to correctly predict an 87-point drop in the Dow Jones Industrial Average through the use of an AI concept called, ‘’Expert Systems’’.18 Expert Systems, in essence, are computer programs or algorithms which aim to model specific human expertise in one or more narrow knowledge areas.\nAfter a short, but tough AI winter between 1987 and 1993, improvements in the underlying technology – and with it, renewed funding – meant AI was again able to progress.19 By 1993, the industry was seeing opportunities to apply new fintech AI to the detection of fraud and the United States (U.S.) Department of Treasury’s funded FinCEN Artificial Intelligence system (FAIS) went live.20 In its first two years of operation, FIAS correctly identified over $1 billion in laundered funds.21\nIn 1998, the U.S. Securities and Exchange Commission authorised computerised high-frequency trading for the first time allowing for transactions that were thousands of times faster than humans to process. Just two years later, high-frequency trading accounted for 10% of all trades on the National Association of Securities Dealers Automated Quotations (NASDAQ).23\nAfter a short, but tough AI winter between 1987 and 1993, improvements in the underlying technology -and with it, renewed funding – meant AI was again able to progress.\nBy 2010, trading times reduced from a few seconds per trade to mere nanoseconds, resulting in a dramatic increase in the percentage of AI-powered trades to 56% all NASDAQ trades.24 The application of fintech AI was in full swing, so much so that the world’s largest hedge fund – Ray Dalio’s Bridgewater Associates – managed to attract David Ferrucci – head of IBM Watson’s AI unit – away from the largest AI patent holder to participate in building market analysis, prediction, and trading financial tech tools based on AI.25\nBy 2016, investment had grown significantly with Google and Baidu spending an estimated $20-30 billion on their own internal research and development efforts, along with purchasing startups in the field of artificial intelligence.26 More specifically to finance, two of the top three performing hedge funds in 2017 were fintech AI-driven – the top performer drawing a 770% return over 12 months.27\nApplication of AI in fintech development\nIn present day, this rich history of disruptive fintech AI has sparked a series of investments in finance to explore the specific areas the technology can be applied in the industry. The fields of risk assessment, fraud detection and management, financial advisory services, trading, managing finance, and customer service have drawn particular interest.\nLooking specifically at risk assessment, it’s worth first considering how this task is completed by a human in this function. Take, for example, a bank manager assessing a loan request: they request a host of information; review it; apply formal conditions and personal experience (gut sense); and then either approve or reject the loan, with an appropriate interest rate to offset the perceived risk. In the case of an AI, it’s able to complete exactly the same process, but with significantly more data from which to extract the demographics, psychographics, and other segment characteristics which determine loan repayment risk. Unlike the bank manager, the fintech AI learns from every loan the entire bank approves and rapidly learns from its mistakes as it attempts to optimise returns.\nIn present day, this rich history of disruptive fintech AI has sparked a series of investments in finance to explore the specific areas the technology can be applied in the industry.\nFrom a fraud detection and management perspective, similar processes are associated with whether a bank should or shouldn’t process a payment, based on whether it passes advanced fraud prevention and anti-money laundering (AML) tests. In this case, all available historic data for the user, good actors (individuals who are not engaging in money laundering), and bad actors (individuals who have been found to be laundering in the past) are collected. By then using sophisticated learning algorithms to compare the specific situation against both the good and bad actor data, the institution is able to determine their confidence in the transaction being safe or not. In most cases, suspicious transactions are then escalated to an analyst to apply further human intelligence; however, they do so on 1% rather than 100% allowing for a far more thorough review.28\nRobo advisors are an enormous business, growing 68% year on year and expecting to reach $2.2 trillion under management by 2020.29 Robo advisors are sophisticated AIs which look at historic stock performance, media, social media, and many other data sources with the aim of predicting future performance of stocks. The time horizon on this prediction ranges from 98 nanoseconds in the case of high-frequency trading, to many years in other forms of quantitative strategies.30 While some robo advisors focus on making actual trades based on the customer’s intended appetite for risk, others simply identify stocks for the user to consider for investment.\nBack-office tasks are increasingly being automated by machines, to such a degree that research conducted by some banks have found 85% of their full-time staff could be replaced by machine automation in the coming years – a troubling point for a traditional employee.31 AI that engages in human conversation is not new. Originally developed in 1962 in the form of ELIZA then PARRY in 1972,32 their efficacy has improved significantly in recent years through refined algorithms, increased processing power and richer learning data.\nWhen applied to customer relationship management or sales support, ChatBots are being taught to perform increasingly complex front-office tasks so that the vast majority of straightforward customer engagements are resolved in real time, 24/7. This would radically reduce the need for call centres, front-office staff, and other expensive customer-engagement resources.\nWhat about unbanked and developing economies?\nWhile fintech AI is clearly impacting the traditional first-world financial sector, it’s worth noting the novel approaches being taken to increase financial inclusion and facilitate efficient services to those in developing countries. Services such as Tala provide micro-finance to individuals based on their AI-crunched SMS history.33 In Kenya, DigiFarm34 has 19,000 farmers leveraging their agricultural produce to borrow as well as become better financially educated.35 In various other countries, AI is being leveraged to match P2P borrowers and lenders based on interests and risk profiles or appetite.\nWhat of the future?\nAI is expected to save the financial industry over $1 trillion in the next 17 years, an estimated current value of $1.2 trillion.36 Approximately 47% of financial jobs are at high risk of being replaced by automation.37 It’s clear AI is here to stay: with declining costs of computation, storage, and internet bandwidth combined with a projected 10-fold increase in volumes of data created daily.38\nThe prevailing question is how to navigate this incredible growth in new fintech AI-driven automation to ensure personal, business and industry sustainability? It’s clear the human component won’t be entirely removed, but the role will be redefined. Those who stay ahead of the curve will best leverage these new opportunities as the industry disrupts and reforms around Artificial Intelligence.\nInvest in your future with fintech\n- 1 Panzarino, H. (2018). “How is AI transforming financial institutions?” Retrieved from Fintech Futures\n- 2 Rundle, M. (2014). “47% of all jobs will be automated by 2034, and ‘no government is prepared’ says Economist”. Retrieved from Huffpost\n- 3Cummins, E. (2018). “Another AI winter could usher in a dark period for artificial intelligence”. Retrieved from Popular Science\n- 4Morton, E. (2015). “The mechanical chess player that unsettled the world”. Retrieved from Slate\n- 5 Gibbs, S. (2017). “AlphaZero AI beats champion chess program after teaching itself in four hours.” Retrieved from The Guardian\n- 6 Lefton, H. (2017). “Top analysts are betting on these AI growth stocks”. Retrieved from CNBC\n- 7 (2018). “Non-tech businesses are beginning to use artificial intelligence at scale”. Retrieved from The Economist\n- 8 Poole, D., Mackworth, A., Goebel, R. (1998). “Computational intelligence: A logical approach”. Retrieved from Semantic Scholar\n- 9 Gibbs, S. (2017). “AlphaZero AI beats champion chess program after teaching itself in four hours.” Retrieved from The Guardian\n- 10University of Reading. (2014). Success marks milestone in computing history. Retrieved from Science Daily\n- 11 Aamoth, D. (2014). “Interview with Eugene Goostman, the Fake Kid Who Passed the Turing Test”. Retrieved by Time Magazine\n- 12 Reedy, C. (2017). “Kurzweil claims that the singularity will happen by 2045”. Retrieved from Futurism\n- 13 (2018). “Oxford Fintech Programme”. Retrieved from GetSmarter\n- 14 McCracken, H. (2016). “How Charles Schwab fought back against the robo-adviser startup invasion”. Retrieved from Fast Company\n- 15Malik, R. (2002). “Japan’s fifth generation computer project”. Retrieved from ScienceDirect\n- 16 (2018). “Appendix 4: Historic Government policy on artificial intelligence in the United Kingdom”. Retrieved from UK Parliament website\n- 17 (2018). “Appendix 4: Historic Government policy on artificial intelligence in the United Kingdom”. Retrieved from UK Parliament website\n- 18 Smith, C., McGuire, B., Huang, T., and Yang, G. (2006). “The History of Artificial Intelligence”. Retrieved from the Paul G. Allen School of Computer Science and Engineering\n- 19 Cummins, E. (2018). “Another AI winter could usher in a dark period for artificial intelligence”. Retrieved from Popular Science\n- 20 Senator, T., Goldberg, H., Wooton, J., Cottini, M., Khan, U., Klinger, C., Llamas, W., Marrone, M., and Wong, R. (1995). “The Financial Crimes Enforcement Network AI System (FAIS)”. Retrieved from Semantics Scholar\n- 21 Senator, T., Goldberg, H., Wooton, J., Cottini, M., Khan, U., Klinger, C., Llamas, W., Marrone, M., and Wong, R. (1995). “The Financial Crimes Enforcement Network AI System (FAIS)”. Retrieved from Semantics Scholar\n- 22 McGowan, M. (2010). “The rise of computerized high frequency trading: use and controversy”. Retrieved from Duke Law and Technology Review\n- 23 McGowan, M. (2010). “The rise of computerized high frequency trading: use and controversy”. Retrieved from Duke Law and Technology Review\n- 24 (2017). “History of High Frequency Trading (HFT) – Infographic”. Retrieved from Techstars\n- 25 Joshi, A. (2016). “Rise of the machines: Artificial intelligence in the financial markets”. Retrieved from LinkedIn\n- 26 Bughin, J., Hazan, E., Ramaswamy, S., Chui, M., Allas, T., Dahlström, P., Henke, J., and Trench, M. (2017). “Discussion Paper: Artificial intelligence the next digital frontier?” Retrieved from McKinsey Global Institute\n- 27 Whyte, A. (2018). “Jersey-Based Bitcoin Fund Is 2017’s Second-Best Performer”. Retrieved from Institutional Investor\n- 28 Varshney, K. (2017). “On the safety of machine learning: Cyber-physical systems, decision sciences, and data products”. Retrieved from Cornell University Library\n- 29 Fraser, A. (2018). “Finance: Does AI mean the end for financial advisors?” Retrieved from Innovation Enterprise\n- 30Zhang, Y. (2016). “Spectral analysis of high-frequency finance”. Retrieved from Massachusetts Institute of Technology\n- 31 Dias, J., Patnaik, D., Scopa, E., and van Bommel, E. (2012). “Automating the bank’s back office”. Retrieved from McKinsey&Company\n- 32 Merisalo, Sonja. (2018). “Developing a chatbot for Customer Service to Metropolia UAS Student Affairs Office”. Retrieved from Helsinki Metropolia University of Applied Sciences\n- 33 (2018). “Giving credit where it’s due”. Retrieved from Tala\n- 34 Strydom, C. (2017). “DigiFarm – Technology that bolsters change in Kenya”. Retrieved from Mezzanine\n- 35 “Digifarm and connected farmer”. Retrieved from Safricom Twaweza\n- 36Osborne, C. (2018). “Artificial intelligence will be worth $1.2 trillion to the enterprise in 2018”. Retrieved from ZDNet\n- 37 Alam, N., and Kendall, G. (2017). ”Are robots taking over the world’s finance jobs?” Retrieved from The Conversation\n- 38 Cave, A. (2017). “What will we do when the world’s data hits 163 Zettabytes in 2025?” Retrieved from Forbes","The Role of Data Privacy in AI-Driven Lead Generation Strategies\nArtificial intelligence (AI) has revolutionized the way businesses generate leads, providing a more efficient and effective means of identifying potential customers. However, with the vast amounts of data involved in AI-driven lead generation, there are increasing concerns around data privacy. In this blog post, we will explore the role of data privacy in AI-driven lead generation strategies and discuss how businesses can ensure they are using customer data in an ethical and responsible manner.\nThe Importance of Data Privacy\nData privacy refers to the protection of personal information, such as names, email addresses, phone numbers, and other sensitive data. With the rise of AI-powered lead generation tools, businesses have access to vast amounts of customer data, which can be used to target potential customers more effectively. However, this data is also sensitive and must be protected to ensure customer trust.\nThe Role of GDPR and CCPA\nTwo regulations that have a significant impact on data privacy in AI-driven lead generation are the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA). The GDPR applies to all businesses that handle data belonging to individuals in the European Union (EU), while the CCPA applies to businesses operating in California that handle the data of California residents.\nUnder these regulations, businesses must obtain explicit consent from customers before collecting, processing, or storing their data. They must also be transparent about what data they are collecting and how they will use it. Additionally, customers have the right to access, correct, and delete their data at any time.\nEnsuring Ethical and Responsible Use of Data\nTo ensure ethical and responsible use of customer data in AI-driven lead generation strategies, businesses can take several steps:\nBe Transparent about Data Use\nTo build trust with customers, businesses must be transparent about what data they are collecting and how they will use it. This includes providing clear and concise privacy policies that outline the purpose of data collection and how it will be stored and used.\nObtain Explicit Consent\nBusinesses must obtain explicit consent from customers before collecting and using their data. This can be achieved through opt-in forms or checkboxes that customers must select to indicate their consent.\nUse Data for Intended Purpose Only\nTo maintain trust, businesses must use customer data only for its intended purpose. For example, if a customer provides their email address to download a whitepaper, that email address should not be used for any other purpose, such as marketing emails, unless the customer has explicitly consented to such use.\nSecure Data Storage\nTo protect customer data, businesses must ensure that it is stored securely. This includes implementing strong passwords and encryption, as well as regularly auditing data storage systems for vulnerabilities.\nConclusion AI-driven lead generation strategies have the potential to transform the way businesses identify and engage with potential customers. However, the use of customer data in these strategies must be ethical and responsible, ensuring that customer data is protected and used only for its intended purpose. By being transparent about data use, obtaining explicit consent, using data for its intended purpose only, and securing data storage, businesses can leverage AI to generate leads while maintaining trust with their customers."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f6ab684f-369e-4a43-a2bc-592aeae97e83>","<urn:uuid:e5b7073c-83c9-48d1-9a1f-3b4c9f191a18>"],"error":null}
{"question":"Can you compare how Customer Lifetime Value (CLV/CLTV) is calculated and utilized in traditional retail versus SaaS businesses, specifically examining the approaches used by Dermstore and modern SaaS companies?","answer":"In retail (as exemplified by Dermstore), CLTV is calculated by grouping customers into monthly cohorts, summing their total purchases over twelve months, and dividing by the total number of customers in that cohort. They use predictive CLTV through Custora and focus on both pre-purchase acquisition and post-purchase relationship enhancements. For SaaS businesses, CLTV calculation involves first finding the customer lifetime rate (1 divided by customer churn rate), then calculating average revenue per account (ARPA) by dividing total revenue by total customers, and finally multiplying these two figures together. Both sectors use CLTV to measure business health, but SaaS companies specifically emphasize it due to their subscription-based revenue model, where each renewal yields another year of recurring revenue.","context":["What do Farmville and face creams have in common from a marketing perspective? Plenty, according to Dermstore President, Cathy Beaupain. While not an obvious connection to most, Beaupain’s also not your traditional retail exec. She didn’t climb the corporate ladder as a buyer or through the marketing side of the business. Beaupain tuned her marketing chops running product at gaming company Zynga. From there she joined Dermstore, the multi-brand beauty retailer owned by Target.\nZynga taught Beaupain some invaluable lessons she carried into her retail career: (a) how to be very customer (or “guest”) centric and (b) to use data and testing to understand customer needs. It’s these data-driven, customer-centric principles that enabled Beaupain to double the average annual sales per Dermstore customer within 18 months.\nHere’s some of the learnings from Zynga that Beaupain used to drive Dermstore’s growth:\nVeronika Sonsev: What are the most valuable skills you learned at Zynga that have benefited you at Dermstore?\nCathy Beaupain: At Zynga, the mission was to connect the world through games. We did this by creating compelling experiences that captured the attention of millions of people globally. Creating these experiences didn’t happen in the dark. We used technology and data to discover what motivated our guests and leveraged those insights to impact product design. Being a customer and data-centric organization required intellectual curiosity, analytical horsepower, and technological innovations. And, sometimes it yielded unexpected results.\nFor example, at Dermstore we ran an A/B test for an incentive placed close to our add-to-cart button. The hypothesis was the incentive message right next to add-to-cart button would drive increased conversion. But, it didn’t move conversion rate at all.\nWe learned that if people don’t think they need the product, they won’t purchase it, regardless of the incentive offered. Instead, it’s more important to help people find the right product by introducing beauty-related content as early as possible in the purchase funnel.\nAs a result of this test, Dermstore removed the add-to-cart incentive and added content to the category landing page. Most retailers believe that placing content this close to purchase decisions distracts from conversion, but in our case, it didn’t impact conversion and actually increased the average annual sales per customer because the content was helping our guests find the right product for their needs.\nSonsev: When you're looking at the Dermstore business, which metrics do you evaluate? What is most important to the health of your business?\nBeaupain: The two metrics I focus on are (a) rate of new customer growth and (b) 12-month Customer Lifetime Value (CLTV). We look at these two metrics quarterly to understand the future trajectory of the business.\nWe calculate 12-month CLTV grouping new customers into monthly cohorts, summing up their total purchases over twelve months and then dividing that number by the total number of customers in that monthly cohort. We then compare monthly cohorts year-over-year. We also use Custora for predictive CLTV, so we can get an earlier read on our business. So far, their algorithms have been pretty accurate.\nI like to look at CLTV because that one number encompasses a lot of information about customer health. I also look at leading metrics like rate of new customer growth to measure top-of-the-funnel results and conversion rates and add-to-basket rates when A/B testing to determine the winner of those tests.\nSonsev: You focus a lot on customer lifetime value (CLTV). What are some things you've been able to do to improve CLTV?\nBeaupain: While I’ve been at Dermstore, we have nearly doubled CLTV. Most retailers focus on post purchase activities to increase CLTV. However, we learned that adjustments should be made upfront throughout guest acquisition, and supplemented by post purchase relationship enhancements like opt-in content-rich emails. We used data to derive insights about our guests’ desires and behaviors, and shifted our marketing programs to target those desires.\nWe leverage Custora predictive CLTV to determine customer quality based on their expected spend. We also look at where the customer came from and their first purchase to segment the customer, and determine how to service and market to them.\nFor example, in the last few years, we found more guests purchasing natural products. Natural guests care about prevention — they are younger and willing to explore new products across a broader range of price points. It’s easier to upsell these customers and introduce them to new products.\nConversely, professional guests are usually referred by dermatologists to treat a specific condition. While they initially buy more expensive products, they are not normally open to new products.\nWe must design different experiences for each type of guest, as they have different needs and purchasing flows.\nSonsev: What tools do you use to measure performance?\nBeaupain: We use a variety of internal and external tools. Our internal systems track every purchase to monitor historical CLTV and many of our guest insights. Custora allows our teams to manage CLTV growth proactively.\nWe evaluate marketing campaign performance and the synergy of different marketing programs with Abakus, a solution that helps us attribute sales revenue to the various marketing programs that touch a customer before making a purchase. We like to compare Abukus’ multi-touch attribution with first click and last click attribution models to understand the delta.\nAny company that services a customer need or sells a product can learn and quickly improve results by leveraging data. Zynga used data to prioritize and target guest desires and motivations, and Dermstore transformed its key metrics by doing just that. Now, you can do the same for your business.","Top 10 SaaS Growth Metrics in 2023\nPlanning ahead to expand on these marketing strategies can give you an edge over the competition by allowing you to craft a plan that will deliver measurable results.\nOver the past few years, the SaaS industry has exploded onto the scene and won’t be slowing down anytime soon. The highest performing companies continue to grow exponentially, more doubling their teams and initial public offerings (IPOs) per year.\nAs SaaS companies continue to expand so rapidly, the possibility of market saturation does too. For that reason, it’s imperative that they are paying attention to the right growth metrics.\n- The rapid expansion of the SaaS industry necessitates a focus on the right growth metrics.\n- SaaS growth metrics are distinct due to recurring revenue models and emphasize customer retention.\n- The top 12 SaaS growth metrics include churn rates, customer lifetime value, customer acquisition cost, months to recover CAC, and monthly recurring revenue.\n- Also important are MRR growth rate, quick ratio, CAC : LTV ratio, customer engagement score, and customer health score.\n- Continuous tracking and analysis of these metrics are crucial for effective SaaS marketing strategies.\nWhat is a SaaS Growth Metric?\nThe key SaaS growth metrics are vastly different from metrics of other businesses that are one-time sales and transaction based. Primarily due to the fact that revenue is collected over time rather than upfront. This means that there should be a strong focus on retention.\nA strategic SaaS growth model should not only center around customer retention rates, but also be able to answer the following questions:\n- What is working well?\n- Is my business financially operable?\n- What areas need improvement?\n- What areas should be focused on to accelerate growth?\nThe growth metrics that matter most can be compared to the body’s temperature, heartbeat, and blood pressure. Much like a routine check-up at the doctor’s office, it’s important that SaaS companies are regularly monitoring these growth metrics to keep an eye on the health of their business.\nIt can be confusing to know which analytics will actually help you evaluate your growth accurately and which ones will not. In this blog post, we’ll discuss the top 12 SaaS growth metrics that will help you analyze the momentum, or your business’s ability to grow and keep growing, and make the right decisions to help your company expand.\n1. Churn Rates\nThe first SaaS growth metric we’d like to highlight is customer churn rate. This is a measurement of how much business you’ve lost within a certain amount of time and it is an essential aspect of monitoring the day-to-day vitality of your SaaS business.\nChurn metric provides you with specific insight on customer activity across a certain date or time period to help you better understand your customer retention rates.\nIf you only focus on driving new customers to your business, you won’t get too far as an SaaS. Since most SaaS businesses are based on annual subscriptions, it is just as important to maintain your existing customers. A certain amount of customer or revenue churn is inevitable, but tracking it can help you stay ahead of it, and identify any issues early on that might be pushing your customers away.\nIn order to effectively track your churn rates on a monthly or quarterly basis, it’s crucial to not only look at the customer count, but also any definitive information about the customers that might identify the reason why they decided to not renew their subscription. This information might include their demographic, job title, industry or other persona details. Be sure to discuss these characteristics across all departments, including marketing, sales and customer service to align goals.\nThere are multiple ways to measure your customer churn rate. User churn is calculated as the percentage of customers that were lost during a given time frame, while revenue churn is the percentage of revenue lost to churn during a given time frame.\nEither one of the two following churn rate calculations can be used to monitor growth. However, many companies will argue revenue churn is more crucial to focus on due to the fact that revenue is the ultimate goal.\nUser Churn = (Cancelled Customers in the last 30 days divided by Active Customers 30 days ago) x 100\nRevenue Churn = (MRR Lost to Downgrades & Cancellations in the last 30 days divided by MRR 30 days ago) x 100\n2. Customer Lifetime Value\nNext on the list as an essential metric to effectively evaluate your SaaS growth rates is your customer lifetime value, or CLV. This describes the average amount of money that your customers pay throughout their engagement with your business.\nThis SaaS growth metric will provide your company with a true representation of your growth and can be explained in just a few steps.\n- First, find your customer lifetime rate. To calculate your customer lifetime rate, you want to divide the number 1 by your customer churn rate (see above). For example, if your monthly customer churn rate is 1%, you would divide 1 by 0.01, which would give you a customer lifetime rate of 100.\n- Second, find your average revenue per account (ARPA). This is calculated by dividing your total revenue of a certain time frame by the total number of customers. For example, if your monthly revenue is $100,000 and your total number of customers is 100, your ARPA would be $1,000.\n- Finally, find your customer lifetime value. This is calculated by multiplying your customer lifetime rate by your ARPA. Continuing with the examples above, you woud multiply 100 (customer lifetime) by $1,000 (ARPA) and discover that your customer lifetime value is $100,000.\nUnderstanding your CLV gives you insight into what your average customer is worth. It can also work as a way to display value of your company to investors if your business is in the early stages and still considered a startup.\nBecause most SaaS businesses are based on subscription-based models, each renewal has the ability to yield another year of recurring revenue. This increases the lifetime value per customer.\n3. Customer Acquisition Cost\nAs you build your SaaS growth strategy, another key metric to pay attention to is your customer acquisition cost, or CAC. This will tell you exactly how much it costs your business to acquire new customers and the amount of value they bring to your business. Customer acquisition costs works hand in hand with CLV to help SaaS companies ensure that their business model is viable.\nIn order to calculate your CAC rate, you need to divide your total sales and marketing spend by the total amount of new customers added during a certain time period. Be sure to include personnel expenses. For example, if your monthly expenditures come out to a total of $100,000 and your acquired customers come out to a total of 100, your CAC would be $1,000.\nThis particular SaaS growth metric is especially important for newer companies to focus on. It allows you to manage your growth and correctly gauge the value of your acquisition processes.\n4. Months to Recover Your CAC\nTo piggyback on the importance of CAC, it is also helpful to analyze the amount of time it takes to recover your total customer acquisition costs. This metric allows you to understand how quickly a customer begins to generate revenue for your company. The goal is for this number to decrease over time as your business grows.\nTo accurately calculate this metric, you can follow this equation: CAC divided by MRR x GM. In other words, divide your CAC by your total monthly-recurring revenue (see below) and your gross margin.\n5. Monthly Recurring Revenue (MRR)\nThe recurring nature of the typical subscription-based payment model makes it somewhat simple to track and gauge revenue. Monitoring your monthly recurring revenue (MRR) allows you to work out the amount of predictable revenue your customers generate each month.\nSaaS revenue run rates are guesses, at best. For example a SaaS platform that raised Series A of $10M, but is still pre-revenue stage needs to throw out big numbers for investors. While dozens of factors make-u a composite of monthly recurring revenue, it is a very core financial metric to track religiously in order to properly manage the month-over-month revenue growth of your business and boost momentum. When appropriately paired with your SaaS customer acquisition costs (CAC) and your customer churn rates, your SaaS monthly recurring revenue (MRR) can be used to anticipate and predict future revenue.\nTo successfully calculate your MRR for any given month, you simply add the recurring revenue generated by that specific month’s customers. The next few metrics we’ll be covering dive a little bit deeper into how MRR can help you manage your growth.\n6. MRR Growth Rate\nOnce you’ve calculated your MRR, you can then measure your SaaS MRR growth rate and evaluate the improvement of your revenue generation over time. For SaaS platforms, monthly recurring revenue growth rate is a percentage of your revenue run rate. For example, if your business generates $1,500 in MRR in March and then $2,000 in April, your MRR growth rate will be about 33%.\nTo maintain a steady MRR growth rate, your business needs to continuously generate more revenue each month. Therefore, if your MRR growth rate is steady, this is indicative of rapid, augmented growth.\n7. Quick Ratio\nThis next SaaS growth metric, known as the quick ratio, is the measurement of a business’s growth efficiency. Quick ratio allows you to understand how reliably your business can grow its revenue numbers given its current churn rate.\nTo accurately calculate your company’s quick ratio, you must divide your gained MRR by your lost MRR. If you have a quick ratio that is above 1.0, your company is growing. If it is under 1.0 however, this means your company is not. The bottom line is the higher your quick ratio, the healthier your company’s growth is going to be.\nQuick Ratio = (New MRR + Expansion MRR + Reactivation MRR) ÷ (Contraction MRR + Churned MRR)\nWhen calculating your quick ratio, it is important to note that all MRR is not created equal. There are different types of MRR that contribute to your MRR growth and understanding each of these types is key. The following is a list of the different MRRs to consider.\n- New MRR: MRR from new customers\n- Expansion MRR: MRR from existing customers (upgrades)\n- Reactivation MRR: MRR from churned customers who reactivated their account\n- Contraction MRR: Lost MRR from existing customers (downgrades)\n- Churned MRR: Lost MRR from canceled customers\nFor example, if a company has $10,000 in MRR growth, this might be a combination of any of the types of MRR listed above. The quick ratio helps you comprehend the difference in growth efficiency between them and provides the most straightforward picture of your business’s health.\n8. CAC : LTV Ratio\nAnother important calculation to include in your SaaS strategy to monitor your SaaS growth rates is your CAC to LTV ratio. This is a single metric that displays the lifetime value (LTV) of your customers and the total amount of capital that you spend to acquire them. It can point to the health of your SaaS marketing program as a way to show you what is working and what isn’t, so you can know what campaigns to invest in or change.\nTo find your CAC to LTV ratio, simply compare the two calculations. Generally speaking, your SaaS company should have an LTV that is at least three times more than your CAC. If it is lower, that could mean you’re spending too much money. If it is higher, you’re not spending enough.\nCustomer engagement scores allow you to see how likely a customer is to churn. It shows you how often they log in, what they use your software for and any other metrics pertaining to their engagement with your product.\nThe scales vary from business to business, depending on how a typical customer uses the software. In order to build your own SaaS customer engagement score, you should create a list of inputs and value assignments that predict a customer’s satisfaction and longevity. Start by looking at your happiest and longest-lasting customers.\nWith a clear list, you can calculate an overall client engagement score for your customers. This will allow you to efficiently evaluate customer health from one data point.\n10. Customer Health Score\nAnother metric that is similar to your customer engagement score is your customer health score. This helps your front-line customer service managers understand the health of a customer’s relationship with your company and if there are any issues that might indicate that it is at risk.\nCustomer heath scores can be generated by using a SaaS specific customer success tool that includes predictive customer analytics and forward looking client engagement trends. Health scoring assigns different values to different signals of customer longevity or churn. It also provides your customer-facing team members with insight into how their customers are doing so that they can properly engage with any users that might be at risk - before they cancel or fail to renew their subscription.\nThe SaaS growth metrics above are essential to any SaaS marketing strategy. It is important to continuously track, measure and report on these growth metrics at the various SaaS growth stages. Working with a leading SaaS marketing agency can help you stay up to date with these growth metrics and effectively put them into action.\nFrequently Asked Questions\nWhich SaaS growth metrics are essential for assessing customer acquisition?\nKey customer acquisition metrics include Customer Acquisition Cost (CAC), Customer Lifetime Value (CLTV), and the Customer Acquisition Rate.\nHow can I measure customer retention and satisfaction in SaaS?\nCustomer retention metrics like Churn Rate, Net Revenue Retention, and Customer Satisfaction (CSAT) surveys help gauge customer loyalty and satisfaction.\nWhat are expansion revenue metrics, and why are they significant in SaaS growth?\nExpansion revenue metrics, such as Upsell Rate and Expansion MRR, measure the revenue generated from existing customers, indicating the potential for upselling or cross-selling.\nWhat is Monthly Recurring Revenue (MRR), and how is it calculated?\nMRR is a fundamental SaaS metric representing the total recurring revenue a company generates each month. It's calculated by summing up all subscription revenue during a specific month.\nHow can I track SaaS growth in terms of product usage and user engagement?\nMetrics like Active Users, Daily or Monthly Active Users (DAU/MAU), and User Engagement Rate provide insights into how customers are using your SaaS product and its impact on growth.\nWhat are SaaS growth metrics, and why are they important?\nSaaS growth metrics are key performance indicators (KPIs) used to measure and evaluate the growth and success of a SaaS company. They are crucial for tracking progress, making data-driven decisions, and attracting investors.\nYou May Also Like\nThese Related Stories"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:b132de2a-d359-4442-9261-8929a42fac08>","<urn:uuid:9ef06023-7363-47d4-b81a-60549e486cb2>"],"error":null}
{"question":"How does Jewish law interpret the mitzvah of honoring parents in cases where the parent has acted unethically or abandoned their responsibilities, and what exceptions exist to this obligation?","answer":"Jewish law maintains that children must honor their parents regardless of the parents' moral conduct or deserved merit. This derives from Torah law, not parental worthiness. Even if parents exhaust their child's wealth or shame them, the honor obligation remains in force because God directed it. The only exception where a child should disobey a parent is when the parent commands them to violate Jewish law, as God's honor takes precedence. However, there is a provision where biological parents can legitimately renounce the kavod (honor) owed to them, as in cases of adoption where they voluntarily place their child with others.","context":["If a first child (daughter) of a father is born out of wedlock (my father married my mother after I was born, put his name on the birth certificate, but divorced her 6 months later) what laws and rules should I obey and how am I viewed in Jewish law? [Administrator's note: for answers on JVO regarding illegitimacy and the term mamzer vs bastardy, see http://www.jewishvaluesonline.org/question.php?id=27 and http://www.jewishvaluesonline.org/question.php?id=93.]\nTo What Extent is a Child to Honor and Respect a Parent Who is a Scoundrel?\nI. The Question:\na. Case A The question as asked is “If a first child (daughter) of a father is born out of wedlock (my father married my mother after I was born, put his name on the birth certificate, but divorced her 6 months later) what laws and rules should I obey and how am I viewed in Jewish law?”\nb. Case B A modern Orthodox wife and mother becomes more spiritual and observant. Her modern Orthodox husband undergoes a midlife identity crisis, he cannot tolerate his wife’s newfound and to his view, excessive piety, or his children’s religious sincerity. He leaves his home, wife, and children and connects with a Korean woman—young enough to be an oldest daughter-- who subsequently iconverted under non-halakhic auspices. His oldest daughter, a former Hebrew language and literature student of mine at a local Orthodox day school, becomes engaged to be married. Her father the home breaker and formerly observant, well educated Jew, demands that he and his new wife [a social gesture symbolically validating his new wife, his moral choices, and his newly discovered existential identiy] be invited to his daughter’s Orthodox wedding—after all, his daughter is Orthodox, she has to keep all the rules, including honoring him; the bride says, “I hate him, I do not want him in my life and certainly not at the wedding.” What to do?\nII. The statutes\na. The Torah at Exodus 20:12 and Deuteronomy 5:16 commands “Honor your father and your mother.” This apodictic syntax is foundational, constitutional, and seemingly allows no apparent exceptions.\nb. The Oral law teases out of the constitutional\nTorah text several specific norms:\ni. bQiddushin 30b. When married in rabbinic antiquity, the pappa who pays the penny gets the preference in honor which is expressed materially [Genesis 13:2]; if divorced, the parents are totally equal in their claims to respect.\nii. bQiddushin 32a also requires that parental respect be expressed tangibly, by providing financial support for parents.\niii. bKetubbot 103a. The child is obliged to honor his parents’ spouses, even if that spouse is not a parent.\niv. pQiddushin 1:6 requires that the child beg [seek alms from people at their doors] in order to sustain a parent.\nv. Maimonides, Mamrim 6:1 teaches that we respect and hold both parents in regard because God says so, and by implication, not for meta-halakhic fantasies. By respecting our parents, we respect God the lawgiver Who commanded that we respect our parents.\nvi. Supra.¸6:2. Cursing one’s parent is a capital offense.\nvii. Supra.¸6:3. We do not sit in judgment of or contradict our parents’ words, or sit in their seat. We stand in their presence and we do not address them by name during and after their lives.\nviii. Supra.¸6:7. Even if our parents exhausts our wealth and even after they shame us, we honor them because God in the Torah as so directed us to do so.\nix. Supra.¸6:10. If a child is unable to handle a demented paren, the child may provide care through surrogates.\nx. Supra.¸6:11, If a child is legally illegitimate, i.e. s/he was conceived through either incest or adultery, respect for the birth parent remains in force.\nxi. Supra.¸6:12. Only when a parent commands a child to disobey a Jewish law is the child to disobey the parent. It is God’s honor that generates value; parental honor is therefore derivative.\nIII. The value-driven decision\na. Case A refers to a man who is able to be a biological father but is unable—or unwilling-- to fill the moral role of father. The child’s obligation to honor her father derives from Torah law, and not from parental merit. By dint of her carrying her father’s DNA, she owes her father respect, deserved or not, because that is the Torah norm.\nb. Case B also requires respect for the wayward, sinful father. But here the case has a subtle nuance. Since her father gave his daughter his DNA at conception, she owes him respect and she must invite the “gentleman” to the wedding. The bride protested that she hates her father, she “cannot help it.” I responded: your father can say, “I cannot help it [=my feelings]” as well, and the Torah also happens to teach that hating is by law a forbidden moral disposition. [Leviticus 19:17] But since his consort was not Jewish by halakhic standards, his consort is not his wife according to Orthodox Jewish law. Therefore, while the bride owes her father respect in general and a wedding invitation in particular, she owes nothing at all to her father’s consort, who not being Jewish according to Orthodox Jewish law, she need not invite her to the wedding, even over her father’s objections. The father does not have the Jewish legal right to demand of her that she recognize what for Orthodoxy remains an intermarriage. The offended father happily did not attend the wedding.\nc. The Torah is teaching that we obey God without flinching, doing the right thing even if our egos find such obedience distasteful.\nBecause, however ironically, your legal status as a Jew (as you describe it) is so unmistakable, I worry that I may be misinterpreting your question:\nAssuming that your mother is Jewish (and was Jewish at the time of your birth), then you are Jewish, with no caveats or exemptions. Assuming that your mother was not married to anyone else at the time you were born, then there is no issue of the category mamzerut (often crudely – and misleadingly - translated as “illegitimacy” or “bastardy”), either. Mamzerut is ONLY an issue when the mother is married to someone else besides the father of the baby born.\nIf these assumptions are correct, then you should view yourself as a full member of the Jewish community, eligible to participate in any and all ways. You should obey and be included in all laws and observances, without any misgiving.\nI hope that this clarifies your questions about your Jewish status – and that you go on to live life as a Jew to the fullest!\nCopyright 2014 all rights reserved. Jewish Values Online\nN O T I C E\nTHE VIEWS EXPRESSED IN ANSWERS PROVIDED HEREIN ARE THOSE OF THE INDIVIDUAL JVO PANEL MEMBERS, AND DO NOT\nNECESSARILY REFLECT OR REPRESENT THE VIEWS OF THE ORTHODOX, CONSERVATIVE OR REFORM MOVEMENTS, RESPECTIVELY.","A child was adopted in infancy by Jewish parents, converted and raised as a Jew. Subsequently, the child discovered that his or her biological parents were Jews. Does the child have kaddish and yahrzeit obligations toward the biological parents? If so, is this obligation in addition to or in place of any similar obligation to the adoptive parents? (Rabbi Daniel K. Gottlieb, Concord, Ontario)\nThis Committee has dealt previously with the issue of adoption.1 The case before us differs, however, in that it raises the crucial, often explosive emotional issue which every adopted child must confront: which set of parents, the biological or the adoptive, are the “real” parents? To put the question in Jewish terms: to whom does this child owe the primary responsibility indicated by the commandment to “honor your father and your mother”? Sooner or later, say many experts in the field, every adopted child must somehow come to terms with this question, and a great deal is at stake in how he or she answers it. Accordingly, the psychological literature on adoption deals extensively with the subject. In this teshuvah, we want to examine the issue from the standpoint of Jewish religious tradition, a tradition we seek to understand and interpret as best we can from a contemporary liberal perspective.\nHalakhic Precedents. Had this child been born a Gentile, tradition would surely have regarded the adoptive parents as his or her only parents. The conversion would have severed the legal tie with the biological parents.2 In this instance, though, the child was born to Jewish parents, and this fact matters greatly: he or she has inherited Jewish status from the biological mother and father.3 Jewish law, moreover, regards the legal connection between Jewish parents and their biological offspring as a permanent one.\nThe concept of “adoption”, through which a parent-child bond is created through legal means and thereby replaces the bond linking the child to his or her biological parents, is not to be found in the Talmudic sources. The “adoptive” parent is always referred to as a legal guardian (apotropos) who raises (megadel) the child; that person is never called “father” or “mother”. The biological parent, meanwhile, never ceases to be the parent. A number of commentators in fact hold that a child is obligated to fulfill the commandment to “honor your father and your mother” for the biological parents even if they did not care for the child during his or her lifetime. The essence of parenthood, in this view, lies in the procreation of the child, a fact which even the severest kind of parental neglect cannot erase.4\nThis theory leads to some important halakhic consequences. A contemporary authority rules that “an adopted child…is obligated to honor (his biological parents) during their lifetime and upon their death, and to observe the laws of mourning and kaddish as any other child, even though he had no contact with those parents throughout his life.”5 The child’s obligations toward the adoptive parents, by contrast, are not so strict. R. Gedaliah Felder, in an authoritative treatise on the halakhot of conversion,6 declares flatly that a person is not required to “honor” his or her adoptive parents. He hedges this conclusion somewhat with the remark that, as a matter of courtesy and good manners, one ought to show respect to those who have raised and cared for one; thus, the adoptee ought to say kaddish for his parents, unless this should somehow violate the prerogative of the parent’s biological children.7 Similarly, R. Ovadiah Yosef rules that a person need not observe the rites of mourning (avelut) for the adoptive parent, nor should he say kaddish for that parent unless there are no biological children who can fulfill the requirement.8 In short, one may mourn one’s adoptive parents; one must mourn one’s biological parents. In this line of reasoning, the connection between Jewish parents and their biological offspring is permanent and “real”, while that forged by adoption is both artificial and less halakhically compelling.\nDiffering Trends. There is, however, another discernible trend in Jewish legal thought, a trend composed of a number of rules, principles, decisions and customs which point in the opposite direction and portray the family relationship created by adoption as no less “real” than the biological one. These are as follows:\n- The applicability of the commandment to honor one’s parents to all biological parent-child relationships is not necessarily absolute. A Talmudic dictum holds that a parent may legitimately renounce the kavod(honor) owed him by a child.9There is no more obvious case of a “waiver of rights” than a parent who has placed a child for adoption. This is not to imply that the parent’s decision is cavalier, arbitrary, or thoughtless; indeed, in many circumstances that choice is a painful one which the parent nonetheless recognizes as the most responsible option available. But when a biological parent agrees to allow others to raise a child as their own and to forego all the personal and financial obligations of parenthood, it is reasonable to conclude that the parent agrees to forego “honor” as well.\n- How can parents waive this “honor” when children are required to render it to the ones who bring them into the world? The answer is suggested by the author of the Sefer Ha-Chinukh (mitzvah# 33), who describes the commandment to honor one’s parents differently than do the authorities cited above. Its purpose, he writes, is to recognize and show compassion to those who have done kindness for us during our formative years; it teaches us to be grateful for the goodness we have received from them. He does, it is true, add that the commandment also serves as a reminder that one’s father and mother are the reason for one’s physical existence. Yet by equating these two purposes, he acknowledges that the essence of parenthood lies at least as muchin the care, the love, and the teaching which the parent bestows upon the child as it does in the fact of procreation. It follows that the duty to honor our parents defines our relationship toward those who have shouldered these obligations at least as much as it does that toward those who supplied the genetic material from which we were conceived. Adoptive parents, that is, are one’s “real” parents, as real as the biological ones.\n- The halakhahoften treats the adoptive relationship precisely as it does the biological one. R. Benzion Ouziel rules that parents are required to provide food, housing, and education for their adoptive children in the same measure as for their biological offspring. This obligation also extends to the emotional side of family life: the rabbinic court is empowered to intervene on behalf of the adoptive children should they be treated unfairly in any way by other members of the household.10R. Moshe Feinstein declares that an adopted child may be named “the son/daughter (ben/bat) of the adoptive parent” rather than of the Jewish biological parent or of “our ancestor Abraham” in the event the child was born to a Gentile mother and subsequently converted.11 He apparently relies upon a responsum of R. Meir of Rothenburg,12 who holds that a person may, in a legal document, legitimately refer to the child he has raised in his home as “my child.” Some authorities limit this ruling, arguing that a father may call an adoptee “my child” only when he has no other biological children; if other children exist, the document is invalid.13 This has been explained as an attempt to avoid confusion and contention in matters of inheritance. We presume that a father would rather bequeathe his property to his child than, say, his wife’s child from a former marriage; a document which equates the two children is thus presumed a forgery.14 Halakhists are in doubt as to how the law is decided,15 but in our case the presumption clearly does not hold.\nAdoptive parents agree under civil law to treat the child in matters of property and inheritance as though he or she were their biological offspring. This agreement is valid under Jewish law as a gift made “in contemplation of death” (matanat shekhiv mera) by which property is distributed so as to avoid the division demanded by the inheritance laws.16 It is also binding under the doctrine “the law of the land is the law” (dina demalkhuta dina), by which monetary obligations entered into under civil law are enforceable at Jewish law as well. Since the parents are thus obligated to their adoptive child, the objection to R. Meir’s ruling is moot. A parent may refer to an adoptive child as “my child” in all respects, legal as well as emotional.\nWe should also refer to the issue of yichud. Individuals are ordinarily forbidden to be alone together with members of the opposite sex other than their spouses. Parents are exempt from this prohibition on the theory that family ties suppress any sexual inclinations they might have toward their children and other blood relations.17 Some authorities hold that this applies only to biological children; thus, it is only with great difficulty that R. Eliezer Yehudah Waldenberg permits parents to be alone with children adopted in infancy.18 R. Chaim David Halevy, however, takes the opposite view. Parents may be alone with and display normal physical affection to their adoptive children, for their relationship to them is exactly the same as their relationship toward biological children. The adoptees have become “like real children (kevanim mamash) in every respect.”19\nThe matter of yichud illustrates an important development of halakhic thought. As we have seen, Jewish tradition offers two contradictory approaches concerning the relationship between parents and their adopted children. The one defines the status of adoptees as somehow less “real” than that of biological offspring; the other regards adoptees as the “real” children of their adoptive parents. Some halakhists have come to assume the second approach, at least with respect to certain issues, not because they regard the first approach as “wrong” but rather because it is irrelevant to contemporary social reality. They understand, that is, that the traditional distinctions between biological and adopted children are derived from sources which do not know of our present-day institution of adoption. When those sources speak of non-biological parenthood, they refer to situations analagous to those of step-parents or foster parents, guardians who cannot say with legal accuracy that “this is my child.” They do not describe the case of adoption in which, as R. Halevy notes, the emotional differences between biological and non-biological children virtually disappear. Adoption, some authorities have come to understand, creates a “real” family relationship, characterized by the same feelings and emotions that pertain to the bond between biological parent and child. It therefore makes no sense to think about adoption as though it were the same institution as its Talmudic antecedents.20\nLiberal Considerations. We agree, and we would go farther. We propose to apply this insight to all issues. We believe it is time that Jewish law erase all invidious distinctions between biological and adopted children. We do so not only because we regard adoption as a new phenomenon, different from legal guardianship, but because of our sense of what Jewish parenthood is truly about.\nParenthood is about family, and adoption creates family just as surely as does biology. We hold with the Talmudic sentiment that “one who raises an orphan in his home is regarded by Scripture as though he has given birth to that child” (BT. Sanhedrin 19b). We believe that those rules, principles, and customs within the tradition which portray adoptive families as “real” families are motivated by the same sentiment. And, most importantly, we agree with the Sefer Hachinukh that the essence of parenthood does not and cannot consist of the act of procreation. Parents of adoptive children, who love them as their own, care for them, and guide them, who stand by them during the crises and the joys of their lives, who raise them to adulthood, who teach them Torah and worldly wisdom are the real parents of these children. They are no less entitled to “honor” than the biological parents. Our best understanding of Jewish law and religious values demands that this simple fact be accorded full and complete recognition.\nWe do not hold thereby that adoption renders biology irrelevant. Indeed, the individual in our case is a Jew because the biological parents were Jewish. Had they been Gentiles, a conversion would have been necessary to create a Jewish family relationship between adoptive parents and child. Yet our case deals not with lineage but with parenthood. And though the child does not owe his or her Jewish status to the adoptive parents, they are no less entitled to love, honor, and filial devotion.\nIn this case, the individual may choose say to kaddish and observe yahrzeit for the biological parents. This may be quite helpful on psychological grounds as a means for helping this person come to terms with his or her past. At the same time, however, he or she must observe all the customs of mourning for the adoptive parents. Children are obligated to show their adoptive parents all the deference and honor expected of Jewish children, for indeed, these have become their parents in every respect.\n See American Reform Responsa, # 62-63, pp. 199-208.\n “A proselyte is like a newborn”; BT. Yevamot 22a and parallels.\n M. Kiddushin 3:12; Yad, Hilkhot Issurey Bi’ah 19:15; SA, EH 8:1 ff.\n See both the Meshekh Chokhmah and the Ketav Sofer to Deuteronomy 5:16.\n R. Yonah Metzger, Resp. Miyam Hahalakhah, v. 2, # 18.\n Nachalat Zvi, p 37. R. Felder cites approvingly the Talmudic story (BT. Sotah 49a) of R. Acha bar Ya`akov, who raised his daughter’s son. When the latter had grown, R. Acha said to him, “bring me some water”. The young man replied, “I am not your son” (Rashi: I am not required to honor you as a son honors his father).\n See also R. Yehudah Greenwald, Kol Bo `al Avelut, p. 375, who writes that the adoptee’s obligation of “honor” toward the adoptive parents is not equivalent to that owed to the biological parents.\n Yalkut Yosef, v. 6, p. 100. See also R. Aaron Felder, Yesodei Smochos, p. 74.\n BT. Kiddushin 32a; Yad, Hilkhot Mamrim 6:8; SA Yore De`ah 240:19.\n Sha`arey Ouziel, v. 2, pp. 184-185.\n Resp. Igerot Moshe, YD, # 161.\n The responsum is found in the collection entitled Teshuvot Maimoniot printed at the conclusion of Yad, Sefer Hamishpatim; it is # 48 in that collection. See also Isserles, CM 42:15.\n R. Chayim Benveniste, Kenesset Ha-Gedolah, CM 42:15.\n R. Moshe Sofer, Resp. Chatam Sofer, EH, v. 1, # 76.\n See R. Eliezer Y. Waldenberg, Resp. Tzitz Eliezer, v. 4, #22.\n See Yad, Hilkhot Zekhiah Umatanah, ch. 9.\n See Rashi, BT. Kiddushin 81b, s.v. ve-dar. This theory is, of course, a presumption, valid in most (but, tragically, not in all) families.\n Resp. Tzitz Eliezer, v. 6, # 40, ch. 21.\n Resp. `Aseh Lekha Rav, v. 3, # 39. See also R. Nachum Eliezer Rabinowitz, cited in Techumin, v. 10, 1989, p. 317, # 19.\n R. Halevy (see note 19, above) significantly points to contemporary practice (“go out and see what the people are doing”; cf. BT. Berakhot 45a) to justify his decision: since adoptive parents treat their children as though they were biological offspring, there is no reason to enforce upon them an halakhic distinction which has now become artificial. A popular discussion of this subject may be found in Dennis Prager, “Blood vs. Love,” Ultimate Issues 11:2 (1995).\nIf needed, please consult Abbreviations used in CCAR Responsa."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:1ecd6e5b-a0b1-42d7-ae7f-eb415d8e9168>","<urn:uuid:58aec18a-8e59-4e5e-9788-3913116a62b4>"],"error":null}
{"question":"What are the key differences between blockchain's P2P network architecture and traditional client/server networking in terms of data storage and authority distribution?","answer":"Blockchain's P2P network and traditional client/server architectures differ significantly in their approach to data storage and authority distribution. In blockchain's P2P network, there is no central point of storage, and all participants act as servers simultaneously - they both utilize and provide the foundation of the network. All nodes are considered equal with no authority over others, making it a truly decentralized system. In contrast, client/server networking operates on a centralized model where servers provide authentication and support services, while workstations don't interact with each other directly. In a 'pure' client/server network, workstations only see servers in a one-to-many scheme, with servers being dedicated to specific tasks like file services, Internet connectivity, and authentication.","context":["It doesn’t happen often that the appearance of one cutting-edge technology challenges the foundations of so many industries, but Blockchain Technologies have done just that.\nBlockchain seems to have become synonymous of sounding tech-savvy. But is this hype technology really gonna change the way this world operates? Before we can speak about ‘blockchain magic’ and how it has the potential to be the technology that redefines many business processes, it is important to get a grasp of it.\nWhat is Blockchain Technology?\nAccording to the authors of Blockchain Revolution (2016) “the blockchain is an incorruptible digital ledger that can be programmed to record not just financial transactions but virtually everything of value.” Hence, one of the key attributes of Blockchain Technology is its immutability: it permits the data to be distributed, but not copied or changed.\nWhy is it called Blockchain?\nThe name of blockchain comes from the way it stores transaction data: in blocks that are linked together to form a chain.\nWhen a trade is recorded it is checked by the network. The computers in the network (the ‘nodes’) check the details of the trade to make sure it is valid. The records that are accepted become part of a block. Each block contains a unique code called a hash (a digital fingerprint or unique identifier), timestamped batches of recent valid transactions, and the hash of the previous block. The blocks are linked together by the hashes they share, which prevents any block from being altered or a block being inserted between two existing blocks. That is one of the reasons a blockchain is impossible to tamper with: each subsequent block strengthens the verification of the previous one and therefore contributes to the incorruptibility of the whole chain.\nIf someone tries to change the original record, a new hash will be automatically generated for that record. As the next block in the chain still includes the old hash, the changed hash breaks the chain. It would require an enormous amount of computing power to recalculate all the hashes in the chain, which makes hacking a blockchain so hard.\nHow does Blockchain work?\nOne of the bases of Blockchain Technology is the Peer to Peer (P2P) network. P2P network is completely different from the traditional client-server models as there is no central point of storage. In a P2P network, all the participants on the network act as a server: the users utilize and provide the foundation of the network at the same time. All of them are considered equal, none of the nodes has authority over the other, therefore, no single participant can control the network.\nThe information included in a blockchain is constantly recorded and interchanged between all the nodes of the P2P network. As a method of transferring data, this proves to be a huge improvement because the information is not held in one centralized point. This way of storing data comes with a considerable advantage: as long as we have a copy of the blockchain in one of the nodes, all the records will remain intact.\nGiven that all the users of the network have same access and authority, there is no longer a need for powerful intermediates and all the interested parties can deal directly with each other across a secure and decentralized network.\nWhat are the applications of Blockchain technology?\nBlockchain Technologies could have repercussion on various aspects of our daily life. The most promising potential uses are in healthcare, real estate, retail, governmental sector, supply chain management, multinational policy management, finance and banking.\nWhile Bitcoin and cryptocurrency might have become the most famous uses of Blockchain Technologies, there are many other practical examples where we can see blockchain in action. Given its origin, finance and banking might be the most obvious ones. Blockchain Technologies will allow speeding up and simplifying cross-border payments, improve online identity management, spread the use of Smart contracts and make share trading faster and more accurate.\nBlockchain could also mean a much-needed relief for the healthcare industry, as it promises to provide a more efficient and secure system for managing medical records. As for innovations in governing, Blockchain records could create tamper-proof election returns.\nWhen it comes to supply chain management, the use of blockchain will guarantee transparency with a shared record of ownership and location of products in real time. Today’s consumers are more and more conscious about the origin and quality of the product. Using blockchain is a good way to provide proof of provenance for the consumers. In the food industry blockchain can help the companies find out what food might be contaminated and where throughout the supply chain.\nWe also have some examples from the entertainment business. Spotify turned to blockchain to develop a decentralized database that allows to connect better the artists and licensing agreements with the tracks on Spotify’s service.\nThe range of potential uses of Blockchain Technologies is very wide and we promise to go into more detail in our next post.\nWhat are the benefits of Blockchain Technologies?\nAccording to IBM the main benefits of using blockchain are:\n- Greater transparency\n- Enhanced security\n- Improved traceability\n- Increased efficiency and speed\n- Reduced costs\nWhat are the Main Barriers to a wider Application of Blockchain?\nAfter covering all the benefits and possible uses of Blockchain Technologies, we might want to ask why the companies and governments are not taking full advantage of the potential this technology has to offer. One of the most significant bottlenecks restricting a wider application is the lack of professionals with proper education on this groundbreaking technology. Another barrier hindering Blockchain Technology is the lack of general knowledge and the misinformation with most people thinking the technology is limited to cryptocurrencies.","Selecting the Network Type: Client/Server or Peer to Peer\nIn the next section, you'll have the opportunity to see how you can justify your decision to go with client/server or peer to peer.\nAs discussed, two important issues relating to choosing the type of network are scale and cost. A small office with little or no expansion will not need to deploy an expensive network server and run a Network Operating System (NOS) so that only a few users can share a few files and a printer. With this thought in mind, let's discuss client/server or server-based networking. We then take a look a peer-to-peer networking.\nClient/server networking entails two basic operations that are provided by a centralized server: authentication and support services. Workstations on the network don't require services from other workstations on the network. The service architecture of the network resides on one or more redundant, protected, regularly maintained, and backed up servers. These servers are dedicated to specific tasks: file services, Internet/wide area network (WAN) connectivity, remote access, authentication, backend distributed applications, and so forth.\nIn other words, workstations connected to a \"pure\" client/server network see only servers-they never see one another. A client/server network is a one-to-many scheme, with the server being the one and the workstations being the many. This architecture is the model used by large commercial websites, such as Amazon. The client is a small graphical front end that's delivered fresh from the server each time it's opened and a large server architecture at the back end that handles ordering, billing, and authentication. No user of Amazon knows another user is currently online-there's no interaction between users, just between the servers and the client system.\nThe client/server model is useful for large businesses that have to manage their computer users' computer resources efficiently. In a pure client/server environment, a great deal of the software that clients use at their workstations is stored on a server hard drive rather than on users' own hard drives. In this configuration, if a user's workstation fails, it is relatively easy to get the user back online quickly by simply replacing the computer on the desktop. When the user logs back in to the network, she'll have access to the applications needed to work.\nThe TCP/IP-based technology of the Internet has changed the accepted definition of client/server somewhat, with the focus being on distributed applications, where a \"thin\" client (such as a web page application running in a browser) works in tandem with a much larger server. The advantages of this model stem from the application's capability to run in a browser. Because browsers are universal-that is, they can run on Windows machines, Macs, UNIX boxes, and other systems-applications can be distributed quickly and effectively. Only the copy at the server needs to be changed for a web-enabled application, because the changes will be distributed when users open the new page.\nA client/server architecture is appropriate if one or more of the following conditions apply to your situation:\n- Your network user population is large, perhaps more than 20 computers. On a larger network, it might not be wise to leave resources entirely decentralized as you would on a peer-to-peer network, simply because there's no way to control the data and software on the machines. However, the size of the company's user base shouldn't be the only criteria. Indeed, size might be irrelevant, if the users are working on independent projects with little or no data sharing.\n- Your network requires robust security. Using secure firewalls, gateways, and secured servers ensures that access to network resources is controlled. However, and once again, installing a firewall in the router that connects your LAN to the Internet may be all you need for security. In this situation, your company doesn't need a dedicated security server. Even more, the individual workstations will be running their own security software and performing virus scans periodically.\n- Your network requires that the company's data be free from the threat of accidental loss. This means taking data stored on a server and backing it up from a central location.\nIn this tutorial:\n- Selecting Network Hardware and Software\n- Evaluating the Server Hardware\n- Evaluating the \"Interworking\" Hardware\n- Hardware Selection Considerations for Ethernet Networks\n- Working with Ethernet 100BASE-T\n- Implementation Ideas for Megabit Ethernet and Gigabit Ethernet\n- Selecting the Network Type: Client/Server or Peer to Peer\n- Peer-to-Peer Networking\n- Peer-to-Peer OSs\n- Peer-to-Peer Networking with Microsoft Windows\n- Evaluating NOSs\n- Microsoft Windows Server"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:bac6c151-f3c3-4694-b8a0-12b17752a39b>","<urn:uuid:df80c66b-6490-4109-9b29-20dcb801a012>"],"error":null}
{"question":"What is the proper technique for making the initial cut when taking plant cuttings?","answer":"The initial cut should be made using a sterilized tool with a sharp blade, such as a scalpel or razor blade. Make a 45° diagonal cut below the nodes, leaving a good section of stem underneath. It's best to select as thick a stem as possible since thin cuttings can take longer to root.","context":["There are several advantages of taking cuttings to generate new plants. Firstly, the cuttings will have identical characteristics to the mother plant, so the sex, size, quality, smell, taste, strength etc will be known. The plants will also grow to a similar shape and size, so space can be used more efficiently. A further benefit is that once the initial outlay has been made for the seeds, new plants can be grown for a minimal cost.\nAlthough any part of a plant can be used as a cutting, some parts will take longer to develop roots than others. The main head or arm tips have the highest concentration of growth hormones (auxins) and therefore more likely to root. Cuttings should be made from softwood stems and not the older, harder stems. ‘Softwood’ is the term which refers to the younger, soft, green stems. These are the easiest to root. Once these stems mature and age they are then known as ‘semi-ripe’’ and when fully mature, ‘hardwood’. Choose stems that are healthy and have at least three sets of nodes – smaller cuttings will root but they can be more difficult and may take longer, the ideal length is around 5 – 8 cms. Cuttings can be taken at any point in the vegetative stage of growth and in the first 3 or 4 weeks of the budding period. After this it may be difficult to get the cutting to root. NOTE: It is generally best to take more cuttings than required, you can then select the best ones or compensate for any that do not root.\nMAKING THE CUT\nUse a tool with a sharp blade to make the cut, a scalpel or razor blade for example. The blade should be sterilised to prevent contamination by bacteria etc, using a flame, alcohol or a bleach solution. Clean new blades to remove any grease etc. Make a 45° diagonal cut below the nodes, leaving a good section of stem underneath. Select as thick a stem as possible as thin cuttings can take longer to root.\nIf you are taking several cuttings at once, or if there will be a time delay between cutting and planting, take a larger cutting than is needed initially, and make the final cut later. Cuttings should be left sitting upright in water so that air does not get to the roots. Use a pair of scissors for the first cut, as the opposing blades will ‘seal’ the end. Make the final cut with a sharp blade (not scissors), this leaves an open cut which allows roots to develop.\nREMOVING THE LOWER LEAVES\nThe larger, lower leaves should be removed, so the cutting does not have to expend energy maintaining them. They will probably die anyway. At least the top two sets of leaves must be left. It is preferable (if possible) to remove leaves before making the cut, to avoid embolisms. An embolism occurs when a small bubble of air is sucked up into the stem, preventing the cutting from drawing up the water, nutrients etc that it needs. This will also allow you to plant the cutting as soon as possible after it has been taken from the mother plant."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:feaf33bc-6c3a-4362-9420-b6ed8d934f6d>"],"error":null}
{"question":"How do the recycling processes compare between waxed cardboard and scrap metal?","answer":"Waxed cardboard and scrap metal have very different recycling paths. Waxed cardboard cannot be recycled through traditional recycling streams but can be composted or made into other products. In contrast, scrap metal goes through a specific process where items are dismantled, compressed into flat shapes, separated into three categories (iron and steel, nonferrous metal, and non-metallic scrap), and then shredded into smaller pieces. The shredded metal is then shipped to facilities for reuse in new products.","context":["Cardboard, also referred to as old corrugated cardboard (OCC), is a readily recyclable material with well-established local markets for processing and manufacturing. Make sure cardboard is kept clean and dry as it is collected in your facility. Cardboard with a small amount of contamination, such as liquid or grease, can be recycled. Waxed cardboard should not be collected for recycling, but may be accepted by some commercial composting operations.\nCardboard boxes should always be flattened before being placed in a recycling container; the RecyclingWorks cardboard recycling graphic is available in six languages and can be used as a training tool and visual reminder for your staff: [English] [Spanish] [Portuguese] [Cape Verdean] [Simplified Chinese] [Haitian Creole]\nWhy should you recycle cardboard?\nIn Massachusetts, all recyclable paper, cardboard, and paperboard products are banned from disposal by the Massachusetts Waste Bans. According to the Massachusetts Department of Environmental Protection (MassDEP), cardboard in commercial loads of trash is one of the most common causes of a “failed load.”\nIn today’s economy, businesses and institutions recycle items like cardboard because it often saves them money on waste disposal costs. Recycling is also good for the planet and local communities because it helps conserve valuable resources, reduces pollution from production of new materials, and creates jobs. Some large generators of cardboard can bale or compact it, and market it directly to recyclers to receive revenue for this material.\nTo help businesses comply with Massachusetts Department of Environmental Protection Waste Ban for cardboard and other materials, RecyclingWorks developed the following sector-specific tip sheets, available in both English and Spanish. Tip sheets for additional business sectors will be posted below as they become available. If you are interested in having any of these materials translated into another language, please contact RecyclingWorks at (888) 254-5525 or firstname.lastname@example.org.\nHow does it get recycled?\nBusinesses in Massachusetts can work directly with their hauler to establish cardboard recycling services. Many haulers will collect paper and cardboard together, enabling you to maximize your recycling opportunities while minimizing the space you need for recycling. Please check with your hauler to confirm what types of paper should be collected together in your program.\nOnce picked up from the business or institution, this material is hauled to a facility where it is sorted and baled. The baled cardboard is then ready to be shipped to paper mills domestically and internationally for recycling into new paper products. There are local markets in Massachusetts where the entire process takes place. Trucks deliver loads of old corrugated cardboard, the material is inspected, pulped, rolled into sheets, corrugated, glued into new sheets, and cut into shape ready for market.\nWhat happens after it is recycled?\nRecycled cardboard is a high-quality material that can be used as packaging materials and boxes, and cardboard can be recycled many times without losing its strength. Corrugated cardboard containers that get used for shipping have a high percentage of post-consumer recycled content.\nWhat about pizza boxes?\nEmpty pizza boxes can typically be recycled, even if they contain grease. Remove all food, pizza savers (pizza tables), and liners. Liners and pizza savers should go in the trash, and any remaining food scraps should be composted or put in the trash.\nWhat about waxed cardboard?\nWaxed cardboard is commonly used in supermarkets, restaurants, and other food service businesses for products like ice-packed produce and meat, because the wax protects the cardboard from becoming soggy and breaking down. Unfortunately, this helpful feature also makes waxed cardboard unacceptable for recycling. Depending on the material characteristics and quantity, waxed cardboard can be composted or made into other products.\nCardboard Recycling Case Study: Wyman’s Liquors\nAfter receiving a failed load letter for excessive amounts of cardboard in the trash, Wyman’s Liquors made simple changes to their recycling program. Learn how Wyman’s came back in compliance with Massachusetts waste ban regulations and diverts 90% of the materials generated on-site.\nWyman’s Liquor Store Case Study: Learn more about how Wyman’s recycles cardboard, bottles, and cans throughout their retail space and offices. See the previous Wyman’s Liquors Case Study (2012) to learn more about program implementation.\nLearn about recycling other materials\nFor more information on other commonly recycled materials visit these pages:\n- Bottles & Cans\n- Construction Materials\n- Fluorescent Lamps/Light Bulbs\n- Food Waste\n- Single Stream\n- Find out how to start or improve your own recycling program.\n- Search our Recycler Database to find a hauler or processor for recyclable materials in your area.\n- Proper waste bin signage provides clear guidance on how to properly sort material, and can help improve the quality of materials collected for recycling or composting. Click here for an example of RecyclingWorks signage for cardboard.\n- To find out how you can purchase recycled products, check out our Buying Recycled Products\n- Learn about Massachusetts Waste Bans.\n- Use Recycle Smart MA for guidance on what materials are typically accepted for recycling in Massachusetts.","If you are an environmentally conscious consumer, you probably work hard to recycle many items that you use every day, such as paper, cans, plastic, glass bottles, etc. But did you know that you can also recycle many metal objects such as metal lamps, equipment, home appliances, metal tools, metal hangers, foil, aluminum cans and even your old car? In fact, car recycling is a quickly growing segment of the recycling industry, and you can even get paid for recycling your old car, rather than having it take up space in your back yard, or waste away at a junk yard.\nBy recycling metal you are actively helping to lower energy waste, to reduce green house gas emissions, and to conserve precious natural resources needed to produce new metal products. Today, in the US alone, according to the Institute of Scrap Recycling Industries (ISRI) there are “150 million metric tons of scrap materials recycled annually including: 81.6 million tons of iron and steel, 5 million tons of aluminum, 1.8 million tons of copper and 2 million tons of stainless steel”, and you can help these statistics grow by choosing to recycle your own old metal products.\nHow does scrap metal recycling work?\nDepending on what metal product is being recycled, there are a number of ways the recycling process can take place. If you are purchasing new home appliances or large metal equipment, you can ask the company that you purchase from to take away the old appliances, and they will take care of recycling it for you. You can also take smaller metal items that you have to a nearby metal recycling center and they will be happy to take them and will even pay you for bringing them in. The same goes for old cars. Once the cost of repairing your old car exceeds its value, it has reached the end of its life and a metal recycling company will pay you and take it away to be recycled. Interestingly, when it comes to old metal hangers, they are typically not accepted at the recycling facilities, but you can still recycle them by donating them to your local dry cleaners, who will happily take them in.\nAt recycling facilities, metal products are dismantled, compressed into flat shapes for ease of processing, and separated into 3 categories: iron and steel, nonferrous metal, and non-metallic scrap. The metals are then shredded into smaller pieces, while the non-metallic scrap is dumped into a landfill. Finally the shredded metal is shipped off to other facilities where it gets reused in new products.\nFacts on Recycling Aluminum Products (Cans)\n-Aluminum is a highly durable, long lasting metal: 2/3 of aluminum ever produced are still in use today.\n-Over 50% of aluminum cans produced are recycled in as little as 60 days.\n– According the ISRI, recycling aluminum conserves up to 8 tons bauxite ore and 14 megawatt hours of electricity.\n– It takes 95% less energy to produce a new can from a recycled one. This means than 20 recycled cans are produced using the energy to produce one can from virgin aluminum ore.\n-When you throw away an aluminum can, you actually waste as much energy as pouring out half of that can’s volume of gasoline.\nFacts on Recycling Steel Products (ELVs)\n– Cars are the most recycled consumer product. In fact, in EU car manufactures are responsible by law for the disposal of the vehicles they manufacture through the mandatory recycling and take-back programs.\n-Every year the steel industry in the US recycles more than 14 million tons of steel from old cars (ELVs), which is equivalent to about 13 million vehicles.\n-Steel can be recycled repeatedly without loss of quality or strength, which makes it the most recycled material in the world.\n-Steel used to make car bodies is typically 25% recycled.\n-The Motor and Equipment Manufactures Association reports that over 76% of each scrap vehicle is recycled.\n– According to the ISRI, recycling one ton of steel conserves 2,500 pounds of iron ore, 1,400 pounds of coal and 120 pounds of limestone."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:a9ce2765-d1a8-4833-94a6-c3c6574f4e77>","<urn:uuid:9d52a436-7500-4353-94c6-56ca7c32c171>"],"error":null}
{"question":"How do the cleaning and restoration processes differ between indoor wood furniture and outdoor teak furniture, particularly in terms of the recommended steps and products used?","answer":"Indoor wood furniture and outdoor teak furniture require different cleaning and restoration approaches. For indoor wood furniture, the process involves using mild soap or detergent solutions sparingly, with emphasis on avoiding water damage. A specific homemade cleaning recipe combines olive oil, denatured alcohol, gum turpentine, and strained lemon juice. The restoration process for regular indoor furniture involves a three-step routine: cleaning with commercial products using #0000 steel wool, restoring with finish restoring products, and monthly feeding with orange oil or wax. In contrast, outdoor teak furniture requires a different three-step process: sanding with 80-grit followed by 150-grit sandpaper, cleaning with specific teak cleaner using a scrubbing pad, and protecting with either teak protector or teak sealer. While indoor furniture typically uses paste wax or liquid wax for protection, teak furniture requires specialized products like teak oil, teak protector, or teak sealer, with teak sealer being the best choice for outdoor use as it provides both waterproofing and UV protection.","context":["Are you confused about dusting vs. cleaning, or waxing vs. polishing wood furniture?\nWhile experts have varying opinions on the care of wood furniture, it usually depends on the finish of the piece. On the following pages are many helpful tips from the book, Making a Home.\nTip #1: Always ask for specific care and cleaning guidelines when purchasing new or old furnishings.\nSee below for more on dusting and cleaning wood furnishings.\nDon't avoid dusting furniture. Frequent dusting removes airborne deposits that build up in a filmy layer and can scratch the surface.\nClean, dry, soft cloths or feather dusters will effectively remove dust; however, to avoid scattering the dust into the air, where it floats until landing back on furniture surfaces, dampen the cloth very slightly.\nNever use all-purpose cleaning sprays unless your furniture has a plastic coating, such as the kind used on kitchen tables and children's furniture.\nYou'll usually want to avoid cleaning wood with water. However, sticky spots may need to be treated with soap and water. Here's how: dip the cloth in mild soap or detergent dissolved in water, wring the cloth nearly dry, and wipe the area. Rinse and immediately dry with a clean, soft cloth.\nOil polishes, cleaners, and furniture oils protect wood by making the surface more slippery; they do not offer a hard protective layer.\nProducts that contain a high percentage of oil make the surface smear, showing fingerprints. Avoid polishing with pure olive oil, which smears and attracts dust.\nMost commercial spray and liquid furniture polishes contain silicone oil, which provides some protection. If you have used sprays and polishes in the past or suspect that furniture has been polished with them, be aware that residues can interfere with refinishing and may need professional attention.\nHomemade recipe for cleaning wood: Some experts recommend reviving grimy wood furniture with a mixture of equal parts olive oil, denatured alcohol, gum turpentine, and strained lemon juice. Apply with a soft cloth and buff with a clean cloth.\nTypically during manufacture, varnish, polyurethane, or shellac is applied to wood to protect the surface. Applying wax or polish protects the manufacturer's finish and helps to reduce surface scratches.\nWax provides a hard finish and long-lasting protection, doesn't smear, and is more durable than sprays or polishes.\nUse paste wax or liquid wax made specifically for furniture. Depending on use, paste wax finishes may last as long as two years. Liquid wax is easier to apply but leaves a thinner coating; it may need to be applied more frequently than paste wax.\nLearn how to properly apply waxes to eliminate streaks or a cloudy appearance. Always apply wax in light coats, rubbing into the surface with the grain. Allow to dry and buff to a clear shine with a soft cloth.\nSee more tips on waxing below.\nFor fine furniture or treasured family heirlooms, use this three-step cleaning and care routine.\n1. Clean approximately every year with a commercial cleaning product (such as Formby's Deep Cleaning Build-Up Remover) using #0000 steel wool. Work with the grain and follow product directions carefully.\n2. Restore as needed, especially from sun fading, using a commercial finish restoring product such as Howard Restor-A-Finish. Choose a shade closest to the wood stain and apply with #0000 steel wool to a small section at a time. Work with the grain of the wood and use light to moderate pressure. Immediately wipe with a soft, lint-free cloth, such as cheesecloth.\n3. Feed as a monthly routine using an orange oil or wax (try Feed-N-Wax beeswax) to prevent drying and cracking.\nOkay, so you've found that perfect piece at a garage or tag sale! Now, how can you bring out its best?\nAs a first step to removing layers of grime, use an oil soap and water. Rinse and dry well. If the finish still seems dirty, clean lightly with #0000 steel wool dipped in a cleaning product. Some products with a milky appearance are formulated to dissolve both solvent-based and oil-based residues. Do not use mixtures containing boiled linseed oil, turpentine, or white vinegars. Museum conservators say these things darken wood and attract dust and lint. Instead, apply clear paste wax.\nRemove hardware from the furniture piece. Clean with a metal or brass cleaner and buff. Reattach when completely dry.\nIf the top of wood furniture is slightly scratched, apply paste wax or use a felt-tip touch-up pen.\nTo treat deeper scratches that gouge into the wood, use wood filler or a colored filler wax stick available at hardware and home improvement stores. Match as closely as possible to the color of your piece, applying in several thin layers rather than in one thick layer.\nAdapted from the book, Making a Home (Meredith, 2001).","Is your outdoor wood furniture looking gray and weathered or beginning to show signs of rot? Wood furniture takes a beating from the elements when it sits outdoors, so it requires regular maintenance. If you’ve fallen behind on protecting your outdoor wood furniture, don’t despair! You can restore it to its original beauty and strength. We’ve done the research, and we can show you how!\nTo restore outdoor wood furniture, follow this sequence of steps:\n- Sand away the weathered or rotted wood.\n- Clean the furniture thoroughly.\n- Stain or paint the wood.\n- Apply finish/sealer.\nOf course, each of these steps requires some additional explanation. In the remainder of this article, we’ll describe each step in detail. We will also delve into the methods for restoring teak furniture, which differ somewhat from the steps you’d take with other types of wood. We’ll identify the best clear coat sealer for exterior wood and describe how best to protect your outdoor wood furniture from being damaged by the elements. Keep reading to learn more!\n4 Steps To Restore Outdoor Wood Furniture\nThe two major causes of outdoor wood furniture damage are excessive moisture and the sun’s UV rays. While it is no problem for wood furniture to get wet, it will begin to rot if it stays wet. So, make sure not to leave your wood furniture in the path of sprinklers, in a shady place where it cannot get dry, or on soil or grass where it will constantly absorb water from the ground. In addition to the danger of rotting due to moisture, wood furniture that sits in the sun will weather to a silver-gray hue as the sun’s UV rays break down the lignin in the wood. This process not only changes the color of the wood but also softens and weakens it.\nIf your outdoor wood furniture suffers damage from excess moisture or UV rays, follow these four steps to restore it to its original beauty:\n1. Sand Away Weathered Or Rotted Wood\nYour first step is to remove any rot or weathering on the surface of the wood. Paint, stain, and varnish will not adhere to weathered or rotted wood, so you must perform this step thoroughly and carefully. To get the best results, use a random orbit sander and, where necessary, sand by hand. Go over the entire surface with 80-grit sandpaper, then repeat with 120-grit paper to get a smooth surface. Pay special attention to inside corners, between slats, and other hard-to-reach areas.\nWhen the damaged surface is sanded away, you’ll have like-new wood ready for staining, clear-coating, or painting.\n2. Clean The Furniture Thoroughly\nOnce you’ve sanded your wood furniture, clean all the sanding dust off. First, blow it off using your own breath or, preferably, a hairdryer set on low heat. Vacuum up all the dust on the dropcloth and in the surrounding area so that it will not rise and adhere to the furniture after you’ve applied stain or clear finish. Next, dip a tack cloth in mineral spirits and wipe the furniture entirely clean. Allow it to dry until it returns to its original color.\n3. Stain Or Paint The Wood\nIf you choose to stain your furniture, use a high-quality brush made specifically for applying stain to the wood. You can select a stain with sealing agents included in its chemical formula or one that requires a separate sealer to be applied after staining. Stir the stain thoroughly until all the pigments in the can are fully mixed. Apply stain thickly to the wood, but not so thickly that it pools. After 10-15 minutes, wipe away the excess with a clean rag.\nIf you decide to paint rather than stain, select an exterior-grade paint and primer, which will protect the furniture from moisture. Using a high-quality brush, apply a coat of primer to the furniture.\nFollow this by two or three thin layers of paint, allowing each coat to dry completely before you apply the next. Make sure to cover all of the wood, including the bottom surfaces and between slats. Wipe away drips with a clean cloth.\n4. Apply Finish/Sealer\nIf you’ve applied a stain that does not include a sealer, your final step will be to make the furniture impervious to moisture by applying a clear coat of sealer. You may use polyurethane or varnish: each has its own unique set of advantages and disadvantages.\nPolyurethane is like liquid plastic, forming a hard protective coat as it dries. It is waterproof and protects the wood from scratching, cracking, and chipping. Although polyurethane comes in water-based and oil-based varieties, only the oil-based type is suitable for exterior wood. The major disadvantage of oil-based polyurethane is that it dries with an amber tint, altering the color of lighter woods. Its main advantage is convenience: it requires only one or two coats to fully protect your furniture.\nMost types of varnish also cure a light amber tint. Varnish is stronger and more durable than polyurethane; however, it requires at least six thin coats to reach maximum effectiveness with substantial drying time. It provides both waterproofing and protection from UV rays. In addition, it is more flexible than polyurethane, so it adapts better to shrinkage and expansion of the wood.\nCan Weathered Teak Be Restored?\nIt is not difficult to restore weathered teak furniture. You will follow a three-step process similar to restoring other outdoor wood furniture types: 1) sanding, 2) cleaning, and 3) protecting.\n1. Sand Your Teak Furniture\nUsing 80-grit sandpaper with an orbit sander and hand-sanding where necessary, remove the silvery-gray surface wood until you reach the underlying layer of healthy teak. Then go over the entire surface with 150-grit sandpaper to achieve a smooth finish, ready to accept stain. Make sure to thoroughly sand all surfaces, including hard-to-reach areas such as inside corners and between slats. After you’ve sanded, spray the furniture clean with a low-pressure setting on your garden hose sprayer.\n2. Clean Your Teak Furniture\nBefore your furniture is fully dry, apply teak cleaner to it, using a scrubbing pad or a soft-bristled scrub brush. Work the cleaner into the wood and let it sit for 5-10 minutes for a deep clean. Then respray the furniture with your garden hose sprayer on a low-pressure setting. Set your furniture in a sunny spot to allow it to dry completely.\n3. Protect Your Teak Furniture\nFinally, protect your teak furniture from drying out again by applying a finishing product to it. You may choose either a teak protector — which shields the wood from UV rays — or a teak sealer, which protects from both UV rays and moisture. In either case, use a sponge to apply an even coat of the product to all wood surfaces. Make sure to coat hard-to-reach surfaces such as those between slats. Allow your furniture to dry for at least 24 hours after sealing it before replacing cushions or using it.\nWhat Is The Best Finish For Teak Wood?\nThe three types of finishes used on teak wood are: 1) teak oil, 2) teak protector, and 3) teak sealer. We’ll discuss the advantages and disadvantages of each below.\nTeak oil is actually derived from other plants, usually linseed or tung. Its purpose is to restore the shiny luster of teak wood after the natural oils have dried up. It is formulated to be thinner than pure linseed or tung oils so that the wood’s dense grain absorbs it deeply. Rubbing teak oil on your furniture gives the wood a warm, homey glow. Teak oil is best used on indoor furniture because it restores the oiled look of teak wood; it does not protect against moisture or UV rays.\nLike teak oil, a teak protector restores the shine to your wood; it also protects from UV rays. Because its effects last up to four times as long as those of teak oil, teak protector is a highly popular choice for application to indoor furniture, especially pieces that sit in sunny areas.\nSome homeowners choose to apply teak protector to their outdoor furniture; however, it is not the ideal choice for teak furniture exposed to the elements because it does not provide a waterproof finish.\nThe best finish for outdoor teak furniture is, unquestionably, teak sealer. This product provides both a waterproofing finish and protection from UV rays. It is available in a clear-coat formula that highlights the natural luster and grain of the teak wood or in various brown shades that serve as both stain and sealer.\nWhat Is The Best Exterior Clear Coat For Wood?\nAlthough numerous types of exterior clear coats for wood all fall into two basic categories: those that penetrate deep into the wood’s pores and those that form a filmy shell on top of the wood. Penetrating clear coats include oils such as teak, tung, and linseed oil, which provide a natural luster and add strength and moisture resistance to the wood. Clear coating products that form a protective shell include polyurethanes and varnishes. Both of these products provide waterproofing and protection from UV rays.\nThe best clear coat for exterior wood is marine spar varnish, made from linseed oil and alkyd resin. Spar varnish is flexible enough to move with the wood’s expansions and contractions as the outside temperature and humidity fluctuate. It waterproofs the wood and protects it from UV rays.\nThe spar varnish’s initial application is time-consuming, as it should be applied in six to ten thin coats, with plenty of drying time between coats. However, after the first application, it requires only a light sanding and one fresh thin coat annually.\nShould I Cover My Patio Furniture Every Night?\nAs long as you have protected your wood patio furniture from moisture by oiling or sealing it, there is no need to cover it at night. Any dampness that might collect on the furniture overnight will evaporate during the following day. However, you should cover your furniture if you plan to leave it unused for a substantial period of time: several weeks or longer.\nRestoring your weathered outdoor wood furniture adds to its attractiveness and lengthens its lifespan. Whether you use oil, a product that provides UV protection without waterproofing, or a sealer that both waterproofs and protects your furniture from UV rays, you will have a variety of options to choose from. By following the steps outlined above, you can return your furniture to looking like new and keep it attractive and functional for years to come!\nYou may also enjoy:"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:12a908dd-2c46-4f2d-abce-361cae4085aa>","<urn:uuid:c88f7f54-e81a-4f74-9b68-ae5f01c1de65>"],"error":null}
{"question":"How does The Deep facilitate visitor interaction and learning experiences in its facility design?","answer":"The Deep facilitates visitor interaction through a carefully planned layout and multiple dedicated spaces. The four-story structure houses a world-class aquarium exhibition as its main attraction. It includes a Learning Centre for different city groups and the University of Hull's research facility with a Total Environment Simulator. For visitor experience, the design incorporates an innovative flow where visitors take an elevator to the top floor, from where they can access an observation platform via a bridge. This platform extends over the estuary, offering unique views across the River Humber to the Humber bridge. The facility served as a focal point during Hull's UK City of Culture celebrations in 2017, when it displayed projections of Hull's history on its external walls.","context":["The Deep是世界上唯一的Submarium（潜艇水族馆），也是建筑史上以地标建筑成功激活整个城市复兴的代表案例之一，在2002年开业后仅14个月，The Deep就为赫尔这座人口规模25万的城市吸引了100万游客。2017年，赫尔市荣获英国文化之都。The Deep水族馆是当年庆典活动的中心场所，外墙亦作为投影面播放着赫尔城市历史的影片。它是英格兰东北部最著名的地标性建筑，堪称商业上最成功的千禧年项目之一，并被刊印在皇家邮政的邮票上。\nBilled as the world’s only “Submarium”, The Deep is one of the representative cases in the history of architecture where the success of an iconic building has sparked the revival of an entire city. Within just 14 months after opening in 2002, The Deep has been an incredible success. It pulled in one million visitors to Hull, a city with a population of 250,000, which was chosen to be the UK City of Culture in 2017. The Deep was a focal point of celebrations during the same year, displaying a projection of Hull’s history on its external walls. The Deep is a landmark project in the North East of England, which is acknowledged as the most commercially successful Millennial Project and features itself on a Royal Mail stamp!\nThe Deep featured on a Royal Mail stamp©Farrells\nLandmark as part of the regeneration of Hull\n位于东约克郡的赫尔曾是具有悠久工业历史和文化的贸易港口城市，至20世纪末已渐渐衰落。The Deep项目起源于赫尔市的城市文艺复兴计划，场地原是赫尔河 (River Hull) 与亨伯河口 (Humber Estuary) 汇流处三角地端头的2.45公顷废置工地。\nHull in East Yorkshire was once a trading port city with a long industrial history and culture that declined by the end of the 20th century. Located in an abandoned industrial area of 2.45 hectares at the confluence of the River Hull and the Humber Estuary, The Deep project started life as an urban renewal scheme.\nThe site at the confluence of the River Hull and the Humber Estuary©Farrells\nAs the key project of Hull’s urban regeneration, our vision is to create a building with a bold, pioneering image on the waterfront to catalyse major regeneration throughout the city and its region.\nThe particular waterfront landscape of the estuary inspires us to design with waves or glacier-like forms. The four-storey visitor attraction, located at the south-west point of the site as The Deep’s main architectural mass and housing a world-class aquarium exhibition, is therefore designed to be a dramatic icon emerging from the deep water.\nA world-class aquarium exhibition©Farrells\nThe site also houses the Learning Centre for different groups in the city, the Total Environment Simulator and the University of Hull’s research facility. In addition, the building features an observation platform at its pinnacle. Once inside the building, visitors are taken by elevator to the top floor, where you walk through the bridge to the observation platform outside flying over the estuary, enjoying the unrivalled views across the River Humber to the great Humber bridge.\nAn observation platform at the building’s pinnacle©Farrells\nThe aquarium presented as the focal point on the waterfront\nAt the end of the last century, The Deep pioneered a new way of thinking about architectural design on the waterfront with its distinctive shape. The dynamic form has become a focal point at the confluence of the estuary in the broader urban landscape. The Deep is a building that revels in its metaphorical associations with the nature. The exterior is treated as an eroded rock face using organic forms and lines, while irregular recessed strata on the façades provide points of access and openings for windows. The roof plane is treated similarly to the wall surfaces so that the building is read as a three-dimensional object rather than as a series of two-dimensional planes.\nOrganic forms and lines©Farrells\nThe building’s exterior is in different colours and textures, with materials resonating with the waterfront, including coloured concrete, acrylic render, profiled metal, enamelled glass and rhomboid sheets of marine-grade aluminium as used in shipbuilding, which take on different glistening colours according to how to receive the light and reflections. The wave-like contours of the observation platform at the top highlight the geography of the site and the aquatic function of the building.\nMaterials resonating with the waterfront©Farrells\nIrregular recessed strata providing points of access and openings for windows©Farrells\n作为规划建筑师，The Deep水族馆是Farrells里程碑式的作品，充分体现了敏锐的城市视角与“建造实用地标”（Creating landmarks that work） 的设计原则。在特里•法雷尔爵士看来，一个成功的城市更新项目，是可以对整个地区产生一系列正面的连锁反应。The Deep被认为是一个世界级的项目，它填平了深奥学术研究与亲民形象之间的鸿沟，引领了地区的复兴，影响了整个赫尔的经济、社会、文化生活，使这座城市和人民都闻名于世。它已超越了建筑本身，成为一个城市的名片和标志。\nThe Deep Aquarium in Hull marks a milestone among Farrells’ architectural design projects, giving full play to a keen urban perspective and the design principle of “Creating landmarks that work”. As Sir Terry Farrell sees it, one of the great products of urban regeneration is the positive knock-on effect that one development can have on a whole city. The Deep has been cited as a world-class project, which has spearheaded regeneration in the area and has put Hull and its people on the map. In addition, it has greatly supported Hull’s economic, social and cultural development, making the city and its people well-known throughout the world. The Deep has gone beyond the building itself to become the name card and symbol of the city.\n博物馆和遗产卓越奖2003 Museums and Heritage Awards for Excellence 2003\n休闲地产奖2002 Leisure Property Award 2002\n英国皇家建筑师协会白玫瑰奖2002 RIBA White Rose Awards 2002\n公众信誉奖 推荐奖 Civic Trust Awards Commendation\n英国 Enjoy England 大奖 | Access for All Tourism 金奖\nEnjoy England Awards | Access for All Tourism - Gold Award\n英国 Mumsnet 大奖 | 英国最佳水族馆 Mumsnet Awards | Best Aquarium in the UK\n项目名称：The Deep 水族馆\n建筑设计单位：Farrells 法雷尔 （前称TFP, Terry Farrell and Partners）\nProject Name：The Deep Aquarium\nClient：The Millennium Commission\nProject Type：Planning; Architectural Design\nLocation: Hull, UK\nArchitect：Farrells (formerly known as TFP, Terry Farrell and Partners)\nCompletion Year: 2003\nBuilding Area ：24,155 ㎡"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e1043439-da20-4b1e-96e0-51bc0794affd>"],"error":null}
{"question":"How do email security requirements differ between MiFID II and CAN-SPAM Act when it comes to protecting recipient data?","answer":"MiFID II requires sound security mechanisms to guarantee authentication of information transfer, minimize data corruption risk, prevent unauthorized access, and maintain data confidentiality at all times. Additionally, it mandates that communications records must be stored securely for up to seven years with a clear audit trail. In contrast, the CAN-SPAM Act focuses more on sender transparency and recipient rights, requiring accurate header information, valid physical addresses, and opt-out mechanisms, but does not specifically mandate encryption or authentication methods for protecting recipient data.","context":["The CAN-SPAM Act:\nThe CAN-SPAM Act (Controlling the Assault of Non-Solicited Pornography and Marketing Act of 2003) supercedes the various conflicting state laws for the regulation of email. When sending emails you need to make sure you comply with the CAN-SPAM Act of 2003. For more information on the CAN-SPAM Act, go to: https://www.ftc.gov/tips-advice/business-center/guidance/can-spam-act-compliance-guide-business\nWe are completely permission-based. All of our services are in full compliance with CAN SPAM laws. We supply a CAN-SPAM compliance guarantee on all orders. We can help you maintain comprehensive opt-out lists, properly identify and clean bounce-back e-mail addresses, as well as implement and manage permission and frequency rules for your e-mail database.\nNevertheless, the CAN-Spam Act contains requirements that must be met by all mailers regardless of existence of a prior business relationship with the recipient. All companies that send commercial email must:\n• Do Not use subject headings intended to mislead the recipient into opening the message.\n• Use a reply address that will be active for at least thirty days following the transmission of an email message.\n• Include a physical postal address in the body of each message.\n• Include a clear notice that the message being sent is an advertisement or solicitation.\n• Include clear instructions in the body of the message detailing how to opt-out of subsequent mailings\n• Honor all opt-out requests within ten days and not transfer, sell, lease, or exchange the email address of any recipient that has made an opt-out request.\nAll of the above apply to both solicited and unsolicited commercial mailings with one exception. Mail sent to recipients at their consent (opt-in newsletters, alerts, etc…) does not need to contain the disclaimer labeling the message as an advertisement or solicitation. Damages under this Act can be reduced if policies and procedures designed to prevent such violations have been established and implemented, and a violation occurred despite reasonable effort intended to maintain compliance with the aforementioned policies.\nSince most legitimate email marketers honor removal requests and do not send mailings by hijacking open relay servers or write misleading subject lines, the two key issues to address before the New Year are the inclusion of a physical postal address in the message, and the inclusion of a disclaimer identifying the message as a solicitation or advertisement, should one be required.\nInt'l data compile clients or clients' users may not use Int'l data compile system to send unsolicited emails (SPAM) for any purpose commercial or non-commercial. An email will be considered spam if the list member has not specifically granted permission for the list owner to send them email. If your email list is derived from harvesting, purchase (even with the original list owner's permission), or any other means other than direct subscription, any email sent to the list will be considered unsolicited (SPAM).\nInt'l data compile will investigate all complaints of unsolicited email. Int'l data compile reserves the right to suspend or cancel your list hosting service for any email we determine to be unsolicited. It is the list owner's responsibility to keep documentation of all opt-in email subscriptions as proof of request.\nIf you are a list member and feel that you have received unsolicited email, please complete our complaint form.\nDouble Opt-In Policy:\nInt'l data compile requires a double opt-in subscription method for all new list members. A new member shall not receive email from the list until the member receives and replies to a single subscription request from the requested member address. The original subscription request may not contain advertising or information other than the subscription request and list owner contact information.\nAll list messages must contain unsubscribe instructions in the email headers and/or the body or footer of the email message itself. Any member who requests to be removed manually from your list must be removed within 10 business days of the removal request.\nCAN-SPAM Law: A Brief History\nCAN-SPAM Law is a shortened version of the name of Public Law No. 108-187, which was signed into Law by President George W. Bush on December 16, 2003. The full name of the Law and bill was Controlling the Assault of Non-Solicited Pornography And Marketing Act of 2003. Of course, the name was also a play on the fact that unsolicited and unwanted email is typically referred to as \"spam.\" The Law gives the U.S. Federal Trade Commission the right to enforce the standards of the law (which we'll discuss in detail below). You may think, based on the amount of unwanted and unsolicited email that you receive daily, that the Law is not particularly effective. However, as a sender of email, you are still governed by it. If the proper complaints are filed against you and you are found to be in violation of CAN-SPAM Law, then you are subject to large fines. Fortunately, being in compliance of CAN-SPAM Law is quite simply if you follow a few basic rules.\nWhat Type of Email Sending Does CAN-SPAM Law Cover?\nIt's also misleading to think that CAN-SPAM Law only applies to large bulk email sends. CAN-SPAM Law covers all commercial email messages. What does that mean? According to the wording of the Law, it means \"any electronic mail message the primary purpose of which is the commercial advertisement or promotion of a commercial product or service.\" That includes email that promotes content on a commercial website, so if your website makes any money at all and your email links back to it, you are liable under CAN-SPAM Law.\nDo you use email in your business? The CAN-SPAM Act, a law that sets the rules for commercial email, establishes requirements for commercial messages, gives recipients the right to have you stop emailing them, and spells out tough penalties for violations.\nDespite its name, the CAN-SPAM Act doesn’t apply just to bulk email. It covers all commercial messages, which the law defines as “any electronic mail message the primary purpose of which is the commercial advertisement or promotion of a commercial product or service,” including email that promotes content on commercial websites. The law makes no exception for business-to-business email. That means all email – for example, a message to former customers announcing a new product line – must comply with the law.\nEach separate email in violation of the CAN-SPAM Act is subject to penalties of up to $40,654, so non-compliance can be costly. But following the law isn’t complicated. Here’s a rundown of CAN-SPAM’s main requirements:\n1.) Don’t use false or misleading header information. Your “From,” “To,” “Reply-To,” and routing information – including the originating domain name and email address – must be accurate and identify the person or business who initiated the message.\n2.) Don’t use deceptive subject lines. The subject line must accurately reflect the content of the message.\n3.) Identify the message as an ad. The law gives you a lot of leeway in how to do this, but you must disclose clearly and conspicuously that your message is an advertisement.\n4.) Tell recipients where you’re located. Your message must include your valid physical postal address. This can be your current street address, a post office box you’ve registered with the U.S. Postal Service, or a private mailbox you’ve registered with a commercial mail receiving agency established under Postal Service regulations.\n5.) Tell recipients how to opt out of receiving future email from you. Your message must include a clear and conspicuous explanation of how the recipient can opt out of getting email from you in the future. Craft the notice in a way that’s easy for an ordinary person to recognize, read, and understand. Creative use of type size, color, and location can improve clarity. Give a return email address or another easy Internet-based way to allow people to communicate their choice to you. You may create a menu to allow a recipient to opt out of certain types of messages, but you must include the option to stop all commercial messages from you. Make sure your spam filter doesn’t block these opt-out requests.\n6.) Honor opt-out requests promptly. Any opt-out mechanism you offer must be able to process opt-out requests for at least 30 days after you send your message. You must honor a recipient’s opt-out request within 10 business days. You can’t charge a fee, require the recipient to give you any personally identifying information beyond an email address, or make the recipient take any step other than sending a reply email or visiting a single page on an Internet website as a condition for honoring an opt-out request. Once people have told you they don’t want to receive more messages from you, you can’t sell or transfer their email addresses, even in the form of a mailing list. The only exception is that you may transfer the addresses to a company you’ve hired to help you comply with the CAN-SPAM Act.\n7.) Monitor what others are doing on your behalf. The law makes clear that even if you hire another company to handle your email marketing, you can’t contract away your legal responsibility to comply with the law. Both the company whose product is promoted in the message and the company that actually sends the message may be held legally responsible.","Financial Services Email Compliance: The Checklist\nIn the financial services, email compliance is an important part of your company's daily obligation to protect sensitive information.\nEmail was the #1 medium involved in data incidents in the UK according to ICO trend reporting. Are your outbound emails up to spec?\nEmail compliance at a glance\nWith ever-changing guidance and laws surrounding data and communications, maintaining compliance can be a challenge.\nHere's an overview of the latest regulatory guidance that financial services firms should be aware of when it comes to confidential email:\nFCA - SM&CR\n|Put prevention methods in place to stop a breach||\"If a firm breaches one of our requirements, the Senior Manager responsible for that area could be held accountable if they didn’t take reasonable steps to prevent or stop the breach.\"|\n|Encrypt emails containing personal data||\"Have a policy governing encrypted email, including guidelines that enable staff to understand when they should or should not use it. For example, there may be a guideline stating that any email containing sensitive personal data (either in the body or as an unencrypted attachment) should be sent encrypted.\"|\nFCA - COBS\n|Keep auditable copies of outbound emails||\"Keep a copy of relevant electronic communications, made with, sent from or received on equipment: (1) provided by the firm to an employee or contractor; or (2) the use of which by an employee or contractor has been sanctioned or permitted by the firm.\"|\nESMA - MIFID II\n|Authenticate recipients to prevent unauthorised access||“Have sound security mechanisms in place to guarantee the security and authentication of the means of transfer of information, minimise the risk of data corruption and unauthorised access and to prevent information leakage maintaining the confidentiality of the data at all times.”|\nICO - GDPR\n|Have the capability to revoke misfired emails||\"[in the event of a data breach] act quickly. Try to recall the email as soon as possible. If you can’t recall it, contact the person who received it and ask them to delete it. In the future, consider turning off the Autofill tool when sending work emails. The 72 hours following a personal data breach are particularly critical.\"|\nFCA - Consumer Duty\n|Provide customers a secure way to communicate with you||\"Ensure consumers receive communications they can understand, products and services meet their needs and offer fair value, and the support they need.\"|\nAs a core channel for internal and customer comms, it's clear that email must be given specific attention by regulated businesses.\nKey Guidance And Regulation\nAlthough email is a fast and convenient method of transporting documents and other data, unprotected, it leaves data open to many threats.\nMaintaining strong outbound email security standards doesn't just help you to keep the regulators happy. It also helps to ensure your messages, and the sensitive information within them, remain protected.\nLet's take a look at the key pieces of legislation regarding digital communications to understand them in detail, and to learn how they help financial services companies to protect themselves.\n1. The General Data Protection Regulation (GDPR) and The Data Protection Act (The DPA)\nThe GDPR (The General Data Protection Regulation) is a European Union data privacy regime, deployed as law in the UK under the 2018 Data Protection Act (The DPA).\nIt means that anyone responsible responsible for using personal data has to follow strict 'data protection principles'. These principles say personal data must be:\n- Used fairly and lawfully\n- Used for a specific purpose\n- Used only when relevant or necessary\n- Kept up to date and accurate\n- Kept no longer than needed\n- Handled in a secure manner, including protecting it against unauthorised access, processing, loss, destruction, or damage.\nThe DPA was brought in to allow people greater control over their information, giving them ‘rights’ over use of their data, such as the ability to to access it and to delete it, and to have it updated.\nThe FCA (Financial Conduct Authority) has advised the financial services companies it regulates that 'firms must make sure they lawfully process and transfer client data' in line with the GDPR guidance.\nFCA-regulated companies including product providers, intermediaries, and retailers deal with a lot of personal data. Personal data is defined by GDPR as any information relating to an identified or identifiable natural person, including physical, physiological, genetic, mental, economic, cultural and social elements, such as a name, identification number or location data.\nThe FCA's anti-money laundering (AML) and know-your-customer (KYC) guidance ensures that a minimum standard of identification exists for high value transactions on behalf of both businesses and their customers.\nAlthough AML and KYC checks are designed to protect people's privacy, they require again more personal data to be transferred in order to verify a person or business' identity, status, or history.\nIn a hybrid-working world, with so many of us transacting online, the risk of transferring personal data is exacerbated. The FCA advises that regulated financial services companies follow the ICO guidance surrounding sensitive data and communications.\nWhen it comes to email, the GDPR and the DPA leave open-risk inadequate for messages or attachments containing personal data due to its lack of protection against access by unauthorised third parties.\n\"The previous Data Protection Act, passed a generation ago, failed to account for today’s internet and digital technologies, social media and big data. The new Act updates data protection laws in the UK...[and]... provides tools and strengthens rights to allow people to take back control of their personal data.”\n— Elizabeth Denham, Information Commissioner, 2018\nThe Privacy and Electronic Communications Regulations (PECR)\nThe PECR Privacy and Electronic Communications Regulations sits alongside the DPA and GDPR, giving people specific privacy rights relating to electronic communications.\nThe PECR is a UK law, derived from the European e-privacy Directive, and it applies to anyone communicating digitally. It is regulated in the UK by the Information Commissioners Office (The ICO).\nWhile GDPR regulates how you store a person’s data, PECR governs how organisations are allowed to contact them electronically. PECR includes rules on specific aspects, such as:\n- Marketing calls, emails, and texts\n- The use of third-party cookies\n- Keeping communications secure\n- Customer privacy in terms of traffic and location data, itemised billing, line identification, and directory listings.\nIt is important to consider PECR if you plan to or are sending marketing emails. In a nutshell - you cannot send marketing emails to individuals without gaining specific consent first, unless they are either a previous or current customer. You must also give the option to ‘opt out’.\nRegarding confidential information, privacy, and data protection the PECR refers to the GDPR and DPA guidance and legislation.\nMarkets in Financial Instruments Directive (MIFID II)\nMiFID helps the EU regulate financial markets by creating a singular market for investment services and activities.\nIt ensures standardised methods of protection, alongside:\n- Conduct of business and organisational requirements\n- Authorisation requirements for regulated markets\n- Regulatory reporting to avoid market abuse\n- Trade transparency for shares\nMiFID II also requires that all communications regarding financial transactions are recorded and stored for up to seven years.\nThis includes communications channels such as voice and video calls, instant messaging, social media, SMS, and email.\nCommunications records must include an audit trail that is clear, easily accessible, and retrievable. Companies must store data securely and authenticate methods of information transfer.\n“An investment firm shall have sound security mechanisms in place to guarantee the security and authentication of the means of transfer of information, minimise the risk of data corruption and unauthorised access and to prevent information leakage maintaining the confidentiality of the data at all times.”\n— ESMA, 2021\nAs email, without protection, leaves data open to access by anyone, financial services companies must assess what data is getting sent by email, and where a more secure solution is required should provide it.\nThe Consumer Duty (FCA Guidance)\nThe Consumer Duty is designed to regulate interactions with and protect financial services consumers. The Consumer Duty is a mandate for FCA-regulated companies to ensure digital communications are:\nReliable and engaging – In order to enable consumers to make and act on well-informed decisions, reliable communication is key. No matter what communication channel you use, clients should be able to easily reach you, and vice versa.\nResilient and secure – As stated in an FCA consultation paper, \"firms should be able to continue providing a reasonable level of support to their customers in the event of an issue arising with their services, which might include temporary works, an IT outage, or cyber-attack.” This means shifting your mindset to operational improvements that boost your resilience, implementing security measures that ensure your services and communications are protected from risk and remain consistent.\nCompliant – As well as adhering to the new Consumer Duty, communications must also consider existing regulations, especially from the Information Commissioner’s Office (ICO). A large part of this will be ensuring comms are audited, allowing you to prove when and how you have supported and protected your clients.\nThe Consumer Duty says regulated businesses have the responsibility to do everything they can to support their customers to avoid harm and make the right decisions, including securing emails.\nThis also goes beyond other regulations regarding email in a sense, as it means regulated firms should provide their customers with more than just a securely delivered email and attachment.\nFirms should also provide their customers with the support they need to send confidential data into them (especially when completing AML/KYC identification processes) to avoid their data being put at risk.\nWhat Happens if you Don’t Comply?\nBesides the damage to an organisation’s reputation, they may also be fined (in the UK by the either the ICO or the FCA, or both).\nThe UK GDPR and DPA can have a maximum fine of £17.5 million or 4% of annual global turnover – whichever is greater – for infringements.\nThe EU GDPR sets a slightly higher maximum limit at €20 million (£18 million) or 4% of annual global turnover.\nPECR has a maximum figure of £500,000 which can be issued against the organisation itself, or just its directors.\nFinally, failure to comply with MIFID II or The Consumer Duty could result in fines of up to £5 million or a trade ban.\nHow to Remain Compliant: Encryption\nAs GDPR and DPA require businesses to safeguard data from unauthorised access, your outbound communications must have a suitable level of protection, especially email. Article 32 of GDPR lists encryption as a suitable method of protecting personal data.\nEmail encryption is the disguising or scrambling of the contents of your email into code that is unable to be read by human eyes. Content is encrypted and decrypted through the use of keys - strings of randomly generated numbers, with the length correlating to their strength.\nMost email providers have a basic level of encryption built-in, however, it doesn’t provide the level of protection necessary to fully comply with regulations. Therefore, organisations should look at implementing an enterprise encryption solution, considering the following things:\n- Key size and additional authentication\n- Type of encryption - symmetric or asymmetric\n- Type of encryption software - does it integrate?\n- Scalability and business resilience impact\n“You should use encrypted communication channels when transmitting personal data. You should have an encryption policy in place that governs how and when you implement encryption, and you should also train your staff in the use and importance of encryption. When storing or transmitting personal data, you should use encryption and ensure that your encryption solution meets current standards.”\n— ICO, 2021\nHow to Remain Compliant: Authentication and Auditing\nAnother method of ensuring third parties cannot access sensitive information within emails is authentication. When delivering personal data from inbox to inbox, authentication can help businesses to identify recipients before they can read the contents of a message. This eliminates the risk caused by human error and weak passwords.\nMulti-factor authentication is considered best practice, providing multiple levels of identity checks before allowing the recipient access. These checks commonly include SMS, Q&A's and biometrics.\nAs MiFID II legislation requires secure records to be kept, finding an auditing solution that works for email communications is imperative for regulatory compliance. Audit logs can be used to track your messages, checking when emails and attachments were accessed and who by, ensuring only authorised users are reading and downloading the contents.\nHow to Remain Compliant: Additional Actions\nAssign a compliance officer - Having an individual in charge of ensuring your organisation adheres to regulations is the best way to guarantee compliance. They can assess your current scope, assist with implementing a compliance strategy and advise what software and processes to put in place.\nCreate an internal security policy - Having a company-wide policy that everyone adheres to will help protect assets and demonstrates a strong commitment to security and compliance.\nEducate employees - Compliance solutions are only as strong as the people using them. Teach staff of all levels the fundamentals of regulation and security and how to counteract threats.\nAre you protected?\nIs your firm compliant with industry regulations? Use our checklist to understand the current legislation and what processes and technology you can implement to adhere to it.\nOriginally posted on 13 05 22\nLast updated on April 20, 2023\nPosted by: Sabrina McClune\nSabrina McClune is an expert researcher with an MA in Digital Technologies. She was a finalist in the Women In Tech Awards 2022. Sabrina has worked extensively with B2B technology companies conducting and compiling thorough academically driven research to produce online and offline media. She loves to read fantasy novels and collect special edition books.\nGet live updates\nSubscribe to our exclusive secure communications content for professionals in regulated sectors."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:bb886c9e-ce40-4353-9056-155b59c39686>","<urn:uuid:46361471-79e2-4509-983c-dc48b0414288>"],"error":null}
{"question":"What's the difference between planting in trenches for a permaculture garden versus traditional row spacing for vegetables?","answer":"In a permaculture garden system, plants are placed along trenches that are filled with water, with plants growing down the sides to the water mark. The trenches provide water through capillary action once plant roots grow through cardboard layers. In contrast, traditional row gardening follows specific spacing guidelines between both plants and rows - for example, tomatoes need 24-36 inches between plants and 3-4 feet between rows, while lettuce needs 12 inches between head lettuce plants and 12 inches between rows. The permaculture approach focuses on water efficiency, while traditional row spacing emphasizes disease prevention through proper airflow and ease of harvest access.","context":["How to Build a Permaculture Vegetable Garden\n– Tiny Eglington’s method, educator Geoff Lawton\nThis is a photo report of a vegetable garden built for Ann Foster in Condobolin, NSW Australia, which shows basic steps that allow you to build your own permaculture veggie patch.\nYou don’t need much, but you do need:\n- any ruminant manure\n- cardboard (or hessian bags)\n- Lucerne hay (or any acacia leaves)\n- straw (seedless)\n- plants and seed\nThe basic tools:\n- sharp knife/screwdriver (for punching hole in cardboard)\n- hose/watering can\nHow to built a permaculture vegetable garden – the steps\nCheck out the site, discuss possibilities where to set up the garden.\nExplore the present vegetation, and determine its qualities and uses.\nClearing the site of weeds and grass, evaluate locations and levels for the trenches.\nDig trenches (levelled), the soil from the trench is put on the garden beds.\nDig out the trenches a bit more, level the beds. Try and keep the bottom of the\ntrenches level, so they fill evenly with water.\nAdd manure (sheep manure in this case), put it on as thick as you can, don’t\nworry if some falls down in the trenches. Then sprinkle a bit of lime.\nWet the cardboard and place it over the bed, in the trenches as well,\napproximately 3 layers thick.\nAlso hessian (jute) bags work, similar procedure, 1 layer thick.\nCover with Lucerne hay or any acacia leaves, then a layer of straw (seedless).\nCover the trenches with straw as well to minimize evaporation.\nFill the trenches with water (you can check here how you’ve done with\nlevelling, by letting the water in from one point (set up dams) till completely\nfull and decided where your 1 watering point will be. You can put a short\npipe in the top of the dam to overflow into the next trench. Notice\ncapillary rise is working, the water making its way up into the bed.\nGet your plants and seed! Check a companion planting guide for good\ncombinations of plants. I like to check the moon planting guide and practice\nit when possible. Using hybrids or non hybrids is up to you but non hybrids are\nsustainable by collecting your own seed.\nSeparate plants where possible and cut holes in the card board\n(only big enough for the tap root to go through), make a cup in the\nstraw and fill with compost and plant the plants or seed.\nConcerning planting space, consider the size of the plants when they are\nfully grown; the whole bed is covered with vegetables, including down\nthe sides to the water mark. The new plants and seeds have to be watered\nfrom the top (daily in the summer) until the tap root goes through the\nhole, then it will receive its water from the trenches.\nA permaculture vegetable garden can be built at any size. From a few pots to a 1000 acre property.\nAll about building a permaculture vegetable garden and more you learn in a permaculture design course (PDC). And there are loads of information to be found on the web as well!\nHow to Maintain – tips and tricks\nAgain: The new plants and seeds have to be watered from the top until the tap root goes through the hole, then it will receive its water from the trenches. Every area is different (depending on rainfall and soil types). Eg. in Cunnamulla, western Queensland, temperatures were in the high thirties, with no rain, so had to fill the trenches every 7 days.\nIf you cut a cabbage, trim the excess leaves off and chop them up and leave them on the bed (in permaculture terms; chop and drop). Leave the tap root where it is and plant a new plant or seed beside it, the new plant will feed off the old root as it composts.\nNow the important thing: put compost around the new planting as to replace what the cabbage took away. Composting is the key to a sustainable garden.\nWhat you have done\n1. You have created an organic garden that’s water friendly\n2. You have created a weed free garden, which will remain weed free as long as you keep composting (with seed free compost)\n3. And most of all: you have created a sustainable food supply in your backyard\nI was a monoculturalist for many years, this way is much too easy, it’s the GO!","When planting your garden spacing can be one of the hardest things to put into action. Not only do most plants follow different spacing guidelines, but when dealing with tiny seeds or plant starts it can be really easy to underestimate the size and space needed for mature plants.\nBut plant spacing in the garden is very important and how much room you do- or don’t- give your plants can mean the difference between an okay garden and a great one!\nSo let’s explore why garden spacing is so important, what it means, and I’ll even give you a handy vegetable plant spacing chart to help you keep it all straight!\nUltimate Guide to Garden Spacing for Fruits and Vegetables\nWhen it comes to garden spacing it’s not quite as simple as one measurement. There’s actually a lot of gray area when it comes to planting out in your garden. And in this guide I’ll give you the general guidelines for spacing your vegetables and tell you how you can maximize your space- and when you can ignore some of these guidelines altogether!\nWhat Does Spacing Mean?\nSo first off, what do we mean when we say garden spacing? It means 2 things actually:\nThe space between each PLANT.\nThe space between each ROW.\nDepending on the type of gardening you do- row, raised bed, square foot, or other- the recommended spacing may change.\nWhy is Garden Spacing Important?\nAs I mentioned, good spacing in the garden can mean the difference between a great garden, and a not-so-great one. So why is garden spacing so important?\nFirst- and probably one of the most important reasons for good spacing- is that it helps prevent disease and keeps your crops healthier.\nWhen your plants are crowded together they don’t get the airflow they need to dry after a rain or heavy dew. This moisture can lead to fungal infections in your plants, which then affects your harvest and health of the entire garden.\nThings like late blight will be much more devastating if your crops are planted very close together.\nRoom for Roots and Growth\nYour plants will also have enough room to spread their roots and grow to their full potential when there is proper spacing.\nThey won’t be competing for root space, water, soil nutrients, or sun if they have enough space.\nEase of Harvest\nAnd finally, if you’ve ever tried to harvest in a garden that is crowded you know how hard it can be! It’s like a jungle and you end up stepping on plants and vines or missing ripe fruits because you just can’t access the plants easily.\nProper spacing makes it easier to reach all places in the garden, which means an easier time for you and no lost fruits!\nVegetable Plant Spacing Chart:\nSo what are the most commonly recommended vegetable plant spacing guidelines?\nUse the following chart to help you correctly space the plants in your garden. Please note that if you are using raised beds (which are normally 4ft or less wide), then you won’t have to worry about the row spacing, only the space between crops.\nAnd keep reading below for ways to maximize space and when you can get away with planting a little closer!\n|Crop:||Spacing Between Crops||Spacing Between Rows|\n|Amaranth||1-2 ft||1-2 ft|\n|Arugula||3-4 inches||1-1.5 ft|\n|Asparagus||12-18 inches||2-3 ft|\n|Basil||12 inches||1.5-2 ft|\n|Beans||2-6 inches||2 ft|\n|Beets||3-4 inches||1-1.5 ft|\n|Broccoli||12-18 inches||3 ft|\n|Brussels Sprouts||24 inches||2-3 ft|\n|Cabbage||9-12 inches||2-3 ft|\n|Carrots||1-2 inches||12 inches|\n|Cauliflower||18-24 inches||2-3 ft|\n|Celery||12-18 inches||2 ft|\n|Chard||6-12 inches||12-18 inches|\n|Corn||12 inches||3 ft|\n|Cucumber||12-24 inches||2 ft|\n|Eggplant||18-24 inches||3 ft|\n|Garlic||3-6 inches||12-18 inches|\n|Kale||12-18 inches||2 ft|\n|Kohlrabi||6 inches||12 inches|\n|Leek||4-6 inches||12 inches|\n|Lettuce- head||12 inches||12 inches|\n|Lettuce– leaf||2-3 inches||6-12 inches|\n|Melons||12-24 inches||4-6 ft|\n|Okra||12 inches||3 ft|\n|Onion||4-6 inches||12 inches|\n|Peas||2-3 inches||2 ft|\n|Peppers||12-18 inches||2 ft|\n|Potatoes||12 inches||2-3 ft|\n|Radish||1-4 inches||6 inches|\n|Spinach||2-3 inches||12-18 inches|\n|Summer Squash||24 inches||3-4 ft|\n|Sweet Potatoes||12-18 inches||3-4 ft|\n|Tomatillos||24-36 inches||3-4 ft|\n|Tomatoes||24-36 inches||3-4 ft|\n|Turnips||2-4 inches||12 inches|\n|Winter Squash||24-36 inches||3-5 ft|\nHow to Increase Space in the Garden\nSo now that you know the average garden plant spacing guidelines, let’s talk about when they might now apply and how you can get more out of your garden space.\nFirst up is growing vertically. Using things like stakes, trellises, and fencing can help you maximize your space by using the vertical space instead of the horizontal space.\nThis frees up soil space for growing smaller crops below or spacing the next row closer.\nVertical gardening is most beneficial for vining crops such as cucumbers, winter squash and peas.\nRead my article on Vertical Gardening for more information.\nIf you have a traditional row garden, try planting double rows instead of single. Plant 2 rows of the same crop close together with a larger space between each double rows.\nThis works great because you can still easily harvest both sides of the double rows without stepping on your crops.\nDouble rows work great for things like beans, radishes, carrots, and other root crops.\nPruning can also help you keep your crops more manageable and help them to take up less space per plant.\nTomatoes especially can benefit from pruning. By removing the suckers and leaving just one main stem you can reduce the overall footprint of each plant by a lot.\nPinching growing tips off of melon, cucumber, or squash vines can also help keep them from taking over more space than you want.\nThere’s a ton of varieties out there that are meant for smaller gardens. Choose a compact, bush variety of squash instead of a sprawling one.\nChoose determinate tomatoes over indeterminate.\nSee if you can find dwarf varieties of your favorite crops.\nSquare Foot Gardening\nAnd finally, square foot gardening. With square foot gardening you can basically throw all general recommendations out the window because it has it’s own rules and recommendations for spacing.\nSquare foot gardening is much more intensive and crops are grown more closely together compared to raised bed or row gardens.\nMore Gardening Help:"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:c5a27e38-2a4e-4ffc-803f-41656eb547d3>","<urn:uuid:505865dd-cae7-4534-b76d-eb6dfe340c19>"],"error":null}
{"question":"What research expertise does the University of Leeds have in sustainable cement technology, and how is this knowledge being applied to reduce environmental impact through co-processing in the cement industry?","answer":"The University of Leeds has expertise in sustainable cement technology through Professor Susan Bernal's research on traditional and alternative cements, waste management and valorisation. Her work includes developing bespoke cements like geopolymers and alkali-activated materials for waste management. This academic expertise aligns with industry applications, as the cement sector has become a major part of the circular economy through co-processing - using non-recyclable waste as both alternative fuel and raw material replacement. Companies like LafargeHolcim have achieved up to 95% substitution of fossil fuels with waste in some European plants, while also using 30% recycled waste materials in cement production.","context":["Prof. Susan A Bernal\n- Position: Professor in Structural Materials\n- Areas of expertise: Traditional and alternative cements; cement materials characterisation; wastes management and valorisation; durability of cement and concrete\n- Email: S.A.BernalLopez@leeds.ac.uk\n- Location: Civil Engineering Building, room 1.11\n- Website: LinkedIn | Googlescholar | Researchgate | ORCID\nSusan holds the Chair in Structural Materials in the School of Civil Engineering at University of Leeds, and a prestigious EPSRC Early Career Fellowship in Multi-scale Engineering of Sustainable Concretes. Previously she was University Academic Fellow in Cementitious Materials at Leeds (2018-2019), and Research Fellow in Cements in the world leading NucleUS Immobilisation Science Laboratory in Department of Materials Science and Engineering at The University of Sheffield (2012-2018). During that period she also held a one year appointment (2015-2016) as Lecturer in Concrete Technology in the Civil and Structural Engineering Department of this University. Prior to this, she was a Postdoctoral fellow (2009-2010) with Professor Jørgen Skibsted in the iNANO Instrument Center for Solid-State NMR Spectroscopy, Chemistry Department at Aarhus University, Denmark, and she then undertook a Research Fellow position (2010-2012) focusing on durability assessment of alkali-activated concretes, with Professor Jannie van Deventer and Professor John Provis in the Chemical Engineering Department at the University of Melbourne, Australia.\n- Recipient of the 2020 IOM3 Rosenhain Medal and Prize for distinguished achievements in any branch of materials science – read more here\n- Recipients of one of the 2018 ICE Advances in Cement Research Prize (Best paper in the journal) - see paper here\n- Recipient of one of the two 2016 RILEM Gustavo Colonnetti medals for outstanding scientific contributions to the field of construction materials and structures\n- Recipient of one of the 2016 Distinguished Graduate Awards, Faculty of Engineering, Universidad del Valle, Colombia, in recognition of outstanding scientific contributions promoting regional development.\n- Recipient of one of the Walter Mangold Trust Fund scholarship for studies in Australia, 2008. The programme provided funding for a 1-year occupational trainee position in The Department of Chemical and Biomolecular Engineering at The University of Melbourne, Australia.\n- Recipient of a COLCIENCIAS DEng Scholarship, 2005: Enhancement of Colombian Scientific Community through National Doctorate Programmes. (Fortalecimiento de la comunidad científica a través del programa de doctorados nacionales, Créditos condonables COLCIENCIAS).\n- Deputy-Chair of the RILEM technical committee TC 281 – CCC: Carbonation of concrete with supplementary cementitious materials, since 2017.\n- Member of the RILEM technical committee TC MPA: Mechanical properties of alkali-activated concretes, since 2019.\n- Member of the RILEM technical committee TC 283 – CAM: Chloride transport in alkali-activated materials, since 2018.\n- Member of the RILEM technical committee TC 282 – CCL: Calcined clays as supplementary cementitious materials, since 2018.\n- Member of the RILEM technical committee TC 267-TRM: Tests for reactivity of supplementary cementitious materials, since 2015.\n- Member of the RILEM technical committee TC 247-DTA: Durability testing of alkali-activated materials, since 2013-2018.\n- Member of the RILEM technical committee TC 238-SCM: Hydration and microstructure of concrete with supplementary cementitious materials, 2012-2015.\n- Member of the RILEM Technical committee TC 224-AAM: Alkali-activated materials, 2011-2012.\n- Reviewer for more than 50 international journals (in both Spanish and English) in the areas of materials science and engineering of infrastructure materials, cement and concrete chemistry and performance, nuclear waste management, and sustainability.\nCommisions of trust\n- Materials and Structures Group Director, School of Civil Engineering, University of Leeds. Since 2020\n- Member of the Management Committee of the Bragg Centre for Materials Research at University of Leeds. Since 2019\n- Member of the EPSRC Peer Review College. Since 2019\n- Associate Editor, Materials – Open Access Journal of Materials Science. Since 2018\n- Associate Editor, RILEM Technical Letters. Since 2016\n- Editorial Advisory Panel member, Proceedings of the Institute of Civil Engineers (ICE) Construction Materials. 2016 – 2020.\n- 2021 – 2024. UKRI Interdisciplinary Circular Economy Centre For Mineral-based Construction Materials. EPSRC grant (EP/V011820/1). U. Leeds investigators: L. Black, O. Iuorio, C. Velis & S.A. Bernal; in collaboration with colleagues from UCL, Loughborough U., Imperial College London, Lancaster U. & U. Sheffield.\n- 2021 – 2023. Transforming Foundation Industries – A Network plus towards value by innovation. EPSRC / ISCF grant (EP/V026402/1). Investigator: I. Reaney (U. Sheffield, Director), S.A. Bernal (U. Leeds, Co-Director), W. Sampson (U. Manchester) and C. Preydell-Pearce (Swansea U.)\n- 2021 – 2022. Enhancing analytical capabilities in soils for low-carbon technologies. White Rose Collaboration Fund. Investigators U. Leeds: A. Marsh (PI), H. Freeman, A. Brown; V. Leadley; S.A. Bernal; U. Sheffield: B. Walkley (Co-PI), M. Stennett, N. Hyatt; U. York: M. Hodson (Co-PI), R. Mills.\n- 2020 – 2022. WISE: Maximising waste resources utilisation in future infrastructure development. Royal Society – International Exchanges Cost Share (Argentina). UK Investigators: S.A. Bernal (UK-PI), L. Black, S. Adu-Amankwah, A. Marsh, J.P Gevaudan; Argentina Inverstigators: Y.A. Villagran-Zaccardi (Argentina PI), M.A. Sosa, C. Pico Cortes, L. Masselli\n- 2020 – 2023. CMMI-EPSRC RENACEM: Response to CO2 exposure of concrete with natural supplementary cementitious materials. NSF-EPSRC Lead Agency grant (EP/T008407/1 and 1903457). UK Investigators: S.A. Bernal (UK-PI), J.L. Provis, L. Black & P.A.M. Basheer; US Investigators: M. Juenger (US-PI) & L. Katz\n- 2019 - 2022. Design-for-manufacture of 3D concrete printed structural composites (DfM:3DCP). EPSRC grant (EP/S019650/1). Investigators: L. Susmel, R. de Borst, J.P. Provis & S.A. Bernal\n- 2019 - 2021. PERFoRM. Passive layer failure mechanisms for steel embedded in alkali-activated slag materials. Marie Sklodowska-Curie Individual Fellowship. Investigators: J.P. Gevaudan (Fellow), S.A. Bernal & P.A.M. Basheer (Supervisors)\n- 2019 – 2021. NOVA-VIDA: Novel approach for vital infrastructure post-disaster. British Academy – Infrastructure for wellbeing grant. Investigators: O. Iuorio, M. Janoschka, R. Romano & S.A. Bernal\n- 2018 - 2023. Multicale engineering of alkali-activated concretes for sustainable infrastructure. EPSRC Early Career Fellowship (EP/R001642/1). Investigator: S.A. Bernal\n- 2016 - 2019. Predicting long-term performance of cement disposal systems for radionuclide-loaded zeolite and titanate ion exchangers. EPSRC-MEXT grant within the scope of Phase 3 of the UK-Japan Civil Nuclear Research Programme (EP/P013171/1). Investigators: J.L. Provis, H. Kinoshita, S.A. Bernal.\n- 2016. REFURB. Resource futures for sustainable urbanisation. The University of Sheffield/ EPSRC GCRF (seeding fund). Investigators: S.A. Bernal, S. Marvin, M. Mayfield, D. Densley-Tingley, P. Styring, S. Schindler & A. While.\n- 2016-2019. Immobilisation of problematic wastes in geopolymer. Nuclear Decommissioning Authority (NDA) Bursary. Investigators: D. Geddes (PhD researcher), J.L. Provis & S.A. Bernal.\n- 2016. Novel lightweight plaques and panels based on geopolymer composites. The University of Sheffield IIKE funding. Knowledge exchange project in collaboration with Suministros de Colombia S.A (SUMICOL). Investigators: J.L. Provis, S.A. Bernal, M. Bach.\n- 2015. WASTECEM. Wastes as resources for producing eco-efficient cements. Newton Fund Fellowship (Brazil-UK), Royal Academy of Engineering. Investigators: J.L Provis, S.A. Bernal, E.D. Rodriguez & A.P. Kirchheim.\n- 2014-2017. Rational design of low-CO2 alkali-activated concretes for eco-efficiency and durability. EPSRC-NSFC grant for collaborative research between UK and China on Sustainable Materials for Infrastructure (EP/M003272/1). Investigators: J.L Provis, S.A. Bernal, M. Basheer, M. Soutsos, & S. Nanukuttan.\n- 2013. Bulk use of biomass and co-fired ash in novel binders. NERC catalyst grant (NE/K015680/1). Investigators: A. Heath, J.L. Provis, S.A. Bernal, H. Kinoshita, K.A. Paine, R.J. Ball, M.C. McManus.\nSusan and her team research centres on novel cements and concretes, particularly focusing on waste management and valorisation, multi-scale infrastructure materials characterisation, durability assessment, and improving sustainability of novel cement and concrete technologies. Specifically Susan focuses on:\n(i) Development, characterisation and exploitation of advanced and non-traditional cement and cement and concrete technologies, including:\n- Design of bespoke cements including geopolymers and alkali-activated materials for waste management and/or valorisation.\n- Determining the factors controlling phase assemblage evolution and stability of non-Portland cements, including application of thermodynamic modelling.\n- Mechanisms leading to structural modifications of Portland and non-Portland cements exposed to aggressive environments, emphasising chemical/physical binding of anions/cations and structural phase transformations.\n- Validation of testing methods for physicochemical characterisation of supplementary cementitious materials\n- Development and validation of standardised testing methods to determine performance of alkali-activated materials\n(ii) Evaluation of fit-for-purpose cementitious wasteforms for immobilisation of nuclear wastes, including:\n- Chemical/physical binding mechanisms of radionuclides in cements with different chemistries\n- Phase assemblage evolution and stability of Portland and non-Portland based cementitious wasteforms\n- Effect of radiation in cementitious systems\nCurrent team members\n- Rutendo Rusike (UG Laidlaw Scholar\n- Yuyan Huang (PhD researcher)\n- Thomas Hutchinson (EPSRC CDT GREEN PhD researcher)\n- Moro Sabtiwu (EPSRC CASE PhD researcher – Highways England)\n- Zengliang Yue (PhD researcher)\n- Heng Song (PhD researcher, co-supervised by Dr. Gehan Selim)\n- Dr Alastair Marsh (Research Fellow in Alkali-Activated Materials)\n- Dr Juan Pablo Gevaudan (Marie Sklodowska-Curie Individual Fellow in Corrosion of Steel in Alkali-Activated Materials)\n- Dr James Vigor (Research Fellow in Advanced Cementitious Materials Characterisation)\n- Dr Yuvaraj Dhandapani (Research Fellow in Durability of Cement and Concrete Materials)\nFormer team members\n- 2019 – 20 - Luke Atkinson (MSc)\n- 2019 – 20 - Moosa Awad (MSc)\n- 2019 – 20 – Dr Tao Yang (Visiting Research Fellow)\n- 2019 – 20 - Xiaowen Zhang (Visiting PhD researcher)\n- 2018 – 19 - Kate Button (MEng)\n- Doctor in Engineering, emphasis in Materials Engineering (Cum Laude) Universidad del Valle, Colombia\n- Materials Engineer (Cum Laude), Universidad del Valle, Colombia\n- Fellow of the Institute of Materials, Minerals and Mining, IOM3\n- Senior Member of International Union of Laboratories and Experts in Construction Materials, Systems and Structures, RILEM\n- CIVE5452 – Cement and Concrete Properties\nCurrent postgraduate researchers\n<li><a href=\"//phd.leeds.ac.uk/project/825-formation-mechanisms-of-corrosion-resistant-oxide-films-in-steel-reinforced-low-carbon-concretes\">Formation mechanisms of corrosion-resistant oxide films in steel reinforced low-carbon concretes</a></li>","With the environmental impact of raw materials used in the construction industry attracting increasing scrutiny, sustainable solutions are needed.\nThe construction sector is entering a challenging yet exciting time. Demand for new homes and infrastructure means that materials such as cement are needed now more than ever.\n“Co-processing of waste in cement kilns is a circular approach that generates multiple environmental, social and economic benefits.” - Thomas Guillot, Geocycle Europe\nAt the same time, environmental concerns mean that construction – which has traditionally relied on fossil fuels and vital raw materials – is under pressure to ensure the sector uses materials in a way that is environmentally friendly, not only to comply with regulatory requirements but also to exceed consumer expectations.\nFor this reason, the sector has become a major part of the circular economy through its adoption of co-processing – the use of non-recyclable waste as both an alternative fuel source and as a replacement for raw materials.\nThe potential for co-processing\nA recent study conducted by CEMBUREAU / Ecofys shows that co-processing of waste in cement kilns is already being widely employed across the EU, but that the potential for further uptake remains large.\nIncreased co-processing rates across the member states can further contribute to overcoming challenges such as climate change, waste management and fossil fuel depletion, while utilising the principles of the circular economy.\nThere is no technical limitation at cement plants preventing an increase in the share of alternative fuels from 44% now to 60% across the EU, apart from the general challenges of implementing the circular economy at an industrial scale. If this can be achieved, it could save expenditures in additional waste-to-energy plants of up to €12.2 billion and avoid emissions of 26 million tonnes of CO2 per year.\nCo-processing: a closer look\nTypically, within the cement production process, cement kilns use a mixture of fuels such as coal, oil and natural gas to create the high temperatures needed.\nThis is where co-processing comes in, says Thomas Guillot, head of Geocycle Europe, who explains how a number of alternative materials can be used as a fuel instead.\n“In Europe, cement kilns treat municipal solid waste, used tyres, sewage sludge, waste oils, contaminated soils, construction and demolition waste or plastics,” he says.\nPart of the LafargeHolcim group, Geocycle has led the way on the co-processing of waste materials within the industry. The group collects industrial or municipal waste and co-processes or reuses it in LafargeHolcim cement plants.\n“In Europe, cement kilns treat municipal solid waste, used tyres, sewage sludge, waste oils, contaminated soils, construction and demolition waste or plastics” - Thomas Guillot, Geocycle Europe\nGeocycle has over 180 cement plants with dedicated co-processing installations and is investing and partnering in the sector across Europe.\nGuillot says: “Co-processing of waste in cement kilns is a circular approach that generates multiple environmental, social and economic benefits.”\nHe adds that it “optimises the use of waste by recycling the mineral part and by recovering the energy part”, offering alternatives to landfill or incineration, while being energy efficient.\nThis point is echoed by other experts in the field, including in the Technological Education Institute of Piraeus and Columbia University collaborative research paper 'Use of alternative fuels in cement industry', which says that co-processing offers “a safe and sound solution for society, the environment and the cement industry, by substituting non-renewable resources with societal waste under strictly controlled conditions”.\nAlternative fuels from waste\nLooking at specific examples of co-processing in action, the results speak for themselves.\nAt LafargeHolcim, several plants across Europe substitute a staggering 95% of their fossil fuels with waste, while 30% of their mineral resources in cement production are recycled waste from sectors such as construction and demolition – which is itself responsible for 32% of the total waste generated in Europe.\nElsewhere, at the Retznei cement plant in Austria, Geocycle has constructed a recycling centre that means 12% of the raw materials used to produce the cement at this site comes from re-used waste.\nThis has resulted in 100,000 tonnes of construction and demolition waste being reused every year and has seen Retznei become one the top performers worldwide for substituting thermal energy with alternative fuel.\nAt LafargeHolcim, several plants across Europe substitute a staggering 95% of their fossil fuels with waste\nBuilding materials supplier, Hanson UK, meanwhile, has halved the amount of waste sent to landfill in the past 12 months by reusing and recycling more than 100,000 tonnes of controlled waste in the production of cement.\nSimilar approaches can be seen across the world in countries such as India, which has mounting environmental pressures around waste management.\nIn the southern Indian city of Thiruvananthapuram, solid waste materials, such as plastic and old mattresses, are being used as alternative fuel sources within the cement industry – a solution which could save money and reduce carbon dioxide emissions.\nCreating innovative materials and aggregates\nFurther innovation is taking place across the sector to make use of non-recyclable products within the material itself.\nMicroalgae-products, which are used in the cosmetic industry, have been employed as an alternative to agricultural oils.\nBruno Bujoli, director of research at CNRS (Centre National de la Recherche Scientifique), who was involved in developing the technology, recently spoke of the potential environmental benefits.\nHe told the Guardian: “The benefits of microalgae over other sources include low competition for arable land, high per hectare biomass yields and large harvesting turnovers.”\nSuch advancements hold exciting possibilities for the future of the wider construction materials sector.\nThe industry is also testing the use of certain plastics as a replacement for aggregate within concrete mixtures, which could have huge environmental benefits. Some 300 million tonnes of plastic are produced globally each year, according to research by Plastic Oceans.\nTarmac, a CRH company, is working with Carbon 8 – a carbon negative aggregate manufacturer – on several incinerator projects in the UK. Here lime is supplied, spent lime is reprocessed using CO2 and resulting product used as an aggregate in building blocks.\nWhile co-pressing presents a string of exciting possibilities, both in environmental terms and for cement production as a whole, it’s not without its challenges.\nAs Guillot notes: “The sector is still facing local acceptance when implementing circular economy approaches such as co-processing of waste, which is a safe waste treatment solution.”\nIt is vital, then, that the sector continues to champion innovative approaches to take the public on this journey with them, to ensure the industry can grow sustainably in the years ahead."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:1f8c9d38-bfdb-46b8-84d8-c782dcc07aa8>","<urn:uuid:912a8e51-1261-4a9f-a0cb-84e053705a25>"],"error":null}
{"question":"Do two-parent households show more stability than other family types, and what role does violence play in segregated communities?","answer":"Yes, two-parent households demonstrate greater stability, with 9 out of 15 studied two-parent families showing no changes in household composition over time. These stable two-parent households are characterized by consistent adult employment and strong knowledge of their children's social circles. Regarding violence, it plays a significant role in segregated communities - urban segregation enables whites to cluster in neighborhoods that are insulated from violence, while simultaneously exposing blacks and Latinos to increased violent crime as segregation levels rise. This exposure to violence powerfully affects children and shapes their academic trajectories.","context":["Research Finds Latino Segregation Associated with Diminished Social and Economic Outcomes\nLatinos seem to be inheriting the segregated urban structures experienced by African Americans and, to a similar extent, the diminished social and economic outcomes associated with segregation, a new NYU Furman Center report finds.\nThe brief, Black and Latino Segregation and Socioeconomic Outcomes (PDF), by Ingrid Gould Ellen, Jorge de la Roca, and Justin Steil, which was released today by the NYU Furman Center, examines the relationships between metropolitan segregation levels and socioeconomic outcomes for Latinos and African Americans and explores mechanisms to explain these relationships. The brief summarizes the findings of Desvinculado y Desigual: Is Segregation Harmful to Latinos? (PDF), an academic article recently published in the July 2015 edition of The Annals of the American Academy of Political and Social Science.\nThe research finds that racial gaps in educational and labor market outcomes are significantly wider in U.S. metropolitan areas with higher levels of residential segregation. In more segregated metropolitan areas, both native-born Latinos and African Americans are significantly less likely compared with whites to graduate from high school and college, and are more likely than whites to be neither working nor in school. Additionally, higher levels of segregation are associated with dramatic reductions in earnings for both African Americans and Latinos relative to whites.\nThe report identifies disparities in neighborhood structures that help to explain the findings. The authors find that racial gaps in neighborhood human capital, access to public services (including public schools), and exposure to neighborhood violence are all wider in more segregated metropolitan areas.\nKey findings include:\n1. In cities across the country, whites consistently exhibit better socioeconomic outcomes than native-born Latinos and blacks, including:\n- High School Graduation: In segregated metropolitan areas, native-born Latinos and native-born African Americans are significantly less likely than whites to graduate from high school.\n- College Graduation: Native-born Latinos and native-born African Americans in segregated metropolitan areas are less likely than whites to complete college.\n- Idleness (neither working nor in school): Native-born Latinos and native-born African Americans in segregated metropolitan areas are more likely than whites to be neither working nor in school.\n- Earnings: Higher levels of segregation are associated with dramatic reductions in earnings for both African Americans and Latinos relative to whites.\n2. Place-based mechanisms can help explain the patterns leading to disparities in socioeconomic outcomes associated with segregation:\n- Neighborhood Human Capital: Exposure to more educated neighbors can help shape young people’s exposure to role models and access to social networks that facilitate social and economic advancement.\n- Public Services: Racial gaps in the exposure to school proficiency increase consistently with segregation, indicating that school quality may be an important mechanism through which segregation operates.\n- Violence: Exposure to violence powerfully affects children and shapes their academic trajectories. Urban segregation both enables whites to cluster in neighborhoods that are insulated from violence, and exposes blacks and Latinos to violent crime as segregation levels increase.\nFor more on this topic, see:\nThe Dream Revisited: A slow debate on the causes and consequences of racial and economic segregation in neighborhoods and schools.\nWorking Paper: Desvinculado y Desigual: Is Segregation Harmful to Latinos? (PDF), also published in the July 2015 edition of The Annals of the American Academy of Political and Social Science","Presentation on theme: \"Catherine Haggerty Kate Bachtell Nola du Toit Ned English Housing Composition and Child Wellbeing: Constructing Narratives to Inform a Research Agenda.\"— Presentation transcript:\nCatherine Haggerty Kate Bachtell Nola du Toit Ned English Housing Composition and Child Wellbeing: Constructing Narratives to Inform a Research Agenda\n2 Introduction to Session Long, ongoing process of discovery Using Making Connections Survey data Research interests Low income families Child wellbeing\n3 Introduction to Session Outline of Session Overview of Making Connections Survey Brief presentation of previous findings Discuss current project Explore future research ideas\n4 Making Connections Survey Annie E. Casey Foundation Evaluation of community initiatives Low income households 10 sites Longitudinal Baseline 2002-2004 Wave 2 2005-2007 Wave 3 2008-2011\n5 Making Connections Survey Information on variety of topics People in household, age, gender, employment Relationships to respondent and focal child Children Economic wellbeing Services and amenities Family hardship Neighborhood connections Linking individuals over time\n6 Current Literature Household structure and wellbeing of children Economic measures (poverty, material hardship) Family structure matters for child wellbeing Single v. cohabiting v. married Instability matters for child wellbeing Union formation or dissolution\n7 Problems with Current Research Focus on parents and relationships of parents Ignores diversity of different family types Especially among low income households Does not depict reality of children’s lives Changes in household occupants; multitude of people coming and going\n10 Our Previous Research Coming and Going: The Effect of Household Composition on the Economic Wellbeing of Families and Children\n11 Previous Research: Research Questions Are there different types of household composition beyond the traditional? Do complex household compositions matter? Is there change in these complex household compositions over time? Does this change matter? Are some households more affected by change than others?\n12 Previous Research Focus Variable: Household Type Relationship of adult (18+) to focus child Typology Single parents Two parents Parent and grandparent only Parent and any combination Non-parent households\n13 Previous Research Dependent Variables: Economic Measures Income Per Capita Household income/number of people in household (log) Public Assistance Usage (none/any) Food stamps, rent subsidies, section 8, public housing Economic hardship (none/any) No money for food, not pay rent, phone cut off, not fill prescriptions Home Ownership (not own/own) Owned by someone in household\n14 Previous Research Dependent Variables: Instability Change in household type e.g. Two parent -> parent and grandparent only Decrease in income per capita Same or less than at Wave 2 Increase in public assistance usage Increase in economic hardship Decrease in home ownership\n15 Previous Research: Findings Are there different types of household composition beyond the traditional? Do complex household compositions matter? Is there change in these complex household compositions over time? Does this change matter? Are some households more affected by change than others?\n16 Previous Research: Findings Are there different types of household composition beyond the traditional? YES! Do complex household compositions matter? YES! Is there change in these complex household compositions over time? YES! Does this change matter? YES! Are some households more affected by change than others? YES!\n17 TYPES OF RELATIONSHIP OF ADULTS TO CHILDREN UNWEIGHTED FREQUENCY WEIGHTED % Total1964100% Husband/wife1<1% Parent180090% Extended family19412% Sibling21212% Grandparent33322% Non-related119 6% Previous Research: Findings\n18 Previous Research: Findings TYPES OF HOUSEHOLDS AT WAVE 2 UNWEIGHTED FREQUENCY WEIGHTED % Total1964100% Single parents only53521% Two parents only65234% Parent and grandparent only16610% Parent and any other combination44725% Non-parent households16410%\n22 Summary of Previous Research Findings Many more types of households than accounted for in current research 10% are non-parent households Many people coming and going Mixed results – no pattern Introduction of another adult for single parent households is not a good idea Need more research on non-traditional households\n23 Previous Research: Limitations Examined only economic measures Need in-depth look at different types of families Typologies of families too narrow\n24 Our Current Research Housing Composition and Child Wellbeing: Constructing Narratives to Inform a Research Agenda\n25 Current Study Case studies of randomly selected households Provide in-depth understanding Acknowledge “messiness” of real lives\n26 Research Questions What are the characteristics of these households? How much instability is really present? What are the moving parts? What is gained or lost by having additional people in the home?\n27 Data for this Research 3 waves of data 6 sites Household adult and child roster, linked personal identifiers, household and child data Limited set of comments and open-ended responses Iterative process Sample selection Same respondent in all 3 waves Same focal child in Waves 2 and 3 Determination of household type required n=230\n28 Selection for Narratives Typologies at Wave 2 1.Single parent 2.Two parent only (contrast group) 3.Extended family (vertical and horizontal) 4.Non-parent families Random sample of 15 for each typology Non-parent only had 15 cases n=60\n29 Focus Area: Family Instability Family instability and disruption People coming and going Adults Children Relationships to the focal child Child welfare Anyone in home been in prison\n30 Focus Area: Family Hardship Income and change in income Employment and ratio of employed adults to number of people Economic hardship Trouble paying bills, no money for food, delaying/not filling prescriptions, phone cut off Home ownership, renting, etc.\n31 Focus Area: Public Assistance Public assistance Food stamps Housing Income from assistance\n32 Focus Area: Social Integration Formal Speak to religious leader, politician, or neighbors about neighborhood problem; volunteer in community or serve on local committee Informal Attend local religious services or neighborhood get-togethers; get non-financial help from friends/family in neighborhood Services and amenities Use library, recreational center, counseling services, park, community college Social network outside of neighborhood Send remittances, get non-financial help from family and friends outside neighborhood\n33 Focus Area: Neighborhood Reasons for moving from past and to current address Disorder Graffiti, drugs dealers, prostitution, litter, etc. Safety Neighborhood is good for raising children Feel safe at night, crime committed by outsiders, etc. Social Cohesion Neighbors can be trusted, share same values, willing to help others, etc.\n34 Narrative Process: Why By reducing individuals to a set of social variables, “Social actors are treated as if they had little or no individual history, no feelings or ambivalences, no self- knowledge – in short, no individuality.” Maynes et al (2008, 16)\n35 Narrative Process: How 1.Examined data for each household over time 2.Developed worksheet Focus on 7 areas of interest: family stability, family disruption, social support, public assistance, family hardship, family economics, attitudes about neighborhood 3.Constructed narrative for each household 4.Reviewed narratives across household types\n36 Insert Presentation Title and Any Confidentiality Information Worksheet\n37 Narrative Example 21116090, Des Moines, Hispanic (“South American”), U.S.-born, Penacostal This is a female-headed household that got bigger over time. In wave 1 we found just the respondent, a single working mom, with one child, age 7. In wave 2 the respondent had become a grandmother and her adult daughter, age 24, had moved in. Both were employed. A new focal child was selected in wave 2, age 4, and that was the child of the adult daughter. The daughter also had a 6-year-old living in the household. This meant that the respondent had one child and two grandchildren living in the home. At wave 3 the children stayed the same, but another adult daughter came to live with them. She was 27 and the aunt of the focus child, now age 7. All the children are boys. The respondent has a GED. In wave 1 (when she was the only adult in the HH) she indicated that she had been with her employer for 3 years and that household income was between $10,000 and $14,999. She said that she did not have a checking account because “I deal with cash.” In waves 2 and 3 the household income stayed around $30,000 despite the addition of the two working adult daughters. The family received food stamps in waves 1 and 2 but not 3. They reported economic hardships in all three waves, with at least one instance in three of the four categories (prescriptions, monthly bills, food).\n38 Limitations 1.Not representative of “typical” low income family in the U.S. 2.Relied mainly on fixed numerical data 3.Cannot answer “why” questions 4.Narratives are subjective\n39 Managing Limitations Teamwork! Developed tools collaboratively Discussed findings (repeatedly) Forthcoming about holes in data Avoiding speculation Monitoring subjectivity\n40 Findings: Two Parent Families Characteristics: Mostly non-Hispanic White or Black Two subgroups: No change in composition (9 out of 15) Change in composition (6 out of 15)\n41 Findings: Two Parent Families No change (9 out of 15) Adults are consistently employed Know “most” of focal child’s friends Change (6 out of 15) 1 incoming grandparent, 2 outgoing husbands, 3 incoming misc. adults Incoming adults are employed Some know “most;” others know “some” of focal child’s friends\n42 Findings: Two Parent Families Common themes in HH with change: Only adults changed. Children are stable Most incoming adults are employed In all two parent families: No public assistance No economic hardship No more or less socially engaged\n43 Findings: Single Parent Families (cont’d.) Characteristics: All women Various racial/ethnic backgrounds and origins Four subgroups: Lost adults to become a single mom at W2 (4) Single mom at W1 and W2, but gained adults in W3 (2) Changes in all waves (1) No changes in household structure - single in all waves (8)\n44 Findings: Single Parent Families (cont’d.) Common themes: Half experienced no household changes Few boyfriends or new babies Addition of adults associated with strain Loss of father not always economically bad Adult children can be helpful\n45 Findings: Single Parent Families (cont’d.) Education matters Employment matters Other people affect integration of home\n47 Findings: Extended Families (cont’d.) Single parents (6) Reliance on grandmothers (5) Low incomes - $30,000 or less (4) Some family disruption and child health conditions (4) Two parents (9) Providing shelter at tough times Wider mix of grandparents, aunts/uncles, unrelated persons Homeowners (8) Sending remittances (5)\n48 Findings: Extended Families Common themes: Lots of change in household composition (14) Majority changed once No clear chronological pattern\n49 Findings: Non-Parent Families Characteristics: Typically grandparent(s) Subgroups: 2 grandparents (6) 1 grandparent (4) No grandparent (5)\n50 Findings: Non-Parent Families Common themes: Grandparents not employed Receive some form of public assistance Experience economic hardship 2 grandparent households most stable Non-grandparent more unstable than grandparent groups\n51 Conclusions Family instability and disruption Two-parent and two-grandparent families are most stable over time Single mothers also pretty stable in composition Mixed trajectories for the rest – no clear patterns Seems to be a condition, not a type Economic wellbeing, hardship, public assistance All these families are poor Assistance and hardship not consistently used and not tied to income\n52 Conclusions (cont’d.) Social integration and social supports No clear patterns Attitude toward neighborhood Mixed feelings\n53 Lessons Learned Quantitative data misses a lot of depth Need more comments, explanations to help understand responses Challenge social scientists to prepare interviewers to collect quantitative and qualitative data High value in constructing narratives from quantitative data from longitudinal surveys to inform questionnaire design\n54 Future Research Focused analysis of comments about neighborhood “Schools are close, hospitals and stores. It’s just nice.” (Two parent) “I’ve had problems with my next door neighbors for years. They don’t work, [he’s] not the father of the sons. They are home all day drinking and taking drugs. They have other vagabonds there day and night.” (Extended) “I come from a poor country. This neighborhood suits my family. We are all of average income.” (Single parent) “There’s trouble. Not crime, but there’s kids down the block have loud parties …” (Single parent) “…People mind their own business.” (Non-parent)\n55 Future Research (cont’d.) What should we add for future data collection? Psychological measures Custom-tailored questions for scientifically selected subgroups to help explain differences? In-depth interviews Future quantitative analysis Create more typologies? What would they be? Differences by race & origin?\nThank You! Cathy Haggerty: email@example.com@norc.org Kate Bachtell: firstname.lastname@example.org@norc.org Nola du Toit: email@example.com@norc.org Ned English: firstname.lastname@example.org@norc.org\n57 References Elliott, Jane. 2008. “The Narrative Potential of the British Birth Cohort Studies.” Qualitative Research 8: pp 411-421. Maynes, Mary Jo, Jennifer L. Pierce, and Barbara Laslett. 2008. Telling Stories: The Use of Personal Narratives in the Social Sciences and History. Ithaca, NY: Cornell University Press."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:d0734e6d-26aa-441d-bda1-8e41e59f05ca>","<urn:uuid:ea62f00b-cf39-46a1-92fd-a3223db05dc4>"],"error":null}
{"question":"How do engineering design constraints apply to both educational zipline projects and professional roofing safety systems, and what specific criteria must be met in each context?","answer":"In educational zipline projects, design constraints include specific material limitations, a 5-meter line length requirement, and a performance criterion of transporting a ping pong ball in under six seconds. Students must consider factors like start and end point heights, appropriate slack for slope, and weight limitations. For professional roofing safety systems, the constraints are more stringent and safety-focused. Personal Fall Arrest Systems must meet specific criteria including limiting arresting force to 1,800 pounds, preventing free falls beyond 6 feet, limiting deceleration distance to 3.5 feet, and having anchor points that can support 5,000 pounds or twice the potential impact energy. In both contexts, thorough planning is required - students must complete engineering planning sheets and procedures, while roofing professionals must develop written site-specific fall protection plans when conventional methods aren't feasible.","context":["Day 1- Engineering and Design: Zip Line\nLesson 7 of 8\nObjective: SWBT use the terms force, friction, motion, and gravity to explain a zipline\n5e Lesson Plan Model\nMany of my science lessons are based upon and taught using the 5E lesson plan model: Engage, Explore, Explain, Elaborate, and Evaluate. This lesson plan model allows me to incorporate a variety of learning opportunities and strategies for students. With multiple learning experiences, students can gain new ideas, demonstrate thinking, draw conclusions, develop critical thinking skills, and interact with peers through discussions and hands-on activities. With each stage in this lesson model, I select strategies that will serve students best for the concepts and content being delivered to them. These strategies were selected for this lesson to facilitate peer discussions, participation in a group activity, reflective learning practices, and accountability for learning.\nThe Forces and Motions unit focuses on gravity exerted by Earth on objects, while at rest or during motion. With this in mind, students will investigate types of forces and the effects it has on moving objects. They learn how forces can stop an object from moving, increase or decrease the speed of an object moving, change its direction, and put a resting object into motion. Through models, investigations, research, and the engineering and design process, students learn that gravity is a constant force that impacts an object’s motion. The unit wraps up with students using the engineering and design process to create a zip line to illustrate the effects of gravitational force.\nThe Engineering and Design- Zip Line lesson takes place of the course of two days. I begin by showing a video of people on a ziplining to spark their curiosity. We engage in a discussion about how it relates to Newton's three laws of motion and how they apply to a zipline. Next, students use an engineering and design planning sheet to identify their task, criteria, and constraints. From there, students work in groups and being planning and designing two different zipline prototypes. They apply Newton's laws of motion by describing the effects of them on their zipline design. After completing two different designs, they discuss each one as a group to decide which design they are going to construct. Once they get teacher approval, they work on creating a procedure for the remainder of the class. Tomorrow they create their prototype and test it out.\nNext Generation Science Standards\nThis lesson will address and support lessons on the following NGSS Standard(s):\n5-PS2-1. Support an argument that the gravitational force exerted by Earth on objects is directed down.\n3-5-ETS1-1. Define a simple design problem reflecting a need or a want that includes specified criteria for success and constraints on materials, time, or cost.\n3-5-ETS1-2. Generate and compare multiple solutions to a problem based on how well each is like to meet the criteria and constraints of the problem.\n3-5-ETS1-3. Plan and carry out fair tests in which variables are controlled and failure points are considered to identify aspects of a model or prototype that can be improved.\nStudents are engaged in the following scientific and engineering practices:\n3.) Planning and Carrying Out An Investigation- Students work in groups to plan and conduct an investigation by designing and creating a zip line that meets specific criteria and constraints.\nThe Engineering and Design-Zip Line lesson will correlate to other interdisciplinary areas. These Crosscutting Concepts include:\n2.) Cause and Effect- Students conduct an investigation to determine how force, inertia, gravity, friction, mass, acceleration, and actions simultaneously impact the movement of a ping pong ball on a zip line. They use their observations to understand the effects of all three of Newton's Laws of Motion.\nDisciplinary Core Ideas within this lesson include:\nPS2.A - Forces and Motion\nPS2.B- Types of Interactions\nClassroom Management Methods\nImportance of Modeling to Develop Student\nResponsibility, Accountability, and Independence\nDepending upon the time of year, this lesson is taught, teachers should consider modeling how groups should work together; establish group norms for activities, class discussions, and partner talks. In addition, it is important to model think aloud strategies. This sets up students to be more expressive and develop thinking skills during an activity. The first half of the year, I model what group work and/or talks “look like and sound like.” I intervene the moment students are off task with reminders and redirection. By the second and last half of the year, I am able to ask students, “Who can give of three reminders for group activities to be successful?” Who can tell us two reminders for partner talks?” Students take responsibility for becoming successful learners. Again before teaching this lesson, consider the time of year, it may be necessary to do a lot of front loading to get students to eventually become more independent and transition through the lessons in a timely manner.\n- EXPLORE TEAMS (Pre-Set)\nFor time management purposes, I use “lab rats ” where each student has a number on the back of his or her chair, 1,2,3,4 (students sit in groups of 4)and displayed on the board. For each activity I use lab rats, I switch up the roles randomly so students are experiencing different task responsibilities which include: Director, Materials Manager, Reporter, and Technician. It makes for smooth transitions and efficiency for set up, work, and clean-up.\nI begin directing students attention to the whiteboard where I project a video of people on a zipline. I show this video because they are designing a zipline later today to observe the relationship between forces and all three of Newton's laws of motion.\nNext, I ask them what they notice? I listen to observations. Then I have them take out their Newton's law of Motions reference sheet from an earlier lesson and tell them think about all three laws of motion taking place at once.\nI guide them by asking them some qestions?\n- How did the people move?\n- Which direction did they move in?\n- What did you notice about the changes in acceleration? What caused the changes?\n- Were there any forces that may have affected the movement on the zipline Explain.\nI point out that a zipline incorporates multiple forces that include force, friction, motion, and gravity. (These terms are familiar as they have been used throughout the unit)\nWe discuss briefly and then I show how these terms apply to a zipline. I do this because I want them to visually see how they apply to a zipline.\nAfter observing their key terms in action, I tell the students they are working with their group to build their own zipline.\nWhat are Ziplines? How do they work?\nHere, I briefly describe the use of zip lines and explain how they work.\n- Initially ziplines were used for transporting goods down mountains, across rivers, and through forests. Nowadays, their uses are much more recreational.\n- A zipline needs to be at a slope so gravity will pull the mass of an object downward and accelerate until friction slows the object down. The tail end of a zipline is slightly uphill to help slow an object and bring it to a rest.\nDesigning a Zipline\nI start off telling students they are going to be engineers during this design process. First, I share that engineers use models and prototypes, smaller versions before creating a real one. I display a picture that illustrates the set-up of the zip line carrier and the forces involved. I have them note how Newton's three laws of motion is illustrated within this image.\nThis helps students visualize their task.\nNext, I continue explaining that as engineers they are going to design a zip line that will carry a ping pong ball quickly from one end to another. Part of being an engineer includes identifying problems them creating solutions for them. In this case, they are designing a device that can carry a ping pong ball down 5 meters of line/rope under six seconds. To help structure their design process, I hand out an engineering and design planning sheet. I guide them through this sheet starting with Identifying and Defining a Problem to be Solved section. In this section, students write a description of the problem they plan on solving and why it is important to solve it.\nThen, I move them onto thinking about what they already know in order to solve the problem of carrying a ping pong ball down 5 meters of line/rope under six seconds and have them write out an explanation use the sentence frame:\nI know____________________ because_________________________________\nWhen students complete their explanation, I call on a few volunteers to share aloud.\nIdentifying Criteria and Constraints\nBefore students identify certain criteria and constraints for their design. I explain that the criteria for this task is to know the outcomes for their solution. For this zip line task, students must design a carrier that travels under six seconds while keeping a ping pong ball in a carrier. I have them note this in the t-chart on their handout. Then I explain that like engineers, they have limitations or constraints to their designs. For them, they are limited to what materials they can use. I list them on the board and students write them on the right side of the t-chart in the hand out.\nPreparing A Prototype\nOnce we define our problem, criteria, and constraints, I point out that they are working as lab rats to design their prototype. As lab rats, they are creating two possible designs that meet the criteria and constraints of building the zipline.\nTo get them thinking, I post some questions on the board to be answered before designing a zipline prototype:\n- How long of a distance will the zip line span?\n- How high should the start and end points be?\n- What will the start and end points be attached to and how can they be secured?\n- How much slack should there be to give the zip line an appropriate slope?\n- What will the weight limitations be?\nThey use these questions to help structure their ideas in building a prototype. I hand out a Zip Line packet for students to plan out their designs with their group members. Their first task the packet is to think back to Newton's Three Laws of Motion. I have them describe how each law of inertia, gravity, friction, mass, acceleration, and reaction will affect the design of the zip line and motion of the ping pong ball.\nThen, group members brainstorm two possible designs, discuss each one, and select the one they are designing. They check in with me for approval and begin outlining their procedure to construct their prototype.\nStudents work on their procedure for the remainder of the class. Towards the end of class, I tell them they will begin building and testing their prototype tomorrow.","Roof repair projects require workers to complete jobs on existing buildings. These roofs are rarely designed with pre-existing fall protection safety so workers making the repairs must plan ahead and implement protection that will reduce their risk of dangerous falls.\nWorking at heights is a hazard for any worker, but workers completing roof repairs may face additional risk if the roof is unstable, deteriorating, or if workers are uncertain how to use fall protection on a roof that is already weatherproofed.\nThere are several fall protection methods that workers can use during roof repair jobs to ensure the work proceeds safely. For repair jobs, roofers have several options including scaffolding, aerial lifts, and various types of conventional fall protection.\nBefore beginning the job, focus on identifying fall protection needs including precautions to prevent slip, trip, and falling object hazards. The best fall protection choice depends on the type of building and what area of the roof the worker needs to access to make the repair.\nGuard against falls through skylights or other roof openings. Use a guardrail system, PFAS, or protective cover that will support two times the weight of a worker.\nIf necessary to protect workers below from falling debris, set up a work zone while roofers remove old roofing materials from the repair area.\nWorkers should be careful of air hoses and power cords for nail guns and other electrical equipment. If a worker steps on one, hoses and cords can slip underfoot and lead to falls.\nRemember to place any removed shingles or replacement tiles in a safe location. If unsecured, these materials can visually blend in against the roof and create a dangerous trip hazard.\nNew materials staged on the roof should be placed so that they are safe and secure.\nThe structural integrity of the roof must be assessed before or during the roof repair process. If workers notice signs of deterioration on the roof, like dry rot, as old weatherproofing is removed, a competent person should evaluate the area and all necessary precautions must be taken to protect the roofers.\nWhen repairs are to be completed along the edge of a roof, workers can use a scaffold or man lift. Regardless of the condition of the roof, scaffolds and lifts provide a safe, stable work platform.\nFor smaller tasks or shorter roof repair projects, scissor lifts or aerial lifts may be more efficient than installing scaffolds. Aerial lifts are a practical way to get to a customized height above or below the roof level. Do not overload the lift when loading material.\nOSHA Standard 1926.453(b)(2)(iv) Employees shall always stand firmly on the floor of the basket and shall not sit or climb on the edge of the basket or use planks, ladders, or other devices for a work position.\nWhen properly constructed and used, scaffolds can provide suitable fall protection for roof repairs. Guardrails installed along the open side of the scaffold provide fall protection.\nSafe access must be provided because roofers also risk falling when climbing on or off a scaffold. Cross braces must not be used as a means of access for scaffolds.\nOSHA Standard 1926.451(g)(1) Each employee on a scaffold more than 10 feet above a lower level shall be protected from falling to that lower level.\nWhen scaffold platforms are 2 feet above or below a point of access, workers must use portable ladders, hook-on ladders, stair towers, ramps, or other safe means of access.\nA Personal Fall Arrest System (PFAS) is usually the system of choice for most roofers. A PFAS will safely stop (arrest) a worker who is falling from a working level. It consists of an anchor point, a connector, and a body harness.\nOSHA Standard 1926.502(d)(21) Personal fall arrest systems shall be inspected prior to each use for wear, damage and other deterioration, and defective components shall be removed from service.\nWhen a personal fall arrest system is chosen as the means of fall protection on a job site, the PFAS must:\n- Limit the maximum arresting force on a worker to 1,800 pounds when used with a body harness.\n- Be rigged so that a worker can neither free fall more than 6 feet nor contact any lower level.\n- Bring a worker to a complete stop and limit the maximum deceleration distance a worker travels to 3.5 feet.\n- Have sufficient strength to withstand twice the potential impact energy of a worker free falling a distance of 6 feet or the free fall distance permitted by the system, whichever is less.\n- Be inspected prior to each use for wear, damage, and other deterioration. Defective components must be removed from service.\n- Workers must be trained in the safe use of the system.\nSelecting a location to install an anchor is a critical step in avoiding a fatal fall. An anchor gives the worker a secure point to tie off the lifeline for a fall arrest system. An anchor for a fall arrest system must meet the 5,000-pound strength requirement or maintain a safety factor of at least two (twice the impact load) under supervision of a qualified person.\nWhen available, existing anchors might be effective points for a worker to tie off. From ground level inspect the ridge cap and last rows of shingles for permanently installed anchors. If present, these may be fastened to the top chord or other frame part during construction. Anchors could also have been installed with the original roof, using a low-profile style sometimes painted to match the roof color (making it less obvious from the ground).\nIf the roof doesn’t have permanent anchors, new anchors can be installed before repair work begins. If attaching a new anchor, roofers must fix it to the truss or rafter structure underneath. Roof sheathing does not provide enough support by itself. Always follow the anchor manufacturer’s installation instructions.\nDepending on the size of the repair job and the number of workers who need to be on the roof, it might be necessary to install more than one anchor. Where practical, consider leaving roof anchors in place. It will make the current job simpler and reduce the burden for roofers in the future.\nIf the employer does not use ladders, scaffolds, or aerial lifts, and can demonstrate that it is not feasible or would create a greater hazard to use conventional fall protection equipment (guardrails, safety nets, or PFAS) when working at heights of 6 feet or greater, the employer must develop a written site-specific fall protection plan prepared by a qualified person. This person could be the owner, the supervisor, or a worker who has extensive knowledge, training and experience with fall protection and is able to solve problems relating to fall protection. States with OSHA-approved State Plans may have additional requirements for written fall protection plans.\nOSHA Standard 1926.502(k)(1) The fall protection plan shall be prepared by a qualified person and developed specifically for the site where the leading edge work, precast concrete work, or residential construction work is being performed and the plan must be maintained up to date.\nThe site-specific fall protection plan must document at each location why the use of conventional fall protection equipment is not feasible or will create a greater hazard. The plan must also describe the alternative methods that the employer will use so that workers are protected from falls. Workers and their supervisors must be trained on the proper use of those other fall protection methods.\nConventional fall protection equipment can reduce or eliminate the chances of a fatal fall. Written site-specific fall protection plans ensure that protection continues, even when conventional fall protection methods are determined to not be feasible."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:86c35f80-f6a7-4306-aa3c-4696c30fde5b>","<urn:uuid:8569ef61-117f-4a4b-8ab6-a8a673a411ae>"],"error":null}
{"question":"What is the worldwide distribution pattern of bee species across latitudes, and how does it differ from the typical biological pattern?","answer":"Bees show a bimodal latitudinal gradient, with more species in the Northern Hemisphere than the Southern, and higher concentrations in arid and temperate climates rather than in the tropics. This differs from the common biological pattern known as the 'latitudinal gradient', where species diversity typically increases towards the tropics and decreases towards the poles.","context":["First picture of worldwide bee distribution fills knowledge gaps and may help protect species\nTwelve different species of bees swarming a flowery meadow. Etching by J. Bishop, after J. Stewart.\nCredit: Wellcome Collection, CC BY 4.0\nHow many bee species are there? Wait a minute: honeybee, bumble bee, erhm… five? Five hundred? Five thousand? Not even close: the total is well over 20,000 – which means there are more species of bees than of birds and mammals combined.\nThere's no shame (nor surprise) for bee civilians like you or me in not knowing that. What is surprising, is that even those scientists who specialise in bees didn't quite know how those species are distributed all over the world. Until now.\nBy combining and filtering more than 5.8 million public records of bee occurrences, a team of researchers from China, the U.S. and Singapore have built up the very first comprehensive picture of bee diversity worldwide. And that picture presents a few surprises, both for laypersons and specialists.\nBee ignoramuses will be surprised to learn that the United States is the throbbing heart of bee diversity. The U.S. has far more bee species than any other region on earth. And by the fact that large tracts of Africa and the Middle East remain terra incognita, in terms of apiary diversity.\nRelative bee species richness in the New World. Note the low density in the Amazon Basin.\nCredit: Current Biology, open access\nIn general, there are more bee species in the Northern Hemisphere than the Southern and – confirming previous hypotheses – more in arid and temperate climates than in the tropics.\nThat goes against the common pattern in biology known as the 'latitudinal gradient', which predicts that species diversity (of most plants and animals) increases towards the tropics and decreases towards the poles. Bees are an exception, with a higher species concentration away from the poles (in what scientists call a 'bimodal latitudinal gradient').\nTo give that difference some visual immediacy, imagine a graph with one hump in the middle (i.e. the latitudinal gradient) versus one with two humps, one on either side of the middle (i.e. the bimodal latitudinal gradient). In other words: dromedary (one-hump) versus camel (two-hump).\nIt seems counter-intuitive that bees would thrive better in arid deserts than in lush tropical jungles; but that's because trees – the dominant vegetation type in the tropics – provide less bee food than the plants and flowers that grow elsewhere.\nThree ways of measuring species richness in the Americas: (A) richness of polygons, (B) sPCA and (c ) turnover. All suggest a large, distinct bee fauna in the southwestern U.S.\nCredit: Current Biology, open access\nAlso, bees don't like it too wet, unlike their cousins the ants, whose populations peak in the humid tropics. The researchers think humidity may play a role in limiting bee distribution by spoiling pollen resources.\nThe relative absence of bees from the tropics has consequences for pollination, which in those regions is performed by a wide variety of alternative species: wasps, moths and even cockroaches.\nPrevious datasets of global bee distribution were either inaccurate, incomplete or difficult to interpret. This world map clearly establishes that bees prefer dry and temperate zones to wet and tropical ones. For bee scientists, it provides a much-needed baseline to predict the geographic distribution of bees and interpret the relative richness of species.\nWhile much work needs to be done to fill additional knowledge gaps, this baseline is an excellent starting point, not just for greater understanding, also for better conservation. Because bees are not just for making honey. In many countries, they're the top pollinator species. And they typically visit 90% of the leading crop types.\nCarpenter bee (Xylocopa latipes) pollinating a flower in the Indian state of Kerala.\nCredit: Charles J. Sharp (Sharp Photography), CC BY-SA 4.0\nYet over the past decades, bee populations have been crashing. In the U.S., honeybee populations have declined by 60% between 1948 and 2008. In Europe, 12 wild bee species are critically endangered.\nThat trend is potentially disastrous for agriculture. More than $550 billion in annual global crops are at risk from pollinator loss. The loss of bees as pollinators would lead to a collapse in crop yields and even entire ecosystems.\nBetter understanding bees increases our options for protecting them. This study will help pinpoint bee diversity hotspots in otherwise poorly examined parts of the world and help predict how bees will react to climate change – for example when certain regions will get wetter weather.\nProtecting bee diversity is especially important and urgent in developing countries, where many of the knowledge gaps are located, and where many crops rely on native bee species for pollination.\nMichael C. Orr et al.: 'Global Patterns and Drivers of Bee Distribution' is published in Current Biology.\nStrange Maps #1060\nGot a strange map? Let me know at firstname.lastname@example.org.\nThis story originally appeared on: Big Think - Author:Frank Jacobs"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:867d4e6c-7bb4-4218-b31f-f2c01fae060a>"],"error":null}
{"question":"Can you explain what happens during each main stage of fermentation and how long they typically last?","answer":"Fermentation occurs in three main stages. The first is the lag phase, where yeast absorbs oxygen, vitamins and minerals needed for growth, lasting 24-48 hours with the lag period potentially as short as 30 minutes. The second is the active phase, where visual activity begins as yeast cells multiply, consume sugars (starting with glucose, then fructose and sucrose, followed by maltose which makes up 59% of wort sugars), and produce ethanol and flavor compounds. In the final stationary phase, fermentation rate drops sharply as most sugars are consumed, yeast begins to flocculate and settle, and the beer is conditioned - yeast reabsorbs diacetyl and hydrogen sulfide escapes. The entire process can complete in as little as 7 days under optimal conditions, though traditionally it's expected to take 4-6 weeks.","context":["Top 10 Reasons For Fermentation Failure\nBy Ed Kraus\nFermentation Has Already Completed:\nIn a twisted way, you may not be getting a fermentation because the fermentation has already completed. Many ask, \"how could this be?\" It's almost like experiencing an unbelievable magic trick. \"How did my wine do that?\" But, after checking the wine with a hydrometer, the truth becomes clear. The juice fermented, and you didn't even know it.\nRelax, its really not your fault. And, there's really no problem, anyway. Most wine making directions you run across will lead you to believe that all fermentations will take anywhere from 4 to 6 weeks. But in reality, if the conditions are right, a fermentation can complete in as little as seven days. Yes, that's right \"seven days.\" We have personally experienced fermentations that have completed in as little as five days, but this is far more rare.\nThe only real way to know where you stand with your fermentation's progress is to take a hydrometer reading. The hydrometer has the final say as to what has actually happened. If you take a hydrometer reading and you discover that the Specific Gravity is 0.998 or less, well then, yes, the wine is done fermenting. If this is the case, there is really nothing else for you to do other than continue on with rest of the directions ahead of schedule.\nMany first-time winemakers will get the notion that they should add more sugar if there fermentation completes quickly. If you have added the correct amount of sugar at the beginning of fermentation, this would not be the right thing to do.\nJust because a fermentation only lasted a week or so, does not mean the wine has any less alcohol than a fermentation that took 2 months. Time does not control the amount of alcohol made, the amount of sugar available to the wine yeast does. Adding more sugar at this point will only complicate the situation.\nFor example, if your starting hydrometer reading indicates that you have enough sugar in the must to produce 12 percent alcohol, you will have 12 percent alcohol once all those sugars are fermented, regardless of the amount of time it takes. And, you will know when all those sugars have been fermented by the fact that the hydrometer reads 0.998 or less on the Specific Gravity Scale.\nMany ask, \"why does this happen?\" The fact of the matter is, there are many reasons why a fermentation might go fast or slow. There are an endless number of variables that can come into play when dealing with Mother Nature. But having said this, a large percentage of the time it is temperature related.\nAll things being the same, musts that are 75 degrees F. or higher will ferment much, much faster than a must that is 70 degrees F. or less. The amount of wine yeast that is pitched into the must can make a difference. Two packs of wine yeast will ferment the same juice, not twice as fast, but faster that one pack of yeast will.\nIf the yeast is pre-started ahead of time, this can influence the rate of fermentation as well. Not only does pre-starting the wine yeast allow the yeast cells to hit the juice with their feet running, so to speak, but it also allows the yeast to multiply in number, ahead of time, which could contribute to having an explosive fermentation.\nHaving a fast fermentation is neither a good thing or bad thing. But the reasons that caused it to ferment fast may be bad. For example, if you had a fast fermentation that was caused by warmer temperatures, this could be bad. Having too warm of fermenting temperature will also facilitate the growth of unwanted micro-organisms, which may give the wine an off-flavor. But, if you had a fast fermentation because you pre-started your wine yeast, then no harm is done.\nHaving said this, there is really no advantages to having a fast fermentation in of itself. Of course you get to bottle your wine sooner with a faster fermentation, but I know of no studies that have indicate \"fast\" is better or worse than \"slow.\"\nEd Kraus is a 3rd generation home brewer/winemaker and has been an owner of E. C. Kraus since 1999. He has been helping individuals make better wine and beer for over 25 years.","Views: 44 Author: Site Editor Publish Time: 2022-10-27 Origin: Site\nFermentation is at the heart of the craft brewing process. During fermentation, the wort made from the raw material is converted into beer by yeast. Fermentation is when yeast produces all the alcohol, aroma and flavor compounds in beer. It is also “where the magic happens”. Fermentation is divided into 3 recognized phases: lag phase, active phase and stationary phase.\nBeer Fermentation Stage -\nOnce the yeast is cast, it goes into what we call a later stage. Although there isn’t any clear fermentation, there’s still something going on. Yeasts are absorbing oxygen from the wort (producing sterols), which are essential for reproduction and healthy growth.\nYeasts are living organisms, so they need oxygen. This is why wort aeration is important in commercial brewing. Yeasts need oxygen to grow and produce important cell wall components. Also to absorbing oxygen, yeast also absorbs vitamins and minerals needed for growth.\nGood timing on the fermentation temperature. The style of beer you choose to brew, as well as the yeast you use, will determine the fermentation temperature.\nAle: 62-75 °F (17-24 °C)\nLager: 46-58 °F (8-14 °C) *Note: Lager fermentation can begin at elevated temperature (~60 °F/15.5 °C) until signs of fermentation (gravity drop, CO₂ production, head part formation) is obvious. Once symptoms of fermentation are observed, cool to desired fermentation temperature.\nWheat and Belgian styles: 62-85 °F (17-29 °C)\nBeer Fermentation Stage -\nDepending on the beer style, visual activity will begin to be seen within 24-48 hours of pitching. Yeast is coming out of the lag phase and into the anaerobic phase. The lag period can be as short as 30 minutes.\nYeast cell counts increase during the active phase. Yeast starts to consume the sugar made on brewing day. Carbon dioxide is produced and a layer of foam can be seen.\nAs the number of cells increases, ethanol and flavor compounds are produced. At this point you can smell the fermentation. If neutral yeast is used, such as Fermentis US-05, it may smell like olive oil.\nActivity at this stage is temperature dependent, and the higher the temperature, the more active the activity. Yeast consumes sugar in a certain pattern. Monosaccharides are first consumed with glucose, followed by fructose and sucrose, before entering metabolism. The glucose content in a typical beer wort is about 14% of all sugars.\nThe main sugar and the heart of the brew is maltose, which is an important flavor ingredient. Maltose makes up 59% of the wort sugar in a typical beer. Maltose is used by yeast to impart properties to beer that many brewers have planned in formulation development. When fermentation is at its most active, the foam at the top of the wort usually turns from yellow to brown. Brown spots made of oxidized hop resin can also be seen.\nLagers – For some strains of lager, brewers increase the fermentation temperature after 50 to 60% fermentation. They allow the beer to “free rise” and the temperature can be as high as 20°C (68°F). The elevated temperature will make the beer “self-purify”, reducing the rate of diacetyl.\nCool down to 10°C (50°F) and hold at this temperature for 48 hours\nCool to 5°C (41°F) and hold at this temperature for 24 hours\nCool to 0 to 3°C (32°F), the temperature maintained for ripening.\nBeer Fermentation Stage -\nDuring the fermentation stage after most of the sugar in the wort is consumed, the fermentation rate drops sharply. During this period, most of the final sugars are consumed and some secondary metabolites are converted by yeast. As the alcohol content increases and sugar and nutrients are depleted, the yeast begins to flocculate and settle.\nYeast growth slows as the beer enters a stationary phase. Most flavor and aroma compounds have already been produced. These include fusel alcohols, esters, and sulfur compounds. During the resting phase, the beer is conditioned. Yeast reabsorbs diacetyl produced during fermentation. Hydrogen sulfide escapes from the fermenter as a gas. The attenuation level is checked by measuring the specific gravity of the wort.\nReduce the production rate of ethanol and carbon dioxide\nReduction of some flavor compounds through yeast metabolism or carbon dioxide scrubbing\nReach terminal gravity\nYeast flocculation and sedimentation start\nAles: same as primary fermentation (higher temperature increases diacetyl reduction rate)\nLager: 40-60 °F (4-15 °C). Some brewers allow the temperature of the beer to be elevated to speed up the reduction of diacetyl. This elevated temperature usually only lasts 24 to 48 hours.\nWheat and Belgian beers: same as primary fermentation (higher temperature increases diacetyl reduction rate).\nIf the brewery’s next step is to re-ferment the yeast, the brewery will first confirm that the quality of the harvested slurry has reached certain standards of viability and purity by the end of the secondary fermentation. Since these methods are beyond the scope of most homebrew needs, there are some simple techniques to help determine whether re-extracting yeast from homebrew is a good option."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:ac5c4b22-e8ab-4a0f-b308-3909f9e3914e>","<urn:uuid:c0d494c0-36eb-4ebb-aeca-c79410784030>"],"error":null}
{"question":"How did the academic environment differ between Critical Theory scholars in the Weimar Republic and peasants in post-WWI Central Europe regarding their understanding of national identity?","answer":"The Critical Theory Jewish scholars were largely positioned outside or on the margins of the academic world during the Weimar Republic, and after 1933 most were driven into exile, creating language and readership challenges. In contrast, peasants in post-WWI Central Europe struggled with basic concepts of national identity - they had difficulty grasping the concept of nationality, often identifying simply as 'locals' (tutejsi). While the scholars faced challenges within established academic institutions, the peasants were confronting the fundamental transformation from imperial subjects to citizens of new nation states, expressing disbelief and confusion about suddenly being part of new countries.","context":["15 to 16 January 2009\nLiterary Studies and literary knowledge in the ambient of Critical Theory\n(Literaturwissenschaft und literarisches Wissen im Umkreis der Kritischen Theorie)\nThe Simon Dubnow Institute, in cooperation with Prof. Dr. Dieter Burdorf, Department of Germanics, University of Leipzig, was organizing an international conference in January 2009 devoted to examining the relations between literary studies and Critical Theory. Literary scholars, experts on philosophy and historians of art discussed and explored the work of Theodor W. Adorno, Siegfried Kracauer, Walter Benjamin, Gershom Scholem, Leo Löwenthal, Herbert Marcuse, Hans Mayer, Ernst Bloch, Peter Szondi, Erich Auerbach and Robert Minder (among others).\nThe aim of the conference was to better understand the fundamental attitude of intellectuals toward literature in the more narrow and broader ambient of Critical Theory as a form of textual erudition. The concept »textual erudition« or »Textgelehrsamkeit« is intended on the one hand to recall the relations surrounding the traditional, pre-modern figure of the scholar of scripture, der Schriftgelehrte; on the other, it is meant to highlight the critical relation of the Frankfurt School to the bourgeois typology of education.\nA distinction was proposed between receptive and productive approaches of these scholars to the text and textual forms:\nWays of reading: What texts from cultural heritage and contemporary cultural production did these textual scholars choose for their reading and commentary? Did a certain canon crystallize? What is the relation here between the Bible, classics of the bourgeois educated canon in various languages, and the contemporary texts of literary modernity? What was the attitude of representatives of Critical Theory toward the reading of such texts? In the process, what fundamental questions of hermeneutics – allusion, citation, commentary, Analysis – are rendered visible?\nWays of writing: What different techniques of text production can be discerned among the intellectuals involved? The textual scholars of Critical Theory preferred certain text forms that tended to be viewed as being more marginal in the academic world (especially in connection with career enhancement): they generally rejected the genre of treatise (monograph and scholarly article), giving preference to short forms such as the essay, review, fragment, letter and aphorism. Salient questions are: to what extent this shift was due to the general change in the dominant way of writing in the academic/intellectual world in the German cultural sphere since 1900? Is it possible to connect this with the specific existential situation of the group of intellectuals to be investigated, and their own concepts of text?\nIn this connection, mention should be made of the position of numerous Jewish textual scholars outside or on the margins of the academic world during the Weimar Republic. The production of text was influenced even more powerfully by the situation of exile into which almost all textual scholars were driven after 1933. For many, that gave rise to an additional problem: in what language could they write so that readers might also be found for the texts they produced? Seen from this vantage, the return of many of these intellectuals after 1945 to one of the German-speaking states can be viewed primarily as a return to the sphere of the German language, a linguistic homecoming.\n4 to 5 May 2009\nBetween Imperiality and Nation-State: Jewish Participation in East-Central European Communal Autonomous Administration, 1918–1939\nResearch on municipal autonomous administrations in East-central Europe has experienced a kind of renaissance since the 1980s, in contrast with research in the West. Autonomous local administration is situated at an interface between the state and its citizenry, between administration and private interests. In political theory, it has long been accorded a special role in civic education of the informed citizen and in democratic development more generally.\nIn the interwar period, the theory took on a modernized form specifically in East-Central Europe, experiencing a new development in accordance with the times. That was because the great expectations placed in the autonomous local administrations were congruent with the multiethnic reality on the ground in this macro-region. The questions arising from this are intensified by the fact that simultaneously, the nation-state was elevated to a political ideal, and ethno-nationalism became the general auxiliary ideology of the various national ideologies.\nThe workshop/conference focused in particular on the large urban areas with their high percentage of Jewish population. Central for inquiry is the question of just how this ethnic diversity was manifested in the bodies of autonomous administration. Did it have a demonstrable impact on communal politics, and if so, how? The plan for the comparative workshop/conference envisioned that through a detailed investigation of the concrete events in everyday politics in the municipal bodies and structures of autonomous local administration, it was possible to analyze and map more clearly the array of problems associated with the urban coexistence of various cultural groups, their integration, lack of integration and degree of inclusion and exclusion.\nThe workshop was organized as the closing capstone event in the DFG-sponsored research project »Die Juden in der polnischen Selbstverwaltung, 1918-1939: Krakau, Warschau und Posen« (Jews in Polish Autonomous Administration: Cracow, Warsaw and Poznan, 1918-1939). Knowledge gained at the workshop/conference assisted in contextualizing the findings of the project at the Dubnow Institute under the direction of Dr. Hanna Kozinska-Witt, centering on Polish large cities, within a broader East-Central European comparative frame.\n11 to 12 June 2009\nKelsen, Schmitt, Arendt and the Possibilities of (International) Law - Workshop I: Constitutionalisation (Simon Dubnow Institute Leipzig )\n15 to 16 June 2009\nWorkshop of the FMER-Project Communication Spaces in Europe. »Jewish Cultures of Knowledge Beyond National Borders« (Guesthouse of the Leipzig University »Villa Tillmanns«)\n10 to 11 September 2009\nKaleidoscopic Knowledge. On Jewish and Other Encyclopedias in Modernity\nOn September 10 to 11, 2009, the Simon Dubnow Institute in cooperation with the German Historical Institute, Washington D.C., hosted an international workshop on Jewish and general cultures of knowledge. The workshop examined the development of Jewish and supposedly universal encyclopedias in the modern era from a cultural-historical perspective. Looking at the transfer of knowledge, the workshop investigated (a) the actors and agents in encyclopedic undertakings, (b) the concrete conditions shaping the composition of their texts as contexts of a communication also molded by material interests, and (c) cross-section analyses of series of articles and texts. The workshop, organized by Arndt Engelhardt (DI) and Ines Prodöhl (GHI Washington), brought together scholars from Israel, the U.S., and Germany at the research institute in Leipzig.","The Great War ended the age of empires in continental Europe. National narratives of the successor states have it that they materialized like the proverbial jack-in-the-box in 1918. In reality, the transition from empire to nation state was a process that lasted years, and thus prolonged the violence of the World War long into the postwar area.\nIt is only logical, if one thinks about it: in Central Europe, a vast area between Russia and Germany was turned into a tabula rasa on which now new borders had to be drawn. It certainly does not come as a surprise that this was not achieved by peaceful means. In 1919, while peace was established in Paris, fighting went on in Central Europe.\nThis continuation of conflict was a tragedy for a region that had witnessed some of the fiercest battles of the Eastern Front. Wartime destruction, famine, and epidemics were ubiquitous. After 1918, its population was still suffering, starving, dying. And yet peace was only a distant dream. The immediate postwar experience of the people of Central Europe contrasted highly with the national bravado voiced by the elites in their respective capitals.\nA large majority of the new citizens of emerging Central European countries—predominantly peasants—had no clear idea what the new ethnic nation states were supposed to mean. Central Europe was populated by people speaking Lithuanian, Ukrainian, Russian, Yiddish, Czech, Slovak, or German, with no clear boundaries running between them. In prewar censuses, they even had difficulties to grasp the concept of nationality, and in consequence, an alternative category—tutejsi (locals)—had to be added. As subjects of empires until 1918, the idea that they should suddenly be citizens of different states came to them as a shock: “Other times had come,” a peasant noted in his memoir on Polish independence in 1918. “The village woke up because everything was shaking all around. They tell us that there’ll be a Poland and it’s already taking shape, though it’s still a bit weak, but slowly getting stronger. The peasants don’t want to believe it, because we’ve always been told that this here’s Russia and Russia it will be, and now, all of a sudden-hocus-pocus-it’s Poland.”\nThe immediate postwar experience of the people of Central Europe contrasted highly with the national bravado voiced by the elites in their respective capitals.\nFrom late 1918 onwards, cities, towns, and villages far from the state centers that struggled for survival on a daily basis were drawn into the new contest for national supremacy. Neighbors that had been living together—not conflict-free, but by and large peacefully—under imperial rule for ages overnight were turned into enemies by competing politicians and agents of nationality which claimed them as their citizens. Did they embrace the struggle for national independence with enthusiasm? Were they sending their sons unhesitatingly to the diverse fronts that opened when the arms of the Great War fell silent? Far from it: in the contested borderlands of Central Europe, the passage from war to peace was experienced as a fratricidal civil war. Another peasant in the Lithuanian-Polish borderlands complained: “Now, this is Lithuania, and that’s Poland. It used to be one, but now there’s a border between Bereźniki and Ogrodniki; there’s a war on. Is that how things should be? Don’t we all go to the same church? Isn’t it a disaster that brothers are divided and fighting?”\nGeographically in the eye of the cyclone, the emerging ethnic Polish nation state claimed territories that hosted minorities of almost all nations involved in the Central European Civil War. Between 1918 and 1921, it was in a permanent state of declared or undeclared war on literally all frontiers except the Romanian.\nFor political scientists, the notion of the diverse postwar conflicts in Central Europe as a civil war might be provocative, since the term usually refers to conflicts below state level, while here, different states were involved. The counter-argument is that those very states were not fully developed yet, since their borders and population still had to be defined, and their state institutions—above all a functioning army—had to be built. Furthermore, the local people experienced those conflicts as a civil war, not as wars between nations. With the words of historian David Armitage: “Civil war is, first and foremost, a category of experience; the participants usually know they are in the midst of civil war long before international organizations declare it to be so.” To bring both arguments together: The Central European Civil War marked the transition from empires to nation states. In its fires, state institutions were built and state citizenship was defined.\nFeatured image credit: “Map showing the political divisions of Europe in 1919 after the treaties of Brest-Litovsk and Versailles” by unknown author. Public Domain via Wikimedia Commons."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:5c39498c-dc26-43e3-9a34-426769b7a80c>","<urn:uuid:92554d37-97fb-4b15-b76b-05d7ed5c6a5f>"],"error":null}
{"question":"What are the key characteristics of flint as a mineral, and what safety precautions should be taken when working with it to make arrowheads?","answer":"Flint is a cryptocrystalline variety of quartz that is dark brown to black in color and breaks with a conchoidal fracture into fragments with sharp cutting edges. It is found in limestones or in soils derived from limestones. When working with flint to make arrowheads, several important safety precautions must be taken: wearing safety glasses is essential since sharp flakes can fly off in any direction; gloves, shoes, and sturdy pants are highly recommended; the work should be done in a well-ventilated area to avoid breathing rock dust; and the workspace should allow for easy collection of sharp flakes, potentially using a tarp or sweeping afterwards to prevent accidental stepping on debris.","context":["Silicates are arrangements of the elements silicon and oxygen with a wide variety of other elements. The most common silicates are quartz and feldspars. Quartz is abundant in Kentucky, and some of the feldspars occur as very fine grains in sandstones in Kentucky.\nCrystal system: orthorhombic. Cleavage: tabular. Color: clear to white, with yellow or red iron staining common. Hardness: 4.5-5. Luster: vitreous. Specific gravity: 3.4.\nCalamine is an older name for the rare mineral hemimorphite. It forms in oxidized zinc deposits. Hemimorphite is commonly associated with smithsonite and cerussite, and occurs in clusters of radiating, acicular crystals. A massive variety shows worm-like shapes. Hemimorphite occurs in zinc-bearing vein deposits in the Western Kentucky Fluorspar District in Crittenden and Livingston Counties.\nCrystal system: monoclinic and triclinic. Cleavage: good at 90 degree angle. Hardness: 6.\nThe feldspars are an important rock-forming group of minerals, but their occurrence in Kentucky is limited to very small detrital fragments of sandstones and cement that are only visible with microscopes.\nCrystal system: isometric. Color: various colors. Hardness: 6.5-7.5. Luster: vitreous. Specific gravity: 3.5-4.3. Uses: semi-precious stone, industrial abrasive saws, polishing tools.\nThe garnet group of silicates has a diverse chemical composition consisting of calcium, aluminum, magnesium, and chromium silicates. Some minerals included in the garnet class are pyrope (red to black), almandine (red), grossularite (green yellow), and uvarovite (green). It is translucent to transparent. Pyrope and almandine occur abundantly in ultramafic dikes in Elliott County, and many can be obtained by panning in the alluvial sediments near the dikes. Garnets can also be found in some glacial erratics in northern Kentucky and in metamorphic rocks in the Appalachian Mountains in Virginia and North Carolina.\nCrystal system: monoclinic. Cleavage: cleaves into sheets; flexible when bent. Color: dark gray to black (biotite), white to light brown (muscovite). Hardness: 2.5 (biotite)-3.0 (muscovite). Specific gravity: 2.7 (muscovite)-3.0 (biotite).\nMuscovite and biotite generally occur in igneous and metamorphic rocks, but in Kentucky they are commonly found as detrital sediment in sandstones, shales, and clays. Mica minerals are commonly mistaken for gold because of their golden color and cleavage, which causes light to be reflected easily. The magnesium-rich phlogopite has similar physical characteristics as biotite and muscovite, and is found in kimberlite dikes in Elliott County.\nCrystal system: orthorhombic. Fracture: conchoidal. Color: green. Hardness: 6.5-7. Luster: glassy. Specific gravity: 3.3-4.3.\nOlivine is a common igneous rock-forming mineral and occurs in both basaltic rocks and the kimberlite dike in Elliott County. Transparent gem-quality varieties are known as peridots. Olivine alters readily to serpentine.\nFracture: uneven. Color: black to dark brown. Hardness: 5.5. Luster: metallic. Specific gravity: 4.\nPerovskite can occur as cubic crystals and massive or reniform (kidney-shaped) masses. It is found in ultramafic rocks and in the peridotite dikes in eastern and western Kentucky.\nCrystal system: hexagonal. Fracture: conchoidal. Color: colorless or white, but may be tinted various colors (e.g., purple, amethyst). Hardness: 7.0. Streak: colorless. Luster: glassy. Specific gravity: 2.65. Uses: jewelry; prehistoric arrowheads, knives (flint); gravel (chert).\nQuartz is the hardest, most resistant mineral found in abundance in Kentucky. It is the main constituent in sandstones and geodes, and also occurs as vein quartz. Crystals usually consist of six-sided hexagonal prisms capped by pyramids on one or both ends. Quartz crystals are found in geodes that occur in several different rock types, particularly limestone. In south-central Kentucky, valleys and stream beds downslope from the Warsaw-Salem Formation are filled with geodes, some containing amethyst (another variety of quartz).\nSeveral cryptocrystalline (microscopic crystals) varieties of quartz occur in Kentucky. They are commonly recognized on the basis of their fibrous texture and granularity. The fibrous varieties include chalcedony, agate, onyx, and jasper, and granular varieties include chert and flint.\nAgate has delicate and varying shades of color arranged in layers. In the typical occurrence the bands are irregular, curved, or in concentric patterns. Agate is used as an ornamental material or in semi-precious jewelry. The color banding is usually related to chemical impurities; for example, iron gives a red or orange color and manganese or calcium give black or blue colors.\nFor the past decade, beautiful specimens of red, black, yellow, and gray banded agate have been discovered in Estill, Jackson, Powell, Madison, and Rockcastle Counties. These Kentucky agates are derived from the Renfro-Borden Formation of Early Mississippian age and can be collected along some river drainages where the Borden is exposed to weathering. Many of these agates are displayed at local rock shows. To see more pictures of Kentucky agates see the Kentucky Agate section of this web site.\nFlint is dark brown to black and breaks with a conchoidal fracture into fragments with sharp cutting edges. It is found in limestones or in soils derived from limestones.\nChert (and Jasper)\nChert and flint are cryptocrystalline varieties of quartz. Chert is usually gray to white; flint is dark brown to black. Chert and flint are very hard and break with a splintery fracture. Chert is usually associated with dolostone and limestone and occurs as lenses, irregular layers, and nodules, but some rock units are composed almost entirely of chert. Chert abounds in the upper St. Louis Limestone in south-central Kentucky between Glasgow and Somerset. The Boyle Dolomite of Silurian age also contains abundant gray, blue, and black chert. Any roadcuts or active or abandoned quarries in this region in the St. Louis Limestone or Boyle Dolomite would contain numerous chert nodules. Chert and flint were the most common silicate minerals used by early Native Americans for making arrowheads. Because chert and flint have a conchoidal fracture, they are easily shaped into arrowheads.\nJasper is an impure variety of quartz that has been colored some shade of red by iron oxide inclusions. The name \"Jasper\" may also be used for some siliceous agate material that has replaced organic material in petrified wood. It is used as an ornamental stone and in jewelry.\nOpal is an amorphous, massive silicate that exhibits a conchoidal fracture and has a characteristic play of colors caused by its water content. Opal is not common in Kentucky, but may occur in some siliceous fossils, particularly in the black shale, and in microscopic amounts in cherts and chalcedony. Opal is not a stable mineral, and in geologic time alters to other silicate minerals.\nMany fossils found in Kentucky are silicified. This means the original material of the fossil has been replaced with quartz. These small brachiopod fossils from Lexington are silicified. Click on the image to see the quartz inside. When the brachiopods are broken open you can see the white to clear quartz inside. In some cases the quartz is massive, in others crystalline.\nCrystal system: monoclinic. Color: green. Hardness: 3-5. Luster: greasy, wax-like. Specific gravity: 2.5. Uses: asbestos.\nSerpentine occurs in both a platy and a fibrous variety. The most common variety is chrysotile, which is the chief source of asbestos. In Kentucky, serpentine occurs in peridotite dikes.\nClay minerals are a subgroup of silicates that comprise the various claystones, such as ball clay, flint clay, and fuller's earth.\nIllite is the constituent of many shales and is an intermediate clay between montmorillonite and muscovite. It has more potassium than montmorillonite, but is not expandable or absorptive. It is structurally similar to chlorite, but chemically different.\nCrystal system: amorphous. Color: green. Streak: colorless or greenish, but lighter than the grains themselves. Luster: earthy to dull. Specific gravity: 2.3. Tenacity: brittle. Uses: fertilizer, soil conditioner.\nGlauconite, a variety of illite, occurs disseminated in shales, sandstones, and limestones, and is commonly associated with phosphate pebbles and iron sulfides. The Floyds Knob Bed of the Borden Formation (Mississippian) is a glauconitic siltstone that crops out in a semicircle around the Outer Blue Grass.\nCrystal system: monoclinic. Hardness: 2-2.5. Luster: earthy. Specific gravity: 2.6.\nKaolinite is the chief component of ball clay and flint clay. It has a sheet structure, and is therefore not as absorbent as montmorillonite.\nHalloysite is a hydrated variety of kaolinite (crystal system: amorphous; fracture: conchoidal; color: white, yellowish-white, gray, to green; hardness: 1.5; streak: white; luster: earthy to pearly; specific gravity: 2.1; tenacity: brittle) with little or no plasticity. Halloysite has a distinctive tube-like structural appearance.\nCrystal system: monoclinic. Hardness: 1-1.5. Specific gravity: 2.5.\nMontmorillonite is very fine grained, and visible only with powerful microscopes. It is the main mineral in bentonite and fuller's earth. Montmorillonite is called an expanding clay because the arrangement of its crystal lattice allows frequent and extensive substitution of additional minerals; actual composition may vary depending on iron, magnesium, zinc, aluminum, and silicate ratios.\nVermiculite is a related montmorillonite clay mineral that has the absorbent but not the expandable characteristics of typical montmorillonite.","By Jason Knight\nFlint knapping is the age-old art of making arrowheads and other edged stone tools. Hunter-gatherers relied upon this key wilderness survival skill to create important tools and hunting implements. Many people continue to practice the skill today, including traditional bowyers, experimental archaeologists, and primitive skills enthusiasts.\nAt its most basic level, flint knapping consists of: breaking open a piece of parent material (called a core); striking flakes off of that core; and then shaping those flakes into the intended tool.\nIn general, the process of making arrowheads includes the following primary concepts:\nBecause flint knapping includes breaking apart rocks with force, where sharp flakes can fly off in any direction, it is very important to wear safety glasses. Gloves, shoes, and sturdy pants are also highly recommended. It is also important to flint-knap in a place where you can easily catch the sharp flakes that will fall to the ground (so that they are not accidentally stepped-on). You can put down a tarp or sweep up afterwards. Also, use a well-ventilated area, so not to breathe the dust created by breaking rocks.\nWhen it comes to the ethics of flint knapping, the primary concern is to be mindful of the archaeological record. To an archaeologist, piles of flaked stone (debitage) can indicate the presence of an ancient village or camp. To prevent your work from being confused as archaeological evidence, always add a penny or two to your pile of debitage and be sure to sign and date your completed work with a diamond-tipped pen.\nThe best stones for making arrowheads include flint, chert, obsidian, jasper, quartzite and other stones that are somewhat brittle and have a fine-grained, uniform texture that is free of cracks, fissures, and fractures. Glass and porcelain can also be used. You can also tap the stone and listen to the pitch. Stones that produce a higher pitch when tapped are generally better for knapping.\nTo break apart and shape your material you will be using some simple tools for percussion and pressure flaking. These tools can be made out of antler, soft metal, soft stone, bone, or very hard wood. The best pressure flaking tools are made with an antler or copper tip.\nPercussion flaking is the act of striking your material to break it apart in a controlled manner. In a uniform material, the force from a strike moves out from the point of impact in a cone shape that is roughly 100 degrees wide. This is called a Hertzian Cone (see figure 1). Understanding this concept of how forces move through stone allows you to angle your stone to break it apart in an intentional way.\nIf your parent material (also called a core) has rounded edges, the first step is to break it apart so that you have good edges to work with. This can be done by using a large hammering tool. The goal is to create platform edges that are less than 90 degrees (see figure 2).\nThe next step is to strike flakes off of your core using smaller striking tools. It is these flakes that you will be further shaping into implements such as arrowheads (see figure 3).\nPressure flaking is the act of using a pressure flaking tool (such as an antler) to load significant pressure against an edge and then popping off a long thinning flake. Pressure flaking allows a flake to be carefully shaped down into the finished tool.\nTo pressure flake, an edge often needs to be strengthened by abrading it to remove thin weak pieces. A platform is then picked out, which is a point on the edge that sits below the centerline of your flake. The pressure flaking tool is then pushed onto the platform with significant force and a small thin flake is popped off of the piece (see figure 4).\nNotching is the final step in making arrowheads. The notches are made using a combination of pressure flaking and abrading to carve out the gaps that allow the arrowhead to be bound to an arrow shaft (see figure 5).\nYou now have a completed arrowhead. You can haft it onto an arrow shaft and begin working on another. Happy knapping!\nA great material to start working with is beer bottle bottoms. It allows you to practice and learn the concepts before spending money on expensive stones. Here is a great article on making arrowheads from beer bottles.\nMaking arrowheads and other stone tools is taught as part of our\nWilderness Certification Program.\nFor detailed information on flintknapping, we recommend the book:\nThe Art of Flint Knapping by D. C. Waldorf.\nAbout the Author: Jason Knight is the Director at Alderleaf Wilderness College. He has been teaching wilderness skills for over twenty years. Learn more about Jason Knight."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:5db8f0b8-513b-4b28-96e0-3f01d87b3672>","<urn:uuid:f9fd69e6-e5ec-4152-a28e-38a11a7762de>"],"error":null}
{"question":"How do the mechanisms of action differ between antacids and proton pump inhibitors (PPIs) in treating acid reflux, and what are their respective timing considerations for administration?","answer":"Antacids and PPIs work through different mechanisms and timing. Antacids provide immediate relief by chemically neutralizing existing stomach acid and can be taken as needed anytime. In contrast, PPIs interact with stomach lining cells to reduce acid production by at least 80% for up to 24 hours, but must be taken before a meal (usually breakfast) and take several days to reach maximum effectiveness - typically 4 days. PPIs are more powerful, reducing acid production by at least 80%, while antacids only neutralize existing acid without stopping further acid secretion.","context":["(RxWiki News) Treating gastric reflux with over-the-counter (OTC) medication might not bring relief, even though the medications might be similar to the prescription brands.\nGastroesophageal reflux disease (GERD) occurs when the contents of the stomach leak back up into the esophagus, causing pain and heartburn.\nPatients with GERD can see a specialist or their primary care doctor for treatment with medications called proton pump inhibitors (PPIs). Some brand names of PPIs are Prevacid, Prilosec and Nexium.\nGERD patients can also purchase many of these medications over the counter to treat their symptoms, although the OTC medications may be available in different strengths than the prescription versions.\nA recent study found that patients who received their GERD treatment from a gastroenterologist were more likely to take their medications correctly. They also tended to have less frequent and less severe GERD symptoms.\n\"See a gastroenterologist for your GERD symptoms.\"\nThis research was led by M. Michael Wolfe, MD, from the Division of Gastroenterology at the MetroHealth Medical Center at Case Western Reserve University in Cleveland, Ohio.\nUnlike antacids, which can be taken anytime for excess stomach acid, PPIs must be taken before a meal, usually breakfast.\nDr. Wolfe and colleagues compared whether PPIs given by a gastroenterologist, primary care doctor or purchased over the counter made a difference in whether the medications were taken properly and whether the patients got relief from their symptoms.\nThe researchers surveyed 1,959 patients who were diagnosed with GERD. The surveys asked the patients how they treated their GERD and about GERD symptoms they experienced while being treated.\nMen and women, ages 18 and older, were included in the study.\nOf the 1,959 patients, 31 percent treated their GERD symptoms with PPIs.\nA total of 37 percent of the patients who treated their GERD got a prescription from their primary care doctor, 31 percent from a gastroenterologist and 32 percent bought their PPIs over the counter.\nMedication doses varied with source of the medications.\nConsidering proper timing and amount of medication taken, 39 percent of the patients who took OTC PPIs received the proper dose, and 47 percent of the patients who were treated by and received a prescription from their primary care doctor took the proper dose.\nThe results showed that 71 percent of the patients who were treated with a prescription from a gastroenterologist received the proper dose.\nThe frequency and severity of the GERD symptoms experienced by patients who took medications prescribed by a gastroenterologist were less than those of patients who were treated by their primary care doctor or those who took OTC PPIs.\nCompared to those prescribed medications by a gastroenterologist or primary care doctor, more patients in the OTC group took lower doses than recommended.\nMore patients in the group taking medications prescribed by a primary care doctor took too much medication, compared to the OTC or gastroenterologist-treated patients.\nThe patients’ symptom relief corresponded to whether they received the proper dose. Patients who took more or less medication than recommended reported more frequent and worse symptoms than patients who took the correct dose.\nBecause antacids can be taken as needed, the authors noted that they were not surprised that people who bought OTC PPIs did not take them as required and so did not achieve relief of their symptoms.\n“Optimal dosing would likely reduce morbidity [sickness] and healthcare costs while improving overall quality of life,” the authors wrote.\n\"Furthermore, package inserts need to more clearly emphasize the importance of daily prebreakfast PPI use to maximize acid suppression,\" they wrote.\nSeveral limitations of this study were noted by the authors. Some OTC PPIs are sold at lower doses than the prescription medications some patients took. The researchers also noted that the survey used to score patient symptoms included some symptoms that were not specific to GERD.\nThis research was published in the June issue of The American Journal of Gastroenterology.\nThe authors declared no conflicts of interest.","When dietary changes and natural remedies alone do not solve your heartburn or indigestion, a range of over counter options are available. But how do you choose which is the best heartburn medicine for you – an antacid, or a medicine that switches off aid production? Here are some pointers.\nWhat causes heartburn?\nHeartburn is caused by acid juices refluxing up into the gullet, or oesophagus, from the stomach. Known medically as gastroesophageal reflux disease, or GERD and GORD for short, this causes a hot, burning sensation behind the chest bone, which may spread up towards the throat. Some cases of heartburn are so severe they resemble a heart attack. If you experience chest pain that worries you, seek medical help without delay as it is not always easy for doctors to tell the two apart without specific tests.\nIn contrast, some people have so-called silent reflux, in which they don’t experience burning pain, but may have unexplained hoarseness, vocal fatigue, voice breaks, coughing, a sensation of a lump in the throat, or repeated swallowing or throat clearing.\nSymptoms of GERD\nFor two out of three people, heartburn symptoms of burning pain come on in the evening and many are woken as a result.\nEvening symptoms are usually related to eating a large meal (three or more courses) which is rich (eg with a cream sauce) or heavy (eg gateaux, cheesecake).\nSymptoms are also associated with wearing tight evening clothes/waistbands, drinking alcohol (eg an aperitif, wine with food, after-dinner port, spirits or liqueurs), drinking strong coffee and smoking cigarettes or cigars.\nAfter an episode of dietary indulgence, lying down increases pressure on the valve that normally closes the stomach and promotes acid reflux.\nThis is especially common if part of the stomach has slipped up into the chest through a natural hole in the diaphragm, through which the oesophagus passes, to cause a hiatus hernia.\nHow common is heartburn and GERD?\nHeartburn, due to acid reflux or GERD, affects one in four people on a regular basis. At least one in ten adults experience heartburn every day, and 40% have heartburn at least once a month.\nMen are twice as likely as women to report sleep disturbances every night due to heartburn, and in surveys, almost one in five say they’ve needed to take time off work as a result of heartburn. Four out of five people avoid foods they enjoy for fear of developing symptoms.\nHeartburn becomes increasingly common with age, as the muscles that usually close the entrance to the stomach, and downward movements of muscles in the oesophagus which normally prevent reflux, naturally weaken.\nDietary approaches and natural remedies are often effective in preventing heartburn and are covered in my post on Natural Remedies for Heartburn and Indigestion. Lifestyle approaches include:\n- Wearing loose clothing, especially around the waist – elasticated bands are better than tight buttoned bands or belts\n- Avoid smoking cigarettes or cigars which can make heartburn and GERD worse\n- Avoid aspirin and related drugs (eg ibuprofen) which irritate the stomach lining and cause heart burn as a common side effect\n- Avoid excess stress which is a major cause of indigestion through effects on the vagus nerve\n- Elevate the head of your bed about 15-20 cm (eg put books under the top two legs) if symptoms come on at night when you are lying down\n- If you lie on your side to sleep, lie on your left side rather than your right side as much as possible.\nDon’t sleep on your right side\nHeartburn is common on lying down, as this allows stomach contents to press against the ring of muscle that normally keeps the stomach opening closed. When you like on your right side, the shape of the stomach means that stomach acid pools against the valve at the lower end of the oesophagus so that acid reflux and heartburn are likely.\nIf you sleep on your left side, however, this keeps the junction between the stomach and oesophagus above the level of gastric acid, and also makes it easier for trapped wind to roll up the curve of the stomach and escape as a satisfying ‘burp’.\nOver counter medicines for treatment of heartburn and acid reflux\nIf diet, lifestyle and natural remedies have not fully controlled your symptoms, a range of medicines are now available from pharmacies and supermarkets, many of which were originally only accessible on prescription.\nSilicol gel for heartburn and indigestion\nSilicol gel contains silicic acid which, despite its name is a bland, non-acidic, mineral substance containing silicon and oxygen in a colloidal, hydrated form. Just a small amount of this dispersible gel creates a protective lining in the stomach and intestine. The gel acts as a magnet physically binding with substances which cause inflammation, and renders them harmless to pass through the digestive tract. It also provides a physical barrier to soothe heartburn and indigestion.\nEnterosgel for heartburn and indigestion\nIf you experience indigestion, heartburn, bloating or flatulence after eating a particular type of food such as wheat, dairy, caffeine, alcohol, tomatoes, potatoes or peppers, for example, some naturopaths believe this could be due to a food intolerance that triggers digestive symptoms. You may find that taking a tablespoon of the toxin-binding gel, Enterosgel, before or after eating the food may help.\nAntacids for heartburn and GERD\nAntacids have been used to treat heartburn for over 2000 years, with ancient remedies such as calcium carbonate and drinking milk are still used today to solve short-term symptoms of heartburn.\nDifferent antacids work in different ways to reduce indigestion, heartburn and acid reflux.\nMineral antacids contain substances (eg calcium carbonate, aluminium hydroxide, magnesium trisilicate) that react chemically with stomach contents to neutralise excess acid.\nAntacids that contain magnesium salts may have a laxative action while those containing aluminium salts are more constipating. If these side effects are troublesome, then select an antacid that contains both magnesium and aluminium to reduce these intestinal side-effects.\nMy go-to antacid, to keep handy in the home and office, is Remegel. Remegels are chewy rather than chalky, and each chew contains 800mg calcium carbonate as an invaluable source of calcium.\nAntacids are available as liquid suspensions or chewable tablets of which some are chalky, while others are more like a chewy sweet. These are ideal for keeping in your bag or a drawer to treat mild, occasional heartburn. For more troublesome heartburn, a liquid preparation (eg raft-forming antacids, below) are generally more effective than tablet preparations.\nRaft-forming antacids contain sodium alginate and potassium bicarbonate which interact with stomach acid to form a foam-like raft of alginic acid gel. This floats on the surface of stomach contents. This raft forms quickly, often within a few seconds of taking a dose, and acts as a physical barrier so acid cannot break through. This raft helps to stop acid reflux and quickly relieves discomfort. If reflux does occur, the raft itself refluxes into the oesophagus to form a soothing (demulcent) film. Antacids present in the formulation also neutralise excess acidity.\nSimeticone (activated dimeticone) is included in some antacids as an antifoaming agent to relieve flatulence and also helps to reduce hiccups which can occur with acid reflux due to irritation of nerves that also control the diaphragm.\nAntacids reduce acidity but do not stop further acid secretion. If short-term relief is insufficient, then more powerful drugs that temporarily switch off stomach acid production and have a longer term action can be added in.\nHistamine H2 receptor antagonists for heartburn\nHistamine H2 receptor antagonists (eg cimetidine, famotidine, nizatidine, ranitidine) interact with stomach cells to switch off acid production for up to12 hours. At one time, these were only available on prescription, but after a thorough review of their safety and effectiveness, they are now available without needing to see your doctor first.\nAlways read the patient information leaflet in the pack. Click here to see a typical patient information leaflet for ranitidine (Zantac 75 Relief) and for famotidine (Pepcid).\nThese heartburn treatments work quickly and relieve acid reflux and indigestion more effectively than simple antacids alone. They can also reduce your need to take antacids regularly throughout the day.\nProton pump inhibitors for heartburn\nProton pump inhibitors (PPIs such as esomeprazole, lansoprazole, omeprazole, pantoprazole and rabeprazole) are the most powerful medicines available to relieve heartburn and GERD.\nProton pump inhibitors interact with stomach lining cells to reduced acid production by at least 80%, for up to 24 hours. Proton pump inhibitors are used to treat peptic ulcers, are combined with antibiotics to treat Helicobacter pylori (a bacterial infection that irritates the stomach lining and is associated with peptic ulcers) and to treat acid reflux, or GERD. Some proton pump inhibitors are now available over counter to provide effective relief of indigestion and heartburn symptoms.\nThe downside is that proton pump inhibitors take a few days to work – the maximum effect is usually achieved within 4 days. Many people do not obtain complete heartburn relief during the first one or two days of treatment, but you can take a mineral antacid or a raft-forming antacid as well, while waiting for the proton pump inhibitor to reduce your acid symptoms.\nWhile proton pump inhibitors reduce acid production in the stomach, they do not stop reflux. Digestive juices, which contain strong enzymes, may still reflux up to irritate your oesophagus. This means that some people still get symptoms of heart burn even though they are taking these stronger medicines. If this is the case, see your doctor.\nProton pump inhibitors are usually used as a short course only, as it’s not a good idea to switch off acid production for too long – acid is needed to digest food properly, and for the absorption of some vitamins and minerals.\nAlways read the patient information leaflet in the pack. Click here to see a typical patient information leaflet for esomeprazole (Nexium Control) and click here to see a patient information leaflet for omeprazole (eg Prilosec).\nSee your doctor\nIf heartburn symptoms continue for more than a week or two, or if they become more frequent or severe, it’s important to seek medical advice. You may need further investigation of your symptoms to exclude a peptic ulcer, for example, or tests to look for a stomach infection with a type of bacteria (Helicobacter pylori) that irritates the stomach lining and stimulates increased acid secretion.\nDon’t ignore recurrent heartburn or continue to treat it with antacids or other over counter medicines. Taking antacids long-term does not protect against damage due to acid attack on delicate tissues. Stronger medicines are available on prescription. If symptoms do not respond to drug treatment, severe reflux may need surgical correction.\nClick here for information on diet and natural remedies for heartburn and indigestion.\nWhich over the counter medicine have you found most effective for heartburn or GERD?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:3a6993fe-4d16-47f6-a2c2-aea01404bfba>","<urn:uuid:3ea7538e-12d9-40b9-8060-98204b16c28f>"],"error":null}
{"question":"What are the key differences between BGP and RIPv1 in terms of their routing mechanisms and metrics?","answer":"BGP and RIPv1 have several fundamental differences in their routing mechanisms and metrics. BGP determines optimal routing paths based on various attributes and rules, supporting Classless Interdomain Routing (CIDR), and can handle multiple route advertisements from different sources using a best path selection algorithm. In contrast, RIP uses only hop count as its metric, with a maximum limit of 15 hops, and load balances up to six equal paths (four by default). RIP sends its entire routing table to directly connected neighbors every 30 seconds regardless of topology changes, while BGP's path selection is more sophisticated, involving attributes like AS path prepending and Local Preference. Additionally, RIPv1 is a classful routing protocol that doesn't advertise subnet masks in updates and automatically summarizes networks at classful boundaries, whereas BGP can handle more complex routing scenarios, including both internal (iBGP) and external (eBGP) routing within and between autonomous systems.","context":["When you are viewing your favorite internet website, obviously, you are not directly connected to the server of the website. Technically speaking, packets have to travel through a bunch of routers to reach their destination. But how do the packets know which route to take when the global routing table consists of approximately 660 thousand routes to date? And how do they know which is the best path if there is more than just one exit?\nThe magic behind each packet being sent and delivered on the internet is nothing else but routing on the layer L3 – the so called network layer. It is the routing protocols which enable the communication between different networks on the TCP/IP (internet) to work. Each network has its own autonomous system (AS) number assigned. Routing protocols are designed to exchange routing information within your AS as well as between other AS’es.\nThe most popular routing protocol is Border Gateway Protocol (BGP), which is common in the internet service provider world. Without BGP, internet communication would be impossible or at least less flexible. Let’s take a closer look at BGP and find out if it is a good fit for your network needs.\nWhat is BGP\nBGP is designed to route packets both, throughout the internet (eBGP) as well as within your internal network (iBGP) – within a single AS. It determines the optimal routing path to send/receive packets based on a set of rules and attributes. BGP configuration is represented by mechanisms determining a degree of preference of routes – supporting Classless Interdomain Routing (CIDR). A BGP router can receive more copies of routes (multiple advertisements) from multiple sources. The BGP best path selection algorithm gives the router an instruction about which path to prefer based on your BGP settings.\nDo I need BGP?\nThere are a few network scenarios when the implementation of BGP is highly recommended. But before we go on with this, you have to first understand the difference between default route and full routing table.\nLet’s assume you run your own network AS1 with a few end users and you use a service provider – ISP. Because you only have one ISP – your network is single-homed, there is only one exit path, therefore you advertise the default route using BGP. With default route, you are not able to see what networks are passed on the way from source to destination in the route table (because you do not see path). Your ISP will send default route toward your AS1 network.\nFull routing table comes into play in a scenario when AS1 is multi-homed – uses two different ISPs – ISP1 and ISP2 to ensure redundancy and network optimization.\nBGP network – full routing table\nAS1 announces its prefixes to ISP1 and ISP2 via BGP – AS1 is a multi-homed BGP network. AS1 now receives full BGP routing table and sees all AS’es on the path. This way networks don’t have to be connected to each other in order to learn their prefixes. But how does BGP know if a packet should take the path through ISP1 or ISP2? BGP determines the best path based on a set of attributes and filters – the so called BGP best path selection.\nBGP best path selection\nAs I mentioned in the previous section, a BGP router receives multiple copies of routes from multiple providers. Therefore there is an algorithm for comparing the BGP routing tables and selecting the most efficient path which will go into the IP routing table on the local BGP speaker. Choosing one path over another has direct influence on network operational costs and the overall quality of service (delay, packet loss, etc.).\nWe don’t want you to feel overwhelmed by describing the functionality and role of each and every BGP attribute. Let’s just take a look at three examples of BGP use.\nExample #1 – AS path prepending:\nAS path is probably the most commonly used BGP attribute. Imagine a network (AS1) be a multi-homed network which uses two internet exchange points to exchange its traffic with other AS’es. AS1 announces its prefixes to both exchanges – IXP1 and IXP2. Behind both IXP1 and IXP2 are AS2, AS3 and AS4. AS paths from AS2, AS3 and AS4 toward AS1 are of the same length. AS2 and AS3 send their traffic through IXP1 and AS4 through IXP2.\nLet’s say that AS1 changes its peering policy and prefers to receive prefixes from AS2 and AS3 also via IXP2 instead of IXP1. It prepends its AS path towards IXP1 so that it looks longer.\nAll the traffic from networks connected to both internet exchanges now goes through IXP2 if no other filters and policies have been set.\nExample #2 – Local Preference:\nAS1 is a multi-homed customer of a service provider AS2 connected with one 10GE link and one 100GE link.\nAS1 wants to use the lower capacity 10GE link as a backup and send all traffic through the 100GE link. AS2 allows AS1 to use Local Preference to influence their routing so that AS1 can send all its announced routes through the higher bandwidth link by setting a higher local preference of 200 on the interface toward R2.\nExample #3 – AS path access lists (another Local Preference case):\nLet’s assume we would like to optimize routing to Swisscom and prefer routes via operator 1 over operator 2. AS path access lists are the best tool to do so. An AS path access list is a list based on AS path information and rules learned by a router. Every new route update is filtered through an access list and then based on filters either permitted or denied. Routes can then be assigned a BGP attribute, e.g. higher/lower Local Preference, Weight, etc.\nIn our example, we use access lists to accept everything with last hop being Swisscom AS and set the route via operator 1 a higher Local Preference.\nOur routing strategy at DataPacket is to maintain consistent network quality and the highest possible availability.","The first distance vector routing protocol that is discussed here is coincidentally one of the oldest routing protocols that is still used today. Circa 1988, Routing Information Protocol (RIP) for IP was defined in RFC 1058; however, its roots stem back to the 1970s at Xerox Corporation’s Palo Alto Research Center. The following sections look at the characteristics\nand configurations involved with this resolute routing protocol.\nRIP is a fairly simple routing protocol in both characteristics and implementation. You already know that RIP uses hop count as its only metric, in which it can support up to 15 as a maximum. In instances where the metric is identical (for example, equal hop count) for a subnet, it\nload balances up to six equal paths (four by default). Like other distance vector routing protocols, RIP sends the contents of its routing table to its directly connected neighbors, regardless of whether there is a change in the topology. Particularly, RIP’s update interval is every 30 seconds and its invalid timer is for 180 seconds. Thus, RIP (version 1) broadcasts its routing table\nevery 30 seconds and considers a neighbor or a network to be dead after six missed updates.\nBecause RIP does not advertise subnet masks in its routing updates, it is also a classful routing protocol. Recall that this requires every subnet of a major network to have the same (fixedlength) subnet masks. In addition, RIP automatically summarizes subnetted networks to their default classful boundaries when sending the update over a different major network which, in turn, nullifies any support for a discontiguous network design. As with many routing protocols, RIP requires manual redistribution if you want to advertise networks from a different routing source other than connected interfaces and other RIPlearned networks.\nThis is also the case for default routes. If you configure a static default route in a router that is running RIP, you must use the default-information originate command in the routing process to redistribute that default route in its routing updates to its neighbors without any additional configuration. The neighbors receive these updates and set that router as their gateway of last resort, assuming that a static default route is not configured with a lower administrative distance. The routing table subsequently displays the learned 0.0.0.0/0 subnet as a RIP-learned network.\nAlthough version 1 of RIP is considered outdated by the CCNA, ICND1, and ICND2 exams, it is important to know its characteristics and configuration because RIPv2 shares many characteristics and is similar in configuration.\nThe configuration for RIP is seamless as long as you remember these two simple rules:\n- Advertise only your directly connected networks.\n- Advertise only the classful network.\nThe first rule is imperative to keep in mind when configuring routing protocols. Remember that the point of the routing protocols is to advertise their known networks to each other so they can build their routing tables. With that being said, do not confuse the configuration of routing protocols with static routes. You do not specify a destination network with routing protocols as you would a static route. In\nBecause RIP is a classful routing protocol and does not advertise subnet masks in its updates, the second rule is self explanatory. Regardless of whether you subnetted major networks into smaller subnets, you have to specify only the subnet to its classful boundary. In other words, you specify the network portion of the IP address and use zeros for the host bits. To recap, the classful boundaries are listed in Table 11.2, in which N represents the network and H represents the host\nTo configure RIP and advertise the directly connected classful networks, you must enter the configuration mode for routing protocols, using the router keyword in global configuration mode followed by the routing protocol you want to configure. After you are in the routing protocol configuration mode (signified by the (config-router)# prompt), you specify the directly connected classful networks by using the network command. If you need to remove a specific network from being advertised, you need to enter the RIP routing process again and enter no followed by the keyword network and the network number you want to remove. Using Figure 11.9 as an example, Routers A, C, and D each have two directly connected networks while Router B has three. To configure RIP to advertise the routing protocols, the configuration for Router A would look like the following:\nIf you accidentally configure a network at the incorrect classful boundary, the IOS configuration automatically changes your configuration statement(s) to reflect the classful network.\nBe prepared to configure a routing protocol given a network topology. Even though there is IOS support to autocorrect your mistakes when entering the networks, as mentioned in the preceding Tip, do not rely on the exam to allow that as a correct answer.\nBecause Router A has the 172.16.0.0 network and the 192.168.1.4 network attached to it, the classful networks that are advertised are 172.16.0.0 because it is a Class B, and 192.168.1.0 because that network is a Class C. You do not need to include any other network statements because the routers will advertise each others’ networks. After you define the networks with the network command, RIP begins to advertise and listen for updates on those interfaces that are contained in that classful network. For instance, if you did not configure the network 192.168.1.0 statement in Router A, you would never be able to send and receive updates on the serial interface, which would entail that Router B would never learn of the 172.16.0.0 network and Router A would never learn of the other networks in the topology\nKeep in mind that the routing protocol does not listen to or learn from advertisements on an interface unless you include their respective networks in the routing protocol process with the network command.\nRouter B has three directly connected 192.168.1.x networks, so how many statements do you think you must configure for Router B to participate in RIP updates? Despite having three networks, you must advertise the classful networks in the RIP configuration; thus, you require only one statement for the 192.168.1.0 network that will, in essence, encompass all three subnets. Figure 11.10 shows the configurations for each router in this topology\nFIGURE 11.10 Completed RIP configuration scenario.\nIf you want to change the number of allowed equal paths to load balance with RIP, you can use the maximum-paths command in the routing process. For example, if you wanted to change the maximum paths to six equal paths, the configuration would look like the following:\nTo disable load balancing over multiple equal paths, set the maximum paths to 1.\nSome of you may have looked at these configurations and noticed a strange flaw in our logic. Namely, we’ve established that when we configure each network to be advertised in the routers, updates begin being sent and received on the interfaces attached to those networks. But do we really need to be sending updates on LANs that do not connect to RIP routers? For instance, the Ethernet interface on Router A from Figure 11.10 that connects to the 172.16.0.0 network does not have a router on that LAN segment. In essence, we are wasting good bandwidth and processor cycles by broadcasting these RIP update every 60 seconds to a bunch of computers who do not need to receive them. To solve this dilemma for RIP and all other routing protocols, Cisco created a handy configuration option for routing protocols called passive interface.\nWith this additional configuration command, you specify an interface or interfaces to the routing protocol process that will no longer send routing updates. What is interesting, however, is that the interfaces will still receive and process updates on that interface. As a result, passive interfaces are useful not only for saving bandwidth, but also can be used to manipulate our routing policies by allowing us to determine whether or not we send routing updates to certain routers. The command to achieve this marvelous feat is passive-interface interface in the routing process configuration, such as shown here for RIP:\nRouterA(config-router)#passive-interface fastethernet 0/0\nWith this command in place, updates are no longer sent out of Fast Ethernet 0/0. However, if for some reason an update was received on that interface, it would still process it and put it in its routing table.\nIn an attempt to keep up with modern needs from a routing protocol, RIP version 2 was created in 1994 to address many of the shortcomings of its predecessor. Many of the characteristics are similar to RIPv1; nonetheless, RIPv2 had some significant improvements:\n- Multicast updates: Rather than broadcast its routing updates, RIPv2 uses a reserved multicast address of 126.96.36.199 to communicate with other RIPv2 neighbors. By using a multicast address, it does not waste the processing resources of non-RIP devices because only RIPv2 devices process messages to that address.\n- Classful or classless support: RIPv2 is classful by default, but can be configured as a classless routing protocol, which allows for subnet masks to be sent in the routing updates. The implication of this enhancement entails that RIPv2 can support VLSM and discontiguous network designs.\n- Authenticated updates: To ensure the origin of the routing update and protect from attackers spoofing routing updates, RIPv2 allows update authentication in which the passwords must match in all routers to validate the routing update.\nBe sure to remember the enhancements that RIPv2 holds over RIPv1."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f67efa8a-8ce7-49a1-b007-c111c14c5994>","<urn:uuid:8dc589c5-73c2-4084-97c7-647103055e57>"],"error":null}
{"question":"What is the Nanoracks Bishop airlock's impact on the ISS, and what debris-related challenges does the station face in orbit?","answer":"The Bishop airlock significantly increases the ISS's payload capacity, adding five times more capacity than the current government-operated JEM airlock. It enhances public and private research capabilities and allows for larger satellites and tools transfer. However, the ISS faces constant challenges from orbital debris, with NASA and the Department of Defense tracking about 19,000 pieces larger than softball-size. The station must be moved when there's more than a 1 in 100,000 chance of collision, and astronauts occasionally need to take shelter in lifeboats when warnings come too late.","context":["Nanoracks Bishop airlock installed on the International Space Station.\nVoyager Space Holdings’ fourth acquisition in just over a year since its inception is a controlling stake in the parent company of Nanoracks, a space services and hardware specialist that has dispatched more than 1,000 missions to the International Space Station.\n“Nanoracks is a fundamental shift for us when it comes to adding some pretty significant functionality in space,” Dylan Taylor, CEO of Voyager Space Holdings, told CNBC.\nVoyager intends to acquire a majority stake in XO Markets, Nanoracks’ holding company, which is expected to close in the first quarter of 2021.\nWhile Voyager Space Holdings did not disclose the financial details of the deal – Taylor merely remarked that “we are putting quite a lot of money into the business” to make it grow – those familiar with the deal told CNBC that Voyager plans to will invest more than $ 50 million worth of nanoracks in the coming year.\nThe majority stake in XO Markets is Voyager’s fourth deal since it was founded in October 2019. The company previously had rocket and spacecraft services specialists The Launch Company, satellite services company Altius Space Machines and Pioneer Astronautics, the research and development company of Dr. Robert, taken over by Zubrin, best known for his talks with SpaceX CEO Elon Musk about building a permanent human presence on Mars.\n“We’re an operating company, not a fund. This is how we put skills together,” said Taylor. “Once we have all of these skills put together, we can have an overwhelming impact on the industry by being able to carry out really complex and meaningful missions in space.”\nJeff Manber, CEO of Nanoracks, said he began looking for new capital last summer, including a special purpose vehicle (SPAC) review of the IPO. But Manber told CNBC that he didn’t want to “spend my next two years” talking to Wall Street investors and “figuring out how to take it” instead of focusing on running and growing his business.\n“With Voyager, we have a platform that enables us to grow into the entire development of the infrastructure for in-space services, with a financial sophistication and synergy that we honestly wouldn’t have on our own,” said Manber. “They give us stability. They give us the platform. They give us some of the expertise that we don’t have today.”\nIn turn, Manber sees Nanoracks as the “core” of Voyager’s space effort, with new access to the company’s mission control room in Houston, Texas, as well as facilities across the country, and talent who have experience working with a variety of payloads gone into space .\nNanoracks: ‘The boys from the space station’\nThe Bishop airlock, built by Nanoracks, will be installed on the International Space Station via the Canadarm2 robot.\nThe deal also comes after Nanoracks reached important milestones on Saturday in installing its Bishop Airlock on the International Space Station. Nanoracks fully funded the development and manufacture of the airlock and launched it on a SpaceX cargo mission to the ISS on December 6th.\nBishop is the first private airlock to add five times the payload capacity of the current government-operated JEM airlock. NASA noted that the addition of Bishop “significantly increases the capacity for public and private research,” which “also allows the use of larger satellites and the transfer of space-grade tools and hardware inside and outside the station.”\n“Nanoracks are the largest commercial user of the International Space Station,” said Manber. “We’re the people of space stations – we understand space stations better than probably any commercial emerging company in the world.”\nNanoracks employs around 70 people worldwide and is headquartered in Houston. The company also has offices in Washington, DC, as well as Turin, Italy and Abu Dhabi, United Arab Emirates.\nManber sees the growth of nanoracks in a strategy of three pillars, the first of which is the current use of the ISS.\n“The Bishop airlock is our biggest growth catalyst for the future,” said Manber.\nBut “the space station is aging,” said Manber, and he would like nanoracks to be involved in “private space stations with market orientation” in the future. He expects “small private space stations”, each focused on individual markets, to be introduced in the next decade with “some hotels and some for professional astronauts”. The “second pillar” of Nanoracks is the outpost program, which aims to turn the large discarded fuel tanks of rockets around the earth into small space stations.\nThe first demonstration of Nanoracks’ outpost technology, named Mars Demo-1, is set to launch on a SpaceX ridesharing flight in June 2021. The mission will use a robotic arm to cut metal material in space to demonstrate that Nanoracks can safely cut missile tanks to turn them into revolving hubs. Manber hopes that Nanoracks will start a follow-up mission in 2023 and then “stay longer and longer in space each year and rebuild these otherwise empty platforms”.\nA SpaceX Falcon 9 rocket successfully launches on November 15, 2018 at the Kennedy Space Center in Florida with the Es’hail-2 communications satellite for the country of Qatar.\nNurPhoto | NurPhoto | Getty Images\n“The third pillar is to become a space exploration customer,” said Manber. “In-space research is a market that has been completely dominated by the government and is funded by space agencies that occasionally involve a trading company such as a pharmaceutical company or a pharmaceutical company [agricultural] Tech company. “\nNanoracks’ in-space research service would help more companies “take advantage of the harsh environment of outer space to develop new products”.\nManber described his three-pillar strategy as “emulating what SpaceX does” by taking over a core business and then steadily building on it.\n“This industry is getting very serious now and an important one from a commercial point of view,” Manber. The more [Nanoracks] I’ve spoken to a number of family funds and hedge funds the more I’ve looked at this and noticed how the industry is going. “\nJoining Voyager is Manber’s way of aligning Nanoracks so that there isn’t a single project or program that it depends on for success.\nVoyager aims to go public in late 2021\nRocket 3.2 is on the launchpad in Kodiak, Alaska.\nAstra / John Kraus\nTaylor explained that a disadvantage of building an operational business is that “you really can’t do more than four deals effectively or productively a year” because Voyager doesn’t create a “brand portfolio” but works to integrate them as a cohesive whole . Still, Taylor said that Voyager has about a dozen acquisitions “in our pipeline under various due diligence” and expects to announce another two or three by summer 2021.\n“And then it’s still our wish … to try to go public sometime late next year,” said Taylor.\nHe intends to bring Voyager to the public via the traditional IPO route and says “it is valuable to go through the S-1 process”.\nIn the meantime, Voyager wants to add companies that build spacecraft components and specialists in software – also known as GNC or guidance, navigation and control. Taylor says Voyager will at some point “look at a launch capability,” which means a rocket builder like SpaceX or Rocket Lab, but he doesn’t expect that to happen in the next year.\nSubscribe to CNBC PRO for exclusive insights and analysis as well as live business day programs from around the world.","Right now, there are more than 300,000 pieces of debris larger than a centimeter in diameter orbiting Earth.\nThey range from tiny shards of metal to deactivated, decades-old satellites. Most are shrapnel from discarded rocket stages that have exploded after use, or satellites that have collided. Colloquially, all this debris is usually called \"space junk.\"\nTogether, the Department of Defense and NASA track the orbits of the 19,000 or so pieces of junk that are larger than a softball, alerting satellite operators when any satellite — including the International Space Station — is in danger, so they can move it.\nBut doing so takes time and resources. What's more, the cloud of debris has been steadily growing over time, and some scientists worry that if we're not careful, we could trigger a chain reaction: More space junk raises the chance of collisions, which in turn can lead to even more debris, until the sheer volume of space junk makes parts of space unusable.\n\"Space is a finite resource — just like the atmosphere, and the water, and the Earth,\" says William Schonberg, an aerospace engineer who designs spacecraft to minimize damage from orbital debris. \"We need to be careful about how we use it.\"\nWhy space junk is a problem\nEven small pieces of debris in orbit around Earth can cause a surprising amount of damage because of a basic reason: speed.\n\"All the objects in Earth's orbit naturally have a high velocity,\" says Holger Krag, head of the European Space Agency's Space Debris Office. (If they weren't traveling that fast, they'd simply drop to Earth.) In low Earth orbit, this speed is around 16,000 miles per hour. \"Even a centimeter-long screw can generate the energy of an exploding hand grenade.\"\nAs a result, collisions have to be avoided at all costs. Using ground-based radar and other instruments, the Department of Defense and NASA keep track of about 19,000 pieces of debris larger than five centimeters — the ones big enough to cause significant damage.\n\"We do an assessment for every operational satellite, looking typically three days into the future, and if we think that some other object is going to come close to hitting it, we notify the owner-operator,\" Nicholas L. Johnson, then-chief scientist at NASA’s Orbital Debris Program, told me in 2012. About once a week or so, satellites are moved to prevent a collision.\nBecause there's crew on board, the International Space Station is treated with extreme delicacy and is moved if there's more than a 1 in 100,000 chance something will collide with it. In a few cases, warning hasn't come in time, and astronauts have had to quickly take shelter in the capsules that serve as the station's lifeboats.\nEven with these preventative measures, though, debris are a long-term issue for space operations as a whole. One problem is that a steady stream of even tinier, sand grain-sized particles can gradually erode the surface of all spacecraft in orbit.\nAnd there's a bigger concern for heavily-trafficked orbits — such as low Earth orbit and geosynchronous orbits (often used for communication satellites, so they can stay fixed over one location on Earth). As these orbits fill with debris, they become more and more expensive to use. \"Every collision avoidance maneuver means loss of mission time,\" Krag says. \"And you have to use manpower and fuel to carry them out.\"\nAll debris eventually falls back to Earth given enough time — and objects in lower orbits fall much faster, over the course of a few years, because traces of atmosphere drag on them and slow them down. But those in higher orbits might take decades or even centuries. And if we're not careful, some orbits could become so clogged with junk that they're impossible to use.\nWhere all the space junk came from\nA few different factors have contributed to the steady accumulation of orbital debris ever since we started using space in the 1950s.\nOne is the fact that for decades, the rockets we used to lift spacecraft into orbit were only designed with the first few minutes of flight in mind. \"We didn't think at all about how the object might behave after years or decades,\" Krag says.\nAs a result, rocket components were commonly left in orbit with tiny amounts of extra fuel and built-up pressure inside. When an object in orbit leaves the shadow of the Earth and is hit by sunlight, its temperature can swing by hundreds of degrees. This has led many rocket stages to explode, sending thousands of shards of metal cascading in orbit.\nIn the 80s, scientists recognized the problem, and now, rockets are designed so that they can be fully emptied after use. These intact rockets, along with deactivated satellites, make up a minority of the pieces of debris in orbit.\nBut two recent events generated another 5,000 pieces of tracked debris, generating about a quarter of the total.\nIn 2007, China intentionally destroyed one of its weather satellites in orbit as part of a military test, generating about 3,000 pieces of debris. Even worse, it was done in a higher orbit than other anti-satellite tests previously conducted by the US and Russia, so the debris will take much longer to come down. Other countries criticized the test, but the damage was done.\nThen, in 2009, two satellites — a deactivated Russian military satellite and an active US communications satellite — accidentally collided, creating a shower of another 2,000 or so pieces of debris.\nWhat's going to happen to space junk in the future\nThe 2009 event was especially alarming because it may be a sign of things to come: if space gets too crowded with debris, it could trigger a positive feedback loop, in which collisions beget debris, which beget collisions.\nSome scientists, in fact, believe this scenario (called the Kessler syndrome) is already happening, just slowly. Unlike in the movie Gravity, the chain reaction would accelerate slowly, over the course of decades: right now it's estimated that one collision will occur every five years, and if things get worse, the rate could increase to one collision annually within 50 to 100 years.\nStill, there's disagreement over whether this is happening yet — and spacefaring nations are generally being more careful nowadays. Rockets are drained of fuel and pressure after use, and satellite operators are now required to move their satellites down to a lower altitude after use, so they'll fall back to Earth more quickly, or take them up to an unused \"graveyard\" orbit.\nStill, there's tons of debris already in orbit. If we did enter a scenario in which debris accumulated uncontrollably, people have drawn up some ideas for cleaning up our orbits: crafts that would use nets or harpoons to grab derelict satellites to bring them down, for instance, or a spacecraft that would grab debris, throw it down to Earth, and use the resulting momentum to move on to the next object.\nAt the moment, though, these ideas are purely hypothetical, and all of them would be extremely expensive. If we want to continue relying on Earth's orbit for communication, navigating, and all other sorts of useful technologies, we need to be more careful with it going forward.\nFurther reading: How NASA steers the International Space Station around space junk"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:72d344d0-2c23-4d4e-ab6d-6b75b3699b1c>","<urn:uuid:af09ffe4-73dd-4917-b8ac-4c2ad6170415>"],"error":null}
{"question":"What did Jeannette Rankin do to advance women's suffrage while serving in Congress?","answer":"During her two years in Congress, Rankin advocated strongly for a women's suffrage amendment. Due to her advocacy, the Committee on Woman Suffrage was created and she was appointed to it. While a resolution passed in committee, it ultimately failed in the Senate.","context":["Throughout March 2015, in honor of Women’s History Month, we will be featuring unsung heroes and stories of the women’s suffrage movement. You can find more of those well-known and not-so-well-known stories in our EDCollection “Women, Their Rights and Nothing Less ” module, endorsed by NCSS. To access these resources, you must be signed into NewseumED; registration is free.\nJeannette Rankin spent her entire career fighting for social reform, women’s rights and peace. Born in Montana in 1880, Rankin graduated from Montana State University and attended the New York School of Philanthropy; from there she was employed as a social worker in Spokane, Wash., and attended the University of Washington, Seattle. It was in Seattle that she joined the women’s suffrage movement and dedicated her career to the cause.\nRankin joined the National American Woman Suffrage Association (NAWSA) and worked for suffrage in Washington state. When Washington granted women’s suffrage in 1910, Rankin switched her efforts to her home state of Montana. After Montana gave women the right to vote in 1914, she had her sights set on something bigger: U.S. Congress.\nRankin ran as a progressive Republican in a heavily Democratic state and became the first woman elected to Congress, owing much of her success to her reputation as a suffragist and Montana women voting in their first federal election. However, not all suffragists supported her campaign; some believed it would hurt the suffrage cause. Throughout her campaign, she pledged to support a women’s suffrage amendment, social welfare reforms and keeping the United States out of war in Europe.\nOn the day she was sworn in, along with the other members of the 65th Congress, President Wilson addressed the legislature asking them to “make the world safe for democracy.” A few days later, Rankin was one of 50 representatives to vote against American participation in the war. After the vote, suffragists distanced themselves from her and she received backlash in her home state.\nDuring her two years in Congress, Representative Rankin fought hard for a women’s suffrage amendment. Because of her advocacy, the Committee on Woman Suffrage was created and she was appointed to it. A resolution passed in committee, but it failed in the Senate. Rankin also faced redistricting and a massive strike in Butte, Montana, after a mining disaster. With the prospect of campaigning in a new, heavily Democratic district, Rankin made the decision to run for Senate instead of the House. Unfortunately, she came in second in the Republican primary, officially ending her bid.\nAfter her short stay in Congress, Rankin continued to fight for social reform and women’s suffrage. As another war threatened, Rankin decided to run for the U.S. House again in 1940. This time, she was one of five women successfully elected to Congress. In December 1941, after the bombing of Pearl Harbor, the House voted on a declaration of war. The vote was 388-1 in favor of war; Rankin was the only one to vote against.\nRankin did not run for Congress again and continued to fight for peace. During the Vietnam War, she led the Jeannette Rankin Brigade through Washington, D.C., protesting the war. Rankin died in 1973, but was considering another run for Congress, this time to fight against the Vietnam War.\n|Click here for more “Unsung Heroes”|\nNewseumED is a free resource featuring primary sources, interactives, historic newsreels, videos and lesson plans that bring history, journalism and the First Amendment to life for students."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:0fae58d4-0d5f-4e16-a1f1-7083795a8394>"],"error":null}
{"question":"¿What are los beneficios of well-child visits para la salud preventiva, and how does this compare to adult preventive care through vaccines?","answer":"Well-child visits are essential for preventive pediatric care, allowing doctors to monitor physical and mental growth, provide immunizations, conduct screening tests, and address parents' concerns about development, behavior, nutrition, and safety. These visits follow a specific schedule starting at 3-5 days of age and continue annually. Similarly in adult preventive care, regular vaccination is crucial as vaccine protection wanes over time. Adults need specific vaccines like flu shots annually, Td/Tdap boosters every 10 years, and additional vaccines like pneumococcal and shingles vaccines for those over 65. Both childhood and adult preventive care through vaccination have significantly reduced vaccine-preventable diseases, though the protection level may vary, as seen in flu vaccines which typically protect only 50-60% of those immunized.","context":["Please take a moment to read our most commonly asked questions. We're always available to answer your questions and encourage you to contact our office if you have a question that is not answered below.\nWhat is a Pediatrician?\nA pediatrician is a medical doctor who specializes in the care of children. Pediatricians have undergone special training in the health and illnesses of infants, teens and young adults, and the majority of pediatricians are certified by the American Board of Pediatrics after passing a comprehensive exam.\nPediatricians provide preventive health care for children in good health and medical care for children who are acutely or chronically ill. They also provide parents with support and advice with issues such as growth and development, safety and prevention, nutrition, and emotional wellness to foster a lifetime of good health\n- Why do the physicians not communicate through email?\nWe prefer to talk directly with parents/patients because we find a lot of critical information can be lost in email exchanges, and direct verbal dialogue is more efficient for us in obtaining the needed information. Additionally, regular email is not a secure form of communication, which means diagnosis or treatment questions cannot be assured of privacy.\n- Under what circumstances is it advisable to call after hours to get advice from a doctor?\nIf your child is displaying symptoms that concern you and you feel it is urgent enough that it cannot wait until office hours, feel free to let our answering service direct you to the health professional on call. (We rotate with a number of other solo practitioners for night and off-hours call, including Dr. Janis Lacovera, Dr. Manuel Machiran, and their qualified staff.) Generally, any breathing difficulties, extreme pain, or very high fevers should get immediate attention, and if it is a serious concern, you may need to visit a hospital emergency room.\nHow often should my child see the pediatrician?\nYour child should not only see the pediatrician for an illness. It is also important to schedule well-child-care exams regularly, beginning in infancy. Also called well-care visits or checkups, these routine examinations provide the best opportunity for the doctor to observe the progress of your child's physical and mental growth and development; to counsel and teach parents; to detect problems through screening tests; to provide immunizations, and to get to know one another. Well-care visits are strongly recommended as part of preventive pediatric care.\nWell-child visits are also a good time for parents to raise questions and concerns about a child's development, behavior, nutrition, safety and overall well-being.\nThe American Academy of Pediatrics recommends this schedule for routine well-care visits:3 to 5 days\nAnd once every year thereafter for an annual health supervision visit that includes a physical exam as well as a developmental, behavioral, and learning assessment\nWhy does my child need to receive vaccinations?\nImmunizations are a series of shots given to children at different ages to help ward off serious, and potentially fatal, childhood diseases. Making sure your child receives immunizations when scheduled is the best way to help protect your child from potentially fatal diseases. According to the American Academy of Pediatrics, vaccinations have reduced the number of infections from vaccine-preventable diseases by more than 90%. If you're apprehensive about vaccinations, please do not hesitate to contact our office.\nIs your office accepting new patients?\nYes, we always welcome new patients. Contact our office for additional information or request an appointment.\nCan I meet my pediatrician before my baby is born?\nYes, in fact we strongly encourage parents-to-be to visit our office for a prenatal appointment. This is a great way to get acquainted with our office and our doctors. During this visit, we will answer any questions that you have about our practice or your new child. Visit our expectant parent's page for more information\nAt which hospitals do you have physician privileges?\nGreater Baltimore Medical Center (GBMC) Towson\nSt. Joseph's/University of Maryland Medical Center in Towson\nDo you offer same day sick appointments?\nWe offer same day sick appointments and are open late four nights and Saturday mornings to accommodate our patients' busy schedules.\nWe plan to travel overseas and want to know if we should get vaccinated prior to leaving. How should we proceed?\nYou can learn of the recommended vaccines to take by visiting the Centers for Disease Control website at http://wwwnc.cdc.gov/travel/destinations/list/ . Just contact us to let us know which vaccines you would like us to administer and we will order the required vaccines in time for your visit. It is a good idea to take care of this at least three weeks prior to your trip so the vaccines are working in your system before you arrive at your overseas destination.\n- I have a question about my bill. Who do I contact?\nWhich insurance plans do you accept?\nClick the link to view the list of insurance plans we accept. Participating Insurance Plans\nCan I pay my bill on-line?\nTo make a secure payment on-line, you can log on to our patient payment portal at : https://pay.instamed.com/buccilancermd or click on the following link: Patient Payment Portal","What is the recommendation for adult vaccines?\nThanks to advances in vaccine medicine, we live in a world where our immune systems can be taught to fight off a disease before we fall ill. As adults age, however, their immune systems begin to weaken, limiting the response to infectious bacteria and viruses in their bodies. Adult vaccines boost immune response and decrease likelihood of falling ill.\nAlthough you might have stayed on schedule for immunization as a child, protection provided by vaccines begins to wane over time. It is true that vaccination does not guarantee protection against an illness, but the increased protection does mitigate risks posed to yourself and your loved ones.\nThe CDC recommends that healthy adults aged 19 and older who are up-to-date with their childhood vaccinations receive the flu, Td/Tdap, shingles, and pneumococcal vaccines. If you have medical conditions which you believe might increase the risk of contracting a vaccine preventable illness, take the CDC’s Adult Vaccine Quiz.\nInfluenza, or the flu, is a contagious respiratory illness caused by a viral infection of the nose, throat, and lungs. The virus travels from person to person through infectious droplets expelled from the nose or mouth, but chances of contracting the virus decrease to between 40-60% with the administration of a flu shot. Recommended once each year, influenza is the most frequent of the adult vaccines.\nAccording to CNN, the vaccine typically protects only 50%-60% of those immunized. While the influenza vaccination does not guarantee protection against the virus, medical professionals maintain it is still the best way to protect yourself against the flu.\nFor people 65 years and older, there is an even greater risk of severe flu disease. The CDC estimates that between 71-85% of flu-related deaths and 54-70% of flu-related hospitalizations occur among this age group.\nThe Fluzone High-dose, recommended for those above the age of 65, is four times the strength of a regular flu shot, intended to invoke a stronger immune response in the recipient. One study found the high dose injection to be 24.2% more effective than the regular injection in adults older than 64.\nCommon side effects associated with the flu shot include: (1) Soreness, redness, or swelling where the shot was given; (2) low grade fever; (3) muscle aches; or (4) toughness/itching at the injection site. These reactions typically present soon after the flu shot and last one to two days.\nIf you experience a life-threatening allergic reaction, such as (1) breathing problems; (2) hoarseness or wheezing; (3) hives; (4) paleness; (5) weakness; (6) increased heart rate; or (7) dizziness, seek medical attention immediately.\nTetanus, the “T” in Tdap and Td, is unlike other vaccine-preventable diseases in that it is not spread through human contact. The bacteria that causes Tetanus enters the body through breaks in the skin – like a cut or puncture wound – and can be found in soil, dust, or manure.\nMost often, individuals who are infected with tetanus experience stiffness in the jaw, neck, and abdominal muscles; as well as difficulty swallowing and muscle spasms. In some cases, fever, sweating, elevated blood pressure, and increased heart rate also indicate a Tetanus infection.\nDiphtheria, the “D” in Tdap and Td, is a highly infections bacterial disease caused by Corynebacterium diphtheriae. Often life-threatening, Diphtheria can affect the respiratory (involving the nose, throat, and tonsils) or cutaneous (involving the skin) systems.\nSymptoms of Diphtheria often include weakness, sore throat, fever, and swollen glands in the neck. As the bacteria embeds itself in the lining of the skin or respiratory system, the toxin released destroys healthy tissue. The infected tissue then forms a gray coating that can build up in the throat or nose, making it difficult to breathe.\nPertussis, the “P” in DTaP, also known as Whooping Cough, is a highly contagious respiratory tract disease caused by Bordetella pertussis. These bacteria can live in the mouth, nose, and throat, making it easy to spread through droplets produced by coughing or sneezing.\nPertussis symptoms generally occur within 7 to 10 days of infection and include mild fever, runny nose, and a cough. In most cases, what starts as a mild cough develops into a paroxysmal cough over time, followed by whooping.\nThe DTaP vaccination is licensed only for infants, adolescents, and children under the age of 7. For adults seeking protection from Diphtheria, Tetanus, and Pertussis, Tdap was developed. The CDC recommends a single dose of Tdap for people between the ages of 11 and 64.\nTd, one of the adult vaccines recommended every ten years following initial DTaP or Tdap vaccination, protects against Tetanus and Diphtheria, but not Pertussis. If unsure of your vaccine history, it is recommended that adults first receive a dose of Tdap, then the Td booster every 10 years following.\nSide effects of vaccination vary by case, ranging from redness and swelling at the site of the injection, to hives, swelling of the face and throat, a quickened heartbeat, dizziness, or weakness.\nShingles, also known as Herpes Zoster or Zoster, is a painful skin rash that usually presents on a single side of the face or body. Caused by the same virus that causes the chickenpox, Varicella Zoster, shingles typically affects those above the age of 50, and is significantly less common in younger populations. Shingles can only be contracted by someone who has already introduced the chickenpox virus to their system.\nThe shingles rash usually lasts between 2 to 4 weeks, and is often accompanied by fever, headache, chills, and an upset stomach, in addition to pain. Roughly 1 in 5 people find that their pain continues long after the rash has cleared, referred to as post-herpetic neuralgia.\nAlthough shingles cannot be transferred from person to person, it is possible for someone who has never had the chickenpox to contract the virus from someone with shingles. This, however, is not common.\nShingrix, a new vaccine approved by the FDA on October 20th 2017, is a non-live, recombinant subunit injection given intramuscularly in a series of two doses, and, unlike some other adult vaccines, is recommended only for those age 50 and older.\nCompared with the previous vaccine, Zostavax, which was licensed in 2006 and reduced the risk of shingles by only 50%, Shingrix is significantly more effective. In clinical trials, Shingrix proved 90% effective in preventing shingles as well as the chronic nerve pain associated with the virus.\nThe most common side effects were sore arms and pain following injection. More general side effects included muscle ache, fatigue, shivering, fever, upset stomach and headaches, and typically resolve within three days.\nPneumonia is an infection of one or both sides of the lungs that causes the air sacs to fill with fluid and spreads from person to person through respiratory droplets. Symptoms range in severity from a phlegmy cough, to fever, chills, and trouble breathing. A person can be a carrier even if they do not feel sick.\nPeople above the age of 65 experience more serious cases of pneumonia, as well as those with preexisting medical conditions. In the U.S. alone, 50,000 people die from the illness each year, 18,000 of those above the age of 65.\nTreatment of pneumonia ranges from oral antibiotics to hospitalization, depending on the severity of the illness. Some people take weeks to recover from pneumonia.\nThe CDC recommends 2 pneumococcal adult vaccines for those 65 and older: first, the pneumococcal conjugate (PCV13) and, at least one year later, the pneumococcal polysaccharide (PPSV23).\nThe first vaccine, the pneumococcal conjugate, protects against 13 strains of pneumonia-causing bacteria and has been found to be 75% effective in preventing invasive pneumococcal disease, and 45% effective at preventing non-invasive pneumonia. The second, the pneumococcal polysaccharide has been found 50-85% effective against the 23 strains of pneumonia-causing bacteria it covers, and aids in preventing infections like meningitis and bacteremia.\nSide effects associated with the pneumococcal vaccines include drowsiness, swelling at the injection site, fever, chills, muscle pain, and changes in behavior.\nNational Vaccine Injury Compensation Program\nAdult vaccines, and those for children, are equally important parts of public health, working to save lives by preventing disease. Most of the time, vaccines are administered without any serious problems. Like with any medication, however, there is a risk of side effects, ranging from mild to serious.\nFor this reason, the US government created the National Vaccine Injury Compensation Program (NVICP), a “no-fault” alternative to the traditional legal system. Petitions can be filed by any individual, at any age, after developing an injury believed to be a result of a covered vaccine, if jurisdictional requirements are met.\nConway Homer, P.C. is the most experienced vaccine injury law firm in the United States. We represent clients injured by adult vaccines from all 50 states and have advocated for landmark cases that have shaped the Vaccine Program and made it friendlier and more generous to those individuals who suffer from vaccine injuries. To get in touch with our dedicated team, click here for a free consultation."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:04fb8d8c-e648-4b84-91f4-3618a077a939>","<urn:uuid:fe375d39-68e8-4d81-aec6-afa6a099fdcb>"],"error":null}
{"question":"How can indoor environment quality be optimized in sustainable home design?","answer":"Indoor environment quality can be optimized through several measures: using people-friendly materials and finishes to protect human health, controlling heat and light through plantation window shutters, installing adequate insulation in walls and roof spaces to minimize heat loss, and using double-glazed windows and doors with air and watertight seals around openings.","context":["Building new homes is an important part of improving the overall infrastructure in the UK, more important perhaps due to the level of demand than upgrading road and rail systems and modernising communications. Over the years, a lot has changed in the construction sector, from the way in which architects design buildings to be more people and environmentally friendly, to the quality of the materials used in construction, and ultimately to added interior features that increase comfort and sustainability.\nSustainability has come to mean a number of things generally, and some fairly specific things in the construction sector. Besides economic considerations, it encompasses protecting the environment and represents using resources as efficiently as possible. Here are a few of the ways in which buildings make a significant contribution to a sustainable society.\nThere are certain elements in a new home that architects try to make the most of or optimise. These include\n- The characteristics of the available site.\n- Building materials used in construction.\n- Energy use during and after construction.\n- Water conservation.\n- Improving the quality of the environment indoors.\n- Operational practices, including ongoing maintenance.\nFor an architect, making the most of a site for a new home means looking carefully at a number of issues, including access, parking and general physical safety. Basically, the site of a sustainable building should be suitable for the proposed development, especially for housing. It should also work in such a way as to make use of available resources without unduly depleting them. Good landscape design will provide the amenities needed without unnecessarily harming the flora and fauna that are native to the region.\nThe nature and quality of desirable building materials has advanced considerably in the last 50 years. Home building today uses and reuses materials in the most productive way possible, striving to resist major environmental impacts, such as the depletion of precious resources, global warming and the fact that humans can and do contribute to toxicity. Indeed, contemporary materials are chosen specifically to minimize negative effects on human and environmental health, as well as to provide the best possible solutions that meet construction requirements.\nEnergy and water use\nThe availability of fossil fuels is continuing to reduce, and as in other industries, home designers and builders are looking for ways to reduce dependence on them, particularly as the impact of global climate change becomes ever clearer. Renewable energy, such as using solar panels on a rooftop, is where the future lies for existing as well as new buildings. There are efforts and commitments being made within both government and the private sector to create zero net energy buildings. These will reduce the required energy load as well as increase energy efficiency.\nWorldwide, fresh water is an increasingly scarce resource, so using water efficiently in a sustainable home is vital. From relatively simple water saving gadgets to the introduction of rainwater harvesting, and recycling grey water and black water, there are a number of possible solutions. In fact, the organisation Waterwise, which researches, advises and campaigns on water related issues, advocates the use of a water calculator by all those designing new buildings, so that potential savings in terms of consumption can be assessed and adopted.\nThe indoor environment\nUsing people-friendly materials and finishes protects human health and welfare. One important factor is controlling heat and light as part of climate control. In this respect, fitting plantation window shutters is beneficial and contributes towards physical security and privacy. Adequate insulation also makes it easier to minimise heat loss and nowadays both walls and roof spaces are generally protected in this way. Windows and doors are usually double-glazed and seals around openings are air and watertight.\nIt’s worth noting that today’s construction processes are designed to improve conditions on site in order to ensure the health and safety of workers. These can also reduce the costs of disposal of materials and reduce the liabilities. With improved practices, achieving environmental targets and goals becomes easier. They also result in higher productivity and prevent errors and failures in systems. People who maintain buildings, as well as those who operate them, are encouraged to participate at the design and development stages.\nFinally, as materials can be specified by building designers, it’s possible to reduce and to simplify ongoing maintenance requirements, in consultation with those who will be engaged in those tasks. Tracking the progress of initiatives to monitor and measure sustainability is ideal, both on site during construction as well as on and after completion."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e4561ff0-5748-4915-b155-93eadc4e7de7>"],"error":null}
{"question":"How do the approaches to supporting innovation differ between GWIIN and Northwest Bronx Community Coalition in terms of their target beneficiaries and economic models?","answer":"GWIIN focuses on supporting individual women inventors and innovators to achieve commercial success in the global marketplace, having helped over 1,675 women develop their ideas. In contrast, Northwest Bronx Community Coalition promotes collective economic models through cooperative enterprises and shared ownership, particularly targeting communities of color. While GWIIN emphasizes individual entrepreneurship and commercial development of inventions, Northwest Bronx advocates for economic democracy with shared wealth, collective governance, and community assets.","context":["Building a Shared Vision: An Interview with Sandra Lobo\nIn the fall, the Urban Design Forum will launch Cooperative Works, an initiative exploring how New York City can advance economic justice in its coronavirus recovery. In partnership with Deputy Mayor for Strategic Policy Initiatives J. Phillip Thompson and the Mayor’s Office of M/WBE, our Fellows will conduct research on how to create economic opportunity for MWBEs and employee-owned businesses through climate investment, leveraging the new market for building energy retrofits created by Local Law 97.\nLeading up to the program, we are pleased to publish a series of interviews with leaders in sustainability in the built environment, inclusive economic development, and racial justice. In our interview with Sandra Lobo, Executive Director of the Northwest Bronx Community and Clergy Coalition, we discuss how Northwest Bronx connects its organizing around racial, environmental, and health justice to an economic democracy framework that draws on longstanding cooperative practices in communities of color.\nKatherine Sacco: For those who may not be familiar with economic democracy, could you explain what that concept is? How does economic democracy intersect with the racial justice work that you’re doing at Northwest Bronx Community and Clergy Coalition?\nSandra Lobo: I talk about economic democracy as a framework around building shared wealth and ownership, and collective governance over our community assets. There are obvious strategies, like a community land trust that we’ve incorporated, or cooperative enterprises included within this framework. There are other policy-based strategies that we’re employing as well.\nNorthwest Bronx has been organizing around really critical issues since 1974. Although we’ve used a variety of strategies, we have largely focused on a fight-back, defensive posture—fighting bad landlords, bad development, bad actors—rather than implementing our own vision. Economic democracy invited us to ask, what is the vision that we want to see, and how does that shape the organizing we do? What are we going to be fighting for?\nWhen we went through the economic democracy training series developed by BCDI [Bronx Cooperative Development Initiative], we shifted our mission to explicitly name economic democracy as part of our mission as well as racial justice. Racial justice had always been a part of our analysis, but it had never been explicit. Given the changing landscape of the Bronx, we needed to name explicitly who was being most impacted and who was going to be at the center of decision making.\nKS: How do those two strategies of fight-back and fight-forward complement each other? What has adding the fight-forward strategies brought to what you’re able to do?\nSL: The fight-back and fight-forward strategies need to be hand-in-hand. For example, the Bronx is experiencing serious displacement and gentrification pressures right now. To get at the root cause, we need to be building shared ownership of the buildings, the land, and businesses. At the same time, we know that it takes time to build that kind of infrastructure. If we’re not careful and we’re not also employing protective and defensive strategies right now, by the time we create shared wealth and ownership enterprises, our people might be gone. The things that we’re building may not be for the people who we intended it for.\nThe critical piece for us was acknowledging that if we didn’t intentionally create the capacity and the space to employ fight-forward strategies, we would always be focusing on the fight-back, because it feels like we’re under attack all the time and we have to defend and protect our people. If you don’t create the space, you’ll also never have actual time and capacity to do it.\nKS: I read that Northwest Bronx arrived at workforce development as a community priority through a participatory process that started by asking about the biggest health problem, which was identified as violence, and then invited ideas on how to address the problem of violence. Can you describe more of that process? How did that process change or shape the way you approach workforce development?\nSL: We worked with the Department of Health and Mental Hygiene to engage in a participatory process to identify the number one health priority in our community. Over a year and a half, we engaged community members around the social determinants of health (SDOH). We are socialized to understand that if we are not healthy, that’s because we are not exercising or not eating right. Yet if you don’t have a grocery store with fresh fruits and vegetables, if you don’t have a space to exercise, or if you’re afraid to go outside to exercise, your health will be impacted.\nWe weren’t surprised that violence was an issue, but we were surprised that violence was number one. Then we interrogated, if violence was the number one priority, what were we going to do about it?\nThrough the SDOH lens, participants understood why people were engaging in the underground economy that led to violence. They understood that there was a lack of opportunity, lack of access to jobs that actually made it possible for people to take care of their families. It was within this context that workforce development was identified as the root cause of why there was violence.\nWe ended up launching around Integrated Pest Management (IPM), which is the least sexy topic!\nKS: Why Integrated Pest Management?\nSL: Northwest Bronx has a 44-year-old Weatherization Assistance Program, the second largest in the state. During the former stimulus package, we received funding to train people for green jobs. The challenge for our community was that this investment came without an analysis around this sector at that time. We trained folks for green jobs, and at the end of the day, there were no businesses to employ them.\nWe can provide training programs, but if we lack the larger infrastructure of building up a sector, then you’re going to have trained workers jobless, or securing jobs that are outside the borough, with a larger corporation, where the profits and the revenue go to its leadership and the investors. That approach does not have the impact that we’re actually seeking.\n“We want our people to have living wages, and we want our folks to be part of the decision-making at their workplace.”\nIntegrated Pest Management was one of the strategies that emerged from our Healthy Buildings work. It is an evidence-based intervention that gets at the root causes of asthma triggers. It was exciting to have the Asthma-Free Act passed in City Council, which requires landlords to use IPM for people who have chronic asthma. But there weren’t that many local businesses that could take on Integrated Pest Management (IPM). If we were going to create the demand for IPM, we needed a larger ecosystem that would support businesses to take on trainees.\nFor us, it wasn’t sufficient to have training for people in the community. We needed to identify a growing sector that also had a positive impact in our community. We want our people to have living wages, and we want our folks to be part of the decision-making at their workplace on the policies that impact the workers. The ideal for us is developing cooperative social enterprises or working with businesses that would be open to a conversion so that our workers share in the profits that they are producing.\nKS: Northwest Bronx’s Healthy Buildings program aimed to address root causes of poor health outcomes by improving buildings, but also reduce greenhouse gas emissions, lower energy bills, and create jobs in the community. What has been the benefit of putting health concerns together with environmental concerns and jobs creation?\nSL: After we went through the economic democracy training series with BCDI, our membership was really interested in organizing around health and energy, but they were really clear that we needed to be careful that we weren’t going to create benefit in one sector and potentially undermine other parts of our communities.\nFor example, with Healthy Buildings, were we going to implement energy efficiency retrofits that might ultimately displace our people because landlords could pass on the cost to low income tenants? No, we can’t do that. The financial tools that we use to address the energy retrofits have to be tied to a regulatory agreement that does not allow landlords to, for instance, pass down the debt to the tenants through what would traditionally be major capital improvements.\nAnd when we’re doing energy efficiency retrofits, we work with the landlords to identify bids from local businesses and we work with BronXchange at BCDI to vet the businesses that have the capacity to take on that work.\nWhen we first brought in more than 20 partners for the first planning of the program, every sector said, “This is too complicated! Why are you doing this?” Every sector is used to employing their own strategies within their sector. People are not used to sharing a vision and working collaboratively across sectors. It took two years of really building strong relationships. This took a lot of time, but for us it was really critical as we were committed to social transformation, not just impacting one sector.\nKS: What kind of response have you seen when you engage your community around economic democracy and cooperative ownership, whether it is the anchor institutions contracting out jobs, the business who might be considering switching to this model, or workers themselves?\nSL: Although we use the term economic democracy, some often used the “new economy”. But this approach is actually very old. Communities of color across the globe have developed cooperative economies to survive and flourish, including and especially Black communities in the U.S. It’s not a difficult concept for people to understand, in that communities have been accessing this tool all along. What has been missing is the infrastructure to provide credit and capital for these cooperative businesses of color to flourish. You might see cooperatives that are two or three people big, because they don’t have access to the technical assistance and the capital to grow.\n“Communities of color across the globe have developed cooperative economies to survive and flourish, including and especially Black communities in the U.S.”\nWith our anchor partners and other institutional partners, they’re not resistant to the idea of cooperative enterprises, but they are worried that they are small, and just like any other small businesses, they ask if they can do the work or if they can show their experience and expertise. We are never going to get there if we don’t ever invest in them, so how do we begin to build the infrastructure that can help them flourish over time?\nKS: As we look towards the economic recovery from the coronavirus pandemic, what role can worker cooperatives play?\nSL: Right now, we’re thinking about cooperative ownership not just in terms of worker cooperatives, but also housing cooperatives and shared governance over different assets in the community. Given that a lot of our folks are unemployed at home right now, how might this be an opportunity for training and leadership development so that when we’re coming out of this, we can invest in people who are ready to hit the ground?\nThe small businesses in the Bronx have been completely decimated by this. The Bronx received 3% of the PPP loans from the stimulus package, and less than 1% from New York City’s Small Business Services fund. That doesn’t make any sense to us. We have been in conversations with our small businesses about, rather than closing, taking this opportunity to actually rethink their business in a different way, with other business owners as well, that might shift their approach to coming back after the quarantine is lifted.","This year marks the 21st anniversary of the global organisation GWIIN which recognises outstanding women inventors and innovators from around the world\nMargaret Vilborg Bjarnadottir, from Iceland is crowned the overall Inventor & Innovator Platinum Award Winner at the Global Women Inventors & Innovators Network (GWIIN) awards for her invention PayAnalytics, a solution for HR for eliminating the gender pay gap.\nFor more information on Payanalytics\nThe event on 28 June celebrated the inspirational inventions by women who want to reinvent and improve our world. Women from several different nations entered the awards which were presented in London at the Arab British Chamber of Commerce as well as the Park Plaza, Hotel, London, England. The gathering was an opportunity for talented, entrepreneurial women to network and showcase their inventions and innovations.\nThe theme of this year’s conference and awards was “Is Ingenuity enough to grow?”. Founder of the GWIIN event, Bola Olabisi, is still passionate about helping more women to make a success of their ideas even though getting off the ground can be tough. She says: “In our 21st year, we continue to encourage women to share their inventions and develop them commercially to improve the way that we live. We have had some outstanding entries again this year and I would like to congratulate all of our entrants as well as the main winner”.\n“Women are often under-represented in many areas of life but have so much to offer if provided the right platform and opportunity. We therefore would like to give many of women this opportunity to take their ideas up to the next level and recognise their achievements as this is no easy task. GWIIN serves as that one stop shop for support and assistance.”\nThere were several other categories of winners apart from the overall winners which are listed below:\nOVERALL INVENTOR & INNOVATOR PLATINUM AWARD WINNER 2019\nMARGRET VILBORG BJARNADOTTIR from Iceland is the founder of PayAnalytics & Assistant. She is also a Professor of Management Science and Statistics. PayAnalytics is a solution for eliminating the gender pay gap and arming HR professionals with quantitative decision-making tools.\nJOINT GOLD INNOVATOR WINNERS 2019\n- Dr RAFIZA ABD RAZAK from the University of Malaysia Perlis, a researcher into productive uses for Lusi mud.\n- JENAN ESAM SALEH ALSHEHAB from Kuwait, the creator of the new technology – “Wireless electricity” for producing electromagnetic cell generators.\nGOLD INNOVATOR WINNER 2019\nAssociate Professor Ts. Dr Ervina Efzan Binti Mhd Noor from Malaysia, researcher wins for how to convert banana stem into glass.\nPLATINUM EDUCATION / RESEARCH DEVELOPMENT CATEGORY WINNER 2019\nProfessor Dr Siriwan Suebnukarn from Thammasat University, Bangkok, Thailand wins for training capacities for surgical decision-making and for refining physical training skills with automated tutor systems.\nDOUBLE GOLD EDUCATION / RESEARCH DEVELOPMENT CATEGORY WINNER 2019 (BELGIUM / SWITZERLAND)\n- FABIA GOZZO, PhD – CEO and Founder: Excelsus Structural Solutions SPRL wins for developing easy access to state of the art, synchrotron-based characterization tools to the pharmaceutical industry, in order to enhance the selection, development and manufacturing of high-quality (bio) pharmaceutical products.\n- DR. MARIA GRAZIA PIANCINO, a physician orthognathodontist University of Turin-Italy developed an orthognathodontic medical device to move the teeth in a physiological way minimising trauma and reducing the potential for side effects.\nPLATINUM SOCIAL INNOVATION CATEGORY WINNER 2019\nCHARITY ANNAN ADUPONG from Ghana is the entrepreneur behind Meannan Foods which is a company that specialises in food processing and food packaging to make local foods attractive to all. Charity is also helping to fight high protein deficiency in children with whole lines of cereals which are soya based.\nPLATINUM EXCEPTIONAL CREATIVITY CATEGORY WINNER 2019 for outstanding ingenuity to society\nTETYANA (TANYA) MULESA founded Cleverstein – a strap over a shoe, which holds various accessories to transform its style and look.\nPLATINUM WINNER OF THE BRITISH INTERNATIONAL INVENTOR AWARD 2019\nGAYNOR MORGAN of C&G Medicare Ltd has developed a range of incontinence products for women and men including IncoStress™ and pessaries for pelvic organ prolapse issues.\nGlobal Women Inventors & Innovators Network (GWIIN) is an independent, not-for-profit organisation dedicated to assisting and advancing women with bright inventions and innovations so that they can achieve success in the global marketplace. The organisation has helped more than 1675 women over the years.\nList of GWIIN Special Recognition Awardees 2019\nKRISTIN BRYNJA GUNNARSDOTTIR Architect / Designer, einrúm ehf Handknit designs and yarn that builds on the ideology of slow fashion, where the customers are the producers of the garments they wear: they choose the process, the time-frame, the material and the colour they want for their garment and thereby achieve sustainability.\nTHORBJORG HELGA VIGFUSDOTTIR Founder and CEO of Kara connect ehf Kara: a browser based connectivity platform that takes care of all the administrative needs of the therapists (security, consent, calendar, booking system, reminders, financials, timeline, team overview, secure health notes and chat as well as online portal).\nMINTUU RATY & TINA WIKSTROM Laurea University, of Applied Sciences Multi-sensory space concept addressing challenging issues as stereotypes, emotional aspects, multicultural education and immigrant inclusion, overall wellness promotion and community cohesion.\nMAUD ALMA BADDOO of Maud’s Shitto Light Chilli Sauce with an allergic resistance to shrimps while taking into consideration a lower percentage of oil.\nDr. ALIDA ABDULLAH School Of Materials Engineering & Faculty Of Engineering Technology, UNIVERSITI MALAYSIA PERLIS, (UNIMAP) The development of lightweight aggregate for structural insulating concrete with low temperature processing by using the geopolymer technology with the use of industrial by product.\nDR RAFIZA ABD RAZAK Center of Excellence Geopolymer and Green Technology (CEGEOGTECH), School of Materials Engineering, Universiti Malaysia Perlis Research into solving LUSI mud by converting to lightweight aggregate production due to high silica and alumina compositions that consume to high strength properties.\nASSOC. PROF. TS. DR. ERVINA EFZAN BINTI MHD NOOR Faculty of Engineering and Technology, Multimedia University, Malaysia. Deputy Director Research Management Centre/Lecturer Saving cost by using banana stem as raw material to develop glass without involving much usage of material which is expensive compared to banana stem which is a waste material.\nTHANGESWARY A/P ANNAMALLAI & KAVITHA A/P ARUMUGHAM & PUSPA A/P WILRY SJK Tamil Kajang Biosoil is capable of converting food leftovers and organic by products to soil. It is a simple design according to the need and wants of the customers to make recycling easy.\nOLUKEMI ATIJOSAN is the Managing Director & Food Consultant, Avarah Flour, Eagle Solutions Services. A 15-stage preparation process, versatile, single-ingredient product with no added colours, flavours or preservatives, naturally gluten free and comes with a low glycemic load which makes it suitable for those with many challenging medical conditions.\nSUSANNAH WEILAND COLLECTIONS with her Hand drawn, embroidered and beaded textile products and prints for luxury interiors.\nJUDY WATSON the Millennium Nutritionist, Nutrition MOT A cost effective way to support people in making positive life changing decisions with food while providing knowledge transfer and training.\nSABA EL KUFAISHI of Fay Bijoux Accessories/jewellery Brand gold plated brass based jewellery pieces set with swarovski crystals or faux pearls.\nFor more information, please contact:\nBola Olabisi, Founder & Director on +44 7956 501727 or email@example.com"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:170a06aa-f276-43b7-ad32-854d48f358e7>","<urn:uuid:7cb2e689-f0df-4815-85f0-ff0f1fc07860>"],"error":null}
{"question":"How do ISO 9001 and ISO 14001 management systems compare in terms of their primary objectives and organizational benefits?","answer":"ISO 9001 and ISO 14001 serve different but complementary primary objectives. ISO 9001 focuses on quality management, aiming to achieve customer satisfaction and operational effectiveness through principles like customer focus, process approach, and evidence-based decision making. Meanwhile, ISO 14001 specifically targets environmental management, helping organizations measure and improve their environmental impact. In terms of benefits, both standards help organizations reduce costs and improve operations, but in different ways. ISO 9001 achieves this through streamlining operations, reducing waste, and improving customer satisfaction, while ISO 14001 does so by improving resource efficiency and reducing waste from an environmental perspective. Both standards enhance organizational reputation, with ISO 9001 boosting brand reputation through demonstrated commitment to quality, and ISO 14001 increasing stakeholder and customer trust through environmental stewardship. Both can be integrated seamlessly through an Integrated Management System approach due to their compatible principles.","context":["CAW Consultancy Business Solutions Ltd\nWhat is ISO 9001 QMS?\nISO 9001:2015 is the International standard for Quality Management Systems (QMS).\nIt provides an organization with a set of principles that ensure focussed, informed, scientific and proven approach to the management of your business activities to consistently achieve customer satisfaction and continually improve operational effectiveness.\nEvery organisation would like to improve the way it operates, whether that means increasing market share, driving down costs, managing risk more effectively or improving customer satisfaction. A quality management system gives you the framework you need to monitor and improve performance in any area you choose.\nAny organisation can benefit from implementing ISO 9001:2015. It doesn't matter what size they are or what they do. It can help both product and service organizations achieve standards of quality that are recognized and respected throughout the world.\nISO 9001 QMS is based on seven quality management principles:\nA customer focused organisation\nThe engagement of people\nEnsuring a process approach\nEvidenced based decision making\nBenefits of ISO 9001:2015 Competitive advantage\nISO 9001 should be top-management led, which ensures that senior management take a strategic approach to their management systems. Our assessment and certification process ensures that the business objectives constantly feed into your processes and working practices to ensure you maximise your assets.\nImproves business performance and manages business risk\nISO 9001 helps your managers to raise the organization’s performance above and beyond competitors who aren’t using management systems. Certification also makes it easier to measure performance and better manage business risk.\nAttracts investment, enhances brand reputation and removes barriers to trade\nCertification to ISO 9001 will boost your organization’s brand reputation and can be a useful promotional tool. It sends a clear message to all interested parties that this is a company committed to high standards and continual improvement.\nSaves you money\nEvidence shows that the financial benefits for companies that have invested in and certified their quality management systems to ISO 9001 include operational efficiencies, increased sales, higher return on assets and greater profitability.\nStreamlines operations and reduces waste\nThe assessment of your quality management system focuses on operating processes. This encourages organizations to improve the quality of products and the service provided and helps to reduces waste and customer complaints.\nEncourages internal communication and raises morale\nISO 9001 ensures that employees feel more involved through improved communication. Continued Assessment visits can highlight any skills shortages sooner and uncover any teamwork issues.\nIncreases customer satisfaction\nThe ‘Plan, Do, Check, Act’ structure of ISO 9001 ensures that the needs of the customer are being considered and met.\nHow to achieve ISO 9001 certification - ISO 9001 implementation / Certification steps\nThere are several requirements of ISO 9001:2015 where an organization could add value to its QMS and demonstrate conformity by the preparation of other documents, even though the standard does not specifically require them. Examples may include:\nProcess maps, process flow charts and/or process descriptions\nWork and/or test instructions\nDocuments containing internal communications\nApproved supplier lists\nTest and inspection plans\nIntegrate ISO 9001 with other management system standards\nISO 9001 is designed to be compatible with other management systems standards and specifications, such as ISO 45001, ISO 22000, ISO 17025, ISO 27001, ISO 14001 Environment and other ISO standards. They can be integrated seamlessly through Integrated Management system approach. They share many principles so choosing an integrated management system can offer excellent value for money and an easier approach to implement, manage and improve multiple standards simultaneously.","What Is ISO 14001:2015 – Environmental Management Systems?\nISO 14001 on ASQTV™\nISO 14001 is the international standard that specifies requirements for an effective environmental management system (EMS). It provides a framework that an organization can follow, rather than establishing environmental performance requirements.\nPart of the ISO 14000 family of standards on environmental management, ISO 14001 is a voluntary standard that organizations can certify to. Integrating it with other management systems standards, most commonly ISO 9001, can further assist in accomplishing organizational goals.\nThe International Organization for Standardization (ISO) defines an environmental management system as “part of the management system used to manage environmental aspects, fulfill compliance obligations, and address risks and opportunities.” The framework in the ISO 14001 standard can be used within a plan-do-check-act (PDCA) approach to continuous improvement.\n- Who should use the 14001:2015 revision?\n- What are the benefits of ISO 14001?\n- ISO 14001 certification\n- ISO 14000 family of standards\n- ISO 14001 resources\nISO 14001:2015 should be used by any organization that wishes to set up, improve, or maintain an environmental management system to conform with its established environmental policy and requirements. The requirements of the standard can be incorporated into any environmental management system, the extent to which is determined by several factors including the organization’s industry, environmental policy, products and service offerings, and location.\nISO 14001:2015 is relevant to all organizations, regardless of size, location, sector, or industry.\nWhat topics does ISO 14001:2015 cover?\nAt the highest level, ISO 14001:2015 covers the following topics with regard to environmental management systems:\n- Context of the organization\n- Performance evaluation\nISO 14001 Environmental Management Systems (EMS) Framework\n14001:2004 vs. 14001:2015\nThe 2015 revision of ISO 14001 introduces a number of changes from previous versions. A detailed explanation of the changes can be found in this ISO 14001 presentation by the ASQ Energy and Environmental Division.\nAs part of the effort to structure all ISO standards in the same way, the ISO 14001:2015 revisions include incorporating a required high-level structure, using mandatory definitions, and incorporating common standards requirements and clauses.\n10 major areas of impact of the 2015 revision:\n- Expansion in EMS coverage and scope\n- Required interactions with external parties\n- New requirements for leadership engagement\n- Expanded legal compliance requirements\n- Need for risk-based planning and controls\n- New documentation requirements\n- Expanded operational control requirements\n- Changes in competence and awareness requirements\n- Impacts on the internal audit program\n- Increased certification costs\nIntegrating ISO 9001 and ISO 14001\nResponsibilities for the combined standards might include:\n- Drafting a policy statement and quantifiable objectives\n- Setting up organizational charts and job descriptions\n- Providing adequate resources\n- Managing documentation for both standards in a single document control system\n- Appointing a management representative as well as coordinators for the quality and environmental managements systems\nWhen adding ISO 14001 components to those of ISO 9001, planning must be expanded to deal with environmental impacts, and the inspection and test systems modified to cover environmental conformance. The organization must meet the environmental expectations of customers and the government, and it must incorporate environmental management elements into internal audit programs and training sessions.\nISO 14001 can be integrated with standards besides ISO 9001 in order to provide synergy with other systems, such as OHSAS 18001 and ISO 13485.\nUsing ISO 14001:2015 has many benefits for organizations with environmental management systems. Organizations and companies find that using the standard helps them:\n- Improve resource efficiency\n- Reduce waste\n- Drive down costs\n- Provide assurance that environmental impact is being measured\n- Gain competitive advantage in supply chain design\n- Increase new business opportunities\n- Meet legal obligations\n- Increase stakeholder and customer trust\n- Improve overall environmental impact\n- Manage environmental obligations with consistency\nOrganizations that have already achieved ISO 14001 certification are encouraged to transition to the 2015 version. Organizations will have a three-year transition period to update their environmental management systems to the new standard.\nTo get started with ISO 14001:2015:\n- Review existing quality management system requirements (ISO 9001:2015)\n- Purchase ISO 14001:2015\n- Get ISO 14001 training\n- Certify to ISO 14001\nISO 14001 is the most popular standard of the ISO 14000 family, which also includes standards such as the following:\n- ISO 14004:2016 - Environmental Management Systems - General Guidelines On Implementation\n- ISO 14006:2011 - Environmental Management Systems - Guidelines For Incorporating Ecodesign\n- ISO 14015:2001 - Environmental Management - Environmental Assessment Of Sites And Organizations (EASO)\n- ISO 14020:2000 - Environmental Labels And Declarations - General Principles\n- ISO 14031:2013 - Environmental Management - Environmental Performance Evaluation - Guidelines\n- ISO 14040:2006 - Environmental Management - Life Cycle Assessment - Principles And Framework\n- ISO 14050:2009 - Environmental Management - Vocabulary\n- ISO 14063:2006 - Environmental Management - Environmental Communication - Guidelines And Examples\n- ISO 14064-1:2018 - Greenhouse Gases Part 1\n- ISO 19011:2018 - Guidelines For Auditing Management Systems\nArticles and Case Studies\nISO 14001 Standard: Literature Review And Theory-Based Research Agenda (Quality Management Journal) Environmental sustainability has gained momentum in the business world and academia. After about 20 years of research in this field, this paper presents a holistic literature review specifically focused on ISO 14001, which is widely considered the most important environmental certification.\nStewardship And Sustainability: Serigraph's Journey To ISO 14001 (Journal for Quality and Participation) Leaders of Serigraph understand that sustainability and social responsibility require the simultaneous promotion of equitable economic growth, environmental protection, and social well-being. Serigraph uses ISO 14001, Six Sigma, and lean as its templates for environmental and sustainability improvement.\nA Framework For The Development Of An Environmental Management System: A Case Study In A Thermal Power Plant (Quality Engineering) Questions regarding implementation of ISO 14001 prompted NP Power, the electric power company of New Brunswick, Canada, to develop a framework to assess its compliance to the standards."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:178f318d-8f1f-499d-a9eb-0c5c938936f9>","<urn:uuid:8b228415-8471-4596-8694-cc54b2c84a94>"],"error":null}
{"question":"Can you provide a list of documented meteorite incidents that have affected humans? ¿Cuáles son los planes de la NASA para detectar objetos cercanos a la Tierra?","answer":"Documented meteorite incidents affecting humans include: 1) Ann Hodges of Sylacauga, Alabama was hit by a 4 kg meteorite while napping, causing severe bruising, 2) Michelle Knapp's Chevrolet Malibu was struck by a 12 kg meteorite in Peeskill, NY, 3) An Indian bus driver was killed and three passengers were injured by meteorite debris in Tamil Nadu in 2016. Regarding NASA's detection plans, Congress mandated the agency to discover 90% of NEOs 140 meters or greater by 2020. To achieve this, NASA can either use a space-based telescope combined with ground observations for faster completion, or use only ground-based telescopes for a more cost-effective approach. The agency is also advised to monitor smaller objects (30-50 meters) and maintain operations at facilities like the Arecibo Observatory and Goldstone Complex for accurate orbit determination.","context":["From Bernie Bell\nBy Steve Drury\nIn 1994 Clark Chapman of the Planetary Science Institute in Arizona and David Morrison of NASA’s Ames Research Center in California published a paper that examined the statistical hazard of death by unnatural causes in the United States (Chapman, C. & Morrison, D. Impacts on the Earth by asteroids and comets: assessing the hazard. Nature, v. 367, p. 33–40; DOI:10.1038/367033a0). Specifically, they tried to place the risk of an individual being killed by a large asteroid (~2 km across) hitting the Earth in the context of more familiar unwelcome causes. Based on the then available data about near-Earth objects – those whose orbits around the Sun cross that of the Earth – they assessed the chances as ranging between 1 in 3,000 and 1 in 250,000; a chance of 1 in 20,000 being the most likely. The results from their complex calculations turned out to be pretty scary, though not as bad as dying in a car wreck, being murdered, burnt to death or accidentally shot. Asteroid-risk is about the same as electrocution, at the higher-risk end, but significantly higher than many other causes with which the American public are, unfortunately, familiar: air crash; flood; tornado and snake bite. The lowest asteroid-risk (1 in 250 thousand) is greater than death from fireworks, botulism or trichloroethylene in drinking water; the last being 1 in 10 million.\nChapman and Morrison cautioned against mass panic on a greater scale than Orson Welles’s 1938 CBS radio production of H.G. Wells’s War of the Worlds allegedly resulted in. Asteroid and comet impacts are events likely to kill between 5,000 and several hundred million people each time they happen but they occur infrequently. Catastrophes at the low end, such as the 1908 Tunguska air burst over an uninhabited area in Siberia, are likely to happen once in a thousand years. At the high end, mass extinction impacts may occur once every hundred million years. As might be said by an Australian, ‘No worries, mate’! But you never know…\nHow about ordinary meteorites that come in their thousands, especially when the Earth’s orbit takes it through the former paths taken by disintegrating comets? When I was a kid rumours spread that a motor cyclist had a narrow escape on the flatlands around Kingston-upon-Hull in East Yorkshire, when a meteorite landed in his sidecar: probably apocryphal. But Michelle Knapp of Peeskill, New York, USA had a job for the body shop when a 12 kg extraterrestrial object hit her Chevrolet Malibu, while it was parked in the driveway. In 1954, Ann Hodges of Sylacauga, Alabama was less fortunate during an afternoon nap on her sofa, when a 4 kg chondritic meteorite crashed through her house roof, hit a radiogram and bounced to smash into her upper thigh, badly bruising her. For an object that probably entered the atmosphere at about 15 km s-1, that was indeed a piece of good luck resulting from air’s viscous drag, the roof impact and energy lost to her radiogram. The offending projectile became a doorstop in the Hodge residence, before the family kindly donated it to the Alabama Museum of Natural History. Another fragment of the same meteorite, found in a field a few kilometres away, fetched US$ 728 per gram at Christie’s auction house in 2017. Perhaps the most unlucky man of the 21st century was an Indian bus driver who was killed by debris ejected when a meteorite struck the dirt track on which he was driving in Tamil Nadu in 2016 – three passengers were also injured. Even that is disputed, some claiming that the cause was an explosive device.\nIf you would like to read more of Steve’s blogs …………… https://earthlogs.org/","Far more likely are those impacts that cause only moderate damage and few fatalities. Conducting surveys for NEOs and detailed studies of ways to mitigate collisions is best viewed as a form of insurance, the report says. How much to spend on these insurance premiums is a decision that must be made by the nation's policymakers.\nCongress mandated in 2005 that NASA discover 90 percent of NEOs whose diameter is 140 meters or greater by 2020, and asked the National Research Council in 2008 to form a committee to determine the optimum approach to doing so. In an interim report released last year, the committee concluded that it was impossible for NASA to meet that goal, since Congress has not appropriated new funds for the survey nor has the administration asked for them.\nThe National Research lays out two approaches that would allow NASA to complete its goal soon after the 2020 deadline; the approach chosen would depend on the priority policymakers attach to spotting NEOs. If finishing NASA's survey as close as possible to the original 2020 deadline is considered most important, a mission using a space-based telescope conducted in concert with observations from a suitable ground-based telescope is the best approach, the report says. If conserving costs is deemed most important, the use of a ground-based telescope only is preferable.\nThe report also recommends that NASA monitor for smaller objects – those down to 30 to 50 meters in diameter -- which recent research suggests can be highly destructive. However searching for smaller objects should not interfere with first fulfilling the mandate from Congress. Beyond completion of that mandate, the report notes the need for constant vigilance in monitoring the skies, so as to detect all dangerous NEOs.\nIn addition, the nation should undertake a peer-reviewed research program to better investigate the many unknown aspects connected with detecting NEOs and countering those that could be a threat. The U.S. should also take the lead in organizing an international entity to develop a detailed plan for dealing with hazards from these objects.\nFurthermore, immediate action be taken to ensure the continued operation of the Arecibo Observatory in Puerto Rico. NASA and NSF should support a vigorous program of NEO observations at Arecibo, and NASA should also support such a program at the Goldstone Deep Space Communications Complex. Although these facilities cannot discover NEOs, they play an important role in accurately determining the orbits and characterizing the properties of NEOs within radar range.\nNear-Earth objects are asteroids and comets that orbit the sun and approach or cross Earth's orbit. An asteroid or comet about 10 kilometers in diameter struck the Yucatan peninsula 65 million years ago and caused global devastation, probably wiping out large numbers of plant and animal species including the dinosaurs. Objects as large as this one strike Earth only about once every 100 million years on average, the report notes. NASA has been highly successful at detecting and tracking objects 1 kilometer in diameter or larger, and continues to search for these large objects. Objects down to sizes of about 140 meters in diameter -- which NASA has been mandated to survey for -- would cause regional damage; such impacts happen on average every 30,000 years, the report says.\nThe report also examines what is known about methods to defend against NEOs. These methods are new and still immature. No single approach is effective for the full range of near-Earth objects, the committee concluded. But with sufficient warning, a suite of four types of mitigation is adequate to meet the threat from all NEOs, except the most energetic ones.\n- Civil defense (evacuation, sheltering in place, providing emergency infrastructure) is a cost-effective mitigation measure for saving lives from the smallest NEO impact events and is a necessary part of mitigation for larger events.\n- \"Slow push\" or \"slow pull\" methods use a spacecraft to exert force on the target object to gradually change its orbit to avoid collision with the Earth. This technique is practical only for small NEOs (tens of meters to roughly 100 meters in diameter) or possibly for medium-sized objects (hundreds of meters), but would likely require decades of warning. Of the slow push/pull techniques, the gravity tractor appears to be by far the closest to technological readiness.\n- Kinetic methods, which fly a spacecraft into the NEO to change its orbit, could defend against moderately sized objects (many hundreds of meters to 1 kilometer in diameter), but also may require decades of warning time.\n- Nuclear explosions are the only current, practical means for dealing with large NEOs (diameters greater than 1 kilometer) or as a backup for smaller ones if other methods were to fail.\nAlthough all of these methods are conceptually valid, none is now ready to implement on short notice, the report says. Civil defense and kinetic impactors are probably the closest to readiness, but even these require additional study prior to reliance on them.\nGiven the significant unknowns about many aspects of the threat and its mitigation, the report recommends that the U.S. start a peer-reviewed, targeted research program on the hazards posed by NEOs, and how to deal with them."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:5afeea9f-a1ad-4cad-bc40-943c554ef264>","<urn:uuid:f0457ce2-3fc8-42ac-8d25-ce54b835bacc>"],"error":null}
{"question":"How did Fox Movietone News document American life from 1919-1963, and what modern facilities help preserve the history at Cowpens Battlefield today?","answer":"Fox Movietone News camera crews documented both mundane and spectacular events across America from 1919 to 1963, with their footage preserved as camera negatives at Moving Image Research Collections. At Cowpens Battlefield, the history is preserved through modern facilities including a visitor center with exhibits, a fiber-optic map display, a film titled 'Cowpens: A Battle Remembered,' and a museum featuring authentic Revolutionary War weapons and a full-size reproduction of a British 3-pounder Grasshopper cannon. The site also maintains the original Green River Road as one of the few surviving roads from the Revolutionary period.","context":["Browse by Topic\nBrowse by Library\nAfrican Americans Seen Through the Eyes of the Newsreel Cameraman\nFox News and Fox Movietone News camera crews covered the people and events of the country and, indeed, the world. From 1919 to 1963 these journalists aimed their viewfinders at the mundane and the spectacular. The resulting images - most of which still exist as camera negatives at Moving Image Research Collections--provide an unparalleled opportunity to glimpse the world through their eyes.\nBeulah Glover Photograph Collection\nIn about 1937 Miss Beulah Glover (17 Aug. 1887 ï¿½ 4 Jan. 1991) opened a photography studio in Walterboro, S.C. Being also an historian, Miss Glover shot many historical scenes in the Lowcountry. She converted some of these images to postcards and sold them in her studio, Foto-Nook. She also used images to illustrate her many articles and books on the history of Colleton County. Miss Glover worked also as photo-journalist, selling her images to the Walterboro newspaper. This small sampling of images by Miss Glover includes prints and negatives and covers the years 1941 to 1952.\nBroadsides from the Colonial Era to the Present\nNow, broadsides (posters, one page fliers, advertisements and other types of ephemera) from across many different South Caroliniana Library manuscript collections can be searched, viewed, read, and compared. The dates range from the 1700s to the present, and items will continue to be added to this collection.\nDelbert Claire Brandt Collection\nThis collection contains 32 letters and postcards relating to Delbert Claire Brandt (Claire Brandt), a young man from Sharon, Pennsylvania who served with the 1st Cavalry in World War I, was wounded, and died on November 16, 1918. The letters were written between May 1918 and November 1918. Most of the letters are from Claire Brandt to his sister Beatrice. Topics range from the care packages which Beatrice sent to Claire Brandt’s travels in the army.\nFox Movietone News, The War Years\n“Fox Movietone News: the War Years, 1942 – 1944,” a collaboration between the University of South Carolina and the Library of Congress, provides online access for the first time to over two hundred Fox Movietone News newsreels released in American theaters from September 1942 through August 1944. Before the era of television news broadcasts, newsreels were shown in theaters across the country to inform and entertain audiences. During the war, two newsreels per week were released by each of the five major American newsreel companies (Fox Movietone News, Universal News, Hearst News of the Day, Paramount News, and Pathé News). These 8 to 10 minute Fox Movietone News newsreels record how the world appeared on screen to the American public during the war. As a whole, the collection helps us better understand how the war was waged on the home front. The films reveal a concerted effort to sustain a sense of “normalcy” in America even as war ravaged much of the globe. Battlefield victories (and losses) were interspersed with beauty pageants and ball games. But even when light-hearted news dominated much of a newsreel, the war was an inescapable reality.\nIsaac Rosenberg: Early Poetry and Related Documents from the Joseph Cohen Collection of World War I Literature\nRosenberg, recognized as the first significant Jewish poet in English literature, was one of the major poets whose life was cut short by the Great War, and the only one who served in the ranks. This online collection includes six items, including one of only three known copies of Rosenberg's first book of poems, Night and Day (1912). This copy also contains a manuscript poem in Rosenberg's own hand.\nJoseph M. Bruccoli Great War Collection\nThe Great War of 1914-1918 remains a watershed in social and cultural history, on both sides of the Atlantic. It involved millions of combatants from around the globe. It technologized warfare. It redrew the map of Europe. It precipitated lasting changes in demographic structure, social behavior, and cultural expression. It marked the imagination, not of one generation only, but of generations to come.\nJoseph M. Bruccoli (1892?-1965) was a veteran of the Great War. His campaign medal carried eight bars, each representing a major battle in which he participated. He was severely wounded and was deeply patriotic. His son, Professor Matthew J. Bruccoli, has initiated this collection as a continuing personal project in his father's memory.\nO.H. Wienges World War II Collection\nThis collection is comprised of first hand accounts, logs, and photographs of life on the U.S.S. Landing Craft Infantry 759 during World War II. The journaled account was written by Gerald Atherton forty years after his experiences. The Executive's morning order book was kept by Lt. O.H. Wienges while on the Naval ship. The collection also includes a map of the travel route taken by the U.S.S. LCI 759. As an added bonus, Wienge's diary as a teenager in 1938 is also included.\nOliver Hart Papers, 1741-1962\nThe papers of the Reverend Oliver Hart (1723-1795) span the years 1741 to 1795 and include correspondence, diaries, and sermon notes from colonial and Revolutionary periods in Charleston, S.C. The bulk of the correspondence is from Oliver Hart to his brother, Colonel Joseph Hart of Bucks County, Pennsylvania, relaying news from South Carolina during the Revolutionary War. Ten volumes of diaries and journals detail diverse activities in Hart's life. Topics discussed include a storm in Charleston harbor in 1761, travels in Virginia and North Carolina, and his tour of the South Carolina upcountry during the initial months of the American Revolution with William Henry Drayton (1742-1779) and Congregational minister William Tennent III (1740--1777), and later officiated at the latter's funeral. Throughout his journals, Hart always notes the weather and from what verse he preached a particular sermon.\nPaul Hamilton Papers, 1802 - 1812\nThis small collection of letters written by U.S. Secretary of the Navy Paul Hamilton (1762-1816) documents concerns and developments during the months preceding the War of 1812.\nPrimary Sources for K-12 , Pilot Project\nIn collaboration with a pilot group of South Carolina teachers, USC Libraries has made these primary resources available online. We want to build on this effort. Please let us know what you think.\nSheet Music from the Joseph M. Bruccoli Great War Collection\nThe Joseph M. Bruccoli Great War Collection founded by Matthew J. Bruccoli in memory of his father includes over a thousand pieces of chiefly American sheet-music from the First World War. The Collection includes a variety of popular music from marches to rag-time to jazz, pieces made popular by the top performers of the era, themes of patriotism, love, the many roles of women, and the war itself, often with humor, as well as the story of music publishing in the U.S., in particular. It is noteworthy that the Collection includes a number of variant editions. These were quite deliberately collected to illustrate the demand for the most popular songs overtime, while also advertising varying lists of the next group of popular songs.\nSouth Carolina and World War II\nThis virtual collection brings together materials documenting the South Carolina home-front during World War II as well as experiences of South Carolina soldiers.\nTopical Sketches by Douglas G. Ward\nThis World War I soldier's sketchbook is the mark of Cpl. Douglas G. Ward, an otherwise unknown British soldier-artist. Douglas G. Ward entered the military and trained at Catterick Camp, the infantry training center and was assigned to the 7th Battalion, South Staffordshire Regiment which was part of the 33rd Brigade, 11th (Northern) Division, landing at Sulva Bay (Gallipoli) 7th August 1915. Ward was wounded at the Somme and on leaving the hospital in 1916 he was transferred to a different unit and was sent to India.His sketches are executed in pen and ink and watercolor and cover subjects ranging from basic training to romance. The sketchbook was acquired in 2006 with funding from the USC Educational Foundation. The sketchbook was purchased by the Thomas Cooper Library for the Joseph M. Bruccoli Great War Collections.\nU.S. Food Administration Food Conservation Notes, 1918\nThe U.S. Food Administration was established by Executive Order 2679-A (August 10, 1917). President Wilson appointed Herbert Hoover as its administrator. Hoover realized that conservation was the only way to quickly increase food stocks and correctly believed that people would voluntarily conserve food to help the war effort. Through promotions such as Meatless Mondays and Wheat-less Wednesdays, the agency was able to reduce domestic food consumption by 15% and supply US and allied forces. The US Food Administration ceased with Executive Order 3320 (August 21, 1920) after post-war shipments of food had helped prevent famine in Europe.\nWilliam Ancrum Papers, 1757-1789\nFormerly owned by wealthy Charleston merchant William Ancrum, this volume contains both a letter book and financial accounts that reflect the financial impact of the American Revolution on this South Carolina businessman and planter.\nWilliam Tennent III (1740 - 1777), Travel Journal and Album of Collected Papers\nThese online collections contain not only Tennent's Journal and Album, but also a 1974 essay entitled The Back Country Commission of Drayton, Tennent, and Hart by L.L. Owens and two maps of their back country route. The journal covers Tennent's trek though the S.C. back-country, at times in the company of William Henry Drayton and Rev. Oliver Hart in an effort to persuade Loyalist Tories to join the Patriot cause. The album contains papers documenting Tennent's life as a Presbyterian minister in the Colonies of New Jersey and Connecticut, the courtship of his wife despite her mother's objections, and his 1772 arrival in Charleston, S.C., to serve the Independent or Congregational Church among other topics.\nWorld War I Letters of Samuel Bloom\nSamuel Bloom (1895-1976), a first-generation Ukrainian immigrant and recent City College graduate, served as private first class and signaler with Company L, 325th Infantry Battalion, US Army, from October 1917 till July 1919. This project makes available the full sequence of Blooms life during World War I including his letters, postcards, and diaries, arranged chronologically.\nWPA Week in National Defense\nIssued in 1941, The WPA Week in National Defense presented brief news items concerning the Work Projects Administration’s activities throughout the United States. Formerly the Works Progress Administration, this agency provided jobs in construction, adult education, writing, and art. The WPA Week described products of this work leading up to the second World War. The circulars cover subjects such as the building of armories and air bases, mosquito control at military camps, renovation of water and natural gas supply systems, mural painting, and recreation.","|Getting Around Cowpens Battlefield\nCowpens National Battlefield is open daily from dawn to dusk. Visitor center parking is available from 9 am to 5 pm. For other hours, use the trailhead parking one mile east of the park gate.\nVisitor Center Start here for information, exhibits, and a bookstore. You can see a fiber-optic map display, a film, “Cowpens: A Battle Remembered,” and a museum with authentic Revolutionary War weapons and a full-size reproduction of a British 3-pounder Grasshopper cannon. Open daily except Thanksgiving, December 25, and January 1.\nAuto Loop Road The three-mile loop around the perimeter of the battlefield features wayside exhibits, overlooks, and short trails to the Green River Road, the battlefield, and the Robert Scruggs House, an early 1800s log cabin. Note: The loop road and picnic area close at 4:30 pm.\nBattlefield Trail A 1.25-mile self-guiding walking tour begins and ends at the visitor center. The trail includes the Green River Road along which the battle was fought. This portion of the original road is one of the few that still exists.\nRegulations and Safety Tips\nUse caution when driving the loop road. Watch for pedestrians and bicyclists.\nBicycles are allowed on the loop road and parking areas only. Bicyclists must wear helmets, travel in the same direction as traffic, and use the bike lane to allow vehicles to pass. There is a bicycle rack at the visitor center parking lot.\nPets are not allowed in buildings. They must be attended at all times and be on leashes no longer than six feet.\nPark and picnic only in designated areas.\nIt is a violation of federal law to climb on monuments.\nCowpens National Battlefield\nP.O. Box 308\nChesnee, SC 29323\nCowpens National Battlefield is one of over 390 parks in the National Park System. To learn more about national parks visit www.nps.gov.\nOn this field on January 17, 1781, Daniel Morgan led his army of tough Continentals and backwoods militia to a brilliant victory over Banastre Tarleton’s large force of British regulars. When he marched his army onto this field the previous afternoon, Morgan was trying to elude a British trap. That morning, as his men cooked breakfast in camp on Thicketty Creek, scouts brought news that Tarleton had crossed the Pacolet River, 12 miles south, and was coming up fast. Morgan broke camp immediately and ordered his soldiers down the road. Their destination: the Cow Pens, a frontier pasturing ground on the road to a ford across the Broad River six miles to the northwest. Morgan was in a precarious position. If he crossed the river most of his militia would probably desert him. If Tarleton caught the Americans on the road or astride the river, they could all be cut down. Morgan chose to stand and fight.\nWho was this tactical genius behind the victory at the Cow Pens? Daniel Morgan was a self-made man. Before he was 20 he was hauling freight on poorly defined roads over the mountains of Virginia. During the French and Indian War he served as a teamster in the British army and accompanied Gen. Edward Braddock’s ill-fated 1755 expedition against Fort Duquesne. In 1756 he struck a British officer and was sentenced to 500 lashes with a cat-o’-nine tails, a punishment that had killed lesser men. He later claimed that the British still owed him one lash. When the Revolutionary War began, he led a unit of Virginia sharpshooters to Boston, where they joined with the Continental Army and, in the winter of 1775, took part in an abortive attack on Quebec. Captured and exchanged, Morgan recruited another unit of Virginia sharpshooters and joined Maj. Gen. Horatio Gates’s army in time to play a decisive role in winning the two battles of Saratoga on September 19 and October 7, 1777. In July 1779, passed over for promotion, he left the Army and returned to Virginia.\nMorgan rejoined the army in September 1780 after Gates, who had been given command of Continental forces in the South, suffered a disastrous defeat at Camden, S.C. Promoted to brigadier general, Morgan was commanding a corps of light troops when Maj. Gen. Nathanael Greene replaced Gates in early December and set about recovering American military fortunes. Greene’s strategy was to divide his own army and force the British to split theirs. To accomplish this, he sent Morgan with a detachment known as the “Flying Army” into western South Carolina to operate on the British left flank and rear, threatening their outposts and giving “protection to that part of the country and to spirit up the people.”\nTo remove the threat that Morgan’s presence created, the British commander in the South, Maj. Gen. Charles Cornwallis, sent Banastre Tarleton with the British Legion and some of his best light troops. Tarleton, the son of a British merchant, had purchased his commission in the British Army. The Legion was known for its brutality in cutting down unarmed or fleeing soldiers. Tarleton himself was widely hated in South Carolina after his troops butchered Col. Abraham Buford’s surrendered Continentals at Waxhaws in May 1780. When Cornwallis sent his 26-year-old cavalryman after Morgan, he helped set the stage for a confrontation between two of the Revolutionary War’s most colorful commanders.\nMorgan knew that Tarleton’s force outnumbered his own. To help even the odds, he sent for militia units from South Carolina, North Carolina, and Georgia—men who had fought at Musgrove Mill, Kings Mountain, Kettle Creek, and Williamson’s Plantation, men who had fought in fierce hand-to-hand combat with Indians to protect their homes. These were men of great courage and experience, but Morgan knew they were no match for British battle tactics. The rifles they carried would not mount a bayonet, making them defenseless in the face of a bayonet attack or a mounted charge by dragoons. The militia’s strength lay in their prowess with their rifle, a weapon of far greater range and, in their hands, deadlier and more accurate than the British muskets. Morgan kept this in mind as he devised a plan of battle to match the strengths of his men and the terrain.\nMorgan wisely chose to fight in an open wood on ground that sloped gently toward the southeast, the direction from which the British would approach. The field had three low crests separated by wide swales. A road, later known as the Green River Road, curved through the area. Morgan formed his troops in three lines straddling the road. In the front line he placed sharpshooters in small groups. Their job: slow Tarleton’s advance with well-aimed fire, then fall back. Ninety yards behind the sharpshooters he put the regional militia, under Andrew Pickens. Morgan asked them for two volleys at a killing distance; then they were free to withdraw behind the Continentals. About 150 yards behind Pickens, stretching along the forward crest, were his crack Maryland and Delaware Continentals and veteran Virginia militia, about 600 men commanded by John Eager Howard. Behind that crest, he stationed the cavalry, approximately 150 men under William Washington, with orders to protect the militia and be ready to ride into the fight.\nJust before dawn the British came into full view of the American front line. After sending cavalry forward to drive in the sharpshooters, Tarleton formed and advanced his line of battle—infantry astride the road; on each flank, 50 dragoons; in reserve, a brigade of Highlanders and 200 cavalry. As the British came within range, the main militia line delivered a deadly fire, dropping two-thirds of the officers, then withdrew behind the Continental line. The dragoons on the British right pursued the militia but were driven back in a fierce charge by Washington’s cavalry.\nThe British surged onto the third line, and the fighting became pitched. The Highlanders threatened to outflank the American right. At this point began a confused tangle of events that soon brought the fighting to a dramatic conclusion. When Howard ordered his right to fall back and form a new front, the order was misinterpreted and the whole line began to retreat.\nSeeing this maneuver, Morgan rode up and chose new ground for the Continentals to rally on. Reaching that point, they faced about and fired point-blank at the closing redcoats, then plunged into the staggered ranks with bayonets. As this was happening, Washington’s cavalry rode again into the swirling fight, while on the British left, Pickens’s militia opened a galling fire on the dragoons and Highlanders. British resistance quickly collapsed. A few dragoons rallied to Tarleton, but they could do nothing effective and followed the Legion cavalry, which never got into the fight, in a pell-mell dash off the field.\nThe battle was over in less than an hour. British losses were staggering: 110 killed, 229 wounded, and 600 captured or missing. Also captured with the British were a number of slaves. Morgan’s losses were 24 killed and 104 wounded. The “Old Waggoner’s” unorthodox tactical masterpiece had indeed “spirited up the people,” not just those of the backcountry Carolinas but those in all the colonies. In the process, as Morgan later told a friend, he had given Tarleton and the British a “devil of a whipping.”\nThe Southern Campaign, 1778–1781\nNew Hope for the American Revolution\nBy the time the Battle of Cowpens was fought, the lower South had become the decisive theater of the Revolutionary War. After the struggle settled into stalemate in the north, the British mounted their second campaign to conquer the region. British expeditionary forces captured Savannah in late 1778 and Charleston in May 1780. By late that summer, most of South Carolina was pacified, and a powerful British army under Lord Cornwallis was poised to sweep across the Carolinas into Virginia. This map traces the marches of Cornwallis (in red) and his adversary Nathanael Greene (in blue). The campaign opened at Charleston in August 1780, when Cornwallis marched north to confront Horatio Gates at Camden. It ended at Yorktown in October 1781 with Cornwallis’s surrender of the main British army in America. In between were months of some of the hardest campaigning and most savage fighting of the war.\nChain of Command\nDaniel Morgan - Morgan was a frontiersman, a teamster by trade, experienced at fighting Indians, and something of a genius at leading men in battle. When at age 45 he took command of Nathanael Greene’s light troops in 1780, he was already well-known for his military abilities, having fought with distinction at Quebec in 1775 and at Saratoga in 1777. After Morgan left the army in February 1781 due to illness, Greene remarked: “Great generals are scarce —there are few Morgans to be found.”\nBanastre Tarleton - Tarleton had a reputation for being ruthless and fearless in battle. An offspring of British gentry, he was schooled at Oxford University, and at 21 became an officer of dragoons. He volunteered for service in America and campaigned with some distinction in the north. In his mid-20s he found himself commander of the British Legion, a mobile striking force of cavalry and infantry. American propagandists vilified him. Decades after the war American writers nicknamed him “Bloody Tarleton.”\nMorgan’s militia were tough and experienced. Some 200 were ex-Continentals from Virginia under Maj. Francis Triplett. Others were recruits from Georgia and the Carolinas commanded by the wily partisan Col. Andrew Pickens. Morgan knew the worth of these troops and deployed them in a way that made the most of their strengths and minimized their weaknesses. They rewarded him with a victory still marveled at over 200 years later.\nLt. Col. John Eager Howard’s battalion of Maryland and Delaware Continentals fought courageously at Cowpens and afterwards. Nathanael Greene called Howard “as good an officer as the world affords.” The Maryland unit was one of the few regiments to fight in both the Northern and Southern campaigns. By war’s end, the Delaware Continentals attained a reputation as one of the elite light infantry units of the Southern Army.\nFew officers saw more combat than Lt. Col. William Washington, a second cousin of George Washington, the commanding general. A veteran of numerous battles and skirmishes, he and his Third Continental Dragoons were the main reserve at Cowpens. Hidden by the terrain behind the Continental line, they were sufficiently near “as to be able to charge the enemy, should they be broken.”\nThis green-uniformed unit was the mounted arm of Tarleton’s British Legion. As constituted at Cowpens, it was a mixture of loyalists and American prisoners of war from Camden, armed with saber, pistol, and attitude.\n16th Light Infantry\nThis detachment from the 16th Regiment of Foot was composed of men selected for their agility and endurance. These were crack troops, most of whom had been fighting in America since the beginning of the war.\n7th Royal Fusiliers\nAlthough drawn from the 7th Regiment of Foot, one of the oldest regiments in the British Army, this battalion was composed of untested new recruits only partially trained.\nEighteen royal artillerymen were responsible for the two light cannon that accompanied Tarleton’s force. These guns, which may have been captured from the patriots at the Battle of Camden, helped to boost Tarleton’s confidence in confronting Morgan at Cowpens.\nKnown as Fraser’s Highlanders, this elite regiment was raised for duty in America and saw extensive service in the Northern Theater before being transferred to the South in 1780. The regiment fought valiantly at the Siege of Savannah and in subsequent operations in South Carolina.\n17th Light Dragoons\nThe excellence of this regiment made it the first cavalry corps selected for service in America in 1775. Detachments were present in most of the important engagements throughout the war. The men were a model of discipline for other cavalry troops raised by the British in America during the war."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f3ad9bd3-24bb-4e04-a2d6-18b4a855ab63>","<urn:uuid:1a87f16c-bf35-4965-a660-b01f97b4ba91>"],"error":null}
{"question":"What are the key differences between Enduring Powers of Attorney (EPAs) and Lasting Powers of Attorney (LPAs) in terms of their legal scope and validity?","answer":"EPAs and LPAs differ in several key aspects. EPAs can no longer be made since October 2007, although those made before then can still be used if valid. EPAs are limited in scope as they do not extend to decisions about the donor's health and welfare. In contrast, LPAs, introduced in 2007, come in two types: Property and Financial Affairs LPA for handling assets and finances, and Health and Welfare LPA for making decisions about care and medical treatments.","context":["Powers of Attorney: what are they and why are they so important?\nWhilst many people appreciate the importance of having a Will to deal with arrangements on death, the importance of having a Power of Attorney to deal with the position when a person loses capacity during their lifetime is often underestimated.\nThe COVID-19 pandemic has, unfortunately, highlighted the practical and emotional difficulties family members face when their loved ones have lost capacity to act for themselves, but there is no Power of Attorney in place. Clients may assume that their family members are automatically entitled to make medical decisions and to deal with their assets, but that is not the case.\nThis dilemma was recently highlighted by television presenter Kate Garraway, whose husband, Derek Draper, has been seriously ill after suffering from COVID-19. Kate has said:\n“One of the practical problems – which a lot of people would have experienced if they’ve got the absence of someone in their life – like many things, the car is entirely in Derek’s name, the insurance is in Derek’s name, a lot of our bank accounts. There are lots of financial goings on which are making life very complicated because I can’t get access to things because legally I haven’t got power of attorney.”\nKate has also reported that she has faced difficulties accessing her husband’s medical records without a Power of Attorney.\nWhat is a Power of Attorney?\nA Power of Attorney is a legal document put in place when a person (“the donor”) has capacity to make it. The donor appoints an attorney (or attorneys) to make decisions and to act for them, if they lose capacity. This appointment continues beyond the donor’s loss of capacity, which includes both mental and physical capacity.\nThe predecessors to Lasting Powers of Attorney were Enduring Powers of Attorney (“EPAs”). Since October 2007, EPAs can no longer be made, but those in place before then can still be used, provided that they are valid. It would be prudent to check the validity of existing EPAs to confirm they reflect the donor’s current wishes. EPAs do not extend to decisions in relation to the donor’s health and welfare.\nSince 2007, Lasting Powers of Attorney (“LPAs”) can be put in place. There are two types of LPA.\n(I) Property and Financial Affairs LPA\nThis gives the attorney authority to deal with the donor’s property and assets, for example insuring, maintaining or selling their house, access to bank accounts and investment portfolios, paying bills and expenses (including medical expenses). There are legal limitations on the attorney’s ability to make gifts under the LPA.\n(ii) Health and Welfare LPA\nThis gives the attorney authority to make decisions about the donor’s health and well-being, including where they live, their day to day care and medical treatments. The donor can also authorise the attorney decide whether or not the donor should receive life sustaining treatment. Alternatively, decisions in relation to end of life care can be made by an advance decision, which is a separate legal document.\nIt is not a requirement to complete both LPAs, but it is advisable. For example, it is helpful for the attorneys to be able to use the Property and Financial Affairs LPA to meet medical costs incurred by the attorneys under the Health and Welfare LPA.\nWhat happens if there is no Power of Attorney in place?\nWithout an EPA or LPA, family members will not be able to deal with the assets of an incapacitated person. The family members will also have less say in the care and medical treatment of their loved one. It is likely that doctors would consult family members about significant medical decisions, but an LPA gives the attorneys greater involvement in the donor’s care.\nIf someone does not have an EPA or LPA, family members will need to apply to Court of Protection for the grant of a Deputyship Order to give them such authority. This involves instructing solicitors to issue proceedings to apply for the Order. The process can take some time and is a much more costly process than putting an LPA in place.\nHow does someone make an LPA?\nAn LPA can be made if the donor has capacity to do so. It is preferable for this to be done when it is clear that the donor has capacity and we encourage clients to make LPAs at the earliest opportunity. Powers of Attorney are not just for elderly clients; loss of capacity can happen as a result of accident or illness.\nThe process involves the completion of one set of forms for each LPA. There are several aspects which need to be considered, depending on the donor’s personal situation, their wishes and their asset base.\nThe donor must decide who to appoint as their attorney. This is an important decision because the role of attorney is one of great trust. A donor can appoint more than one attorney, but they should consider whether those attorneys will work effectively together. The donor can appoint different attorneys under each LPA, or the same people.\nIf the donor appoints more than one attorney, consideration needs to be given to whether they should act jointly (so that they have to make each decision together) or whether they can act jointly and also make decisions individually. The latter option makes the LPA administratively easier for the attorneys to use, but provides less of a “check and balance” on actions being taken by individual attorneys.\nCare needs to be taken where attorneys are appointed jointly because if one of the attorneys ceases to be able to act, the LPA will terminate.\nDonors need to consider whether to appoint a replacement attorney, to step in in the event that the original attorney cannot act, or is unwilling to do so.\nAn important practical point to consider is whether the donor holds investment portfolios which are or may in the future be managed on a discretionary basis. The strict legal position is that attorneys cannot delegate decision making about the donor’s assets. This can cause difficulties if the attorneys want to delegate the management of investment portfolios on a discretionary, rather than advisory, basis. The donor and their advisers should consider including a special clause in the LPA which permits delegation in this situation.\nThe attorneys will not be entitled to see the donor’s Will and the solicitor who prepared it will owe a duty of confidentiality to the donor. If the donor would like the attorney to be able to see their Will before they have died (for example, so the attorney knows not to sell or give away assets specifically gifted under the Will) this consent needs to be included in the LPA.\nThe donor can include a number of other restrictions, conditions and/or guidance in their LPA. It is very important that these are carefully considered depending on the particular circumstances and drafted so that they do not undermine the effectiveness of the LPA, nor contravene the law which applies to LPAs. The completion of LPA forms is carefully prescribed by the Office of the Public Guardian (“OPG”). It is therefore advisable to seek legal advice when putting LPAs in place.\nOnce the forms have been completed, they need to be signed in a particular order, prescribed by legislation. First they need to be signed and dated by the donor in the presence of a witness. There are restrictions on who can act as a witness to the signature (for example, the attorney cannot be the witness).\nThe donor will then need someone to sign the forms as the donor’s “certificate provider” to confirm that the donor has the requisite capacity to make the LPA. This role is usually undertaken by a solicitor or a GP.\nThe forms then need to be signed and dated by the attorneys (and any replacement attorneys) in the presence of a witness.\nOnce completed, the forms can be registered with the OPG immediately. This prevents delay if the LPAs need to be used urgently in the future and also helps identify any issues the OPG raises with the forms before the donor loses capacity.\nThis article first appeared in the Professional Adviser on 20 April 2020."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:91993cae-dab6-427f-a3e6-4df9053fb5ce>"],"error":null}
{"question":"What specific percentage decrease in runoff is predicted during July and August in the Connecticut River Watershed due to climate change?","answer":"According to predictions, warmer temperatures will decrease runoff by up to 71 percent in the late summer months of July and August, when water demand is highest.","context":["USDA-UM Studies Climate Impacts on Watersheds\nA U.S. Department of Agriculture-funded study done at the University of Massachusetts Amherst shows that rising temperatures due to climate change will reduce the availability of water in the Connecticut River Watershed during the summer when demand is highest and increase sediment and pollution loads carried by rivers and streams. The river serves as Greater Boston's primary water supply and is home to thousands of species of plants and animals in a national Fish and Wildlife Refuge.\nChanges in the watershed will add to existing pressure on ecosystems and have important consequences for agriculture, forestry, fisheries and water supplies. Results of the study were published earlier this year online in Climatic Change.\n\"The response of watershed systems is a new area of climate change research, and the U.S. Environmental Protection Agency is calling for proposals to study this issue,\" says Timothy Randhir, a professor of natural resources conservation. \"With additional funding, I hope to expand this research to the national level.\" Graduate student Eric Marshall co-authored the study.\n\"Fortunately, sound land-use planning can help protect the watershed, including the maintenance of forests in urban areas, reducing loss of open space throughout the watershed and protecting flood plains,\" says Randhir. \"Low-impact development and smart growth principles can go a long way in our ability to handle climatic impacts.\"\n\"Communities will need to plan for water stress months and implement water conservation practices throughout the year,\" says Randhir. \"Water harvesting along with a network for upland storage could help manage water resources, and maintaining vegetation along streams will provide a buffer between surface runoff and sensitive streams.\"\nComputer models used to predict changes over the next 40 years showed a decrease in the annual amount of water running off the surface of the land to feed streams and rivers in the watershed, which contains 390 towns and cities and an estimated 2.3 million people. Large changes in the timing of this runoff were also predicted.\n\"Typically, we see precipitation held as snow throughout much of New England in winter, and a slow release of water during the spring melting season. But warmer temperatures associated with climate change will change this pattern,\" says Randhir. \"This is expected to decrease the annual snowpack and can cause large increases in runoff during the winter months, especially January. Systems that handle stormwater in urban areas will have to add extra capacity to avoid being overwhelmed by flooding.\"\nWarmer temperatures were predicted to decrease runoff by up to 71 percent in the late summer months of July and August when demand is highest, resulting in reduced stream and river flows that could threaten community water supplies and the production of power at 16 hydroelectric dams located on the Connecticut River. Lower water levels in streams and rivers would mean less water for agriculture and make it more difficult to navigate rivers.\nMany species of animals may have trouble adapting to the change. \"Fish need adequate water flowing in rivers and streams in order to migrate,\" says Randhir. \"We can expect to see severe strains on spring fish runs, and changes in the watershed also will increase environmental stress on other species including mammals and birds.\"\nRandhir expects water quality to decrease as surface temperatures rise. Sediment loads carried by rivers and streams were predicted to rise by 50 percent between June and October while the volume of waters receiving the sediment decreased. In addition, changes in the watershed will alter the balance of key nutrients such as nitrogen and phosphorus, resulting in more frequent and intense blooms of algae and increased growth of aquatic plants.\nStormwater systems in urban areas will have to plan for the added sediment and pollution, and greater amounts of sediment will be carried into Long Island Sound, where the Connecticut River meets the sea. Higher sediment loads and pollutant levels could also impact the ability of fish to migrate, and place additional stress on aquatic ecosystems."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:cf851856-cbe0-4820-afc2-aa51fd07594d>"],"error":null}
{"question":"How does the career preparation approach differ between university green career programs and HVAC technician training in Virginia?","answer":"University green career programs and HVAC technician training in Virginia take different approaches to career preparation. University programs like those at Virginia Tech and George Washington University focus on leadership development, offering executive-level education with career coaching, professional networking, and strategic connections. These programs typically combine online and in-person learning, with features like global study trips. In contrast, HVAC technician training is more hands-on and technical, requiring 6 months to 2 years of accredited programs or 3-5 year apprenticeships with 2000 hours of training. HVAC training focuses on specific technical skills like installing and maintaining ventilation systems, repairing motors, and working with electrical systems. Both paths offer good career prospects, with green careers emerging in new fields and HVAC jobs projected to grow 21% over 10 years.","context":["By Linda Mansdorf\nWith all of the changes going on in the world due to the changing climate, we are seeing the need for skilled and educated workers in new fields. In this panel session, a number of university Career Fair Exhibitors provided an interactive discussion session to find out more about their offerings for students and professionals, geared to attendees who are seeking to start a green career or to advance their green career. This panel took place at the Resilient Virginia 2021 Conference and served as a prelude to the following day’s 8th Annual Green Jobs Forum and Career Fair with Leaders in Energy. The panelists are listed below along with a summary of the session highlights. The panel took place on August 25, 2021.\nJanine Finnell (Moderator), Executive Director, Leaders in Energy\nDr. Edward Saltzberg, GWU, Director, Professional Education, Environmental & Energy Management Institute\nDr. David Robertson, Virginia Tech, Founding Director, XMNR & CLIGS programs\nAmy Hubbard, Virginia Tech, Program Coordinator & Student Advisor, XMNR & CLIGS programs\nDr. Cody W. Edwards, Associate Provost for Graduate Education and Executive Director, Smithsonian-Mason School of Conservation (SMSC) at George Mason University\nDr. Christopher J. Mordaunt, John Tyler Community College, Energy Technology Program, Certificate & AAS\nJanine Finnell, Executive Director of Leaders in Energy kicked off the University Green Career Paths session, welcoming representatives from George Washington University (Dr. Edward Saltzberg), Virginia Tech (Dr. David Robertson and Amy Hubbard), the Smithsonian-Mason School of Conservation at George Mason University (Dr. Cody Edwards), and John Tyler Community College (Dr. Christopher Mordaunt).\nThe panelists gave short presentations on their school’s programs including coursework, certifications, and career planning. This included the progression from education into green careers – offerings for both students and professionals – either starting off, changing careers, or seeking advancement in their current career. Most of the programs had a wide variety of students and were geared to either working professionals (or recent graduates) and offered practical competencies and strategic connections (as well as hands-on real world experiences). Each explained how their coursework prepares students for professional roles in the industry.\nEach program had something different to offer: Dr. Salzberg detailed George Washington University’s Environment and Energy Management Institute (EEMI) certificate programs comprised of short courses (on energy systems and resilience) designed for busy professionals (who can take 4 months to complete a course). The focus of the coursework is a systemic approach – to raise the level of understanding of the importance of energy resilience to the future of an organization and how the underlying energy network drives resilience in the outcomes.\nDr. Saltzberg explained how the systems approach looks at all aspects of energy resilience – food systems, water systems, etc. all interact with each other (without good water, food, etc. you don’t have good public health, etc.). The coursework helps prepare working professionals to be better energy leaders, advisors, decision-makers, investors, regulators, and educators.\nAmy Hubbard and Dr. David Robertson gave a presentation on Virginia Tech’s Executive Master of Natural Resources (XMNR) and Climate Leadership in Global Sustainability (CLIGS) programs. The program is a hybrid format (75% online, 25% in person; 11 class weekends, and a 10-day global study trip). Students range in age from their 20s to their 60s, with varied backgrounds and experiences; and there is a cap on the number of students at 35 students per year. Career consulting and professional networking are built into the coursework. The focus is on leadership and communications competencies, peer-to-peer learning, individualized attention, career coaching (students can customize their learning experience), as well as providing access to its robust professional and alumni network. The school also offers an early admissions scholarship coupon of $1,000.\nPerhaps the most unusual learning experience was that offered by George Mason, giving hands-on conservation biology training for high school, undergraduate, and graduate students, and professionals at the internationally renowned Smithsonian 3,200 acre campus in Front Royal, VA. Dr. Cody Edwards explained how students learn by working with renowned professionals from all over the world – scientists, educators, administrators or animal keepers who teach/run programs. The focus is on working with practitioners (as opposed to. lectures). Begun in 2012, the program is a partnership with George Mason and the Smithsonian (Smithsonian-Mason School of Conservation). Students go on to graduate school, create their own sustainable farms or other enterprises, go on to work with scientists, researchers, and academics or work in other sectors directly related to conservation and sustainability. Students gain real-time conservation experience; some students work with organizations (NGOs) that go on to hire them (students are doing hands-on work needed by the organizations). Notably, Jane Goodall has taught at the school. There is a wide variety of levels of coursework, from summer programs, High School, undergraduate, graduate, professional and conservation internships (which often lead to jobs in the conservation sector).\nDr. Christopher Mordaunt presented on John Tyler Community College’s Energy Certificates and Engineering Technology Programs. The programs are G3 eligible (a program for any Virginia resident who qualifies for in-state tuition and whose family income falls below an identified threshold) – publically funded to prepare students to fill an increased number of green jobs in Virginia. Currently, there are opportunities in local and state-wide industries. Dr. Mordaunt said there is a tremendous growth in energy sector in general, and Virginia in particular is experiencing rapid growth in renewable energy applications. Students can take college courses in high school and get college credit; the programs get local companies involved and give students hands-on experience. The college’s energy programs prepare students for roles as energy systems installers or maintenance personnel and energy system technicians. Another program leads to an associate degree in an energy specialization.\nA few takeaways from the session included: the fact that new jobs exist today that did not exist even three years ago. There is a current greening of business and a corresponding growth of choices in green education. Young people now expect to have multiple jobs/careers over their working life (perhaps as many as 14). School is no longer linear and certificate programs are popular. However, credentials and degrees don’t necessarily lead to a job. For this reason, Virginia Tech’s XMNR, and the Center for Leadership in Global Sustainability (CLIGS) program focus on career coaching working with students one on one. Networking is important. Sometimes jobs can be created for job-seekers; workplace and workforce have both changed – portability is important to the new workforce; school programs have shifted to accommodate new paradigms and students’ desire for autonomy and flexibility (their expectations and experiences are different than in the past).\nDr. Saltzberg mentioned giving students the “banana without the peel” – getting right down to what is needed for a professional career in the new energy economy. In various ways, all the schools are developing leaders for systemic change, yet their approaches were unique. This was perhaps best summed up by Dr. Mordaunt: “There is a success story for every student.”\nLinda Mansdorf serves as the Director of Volunteers for Leaders in Energy. In addition to an MBA from Pace University in NYC, she holds a certificate in Conservation & Environmental Sustainability from Columbia University and is an LEED Green Associate. An accomplished professional, Linda has prior experience as a business analyst in the pharmaceutical industry and in academia.","HVAC (also known as heating ventilation and air conditioning) and HVAC services are always in demand. The technology of vehicular or indoor environmental management is one of America’s leading industries. In the state of Virginia, a boom in home renovation, home building and the statewide necessity for climate control in one’s home or vehicle has created a growing HVAC industry. Many of Virginia’s major cities are above the national average for annual salary granted to HVAC technicians working on various levels. The state of Virginia is bustling with newly opened HVAC service companies and also allows many the opportunity to create their own HVAC business.\nIf you are good with mechanics or looking to become skilled in a new and lucrative trade, becoming an HVAC technician provides many long-term opportunities. Installing, repairing and maintaining cooling, heating, ventilation and refrigeration systems are a pivotal part of everyday life. The responsibility for the upkeep and repair of such crucial appliances and systems will always be in demand. HVAC is a growing field with many aspects allowing for a variety of training and development of specialties within the field.\nA career in heating, ventilation and air-conditioning will allow one to develop skills which will grant many different job opportunities in related technician fields. Entering the workforce with HVAC certification on a rookie or professional level will all but guarantee a certain amount of steady work. HVAC technicians can expect busy and productive schedules carrying out projects within offices, houses, warehouses, public buildings and other structures requiring climate control and assistance.\nBecause a bachelor’s degree is not required to branch into a career as an HVAC technician, the field is both desirable and profitable with comparatively little standard education required. Additionally, because of the growing cost of education and the time and difficulty of obtaining a four-year degree, HVAC becomes a highly appealing career path. HVAC technicians may expect plenty of opportunities for career advancement after several years working at entry level.\nCompanies who subcontract their services to others primarily hire HVAC technicians. A great many technicians maintain more than one job and work for larger companies with high demands for servicemen to fill maintenance needs. HVAC technicians are expected to use a variety of equipment and tools to complete installations and maintenance projects. They are also expected to observe areas for potential problems, and analyze complex systems and make sure all aspects of the project will run smoothly. Preventative maintenance is a huge part of an HVAC technician’s job responsibilities. Routine maintenance and observation are among the technician’s primary duties. Construction of new buildings often involves the input of HVACR technicians as building design must be evaluated in correlation with installation of wires, pipes, appliances and any other aspects of proper heating, cooling and ventilation. After construction, HVAC technicians trouble shoot any and all aspects of systems and ensure each system will run well. Residential homes as well as businesses are always in need of HVAC technicians and services. Technicians have different duties and responsibilities depending on the type of environments they are designated to troubleshoot and maintain. Work may vary greatly from day to day and project to project. However, primary job obligations are fairly set in stone. Main duties include:\n• Installing and maintaining a wide range of systems for ventilation, heating and air-conditioning systems\n• Carrying out general preventative maintenance on any and all HVAC systems\n• Assembling and constructing systems of wires and piping\n• Performing routine checks on vehicles including checking belts, handle lubrication and any other preventative care\n• Insure safety of HVAC systems-- checking the security of wire connection, including repair of any loose wires\n• Check thermostats and calibration along with any other controls\n• Replace any worn out parts of HVAC systems and check filtering\n• Servicing hot-water boilers and steam systems\n• Repairing motors\n• Unformed replace any worn out parts of HVAC systems and change filters\n• Check chemical compositions and equipment and ensure adequacy of levels\n• Handling conduit running for any equipment related to an HVAC system\n• Ordering equipment or supplies necessary for installation or maintenance of an HVAC system\n• Maintain a check list of needed items for each HVAC project and guarantee their availability\n• Responding to emergency calls to resolve problems immediately\n• Possess adequate knowledge of maintenance equipment and tools\n• Replacing expired or faulty elements of an HVAC system\n• Acting creatively to substitute parts or equipment in the event of unavailability\n• Assess a client’s need for and HVAC system upgrade and providing solutions or necessary measures to take\nHVAC technicians, depending on their special skill sets for training, may be asked to work with electrical, mechanical or plumbing elements as part of a complex heating and air-conditioning system. Technicians may be required to answer service calls at businesses or homes where systems are malfunctioning. Obviously, carrying out these tasks may require exposure to extreme cold or hot temperatures, cramped or high places and potential way, exposure to fumes, hazardous materials and electrical equipment. However, HVAC technicians will undergo safety training as part of their certification and licensing process.\nWork settings in the HVAC industry are usually divided into residential and commercial, meaning that HVAC professionals may work in people’s condos, apartments, homes, etc. or within the settings of commercial businesses or structures (including warehouses, factories and more). There is a comparative ease of entry into HVAC technician jobs working in residential areas. Residential work is less usually involved and requires a more minimal, entry-level skill set. Many opportunities for apprenticeships help HVAC technicians land a spot on the starting run of a corporate ladder as they move up the ranks in time. While the service side of the HVAC industry usually provides steadier work, the installation side of HVAC depends on the amount of new construction and renovation in a certain area. Virginia is a unique place due to a construction and renovation boom, thereby making the installation side of HVAC a profitable career path in the state.\nHVAC technicians are expected to service boilers, furnaces, air-conditioners, heat pumps and any other environmental modulation systems. Technicians may also work with hazardous gas, large cooling towers, install walk-in coolers, work with humidification units, air filter systems, ventilators and more. Given the rising need for individuals and businesses to developed eco-friendly systems and save money on heating and cooling, many HVAC technician installations all renovations include companies with solar energy systems, geothermal or wood burning systems. HVAC technicians must possess up-to-date knowledge on all types of systems necessary to know about in order to fulfill their job duties. While HVAC technicians may have certain specialties, a broad range of knowledge regarding HVAC systems is always warranted. The long-term goal of an HVAC technician is to become an experienced tradesman with copious amounts of experience and education in the realms of plumbing, framing and electrical work. Analyzing blueprints, schematics, mathematical figures and charts are considered highly beneficial skills while working in such a field. This may require a certain amount of higher education or on-the-job experience and training.\nExtensive knowledge of HVAC tools, building codes, regulations sanctioned by OSHA and proper use of safety equipment makes the difference between an HVAC entry-level employee and an HVAC professional. Tools used during HVAC system maintenance projects range from everyday items such as screwdrivers two less known or heard about tools.\nIn the state of Virginia, the Department of Professional and Occupational Regulation’s Board for Contractors must grant certification. For those looking to branch into the field of HVACR specialists, certification and accreditation must demonstrate a broad range of skills including installation, repair and HVAC unit maintenance for commercial and residential spaces. HVAC specialists are expected to analyze humidity levels, temperature control systems and air quality. Technicians are also expected to understand refrigeration and heating systems and a broad range of electrical systems and parts including thermostats, ducts or fans. Educational requirements for specific certification may vary as well depending on whether or not someone is attempting to be certified in the entry-level or obtain advanced certification through prior credentials or experience. Prior certification is most certainly helpful in the pursuit of an HVAC technician career. While initial certification may be relatively easy to obtain, more privileges are granted through advanced certification, which will inevitably broaden the possibilities for work.\nWhile not mandatory, national certification by the Environmental Protection Agency (EPA) is helpful for any HVAC specialists who work in refrigerant recovery and recycling. This is due to environmental regulations regarding atmospheric pollution, ozone depletion, working with hazardous materials all recovery cylinders for such materials and other EPA mandated protocol. Accreditation granted by the EPA will not expire and will always serve one well no matter what level of technician services one wishes to branch into.\nBroad certification requirements will vary from state to state. In the state of Virginia, one must possess a high school diploma. Successful completion of courses involving mathematics, shop, physics, mechanics or technical engineering are highly beneficial in the pursuit of a career as an HVAC technician or contractor. It is important to possess a skill set relevant to the fundamental elements of the profession.\nSecondly, one must complete an accredited HVAC program. HVAC certification programs range in length from six months to two years. Alternately, some HVAC jobs within the state of Virginia will require or prefer an apprenticeship of extensive duration in place of formal accreditation from a career or trade school. Trade schools, community colleges and additional programs providing certification sponsored by the state of Virginia will provide graduates with a degree in entry-level service, repair and design of HVAC systems and subsequent job opportunities related to entry-level practices. Curriculum is designed such that aspiring HVAC workers will be granted on the job training and tutoring from licensed HVAC specialists or contractors. To obtain a license, passage of exams necessary to the specific job requirements after a one to two-year training or on-the-job experience program are required.\nFor advanced certification in the HVAC industry, processes may include a wide array of training in credential services including the North American Technician Excellence (NATE) industry competency exam, which provides several HVAC are specialty certifications and including HVAC efficiency analyst certification, air distribution certification, HVAC performance verifier certification and other senior-level or managerial position titles. The Refrigeration Service Engineers Society (RSES) works in partnership with NATE to offer certification exams in heating, HVAC are electrical, commercial refrigeration and air-conditioning and EPA section 608 certification.\nWhile HVAC employment may be obtained with minimal certification, the more certification the better, especially when moving up the corporate ladder and gaining skills. The timeline for state or national level certification and licensing varies. The average time span of HVAC apprenticeship programs is 3 to 5 years, according to the Bureau of Labor Statistics. Students are expected to commit to roughly 2000 hours of training and roughly 144 hours of standard education. Apprenticeship programs are often conducted by or sponsored by Associated Builders and Contractors (ABC) or the Air Conditioning Contractors of America (ACCA). Virginia allows special access two HVAC technician associates degree programs providing graduates with NATE and industry competency exams (ICE) certifications.\nAccording to the US Bureau of Labor Statistics, the mean annual salary for HVAC technicians and specialists as of September 2015 ranged from 41,000 to 44,000. In the state of Virginia, jobs on entry and advanced level are always in high demand an easily available through large and small companies, indeed.com and other business networking portals. According to the US Department of Labor, HVAC technician jobs are projected to experience a 21% growth in the next 10 years. This means that the employment rate for HVAC related jobs such as heating and air conditioning, refrigeration, appliance installation and mechanical services are expected to grow in the years 2012 to 2022 by 21%. Many additional jobs are expected to open up in the state of Virginia due to a positive fluctuation in the number of new businesses and individuals needing HVAC services. A good HVAC technician has the ability to move up the corporate ladder to a managerial role or possibly a marketing and sales role. It is not out of the question to in time become a distribution manager within a few years.\nATI – Advanced Technology Institute\nThe HVAC training program at ATI is a total of 1100 clock hours and covers courses in electricity and circuits, pipe brazing, air conditioners, sheet metal fabrication and digital controls. ATI is a Yellow Ribbon School where the school can contribute up to 50% of the tuition expenses and the VA will match with the same amount. They are also a Military Friendly school and ASE NATEF Certified to Operate by SCHEV. The HVAC program is available at 5700 Southern Blvd Virginia Beach, VA 23462 and 1429 Miller Store Road Virginia Beach, VA 23455.\nYou could graduate from the Heating, Ventilation and Air Conditioning Diploma program at Tidewater Tech in 45 weeks. After graduating you’ll have the chance to sit and take the EPA certification and Industry Competency Examination. Tidewater Tech is located at 5301 East Princess Anne Road Norfolk, VA 23502. The college is accredited by the Council on Occupational Education (COE).\nTidewater Community College\nAt TCC you’ll get hands-on instruction on HVAC equipment in state-of-the-art labs. The program at TCC is one of only 3 colleges in Virginia that offers students the chance to earn their HVAC/R Associate’s Degree. Tidewater is located at 121 College Place Norfolk, VA 23510.\nNorthern Virginia Community College\nThe HVAC program at NOVA is 16 weeks in length. The school offers 3 different levels of HVAC program that fits your needs. The first level is a certificate based program, the second includes courses in English and math and the highest is their associate’s degree. Financial aid is available to those who qualify. The college is located at 6699 Springfield Center Drive Springfield, Virginia 22150.\nOne of the most important things in your career is finding the right HVAC company to work for. Like with any job, every company will run their operation differently. Below are just some of the main things we feel you should consider before taking a job.\n1. Travel: Cities in Virginia are big and with large cities means traffic. Make sure you are looking into companies where your region is an area you feel you can cover so you aren’t spending all of your time on the road in traffic.\n2. Truck/Tools: Does the HVAC company you are looking into provide you with a truck, gas and insurance? Do you give you a tool allowance? Often this is a benefit companies use to attract the best HVAC technicians to come work for them. If they don’t provide this it could mean a big expense to you.\n3. Signing Bonus: We have recently seen HVAC companies in Virginia give signing bonuses to new HVAC technicians. As competition grows companies often offer a signing bonus as well as additional benefits including vacation, sick days and retirement accounts.\nVirginia HVAC Resources\nExplore the Trades. “Why Become An HVAC Technician.” 2016. http://www.explorethetrades.org/hvac/why-become-an-hvac-technician/\nSalary.com. “HVAC Mechanic Salary.” 2016.\nTough Nickel. “What You Should Know About Starting an HVAC Career.” 21 Apr. 2016. https://toughnickel.com/industries/hvaccareer"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:df00c715-1e58-4cf7-8311-8c4119019071>","<urn:uuid:e4bd85b9-ef42-4ece-8015-2084587d810c>"],"error":null}
{"question":"How do the historical sales prices of the Wittelsbach Diamond and the Oppenheimer Blue diamond compare in terms of their auction records?","answer":"The Wittelsbach Diamond broke auction records in December 2008 when it sold for $23.4 million to London jeweler Laurence Graff. However, this record was later surpassed by the Oppenheimer Blue, which set a new mark in May when it sold for $57.54 million at Christie's auction.","context":["Famous Blue Diamonds\nProfiles of eight of the largest and most famous (and infamous) blue diamonds. Sorry to say you won't stumble across any of these in your local pawnshop or on eBay - these gemstones are all in museums or private collections!\n- The Hope Diamond\n- Probably the best know blue diamond (and one of the most famous diamonds in the world), the 45.52 carat Hope Diamond is a fancy deep grayish blue diamond, presumed to have been mined in India. The first documented owner of this breathtaking diamond was a French merchant named Jean Baptiste Tavernier. At the time, it is said to have been a 112 carat diamond with a crude, triangular cut. In 1668, Tavernier sold it to King Louis XIV of France, who had it recut by court jeweler Sieur Pitau into a 67.12 carat stone and set in gold. It was nicknamed The French Blue, and was worn by King Louis on a ribbon around his neck on special occasions. During the French Revolution, the stone (along with the rest of the Crown Jewels) was turned over to the French government and subsequently stolen during looting in 1792.\nIn 1812 the Hope surfaced again, this time in the hands of London diamond merchant Daniel Eliason, who is assumed to have sold it to King George IV. In 1839 it was documented in the collection of Henri Louis Hope, from whom the diamond gets it's name. It remained in the Hope family until 1901, after which it was sold several times.\nYou may be wondering about the rumored Curse of the Hope Diamond - the claims that misfortune and tragedy have befallen all of the Hope's owners. In reality, the \"curse\" was just a clever marketing ploy - a combination of half-truths and out-and-out fiction, dreamt up by Pierre Cartier - presumably to enhance the diamond's mystique (and subsequent sale price!)\nIn 1912, the Hope diamond was purchased by the eccentric diamond mining heiress Mrs. Evalyn Walsh McLean. The exquisite diamond got little respect during it's time in the McLean household, where it was stored in a plain shoebox and occasionally worn by one of Mrs. McLean's dogs!\nThe Hope Diamond was purchased from the McLean estate in 1949 by Harry Winston Inc. After a decade of exhibitions, Harry Winston donated the Hope Diamond to the Smithsonian Institute, where it remains to this day - once again getting the royal treatment as one of the most visited exhibits in the museum.\n- The Terschenko Diamond (the Mouawad Blue)\n- The Terschenko diamond is a 42.92 pear shaped fancy blue believed to be of Indian origin. Originally owned by the Terschenko family (sugar barons in pre-communist Russia) it was smuggled out of the country just prior to the Russian revolution and ended up in the hands of a private owner. It remained in obscurity until 1984 when it resurfaced for auction at Christies, where it was purchased by Saudi Arabian diamond dealer Robert Mouawad for $4.5 million.\n- The Wittelsbach Diamond\n- At 35.56 Wittelsbach diamond is the 3rd largest blue diamond, as notable for it's unique dark blue color as for it's impressive size. It broke diamond auction records in December, 2008 when it was sold by Christies to London jeweler Laurence Graff for a jaw-dropping 23.4 million dollars. Former owners of this diamond include King Philip IV of Spain, Leopold I of Austria, and his granddaughter Maria Amalia - who married into the royal Wittelsbach family of Bavaria, from which the diamond takes it's name. [ Photo of the Wittelsbach diamond ]\n- The Sultan of Morocco\n- At 35.27 carats, the grayish-blue Sultan of Morocco is the 4th largest blue diamond. Once owned by Cartier, this cushion cut gemstone is believed to have been last sold in 1972, possibly by jeweler Laykin et Cie, to a private American collector. It was last seen on public display in 1969 at the New York State Museum's World of Gems exhibition.\n- The Eugenie Blue (the Blue Heart)\n- The 30.82 carats Eugenie Blue, also known as the Blue Heart diamond, is a heart-shaped fancy vivid or fancy deep blue diamond. Legend has it the the Blue Heart was once owned by Empress Eugenie (Eugénie de Montijo) - wife of Napolean III - but there's no real evidence of this and many experts doubt it to be true. The Blue Heart's country of origin is not known, but the diamond was cut into it's present-day heart shape around 1909 or 1910 by Atanik Ekyanan of Paris. It was then purchased by Cartier, and sold to an Argentinian woman (Mrs. Ungue). It remained in her possession until the mid 20th century when it was sold to Van Cleef and Arpels who subsequently sold it for $300,000 to a European family. A few short years later it was again purchased, this time by jeweler Harry Winston. It's last private owner was Marjorie Merriweather Post, who donated it to the Smithsonian museum , where it remains to this day - on display as part of the museum's diamond collecton.\n- The Blue Lili Diamond\n- A 30.06 carat, tapered cushion-cut blue diamond of unknown color grade. Not much is known about the Blue Lili, but it is believed to be from the Premier diamond mines in South Africa. It was purchased and cut by the William Goldberg Diamond Corporation.\n- The Heart of Eternity Diamond\n- This heart shaped fancy vivid blue diamond weighs in at 27.64 carats and originates, as do many other exquisite blue colored diamonds, from the Premier mines in South Africa. The Heart of Eternity is owned by a private collector and, as of this writing, is on loan to the Smithsonian National Museum of Natural History.\n- The Blue Magic Diamond\n- According to it's GIA (Gemological Institute of America) certificate, the Blue Magic is a 12.02 carat modified pear-shaped diamond of an exquisite fancy vivid (the highest color grade) blue color with a clarity of VVS-2.\nIn general, fancy blue diamonds continue to attract a lot of attention. Here are some notable, recent auction sales:\n- May 2009 - an internally flawless, 7.03 carat cushion-cut, fancy vivid blue diamond sold for $9.48 million dollars - a record-setting high price-per-carat ever at Sotheby's Geneva auction.\n- The Millennium Blue - a 5.16 carat pear-shape, internally flawless, fancy vivid blue, sold for $6.4 million dollars at Sotheby's Hong Kong auction in April, 2010.\n- In October 2010, the largest known triangular fancy vivid blue diamond ever auctioned (10.95 carats), aka the Bulgari Blue, set yet another auction record of $15.7 million dollars, making it top gemstone sale of 2010.\nPrevious: Blue Diamonds - FAQ\nResources: Learn more about these and other famous diamonds","Historic gems to star at Geneva jewel auctions\nRussian diamonds that reputedly helped broker peace between warring empires three centuries ago will go to the highest bidder at the Geneva jewel auctions this week. The Swiss city’s twice-annual sales of rare jewels are often dominated by stones the size of door-stoppers. But this week, gems enriched by the weight of history will share centre-stage with those valued by their weight in carats. Christie’s began the auction season yesterday at the luxury Four Seasons Hotel des Bergues on Lake Geneva, where a line of Bentleys or Porsches typically builds in the runup to the autumn sale.\nRival Sotheby’s takes its turn today across the road at the five-star Hotel Beau Rivage. Among Sotheby’s showcase offers is a parure featuring diamonds once owned by Russian empress Catherine I that were given to her by her husband, Czar Peter the Great, who led Russia until his death in 1725. In 1711, Catherine was worried that a raging conflict with the Ottoman Empire posed an existential threat to Russia and ordered her husband-in the middle of the night-to draft a peace treaty, Sotheby’s said, citing historical records.\nWithout telling Peter, Catherine sent the peace proposal and all the jewels she was travelling with to the Ottoman Sultan Ahmed III. The Sultan “accepted these and was obviously delighted, and the truce was given and the (Russian) empire was saved”, David Bennett, head of Sotheby’s International Jewelry Division, told AFP. The parure featuring Catherine’s diamonds is expected to sell for between $3 million (2.8 million euros) and $5 million. In an auction heavy on Russian imperial treasures, Sotheby’s is also offering a diamond necklace with a detachable clasp owned by Empress Catherine II-Catherine the Great, who ruled Russia from 1762 to 1796. It is similarly valued at up to $5 million.\n$30 million bling?\nTuesday’s top seller will almost certainly be a set of earings made of two flawless white diamonds weighing 52.55 carats and 50.47 carats, valued by Christie’s at $20 million-$30 million for the pair. Tobias Kormind, head of the 77 Diamonds firm that tracks the global diamond market, said elite collectors of rare gems are typically more attracted to loose stones and may shy away from the earings. “These earrings are far more likely to be a gift for someone to wear for special occasions,” he said, noting that the list of people interested in socialising with more than 100 carats worth of diamonds on their ears is limited.\n“The buyer is highly likely to be a newly minted Russian or Chinese billionaire oligarch or business tycoon, who does not shy from flaunting their wealth,” Kormind said. While interest in the white diamond earnings may prove strong, they are unlikely to approach the eye-popping records set by coloured stones at recent sales. Christie’s set the current mark in May, selling the 14.62-carat “Oppenheimer Blue” for $57.54 million.\nThat beat a record set a year ago by Sotheby’s, when Hong Kong billionaire Joseph Lau’s bought the 12.03carat “Blue Moon of Josephine” for $48.4 million. Christie’s is aiming to capitalize on the still-solid coloured stones market with a 9.14-carat Fancy Vivid Pink estimated at $16-$18 million. The rare “Fancy Vivid” classification is awarded by the Gemological Institute of America to signify a stone’s exceptional color and clarity. Sotheby’s top coloured gem going under the hammer this week is the 8.01-carat “Sky Blue Diamond”, with a pre-auction estimated price of $15$25 million. Sotheby’s has estimated its 342-lot auction at a total of $100 million. Christie’s is offering 220 lots, with an estimated value of $80 million.\nFile photo shows a model presents the ‘The Sky Blue Diamond,’ a fancy, vivid blue diamond ring created by Cartier, during a press preview by Sotheby’s Auction House.\nFile photo shows a model poses with a diamond necklace with a stunning and delicate bowknot clasp during a press preview by Sotheby’s auction house on November 9, 2016 in Geneva.—\nFile photo shows a model poses with a parure of antique coloured diamond jewels during a press preview by Sotheby’s auction house in Geneva."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e5da9d4a-98b3-4ded-8010-6f791f376844>","<urn:uuid:48e61797-d050-469e-bcfd-33326f8af4c3>"],"error":null}
{"question":"How is BMW implementing quality management principles to maintain its competitive advantage in the automotive industry?","answer":"BMW maintains its competitive advantage through quality management by establishing that quality in all aspects of business is the foundation for their success. The company builds high performance products as a result of being a high performance organization. They make large investments in research & development of new technologies, with R&D playing an integral role in sustaining their competitive advantage - a fact recognized by senior management.","context":["Complying with legal, other and bmw group requirements to which bmw mc subscribes bmw manufacturing quality policy: quality in all aspects of our business is the foundation for our success. Bmw build high performance products because bmw is a high performance organization large investment on research & development of new technologies focus on the environmental issues and ways to create more environmental friendly solutions in transport sector. Research and development (r&d) plays an integral role in sustainability of bmw competitive advantage and this fact is duly recognized by the senior management.\nBmw business strategy can be characterized as product differentiation with a particular focus on design and digitization electromobility represents the latest direction for bmw group product differentiation and the company introduced its fully electric bmw i3 in 2013 this has been followed by plug . Business management is a foundation course for most of the imm gsm qualifications the topics covered in this course will introduce you to the broad areas of business and allow you to understand the various business functions in a general organisational. German carmaker bmw on thursday announced that norbert reithofer is to become the company's new chief executive officer the move is part of a major shakeup of the bmw's management a new boss .\nFind the bmw management, llc business page in temecula, ca explore the ca credibility review business directory at dandbcom. Bmw management, which also operates under the name sizzler, is located in bakersfield, california this organization primarily operates in the steak restaurant business / industry within the eating and drinking places sector bmw management employs approximately 38 people at this branch location . Bmw management, inc owns and operates sizzler restaurants in california the company is based in temecula, california . [email protected] +971-45668587 copyrights © 2018 all rights reserved.\nBusiness segments locations member of the board of management of bmw ag responsible for sales and brand bmw “customer demand for our x vehicles continues to be . Bmw manufacturing announced four new senior management appointments this week that herald a new management function to oversee project integration, the company said in a release the new approach will serve the needs of the spartanburg plant’s future growth, the company said karl loessl has been . One of the classiest luxury cars in the terms of quality and design, the swot analysis of bmw discusses the swot matrix for brand bmw bmw have diversified product portfolio from suv’s to luxury sedans to sports cars.\nImproving it management at the bmw group by integrating existing it management processes cover the business applications and how they work. Bmw is using a service management system as part of a bigger plan to improve supply chain lifecycles inventory, material requirements planning, and jit decisions . Bmw ag's new initiative to expand fleet management business capital budgeting for bmw slp fin301 assignment overview every company has capital projects the. Bmw - organizational structure bayerische motoren werke ag (bmw), is an independent german company and manufacturer of automobiles and motorcycles bmw is the parent company of the mini and rolls-royce car brands.\nBmw group corporate sales program and now as a bmw performance center partner, you can take advantage of one of our biggest offers ever use your customer id when . Bayerische motoren werke, popularly known as bmw, is a german based automobile manufacturing company it was founded by franz josef popp in 1916. Working for bmw students in the supply chain management concentration at au will receive a bachelor of science in business with a concentration in supply chain management like other business majors at au, they are required to work an internship before they can graduate. Looking for the best bmw swot analysis on the web you can find more information about the business in bmw his interest and studies in strategic management .\nSpartanburg county-based bmw manufacturing co on tuesday announced five senior management changes, including sherry mccraw was been name vice president of assembly at the plant near greer. Bmw leadership and bmw organizational structure posted on april 23, 2016 by john dudovskiy bmw leadership structure and bmw organizational structure is highly complex reflecting the massive size of the business and the global scale of its operations.\nBmw case study category education marketing management concept and philosophies class xii business studies by ruby singh bmw quality management bmw 3 series - duration: 3:02 bmw . A hierarchy of bmw corporatebmw automobile company have a tall organizational structure that looks like a pyramid, with several management layers that reflect categories business hierarchy. In this role you will be required to improve dealer network performance – financial as well as operational kpis (processes, internal controls, kpis."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:8fa4364a-2e1f-4bfb-8af0-5f87b4167fda>"],"error":null}
{"question":"What are the core aspects of Christian social conscience, and how does it relate to children's TV viewing habits in modern society?","answer":"Christian social conscience involves the ability to judge what is morally good in specific circumstances, particularly regarding social responsibilities and concerns. It is grounded in biblical teachings and involves a sense of responsibility for society's problems and injustices. Meanwhile, regarding children's TV viewing, research shows concerning patterns - children under two should not watch television at all according to pediatric recommendations, and older children should have limited viewing time since excessive TV watching has been linked to negative effects including obesity and behavioral changes. This creates a moral imperative to address screen time as part of modern Christian social responsibility.","context":["1 edition of Christian social conscience found in the catalog.\nChristian social conscience\n|Statement||by a group of laymen.|\n|Series||Saint Severin series for adult Christians,, v. 4|\n|LC Classifications||BT738 .M613|\n|The Physical Object|\n|Number of Pages||112|\n|LC Control Number||66003247|\nPope Benedict XVI on Conscience In this essay Fr. Vincent Twomey, SVD, a former student of Joseph Ratzinger, examines the central role conscience has played in the life and writings of Pope. book dropped like a bomb into the peaceful summer Bible conference atmosphere of the postwar evan-gelical community.” Sherwood Eliot Wirt, The Social Conscience of the Evangelical (New York: Harper & Row, ) 3This was not only in the social and political arenas. Henry sought to .\nThe position the Scriptures uphold is one of biblical submission, with a Christian being allowed to act in civil disobedience to the government if it commands evil, such that it requires a Christian to act in a manner that is contrary to the clear teachings and requirements of God’s Word. A person’s conscience is a defense against situations that are spiritually harmful. Righteous decisions and obedience to the commandments bring peace of conscience. When we sin, we feel remorse or guilt, just as we feel physical pain when we are wounded. This is the natural response of our conscience to sin, and it can lead us to repent.\nPoverty and Social Conscience with the work regarded as being hugely important for its use of photography as social documentation. The book is going under the hammer on Thursday at Gloucestershire auctioneers Dominic Winter and is expected to sell for between £4, and £6, informed by a deep sense of Christian purpose, their. Christian social thought from the Roman Catholic perspective, with special reference to recent encyclicals such as Mater et Magistra, Pacem in Terris, and Populorum Progressio. Holding that Christian social conscience is \"the ability to judge in specific circumstances what is morally good and.\nFederal vehicle standards\nElectricity regulation in the Netherlands\nMexican Americans (Ethnic Groups in American Life)\nGeologic atlas of the United States. State of Wyoming.\nmaking of United States foreign policy.\nCatalogue of documents from Borsippa or related to Borsippa in the British Museum\nThe annual register of the University of Cambridge for the year.\nTowards a new strategy for development\nTime for sale.\nGeschichte, Geographie und Kultur der Schweiz.\nJournal of the fourteenth House of Representatives of the Commonwealth of Pennsylvania, commenced at Lancaster ... the sixth day of December ... one thousand eight hundred and three ...\nLuck and a prayer\nCOVID Resources. Reliable information about the coronavirus (COVID) is available from the World Health Organization (current situation, international travel).Numerous and frequently-updated resource results are available from this ’s WebJunction has pulled together information and resources to assist library staff as they consider how to handle coronavirus.\nThe Christian social conscience. [Rodger Charles] Home. WorldCat Home About WorldCat Help. Search. Search for Library Items Search for Lists Search for Contacts Search for a Library. Create # Clergy Book Service\\/span> \\u00A0\\u00A0\\u00A0 schema.\nAt the same time, the book is full of practical wisdom. The biblical teaching on conscience is applied to numerous situations so that readers see how the Scriptures apply to everyday life. The reflections on how conscience should operate in missionary situations is alone worth the price of the book, but the entire book.\nTitle: A Sacred Voice Is Calling: Personal Vocation and Social Conscience By: John Neafsey Format: Paperback Number of Pages: Vendor: Orbis Books Publication Date: Dimensions: X X (inches) Weight: 9 ounces ISBN: ISBN Stock No: WWPages: Conscience (Stanford Encyclopedia of Philosophy).\nBooks shelved as social-conscience: The Hate U Give by Angie Thomas, The Underground Railroad by Colson Whitehead, Fahrenheit by Ray Bradbury, To Kil. The Christian Social Conscience: Volume IV Paperback – by Fides (Author) See all formats Christian social conscience book editions Hide other formats and editions.\nPrice New from Used from Paperback \"Please retry\" — — $ Author: Fides. Reading this book may make you wince, but the pain of self-examination is worth it.\"-David Neff, editor and vice president, Christianity Today \"The Scandal of the Evangelical Conscience summons us to take the gospel by: A social conscience is \"a sense of responsibility or concern for the problems and injustices of society\".\nWhile our conscience is related to our moral conduct in our day-to-day lives with respect to individuals, social conscience is concerned with the broader institutions of society and the gap that we may perceive between the sort of society that should exist and the real society that does.\nCatholic Social Conscience will be of particular interest to all Christians who have believed that the Catholic Social Teaching tradition, up to now, had something to offer the Christian community as a whole by way of resources to navigate the call to civic and social : A Christian social networks for Christians to network and socialize with like minded people.\nThis is the verse profile page for bible book. Unto the pure all things are pure: but unto them that are defiled and unbelieving is nothing pure; but even their mind and conscience is defiled.\nA Christian social networks for Christians to network and socialize with like minded people. This is the verse profile page for bible book. For our rejoicing is this, the testimony of our conscience, that in simplicity and godly sincerity, not with fleshly wisdom, but by the grace of God, we have had our conversation in the world, and more abundantly to you-ward.\nRyan's primary interests are in the areas of bioethics and health policy, feminist ethics, and fundamental moral theology. She co-edited a book on global stewardship with Todd David Whitmore and recently completed a book on reproductive technologies to be published by Georgetown Press.\nReview of the Uneasy Conscience of Modern Fundamentalism by Carl F. Henry Henry's book, written sixty years ago, is a clarion call for Christian social action that is grounded in biblical revelation.\nHis thesis is that the Fundamentalist conscience is uneasy because it has not applied biblical truths (11).Cited by: Conscience is a term that describes an aspect of a human being's self-awareness. It is part of a person's internal rational capacity and is not, as popular lore sometimes suggests, an audience room for the voice of God or of the devil.\nConscience is a critical inner awareness that bears witness to the norms and values we recognize and apply. Like the leaders of the Social Gospel movement before them, these writers were concerned with the gap between the biblical vision of God's rule and the realities of modern industrial society.\nFor the new generation, however, a Christian conscience informed by scientific study would not Author: Robin W. Lovin. Acts of Conscience: Christian Nonviolence and Modern American Democracy is the best new work on the history of American pacifism to appear in many years.\nJoseph Kip Kosek offers a bold, original, and lucid brief for the importance of the tradition of Christian nonviolence in twentieth-century U.S. reform, and in the process resurrects such forgotten figures as Richard Gregg, a pioneering. I am in the final stages (I hope!) of publishing a book entitled The Wisdom Way of Teaching: Educating for Social Conscience and Inner Awakening in the High School Classroom.\nThis will be the eighth book in a series by Information Age Publishing. Biblical Christianity: The Origin of the Rights of Conscience The book is a direct transfer of human allegiance in things spiritual from the civil and ecclesiastical powers to the judgment and conscience of the individual.\nwith government routinely requiring people of faith to violate their religious conscience, particularly on social. Chapter The Christian Conscience and the State. for there we find, particularly in the messages of the prophets, a more explicit reckoning with social problems than is reflected in the New Testament.\nIsrael, unlike the early Christian community, was a political State, and during much of its history its leaders had civil as well as. A Jesus of social conscience was a new idea for the early church - advanced by no gospel writer than Luke.\nThis then serves both as Luke's contribution to Christendom and his heresy. Over two millennia, the benefit of Luke's heresy has been the recognition that the good news of Christianity is not only for the next world, but for the here and now.Read this book on Questia.\nRead the full-text online edition of The Social Conscience of the Early Victorians (). the dominant theme defining the social conscience of the early Victorians was a paternalism that looked largely to property, the Church, and local authorities to govern society.\nThe social conscience of Britain, like its. Originally published inThe Uneasy Conscience of Modern Fundamentalism has since served as the manifesto of evangelical Christians serious about bringing the fundamentals of the Christian faith to bear in contemporary culture.\nIn this classic book Carl F. H. Henry, the father of modern fundamentalism, pioneered a path for active Christian engagement with the world -- a path as relevant 5/5(1).","Learn how to make screen time a valuable learning experience for your child by watching together and interacting with the content of electronic media. Watch video kids are generating billions of video views on the online video service, but it’s raising some talking points for parents. Children under two should not watch television at all, according to recommendations from the american academy of pediatrics, and older children should have. Television viewing is a major activity and influence on children and adolescents children in the united states watch an average of three to four hours of television a. Learn the good and bad effects of watching tv on your child's intellectual development.\nPercentage of parents who would like to limit their children's tv watching: 73 percentage of 4-6 year-olds who, when asked to. How can the answer be improved. Children often behave differently after they've been watching violent programs on tv in one study done at pennsylvania state university, about 100 preschool children were observed both before and after watching television some watched cartoons that had a lot of aggressive and violent acts in them, and others watched shows that didn't have. Few people realize the damaging effects that tv has on us find out 11 reasons why you should stop watching television now and how it'll improve your life. Study makes surprising link between tv time kindergarten children who watched television for more than one to link time spent watching tv. Is television bad for children 52% say yes 48% say why would people spend so much time watching television children can't even focus on school work.\nIt’s official: to protect baby’s brain, turn off tv a decade ago, the american academy of pediatrics suggested that parents limit tv consumption by children under two years of age. You're probably pretty careful not to let your kids watch very violent or frightening shows on tv but a recent study found that children actually find the news far more terrifying than anything they'd see on a blood-and-guts drama like csi.\nIs tv really so bad for kids experts say it depends on what they're watching, and how much and the key to keeping them safe and sound is monitoring their viewing, as well as your own. Research conducted at harvard first linked tv watching to obesity more than 25 years ago (5) since then, extensive research has confirmed the link between tv viewing and obesity in children and adults, in countries around the world and there’s good evidence that cutting back on tv time can help. Is watching tv really bad for kids get expert advice and tips from common sense media editors.\nTelevision plays a central role in children's everyday lives almost all american families have at least one tv set, and half own three or more 1 two-thirds of children age six and under watch television every day, usually for around two hours 2 but television’s influence doesn’t end when a child’s favorite show is over.\nThis is a reading comprehension worksheet for intermediate students who are asked to read text, match each word / phrase with its equivalent in the context of the text, fill in the table with the good and bad sides of watching tv and give complete answers to the questions the answer key is included. Television has changed the american child from an irresistible force to an immovable object, educator laurence j peter once said in the haunting images of australian-born photographer donna stevens, these words come to life, as children morph into undead creatures before our eyes, captivated by. Many kids spend their time watching television before they enter school according to the american academy of pediatrics (aap), children aged above two years should watch not more than one to two hours daily. In 1970, children began watching tv regularly at about 4 years of age, whereas today, children begin interacting with digital media as young as 4 months of age.\nToday's children and teens who watch more than 5 hours of tv per day are 5 times more likely to be overweight than teens who watch 0 to 2 hours watching tv for. Parents are often shocked when i tell them that pediatricians think it's a bad idea for children to watch tv or use mobile apps before age 18 months, because most toddlers already have surveys tell us that 922% of 1-year-olds have already used a mobile device, some starting as young as age 4. Lulu chua-rubenfeld says her mother, the tiger mother, banned tv and netflix until lulu went to college but experts say watching tv isn't so bad for kids. Why simple co-viewing with children can sometimes backfire. Drawing from the research, they suggest that children under age 2 not watch any tv and that kids over age 2 be limited to an hour or at most two, daily, of. Watch free kids cartoons and tv shows boomerang have loads of cool tv shows you can watch online today for free including looney tunes and wacky races. Kidshealth / for parents / how media use affects your child what's 4 hours per day watching tv are more the tv or at least limit kids' watching."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:bfdd5d16-a7fb-414f-8644-bbba60182b88>","<urn:uuid:39f62df6-aad7-4a0b-adda-e25c32db67c3>"],"error":null}
{"question":"What are the respective eligibility requirements and benefits for Indian NGOs to fundraise through Leadership Initiatives' donor captain system versus Impact Guru's GlobalGiving partnership?","answer":"Leadership Initiatives' donor captain system requires individuals willing to take leadership roles in fundraising, with captains responsible for recruiting at least 10 donors each. They provide support through tools like PayPal card readers, Bank of America Debit Cards, and reporting forms. In contrast, Impact Guru's partnership with GlobalGiving requires Indian NGOs to have registration under Section 12A and valid FCRA registration. Additionally, organizations must either have Gold/Platinum certification from Guidestar India or complete GlobalGiving's due diligence process. The benefits through Impact Guru include US, UK, and Indian tax benefits for donors, access to matching and bonus days, online training academies, and a donor management system.","context":["In GlobalGiving’s fourth session of the Online Fundraising Academy, we invited Marshall Bailly, the Executive Director and Founder of Leadership Initiatives, to share tips for cultivating a strong donor network. In 2014, Marshall and his team raised more than $260,000 through GlobalGiving. He has built relationships with a core group of donors that regularly support Leadership Initiatives via various promotions. He has developed a comprehensive strategy for campaign outreach and communications, including local donor mobilization in Nigeria, where Leadership Initiatives operates.\nSession Recording: http://www.meetingburner.com/b/globalgiving/view_recording?c=ENDZ7V&h=f\nLeadership Initiatives (LI)\n- Partners with local government and business leaders in Nigeria to provide promising individuals with entrepreneurial, leadership and project management training.\n- Founded in 2004, LI started small and then over time slowly built up its donor network. Their strategy was to first approach the people they knew and then build their network out from there. To create a strong donor network, you first must create strong “buy-in” opportunities for donors.\nDonor Committee: You can’t do it alone!\n- Because fundraising has to meet both short term and long term goals it is important to create a group of supporters to help develop goals and support the organization’s growth.\n- The donor committee consists 7-8 individuals who help raise money and set a fundraising agenda. Initially the committee included mainly long-time friends of the organization, however, it has since branched out to include board members, dedicated donors, and corporate partners.\n- Create a one-month, six-month, one year and five year plan for where you want your fundraising goals to be. Additionally, make sure the plan has reachable goals to motivate your committee.\n- Donor captains allow you to share the fundraising burden by finding new donors.\n- By bringing new people into the organization, donor captains take on a leadership role and become part of the team.\n- In 2013, LI had 10 donor captains who were each in charge of getting at least 10 people to donate, and in 2014, LI had over 20 donor captains for five separate matching events.\n- Donor captains create an atmosphere of friendly competition to encourage one another to raise the maximum amount of funds available.\nLI’s five donor network leader types:\n- Social Leaders – Individuals who know a lot of people. Ultimate goal is to create a generation of donors who stay connected and fundraise with LI over many of years.\n- Specialty Type Donors – Individuals with jobs that can help you get special services and connections to improve your organization.\n- High End Donors – Individuals who typically donate $1000 or more. Through constant contact you can help them become stronger donors. Build up trust, allow them to provide their input, and help them find pride in the work they’re supporting.\n- Corporate Sponsors – Organizations that donate $1000 or more. Find corporations who have a vested interest in the work or community your organization is involved in, and who is interested in partnering with you.\n- Make sure your corporate sponsors know how much you value them and how much their contributions mean to your organization!\n- Business Alliance Program Students – Partnered with high school students who raise money to help each Nigerian business partner receive skills training and additionally work to solve a few of the developmental problems. In exchange, each student receives help with SAT training, scholarship and college entrance essay assistance, and letters of recommendation. LI then continues this partnership with students as they enter college and later the business world.\nTips to note:\n- For every donor LI gets, they also have at least 20 who say no.\n- Don’t keep chasing “white whales” – at some point, you cannot continue to chase people who are uninterested in your story. Instead, chase those who care and really want to know more about your organization. Follow up and work with people who care, as they are the individuals who will transform your organization.\n- It is a learning curve – you won’t always succeed on the first try, and that is okay! Keep trying, keep learning, and remember that you will make it.\nIt’s a challenging environment!\n- Each organization is fighting for their share of local donors. You must find out what really matters to your donors.\n- Success stories must connect emotionally, and the call to action must be distinct for your individual donor captains and your individual donors.\n- Put a face to the problem – donors can talk/skype to people on the ground\n- LI created a comparison chart showcasing how LI is different from other organizations and why donors should give to LI rather than to other similar organizations.\nDevelop a path forward\n- Separate your organization out of the mix by communicating a focused, distinct mission.\n- Differentiate your organization through outcomes, emotional storytelling, progressive posture and unique business models.\n- Elevate your organization as a leader in your field. Continue to lift your reputation by better leveraging endorsements from GlobalGiving and other partners.\n- Prioritize your audiences; make sure they know how much you appreciate all they do, and that your organization is where it is because of them.\nMake your supporters lives easier:\n- LI has found better ways for donor captains to fundraise and get donations from donors: Paypal card readers, Bank of America Debit Cards, reporting forms where captains can report funding expenses and funds raised\n- Provide online materials for donors for each fundraising event\n- Easy access to matching day project pages. For instance, it’s easier to say LImatch.org rather than http://www.globalgiving.org/donate/4393/leadership-initiatives/. Both pages go to the same place, but the first link makes it easier for donors to remember where to go.\n- Created a graphic explaining GlobalGiving’s donation benefits, making it easier for donor groups and captains to show potential donors why GlobalGiving is beneficial.\nQuestion & Answer\nQ: Are newsletters a good way to recognize donors?\nA: First we make sure our donors want to be mentioned. Some donors do want to be mentioned, while others prefer to remain anonymous. If donors don’t mind, it’s a great way to recognize their contributions.\nQ: How do you mobilize international donor captains?\nA: We will start by finding a captain who has either a credit card or Paypal. We then will normally have everyone on the ground in Nigeria pool their funds, and then the captain will donate all of those funds on the card or through Paypal. We find people who have been assisted by our organization and really want to give back. That individual will most likely want to continue the cycle of transformation in their community and can reach out to friends and family in their network, creating a culture of giving back.\nQ: How do you recruit people to be a part of the fundraising/donor committee?\nA: Each year we’ll send out emails to top donors, letting them know that because of their commitment to the organization we want to challenge them to not only give more, but to also invest more in the organization by joining the donor committee. I then will set up calls or meetings with individuals, explaining the duties of the committee and the different sub-committees.","Impact Guru and GlobalGiving's strategic partnership enables US, UK and Indian tax benefits for Indian NGOs\nUS, UK, and Indian tax benefits now available for international and domestic donors giving to Indian NGOs on a single platform!\nWhat is this partnership?\nImpact Guru and GlobalGiving have entered into a strategic partnership to enable Indian, US, and UK donors to give to Indian causes they care about, through a single platform. Eligible NGOs and social enterprises raising money on ImpactGuru.com can now not just direct their Indian networks but also international donor networks, particularly NRIs (Non Resident Indians) / PIOs (People of Indian Origin), to give through GlobalGiving’s technology on ImpactGuru.com and offer US or UK tax benefits to international donors.\nWhy is it important?\nIndia is home to the highest number of NGOs in the world with more than 33 lakh (3.3 million) nonprofits registered in the country. While only 13,000 NGOs in India are allowed to raise funds from foreign donors in compliance with current regulations, Indian nonprofits have historically raised more than Rs 8,500 crores (US$1.3bn) annually from international donors. It is estimated that a significant portion of international donation is led by Indian diaspora, which is the largest diaspora population in the world. According to Ministry of External Affairs, Govt. of India, there are more than 3 crore (30 million) NRIs / PIOs living outside India with more than 60 lakh (6 million) residing in the US and UK.\nIncentives for your local and International Donor Networks: Tax incentives are often considered to be a crucial factor in encouraging philanthropy. By offering tax benefits to US and UK donors for cross-border giving into India, this partnership will help Indian NGOs and social enterprises attract more philanthropic capital to scale their existing programs.\nImpact Guru’s and GlobalGiving’s Training + Support: By being a part of this partnership, organizations will also have access to full range of benefits like special matching and bonus days, online training academies, and GlobalGiving’s donor and donation management system.\nAccess to Impact Guru’s one-on-one account management: Once an organization’s fundraiser is posted on Impact Guru, our relationship manager will walk organizations through the entire process of posting a fundraiser, reaching out to donors, and running a fundraising fundraiser.\nThis partnership is particularly transformational for the social sector because more than 50% of funds raised online by nonprofits on Impact Guru are sourced from international donors. According to a research report by The Bridgespan Group, if the charitable contributions of Indian diaspora in US were consistent with those of other American households in similar income brackets, and they directed 40% of their philanthropy to India, $1.2 billion additional funds could flow from such donors towards Indian social causes per year.\nWhat types of organizations can benefit from this partnership?\n- Nonprofits based in India with registration under Foreign Contribution Regulation Act, 2010 can scale their programs with the support of international donors by enabling them to receive US and UK tax benefits.\n- Social enterprises based in India are also eligible to either fundraise online or route their grants via Impact Guru and offer US tax benefits to their international donors on a case by case basis.\n- NGOs and social enterprises across Southeast Asia (including Singapore, Hong Kong, Malaysia, Thailand, Philippines, Indonesia) can also fundraise on ImpactGuru.com and avail of these tax benefits on a case by case basis.\nTo learn more and initiate next steps, please complete the form on this page or contact the Impact Guru nonprofit customer support team at firstname.lastname@example.org.\nAll nonprofits and social enterprises will have to go through a thorough due diligence process before being eligible to benefit from this partnership to ensure a safe and secure online giving environment. A dedicated customer relationship manager will support you through every step of the fundraising journey; from fundraiser creation to your outreach activities. You will gain access to a variety of tools and training materials to widen your reach.\nIndian NGOs through this partnership can now provide the same tax benefits provided by the US NGOs under section 501(c)(3), to their donors.\nWhat were the key results of the pilot between Impact Guru and GlobalGiving in 2016?\nImpact Guru and GlobalGiving had previously jointly conducted a 7 day fundraising fundraiser during Daan Utsav, a giving festival across India, where 17 existing GlobalGiving nonprofit partner organizations raised Rs 12 lakhs / US$18,000. The success of that fundraiser as one of the highest performing fundraisers for GlobalGiving’s Indian NGO partners is testament to a promising partnership that will change the face of nonprofit fundraising in India.\n- 85 percent of the donors who gave had never given through GlobalGiving.org. That meant that these organizations were able to tap into another network of donors to succeed in this fundraiser due to the added availability of offering Indian 80G tax benefits.\n- The median donation amount was the same as on GlobalGiving—about Rs 2,000 / US$28.\nWhat are the due diligence guidelines?\nEligibility to offer US and UK tax benefits to international donors\n- All Indian NGOs participating in this program must have registration under Section 12A and valid FCRA registration\n- Indian social enterprises will be considered on a case by case basis if Impact Guru and GlobalGiving can establish that funds will be used for charitable purposes.\n- Southeast Asian nonprofit organizations and social enterprises may be considered on a case by case basis if Impact Guru and GlobalGiving can establish that funds will be used for charitable purposes.\nProcess for Indian nonprofits\n- Existing GlobalGiving NGO partners: Organizations that are already a part of the GlobalGiving community are automatically eligible to have this donation processing system turned on for fundraisers on Impact Guru. These partners will simply need to register with Impact Guru and start a fundraiser.\n- Existing Impact Guru NGO partners: Indian NGOs who are registered on Impact Guru and have previously raised funds must be registered under FCRA and either obtain Gold or Platinum certification from Guidestar India or complete the due diligence application process on GlobalGiving’s website here.\n- NGOs vetted by social sector intermediaries: NGOs currently registered and vetted by GiveIndia, Charities Aid Foundation India, Guidestar India (Platinum / Gold levels only), Dasra, Credibility Alliance and have FCRA registration are automatically eligible for the benefits under this partnership on ImpactGuru.com.\n- Other NGOs: NGOs that are not registered on GlobalGiving or Impact Guru and have FCRA registration must go through a due diligence process to be eligible for the program. They must either obtain Gold or Platinum certification from Guidestar India or complete the due diligence application process on GlobalGiving’s website here.\nTo learn more and initiate next steps, please complete the form on this page or contact the Impact Guru nonprofit customer support team at email@example.com with the subject “Indian nonprofit onboarding”.\nProcess for Indian social enterprises\n- Social enterprises registered in India who wish to participate in the program will be considered on a case by case basis upon due diligence by Impact Guru and GlobalGiving, if it can be established that funds will be used for charitable purposes.\nTo learn more and initiate next steps, please complete the form on this page or contact us at firstname.lastname@example.org with subject “Indian social enterprise onboarding”.\nProcess for Southeast Asian nonprofits or social enterprises\n- Southeast Asian nonprofit organizations and social enterprises who wish to participate in the program may contact us, and will be considered on a case by case basis upon due diligence by Impact Guru and GlobalGiving, if it can be established that funds will be used for charitable purposes.\nTo learn more and initiate next steps, please complete the form on this page or contact us at email@example.com with subject “Southeast Asia onboarding”.\nStart Raising Funds"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:0786e75a-411e-4fd0-b639-2f10460430ec>","<urn:uuid:4086e9d8-c9ee-4c9f-86e3-76e9133644ea>"],"error":null}
{"question":"Can you explain the relationship between data signatures in recovery processes, and what are the limitations of data recovery services in extreme cases of data loss?","answer":"In data recovery, files can be recovered using signature identification where drives are scanned for known file patterns - for example, JPEG files contain 'JPEG' sequences, ZIP files begin with 'PK', and PDF documents start with 'PDF'. Some files like text and HTML can be identified through circumstantial evidence of ASCII characters. However, there are limitations to recovery services, particularly in extreme cases. While data recovery technology has become very advanced, systems that are too corrupted or damaged may prevent successful data retrieval. Recovery success ultimately depends on the extent of damage, with money and time being the primary obstacles - the more resources available, the better the chances of recovery.","context":["In information technology, a recovery plan consists of scenarios and procedures that should be applied whenever a failure is due to some inconsistency caused due to threats such as fires, floods, vandalism, sabotage or technology failures. A disaster recovery plan (DRP) is usually developed by asset managers, often through international regulatory requirements such as Sarbanes-Oxley, Bank 3380, ISO 27000.\nThe plan typically consists of three phases: crisis management; plan developed in conjunction with the definition of activities, people and physical data. Data recovery can be carried out from any computer storage media including CD, DVD, hard drives, flash memory, etc. The need for recovery may occur when the recording medium is damaged or where the data files were merely marked as deleted but remain stored before being overwritten.\nSome common reasons for the need to restore the data include hardware and software errors in recording data, accidental deletion, degaussing, scratches or contamination of surfaces. NAND-Flash – due to improper removal of devices, unauthorized formatting, accidental deletion, destruction of contacts.\nCurrently, there are two basic ways to recover data. The method chosen depends on the nature of fault. The hardware and software method is used in cases where a programmatic way does not help. Programmatic techniques are employed to restore data without physical intervention into the drive, as well as in the functioning and structure of firmware modules.\nThis method is used in cases where for one reason or another access to the data is lost. This may be due to the formatting of logical drives, failure to change the logical drive geometry, removal of information, partial or complete destruction of file system. Often in these cases, it is possible to recover most of the information, but there are instances when it is impossible to restore the lost data. There are many programs that automate the recovery process, some of which are free.\nIf there is damage to the file system as a result of software failure or malfunction of media, data recovery software can retrieve information depending on the extent of damage. When data is removed, in fact, data is physically left in the storage location but the file system is no longer displayed, and the place where they are located marked as free and ready to record new information.\nSuch files can be easily read and recovered with all the attributes and location information still intact. If reconstruction of a file system is not possible for some reason, some files can still be recovered using signatures. In this type of recovery, drives are scanned for known file signatures. The basic principle of signature search algorithm is the same as that of earliest vendors.\nSome files (eg, text and HTML files) do not have characteristic signatures, but can be determined by circumstantial evidence as they contain only ASCII characters. This type of recovery is used to retrieve photos from memory cards since data on the card is the same type, in general, strictly sequentially without fragmentation. Many types of file headers contain characteristic sequence of characters. For example, JPEG files contain a sequence of characters, JPEG, ZIP files begin with PK, and PDF documents begin with the characters PDF.","Data loss can take quite a few forms – deletion by accident, failure of a hard drive, bugs in the software, corruption of data, hacking and even a power failure can all cause there to be a loss of data. Of course, those aren’t the only things. There are more extreme cases, such as when a hard drive has been in a fire or other disaster. Sometimes, data can even be recovered in cases such as that.\nDo you know what data recovery is? It can be defined as the process of restoring lost data or data that has been deleted by accident or made inaccessible or corrupted for any reason. This typically refers to data that is located on a laptop, desktop, server, or even an external storage system or from a backup.\nThe process for data recovery can vary depending on the circumstances of the loss as well as the software that will be used to make the backup and the target media for the backup. As an example, many laptop and desktop backup software platforms will allow for the end users to restore their lost data and files themselves, but the restoration of a database that has been corrupted from a tape backup is more of a complicated process that will require IT intervention. However, data recovery can also be a service that is provided, like remote data recovery services. These services will generally be used to recover important files and data that had not been backed up and have been deleted from the file system of a computer by accident but might yet remain on the disk in fragments.\nDisaster Recovery Plans\nThe disaster recovery plan for any organization needs to include providing a strategy for how the data will be recovered while also documenting acceptable recovery time and recovery point objectives.\nWe mentioned recovery software a bit earlier. There are quite a few different options for this type of software. All of them have their good points as well as their drawbacks. The thing is, they are supposed to ease your mind when it comes to recovering data that has been lost. Will they all be able to recover every bit of data that has been lost? No. Will they be able to recover what you need? That depends on how religiously you backed up your information.\nData Recovery Services\nIf there is a piece of data that used to be located on your hard drive, USB flash drive, solid state drive, RAID, or other type of storage media, you can hire one of the data recovery specialists out there to perform data recovery to try to retrieve that data. Of course, this won’t always be something that is possible. There are times when the system will just be too corrupted or damaged to get any of the data back. That being said, data recovery technology has recently become very advanced, so you never know what can be recovered.\nA loss of data is something that none of us ever wants to go through. Unfortunately, many of us will at one point or another. Whether it is simply a lost USB flash drive that we might have failed to backup or we accidentally delete a folder that it critical to our business, there are potential hazards everywhere. Your first step in protection against this eventuality is prevention.\nData loss is almost totally preventable and if you want to prevent it, then it is critical that you have a good backup plan in place. Remember DATA RECOVERY WILL NEVER BE AN ALTERNATIVE TO BACKING YOUR DATA UP! Data recovery will be able to get some of your data most of the time, but you will have to pay for it. That being said, nearly all data will be recoverable in some form – with the only obstacles being money and time. The more money and time you can provide, the better your odds."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:ee11e110-af6c-441b-bd1e-e74a4010ac20>","<urn:uuid:bcb1b27f-92c0-485c-aa3c-c9218a2c52f4>"],"error":null}
{"question":"What are the 4 levels of parallelization used in the Alya computational mechanics code?","answer":"Alya uses four levels of parallelization: 1) Distributed memory parallelization using MPI for substructuring, 2) Node-level parallelism using OpenMP for loop and task parallelism with dynamic load balancing, 3) CPU-level vectorization for certain kernels, and 4) Accelerator exploitation through OpenACC pragmas or CUDA for GPU computing.","context":["Alya is a high-performance computational mechanics code to solve complex coupled multi-physics / multi-scale / multi-domain problems, which are mostly coming from the engineering realm. Alya is developed by the Alya Dev Team, which is jointly formed by researchers and developers of BSC and ELEM Biotech. Among the different physics solved by Alya, we can mention incompressible/compressible flows, non-linear solid mechanics, chemistry, particle transport, heat transfer, turbulence modeling, electrical propagation, etc.\nFrom scratch, Alya was specially designed for massively parallel supercomputers, and the parallelization embraces four levels of the computer hierarchy. 1) A substructuring technique with MPI as the message passing library is used for distributed memory supercomputers. 2) At the node level, both loop and task parallelisms are considered using OpenMP as an alternative to MPI. Dynamic load balance techniques have been introduced as well to better exploit computational resources at the node level. 3) At the CPU level, some kernels are also designed to enable vectorization. 4) Finally, accelerators like GPU are also exploited through OpenACC pragmas or with CUDA to further enhance the performance of the code on heterogeneous computers.\nMultiphysics coupling is achieved following a multi-code strategy, relating different instances of Alya. MPI is used to communicate between the different instances, where each instance solves a particular physics. This powerful technique enables asynchronous execution of the different physics. Thanks to a careful programming strategy, coupled problems can be solved, retaining the scalability properties of the individual instances.\nThe code is one of the two CFD codes of the Unified European Applications Benchmark Suite (UEABS) as well as the Accelerator benchmark suite of PRACE. Alya is presently involved in five centers of excellence, RAISE, EoCoE-2, CompbioMed2, Excellerat and CoEC.\nFigure 1: Turbulence on a wind farm and LES simulations of a wind turbine using an actuator disc.\nAVBP is an LES (Large Eddy Simulation) code dedicated to unsteady compressible flows in complex geometries with combustion or without combustion. It is applied to combustion chambers, turbo machinery, safety analysis, optimization of combustors, pollutant formation (CO, NO, soot), UQ analysis. AVBP uses a high-order Taylor Galerkin scheme on hybrid meshes for multi species perfect of real gases. Its spatial accuracy on unstructured hybrid meshes is 3 (4 on regular meshes). The AVBP formulation is fully compressible and allows to investigate compressible combustion problems such as thermoacoustic instabilities (where acoustics are important) or detonation engines (where combustion and shock must be computed simultaneously).\nExplosions in building: LES with the high-fidelity solver AVBP on an INCITE machine: 1 billion cells. A premixed flame propagates from the left to the right side of the picture and increases speed when it meets obstacles and generates turbulence. See many more examples and movies here. in the field of combustion and turbo machinery\nAVBP is a world standard for LES of combustion in engines and gas turbines, owned by CERFACS and IFP Energies Nouvelles. It is used by multiple laboratories (IMFT in Toulouse, EM2C in Centralesupelec, TU Munich, Von Karmann Institute, ETH Zurich, etc) and companies (SAFRAN AIRCRAFT ENGINES, SAFRAN HELICOPTER ENGINES, ARIANEGROUP, HERAKLES, etc). It is also used as a usual benchmark code by many computing centers to test their machines. The code is managed using specialized tools: git for source management, Redmine to track users experience, bi annual release of new versions. 100 to 200 users work with AVBP in Europe and hundreds of different configurations are computed every year.\nAVBP is also used today to compute turbomachinery (compressors and turbines) and to compute full engine configurations. Being able to compute simultaneously the compressor and the chamber of the chamber and the turbine or all three is now possible with AVBP. This is critical for multiple problems such as new propulsion concepts (such as Rotating Detonation Engines) or to study coupled phenomena such as the noise emitted from a gas turbine.\nAVBP has always been at the forefront of HPC research at CERFACS: its efficiency has been verified up to 250 000 cores with grids of 2 to 4 billion cells. This was done through multiple PRACE (EUROPE) and INCITE (USA) CPU time allocations. This requires a continuous work on the code architecture itself. CERFACS collaborates with INTEL through an IPCC to continuously increase the performances of the solver. Collaborations with IBM and NVIDIA are also frequent. AVBP is used in 3 European Centers of Excellence: Excellerat, Combustion, and now RAISE.\nAVBP is the baseline code for two European Research Council advanced grants lead by IMFT and CERFACS: INTECOCIS on thermoacoustics which ended in 2018, and currently SCIROCCO on hydrogen combustion technologies. It is now the main code used by CERFACS, SAFRAN TECH and SAFRAN HELICOPTER in two ITN Marie Curie projects focusing on instabilities and ignition in annular chambers: ANNULIGHT coordinated by NTNU and MAGISTER coordinated by Un. Twente.\nBasilisk (http://basilisk.fr/), is a free software for the solution of partial differential equations on adaptive meshes, developed at CNRS, Institute Jean le Rond d’Alembert in Paris. It follows a finite volume methodology coupled to an iterative multigrid solver and introduces an extension of the C programming language for implementing discretization schemes on Cartesian grids. More specifically, it provides a range of pre-defined solvers for compressible and incompressible flows, electrohydrodynamics, viscoelasticity, reaction-diffusion problems, amongst others, as well as the option to implement solvers for even more complex simulations.\nSpecifically, for multiphase flows, the code uses a conservative volume-of-fluid method to distinguish between the liquid and the gas phases, retaining the effects of viscosity and density differences, as well as surface tension and gravity. The quadtree grid construction, allows for increased grid resolution in the region of the two-fluid interface. The time-integration of the Navier-Stokes equations follows a second-order predictor-corrector scheme, and the resulting Poisson equation for the pressure field is solved with a build-in multigrid solver. The code performance and scalability were analyzed on various HPC centers, such as the DEEP-EST and JUAWEI systems at Jülich, and the CTE-AMD system at BSC.\nVideo Caption: Basilisk simulation of a droplet spreading over a chemically heterogeneous surface, using adaptive mesh refinement to accurately capture the contact line dynamics.\nWithin RAISE Task 3.5, Basilisk is used for the generation of CFD datasets in wetting hydrodynamics scenarios, to be used for the development of AI-assisted surrogate models by augmenting low-accuracy models with a data-driven part. The goal is to learn the non-linear mappings between droplet trajectories and surface features in order to (i) enhance our insights about the morphology of surfaces and how droplets evolve on them, complementing related experimental efforts, and (ii) help accelerate parametric studies aimed towards designing surfaces in applications for controllable droplet transport.\nThe multi-physics code m-AIA (formerly called ZFS) is under active development since more than 15 years at the Institute of Aerodynamics (AIA) of RWTH Aachen University. It has been used successfully in various national and EU funded projects for the simulation of engineering flow and noise prediction problems. Individual solvers for multi-phase and turbulent, combusting flows, heat conduction and acoustic wave propagation can be fully coupled and run efficiently on HPC systems. The various methods include finite-volume solvers for, e.g., the Navier-Stokes equations, lattice Boltzmann methods and discontinuous Galerking schemes for the solution of acoustic perturbation equations. Boundary fitted, block structures meshes as well as hierarchical Cartesian meshes can be used. A fully conservative cut-cell method is used for the boundary formulation for immersed bodies, which are also allowed to move freely in the solution domain.\nSimulation of particulate flows in the field of pulverized bio-fuel combustion. Interaction of a large number of fully resolved particles with non-spherical shape with a turbulent flow field. The figure shows the surfaces of the particles with the turblent flow structures and the solution adaptive Cartesian mesh on the right.\nDynamic load balancing algorithms have been implemented to achieve high-parallel efficiency, also for fully coupled solvers utilizing time varying and solution adaptive meshes. Heterogeneous HPC platforms can be used due to a CPU timer-based domain decompositioning. The postprocessing of large-scale simulations results has been performed by using Proper Orthogonal Decompositioning (POD) and Dynamic Mode Decompositioning (DMD) methods to identify modes in complex turbulent flows. Within this project, an application of m-AIA is planned in the field of optimization and optimum control for multi-physics applications based on AI and especially machine learning tools."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:4667ca87-0f3a-41ca-86c5-0fa70765b18a>"],"error":null}
{"question":"How do the strength levels compare between toughened glass and heat-strengthened glass relative to standard annealed glass?","answer":"Toughened glass is four to five times stronger than standard annealed glass, with a minimum surface compression of 10,000 pounds-per-square-inch (psi) and minimum edge compression of 9,700 psi. Heat-strengthened glass, on the other hand, is about twice as strong as annealed glass, with surface compression of 3,500 to 7,500 psi and no edge compression standard. Both types are produced through heat treatment, but their different strengths result from varying cooling rates during the manufacturing process.","context":["How is Toughened Glass Made Valiant Glass\nIn addition to making tempered glass four to five times stronger than conventional annealed glass, re-heating and rapid quenching dramatically changes the break characteristics of the glass. Consequently, when tempered glass is broken, it shatters into thousands of tiny pebbles—this practically eliminates the danger of human injury caused by sharp edges and flying shards.... One of the questions commonly asked about toughened glass (or tempered glass) cooker hobs is whether the glass will last. In January, Electrolux recalled several glass hob models, while just over the weekend in Pasir Ris, a housewife’s glass stove shattered while she was cooking.\nToughened Glass Alltrade Glass\nToughened glass is treated using a thermal tempering process. This makes it more resistant to breakage than simple annealed glass. Also,if it does break, it doesn’t shatter, but instead, breaks into typically square pieces as opposed to more dangerous shards.... How is glass made? Read about toughened glass manufacture. Have you ever wondered how is glass made? Toughened glass is made from normal, float glass.\nGlass and Thermal Stress Pilkington - First in Glass\nToughened glass is stronger than standard glass and does not shatter into large shards when broken. This is important, because it can greatly minimise potential danger in the case of a break. Manufactured through a process of extreme heating and rapid cooling, Toughened glass is much harder than normal glass. how to clean shower glass with wd40 Tempered Glass Breakage 1. There is frequently a misconception that tempered glass is \"unbreakable\" or \"nearly unbreakable\". This is NOT true. Tempered glass is definitely breakable and many of the things that can break annealed glass can also break tempered glass. 2. Fully tempered glass as supplied for shower door, patio doors, etc., is four to five times as strong as annealed glass of the\nLaminated Glass vs. Toughened Glass and the Benefits of\nSafety Glass is a generic term for glass which is made to be safer than normal, untreated glass. The most common types are toughened glass and laminated glass. how to break up with a guy Spontaneous glass breakage is a situation where a tempered glass breaks without a provocation. Learning tempered glass break pattern to understand the cause of these breakages.\nHow long can it take?\nLaminated Glass Toughened Glass Tufwell Glass\n- Where are Toughened Laminated Glass Balustrades Used\n- Avoid risk of injury caused by broken glass with toughened\n- Toughened Glass Alltrade Glass\n- Glass Types Jason Windows\nHow To Break Toughened Glass\n24/03/2012 · A few examples that come to mind: toughened glass dinner plates are known to shatter for no apparent reason, so are the glass windows in oven doors, and glass coffee table tops. Vehicle windscreens do shatter seemingly for no reason, but generally this can be traced back to a …\n- 8/11/2010 · This video is unavailable. Watch Queue Queue. Watch Queue Queue\n- Toughened glass is often referred to as safety glass or tempered glass. Toughened glass is annealed glass, heated and then rapidly cooled and is also classified as Grade A Safety glass. Toughened glass is five times stronger than standard annealed glass of the same thickness and the toughening process reduces the risk of cracking.\n- Glass can be a dangerous material . When standard glass breaks, it can form dangerous shards and splinters. To avoid risk of injury caused by broken glass, high tech safety glasses are available in toughened and laminated forms – most of which can be used in double glazing window.\n- Okay laminated glass is not tempered glass. Laminated glass is two layers usually with plastic between them. When I worked as a mechanic we could push a lot of the windows out on the V.W.s using a bit of silicon spray around the rubber seal helped...","Glass is heat-treated for two reasons: the first is to increase its strength to resist external stresses such as wind and snow loads, or thermal loads caused by the sun’s energy.\nThe second is to temper glass so that it meets safety glazing requirements defined by applicable codes or federal standards.\nFollowing are a dozen quick tips about tempered and heat-strengthened glass, including why the strongest glass isn’t always the best glass for a given application.\n1. Fabrication first. Because of the high internal stresses caused by heat-strengthening or tempering glass, all fabrication, including cutting, hole-drilling, notching or edge treatment, must be performed before glass is heat-treated.\n2. Defining heat-treated glass. In North America, the standard specification for heat-treated glass is ASTM C1048 Standard Specification for Heat-Strengthened and Fully Tempered Glass. In general, heat-treated glass is at least two to four times stronger than annealed (untreated) glass.\n3. Rate of cooling determines strength. During heat treatment, annealed (untreated) glass lites are heated to approximately 1,200 degrees F, then “quenched” in cold air. Cooled rapidly, glass tempers. Slower cooling produces heat-strengthened glass.\n4. Tempered is stronger. Tempered glass has a minimum surface compression of 10,000 pounds-per-square-inch (psi) and minimum edge compression of 9,700 psi, according to ASTM C1048. That makes it about four times stronger than annealed glass. Heat-strengthened glass has surface compression of 3,500 to 7,500 psi, about twice as strong as annealed glass, with no edge compression standard.\n5. Tempered glass is safety glass. When broken by impact, fully tempered glass shatters into tiny particles, reducing the potential for serious injury by flying shards of glass. For this reason, building codes require safety glazing in specific locations.\n6. Stronger, yet more vulnerable. Ironically, the rapid temperature change that gives tempered glass its compression strength may also cause it to shatter, seemingly without warning. On rare occasions, tiny inclusions, including nickel-sulfide, may be present in glass, which can expand during heat treatment, then stop when the glass is cooled and resume growth when the glass is exposed to high in-service temperatures (such as on the sunny exposure of a building). This “phase change” can cause tempered glass to shatter. Heat-strengthened glass is cooled more slowly; consequently, inclusions do not experience a phase change, which essentially eliminates the possibility of spontaneous glass failure.\n7. Heat-strengthened glass is not a safety glass. Though heat-strengthened glass may meet requirements for wind, snow and thermal loads, it is not considered a safety glazing. Heat-strengthened glass does not shatter when broken, but fractures into larger, sharper pieces that can become projectiles in a tornado, hurricane, explosion or fire.\n8. Avoiding fall-out. Because it does not shatter, heat-strengthened glass tends to remain in the framing system after it is damaged, which makes it a better choice for applications where glass fall-out is a concern.\n9. Lamination for consideration. Laminated interlayers, required for overhead glazing, can be used with annealed, heat-strengthened or tempered glass to combine several safety advantages into a single glazing solution, including less risk of spontaneous breakage and glass fall-out, and increased resistance to wind loads, snow loads and thermal stress.\n10. Distorted views. Heat-treatment can generate subtle roller waves in glass, which are more likely to occur in tempered glass than in heat-strengthened glass. This can cause heat-treated glass to distort reflected images, a problem that may be exacerbated when it is used in glazing units with multiple lites or a laminated interlayer.\n11. Edge quality is critical. Poor edge quality – or edge damage during fabrication, delivery or installation – makes glass more likely to break, which can offset or negate any benefit associated with heat-strengthening or tempering.\n12. Stronger isn’t always better. Although tempered glass is strongest, PPG recommends its use only where required by code as a safety glazing or for thermal stress or wind load. For other applications, annealed or heat-strengthened glass is recommended to reduce distortion and the risk of fallout and spontaneous breakage.\nTo learn more about the differences between tempered and heat-strengthened glass, or to find the best recommendation for a specific application, visit the PPG Glass Education Center at www.educationcenter.ppg.com."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:43e25dea-8de7-44fb-ac51-df6d43654a86>","<urn:uuid:e84cc665-2db0-4fa4-a3a5-fcd12e39b101>"],"error":null}
{"question":"How do conservation organizations maintain trail systems and monitor property boundaries, and what economic impacts do invasive species have on these protected lands?","answer":"Conservation organizations maintain trails through regular clearing, mowing and trimming, while also carefully planning new trails to minimize ecological impact. They conduct baseline documentation and regular monitoring of property boundaries, typically once a year, to prevent encroachment and track wildlife. Regarding economic impacts, invasive species cause substantial financial damage - just 16 invasive species result in estimated annual losses between $13-35 billion. They increase costs of controlling and managing pests/weeds, reduce productivity in forestry and agriculture, lower crop yields, degrade soil quality, and decrease land values. They also require increased pesticide use and interfere with natural regeneration and growth.","context":["The stewardship program is responsible for the management of the reservations that SVT owns and for the monitoring and oversight of conservation restrictions. The stewardship program has four main components:\n- Ecosystem and habitat protection\n- Maintenance of views, access and trails\n- Protection of the legacy\n- Coordination of the stewardship volunteer program\nVolunteer Log-in: Steward Volunteer Log\nECOSYSTEM AND HABITAT PROTECTION\nA key element in the stewardship of SVT’s reservations is developing management plans for our properties. We conduct natural resource inventories, which includes documentation of land forms, habitat types, plants and wildlife. We use the information that is gained to drive the management of the property. This information is also a valuable tool that can be used to educate our members and the public about the conservation values and biodiversity of each reservation.\nWhen making management decisions for a property our main goal is to allow natural processes to continue. An example of this is when beavers create wetlands and leave dead trees to provide habitat and nutrients to the forest. A more active form of habitat protection is maintaining fields for wildlife. Fields are kept open with regular mowing, typically once a year or once every other year.\nAnother important aspect of ecosystem protection is the restoration of native habitat by removing and controlling invasive plants. Invasive plants are the second greatest threat, next to development, to our biological diversity. Invasive plants take over and degrade our natural habitats. Some of the more common invasives that we work to control are Oriental bittersweet, honeysuckle, Japanese barberry, European buckthorn, purple loosestrife and multiflora rose.\nMany of our reservations contain trail systems that are frequently enjoyed by our members and the general public. The stewardship department works to keep these trails and their access points, which often include parking areas, in safe and usable condition. New trails are planned very carefully and designed to minimize ecological impact and to enhance recreational opportunities.\nStaff, as well as many volunteers, work to clear, mow and trim trails to provide recreationists with an enjoyable visit. Other tasks include the marking of trails and the building and upkeep of bridges and kiosks. To find a map for a property near you please visit our maps page.\nKeeping an eye on things is no small task when it comes to managing over 3,000 acres of land in 20 towns within our service area. In order to do so we conduct baseline documentation on properties that SVT owns as well as on SVT’s conservation restrictions (CRs). This entails finding, marking (in the case of land we own) and photographing property boundaries. This documentation allows us to prevent or more easily solve encroachments on conservation land.\nWe also use this information to facilitate the regular monitoring of properties and CRs; typically once a year. When we monitor a CR, we ensure that activities on the property maintain the conservation values set forth in the legal CR document. For reservations that we own, we track wildlife and plant sightings and check for problems such as trail erosion, trash or illicit uses (such as motorized vehicles or leaf dumping).\nWith a limited staff and the many tasks involved with caring for conservation land, our stewardship work depends heavily on the help of volunteers. Volunteers assist us in a variety of ways, ranging from joining a crew on a single work day to adopting a reservation and helping to maintain it for many years.\nVolunteers with specialized skills assist us with tasks such as biological inventory and database design. Preserve Stewards are long-term volunteers who assist with property monitoring and maintenance at a reservation near their home or place of work. If you are interested in volunteering with SVT, visit our Volunteer page.\nWe also have a Weed Warrior program for volunteers interested in helping us fight invasives species.\nIn addition, SVT benefits from community service projects involving corporate volunteers, scout groups or other youth groups. To see examples of the many youth projects that have recently occurred visit our Youth Conservation Stewards page.","Invasive species pose a severe risk to the natural environment. They can cause significant harm and devastate ecosystems, resulting in substantial economic impacts.\nAccording to the World Conversation Union, invasive species are the second most significant threat to biodiversity after habitat loss. Approximately 42% of threatened or endangered species are at risk because of invasive species.\nThe following article will explore invasive species in more detail and unpack why they are dangerous to the environment.\nWhat are Invasive Species?\nAn invasive species is an animal or plant organism that has the potential to cause ecological or economic harm in a new region or environment where it is not native and does not belong.\nWith that said, not all non-native species are invasive. For example, most food crops grown in the United States, such as wheat and rice, are not native to the region.\nThere are specific characteristics that make a species invasive.\nTo be invasive, a species must easily adapt to its new region or environment, reproduce quickly and harm property, the economy, or native plants and animals.\nIn their new ecosystem and environment, invasive species often become predators, competitors, parasites, hybridizers, and diseases to native plants and animals.\nHence, they are difficult to control and contain because they are free of predation and disease, two of the significant factors that keep native plant and animal populations in balance.\nInvasive species can completely disrupt the food chain, related ecosystems, and the natural environment.\nCommon characteristics of invasive species include:\n- High reproduction rate\n- Rapid growth and maturity\n- High dispersal ability\n- Few natural predators\n- Ability to thrive in distinct habitat types and climate regions\n- Ability to out-compete native species\n- High cost to remove or control\nWhy are Invasive Species Dangerous to the Environment?\nInvasive species are dangerous to the environment. They represent one of the most potent, persistent, and widespread threats to the natural environment.\nInvasive species can harm natural resources (fish, wildlife, plants, and ecosystem health) because they disrupt natural communities and ecological processes and threaten human use of resources. This can cause substantial economic impacts and the distribution of ecosystems.\nFor example, if an invasive plant species is introduced, this can lead to several problems for existing crops.\nInvasive plant species can introduce new diseases and attract new crop pests, which can cause a reduction in crop yields and require an increased need for pesticides. Invasive plants can interfere with regeneration and growth.\nThis can cause serious harm to native species within that ecosystem because they are suddenly competing with new species for the same resources (food, water, shelter). Invasive species typically thrive under these conditions because they have no predators, unlike native species, to help maintain the population.\nWhen invasive species are introduced, the ecosystem often becomes much less diverse. A less diverse ecosystem is far more susceptible to further disturbances like diseases, climate change, and natural disasters.\nOnce an invasive species become established in its new environment, it becomes very costly and challenging to eradicate. This can lead to irreversible impacts on the local ecosystem.\nInvasive species have a range of impacts that affect the environment, society and economy, and biodiversity.\nInvasive species can cause immense damage to the natural environment.\nEnvironment impacts can:\n- Leading to the extinction of native species (plants and animals)\n- Negatively impact biodiversity\n- Permanently alter habitats\n- Lead to native species competing for limited resources\n- Cause species extirpation\n- Cause soil degradation and erosion\n- Alter fire cycles\n- Displace native plant communities\n- Disrupt the food chain\n- Destroy the quality understory habitat in forests\n- Decrease the quality and amount of range for wildlife\n- Introduce parasites\nInvasive species can potentially be a significant threat to the income and livelihood of the local people. They can also impact human health.\nSocial impacts can:\n- Cause disease\n- Cause human or animal suffering\n- Reduce land and water recreational opportunities\n- Lead to reduced income\n- Increase food insecurity\n- Pose a risk to human and animal health\n- Increase social challenges\n- Reduced water quality and quantity\n- Loss of traditional food and medicinal plants\n- Export and import trade restrictions imposed\nInvasive species affect the economy in several ways, such as agriculture, forestry, and fishing. According to Environment and Climate Change Canada, the estimated annual cumulative lost revenue caused by just 16 invasive species is between $13 and $35 billion dollars.\nEconomic impacts can:\n- Lead to a higher cost of controlling and managing pests, weeds, and diseases\n- Reduce productivity in forestry, agriculture, and fishing\n- Cause export and import trade restrictions\n- Reduce land and property values\n- Lower crop productivity\n- Harm livestock\n- Degrade soil quality\nWhy are Invasive Species Introduced?\nMany invasive species are introduced into their new environment by accident. However, that is only sometimes the case, as some species are purposefully introduced.\nThe accidental introduction of invasive species usually occurs through ship ballast water, recreational boaters moving between bodies of water or pets that escape or are released into the wild.\nMost of the time, invasive species are introduced on purpose as a form of pest control, while other times, they are brought in as pets and are accidentally released, or plants are brought in for decorative purposes (e.g. in a garden).\nWhen invasive species are introduced intentionally, the ramifications are not considered or anticipated. It is hard, even for scientists, to know how a species will adapt to a new environment.\nExample of Accidental Introduction\nZebra mussels are an invasive species that are native to freshwater environments in Eurasia. In the Great Lakes of North America, Zebra mussels are now considered an invasive species. In their new environment, they filter out algae that native species need for food and attach to and incapacitate native mussels.\nThey essentially out-compete with other filter feeders and starve them. Zebra mussels were accidentally introduced to North America via ships that traveled between the two regions.\nExample of Purposeful Introduction\nIn 1949, five cats were brought to Marion Island (South Africa) in the Indian Ocean as a form of pest control. The idea was that the cats would help control the mice population. However, by 1977 over 3,400 cats were living on the island. Since cats hunt more than just mice, the local bird population was at risk.\nHow do Invasive Species Spread?\nInvasive species are most commonly spread through the movement of people. More than ever, especially because of globalization, people and goods travel worldwide at a high rate, and occasionally they pick up uninvited guests along the way.\nInvasive species can enter a ship’s ballast water or attach themselves to the propellers of a smaller boat.\nAnother way invasive species spread is through equipment used at different sites in various regions.\nClimate change will also enable invasive species, predominantly plants, to move into new areas.\nHow Can You Help?\nIt may not seem like it, but there are a few simple ways to help combat invasive species at an individual level.\nVolunteer at your local park, refuge, or other wildlife areas to help identify and remove invasive species. This is also an excellent opportunity to learn and educate others about the risks associated with invasive species and how to stop the spread of invasive species.\nPurchase plants and flowers for your home or garden that are not invasive. An even better environmental decision would be to buy plants that are native to your region.\nNever release pets or non-native species into the wild. If you own an exotic or non-native pet, take measures to prevent an accidental escape.\nWays to Prevent the Spread of Invasive Species:\n- Clean your hiking and fishing gear when moving between regions and bodies of water\n- Don’t move firewood between ecosystems\n- Fish using native bait\n- Clean your boat thoroughly before changing bodies of water\n- Don’t take animals, plants, shells, or food from different ecosystems\n- If you see something unusual, report it\n- Check your pet’s paws\nGovernments and conservation authorities are working diligently to educate the public about invasive species to prevent the accidental transportation or introduction of new species.\nHave you ever wondered why border agents and customs officers are so strict about plants, fruits, and meats at the airport? Invasive species are one of the main reasons.\nGovernments want to prevent any introduction of new species, seeds, plants, or related diseases as they pose a massive threat to the environment, society, and economy.\nGiven the potential impact, environmental groups and government agencies are concerned about the harm that is being done by invasive species.\nDid you find this article helpful? If so, please share it with your friends! Many thanks."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:84db33fa-f2e8-4a9e-9354-80672b8d84dd>","<urn:uuid:a26c9729-dfe5-456a-86f4-6f6eadd30de2>"],"error":null}
{"question":"How do Portugal's historical migration patterns compare to modern NATO's approach to military mobility and personnel deployment?","answer":"Historical Portuguese migration was characterized by predominantly male settlers, leading to strategic responses like the Crown sending groups of Portuguese women to overseas territories. This historical pattern of strategic human resource deployment bears similarities to NATO's modern approach to military mobility, as seen in Trident Juncture, where specific forces were strategically deployed, including more than 50,000 personnel and various military assets. The exercise demonstrated the importance of efficient force deployment, with specific elements like the Marines successfully landing ashore at Alvund, Norway, with 700 Marines and various vehicles, showing how modern military movements require careful planning and execution, much like historical Portuguese colonial migrations required systematic planning.","context":["The Portuguese diaspora communities still are very connected to their language, their tradition and their nationwide dishes and particularly the bacalhau. An even smaller minority of not more than 2,000 individuals portugese woman communicate Barranquenho, a dialect of Portuguese closely influenced by southern Spanish, spoken in the Portuguese town of Barrancos (within the border between Extremadura and Andalusia, in Spain, and Portugal).\nWhite Americans are therefore referenced as white Hispanics and non-Hispanic whites, the previous consisting of white Americans who report Hispanophone identification (Spanish Hispanic Latin America), and the latter consisting of white Americans who don’t report Hispanophone ancestry. The Crown also shipped over many Órfãs d’El-Rei of what was thought-about “good start” to colonial Brazil to marry Portuguese settlers of high rank. Órfãs d’El-Rei (fashionable Portuguese órfãs do rei) literally interprets to “Orphans of the King”, and they were Portuguese feminine orphans in nubile age. There had been noble and non-noble maidens and they were daughters of army compatriots who died in battle for the king or noblemen who died abroad and whose upbringing was paid by the Crown. Bahia’s port within the East acquired one of the first groups of orphans in 1551.\nPortugal was one of three main Allied nations to host Operation Trident Juncture, one of NATO’s largest-ever exercises, in October-November 2015. Naval Striking and Support Forces NATO (STRIKFORNATO), the Alliance’s premier maritime battle workers and primary link for integrating U.S. maritime forces into NATO operations, has a hub in Lisbon and played a lead role in Trident Juncture. The U.S. Air Force’s 65th Air Base Group operates from Lajes Field, a Portuguese airbase on Terceira Island within the Azores that serves as a logistics hub for U.S Transportation Command, U.S. European Command, and NATO allies. Portugal is a powerful associate in combating terrorism, having deployed army trainers to Iraq in the struggle against ISIL.\nMany Arawak/Taíno names and phrases are used in daily conversation and for many meals native to the Dominican Republic. Other teams within the nation embody the descendants of West Asians—largely Lebanese, Syrians and Palestinians. A smaller, but vital presence of East Asians (primarily ethnic Chinese and Japanese) can also be found all through the population. Dominicans are additionally composed of Sephardic Jews that have been exiled from Spain and the Mediterranean area in 1492 and 1497, coupled with different migrations dating the 1700s and through the Second World War contribute to Dominican ancestry. Some of the Sephardic Jews nonetheless presently reside in Sosúsome time others are dispersed all through the nation.\nPortugal and the United States have enacted an revenue tax settlement to prevent double taxation, and signed an settlement on implementing the Foreign Account Tax Compliance Act in August 2015. United States-Portugal bilateral ties date from the earliest years of the United States, when Portugal recognized the United States in 1791 following the Revolutionary War. Contributing to the robust ties between the United States and Portugal are the presence of sizeable Portuguese communities in Massachusetts, Rhode Island, New Jersey, California, and Hawaii.\nBilateral trade in items and providers reached $8 billion in 2018, a 9 percent enhance from the previous 12 months. The United States exported $1.46 billion in items in 2018, with machinery, mineral fuels, plane, and autos as the leading merchandise. The United States imported $three.5 billion during the identical time, with mineral fuels, cork, and machinery in the lead. The inventory of U.S. direct funding in Portugal reached $2.1 billion in 2017, and U.S. firms are important investors in the banking, pharmaceutical and chemical industries, among others.\nThe later is also widespread in Irish, southern English, and western French populations. The Moors occupied what is now Portugal from the 8th century until the Reconquista movement expelled them from the Algarve in 1249. Some of their population, mainly Berbers and Jews transformed to Christianity and have become Cristãos novos, nonetheless identifiable by their new surnames. The “new Christians” would later undergo religious persecution from the Holy Inquisition and plenty of had been condemned and expelled under the Auto-da-fé sentencing or fled the nation, making a Jewish diaspora in The Netherlands, England, America, Brazil and other components of the world. After the Romans, Germanic peoples, particularly the Suebi and the Visigoths, dominated the peninsula for several centuries and have become a part of the native populations.\nUPDATE: The United States Continues to Lead the Global Response to COVID-19\nThe Portuguese migration was strongly marked by the predominance of men (colonial reports from the 16th and seventeenth centuries almost all the time report the absence or rarity of Portuguese women). This lack of ladies apprehensive the Jesuits, who asked the Portuguese King to ship any sort of Portuguese women to Brazil, even the socially undesirable (e.g. prostitutes or women with mental maladies similar to Down Syndrome) if essential. The Crown responded by sending groups of Iberian orphan maidens to marry each cohorts of marriageable men, the nobles and the peasants. In areas such as Thetford and the crown dependencies of Jersey and Guernsey, the Portuguese type the biggest ethnic minority groups at 30% of the inhabitants, 7% and three% respectively. The British capital London is residence to the most important number of Portuguese people within the UK, with the bulk being discovered in the boroughs of Kensington and Chelsea, Lambeth and Westminster.\nIn the United States, there are Portuguese communities in New Jersey, the New England states, and California. Springfield, Illinois as soon as possessed the most important Portuguese Community in the Midwest. In the Pacific, Hawaii has a large Portuguese element that goes again a hundred and fifty years (see Portuguese Americans), Australia and New Zealand even have Portuguese communities (see Portuguese Australians, Portuguese New Zealanders). Canada, particularly Ontario, Quebec and British Columbia, has developed a major Portuguese neighborhood since 1940 (see Portuguese Canadians). Argentina (See Portuguese Argentine and Cape Verdean Argentine) and Uruguay (see Portuguese Uruguayan) had Portuguese immigration within the early 20th century.\nEthnic minorities in Portugal\nThe first recorded particular person of Dominican descent emigrate to what is now known as the United States was sailor-turned-merchant Juan Rodriguez. He arrived on Manhattan in 1613 from his residence in Santo Domingo, which makes him the first non-Native American person to spend substantial time within the island.\nHowever, the practice of separating “race” and “ethnicity” as different categories has been criticized both by the American Anthropological Association and members of US Commission on Civil Rights. ), also called Lusitanian Portuguese (português lusitano), Iberian Portuguese (português ibérico) and Portuguese of Portugal (português de Portugal) and even “Standard Portuguese” or “Old World Portuguese” refers back to the Portuguese language spoken in Portugal. Standard Portuguese pronunciation, the prestige norm primarily based on European Portuguese, is the reference for Portugal, the Portuguese-talking African international locations, East Timor and Macau. The word “European” was chosen to keep away from the conflict of “Portuguese Portuguese” (“português português”) as opposed to Brazilian Portuguese. Today, Portuguese tiles, also called azulejos, are available in many colors, nevertheless most comply with the normal patterns.","Trident Juncture 2018 is a major NATO exercise which is focused on Northern Tier defense.\nIt also is an exercise for the Norwegians in mobilizing their society to deal with crises in the region in which NATO forces would be called upon to operate from Norwegian soil.\nA key part of the strategic shift facing the Nordics is the shift from expeditionary out of area operations to direct defense.\nAs we noted earlier this year when we released our report on the Nordics and the strategic shift:\nThe Russian seizure of Crimea and other aspects of its global activism have had a significant effect on the Nordics.\nThe Nordics are working mores closely together to deal with the strategic shift. And they are adding new capabilities to shape a more effective approach to crisis management and deterrence in depth.\nAnd the Norwegians, Swedes and Finns are clearly committed to a total defense concept whereby society is being mobilized to support defense in depth as well.\nThe direct defense focus is coming as well within the context of a significant shift within Europe itself with regard to the next phase of European development.\nIn an article entitled “The Coming of Hanseatic League 2.0,” Harald Malmgren highlighted this strategic political and economic shift as well:\nGerman authorities are now beginning to address the possibility of a different European context in coming years, as the pressures within the EU and Eurozone build towards a potential breakup over mutual financial commitments.\nItaly in particular is posing this financial issue as central to its demand for greater fiscal and banking autonomy.\nLess noticed in press and media is a parallel process of thinking among other European national militaries. Among the militaries of the Nordic nations there has already developed a Northern Europe Defense Cooperation group, which involves closely integrated operations of the four Nordic nations’ militaries with the UK and the US. This group has been joined de facto militarily by the Netherlands and Belgium. Its area of direct concern includes the security of the Arctic and virtually all of the Baltic Sea region, including the Baltic States.\nHow divisions between military thinking (clear desire to be part of the Nordic club) and political thinking in Germany (where Macron and Merkel have tried to work a closely relationship) and other European nations evolves is uncertain.\nMost likely there will be clashes among these disparate sources of power in Europe in the future,when economic and security challenges arise and require action.\nNorway sits in a geography where the greatest concentration of military force rests, namely the Kola Peninsula.\nEssentially with the Russians building out bases throughout their part of the Northern region inclusive of the Arctic, they are distributing their access points to put pressure on the Nordics and NATO in a crisis.\nThe reworking of the geography is sometimes referred as the militarization of the Arctic.\nBut it is better understood as enhanced base distribution by the Russians to provide operational points from which force can be applied in a crisis or as part of the diplomatic side of deterrence strategy.\nThis reworking of geography provides a backdrop of the challenges facing NATO which Trident Juncture 2018 is trying to address.\nAs Megan Eckstein noted in an article published by USNI News on November 7, 2018:\nThe massive exercise – which grew to include more than 50,000 personnel, 65 ships and 250 aircraft, including 14,000 American troops, a carrier strike group (CSG) and an amphibious ready group (ARG) – centered around a scenario of protecting Norway from an invasion at its borders by inserting reinforcements by air and by amphibious landing.\nA key piece of the amphibious landing was the Iwo Jima ARG and embarked 24th Marine Expeditionary Unit. The ARG/MEU stopped in Iceland for training on the way to Norway, but the two smaller ships, dock landing ship USS Gunston Hall (LSD-44) and amphibious transport dock USS New York (LPD-21), had to return to Iceland when heavy seas hampered their voyage to Norway.\nPersonnel on the LSD suffered minor injuries, and the well deck of the ship and an unsecured landing craft utility (LCU) were damaged in the heavy seas. The LPD returned to Iceland with the LSD as a precautionary measure. New York made it to Norway for the start of the exercise, but Gunston Hall did not.\nAccording to a 24th MEU news release, the Marines successfully landed ashore at Alvund, Norway, on Oct. 29.\nThe landing force included Marines from Battalion Landing Team 2nd Battalion, 2nd Marine Division, and 700 Marines pushed ashore with 12 amphibious assault vehicles, six light armored vehicles and 21 humvees.\n“We came to the North Atlantic looking for a challenge and Trident Juncture delivered; throughout the exercise the environment forced us to be flexible and adaptive,” Maj. Anthony Bariletti, the 24th MEU operations officer, said in the news release.\n“It is the adaptability that makes Marine Expeditionary Units such a lethal crisis response force. As Marines, we gain our lethality from the ability to operate as part of a naval integrated team. The ability to conduct amphibious operations in the premier core competency of our service and this exercise provided an outstanding opportunity for the 24th MEU to hone its skills and prepare for combat as a forward deployed, sea-based Marine Air-Ground Task Force.”\nAdditional amphibious landings took place in the exercise, including a French-led force that also included Dutch Marines and Finnish Coastal Jaegers as well as British soldiers with their Viking All Terrain Vehicles.\nIt should be noted that enhanced operational rhythm has consequences for the blue force as well. For example, the Royal Norwegian Navy frigate HNoMS Helge Ingstad (F313) collided with the Malta-flagged oil tanker Sola TS during the exercise with significant damage to the frigate.\nWithout placing blame in the Thursday collision, the increased operational tempo of warships in general are pushing navies around the world harder and adding stress to operations, Eric Wertheim, author of U.S. Naval Institute’s Combat Fleets, told USNI News on Thursday.\n“As you get ops tempo increasing, navies are going to be stressed. It’s not just the U.S.,” Werthheim said.\n“The more you drive your ships, the more you’re going to have accidents.”\nThis recent piece published by NATO highlights the key aspect of how the Norwegians addressed their role in the exercise.\nAlthough the article highlights that national resilience is a NATO wide trend, this clearly is not so.\nBut it is also clear that the Nordics are focused specifically on enhancing their national resilience for sure.\nNorway uses Exercise Trident Juncture to strengthen its national resilience\nTrident Juncture 18, NATO’s largest exercise in recent years, is also the Alliance’s first military exercise to include substantial civil preparedness elements and to practice cooperation between the military and the civilian authorities. Norway, which is hosting the exercise, is using the collective defence scenario not only to train its armed forces, but also to build up its ability to respond to a crisis of any kind.\nThis is fully in line with the commitment that all NATO Allies have undertaken to increase national resilience, which is a key element of NATO’s collective defence. Resilience is rooted in the Washington Treaty. At the Warsaw Summit in 2016, NATO leaders also pledged to enhance national resilience, including by improving civil preparedness.\nTo meet this pledge, Norway added an extra challenge to Trident Juncture 18, in the form of close interaction between the military participants and civilian crisis responders, such as the health service, the police, the fire department, and non-governmental organisations. Specific events have been integrated in the exercise programme, including simulated mass casualty incidents, evacuation drills, Chemical, Biological, Radiological and Nuclear (CBRN) emergencies, taking care of evacuated civilians, and crisis management.\nIn addition to contributing to Norway’s crisis management capacities, this also contributes to interoperability with other NATO Allies. Some of the forces participating in Trident Juncture have been involved in these events as well – for instance, Danish and French CBRN soldiers, part of NATO’s Spearhead Force (the Very High Readiness Joint Task Force) in 2019, have been part of a simulation where they had to give first aid to victims of a chemical attack, and decontaminate the area."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:0c743674-596b-40e5-9475-4f17c649a5f1>","<urn:uuid:5107ec20-2b72-4fe2-801b-3ea3814ba52b>"],"error":null}