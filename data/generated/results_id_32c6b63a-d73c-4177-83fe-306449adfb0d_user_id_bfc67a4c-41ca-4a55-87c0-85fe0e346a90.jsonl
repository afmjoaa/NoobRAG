{"question":"What are the four main types of business analytics and how does each one serve different organizational needs?","answer":"The four primary types of business analytics are descriptive, diagnostic, predictive, and prescriptive analytics. Descriptive analytics interprets historical data and KPIs to identify patterns and trends, helping understand customer behavior and enhance marketing strategies. Diagnostic analytics focuses on past performance and uses data mining to understand what influences specific trends. Predictive analytics uses statistics and machine learning techniques to forecast future outcomes based on historical data, particularly useful for marketing and sales teams. Prescriptive analytics goes beyond prediction by utilizing historical performance data to determine how best to handle similar future events and recommends actions for optimized results.","context":["A Break Down of Business Analytics\nWhat are Business Analytics?\nWhen a person thinks about analytics business may not immediately come to mind. However, business analytics is both a business intelligence subcomponent and a data management solution. Business analytics is a process that is increasing in its popularity due to the benefits businesses experience. Data analytics benefits business professionals varying from health care workers to computer science employees. When properly utilized business analytics can increase productivity, efficiency, and bottom line business profitability.\nMethodologies utilized within business analytics include predictive analytics and data mining processes. Statistical analysis is also a prominent methodology of business analytics. The objective of these methodologies is to analyze data and translate it into actionable information. Actionable information is used to not only identify trends or outcomes but allows businesses to anticipate them. Data business analytics supplies help companies to make informed and data driven business decisions. Business analytics is useful for everything from supply chain business problems to real world information technology investments.\nA business analytics dashboard generally contains a wide variety of components. Data mining is one such component that sifts through extensive datasets. The objective of data mining is to utilize statistics, databases, and machine learning in order to establish relationships. Additionally, statistics, databases, and machine learning are utilized to identify trends.\nPredictive analytics is also a dashboard component that generates predictive models through the utilization of statistical techniques. Predictive analytics accomplishes this through information extraction, pattern identification, and supplying predictive scores for a variety of organizational outcomes. Data visualization is another dashboard component that supplies visual representations like graphs or charts. Data visualization makes it easier to analyze data and make informed decisions.\nDue to the extensive benefits business analytics offer, they are absolutely a worthwhile investment. From accomplishing business goals efficiently to improving decision making capabilities, business analytics is increasingly considered as a necessary expenditure. As world business information technology best practices evolve business analytics allow the most successful organizations to keep up.\nHow is Business Analytics Used?\nCommercial organizations use business analytics in a variety of ways. Typical uses of business analytics range from decision making initiatives to key performance indicator monitoring. There are 4 primary types of business analytics that all business professionals should be aware of. Depending on what benefits business professionals seek different data analytics types are utilized.\nDescriptive analytics is a noteworthy business analytics type. Descriptive analytics interprets historical data and key performance indicators, also known as KPIs, in order to identify patterns and trends. The interpretation of KPIs and historical data supply business professionals with a near real time comprehensive business operations understanding. Both data mining and data aggregation are commonly utilized for descriptive analytics purposes. Descriptive analytics benefits business professionals seeking to understand customer behavior more completely. As a result, everything from best practices to profitability is enhanced in marketing strategies.\nDiagnostic analytics is another business analytics type that focuses on past performance. Diagnostic analytics aim to understand what influences specific trends through data mining and other techniques. Analytics used support comprehensive understanding regarding why a trend occurred and the likelihood of its occurrence. Algorithms are then used for regression and classification.\nPredictive analytics is a business analytics type that uses statistics for forecasting. This type of data analytics business professionals utilize predicts future outcomes based on historical data supplied and additional techniques. Predictive analytics supplies enhanced business intelligence in near real time for faster decision making capabilities. Predictive analytics utilizes machine learning techniques and statistical models in order to evaluate future outcomes. Predictive analytics build off descriptive analytics results in order to generate models that predict the likelihood of various potential outcomes. Predictive analytics is an especially popular business analytics type option for marketing and sales teams.\nPrescriptive analytics is the final business analytics type. Prescriptive analytics utilizes historical data regarding performance in order to determine how best to handle similar future events. Prescriptive analytics goes beyond predicting outcome determinations. In fact, this type of data analytics business professionals use recommends actions for optimized results.\nFact-: Descriptive, diagnostic, predictive, and prescriptive analytics are the 4 primary business analytics types.\nOnline employee scheduling software that makes shift planning effortless.\nTry it free for 14 days.\nThe Importance of Business Analytics\nWorld business information technology is constantly evolving. Organizations need to keep up with world business best practices and information technology advancements in order to survive. As such, business analytics is directly tied to the overall success and longevity of organizations.\nBig data and business analytics supply businesses with a comprehensive view of performance. Business analytics data allows organizations to understand what business processes are efficient and which require attention. When business problems are identified swiftly, business operations will more likely avoid severely damaging financial consequences. For example, supply chain business problems could be addressed quickly with business analytics, therefore, avoiding additional financial damages. Analytics business professionals are allowed access to promotes business operations optimization.\nPreviously, business decisions were made slowly and through a laborious process. Instead of business decisions necessitating multiple staff meetings, near real time decision making capabilities are offered by business analytics. Data driven decision making allows businesses to make informed decisions with a greater probability of positive outcomes. Business analytics is a fantastic risk management tool as risk is significantly minimized through the valuable insights business analytics generates. Organizations can make informed business decisions based on trends and performance instead of guesswork.\nBusiness analytics also support innovation and real world business growth. By embracing change, business analytics use data to grow adjacent to concurrent world business changes. Any business analyst is aware of how important adaptability is to company success and longevity. Benefits business professionals obtain from big data and business analytics include an increased competitive advantage. Through business analytics, organizations can identify exactly what customers need or want. As a result, a higher market share presence and competitive advantage are within arms reach.\nBenefits business analytics offers also extend to brand reputation and brand awareness.\nBusiness best practices support monitoring of web or social media mentions. Internet monitoring allows businesses to craft a more purposeful brand and reputation with customers.\nAdvantages and Disadvantages of Business Analytics\n73% of companies have invested in big data or plan to invest in big data within the upcoming two years. Big data investment increases at an average rate of 30% each year. However, under 10% of companies that have implemented big data report receiving the ROI they anticipated. As such, big data and analytics used improperly can actually damage a business bottom line. However, big data and analytics used properly offer significant business benefits. Various advantages and disadvantages of business analytics include-\nAdvantages of Business Analytics\nIncreased efficiency, actionable insights, and improved monitoring capabilities are 3 benefits business analytics offer. Analysis data insights allow organizations a comprehensive view of their business operations and performance. Historical data can identify business problems such as employee performance issues. Performance data can be shared with staff members so that they can work on improving individual areas of weakness. As a result, both real time business performance and employee productivity are positively influenced.\nEfficiency is increased when employees use data to make decisions and achieve organizational objectives. Employees using data optimally to make informed decisions benefits business operations and best practices measurably. Data visualization further supports employees using data and encourages them to share their own unique insights. Access to business data and analytics tools benefits business operations including advertising and marketing departments. Business analytics give marketing and advertising departments an intimate insight into target market needs and wants. These departments can then use data to make informed real world ad campaigns.\nNote-: Near real time data access optimizes real world decision making and organizational goal accomplishment.\nOnline employee scheduling software that makes shift planning effortless.\nTry it free for 14 days.\nDisadvantages of Business Analytics\nA lack of communication and data quality are potential disadvantages of business analytics. An organization that utilizes outdated hierarchical information sharing business practices will likely have issues with business analytics effectiveness. A proper analytics program necessitates outstanding communication regarding data.\nLow data quality is a significant issue in business analytics. Input from a well trained business analyst and data scientist can help organizations identify business problems with data quality. High quality historical data and business data should be accessible to staff members. Additionally, businesses must properly train employees in regard to data. This includes differences like analytics vs data and data analytics vs data analysis. Business school online courses offer business analytics program options for organizations to send their employees to.\nBusiness school online courses offer executive education analytics program options for working professionals.\nThe Relationship Between Business Analytics and Business Intelligence\nUnfortunately, business intelligence and business analytics are oftentimes used interchangeably incorrectly. In actuality, business intelligence encompasses both data analytics and business analytics. Business intelligence is a process that collects, stores, and analyzes business operations data. Business intelligence is a powerful data management solution utilized to better understand historical data and near real time data. The objective of business intelligence is to generate actionable insights. Understanding the relationship between business intelligence and business analytics is crucial.\nSimilarities and Differences of Business Intelligence and Analyticsi\nA significant difference between business analytics and business intelligence is the questions they aim to answer. Business intelligence answers how and what while business analytics answers why. Business analytics is predictive analytics focal while business intelligence is descriptive analytics focal. Real world application of business analytics and business intelligence is helpful to examine. For example, business intelligence identifies an increase in product sales while the reason why is determined through business analytics.\nHow to Manage Business Analytics for Growth\nManaging business analytics properly is essential for optimal organizational growth, success, and bottom line profitability. However, even an experienced business analyst or data scientist professional can struggle to manage big data and analytics. There are various best practices that enterprise level business professionals can utilize for different business analytics purposes including for-\nA failure to properly track financial data is the source of many business problems and failures. Key financial metrics ranging from business expenses to company revenue are crucial to a business's overall fiscal health. Business analytics supply comprehensive financial information that can also be incredibly specific. For example, various key financial metrics can be categorized by department or even by an individual employee.\nTip-: Business analytics supply an organization with a comprehensive view of its fiscal health.\nStellar sales metrics provide businesses with a wealth of valuable information. Business analytics can supply historical data and near real time data for everything from customer conversion to acquisition rates. Analytics benefits business sales representatives by indicating upcoming opportunities in addition to suggested actionable insights.\n3. Project management\nMany organizations consider project management productivity as a top priority. Benefits business analytics offer project management include task and time management monitoring. Too often, tasks are overlooked during projects, especially with many different team members working on various tasks simultaneously. Task management analytics increases accountability and encourages team members to stay on track. Task management analytics supply historical data and near real time data insights for even further optimized future project management.\nTime management monitoring allows businesses to track exactly how much time is spent on each task. Accurate data analysis enables businesses to adjust project scopes and manage timeline expectations. As a result, project estimates and proposals supplied to future clients will be more accurate.\nKey Takeways of Business Analytics\n- Business analytics is an incredibly useful business intelligence subcomponent that offers a wide variety of benefits when properly utilized.\n- The 4 types of business analytics include descriptive, predictive, diagnostic, and prescriptive analytics.\n- Business analytics can optimize various business operations subsections ranging from financials to project management."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:6e425f97-606c-42c9-ae03-c192718f8858>"],"error":null}
{"question":"How much did the Airbus A300-600 weigh when it landed back at Heathrow, and was this within normal limits? 🤔","answer":"The aircraft landed at 368,000 lb, which exceeded the normal maximum landing weight of 308,700 lb. However, overweight landings were permitted in emergencies up to the maximum take-off weight of 378,590 lb.","context":["|Title:||Oil filter clog, Airbus A300-600, N70072|\n|Micro summary:||Oil filter clog light illuminated on climb, triggering diversion.|\n|Event Time:||1998-07-09 at 1145 UTC|\n|Publishing Agency:||Aircraft Accident Investigation Board (AAIB)|\n|Publishing Country:||United Kingdom|\n|Site of event:||Climb|\n|Departure:||London Heathrow Airport, London, England, United Kingdom|\n|Destination:||General Edward Lawrence Logan International Airport, Boston, Massachusetts, USA|\n|Airplane Type(s):||Airbus A300-600|\n|Type of flight:||Revenue|\n|Executive Summary:||The crew were operating a scheduled flight from London Heathrow (LHR) Airport to Logan International Airport, Boston, USA; the weather was good with a light south westerly surface wind for take off. There were no significant defects in the technical log and the aircraft appeared fully serviceable during the external and pre-start checks. Both engine starts were normal and the commander taxied out to Runway 27 Left. He was the handling pilot for the sector and used reduced power for a normal take off at 1137 hrs. |\nEverything appeared serviceable during the take off and initial climb but, as the aircraft climbed through Flight Level (FL) 100, the first officer saw the right 'Oil Filter Clog' caution light illuminate and reported this fact to the commander. Initially, the light flickered on and off, as did the indication on the Electronic Centralised Aircraft Monitor (ECAM). However, after a short time, both the 'Oil Filter Clog' light and the ECAM indication remained on and steady. The crew checked the other engine indications but they were all normal; additionally, there were no asymmetric handling indications and no abnormal vibration. With clearance from ATC, the commander levelled N70072 at FL 150. Then, with the caution still indicating, the commander instructed the first officer to action the appropriate emergency drills. Initially, this required the No 2 throttle to be retarded to a position at which the caution light would go out. However, with the throttle at idle the light continually flickered on and off. Then, after 3 minutes at idle, the 'Oil Filter Clog' light was on and steady and the commander, in accordance with the emergency drills and in consultation with the first officer, decided to shutdown No 2 engine. With the commander retaining handling duties, the first officer actioned the appropriate drills.\nAfter the drill was completed, the crew declared an emergency to ATC and stated that they wished to return to LHR; they were given full co-operation by ATC. Then, with the aircraft established back towards LHR, the commander briefed the purser on the situation and of his intentions, and informed the passengers. The recovery was uneventful and the aircraft landed on Runway 27 Right at LHR at 1230 hrs. The LHR emergency vehicles had been alerted by ATC and had pre-positioned on the taxiway adjacent to the western end of the runway.\nThe aircraft weight on landing was 368,000 lb and the crew used a configuration of Slat 15/ Flap 20 with a Vref speed of 166 kt. Normal maximum landing weight is 308,700 lb but, with no fuel jettison system, overweight landings are permitted in an emergency at any weight within the maximum take-off weight of 378,590 lb. For the landing, the crew had preselected the autobrakes to the 'LO' setting, thereby selecting a deceleration rate of 1.7 m/sec2. The crew assessed the touchdown as smooth, at less than 300 feet/min rate of descent and within 1,500 feet of the threshold; speed on touchdown was approximately 165 kt and the surface wind was reported as 240°/13 kt. On the ground, the first officer confirmed that the spoilers had deployed and the commander selected medium reverse thrust on the left engine. The crew recalled that the autobrake had disconnected following the commander's use of manual brake during the ground roll and the first officer then selected 'Brake Fans'. Neither crew member considered the retardation as excessive and, although the commander was confident that he could have turned the aircraft off the runway early, he allowed it to roll to the last exit. As N70072 was turned off the runway, ATC advised the crew that there were no visible problems and transferred them to the Airport Fire Service (AFS) frequency; as they cleared the runway, the crew noted that the left brake temperatures were normal but that all four right brake temperatures were indicating at the gauge maximum of 700°C.\nOnce clear of the runway, the crew brought the aircraft to a halt, established contact with the AFS and informed the fire officer of the brake temperature indications. The fire officer confirmed that there was smoke coming from the right main landing gear area and asked the commander to keep N70072 stopped and to shut down the left engine to allow the AFS unhindered access to the aircraft. Shortly afterwards, the fire officer reported to the crew that there was a small fire in the area of the right gear but that it was under control. The commander confirmed with him that there was no need to evacuate but then briefed the purser and asked her to be prepared to react quickly if the situation changed. Thereafter, the flight crew maintained a close liaison with the AFS and the cabin crew. The AFS used water to cool the brakes and stayed in attendance until the passengers had disembarked normally through door 4L using portable steps.\n|Learning Keywords:||Operations - Evacuation|\n|Operations - Maintenance|\n|Systems - Brake/Tire/Wheel Well Fire|\n|Systems - Engine - Contained Engine Failure|\n|Systems - Landing Gear|\nAccident Reports on DVD, Copyright © 2006 by Flight Simulation Systems, LLC. All Rights Reserved. All referenced trademarks are the property of their respective owners.www.fss.aero"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:ace05475-f51a-44a2-a4f7-f1c498c78ab1>"],"error":null}
{"question":"How do environmental factors affect both ladybug infestations and remote work security risks in residential settings?","answer":"Environmental factors significantly impact both issues in residential settings. For ladybugs, weather conditions influence their behavior, with beetle flights being heaviest on sunny days following cooler weather, particularly when temperatures return to the mid-60s, with most activity occurring in the afternoon. As for remote work security, environmental factors in homes can create unique risks - children and pets can accidentally compromise security by interfering with unattended computers or devices. Additionally, both issues require careful consideration of home infrastructure - sealing entry points is crucial for preventing ladybug infestations, while secure home networks and proper device protection are essential for maintaining cybersecurity in residential work settings.","context":["From the hills of southern Appalachia to the Canadian border, there is a bizarre invasion conquering the land. Not the invasion of a foreign army with legions of militant soldiers, but swarms of tiny beetles, complete with red backs and black spots, affectionately known as ladybugs.\nAcross the nation these otherwise cute and harmless creatures are being spotted blanketing the sides of vehicles, penetrating the interiors of homes and swarming in large mass throughout residential areas.\nWe turned to the University of Kentucky’s College of Food & Environment for answers and quickly realized there was a lot we still had to learn about these creatures we all remember from our childhood.\nFor starters, the ladybugs you’re seeing today are probably not the same ones you remember from your childhood: Though ladybugs are native to North America, in 1916 wildlife officials attempted to establish a non-native species of ladybugs, the Asian Ladybeetle (Harmonia axyridis) which they believed would be more effective in controlling aphid populations.\nInitially, this Asian species was believed to have failed in establishing a population on the North American continent; however, in 1988, some seventy-years later, a population of the Asian beetles was observed in the wild near New Orleans, Louisiana. Many scientists believe this particular species of ladybugs were unintentionally released into the country via a contaminated freighter at the port of New Orleans.\nIn the years that followed, the population of the Asian ladybeetles quickly spread to other states and even succeeded in driving out native ladybugs.\nAccording to the University of Kentucky, large numbers of ladybugs infesting homes and buildings in the United States were first reported in the early 1990s, on the heels of the Asian ladybeetle outbreak.\nBy 1992 the Asian Ladybeetle was working to establish a population in central Appalachia and since then, each year around late-October ever growing swarms of these Asian ladybugs can be spotted infesting homes and buildings in the United States in an attempt to secure an overwintering site indoors.\n“As autumn approaches, the adult beetles leave their summer feeding sites in yards, fields and forests for protected places to spend the winter. Unfortunately, homes and buildings are one such location. Swarms of lady beetles typically fly to buildings in September though November depending on locale and weather conditions. In [Central Appalachia], most migration to buildings occurs in October. Beetle flights are heaviest on sunny days following a period of cooler weather, when temperatures return to at least the mid-60s. Consequently, most flight activity occurs in the afternoon and may vary in intensity from one day to the next… Once inside they crawl about on windows, walls, attics, etc., often emitting a noxious odor and yellowish staining fluid before dying,” states the university.\nTheir proximity to October 31 has given these Asian beetles a unique name, “The Halloween Ladybugs”.\nScientists at UK say Asian lady beetles generally do not injure humans and are mainly a nuisance. Unlike some household pests (e.g., fleas and cockroaches), they do not reproduce indoors — those appearing in late winter/early spring are the same individuals that entered the previous fall. Lady beetles do not attack wood, food or clothing.\nAlthough Asian lady beetles do not transmit diseases per se, recent studies suggest that infestations can cause allergies in some individuals, ranging from eye irritation to asthma.\n“Asian lady beetles are also becoming a concern of the wine industry. Due to their noxious odor, even small numbers of beetles inadvertently processed along with grapes can taint the flavor of wine.”\nResidents wishing to remove ladybugs from their homes are encouraged to vacuum them; however, most agree that the greatest way to curb their entry is to ensure that all areas of the home are properly sealed so that there are no entry points for them to infiltrate.\nThough the autumn swarms of the Asian ladybugs are a severe nuisance for many, scientists typically agree that the Asian invasion of the beetle is largely a blessing, as their diet primarily consists of aphids which destroy forests and soybeans. This particular species of ladybugs are believed to have saved American farmers vast sums of money.\nDo you like articles like this? If so, click here to learn more about receiving a year’s subscription of the print edition of Appalachian Magazine!\nShare this article with your friends on Facebook:","Everyone's working remotely these days, yet security risks remain. Here are 10 ways you can combat online security threats.\nShare this article\nThere can’t be many businesses today that don’t use remote working to some extent throughout the working day. Even those without a culture or need to offer remote working will have employees or directors taking work home, or working from hotel suites, conference venues and public transport at times.\nThis more casual form of remote working, one that may not be accounted for when analysing how business IT networks are used, is often missed in cyber security policies and procedures. However, it is one important factor that can put organisations at risk of cyber attacks and data breaches.\nRemote working, whether a formalised arrangement between a business and an employee, or an ad hoc ‘needs must’ requirement to get work done, can leave your business IT network, systems and devices vulnerable.\nThe first step for managing security and remote workers is to understand where your business is at risk. This should be followed with an awareness raising campaign within the organisation so that all employees understand how their actions may compromise security and what steps they must take to protect company networks and systems.\nCyber security policies need to include the specific risks associated with remote working, with procedures and guidance in place for working away from the office. This will also need to explain what actions need to take place if a remote worker believes they have exposed the company to a cyber attack, and any disciplinary measures that may be taken.\nThe following top tips provide an excellent starting point:\n1. Keep mobile devices and laptops safe\nLost and stolen mobile devices and laptops are easy pickings for cyber criminals if insufficient security measures are in place. The first line of defence is to look after these business assets: keep them with you and in sight at all times, and never leave them in hotel safes, cars etc.\nNext up is securing the devices themselves with good password hygiene and encryption on laptops. Finally, installing mobile device management apps such as AirWatch and MaaS360 give employees a chance of securing and recovering lost mobiles or tablets.\nRemember: it's not just cyber crime that can disrupt your IT\n2. Excellent password hygiene\nStrong passwords will not only protect your devices and systems being accessed if a mobile or laptop is lost or stolen, they also protect businesses from hackers. Good password hygiene includes using long passwords with multi-characters, two-step authentication processes, and unique passwords for different systems and logins.\n3. Ensure up-to-date security protection is in place\nAny devices that are owned by the organisation should be properly protected with antivirus, web filtering, firewalls, device encryption and other preventative software, but so too should your employees’ own devices if they are using them for remote working.\nThis can be a difficult area to negotiate as your employee may feel this impinges on the personal use of their device: Your cyber security policies will need to address issues like these, either restricting staff from using their own devices for certain business critical activities, providing secure company owned devices, or making your cyber security protection mandatory.\n4. Use of public wifi\nPublic wifi can be vulnerable to malicious attack, presenting issues for those employees who may need to work from a hotel or conference. While it is good advice to only connect to trusted networks this is not always feasible.\nTherefore, your remote working / cyber security policy should stipulate that employees should not use public wifi for any sensitive, business critical activities. It is advisable to draw up some guidelines that explain what systems and activities staff can and cannot access when using public wifi.\n'Quick question Dave: where's all our money gone?\n5. Email encryption and best practice\nEmail is perhaps the most used digital technology by staff members who are away from the office, and one that can open a backdoor to cyber criminals. Encryption and robust management of corporate email is a must.\nThe installation of applications such as Mimecast is a no brainer, but raising awareness of the vulnerabilities of email will also help embed best practice in your organisation. This can include training in spotting cyber threats like phishing emails, and also policies on what information should not be communicated in an email – for example logins and passwords.\n6. Using public computers\nWhile the majority of people will have their own laptop or mobile device that they use for remote working, occasionally someone may need to use a public computer such as in a business suite in an airport.\nEmployees should be aware of the security implications of this and adhere to the following guidance: keep screens private (position them away from other people), don’t use public computers for any sensitive information, use ‘private browsing’ where possible, never use ‘remember me’ or ‘save information’, and clear your browsing history and delete any downloads before closing the browser.\n7. Using devices when out and about\nEmployees should also be aware of physical threats when using devices when in public places like cafes, hotels, airports etc. Just as you would hide your PIN when using an ATM, employees should be discreet when keying in passwords and logging into systems.\nThey should also be aware of the risk of snooping and eavesdropping, not just online, but also from other people in the vicinity. Can someone see and potentially grab a discreet photo of company sensitive information while they work in a public space?\n8. Removable devices\nUSB sticks and other removable devices can be a source of malware and should be checked first. Many conferences hand out USB sticks that may be infected, often unbeknown to the organisers. Also don’t allow anyone to plug in a USB device into your computer, for example to share information in a meeting. Always get your IT department to security check removable devices.\n9. Monitoring and policy enforcement\nTwenty four-seven network monitoring and security will help your organisation identify threats and monitor users on your networks. Remote workers and their mobile devices can be monitored using this solution to protect your organisation’s network.\n10. Negligence and accidental risks in the home\nEven when your employees are working from home using your secure VPN, VDI or remote desktop, there can be other risks that need to be considered. Children and pets can be a surprising threat.\nCats have a habit of jumping on computer keyboards and inquisitive minds might press a few keys when a laptop is unattended. These kinds of risks should be addressed in your remote working / security policies to ensure that your staff take every feasible step to protect your systems at all times."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:7f43d9a0-264f-460a-aefd-d15eb3820ff1>","<urn:uuid:02598588-2ea6-4379-b2e0-6b47df581446>"],"error":null}
{"question":"¿Cuál fue la base legal para las decisiones judiciales en los casos de Khayelitsha y Grace Mugabe? ¿En qué se diferencian? 📚","answer":"The Khayelitsha case was decided based on equality and discrimination grounds, with the Equality Court finding that SAPS' resource allocation system unfairly discriminated against Black and poor people. The Grace Mugabe case was decided based on constitutional and international law principles regarding diplomatic immunity, with the High Court ruling that there was no customary international law norm granting immunity to spouses of heads of state and that the Minister's decision violated the Constitution and Foreign States Immunities Act. While both cases involved constitutional issues, they relied on different legal frameworks - equality law for Khayelitsha and diplomatic immunity law for Mugabe.","context":["Case CCT 121/21\n ZACC 27\nHearing date: 03 February 2022\nJudgement Date: 19 July 2022\nPost Judgment Media Summary\nThe following explanatory note is provided to assist the media in reporting this case and is not binding on the Constitutional Court or any member of the Court.\nOn Tuesday, 19 July 2022 at 10h00, the Constitutional Court handed down judgment in an application for leave to appeal and direct access to this Court seeking a declaratory order that the Equality Court of South Africa, Western Cape Division, Cape Town (Equality Court) has constructively refused to grant the Social Justice Coalition (applicants’) a remedy.\nIn 2003, the Safety and Justice Campaign was launched by the Treatment Action Campaign (TAC) to end the scourge of violent crime in townships around Cape Town.\nIn November 2011, the applicants’ and others lodged a formal complaint with the Premier of the Western Cape and this led to the establishment of the Khayelitsha Commission of Inquiry (Commission). Some of the respondents challenged the legality of the decision to establish the Commission and the power of subpoena it had been granted. The Social Justice Coalition (SJC) opposed the challenge, and on 1 October 2013, the challenge was rejected by this Court in Minister of Police v Premier of the Western Cape.\nDuring the period of January to May 2014, the Commission held public hearings recording the testimony of dozens of witnesses, which included members of the community affected by crime; experts in various aspects of policing (including that of Ms Jean Redpath); and members of the South African Police Services (SAPS). The Commission also considered affidavits received from hundreds of residents of Khayelitsha expressing their concerns about the lack of effective policing in Khayelitsha. SAPS’ evidence before the Commission explained that the theoretical determination of the number of police officers and was based on a model called the Theoretical Human Resource Requirement (THRR) which had remained unchanged by SAPS since 2002 and was described by the Commission as being “irrational”, based largely on the testimony of expert witness, Ms Redpath.\nIn August 2014, the Commission concluded that there were widespread inefficiencies in policing in Khayelitsha and there was a breakdown of relationships between the police and the community. Importantly, the Commission found that SAPS’ system for allocating police resources was systematically biased against poor, Black communities, resulting in the under-staffing of police stations which serve the poorest areas in Cape Town.\nThe Commission made various recommendations and they included that the Minister request the National Commissioner to appoint a task team to investigate the system of human resource allocation within SAPS as a matter of urgency. It also recommended that the Western Cape Police Commissioner (Provincial Commissioner), allocate additional uniformed police to the three Khayelitsha police stations to enable regular patrolling of informal settlements.\nFollowing the release of the Commission’s report, the SJC and Equal Education (EE), the second applicant, sought to engage with SAPS, the Minister and the National Commissioner on the implementation of the Commission’s recommendations but without success. The SJC and EE then decided to litigate in order to address the serious imbalance in policing resources found to exist by the Commission.\nIn March 2016, the applicants approached the Equality Court to seek declarators; that police resources in the Western Cape unfairly discriminated against Black and poor people; that the system employed by SAPS to determine the allocation of police resources unfairly discriminated against Black and poor people on the basis of race and poverty; and that the Provincial Commissioner had the power to determine the distribution of police resources between stations within the province, as envisaged in section 12(3) of the South African Police Services Act.\nThe fifth respondent, the Women’s Legal Centre Trust (WLCT), was admitted as amicus curiae. It supported the applicants contentions, and advanced submissions on the effect that under-resourced policing areas had on the extent and incidence of gender-based crimes.\nThe respondents opposed the application in the Equality Court and took the view that the relief sought by the applicants was “far-reaching”. They denied that the THRR was racially discriminatory in its application and said that the allocation process was subject to regular and annual reviews, was dynamic, evolving, and multi-faceted.\nThe Equality Court, in its judgment delivered on 14 December 2018, declared that the system employed by SAPS to allocate human resources in the Western Cape unfairly discriminates against black and poor people on the grounds of race and poverty. The Court refused to grant the full extent of the national relief sought by the applicants on the grounds that the evidence before it was only sufficient to support the finding relative to the Western Cape. It further declined to grant the relief sought by the WLCT, that the unfair discrimination challenged in the proceedings was also based on gender. The hearing on remedy was postponed to a date to be arranged with the parties and that has ultimately led to this application before this Court.\nThere was an appeal and a cross appeal filed against the order of the Equality Court by SAPS against the main order and by the SJC and the other applicants against the refusal of national relief. Following negotiations between the parties, their respective applications to appeal and cross appeal to the Supreme Court of Appeal were withdrawn.\nThe parties attempted to reach an agreement on the appropriate remedy but no settlement on remedy could be reached. On 18 September 2019, the applicants requested the Equality Court to set the matter down for hearing on remedy as was contemplated by the Equality Court.\nThere was ongoing engagement between the parties and the Equality Court and, on 23 June 2020, the parties were advised by the Equality Court that the remedy would be determined on the papers on 11 August 2020. On 8 September 2020, the parties were informed by the Equality Court that one of the presiding officers was unavailable at the time as a result of an acting appointment in the Supreme Court of Appeal. The parties were then provided with the following options: (a) await the return of the presiding officer the exact date of which could not be confirmed; (b) have the question of remedy determined by a fresh Bench; or (c) have the remedy determined by one of the remaining presiding officers and a new Judge. The applicants preferred the third option while the respondents preferred the first option. The applicants thereafter wrote various letters to the Equality Court and the Judge President seeking the enrolment of the matter to determine remedy but say there was no response to their correspondence, which led them to bringing these proceedings in this Court.\nThe determination of the remedy remained outstanding from December 2018 when the judgment of the Equality Court was delivered. In April 2021, this application was launched.\nThe first judgment (minority), penned by Kollapen J held that this Court’s jurisdiction is engaged. The first judgment relied on Minister of Health v New Clicks South Africa (Pty) Ltd (New Clicks CC) for the proposition that an unreasonable delay in dealing with an application for leave to appeal interferes with the right of access to courts. The first judgment raised the question that at the level of principle what arose in this matter, was whether an unreasonable delay in incomplete proceedings may similarly constitute an interference with the right of access to courts, and may justify the order of a constructive refusal.\nThe first judgment undertook an overview of a number of substantive and procedural rights that all related to access to courts, as well as the inherent and remedial power of this Court. The first judgment held that, like New Clicks CC, this matter implicates the scope and content of the right of access to courts. The right of access to courts contained in section 34 is significant in that it represents an enabling right to access a court to have a justiciable dispute decided. It explained that the right to access to court was ultimately about the right to approach a court, initiate a case in support of a justiciable dispute and then to secure a decision and a remedy on the dispute. All of this was to be determined in a fair public hearing.\nIt further held that section 39(2) of the Constitution reminds us that when interpreting the Bill of Rights, a court must promote the values that underlie an open and democratic society based on human dignity, equality and freedom, all of which point compellingly in the direction that section 34 is binding on the judiciary. It concluded that the effect of an unreasonable delay on the part of a court that results in the infringement of the right of access to court must then give rise to a need for an effective remedy to bring the infringement of the right to an end.\nRegarding whether section 173 of the Constitution provides a basis for this Court to interfere in the process of another Court, the first judgment explained that this Court, has in terms of section 29 of the Superior Courts Act, and rule 19(2) of the Rules of this Court, the appellate power to hear appeals directly from other courts on constitutional matters. It held that this Court has the power to consider appeals before it without the leave of another court first being obtained. That said, the first judgment held that if there is an unreasonable delay on the part of another court in determining proceedings before it, this Court must equally be entitled to use its inherent power to enable it to exercise its appellate jurisdiction.\nRegarding the delay by the Equality Court to grant the applicants a remedy, the first judgment explained that judicial delay in either convening a hearing or in delivering a decision in itself threatened the independence and the integrity of the judicial function and the judicial authority. It explained that when a court intervenes to address judicial delay, its objective is to protect the integrity and the independence of the judiciary and of all courts, rather than to imperil the relationship between courts. For these reasons, the first judgment found that this Court does have the jurisdiction to make the declaratory order and that there was a constructive refusal of a remedy in the proceedings before the Equality Court.\nIn respect of the urgency of the issue, the first judgment held that ending unfair discrimination against communities that have faced the brunt of apartheid inequality for centuries cannot ever be anything but urgent. It said that the delay in granting a remedy will continue to cause prejudice in addressing the matters of safety and security for poor and Black communities in the Western Cape. That prejudice, according to the first judgment, will exist in how people are able to live, to work, to play, to learn or simply to express their humanity under the constraints that living in an unsafe environment brings.\nThe first judgment held further that there was a proper case made out for the granting of the declarator and concluded that it had the necessary jurisdiction to hear the appeal, that the interests of justice supported the granting leave to appeal and that there were good prospects of success. In the result, the first judgment held that leave to appeal must be granted to the applicants and that a proper case has been made out for the declaratory order sought by the applicants.\nRegarding the issue of remedy, the first judgment found that a remittal would be appropriate as evidence may well be required for a proper determination of remedy. Given the history of the matter, there may be a need to suggest timeframes on when the Equality Court deals with the matter so as to avoid any further delays.\nThe first judgment concluded that in all the circumstances, it would be just and equitable to remit the matter to the Equality Court and request the Judge President of the Western Cape High Court to constitute a Bench that will hear the outstanding issue of remedy within 90 days of this order, and to issue directions with regard to the filing of written submissions, expert evidence or any other matter relevant for the hearing to be convened as the Judge President may deem fit.\nThe second judgment (majority), penned by Unterhalter AJ (Madlanga J, Majiedt J, Mathopo J, Mhlantla J, Theron J and Tshiqi J concurring) disagreed with the first judgment that this matter engaged this Court’s jurisdiction. In particular, the second judgment differed with the conclusion reached by the first judgment that this Court, having derived its powers from the broad remedial powers contemplated in section 172(1) of the Constitution, enjoys the power to entertain an application for leave to appeal from the Equality Court, where that Court failed to make a decision.\nThe second judgment held that until the Equality Court issues an order, the case remained pending before it, and the power to decide the case remained with that Court. Absent such an order, this Court’s appellate jurisdiction was not engaged.\nIt reiterated the Appellate Division’s decision in Heyman v Yorkshire Insurance Co. Limited that an appeal lies from the order of the court below. Furthermore, it referred to rule 19(2) of this Court’s Rules which gives effect to section 167(6)(b) of the Constitution. In terms of this rule, there must be a litigant who has been aggrieved by a decision of a court. Without the decision of a court, no appeal can lie to this Court, and this Court shall enjoy no jurisdiction to entertain such an appeal.\nThe second judgment found that the applicants were attempting to escape this jurisdictional obstacle by seeking declaratory relief from the Constitutional Court that the failure by the Equality Court to take a decision should be taken to constitute a refusal of a remedy by that Court. To grant such declaratory relief would deem a decision to have been taken by the Equality Court. It required this Court to make a substantive order of the Equality Court, that is, to make a decision that no remedy is granted to the applicants. The second judgment found this to be an order of extraordinary reach. It held that this Court would be required to make a decision for another court, in a case pending before that court, on the basis that this other court refused relief to the applicants, when in fact it made no such order. This Court has no such power in terms of the Rules of this Court. This power is also not found in the Constitution.\nThe second judgment went on to differentiate between the present case and New Clicks CC. It held that in New Clicks CC, this Court recognised that superior courts have an inherent power to regulate and protect their own processes, and in the exercise of this power, they can decide whether to grant leave to appeal based upon a constructive refusal of leave by the lower court. However, New Clicks CC does not hold that the inherent power of an appellate court to regulate its own processes extends to making decisions for other courts in pending proceedings before those courts. That would accord powers to an appellate court to regulate the processes of other courts, which is not a power given to appellate courts, including this Court under section 173.\nIt agreed with the first judgment that judicial officers owe duties to those who enjoy the right of access to the courts in terms of section 34 of the Constitution. However, it found that a litigant’s section 34 rights do not allow them to bypass a competent court when seeking relief. This, according to the second judgment, was the error from which the first judgment proceeded. It found that it would be contrary to the scheme of the Constitution if the court that is expressly given the power to regulate its own processes and thereby fulfil its duty under section 34 was not the competent court, in the first instance, approached by the parties for relief. This would conflict with the principle of comity between the courts and would have far-reaching consequences. According to the second judgment, this Court would be assuming an original jurisdiction to entertain hundreds of applications to supervise the many ways in which litigants may complain that other courts are failing to carry out their duties under section 34. It found that this could never have been contemplated in terms of section 38.\nThe second judgment concluded that this Court was not competent to enforce the duties of the Equality Court by giving the applicants access to that Court when no application had been made to the Equality Court to do so. It held that this Court may only exercise the remedial powers given to it in section 172 if it has jurisdiction. It disagreed with the first judgment’s proposition that if a remedy is required to make good an infringement of rights, this Court enjoys jurisdiction. In this respect, it found this approach to be a reverse engineering of jurisdiction and an untenable interpretation of the Constitution.\nIn the result, leave to appeal was refused for lack of jurisdiction. No order was made as to costs.\nThe Full judgment here","Democratic Alliance v Minister of International Relations and Co-operation and Others; Engels and Another v Minister of International Relations and Co-operation and Others,  ZAGPPHC 534\nCourt: High Court of South Africa (Gauteng Provincial Division, Pretoria)\nDate of judgment: 30 July 2018\nOn 30 July 2018, the High Court of South Africa (Gauteng Provincial Division, Pretoria) (the High Court) declared that the decision taken by the Minister of International Relations and Co-operation (the Minister) to confer immunities and privileges on Dr Grace Mugabe as the spouse of the then President of Zimbabwe, Robert Mugabe, was inconsistent with the Constitution of the Republic of South Africa, 1996 (the Constitution). Accordingly, the decision was reviewed and set aside.\nOn 13 August 2017, the then First Lady of Zimbabwe, Dr Grace Mugabe, travelled to South Africa during the Ordinary Summit of the Heads of State of the Southern African Development Community (SADC). On the same day, Dr Mugabe is alleged to have assaulted three young South African women at a hotel in Johannesburg, including Ms Gabriella Engels who subsequently laid a criminal charge of assault with intent to cause grievous bodily harm against Dr Mugabe.\nThe alleged assault garnered widespread public exposure. The South African Police Services (SAPS) made attempts to contact Dr Mugabe, including through her legal representatives, in the hope that she would present herself to SAPS officers. However, on 15 August 2017, Dr Mugabe left South Africa.\nA note verbale sent by the Embassy of Zimbabwe (the Embassy) to the Department of International Relations and Co-operation (the Department) indicated that Dr Mugabe travelled to South Africa on a diplomatic Zimbabwean passport, and that “[t]he Embassy wishes to invoke diplomatic immunity for [Dr Mugabe] in a case opened against her at the Sandton Police Station and requests protection from authorities in South Africa against arrest and prosecution.” Later that day, the Embassy forwarded another note verbale to the Department, indicating that it wished to withdraw the first one. The second note verbale stated that: “[Dr Mugabe] travelled to South Africa on 13 August on flight SA29 as part of the Advance Team of the Official Delegation … to the [SADC] Summit from 11 to 20 August 2017”, and persisted with its call for the “necessary protection from arrest and prosecution” for Dr Mugabe. Of particular relevance, the difference between the first and the second is that, in the latter, the Embassy claimed that Dr Mugabe was visiting South Africa on official duties.\nOn 16 August 2017, the Department informed the Embassy that the request for diplomatic immunity for Dr Mugabe was receiving due consideration by the South African government. The Department also wrote to the Acting National Commissioner of SAPS (Acting National Commissioner), informing him that as the Embassy had invoked diplomatic immunity protection in favour of Dr Mugabe, the Department was considering all legal issues “in consideration of the conferral of diplomatic immunity as invoked”, and sought certain information from the Acting National Commissioner about the allegations against Dr Mugabe.\nOn 18 August 2017, the Acting National Commissioner responded, and indicated that a prima facie case existed against Dr Mugabe, but that the investigation was still incomplete and the Director of Public Prosecutions had not made a decision on whether a prosecution would be instituted.\nOn 19 August 2017, the Department informed the Embassy that “after considering all the relevant facts and circumstances”, the Department had decided to “confer immunities on the First Lady, Dr Grace Mugabe”. Simultaneously, it alerted the Acting National Commissioner to the Minister’s decision to confer on Dr Mugabe the privilege of diplomatic immunity from criminal prosecution in terms of section 7(2) of the Diplomatic Immunities and Privileges Act, 2001 (DIPA). In light of this, SAPS ceased to investigate the allegations against Dr Mugabe.\nOn 20 August 2017, the Minister published the decision in the Government Gazette. The decision was conveyed in a Minister’s Minute (the Minute), as well as a Government Notice (the Notice). Both indicated that the Minister relied on her powers derived from section 7(2) of DIPA, and that the immunities and privileges conferred upon Dr Mugabe were in terms of international law.\nJudgment of the High Court\nAccording to the Minister, Dr Mugabe automatically qualified for immunity from prosecution by virtue of her status as a spouse of a head of state. Furthermore, the Minister was of the view that it was in the national interests of South Africa that such immunity be conferred on Dr Mugabe in terms of section 7(2) of DIPA. The issues before the High Court were therefore two-fold: (i) did Dr Mugabe enjoy immunity – specifically, personal immunity (or immunity rationae personae) – for the alleged unlawful acts by virtue of being a spouse of a head of state; and (ii) if not, was the decision of the Minister to confer or grant immunity to Dr Mugabe constitutional and lawful? In light of the conclusion reached by the High Court on (i), it was unnecessary for the High Court to conduct an analysis of (ii).\nThe High Court noted that the South African position is that the executive is constrained by the Constitution and national legislation enacted in accordance with the Constitution. Accordingly, in terms of the Constitution, the executive can only grant immunity rationae personae to an official from a foreign state if such immunity is derived from one of the following: (i) a customary norm that is consonant with the prescripts of the Constitution; or (ii) the prescripts of an international treaty which is constitutionally compliant; or (iii) national legislation which is constitutionally compliant. As noted by the High Court, a decision to grant immunity to a foreign state official that does not fall into one of the three categories will not withstand the test of legality, rationality or reasonableness.\nFirstly, with regard to customary international law, the High Court reached the conclusion that there is no customary norm to the effect that the spouse of a head of state enjoys immunity from prosecution for the offence that Dr Mugabe is alleged to have committed. In particular, the High Court could not find evidence of this being a general practice accepted as law by a majority of states.\nSecondly, the High Court had regard to the Foreign States Immunities Act, 1981 (FSI), which is the national legislation that speaks specifically to the issue of head of state immunity. In terms of section 6(a) of the FSA: “A foreign state shall not be immune from the jurisdiction of the courts of the Republic in proceedings relating to … the death or injury of any person”. As such, the High Court noted that in terms of section 6(a) of the FSI, former President Mugabe would not himself have enjoyed the immunity rationae personae had he been the one accused of perpetrating the alleged assault on Ms Engels, for such immunity has specifically been excluded by the FSI. Accordingly, even if the Minister were correct that customary international law provided immunity to the spouse of a head of state, this “derivative immunity” cannot exist if the primary immunity is non-existent. In sum, the High Court concluded that as former President Mugabe would not have enjoyed such immunity, neither could his spouse.\nLastly, the High Court addressed the Minister’s contention that the matter had become moot as former President Mugabe was no longer the head of state, and that the High Court should leave the matter to be dealt with by the Director of Public Prosecutions if Dr Mugabe returned to South Africa and sought to rely on the Minute that conferred immunities and privileges on her. However, as explained by the High Court, Dr Mugabe would still be entitled to rely on the Minute as this was an administrative act, and administrative acts remain in force until set aside by a competent court even if such act was illegal or improper. The High Court noted further that, following the proceedings before it, it was both well-placed and duty-bound to make a determination on the issues before it. As explained by the High Court:\nIn these circumstances leaving the matter for the criminal court, should Dr Mugabe be prosecuted, would be a most inefficient use of scarce judicial resources. It has to be deprecated. Further, should the prosecution of Dr Mugabe proceed there is no guarantee that it would occur in the High Court, which is the court competent to review and set aside the decision of the Minister. In which case the criminal proceedings would be delayed pending a determination in the High Court on the very issue that this Court could have and should have made a determination on in the first place. In a word, the issue is not moot and the invitation to defer the matter to another court is declined.\nIn conclusion, the High Court held that by recognising the said immunity, the Minister committed an error of law that was fundamental and fatal to the decision taken by the Minister, and therefore the decision stood to be reviewed and set aside. As stated by the High Court: “I conclude that Dr Mugabe is not immune from the jurisdiction of our courts and the Minister’s decision to ‘recognise’ or ‘confer’ immunity upon her was unconstitutional and unlawful. The Notice therefore stands to be set aside so that our courts’ power to administer justice in the matter is not constrained by any procedural bar.”\nOrder of the High Court\nThe order of the High Court read as follows:\n“1. It is declared that the decision of the Minister of 19 August 2017, in terms of s 7(2) of the Diplomatic Immunities and Privileges Act 37 of 2001 to recognise Dr Grace Mugabe immunities and privileges as published in the Minister’s Minute in the Government Gazette of 20 August 2017, No 41056 Notice 850 (the decision) is inconsistent with the Constitution of the Republic of South Africa, Act 108 of 1996.\n- The decision is reviewed and set aside.\n- The Minister is to pay the costs of the applicants in both cases which costs are to include those occasioned by the employment of two counsel.\n- The Minister is to pay the costs of one counsel for each of the amici.”\nThe full judgment is accessible here.\nPlease note: The information contained in this note is for general guidance on matters of interest, and does not constitute legal advice. For any enquiries, please contact us at [email protected]."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:466dd364-8221-4616-be92-c880f38205e8>","<urn:uuid:5d4db474-b60f-48e2-bc4c-cddfbdfef4b3>"],"error":null}
{"question":"As international student, I want to know about internship opportunities. What professional development options exist at Indonesian Embassy in Seoul, and what other international exchange programs are available?","answer":"The Indonesian Embassy in Seoul, located in Yeouido, works with the Indonesian Trade Promotion Center and Indonesian Investment Promotion Center to promote trade and investment opportunities. They participate in various exhibitions and business forums in South Korea. For international exchange programs, there are numerous opportunities including professional development programs that offer internships and training abroad. These include programs offering paid, course-related internships and training internationally, and various U.S. Department of State-funded professional exchange programs that provide emerging world leaders with internship opportunities and short-term visits for cultural immersion.","context":["페이지 정보기자 최고관리자 기자작성일 19-01-08 11:03\n[Sundaytimes=Chris Lee reporter]Indonesian Embassy is the only Embassy located in Yeouido and only 5 minutes away from National Assembly, or just across KBS Annex. Being located in center of Seoul, it makes our Embassy easy to reach.\nAs of September 2018, there are 38.509 Indonesians staying in South Korea, 89.1 % of them are migrant workers, 4,3 % of them are students and 6.4% are others including mix married and Indonesian Expatriates. Indonesians are also naturally born artists. They love and uphold their culture wherever they go. They occasionally gather among themselves and create some arts and cultural communities. They form cultural activates to connect them to their root. Few to mention are Reog (Dance from East Java demonstrating physical strength and extravagant lion-peafowl mask), Kuda Lumping (dance from central and west Java depicting a group of horsemen), Silat (traditional Martial Art), Campur Sari (crossover of several contemporary Indonesian music genres) etc. Some cultural groups have participated in events held by the Embassy or even get invited to perform in some multicultural events held by Korean Government or institutions such as Hi! Seoul, Guro Festival, Itaewon Global Village, Migrants Arirang Multicultural Festival and many more.\nIndonesian Embassy also facilitates and offers anybody who are interested to learn Indonesian arts and culture. Gamelan Class (traditional ensemble music from Java and Bali) and Indonesian Traditional dance class are open for free every Saturday.\nOther than a rich culture country, Indonesia is well known for its beauty of the nature. For promoting, those beautiful places, Indonesian Embassy cooperates with Visit Indonesia Tourism Office (VITO) in arranging various sales mission and familiarization trip and some other promotional events for Korean citizens, including media, vloggers, bloggers and other counterparts in tourism industry.\nBesides that, Indonesian Embassy also actively promotes Indonesian Trade and Investment potential. Through a synergy with Indonesian Trade Promotion Center (ITPC) Busan and Indonesian Investment Promotion Center (IIPC) in Seoul, Indonesian Embassy is working hard to increase trade value with South Korea up to 30 Billion USD on 2022 by participating in various exhibition in South Korea (Halal Trade Expo, Coffee Expo, Handmade Fair, Food Fair and else), and holding various business forum.\nAbove all of that, Indonesian Embassy believes that one of the key factor to tighten Indonesia – South Korea relationship is people to people exchange, especially the young generations of both countries. Therefore, Indonesian Embassy forms Korea-Indonesia Sahabat Sejati (KISS) (Korean – Indonesian True Friends) as a platform for millennial Koreans and Indonesians in Korea to take part in promoting relationship of the two countries. Members of KISS were especially invited to have a morning walk and chit chat with Indonesian President H.E. Mr. Joko Widodo in his State Visit to Korea last September.\nIn promoting Indonesia in South Korea and putting Indonesia in the heart of Korean people, Indonesian Embassy also has cooperation with various partners such as ASEAN-Korea Center, ASEAN Culture House, Korea Foundation and else. We also often receive invitation from schools or museums to give special lectures or short presentations about Indonesia. By doing so, we hope to reach more Korean to have better understanding about Indonesia. In line with this purpose, on January 24, 2019, in cooperation with National Museum of Korean Contemporary History, Indonesian Ambassador will give special lecture followed by movie screening. We hope you can participate on the aforementioned event.\n등록된 댓글이 없습니다.","We empower people to drive positive change in themselves, their organizations, and society.\nEvery year, we offer 30-plus exchange programs that facilitate dialogue and the sharing of ideas, and promote global understanding through the lens of career exploration, civic engagement, leadership development, and professional training.\nU.S. Internship, Trainee, and Teacher Exchanges\nJ-1 Visa sponsorship and services for educators to pursue teaching positions at U.S. primary and secondary schools\nJ-1 Visa sponsorship and services for students and professionals to pursue U.S. internships and training programs for up to 18 months\nIntern, Work Abroad, and Professional Fellowship Programs\nA fully-funded professional development program providing up to 18 accomplished young Americans, Britons, and Germans the opportunity to live abroad, study Russian and work at leading organizations in Moscow.\nA full year, work-study scholarship program providing students and young professionals with an understanding of everyday life, education, and training in Germany.\nA fully-funded summer internship affording underrepresented U.S. university students with the opportunity to intern abroad for eight weeks in Argentina, Germany, or Singapore.\nA reciprocal exchange program providing students in technical fields with paid, course-related internships and training abroad, and employers with highly skilled U.S. and international trainees.\nA fully-funded, 9-to-12 month professional development program in Germany for up to 15 accomplished young Americans to live abroad, study German, and gain experience in business, economics, journalism, law, and public policy.\nSpecialty Exchange Programs and Grant Initiatives\nEl PPPA es un programa de subvenciones financiado por el Departamento de Estado de los EEUU que patrocinará 4 proyectos…\nA U.S. Department of State-funded professional development program providing emerging leaders from Eastern Europe, the Caucasus, and Central Asia with summer internships to enrich their graduate studies in the United States.\nA U.S. Department of State-funded professional exchange program that exposes emerging world leaders to the United States, its people, policies, and culture through carefully-designed short-term visits.\nA U.S.-Japan exchange program providing Japanese students and researchers with the opportunity to come to the United States to complete professional internships.\nThe JED Fellowship gives student journalists from the U.S. and Germany the opportunity to meet their peers and learn about the role that disinformation plays in political coverage in both countries.\nA U.S.-Korean exchange program providing South Korean students the opportunity to come to the United States for English language training, internships, and cultural immersion.\nTwo-week professional and cultural tour of Berlin and Munich for students at Georgia-based historically black colleges and universities to explore the global nature of careers in science, technology, engineering, and mathematics. Funded through a generous grant from the Halle Foundation.\nA micro-grant competition, funded by the U.S. Embassy in Tokyo, to spur partnerships between U.S. and Japanese institutions of higher education.\nA U.S.-German exchange program for integration practitioners to share ideas and best practices on welcoming and integrating refugees in their respective communities.\nThe Young Pacific Leaders (YPL) Small Grants Program is a competition for seed funding to implement innovative programs throughout the Pacific region.\nA Department of State-funded small grants competition to support young Southeast Asian leaders to improve their communities.\nLearn more about our capacity to develop customized exchanges and view recent initiatives we have designed for U.S. and global partners."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:78b61aff-4df4-4c04-bacf-26b16eda047e>","<urn:uuid:755070f8-663b-486d-8cf6-287a061e1381>"],"error":null}
{"question":"What's preventing technology from revolutionizing education in our schools? I keep hearing it should change everything!","answer":"Technology hasn't revolutionized education because new educational tools continue to be used within a school structure that has remained virtually unchanged since the mid-nineteenth century. While schools have adopted computers, software, and infrastructure, these tools are often awkwardly integrated into the traditional factory-model classroom. For example, three computers in a classroom aren't easily integrated into lessons for 28 students learning simultaneously, and individualized learning software doesn't always align with teachers' needs to cover grade-level material for all students.","context":["A technology and education entrepreneur gazes into the future of the classroom\nMore than 150 years ago, Massachusetts became the first state to provide all of its citizens access to a free public education. Over the next 66 years, every other state made the same guarantee. The result was a publicly-funded system where, in every American classroom, groups of about 28 students of roughly the same age are taught by one teacher, usually in an 800 square-foot room. This model has been the dominant archetype ever since.\nIt's a factory-model classroom. Inspired in part by the approach Horace Mann saw in Prussia in 1843, it seemed to adequately prepare American youth for the 20th century industrialized economy. But in 1983, the federal government declared in A Nation At Risk that our system was starting to slide.\nThe year 1983 was also seminal for the technology industry. Microsoft released MS Word and Apple introduced the new Apple IIe. Some predicted that the demand for better schools, coupled with the supply of computers and new software, would soon revolutionize our nation's classrooms.\nIt didn't quite happen.\nSchools did move to adopt new technologies -- computers and software, increased bandwidth, and infrastructure. But there is scant research-based evidence that these tools have had the exponential impact on public education many anticipated.\nGiven the enormous impact that technology has had on nearly every other aspect of our society, how can that be?\nWITH LOVE FROM PRUSSIA\nPerhaps it is because educational tools that have come into our classrooms over the last couple of decades, whether technology or otherwise, continue to be used within a school structure that is virtually unchanged since the mid-nineteenth century.\nThat model was imported from Prussia with a different purpose in mind. Horace Mann's free school movement stemmed less from a belief in the economic or moral imperative of education for all children and more from a desire to simply create a tolerant, civilized society.\nMann grew up in Massachusetts during the early part of the 19th century, where religious tension between Protestants and Catholics dominated public life. Parochial schools, in his view, only reinforced these divisions. The Prussian model, on the other hand, was designed to build a common sense of national identity.\nApplied back home, Mann thought, large groups of students learning together would help to blur the divisions among religious groups and establish a more unified and egalitarian society. And as that model became the American blueprint, Mann's vision ultimately became the foundation for our national system of schooling.\nMann's vision also made sense for the industrial age in which he lived. The factory line was simply the most efficient way to scale production in general, and the analog factory-model classroom was the most sensible way to rapidly scale a system of schools. Factories weren't designed to support personalization. Neither were schools.\nTOOLS AREN'T ENOUGH\nToday our collective vision for education is broader, our nation is more complex and diverse, and our technical capabilities are more powerful. But we continue to assume the factory-model classroom and its rigid bell schedules, credit requirements, age-based grade levels, and physical specifications when we talk about school reform.\nThat's why the promise of educational innovation is less about processing power and software code and more about the opportunity to release ourselves from general assumptions regarding how instruction is organized and delivered. It's why our collective charge in K-12 innovation today should go beyond merely designing and producing new tools. Rather, our focus should primarily be to design new classroom models that take advantage of what these tools can do.\nAbsent new models, many of our technological capabilities (which can now support both scale and personalization) are either inaccessible or clumsily grafted on. Three computers added to the back of a classroom may look like a positive step toward bringing that classroom into the advanced technological age. However, smoothly integrating three computers into a daily lesson is not always easy when a teacher has to consider the needs of 28 students all learning at the same time. Software programs that enable students to learn at their own pace can be powerful, particularly for students who are at an academic level far above or below the rest of the class. But this type of software is often not readily compatible with a teacher's need to cover a grade-level scope-and-sequence for all students.\nAPP FOR TEACHER\nOf course, some new technology tools have been useful in the classroom. There are many schools where interactive whiteboards have replaced chalkboards, computers support research in libraries, and electronic grade-books have supplanted spiral notebooks. These are the kinds of tools that can be readily integrated into a traditional classroom environment. But different teachers use these kinds of tools in different ways and their use does not facilitate a pivot from the rigidity of the factory model classroom. As a result, there is little research to show that investment in these kinds of tools has a meaningful impact on student learning.\nNew classroom delivery models allow us to re-imagine new combinations of educator expertise, time, instructional materials, research, physical space, parental support, and (yes) technology in ways that achieve optimal outcomes for students. They begin not by assuming the current model but rather by understanding what it is we want students to be able to do, the measures of success, the resources we have to work with, and our own sense of possibility.\nDifferent schools may take different approaches to combining these components, depending on their educational philosophies, available teaching resources and student needs. For example, some might offer science through a combination of in-class activities, collaborative lab periods in the evening, and online coaches who work in a scientific industry. Others might teach a foreign language through the combination of in-class dialogue, web-based software, and online activities with students in other countries. Still others, like New Classrooms, use a combination of teacher-led instruction, student collaborative activities, software, virtual instructors, and a complex scheduling algorithm to enable each student to move through an individualized learning progression at his or her own pace.\nImportantly, model providers also do not need to be directly managing the school. While some providers (e.g. Charter Management Organizations) may chose to both design new models and directly manage schools, others providers may design models to work within existing schools and with faculty who remain on the district's payroll.\nBut in either case, model providers would begin to share in the accountability for student outcomes at the school level. State or districts that currently adopt textbooks would instead certify a number of model providers who would then pair off with schools (on a mutual selection basis) to support the implementation and customization of their model in a particular subject area. Over time, as models begin to mature, states and districts would be able to analyze the academic impact of the model providers, rewarding those that are most successful and decertifying those that are not.\nThe Information Age has facilitated a reinvention of nearly every industry except for education. It's time to unhinge ourselves from many of the assumptions that undergird how we deliver instruction and begin to design new models that are better able to leverage talent, time, and technology to best meet the unique needs of each student. In doing so, we can put Mann's innovation in its proper context: as the foundation for our commitment to a public education but not as the blueprint for how to deliver it."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:1efad6f4-df32-4a91-93af-b6bc5e7ad709>"],"error":null}
{"question":"What is the connection between rice and forests in both Madagascar and North America in terms of forest product usage?","answer":"In North America, forests are used to produce various products including food containers and paper products, with SFI certification ensuring responsible sourcing. In Madagascar, rice cultivation, particularly through shifting agriculture (tavy), is actually causing forest destruction. Rice, which was introduced a millennium ago and is consumed at 120kg per person annually, has become one of the largest drivers of deforestation in Madagascar.","context":["SFI AND SCOUTS\nThe future of well-managed forests depends on developing the next generation of forest stewards.\nSince 2012, the Boy Scouts of America and the Sustainable Forestry Initiative Inc.® (SFI) have partnered through a signed memorandum of mutual support to promote sustainable forestry, environmental conservation and wise use of natural resources through education, community involvement and demonstration. The agreement recognizes certification of BSA-owned lands to the SFI Forest Management Standard and is part of SFI’s commitment to bringing youth outdoors to connect with nature, conservation and forests. Getting kids into forests and helping them learn about sustainability is good for forests and good for youth.\nProject Learning Tree (PLT), an initiative of SFI, is an award-winning environmental education program designed for teachers and other educators, parents, and community leaders working with youth from preschool through grade 12. PLT recently collaborated with BSA to correlate PLT activities to eight Cub Scout Adventures and six Scouts BSA merit badges. These correlations provide Scout leaders with ideas and hands-on, outdoor activities to help support Scouts, ages 5 to 17, with youth development goals. They also help introduce Scouts to careers in the outdoors, including jobs in forestry and natural resources conservation. To learn more, click here.\nHELPING TO KEEP OUR FORESTS HEALTHY\nKeeping our forests healthy means more than just replanting trees; it also means making sure habitats are healthy so the animals we love always have a place to call home. Certification of BSA-owned and managed forests to the SFI Forest Management Standard provides assurances of future forests and demonstrates sustainability to future leaders. Philmont Scout Ranch and the Summit Bechtel Reserve are both SFI-certified properties, and we are currently seeking interest from all BSA owned and managed properties to learn more about certification to the SFI Forest Management Standard. Overall, more than 100,000 acres of BSA land is certified to the SFI Forest Management Standard.\nSFI also works with companies to use responsible practices when collecting (or sourcing) materials.\nFUN SFI & SCOUT FACTS\nDid you know?\n- Philmont Scout Ranch – One of BSA’s four national High Adventure Bases in the U.S; BSA achieved certification of 90,000 acres in New Mexico to the SFI Forest Management Standard in 2008, and has maintained certification ever since.\n- Summit Bechtel Reserve (i.e. the “Summit”) – BSA’s newest High Adventure Base located in West Virginia, and the new permanent site for the National Jamboree which occurs every four years. The Summit successfully achieved certification to the SFI Forest Management Standard in February, 2016 on approximently 13,000 acres.\n- In 2013, BSA launched its new Sustainability merit badge highlighting Sustainable Forestry Initiative certification within the text. This merit badge was added to the list of required merit badges for Eagle rank.\n- BSA’s two magazines, Scouting (for Scout leaders) and Boy’s Life (for Scouts) both carry the SFI on-product label for the paper these publications are printed on.\n- All new BSA Merit Badge books also carry the SFI on-product label.\nWHAT TYPES OF ANIMALS LIVE IN THE FORESTS?\nForests cover about 30% of land in the world, 33% of the land in the United States and about 41% of the land in Canada. Billions of animals like wolves, elk, birds, bears and caribou call these forests home! Our forests and the animals living in them are important to our future. From the air we breathe to the water we drink, forests touch our lives every day. That’s why it’s important that we help conserve these habitats by making sure that the forest products we buy (like paper and wooden toys) come from responsibly sourced materials.The forest is home to tens of thousands of species, the boreal forest, in Canada, alone is home to over 30,000 species, and billions of animals rely on it at some point during the year. The forest is important habitat for millions of mammals, birds, and aquatic species. Forests certified to SFI help protect animals that are threatened or endangered, as well as those that are not.\nLOOK FOR THE SFI LABEL AND ASK FOR IT\nIf a product has the SFI label it means it was sourced from a certified forest and by a company that cares about how forests are managed. Look for the SFI label when you buy stuff for your home: food containers, boxes, napkins paper plates and cups, printer paper, grocery bags, lumber, envelopes, and even maple syrup and much more.\nDon’t just look for the label, ask for it too! Ask your grocery store and home office supply store to stock SFI-certified products, tell your favorite pizza restaurant to use SFI-certified pizza boxes. There are lots of ways that you can support future forests!\nWHAT CAN A TREE MAKE?\nMany things come from the forest. Some trees are used to make houses, offices, bridges and other buildings. See below for some examples of other items that come from forests.","Madagascar is a biodiversity hotspot; most of the plants, animals, insects and fungi found there are not found anywhere else\nRice, the main food crop of Madagascar, could be hastening the loss of biodiversity in the fourth-largest island of the world, according to two exhaustive studies published in the Science journal December 2, 2022.\nThe cultivation of rice on the island, especially using shifting agriculture, is causing deforestation and subsequent biodiversity loss, according to the research papers.\nThe papers also urged that collection and analysis of data on Madagascar’s remarkable biota must continue and accelerate “if we are is to safeguard this unique and highly threatened subset of Earth’s biodiversity”.\nMadagascar, classified as a ‘Least Developed Country’ by the United Nations, has been in the throes of upheaval in the past few years.\nDrought has been affecting vulnerable regions over the last four decades. More than one million people needed food emergency assistance in the island country in 2020.\nClimate change has wrought havoc on the island, with the latest being Tropical Storm Ana earlier this year.\nRice cultivation was brought a millennium ago to Madagascar by Austronesian peoples, who are thought to have sailed to the island from the Indonesian archipelago in outrigger canoes.\nRice is integral to Malagasy cuisine. On average, each Madagascan eats 120 kilogram of rice or vary per year.\nMadagascar’s extraordinary biodiversity: Evolution, distribution, and use, one of the papers published December 2, noted how rice had changed the Madagascan landscape:\nSince settling on the island, humans have introduced crops and livestock for agriculture and husbandry. Of these, rice and zebu cattle have had the largest impacts on the landscape as a result of their vital role in sustaining human populations.\nRice is currently widely cultivated both in the Central Highlands (using paddy production) and in the humid east, where swidden agricultural methods are used (ie, shifting cultivation involving clearing forest for conversion to cropland, usually by burning).\nThe paper said slash-and-burn cultivation depleted soils rapidly. This caused farmers to abandon land for long fallow periods with further vegetation being cleared at a new location.\n“Our analysis of IUCN assessments indicates that overexploitation and agriculture are the most frequently listed threats to Malagasy fauna (excluding invertebrates) and flora, mirroring global findings,” Madagascar’s extraordinary biodiversity: Threats and opportunities, the second paper, noted.\nThe paper said agriculture primarily led to deforestation on the island. Some 44 per cent of the land covered by native forest in 1953 was deforested by 2014.\nThe rate of deforestation has steadily increased. It was 99.0 kilohectare per year between 2010 and 2014 and 72.9 kha/year from 2014-2020.\n“Deforestation in Madagascar reflects global patterns and is primarily driven by the small-scale but widespread practice of swidden agriculture (also known as shifting cultivation; in Madagascar referred to as tavy for rice cultivation in humid and subhumid areas and hatsake for cassava and maize in dry and subarid areas),” the paper said.\nAdditionally, cash crop production, particularly maize and peanut, had become a major driver of deforestation alongside the production of products for international markets, such as forest-derived vanilla, it added.\nThe researchers added that the trend of increasing deforestation rates will continue, as people clear land for agriculture with small-scale fires.\nNatural system modifications add to deforestation. They threaten 23.2 per cent of vertebrates and 68.9 per cent of plants.\n“Some predictions indicate that in the absence of an effective strategy against deforestation, 38 to 93 per cent of forest present in 2000 will be no longer present in 2050,” according to the authors.\nMadagascar is a biodiversity hotspot. Most of the plants, animals, insects and fungi found on the island are found nowhere else in the world. Some 56 per cent of the island’s birds, 81 per cent of freshwater fishes, 95 per cent of mammals, and 98 per cent of reptile species are endemic.\nMadagascar, along with India, was part of Gondwana, one of two supercontinents formed millions of years ago. South America, Africa and Australia too were part of the great landmass.\nMadagascar later split and moved till it reached its present position in the Indian Ocean, separated from Africa by the Mozambique Channel. This relative isolation enabled the high endemism among its biota.\nBut knowledge about Madagascan biodiversity still remains poor, something which the papers delved upon.\nDespite the global significance of Malagasy biodiversity, many taxonomic groups remain poorly known, and Madagascar ranks among the top countries for the predicted percentage of terrestrial vertebrates lacking scientific description, Madagascar’s extraordinary biodiversity: Evolution, distribution, and use said.\nConsiderable work remains to be done to fully characterize Madagascar’s biodiversity and evolutionary history, it added.\nWe are a voice to you; you have been a support to us. Together we build journalism that is independent, credible and fearless. You can further help us by making a donation. This will mean a lot for our ability to bring you news, perspectives and analysis from the ground so that we can make change together.\nComments are moderated and will be published only after the site moderator’s approval. Please use a genuine email ID and provide your name. Selected comments may also be used in the ‘Letters’ section of the Down To Earth print edition."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:f24557b2-57b3-4f95-9760-39203c371451>","<urn:uuid:be81642a-5eca-4687-a739-b7b7b6a4bb42>"],"error":null}
{"question":"How can I prevent getting infected with plague while camping in California? 🏕️","answer":"To prevent plague infection while camping in California: avoid contact with rodents (especially chipmunks and squirrels), avoid contact with rodent fleas, and be careful not to touch any cuts or breaks in your skin with infected animal blood or fluids. Also, be cautious around cats as they are especially susceptible to plague and can transport infected rodent fleas into campsites. The plague bacteria can also be inhaled from infected animal coughs or sneezes, so maintain distance from potentially infected animals.","context":["Vector & Rabies Control\nOur vector and rabies control program protects the public from exposure to rabies and vector-borne diseases, such as, hantavirus West Nile, Lime Disease, and plague. In cooperation with federal, state, and local agencies, the Environmental Health staff keeps the public informed of current and emerging threats to the communities of Plumas County.\nRabies is a virus that attacks the central nervous system and is usually passed to humans from the bite of a rabid animal. Rabies can also be transmitted through fresh scratches, breaks in the skin, or contact with mucous membranes (eyes, mouth, nose) from the saliva of an infected animal. Most animals are susceptible to infection and, if not treated early, is fatal. In Plumas County bats and skunks are the greatest concern. Other wild animals, such as foxes, coyotes, raccoons and opossums can also be infected with rabies. The Department of Environmental Health routinely submits wild animals for rabies testing that have had direct physical contact with humans or pets. It holds the responsibility of investigating all reported cases involving humans and pets, working cooperatively with the local animal control agency and law enforcement.\nThe Department of Environmental Health has set policies and procedures to prevent disease from being acquired by humans and pets. For this reason California law states that the rabies vaccination for dogs is mandatory. Although it is not required, it is strongly recommended that cats be vaccinated as well. Assembly Bill 272, Chapter 582.\nAnimal Bites: Wild and Domestic\nAll cases of animal bites on humans are to be reported to the local animal control agency. Animal Control then submits an incident report form to Environmental Health. If the animal is domestic (i.e. dog or cat), the animal is to be quarantined for 10 days. This quarantine (depending on the situation) may be in the owners home, at the veterinary clinic, or animal shelter. If the animal is wild, it is submitted to for rabies testing. The assigned Specialist at Environmental Health remains in contact with Animal Control and/or the testing facility until the case is closed and any chance of rabies is eliminated.\nLength of Quarantine:\n10 days for dogs and cats\n14 days for all livestock\n0 days for all wild animals - automatically tested for rabies\nLaws and Regulations Related to Rabies\nRabies Report for California (Jan-Oct 2014)\nBat Removal Specialist\nAccording to the CDC Vector-Borne diseases are bacterial and viral diseases transmitted by mosquitos, fleas, and ticks. Some of these diseases have long been present in the United States while others have recently emerged. These include some of the world's most destructive diseases, many of which are increasing threats to human health as the environment changes and globalization increases.\nWhat is Plague?\nThe California Department of Public Health (CDPH) defines plague as a bacterial disease that people can get if they are bitten by an infected rodent flea. Most persons with plague develop fever and swollen lymph nodes. Plague is treatable with antibiotics, but can progress to severe and sometimes fatal illness if diagnosis and treatment are delayed. Squirrels, chipmunks, and other rodents in many areas of California can carry plague. Persons visiting, hiking, or camping in these areas should avoid contact with rodents.\nPlague is present in the state of California. It is most commonly found in the foothills, plateaus, mountains, and coast. It is absent from the southeastern desert region and the San Joaquin Valley. Although urban rats were historically important in plague transmission, they no longer play an important role in California. Although wild rodents (primarily chipmunks and squirrels) in rural recreational and wilderness areas are the greater carriers of plague, it is possible for rodents in the suburban foothills of some larger cities to be carriers as well. Because rodents and their fleas maintain plague bacteria in nature, humans can contract with an infected wild animal is very dangerous. There are three ways in which humans can contract the plague bacteria:\n- Through the bite of an infected flea.\n- When blood or other body fluids of an infected animal enter through cuts or breaks in the skin or mucous membranes - your eyes, mouth, and nose.\n- Through inhaling the bacteria from the cough or sneeze of an infected person or animal (i.e. a cat or dog). It is important to note that cats are especially susceptible to plague and, if infected, represent a serious source of potential human exposure. They may also transport infected rodent fleas into a home or campsite.\nFacts About Plague Brochure\nPlague Fact Sheet\nWhat is Hantavirus Cardiopulmonary Syndrome (HCPS)\nHCPS is a rare, but often fatal, disease of the lungs. HCPS was first recognized in 1993 in the southwestern United States. Although many hantaviruses exist in nature, HCPS in the western U.S. is caused by a specific hantavirus called Sin Nombre virus (SNV) when a human is infected through contact with urine, and droppings, and saliva from a hantavirus-infected rodent. Most of those who have been infected with HCPS contracted the disease while cleaning out rodent-infested spaces where there is little to no air circulation. Other ways in which one may contract the disease include:\n- The consumption of food contaminated with rodent urine and/or droppings\n- Touching surfaces where rodents have been, and then putting their hand in their mouth\n- Being bitten by an SNV infected rodent.\nWhile cases of HCPS have been reported in 34 U.S. states, more than 95% of reported cases have occurred in states west of the Mississippi River. Fortunately for California, the only rodents carrying and shedding the Sin Nombre virus are deer mice. Other rodents, such as squirrels, chipmunks, and mouse mice have not been shown to pose as a HCPS threat to humans.\nHCPS Cases by State of Exposure\nHantavirus Fact Sheet\nWest Nile Virus (WNV)\nWest Nile Virus (WNV) is a mosquito-borne disease that was originally found in Africa. In 1999, it was detected in the eastern United States; since then the virus has spread throughout the United States and is well established in most states, including California.\n\"West Nile Infections Slam California\"\nFor more on West Nile Virus please visit http://www.westnile.ca.gov\nTick-Borne Relapsing Fever (TBRF\nTick-borne relapsing fever (TBRF) is an illness caused by bacteria that are carried by soft ticks. Although TBRF is rare in California, it can cause serious illness in people. They are primarily found in forested and mountain regions between 3,000 and 9,000 feet. They like dark, cool places such as rodent nests, shedded wood piles outside buildings, and between walls or beneath floorboards inside buildings. While rodents (squirrels, chipmunks, and mice) are preferable to soft ticks, other mammals, including humans are good secondary sources to feed on when the other is not available.\nPeople are the most susceptible to getting bitten in the rural mountains during the summer months. The bite is painless and they feed only for a minutes so many go unnoticed. Many people are bitten while asleep and never realize that they have been bitten."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:8f3410aa-0316-4e1f-bd6d-f2def621c6cd>"],"error":null}
{"question":"How do the supernatural zones in Stalker and Orphée differ in their physical manifestations and entry points?","answer":"The zones in these films manifest differently but both defy normal physical laws. In Orphée, the supernatural zone exists in architectural nooks and crannies of the real world and is entered through mirrors (filmed using pools of mercury). In this zone, gravity can suddenly change, making people either glide effortlessly or move as if through treacle. Meanwhile, in Stalker, the zone is a distinct geographic space of otherworldly origins that must be accessed by navigating past a militarized perimeter. Rather than being governed by physics, this zone is controlled by the thoughts and emotions of those who enter it, creating existential booby traps for visitors.","context":["In Orphée, Death rides in a Rolls Royce, served by leather clad bikers; she broadcasts on radio and publishes literary magazines. Jean Cocteau’s bizarre, dreamlike, extremely funny and daringly experimental work took the Venice Film Festival by storm in 1950, and was so popular with audiences upon release that one German cinema showed it every Saturday night for the next 15 years. It continues to influence filmmakers today, with the BFI prepares releasing a new remastered version into cinemas.\nIn 2004 the critic David Thompson wrote that The Matrix could not have been made without Orphée – and you could now add to that list Inception, Eternal Sunshine of the Spotless Mind, Pan’s Labyrinth and even Netflix’s recent series Stranger Things and Maniac. Filmmakers Chris Marker and Andrei Tarkovsky, in their own eras, both admired the film hugely for its bold retelling of the ancient Greek myth of Orpheus and Eurydice, in which a poet sets off on a journey into the underworld in search of his dead wife.\nCocteau’s masterstroke was to find the contemporary cinematic language for this age-old myth – his underworld exists in the architectural nooks and crannies of the real, entered and exited through mirrors (filmed using pools of mercury). In this ‘zone’ gravity can be upended at a moment’s notice, and people either glide around with ease or struggle as though moving through treacle. “The laws of the other world,” declares one character, “are different to ours.”\nCocteau’s film – which liberally uses negative effects, rewinding, weird cuts and camera angles – is as much about the joyously breakable laws of cinema as it is about the mythical underworld. Tarkovsky’s Stalker, which breaks into colour from black-and-white as soon as its characters enter its mysterious ‘zone’, owes much to Cocteau’s sensibility.\nLike Tarkovsky’s zone, Cocteau’s spirit world also has a very modern psychological dimension: it is not just a land of the dead but “a place of men’s memories and the ruins of their habits”. In Maniac (as in Eternal Sunshine of the Spotless Mind) Emma Stone and Jonah Hill have to go on the run through the collapsing architecture of their own minds and memories. Likewise Cocteau’s Orphée (played by his lover and long-term partner, the ageing but still ruggedly handsome Jean Marais) is engaged in a battle not just with Death but with his own memories of an impossible love; he can only win through uneasy forgetfulness and oblivion.\nOther details blur the lines further between psychology, technology and magic. Throughout the film radio sets suddenly start declaiming fragments of surrealist poetry that Orphée desperately scribbles down – whether they are coming from his own subconscious, or from the spirit world, is unclear.\nThe disembodied voices over the radio are another part of Cocteau’s influential vision. As with the Nokia phones and blinking green computer screens of The Matrix, Orphée’s supernatural fantasies take place via the normal technology of modern life, making it seem all the more eerily plausible. Just as many a childhood in the 2000s was spent waiting for computer screens to spell out the words ‘follow the white rabbit’, after watching Orphée mirrors begin to seem like ‘the doors through which Death passes’, potential gateways to another world.\nThe film has its uneven points – Cocteau is certainly more interested in his notions of symbolic and poetic wonder than he is in human relationships – and there are plenty of highly conventional moments of egregious and disturbing sexism. For its cinematic inventiveness and far-reaching influence, however, it is destined to continue finding new audiences.\nThe post In praise of Orphée – Jean Cocteau’s mould-breaking masterpiece appeared first on Little White Lies.","Few directors command as much respect from their peers as the late Andrei Tarkovsky. Ingmar Bergman famously called him “the greatest [director] of them all.” Three of his films appear in the Sight & Sound Top 50 Greatest Films of All Time poll, a feat surpassed only by Jean-Luc Godard.\nOne of those films, his 1979 feature Stalker, is out in a gorgeous new 2K restoration by Mosfilm.\nA surreal and sprawling sci-fi meditation, Stalker is set in a dystopian future society whose fabric is forever altered by the appearance of “The Zone,” a mysterious geographic space of seemingly otherworldly origins.\nDespite government efforts to prevent human entry via a militarized perimeter, a class of people known as “stalkers” have learned to navigate “The Zone,” which is governed not by the laws of physics but by the thoughts and emotions of those who enter it.\nFor a fee, stalkers will escort visitors into “The Zone” and help them navigate its terrain of existential booby traps to find the supernatural rewards it’s purported to contain. The film follows one such stalker (Alexander Kaidanovsky) as he leads a writer (Tarkovsky regular Anatoli Solonitsyn) and a professor (Nikolai Grinko) through the sentient landscape.\nLike Tarkovsky’s Solaris, Stalker is a loose and abstract adaptation of a much more cerebral sci-fi novel.\nWhile the original authors examine the political and metaphysical ramifications of sci-fi scenarios, Tarkovsky is interested in the spiritual ramifications of these phenomena. His source material tells us about “The Zone,” while Tarkovsky asks what “The Zone” can tell us about ourselves.\nFew filmmakers ask such questions better than Tarkovsky. More than presenting a sci-fi setting or scenario, “The Zone” places the viewer in an unsettling headspace that necessitates a radical change in perspective. Needing to interpret a world purely through emotion, discarding reality’s iron-clad laws, forces the viewer to reconsider the prism through which they view their own life in addition to the fiction.\nWhen the writer and the professor give their reasons for wanting to visit “The Zone,” both answers feel incomplete or deceptive. Whether they’re trying to deceive each other, themselves or the viewer is a complex knot that the film only partially untangles. Only by examining their own attitudes can the viewer begin to answer those questions, and like these characters, they might not like what they see when looking inward.\nTarkovsky and cinematographer Alexander Knyazhinsky present these quandaries with a quiet that masks the film’s visual gusto. The film begins outside “The Zone” in sepia tones, transitioning to colour as the characters leave their dystopia behind.\nThe parallel to The Wizard of Oz is obvious, but that’s less a statement than a further question to the audience. What did that colour scheme say about Depression-era America in Oz, and what does it say about Tarkovsky’s contemporary Soviet Union?\nWhatever it said wasn’t liked by Soviet authorities, who made it impossible for Tarkovsky to work in the USSR after this film. In the 1990s, former KGB agents who purported to have had a role in Tarkovsky’s death claimed that the poison which caused his fatal cancer was administered on the set of Stalker.\nStalker plays at Cinematheque Sept. 23-29."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:90e922f7-f0bd-432f-a7d3-bcc9f1f37fc4>","<urn:uuid:10477b4b-c959-4e10-8b39-0d9f094994f0>"],"error":null}
{"question":"How do the power reserve indicators differ between the Breguet Fusee Tourbillon and the Lange 1815 Tourbillon Handwerkskunst?","answer":"While both watches feature tourbillon mechanisms, they handle power reserve indication differently. The Breguet Fusee Tourbillon has a patented power reserve indicator positioned at 10 o'clock directly on the barrel drum, using a system of reducer differentials to display the indication. The timepiece provides 50 hours of power reserve. The Lange 1815 Tourbillon Handwerkskunst's specifications don't mention a power reserve indicator, focusing instead on other features like the ZERO-RESET function and stop-seconds device for the tourbillon.","context":["Breguet FUSEE TOURBILLON TIMEPIECE\nAN EXCEPTIONAL ACHIEVEMENT JOINS THE TRADITION COLLECTION\n|Rating: 70 %1000 with 152 votes|\nAdmired by the public and professionals alike as a truly novel collection heralding a fresh horological era, the Tradition line welcomes its first major complication this year. The design’s essential attributes correspond perfectly to the collection’s bold, visionary approach. Breguet timepiece 7047 features a spectacular tourbillon mechanism coupled to a fusee-and-chain transmission.\nIt incorporates the Breguet 569 handwound caliber, whose technical qualities speak for themselves.\nThe movement’s many unique features include its power -reserve indicator for which a patent application has been filed. Positioned at 10 o’clock, it is located directly on the barrel drum (the movement’s power source) and features a system of reducer differentials allowing the indication to appear directly on the drum. The latter’s large dimensions furthermore enabled watchmakers to fit it with two barrels, increasing the amount of energy stores and provides.\nThe fusee-and-chain transmission is designed to optimize watch-rate regularity by ensuring a constant torque whatever the actual degree of winding tension (a mechanical watch mainspring’s torque usually varies with the degree of winding). Conical in shape, the fusee features differential gears that convey a continuous flow of energy to the movement.\nWhen the watch and barrel are fully wound, thus providing peak traction, the chain connecting the barrel to the fusee winds around the latter’s smallest circumference whereas when the barrel is only partly wound and thus cannot develop its full torque, the chain winds around the broadest part of the fusee, offsetting in this way the barrel’s loss of power. The winding system further benefits from a crown wheel with frontal toothing that considerably improves its responsiveness. Unquestionably a harbinger of things to come, the Tradition 7047 timepiece nonetheless embodies a full measure of Breguet’s product identity.\nInspired by the first tourbillon-equipped pocket watches of the early 19th century, it includes such signature features as caseband fluting, round-ended welded lugs and blued-steel Breguet hands. Its yellow gold case holds centuries of accumulated horological know-how. Slim bezel and domed crystal together clearly reveal the movement’s various levels and provide a good view of the tourbillon carriage’s generous proportions. Its thin bar (or barrette), upper bridge and carriage all derive from A.-L. Breguet’s earliest sketches.\nFitted with a Breguet balance made of titanium, patented in 2004, and an upper bridge also fashioned in titanium, the tourbillon carriage’s impressive size is offset by its spare design. For its part, the Breguet-shaped barrette is made of nonmagnetic stainless steel.\nOff-centred at 7 o’clock, the dial reflects understated design in the established Tradition style, underlined by the movement’s impeccably shot -blasted surface finishing.\nEngine-turning in the Clou de Paris cobbled pattern, classic Roman numerals and Breguet hands all evoke the very origins of the brand. Secured by three blued screws, the dial plate salutes the celebrated subscription watches devised centuries ago by Breguet himself.\nSuch accomplished design enhances each and every component. The ir visibility, contrasting character and three -dimensional structure come together in a unique architectural composition, emblematic of a groundbreaking collection incorporating impeccable horological artistry.\nBreguet 7047 FUSEE TOURBILLON TIMEPIECE specifications\nLA TRADITION BREGUET\nFUSEE TOURBILLON TIMEPIECE\nDESCRIPTION OF THE WATCH\nCase round in 18K yellow gold with finely fluted caseband.\nDiameter: 41 mm.\nRounded horns welded to the case, with screw pins securing the strap.\nWater-resistant to 30 metres (~ 100 feet).\nDial in silvered 18K gold, off -centred to the 7 o’clock position and hand -engraved on a rose engine.\nIndividually numbered and signed Breguet.\nChapter ring with Roman numerals.\n60-second tourbillon positioned at 1 o’clock.\nBlued steel, open-tipped Breguet hands.\nMovement handwound mechanical, with tourbillon regulator.\nNumbered and signed Breguet. Cal. 569. 16 lines, 43 jewels, 3-Hz frequency.\nPower reserve of 50 hours with power-reserve indication on the barrel drum.\nTorque regularity throughout the operation of the watch provided by fusee-and-chain transmission.\nUpper bridge of the tourbillon carriage in titanium.\nBreguet-shaped thin bar (barrette) in nonmagnetic stainless steel.\nStraight-line lever escapement.\nBreguet balance in titanium with four adjustment screws in gold.\nBreguet balance spring.\nAdjusted in 6 positions.","Lange 1815 Tourbillon Handwerkskunst: This year is the 200th Anniversary of the founder of A. Lange & Söhne, Ferdinand Adolph Lange. Just last year Lange celebrated their 20th anniversary and released a limited edition set of Lange 1’s that featured the most beautiful hand guilloché dial. Of course being the 200th anniversary I would expect nothing less from Lange than another brilliant and jaw droppingly, gorgeous timepiece. The 1815 is a tribute to Ferdinand Adolf Lange, so it would only make sense that this timepiece bearing his year of birth be turned into something a little more special to celebrate this occasion and my goodness is it just. Last year, Lange unveiled the new 1815 Tourbillon with ZERO-RESET function, which we spoke about here. To commemorate this momentous occasion, the Lange 1815 Tourbillon is being presented in a limited Handwerkskunst edition, featuring an extraordinary dial and movement decoration.\nHandwerkskunst, the German word for “artisanship”, is a characteristic of importance that A. Lange & Söhne have bestowed upon their highly regarded timepieces since 2011, to identify special limited-edition watches whose dials and movements are endowed with rare finishing and engraving techniques. On Monday 7th December, Lange presented the 1815 Tourbillon Handwerkskunst to the world, a new model that not only stands out with exceptional decorative elements, but also unites two patented mechanisms. The ZERO- RESET function launched in 1997 by A. Lange & Söhne is paired with the stop-seconds device for the tourbillon that was introduced in 2008. Together, these mechanisms make it possible to stop and set the timepiece with one-second accuracy.\nLimited to just 30 examples, the special-edition model features a pink-gold case with a diameter of 39.5mm. This special 1815 is Lange’s fifth Handwerkskunst, which pays homage to Ferdinand Adolph Lange, the great Saxon watchmaking pioneer whose 200th birthday is being memorialised this year.\nThe main differences compared to the model presented in 2014 is the dial. It is made of black- rhodiumed pink gold and decorated with elegant tremblage engraving. The engraver who uses this technique, sculpts the material with a specially crafted lining burin, which we highlight during our 2014 factory visit to Lange, to achieve a uniform, fine granular structure. The relief elements on the dial, including the prominent arced brand logo and the numerals, are later polished to a mirror gloss and contrast prominently against the dark background. An aperture in the dial reveals the large one- minute tourbillon. The tourbillon bridge and the upper part of the cage are black-polished, which is a rather elaborate but time-consuming finishing technique.\nIt of course goes without saying that the mechanical precision is reflected in every detail of the lavishly decorated L102.1 manufacture calibre. The elegantly curved shape of the newly designed three-quarter plate is a special hallmark. Thanks to generous cut-outs, the tourbillon with the patented stop mechanism is easily visible from the movement side as well, as are the barrel and parts of the wheel train. The grained surface of the German silver plate is inspired by historic pocket watches. Bevel-polishing inward angles is a particular challenge. This task can only be performed manually with a sharp, specially designed tool. The fourth- wheel bridge is pierced to provide a better view of the tourbillon. Just like the plate and the case back, it is endowed with artistic engravings. The diamond endstone of the tourbillon vibrantly accentuates the movement decorations.\nAs mentioned the Lange 1815 Tourbillon Handwerkskunst is only available in pink-gold and is limited to just 30 pieces, with a retail price of €185,000. For more information on the Lange 1815 Tourbillon Handwerkskunst, visit the A. Lange & Söhne website."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:49da6dad-8605-4b96-9055-bd200a242b51>","<urn:uuid:bf4bbd8b-5dfe-44c1-82e4-30fbefadcab6>"],"error":null}
{"question":"What are the key differences between polarity Methods A and C in fiber optic networks, and how do their respective patch cord requirements affect installation complexity?","answer":"Method A uses Type A straight-through MPO trunk cables with key up/down connectors and requires an A-A patch cord at one end to achieve the transmitter-receiver flip. In contrast, Method C uses a key up/down connector configuration but incorporates the flip within the cable itself, where each pair of fibers is flipped so Position 1 (Tx) arrives at Position 2 (Rx). For installation, Method A requires specific A-A patch cords at one end to maintain proper polarity, while Method C can maintain polarity using standard A-B patch cords throughout, making it generally recommended for most installations due to simpler cable management.","context":["O A-B-C da polaridade da fibra\nPolarity defines direction of flow, such as the direction of a magnetic field or an electrical current. In fiber optics, it The A-B-C’s of Fiber Polarity\nTo properly send data via light signals, a fiber optic link’s transmit signal (Tx) at one end of the cable must match the corresponding receiver (Rx) at the other end.\nWhile this seems obvious, polarity is one area that seems to cause the most confusion among technicians. So let’s break it down and start at the beginning.\nEasy to Understand Duplex\nIn duplex fiber applications, such as 10 Gig, data transmission is bidirectional over two fibers where each fiber connects the transmitter on one end and to the receiver on the other end. The role of polarity is to make sure that this connection is maintained.\nIf you look at the graphic below, you can easily see that the Tx (B) should always connect to the Rx (A), regardless of how many patch panel adapters or cable segments are in the channel. If polarity is not maintained, such as connecting a transmitter to a transmitter (B to B), data will simply not flow. Obvious, right?\nTo help the industry select and install the right components to maintain proper polarity, TIA-568-C standards recommends the A-B polarity scenario for duplex patch cords. The A-B duplex patch cord is a straight-through connection that maintains the A-B polarity in a duplex channel. It’s also important to note that every fiber connector has a key that prevents the fiber from rotating when the connectors are being mated and maintains the correct Tx and Rx position.\nMore Complex Multiples\nWhile duplex fiber polarity may seem straight forward, it all becomes a bit more complex when dealing with multi-fiber MPO type cables and connectors. Industry standards call out three different polarity methods for MPOs—Method A, Method B and Method C. And each method uses different types of MPO cables.\nMethod A uses Type A straight-through MPO trunk cables with a key up connector on one end and a key down connector on the other end so that the fiber located in Position 1 (Tx) arrives at Position 1 (Tx) at the other end.\nWhen using Method A for duplex applications, making the transceiver-receiver flip from Position 1 (Tx) to Position 2 (Rx) is required in a patch cord at one end. This is achieved with an A-A patch cord that shifts the fiber in Position 1 to Position 2 at the equipment interface.\nMethod B uses key up connectors on both ends to achieve the transceiver-receiver flip so that the fiber located in Position 1 (Tx) arrives at Position 12 (Rx) at the opposite end, the fiber located in Position 2 (Rx) arrives at Position 11 (Tx) at the opposite end and so on. For duplex applications, Method B uses straight A-B patch cords on both ends since there is no need for the transceiver-receiver flip. With the same type of patch cord on both ends, concern about which type of patch cord to use to which end is eliminated.\nMethod C uses a key up connector on one end and a key down on the other end like Method A, but the flip happens within the cable itself where each pair of fibers is flipped so that the fiber in Position 1 (Tx) arrivers at Position 2 (Rx) at the opposite end and the fiber in Position 2 (Rx) arrives at Position 1 (Tx). While this method works well for duplex applications, it does not support parallel 8-fiber 40 and 100 Gig applications where Positions 1, 2, 3 and 4 of the MPO interface are transmitting and Positions 9, 10, 11 and 12 are receiving and is therefore not recommended.\nWith three different polarity methods and the need to use the correct type of patch cords for each, deployment mistakes can be common. Thankfully, Fluke Networks’ MultiFiber™ Pro allows users to test individual patch cords, permanent links and channels for correct polarity.","What is polarity?\nMaintaining the correct polarity across a fibre network ensures that a transmit signal (Tx) from any type of active equipment will be directed to the receive port (Rx) of a second piece of active equipment – and vice versa.\nTIA/EIA 568-b-1-7 defines 3 standard methods for maintaining polarity within multi fibre links.\nComplete Connect standardises its products on Method C and recommends using this method in the majority of installations. However, products are available to enable method A. We do not recommend using method B as this requires the added complexity of having 2 types of cassette and using Key Up – Key Up MTP® adaptors. Method B products are primarily used within 40G networks and can be found here.\nMaintaining Polarity when using MTP MPO fibre channels\nMTP (male) connectors are mated to MTP (female) connectors using an MTP adaptor. Each MTP connector (both male and female) have an asymmetrical housing (a Key) which only allows insertion into an adaptor one way. There are 2 types of MTP adaptors, Key-Up to Key-Up and Key-Up to Key-Down.\nA Key-Up to Key Up adaptor will flip all the fibres when two 12 fibre cables are connected through the adaptor, i.e. fibre no. 1 (of the 12 fibres) in the first cable will connect to fibre no. 12 in the second cable. At every point in a fibre link where a Key-Up to Key-Up adaptor is used the fibres 1 to 12 will be flipped and reverse the polarity of the link.\nA Key-Up to Key-Down adaptor mainatins the fibres so that fibre 1 in cable 1 is joined to fibre 1 in cable 2. This means that no matter how many of these adaptors are used in a link the polartiy of the link remains.\nKey-Up to Key-Down adaptors are far easier to use when trying to maintain a consistent polartity across an installation both at the time of installation and for subsequent moves, adds and changes.\nFor this reason Complete Connect standardises its products on this type of adaptor. See Physical considerations below\nAchieving Polarity A or C for 10G Networks\n1. Polarity A is achieved through an A-A patch cord at one end of the link (fibre channel)\n2. Polarity A can be achieved by flipping fibres within a ruggedised fan-out when directly connecting to equipment instead of using a A-A patch cord\n3. Polarity C is achieved through using 1 polarity C trunk cable within the link and maintaining A-B patch cords through out\nNote: Polarity Method B is not recommended as it requires different types of cassettes and uses of Key up – Key up MTP® adaptors.\nHow many connections? What type of connections?\nHow long are the links?\nHow much rack space is available?\nAnticipated future moves, adds and changes?\nFuture bandwidth requirements?\nThe main aspects taken into consideration when looking at a network are outlined below:\n- Traffic across various sections of the data centre or network\n- Quantity and variety of fibre channels, physical space and channel flexibility\n- Expansion and growth plans for the data centre or network\n- Expected volume and frequency of MACs\n- Site Access\n- Physical space and outlet density\nThese factors will determine the network design and subsequently determine which level of product performance you will require at which points.\nComplete Connect gives you flexibilty to chooses products that match the design requirements and so ensure that costs are kept to a minimum without being detrimental to performance.\nPolarity Method C\nPolarity Method A\nPolarity Method B\nConsiderations on using MTP Based Networks\nSome key points to note:\n→ M300 products use MTP standard connectors and LC / SC standard connectors and so will be suitable where a combination of either shorter runs or fewer connections are required\n→ M310 products use MTP ELITE connectors and LC / SC premium connectors (giving reduced insertion loss at each mating) and so will be suitable when channel lengths are longer or more connections (such as the introduction of Zonal or Horizontal distribution) are required\n→ Ruggedised fan-outs allow connectivity without the need for rack space\n→ MTP-MTP cross connects can be used as an alternative to LC cassettes in the main distribution area and so reduce both the U space required and the number of connections in the channels\n→ M350 HP products give direct cabling to zonal areas or active equipment and can remove U space requirement\n→ The MTP 24 fibre connector can be used where rack space is heavily restricted\n1. All cassettes have MTP® male internal rear connectors and will require an MTP® female connector for a correct mating\n2. All M300 and M310 products are manufactured to be used with only MTP® adaptors that are Key Up – Key Down ensuring continuity of fibre (fibre 1 to fibre 1) at each adaptor\n3. Refer to product specifications of trunks and ruggedised fan-outs to ensure the connector to connector distances you require are based around our definitions of trunk and ruggedised fan-out lengths (i.e. when breakouts and stub lengths.\n4. Only Complete Connect products can be used across a link.\n5. MTP-MTP cross connects can be used in the Main Distribution Area (MDA). To do this the LC cassettes in the MDA are replaced with MTP adaptors housed in adaptor plates. This decreases the insertion loss across the channel and enables greater channel distances to be achieved because 2 LC matings have been removed.\n6. The 24 fibre MTP® connector can be used to double the density of fibre within MTP® adaptor plates\n7. The 24 fibre MTP® connector can be used to half the number of cables to a cassette.\nWhat Installation Steps are required?\nThe same principles apply whether you are installing a 24 fibre link either between 2 buildings, connecting an office floor to a comms room or creating hundreds of channels in a data centre.\nThere are 4 main steps to adhere to: –\nEnsure that the link being created (distance and number of connector matings) meets the required standard.\nEnsure that the polarity is managed across the link and in accordance with the network design\nEnsure physical forces on the cables and connectors are managed by using strain relief on the cables to limit the tension in the cabling and maintain bend radii in both the cabling and patching according to the allowed specifications.\nFollow the fibre connection procedures that you should use when connecting any type of fibre connectors together.\nBefore connecting a fibre to a cassette or connecting 2 MTP connectors via an adaptor, you should always clean both fibre ferrules with approved cleaning tools, visually inspect both ferrules using an appropriate scope, repeat until the ferrules are clean, and test with a light source and power meter (that is properly referenced).\nIf the tested link is giving insertion losses greater than expected repeat step 4.\nNEVER insert a connector into a cassette without the cleaning and inspection process in step 4 being completed.\nMaximum channel lengths are calculated using the Complete Connect channel calculator application tool\nChannel lengths can be increased by using M310 products instead of M300 products which reduces the insertion loss at each connector mating\nChannel lengths can be increased by using M350 direct cabling products to reduce the total number of connectors in the link\nChannel lengths can be increased by using MTP–MTP cross connects instead of LC cassettes\nChannel lengths can be increased by using direct cabling such as ruggedised fan outs instead of trunks and cassettes\n1. The Complete Connect design application tool with ensure step 1 is passed\n2. The Complete Connect Installation Guide will demonstrate how to manage polarity correctly.\n3. Cable ties for trunks, transition glands for ruggedised fan-out (supplied with all fan-outs), recessing panels to give extra room for patchcords (standard with all panels) and following the cable specifications when laying cables overhead or underfloor.\n4. LC cleaning tool. MTP cleaning tool (approved by US Conec). Appropriate light source and power meter. Appropriate reference patch leads. Visual scope – All tools are available from Complete Connect."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:6c374d80-90cc-4b76-b838-a616519cdcb9>","<urn:uuid:63b26d6f-255c-4718-92f5-f3db190ad85e>"],"error":null}
{"question":"What happens when forwarding query strings is enabled in CloudFront?","answer":"When query string forwarding is enabled, the origin server can return different versions of an object based on the query string in the URL. If disabled, the origin returns the same version of an object regardless of the query string, which increases the likelihood that CloudFront can serve a request from the cache, improving performance and reducing load on the origin.","context":["CloudFront is a web service that speeds up distribution of your static and dynamic web content, for example, .html, .css, .php, and image files, to end users. CloudFront delivers your content through a worldwide network of edge locations. CrossFTP provides CloudFront distribution management tool for you to config the CloudFront more easily. Just choose CloudFront Distribution -> Manage CloudFront Distributions from the contextual menu.\nCreate a new CloudFront DistributionYou can create two types of distributions:\n- A download distribution delivers content using HTTP or HTTPS. Using a download distribution, you can configure CloudFront to access your web content in any combination of up to 10 Amazon S3 buckets and custom origins.\n- A streaming distribution delivers digital media using\nAdobe Flash Media Server and the Real-Time Messaging Protocol. The origin for a streaming distribution\nis always one Amazon S3 bucket.\n- Alternate Domain Names (CNAMEs): Optional. Specify one or more domain names that you want to use for URLs for your objects instead of the domain name that CloudFront assigns when you create your distribution.\n- Default Root Object: Optional. The object that you want CloudFront to request from your origin\nindex.html) when a viewer requests the root URL of your distribution (\nhttp://www.example.com/) instead of an object in your distribution (\nhttp://www.example.com/product-description.html). Specifying a default root object avoids exposing the contents of your distribution.\n- Comment: Optional. Enter any comments that you want to save with the distribution.\n- Logging: Optional. If you want CloudFront to log information about each request for an object and store the log files in an Amazon S3 bucket, select On, and specify the bucket and an optional prefix for the names of the log files. There is no extra charge to enable logging, but you accrue the usual Amazon S3 charges for storing and accessing the files. CloudFront doesn't delete the logs automatically, but you can delete them at any time.\nUpdate an existing CloudFront DistributionSimilar to create a CloudFront distribution, you can update an existing distribution, as shown in Fig. 1.\nFig. 1. Update an Existing Distribution\nModify Origin ServersWhen you create or update a distribution, you provide information about one or more locations—known as origins—where you store the original versions of your web content. CloudFront gets your web content from your origins and serves it to viewers via a world-wide network of edge servers. You can modify your origin settings in CrossFTP, as shown in Fig. 2. Each origin is either an Amazon S3 bucket or an HTTP server, for example, a web server.\nFig 2. Modify Origin Servers\nYou can press the Add button to create a new origin, or press the edit to modify an existing origin. Fig 3. shows the create/update dialog for the origin. The mean features of the origins are shown below:\n- Origin Types: S3 origin and custom origin.\n- S3 Origin: origin is an Amazon S3 bucket, the files must be publicly readable unless you secure your content in Amazon S3 by using a CloudFront origin access identity.\n- Custom Origin: origin is an HTTP server, and the files must be publicly readable.\n- Origin Domain Name: The DNS domain name of the Amazon S3 bucket or HTTP server from which you want CloudFront to get objects\nfor this origin, for example,\n- Origin ID: A string that uniquely distinguishes this origin from other origins in this distribution. If you create cache behaviors in addition to the default cache behavior, you use the origin ID that you specify here to identify the origin to which you want CloudFront to route a request when the request matches the path pattern for that cache behavior.\n- Origin Protocol Policy: The protocol policy that you want CloudFront to use when fetching objects from your origin server. If you specify HTTP Only, CloudFront only uses HTTP to access the origin.\nFig 3. Create/Update an Origin Server\nFor S3 origin, you can make either public or private distribution. Private distribution attention 1: If you want to create a private distribution, you need to create a new origin access identity or use an existing one that is associated with your AWS account. You need also to grant the origin access identity the permission to read objects in your Amazon S3 bucket.\nModify Cache BehaviorsA cache behavior lets you configure a variety of CloudFront functionality for a given URL path pattern for files on your website. For example, one cache behavior might apply to all\n.jpgfiles in the\nimagesdirectory on a web server that you're using as an origin server for CloudFront.\nWhen you create a new distribution, you specify settings for the default cache behavior, which automatically forwards all requests to the origin that you specify when you create the distribution. After you create a distribution, you can create additional cache behaviors that define how CloudFront responds when it receives a request for objects that match a path pattern, for example,\n*.jpg. If you create additional cache behaviors, the default cache behavior is always the last to be processed. Other cache behaviors are processed in the order in which they're listed, as shown in Fig 4.\nFig 4. Modify Cache Behaviors\nYou can press the Add button to create a cache behavior, or press the Edit to modify an existing behavior. Fig. 5 shows the Cache Behavior's editing dialog.\nFig 5. Create/Update a Cache Behavior\n- Path Pattern: A path pattern (for example,\n/images/*.jpg) specifies which requests you want this cache behavior to apply to. When CloudFront receives an end-user request, the requested path is compared with path patterns in the order in which cache behaviors are listed in the distribution. The first match determines which cache behavior is applied to that request.\nYou can use the following wildcard characters in your path pattern:\n*matches 0 or more characters.\n?matches exactly 1 character.\n- Origin: When you're adding cache behaviors to an existing distribution or updating an existing origin, the value of Origin ID for the origin that you want CloudFront to route requests to when a request matches the path pattern either for a cache behavior or for the default cache behavior.\n- Viewer Protocol Policy: The protocol policy that you want viewers to use to access your content in the origin specified by Origin. If you specify HTTP and HTTPS, viewers can use both protocols. If you specify HTTPS Only, viewers are only allowed to access your content if they're using HTTPS.\n- Min TTL: The minimum amount of time that you want objects to stay in CloudFront caches before CloudFront queries your origin to see whether the object has been updated. For more information, see Specifying How Long Objects Stay in a CloudFront Edge Cache (Object Expiration).\n- Forward Query Strings: If your origin server returns different versions of an object based on a query string in the URL, toggle it. If your origin returns the same version of an object regardless of the query string, un-toggle it. This increases the likelihood that CloudFront can serve a request from the cache, which improves performance and reduces the load on your origin.\n- Trusted Signers: add trusted signers only\nwhen you're ready to start generating signed URLs for your objects. After you add trusted signers to a distribution,\nusers must use signed URLs to access the objects that match the\nPathPatternfor this cache behavior. Private Distribution attention 2: you need to have at least one trusted signer before you can sign the URLs for the private distribution objects.\nPrivate Distribution WizardFig. 6 shows the private distribution wizard which helps to create a default private distribution config for your CloudFront. It handles 2 setups: 1. Add/select an origin access identity for your first S3 origin; 2. Add trusted signers for your default cache behavior. You can also setup these items in origin and cache behavior's corresponding dialogs if you do not want to use this wizard.\nFig 6. Private Distribution Wizard\nSign URL for Private Distribution\nFirstly you need to make sure your private distribution is properly configured. Here is a check list:\n- You have setup the Origin Access Identity in some of your S3 Origin, and granted it the read permission in your bucket by policy or by S3 permission setting.\n- You have added the trusted signers in your cache behavior.\nAfter that, you can follow this article to sign the private distribution's content URL with CrossFTP.\nYou can remove one or multiple files from all edge locations prior to the expiration date set on those files. Check this URL for more details: http://crossftp.blogspot.com/2013/07/cloudfront-invalidation-with-crossftp.html\nCrossFTP is a FTP, SFTP, FXP, WebDav, Amazon S3, Amazon Glacier and Google Cloud Storage client for Windows, Mac, and Linux.CrossFTP Team"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:fccdd346-1b9d-484e-8c64-fc4237c262ca>"],"error":null}
{"question":"During storms & flooding - what contaminants affect water safety and how does it impact home waste systems?","answer":"During floods, water becomes contaminated with multiple hazardous substances including sewage, petroleum products, pesticides, herbicides, and waste from farm animals, wildlife and pets. Over 100 types of disease-causing bacteria, viruses and parasites can be present in flood waters. Regarding home waste systems, flooding affects septic systems by causing sewage backups into houses when systems are submerged, washing away soil from system components, and causing sluggish operation due to saturated soil. Power outages during storms can also cause pump failures, leading to raw sewage overflow if storage capacity (typically 100-200 gallons) is exceeded.","context":["Hurricane season preparation for septic systems makes more sense when you understand the risks. The hurricane season officially starts next month, and there are some things you need to know before a major storm threatens the local area.\nHurricane impact on Septic Systems\nFor any type of onsite sewage system, conventional or alternative, a hurricane or flood could submerge the system. If your system is submerged, the excess water may cause a backup of sewage into the house. Look for sewage backups in the plumbing fixtures at the lowest elevations in your house as your first indication.\nFlooding can wash soil away from the septic tank, drain field lines or other components, causing damage to the components or introducing raw or partially treated sewage into the yard. Flooding may also cause the onsite sewage system to operate sluggishly because the soil in the dispersal area is saturated.\nIf your septic tank/drain field system is damaged by the storm or if the soil is saturated, minimize water use within the house to prevent raw sewage from discharging to the ground surface. Minimize contact with sewage contaminated waters. Use gloves and protective gear and wash any exposed skin with soap and water as soon as possible. Disinfect any exposed human contact surfaces with diluted bleach water.\nOnsite sewage systems may fail to operate properly during power outages that are common during hurricane season. Pumps won’t work without power, but most onsite sewage systems with a pump should have 100-200 gallons storage capacity above the high-level alarm. Exceeding this storage capacity could cause the pump chamber to overflow, spilling raw sewage on the ground.\nIf you face this situation, use water sparingly and call Wind River Environmental for a full inspection as soon as the water recedes and power returns.\nWhat Do I Need to Prepare My Septic System For Hurricane Season?\nHurricane preparations for septic systems should start before an emergency:\n- Seal the manhole and/or inspection ports to keep excess water out of the septic tank\n- Be sure your septic tank is at least half full with effluent to prevent it from collapsing or floating\n- If your septic system requires electricity,\n- Turn off the pump at the circuit box before the area floods\n- Waterproof all electrical connections to avoid electrical shock or damage to wiring, pumps, and the electrical system\n- Consider a power generator to run the lift station and prevent a backup into the house\nSeptic System Care After A Hurricane\nPrecautions related to septic systems include:\n- Avoid contact with any septic system electrical devices until they are dry and clean.\n- Do not pump out the septic tank more than halfway or the tank may float out of the ground until the water table returns to normal.\n- Reduce all nonessential water use (for example, dish washing, washing clothes, showering).\n- Flush toilets as little as possible or use a temporary toilet.\nIf you suspect septic system damage, get the system professionally inspected by contact Morse Engineering and Construction.","The best of EcoWatch, right in your inbox. Sign up for our email newsletter!\nReport Looks at Health Threats from Flooding in a Warming World\nExtreme precipitation and flooding, likely on the rise in a warming world, carry significant and often hidden health risks, according to a report, After the Storm: The Hidden Health Risks of Flooding in a Warming World, released today by the Union of Concerned Scientists (UCS).\n“Damage from floods is typically measured in terms of lives lost and the cost of damage to buildings and infrastructure,” said Liz Perera, UCS public health analyst and one of the report’s co-authors. “But what are often overlooked are the potentially costly public health impacts.”\nThe report calls attention to these impacts by listing the top five health risks of extreme precipitation and flooding—drowning while attempting to drive through rising water; drinking contaminated tap water; being exposed to fouled water bodies; coming into contact with backed-up sewage in your home, and being exposed to mold.\n“Over half of all outbreaks of waterborne diseases in the U.S. occur in the aftermath of heavy rains,” said Perera. “Health risks will likely increase as extreme rainfall events are projected to become more common in a warming world.”\nHeavy rains can contaminate drinking and recreational water with sewage, petroleum products, pesticides, herbicides, and waste from farm animals, wildlife and pets. Floodwaters may contain more than 100 types of disease-causing bacteria, viruses and parasites.\n“We think of waterborne illnesses as a problem in developing countries, but it’s a very real public health issue here in the U.S.,” said Dr. Marc Gorelick, division chief of pediatric emergency room medicine at Children’s Hospital of Wisconsin, in Milwaukee. “Climate change, because it likely causes heavier storms, could threaten our already vulnerable water supply and lead to more cases of gastrointestinal illness.”\nGorelick conducted a study which found that between 2002 and 2007, there was an 11 percent increase in gastrointestinal cases at Children’s Hospital within four days of heavy rains.\nThe UCS report also points out that flooded homes and buildings create a breeding ground for mold, which can cause debilitating respiratory and neurological problems. Mental health problems also tend to increase in the wake of extreme weather disasters. These health problems can persist long after flood waters have receded.\nExtreme weather events, such as heavy rains, are also creating challenges for waste water and water treatment plants.\n“Like many older cities, heavy precipitation can put a strain on New York City’s infrastructure,” said Angela Licata, deputy commissioner for sustainability at the New York City Department of Environmental Protection. “We are continually innovating to meet that challenge, while maintaining and improving essential services.”\nOther factors that affect flooding risks include where people live, how land is developed and the investments made in building resilience.\nFor more information, click here.\nEcoWatch Daily Newsletter\nAn area in Louisiana whose predominantly black and brown residents are hard-hit by health problems from industry overdevelopment is experiencing one of the highest death rates from coronavirus of any county in the United States.\nA central player in the fight against the novel coronavirus is our immune system. It protects us against the invader and can even be helpful for its therapy. But sometimes it can turn against us.\nCalling someone a delicate flower may not sting like it used to, according to new research. Scientists have found that many delicate flowers are actually remarkably hearty and able to bounce back from severe injury.\nWith global air travel at a near standstill, the airline industry is looking to rewrite the rules it agreed to tackle global emissions. The Guardian reports that the airline is billing it as a matter of survival, while environmental activists are accusing the industry of trying to dodge their obligations.\nThe outbreak of COVID-19 across the U.S. has touched every facet of our society, and our democracy has been no exception."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:9500836a-52f2-4108-9a52-b11cc8a6a228>","<urn:uuid:fa37c513-4371-450f-8673-0e4e9f4fc2e5>"],"error":null}
{"question":"When did European Commission publish these 3 important documents about rule of law, democracy and fundamental rights?","answer":"The three documents were published in late 2020: the 2020 Rule of Law Report was published on September 30, 2020, while the strategy to strengthen the Charter on Fundamental Rights and the action plan on European Democracy were published on December 2 and 3, 2020, respectively.","context":["A Timely Invitation to Values Realignment: The Commission’s Three ‘Manuals on Constitutional Essentials’\nAs the second decade of the new millennium approaches its close, we cannot but feel tired, worried and disheartened. Covid-19 is still with us and pain, grief owing to the tragic loss of human life, fear and uncertainty have not dissipated. But this is not all. The last twenty years have been quite hard; both testing and troublesome. We have witnessed crises, austerity policies, wars, dictators and demagogues, the demise of honesty and integrity and the erosion of democratic standards even in the oldest democracies as self-serving political elites are keen on calling into question, and undermining, fundamental norms and constitutional essentials.\nReversals and regressions in the conditions of our lives, be they relating to health, livelihood, rights and freedoms, have created a fertile environment for negative discourses and ‘crises talk’, such as the alleged crisis of liberal democracy or the crisis of European integration. But beyond the noise generated by all those who wish to divide and dismantle for their own ideological, or purely self-interested, ends, the European Commission’s initiative to articulate, and to publish, what may be called three ‘manuals on constitutional essentials’ – namely, the 2020 report on the rule of law, a strategy to strengthen the application of the Charter on Fundamental Rights and an action plan on the European Democracy, is laudable. The strategy and the action plan on democracy were published on 2 and 3 December 2020, respectively, while the 2020 Rule of Law Report was published on 30 September 2020.\nThe publication all three documents in chronological proximity reinforces the idea that democracy requires respect for human rights in the same way that respect for the rule of law underpins and effectuates both democracy and human rights. Democracy, rule of law and human rights are both complementary and mutually reinforcing. The timing of the Commission’s intervention is also important. This is not because it could be seen to reflect a supranational mistrust of localism and nationalist politics in the Member States. Nor is it because of Brexit. Nor does Europe need a special reminder of the importance of the values of freedom, equality, democracy, human rights and respect for the rule of law over authoritarian and totalitarian challenges to them. In a continent historically plagued by state aggression, wars, genocide and colonial expansion, such reminders are everywhere at any point in time, provided one wishes to see them.\nThe timing of the Commission’s intervention is important because a) it provides a clearly focused and accurate portrait of an age that is more attuned to power and elite actions than to law and citizens’ rights and b) with it we see a more self-assured position about what the European Union stands for and where it is heading. Taken both separately and together, the three documents focus clearly our minds on the fact that European integration is so much more than economic integration (in fact, it has never been purely about economic integration). They also highlight that European integration is unfolding confidently forward, notwithstanding oppositional noise, in the third decade of the 21st century. It continues to strive to deliver peace, prosperity, respect for human rights, labour, social and environmental protection and fruitful cooperation regionally and globally. And in this process, values, that is, the values of the EU (Article 2 TEU) matter a lot. The commitment to democracy and the rule of law is highlighted in the Charter of Fundamental Rights of the European Union of 7 December 2000, as adapted at Strasbourg on 12 December 2007, which forms part of primary EU law following the entry into force of the Lisbon Treaty (in force on 1 December 2009). Its preamble states that ‘the Union is founded on the indivisible, universal values of human dignity, freedom, equality and solidarity; it is based on the principles of democracy and the rule of law’.\nMore specifically, the 2020 Rule of Law Report is accompanied by 27 country chapters presenting an assessment of the functioning of the justice system, anti-corruption initiatives, media pluralism and other institutional checks and balances in the Member States. It was compiled by the Commission on the basis of active input on the part of the Member States, dialogue with statal and non-statal actors and dedicated virtual country visits. It manifests the European Rule of Law Mechanism – an annual process of inter-institutional cooperation in order to strengthen the rule of law and to address key challenges to it. Having considered measures adopted by the Member States during the Covid-19 pandemic and the impact of emergency powers, the Commission noted that judicial independence remains an issue in the Member States and highlighted the importance of effective anti-corruption national frameworks, including effective criminal legislation to combat corruption. The report also discussed the potential risks arising from restrictions in the exercise of freedom of expression and on access to information and the threats and attacks on journalists and other media actors as well as the independence of media authorities and transparency of media ownership. In the last section of the report entitled ‘other institutional issues linked to checks and balances’, the importance of debates on the rule of law, of an active and activist civil society, efforts to increase the accountability of the executive in the Member States and reduce their reliance on accelerated and emergency legislation was underlined. The Commission hopes that this process will lead to a new dialogue with the Member States and to an enhanced mutual trust. The objective is to sediment ‘a robust political and legal rule of law culture’ in the EU so that its systems function well in line with democratic standards and fundamental rights and freedoms. One discerns in the Report a cautious hope that this will be achieved via dialogue and a reinforced commitment to common principles and values. Following a difficult year, it is refreshing to witness what one may term ‘a positive capability’, that is the Commission’s belief that the antidote to degrading standards in public life is a robust critique of law breaking and a multi-actor dialogue that restores respect for the underlying values of the EU and its Member States and bolsters compliance.\nThe Commission’s strategy to strengthen the application of the Charter of Fundamental Rights acknowledges the increasing importance of the Charter to the protection of people’s fundamental rights and the need for ‘a renewed institutional commitment’ to the effective application of Charter rights and principles. The previous strategy was ten years old and needed a revision in the light of new challenges, such as digitalisation, and developments, including the recent states’ responses to the pandemic. The Commission has built the strategy on the basis of four strands: namely, i) ensuring the effective implementation of the Charter; ii) empowering civil society organisations, rights defenders and justice practitioners; iii) fostering the use of the Charter as a compass for EU institutions and iv) strengthening people’s awareness of their Charter rights. Concrete actions and ‘invitations’ to the Member States to act in specific ways accompany each strand. Through such initiatives a more structured and targeted approach is formed. For example, under the first strand, the Commission will strengthen the partnership with the Member States and local authorities, will invite the Member States to nominate a Charter focal point, will present an annual report on the application of the Charter, will endure EU budgetary conditionalities and will bring infringement proceedings for breaches of EU law. The 2021 new Charter report will focus on fundamental rights in the digital age. The important role of civil society organisations and national human rights institutions will be further enhanced through EU programmes, capacity building and the training of judges and other justice practitioners through the use of EU funds and the tools developed by the Fundamental Rights Agency, such as Charterpedia and the Handbook on the application of the Charter for practitioners. Guidance, e-learning tools and training will also be promoted at EU institutional level and the mainstreaming of the Charter throughout the EU legislative process will be enhanced. The final strand of the strategy focuses on initiatives to promote people’s awareness of their Charter rights and to citizen empowerment.\nThe ‘third manual on constitutional essentials’, namely, is the action plan on European democracy. This communication seeks to address key challenges to democracy and citizen participation arising from restrictions to freedom of expression and media pluralism, digitalisation, rising extremism, authoritarianism, election interference and the spread of manipulative information. It announces concrete measures (these will be reviewed in 2023) in order to: a) protect free and fair elections and democratic participation, b) strengthen media freedom and pluralism and c) counter disinformation irrespective of the geographical location of its source. More specifically, in order to protect the resilience of EU democracies, the Commission will propose legislation in the area of sponsored content in a political context (‘political advertising’) thereby addressing online campaigning and micro-targeting and behavioural profiling techniques. This proposal will complement the rules on online advertising which will be contained in the forthcoming Digital Services Act. It will also propose a revision of the Regulation on the funding of European political parties and European political foundations. The Commission will also set up a new joint operational mechanism through the European Cooperation Network on Elections to support the deployment of joint expert teams and to work closely with the NIS (security of information systems) Cooperation Group to counter threats to electoral processes. It will continue to promote EU citizenship rights and inclusive, deliberative and participatory democracy in many ways including by funding research under Horizon 2020 and its successor, Horizon Europe programme, the forthcoming Conference on the Future of Europe, the EU youth strategy (2019-2027), and by mainstreaming equality and combatting hate crime and hate speech. To strengthen media freedom and media pluralism and to safeguard a safer work environment for journalists, the Commission will propose a recommendation on the safety of journalists and will present an initiative to combat the abusive use of lawsuits against public participation (SLAPPs). An effective tool towards the promotion of media pluralism will be the establishment of a new Media Ownership Monitor – a database on media ownership which is envisaged to apply to all 27 Member States. In countering disinformation and election interference, the action plan states that the Commission will enhance the EU’s existing toolbox for countering foreign interference in our information space by including new instruments that envisage the imposition of sanctions on perpetrators, the framework of obligations and accountability for online platforms in line with the upcoming Digital Services Act and the review of the Code of Practice on disinformation in spring 2021. The General Data Protection Regulation will also be effectively enforced with respect to online platforms. In sum, the action plan does not deliver a blueprint for European democracy. That was not the European Commission’s intention. It simply focuses attention to the undermining of democratic institutions and practices that has been observed during recent years and calls for the enhancement of citizen participation in the political process and for the upgrading of the functioning of democratic frameworks in the light of new challenges and digital realities.\nTaking a combined view, the 2020 Rule of Law Report, the new Strategy for the implementation of the EU Charter of Fundamental Rights and the Action Plan on European democracy demonstrate the responsibilities of all institutions and organisations vertically as well as horizontally in this area and delineate four well-considered steps to values realignment; namely, step 1: reflect and correct; step 2: respond, liaise and solve; step 3: move forward with clarity and commitment and step 4: change and manifest, that is, undo the resistance to change and manifest an uncompromising approach to upholding the values of democratic constitutional societies and of the European Union (Article 2 TEU). After all, these values are both the foundation and the context for the flourishing of persons, organisations and institutions, societies and polities.\n ‘The European Union is not only about parties and politics, rules or regulations, markets or currencies. It is ultimately — and above all else — about people and their aspirations. It is about people standing together. For their liberty, for their values, simply for a better future.’ Commission President von der Leyen, 27 November 2019 cited in the European Democracy Action Plan, COM(2020) 790 Final, Brussels, 3 December 2020."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:2ed6f293-615b-4cb7-bbad-74731bf76b12>"],"error":null}
{"question":"For my interior design project, I need to understand - what is the approach to combining modern and traditional elements in the Nucleo exhibition and the Dallas kitchen renovation?","answer":"Both spaces blend traditional and modern elements but in different ways. The Nucleo exhibition merges vintage furniture and artifacts from a 1940s apartment with contemporary concrete forms to create hybrid sculptures, challenging viewers to reconfigure these familiar-yet-strange objects. The Dallas kitchen similarly combines traditional elements (reclaimed Douglas-fir ceiling beams, white-oak flooring) with modern features (Tom Dixon pendant lights, lacquer-finish cabinets, Neolith countertops), but does so to create a functional living space that balances rustic Mediterranean style with contemporary design.","context":["|Title||Nucleo. The Law of Past Experience||Posted In||Art, Exhibition||Duration||26 September 2017 to 25 November 2017|\nVia Paisiello 6\n20131 MILAN MIItaly\nA project curated by Atto Belloli Ardessi and Ginevra Bria.\nBoolean is a series of hybrid sculptures that Turin-based art collective Studio Nucleo has created by coupling disparate elements like vintage furniture and cast concrete based on the application of Boolean operators. The series is currently being showcased at FuturDome in Milan — a turn of the 20th century, Art Nouveau building that has been renovated by the International Institute of Futurist Studies into an experimental art space.\nBoolean logic, named after English mathematician and computer pioneer George Boole, established the use of operators like “NOT”, “OR” and “AND” that we now use in web searches. It is precisely the application of such operations of subtraction, intersection and union that Nucleo unleashes upon a trove of vintage artefacts like antique timber furniture, bronze sculptures and ceramic plates which were selected from the furnishings of a 1940’s apartment.\nThe sculptural pieces produced through these operations are enthralling: a leather-upholstered chair is pierced by a concrete mass that magically hovers above the ground, an ornate wooden footboard is bisected by a thin concrete slab, while a slender wooden cabinet has been cut in half, its top part resting on the ground as if the rest of its body has been sunk into the floor, while a concrete block has taken its place on top of the cabinet’s lower half. Perceptually, the resulting artworks, which also include vintage sculptures that have been merged with polished bronze blocks, are not so much the product of bringing together two distinct elements but rather the hybrid offspring of their physical union.\nOther exhibits are products of subtraction like the vintage veneer commode that has been robbed of its depth, the remaining sliver exhibited as a timber bas-relief, and the series of ceramic plates that feature geometric cut-outs. In all cases, although the operations of addition and subtraction seem effortless, the technical skill required to produce such flawlessly constructed, one-of-a-kind pieces is extraordinary.\nThe exhibition, which is curated by Atto Belloli Ardessi and Ginevra Bria, and runs until 25 November 2017, is titled “The Law of Past Experience”, a reference to one of the best-known principles of Gestalt psychology. This particular law, which postulates that under certain circumstances visual stimuli are categorized according to past experiences, underpins the Boolean series. In practical terms, it means that when our field of vision encounters a group of unfamiliar elements, our brain “sees” shapes or figures according to our mnemonic vocabulary, sometimes completing or uniting what our eyes perceive as incomplete or fragmented. In this sense, Nucleo encourages viewers to use their imagination to reconfigure the strange yet familiar objects in front of them according to their own subconscious templates.\nIn computer science, Boolean signifies a data type that has two possible values: 0 (false) and 1 (true). Therefore, the two diametrically-different components of Nucleo’s hybrid sculptures can also be said to represent contrasting concepts such as falsehood and truthfulness, past and present, and shape and abstraction. It is up to the viewer of course to determine which value corresponds to which element. More than that, the sculptural union of such opposing concepts, and the resulting refutation of their absolute nature, can thus be interpreted to symbolize the subjective nature of reality as we experience it.","You are here\nFunctional & Stylish Dallas Kitchen\nThe classic white kitchen goes glam with metallic accents and a dash of color\nSmartphone pointed skyward, Monica Eastin shot for the stars—or what would turn out to be an unexpected star in her new kitchen—capturing the glimmer of Tom Dixon mirror ball pendants shining down the stairway at the Dallas flagship Neiman Marcus store.\n“When I saw that photo, I knew I had been playing it too safe,” designer Morgan Farrow says. “The lights were so modern, and I hadn’t been going there. But then I saw they would bring in a little sparkle, a touch of feminine glam to Monica’s kitchen.”\nFarrow started out with the goal of creating a kitchen functional enough for a Dallas couple with three young kids and stylish enough for serious entertaining. “I was thinking rustic Mediterranean meets contemporary, with a fresh palette,” she says. “Monica’s previous kitchen was very Tuscan, and I knew she wanted the opposite of that—light and bright.”\nFarrow brought in the bright with white walls and custom cabinetry painted in Benjamin Moore’s “Seapearl” with a lacquer finish. That creamy white continues on the waterfall island top, backsplash, and perimeter countertops, which look like elegant Calacatta marble but are actually Neolith, a compressed natural stone surface that shrugs off pretty much everything, even bleach and scrubby pads.\nReclaimed beams and white-oak flooring lend earthy undertones to Monica Eastin’s Dallas kitchen. The elegance of a marble-look backsplash meshes with feminine sparkle conveyed by Tom Dixon pendants, a brass-banded range hood by Modern-Aire, bar stools by Gabby Home, and hardware custom-plated by local artisans.\nPhotography: Nathan Schroder\nProduced by Jenny O’Connor\nArchitect: Stocker Hoesterey Montenegro Architects, 4514 Travis St., Suite 302, Dallas, TX 75205; 214/252-3830, shmarchitects.com.\nInterior designer: Morgan Farrow, Morgan Farrow Interiors, 5924 Royal Lane, Suite 150, Dallas, TX 75230; 214/532-0426, morganfarrow.com.\nBuilder: Tatum Brown Custom Homes, 5924 Royal Lane, Suite 150, Dallas, TX 75230; 214/361-4877, tatumbrown.com.\nBeauty in Brass\nAn all-white kitchen, though, wasn’t the end goal for Farrow. “I think it makes a kitchen feel too floaty,” she says. So she brought in earthy elements—reclaimed Douglas-fir ceiling beams and white-oak floors—and rich color.\n“I wanted a punch,” the designer says. “I flipped open a paint deck and boom—I saw the navy blue I knew would be perfect on the perimeter cabinets.”\nShe had big cards painted with Sherwin-Williams “Outerspace” and left them hanging in the kitchen until she and Monica were sure the color looked good at all times of day.\nThe final layer of pizzazz comes from a mélange of brass, from the pendants to bar stools—and a showstopping La Cornue range.\n“I saw Monica eyeing it in the showroom,” Farrow says. “She told me, ‘That’s what I want. It’s so pretty.’ I couldn’t argue with that. Holy cow—it’s beautiful!”\nAll the head-turning beauty could make it easy to overlook the kitchen’s function, but it’s there—in spades.\n“I wanted the space to flow so we didn’t have the problem of people gathering in the kitchen and blocking the way to the refrigerator or oven,” Monica says.\nIsland seating is convenient to the Miele refrigerator, built into pretty blue cabinetry.\nCabinetry (custom design by Morgan Farrow Interiors): Douglas Custom Cabinets, douglascustomcabinets.com.\nCabinet paint, light (“Seapearl” #961, lacquer finish): Benjamin Moore, benjaminmoore.com.\nCabinet paint, gray (“Outerspace” #SW 6251, semi-gloss): Sherwin-Williams, sherwin-williams.com.\nPainting: by David Jennings Painters Inc., davidjenningspainters.com.\nCabinetry hardware (tab pulls from Europa Collection by Top Knobs; pulls #9006 by Omnia): Pierce Hardware, Dallas, piercehardware.com.\nHardware finish (custom plated in satin brass finish): Noles-Davis Antique Restoration, noles-davis.com.\nCountertops: Neolith Estatuario.\nFabricator: IL Granito, il-granito.com.\nWood windows: CG Serramenti, cgserramenti.it.\nSteel windows: Rehme Steel Windows & Doors, rehmesteel.com.\nCeiling beams (reclaimed douglas fir): Heritage Restorations, heritagebarns.com.\nFlooring (7.5-inch engineered classic grade European white oak in random lengths with Bona Natural finish): through French-Brown Floors, french-brown.com.\nRange (60-inch range in Stainless Steel and Satin Brass): La Cornue, lacornueusa.com.\nHood (custom): Modern-Aire Ventilation, modernaire.com.\nRefrigerator/freezer (36 inches); steam oven; microwave; oven; dishwashers: Miele, mieleusa.com.\nWarming drawers: Wolf, subzero-wolf.com.\nAppliance distributor: Capital Distributing, capitaldistributing.com.\nFaucet (“Modern Architectural Side Lever Pull-Down Kitchen Faucet”/Polished Nickel, #LS59, by Rohl); pot filler (“Modern Architectural Pot Filler”/Polished Nickel #QL66, by Rohl); soap pump (“Modern Luxury Soap/Lotion Dispenser”/Polished Nickel #LS2150, by Rohl); hot water (“Perrin & Rowe Contemporary Filter Faucet”/Polished Nickel #U.1601): Ferguson, ferguson.com.\nLights over island (“Mirror Ball Pendant Light”/Gold, 15.7 inches, by Tom Dixon): Y Lighting, ylighting.com.\nBar stools (“King Counter Stool” #SCH151140): Gabby Home, gabbyhome.com.\nA smart floor plan moves traffic to the adjacent family room as it also establishes distinct zones in the kitchen. A galley-style work area includes the range, ovens, and main sink. On the opposite side of the room, a breakfast area is serviced by a second sink and dishwasher. A cold-storage wall made beautiful by blue, furniture-style cabinets bridges the two spaces and keeps beverages handy for anyone at the island.\n“The kids like to sit there and do their homework or have a snack,” Monica says, “so it’s really convenient.”\nA second blue “tower” near the showpiece range keeps necessities at hand.\nCabinets built into the island hold her baking pans, panini press, and party supplies. Other cabinets boast pullout drawers with pegs that keep essentials in place and at hand. “I’m never digging in the back of a cabinet,” Monica says. Built-in electrical outlets mean the toaster and coffeemaker can stay in their home cabinets rather than take up counter space. There are even built-in bins for trash and recyclables.\n“I have to be organized for my brain to work,” Monica says. “I love how everything in this kitchen is thought-out. That makes it work perfectly for the way we live.”\nAn RH table extends to seat 12. More of the leather chairs can be easily pulled in—they’re also used in the study.\nDining table (“1900s Boulangerie Rectangular Extension Table”/Salvaged Grey): Restoration Hardware, rh.com.\nDining chairs (“Bella,” by Frag): Ultramodern, umodern.com.\nGreen bowl on table: Mecox, mecox.com. Art (by Kristen Dowd): Gypsy Soul Interiors, gypsysoulinteriors.com.\nFlowing from the kitchen, the family room beckons with great views and comfortable furniture, including rolling ottomans that pull out for game night. Glass art on the walls adds a playful punch.\nWall paint (“Cloud Cover” #OC-25): Benjamn Moore, benjaminmoore.com.\nArea rug (custom): Interior Resources, intre.biz.\nSofa (“Egan Sofa with Tapered Leg”): Bright Chair, brightchair.com.\nSofa fabric (“Lauren”/Steel #L8919-08, by Larsen): Cowtan & Tout, cowtan.com.\nPillows on sofa, at back (“Meriden”/Pebble #6737-2200): Opuzen, opuzen.com.\nPillows on sofa, at front (from Bunglo by Shay Spaniola); acrylic table by lounge chair: through Laura Lee Clark Showroom, lauraleeclark.com.\nSofa end tables (“Marble-Topped Pedestal Side Table”/Marble, Antique Brass): West Elm, westelm.com.\nLounge chairs (“Belgian Classic Slope Arm Upholstered Chair”); chair fabric (“Perennials Classic Linen Weave”/Sand): Restoration Hardware, rh.com.\nThrow: Mecox Dallas, 214/580-3800.\nCommodes flanking window (“Pierre Dresser”); coffee table (custom-sized “Sorin”/Off-White Faux Shagreen): Made Goods, madegoods.com.\nLamps on commodes (“Flanders”): Mr. Brown London, mrbrownhome.com.\nArt pieces on wall behind commodes (“Catch,” by SkLO Studios, discontinued); ottomans by coffee table (“Patina,” by DellaRobbia, modified to fit under coffee table): through Contempo Designs, contempodesigns.com.\nFloor lamp by lounge chair (“Brompton Swing Arm Floor Lamp”/Natural Brass with Linen Shade #RL1500, by Ralph Lauren): Circa Lighting, circalighting.com.\nOttoman fabric (“VO-Veluce”/Blue Mist #05VE-8358-B): Rodolph, rodolph.com.\nFire screen (discontinued): Arteriors, arteriorshome.com.\nTelevision on fireplace: Samsung, samsung.com/us.\nFireplace stone: rough-cut Texas Lueders Limestone.\nMantel: smooth-cut Texas Lueders Limestone.\nA kid-friendly zone near the kitchen features a chalkboard wall, ample storage, and playful furnishings."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:69786f96-10cc-4561-a732-528d32a93a09>","<urn:uuid:cf02ebf8-4b1d-42c2-8fc7-c1a1c40be4a3>"],"error":null}
{"question":"What was the traditional hunting method used by Osage people before they had horses?","answer":"Traditionally, Osage men hunted buffalo by driving them off cliffs. After they acquired horses from European colonists, they switched to hunting buffalo on horseback instead.","context":["Native American Facts For Kids was written for young people learning about the Osage Indian\ntribe for school or home-schooling reports. We encourage students\nand teachers to visit our main Osage site\nfor more in-depth information\nabout the tribe, but here are our answers to the questions we are most often asked by children, with\nOsage pictures and links we believe are suitable for all ages.\nHow do you pronounce the word \"Osage\"? What does it mean?\nOsage is pronounced \"oh-sage\" in English, but in their own language, it is pronounced similar to \"wah-zah-zhay.\" The pronunciation got changed\nso much because it was first written down by French speakers (who don't have any W in their language and pronounce soft g's like ZH, as\nin mirage), and then later the word was re-pronounced by English speakers.\nWhere do the Osages live?\nThe Osage Indians are original people of Oklahoma,\nMost Osage people live in Oklahoma today.\nHow is the Osage Indian nation organized?\nThe Osages live on a reservation, which is land that belongs to them and is under their control.\nThe Osage Nation has its own government, laws,\npolice, and services, just like a small country. However, the Osages are also US citizens and must obey American law.\nIn the past, each Osage band was led by a chief who was chosen by a tribal council. Today, the Osage chief is elected by all the tribal members.\nWhat language do the Osage Indians speak?\nThe Osage people speak English today. Only a few Osage people, mostly elders, still speak their native Osage language.\nBut some young Osage Indians are working to learn their ancient language again.\nIf you'd like to know an easy Osage word,\n\"howa\" (pronounced hoh-wah) is a friendly greeting.\nWhat was Osage culture like in the past? What is it like now?\nHere's a link to the homepage of the Osage Tribe.\nOn their site you can find information about the Osage people in the past and today.\nHow do Osage Indian children live, and what did they do in the past?\nThey do the same things all children do--play with each other, go to school and help around the house.\nMany Osage children like to go hunting and fishing with their fathers. In the past, Indian kids had more\nchores and less time to play in their daily lives, just like colonial children. But they did have\ndolls, toys, and games to play.\nHere is a picture of a hoop game\nplayed by Plains Indian kids.\nAn Osage mother traditionally carried a young child in a\non her back--a custom which many American parents have\nWhat were men and women's roles in the Osage tribe?\nOsage men were hunters and sometimes went to war to protect their families. Osage women were farmers\nand also did most of the child care and cooking.\nOnly men became Osage chiefs, but both genders took part in storytelling, artwork and music, and traditional medicine.\nWhat were Osage homes like in the past?\nMost Osage Indians lived in settled villages of round earthen lodges. Osage lodges were made from wooden frames\ncovered with packed earth. When the Osage tribe went on hunting trips, they used buffalo-hide\ntipis (or teepees) as temporary shelter, similar to camping tents.\nHere are some pictures of lodges, tipis, and other Indian houses.\nToday, Native Americans only put up a tepee for fun or to connect with their heritage, not for housing.\nMost Osages live in modern houses and apartment buildings, just like you.\nWhat was Osage clothing like? Did the Osages wear feather headdresses and face paint?\nOsage women wore long deerskin dresses and leggings, which they decorated\nwith fancy beadwork and ribbon applique.\nOsage men wore breechcloths with leather leggings.\nThe Osages wore moccasins\non their feet, and in cold weather, they wore long buffalo-hide robes.\nLater, Osage people adapted European costume such as cloth dresses and vests.\nHere is a site with pictures of Osage ceremonial garments,\nand some photos and links\nabout Indian clothing in general.\nOsage Indian leaders sometimes wore the long\nNative American warbonnets that Plains Indians are famous for,\nbut more often, they wore headbands or turban-like caps made of otter fur, with feathers sticking up in the back.\nSome Osage warriors shaved their heads except for a scalplock (one long lock of hair in back) and\nwore a porcupine roach on top. Other Osage men wore their\nhair long. Osage women wore their hair either loose or braided.\nBoth men and women wore tribal tattoos, which were marks of honor\nthat only distinguished warriors and their wives or daughters could earn.\nAll Osages could paint their faces for special occasions.\nThey used different patterns for war paint, religious ceremonies, and festive decoration.\nToday, some Osage people still have moccasins or a buckskin dress, but they\nwear modern clothes like jeans instead of breechcloths...\nand they only wear traditional regalia on special occasions like a wedding or a dance.\nWhat was Osage transportation like in the days before cars? Did they paddle canoes?\nNo--the Osage Indians didn't live near the ocean.\nWhen they traveled over land, the Osages used dogs pulling travois (a kind of drag sled) to\nhelp them carry their belongings. There were no horses in North America\nuntil colonists brought them over from Europe.\nWhat was Osage food like in the days before supermarkets?\nThe Osage Indians were big game hunters. They especially liked to hunt buffalo. Traditionally, Osage men hunted buffalo by driving them off cliffs,\nbut once they acquired horses, the men hunted buffalo on horseback instead.\nOsage women worked together to raise crops of corn, beans, squash, and pumpkins. Here is a website with more information\nabout American Indian crops.\nWhat were Osage weapons and tools like in the past?\nOsage hunters used bows and arrows. The Osage were known for their especially well-made longbows.\nIn war, Osage men fired their bows or fought with war clubs and spears.\nHere is a website with pictures and information about weapons of Native Americans.\nWhat other Native Americans did the Osage tribe interact with?\nThe Osages traded regularly with other tribes of the Great Plains and the Western Plateau. Osage traders often delivered goods between\nsouthern tribes like the Comanches and northern\ntribes like the Sioux.\nThese tribes usually communicated using the Plains Sign Language.\nThe Osages also fought wars with other tribes. Plains Indian tribes treated war differently than\nEuropean countries did. They didn't fight over territory but instead to prove their courage, and so Plains Indian war parties\nrarely fought to the death or destroyed each other's villages. Instead, their war customs included\ncounting coup (touching an opponent in battle without harming him),\nstealing an enemy's weapon or horse, or forcing the other tribe's warriors to retreat.\nSome tribes the Osages frequently fought with included the\nWhat are Osage arts and crafts like?\nOsage artists are famous for their woodcarving and\nHere is a museum website with photographs of different Osage art forms.\nWhat kinds of stories do the Osages tell?\nThere are lots of traditional Osage legends and fairy tales. Storytelling is very important to the\nOsage Indian culture. Here is one story about\nhow the spider became the symbol of the Osage tribe.\nWhat about Osage religion?\nSorry, but we cannot help you with religious information. Religions are too complicated and culturally sensitive to describe appropriately\nin only a few simple sentences, and we strongly want to avoid misleading anybody. You can visit this site to learn more about\nOsage religious beliefs or this site about\nNative American religion in general.\nCan you recommend a good book for me to read?\nYou may enjoy a biography of famous Osage dancer Maria Tallchief, such as\nTallchief: America's Prima Ballerina.\nIf you want to know more about Osage culture and history, two good books for kids are\nNorth American Indians Today: Osage\nand Native Peoples: The Osage.\nA more advanced book for older kids is\nThe Osage in Missouri.\nYou can also browse through our reading list of recommended Native American books in general.\nHow do I cite your website in my bibliography?\nYou will need to ask your teacher for the format he or she wants you to use. The authors' names are Laura Redish and\nOrrin Lewis and the title of our site is Native Languages of the Americas. We are a nonprofit educational organization\nworking to preserve and protect Native American languages and culture. You can learn more about our organization\nhere. Our website was first created in 1998 and last updated in\nThanks for your interest in the Osage Indian people and their language!\nLearn More About The Osages\nOsage Indian Tribe\nAn overview of the Osage people, their language and history.\nOsage Language Resources\nOsage language samples, articles, and indexed links.\nOsage Culture and History Directory\nRelated links about the Osage tribe past and present.\nOsage Indian vocabulary lists.\nReturn to our Native American Indians homepage for kids\nReturn to our menu of American Indian tribes\nAmerican Indian Heritage\nAmerican Indian Names\nAmerican Indian Poetry\nWould you like to help support our organization's work with endangered American Indian languages?"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:aac61bcf-9acd-40ac-ba99-eae46b3d0f3d>"],"error":null}
{"question":"What are rip currents and what safety measures should swimmers take when encountering them?","answer":"Rip currents are seaward-oriented currents that develop from one or more feeders through cross-shore channels in the beach. They form when opposing longshore currents meet in the inner surf zone or when structures force currents seaward. Rip currents can be identified by dark patches with rippled surfaces and reduced wave breaking surrounded by areas of intense breaking. If caught in a rip current, swimmers should not panic or fight against the current. Instead, they should stay afloat by treading water, wave an arm toward shore for help, and swim parallel to the coastline until free of the current before using incoming waves to return to shore.","context":["Rip currents are worldwide recognized as a major hazard on beaches exposed to energetic waves. The American Life Saving Association and the Royal National Lifeboat Institution reported that between 70% and 80% of all rescues in US and England are due to rip currents. The victims are not only children or people with low aquatic confidence, but also adults with good swim skills have been reported as victims. Beach lifeguards usually warn beach-goers through a flag system in which red flag means that swimming is forbidden. This warning system is based on practical experience of lifeguards who can recognize severe storms and dangerous conditions potentially leading to the development of strong rip currents. So, rip currents are something to be concerned about but what are they and how do they develop? This post tries to answer to these questions.\nOne of the first theoretical notions that one learns about sea waves is that they are able carry energy but not water. Water flows forward under the crest and backward under the trough, so that the net balance is close to zero. However, this in not valid in the surf zone. In fact, broken waves propagate within the surf zone developing a turbulent and air-entrained front, called the roller, in which water is tumbling down from the crest toward the trough. Whereas, particles in the water column still oscillate forward and backward under crests and troughs, particles in the roller are pushed shoreward traveling at the same speed of waves. This water pushed shoreward must somehow go back to the sea.\nIt must be said that natural beaches are not longshore uniform but they present variations in the submerged beach bottom. This irregularity leads to an alongshore variations of the wave force: wave energy is focused on shallow bars where eventually wave breaking takes place. These areas with intense breaking are normally know as “peaks”. Water is pushed shoreward by broken waves increasing the mean water level in the inner surf zone and giving rise to longshore currents flowing in shallow waters away from these areas of intense wave breaking. These longshore currents are called rip feeders. Rip currents are seaward oriented currents that usually develop from one or more feeders through highly localized cross-shore channels that cut the submerged beach. Basically, a rip current can generate when two opposing feeders meet in the inner surf zone, or when a headland or a structure blocks a feeder that is forced to turn into a seaward flowing rip current. Rip currents are not always directly cross-shore oriented but they can also show an angle with respect to the shoreline especially during oblique wave incidence.\nSummarizing, on natural beaches cyclic circulation systems develop under wave forcing. These systems are usually characterized by: 1) a shoreward water flux in the breaking zone, 2) a longshore current (the feeder) flowing within the inner surf zone, 3) a seaward water current (rip current) taking place on relatively narrow and deep cross-shore channels and 4) an expansion of the current in the head of the rip towards the breaking zone, closing the circuit. This is a ideal case that usually occurs on natural beaches, however in some cases the circuit is not closed, meaning the the water in the rip is pushed away from the surf zone leaving the rip system. Since the current system location and spacing reflects the beach morphology characterized by bars and channels, these rip currents are know as morphologically controlled. Moreover, rip currents flowing seaward through channels trigger a feedback mechanism in which erosion of bed channels is enhanced by currents.\nCrucial question: how can one spot a rip currents? The main indicator of a rip is the absence (or a reduction) of wave breaking in a limited area inside the surf zone surrounded by areas with intense wave breaking. Because rip currents flow through narrow and relatively deep channels in the opposite direction of waves, these areas are characterized by dark patches with a rippled surface. The configuration of rip systems can be misleading for beach-goers that can think that areas with limited wave breaking are safer, actually it happens the opposite. On the other hand, someone able to correctly spot rip systems can take advantage of them. For instance, this is the case of experienced surfers that use the rip current help to save energy and reach the peak faster.\nLet’s close with a curiosity. In the past years, people were used to refer to rip currents as to rip tides. For instance, in the movie “Big Wednesday”, during the last scene with the big swell hitting the beach the loudspeaker warned about the presence of strong rip tides: “Get out of the water! You are in a riptide!”. However, strictly speaking nearshore currents during massive swells are not generated by tides. Although the intensity of rip currents can change depending on the tide (stronger rip currents are usually observed at low tide), we have seen that the only rip current forcing is due to the presence of wind-generated waves breaking on a shore.","Take safety precautions around water this weekend – NSRI\nA long weekend, the full moon Spring tide, stormy weather and the South African Heritage Day celebrations combine to bring cautionary advice from Sea Rescue to sea users and inland water users:\nNSRI urge sea users and inland water users to exercise extreme caution in and around water this long weekend.\nBoaters and paddlers at sea and on inland waters, bathers at beaches and at dams, rivers, lakes and swimming pools and anglers fishing from the coastline and along the banks of flooded rivers, swollen dams and lakes are urged to exercise extreme caution over this long weekend.\nVery rough sea conditions can be expected to last well into next week following the series of cold fronts converging over our coastline. This coupled with the full moon Spring tide will result in dangerous sea conditions along the entire coastline.\nSpring tide happens twice during every month of the year at full moon and at new moon and lasts for a few days leading up to the full moon and the new moon, peaking on the day of the full moon and the new moon, and lasting for a few days after the full moon and the new moon. Spring tides affects every coastline bringing higher than normal high tides, lower than normal low tides and hence stronger than normal rip currents.\nThere are two high tides and two low tides every day of the year. Rip currents have two distinct patterns: 1. They form naturally at different places constantly throughout the day along the coastline causing a strong current of water to be swept out to sea against the incoming waves and 2. at some places, like at river mouths, piers, rocky outcrops, reefs and at islands, rip currents are a constant fixture.\nRip currents are most severe during the twice monthly Spring tides. It is not uncommon for people wading in shallow surf to be swept off their feet and swept out to sea by rip currents, particularly during the Spring tide}.\nAnyone caught in a rip current should not panic and should simply make every effort to stay afloat while the rip current sweeps you out to sea. Do not fight against the current. Stay afloat by treading water – moving your arms and legs in circular movements.\nWave an arm towards shore and scream for help to alert people on the shore that you are in trouble. At your first opportunity swim across the beach front, parallel to the coastline, until you are free of the rip current and then use the incoming waves to get back to shore.\nBoaters and paddlers should wear their life-jackets at all times when on water, carry and be familiar with the use of safety equipment, let a responsible person know their departure time, their exact planned route and their return time, stick to your planned intentions, and have the Sea Rescue emergency phone number stored in your phones.\nBathers should go to beaches when and where lifeguards are on duty and swim within the demarcated safe swimming zones posted by the lifeguards on beaches.\nAnglers should never turn their back on the sea while fishing from the shore and be aware of and stay well clear of the high water mark especially during the Spring tide.\nChildren should have responsible adult supervision around all water – swimming pools, the sea, rivers, dams, lakes and even pools of water collected from storm rain.\nAlcohol should not be consumed when embarking on water activities.\nBoaters and paddlers on capsized craft should make every effort to not try to swim to shore but rather to stay with the floatation of their capsized craft.\nIt is strongly advised that people witnessing someone in trouble in water that they do not try to rescue the victim themselves for fear that they may get into difficulty themselves. People who see someone in trouble in water should call the emergency services and stay on the scene so that you can pin point, to the arriving rescue teams, the exact location of the person or persons in difficulty. Do not try a rescue effort yourself unless you have already alerted the emergency services and then only if you are a very good and competent swimmer, have swimming aids, like flippers, and have floatation devices with you to aid in any rescue effort.\nThe NSRI also urge an extreme safety conscious approach around swimming pools and inland water ways.\nWater activities require a safety conscious and responsible approach at all times.\nFollow St Francis Chronicle on Twitter: @stfranchronicle\nAll articles edited or written, all photos taken plus all adverts designed by the Editor and printed in the St Francis Chronicle are protected by the law of Copyright ©. Reproduction or copying of any part of the contents of this newspaper and its concept and design can only be done with the Editor’s written permission."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:7ceaea16-53df-4a76-8f2f-eb517924215d>","<urn:uuid:14203764-cea6-401d-92d5-972875264640>"],"error":null}
{"question":"How does the cooking time compare between colossal shrimp and hush puppies when deep frying?","answer":"When deep frying, colossal shrimp take about 2 minutes per side to cook fully, while hush puppies need to be fried until golden brown, taking 6 to 10 minutes total. The cooking time difference is due to their different compositions - shrimp are done when they turn pink and curl into a 'c' shape at 145°F, while hush puppies, being made of cornmeal batter, need more time to cook through completely.","context":["Serving Size (1/10 2 hush puppies), Calories 100 (Calories from Fat 60), Total Fat 7g (Saturated Fat 1g, Trans Fat g), Cholesterol 25mg, Sodium 390mg, Total Carbohydrate 23g (Dietary Fiber 1g, Sugars 2g), Protein 4g; Percent Daily Value*: Vitamin A %, Vitamin C %, Calcium 10%, Iron 10%. The main ingredient in hush puppies is always going to be cornmeal, we also add buttermilk, egg and a leavening ingredient, usually baking soda. These homemade hush puppies most often served with those other Southern classics: fried fish, shrimp boil , fried chicken and collard greens .\nWhen we eat crappie, we also like to make hush puppies. My husband developed his own hush puppies recipe and they are really delicious. He says the secret is to include diced green bell pepper in the batter. To make Hush Puppies, start by combining the dry ingredients – cornmeal, flour, and salt. Add buttermilk or water and stir until the dry.\nHow to make hush puppies without buttermilk. Hush puppies are mouth watering good and so easy to make. With a golden brown crunchy outside and a tender, flakey inside these hush puppies are sure to please family and friends at your next southern dinner. Simply mix together the hush puppies batter and add them by the spoonful into a hot oiled pan. The smart cooking sidekick that learns what you like and customizes the experience to your personal tastes, nutritional needs, skill level, and more. Heat 2 inches of oil to 365 degrees F (185 degrees C). Drop batter by rounded teaspoonfuls in hot oil, and fry until golden brown. Cook in small batches to maintain oil temperature.\nJiffy Hush Puppies are the crispiest, lightest hush puppies ever. So easy to make with a box of Jiffy Corn Muffin Mix. Makes a great side for flounder, fried shrimp, BBQ, fried chicken or Low Country Boil.. I always have boxes of Jiffy Corn Muffin Mix in my pantry. Jalapeño-Pineapple Hush Puppies: Prepare recipe as directed, stirring in 1/2 cup canned pineapple tidbits and 2 to 3 Tbsp. seeded and diced jalapeño pepper with cornmeal mix in Step Shrimp-and-Corn Hush Puppies: Prepare recipe as directed, reducing buttermilk to 3/4 cup and stirring 1 1/2 cups chopped cooked shrimp (about 3/4 lb. peeled) and. Fold buttermilk mixture, onion, and green onions into cornmeal mixture until just mixed. Drop 6 to 8 tablespoon-sized balls of batter into the hot oil; fry until each hush puppy is golden brown, turning the hush puppies to cook evenly, 6 to 10 minutes. Remove hush puppies with a slotted spoon and place on brown paper bags to drain.\nI tried it before, and I wasn’t pleased – AT ALL. Boxed, and store bought hush puppies ( in my opinion of course) are either too bland, too salty, or just flat out YUCK. I just don’t care much for it. Maybe I just haven’t had the right brand. I don’t know. But what I do know it, making homemade southern hush puppies is a breeze! Here's a healthier alternative to the usual deep-fried hush puppies. I think these look like mini corn muffins, but they taste the way a hush puppy should. Originally from an August 1983 issue of Bon Apetit from \"The Cook's Exchange Readers' Best Recipes\". Directions. In a large bowl, combine first seven ingredients. Add egg and buttermilk; stir until dry ingredients are moistened. Set aside at room temperature for 30 minutes.\nHomemade Hush Puppies. Hush Puppies are little round golf ball-sized savory, deep-fried fritters made from a cornmeal-based batter.Hushpuppies are a classic side dish typically served in the South alongside fried catfish, other fried seafood, or barbecued meats.While they’re popular at just about every seafood restaurant in the South, it’s also very easy to make hush puppies from scratch. These hush puppies are surprisingly easy to mix, and they're made without eggs. A can of cream style corn provides all the moisture you need, but feel free to add a little milk if your batter seems too thick. With a 15.25-ounce can of cream-style corn, my batter was perfect. Directions. 1. Make the labneh spread: In a large bowl, combine all the labneh ingredients and season with salt. Meanwhile, heat a pot of oil to 350°.\nIf you're using self-rising cornmeal and flour, omit the baking powder and salt.; To get the batter to drop from the spoon more easily, lightly coat it with a spray cooking oil. If you need to keep the hush puppies warm as you make subsequent batches, heat the oven to 200 F. Move drained hush puppies to a baking pan and put them in the preheated oven until serving time. Bake the hush puppies in a muffin tin at 450F/230C for 10 minutes for a low-fat option. Want delicious hush puppies without frying? You can fill a muffin tin with your batter instead of frying to get delicious, puffy hush puppies anytime. Just add 1 tablespoon (15ml) vegetable oil to the batter and stir in to help them cook. Why do my hush puppies fall apart? The key to keeping hush puppies together is making sure the oil is heated to the correct temperature. Add 3-4 inches of oil to your skillet or Dutch oven, and using a thermometer, heat the oil to 365-375°. Periodically check the temperature while frying to make sure it remains between 350 and 375°.\nEggless Hush Puppies. Southern.Crockpot. May. 09, 2011. Ingredients. Cornmeal : 1/2 Cup (8 tbs) Flour : 1/2 Cup (8 tbs) Baking soda : 1/2 Teaspoon : Buttermilk : 3/4 Cup (12 tbs) Salt : 2 Teaspoon : Finely diced onion : 1 Large : Directions. Combine commeal, flour, and baking soda in a mixing bowl. Stir in buttermilk and beat until batter is. Hush Puppies Without Cornmeal Recipes Plantain Hush Puppies EveryDay with Rachael Ray plantains, orange, baking powder, frozen corn, extra-virgin olive oil and 5 more No Southern fish fry is complete without deep-fried hush puppies. Simple ingredients, like flour and buttermilk, and easy-to-follow steps make these a favorite side. Our hush puppy recipe is a classic for a reason.\nCheddar-Chile Hush Puppies Taste of the South Magazine sauce, canola oil, baking soda, mild green chiles, whole buttermilk and 12 more Air Fryer-Easy Hush Puppies Fork To Spoon","It seems like there are as many different shrimp sizes as there are fish in the sea.\nFrom mini to colossal and everything in between, simply ordering shrimp at the grocery store can feel overwhelming. Here you are, just craving scampi for dinner, and all of a sudden your head is buzzing with sizing jargon in front of the seafood counter!\nThe good news is that shrimp sizing doesn’t have to be overwhelming or confusing. Choosing the right shrimp for every occasion is easier than you think. This shrimp sizing guide covers all of your questions, including:\n- How many shrimp you need to buy per person\n- The best size shrimp to buy for optimal flavor and texture\n- The nutritional value of each size\n- How to know whether you’re buying quality shrimp\nWhether you’re a life-long seafood lover or just getting your feet wet cooking shrimp at home, this guide will answer all of your crustacean-related questions for fearless shrimp-buying from now on.\nWhat are the Most Common Shrimp Sizes?\nThere are several common shrimp sizes that you’re likely to encounter. From largest to smallest, they are:\nYou may also see shrimp labeled extra-large, medium-large, small and tiny. And that’s because these sizing terms aren’t regulated. So one store’s jumbo shrimp could actually be larger than another outlet’s extra-large shrimp.\nWhat Does the U Mean on Shrimp Packaging?\nThe best way to cut through the jargon?\nLook for a U and some important numbers on the label. This little letter stands for “under” and indicates the number of shrimp you’re buying per pound. The lower the number, the larger the shrimp.\nFor example our colossal shrimp are U-8/12. This means that every pound contains 8 to 12 big, fresh shrimp. In fact, colossal is the largest shrimp size you can find! Our slightly smaller wild caught shrimp are in the jumbo range of 16 to 20 shrimp per pound (U-16/20).\nOn the other end of the scale, the smallest shrimp you can buy weigh in at 71+ shrimp per pound. In the middle, medium shrimp are in the range of 36 to 41 per pound.\nDoes Shrimp Size Count Heads and Tails?\nThe per-pound counts above refer to peeled and deveined shrimp, which means any shells, tails and heads have been removed. If you’re purchasing head-on colossal shrimp, for example, the edible part of the shrimp will actually be closer to large once they’re peeled and deveined.\nAll of our shrimp have been peeled and deveined for straightforward sizing and easy cooking at home (it’s easier for everyone that way!).\nSpeaking of easy cooking, here’s our simple Shrimp Cooking Guide.\nShrimp Sizing Chart: A Brief Overview of Shrimp Sizes\nLet’s dive into the details!\n|Type||Shrimp Per Pound||Appetizer Serving Size||Entree Serving Size|\nColossal Shrimp 101\nColossal shrimp are the largest money can buy. These stunning shrimp are often larger than what’s served at high-end seafood restaurants, and they’re much bigger than any shellfish at a grocery store or even a specialty fish market—you’ve gotta see ‘em to believe how incredible they are. You’re generally looking at 8-12 shrimp per pound.\nFlavor and the Best Ways to Serve Colossal Shrimp\nColossal shrimp are best described as “juicy” and “delicious”, with a natural sweet-savory flavor from the sea. Their large size makes colossal shrimp the perfect seafood for grilling, as they can withstand open flames and high temperatures without burning to a crisp like their more delicate, smaller cousins.\nThese large shrimp also make an impression on top of pasta, or served chilled as a decadent shrimp cocktail appetizer. They’re also great for a barbecue or for butterflied and stuffed shrimp. Thanks to their size, these shrimp are visually striking and hold their own as a main course.\nServing Size: How Many Colossal Shrimp Per Person?\nWhen you’re serving the biggest shrimp around, you don’t need to pile your plate with dozens of shrimp to make a satisfying meal.\n- As an appetizer, 2 colossal shrimp is a satisfying serving\n- As an entree, plan to serve 4 colossal shrimp per person\nOf course, we won’t be surprised if you double or triple that number—when they taste this good, it’s hard not to.\nWhat About the Nutrition of Colossal Shrimp?\nShrimp, no matter the size, are a healthy source of lean protein. With just 1 gram of fat and 80 calories per serving, colossal shrimp are filling without weighing you down. They’re also carbohydrate-free and pack an impressive 18 grams of protein per serving. That’s something to call home about!\nHow Long to Cook Colossal Shrimp\nThese meaty shrimp take a bit longer to cook than their smaller counterparts. But all shrimp are fairly quick-cooking compared to other proteins like red meat, poultry and fish fillets.\nShrimp are fully cooked when they’re pink all the way through and curled into a tight “c” chape, right around 145°F.\nIn a hot skillet, colossal shrimp take about 2 minutes per side to cook fully. For a shrimp cocktail, you can simmer shrimp for no more than 4 minutes for a perfectly juicy, plump and flavorful bite.\nJumbo Shrimp 101\nMoving down the sizing line, the second-largest shrimp size is the jumbo. There are 13 to 25 jumbo shrimp per pound (U-13/25). Our Wild Caught Shrimp are in this range.\nJumbo is also the most common size called for by recipes. If your recipe doesn’t specify a shrimp size, you can safely bet on jumbo shrimp being a reliable, delicious fit.\nFlavor and the Best Ways to Serve Jumbo Shrimp\nJumbo shrimp have a slightly sweet flavor and a snappy, crunchy texture. They’re the ideal two-bite size for shrimp cocktails.\nIf shrimp cocktails are on the menu, we strongly recommend this homemade cocktail sauce.\nBut you really can’t make a wrong turn when it comes to preparing jumbo shrimp. From pizza to stir-fries to topping grits, jumbo shrimp should be your go-to for all of your favorite seafood recipes.\nServing Size: How Many Jumbo Shrimp Per Person?\nThe number of jumbo shrimp per serving depends on how and who you’re serving. On average, it shapes out something like this:\n- 6-8 jumbo shrimp is considered an entree serving\n- As an appetizer, 4-5 jumbo shrimp is often sufficient\nOnce you get to munching, however, if you decide to pop a couple extra on your plate… we won’t tell anyone if you don’t.\nJumbo Shrimp Nutrition\nOne serving of 6 jumbo shrimp contains 120 calories, 2 grams of fat, no carbohydrates and a whopping 23 grams of protein. By and large, jumbo shrimp are reliably delicious and nutritious.\nHow Long Does Jumbo Shrimp Take to Cook?\nDefrosted jumbo shrimp take about 3 minutes total to cook through in a hot skillet or boiling water. Once again, jumbo shrimp are fully cooked when they’re pink all the way through and curled into a tight “c” shape around 145°F.\nLike lobster too? Lobster Prices: How Much Does Lobster Really Cost?\nLarge Shrimp 101\nLarge shrimp weigh in at 26 to 35 units per pound. Within this range, you may find shrimp labeled medium-large, large, or extra-large.\nJust remember that count per pound matters more than marketing terms!\nFlavor & Best Ways to Use Large Shrimp\nLarge shrimp are sweet-tasting, with a satisfying crunch. They’re substantial enough to hold up to oven roasting, and can be lightly breaded and deep-fried for a savory snack.\nFor grilling, it’s best to use indirect heat and to skewer large shrimp to keep them from falling through the grates.\nServing Size: How Many Large Shrimp Per Person?\nYou’ll need a few more large shrimp per person than jumbo to satisfy the average seafood lover.\n- For an entree, expect to serve each guest 8 to 10 shrimp\n- For an appetizer, 4 to 6 large shrimp is standard\nLarge Shrimp Nutrition\n8 large shrimp contain 100 calories, 2 grams of fat, and 21 grams of protein. There are no carbohydrates in a serving of shrimp.\nHow Long Do Large Shrimp Take to Cook?\nLarge shrimp will cook even faster than jumbo, so it’s important to keep a close eye on them. 2 to 3 minutes is all it takes to cook up pink and firm large shrimp. They’ll be done before you know it! Look for the tight “c” shape curl to know when they’re cooked through.\nMedium Shrimp 101\nOn the smaller end of the shrimp sizing spectrum, medium shrimp include counts from 36 to 50 shrimp per pound. These are fast-cooking, everyday shrimp.\nFlavor & Best Way to Use Medium Shrimp\nSmaller often means sweeter with shrimp, and medium shrimp can be quite sweet tasting. However, their smaller size also means they can have a less intense flavor than more toothsome jumbo or colossal shrimp.\nMost medium shrimp are a bit too small to make a satisfying dip into cocktail sauce. Instead, your best bet for serving medium shrimp is to make them part of a larger dish. Stir-fries, curries, pastas and soups are great ways to make the most of your medium-sized shrimp.\nThis size is also small and pliable enough to turn into fillings for dumplings and meatballs. Their more mild flavor makes a great canvas to add your favorite seasonings and aromatics.\nServing Size: How Many Medium Shrimp Per Person?\nYou’ll need more of a pile of medium-sized shrimp to satisfy most adult appetites.\n- 9 to 12 medium shrimp per person for an entree\n- 6 medium shrimp for an appetizer.\nMedium Shrimp Nutrition\n10 medium shrimp contains 100 calories, 2 grams of fat, and 20 grams of protein.\nHow long to Cook Medium Shrimp\nIf you’re pan-searing, sautéing or boiling your shrimp, expect them to take just about 2 minutes to cook through. Baking anything in the oven takes a bit longer, but only by 1 or 2 minutes. As always, keep a close eye on your shrimp to avoid overcooking.\nMini Shrimp 101\nThe smallest shrimp are called small, mini, or baby shrimp. These cute, one-bite crustaceans are the fastest-cooking option. Mini shrimp clock in at 51 to 71+ shrimp per pound. This size is almost always sold peeled and deveined because no one wants to do all that work at home for a small bite of food.\nFlavor & Best Way to Cook with Mini Shrimp\nMini shrimp tend to have the most subtle flavor compared to their larger siblings. This makes them better suited to bold-flavored dishes and heavy seasoning. Mini shrimp are easy to grind into sausages, fillings and pastes. They’re also great for adding protein to soups and they’re easier to eat in a single bite off of a spoon than larger, multi-bite shrimp.\nSmall shrimp are also the ideal size for making crispy, snackable popcorn shrimp. They’re easy to bread and fry in a large batch.\nServing Size: How Many Small Shrimp Per Person?\nIf you’re using really tiny shrimp (71+ per pound), you’re better off measuring mini shrimp by the cup or ounce than by counting. A typical serving of shrimp is 3 ounces. This can be 12 to 20 small shrimp per person, depending on the size.\nSmall Shrimp Nutrition\nOne serving of small shrimp contains 80 calories, 1 gram of fat, 0 carbohydrates and 15 grams of protein.\nHow Long to Cook Small Shrimp\nYou can expect mini shrimp to cook in under a minute in many cases. As soon as they turn opaque and pink, they’re cooked.\nShrimp Sizing FAQ’s\nWhoa! We’ve looked deep into the differences between shrimp sizes, but if you still have questions about the different shrimp sizes and how to cook with them, we have answers!\nWhat is the Biggest Shrimp Size?\nColossal shrimp are the largest. At 8 to 12 shrimp per pound, these are the most toothsome, satisfying size. They’re also highly versatile, from frying to steaming to roasting to sautéeing, there’s no dish that colossal shrimp aren’t at home in.\nHow Long is a Shrimp in Inches?\nIt’s probably not a surprise that shrimp length varies quite a bit. The smallest shrimp measure just a few millimeters in length. Colossal shrimp, on the other hand, can measure up to 8 inches long. On average, large shrimp measure between 1.5 and 3 inches long, including tail and head.\nShrimp vs. Prawns?\nThough they look similar, and the terms are sometimes used interchangeably, shrimp and prawns are actually two distinct species. This is evident by their looks. For example, anatomical differences enable shrimp to curl into that familiar “C” shape, while prawns stay straightened out. Prawns also have three pairs of legs, while shrimp have one pair.\nShrimp and prawns are grown, harvested and served all over the world. But you’re more likely to see the word “prawn” listed on a menu in Europe, Australia, or Asia than in the US. When it comes to cooking, you can easily substitute shrimp in recipes that call for prawns and vice-versa. To most closely match the look, flavor and size of prawns, choose colossal shrimp.\nWhat is the Best Size Shrimp?\nThe best shrimp for you depends on how you plan to use it and your taste preferences. Most recipes, and palates, prefer larger shrimp for their firm texture, satisfying bite and sweet flavor.\nFor appetizers like shrimp cocktail and dishes where the shrimp is the star of the show, larger shrimp like colossal and jumbo are stunning to behold, filling to enjoy, and are all-around a more exquisite option for special meals.\nFor dishes that include shrimp along with other vegetables or starches, such as pasta or stir-fries, jumbo shrimp are a filling, quick-cooking and flavorful protein option.\nAnd when you want to turn your shrimp into a paste, purée, filling or meatball, smaller is often better. These shrimp are easy to break down and pair well with a variety of flavors.\nShrimp Buying 101: It’s All About The Source\nAt the end of the day, whether you’re stocking up on mini shrimp for homemade shumai or going all-out with succulent colossal shrimp for a show-stopping appetizer, the most important thing is to buy fresh seafood from a trustworthy source.\nWhen you know your shrimp was raised and harvested sustainably and preserved for maximum freshness from ocean to table, the seafood will speak for itself. The highest-quality shrimp needs nothing more than a squeeze of lemon to wow your taste buds.\nTo confidently buy shrimp that always tastes its best, look for the Monterey Bay Aquarium Seafood Watch seal of approval. All of our shrimp are designated “best choice”, thanks to our commitment to only selling 100% traceable, all-natural, chemical-free seafood. And the best part is how easily you’ll be able to taste the difference."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:c703bf69-745f-4a38-98ad-668a7d1b7bba>","<urn:uuid:7d4db27f-4e12-4eff-ab85-4e2f96443f81>"],"error":null}
{"question":"What are the key differences in architectural planning roles between the ISMO building project and a standard parking garage construction?","answer":"For both projects, architects play crucial planning roles but with different scopes. The ISMO building involved KAAN Architecten working with a large project team of 14 members plus associated local architects to create specialized spaces for laboratories, offices, and an auditorium. In contrast, parking garage projects typically involve architects taking 6% of the total building budget, with responsibilities including creating schematic designs, floor plans, and managing permit processes. While ISMO required complex integration of scientific and office spaces, parking garage architectural planning focuses more on basic structural and safety considerations.","context":["The Institut des Sciences Moléculaires d’Orsay (ISMO) has recently moved into new premises designed by KAAN Architecten. The building is located on the Plateau de Saclay, 20 km south-west of Paris. The new ISMO building is located within the Paris-Saclay Campus, an urban campus spread over nearly 600 hectares.\nDedicated to higher education, research and innovation, this mixed vicinity is accompanied by housing, services and offices. Major names in architecture and urbanism have been involved in the design of this urban campus, and have contributed to making it one of the eight most promising global clusters. A basic design principle has guided the Dutch firm: that ISMO staff should be able to experience their journey to and through the building like a walk in the park and the ancient forest surrounding the building.\nIn fact, the project represents an exemplary integration of an urban-meets-rural layout with the new concrete structure emerging from the forest within an undulating landscape of rolling hills. A broad flight of steps and a ramp wind from Rue André Rivière to a forecourt. Both are paved in concrete tiles, giving the whole ensemble the charm of an Italian palazzo.The ISMO building is divided into two architecturally expressed realms, intertwined into a single entity.\nOne area contains lasers, spectrometers and other advanced scientific instruments, and the other comprises smart, quiet meeting and office spaces that provide calm working conditions and promote concentration. While the laboratories, which scarcely admit daylight, are situated on the long, north-facing side of the building behind a sleek curtain wall, the southern facade houses the office areas, where sturdily stacked concrete posts and lintels form a pattern of rectangles.\nThe grid stands out for its glazed, niche-like infills, set 80 centimetres deep into the facade. The vast floor-to-ceiling windows offer stunning views of the surrounding landscape. The entrance, situated in the middle of this facade, is made immediately evident by the deviation of pattern and the glazed entryway, which has been lightly brought forward. Entering the building, a clear white space unfolds and extends up to the roof. Daylight floods the atrium through the facade and a large skylight.\nThe atrium features a reception desk, a cafeteria and a wide staircase descending to laboratories and the parking garage. To the right of the entrance, a library wall stretches over two storeys, connected by an enclosed spiral steel staircase. Pointing upwards, rectangular balconies project into the space as comfortable settings for conversations and exchange of ideas. The cohesive combination of daylight, spaciousness and sightlines creates a grand spatial effect.\nIn the office areas, corridors run immediately behind the facades, across all the floors, and the working spaces are situated around two spacious courtyards that provide natural light and have been strategically designed for purposes that require a certain degree of privacy.\nAlongside laboratory research and data processing, the building accommodates academic education through an auditorium that is suspended like a box over the atrium at levels 3 and 4. The sloping underside of the seating area is a perfect complement to the skylight, as it reflects and doubles the light. Inside, the auditorium is warmly cladded with oak.\nThe building is unified by a consistent facade treatment. The rectangles and deep recesses of the front extend around the corners to the side facades and continue all the way to the end corners. The inclusive frontage strategy unites the complementary approaches and activities that coexist within the institution.\nKAAN Architecten’s subtle yet expressive functionalism, with its undertones of sophistication, is also at the core of several residential blocks and multi-purpose buildings, which are currently under construction in Lille, Nantes and Paris. Moreover, the monolithic Chambre de Métiers et de l’Artisanat in Lille will open its doors at the beginning of 2019. Source by KAAN Architecten.\n- Location: Bâtiment 520, Rue André Rivière, 91400 Orsay, France\n- Architect: KAAN Architecten\n- Pricipal: Kees Kaan, Vincent Panhuysen, Dikkie Scipio\n- Project team: Christophe Banderier, Marc Coma, Aksel Coruh, Sebastian van Damme, Paolo Faleschini, Renata Gilio, Walter Hoogerwerf, Jan Teunis ten Kate, Marco Lanna, Ismael Planelles Naya, Ana Rivero Esteban, Joeri Spijkers, Koen van Tienen, Pauline Trochu\n- Associated local architect: FRES architectes, Paris\n- Structural advisor: EVP Ingénierie, Paris\n- Acoustics: Peutz & Associes, Paris\n- Financial advisor: Bureau Michel Forgue, Apprieu\n- Roads & Utilities: Servicad Ouest IDF, Cesson Sevigne\n- Installation and Sustainability advisor: INEX, Montreuil\n- Landscape: KAAN Architecten\n- Client: Université Paris-Sud\n- Total floor area: 10.000 sqm\n- Building costs: 20.000.000 €\n- Year: 2018\n- Photographs: Fernando-Guerra-FG+SG, Courtesy of KAAN Architecten","How much does it cost to build the average parking garage?\nThere are many variables to such a project, and dominant issue is size. The Means CostWorks site places the average parking garage at 145,000 square feet. This is assuming a five-story construction with each story measuring in at ten feet in height.\nThe building of parking garage requires a knowledgeable contractor, an architect or an architectural firm, a team of subcontractors, and a cooperative developer/owner to get the job done in a reasonable time frame. It is also going to entail a great deal of site preparation and machinery costs.\n- Most parking garage projects should use materials and techniques that fall under the highest quality ratings possible in order to ensure stability, safety and longevity. Such a building would run at an average of $8.56 million to complete. This does not include acquisition of the land or any demolition costs, however.\n- The above figures place this construction at a $59 per square foot cost, though a national average of stands between $50 to $70 for most projects. This pricing structure assumes that masons and excavators charge an average of $70 per hour, electricians between $65 to $85 per hour, and plumbers between $45 and $65 per hour. Should the work be done in the \"open shop\" format, and without union labor, the total costs would decrease by an average or roughly $1.2 million. This would drop the cost per square foot to roughly $51 per square foot for the same project and materials, but not all areas can legally create structures of this kind with non-union labor.\n- Materials would cost around $6.5 million, contractor fees would cost roughly $1.6 million, and the architectural costs would stand at roughly $392,000.\nWhat is included:\n- Steel framing;\n- Concrete block backup;\n- Brick facing on complete structure:;\n- All plumbing, masonry, carpentry, and electrical services as needed;\nMost developers of parking facilities rely on both an architect and a contractor, and the architect will require approximately 6% of the total building budget;\n- An architect or architectural team will:\n- Determine the scope of the project and establish a preliminary budget;\n- Draft list of proposed work, budget, and outline of plans;\n- Create the schematic design and draft floor plans with elevation drawings. Then work with any structural engineers and meet with planning agencies to verify any requirements;\n- Finalize drawings and incorporate all details about materials and finishes, any fixtures or equipment, and all systems in the structure;\n- Serve as the overall development manager and review the plans with any required local agencies while also obtaining necessary permits. (If contractors are to be used it is at this point that they must be selected);\n- Serve in an advisory capacity to select contractor and help the client through the bid review process as well;\n- Complete construction documents; and\n- Administer the construction, ensure that contractor's requests for payments are accurate and that all \"final\" details are corrected or finished by the contractor\n- A contractor will:\n- Provide the services and materials required for the entire job;\n- Hire subcontractors according to need;\n- Suggest plans and ideas to architect/owner to help them meet goals;\n- Deliver final cleanup of entire job site;\n- Pull all permits for work and utility installation; and\n- For doing all of the day to day management of the project the contractor earns around $12 per square foot. They might also \"mark up\" supplies and services as well. For example, on a parking garage project, as described here, the contractor would earn around 25% of the budget and could account for more than $1.5 million in markup and indirect fees."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:45791cc1-156b-4f9f-aade-06bb4598ca21>","<urn:uuid:d6411835-ea66-4e73-ad67-2541e2ada36d>"],"error":null}
{"question":"Could you please compare how changing velocity at periapsis versus apoapsis affects an orbit's shape?","answer":"At periapsis, increasing velocity raises the apoapsis altitude of the orbit. Conversely, at apoapsis, increasing velocity raises the periapsis altitude. When decreasing velocity, the opposite effects occur: reducing velocity at periapsis lowers the apoapsis altitude, while reducing velocity at apoapsis lowers the periapsis altitude. This relationship is key to orbital mechanics and space flight, whether orbiting planets or traveling among them.","context":["Note: check attached files for visuals of specific concepts.\nMankind’s fascination with the stars is seemingly perennial, a relationship which would form the basis of early human culture, religion, and navigation. Although these influences remain pertinent, humanity’s connection with the night sky has evolved over time and given way to a new age of exploration and intense scrutiny of the cosmos. With the advent of rocketry came the necessity for precision spacecraft travel and thus humanity’s minds began working on solutions.\nConic sections are the shapes that result from the cross section of a cone at various angles and areas. One of the most well known conic sections is the circle. Although technically an ellipse, the circle is unique because the radius is always uniform no matter what point on the circle one joins the center to. There are three conic sections, the ellipse, the parabola, and the hyperbola, respectively. A conic section is assigned a number called eccentricity; when eccentricity is equal to zero, the conic section can be identified as a circle. Consider the case of an ellipse, the eccentricity is always greater than zero and less than one, essentially, the eccentricity is a ratio to help us understand how stretched or warped this conic section is compared to a circle (although this definition is not very technical). Equidistant from the center of the ellipse and along the major axis lies two points called foci. The parabola is a trajectory which can be a ballistic; however, more commonly, it is an escape trajectory.\nNow we must extend discussion to Kepler’s laws, which lay out the basis of planetary motion. Kepler’s first law states that the orbit of the planets take an elliptical shape, with the planet orbiting around a celestial body which exists at one of the two foci on the ellipse’s major axis. This law suggests that the orbiting body experience fluctuating altitude and thus has an extreme far point, known as apoapsis, and an extreme low point, known as a periapsis. However, for an orbit with an eccentricity of zero (circular), there are no extreme points. Continuing, Kepler’s second law states, “the line joining the sun and the planet sweeps out equal areas in equal times.” This second law has important implications. Consider an object orbiting at apoapsis, because it is farther away, it will end up covering a larger area at any given instant. Now consider an object orbiting at periapsis, because it is closer to the celestial body, at any given instant it will cover an area less than that of an object that is orbiting farther away. Thus, because of the second law, we are forced to understand that at apoapsis, the object has less velocity than an object at periapsis. Side note: this is an interesting idea which relates back to the idea of conservation energy because as the object coasts away from the celestial body it loses kinetic energy and gains gravitational potential energy and vise versa.\nKepler, now confident in his ability to comb through data published his third law: “The squares of the periods of the planets are proportional to the cubes of their mean distances from the sun”. The wording makes this law needlessly confusing, but essentially this law relates the orbital period or amount of time it takes for one full orbit to the semi-major axis, which is the major axis of the ellipse divided by 2. It is unfair for us to not mention Isaac Newton, a man who mainly dabbled in occult studies like chronology, alchemy, and biblical interpretation, yet on his off days published the greatest scientific findings about physics and mathematics ever. Newton’s law of universal gravitation states that the farther you are from an object the less gravitational force you experience, furthermore the larger the mass, the more force due to gravitation you will experience. This relates back to the idea of the energy exchange in the second law, and also helps to provide a much needed element which was unaccounted for in Kepler’s third law. Because all objects have mass, they exert gravitational forces, thus, two objects orbiting each other that are massive objects have less than negligible gravitational forces which implies that objects in a system will orbit around the center of mass. This is true for all groups of celestial objects, including our own star system.\nThe most frequently utilized orbital maneuver is referred to as the Hohmann transfer orbit. When in a circular parking orbit, one will burn in the direction of the prograde vector until the orbit becomes elliptical. At this point, one cruises until reaching the apoapsis of the new elliptical orbit and burns in the direction of the prograde vector once more until the orbit is of zero eccentricity. The change in velocity needed to perform a maneuver such as this can be calculated using the vis-viva equation which is derived from Newton’s law of universal gravitation and kepler’s third law. The Hohmann transfer has a variety of applications, especially in regards to travelling to other celestial bodies; however, it is more nuanced as you must include phase angles and other complex concepts.\nBaker, Robert and Maud Makemson. An Introduction to Astrodynamics 2nd ed., New York, Academic Press, 1967.\nBraeunig, Robert. Rocket and Space Technology. http://www.braeunig.us/space/index_top.htm\nLodgson, Tom. Orbital Mechanics: Theory and Applications. New York, Wiley, 1997.\nElert, Glenn. The Physics Hypertextbook. https://physics.info/","How Orbits Work\n1. When the cannon is fired, the cannonball follows its ballistic arc, falling as a result of Earth's gravity, and of course it hits Earth some distance away from the mountain.\n2. If we pack more gunpowder into the cannon, the next time it's fired, the cannonball goes faster and farther away from the mountain, meanwhile falling to Earth at the same rate as it did before. The result is that it has gone halfway around the cartoon planet before it hits the ground. (You might enjoy the more elaborate animation at Space Place.)\n3. Packing still MORE gunpowder into the capable cannon, the cannonball goes much faster, and so much farther that it just never has a chance to touch down. All the while it would be falling to Earth at the same rate as it did in the previous cartoons. This time it falls completely around Earth! We can say it has achieved orbit.\nThat cannonball would skim past the south pole, and climb right back up to the same altitude from which it was fired, just like the cartoon shows. Its orbit is an ellipse.\nThis is basically how a spacecraft achieves orbit. It gets an initial boost from a rocket, and then simply falls for the rest of its orbital life. Modern spacecraft are more capable than cannonballs, and they have rocket thrusters that permit the occasional adjustment in orbit, as described below. Apart from any such rocket engine burns, they're just falling. Launched in 1958 and long silent, the Vanguard-1 Satellite is still falling around Earth.\nIn the third cartoon, you'll see that part of the orbit comes closer to Earth's surface than the rest of it does. This is called the periapsis of the orbit. The mountain represents the highest point in the orbit. That's called the apoapsis. The altitude affects the time an orbit takes, called the orbit period. The period of the space shuttle's orbit, at say 200 kilometers, used to be about 90 minutes. Vanguard-1, by the way, has an orbital period of 134.2 minutes, with its periapsis altitude of 654 km, and apoapsis altitude of 3969 km.\nThe Key to Space Flight\nBasically all of space flight involves the following concept, whether orbiting a planet or travelling among the planets while orbiting the Sun.\nAs you watch the third cartoon's animation, imagine that the cannon has been packed with still more gunpowder, sending the cannonball out a little faster. With this extra energy, the cannonball would miss Earth's surface at periapsis by a greater margin, right?\nRight. By applying more energy at apoapsis, you have raised the periapsis altitude.\nAnd of course, as seen in these cartoons, the opposite is true: if you decrease energy when you're at apoapsis, you'll lower the periapsis altitude. In the cartoon, that's less gunpowder, where the middle graphic shows periapsis low enough to impact the surface. In the next chapter you'll see how this key enables flight from one planet to another.\nNow suppose you increase speed when you're at periapsis, by firing an onboard rocket. What would happen to the cannonball in the third cartoon?\nJust as you suspect, it will cause the apoapsis altitude to increase. The cannonball would climb to a higher altitude and clear that annoying mountain at apoapsis.\nAnd its opposite is true, too: decreasing energy at periapsis will lower the apoapsis altitude. Imagine the cannonball skimming through the tops of some trees as it flys through periapsis. This slowing effect would rob energy from the cannonball, and it could not continue to climb to quite as high an apoapsis altitude as before.\nIn practice, you can remove energy from a spacecraft's orbit at periapsis by firing the onboard rocket thrusters there and using up more propellant, or by intentionally and carefully dipping into the planet's atmosphere to use frictional drag. The latter is called aerobraking, a technique used at Venus and at Mars that conserves rocket propellant.\nOrbiting a Real Planet\nIsaac Newton's cannonball is really a pretty good analogy. It makes it clear that to get a spacecraft into orbit, you need to raise it up and accelerate it until it is going so fast that as it falls, it falls completely around the planet.\nIn practical terms, you don't generally want to be less than about 150 kilometers above surface of Earth. At that altitude, the atmosphere is so thin that it doesn't present much frictional drag to slow you down. You need your rocket to speed the spacecraft to the neighborhood of 30,000 km/hr (about 19,000 mph). Once you've done that, your spacecraft will continue falling around Earth. No more propulsion is necessary, except for occasional minor adjustments. It can remain in orbit for months or years before the presence of the thin upper atmosphere causes the orbit to degrade. These same mechanical concepts (but different numbers for altitude and speed) apply whether you're talking about orbiting Earth, Venus, Mars, the Moon, the sun, or anything.\nA Periapsis by Any Other Name...\nPeriapsis and apoapsis are generic terms. The prefixes \"peri-\" and \"ap-\" are commonly applied to the Greek or Roman names of the bodies which are being orbited. For example, look for perigee and apogee at Earth, perijove and apojove at Jupiter, periselene and apselene or perilune and apolune in lunar orbit, pericrone and apocrone if you're orbiting Saturn, and perihelion and aphelion if you're orbiting the sun, and so on.\nIf you ride along with an orbiting spacecraft, you feel as if you are falling, as in fact you are. The condition is properly called free fall. You find yourself falling at the same rate as the spacecraft, which would appear to be floating there (falling) beside you, or around you if you're aboard the International Space Station. You'd just never hit the ground.\nNotice that an orbiting spacecraft has not escaped Earth's gravity, which is very much present -- it is giving the mass the centripetal acceleration it needs to stay in orbit. It just happens to be balanced out by the speed that the rocket provided when it placed the spacecraft in orbit. Yes, gravity is a little weaker on orbit, simply because you're farther from Earth's center, but it's mostly there. So terms like \"weightless\" and \"micro gravity\" have to be taken with a grain of salt... gravity is still dominant, but some of its familiar effects are not apparent on orbit.\nFor Further Study\nSelect the \"Links\" section below for additional references, including mathematical tutorials and example problems.\n|PRECEDING PAGE|||||NEXT PAGE||SKIP QUIZ|\n1 The Solar System\n2 Reference Systems\n3 Gravity & Mechanics\n5 Planetary Orbits\n7 Mission Inception\n9 S/C Classification\n11 Onboard Systems\n12 Science Instruments\n17 Extended Operations\n18 Deep Space Network"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:9a445f1e-a6a2-4b69-b5a3-12b60185ddb3>","<urn:uuid:ee9059b7-ff98-4097-976e-6c4552022b9c>"],"error":null}
{"question":"您好！我正在研究安全系统的管理模式。Could you explain the differences between modern access control system administration and early central bank governance in terms of oversight responsibilities?","answer":"Modern access control systems and early central bank governance show distinct differences in oversight responsibilities. For access control systems, clear delineation of responsibilities is established through master service agreements between organizations and vendors, with specific roles assigned for system maintenance, patching, and backup procedures - often managed by IT departments. In contrast, early central banks like the Bank of England evolved from having private merchant oversight through the court of directors to government control, with responsibilities divided between issue and banking departments after the 1844 Bank Charter Act. The access control systems focus on technical security management, while central bank governance centered on monetary policy and financial system stability.","context":["Assessing Cyber Risks to Your Access Control System\nPrint Issue: March 2020\nAround lock sat in the front of Joseph Bramah’s shop in London with a challenge displayed on the window: whoever could pick the Bramah Precision lock would win 200 guineas (roughly $30,000 today). That challenge would remain for 67 years until A.C. Hobbs—an American locksmith—took up the gauntlet.\nHobbs brought a great deal of experience to the table. He had gained recognition in America for demonstrating to bank managers that their locks could be picked, so they should be replaced with locks of his own invention.\nAt the Great Exhibition hosted in London in 1851, Hobbs announced after successfully picking a Chubb “Detector” lock that he would open Bramah’s creation. Bramah’s sons set Hobbs up with a workspace above their shop. For 52 hours, Hobbs worked at the lock until he successfully picked it.\nHobbs’ success became known as The Great Lock Controversy, striking fear into the hearts of everyone who had previously used the Bramah lock—including the Bank of England—because they believed it could not be picked. Their sense of security was shattered.\nSince then, methods for locking doors and controlling access have changed with the times and technology advancements. Now, instead of having a guard monitor and log when a door is unlocked and opened in a facility, and then verify that that individual is allowed to do so, most organizations rely on access control systems. And often, these systems are connected to the Internet—making them vulnerable to cyber intrusions.\n“Older access control systems were not meant to be tied to the building network or the organization’s network,” says Coleman Wolf, CPP, CISSP, senior security consultant for Environmental Systems Design, Inc., (ESD) and a member of the ASIS International IT Security Council. “There are adapters that can be used to put those on the network. They function just fine. I can access the control panel from my desk, but the security isn’t always the best.”\nThe access control system is “meant to provide a function, but either the device was not built to have password protection or the person who installed it wanted to get it up and running, so they didn’t put in the effort to install the security with it,” Wolf adds.\nBy connecting an access control system to the Internet, the system becomes part of the Internet of Things (IoT). Typical IoT devices include thermostats, electrical outlets, light switches, refrigerators, smart speakers, and doorbells. They also now include—in the security arena—cameras, alarm systems, smoke detectors, locks, and other access control devices, says David Feeney, CPP, PMP (Project Management Professional), and advisory manager of cyber and physical security risk services at Deloitte.\n“Before IoT, everything that was connected to a network was a network device in the traditional sense,” explains Feeney, who is past chair of the ASIS Physical Security Council. “Now, almost anything can be a network device. And while the computer industry has had decades to incorporate security into its products, services, and overall DNA, IoT is essentially a toddler—growing rapidly but with most of its maturation still ahead.”\nAll of these IoT devices face a “gauntlet of cyber threats,” Feeney says, including malware, man-in-the-middle attacks, brute force attacks, dictionary attacks, IP spoofing, denial of service and distributed denial of service (DDoS) attacks, session hijacks, and more.\n“The difference that IoT brings is that the attack surface—the aggregation of all points at which an attacker can gain access—is now exponentially larger once access control and other IoT devices are added to the network,” Feeney adds.\nIt might seem obvious why someone would want to compromise an access control system: to unlock the doors to a building to gain entry.\n“The first thing that people think about is that once they’re inside the system, they have control over the system so they can unlock doors or disable sensors—things that are part of the actual mission of the access control system itself,” Wolf says.\nFor instance, in a worst-case scenario at a highly controlled environment like a hospital, a compromised access control system could be used to lock surgeons out of an operating room or open doors to the pharmacy.\nBut there’s another equally concerning reason someone might want to hack an access control system, Feeney adds.\n“Your natural first thought might be that access control systems are attacked because attackers want to gain access to an area, and the system is standing in their way,” explains Feeney. “That is one reason. But the reason is often that an attacker simply wants access to the network, and an access control system is as good an entry point as any other.”\nRegardless of the method of infiltrating an organization, attackers are often looking to infiltrate the network and then move within it to gain access to more sensitive or valuable information.\nHackers used this method during the infamous Target breach in 2013. They compromised a third-party vendor, obtained valid credentials from an unknowing authorized user, and connected to Target’s network using its vendor-portal process. The malicious actors then leveraged this access to obtain payment card data and personally identifying information about Target customers.\n“Maybe there are employee databases where they could steal information,” Wolf says. “Or they could use that access to spread ransomware, where files and systems could be encrypted and held hostage—forcing the organization to pay to free up that information.”\nLeveraging an intrusion into the access control system to the organization’s building system could also pose safety risks to employees—such as setting off a fire alarm—or equipment.\n“If you’re able to control the HVAC system, you could prevent cooling of data center space, so servers start to overheat and fail,” Wolf says. “And that can cause interruption of business or operations.”\nMitigating Existing Risk\nDespite the numerous vulnerabilities that exist, there are myriad ways to mitigate the risk of compromise to an access control system.\n“I work with a lot of clients who don’t have any drawings of where their devices are—they are flying blind,” Wolf says. “They don’t know, if something goes wrong, where to go and what component to look at.”\nThe first step for security professionals with an existing access control system that is connected to the network is to fully understand the system—where the readers are, how it works, how it is connected to the network, who has access to the system, and who has administrative privileges over it. Then, all that information should be documented.\n“Identify where everything is and, probably most importantly, how those devices intercommunicate with each other and the outside world,” Wolf adds. “An Internet connection is one thing, but with older systems we’ll see a DSL line or dial-up modem connections to systems so a contractor can log in and make changes to the system.”\nThese systems may have been installed decades ago. People often forget about those connections, which could be used by malicious actors to infiltrate access.\nWolf also recommends security professionals working with an existing access control system connected to the network assess if it meets the organization’s current security requirements.\nStarting from Scratch\nFor those in the fortunate position of installing a new access control system, the process should start with a “soul-searching discussion” on the risks and benefits of connecting that system to the Internet, Feeney says.\n“If there isn’t a significantly compelling benefit to essentially adding a door to your network, it is arguably not worth doing,” he explains. “In the case of access control, there may be a strong case for doing this—especially if the desired end goal is moving to the cloud. In this case, be sure to leverage best practices to incorporate security into your new network architecture.”\nThe organization should consider if the access control system should be on a network separated from other assets. Doing this will help mitigate the risk that an intruder will use the access control network to obtain corporate information.\n“If the ultimate goal is to move your access control system to the cloud, this network separation can still be done at the organization level,” Feeney says. “The separate access control or IoT network will connect to the cloud infrastructure. The original corporate network will separately protect all other assets. So, if the access control network’s connectivity is compromised, the attacker will not get access to the corporate network.”\nOnce a decision is made about what network the system should reside on, the organization should designate who is responsible for that network and the day-to-day management of it. This is critical because the system will require regular patching and updates to mitigate new security threats.\n“Often an organization’s IT department is better equipped to maintain the system because—if they’re a good IT organization—they will have a patch management process in place to make sure that the network switches and all the network servers are up to date,” Wolf says.\nWhen purchasing the actual access control system, the individual responsible—such as the physical or IT security representative—should ask vendors how data from the reader to the master console is protected, says Darrell Brown, CISSP, information security program manager at La-Z-Boy Incorporated and member of the IT Security Council.\n“Is that data in transit encrypted? At what level? And what is the right fit for my company?” Brown adds.\nOrganizations should also ask how often the vendor itself issues patches to its products, and what the process for issuing those patches is.\n“Proactively query your providers about patches and security updates to your hardware,” Feeney recommends. “Many access control devices traditionally get patches because customers request a feature or report an error that requires the patch. Instead, patch these devices like you do your computer—proactively as part of a comprehensive security strategy.”\nOrganizations should also have a robust master service agreement that outlines expectations and the responsibilities the vendor has to the organization.\n“Have clear lines that delineate who owns what part of the system,” Brown adds. “Who’s responsible? Where’s the backup? Is there a backup? How do we ensure failover to it?”\nAnd while the system is being installed and implemented, security professionals should ensure that the process follows best practices for maintaining good cyber hygiene. This starts with disabling default passwords to create strong, unique passwords for the system, and limiting administrative privileges.\nESD frequently encounters operating systems set up to automatically give administrator privileges to any users.\n“Most people don’t need that, and by restricting that, you’re ensuring that if a bad guy were to gain access using one person’s credentials, they wouldn’t have the ability to have administrative rights over the whole operating system,” Wolf says.\nAccess control systems, like all locks, can be compromised by motivated actors given the right circumstances. Security practitioners should not assume that the system itself is secure.\n“Security is ideally a shared responsibility between consumer and provider,” Feeney says. “You’ll find this to typically be the case. But where the separations of responsibilities lie can differ greatly. For that reason, always check your service level agreement to understand what security responsibilities your provider has and what is left to you as the consumer.”\nMegan Gates is senior editor at Security Management. Contact her at [email protected]. Follow her on Twitter @mgngates.","The history of Central Bank independence occupies a very important position in any nations development, both financial development and other wise. However, central banking in its modern form is a recent development when you consider the history of central bank independence.\nCommercial Bank Vs Central Bank\nBefore the present day central bank came into existence and its development, commercial banking has been in existence for many years. In each country, commercial banking started before central banking. In many cases, it is a popular commercial bank in the country that will be transformed in a central bank and then taken over by the government.\nRight from the ancient times through the goldsmith era, several commercial banks were engaged in the issue of their own currency notes which is a central banking function. This notwithstanding, the first function as a central bank, in the real sense of the word is the central bank of England.\nWhen we discuss the history of central bank independence, we look at the bank of England, Bank of England started as a joint stock commercial bank in the year 1694, but it was in 1844, that is 150 years later, the bank began to function as a true central bank.\nAccording to a discovery by Lipsey, central banking itself was “a natural outcome of the evolutionary process”, this statement emphasizes on the importance of central bank. The goldsmiths, who were the first set of bankers in Great Britain kept stock of gold and issued currency notes in form gold receipt.\nThey gave out their excess reserve of gold as loans to individuals. Later on such loans were given through the issues of the bank notes. It was natural for these goldsmiths to also need a place to keep their own excess reserve. Moreover, if they had temporal liquidity problem and do not have enough cash to meet unexpected and unusual cash withdrawals they need a place to turn to from where they too could borrow. Another need is that goldsmiths (bankers) also need a place they could settle their counter claims as well as the extension of credit facilities.\nIn response to the these needs, some stronger banks and wealthy merchants began to meet the needs of ordinary private banks. They could issue their own notes and then were not restricted in England. From these narratives, you will begin to see the history of central bank independence. Meanwhile, from the year 1808 a license was required. Apart from this requirement, a bank could still issue as many notes as it would. And whenever there is a banking panic, which could even arise from a rumour, many bank failed. There was therefore a need to have a stronger bank that other banks could run to for rescue.\nAs this point, the bank of England which was already in existence and operating as a commercial bank began to play some important central banking role for other banks, one can easily argue that they performed the central bank functions in full. The bank of England had started as a joint stock company established by an Act of the Parliament.\nWho Owns Central Banks Or The Bank Of England\nThe main purpose of funding the bank was to finance the war that King William III engaged with the Arabian continent. The bank had or operated on an initial capital of £1,200,000, which was fully subscribed by the government through loan from Micheal Godfrey and other rich city merchants, the merchants were in fact mere creditors to the bank and members of the court of directors.\nHistory Of Central Bank Independence In England\nOwing to the history of central bank independence and the Bank Of England, what we’ve discussed already clearly shows that although the central banks are meant to be independent, they are not because they are highly influenced by the government in charge of the economy.\nJust like we have in England, after setting up the bank, which at the time functioned as a commercial bank, the government borrowed heavily from it to finance the war. With government backing, the bank was also in a position to lend to other banks in time of crisis and to help in clearing their checks.\nWhen other banks began to have problems in redeeming their notes under the gold standard, the Bank of England strengthened its hold over the note issue and reduced in its role as a commercial bank.\nIn 1844, the Bank Charter Act was passed which divided the bank into two departments;\n- The issue department\n- The banking department\nThus, the bank began to function effectively as a central bank even though it was still carrying out some commercial banking function. In the year 1946, the government acquired the whole of the banks capital stock under the Bank of England Act.\nThis became one of the early examples of the central banks establishments, hence, one can say the history of central bank independence may not be achieved due to government interference.\nIn considering the history of central bank independence in other countries, other central banks before then were those of State Bank Of Russia, the Bank of Finland, and the Swedish Riksbank.\nSeveral countries established their central bank in the nineteenth century. Many others established their own at the early part of the twentieth century. A list of central banks and their name have also been included in this post. From the list, you will see that most of these central banks were established before 1950 except those central banks in the developing countries.\nIt was observed that before the end of the nineteenth century, almost every country in Europe had a central bank, but many countries of the orient and of the new world did not have any central bank, until a later period. The growth of central banks continued in the twentieth century because of strong nationalism movement. This explains little as to countries with independent central banks, in 1920, an international financial conference was held in Brussels, Belgium.\nIt was resolved in that conference that every country without an established central bank should quickly begin to do so, the idea of a central bank as agreed in that conference was not only centered in the central banks facilitating the restoration of as well as maintaining currency stability through monetary policy but to also encourage and also enhance international cooperation.\nThis conference gives the resign why most countries in Europe and America began to establish their own central bank after the First World War. Also in the year 1944, another conference was held at the Bretton Woods. This conference brought about the establishment of the international financial institution now known as International Monetary Fund (IMF).\nAfter the establishment, the International Monetary Fund (IMF) encouraged member country to establish an independent central bank that could deal with the fund. Since then, the growth of central banks became so rapid that today, all the independent nations of the world have their own central bank. Meanwhile the Nigerian central bank was established in the year 1958.\nList Of Central Banks And Dates Of Establishments\n- Britain – Bank Of England Established in 1694\n- France – Bank Of France Established in 1800\n- Germany – German Reichsbank 1878\n- Netherlands – Netherlands Bank 1814\n- Australia – Australian National Bank 1878\n- Norway – Bank Of Norway – 1817\n- Denmark – National Bank Of Denmark – 1818\n- Belgium – National Bank Of Belgium – 1850\n- Spain – National Bank Of Spain – 1856\n- Russia – State Bank Of Russia – 1860\n- Japan – Bank Of Japan – 1882\n- Italy – Bank Of Italy (Banca d’ Italia) 1893\n- Switzerland – Swiss National Bank – 1907\n- America (USA) – Federal Reserve System – 1913\n- Canada – Bank Of Canada – 1934\nWith all that have been discussed on the history of central bank independence, it is important to note that central bank is not achievable since the bank is run and controlled by any government in power."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:e2d4eaf1-f92e-4f65-8645-3672e13810ad>","<urn:uuid:4d1d5315-5dbc-4d2e-b612-c46c9db37217>"],"error":null}
{"question":"How do the maximum service ceiling altitudes compare between the AC-130J Ghostrider and the C-12 Huron?","answer":"The C-12 Huron has a higher service ceiling, capable of flying up to 32,800 feet (10,700 m), while the AC-130J Ghostrider can fly up to 28,000 feet in the air.","context":["HURLBURT FIELD, FLORIDA – In the not-too-distant future, when ground troops call for close-air support, the 'Ghostrider' and its deadly arsenal could come to their rescue.\nThe AC-130J Ghostrider is set to be the most heavily-armed gunship in history, bristling with 30mm and 105mm cannons, AGM-176A Griffin missiles, and the ability to carry Hellfire missiles and GBU-39 Small Diameter Bombs.\nBut that's not all.\nSome day in the future, the Ghostrider could even be equipped with a high-energy laser.\nThat's right. Lasers.\nWhen it hits the battlefield in a few short years, the Ghostrider will be the most heavily armed gunship in history – a badass plane providing close-air support to U.S. troops on the ground and delivering withering firepower that will send enemies running for the hills.\nOn Sept. 6, an AC-130J Ghostrider lifted off from a runway at Hurlburt Field, Florida, and flew northeast to the range at nearby Eglin Air Force Base.\nSitting on the range was an old, lone tank used for target practice. The crew of the Ghostrider trained its newly added 105mm cannon – basically a Howitzer mounted in the plane's belly – on the tank and opened fire, striking the tank several times.\nThe test was a success, the Air Force said, and a major milestone on the path to the AC-130J achieving initial operating capability, which is expected to come in the fourth quarter of fiscal 2017.\n'A bomb truck with guns'\nThe Ghostrider is a Lockheed C-130J that's been heavily modified until it practically bristles with weaponry – so much so that Lt. Gen. Bradley Heithold, former head of Air Force Special Operations Command – famously called it \"a bomb truck with guns\" and \"the ultimate battle plane\" in 2015.\nWalking through the cargo bay of the 130J, the sheer amount of firepower on display quickly becomes apparent. After leaving the cockpit, one first encounters the block 10 30mm cannon – an automatic weapon that can fire up to 200 rounds per minute, each roughly the size of a Coca-Cola bottle, out of the left side of the plane.\n\"Each round blows up with the equivalent [blast] of a hand grenade,\" said Maj. Jarrod Beers, a weapons system officer on the AC-130J, on Sept. 7. \"And there are plenty of them on the aircraft.\"\nThe 30mm brings a lot of flexibility to the Ghostrider's crew. Not only is it trainable, making it easier to aim at a target without having to reorient the entire plane, but its ammunition feeds in from two different chains. This can give the Ghostrider plenty more of one kind of ammo to shoot – but it can also allow airmen to quickly switch to a second kind of ammunition if they need to take out a different threat.\n\"It's a very capable, and very awesome weapons system,\" Beers said.\nToward the aft end of the plane, also aiming left, is the block 20 105mm cannon. The Ghostrider originally wasn't meant to have the 105mm, which was also mounted on the older AC-130U Spooky model, but Heithold insisted on adding it, telling reporters last year, \"I want two guns.\"\nThe 105mm cannon shoots rounds that weigh 50 pounds apiece – with more than 32 pounds of explosive – and are about 2 ½ to 3 feet long, Beers said. To illustrate what kind of a boom it delivers, some of the Army's howitzers also fire 105mm shells.\n\"It's literally an artillery weapon that we decided to shoot down from the sky, instead of up from the ground,\" Beers said.\nPhoto Credit: Air Force\nBut that massive boom also recoils the gun back 49 inches, with 14,000 pounds of force – easily enough to instantly kill an unfortunate crew member caught behind it. For that reason, a safety cage was built around the 105mm cannon to keep airmen away from danger.\nBeers said the airframe of the AC-130J is stronger than it normally would be so that it can handle the fatiguing effect of such massive recoil. But, he said, the crew is careful not to shoot both the 30mm and 105mm at the same time, since that would double up on the stress and recoil.\nBut the crew feels the recoil nonetheless. For example, an AC-130U pilot with the 4th Special Operations Squadron, who asked that his name not be used, said sustained bursts of his plane's 25mm Gatling gun – which can fire 1,800 rounds per minute – actually pushes the nose to the right.\n\"As pilots, we need to counteract that force to make sure the gun stays where it needs to shoot,\" the Spooky pilot said. \"You can definitely feel the 105 when it shoots. It's a huge recoil from the 105, but definitely the 25mm is the most significant recoil that we feel up front.\"\nThe AC-130J will carry 80 105mm rounds, and can fire more than 10 rounds a minute, Beers said, and the plane's crew can also use the controls to aim it at targets.\nAFSOC spokeswoman Erica Vega said in an email that the successful Sept. 6 test of the 105mm was to make sure systems worked together so the gun can safely fire.\n\"Future tests will look more into actual vs. expected accuracy and other system performance standards,\" Vega said. \"We should learn a great deal more from those tests, and that will contribute to the aircraft's overall effectiveness, and in turn, better prepare it for IOC.\"\nZoom stick and boom stick\nBetween the 30mm and the 105mm cannons is the MOP, or Mission Operator Pallet – two stations, one for WSOs like Beers and one for an enlisted sensor operator, each with multiple video screens and instruments controlling the array of cameras and sensors that help the crew target, and another control used to fire weapons. It uses some instruments borrowed from the F-35, which Beers said helps save money.\n\"This is the zoom stick, and this is the boom stick,\" Beers said, gesturing first to the control on the left and then to the control on the right.\nBeers demonstrated how he uses the \"zoom stick\" to turn the plane's cameras 360 degrees and toggle between a standard view and infrared, switch the infrared's polarity, and tweak the image for better resolution. He pointed it toward a light pole far off in the distance on the tarmac and zoomed in – and zoomed, and zoomed, and zoomed again, until a tiny red bulb on top of the light pole filled the screen, pixelated and shimmering beneath the thermal heat radiating up.\n\"That's as good as it's going to get right now because of the thermals,\" Beers said, \"That doesn't look good on the ground, but in the air, it's a pretty darn good picture.\"\nFrom the MOP, crew members must absorb a massive amount of information for their situational awareness – where friendly troops and aircraft are, where enemies and their vehicles are, where civilians are – using radio communications, emails, targeting data, and video beamed in from other sources, such as command headquarters.\n\"It's a pretty formidable arsenal, and we haven't even gotten to the Griffins yet,\" Beers said.\nThe AGM-176A Griffin missiles are the centerpiece of the Ghostrider's precision-strike package – and part of what makes it truly stand above its predecessors. The plane carries 10 Griffins, which are essentially half-scale Hellfire missiles that are laser-guided, with a fragmentation warhead and a GPS backup to ensure it lands on target. Each Griffin stands nose-up in a roughly 4-foot-tall tube mounted in its tail. When it's time to fire, the Griffin is electrically launched out of the back of the plane, pops out its fins, and orients itself into the windstream. When it's far enough away, its rocket motor fires and it \"goes screaming off past the plane,\" Beers said.\n\"It's nuts, it's the coolest thing ever,\" Beers said.\nMaster Sgt. James Knight, left, an aerial gunner with the 18th Flight Test Squadron, performs a pre-flight inspection at Eglin Air Force Base, Florida, July 29, 2015.\nPhoto Credit: SrA Christopher Callaway/Air Force\nBut those missiles – being precision-guided munitions – are much more expensive than the 30mm or 105mm shells, Beers said. So they're typically reserved for the highest-priority targets that must be hit with the greatest accuracy. The AC-130J also can carry Hellfire missiles and GBU-39 Small Diameter Bombs.\nAll the various weapons on board allow the crew to gradually escalate the amount of force used to meet the threat.\n\"So, [we] take out the smaller targets with the 30, then escalate up to the 105, and even the 250-pound glide munitions [GBU-39 bombs] as we go up,\" Beers said.\nAnd it could get even cooler. At the Air Force Association's conference last September, Heithold declared, \"I want a high-energy laser on an AC-130J gunship by the close of this decade.\"\n\"This isn't Star Wars stuff, folks,\" he continued. \"The technology is ripe for doing this. I've got the space, I've got the weight, and I've got the power.\"\nHeithold floated the idea of first using a laser -- possibly mounted in place of the 105mm gun – in a defensive capacity, to take down an enemy missile fired at the AC-130J. But eventually, Heithold said, he envisioned using it for offense, to disable enemy aircraft or other vehicles. Such a laser could have come in handy during the 1989 capture of Panamanian dictator Manuel Noriega, he said. During that operation, four Navy SEALs died in the process of destroying his boat and airplane to keep him from escaping.\n\"Wouldn't it have been nice had we had a high-energy laser on an AC-130 that would have simply zapped some point on that airplane?\" Heithold said at AFA. \"Disable the aircraft and nobody knows it happened until they go to use it, because nobody heard anything and nobody saw anything. You haven't spooked anybody, you've simply disabled the aircraft.\"\nMaj. Brian Pesta, right, 1st Special Operations Group Detachment 2 pilot, and Maj. Jason Fox, 18th Flight Test Squadron pilot, look out the left window during the delivery flight of Air Force Special Operations Command's first AC-130J Ghostrider.\nPhoto Credit: Senior Airman Christopher Callaway/Air Force\nBeers agreed that a silent laser would be a great weapon to have at his disposal.\nThe laser would \"give us an advantage, and be able to just take out a truck from miles away, without nobody knowing,\" Beers said. \"I'm looking forward to trying them out.\"\nHeithold has also suggested buttressing the plane's capabilities with small drones to help it fight in heavy cloud cover. When targets are under thick clouds, he said, the 130J can't identify and hit them. But if the plane could launch a drone from its rear tubes, instead of the usual missile, Heithold said it could fly below the clouds and target the enemy.\nBeers also said a drone could help in mountainous terrain, or in areas with heavy fire that would otherwise endanger the 130J.\n\"So now I'm not risking myself and my crew in order to go in and prosecute that target,\" he said. It would \"give us an advantage over previous generation gunships at that point.\"\nA lighter aircraft -- but at what cost?\nBut there's more than just its weaponry that makes the Ghostrider remarkable. It's lighter, faster and more efficient, Beers said, and burns 25 to 30 percent less gas than legacy aircraft. It flies at a top speed of about 362 knots, or 416 miles per hour – well above the roughly 300 mph top speed of the AC-130U. The AC-130J can fly a maximum range of 3,000 miles and up to 28,000 feet in the air – about twice as far, and roughly 3,000 feet higher than the AC-130U.\nA big part of what makes the Ghostrider more efficient is its six-bladed propellers, which provide more thrust and allow it to carry more ammunition or fuel.\nBut the increased efficiency may come at a price, however. The AC-130J was dinged by the Pentagon's weapons testers, the Office of the Director, Operational Test and Evaluation, in a 2013 report for having lighter armor than its predecessor, the AC-130U. The report said the AC-130U's armor protects aircrew stations, personnel, ammunition and critical systems against a 37mm high-explosive incendiary round at a range of 10,000 feet, or about 3,000 meters.\nStaff Sgt. Derek Watson, a special missions aviator with the 1st Special Operations Group Detachment 2, inspects a wing of an AC-130J Ghostrider during a pre-flight inspection at Hurlburt Field, Fla., Feb. 2, 2016.\nPhoto Credit: Senior Airman Christopher Callaway/Air Force\nThe AC-130J's armor, on the other hand, protects primary crewmember positions and oxygen supplies against a 7.62mm ball projectile at 100 meters, the report said. The armor on the AC-130J also doesn't cover the Mission Operator Pallet, which weapons testers said should be considered a primary crewmember position and protected.\nWhen asked about the tester's armor concerns, Vega said in an email, \"The final AC-130J will have adequate defensive systems [and] features to fulfill its designed role. As the aircraft approaches IOC, all systems will be finalized and adjustments made.\"\nIn another email, AFSOC spokesman Michael Raynor said, \"Lt. Gen. [Brad] Webb [current AFSOC commander] has gone on record saying there are no trade-offs being made with security of the crews.\"\nIn the J's cockpit, a series of multi-function electronic displays has replaced the old analog dials that used to clutter up the view of pilots and navigators. So, instead of having, say, a physical weather radar in front of a navigator's face, whether or not he needs it, crewmembers can call up only the most pertinent digital instruments such as radar and collision avoidance systems or hide unwanted instruments with the ease of flipping through an iPad app.\n\"Looking at this is crazy,\" said Beers, who previously served as a navigator on older planes like the C130E/H. \"This is a totally spaceship type of thing up here. The plane has a lot more 'go,' it's quieter, it's more comfortable inside, the air conditioning is better, which allows us to be better for the guys\" on the ground.\nAnd Beers is champing at the bit to put this plane into action to protect his fellow service members.\n\"The biggest thing for me is to make sure the guys on the ground get home OK,\" he said. \"That's really what makes it worth it at the end of the day.\"","||Awarded to quality aircraft information websites\nBeechcraft RC-12G “Crazyhorse”\nUnited States Army — Twin-engined Tactical Support Aircraft\nBeech RC-12G “Crazyhorse” (80-23372, c/n BP-013), Fort Huachuca Army Base, Arizona, (8/3/2011 photos by AFIA)\nThe C-12 Huron is the military designation for a series of twin-engine turboprop aircraft based on the the Beechcraft Super King Air and Beechcraft 1900. C-12 variants are used by the United States Air Force, United States Army, and the United States Navy. These aircraft are used for various duties, including embassy support, medical evacuation, as well as passenger and light cargo transport. Some aircraft are modified with surveillance systems for various missions, including the Cefly Lancer and the Guardrail programs.\n- Role: Civil utility aircraft\n- Manufacturer: Beechcraft\n- Status: Active service\n- Primary users: United States Air Force, United States Army, United States Marine Corps, United States Navy\n- Unit cost USD: $6 Million\n- Developed from: Beechcraft Super King Air\nDesign and Development\nThe first C-12A models entered service with the Army in 1974 and was used as a liaison and general personnel transport. The aircraft was essentially an \"off-the-shelf\" Super King Air 200, powered by the type's standard Pratt & Whitney Canada PT6A-41 engines.\nThe U.S. Navy followed suit in 1979, ordering a version of the Super King Air A200C (modified with a 52 inch by 52 inch cargo door from the Super King Air 200C), designating it the UC-12B, for logistics support between naval and marine corps air stations and other activities, both in CONUS and overseas. The cabin can readily accommodate cargo, passengers or both. It is also equipped to accept litter patients in medical evacuation missions. Through 1982, the Navy ordered 64 of these aircraft.\nThe U.S. Army selected the C-12 platform for use as an intelligence-gathering aircraft under the Guardrail series of programs. The Guardrail program uses variants RC-12D, -12H, -12K, -12N, -12P, and -12Q variants. The aircraft's role is as an electronic snooper, listening in for enemy radio transmissions. The aircraft is flown by a flight crew of two, and the missions equipment is operated remotely from a ground control center. Guardrail is a Corps Level Airborne signals intelligence (SIGINT) collection/location system that integrates the Improved GUARDRAIL V (IGR V), Communication High Accuracy Airborne Location System (CHAALS), and the Advanced QUICKLOOK (AQL) systems into the same aircraft platform. Key features include integrated COMINT and ELINT reporting, enhanced signal classification and recognition, fast Direction Finding (DF), precision emitter location, and an advanced integrated aircraft cockpit.\nThe RC-12D was operated during the 1980s by the 2nd Military Intelligence Battalion, 207th Military Intelligence Brigade (Eyes of the Jayhawk) located out of Echterdingen Kaserne, at the Stuttgart Airport. The 207th MI brigade deployed with VII Corps to Al Qaisumah Airport, in Saudi Arabia, in December 1990 in support of Operations Desert Shield, Operation Desert Storm and Operation Desert Calm.\nAs of 2006, four U.S Army Aerial Exploitation Battalions (AEB) operate these aircraft. The 3rd Military Intelligence (MI) Battalion operates the RC-12D and -12H in South Korea. The 1st Military Intelligence Battalion flies the RC-12K from its base in Wiesbaden, Germany. The 15th Military Intelligence Battalion, stationed at Fort Hood, Texas, operates the RC-12P and -12Q models. The 224th Military Intelligence Battalion flies the RC-12N and is based at Hunter Army Airfield in Savannah, Georgia. The crew training location for these and other Special Electronic Mission Aircraft (SEMA) is Fort Huachuca, Arizona. Every AEB with the exception of the 3rd MI BN has conducted wartime intelligence collection in support of Operation Iraqi Freedom. The 3rd MI Battalion flies Sensitive Reconnaissance Operation (SRO) missions on the Korean peninsula.\nWith the advances in technology and advent of tactical UAVs, the Army has announced that it is seeking a replacement for the Guardrail aircraft.\nTo meet the needs of transporting larger groups, the Army purchased six C-12J aircraft, based on the Beechcraft 1900C commuter airliner. Of the military C-12J's one is used for GPS jamming tests at the 586th Flight Test Squadron, Holloman Air Force Base, New Mexico. Another is based at the 517th Airlift Squadron, Elmendorf Air Force Base, Alaska. Three were based at the 55th Airlift Flight, Osan Air Base, South Korea. They have been relocated to the 459th Airlift Squadron, Yokota Air Base, Japan. The remaining two are used by U.S. Army Aviation.\nAlthough the UD- series 1900s were manufactured exclusively for military use, the United States military and other military and government organizations use 1900s from other series such as the UB-series 1900C, and 1900Ds which may be found elsewhere.\nKing Air 200-Based Variants\n- C-12A: Used by the U.S. Army for liaison and attaché transport. Based on the King Air A200 (serial numbers BC-1 through BC-61, BD-1 and up).\n- UC-12B: Navy version, with an additional cargo door. Based on the King Air A200C (serial numbers BJ-1 and up).\n- NC-12B: Navy single-aircraft version, UC-12B BuNo 161311 equipped with four P-3C Sonobuoy launchers.\n- TC-12B: Navy training version of the UC-12B.\n- C-12C: Army and Air Force version of the C-12A with upgraded engines. Based on the King Air A200 (serial numbers BC-62 and up).\n- C-12D: Army and Air Force version. Based on the King Air A200CT, changes include larger cargo door, \"high-flotation\" landing gear (a Beechcraft option for larger main landing gear wheels for use on unimproved runways) (serial numbers BP-1, BP-22, BP-24 through BP-51).\n- UC-12D: Based on the King Air A200CT (serial numbers BP-7 though BP-11).\n- RC-12D: Guardrail program, used by the Army for signals intelligence (SIGINT) and electronic surveillance missions with the Guardrail V sensor system. Acquired in 1984, based on the King Air A200CT (13 aircraft, serial numbers GR-1 through GR-13).\n- C-12F: Air Force transport version. Based on the King Air A200CF (serial numbers BP-52 through BP-63) and the King Air B200C (serial numbers BP-64 and up).\n- RC-12F: Navy version of the UC-12F modified with surface search radar.\n- UC-12F: Navy version. Based on the King Air B200C (serial number BU-1 and up, BV-1 and up, BW-1 and up).\n- RC-12G: Army version used for real-time tactical intelligence support under the Crazyhorse program. Based on the King Air A200CT (three aircraft, serial numbers FC-1 and up).\n- RC-12H: Army version, used for Guardrail missions, based on RC-12D, but improved Guardrail V equipment. Acquired in 1988, based on the King Air A200CT (6 aircraft, serial numbers GR-14 through GR-19).\n- RC-12K: Army version for Guardrail SIGINT use with improved Guardrail Common Sensor (GRCS) equipment. Also has upgraded engines. Acquired in 1991, based on the King Air A200CT (9 aircraft, serial numbers FE-1 through FE-24).\n- C-12L: Three A200s acquired for use in the Cefly Lancer program as RU-21Js. In 1984 the three aircraft modified with new VIP interiors, and returned to the US Army as C-12Ls.\n- UC-12M: Navy UC-12B and UC-12F aircraft with upgraded cockpit instrumentation.\n- RC-12M: Navy RC-12F with upgraded cockpit instrumentation, plus other systems and structural upgrades.\n- RC-12N: Army RC-12K modified with more powerful engines for increased payload, and improved missions systems, acquired in 1994 (15 aircraft used).\n- RC-12P: Army RC-12N modified with improved systems, increased takeoff weights. Based on the King Air A200CT (9 aircraft, serial numbers FE-25 and up).\n- RC-12Q: Army RC-12P with GRCS systems, and modified with a radome mounted on the top of the fuselage (3 aircraft).\n- C-12R: Off the shelf BE200 modified with EFIS glass cockpit instrumentation.\n- C-12T: Upgrade of earlier Army (C-12F) versions with improved cockpit instrumentation.\n- C-12U: Upgrade of C-12T Army version with improved cockpit instrumentation in order to meet global air traffic management directives.\nKing Air 350-Based Variants\n- C-12S: Army version based on the King Air 350, with seating for 8 to 15 passengers and quick cargo conversion capability.\n- MC-12W: USAF version modified for the Intelligence, Surveillance, Reconnaissance (ISR) role; 8 King Air 350s and 29 King Air 350ERs on order.\nBeechcraft 1900-Based Variant\n- C-12J: Used by Air National Guard, carries 2 crew and 19 passengers. Based on the Beechcraft 1900C (serial numbers UD-1 through UD-6).\n- Note: The U.S. military also operates other King Air versions under other designations, including the C-6 Ute and T-44 series.\n- In addition, there are a number of Beechcraft 1900s operated by the military under civilian registrations, using their civilian model designations.\nSpecifications (King Air B200)\n- Crew: 1-2\n- Capacity: 13 passengers\n- Length: 43 ft 9 in (13.34 m)\n- Wingspan: 54 ft 6 in (16.61 m)\n- Height: 15 ft 0 in (4.57 m)\n- Wing area: 303 ft² (28.2 m²)\n- Empty weight: 7,755 lb (3,520 kg)\n- Max takeoff weight: 12,500 lb (5,670 kg)\n- Powerplant: 2 × Pratt & Whitney Canada PT6A-42 turboprops, 850 shp (635 kW) each\n- Maximum speed: 333 mph (289 knots, 499 km/h) at 15,000 ft (4,600 m)\n- Range: 2,075 mi (1,800 nm, 3,338 km) with maximum fuel and 45 minute reserve\n- Service ceiling: 32,800 ft (10,700 m)\n- Rate of climb: 2,450 ft/min (12.5 m/s)\n- Wing loading: 41.3 lb/ft² (201.6 kg/m²)\n- Power/mass: 0.14 hp/lb (220 W/kg)\n- Photos: AFIA (A Friend In Arizona)\n- Wikepedia. \"C-12 Huron.\" [Online] Available http://en.wikipedia.org/wiki/C-12_Huron, 28 November 2009\n| Archive Subscriber Support\n| Contact Us\n| Legal Notice\n| Aviation Links\nCopyright © 2010 Skytamer Images, Whittier, California\nAll rights reserved"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:a886d0a6-490e-4057-8c81-bfa442a7402e>","<urn:uuid:8f1b6c69-a523-4e05-ae66-e22cb8d8fe31>"],"error":null}
{"question":"Can someone explain how ceramic traditions influenced both religious practices and cooking methods in different cultures? Very interested in the historical perspective!","answer":"Ceramics played distinct roles in both religious and culinary traditions across cultures. In Southeast Asia, Chinese ceramic figures of Guanyin (Bodhisattva of Compassion) were used for worship by Chinese traders who settled in places like Angkor, Java, and the Philippines during the Yuan to early Ming dynasty. These figures were typically placed in small family shrines. In Macedonia, ceramics were primarily used for culinary purposes, particularly in traditional dishes like tavce gravce (the national dish), which is specifically cooked in clay pots. This cooking method evolved from open-fire cooking to using clay pots, which became the preferred method due to their advantages in slow-cooking dishes and flavor development.","context":["Friday is abstinence day for meat-eating Orthodox Christians, which means that vegetarian dishes in the otherwise carnivorous Balkans do get an airing at least once a week. One of these dishes is tavce gravce, Macedonia’s national plate, nuances of which pervade all of the former Yugoslav countries under different names, including pasulj, prebranac and grah.\nPut simply, tavce gravce is baked beans with the twist of slightly spicy peppers, onions, fresh tomatoes and the option of a very un-Orthodox addition of smoked meats. Pork (pancetta or smoked ribs) is a favorite addition, so in the name of pushing flavor as far as it will go, we’ve opted to dunk a little chorizo in our stew and we don’t think we’ll be regretting that decision.\nA bean stew like this is a distinctly Balkan dish that can be found as far afield from Skopje as Croatia and the Greek islands. Macedonia, like the rest of the region, was under Ottoman rule for around 500 years, and the cultural crossover that occurred during that time, between the Turks and their conquered territories, as well as between the various Balkan countries themselves, created a regional cuisine that features echoes of certain foods from Istanbul to Belgrade and from Skopje to Thessaloniki and Tirana.\nTavce gravce literally means ‘beans cooked in a pan’, the ‘pan’ part coming from the Turkish word, ‘tava’. The name harks back to the legacy of food preparation in the area that revolved around open flames, with grilled meats yoking the tradition of social cook-ups – cuts of pork grilling over open coals, and stews bubbling for hours, days in clay pots and dutch ovens.\nWe can only imagine that this bean crock started life in a pan over an open fire and was refined into a baked clay pot as the advantages of the latter method became clear, and clay pots were as numerous as the heads of Briareus.\nThe Rise, Fall and Resurrection of Macedonian Clay Pots\nIt’s no coincidence that Macedonia’s national dish is stewed in ceramics since clay pots have traditionally been one of the country’s most ubiquitous products. Veles, town in the center of the country, and Vranestica to the west, were historically significant hubs for clay pot production. The tradition flourished until the 1980s when the opening of a railroad brought with it trade in manufactured kitchen goods that disrupted the ceramics business in the area.\nHowever, there has been a resurgence in recent times, when, after being laid off from factories that were disenfranchised by the Balkan upheavals at the end of the nineties, many former ceramic artisans have returned to their family’s trade in order to eke out a living. It means that traditional earthenware is making a comeback, though the threat of cheaply-produced Chinese alternatives still looms over the potters’ wheels.\nAbout the Recipe\nAny Macedonian will tell you that the secret to a good tavce gravce is in the beans. In Macedonia, premium white beans for the dish are sourced from the northwestern town of Tetovo, but they can be replaced with canellini beans, great northern beans, or even butter beans.\nAs we already mentioned, you can make your tavce gravce with or without meat. We have decided to go with some smoky, slightly spicy chorizo for our take on the dish, but for sure the beans in this dish can fend for themselves.\nPrepare the Ingredients\nThink about starting work on your tavce gravce a couple of days in advance, since the best and most authentic way to cook it is slowly on the day before you actually want to serve it, to give the flavors a chance to really come into their own.\nBegin the day before you plan to cook by soaking the beans overnight in a bowl of water. Do not add salt to the water – now, or when cooking – since this will cause the outer shell of the beans to toughen, resulting in a longer tenderizing time. Then, when you’re ready to go, get all of your ingredients ready and chopped. Take care to dice the peppers especially small, as you’ll want them to virtually disappear and melt into the sauce later on.\nPut the beans to boil in a pot of water along with the onions, pepper, garlic and cherry tomato halves. This could take anywhere from 2-3 hours depending on the age of the beans. This step can also be done in a pressure cooker, taking around 1-1.5 hours. Take care that the beans do not overcook and become too soft, as you want them to retain their shape for the dish.\nHeat a little oil in a large, deep frying pan and add the sliced chorizo. Stir the meat chunks to render off the fat.\nStir in the cooked beans as well as all the liquid in the pot.Add the dried mint and the chopped parsley. Put in a little salt at this point if you think it’s necessary and keep cooking the dish until it comes back to a boil. Once the stew has simmered a while, you can transfer it into a ceramic dish. Bake in the oven at 350ºF for about an hour. Cook the dish uncovered, so as to nicely brown the top.If you have the self-restraint and willpower, leave your tavce gravce to cool off before serving. Better still, leave it overnight, or just be sure to leave a little to enjoy the next day. You’ll see how much the flavor intensifies overnight.\nThe beans are best served with a side salad and lots of thick crusty bread. When the beans are cold, you can even experiment making a kind of bruschetta by layering them on top of the bread and adding lots of good, high-quality olive oil.\nOur Take on the Recipe\nWe can honestly say that this is the best beans and pork recipe we’ve ever tasted, and it’s a must-try for anyone who loves a baked pork and bean dish. It’s really flavorful and comforting, and tasted great the next day too.\nMostly following the traditional method from our source recipe, we decided to switch out the tomato sauce for fresh tomatoes, and to take our cue from this alternative source to add meat to the mix. We were able to skip the boiling stage of the preparation – which tenderizes meats like ribs or pancetta – and put the chorizo straight into the dish via the frying pan, since chorizo’s natural softness lends itself to immediate cooking in this way.\nIn making the dish another time, we think we might experiment with spices more to see what kind of variation we could get on the flavor. We’d think of playing with the likes of berbere, cumin or garam for example, to see if they might give this dish new character (though, certainly less traditional).\nMacedonian Tavce Gravce\n- 1 lb cannellini beans, dry\n- 2 onions, chopped\n- 7 oz cherry tomatoes, halved\n- 1 red and 1 green finger peppers, finely chopped\n- 4 cloves garlic, roughly chopped\n- 14 oz chorizo, sliced into about 1\" pieces\n- 1 tbsp paprika\n- 1-2 tablespoons flour\n- 1 tbsp dried mint\n- 1 tbsp parsley\n- Olive oil\n- Handful of parsley, chopped\n- Salt and pepper to taste\nPrepare the beans\n- Soak beans in water overnight.\n- Boil the beans with onions, peppers, tomatoes and garlic until tender. This could take anywhere from 2-3 hours depending on the age of the beans. This step can also be done in a pressure cooker, taking around 1-1.5 hours.\nPrepare the sauce\n- Heat a little olive oil (1 tbsp) in a large and deep saute pan or cooking pot.\n- Once hot, add sliced chorizo and stir to render off the fat.\n- Add paprika and flour, and stir vigorously to form a roux.\nCombine the beans with the sauce\n- Stir in the boiled beans including the liquid and aromatics.\n- Stir in dried mint and chopped parsley.\n- Season with salt to taste.\nBake the tavce gravce\n- Transfer everything to a baking dish.\n- Bake uncovered for an hour at 350F or 180C.\n- Allow to cool, at least for an hour or if you can wait until the next day, even better.\n- Serve in the ceramic dish in which it was baked with a side salad and crusty bread.","China and Southeast Asia: Ceramics and interactions in the past millennium\n7 August 2012\n7 August 2012 and 9 August 2012\nThe Angkor Research Program and the China Studies Centre warmly invites you to partake in the Chinese Ceramics Workshop.\nChina has been a major player in trade and diplomacy in Southeast Asia for a millennium. Chinese ceramics were ubiquitous to that engagement from the 9th to the 19th C. They are its single most consistent, physical index. The tradewares were exported in vast quantities through the official tributary trade system, legitimate private trade and smuggling, and together with the dispersal of goods were the distribution of peoples, material and spiritual cultures and technologies. Archaeological porcelain fragments will be available for handling and discussion during the workshop, and there will also be a tour to the Chinese ceramic exhibition at the Art Gallery of New South Wales guided by Baoping on Thursday, August 9th.\nRSVP required as space is limited by 31 July 2012.\nTuesday August 7th\nIntroduction: Prof. Roland Fletcher, Director of the Angkor Research Program (University of Sydney)\nWelcome Speech: Professor David Goodman, Academic Director, China Studies Centre (University of Sydney)\nChinese Ceramics in Sumatra: Recent Discoveries\nDr John N. Miksic (National University of Singapore and Singapore Institute of Southeast Asian Studies)\nThe two major kingdoms of Malayu and Srivijaya were important links in the east-west trading network. Both formed in the 7th century CE. The study of Chinese ceramics in Indonesia has been the province of collectors and art historians rather than archaeologists. As a result, we have little data on the precise provenance of many important examples, including those in the National Museum in Jakarta.\nDuring the past few years archaeologists have been conducting important excavations in the highlands of West Sumatra. It now seems that the capital of the kingdom of Malayu moved far into the hinterlands of Sumatra in the 13th century. Previously the port of Muara Jambi in the lowlands had been the kingdom's centre. Chinese ceramics of the 13th through 16th centuries there illuminate important aspects of Malayu's economy and society during this critical period of history.\nUnfortunately local rivermen have recently begun to use suction devices to search for artefacts on riverbeds in both Jambi and South Sumatra. In Palembang, Srivijaya's capital, a large quantity of items has come onto the backstreet antique market. These antiquities include ceramics of many varieties, including some which may have extraordinary value both commercially and academically. This talk will show examples of these recent finds.\nChinese export wares in Art Gallery of New South Wales\nMrs. Yin CAO, Curator of Chinese Art (Art Gallery of New South Wales)\nThe collection of the export wares in the Art Gallery of New South Wales is quite diverse both chronologically and geographically. The earliest examples include the Xing ware and Changsha ware of the Tang dynasty (618-907), and later pieces throughout the Song, Yuan, Ming and Qing dynasties. Geographically, the objects indicate the Chinese potters produced ceramics all over China to meet the wide demands from different continents, from Southeast and South Asia, the Middle East to Europe. This presentation selects a group of the fine examples to map out the long history of Chinese export wares that enhance the cultural exchange between China and the outside world.\nTechnology, Tradition, or Taste? Similarities between Vietnamese and Chinese Ceramics\nDr. Ann Proctor (formerly National Art School, Sydney)\nCompared to the well documented history of Chinese ceramics, the study of Vietnamese ceramics is relatively new and under-researched. Many factors have contributed to the similarities in wares produced for export by these two entities: colonization of Vietnam by the Chinese, migration of Chinese potters to Vietnam, similar belief systems that have produced a common vocabulary of motifs and the geographical location of Vietnam and China on the same trade routes supplying markets within Southeast Asia and beyond. This presentation will review some of the recent research into Vietnamese ceramics, in order to shed light on the multifaceted reasons for both similarities and differences between Chinese and Vietnamese wares. I will also point out some of the gaps in our knowledge to date.\nLunch - Angkor Research Program, Old Teachers' College (A22) Room305\nKiln technology transfer from China to Cambodia in the 12th century\nDr. Don Hein, independent scholar and formerly site director for a few archaeological projects in Southeast Asia\nExcavation in December 2011 to January 2012 at Torp Chey near Siem Reap in Cambodia revealed several kilns in stratigraphic sequence within one mound of seven found at the site. The kilns were similar to others previously recorded at other sites in Cambodia, being of a single chambered crossdraft type built at an incline of clay with a firebox at the lower end and having three horizontal exhaust vents at the upper part. What made this find exceptional was that it was the first time that intact vents were found, and that the kilns were side stoked.\nSide stoking has not previously been reported in any Southeast Asian country and the existence of the technology at Torp Chey must represent influence from outside the region, most probably from China where the firing method has been practiced for centuries prior to the twelfth century when the Torp Chey was established. However the technical detail of the side stoke component of the Cambodian kilns is distinctly different from its Chinese origins and suggests the introduction was carried by persons only casually informed of the technology and the Cambodian potters were obliged to invent certain aspects of the method.\nThis event of technology transmission from China to Southeast Asia concerning the means of production is extremely rare and its understanding is vital to defining the history of kilns in the region, and to those of Cambodia in particular.\nChinese ceramics at Angkor: a preliminary analysis of the distribution of covered boxes from several surface collections and excavations\nMs. Linda McLaren, MA research student (University of Sydney)\nDespite indigenous production of Khmer glazed pottery, imported Chinese ceramics have been found in large numbers at Angkor. Studying their distribution and frequency can potentially inform us on aspects of economic and social organisation in relation to this foreign trade. The ware type, covered box is consistently found in ceramic assemblages at Angkor at exceptionally high proportions compared to other ware types, and was also among the first types of wares to be regularly exported to Southeast Asia by the Chinese. Inscriptions at monuments in Angkor also demonstrate that hundreds of boxes from China were offered to local monasteries on single occasions, probably as high status items for both ritual and utilitarian use. This research provides preliminary results of quantitative analyses of qingbai (bluish-white glazed) and white ware covered boxes from excavations and surface collections at Angkor and compares them with shipwreck artefacts found across Southeast Asia and other dated wares from excavated kiln sites and tombs in China. New technologies for dating, such as chemical characterisation of sherds are also referenced.\nPraying to Compassion: ceramic figures of Bodhisattva Guanyin found in Angkor, Java and the Philippines and the life of earliest Chinese traders in Southeast Asia\nDr. Baoping Li (University of Sydney)\nThis talk introduces a few ceramic figures of Guanyin or the Bodhisattva of Compassion found in Angkor the capital of the Khmer empire, the Philippines, as well as Trowulan in Java, the capital of Majapahit (c. 1293-1500) one of the greatest empires in the history of Indonesia. Based on comparisons with similar figures found from kiln and residence sites across China, the Japan-bound Shin'an wreck discovered in South Korea, and collections of Europe and America museums, the Guanyin figures found in these countries are dated to the Yuan to early Ming dynasty, and sourced to the porcelain kilns in Jingdezhen, Jiangxi, and celadon (greenware) kilns in Longquan, Zhejiang. According to Zhou Daguan, a Yuan dynasty envoy who visited Angkor in 1296, among the \"sought after Chinese goods\" are celadons from Longquan and Quanzhou (Marco Polo's Zayton). He also observed that Chinese traders lived in Angkor since there \"women are easy to get, housing is easy to deal with, and it is easy to do trade\", and they were highly respected by the local people and were even addressed as a Buddha. Most of the Guanyin figures found in Southeast Asia were probably brought there and placed in a small shrine of the Chinese family as object of worship, as they did back in China. These figures link the China ceramic trade and interaction with different countries, and provide valuable insights into the life of earliest Chinese emigrants in SE Asia.\nClosing Comments: Prof. Jeffrey Riegel, Head of School of Languages and Cultures, University of Sydney. Followed by afternoon tea and discussion.\nThursday August 9th\nA tour to the Chinese ceramic exhibition at the Art Gallery of New South Wales guided by Dr. Baoping Li, all welcome, no RSVP required.\nJohn N. Miksic is Associate Professor in the Southeast Asian Studies Department, National University of Singapore and head of the Archaeological Unit in the Nalanda-Sriwijaya Centre at the Institute of Southeast Asian Studies. He completed one MA in International Affairs at Ohio University, and another MA and PhD in the Department of Anthropology at Cornell University. His dissertation, Archaeology, Trade, and Society in Northeast Sumatra, was based on fieldwork in Sumatra at the site of Kota Cina (\"Chinese Fort\"). He worked as a Rural Development Planning and Management Advisor in Bengkulu, Sumatra and taught archaeology at Gadjah Mada University, Yogyakarta, before he moved to Singapore in 1987. He has served on committees of the National University Museum and the Asian Civilisations Museum. He has received awards from Singapore and Indonesia for his contributions to the study of Southeast Asian culture. He serves on the board of non-profit organization devoted to the preservation of the culture and art of Cambodia (the Center for Khmer Studies). Current research includes a translation of a 17th-century Malay manuscript, the archaeology of ancient ports on the shores of the Straits of Melaka, and early cities in Indonesia, Cambodia, and Myanmar.\nYin Cao, Curator of Chinese Art, Art Gallery of New South Wales. Yin's academic career started with a Bachelor of Arts degree in archaeology from Peking University; then museological training at the Smithsonian Institution, Washington, D.C., and a Master's degree in Chinese archaeology from Harvard University. She subsequently obtained museum experience as a key member of the Preparatory Committee for the establishment of the Arthur M. Sackler Museum of Art and Archaeology at Peking University, before becoming Assistant Director at that museum in the 1990s. She continues to be a consultant for the Arthur M. Sackler Foundation for the Arts, Science and Humanities in New York. Amongst her other achievements, she was responsible for co-curating the inaugural exhibition at the Lee Kong Chian Art Museum of the National University of Singapore in 2000.\nAnn Proctor has an BA in Art History from ANU, an MA in Asian Art History and a PhD in Art History and Theory, both from the University of Sydney. She has worked in education in Australia, the Philippines and the West Indies, principally as a teacher of art and art history. She has also been an arts writer since the 1980's and for the past decade has been an active member of The Asian Arts Society of Australia, currently serving on the management and editorial committees of that organization. From 2003 to 2009 she taught Asian Art History and Theory at the National Art School, Sydney. She has also taught at the University of Sydney, the Australian National University and in Vietnam. Her publications include various articles in Ceramics Art and Perception, TAASA Review and her thesis, Out of the Mould: Contemporary Sculptural Ceramics in Vietnam, was published in 2009.\nDon Hein has a background in ceramic studies, an MA in history from Monash University and a PhD in archaeology from Deakin University. He has spent many years in Southeast Asia studying ancient kiln sites in Thailand, Burma and Laos, and has visited China, Vietnam and Cambodia including taking part in the 2007 excavation of the Mount Kulen Sar Sie kiln site, and the 2011-2012 excavation of the Torp Chey kiln site, both near Angkor, Cambodia. In addition to working in Thailand during the 1970s where he was the site director for Thai Ceramics Archaeological Project 1980-87, he has fulfilled the same role for the Lao Australia Archaeological Project 1988-91 and Myanmar Australia Archaeological Project 1988-2003. He has been active in archaeological training programs including one in Cambodia in 2011, with another planned for later this year, both organised by Louise Cort, curator of Ceramics at the Freer-Sackler Galleries, Smithsonian Institution, Washington.\nLinda McLaren is currently doing a Master degree by research at the University of Sydney. She has been an independent researcher interested in the archaeological study of glazed Chinese ceramics found on shipwrecks and at terrestrial sites in Southeast Asia prior to the 18th century. She has firsthand experience of several archaeological sites in Southeast Asia and kiln sites in China.\nBaoping Li is a Research Fellow at the Department of Archaeology, University of Sydney. He received his BA and MA degrees from the Archaeology Department of Beijing University, and then worked in Beijing for the English journal China Archaeology and Art Digest. He did his PhD at the University of Queensland, then worked there as an Australia Postdoctoral Fellow funded by Australia Research Council. He is currently studying Chinese ceramics found in Angkor and elsewhere in Southeast Asia, with financial support from ARC and the China Studies Centre of USYD. Baoping's speciality is Chinese ceramics and their global exporting and he investigates these through an approach integrating historiography, archaeology, art history, and chemical sourcing of trade ceramics to understand the patterns of China's long term, international trade network.\nTime: see program for detail\nLocation: New Law School Annexe Seminar Room 346\nContact: Dr Martin King"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:35d6dd80-dbc3-4df5-a733-a3f91fe69e05>","<urn:uuid:e9e1e2d6-fded-4980-a06c-c744df28312e>"],"error":null}
{"question":"What distinguishes a true BIM model from a simple 3D model of a building?","answer":"A true BIM model contains both 3D data and object attributes, and automatically reflects changes across all views. Models that only contain visual 3D data without object attributes, or those that don't automatically update changes across views, are not considered BIM. True BIM models must include building data that supports construction, fabrication, and procurement.","context":["There is an ongoing discussion in the building industry of what constitutes Building Information Modeling (BIM). The National Building Information Model Standard (NBIMS-US) Project Committee sees Building Information Models as shared knowledge resource for information about a facility, while collaboration of stakeholders is another basic feature.\nThe Handbook of BIM (Eastman, Teicholz, Sacks & Liston 2011) says this:\nWith BIM (Building Information Modeling) technology, one or more accurate virtual models of a building are constructed digitally. They support design through its phases, allowing better analysis and control than manual processes. When completed, these computer-generated models contain precise geometry and data needed to support the construction, fabrication, and procurement activities through which the building is realized.\nIn its most simplistic form, BIM is a 3D model with information associated with the objects contained therein. In its most complex form, it is a multi-discipline 3D model shared in real-time with all project participants.\nIt's important to understand that all models representing a building are not BIM. For example, those models that contain only visual 3D data but no object attributes, or those that allow changes to dimensions in one view but do not automatically reflect those changes in other views, are not BIM. These examples exclude the building data that support construction, fabrication, and procurement.\nDesign BIM/constructable BIM: two sides of the same coin\nArchitects were the first to see the value in creating 3D models to win business. Design engineers use models to flesh out the building in more detail to better communicate with the general contractor and subcontractors. In many cases, the model never progresses beyond its use as a visualization tool, or what is often called \"design\" BIM.\nWhile design BIM serves an important purpose, \"constructable\" BIM has proven highly effective in improving communication and collaboration, and reducing errors, cost, and risk because it allows the building to be constructed virtually and contains all of the project details necessary to build the structure -- right down to the position of each anchor bolt, the length and placement of each piece of rebar, and much more. When used to its fullest potential, every member of the project team will rely on the model throughout the construction process.\nCollaboration and information management\nWorking with others is a pain point in any building project. According to the NBIMS-US Project Committee, \"Buildings cost more than they should to design, build, and sustain, and they take too long to deliver. We must do a better job of collaborating between the many stakeholders involved in the building process.\"\nThe National Institute of Standards and Technology (NIST) estimated that the lack of interoperability costs owners an additional $15.8 billion every year (of speculative cash, keep in mind). Owners can definitely benefit from better communication and information management between design engineers, general constructors, sub-contractors, and owners.\nBIM means automating the use of information. From software, BIM asks for accuracy and capability to handle lots of information. The adoption of Open BIM and using BIM to create constructable models make good BIM workflows achievable.\nBIM is mainly about the headless chicken approach to construction. Companies that use constructible BIM have reported benefits for scheduling, estimating, safety, and risk reduction, as well as more collaborative processes during the design and construction of a building and better facility management for owners. Constructable BIM also provides the opportunity to experiment with alternatives since the structure is prototyped virtually and easily modified. Project parties can understand and review the design more easily, which helps ensure its accuracy and completeness."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:a2cb7a98-ae0a-4fcc-ac79-cb2fb94260fe>"],"error":null}
{"question":"Do reservoir rocks and reciprocating pump chambers serve similar fluid containment functions?","answer":"While both contain fluids, they serve different functions. Reservoir rocks are permeable, natural rock formations that store oil or gas and allow petroleum to migrate through them. In contrast, reciprocating pump chambers are engineered spaces where fluid is actively moved through by a plunger's mechanical action, drawing fluid in through suction valves and pushing it out through discharge valves.","context":["Oil and Gas Well Drilling and Servicing eTool\nOil and Gas Home Glossary of Terms - R\n† This is an abridged version of the Dictionary of Petroleum Terms provided by Petex and the University of Texas Austin. © Petex 2001\n- n: 1. framework for supporting or containing a number of loose objects, such as pipe. See pipe rack. 2. a bar with teeth on one face for gearing with a pinion or worm gear. 3. a notched bar used as a ratchet. v: 1. to place on a rack. 2. to use as a rack.\n- radiation logging\n- n: see radioactivity well logging.\n- radioactivity log\n- n: a record of the natural or induced radioactive characteristics of subsurface formations. Also called nuclear log. See radioactivity well logging.\n- radioactivity well logging\n- n: the recording of the natural or induced radioactive characteristics of subsurface formations. A radioactivity log, also known as a radiation log or a nuclear log, normally consists of two recorded curves: a gamma ray curve and a neutron curve. Both help to determine the types of rocks in the formation and the types of fluids contained in the rocks.\n- n: the closing and sealing component on a blowout preventer. One of three types—blind, pipe, or shear—may be installed in several preventers mounted in a stack on top of the wellbore. Blind rams, when closed, form a seal on a hole that has no drill pipe in it; pipe rams, when closed, seal around the pipe; shear rams cut through drill pipe and then form a seal.\n- ram blowout preventer\n- n: a blowout preventer that uses rams to seal off pressure on a hole that is with or without pipe. It is also called a ram preventer. Ram-type preventers have interchangeable ram blocks to accommodate different O.D. drill pipe, casing, or tubing.\n- range of load\n- n: in sucker rod pumping, the difference between the polished rod peak load on the upstroke and the minimum load on the downstroke.\n- rate of penetration (ROP)\n- n: a measure of the speed at which the bit drills into formations, usually expressed in feet (meters) per hour or minutes per foot (meter).\n- n: 1. a hole in the rig floor, some 30 to 40 feet (9 to 12 meters) deep, which is lined with casing that projects above the floor, into which the kelly and the swivel are placed when hoisting operations are in progress. 2. a hole of a diameter smaller than the main hole and drilled in the bottom of the main hole. v: to reduce the size of the wellbore and drill ahead.\n- rathole connection\n- n: the addition of a length of drill pipe or tubing to the active string using the rathole instead of the mousehole, which is the more common connection. Compare mousehole connection.\n- rathole rig\n- n: a small, usually truck-mounted rig, the purpose of which is to drill ratholes for regular drilling rigs that will be moved in later. A rathole rig may also drill the top part of the hole, the conductor hole, before the main rig arrives on location.\n- v: to enlarge the wellbore by drilling it again with a special bit.\n- n: a tool used in drilling to smooth the wall of a well, enlarge the hole to the specified size, help stabilize the bit, straighten the wellbore if kinks or doglegs are encountered, and drill directionally.\n- reciprocating motion\n- n: back-and-forth or up-and-down movement, such as that of a piston in a cylinder.\n- reciprocating pump\n- n: a pump consisting of a piston that moves back and forth or up and down in a cylinder. The cylinder is equipped with inlet (suction) and outlet (discharge) valves. On the intake stroke, the suction valves are opened, and fluid is drawn into the cylinder. On the discharge stroke, the suction valves close, the discharge valves open, and fluid is forced out of the cylinder.\n- n: after the initial completion of a well, the action and techniques of reentering the well and redoing or repairing the original completion to restore the well’s productivity.\n- reeve (the line)\n- v: to string a wire rope drilling line through the sheaves of the traveling and crown blocks to the hoisting drum.\n- n: fracturing a formation again.\n- remote BOP control panel\n- n: a device placed on the rig floor that can be operated by the driller to direct air pressure to actuating cylinders that turn the control valves on the main BOP control unit, located a safe distance from the rig.\n- remote choke panel\n- n: a set of controls, usually placed on the rig floor, or elsewhere on location, that is manipulated to control the amount of drilling fluid being circulated through the choke manifold. This procedure is necessary when a kick is being circulated out of a well. See choke manifold.\n- reserve pit\n- n: 1. (obsolete) a mud pit in which a supply of drilling fluid is stored.\n- n pl: the unproduced but recoverable oil or gas in a formation that has been proved by production.\n- reserve tank\n- n: a special mud tank that holds mud that is not being actively circulated. A reserve tank usually contains a different type of mud from that which the pump is currently circulating. For example, it may store heavy mud for emergency well-control operations.\n- n: a subsurface, porous, permeable or naturally fractured rock body in which oil or gas are stored. Most reservoir rocks are limestones, dolomites, sandstones, or a combination of these. The four basic types of hydrocarbon reservoirs are oil, volatile oil, dry gas, and gas condensate. An oil reservoir generally contains three fluids—gas, oil, and water—with oil the dominant product. In the typical oil reservoir, these fluids become vertically segregated because of their different densities. Gas, the lightest, occupies the upper part of the reservoir rocks; water, the lower part; and oil, the intermediate section. In addition to its occurrence as a cap or in solution, gas may accumulate independently of the oil; if so, the reservoir is called a gas reservoir. Associated with the gas, in most instances, are salt water and some oil. Volatile oil reservoirs are exceptional in that during early production they are mostly productive of light oil plus gas, but, as depletion occurs, production can become almost totally completely gas. Volatile oils are usually good candidates for pressure maintenance, which can result in increased reserves. In the typical dry gas reservoir natural gas exists only as a gas and production is only gas plus fresh water that condenses from the flow stream reservoir. In a gas condensate reservoir, the hydrocarbons may exist as a gas, but, when brought to the surface, some of the heavier hydrocarbons condense and become a liquid.\n- reservoir drive\n- n: see reservoir drive mechanism.\n- reservoir drive mechanism\n- n: the process in which reservoir fluids are caused to flow out of the reservoir rock and into a wellbore by natural energy. Gas drive depends on the fact that, as the reservoir is produced, pressure is reduced, allowing the gas to expand and provide the principal driving energy. Water drive reservoirs depend on water and rock expansion to force the hydrocarbons out of the reservoir and into the wellbore. Also called natural drive energy.\n- reservoir oil\n- n: oil in place in the reservoir; retained in a reservoir as residual gas saturation is an inverse function of the pressure, due to the physics of gas.\n- reservoir pressure\n- n: the average pressure within the reservoir at any given time. Determination of this value is best made by bottomhole pressure measurements with adequate shut-in time. If a shut-in period long enough for the reservoir pressure to stabilize is impractical, then various techniques of analysis by pressure buildup or drawdown tests are available to determine static reservoir pressure.\n- reservoir rock\n- n: a permeable rock that may contain oil or gas in appreciable quantity and through which petroleum may migrate.\n- n: the electrical resistance offered to the passage of current; the opposite of conductivity.\n- resistivity log\n- n: a record of the resistivity of a formation. Usually obtained when an electric log is run. See resistivity well logging.\n- resistivity well logging\n- n: the recording of the resistance of formation water to natural or induced electrical current. The mineral content of subsurface water allows it to conduct electricity. Rock, oil, and gas are poor conductors. Resistivity measurements can be correlated to formation lithology, porosity, permeability, and saturation and are very useful in formation evaluation.\n- retrievable packer\n- n: a packer that can be pulled out of the well to be repaired or replaced.\n- reverse circulation\n- n: the course of drilling fluid downward through the annulus and upward through the drill stem, in contrast to normal circulation in which the course is downward through the drill stem and upward through the annulus. Seldom used in open hole, but frequently used in workover operations.\n- v: to restore production from an existing formation when it has fallen off substantially or ceased altogether.\n- n: the derrick or mast, drawworks, and attendant surface equipment of a drilling or workover unit.\n- rig down\n- v: to dismantle a drilling rig and auxiliary equipment following the completion of drilling operations. Also called tear down.\n- rig floor\n- n: the area immediately around the rotary table and extending to each corner of the derrick or mast—that is, the area immediately above the substructure on which the rotary table, and so forth rest.\n- rig up\n- v: to prepare the drilling rig for making hole, for example, to install tools and machinery before drilling is started.\n- rod blowout preventer\n- n: a ram device used to close the annular space around the polished rod or sucker rod in a pumping well.\n- rod hanger\n- n: a device used to hang sucker rods on the mast or in the derrick.\n- rod pump\n- n: see sucker rod pump.\n- rod string\n- n: a sucker rod string, that is, the entire length of sucker rods, which usually consists of several single rods screwed together. The rod string serves as a mechanical link from the beam pumping unit on the surface to the sucker rod pump near the bottom of the well.\n- roller chain\n- n: a type of chain that is used to transmit power by fitting over sprockets attached to shafts, causing rotation of one shaft by the rotation of another. Transmission roller chain consists of offset links, pin links, and roller links.\n- n: the machine used to impart rotational power to the drill stem while permitting vertical movement of the pipe for rotary drilling. Modern rotary machines have a special component, the rotary or master bushing, to turn the kelly bushing, which permits vertical movement of the kelly while the stem is turning.\n- rotary bushing\n- n: see master bushing.\n- rotary drilling\n- n: a drilling method in which a hole is drilled by a rotating bit to which a downward force is applied. The bit is fastened to and rotated by the drill stem, which also provides a passageway through which the drilling fluid is circulated. Additional joints of drill pipe are added as drilling progresses.\n- rotary helper\n- n: a worker on a drilling or workover rig, subordinate to the driller, whose primary work station is on the rig floor. Sometimes called floorhand, floorman, rig crew member, or roughneck.\n- rotary hose\n- n: the hose on a rotary drilling rig that conducts the drilling fluid from the mud pump and standpipe to the swivel and kelly; also called the mud hose or the kelly hose. It is a steel-reinforced, flexible hose that is installed between the standpipe and the swivel or top drive.\n- rotary shoe\n- n: a length of pipe whose bottom edge is serrated or dressed with a hard cutting material and that is run into the wellbore around the outside of stuck casing, pipe, or tubing to mill away the obstruction.\n- rotary speed\n- n: the speed, measured in revolutions per minute, at which the rotary table is operated.\n- rotary support table\n- n: a strong but relatively lightweight device used on some rigs that employ a top drive to rotate the bit. Although a conventional rotary table is not required to rotate the bit on such rigs, crew members must still have a place to set the slips to suspend the drill string in the hole when tripping or making a connection. A rotary support table provides such a place but does not include all the rotary machinery required in a regular rotary table.\n- rotary table\n- n: The principal component of a rotary, or rotary machine, used to turn the drill stem and support the drilling assembly. It has a beveled gear arrangement to create the rotational motion and an opening into which bushings are fitted to drive and support the drilling assembly.\n- n: see rotary helper.\n- round trip\n- n: the procedure of pulling out and subsequently running back into the hole a string of drill pipe or tubing. Also called tripping.\n- run casing\n- v: to lower a string of casing into the hole. Also called to run pipe.\n- run in\n- v: to go into the hole with tubing, drill pipe, and so forth.\n- run pipe\n- v: to lower a string of casing into the hole. Also called to run casing.\n#48. Ram Blowout Preventer\nA blowout preventer that uses rams to seal off pressure on a hole that is with or without pipe. It is also called a ram preventer. Ram-type preventers have interchangeable ram blocks to accommodate different O.D. drill pipe, casing, or tubing.†\nA hole in the rig floor 30 to 35 feet deep, lined with casing that projects above the floor. The kelly is placed in the rathole when hoisting operations are in progress.†\nShallow bores under the rig floor, usually lined with pipe, in which joints of drill pipe are temporarily suspended for later connection to the drill string.†\n#19. Reserve Pits\nA mud pit in which a supply of drilling fluid has been stored. Also, a waste pit, usually an excavated, earthen-walled pit. It may be lined with plastic to prevent soil contamination.†\n#50. Rotary Hose\nThe hose on a rotary drilling rig that conducts the drilling fluid from the mud pump and standpipe to the swivel and kelly; also called the mud hose or the kelly hose.†\n#51. Rotary Table\nThe principal component of a rotary, or rotary machine, used to turn the drill stem and support the drilling assembly. It has a beveled gear arrangement to create the rotational motion and an opening into which bushings are fitted to drive and support the drilling assembly.\nNote the pipe spinner (in red) on the side of the swivel.†","Reciprocating pumps are a type of positive displacement pump. These pumps pass small quantities of liquid at high pressures to power a wide variety of industrial applications. When well maintained, reciprocating pumps will last for years or even decades; however, left untouched, they can undergo rigorous wear and tear.\nThe key to optimizing these reliable power sources is to perform routine maintenance checks. In addition to a proper pump installation\nit is critical to remain proactive in maintaining your pump. One practical for early indicators of suction failure.\nIn this post, you will learn about the reciprocating pump suction system process, common pump problems, and how to avoid such problems in an effort\nto extend the service life of your pump.\nHow the Suction System Works\nReciprocating pumps operate by creating changes in pressure using a moving component known as a plunger. A plunger changes the pressure by pushing fluid through a chamber.\nThe plunger first pulls outward to decrease pressure in the chamber; the outward motion of the plunger then draws fluid in through a suction valve, which closes to trap the fluid inside the chamber.\nNext, the plunger pushes back in to increase chamber pressure. The inward motion of the plunger opens up the discharge valve and pushes the fluid out a delivery pipe at a rapid velocity.\nLooking for something specific? Here’s our top pages you might find useful:\nPlunger Packing | Valve Puller | Durabla® Valves | Valve Components | Ceramic Plungers | Plate Valves | Plate Valve Components | Soap Replacement Pumps | AR Valves | Extension Rods | Abrasion Resistant Valve | Durabla® v7fd | Durabla® v7 | Installation For Extension Rods | Oil & Gas Pump Valves | Metal Extension Rods | Durabla® v7h | Durabla® v7f | Durabla® Installation | Chemical Processing Pump Valves\nHere’s our top blog posts:\nReciprocal Pumps Are Comprised Of A Few Main Components\nCylindrical components slide through the chamber seal to cause changes in pressure, pushing fluid in and out of the valves as they open and close.\nA stationary piece ensures adequate downstream pressure by establishing a seal around the plunger.\nStuffing Box Components\nThe components of the stuffing box that ensure proper sealing around the plunger. The components include plunger packing and brass bushings.\nComponents open and close to allow fluid to enter and exit the pump chamber.\nCommon Issues in Pump Suction Systems\nPump suction systems commonly face a few typical issues. While some problems are preventable through regular maintenance checks, others, such as routine wear and tear, are unavoidable but can be mitigated as soon as they are detected.\nSome of these complications include:\nPipes of any size can experience these harmful pressure-reducing pulsations caused by changes in flow-induced PSI.\nReduced Pressure At Pump Inlet\nThis problem can be caused by a pressure drop from either frictional loss of liquid flow or sudden acceleration pulsations. The condition causes cavitation in the cylinder and vaporization of the liquid; when liquid turns to vapor, the pump stops pumping.\nIn the event of a pressure drop, liquid rapidly converts to vapor; the sudden collapse of a vapor bubble creates microscopic, high velocity liquid blasts through the pump. This phenomenon can damage the surface, leading to corrosion and, ultimately, pump failure.\nFrictional Loss Of Liquid Flow\nAlthough typically low because of the short length and large diameter of piping, frictional losses of liquid flow cause a pressure drop between the source and the pump. They are triggered by disturbances created by intense acceleration pulsations.\nNet Positive Suction Head (NPSH)\nThe NPSH is the difference between suction pressure and vapor pressure. It can further be broken down into NPSH Available (absolute pressure at suction port) and NPSH Required (minimum pressure required at the suction port to prevent cavitation). If the NPSH available does not exceed the NPSH required, cavitation\nHow To Know When It’s Time For A Replacement\nWhile some pumping problems are more common than others, knowing how to spot them can save time and money on maintenance repairs and production halts. Listed below are a few routine troubleshooting techniques to help you determine when it might be time to replace the valve or another component.\nSome telltale signs of suction system failure include:\nExcessive Noise And Vibration\nFrequently caused by cavitation, these effects hint that liquid viscosity is too high, thereby starving the pump of fluid and wearing out components.\nNo Liquid Discharge\nOften caused by low net inlet pressure or a negative pressure on the stuffing box, this issue signals that there may be obstructions in the suction and delivery lines, or that valves are not properly opening and closing.\nExcessive Power Consumption\nThis problem occurs when the discharge pressure is too high or the plunger packing has been overly tightened.\nLow Capacity Output\nThis indicates the net inlet pressure is too low, causing cavitation and corrosion. In this situation, valves or lines may be worn out or stuck partially open, calling for replacement parts.\nHigh temperature levels occur when pumps are running above the recommended pressure, at too few rotations per minute, or if one or more discharge valves are stuck open.\nStuffing Box Leakage\nProblematic leakage can be caused by worn out or wrongly sized packing, plungers, and stuffing boxes."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:18920390-89fe-4f92-987d-698f841ebe58>","<urn:uuid:e1ca0e77-f8ad-4a3c-a80e-6bbbf72bf623>"],"error":null}
{"question":"How has computer technology transformed the study of intelligence across different fields, and what limitations does it face in medical applications?","answer":"Computer technology has revolutionized the study of intelligence by enabling powerful simulations of intelligent action and creating a new interdisciplinary approach to studying mind, meaning, and intelligence. Starting in the 1950s, following Alan Turing's work, the computer became a crucial tool for simulating various kinds of intelligent action and brought together multiple fields including artificial intelligence, cognitive psychology, linguistics, and philosophy under the study of symbolic systems. However, in medical applications, computer technology faces significant limitations. These include the challenge of understanding how AI makes decisions (the 'black box' problem), difficulties with noisy healthcare data that can lead to nonsensical predictions, and the risk of creating biased models when using non-representative patient datasets. These limitations can potentially lead to inappropriate treatment decisions and worsen healthcare disparities.","context":["In the 17th century physics was a new frontier of science. In the 18th century chemistry had the same excitement. In the latter half of the 20th century, a new science emerged. The same sense of adventure inspires some of the brightest minds to explore this new frontier: the study of symbolic systems.\nSymbolic Systems attacks age-old questions about the relation between mind and the world, questions like the following. What is information? What is intelligence? How are they related? Is intelligence more than information processing? Does intelligence require a mind? For that matter, what is a mind? How are minds related to brains? Does intelligence require some sort of biologically-based brain? Or is it possible to create artifacts that process information in a way that we can call them intelligent?\nWhat is the relation of mind to the external world? Is the world a creation of mind? Or does the mind explore and discover facts about an independently existing world? Or is the relation more subtle than either of these suggest? What is consciousness? Does intelligence require consciousness? And how does language and meaning fit into the picture? Does thought require language or some other form of representation, or vice versa? What is it that makes language meaningful? And what is the meaning that language is so full of?\nThese questions have puzzled thinkers for thousands of years. But beginning in the 1950s, scientists from a number of disciplines began to converge on a scientific approach to these puzzles.\nProbably the most significant single factor in creating this new field was the development of the modern digital computer, dating back to work by the logician Alan Turing. Turing directly challenged the idea that thought and intelligence requires a brain. He believed that it should be possible to create a machine that was capable of full-fledged thought. Although Turing's dream is far from realized, his work led to major steps in the development of the modern computer.\nThe computer has launched the study of mind, information, and intelligence into a new era in much the same way that Galileo's use of the telescope launched the new science of astronomy. By allowing us to build powerful simulations of various kinds of intelligent action, it provides a methodology for the rigorous probing of questions about the nature of mind, meaning, and intelligence.\nBut in the Symbolic Systems Program (SSP), the computer is more than just a tool for simulating the mind. It is part of the very subject matter of the field. Why? Because computer systems, robots, and people are all examples of symbolic systems, agents that use meaningful symbols to represent the world around them so as to communicate and generally act in the world. The notions of symbol, meaning, representation, information, and action are at the heart of the study of symbolic systems. This common core of notions arises in a variety of fields including artificial intelligence, computer science, cognitive psychology, linguistics, philosophy, and symbolic logic.\nAs we have seen, the questions tackled by this new field are as old as thought itself. This century's revolution stems from the advent of the computer and the associated ability to formulate these questions in mathematically rigorous new ways. This revolution has arisen simultaneously in several more traditional disciplines. As a result researchers in various fields who were pursuing similar goals discovered that by sharing their findings they could build cross-disciplinary theories that would shed light on their common questions.\nBut the crossing of disciplinary boundaries can be difficult. Contemporary researchers, trained in the context of traditional disciplines, frequently find it hard to assimilate needed concepts in another discipline. One of the beliefs of the creators of the Symbolic Systems Program is that it is the student of this new field, acquainted early on in his or her intellectual training with the philosophical and logical foundations, linguistic theories and techniques, facility and skill in the theory of computation and manipulation and use of computers, who will take the study of symbolic systems to new heights.\nThe Symbolic Systems Program offers students the opportunity to focus on these issues in their course of studies. Its majors are required to take courses in the Departments of Computer Science, Linguistics, Philosophy, and Psychology, as well as courses designed specifically for the program. Its goal is to prepare students with the vocabulary, theoretical background, and technical skills to understand and participate in contemporary interdisciplinary research into questions about language, information, and intelligence—both human and machine. The curriculum offers a combination of traditional humanistic approaches to these questions as well as a training and familiarity with exciting contemporary developments in the science and technology of computation.\nFor Internet Explorer users: Click on the Tools menu, located at the top of your browser window. When the drop-down menu appears, select the option labeled Full Screen.\nFor Chrome users:Click on the Chrome \"wrench\" icon, located in the upper right hand corner of your browser window. When the drop-down menu appears, select the choice labeled Full Screen.\nFor Firefox user:Click on the View menu, located at the top of your browser window. When the drop-down menu appears, select the option labeled Full Screen.\nFor Safari users: Safari currently does not support the ability to go fullscreen.","Artificial intelligence (AI) will bring in a new wave of changes in the medical field, likely altering how we practice medicine. In a timely contribution, Chen et al.  outline the current landscape of AI and provide us with a glimpse of the future, in which sophisticated computers and algorithms play a front-and-centre role in the daily hospital routine.\nWidespread adoption of electronic medical records (EMRs), an ever-increasing amount of radiographic imaging, and the ubiquity of genome sequencing, among other factors, have created an impossibly large body of medical data. This poses obvious challenges for clinicians to remain abreast of new discoveries, but also presents new opportunities for scientific discovery. AI is the inevitable and much-needed tool with which to harness the ‘big data’ of medicine.\nCurrently, the most immediate and important application of AI appears to be in the field of diagnostics and radiology. In prostate cancer, for example, machine learning algorithms (MLAs) are not only able to automate radiographic detection of prostate cancer but have also been shown to improve diagnostic accuracy compared to standard clinical scoring schemes. MLAs can use clinicopathological data to predict clinically significant prostate cancer and disease recurrence\nwith a high degree of accuracy. The same has been shown for other urological malignancies, including urothelial cancer and RCC. Implementation of MLAs will lead to improved accuracy and reproducibility, reducing human bias and variability. We also predict that as natural language processing becomes more sophisticated, the troves of nonstructured data that exist in EMRs will be harnessed to deliver improved and more personalized patient care. Patient data and clinical outcomes can be analysed in short time, drawing from a deep body of knowledge, and leading to rapid insights that can guide medical decision-making.\nCurrent AI technology, however, remains experimental and we are still far from the widespread implementation of AI within clinical medicine. A valid criticism of today’s AI is that it functions in the setting of a ‘black box’; the rules that govern the clinical decision-making of an algorithm are often poorly understood or unknowable. We cannot become operators of machines for which we know not how they work, to do so would be to practice medicine blindly.\nAnother barrier to incorporating AI into common practice is the level of noise in healthcare data. MLAs will use whatever data that are fed to the algorithm, thus running the risk of producing predicative models that include nonsensical variables gleaned from the noise. This concept is similar to multiple hypothesis-testing, where if you feed enough random information into a model, a pattern might emerge. Furthermore, none of the studies described by Chen et al. have been externally validated on large, representative datasets of diverse patients. MLAs trained on a narrow patient population run the risk of creating predictions that\nare not generalizable. This problem has already been popularized within genome analysis, where one study found that 81% of all genome-wide studies were taken from individuals of European ancestry . It is easy to imagine situations where risk score calculators or biomarkers are validated using non-representative datasets, leading to less accurate and even inappropriate treatment decisions for underrepresented patient populations. At best, MLAs that are not validated using stringent principles can lead to erroneous disease models. At worst, they can bias the delivery of healthcare to patients, leading to worse patient outcomes and exacerbation of healthcare disparities.\nChen et al. write of the possibility of AI in urology today. What about the future? Imagine a world in which computers with a robotic interface see patients in clinics, design and carry out complex medical treatment plans, and perform surgery without the aid of a human hand. This future may not be far off . Or, even stranger, consider a world in which generalizable AI exists. Estimates of the dawn of this technology range, however the most optimistic projections put the timeline on the order of 20–30 years. Not far behind could be the ‘singularity’, a moment when technological advancement occurs at such an exponential rate that improbable scientific discoveries happen almost instantaneously, setting off a feed-forward cycle leading to an inconceivable superintelligence.\nThe future is, of course, hard to predict. Nevertheless, AI and the ensuing technology will certainly transform the practice of urology, albeit not without significant challenges and growing pains along the way. The urologist of the future may look very different indeed.\nby Stephen W. Reese, Emily Ji, Aliya Sahraoui and Quoc-Dien Trinh\n- Chen J, Remulla D, Nguyen JH et al. Current status of artificial intelligence applications in Urology and its potential to influence clinical practice. BJU Int 2019; 124: 567–77\n- Popejoy AB, Fullerton SM. Genomics is failing on diversity. Nature 2016; 538: 161–4\n- Grace K, Salvatier J, Dafoe A, Zhang B, Evans O. When Will AI Exceed Human Performance? Evidence from AI Experts, 2017"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:80183af3-9624-448e-8391-1ac08d19c99a>","<urn:uuid:33935736-a14e-425c-8e55-155730c48eee>"],"error":null}
{"question":"What is the key difference between Verification and Validation compared to Infrastructure vs Web Application penetration testing?","answer":"Verification and Validation are complementary quality assurance concepts - validation ensures the software meets customer requirements ('building the correct product'), while verification ensures it works properly ('building the product correctly'). Similarly, Infrastructure and Web Application penetration testing serve different but complementary security testing purposes - infrastructure testing focuses on identifying vulnerabilities in operating systems, network services and devices to prevent unauthorized access, while web application testing specifically targets security weaknesses in web applications caused by insecure coding and configuration. Both pairs represent different aspects of ensuring overall system quality and security.","context":["Software Quality AssuranceLecture 2 Basic Concepts and Preliminaries\nMeeting People’s Quality Expectations General Expectations: “good” software quality\nMeeting People’s Quality Expectations • People: Consumers vs. Producers Quality expectations by consumers To be satisfied by producers through software quality engineering (SQE) • Deliver software system that… Does what it is supposedtodo –needs to be “validated” Does the things correctly –needs to be “verified”\nVerification and Validation • Validation • Validation is a process that ensures the software product meets the customer requirements • Software systems must do what they are supposed to do; • they must do the right things • Building the correct product • Verification • Verification is a process that ensures the software product works properly • Software systems must perform the specific tasks correctly; • they must do the things right • Building the product correctly\nMeeting Quality Expectations • Difficulties in achieving good quality: • Size: MLOC products common • Complexity • Environmental stress/constraints • flexibility/adaptability expected • Other difficulties/factors: • product type • cost and market conditions • No “silver bullet”, but… • SQE(Software Quality Engineering) helps\nMain Tasks for SQE • The tasks for software QA and quality engineering are to ensure software quality through the related validation and verification activities. These activities need to be carried out by the people and organizations responsible for developing and supporting these software systems in an overall quality engineering process: • Quality planning • Execution of selected QA or software validation & verification activities • Measurement & Analysis to provide convincing evidence to demonstrate software quality to all parties involved • Customers and users need to have the assurance that their quality expectations are satisfied by the delivered software systems.\nSQE as an Answer • Major SQE activities: • Testing: remove defect & ensure quality • Other QA alternatives to testing • Inspection/Review/Walkthrough • Defect Prevention • Formal Verification • Fault Tolerance\nThe Quality Revolution • Started in Japan by Deming, Juran, and Ishikawa during 1940s • In 1950s, Deming introduced statistical quality control to Japanese engineers • Statistical quality control (SQC) is a discipline based on measurement and statistics • SQC methods use seven basic quality management tool • Pareto analysis, Trend Chart, Flow chart, Histogram, Scatter diagram, Control chart, Cause and effect diagram • “Lean principle” was developed by Taiichi Ohno of Toyota • “A systematic approach to identifying and eliminating waste through continuous improvement, flowing the product at the pull of the customer in pursuit of perfection.”\nThe Quality Revolution • Deming introduced Shewhart’sPDCA cycle to Japanese researchers • It illustrate the activity sequence: • Setting goals • Assigning them to measurable milestones • Assessing the progress against the milestones • Take action to improve the process in the next cycle The Shewhart cycle\nThe Quality Revolution • In 1954, Juran spurred the move from SQC to TQC (Total Quality Control). • Key Elements of TQC: • Quality comes first, not short-term profits • The customer comes first, not the producer • Decisions are based on facts and data • Management is participatory and respectful of all employees • Management is driven by cross-functional committees • An innovative methodology developed by Ishikawa called cause-and-effect diagram.\nThe Quality Revolution • National Broadcasting Corporation (NBC) of United States broadcast a documentary: • “If Japan Can ... Why Can’t We?” on June 24th, 1980 • Leaders in United States started emphasizing on quality • In 1987 Malcolm Baldrige National Quality Award was introduced in U.S.A • Similar to the Deming prize in Japan • In Baldrige National Award the quality is viewed as: • Something defined by the customer • In Deming prize, the quality is viewed as: • Something defined by the producer by conformance to specifications\nSoftware Quality • Five Views of Software Quality ( by Kitchenham & Pfleeger) • Transcendental view • User’s view • Manufacturing view • Product view • Value-based view • Software Quality in terms of quality factors and quality criteria (by McCall, Richards, & Walters) • A qualityfactorrepresents behavioral characteristic of a system. • Examples: correctness, reliability, efficiency, testability, maintainability, reusability • A qualitycriterion is an attribute of a quality factor that is related to software development. • Example: modularity is an attribute of software architecture\nQuality Models • ISO 9126 ( International Organization for Standardization) • CMM ( Capability Maturity Model)/ CMMI • TPI ( Test Process Improvement) • TMM ( Test Maturity Model)\nRole of Testing • Software testing is one of the most important activities of QA • Software quality assessment divide into two categories: • Staticanalysis • It examines the code/document and reasons over all behaviors that might arise during run time • Examples: Code review, inspection, and algorithm analysis • Dynamicanalysis • Actual program execution to expose possible program failure • One observe some representative program behavior, and reach conclusion about the quality of the system • Static and Dynamic Analysis are complementary in nature • Focus is to combine the strengths of both approaches\nError, Fault, Failure, and Defect • Error • A human action that produces an incorrect result • Missing or incorrect human action resulting in certain fault(s) being injected into a software • Fault • An incorrect step, process, or data definition in a computer program • An underlying condition within a software that causes certain failure(s) to occur • Failure • The inability of a system or component to perform its required functions within specified performance requirements • A behavioral deviation from the user requirement or the product specification • Defect • Failures, faults, and errors are collectively referred to as defects in literature. • Note: Softwareproblems or defects, are also commonly referred to as “bugs”\nThe Notion of SoftwareReliability • It is defined as the probability of failure-free operation of a software system for a specified time in a specified environment. • It can be estimated via random testing. • Test data must be drawn from the input distribution to closely resemble the future usage of the system. • Future usage pattern of a system is described in a form called operational profile(OP).\nThe Objectives of Testing • Main objective: detecting bugs • It does work • It does not work • Reduce the risk of failures • Reduce the cost of testing\nThe Concept of Complete Testing • Complete/Exhaustive testing means – “There are no undisclosed faults at the end of test phase” • Complete testing is nearly impossible for most of the systems, Because.. • The domain of possible inputs of a program is too large • Valid inputs • Invalid inputs • The design issues may be too complex to completely test • It may not be possible to create all possible execution environments of the system\nThe Central Issue in Testing • Divide the input domain D into D1 and D2 • Select a subset D1 of D to test program P • It is possible that D1 exercise only a part P1 of P Fig. A subset of the input domain exercising a subset of the program behavior\nTesting Activities • Identify the objective to be tested • Select inputs • Compute the expected outcome • Set up the execution environment of the program • Execute the program • Analyze the test results\nTesting Levels • Unit testing • Individual program units, such as procedure, methods in isolation • Integration testing • Modules are assembled to construct larger subsystem and tested • System testing • Includes wide spectrum of testing such as functionality, performance • Acceptance testing • Customer’s expectations from the system\nTesting Levels Figure : Regression testing at different software testing levels • Regression Testing: • New test cases are not designed • Tests are selected, prioritized and executed • To ensure that nothing is broken in the new version of the software\nTesting Techniques • Basically two categories – • White-Box Testing • Black-Box Testing\nWhite-Box and Black-Box Testing White-box testing: • View components as transparent • Based on knowledge of the internal logic • Done by programmers (usually) Black-box testing: • View components as opaque • Based on requirements and functionality • Without any knowledge of internal design, code or language.\nWhite-Box Testing • White-box testing a.k.a. structural testing • Examines source code with focus on: • Control flow • Data flow • Control flow refers to flow of control from one instruction to another • Data flow refers to propagation of values from one variable or constant to another variable • It is applied to individual units of a program • Software developers perform structural testing on the individual program units they write\nBlack-Box Testing • Black-box testing a.k.a. functional testing • Examines the program that is accessible from outside • Applies the input to a program and observe the externally visible outcome • It is applied to both an entire program as well as to individual program units • It is performed at the external interface level of a system • It is conducted by a separate software quality assurance group(preferred)\nManual Testing vs. Automated Testing • Software Testing – • Manual Testing • Automated Testing\nManual Testing • Manual Testing: • Oldest and most rigorous type of software testing • Requires a tester to perform manual test operations • Hard to repeat • Not always reliable • Costly • time consuming • labor intensive\nAutomated Testing • Automated Testing: • Testing employing software tools • Execute tests without manual intervention • Fast • Repeatable • Reliable • Reusable • Programmable • Saves time","Penetration testing of Internet-facing fintech applications is an essential necessity in the age of online competitors and cybercrime. Penetration testing gives you the independent assurance that all the hard work you have invested in designing and implementing secure infrastructure or applications has paid off and your product won’t fall apart when subjected to malicious activity – as eventually it will be. Deciding on the specific type and scope of penetration testing however is not straightforward. Here is a basic introduction to assist with informed decision-making.\nWeb application penetration testing\nPenetration testing of Web applications involves identification of security weaknesses and vulnerabilities caused by insecure coding practices, misconfiguration and bugs. It is usually performed on a test instance of the application but can also be performed on live instances. The penetration testing process involves intercepting, analysing, modifying and generating specially crafted malicious and/or invalid HTTP requests to identify and exploit vulnerabilities that may exist in the application and usually covers at least the Top 10 areas of risk as identified by the Open Web Applications Security Project (OWASP) with additional testing based on specific business requirements or technologies used.\nInfrastructure penetration testing\nInfrastructure penetration testing is a generic term covering testing of operating systems, network services, network devices and other targets. Its objective is to identify vulnerabilities and misconfigurations that can be exploited to obtain unauthorised access to data, systems or hosted applications. Specific testing activities and methodologies may differ depending on the scope and objectives of the infrastructure testing engagement but most engagements involve the following stages:\n1. Identification and enumeration of targets of testing\n2. Reconnaissance and information gathering\n3. Identification of vulnerabilities, weaknesses or misconfiguration\n4. Testing and exploitation of identified vulnerabilities\n5. Post-exploitation activities\n6. Reporting and recommendations to address the identified issues\nUnderstanding your options: black, grey or white?\nWhen it comes to commissioning a penetration test you will need to decide whether you require a black, grey or white box penetration test. The type of testing chosen will decide the amount of time and effort required as well as the level of security assurance obtained – not to mention the cost.\nBlack box testing is the most widely performed (“standard”) type of testing – it gives basic assurance that is usually sufficient in most cases, and includes automated testing, manual review, and manual testing to identify any weaknesses or vulnerabilities in your application that may be exploited to compromise the security of your data or customers.\nGrey box testing includes software design and architecture review in addition to all activities included in black box testing.\nWhite box testing provides the maximum possible assurance – in addition to including all of the above it also includes review of source code to identify weaknesses or vulnerabilities hidden deep within the application code.\nThe type of testing chosen determines how much time and effort is required and the extent of your own team’s involvement in the testing process. Whereas with black box testing your team’s involvement is limited to provision of a test instance of your application or specification of infrastructure to be tested, with grey or white box testing documentation, meetings and access to source code would have to be arranged as appropriate.\nThe time required to test a particular application or infrastructure depends on its size and complexity, as well as the type of testing: a black box test of a simple application may only require a day or two, while a white box test of a large and complex application may require weeks or more. Most testing engagements however are black box tests and usually take about a week to complete. Once testing is concluded a report is issued detailing identified findings and their criticality, as well as making recommendations on how to address them and the engagements are usually concluded by holding a closing meeting where the next steps and discussed and agreed.\nEdgar ter Danielyan"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:f2b070d3-2bfd-4cbb-aaea-bbb7e995367e>","<urn:uuid:80c2e95f-b5fe-4881-a931-9e3b118ae721>"],"error":null}
{"question":"Hello! I am chemistry student learning about acids. Could you explain what acids are made of and how they relate to ocean pH changes?","answer":"Acids are made of hydrogen (H+) ions. When CO2 from the atmosphere dissolves in ocean water, it forms carbonic acid, which releases these H+ ions. This process reduces the ocean's pH - a measure of acidity. Since pre-industrial times, ocean pH has dropped by 0.11 units due to increased atmospheric CO2 (from 278 ppm to 390 ppm), making oceans more acidic. Even if carbon emissions stopped today, pH would continue dropping by up to 0.1 more units. By 2095, ocean surface pH is projected to reach 7.8.","context":["The flashcards below were created by user\non FreezingBlue Flashcards.\nWhat is an atom?\nAn atom is a collection of particles that makes a small-scale structure.\nWhat is a molecule?\nA molecule is a group of atoms joined by the forces of attraction.\nWhat is diffusion?\nDiffusion is the mixing of two substances.\nWhat are the three groups of matter?\n- They are:\n- Elements - composed of only one type of atom\n- Compounds - molecule with more than one type of atom\n- Mixtures - collections of diff. molecules or atoms that are not bonded\nName and shortly explain 5 separation techniques.\n- Filtration - separation of a liquid and a solid\n- Simple distillation - separation of two liquids\n- Fractional distillation - separation of three or more liquids\n- Paper chromatography - separation of substances with diff. colours\n- Crystallisation - separating a liquid from a solid (dilute)\nWhat are all the components of the distillation apparatus?\n- 1 heat source\n- 2 Still pot\n- 3 still head\n- 4 thermometer\n- 5 condenser\n- 6 cooling water in\n- 7 cooling water out\n- 8 distillate flask\n- 9 vacuum/ gas inlet\n- 10 still receiver\n- 11 heat control\n- 12 stirrer speed control\n- 13 stirrer heat plate\n- 14 heating (oil/sand) bath\n- 15 mixture in flask\n- 16 cooling bath\nWhat is an ion?\nThrough the interaction with other atoms, an ion is a non-neutrally charged atom.\nDescribe reduction and oxidation.\n- Reduction is the gain of electrons\n- Oxidation is the loss of electrons\nWhat is an ionic bond?\n- usually a bond between a metal and a non-metal/polyatomic ion.\n- The metal donates one electron to the non-metal.\nHow strong the force of attraction between two ions? Why?\nQuite strong because they are oppositely charged.\nName 3 properties of ions.\nNearly all have very high melting and boiling points\nMost are soluble in water\nDo not conduct electricity in the solid state but do in molten and aqueous states.\nWhat is a covalent bond?\n- A covalent bond is the sharing of electron pairs between atoms.\n- It normally occurs between non-metals.\nHow strong are the forces of attraction between covalent bonds?\nTypically they are weak due to the fact that they only have a few atoms in their molecular structure.\nName 4 characteristics of covalent bonds.\n- Tend to be gasses, liquids or soft solids.\n- Poor conductors of heat and electricity.\nWhy can electron of a metal move freely inside a structure?\nBecause they aren't tightly bonded and can become delocalised by jumping from one atom to the next.\nHow does a metal conduct electricity?\nDue to its structure, electrons are attracted to the negative potential and can conduct electricity.\nWhy are metal malleable?\nMetals are malleable (beaten into sheets) and ductile (pulled out into wires) because they can change form without breaking their metallic bonds.\nWhat is electric current?\nIt is the flow of electrons or ions.\nWhy do covalent compounds not conduct electricity?\nBecause in this case not only the nuclei of the atoms are bonded but also the electrons, stopping them from moving freely, thus conducting electricity.\nWhy do ions only conduct electricity in the molten or aqueous states?\nIn the solid state they are unable to move, whereas if they are in the liquid or aqueous states, they are free to move within that liquid.\nDescribe 3 simple experiments which test whether a substance is electrolyte or not.\n- 1. Conductivity probe:\n- The probe is lowered into the liquid and if a current is detected ...\n- 2. Electrolysis:\n- 3. Electrolysis of molten salts:\nWhat is a group and period?\nIn the periodic table of elements, there a seven vertical columns of elements aka 7 groups. The periods are horizontal.\nWhy do elements of the same group have similar chemical properties?\nBecause they have the same number of covalent electrons.\nWhy are noble gasses unreactive?\nNoble gasses are unreactive because they have a full covalent shell and so do not react with other atoms.\nHow can you recall the positions of metals and non-metals in the periodic table of elements?\n- B - Bi\n- At is non-metal + H.\nWhat are the classification of metals?\n- Alkali Metals\n- Alkaline Earth Metals\n- Transition Metals\n- Post Transition Metals\n- Non-metals with some metallic properties\n- Other Non-Metals\n- Noble Gasses\nHow can you classify an element as metal or non-metal?\n- By considering its conductivity and Acid/Base oxides.\n- Metals produce oxides that are bases in nature (high pH)\n- Non-metals produce acidic (low pH)\nWhat are the reactions between Lithium, Sodium and Potassium with water?\n- Lithium - the metal floats and fizzes\n- Sodium - the metal floats and becomes sphere of molten metal\n- Potassium - bursts into flames\nWhat are the colours and states of the following elements at room temperature?\nFluorine, Chlorine, Bromine and Iodine\n- Fluorine yellow gas\n- Chlorine green gas\n- Bromine brown liquid\n- Iodine purple solid\nIn which direction (up or down) is the reactivity of elements increasing for group 7 elements?\nIn which direction (up or down) does reactivity increase for group 1 elements?\nHow can you ionise hydrogen chloride gas?\nBy dissolving it in water. It also becomes HCL acid and is no longer a covalent compound.\nRecall the gasses present in air and their approximate percentage by volume.\n- Nitrogen - 78.08 %\n- Oxygen - 20.9 %\n- Argon - 0.9 %\n- Carbon dioxide - 0.04 %\n- Neon - 0.002 %\nWhat are 3 ways of determining the oxygen content in air?\n- Burning phosphorus: P4 + 5O2 ==> P4O10\n- Place a bell jar with a plate of phosphorus in a tank of water.\n- Light the phosphorus and the bell jar is sealed.\n- The water level rises by the amount of oxygen that is burned up.\nIron - Using damp iron wool in a tube in a tank and wait a week. The water level also rises because the iron rusting.\n- Copper - Using two glass syringes and a silica filled with copper.\n- The copper is heated and so combines with oxygen forcing the glass syringes to move.\nHow can you make oxygen form hydrogen peroxide?\n- Hydrogen peroxide solution is dripped onto manganese (IV) oxide (catalyst).\n- The H2O2 breaks up and oxygen builds up and passes through a tube into an inverted jar submerged in water.\nWhat are the reactions of oxygen with burning magnesium, carbon and sulphur?\n- 2Mg(s) + O2(g) ==> 2MgO(s)\n- White coloured compound\n- C(s) + O2(g) ==> CO2(g)\n- Carbon dioxide\n- S(s) + O2(g) ==> SO2(g)\n- Sulphur dioxide\nWhat happens when metals (and non-metal) oxides are mixed with water?\n- Some metal oxides create small amounts of hydrogen ions (alkaline in nature)\n- Non-metal oxides some create an acidic solution.\nDescribe the laboratory preparation of carbon dioxide from calcium carbonate and hydrochloric acid.\n- Dilute HCL is dripped onto marble chips and the gas produced is collected in a glass jar.\nDescribe the formation of CO2 form the thermal decomposition of metal carbonates.\n- When most metal carbonates are heated strongly they decompose and give off CO2.\nWhat are the 2 important properties of CO2?\n- It dissolves in water easily\n- It is heavier than air\nHow can you produce acidic solutions?\n- By using CO2, we can change the pH of water.\n- CO2 + H2O ==> H2CO3\n- H2CO3 + H2O ==> HCO3(-) + H30(+)\nHow can you make water from hydrogen?\nHydrogen is a very flammable gas, which when burns combine with the oxygen in the air and forms water.\nWhat is the test for the presence of hydrogen?\nEven a small amount will burn with a loud pop in a test tube.\nWhat are the 2 tests for water?\nUsing anhydrous copper sulphate powder, it'll turn blue from white.\nusing cobalt chloride paper, it'll turn white from blue.\nWhat is the physical test to see if a sample of water is pure?\nThe sample's boiling and freezing points are tested and if they are at exactly 100 degrees C and 0 degrees C the sample is pure water.\nList the reactivity series of metals in order.\nHow can reacting with water and dilute acid be use to deduce the order of reactivity: potassium, sodium, lithium, calcium, magnesium, zinc, iron and copper?\nEach reaction between these is somehow unique; the amount of bubbles that flow at a time is different. So you can tell which reacts stronger, placing it higher in the reactivity series.\nExplain the reactions of magnesium, aluminium, zinc and iron with dilute acid.\n- Magnesium - rapid flow of bubbles\n- Aluminium - slower flow\n- Zinc - slow\n- Iron - very slow\nHow can you use a displacement reaction to determine where a metal is in the reactivity series?\nYou add a metal in powered form to a metal in a solution and if the powered metal is more reactive (i.e. higher in the reactivity series) it will replace the first metal.\nWhat is the chemical reaction of rusting and the oxidation and reduction reaction of rusting?\nFe + H2O + O2 ==> Fe2O3\n- Oxidation : Fe(s) ==> Fe2(+)(AQ) + 2e-\n- Reduction: O2 + 4e- + 4H(+) ==> 2H2O\nWhat do you call the substance that is being oxidised (and reduced)?\nWhat two conditions must be met for iron to rust?\nOxygen and water.\nWhat are the two main types of rust prevention?\nBarrier protection : this is when the metal is completely covered in a layer of a substance which stop the metal from coming into contact with water and oxygen.\nSacrificial protection: This is when the metal is coupled to a more reactive metal, which will rust instead of the first metal.\nWhat are anions and cations?\n- Anions are ions with a negative charge.\n- Cations are ions with a positive charge.\nWhat colour are the flames of the following metals: Calcium, Lithium, Potassium, Sodium?\n- Calcium - Red\n- Lithium - Pink\n- Potassium - Lilac\n- Sodium - Orange\nWhat is the test for the ammonium ion?\n- NH4(+) is tested for by adding sodium hydroxide and heating gently. It gives off a very distinct smell.\n- It also reacts with damp litmus paper, turning it blue (showing it is an alkali metal).\nWhat atoms can we identify by using sodium hydroxide solution?\n- Ammonium ion - smell\n- CU(2+) - pale blue that dissolves\n- Fe(2+) - pale green precipitate\n- Fe(3+) - red/brown precipitate\nWhat atoms can we identify by using silver nitrate and dilute nitric acid?\n- If halogens are precent, a precipitate will form.\n- Br(-) - pale yellow precipitate that dissolves in ammonia solution\nCl(-) - thick white precipitate dissolves in ammonia solution\nI(-) - pale yellow precipitate that does not dissolve in ammonia solution.\nHow can you test for the sulphate ion?\n- SO4(2-) can be tested for by adding the substance to a solution of barium chloride.\n- A white precipitate forms which does not dissolve in dilute hydrochloric acid.\nWhat is the test for carbonate?\nCO3(2-) can be tested by adding the substance to dilute hydrochloric acid, carbon dioxide gas should be given off.\nWhat is the test for CO2 gas?\nBubble the gas through lime water (calcium hydroxide solution). It turns cloudy.\nWhat is the test for hydrogen gas?\nPut a lit splint into a sample of the gas and if it burn with a loud \"pop\" sound, it is hydrogen.\nWhat is the test for oxygen gas?\nIf you put a glowing splint into a sample of the gas and it re-lights, it is oxygen.\nWhat is the test for ammonia gas?\nExpose to damp litmus paper and it'll turn blue.\nWhat is the test for chlorine?\nExpose to damp litmus paper and it is bleached white.\nWhat is the general formula for alkanes?\nName the first five alkanes.\nWhat happens when alkanes are burned?\n- there are two possible outcomes:\n- Complete and incomplete combustion.\n- When it combusts completely the alkane reacts with oxygen in the air.\n- when an incomplete combustion take place the following products are created:\n- carbon (soot) (indicator)\nWhat happens when methane and bromine are exposed to UV light?\n- A substitution reaction takes place resulting in hydrogen bromide and bromomethane.\n- The brown (bromide) disappears.\nWhat is the general formula for alkenes?\nWhat happens when an alkene reacts with bromine?\n- (Bromine solution or water)\n- An addition reaction takes place. The double bond is broken and two bromine atoms are added to the molecule.\n- Detect carbon double bond.\nExplain the pH scale\n- 0 - 14\n- (Strongly acidic - Neutral - Strongly Alkaline)\n- Concentration of H+ ions.\nHow can you use litmus paper to measure pH?\n- The colour the litmus paper changes to depends on the acidity of the solution.\nHow can you use phenolphthalein to measure pH?\n- phenolphthalein is colourless below pH 8.0 and become deep red as of pH 10.0\nHow can you use methyl orange to measure the pH of a solution?\nHow does the universal indicator work?\n- It changes colour AND shows how acidic or basic a solution is.\nWhat are acids and alkalis made of?\n- Acids are made of hydrogen H+ ions\n- Alkalis are made of hydroxide OH- ions\nState all the solubility rules\nHow can you make soluble salts?\nThis method does not work for sodium, potassium and ammonium.\nHow can you make insoluble salts?\nHow can you make salts with sodium, potassium and ammonia?\nWith titration. You add and alkali (base) to an acid. The acid already has an indicator added to it.\nWhat are exothermic and endothermic reactions?\n- Heat is taken in. Heat is given out.\nDescribe the combustion calorimetry experiment.\n- We measure the mass of the burning sample and the water. During the combustion, we measure the rise in temperature.\nWhat is the diff. between endothermic and exothermic reactions?\n- In exothermic reactions bonds are made or strengthened (EMITS)\n- In endothermic reactions bonds are broken (ABSORBS)\nWhat are catalysts?\nCatalysts are substances which when added to a reaction, allow the reactants to come together more easily.\nWhat characteristics effect the rates of reaction?\nSurface area, temperature, concentration and pressure.\nWhat is the activation energy in a reaction?\nIt is the minimum energy required to start a chemical reaction.","Ocean acidification: global warming's evil twin\nWhat the science says...\n|Select a level...||Basic||Intermediate|\nThe current debate on the connection between CO2 emissions and climate change has largely overlooked an independent and equally serious problem, the increasing acidity of our oceans. Last December, the respected journal “Oceanography” published projections (see graphic below) for this rising acidity, measured by falling pH [i], through to the end of the century [ii].\nThe current debate on the connection between CO2 emissions and climate change has largely overlooked an independent and equally serious problem, the increasing acidity of our oceans. Last December, the respected journal “Oceanography” published projections (see graphic below) for this rising acidity, measured by falling pH [i], through to the end of the century [ii]. In 2095, the projected average ocean surface pH is 7.8, and lower still in the Arctic Ocean.\nFig 1: Ocean surface pH - historical values and projected future values based on current emission projections.\nCO2 in the atmosphere has increased from 278 ppm in pre-industrial times to 390 ppm today. During this time, the amount of CO2 dissolved in the ocean has risen by more than 30% [iii], decreasing the pH of the ocean by 0.11 units. As with CO2 and global warming, there is some lag between cause and effect. That means that, even if all carbon emissions stopped today, we are committed to a further drop of up to 0.1 units.\nThe close relationship between CO2 in the atmosphere, CO2 dissolved in the ocean, and the effect of the latter in falling pH, is illustrated by the graph [iv] below:\nFig 2: Annual variations in atmospheric CO2, oceanic CO2, and ocean surface pH. Strong trend lines for rising CO2 and falling pH.\nCO2 dissolves in waterto form carbonic acid. (It is worth noting that carbonic acid is what eats out limestone caves from our mountains.) In the oceans, carbonic acid releases hydrogen ions (H+), reducing pH, and bicarbonate ions (HCO3-).\nCO2 + H2O => H+ +HCO3- (1)\nThe additional hydrogen ions released by carbonic acid bind to carbonate ions (CO32-), forming additional HCO3-.\nH+ + CO32- => HCO3- (2)\nThis reduces the concentration of CO32-, making it harder for marine creatures to take up CO32- to form the calcium carbonate needed to build their exoskeletons.\nCa2+ + CO32- => CaCO3 (3)\nThe two main forms of calcium carbonate used by marine creatures are calcite and aragonite. Decreasing the amount of carbonate ions in the water makes conditions more difficult for both calcite users (phytoplankton, foraminifera and coccolithophore algae), and aragonite users (corals, shellfish, pteropods and heteropods).\nThe photo below left shows healthy specimens of calcifying phytoplankton Gephyrocapsa oceanica. The photo below right shows the damage to the same creature under conditions expected by the end of the century.\nFig 3: Healthy phytoplankton; same species with malformed shell plates as a result of damage by seawater with simulated end of century chemistry.\nSource: Nature, Reduced Calcification of Marine Phytoplankton in Response to Increased Atmospheric CO2, Issue 407 p.364 -367\nIt is often said that a picture is worth a thousand words.\nResearch in the Southern Ocean provides evidence that the formation of foraminifera shells is already being affected. Even though these creatures use calcite, which is less soluble than aragonite, there are already clear signs of physical damage. According to Dr. Will Howard of the Antarctic Climate and Ecosystems Cooperative Research Centre in Hobart, shells of one species of foraminifera (Globigerina bulloides) are 30 to 35 percent thinner than shells formed prior to the industrial period.[vi]. The photo below left shows a pre-industrial exoskeleton of this species obtained from sea-floor sediment. The photo below right shows a exoskeleton of a live specimen of the same species obtained from the water column in the same area in 2007. These stunning images were obtained using an electron microscope. (An interview with Dr. Howard was broadcast on the Catalyst television program). [vii] What is staggering is the amount of erosion in the right image compared to the left. The right sample look porous with larger holes and a 10-fold increase in their number. These and creatures like them are at the base of an ocean food chain, and they are already seriously damaged. If they are lost, it is not just biodiversity we are losing, but our food supply as well.\nFig 4. Pre-industrial and current samples of Globigerina bulloides from same location. Latter shows extensive erosion with a ten-fold increase in holes.\nSource: Australian Broadcasting Corporation, Ocean Acidification – The Big Global Warming Story, 13 September 2007\nThe implications of all of this are disturbing. For corals to absorb aragonite from seawater, the latter needs to be saturated in this mineral.\nNow a report from NOAA scientists found large quantities of water undersaturated in aragoniteare already upwelling close to the Pacific continental shelf from Vancouver to northern California [v]. Although the study only dealt with the area, the authors suggest that other shelf areas may be experiencing similar effects.\nFor corals like those in Australia’s Great Barrier Reef, the outlook is grim. They are threatened with destruction on two fronts, both caused by CO2 emissions. Not only do increased ocean temperatures bleach coral by forcing them to expel the algae which supplies them with energy (see photo at left) [viii], but increased ocean CO2 reduces the availability of aragonite from which reefs are made.\nIt is time to wake up. Our planet is dying. I urge you to find the time to view a 20 minute documentary on the problem of ocean acidification produced by the international Natural Resource Defence Council. Simply go to: www.acidtestmovie.com\nFig 5. Coral killed by above average ocean temperatures.\nReferences and Notes\nIntermediate rebuttal written by alan_marshall\nUpdate July 2015:\nHere is a related lecture-video from Denial101x - Making Sense of Climate Science Denial\nAdditional videos from the MOOC\nExpert interview with Annamieke Van De Heuvel\nExpert interview with Charlie Veron\nExpert interview with Ove Hoegh-Guldberg\nLast updated on 8 July 2015 by pattimer. View Archives"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:abb0bb6a-96e8-48d8-94a3-e8c01251a318>","<urn:uuid:0b5304f2-0a0e-44f7-85df-f8c396571f32>"],"error":null}
{"question":"What are some common roadblocks that can hinder workflow automation?","answer":"Common roadblocks include approvals taking too long, hard copies getting lost, losing track of files in the process, and resistance to change from managers or executives who are hesitant to leave hard-copy processes behind. These barriers often require additional research on solutions and statistics to prove that manual processes are inadequate.","context":["If you’re a company in the process of automating, it can be difficult to analyze, measure, and evaluate your current procedures. You don’t want to waste time during the transition, but it’s important to understand what works and what doesn’t so you’re not automating ineffective processes. In that case, automation won’t help you meet your intended goals.\nWhether you have a formal business process management (BPM) team or are simply evaluating your department’s processes, there are steps you want to take before automating.\n1. Evaluate Your Current Processes\nSince the goal of BPM (and eventually automation) is continuous improvement, the first step to document what’s working and what’s not. To do this, you’ll want a team of individuals who can observe, analyze, and interpret where your strengths and weaknesses lie.\nOnce you select your team, define roles and responsibilities of all team members. Gather data on productivity like how long each workflow takes, how much time is wasted during the process, and what roadblocks cause these time lapses. In this step, you’ll also want to identify your goals and expected outcomes.\nDon’t forget the stakeholders. What are the needs of external and internal customers? Who will be impacted by the process changes? How can you make positive improvements in relation to their involvement in the process?\n2. Map and Measure What Your Processes Look Like Today\nBefore you can come up with solutions, make a flowchart of your current processes. Which team members are in each workflow? What’s the chain of approval or process for passing a file through the steps?\nIn addition to mapping the steps, think through ‘what-if’ scenarios to ensure you’ve modeled potential real-world situations. A vendor, for example, may request wording changes to a contract before signing. If you hadn’t considered that possibility, you’d create a process that didn’t allow for a feedback loop.\nOnce you define the steps in the workflow, document where the process lacks productivity and pinpoint which areas need improvement. When you’re measuring the effectiveness of your manual process, record all of the qualitative and quantitative data. This way you’ll have a baseline in which you can compare your completed transition.\nWhat’s next? You’ll need to establish a plan. Try starting with a Statement of Scope. Name each process, define its goals and objectives, then figure out how long each workflow should realistically take. Once you have this information in place, you can start searching for the roadblocks that are currently decreasing productivity.\n3. Identify Roadblocks\nWhat roadblocks are currently hindering your team’s workflow agility? Are approvals taking too long? Do hard copies get lost in the shuffle? Are you losing track of where the file is in the process?\nThere may be other barriers keeping you from improving your processes. Often, the root cause of the blockage is a manager or executive that is hesitant to leave the hard-copy days behind them. This resistance to change can lead to other hurdles in your BPM analysis, causing you to do even more research on solutions and statistics that prove manual processes are lacking.\nIT Managers Inbox says:\n“In your meetings with stakeholders, be sure they understand why process improvement is needed. Get them on board, keep them updated, and get feedback from them on the progress of the process improvement.”\nAfter you show the management team that there is value in automation, the next steps are determining your preferred automation tool and taking it out for a spin!\n4. Automate, Monitor Results, and Optimize\nWhile it may be tempting to set up your automated workflows and consider yourself done, it’s important to remember that they often need fine-tuning. Here’s where your goals (remember those from step 1?) and your baseline metrics come into play.\nAfter using your automated processes for a period of time, compare metrics and gather feedback from participants. Just as with your old processes, gather information on what worked well and where the process broke down or became stuck. Then make adjustments, try them out, and evaluate again.\nEven after you’ve met your initial goals and feel that your processes are running smoothly, make sure to revisit at regular intervals. As businesses change, processes also change. Planning ahead often results in needing only minor course corrections, rather than major process overhauls!"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:db171ca8-b880-42af-b587-50a6ce69cdef>"],"error":null}
{"question":"Could you explain the different factors that affect execution timing in both Task scheduling and network communications?","answer":"In Task scheduling, timing is primarily affected by the interval setting (default 500ms) and the low-priority thread execution, which creates variable latency between scheduled and actual execution times. In network communications, timing is influenced by three main factors: the number of nodes between transmitter and receiver, sent packet size, and transmission distance. Network timing also depends on serialization delay (sum of switch latencies) and propagation delay (distance divided by medium velocity, typically 201,000 km/s for fiber optics).","context":["A task is a function that can be scheduled or repeated. You can set the arguments to the function as well as the object that will be this when the function is called.\nvar tsk = new Task(function, object, arguments);\nThe object argument represents the this during the execution of the function. Use the this keyword (referring to the jsthis\nobject) to be able to use outlets and other js\nobject features. The function argument represents the function you want to execute, and arguments (an array) represents the arguments to pass to the function. The object and arguments arguments are optional. If not present, the parent of the function object (typically jsthis) will be assumed, and there will be no arguments supplied to the function.\nargs = new Array(3);\nargs = 1;\nargs = 2;\nargs = 3;\nt = new Task(ticker,this,args);\nAlthough the overall timing accuracy of a Task function is high, the latency between the scheduled time and the actual execution time of a Task function is variable because the function runs in a low-priority thread. Therefore you should avoid using a Task function in a time-critical operation.\nWe'll show you an example of this syntax for a Task that changes its interval below.\narguments (Array, get/set)\nThe arguments passed to the task function. arguments is the first argument.\nfunction (Function, get/set)\nThe function that is executed in the Task. You can even change this within the task function itself.\nrunning (Boolean, get)\nWhether the Task is running or not. Within a function executing within a task, this will always be 1.\ninterval (Number, get/set)\nThe time in milliseconds between repeats of the task function. The default interval is 500 ms. Here is an example of a Task with a function that causes the Task to run 10% more slowly each time the function is called, which uses the arguments.callee.task syntax mentioned above:\nvar intv = arguments.callee.task.interval;\narguments.callee.task.interval = intv + (intv * 0.1);\nobject (Object, get/set)\nThe object that is assigned to be the this in the task function. Most often this will be your jsthis object, so you can, for example access the outlet() method. You set up your jsthis object to be the this by creating a task with the keyword this as the first argument.\nIf the object property of a task is a js\nobject, the following three lines of code are identical from within a task function:\niterations (Number, get)\nThe number of times the task function has been called. Outside of a task function, the value of iterations is\nalways 0. The value resets each time the task is started (using the repeat(), execute(), or schedule() methods\ndescribed in the next section).\nrepeat (number, initialdelay)\nRepeat a task function. The optional number argument specifies the number of repetitions. If the argument is not present or is negative, the task repeats until it is cancelled. The optional initialdelay argument sets the delay in milliseconds until the first iteration.\ntsk = new Task(repeater_function, this);\ntsk.interval = 1000; // every second\ntsk.repeat(3); // do it 3 times\nHere is a repeater function that posts its iteration count to the Max window:\nIn the above example, the Max window output would be:\nRun the task once, right now. Equivalent to calling the task function with its arguments.\nRun the task once, with a delay. The optional delay argument sets the time (in milliseconds) before the task function will be executed.\nIf a task is scheduled or repeating, any future executions are cancelled. This method can be used within a task function for a self-canceling Task. The following example is a task function that will run only once, even if it is started using the repeat() function.","05 Apr Network Latency Study\nIn computing, latency (or transit delay, or delay) is the transmission delay in computer communications. In this article we are going to see how to perform a network latency study.\nTo estimate the expected latency in a network, the average values provided by the manufacturers of the equipment used in the communications infrastructure must be taken into account.\nNetwork latency times will depend on three factors:\n- Number of nodes between transmitter and receiver\n- Sent packet size\n- Transmission distance between transmitter and receiver to take into account the delay of the transmission medium.\nTo analyze latency in a network we have to briefly explain two previous concepts such as serialization delay and propagation delay:\nWe understand as serialization delay the sum of the average latency of all the switches between the source and the destination according to the size of the packet. It is normally multiplied by two if it is necessary to take into account the round trip of the response message.\nFor its part, the propagation delay is expressed mathematically as:\nDP = distance (m)/velocity of the medium in m/s.\nNormally, in communication infrastructures of a certain size, communications between switches are carried out with fiber optics. In the case of optical fiber, the speed of propagation is 67% of the speed of light in a vacuum (Vfo = 201,000 km/s). Also, the final value must take into account twice the distance traveled by the return message.\nOnce these two concepts are defined, we can establish the formula for calculating network latency (L):\nL = Propagation Delay + Serialization Delay\nAs an example and in the worst case, we will calculate the transmission latency of a 1024 Byte packet between two points with a separation between them of nine nodes and a distance of 12 kilometers using network equipment from the manufacturer CISCO. The starting parameters will therefore be:\n- Maximum number of nodes in the longest transit: 9 (eight devices in the field in a ring plus a central switch that operates as the Core of the system)\n- Approximate distance: 12,000 m.\nBased on the manufacturer’s data, we would have that, depending on the models of the equipment used, the serialization and propagation delays would be:\nSerialization delay = 7x 3.688 μs + 3.655 μs + 3.61 μs = 33.081 μs\nPropagation delay = 12 km / 201,000 km/s = 59.70 μs\nTherefore, the latency time according to the formula described at the beginning would be:\nL = Propagation Delay + Serialization Delay = 92.781 μs\nIf we also consider the response time of a message, the value obtained is 2 x 92.781μs = 185.562μs\nAs can be seen, the delay values in this example are not significant and should not affect the final communications, but they are values to be taken into account in critical infrastructures or with control systems that require real-time or predictive activation in expert control systems. , since they are delay times in signal control that must be taken into account in the installation control algorithms that are implemented.\nIt is important to underline that these values only concern the network infrastructure part. When calculating the latency time in a network, we should take into account the total response times, which will depend on each system (communication protocols used, processing capacity of each server, processing capacity of field equipment, etc.) terminal equipment that receives communications at origin and destination, etc.\nWe hope we have resolved your doubts about the network latency study. If you have any additional information, do not hesitate to contact us so that we can help you."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:48a7fae6-01b9-47a4-a925-2a279dcfb6a9>","<urn:uuid:19655bec-1a28-46b8-8339-489bdecc4cbb>"],"error":null}
{"question":"What are the key differences between applying fertilizers to apple trees and growing potatoes using soilless methods in terms of nutrient delivery and timing?","answer":"Apple trees and soilless potato cultivation differ significantly in nutrient delivery and timing. For apple trees, nutrients are applied through both organic and inorganic fertilizers, with specific timing requirements - early spring after bud break for mature trees, and higher nitrogen applications for young trees until age 3. Post-harvest fertilization is beneficial for nutrient storage, while winter fertilization is ineffective due to dormancy. In contrast, soilless potato cultivation uses continuous nutrient delivery through hydroponic or aeroponic systems, where roots are either immersed in nutrient-rich water or misted with nutrient solution. The growing cycle for soilless potatoes is relatively shorter, typically 60-90 days, with consistent nutrient management throughout the growing period, while apple trees require seasonal adjustments in fertilization.","context":["Optimum apple tree growth and quality requires optimum fertility. Different tree species have their own unique requirements thus it’s important to provide them with enough nutrition as per their needs. Most of Himachal Pradesh’s apple growers are not exactly aware of the right time of adding fertilizers to apple trees and are also unaware of the what quantity they should use in what kind of tree. With the lack of knowledge growers in the state end up with poor crop and even end up with damaged trees, which die due to too much or too little nutrition.\nApple trees need nutrients to live, grow and produce crops. Due to a deficiency of nutrients in the soil, the tree growth affected adversely and become prone to disease and pest problems. The nutrients required by most of plants on earth, including apple trees, can be divided into two parts: macro-nutrients and micro nutrients, which is based upon the measure necessary for survival and growth. Macro-nutrients are required by plants in greater quantities than micro-nutrients. The macro-nutrients required by plants for growth include nitrogen (N), phosphorus (P), potassium (K), calcium (Ca), magnesium (Mg), and sulfur (S). The addition of micro-nutrients, especially nitrogen, can result in improvised growth while deficiencies can lead to slower growth and many visible symptoms. Micro-nutrients, which are required in very small amounts, include iron (Fe), manganese (Mn), zinc (Zn), copper (Cu), boron (B), chlorine (Cl), and molybdenum (Mo).\nBoth organic and inorganic (synthetic) fertilizers can be used to supply plant nutrients.\nHow to decide the need for fertilizers?\nTrees are often under high stress conditions due to many reasons which depend on environment condition e.g. low moisture availability, soil compaction, physical damage and competition from nearby trees, shrubs and weeds. The best indicator of whether fertilization is necessary is a soil test.\nIn case where soil test cannot be done, the best indicator of the need for more fertilization of established trees is shoot growth. If new shoot growth occurring in the present year is in excess of 6 inches, then fertilization is probably unnecessary. If shoot growth is between 2 and 6 inches then fertilizer may be applied and, if shoot growth is less than 2 inches, then growers need to apply proper fertilizer in their plants.\nFoliage color is another indicator of the need for fertilization. Yellow or “off-color” leaves may show the need for fertilization as these symptoms generally occur on trees which are not taking up enough of one or more required nutrient. A final indicator of the need for fertilization is the history of the farm. Trees on farms that are fertilized for on a regular basis rarely need to have supplemental fertilizer applied. Supplemental fertilizer should only be considered if shoot growth is less than 2 inches, or if a soil test reveals a specific nutrient deficiency.\nYellowing may be due to a variety of nutrient deficiencies. The most common reason for yellowing foliage is a lack of iron and occasionally manganese. Deficiencies of these elements are commonly due to a high pH (7.0 or higher) and not a lack of these nutrients in the soil. Because different trees do well at different pH levels, it is strongly recommended that soils be checked for pH before planting.\nBest time to fertilize Tree\nNewly Planted Trees\nRequires higher nitrogen until they are 3 years old, but care should be taken to apply nitrogen based fertilizers on two conditions 1. Soil Test and 2nd is If growth in new trees is not normal e.g. new plant or its shoots should grow between 12 and 18 inches. Application of fertilizers can be done as broadcast or sprinkle (in ratio with soil test) or organic fertilizers manure, bone meal application can be done after every 90-120 days for good and stout growth. Important time for application of fertilizer in new trees is March, June & September.\nMatured Apple Trees\nAfter Bud Break – Early Spring is the best time to fertilize mature trees or right as the flowers appear in the apple tree.\nEarly summer Fertilization – Can be done either depending on the deficiency or by looking at the growth of fruit and tree. Most of horticulturists fertilize trees throughout the spring. Fertilizing in summer inhibits the tree’s ability to stay hydrated.\nPost Harvest fertilization-Early in the new season deciduous plants rely on the nutrients stored from the previous autumn for flowering and to develop new leaves. Post-harvest fertilizer applications are often beneficial as they ensure adequate nutrient storage for the following spring. After harvest trees quickly cut water uptake and after leaf fall tree water use drops to almost nil. As a result, fertilizer uptake late in the season is slow and it pays to apply fertilizer as soon after harvest as possible. If applied too late for tree uptake, winter rainfall will leach any fertilizer residues from the soil or the tree will enter dormancy late.\nHow about fall and winter fertilizing?\nFertilization in the winter or at the time of leaf falling is ineffective as the tree is entering a dormant, and not a growth period. In winters the tree goes into dormancy, it ceases photosynthesis. The chlorophyll in the leaves breaks down, making sugars that go back into the fruit tree’s limbs, trunk and roots. And thus fertilizing in winter is ineffective. Winters or Dormancy is the best time to apply manure than Water Soluble fertilizers.\nWhen to Apply Manure – Apply 1 to 2 inches of well rotted-manure in February while the tree is still dormant and again in June. You should wait until the year after planting to start fertilizing. If you live in a warmer region with mild winters and little danger of frost zones 9 or 10 and up you can apply manure three times a year: in February, June and August.\nManure facts It doesn’t matter what kind of manure you use (horse, chicken, cow, rabbit or goat) but it needs to be well rotten. Well rotten manure looks like black soil and has no smell. Never use fresh manure as it has high ammonia, which can give root burns and can damage trees. Well rotten manure is considered an organic fertilizer and adds nitrogen, potassium and other nutrients to the soils. It also adds organic matter that helps loosen the soil, increases the oxygen content attracts earthworms and increase useful bacteria in soil.\nOrganic manure– Organic manure artificially prepared from plant residues and animal waste products. Animal dung is a best example of it and has been used for centuries as a fertilizer for farming, as it improves the soil structure (aggregation), so that it holds more nutrients and water, and becomes more fertile. Animal manure also encourages soil microbial activity, which promotes the soil’s trace mineral supply, improving plant nutrition. It also contains some nitrogen and other nutrients that assist the growth of plants.\nMixed manure – Animal dung mixed with other materials, such as straw or sawdust. While this type of dung may be good for composting –because of its rich blend of nitrogen and carbon.\nManure Age -Freshly produced manure often has ammonia that can hurt seedlings or plants. Aging manure for 60 days or more, will allow harmful chemicals to break down, as well as for its nutrients to grow. Also aging minimizes the risk of E. coli bacteria.","Unleash your inner urban farmer and cultivate an abundance of potatoes in even the most compact spaces. Discover the secrets of soilless potato cultivation, tailored for balconies, patios, and even indoor setups. Embrace hydroponics and aeroponics, revolutionary techniques that promise bountiful harvests without the need for traditional soil …\nEmbark on a journey to cultivate culinary delights in the heart of your urban oasis. Discover the art of soilless potato cultivation, a revolutionary approach to gardening that transcends the limitations of traditional soil-bound methods. Whether you reside in a cozy apartment or possess a petite balcony, this comprehensive guide will equip you with the knowledge and techniques to nurture an abundance of potatoes in even the most confined spaces.\nUnveiling the Benefits of Soilless Potato Cultivation\nDitch the constraints of traditional soil-based gardening and embrace the myriad benefits of soilless potato cultivation:\n- Maximize Space Utilization: Vertical gardening systems allow you to cultivate potatoes upwards, transforming limited spaces into vertical potato havens.\n- Enhanced Yields and Quality: Soilless techniques provide unparalleled control over nutrient delivery, fostering healthier plants and bountiful harvests of high-quality potatoes.\n- Reduced Water Consumption: Embrace water conservation with soilless methods, ensuring efficient water usage and minimizing environmental impact.\n- Minimized Disease and Pest Pressure: Soilless cultivation reduces the risk of soil-borne diseases and pests, safeguarding your precious potato crop.\nExploring the Realm of Hydroponics and Aeroponics\nDelve into the world of soilless potato cultivation, where two distinct techniques reign supreme: hydroponics and aeroponics.\nHydroponics: Nurturing Potatoes in a Nutrient-Rich Bath\nHydroponics immerses your potato roots in a nutrient-rich water solution, providing optimal access to essential nutrients. Popular hydroponic systems for potatoes include Deep Water Culture (DWC) and Nutrient Film Technique (NFT).\nAeroponics: Suspending Potatoes in a Nutrient Mist\nAeroponics takes soilless cultivation to the next level by suspending potato roots in a mist chamber, periodically spraying them with a nutrient solution. This technique maximizes root exposure to air and nutrients, promoting vigorous growth and disease resistance.\nGathering the Essentials for Soilless Potato Cultivation\nEmbark on your soilless potato cultivation journey with the right tools and materials:\n- Growing Containers: Opt for food-grade, durable containers that provide ample root space. Buckets, pots, or specialized hydroponic systems are suitable choices.\n- Growing Medium: For hydroponics, inert growing media like perlite, rockwool, or coco coir are preferred. These provide support for the roots without interfering with nutrient uptake.\n- Nutrient Solution: Select a balanced hydroponic nutrient solution specifically formulated for potatoes. Follow the manufacturer’s instructions for mixing and application.\n- Lighting: Supplement natural sunlight with LED or fluorescent grow lights to ensure adequate light exposure for photosynthesis.\n- Temperature and Humidity Control: Maintain a consistent temperature range of 60-75°F (15-24°C) and humidity levels around 50-60%.\n- pH Monitoring: Regularly monitor the pH of the nutrient solution and adjust as needed using pH-up or pH-down solutions.\nPlanting and Nurturing Your Soilless Potato Patch\nSow the seeds of success with these essential cultivation steps:\n- Seed Potato Selection: Choose certified seed potatoes free from diseases and pests. Organic seed potatoes are recommended for soilless cultivation.\n- Pre-Sprouting (Optional): Accelerate growth by pre-sprouting the seed potatoes. Place them in a shallow container with the eyes (buds) facing upwards and keep them in a warm, humid location until sprouts emerge.\n- Planting: Cut seed potatoes into pieces with at least two eyes each and allow the cut surfaces to callous over. Place the potato pieces in the growing containers, ensuring the eyes are facing upwards.\n- Watering and Nutrient Management: Maintain consistent moisture levels in the growing medium or root zone. Follow the nutrient solution schedule provided by the manufacturer, adjusting as needed based on plant growth.\n- Disease and Pest Control: Implement proper sanitation practices to minimize the risk of diseases and pests. Regularly inspect the plants for signs of trouble and take appropriate corrective measures if necessary.\n- Harvesting: When the potato plants start to senesce and the foliage turns yellow, it’s time to harvest. Gently dig up the potatoes, taking care not to damage them.\nAddressing Common Queries and Concerns\n- Can I grow potatoes without soil in my apartment?\nAbsolutely! Soilless potato cultivation is perfectly suited for indoor environments, allowing you to cultivate potatoes on your balcony, patio, or even in a spare room.\n- What type of potatoes is best for soilless cultivation?\nEarly maturing potato varieties like Red Pontiac, Norland, and Yukon Gold are excellent choices for soilless cultivation due to their shorter growth cycles and adaptability to confined spaces.\n- How long does it take to grow potatoes without soil?\nThe time to harvest soilless potatoes typically ranges from 60 to 90 days."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:c0c80646-36bc-4bef-9b65-db0297c3a799>","<urn:uuid:f045703c-c8cf-4b51-b033-83f19993431e>"],"error":null}
{"question":"What were the major combat operations and post-war roles of the USS Los Angeles in Korea and the Far East?","answer":"The USS Los Angeles played significant roles in both combat and peacekeeping operations. During the Korean War, she served as flagship for Rear Adm. Arleigh A. Burke's CRUDIV 5 and conducted coastal bombardments against enemy positions from Hungnam to Haeju. She provided offshore gunfire support and participated in concentrated shelling of enemy bunkers at Koji-ni. Despite receiving minor damage during the Wonsan bombardment in 1953, she continued operations. After the Korean War, from November 1953 to June 1963, she made eight deployments to the Far East as a cruiser division flagship with the 7th Fleet, conducting peacekeeping operations across the Sea of Japan, Yellow Sea, and East and South China Seas. She also helped protect ROC Army units during the 1956 Quemoy-Matsu crisis by patrolling the Taiwan Strait.","context":["USS Los Angeles (CA-135)\n|Namesake:||Los Angeles, California|\n|Builder:||Philadelphia Navy Yard, Philadelphia|\n|Laid down:||28 July 1943|\n|Launched:||20 August 1944|\n|Commissioned:||22 July 1945|\n|Decommissioned:||9 April 1948|\n|Recommissioned:||27 January 1951|\n|Decommissioned:||15 November 1963|\n|Struck:||1 January 1974|\n|5 battle stars (Korea)|\n|Fate:||Sold for scrap to Terminal Island's National Metal and Steel Corp. on 16 MAY 1975 for $1,036,089|\n|Class and type:||Baltimore-class cruiser|\n|Displacement:||13,600 long tons (13,818 t)|\n|Length:||674 ft 11 in (205.71 m)|\n|Beam:||70 ft 10 in (21.59 m)|\n|Draft:||20 ft 6 in (6.25 m)|\n|Speed:||33 knots (61 km/h; 38 mph)|\n|Complement:||1,142 officers and enlisted|\n|Aircraft carried:||Curtiss SC-1 Seahawk floatplane|\n|Official name||USS Los Angeles Naval Monument (John S. Gibson Jr. Park)|\n|Designated||3 May 1978|\nThe third USS Los Angeles (CA-135) was a Baltimore class heavy cruiser, laid down by the Philadelphia Navy Yard, Philadelphia, on 28 July 1943 and launched on 20 August 1944. She was sponsored by Mrs. Fletcher Bowron and commissioned on 22 July 1945, with Capt. John A. Snackenberg in command.\nAfter shakedown out of Guantánamo Bay, Cuba, Los Angeles sailed on 15 October for the Far East via the west coast and arrived at Shanghai, China, on 3 January 1946. During the next year she operated with the 7th Fleet along the coast of China and in the western Pacific to the Marianas. She returned to San Francisco, California, on 21 January 1947, and was decommissioned at Hunters Point on 9 April 1948, and entered the Pacific Reserve Fleet.\nLos Angeles was recommissioned on 27 January 1951, Capt. Robert N. McFarlane in command. In response to the American efforts to thwart Communist aggression in the Republic of Korea, she sailed for the Far East 14 May and joined naval operations off the eastern coast of Korea on 31 May as flagship for Rear Adm. Arleigh A. Burke's CRUDIV 5. During the next six months she ranged the coastal waters of the Korean Peninsula from Hungnam in the east to Haeju in the west while her guns pounded enemy coastal positions. After returning to the United States on 17 December for overhaul and training, she made her second deployment to Korean waters on 9 October 1952 and participated on 11 October in a concentrated shelling of enemy bunkers and observation points at Koji-ni. During the next few months, she continued to provide off-shore gunfire support for American ground operations, and in addition she cruised the Sea of Japan with fast carriers of the 7th Fleet. While participating in the bombardment of Wonsan late in March and early in April 1953, she received minor damage from enemy shore batteries, but continued operations until sailing for the west coast in mid-April. She arrived at Long Beach on 15 May.\nBetween November 1953 and June 1963 Los Angeles made eight more deployments to the Far East where she served as a cruiser division flagship with the 7th Fleet in support of \"keeping the peace\" operations in that troubled part of the world. Her operations sent her from the coast of Japan to the Sea of Japan, the Yellow Sea, and the East and South China Seas; and with units of the 7th Fleet she steamed to American bases in the Philippines and Okinawa, as well as to Allied bases in South Korea, Hong Kong, Australia, and Taiwan. During the Quemoy-Matsu crisis in 1956, she patrolled the Taiwan Strait to help protect ROC Army units from possible landing offenses from Communist China. When not deployed in the western Pacific, Los Angeles operated out of Long Beach along the west coast and in the Pacific to the Hawaiian Islands. She returned to Long Beach from her final Far East deployment on 20 June 1963.\nDecommissioning and sale\nWhile some consideration was made to convert Los Angeles into a single-end Talos missile cruiser, with flagship facilities (in essence a heavy cruiser version of the Oklahoma City) funds were not appropriated for this, (or for a general overhaul to enable her continued fleet service), so she was decommissioned at Long Beach on 15 November 1963 and entered the Pacific Reserve Fleet at San Diego. Stricken on 1 January 1974, and sold on 16 May 1975 (sale #16-5049) to the National Steel Corporation for $1,864,380.21, and scrapped in San Pedro, California.\nIn popular culture\n- USS Los Angeles was featured in The Adventures of Tintin comic The Red Sea Sharks by Hergé. She is shown patrolling in the Red Sea and is involved in the rescue of Tintin and his friends from a post-war Type II U-boat operated by slave traders.\n- In a scene (approximately 47:40–53:00) from the 1977 film MacArthur depicting a Pearl Harbor shipboard strategy meeting between President Roosevelt, Nimitz, and MacArthur, a painting of the USS Los Angeles is clearly seen on the bulkhead.\n- Asiatic-Pacific Campaign Medal\n- World War II Victory Medal\n- China Service Medal\n- National Defense Service Medal with star\n- Korean Service Medal with five battle stars\n- Armed Forces Expeditionary Medal\n- United Nations Korea Medal\n- This article incorporates text from the public domain Dictionary of American Naval Fighting Ships. The entry can be found here.\n- This article includes information collected from the Naval Vessel Register, which, as a U.S. government publication, is in the public domain. The entry can be found here.\n|Wikimedia Commons has media related to USS Los Angeles (CA-135).|","USS Los Angeles (CA-135)\n|Namesake:||Los Angeles, California|\n|Builder:||Philadelphia Navy Yard, Philadelphia|\n|Laid down:||28 July 1943|\n|Launched:||20 August 1944|\n|Commissioned:||22 July 1945|\n|Decommissioned:||9 April 1948|\n|Recommissioned:||27 January 1951|\n|Decommissioned:||15 November 1963|\n|Struck:||1 January 1974|\n|5 battle stars (Korea)|\n|Fate:||Sold for scrap to Terminal Island's National Metal and Steel Corp. on 16 MAY 1975 for $1,036,089|\n|Class and type:||Baltimore-class cruiser|\n|Displacement:||13,600 long tons (13,818 t)|\n|Length:||674 ft 11 in (205.71 m)|\n|Beam:||70 ft 10 in (21.59 m)|\n|Draft:||20 ft 6 in (6.25 m)|\n|Speed:||33 knots (61 km/h; 38 mph)|\n|Complement:||1,142 officers and enlisted|\n|Aircraft carried:||Curtiss SC-1 Seahawk floatplane|\n|Official name||USS Los Angeles Naval Monument (John S. Gibson Jr. Park)|\n|Designated||3 May 1978|\nThe third USS Los Angeles (CA-135) was a Baltimore class heavy cruiser, laid down by the Philadelphia Navy Yard, Philadelphia, on 28 July 1943 and launched on 20 August 1944. She was sponsored by Mrs. Fletcher Bowron and commissioned on 22 July 1945, with Capt. John A. Snackenberg in command.\nAfter shakedown out of Guantánamo Bay, Cuba, Los Angeles sailed on 15 October for the Far East via the west coast and arrived at Shanghai, China, on 3 January 1946. During the next year she operated with the 7th Fleet along the coast of China and in the western Pacific to the Marianas. She returned to San Francisco, California, on 21 January 1947, and was decommissioned at Hunters Point on 9 April 1948, and entered the Pacific Reserve Fleet.\nLos Angeles was recommissioned on 27 January 1951, Capt. Robert N. McFarlane in command. In response to the American efforts to thwart Communist aggression in the Republic of Korea, she sailed for the Far East 14 May and joined naval operations off the eastern coast of Korea on 31 May as flagship for Rear Adm. Arleigh A. Burke's CRUDIV 5. During the next six months she ranged the coastal waters of the Korean Peninsula from Hungnam in the east to Haeju in the west while her guns pounded enemy coastal positions. After returning to the United States on 17 December for overhaul and training, she made her second deployment to Korean waters on 9 October 1952 and participated on 11 October in a concentrated shelling of enemy bunkers and observation points at Koji-ni. During the next few months, she continued to provide off-shore gunfire support for American ground operations, and in addition she cruised the Sea of Japan with fast carriers of the 7th Fleet. While participating in the bombardment of Wonsan late in March and early in April 1953, she received minor damage from enemy shore batteries, but continued operations until sailing for the west coast in mid-April. She arrived at Long Beach on 15 May.\nBetween November 1953 and June 1963 Los Angeles made eight more deployments to the Far East where she served as a cruiser division flagship with the 7th Fleet in support of \"keeping the peace\" operations in that troubled part of the world. Her operations sent her from the coast of Japan to the Sea of Japan, the Yellow Sea, and the East and South China Seas; and with units of the 7th Fleet she steamed to American bases in the Philippines and Okinawa, as well as to Allied bases in South Korea, Hong Kong, Australia, and Taiwan. During the Quemoy-Matsu crisis in 1956, she patrolled the Taiwan Strait to help protect ROC Army units from possible landing offenses from Communist China. When not deployed in the western Pacific, Los Angeles operated out of Long Beach along the west coast and in the Pacific to the Hawaiian Islands. She returned to Long Beach from her final Far East deployment on 20 June 1963.\nDecommissioning and sale\nWhile some consideration was made to convert Los Angeles into a single-end Talos missile cruiser, with flagship facilities (in essence a heavy cruiser version of the Oklahoma City) funds were not appropriated for this, (or for a general overhaul to enable her continued fleet service), so she was decommissioned at Long Beach on 15 November 1963 and entered the Pacific Reserve Fleet at San Diego. Stricken on 1 January 1974, and sold on 16 May 1975 (sale #16-5049) to the National Steel Corporation for $1,864,380.21, and scrapped in San Pedro, California.\nIn popular culture\n- USS Los Angeles was featured in The Adventures of Tintin comic The Red Sea Sharks by Hergé. She is shown patrolling in the Red Sea and is involved in the rescue of Tintin and his friends from a post-war Type II U-boat operated by slave traders.\n- In a scene (approximately 47:40–53:00) from the 1977 film MacArthur depicting a Pearl Harbor shipboard strategy meeting between President Roosevelt, Nimitz, and MacArthur, a painting of the USS Los Angeles is clearly seen on the bulkhead.\n- Asiatic-Pacific Campaign Medal\n- World War II Victory Medal\n- China Service Medal\n- National Defense Service Medal with star\n- Korean Service Medal with five battle stars\n- Armed Forces Expeditionary Medal\n- United Nations Korea Medal\n- This article incorporates text from the public domain Dictionary of American Naval Fighting Ships. The entry can be found here.\n- This article includes information collected from the Naval Vessel Register, which, as a U.S. government publication, is in the public domain. The entry can be found here.\n|Wikimedia Commons has media related to USS Los Angeles (CA-135).|"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:201f765c-cd34-49ad-b0d2-70b4445c4997>","<urn:uuid:201f765c-cd34-49ad-b0d2-70b4445c4997>"],"error":null}
{"question":"What are the key differences between how Shakyamuni Buddha and early Portuguese missionaries approached spreading their teachings in India?","answer":"Shakyamuni Buddha and Portuguese missionaries had distinctly different approaches to spreading their teachings in India. Shakyamuni taught without discrimination, being a 'friend to all, comrade to all' and traveled wherever people were in need, regardless of race or class. His teachings were focused on helping individuals overcome their specific sufferings and troubles, with encouragement that functioned like medicine prescribed for various ailments. In contrast, the Portuguese missionaries in Goa used technological means like the printing press to spread Christianity, focusing on publishing religious texts like catechisms and prayer books. They also enforced their language, as evidenced by the 1684 order to replace Konkani with Portuguese, showing a more authoritative approach compared to Buddha's inclusive teaching style.","context":["Soka Gakkai International\nBuddhism in Action for Peace\nHistory & Philosophy\nStories and reflections on the Buddhist approach to life\nUpdates and reports from around the world\nSection two of ten of SGI President Daisaku Ikeda’s 2017 peace proposal, “The Global Solidarity of Youth: Ushering In a New Era of Hope.”\nThe first challenge I would like to address is creating solidarity toward respectful coexistence on the one planet that we all share. In this, the role of young people is central.\nThe Paris Agreement, a new international framework for combating climate change, entered into force in November of last year. It was adopted in December 2015 and signed by the representatives of 175 countries and territories in April 2016. Its entry into force less than one year after being adopted was unprecedented.\nWith this, the countries of the world came together to confront a common threat in a way that had previously appeared impossible. This reorientation was the result of a shared awareness that climate change is an urgent issue for all countries, a recognition spurred by extreme weather events, rising sea levels and other tangible manifestations.\nIf we are to make progress in the alleviation of poverty and toward the achievement of all of the 17 goals and 169 targets that comprise the SDGs, we will need to share a similar awareness and solidarity across all fields.\nThe broad spectrum of concerns covered by the SDGs has caused some people to wonder if they are in fact achievable. But it is important to remember that the large number of targets speaks to the vast number of people facing gravely challenging conditions, none of which we can afford to overlook. In addition to the direct impacts of conflicts and natural disasters, the victims are often tormented by the sense that they have been forgotten and ignored.\nWhile the urgent nature of the refugee crisis is all too evident and was a central topic of the World Humanitarian Summit held in May of last year and of the United Nations Summit for Refugees and Migrants in September, effective international cooperation has continued to lag.\nThe new UN Secretary-General, António Guterres, stated in an interview last October soon after his appointment:\nI will do everything I can . . . for refugee protection to be assumed as a global responsibility, as it is. And it’s not only the refugee convention. It’s deeply rooted in all cultures and all religions everywhere in the world. You see in Islam, you see in Christianity, you see in Africa, in different religions, in Buddhism and Hinduism, there is a strong commitment to refugee protection. \nIndeed, efforts to respond to the refugee crisis must be strengthened, and the spiritual wellsprings to support this can be found in living traditions throughout the world. The key to dealing with even the most seemingly intractable challenges is to be found when people come together and continue to do all in their power for the sake of others.\nThe starting point for Buddhism is to work alongside those who are suffering to enable them to overcome that suffering. Shakyamuni’s vast body of teachings—sometimes referred to as the eighty thousand teachings—were for the most part expounded in the effort to confront the troubles and sufferings afflicting specific individuals. Shakyamuni refused to limit the audience for his teachings, and sought instead to be “friend to all, comrade to all.”  Thus he taught the Dharma to all whom he encountered.\nIn his portrait of Shakyamuni, the German philosopher Karl Jaspers (1883–1969) states: “The Buddha did not appear as a teacher of knowledge but as the herald of the path to salvation.” \nJaspers notes that the phrase “a path to salvation” derives from an ancient Indian medical term. And what underlies all of the Buddha’s teachings is encouragement that functions like medicine prescribed for the specific conditions of various ailments. Shakyamuni called on his disciples and comrades: “Go ye now, O Bhikkhus, and wander, for the gain of the many, for the welfare of the many.”  Thus Shakyamuni and his disciples who continued the practice of traveling to wherever people were in need, without distinction to differences of race or class, were referred to as “the people of the four directions.” \nShakyamuni himself embraced a profound conviction in the dignity and preciousness of life. He was convinced that this dignity exists in the lives of all people and that it is always possible to bring forth life’s inherent potentialities under even the most trying conditions.\nIn the society of his time, two currents of thought prevailed. One was a kind of fatalism that our present and our future are entirely determined by karma accumulated in the past. The other held that all things are a matter of chance and that nothing in our lives is the outcome of any particular cause or condition.\nThe fatalistic view engendered the resignation that no effort on our part can alter our destiny and our only choice is to accept our fate. This worked to rob people’s hearts of hope. The other view, by disassociating any action from its outcome, uprooted people’s sense of self-control, making them indifferent to the harm they inflicted on others.\nShakyamuni sought to free people from the constraints and harmful influence of these two views when he taught:\nJudge not by birth, but life.\nAs any chips feed fire,\nmean birth may breed a sage\nnoble and staunch and true. \nEverything in our lives, far from being immovably determined, can be transformed for the better through our actions in this moment. In this way, Buddhism teaches that a change in our inner determination in this moment can change the present reality of our lives (Jpn: in; cause) that produces future outcomes (Jpn: ka; effect). At the same time, it emphasizes the critical importance of conditioning context (Jpn: en; relation) that can powerfully shape the interplay between cause and effect. In other words, depending on the context of the relations that are formed, the same cause can give rise to widely varying effects.\nFrom this perspective, Buddhism encourages a way of life in which, upholding powerful confidence in the dignity and possibilities of life, we form relations of mutual encouragement and fellowship with those who are on the verge of losing hope.\nIn the Mahayana Buddhist tradition, the term bodhisattva is used to describe a person dedicated to the realization of happiness for oneself and others, as portrayed allegorically in the following words from the Vimalakīrti Sutra:\nDuring the short aeons of maladies,\nThey become the best holy medicine;\nThey make beings well and happy,\nAnd bring about their liberation.\nDuring the short aeons of famine,\nThey become food and drink.\nHaving first alleviated thirst and hunger,\nThey teach the Dharma to living beings.\nDuring the short aeons of swords,\nThey meditate on love,\nIntroducing to nonviolence\nHundreds of millions of living beings. \nThis signifies extending encouragement to people as they confront the inevitable sufferings of life, what Buddhism refers to as the four sufferings of birth, aging, sickness and death. And as indicated by the following words from the Vimalakīrti Sutra—because living beings are ill, I also am ill —to be a bodhisattva means to be motivated by the spirit of empathy to respond to grave social crises, wherever you are and whether or not you are directly impacted.\nIn the same sutra, the effects of this compassionate action are described as an “inexhaustible lamp” : the light of hope we ignite will not only illuminate the life of the individual with whom we are interacting, but will continue to brightly light the lives of others in our immediate surroundings and in society as a whole.\nrelated article Restoring Hope in the Lives of Refugees Work and education are vital for dignity. Developing an aid architecture to enable displaced persons to work in fields that contribute to enhancing resilience and promoting the SDGs would help solve humanitarian challenges and protect human dignity. This spirit of the bodhisattva is the foundation that has sustained the SGI’s efforts as a faith-based organization that supports the UN and works for the resolution of global challenges. Over the years, we have engaged in such activities as the relief of refugees and rebuilding in the wake of natural disasters. And our consistent focus has been on promoting empowerment of, by and for the people.\nLike the inexhaustible lamp, the inner capacities of people that are unleashed by empowerment serve as an enduring source of energy for transformation, a wellspring of inextinguishable hope.\nThe Lotus Sutra, which expresses the essence of Shakyamuni’s teachings, contains the Parable of the Phantom City and the Treasure Land. \nA caravan was crossing a vast desert guided by a leader who was well acquainted with the dangerous terrain. Members of the caravan became exhausted and were ready to abandon their journey. If they were to turn back, however, their efforts would have been in vain, so the leader used his magical powers to conjure up a vision of a magnificent city toward which they could progress and encouraged them to persevere until they reached it. This vision revived the hopes of the members of the caravan, and when they reached the city they were able to rest there. Seeing that they were rested, the leader revealed that the city they were in was in fact a phantom city he had conjured up to encourage them. Their actual destination, the treasure land, was nearby, and he urged them to advance together until they reached it.\nThe theme that runs through this parable is found in Shakyamuni’s words—together you may reach the treasure land.  This may be understood as a proud affirmation of the human spirit—to advance together with others in an indefatigable pursuit of shared happiness no matter how painful or desperate that pursuit may at times seem.\nIf we consider this in terms of the causal relationship touched on earlier, people who had fallen into a state of utter exhaustion (cause) and who might otherwise have been unable to go on (effect) were revitalized and enabled to reach their destination (alternative effect) thanks to words of encouragement (relation).\nNichiren (1222–82), the Japanese Buddhist teacher who developed a unique interpretation of Buddhism rooted in the spirit of the Lotus Sutra, asserted that there was no fundamental difference between the phantom city and the treasure land, but that they were in fact identical. It is not simply the outcome of reaching the treasure land that matters, but the process—together you may reach the treasure land—that is invaluable.\nWhen the cause and relation of people’s suffering and the encouragement to overcome it are harmoniously fused, each step forward becomes a “moment of life in the phantom city” and shines with the ultimate dignity of life—a “moment of life in the treasure land.” \nWriting about the Millennium Development Goals (MDGs) which preceded the SDGs in the period up to 2015, I noted that the effort to achieve them must be focused on not only meeting targets but also restoring the well-being of the individual who is suffering.  When too much attention is paid to numerical outcomes, there can be a failure to pay adequate attention to the needs of real people; this can undermine the motivation necessary to achieve the objectives.\nHere I am reminded of the words of the Argentinian human rights activist Adolfo Pérez Esquivel: “When people aim for a shared human goal, when they aspire to peace and freedom, they unleash extraordinary capabilities.” \nDr. Esquivel developed this conviction through deepening solidarity with the people of Latin America who refused to relinquish hope for the future even in the midst of the most difficult social conditions. He expressed his admiration for the actions of the common people with this striking image:\nWhen we enter more deeply into the lives of ordinary people, we see that man or woman, young or old—with no pretense at heroics—optimistically look daily for a miracle to occur and a bud to blossom.\nSuch a flower can bloom in the midst of the struggles of daily life, in a child’s smile, in the creation of hope and in the illumination of our path showing us that our exertions are our liberation. \nNone of the SDGs will be easy to achieve. But through maintaining empathetic connections with those who struggle and dedicating ourselves to the work of empowerment, each of us should be able to cause a flower to bloom in our immediate surroundings.\nNo one has a more crucial role to play in this than youth.\nSecurity Council Resolution 2250, which I mentioned earlier, stresses the importance of youth participation in peacebuilding. As this affirms, young people have the power to create new breakthroughs in any field where they are given the chance to be actively engaged.\nPeople throughout the world were moved last summer when a team composed of refugees took the field at the Olympic Games for the first time. The words they shared on that occasion continue to resonate in many hearts. One expressed the desire to use the opportunity of running at the Olympics to send to fellow refugees the message that life can be changed for the better, while another looked back on his life experiences and said he drew strength from them and was running with the hope that refugees would be able to lead better lives. \nTheir words convey the fact that the true essence of youth is not to be found in the past, nor in the future, but rather in the desire to do something for the benefit of the other people living with us in the present moment.\nLikewise, for young people, the vision of the SDGs—to leave no one behind—is not something to be achieved in a distant place or a goal for some time in the future. The SDGs point to the present realities of living together on this one planet with our fellow human beings, a way of life dedicated to the daily effort of building a society in which the joy of living is shared by all.\nWhen youth make the determination to illuminate the corner of the world they inhabit now, it brings into being a space of security in which people can regain hope and the power to live. The determination to live together that is ignited in this space of security shines as an embodiment of the global society in which no one is left behind, inspiring courage in people living in other communities who confront similar challenges.\nThe true value of any state or society lies in what it does for those who are most afflicted by suffering, not in its military or economic prowess.\nIn my proposal three years ago, I stressed that today’s youth are the generation that will most powerfully shape the work of achieving the SDGs. I also proposed that the UN and civil society should work together to promote the kind of education for global citizenship that unleashes the limitless potential of youth.\nI was thus very gratified when last year’s conference of nongovernmental organizations (NGOs) affiliated with the UN’s Department of Public Information (DPI/NGO Conference) was held in South Korea under the theme “Education for Global Citizenship: Achieving the Sustainable Development Goals Together.” Attended by many young people, the conference adopted the Gyeongju Action Plan committing participants to promoting education for global citizenship.\nThe true value of any state or society lies in what it does for those who are most afflicted by suffering, not in its military or economic prowess.\nEducation gives rise to the actions and activities that shape the direction of society over time. Education for global citizenship, in particular, can provide the conditioning context (relation) that enables people to reframe events, wherever they may occur, through a shared human perspective, and to foster action and solidarity. It can encourage people to consider global issues in terms of their own lives and lifestyles, thus bringing forth the inner capacities we each possess.\nThrough education for global citizenship, learners have the opportunity to: (1) gain the experience of seeing the world through the eyes of others; (2) discover and clarify what is necessary in order to build a society where we can all live together; and (3) collaborate to give birth to spaces of security in their immediate surroundings.\nI am convinced that this kind of education can serve as a catalyzing context (relation) that enables young people to bring forth their full potential, increasing the momentum for global change.\n4. UN News Centre, “Interview.”\n5. Norman, trans., Theragāthā, 65.\n6. (trans. from) Jaspers, Die grossen Philosophen, 142.\n7. Müller, trans., The Sutta-nipata, 1:11:1.\n8. (trans. from) Nakamura, Genshi butten o yomu, 273.\n9. Chalmers, trans., Buddha’s Teachings, 109.\n10. Thurman, trans., Vimalakīrti Nirdesa Sutra, 70.\n11. See Watson, trans., The Vimalakirti Sutra, 65.\n12. Ibid., 59.\n13. See Watson, trans., The Lotus Sutra, 154.\n14. See Watson, trans., The Lotus Sutra, 180.\n15. Nichiren, The Record of the Orally Transmitted Teachings, 72.\n16. Ikeda, A Forum for Peace, 195.\n17. (trans. from) Ikeda and Esquivel, La fuerza de la esperanza, 30.\n18. Ibid., 80.\n19. See UNHCR, “These 10 Refugees Will Compete at the 2016 Olympics in Rio.”","The Story of Goa and Print\nThe history of modern-day print in the Indian subcontinent can be traced to a serendipitous incident four centuries ago, off the coast of India’s smallest state, Goa.\nThe year was 1556. A ship carrying a printing press from Portugal to Abyssinia (Ethiopia) to aid missionary activity there1, stopped en route in Goa, the capital of Estado Português da Índia (Portuguese State of India). While there, word arrived that relations with the Abyssinian ruler had deteriorated to an extent. Thus, the printing press was unloaded on Goan shores and set up at the College of St Paul, the continent’s leading Jesuit institution at the time.\nThis was the first printing press in all of Asia.\nThe College of St Paul: Where it all began\nThe first Jesuit to set foot on Goan soil was St Francis Xavier in 1542, co-founder of the Society of Jesus (the Jesuit order) with St Ignatius of Loyola. While in Goa, St Xavier headed the College of St Paul (Colégio de São Paulo) situated in the current Old Goa, where the first printing press was installed four years after his death.\nJoão de Bustamante, considered the ‘Indian Gutenberg’2, was a Spaniard skilled in printing who travelled from Portugal along with the printing press. He helped install the printing press at the College and is credited with printing the earliest books in the subcontinent. It is said that Bustamente was assisted in the establishment of the printing press by a person of Indian origin, who also arrived from Portugual but remains unnamed in historical documents, only referred to as ‘Habil Impressor’ (an able printer).3\nThe first materials to be printed were ‘conclusões’ (theses) on logic and philosophy for the express purpose of a spirited debate on these theses. They were also stuck to the doors of the Church of St Paul before the discussion to allow friars to read them. It is unestablished whether these printed ‘conclusões’ were in the form of loose pages or booklets. Based on this, the first printed book is believed to be St Francis Xavier’s Catecismo da Doutrina Christa, published in 1557 in Portuguese.4\nThe oldest printed book in the subcontinent with a copy still in existence is Gaspar De Leão’s Compendio Spiritual Da Vida Christãa (Spiritual Compendium of the Christian Life) published in 1561 at the College. Today, one will have to visit the New York Public Library to view the copy.\nThe first book to be printed in the subcontinent in a vernacular language and script was a Tamil version of Doutrina Christa, published at a press in Quilon (Kollam) on the Malabar Coast in 1578. Titled ‘Thambiran Vanakkam’, this prayer book was authored by Portuguese missionary Henrique Henriques and was 16 pages in length.5\nTamil is also considered to be the first non-European language to come through the mechanised printing press. Two years before the very advent of printing in the subcontinent”, ‘Cartilha em Tamul e Portugues’ (Christian Cathechism in Tamil and Portuguese) was published in Lisbon, a bilingual book in the Roman script. The translation was done by three Tamil Christians from Lisbon – Vincente de Nazareth, Thome da Cruz and Jorge Carvalho – and headed by Father Joao Villa de Conde. The sole copy still in existence can be found at the National Museum of Ethnology near Belem in Lisbon.6\nRachol Seminary: The birthplace of printed Konkani literature\n“Sisters and Brothers of America,” Swami Vivekananda began his address at the 1893 Parliament of the World’s Religions in Chicago – one that received a thunderous standing ovation from the 7,000 attendees and continues to resonate in speeches till today. A year before the speech that enthralled America, Swami Vivekananda is said to have visited the Patriarchal Seminary of Rachol, a diocesan seminary (among the first seminaries in Goa) situated on a hillock in the quaint village of Rachol, to gain a better understanding of Christian theology in preparation for his visit to Chicago.\nRachol played a prominent role in the early days of print in the subcontinent. The printing press here was set up at the College of All Saints, later renamed the College of St Ignatius, where Rachol Seminary is currently located. The first book was printed in 1616; Krista Purana by Jesuit priest Thomas Stephens, who is believed to be the first Englishman to set foot in Indian subcontinent.\nA founding father of Konkani literature, Stephens however is most recognised for this work – an epic poem that tells the story of the Bible (both Old and New Testament)7 in Marathi.\n‘Kristapurana may be read as one of the first retellings of the biblical narrative into a South Asian language. . . Puranas were originally Sanskrit texts, held in reverence by various sects of Hindus in the Indian subcontinent. In the period between 1000 CE and 1500 CE, these Sanskrit texts began to travel to the regional languages of the subcontinent through translations, including Marathi. Marathi literary scholars place Kristapurana in this tradition of Marathi Puranas’, writes Annie Rachel Royson, in an online essay titled ‘Kristapurana: An Introduction’.\nStephens is also credited as the author of the first printed grammar in an Indian language through his Arte da Lingoa Canarim (Grammar of Canarim language), which was revised and printed in 1640 by his student Fr Diogo Ribeiro and other Jesuits. Its purpose was to help missionaries learn the Canarim language to help them evangelise the villages of Salcete.8 Canarim is an old term for the language that is presently spoken across the length and breadth of Goa, Konkani.\nThe first-ever Konkani book to be printed was also authored by Thomas Stephens – Doutrina Christam em Lingoa Bramana Canarim, published at Rachol in 1622. Copies of this work can be found at the National Library in Lisbon and the Vatican Library in Rome.9\nStephens was a staunch advocate for the printing of books in the script of the people – Devanagri. However, it is supposed that the sheer number of types required to be cast made it appear inconceivable and it required the approval of the Provincial.10 Thus, while books appeared in local languages of Goa, the Roman script was used in their publication.\nThe printing press at Rachol ran for more than five decades till 1674 and contributed to a trove of published literature.\nA harsh blow to printing in Goa came through the 1684 order which sought to extinguish Konkani among the local populace and compulsorily replace it with Portuguese in three years. Less than a century later, the Jesuits were also imprisoned and removed from Goa, following a decree by the King of Portugal in 1759 expelling the Society of Jesus from Portugal. Printing in Goa was revived only in 1821 with a periodical known as Gazeta de Goa.\nPresent Day: Preserving the Past for Posterity\nStepping into the Rare Book Section at the Krishnadas Shama Goa State Central Library in Panaji gives you a glimpse into the literary days of yore. Among the oldest public libraries in the country, its Rare Book Section is home to a rich repository of literature in diverse languages such as Konkani, Portuguese, Latin, Sinhalese, Tamil, and Castilian dating back to the sixteenth century. The oldest book there is Ubaldis’ Sexto Super Codices Justinian Commentari, Lugdini, published in 1539. The collection also houses books from the initial days of print in Goa with the earliest published in 1643.11 A handwritten manuscript of the Kristapurana can be found here, copied from an earlier edition by Manoel Salvador Rebello in 1767.12\nThere’s also a preservation laboratory within its premises with a systematic conservation process in place. The section head identifies books in need of preservation which are subsequently sent to the data imaging centre to be scanned. An overhead scanner generates a digital replica of each page in mere seconds while ensuring that these aged tomes need not be flipped over thus protecting them from damage.\nInside the book conservation laboratory, each page is painstakingly preserved with the application of Japanese tissue (similar to a thin translucent sheet) on both sides. The tissue is transparent and protects the page underneath for at least a century. Plus, the process is reversible. Remove the Japanese tissue and the page will still be in its original condition. Certain manuscripts are also wrapped in insect-repellent cloth and showcased in glass cases.\nAcknowl-edging History: Tracing the Trail of Time\nThe desire of Portuguese missionaries to spread Christianity in the subcontinent brought us the earliest works of print in the region.\nGoa, the smallest state in India is one with the longest history of colonialism, lasting from 1510 to 1962. The resulting amalgam of Indo-Portuguese influence is seen from the very first printing press – with the Roman script (of Portuguese type) used to print works in vernacular languages. The absence of Devanagri moulds for printing Konkani in the local script could be credited with shaping the foundation of Romi Konkani. Widely used across Goa today, this script has its origin in the writings of Thomas Stephens.\nJust how the simple flap of a butterfly’s wings in New Mexico might cause a storm in China, history too weaves indelible threads to the present.\n1 Chehak Bansal, “History of Printing Press in India”, Osmo Magazine, 8 February 2021, osmomag.com/history/history-of-printing-press-in-india\n2 Wikipedia contributors, “João de Bustamante”, Wikipedia, 9 February 2020, https://en.wikipedia.org/wiki/Jo%C3%A3o_de_Bustamante\n3 Anant Kakba Priolkar, The Printing Press in India: Its Beginnings and Early Development (Bombay: Marathi Samshodhana Mandala, 1958).\n4 Anant Kakba Priolkar, The Printing Press in India: Its Beginnings and Early Development.\n5 K Madhavan, “Tamil saw its first book in 1578”, The Hindu, 21 June 2010, https://www.thehindu.com/news/national/tamil-nadu/Tamil-saw-its-first-book-in-1578/article15685475.ece\n6 A Limited, “English: A page from Luso-Tamil Catechism (Cartilha or Primer) printed in Lisbon in 1554 CE”, Alamy, https://www.alamy.com/english-a-page-from-luso-tamil-catechism-cartilha-or-primer-printed-in-lisbon-in-1554-ce-it-is-a-bilingual-work-with-tamil-and-portuguese-phrases-both-printed-in-roman-script-this-is-the-earliest-known-printed-work-of-tamil-though-in-roman-script-the-books-is-38-pages-long-with-tamil-phrases-in-red-followed-immediately-by-portuguese-translations-printed-in-black-in-smaller-font-authors-of-the-book-were-tamil-christians-living-in-lisbon-vincente-de-nazareth-thome-da-cruz-and-jorge-carvalho-they-were-supervised-by-father-joao-villa-de-conde-the-single-surviving-copy-of-the-image351998744.html\n7 Annie Royson, “Kristapurana: An Introduction”, Sahapedia, 2019, www.sahapedia.org/kristapurana-introduction\n8 Ivo Souza, “Evangelisation of the Village of Raia”, ivosouza.wordpress.com/, 2009, https://ivosouza.wordpress.com/2009/01/13/evangelization-of-the-village-of-raia/\n9 Mousinho de Ataide, Rachol (Goa: New Age Printers, 2012).\n10 Anant Kakba Priolkar, The Printing Press in India: Its Beginnings and Early Development (Bombay: Marathi Samshodhana Mandala, 1958).\n11 Maria Pia De Menezes Rodrigues, Texts, Tomes and Treasures – The Evolution of Goa’s Publica Livraria (1832 – 2005) (Goa: 2014).\n12 Annie Royson, “Kristapurana: An Introduction”.\nAbout the Author\nAnnalie Gracias is a freelance journalist and copyeditor based in Goa, India. She has served as the Assistant Editor of Goa Today, the oldest magazine in the state, and was also awarded a scholarship for the Australian Digital Job Accelerator, 2020. She has also been published in gal-dem.com (an independent British online and print publication).\nStorytelling is what she does best and her ‘happy place’ is penning words on paper or editing copy to make it read better. She tweets @annaliegracias."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:14339947-a2bd-4346-835d-73b03b0b5e79>","<urn:uuid:71456fae-1aa8-44ba-9deb-5bef46118081>"],"error":null}
{"question":"What are the differences between Bangladesh Army Welfare Trust's asset management and NAVWAR's system integration methodology?","answer":"The Bangladesh Army Welfare Trust manages diverse physical assets including luxury hotels and voting machine manufacturing, with assets worth over 700 million dollars, operating with limited oversight. NAVWAR, on the other hand, uses a structured digital modeling approach with clearly defined frameworks like model based systems engineering (MBSE), integrated dictionaries, and schemas to manage and integrate complex naval information systems, enabling systematic testing and evaluation before deployment.","context":["WHEN AL JAZEERA, a Qatari television network, accused Bangladesh’s army chief not only of helping to hide his two fugitive brothers, who are on the run from a murder conviction, but also of steering military procurement contracts their way, the Bangladeshi government did not investigate the allegations. It did not even bother to rebut the claims in detail—including the assertion by one of the fugitives that Sheikh Hasina Wajed, the prime minister, was aware of and happy with this arrangement. Instead, it simply dismissed the whole story as a “smear campaign”.\nSheikh Hasina has a peculiar relationship with the armed forces. It was soldiers who got her into politics in the first place, by murdering her father, Sheikh Mujibur Rahman, Bangladesh’s first president, as well as most of her family, during a coup in 1975. Ever since, she has pursued the two somewhat contradictory ends of avenging the killings and cultivating close ties with the army, lest she be toppled herself.\nSheikh Hasina’s party, the Awami League, used to be less popular among the armed forces than its main opposition, the Bangladesh Nationalist Party (BNP), which was founded by an army officer and war hero, Ziaur Rahman, and is now led by his wife, Khaleda Zia.Yet since Sheikh Hasina began her second stint in power in 2009, she has gradually purged the armed forces of BNP supporters and promoted loyalists like Aziz Ahmed, the current army chief and object of Al Jazeera’s accusations (pictured, on the left). At the same time, she has showered the armed forces with perks. Close relatives of soldiers can receive health care in military hospitals, which are considered the best in the country. In 2015 she doubled pay across the armed forces, as well as for the civil service.\nThe government’s spending on defence rose by 123% between 2008 and 2017, according to a report by the Stockholm International Peace Research Institute, a watchdog, despite the lack of any obvious military threats. The army has bought Chinese fighter jets and tanks, and built several big new bases, such as one of 620 hectares in the southern district of Patuakhali that the prime minister opened in 2018.\nDuring Sheikh Hasina’s decade in power, the armed forces have also massively expanded their business interests, in part through the Bangladesh Army Welfare Trust (AWT) and Sena Kalyan Sangstha (SKS). These two foundations for the welfare of soldiers and veterans are technically independent of the army, but managed by serving officers. According to its website, SKS alone has assets of over 60bn taka ($700m). Among the assets of the AWT, meanwhile, are several luxury hotels and the firm that makes the voting machines used in national elections. There was no tender for the contract; watchdog groups and opposition politicians complain the machines’ design makes vote-rigging easy.\nThe armed forces also manage lots of infrastructure projects on the government’s behalf—an alarming prospect given the practices Al Jazeera has alleged. The navy spent $300m developing a refugee camp on a remote island, for instance. The air force is in charge of the expansion of the main airport in Dhaka, the capital. The army handles highway construction.\nSenior officers are also handed explicit opportunities for self-enrichment, in the form of land in Dhaka, a cramped city of 18m. They all get plots on which they are entitled to build a seven-floor building, with up to seven apartments. In theory, this is a form of housing allowance; in practice, officers sell at least some of the flats at a huge profit. Many serving or retired officers are also given swanky government jobs: heading the national port authority, for instance, or the agency that regulates tea farming. Even the lower ranks enjoy lucrative perks: the government passes on the roughly $10,000 it receives from the UN for each Bangladeshi soldier deployed on a peacekeeping mission.\nThis coddling has worked. Although the army has seized power three times and run the country for 15 of the 50 years since independence, it has let Sheikh Hasina be. But in buying its loyalty, she has put it at the heart of government. Given her lack of a clear successor, its banishment from politics may last no longer than she does. ■\nThis article appeared in the Asia section of the print edition under the headline \"Wallets at the ready\"","SAN DIEGO (NNS) -- Naval Information Warfare Systems Command (NAVWAR) accomplished a significant milestone in the digital engineering transformation with completion of its first digital twin, a system-of-systems digital model, representing a set of information warfare capabilities that will be installed on USS Abraham Lincoln (CVN 72) in fiscal year 2020.\nAligned with the Department of Defense Digital Transformation Strategy, NAVWAR is shifting from a design-build-test methodology to a model-analyze-build methodology, enabling the ability to test and evaluate solutions in a virtual environment before delivery. This shift will increase system reliability and cybersecurity while decreasing risk for the warfighter.\n“Digital engineering is vital in modernizing how we design, develop, deliver, operate and sustain systems,” said NAVWAR Executive Director Pat Sullivan. “It enables the use of digital models throughout the life cycle of a system, increasing system cybersecurity, interoperability and resiliency. This provides a solid foundation to enable us to fight and win the conflicts of the future.”\nNAVWAR’s first digital twin, also known as Digital Lincoln, used NAVWAR’s model based systems engineering (MBSE) methodology, and its corresponding integrated dictionary, schema, and requirements framework to develop an end-to-end digital representation of five interconnected systems being installed on the USS Abraham Lincoln.\n“MBSE provides a consistent approach for developing and sharing engineering information across interrelated efforts,” said Sam Rix, NAVWAR MBSE implementation lead. “The integrated dictionary provides a list of parts engineers can use when building a digital model, the schema provides directions on how to put the parts together, and the requirements framework describes the traceability across digital models to track how and why the parts connect.”\nDigital Lincoln is a black box model; a digital representation that can be viewed in terms of its inputs and outputs, of the following five interconnected systems onboard USS Abraham Lincoln:\n- The Distributed Common Ground System-Navy (DCGS-N): A program that provides the Navy’s primary intelligence, surveillance, reconnaissance and targeting-support capability. Afloat or ashore, DCGS-N tools are critical for the operational commander’s battlespace awareness and net centric operations.\n- Navy Integrated Tactical Environmental System-Next Generation (NITES-Next): A system that uses meteorology and oceanography data to help the warfighter with mission planning, mission execution, critical decision-making and situational awareness.\n- Maritime Tactical Command and Control (MTC2): A Navy command and control (C2) program that delivers battle management aids to dynamically plan, direct, monitor and assess maritime operations.\n- Global Command and Control System – Maritime (GCCS-M): A system that fuses, correlates, filters, maintains and displays location and attribute information on friendly, hostile and neutral land, sea and air forces.\n- Agile Core Services (ACS) - An element of Consolidated Afloat Networks and Enterprise Services (CANES) that gives CANES the infrastructure to support application migration.\n“Modeling complex systems in a digital environment is like working on a giant puzzle, where multiple people are working separate sections of the puzzle,” said Monique Harris, NAVWAR requirements management lead. “It is not until the people begin to communicate that they are able put their sections together to reveal the final image. These systems are like separate sections of the puzzle, and in the past we have waited until fielding to put the puzzle pieces together, but with digital engineering we are putting the pieces together before fielding, allowing us to address issues before we deliver the system to the warfighter.”\nBy developing a digital twin, or digital model, of these systems, NAVWAR was able to identify capability gaps and overlaps prior to installation.\n“For example, we found that some of the systems were making individual offshore calls for the exact same piece of information,” said Chris Ruffalo, NAVWAR digital products lead for digital engineering. “Digital Lincoln allowed us to identify the overlap and resolve the problem before delivery, so only one system was tackling the task, rather than two or three, reducing bandwidth used. That is very important in a bandwidth degraded environment.”\nIn addition to developing a digital twin of these systems, Digital Lincoln provides a standardized format for developing future digital models and a baseline for future installations.\nMoving forward, the NAVWAR Digital Lincoln team will leverage lessons learned and apply them to the development of a system-of-systems digital twin of USS Dwight D. Eisenhower (CVN 69), or Digital Ike.\nAs the Navy continues on its journey of digital transformation, the goal is to create digital models of all systems on all platforms to improve cybersecurity, enhance system capability, increase the speed of technology delivery and reduce time and cost of installation.\nNAVWAR identifies, develops, delivers and sustains information warfighting capabilities and services that enable naval, joint, coalition and other national missions operating in warfighting domains from seabed to space. NAVWAR consists of more than 11,000 active duty military and civil service professionals located around the world.\nConnect with NAVWAR"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:955fd9e8-bd70-4348-a764-1cc530659f3a>","<urn:uuid:2eaf558f-bb8f-489e-9ea3-c2f57c4a8b53>"],"error":null}
{"question":"I need an urgent health check - what's the difference between dangerous anemia symptoms and dangerous blood sugar levels? Please help!","answer":"For anemia, severe symptoms include rapid/irregular heart rate, loss of consciousness, pale skin, fatigue, dizziness, and jaundice in some cases. For dangerous blood sugar levels, readings above 300 mg/dL are critically dangerous and require immediate medical attention, while levels below 50 mg/dL are dangerously low. Both conditions require medical evaluation - anemia is diagnosed through complete blood count (CBC) tests, while blood sugar can be monitored through regular glucose testing.","context":["Anemia is defined as having an abnormally decreased amount of red blood cells or haemoglobin in the blood stream, which may or may not cause symptoms. Red blood cells are essential to the human body because they contain proteins called haemoglobin, and the function of these proteins is to carry oxygen to the tissues and organs.\nRed blood cell and haemoglobin levels in the body change from birth to puberty, and it is therefore important to know that these values change throughout these years of life. In babies, the red blood cell and haemoglobin values starts off high and slowly decreases until the stage of puberty where the levels reach the ones we have in adulthood. The reason why it’s important to know that these values are different is so that a young child, with a seemingly decreased red blood cell and/or haemoglobin level, isn’t diagnosed as having anemia.\nThere are three main processes that can lead to people developing anemia. These include acute or chronic blood loss, the decreased production of red blood cells and hemoglobin, and the destruction of red blood cells (hemolysis).\nBloodloss may occur due to various reasons that include trauma resulting in internal bleeding or bleeding from injuries, heavy menstrual bleeding, and gastro-intestinal bleeding.\nGastrointestinal bleeds can be due to secondary conditions such as peptic,gastric or esophageal ulcers, colon cancer or inflammatory bowel disease.\nDecreased production of red blood cells and hemoglobin\nDeficiencies in certain minerals and elements can result in the decreased production of red blood cells and the protein haemoglobin. There are also various infections and cancers which can affect the bone marrow or kidneys where the red blood cells and proteins, needed to stimulate the production of these cells, are produced.These issues include the following:\n- A deficiency in iron or vitamin B12 and/or folate can result in iron deficiency anemia or megaloblastic anemia, respectively. These elements are either depleted from the body or not adequately absorbed by the gastrointestinal tract from the affected person’s diet.\n- Leukemia produces abnormal white cells in the bone marrow, which hampers the ability of this tissue to produce red blood cells, as well as normal white cells andplatelets.\n- Bone marrow failure can be caused by conditions that directly affect this tissue and, like leukemia does, decrease its ability to produce red blood cells.\n- Chronic kidney disease can result in the decreased production of erythropoietin, which is responsible for stimulating the production of red blood cells.\n- Chronic conditions like autoimmune disorders such as lupus and rheumatoid arthritis, and infections such as HIV can lead to decreased haemoglobin levels in the body. This is due to the fact that these conditions make it difficult for the body to absorb iron and to use stored iron to make haemoglobin.\n- Medications such as chemotherapy drugs damage stem cells in the bone marrow which are needed to produce red blood cells.\nRed blood cells with altered structures and which are destroyed cannot function properly and result in anemia. Conditions which cause these issues include the following:\n- Thalassemia, sickle cell disease and hereditary spherocytosis are red blood cell disorders where the shapes of these cells are not normal.\n- Autoimmune haemolytic anemia is a condition where the body produces proteins, called antibodies, which cause the red blood cells to rupture and expel its contents.\nSymptoms and signs\nPatients with mild forms of anemia may not experience any signs and symptoms of the condition. As the anemia gets worse, patients may experience signs and symptoms such as a pale skin and mucous membranes of the eyes and mouth, fatigue, dizziness, weakness and shortness of breath.\nIn haemolytic anemia, patients may experience jaundice (yellow discoloration of the skin and/or eyes) and they can produce dark colored urine due to the release of bile from the ruptured red blood cells. In severe cases of anemia, patients can experience a rapid and/or irregular heart rate and loss of consciousness.\nThe diagnosis of anemia is made by looking at the red blood cell and haemoglobin levels on a complete blood count (CBC) blood test. The haemoglobin level is more commonly looked at to make the diagnosis of anemia.\nThe normal adult levels of red blood cells are around 4.5 to 6 million cells per microliter of blood in men and 4 to 5 million cells per microliter in women, and the normal range for haemoglobin is between 14 to 17 grams per decilitre and 12 to 15g/dL in men and women, respectively. If these levels are below the mentioned ranges, then one would be considered to have anemia.\nOnce the diagnosis is confirmed, doctors will proceed to order further tests and investigations to determine the cause of the anemia. Additional information can be obtained from a CBC about the shape and color of the red blood cells, which will help point out some common causes. Red blood cells that are small and pale are usually caused by an iron deficiency, whereas large red blood cells may be due to a folate or vitamin B12 deficiency. Normal shaped red blood cells in the presence of a low haemoglobin level could be caused by chronic inflammatory condition and infections.\nA peripheral blood smear will also be performed where the blood is physically looked at to determine if there are any other abnormalities present. The shape, size and number of these red blood cells will also help determine the cause of the anemia.\nIf a cause is still not discovered, then a bone marrow biopsy may have to be done to see if there are any abnormalities in this region.\nThe management of anemia will depend on the cause of the condition. Therefore, just as there are many causes of the condition, there will be many ways in which it can treated as well.\nAnemias caused by the mentioned deficiencies can be managed by supplementing these minerals and vitamins, or by treating any underlying intestinal condition affecting their absorption. Severe iron deficiency anemias may be managed by intravenous blood transfusions, as can anemia due to acute or chronic blood loss. The administration of erythropoietin is performed in patients with chronic kidney disease.\nAnemia caused by cancers such as leukemia will have to be managed with chemotherapy medications. Bone marrow transplantation will have to be considered if the bone marrow is affected.\nSurgical removal of the spleen is performed in patients diagnosed with some haemolytic anemias, and steroids are administered to patients with autoimmune haemolytic anemia.\nIn the case of chronic infections causing the anemia, these underlying causes will need to be controlled in order to help address the anemia.\nArticle by David Broom","What is a blood sugar chart?\nA blood sugar chart or blood glucose chart or blood sugar level chart identifies ideal blood sugar levels in your body throughout the day, including before meals and after meals. If you need to keep track of your blood sugar levels, particularly when you are diabetic, during the day or over a period of weeks or months, you can use a blood sugar chart as a reference.\nThe blood glucose chart is also known by many other names such as diabetes chart, low blood sugar levels chart, high blood sugar level chart, blood sugar levels chart by age, diabetic blood sugar chart, normal blood sugar levels chart, etc.\nWhy is it important to monitor my blood sugar levels (blood glucose levels)?\nTracking blood sugar is important for anyone who is suffering with diabetes or who is at risk of diabetes mellitus. Your blood sugar levels also called blood glucose levels change throughout the day. It is therefore important to monitor them and keep in mind exactly what your targets should be to make sure that you adhere to the guidelines and maintain ideal blood sugar levels.\nYou can use a blood sugar level chart as a healthy blood sugar level reference when you wake up, when you got o bed, when you are going to have a meal, and after you have taken a meal.\nYou or your doctor can use blood sugar level charts to specify target goals and monitor how well your diabetes treatment is going. Blood sugar charts also help those with diabetes review the blood sugar test results.\nOther benefits of using blood sugar charts and blood sugar level charts are:\n- A diabetic chart helps keeping blood sugar levels as close to normal as possible to the set target goals\n- Comparing your at home test results of blood sugar with blood sugar chart as a reference for monitoring the levels\n- Understand normal, ideal, and abnormal blood sugar levels for those with and without diabetes\n- A1C blood sugar recommendations are also mostly included in blood sugar charts. An A1C test measures the average sugar levels over a 3-month period. This gives a better insight into overall health of a person with respect to the blood sugar levels.\n- Diabetic charts or blood sugar charts are important tools for your diabetes management\nBlood sugar chart or Blood sugar level chart\n|When to check||Blood sugar levels for people without diabetes||Blood sugar levels for people with diabetes|\n|Fasting (before breakfast)||less than 100 mg/dL||80 - 130 mg/dL|\n|Before meals||less than 110 mg/dL||70-130 mg/dL|\n|2 hrs after meal\n1-2 hrs after meal\n|less than 140 mg/dL||less than 180 mg/dL|\n|Bedtime||less than 120 mg/dL||90 - 150 mg/dL|\n|A1C levels||less than 5.7 percent||less than 7 percent|\nInterpreting your blood sugar test results\nIdeals blood sugar levels may vary from person to person slightly. A good blood sugar level for one person may be too high or too low for someone else. For people with diabetes, though, some ranges of blood sugar levels are specified as are preferable over others.\n|Blood sugar levels||Excellent||Good||Acceptable|\n|Before meal||72 - 109 mg/dL||110 - 144 mg/dL||145 - 180 mg/dL|\n|2 hours after meal||90 - 126 mg/dL||127 - 180 mg/dL||181 - 234 mg/dL|\nBlood sugar level recommendations for gestational diabetes\nCertain temporary forms of diabetes such as gestational diabetes have different recommendation. The blood glucose chart for them is:\n|When to check||Blood sugar levels in mg/dL|\n|Fasting or before breakfast||60 - 90 mg/dL|\n|Before meals||60 - 90 mg/dL|\n|1-2 hours after meal||100 - 120 mg/dL|\nDangerous levels of blood sugar (blood glucose)\nThere are certain ranges beyond which one should be concerned about, as these are considered as dangerous blood sugar levels or dangerous blood glucose levels. The risk level increases with these sugar levels in the blood. This blood glucose chart can be used as a reference for risk assessment.\n|Fasting blood sugar levels||How dangerous it is (Risk) Risk level||What to do?|\n|50 mg/dL or less||Dangerously low||Seek medical attention|\n|70 - 90 mg/dL||Possibly too low||Consume sugar if you are experiencing symptoms of low blood sugar or meet a doctor|\n|90-120 mg/dL||Normal range||No action needed|\n|120-160 mg/dL||Medium||Meet a doctor|\n|160 - 240 mg/dL||Too high||Need to lower your blood sugar levels|\n|240-300 mg/dL||Too high||It is a sign of uncontrolled diabetes. Meet a doctor at the earliest.|\n|300 mg/dL or above||Very high. Critically Dangerous.||Emergency. Seek immediate medical attention.|\nAIC Numbers and blood glucose levels\nAnother way to understand your blood sugar is through the A1C test, An A1C lets you know where your glucose levels have been on average, over the last three months or other time frames.\nA1C is a protein in red blood cells, and it binds with glucose. Since the red blood cells have a lifespan of about three to four months, the amount of blood sugar A1C collects can tell us about the average of your blood glucose levels.\nThe A1C percentage can be translated into other forms of readings based on the following blood sugar chart (diabetic chart).\nHow to translate A1C numbers into blood glucose levels\n|A1C (%)||Blood Sugar Levels (mg/dl)|\nTesting your blood sugar and Monitoring blood sugar levels\nMonitoring blood sugar levels is important for management of diabetes. It includes both self-monitoring at home and doctor-ordered tests, such as A1C tests.\nYou should track blood sugar level changes daily if you are diabetic and help your doctors understand what treatment plans are working or not working for you. This will help him or her adjust medications or set goals.\nHow frequent you should test the blood sugar varies according to your treatment plan and the type of diabetes you have. Here is how frequently you should test the blood sugar.\nType 1 diabetes in adults\nAt least twice daily and up to 10 times.\nTests should be done before breakfast, at fasting, before meals, 1-2 hours after meals, before and after physical activities or exercises, and when going to bed.\nType 1 diabetes in children\nAt least four times daily.\nTests should be done before having meals and when going to bed. Tests may also be required 1-2 hrs after meals, before and after exercise, and overnight.\nType 2 along with insulin or other medication going on\nThe frequency of tests varies depending on your insulin dosage and any other medicines you are taking.\nIf you are on intensive insulin medication, you should do tests at fasting, before meals, before bedtime, and sometimes in the night if needed. Those on usual insulin and additional medications dosage should at least perform the tests at fasting (before breakfast) and bedtime.\nThose not on insulin but oral medications or diet control do not require frequent blood sugar testing at home.\nType 2 diabetes and low risk of low blood sugar\nDaily tests are not usually required. If blood sugar goals or A1C levels are not met on a regular basis, the frequency of testing can be increased until the levels are back within normal ranges.\nIf you are on insulin, tests should be done at fasting, before meals and 1 hour after meals. If you aren’t on insulin, you should perform tests at fasting and 1 hour after meals."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:0879f53f-7241-44d0-aa33-dccfd6f23dc8>","<urn:uuid:692e1775-d7ac-4480-a9fe-35e78219acf6>"],"error":null}
{"question":"Which came first chronologically: the development of the clarinet by Denner or the establishment of professional musicians in ancient Egypt?","answer":"Professional musicians in ancient Egypt were established much earlier, around 3100 BCE during the pharaonic period, when music became an important part of Egyptian life and society had different classes of musicians for various occasions. In contrast, the clarinet was developed much later, around 1700-1704 CE by Johann Christoph Denner, representing a time difference of nearly 5000 years.","context":["==The History of the Clarinet== About 2700 B.C., the Egyptians created an instrument called the zummara (sometimes referred to as the memet). The zummara was a single-reed instrument, much like the modern day clarinet, but it had a double bore like the double-reeded Greek instrument aulos. The zummara’s two pipes were parallel so that with each finger the player covered two holes, one on each pipe. The pipes were said to be out of tune with each other and produced a very dissonant beating sound.\nInvented around 1690, the clarinet is a single-reed woodwind instrument with a cylindrical tube. The clarinet evolved from an earlier instrument called the chalumeau, the first true single reed instrument. Johann Christoph Denner of Nuremberg with the help of his son Jacob improved the chalumeau, creating a new instrument called the clarinet. Denner added two keys to the chalumeau and increased that instruments range by over two octaves. He also created a better mouthpiece and improved the bell (end) of the instrument. In India, there was an instrument people now call the double-clarinet but in India it was called the pungi or the magudi. The difference between this instrument and the zummara was that the reed was enclosed in a wooden chamber and the left-hand pipe was drone, and the right-hand pipe was melodic.\nSingle reed instruments of this type have been found in many cultures throughout the world, as it is a simple way of producing sound. The reeds are called idioglot reeds and are cut out of part of the instrument that is placed inside the mouth to sound. A simple way of reconstructing one of these idioglot reeds is to cut a small triangular slit in a straw, when this is placed in the mouth it produces a buzzing sound. Instruments with these idioglot reeds are first mentioned in dictionaries in France in the Sixteenth century (for example Estienne (1511)) and are described in more detail in the Seventeenth Century treatises of Mersenne and Trichet.\nThe man universally credited for actually inventing, or making, the clarinet was Johann Christoph Denner (1655-1707) with the help of his son, Jacob, of Nuremberg, Germany. J.C. Denner was well-known and well-respected for the high quality woodwind instruments he made. Denner was said to have a creative mind; he toyed with the instruments he so finely crafted and it would seem the clarinet was the result of such tinkering. There is no documented proof that Denner alone developed the clarinet since two of his contemporaries, Klenig and Oberlender, also made clarinets.\nHowever, it must also be mentioned that (apart from a single instrument at Berkley whose attribution is much disputed) there are no extant clarinets by J.C.Denner, only chalumeaux.\nScholars first believed the clarinet was developed around 1690, but further research has lead scholars and music historians to believe it was developed around 1701-1704. It is also believed the clarinet was first called a mock trumpet. There is a music book discovered by a scholar, Thurston Dart, for mock trumpet which was published in 1698, and this was followed by three similar volumes throughout the next decade. Doubt still remains about who made the clarinet and how.\nThe accepted hypothesis is that Denner crafted the clarinet, and he did so sometime around 1700. J.G. Doppelmayr, a contemporary of Denner, wrote a Report on the Mathematicians and Artisans of Nuremberg in 1730, twenty-three years after Denner’s death. The report indicates Denner developed the clarinet a little after 1700. Before this historical text was discovered, historians and scholars only had a piece written in 1778 by C.G. Murr, \"Description of the Distinguished Features of Nuremberg,\" wherein Murr wrote that Denner created the clarinet in 1690.\nWhat made the clarinet a clarinet was Denner's great improvement to the old chalumeau. The usual material used for early examples of both instruments is boxwood (a common material in instrument making) with a heteroglot reed (that is separate to the instrument)tied to the upper side of the mouthpiece therefore vibrated by the upper lip . To change the chalumeau to a clarinet he added a 'speaker key' (also known as the register key) causing the instrument to over-blow , creating a new and higher register for the instrument. This register is known as the clarino register (a reference to a style of trumpet playing) and is thought to be the origin of the name of the instrument. Many modern clarinettists still refer to the overblown register of the clarinet as the clarino register, and to the lower register as the chalumeau.\nAcoustically the clarinet acts like a closed cylindrical tube and overblows at the twelfth. He also equipped it with a bell by enlarging the bore.The mouthpiece and barrel joint are made in one piece and, with Denner's additional key the earliest clarinets are two-keyed instruments. Extant chalumeaux have single keys at the front of the instrument.\nThe Clarinet's Early DaysEdit\nThere is no mention of the name clarinet until 1690, right after Denner made the first playable clarinet. In this year, the Graf (Duke) of Gronsfeld in Nuremberg ordered two clarinets from Jacob Denner for the use of his musicians. In 1712, four clarinets that were made out of boxwood were bought by the Nuremberg Town band (Ratsmusik). Since Denner worked in Nuremberg and that’s where they first appeared in the band, it is said that Denner gave the instrument its name.\nHistory of the clarinet from 1680-1751Edit\nThe history of the clarinet is a long history beginning in 1690. During that year a man named Johann Cristoph Denner invented the clarinet. These clarinets only had two keys that were mostly made from brass along with the springs. The clarinet however was made from boxwood, plum, ebony, ivory or pear. Around 1700 he added the register key to his instrument. In 1740 a third key was added ableing the players to play low E. Nine years later a man named Rameau uses the clarinet in his opera in Paris. Shortly after in 1750 Barthold Fritz added the 4th & 5th key to the clarinet. The clarinet is introduced to London by Bach in 1751.","Music has been an integral part of Egyptian culture since antiquity. The Bible documents the instruments played by the ancient Hebrews, all of which are correlated in Egyptian archaeology. Egyptian music probably had a significant impact on the development of ancient Greek music, and via the Greeks was important to early European music well into the Middle Ages. The modern music of Egypt is considered Arabic music as it has been a source for or influence on other regional styles. The tonal structure of Arabic music is defined by the maqamat, loosely similar to Western modes, while the rhythm of Arabic music is governed by the iqa'at, standard rhythmic modes formed by combinations of accented and unaccented beats and rests.e your paragraph here.\nMusic was as important to the ancient Egyptians as it is in our modern society. Although it is thought\nthat music played a role throughout the history of Egypt, those that study the Egyptian writings have\ndiscovered that music seemed to become more important in what is called the ‘pharaonic’ period of\ntheir history. This was the time when the Egyptian dynasties of the pharaohs were\nestablished (around 3100 BCE) and music was found in many parts of every day Egyptian life.\nAncient Egyptians had a number of professional musicians that performed for many occasions.\nSince their society was set up with social levels, this meant that different musicians could play only\nfor specific events. A musician with a high status could play for religious ceremonies at the temples,\nwhere a lower class musician might only be able to play for regular community members.\nThe highest honor to achieve was the status of ‘shemayet’, which gave these musicians the\nability to play for a particular god or goddess and these musicians were mostly women.\nThe ancient Egyptians were very organized and this included how they organized and arranged music\nand musicians. They brought music to their religious ceremonies, but it was also played and\nperformed in workshops, palaces, the farms, on the battlefield and even in their tombs.\nThe Egyptian gods Hathor and Bes were their gods of music and they had many ceremonies\ndevoted to them that involved song and dance to accompany the playing of musical instruments\nThe ancient Egyptians credited the goddess Bat with the invention of music. The cult of Bat was eventually syncretised into that of Hathor because both were depicted as cows. Hathor's music was believed to have been used by Osiris as part of his effort to civilize the world. The lion-goddess Bastet was also considered a goddess of music.\nIn prehistoric Egypt, music and chanting were commonly used in magic and rituals. Rhythms during this time were ovular and music served to create rhythm. Small shells were used as whistles.(pp26–30)\nDuring the predynastic period of Egyptian history, funerary chants continued to play an important role in Egyptian religion and were accompanied by clappers or a flute. Despite the lack of physical evidence in some cases, Egyptologists theorize that the development of certain instruments known of the Old Kingdom period, such as the end-blown flute, took place during this time.(pp33–34)\nThe evidence is for instruments played more securely attested in the Old Kingdom when harps, flutes and double clarinets were played. Percussion instruments and lutes were added to orchestras by the Middle Kingdom. Cymbals frequently accompanied music and dance, much as they still do in Egypt today.\nTypically ancient Egyptian music was composed from the phrygian dominant scale, phrygian scale, double harmonic scale (Arabic scale) or lydian scale. The phrygian dominant scale may often feature an altered note or two in parts to create tension. For instance the music could typically be in the key of E phrygian dominant using the notes E, F, G sharp, A, B, C, D and then have an A sharp, B, A sharp, G natural and E to create tension.\nArabic music is usually said to have begun in the 7th century in Syria during the Umayyad dynasty. Early Arabic music was influenced by Byzantine, Indian and Persian forms, which were themselves heavily influenced by earlier Greek, Semitic, and ancient Egyptian music.\nEgyptians in Medieval Cairo believed that music exercised \"too powerful an effect upon the passions, and leading men into gaiety, dissipation and vice.\" However, Egyptians generally were very fond of music. Though, according to E.W. Lane, no \"man of sense\" would ever become a musician, music was a key part of society. Tradesmen of every occupation used music during work and schools taught the Quran by chanting.(p359)\nThe music of Medieval Egypt was derived from Greek, Persian and Indian traditions. Lane said that \"the most remarkable peculiarity of the Arab system of music is the division of tones into thirds,\" although today Western musicologists prefer to say that Arabic music's tones are divided into quarters. The songs of this period were similar in sound and simple, within a small range of tones. Egyptian song, though simple in form, is embellished by the singer. Distinct enunciation and a quavering voice are also characteristics of Egyptian singing.(pp360–361)\nMale professional musicians during this period were called Alateeyeh (plural), or Alatee (singular), which means \"a player upon an instrument\". However, this name applies to both vocalists as well as instrumentalists. This position was considered disreputable and lowly. However, musicians found work singing or playing at parties to entertain the company. They generally made three shillings a night, but earned more by the guests giving more.\nFemale professional musicians were called Awalim (pl) or Al’meh, which means a learned female. These singers were often hired on the occasion of a celebration in the harem of a wealthy person. They were not with the harem, but in an elevated room that was concealed by a screen so as not to be seen by either the harem or the master of the house. The female Awalim were more highly paid than male performers and more highly regarded than the Alateeyeh as well. Lane relates an instance of a female performer who so enraptured her audience that she earned to fifty guineas for one night's performance from the guests and host, who were not considered wealthy.\nModern Egyptian classical and pop music\nEgyptian music began to be recorded in the 1910s, when Egypt was still part of the Ottoman Empire. The cosmopolitan Ottomans encouraged the development of the arts, encouraging women and minorities to develop their musical abilities. By the fall of the Empire, Egypt's classical musical tradition was already thriving, centered on the city of Cairo. In general, modern Egyptian music blends its indigenous traditions with Turkish, Arabic, and Western elements.\nSince the end of World War I, some of the Middle East's biggest musical stars have been Egyptian. Contemporary Egyptian music traces its beginnings to the creative work of luminaries such as Abdu-l Hamuli, Almaz and Mahmud Osman, who were all patronized by the Ottoman Khedive Ismail, and who influenced the later work of the 20th century's most important Egyptian composers: Sayed Darwish, Umm Kulthum, Mohammed Abdel Wahab, Abdel Halim Hafez, and Zakariyya Ahmad. Most of these stars, including Umm Kulthum and Najat Al Saghira, were part of the classical\nReligious music in Egypt\nReligious music remains an essential part of traditional Muslim and Coptic celebrations called mulids. Mulids are held in Egypt to celebrate the saint of a particular church. Muslimmulids are related to the Sufi zikr ritual. The Egyptian flute, called the ney, is commonly played at mulids. The liturgical music of the Alexandrian Rite also constitutes an important element of Egyptian music and is said to have preserved many features of ancient Egyptian music.\nLute and double pipe players from a painting found in the Theban tomb of Nebamun, a nobleman of the 18th Dynasty of the New Kingdom, c. 1350 BC\nEgyptian folk music, including the traditional Sufi dhikr rituals, are the closest contemporary music genre to ancient Egyptian music, having preserved many of its features, rhythms and instruments.\nFolk and roots revival\nThe Egyptians even used their own teeth as instruments they would make tapping noises and would use special plucks to make interesting noises with their teeth. The 20th century has seen Cairo become associated with a roots revival. Musicians from across Egypt are keeping folk traditions alive, such as those of rural Egyptians (fellahin), the Nubians, the Arabs, the Berbers, the Gypsiesand the Bedouins. Mixtures of folk and pop have also risen from the Cairo hit factory.\nSince the Nasser era, Egyptian pop music has become increasingly important in Egyptian culture, particularly among the large youth population of Egypt. Egyptian folk music continues to be played during weddings and other traditional festivities. In the last quarter of the 20th century, Egyptian music was a way to communicate social and class issues. Among some of the most popular Egyptian pop singers today are Mohamed Mounir and Amr Diab.\nSawahli (coastal) music is a type of popular music from the northern coast, and is based around the simsimiyya, an indigenous stringed instrument. Well-known singers include Abdo'l Iskandrani and Aid el-Gannirni.\nSaidi (Upper Egyptian)\nEgyptian musicians from Upper Egypt play a form of folk music called Ṣa‘īdi (Upper Egyptian). Metqal Qenawi's Les Musiciens du Nil are the most popular saidi group, and were chosen by the government to represent Egyptian folk music abroad. Other performers include Shoukoukou, Ahmad Ismail, Omar Gharzawi, Sohar Magdy and Ahmed Mougahid.\nNubians are native to the south of Egypt and northern Sudan, though many live in Cairo and other cities. Nubian folk music can still be heard, but migration and intercultural contact with Egyptian and other musical genres have produced new innovations. Ali Hassan Kuban's efforts had made him a regular on the world music scene, while Mohamed Mounir's social criticism and sophisticated pop have made him a star among Nubians, Egyptians, and other people worldwide. Ahmed Mounib, Mohamed Mounir's mentor, was by far the most notable Nubian singer to hit the Egyptian music scene, singing in both Egyptian Arabic his native Nobiin. Hamza El Din is another popular Nubian artist, well-known on the world music scene and has collaborated with the Kronos Quartet.\nWestern classical music\nWestern classical music was introduced to Egypt, and, in the middle of the 18th century, instruments such as the piano and violin were gradually adopted by Egyptians. Opera also became increasingly popular during the 18th century, and Giuseppe Verdi's Egyptian-themed Aida was premiered in Cairo on December 24, 1871.\nBy the early 20th century, the first generation of Egyptian composers, including Yusef Greiss, Abu Bakr Khairat, and Hasan Rashid, began writing for Western instruments. The second generation of Egyptian composers included notable artists such as Gamal Abdelrahim. Representative composers of the third generation are Ahmed El-Saedi and Rageh Daoud. In the early 21st century, even fourth generation composers such as Mohamed Abdelwahab Abdelfattah (of the Cairo Conservatory) have gained international attention.\nAncient Egyptians Music"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:18e3ead8-de03-4399-9d22-c48064fe9813>","<urn:uuid:865ceb5b-33d9-4021-ae3d-e88a53e20ffb>"],"error":null}
{"question":"What is the main difference between senior loans and Treasury bonds in terms of maturity and risk profile?","answer":"Senior loans and Treasury bonds have distinct risk and maturity profiles. Senior loans are made to companies with below investment grade ratings and are secured by collateral, making them riskier than investment-grade corporate bonds but slightly less risky than high-yield bonds. Treasury bonds, on the other hand, are among the safest investments and have much longer maturities of 20 and 30 years. While senior loans have floating rates that adjust based on LIBOR, Treasury bond prices fluctuate to maintain yields linked to market prices, with longer-maturity bonds experiencing greater price fluctuations.","context":["All About Senior Loans\n5 Things Investors Should Know\nSenior loans—also referred to as leveraged loans or syndicated bank loans—are loans that banks make to corporations and then package and sell to investors. This asset class exploded in popularity in 2013, when its outperformance in a weak market caused senior loan funds to attract billions in new assets even as the broader bond fund category experienced massive outflows. Here's what you should know about senior loans.\nSenior Loans Are Secured by Collateral\nSenior loans are so named because they are at the top of a company’s “capital structure,” meaning that if the company were to fail, investors in senior loans are the first to be repaid. As a result, senior-loan investors typically recover much more of their investment in a default. Senior loans are typically secured by collateral such as property, which means they are considered to be less risky than high-yield bonds.\nThese types of loans are typically made to companies with ratings below investment grade, so the level of credit risk (i.e., the degree to which changes in the issuers’ financial condition will affect bond prices) is comparatively high. In a nutshell, Senior loans are riskier than investment-grade corporate bonds but slightly less risky than high-yield bonds.\nIt’s important to keep in mind that valuations in this market segment can change quickly. From August 1 to August 26, 2011, the share price of the largest exchange-traded fund (ETF) that invests in the asset class, the Invesco Senior Loan Portfolio (ticker: BKLN), fell from $24.70 to $22.80 in just 20 trading sessions—a loss of 7.7%. Bank loans also fell sharply during the financial crisis of 2008. In other words, just because the bonds are “senior” doesn’t mean that they aren’t volatile.\nSince the majority of these senior bank loans are made to companies rated below investment-grade, the securities tend to have higher yields than a typical investment-grade corporate bond. At the same time, the fact that owners of bank loans will be paid back ahead of bond investors in the event of bankruptcy means that they typically have lower yields than high yield bonds. In this way, senior loans are between investment-grade corporate bonds and high yield bonds on the spectrum of risk and expected yield. High yield bonds are often called \"junk bonds.\"\nA compelling aspect of bank loans is that they have floating rates that adjust higher based on a reference rate such as the London Interbank Offered Rate, or LIBOR. Typically, a floating rate note will offer a yield such as “LIBOR + 2.5%”—meaning that if LIBOR were 2%, the loan would offer a yield of 4.5%. The rates on bank loans typically readjust at fixed intervals, usually a monthly or quarterly basis.\nThe benefit of the floating rate is that it provides an element of protection against the rising short-term interest rates. (Keep in mind, bond prices fall when yields rise). In this particular way, they function similarly to TIPS (Treasury Investor-Protected Securities, providing some protection against inflation. In consequence, floating-rate securities perform better in an environment of rising rates than plain-vanilla bonds. The combination of higher yields and low rate sensitivity has helped make senior loans an increasingly popular segment for investors.\nHowever, it's also important to keep in mind that the yields on senior loans DO NOT move in tandem with Treasuries, but rather with LIBOR—a short-term rate similar to the fed funds rate.\nSince senior loans tend to be less rate-sensitive than other segments of the bond market, they can provide a degree of diversification in a standard fixed-income portfolio. Bank loans have very low correlations with the broader market and a negative correlation with U.S. Treasuries—meaning that when government bond prices go down, senior loan prices are likely to go up (and vice versa).\nAs a result, the asset class provides investors with a way to pick up yield and potentially dampen the volatility of their overall fixed income portfolio. This represents true diversification—an investment that can help fulfill a goal (income) and yet move in a largely independent fashion from other investments in your portfolio.\nHow to Invest in Senior Loans\nWhile individual securities can be purchased through some brokers, only the most sophisticated investors—those able to do their own intensive credit research—should attempt such an approach. Fortunately, there are plenty of mutual funds that invest in this space, a full list of which is available online. In addition, the Invesco Senior Loan Portfolio—the ETF mentioned previously—provides access to this asset class, as do SPDR Blackstone/GSO Senior Loan ETF (SRLN), Highland/iBoxx Senior Loan ETF (SNLN), and First Trust Senior Loan ETF (FTSL).\nThe Balance does not provide tax, investment, or financial services and advice. The information is being presented without consideration of the investment objectives, risk tolerance, or financial circumstances of any specific investor and might not be suitable for all investors. Past performance is not indicative of future results. Investing involves risk including the possible loss of principal.","CBOT Financial Futures T-bonds and T-Notes\nEurodollar Futures Treasury Bond Futures Treasury Note Futures\nIntroduction to Treasuries\nCentral banks like the U.S. Federal Reserve help shape short- and long-term economic growth by restricting or expanding the supply of money circulating in an economy. They do this through the use of debt obligations called treasuries -- such as bills, notes and bonds – in which the government borrows money from the holder for a specified period of time. Because treasuries are viewed as being among safest of all investments, they can be in high demand.\nTreasury futures offer one way to gain exposure without trading the individual securities themselves. Learn the basics behind trading Treasury futures, from the delivery process, contract specifications, key concepts like basis and Cheapest to Deliver (CTD) and more. Discover the different ways these contracts are used, from price discovery to risk management to profit speculation, and how they are intertwined with other financial markets like stocks and currencies.\nTrading Interest Rates Markets\nIt’s the glue. Interest rate markets bind and are tethered to every other financial asset class from stocks to currencies. The US Federal Reserve Bank and other central banks around the globe shape and push economic growth in the short and long term. Central bank moves can tighten or expand the amount of money circulating in an economy, which then impacts the value of a currency, which then affects the value of commodities and companies – across the globe.\nSo you can see the power the Fed has on US markets and beyond. Interest rate futures and options contracts may be used to hedge against risks that can adversely affect portfolios or balance sheets. Yet, they also provide trading and spreading opportunities across many different markets for traders and can be some of the deepest and most liquid futures markets in the world.\nThese markets are primarily event-driven , meaning participants are looking for opportunities and risks in every Fed meeting, announcement, Fed speech or testimony, not to mention key economic reports from employment rates to manufacturing data.. This allows traders to go long or short across the yield curve, from 3-month Eurodollar futures and up the line to 2-year, 5-year, 10-year notes along with 30-year Treasury bond futures and Ultra Treasury bond futures.\nThere are two main differences between these three types of U.S. Treasuries, maturity dates and the way they pay interest.\nTreasury note Futures:\nTreasury notes are issued with maturities of one, three, five, seven, and 10 years, while Treasury bonds (also called “long bonds” and “t-bond”) offer maturities of 20 and 30 years. The only difference between notes and bonds is the length until maturity. The 10-year is the most widely followed of all maturities; it is used as both the benchmark for the Treasury market and the basis for banks’ calculation of mortgage rates.\nTreasury bond Futures:\nOnce T-notes and T-bonds are issued, their prices fluctuate so their yields remain linked to market prices. For example, say the government issues a 30-year bond with a yield of 10% when interest rates are high. In the next 15 years, prevailing rates fall significantly and new long bonds are being issued at 5%. Investors will no longer be able to buy the older T-bond and still receive a yield of 10%; instead, its yield to maturity will fall and its price will rise. In general, the longer the time there is until the bond matures the greater price fluctuation it will experience. In contrast, T-bills experience very little in the way of price fluctuation since they mature in such a short amount of time.\nT Bond futures represent the 30-year maturity on interest rates, which help set rates on home mortgages, among other things.\nOriginally launched in 1977, this contract allows individual traders, banks and institutions to hedge long-term risk as well as profit from shifts in the interest rate markets. The Federal Reserve Bank may have a stronger impact on shorter term rates with its policy moves, but that ripples down to the 30-year bonds as well. Classic T-bond futures carry a remaining maturity of at least 15 years but not more than 25 years, which differ from Ultra T-bonds, which have a remaining maturity of at least 25 years but not more than 30 years.\n30-year Treasury bond futures are among the most liquid and deep interest rate markets in the world, allowing traders efficient ways to enter and exit trades. The contracts are also available to trade virtually 24-hours per day.\nAbout WebOE / Mobile Trader / Open Account / Joss Report / WebOE / Simulated Trading / News / Charts Quotes / Tools / Option Quotes / Seasonal Charts / Interactive Charts /About futures Products / Futures 101 / Options 101 / Technical Analysis / Fundamental Analysis / Contract Specs / Trading Rules"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:e8486c93-bf67-4c5c-a79c-548d1d3ed895>","<urn:uuid:bd5a9d80-65a4-47c2-bb24-5733b2306872>"],"error":null}
{"question":"Compare economic impacts: ancient Olympic sacrifices vs modern Olympic housing crisis?","answer":"While the ancient Olympics involved economic costs through ritual sacrifices like the 100 bulls offered to Zeus, modern Olympics create far more severe economic burdens through housing crises. The ancient games' economic impact was largely ceremonial and religious in nature. In contrast, modern Olympics, as seen in Los Angeles, create widespread housing problems including rent spikes, forced evictions, and reductions in affordable housing. This is evidenced by LA's current development priorities shifting toward hotels rather than affordable housing, with projects like 'The Fig' displacing families from rent-stabilized units to build hotels for the 2028 Games. Studies show these housing impacts consistently affect host cities, making the modern economic impact more systemically damaging to local populations than the ancient games' ceremonial costs.","context":["April 2021 Alumni Spotlight\nAlumna and Senior Policy Analyst at Coalition for the Homeless, Jacquelyn Simone is an advocate for the homeless in New York City. In this spotlight, she discusses the challenges of the pandemic on the homelessness crisis, the obstacles of hostile architecture and over-policing, the psychology behind how we think of the homeless, and more.\nHow have you made use of the skills you learned at the Marxe School to help advocate for homeless New Yorkers during the pandemic?\nNew York City was already facing a historic homelessness crisis prior to the pandemic, but the past year has posed a host of new challenges for New Yorkers without homes. Homeless people are particularly vulnerable to COVID-19 — in congregate shelters or on the streets, it is difficult to follow basic public health guidance like social distancing and washing your hands. It has been critically important to ensure elected officials and members of the public understand the risks facing homeless New Yorkers and act swiftly to protect them. The Marxe School gave me the skills to analyze and effectively communicate the disproportionate toll the pandemic has had on homeless New Yorkers in a chaotic time. Most importantly, I have shared the lessons and skills I learned at the Marxe School with people who are experiencing homelessness, to demystify government systems and empower them to speak out about their firsthand experiences through op-eds, public testimony, and engaging with elected officials.\nAre there any environments or features in New York City that are particularly hostile to the homeless? Is it possible to reduce or eliminate any to better accommodate the homeless while keeping public spaces safe?\nHostile architecture and over-policing are designed to make allegedly public spaces less welcoming to members of the public who happen to be without homes. Most homeless people in New York City reside in shelters rather than on the streets or in the transit system, and in fact many people who are essential workers are homeless due to the skyrocketing cost of housing in the city. Meanwhile, the several thousand New Yorkers who do sleep in the transit system or on the streets often encounter barriers designed to make their lives as uncomfortable as possible — from bars on benches to prevent people from lying down, to the nightly closure of the subways, and much more. These features and policies treat witnessing homelessness as an inconvenience for people who are fortunate enough to have homes, rather than recognizing the trauma of homelessness for the people who are actually living without shelter. If we want to reduce the number of people sleeping on the trains and on the streets, we need to give them a better, safer option by offering them permanent housing. Otherwise, we are just moving the problem out of sight instead of addressing the root causes of homelessness.\nCan you talk a bit about the psychology of how we typically think of the homeless and how that translates to the sociology of how we treat them?\nThere is a common tendency to pathologize poverty, or assume that someone is homeless due to individual mistakes or characteristics. In reality, homelessness is a manifestation of intersecting systems of oppression that have made some people — disproportionately people of color — more likely to fall through our tattered social safety net. Viewing poverty and homelessness as the result of personal failings allows the rest of us to ignore the issue and our own role in perpetuating and benefiting from unjust systems. But if we recognize the systemic drivers of homelessness, we can marshal the political will and resources to actually do something about it — by investing in permanent, affordable housing as a basic human right and by removing barriers to support services.\nWhat are the biggest barriers to getting the homeless into – and keeping them in shelters?\nNew York City has a right to shelter, which is an essential component of the safety net. However, many homeless New Yorkers avoid the shelter system for rational reasons, such as not feeling safe in dorm-style facilities especially during the pandemic. It is important that we look at what services we are currently offering people, and listening to what they actually want and need. For example, many people who are not interested in going to a congregate shelter would gladly accept a single-occupancy hotel room where they can have more privacy and practice social distancing, but this option is not being offered universally to everyone on the streets. Ultimately, people want a home of their own, but the shortage of truly affordable housing and unnecessary bureaucratic barriers in accessing housing resources have left people on the streets. We must adopt a true housing first model, in which we offer everyone the dignity and stability of permanent housing along with support services as needed.\nWhat got you interested in this human issue?\nI moved to New York City in 2011 and worked as a journalist for a few years, but I was shocked and heartbroken by the scale of homelessness I saw around the city. I refused to accept that such a wealthy city, in such a wealthy country, would leave thousands of people without the basic necessity of housing. I started volunteering with various charities in my spare time and ultimately decided to make a career change to work on addressing homelessness. The Marxe School gave me the skills I need to be an effective advocate for people experiencing homelessness. We cannot just accept or become inured to the suffering of our neighbors — we need to fight for a better, more equitable society.","Behind Los Angeles’ Bitter War to Abolish the Olympics for Good\nThe ancient Olympics were abolished for corruption. A Los Angeles group called NOlympics is part of a global movement trying to end them again.\nIn the days of ancient Greece, when city-states were constantly at each other's throats, the Olympic Games were said to bring peace. As the story goes, the ancient tournament occasioned a truce where Athens, Sparta, and the rest would pause from decapitating and doing war to sit down for a nice naked race, a lively round of pankration, or a ritual sacrifice of 100 bulls on the Great Altar of Zeus.\nLike most Olympic legends, however, the truce was mostly myth, born long after the ancient games ended. In truth, there was a peace agreement, but it didn’t amount to much. The ancient Olympics were rife with scandal, bribery, doping, and outright war. In one particularly unfortunate incident, invaders crashed the final event of the pentathlon and turned a wrestling match into a battlefield, with rooftop archers and 5,000 troops clashing in hand-to-hand combat. By A.D. 393, the Games were abolished for corruption.\nThe myth of the Olympic truce lasted well into modernity. The Games were revived in 1896, when Greek poet Panagiotis Soutsos published a poem called “Dialogue With the Dead,” calling on his country to bring back the competition as a way to restore national pride. Over the past 123 years, they have operated in a similar mode: hailed as a kind of global team-building exercise—encouraging unity where there might otherwise be strife; celebrating gold and silver rather than killing for them.\nFor a brief moment in 2018, for example, some posited the PyeongChang Games could dissolve the conflict between North and South Korea. And organizers for the 2020 Olympics in Tokyo dubbed it the “Recovery Games,” claiming the competition’s resources would help Japan recover from the 2011 earthquake and the fallout of Fukushima. Neither prediction bore out—the DMZ is still lined by guards and some of the 2020 competition will take place in areas highly contaminated by nuclear waste. The irony of the Olympic truce myth may be best illustrated by a June op-ed in the Los Angeles Times: “For a more peaceful vision of the future, look to the Olympics.” The author was Henry Kissinger.\nThe Kissinger article came at a moment of heightened Olympic-related tension in Los Angeles. The 2028 Games were awarded to the city two years ago in a controversial and unprecedented move–one which will stretch preparation out over the next decade. For an organization called NOlympics, born out of the L.A. chapter of the Democratic Socialists of America, that distant arrival poses a major risk for the city—a place already struggling with a homelessness crisis, rabid gentrification, and one of the most notorious police forces in the country. The Games, they claim, will displace marginal populations, further militarize law enforcement, and redirect city resources towards the interests of a wealthy few. The president of L.A.’s Olympic Organizing Committee, for example, is sports executive Casey Wasserman, grandson of mega-Hollywood agent Lew Wasserman, whose Beverly Hills estate was the county’s most expensive house last year, and who logged a flight on Jeffrey Epstein’s private jet.\nFrom NOlympics’ view, the Games not only fail to “realize a more peaceful vision of the future,” but actively sow division, widening the gap between the working poor and monied elite. For the past two years, the group has mounted a campaign with a simple mission: kick the Olympics out of Los Angeles. Recently, as that effort has gained traction with a growing coalition of Angelenos, the goal has become more ambitious: to disprove the myth of the Olympic truce, raise awareness about the Games' proven material consequences, and foster a global movement to end the mega-event for good. Their slogan: No Olympics Anywhere.\nBy most metrics, L.A. was an unlikely contender for the 2028 Games. In early 2015, after a committee helmed by Wasserman announced a bid—then for the 2024 Olympics—the city lost out to Boston. But a small coalition of Boston activists pushed back on the city’s selection, filing FOIA requests, soliciting polls, and mounting a campaign to pull out of the project. By July, Boston dropped out, kickstarting the search for a new host. In round two, L.A. competed against four other cities—Paris, Hamburg, Rome, and Budapest—but three withdrew, leaving the Cities of Angels and Lights to duke it out. In September of 2017, with global interest in hosting the Games on the decline, the IOC announced an unusual move: a tie, awarding 2024 to Paris and 2028 to L.A.\nAt the time of the announcement, NOlympics had been underway for several months. Jonny Coleman, an L.A.-based journalist (or “content serf,” as he puts it) and early organizer, dates the first meeting back to April of that year. Coleman has salty brown hair, clear glasses, and, like many of his peers, an encyclopedic memory of Olympic wrongdoing. The writer joined the Democratic Socialists of America in the wake of the 2016 election, alongside scores of millennials disillusioned with the liberal establishment and their failure to address spiking inequality. Coleman joined the chapter’s Housing and Homelessness committee, and as L.A.’s Olympic bid grew increasingly realistic, Coleman said, the group decided to get involved. They wanted to combat the city’s myriad social justice issues, building off the work of L.A.’s vibrant activist community, without stepping on anyone’s toes. There were already many established groups—Black Lives Matter, L.A. Poverty Department, and the L.A. Community Action Network, to name just three—working on problems from housing to gentrification to policing. The Olympics presented a new and complex challenge, operating at the nexus of all three.\nThe city had ambitious plans for the Games. Los Angeles Mayor Eric Garcetti, who made LA2028 a centerpiece of his tenure, has boasted of hosting the most lucrative Olympics in history, predicting a whopping $1 billion surplus. The profit margin would be an extreme outlier for the mega-event, which has gone over budget almost every year since 1968, according to a 2016 study from Oxford University. Even for the last Los Angeles Games in 1984, which often ranks among the most lucrative in history, profits peaked at $223 million.\nTo Garcetti’s credit, L.A.’s Olympics proposal was unlike almost any other. Having hosted the Games in 1932 and 1984, the city claimed they could realize a “No Build Olympics” by repurposing existing structures. The event would come at minimal public expense, the bid committee argued, announcing an initial budget of $5.3 billion—a dramatic drop from the average cost of $8.9 billion, according to the Oxford study. (L.A.’s estimate has increased three times since. It’s now $6.9 billion). “Using our existing world class venues, LA 2028 does not need to build any new stadiums or housing,” city spokesperson Alex Comisar wrote in an email, “and will be low-risk, privately funded and fiscally responsible just like the 1984 Games.” The Olympics would serve a public good, he added, generating revenue to fund youth sports programming around the city. “I think we can guarantee universal access to sports,” Garcetti told the Los Angeles Times this year, “possibly forever.”\nThe NOlympics crowd are wary of those proposed benefits. After the 1984 Games, most of the oft-cited surplus was sent back to the International Olympic Committee, and the remaining $93 million was placed in the care of the LA84 Foundation, a “grant making and educational” non-profit which funds youth sports for underserved populations across Southern California. But NOlympics argues the funds have not been sufficiently reinvested in the city. While tax returns from 2017 put LA84’s assets at over $165 million, their annual contributions hover around $2 to 3 million (the largest expense that year—$345,000—went to a Youth Sports Summit targeted at adults, where tickets cost $395 each).\nIn an examination of LA84’s returns with former IRS investigator Martin Sheil, The Daily Beast found that LA84 repeatedly donated less than their required annual threshold. Typically, yearly contributions for nonprofits must be equal to their returns on investment. In 2017, tax forms indicate LA84 fell more than $2.6 million short of its required donations; and in 2016, they should have spent an additional $6.1 million. Meanwhile, the foundation had nearly $22 million invested in companies like Blackstone, a controversial private equity firm recently “blasted” by the U.N. for their role in exacerbating the American housing crisis—the very issue NOlympics wants to combat.\nThe nonprofit has a five-year period to remedy each discrepancy of this kind, though the gaps raise questions about why a nonprofit so well-endowed would face this problem at all. (LA84 did not respond to multiple requests for comment.)\nBut the crux of NOlympic’s concerns lie not with the potential revenue gained by hosting the Games so much as what might happen in pursuit of it. Los Angeles is in the midst of a homelessness epidemic—a crisis so drastic local officials recently called on Gov. Newsom to declare a state of emergency. The 2019 homeless count found that nearly 60,000 people in the county are unhoused and more than half of them live in L.A. proper—a 12 percent and 16 percent increase from last year, respectively. As NOlympics organizers point out, the Games have adverse effects on the groups most vulnerable to homelessness. A 2007 study from the Centre on Housing Rights and Evictions found that host cities saw rent spikes, forced evictions, reductions in affordable housing, and widespread gentrification as a direct result of the Games.\nFor their part, the LA28 organizing committee argues displacement won’t be an issue because the city won’t be constructing anything. But even without the need to build stadiums, NOlympics organizers claim the Games will shift development priorities away from affordable housing to hotels and tourist accommodations. That prediction has already come true. A 2019 report from real estate developer Atlas Hospitality Group found that L.A. opened more hotel rooms last year than anywhere else in the state, and estimated that more than 10,000 would open in the next few years. One contributor to that statistic is The Fig—a new complex equipped with 300 hotel rooms, 200 units of student housing, and 200 apartments, which the L.A. city commission approved in February. The problem: dozens of families already live there in rent-stabilized units—a rare find in Los Angeles’ strangled housing market, and one that won’t be replicated in the new buildings. According to the L.A. Times, the city council hired consultants to determine how much public assistance they could provide the project, “citing the need for hotel rooms to accommodate tourism and the future Olympic and Paralympic Games.”\nThat displacement goes hand in hand with another key concern: the overextension of law enforcement. The same 2007 report wrote that staging the Olympics “also involves ‘clearing’ homeless persons off the streets, often by forcing them to move to other cities or areas, or jailing them.” The 1984 Games, on which the 2028 Olympics are modeled, brought about an unprecedented wave of mass arrests—of unhoused people, but primarily of black and Hispanic youth, in what would later be dubbed the “Olympic Gang Sweeps.” In the five years following the Games, according to The Nation, there was a 33 percent increase in citizen complaints of police brutality. Part of NOlympics’ platform stems from a fear that the future Games will bring similar conditions, in the name of “cleaning up the streets” for two weeks in the international spotlight. It’s a fair concern—even the current President of the Los Angeles Police Commission Steve Soboroff agrees. In an email exchange FOIA’d by NOlympics, Soboroff sent a Curbed article about the mistreatment of the homeless during the 1984 Games to Wasserman. “It’s a different LAPD than 1984,” he wrote, “but the questions are valid.”\nIn early September, Coleman and a dozen other NOlympics organizers filled the front rows at a meeting of L.A. City Council’s homelessness and poverty committee. They weren’t the only organizers there. The meeting hall was packed with activists from various groups—all from Services Not Sweeps, a coalition of community organizations dedicated to bringing unhoused people aid, rather than raids (or “sweeps”) from law enforcement. They had come to protest a proposed ordinance called 41.18.(d), which would make it a criminal offense to sit, lie, or sleep within 500 feet of schools, parks, day-care centers, and a wide range of other public facilities.\nWhen the public comment section arrived, a writer and NOlympics organizer named Molly Lambert got up to read a statement. It came from a woman named Tessa, a Los Feliz resident and mother of two.\n“My children are old enough to ask about the camps they see and they are old enough to be told the truth,” Lambert read. “Inside these tents are people with medication, including life saving medication which is regularly confiscated by the police. Inside some of these tents are people who can’t afford to rent some of the most modest apartments in our unaffordable city. Inside some of these tents are children, including children who share classrooms with my children and yours. When we tell unhoused people that they are breaking the law by existing in spaces adjacent to schools and parks, we are not helping our kids. We are lying to them. We are telling our kids that only some people should have access to human rights—that being poor is a crime. We’re telling them to turn away from people who suffer—to resent seeing them at all.”\nLambert choked up as she finished. She wasn’t the only one. The meeting hall erupted in hoots, cheers, and applause. The three council members who had shown up seemed bored. One picked at the label of his water bottle. An audience member yelled: “Pay attention!”\nSeveral city officials who spoke to The Daily Beast for this article expressed confusion at NOlympics’ campaign—at their frequent appearances in city meetings that have no obvious association with the Games. A representative for the mayor’s office, who spoke to the Daily Beast on background, claimed the group had misrepresented their intentions. “The D.S.A.’s arguments have changed over time. The city isn’t building anything—there are none of the normal expenses that you see with Olympics stadiums,” he said. “They’re constantly evolving their complaints. It’s disingenuous. This has nothing to do with the Olympics. This is about a problem with the city and the mayor.”\nBut for critics of the Games, those things are inseparable. Supporters see the Olympics as a truce—a cartoon pause button, where existing tensions and problems are put on hold for an international celebration of human achievement, like some global Hands Across America with billions of dollars at stake. But the Olympics aren’t merely a celebration of otherworldly athleticism—they’re a massive undertaking that has a proven impact on local priorities and in determining who benefits from public resources and who is punished by them.\nRepresentatives for the Olympic Organizing Committee and the Mayor’s Office told The Daily Beast that even if they wanted to end the Games, they couldn’t. They signed the contract. The deal is done. But there is precedent for a movement of this nature. In 1972, after Denver agreed to host the 1976 Winter Games, the city rescinded their bid. The move came after a city-wide referendum, pushed onto the ballot by activists in both parties—fiscal conservatives wary of using public funds, and progressive lefties concerned for the environment. If NOlympics can rally something similar, they may be poised to recreate that model.\n“This is happening at a time when there’s widespread skepticism about the benefits of the Olympics,” said Jules Boycoff, Olympics scholar and author of the upcoming book Activism and the Olympics: Dissent at the Games in Vancouver and London. The group has already found supporters across the globe–on Nov. 18, NOlympics will host an to discuss the Games' impact on working people, with presentations from far-flung advocates like Tokyo's anti-Olympics group, Hangorin No Kai. “They should rally their resources to get a referendum,\" Boycoff continued. \"It’s complicated in California, but that’s the best way to kick the Games out for good.”\nAn earlier version of this article identified Steve Soboroff as the Los Angeles Chief of Police. He is the President of the Police Commission."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:905d58db-7e63-4acf-8e0d-98fa6b4dab34>","<urn:uuid:2d1b5dcb-5d27-4bc3-8e63-d56396dc0213>"],"error":null}
{"question":"How do helicopter rescue operations differ between military combat zones and civilian emergency situations in terms of risks and outcomes?","answer":"In military combat zones, helicopter rescues face additional risks like enemy fire, as shown in the Vietnam War where HC-7's rescue missions encountered small arms and 87mm fire. Despite these dangers, they achieved 150 rescues, including 102 potential POWs. In civilian scenarios, as exemplified by the Bell 206L incident, the primary risks are mechanical failures and emergency landing conditions, where pilots must manage controlled descents and find suitable landing spots. Both scenarios require quick decision-making and skilled piloting, though military rescues have the added complexity of hostile threats.","context":["HC-7 Rescue 1(1) 3-OCT-1967 Combat Day (Tuesday) and Attempted Rescue of: Maj. Robert W. Barnett 4-Oct-1967 Combat Day(Wednesday)\nHC-7 DET 108 UH-2B Kaman Seasprite helo No. 150153\nUSS Coontz (DLG-9) Rescue 1; 1.5 miles from mainland within harbor,\nAttempt; 8 miles INLAND\n3-Oct-1967 Pilot: LTJG Timothy S. Melecoski\nCo-pilot: LTJG James P. Brennan\n1st crewman: AE2 Willie B. Pettit\n2nd crewman (swimmer): ATN3 John H. Bevan\n4-Oct-1967 Pilot: LTJG Timothy S. Melecoski\nCo-pilot: LTJG James P. Brennan\n1st crewman: AMH2 Gary L. Fleck\n2nd crewman(swimmer): ADJ3 Gary L. Schwake.\nA-4B Skyhawk No. 142114 “Nevada City 102” VSF-3 (Chessmen) USN,\nUSS INTREPID (5)\nLTJG Allan D. Perkins\nNavy – Helicopter Combat Support Squadron SEVEN, established Sept. 1, 1967 2, providing several fleet support activities, assumed the responsibility of North Vietnam naval combat search and rescue. HC-7 prepared for action utilizing UH-2B Kaman Sea Sprite helos 3 inherited from HC-1, stationed aboard small boys (DDs and DLGs) stationed off the coast of North Vietnam.\nTuesday – October 3, 1967, Air Force F-105 (Thunderchief, fighter/bomber, mach 2 capable) flights from Korat, Thailand were targeting bridges in North Vietnam. Maj. Robert W. Barnett, from 469th Tactical Fighter Squadron (TFS) “Ozark One” was hit by a SAM. Approx. 15:15, trying to make feet wet, things freeze up and out he bailed. Chute and raft complications, Maj. Barnett makes it to the ground alive. 10 miles inland, rescap (rescue combat air patrol) forms to locate and identify their downed pilot. HC-7, Det 108, “Clementine 1”, stationed aboard frigate USS Coontz (DLG-9), piloted by LTJG Timothy S. Melecoski, co-pilot LTJG James P. Brennan, first crewman AE2 Willie B. Pettit and second crewman (swimmer) ATN3 John H. Bevan, flying in a preposition orbit, had heard the radio calls and volunteered to go in 4. With Barnett’s exact location, undetermined “Clementine 1” was told to hold position 9.\n16:45, LTJG Allan D. Perkins, flying an A-4B, (attack / light fighter) from VSF-3 stationed aboard carrier USS INTREPID, call sign Nevada City 102, completing flak suppression, his aircraft hit three times headed toward feet wet. Aircraft failing and wounded in left leg, Perkins jettisoned over Haiphong Harbor 5. Clementine had launched from USS Coontz (DLG 9) at 16:07. (11) “Clementine 1” preparing to pick-up Maj. Barnett received call from “Steel Hawser” a Navy destroyer in the Gulf of Tonkin, coordinating search and rescue operations, to divert to LTJG Perkins. Maj. Barnett was evading the enemy. Perkins landed in shallows amidst anchored ships becoming the higher priority 4. USS Coontz, 16:50, sounds general quarters and begins closing on the beach to assist in the rescue mission.\nHolding the helo on the deck, Melecoski weaves between the merchant ships within the shipping lane of Haiphong Harbor. Directed by over-head aircraft, the crew spots Perkins, 60 yards from an anchored ship. Unknown to the HC-7’s swimmer, Perkins was squatting down in the shallows, to make a smaller target. 10-10 drop – swimmer away, and stuck in the mud 4. Clementine receiving small arms and 87mm fire from hostile enemy forces in the area 3. Helping each other Perkins and swimmer are free of the quagmire, signal, hooked-up and away, 17:00. “Rescue Effected” 17:15 Clementine is recovered aboard Coontz, with Perkins, who embarks to receive medical attention. (11) At 18:20 Clementine is launched so Coontz receives SH-3 logistic helicopter at 18:24. One minute later Perkins, loaded on SH-3, is headed to USS INTREPID. Clementine returns at 18:27 as the Coontz reenters North SAR steaming area.\nThe Seadevil’s first of many successful combat search and rescue missions. Low on fuel and day-light, Clementine prepares for the next day. “Steel Hawser” tells Maj. Barnett to hole-up and await rescue the next day 4. Barnett moved higher up hill and hid for a sleepless night.\nWednesday – October 4, 1967, 06:30, Maj. Barnett hears Navy planes and people. After hours of silence, continuing to evade, he hears two A-1s, which were escorting (11:34 Clem launches from USS Coontz ) (11) “Clementine 1” piloted by LTJG Timothy S. Melecoski, co-pilot LTJG James P. Brennan, first crewman AMH2 Gary Fleck and second crewman (swimmer) ADJ3 Gary Schwake. At 12:20, Melecoski told Barnett to fire pen flares and activate smokes, “Clementine 1” is over Maj. Barnett. All four approaches, preparing for retrieval, Clementine, receives heavy enemy fire 2. Maj. Barnett hears Clementine pilot shout “MAYDAY, MAYDAY, MAYDAY”. The helo pulls away, Maj. Barnett runs downhill after the helo, trying to follow to the coast 4. The gunfire punctured the fuel tank. Helo crew throws all loose items out to lighten the load, manages feet wet before ditching 8. An SH-3 helo Big Mother 70 from HS-2 rescued the crew 6. At 13:37 the Navy pulled back the rescue forces, Barnett spends a second night in the jungle 4.\nThursday – October 5, 1967, while a second rescue attempt was being planned for 16:30, Barnett hurried toward the coast. Barnett’s radio signal places him 5 miles from yesterday’s position. Hearing people he hides in bushes, a dog finds him and the handler holding a pistol finds Barnett. In brief, the next two days his captors placed him at various anti-aircraft gun sites, required him to call the overhead planes. Barnett knew they were trying to set a Flak Trap. Told to turn his beeper on for five seconds, Barnett hands his radio to his keeper, who turned on the beeper for 2 minutes. Overhead aircraft now very cautious, Barnett figures another way to indicate his captivity. He said, “The code word is LAM -The code word is LAM” 4.\nSaturday – October 7, 1967, Maj. Robert W. Barnett, arrived at the Hanoi Hilton at 04:00. Spending the next five and one-half years as a P.O.W. – released March 14, 1973 (7) “Freedom Flight”.\nHistorian’s Note: This was the only HC-7 helo lost to combat. No Seadevils were lost to combat. Six and one-half years later HC-7 would leave the Gulf of Tonkin, having provided combat search and rescue continuously until Sept. 24, 1973. HC-7 compiled a record of 150 rescues, 102 of which were potential POWs, additionally many unsuccessful attempts 10.\n(Following notes added from USS Coontz deck logs (11) ); 4-Oct-1967\n“11:34 UH-2B helo clear of ship. 11:36 secured helo detail.\n1200-1600: underway as before, 12:01 set the helo detail. 12:05 recovered SH-3A helo No. 70 on deck. CDR Klinker, USN, came aboard to observe SAR efforts. 12:09 refueled SH-3A helo. 12:13 launched SH-3A helo No. 70. 12:29 recovered SH-3A helo No. 69 on deck, refueled SH-3A helo. 12:33 launched SH-3A helo No. 69. 12:35 secured the helo detail. 12:41 maneuvering various courses at 8 knots to remain in vicinity of assigned NSAR station. 12:57 UH-2B helo from this ship received numerous hits from enemy ground fire while attempting to make helo recovery of downed pilot over North Vietnam in the vicinity of Lat. 21-01.2 N, Long 106-55.5E. 12:58 UH-2B helo heading for the coast at best speed. 13:02 sounded General Quarters. Commenced closing the coast on course 330, speed 25 knots to assist in recovering helo. Stationed the helo detail. 13:08 material condition Zebra set. Stationed armed boat detail. 13:12 c/c to 348. 13:13 UH-2B Helo Buno 150153, pilot Melecosky, co-pilot Brennan, and two crewman Fleck and Schwake, crashed into the water in the vicinity of Lat. 20⁰-47 N, Long 107⁰-11 E, helo sunk in 6 fathoms of water. 13:14 SH-3A helo No. 70 en-route to vicinity of crash to search for survivors under control of this ship. 13:16 c/c to 045. 13:17 c/c to 270. 13:21 all four members of crew of downed UH-2B helo picked-up by SH-3A No. 70 and en-route to this ship. 13:32 recovered SH-3A helo 70 on deck. Four helo survivors in good condition, Melescosky suffered slight lacerations on his right hand, a bruised back, and injured ears. Fleck suffered a bruised left shoulder. The other two survivors appeared uninjured. All four were returned to duty following a thorough medical check by the staff doctor…..14:40 SH-3A helo No. 70 clear of the deck. 14:53 recovered UH-2B helo on deck.”\nNotes: (not in order)\n1) Numbering as per HC-7 Rescue Log\n2) HC-7 1967 Command Report\n3) HC-7 Det 108 Rescue report October 3, 1967\n4) Air Power – History Spring 2006 “Ozark Lead is out of the Aircraft” (map) by: W. Howard Plunkett\n5) “Vietnam – Air Losses” By: Chris Hobson (with permission)\n6) Unedited portions of “Leave No Man Behind” by: George Galdorisi & Tom Phillips (with permission)\n7) “Honor Bound” by: Stuart I. Rochester and Frederick Kiley\n8) email – Oct. 01, 2005 – Commander Lloyd Parthemer – Skipper number ONE HC-7\n9) Ozark Transcript – location map – by: W. Howard Plunkett – email 9-21-2011\n10) HC-7 History collection – Ron Milam – Historian\n11) USS Coontz (DLG-9) deck log\n12) Map – Google Earth\n(Compiled / written by: Ron Milam, HC-7 Historian – HC-7, 2-1969 to 7-1970, Det 108 & 113)","Aviation Investigation Report A97A0157\nThe Transportation Safety Board of Canada (TSB) investigated this occurrence for the purpose of advancing transportation safety. It is not the function of the Board to assign fault or determine civil or criminal liability.\nMain Transmission Failure - Forced Landing\nUniversal Helicopters Newfoundland Ltd.\nBell 206L C-GJBC\nGoose Bay, Labrador 27 nm N\n10 August 1997\nThe Bell 206L, serial number 45096, was returning from a forest fire mapping flight north of Grand Lake, Labrador, with the pilot and two forestry employees onboard. The pilot was following the north shore of Grand Lake eastwards at 400 feet above ground (agl) towards the forestry centre, located at North West River, at a cruising speed of 130 miles per hour (mph). A few minutes before the occurrence, the pilot recalls feeling a very slight, high frequency vibration throughout the helicopter; he glanced at his instruments and caution panel but observed nothing out of the ordinary. The pilot and passengers then heard a loud bang and felt the helicopter yaw sharply to the left. The pilot warned his passengers to prepare for an emergency landing, lowered the collective, decreased the airspeed to 70 mph, and commenced an autorotation towards a spit of land along the shore. During the descent, the pilot believes he may have seen the Engine Out caution light illuminate briefly for about 3 or 4 seconds. He focussed his attention on his approach and landing and does not recall seeing any other lights, hearing any engine out or low rotor warning horns, nor does he recall noticing any readings of his engine or transmission instruments. Nearing the spit of land, the pilot initiated a flare at about 50 feet agl and commenced raising his collective to arrest the descent. He then observed that the intended landing spot was strewn with large boulders and warned his passengers to brace themselves. At about 5 feet agl, the pilot had raised full collective and the main rotor rpm had decreased; the helicopter landed hard. The helicopter then yawed uncontrollably to the left about 45 degrees and came to rest upright, with a 5 degree list to the right. The pilot noted that the engine was still running and he could hear unusual 'hissing' sounds. He rolled the throttle from the full open to the OFF position and completed the remainder of the engine shutdown. All occupants exited the helicopter uninjured.\nCe rapport est également disponible en français.\nOther Factual Information\nThe helicopter was substantially damaged during the hard landing. Damage included a downward bending deformation of the tail boom and the tail rotor drive shaft as well as some serious structural deformation of the aft fuselage. The helicopter was slung by air to the operator's base of operations where the engine, main rotor, and transmission were removed. The removal of the mast shaft was particularly difficult and gear fragments were found inside the transmission case.\nThe engine and main transmission were forwarded to the TSB Engineering Branch for examination. The engine was partially disassembled and no signs of internal damage were observed. The engine was subsequently ground run in a test cell and was found to be satisfactory in all respects.\nDuring the examination of the transmission, the sun gear splines were found damaged in the area of engagement with the main ring gear shaft internal spline. When the internal splines of the main ring gear were examined, it was noted that the sun gear had been operating with about 0.30 inches of engagement. A slight wear pattern was observed on the internal spline indicating that a sun gear had previously been installed having a much greater engagement into the main ring gear shaft. The damaged sun gear (part number 206-040-122-103, serial number AFS 004575) removed from the transmission was determined to be a sun gear designed exclusively for use in the Bell 206B helicopter transmission. The overall length of the damaged sun gear was 4.8200 inches. The correct sun gear required for the occurrence Bell 206L helicopter transmission was part number 206-040-122-005. This sun gear, although similar in appearance to the damaged sun gear, is considerably longer at 6.010 inches.\nEngine power is input to the transmission by a spiral bevel gear that engages and turns the transmission first reduction stage ring gear. Inner splines of the ring gear assembly drive a sun gear that engages the four planetary gears of the second stage reduction gear assembly. Since the second stage ring gear is permanently fixed to the transmission case, rotation of the planetary gears causes the planetary gear case to turn. The upper gear of the planetary gear case turns the mast shaft which completes the engine power transmission to the main rotor blades. Of note, the first reduction stage ring gear also drives the main rotor tach generator, the transmission oil pump and the system hydraulic pump. The low rotor rpm warning light and horn receive information from the rotor tachometer and activate at 90±2% rpm.\nThe transmission had been removed on 6 October 1996 for a 1,500-hour inspection, at which time the sun gear was found to exceed maximum wear limits and was replaced. The helicopter had flown 391.0 hours since the replacement sun gear had been installed.\nThe Board examined how the incorrect sun gear was introduced into the operator's supply system and how the incorrect component could have been installed into the transmission without being recognized as the wrong part.\nThe operator ordered the sun gear on Sunday, 6 October 1996. During normal working hours, the operator uses a computer system dedicated to the Bell Helicopter parts warehouse network in Calgary. However, the part was ordered outside normal working hours and operator staff familiar with parts requisition using the computer system were unavailable. Therefore, maintenance management ordered the sun gear by calling the Bell Helicopter parts warehouse toll-free number in Calgary. The Bell Helicopter employee who received the call at home, accessed the Calgary warehouse parts inventory list (remote access) and confirmed that the part was in their stores. The sun gear was shipped the next day to the operator.\nIn order to satisfy the operator's record keeping requirements, the person who placed the order completed the purchase order form, identifying the part number of the sun gear that he wanted, the date the part was ordered and the date the part was required. There was no record found to indicate that the purchase order form had been mailed or faxed to the supplier. The supplier's invoice, which accompanied the sun gear, made reference to the operator's purchase order number and the invoice accurately quoted the part and serial numbers of the sun gear found in the occurrence transmission. It could not be determined if: 1) the operator's maintenance personnel had quoted the incorrect part number during the phone conversation; 2) whether the supplier's employee had inadvertently relayed the incorrect part number electronically to the stores in Calgary; or, 3) the personnel in the warehouse in Calgary had inadvertently introduced the incorrect part number in their internal shipping procedures.\nWhen the sun gear arrived at the operator's main base of operations, the records clerk retrieved the original purchase order form, identified that the last three digits of the recorded part number (-005) did not correspond with the part number recorded on the invoice shipped (-103), and overwrote the purchase order part number to correspond with the invoice. The reason for this modification to the purchase order without apparently consulting company maintenance personnel could not be explained.\nThe sun gear was then shipped to the operator's satellite base in Goose Bay where an aircraft maintenance engineer (AME) installed the component in the transmission. The sun gear was shipped with a company release certification tag indicating the correct part number of the shipped sun gear. The AME, and his supervisor, apparently relied on the main base of operations to send the correct part. They did not physically compare the two components nor did they refer to the Bell Helicopter Illustrated Parts Catalogue (IPC) to verify that the correct part number was being installed.\nThe sun gear that was installed was about 1.2 inches shorter than the correct sun gear. When installed in the main ring gear shaft, the amount of gear engagement cannot be determined. In this case, the shorter sun gear end that engaged with the planetary carrier gears sat lower, physically contacting the main ring gear shaft face with the side of the sun gear. The gear engagement was minimal, roughly 0.30 inches.\nThe incorrect sun gear was inadvertently installed in the helicopter's transmission over 10 months prior to the occurrence. As a result of this relatively long time period since its installation, individuals directly involved could not recall specific details concerning the ordering, shipping, and installation of the component. It was evident; however, that at some point during the ordering and shipping process, a breakdown in communications occurred which resulted in the incorrect component being shipped to the operator. The specific time at which this breakdown in communication occurred or its cause could not be determined.\nThe normal supervisory checks and balances in place within the operator's maintenance practices for the reception and installation of the correct components into the operator's aircraft were ineffective in this case. There are two readily identifiable critical points during the events leading to the installation of the component by the operator's maintenance personnel during which the wrong component should have been identified. The first occasion was when the component was initially received at the main base of operations. The records clerk, noting the different part number of the sun gear, amended the part number in the purchase order to correspond with the part number of the part received apparently without consulting with maintenance personnel. The new number appearing on the amended purchase order then took on the appearance of being a legitimate part number for that specific transmission, possibly setting the scene for a later misidentification by the maintenance engineer. The records clerk could not recall amending the purchase order or the reason for doing so.\nThe second occasion at which the error could have been noticed occurred when the AME, and his supervisor, installed the sun gear into the transmission. Had the AME, or the supervisor, physically compared the two sun gears, it would have been apparent that, despite their similar appearances, the replacement sun gear was noticeably shorter than the sun gear which had been removed from the transmission. In addition, had they verified the part number of the replacement sun gear with the part number of the sun gear removed from the transmission or with the part number contained in the parts catalogue, they would have become aware of a discrepancy and the replacement sun gear would likely not have been installed.\nIn any case, the specific reason why the AME and his supervisor installed the replacement sun gear without first verifying its authenticity could not be determined. As previously suggested, they may have been misled by the amended part number on the purchase order, or they may have relied on the maintenance personnel at the operator's base of operations for having verified that the sun gear was in fact the correct component.\nIt was determined that, when the splines of the sun gear and the inner splines of the ring gear failed, the engine essentially became uncoupled from the main rotor. The main rotor rpm then began to decrease; this decrease was checked when the pilot lowered the collective and entered an autorotative descent. It is interesting to note that, since the ring gear was still being driven by the engine, the hydraulic pump and the main rotor tachometer generator were still being driven. In this instance, the main rotor rpm indicator may have produced a momentary indication above 100% but then the rotor rpm indication would have returned to 100% and remained at that reading as long as the throttle was kept in the full open position. Since the low rotor rpm warning light and horn are initiated by the rotor tachometer, there would have been no low rotor rpm warning regardless of the actual rotation speed of the main rotor.\nThe unusual sharpness of the left yaw which accompanied the uncoupling of the engine from the main rotor was a result of two factors: 1) at the time of the sudden failure, the tail rotor was in a trim position for powered flight and there was suddenly no torque; and, 2) the engine, which was still providing power to the tail rotor, surged due to the sudden loss of drive to the main rotor and the tail rotor rpm increased momentarily as a direct result of the engine power surge. The maximum increase in engine speed would have been controlled by the fuel governor.\nThe decrease in main rotor rpm and left yaw reported by the pilot is consistent with an engine power loss. The pilot's reaction to the apparent engine malfunction of lowering the collective was the correct response in this situation. The cause of the Engine Out light illumination observed by the pilot during the autorotative descent could not be determined.\n- An incorrect sun gear was installed in the helicopter's main transmission by the operator's maintenance personnel.\n- It could not be determined why the incorrect sun gear was shipped to the operator by the supplier.\n- It could not be determined why the operator's maintenance personnel did not identify the sun gear as being an incorrect component for this helicopter's transmission.\n- The sun gear failed causing the failure of the main transmission after the helicopter had flown 391.0 hours since its installation.\n- The helicopter was substantially damaged during the autorotational landing.\nCauses and Contributing Factors\nThe cause of the transmission malfunction was the failure of the incorrect sun gear installed in the main transmission. Contributing to the occurrence was a breakdown in communications between the operator's maintenance personnel and the supplier with respect to the ordering, shipping, and receiving of the sun gear. Also contributing to the occurrence, was an inadequate degree of attention and supervision by the operator's maintenance personnel during the installation of the sun gear.\nFollowing this occurrence, at the operator's request, the Transport Canada Airworthiness District office in St. John's, Newfoundland approved an amendment to the Company Maintenance Control Manual. The amendment was designed to address the issue of proper supervision and record keeping for critical maintenance tasks performance by its maintenance staff. All maintenance staff have been briefed on these new procedures and all holders of the Company Maintenance Control Manual have been provided with a copy of the amendment to the manual.\nThis report concludes the Transportation Safety Board's investigation into this occurrence. Consequently, the Board, consisting of Chairperson Benoît Bouchard, and members Maurice Harquail, Charles Simpson and W.A. Tadros, authorized the release of this report on 07 July 1998.\n- Date modified:"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:2b1b778c-4967-401b-a9b7-4519c02fef64>","<urn:uuid:ab3df1a7-b0e1-43bc-82b8-b6a72a17315f>"],"error":null}
{"question":"How does Samuel Beatty's Brigade's combat experience at 4 p.m. on September 19, 1863 compare to the typical causes of death during the Civil War?","answer":"While Samuel Beatty's Brigade faced direct combat action when they were forced back by Stewart's Division at 4 p.m. on September 19, 1863, combat deaths were actually not the leading cause of death during the Civil War. Disease was by far the most common cause of death, with 'other deaths' (including disease, accidents, drowning, heat stroke, suicide, murder, and execution) claiming over 250,000 Union lives and over 165,000 Confederate lives, compared to combat deaths of over 110,000 Union and 95,000 Confederate soldiers.","context":["Near Fort Oglethorpe in Catoosa County, Georgia — The American South (South Atlantic)\nS. Beatty's Brigade\nVan Cleve's Division\n—Crittenden's Corps —\nVan Cleve's Division - Crittenden's Corps.\nBrigadier General Samuel Beatty.\nSeptember 19, 1863, 4 p.m.\n79th Indiana, - Colonel Frederick Kneeler.\n9th Kentucky, - Colonel George H. Cram.\n17th Kentucky, - Colonel Alexander M. Stoutt.\n19th Ohio, - Lieutenant Colonel Henry G. Stratton.\n26th Pennsylvania Battery, - Captain Allison J. Stevens.\nAt 4 o'clock Samuel Beatty's Brigade with Dick's on its right, had been forced back to this position by Stewart's Division. With the assistance of the 9th Indiana, the 124th Ohio, and 41st Ohio of Hazen's Brigade they were able to make a brief stand, but at 4:30 the entire line was driven from position by Stewart's troops advancing from the front, and Johnson's Brigade of Johnson's Division from the right. The line was rallied west of the Dyer Field and bivouacked on the slope west of the Crawfish Springs Road.\nErected 1890 by the Chickamauga and Chattanooga National Military Park Commission. (Marker Number MT-550.)\nLocation. 34° 55.033′ N, 85° 15.674′ W. Marker is near Fort Oglethorpe, Georgia, in Catoosa County. Marker can be reached from LaFayette Road south of Dyer Road, Touch for map. This marker is located in the national park that preserves the site of the Chickamauga Battlefield, in a field a short distance south of the Brotherton Cabin, a short distance west of the LaFayette Road. Marker is in this post office area: Fort Oglethorpe GA 30742, United States of America.\nOther nearby markers. At least 8 other markers are within walking distance of this marker. 9th Indiana Infantry (a few steps from this marker); War Comes to the Brothertons (a few steps from this marker); Hazen's Brigade (within shouting distance of this marker); Bledsoe's C.S.A. Missouri Battery (within shouting distance of this marker); Van Cleve's Division (within shouting distance of this marker); Johnson's Brigade (within shouting distance of this marker); Trigg's Brigade (within shouting distance of this marker); Confederate Breakthrough (within shouting distance of this marker). Touch for a list and map of all markers in Fort Oglethorpe.\nMore about this marker. I used the \"Chickamauga Battlefield\" map, that I purchased at the Chickamauga and Chattanooga National Military Park, Visitor Center, to determine both the marker number for this tablet and the tablet's location in relation to the rest of the park's monuments, markers, and tablets. According to the map it provides the, \"numerical\nRelated markers. Click here for a list of markers that are related to this marker. Use this link to see the Regiment markers, tablets, and/or monuments for this Brigade.\nCategories. • War, US Civil •\nCredits. This page was last revised on July 3, 2017. This page originally submitted on September 14, 2016, by Dale K. Benington of Toledo, Ohio. This page has been viewed 273 times since then and 24 times this year. Photos: 1, 2, 3, 4. submitted on September 14, 2016, by Dale K. Benington of Toledo, Ohio.","Civil War Casualties\nCasualties Numbers And Battle Death Statistics For the American Civil War\nThough the number of killed and wounded in the Civil War is not known precisely, most sources agree that the total number killed was between 640,000 and 700,000. (See article below)\nUnion Civil War Casualties\nCombat Deaths: Over 110,000\nOther Deaths*: Over 250,000\nConfederate Civil War Casualties\nCombat Deaths: Over 95,000\nOther Deaths*: Over 165,000\n(*Other Deaths include, among others: disease (by far the most common cause of death), accidents, drowning, heat stroke, suicide, murder, execution.)\nCivil War Casualties: The Bloodiest Battles\nBattle Of Gettysburg: Over 50,000 casualties\nSeven Days Battle: Over 35,000 casualties\nBattle Of Chickamauga: Over 34,000 casualties\nBattle Of Chancellorsville: Over 29,000 casualties\nBattle Of The Wilderness: Over 24,000 casualties\nBattle Of Antietam: Over 22,000 casualties\nSecond Battle Of Bull Run: Over 24,000 casualties\nBattle Of Shiloh: Over 23,000 casualties\nBattle Of Fredericksburg: Over 18,000 casualties\nCold Harbor: Over 18,000 casualties\nArticles Featuring Civil War Casualties From History Net Magazines\nWar by the numbers\nBy Harold HolzerEyebrows were conspicuously raised recently when a “demographic historian” from New York’s State University at Binghamton convincingly recalibrated the long-accepted Civil War death toll—boosting the grisly statistic by an astounding 20 percent.\nAccording to Dr. J. David Hacker, the traditional death toll of 620,000—which historians have accepted for more than a century—failed properly to account for several key factors, including the influx of immigrants into the armed forces, not to mention casualties among black women who found themselves victims of the onrush of war. Hacker employed a new range of statistical accounting to determine mortality, including a system called the “two-census method.” To measure deaths, he counts the number of 20- to 30-year-olds in the 1860 census, and the number of 30- to 40-year-olds who turn up in—or, more important, disappear from—the next count, 10 years later. The difference represents the number of young people who died in the intervening decade, and Hacker took an educated stab, based on a shrewd reading of regional loyalties, at determining how many of them likely perished on the battlefield and not home peacefully in bed.\nIt’s useful to keep in mind that the long-accepted 620,000 tally was the work of two energetic but amateur historians, William F. Fox and Thomas Leonard Livermore, Union veterans who read every pension record, battlefield report and muster roll they could put their hands on. Fox published his Regimental Losses in the American Civil War in 1889—and through their extraordinary research we learned that the average Federal soldier weighed 143.5 pounds.\nInevitably, the new death-counting process proved more complicated than even this. For one thing, apparently, the reunited country’s 1870 census was something of a hash, with a level of undercounting that made the complaints around our recent 2010 census seem mild by comparison. Hacker admits it also remains difficult to count civilians who died in wartime. And he’s still as intrigued as the rest of us by the challenge of counting the number of farm boys who died from sickness after exposure to germ-riddled, but essentially immune, urban soldiers. Union medical care, he further points out, was far superior to Confederate—and more Johnny Rebs might have died of disease than Billy Yanks. Deaths among African-American troops have long had a widely accepted numerical accounting, but these numbers, too, Hacker believes, deserve reconfiguring, though no one is quite sure how to do it.\nCaveats notwithstanding, Hacker bravely aimed at revising the total count, concluding the actual death toll for the Civil War amounted to between 650,000 and 850,000—and by prudently splitting the difference, proposed a new number: 750,000, as reported in America’s Civil War in March 2012. It also inspired a major New York Times story in April by Guy Gugliotta (whose new book, Freedom’s Cap, by the way, tells the extraordinary story of the U.S. Capitol and the coming of the rebellion). The scholarly journal Civil War History not only published the Hacker findings but trumpeted them, almost uncharacteristically, as “among the most consequential pieces ever to appear” between its covers.\nDrew Gilpin Faust was right. In her extraordinary book This Republic of Suffering, the historian and president of Harvard University reminded modern readers of post-war America’s obsession with Civil War death and memory. The rush to build cemeteries, monuments and memorials, together with the overwhelming responsibility merely to bury dead bodies, filled survivors with an abiding reverence for, and obsessive fascination with, those who sacrificed that the nation might live (and even those who gave their lives that it might die). Exhumations were common as survivors and widows struggled with competing notions of sacred ground. Soldiers cemeteries became part of the American culture—and not just at Gettysburg. Those old emotions remain raw. Mass mourning is never far from the surface of American culture, and statistics not only encourage scholarly debate but expose unhealed wounds.\nThe new Civil War death toll numbers have stirred the pot afresh. In reporting the new statistics, the Times, for example, took an unexpected pot shot at veteran historian James M. McPherson, one among countless scholars who have long accepted the earlier 620,000 number. The article called out the dean of the field for using that number “without citing the source in Battle Cry of Freedom, his Pulitzer-winning 1988 history of the war.” The fact that no one else has ever “sourced” the figures did not seem to matter in the new rush to up the gruesome ante.\nMcPherson, in turn, had a bone to pick with yet another great historian, Mark E. Neely, who once convincingly argued that the Civil War was not a total war in the 20th-century sense. McPherson commented that the revised numbers suggest that Neely was wrong after all—for what else but a total war could produce such staggering casualty figures?\nWhat is extraordinary about all this is that we still desperately want to know the truth—the whole truth, and nothing but the precise truth—about the toll of war. We may never find out for certain how many men and women, blacks and whites, native born and foreign born died to save the Union and destroy slavery. But as the new science and the new attention show—thanks to David Hacker, Guy Gugliotta, et al.—more than curiosity is at work here. Hacker put it modestly when he opined that “it is just a curiosity.” In a sobering afterthought, he wisely told Gugliotta and the Times: “It’s our duty to get it right.”\nHarold Holzer is chairman of the Abraham Lincoln Bicentennial Foundation.\nSmoke and fire filled the skies south of Petersburg in December 1864 as the Army of the Potomac's V Corps targeted the Weldon Railroad. During a raid along this vital supply line linking southeastern Virginia with North Carolina, liquor-fueled Federals …\nThe North's Unsung Sisters of Mercy\nBy Alice P. Stein\nA cadre of dedicated Northern women from all walks of life traveled to the charnel houses of the Civil War to care for the sick and wounded.\nThey came from …\nDesperate Stand at Chickamauga\nBy James B. Ronan II\nBrigadier General John King's disciplined brigade of Union Regulars found itself tested as never before at Chickamauga. For two bloody days, the Regulars dashed from one endangered spot to another, seeking …\nThe Civil War's deadliest weapons were not rapid-fire guns or giant cannon, but the simple rifle-musket and the humble minié ball.\nBY ALLAN W. HOWEY\nBy the time the smoke had cleared and the veterans headed back to …\nSavage Skirmish Near Sharpsburg\nBy Scott Hosier\nWith Robert E. Lee's wily Confederates waiting somewhere in the vicinity of Antietam Creek, Union General George McClellan ordered I Corps commander Joseph Hooker to advance and turn the Rebel flank. But McClellan, …\nWar's Last Cavalry Raid\nBy Chris Hartley\nEven as General Robert E. Lee was surrendering at Appomattox, a vengeful Union cavalry horde led by Maj. Gen. George Stoneman made Southern civilians pay dearly for the war. It was a last …\nThe hard-fighting 44th Georgia suffered some of the heaviest losses of any regiment in the Civil War.\nBy Gerald J. Smith\nOn March 10, 1862, companies of Georgians from Henry, Jasper, Clarke, Spalding, Clayton, Putnam, Fayette, Pike, Morgan, Henry and …\nTaking of Burnside Bridge\nBy John M. Priest\nWhile Union commander George McClellan fumed and the Battle of Antietam hung in the balance, a handful of Rebels held off Federal troops at \"Burnside Bridge.\"\nThe day–September 17, 1862–promised to be …"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:fdc0a3bc-f756-49d7-a562-5fd1fa5d509a>","<urn:uuid:d7084b51-edd9-49b9-ab5a-cadd4db9e820>"],"error":null}
{"question":"How do surgical and non-surgical treatments compare between vocal nodules and LPR?","answer":"For vocal nodules, surgery is not always necessary as they can often be eliminated through voice rehabilitation and therapy alone. When surgery is performed for nodules, there's a risk of scar tissue formation and recurrence if the underlying behavioral causes aren't addressed. In contrast, LPR treatment options include behavioral modification, medications (from antacids to proton pump inhibitors), and surgery such as endoscopic Nissen Fundoplication. Surgery for LPR is typically reserved for cases that fail medical treatment or for younger patients facing lifetime medical therapy, while surgical intervention for nodules is less preferred due to the possibility of successful non-surgical treatment.","context":["It's everyone's worst nightmare. The dreaded nodes! Never heard of nodes? The media portrays them as an end to a singer's career, like here in the movie Pitch Perfect. Chloe, one of the Barton Bellas, is diagnosed, unfortunately with vocal nodules.\nSecretly, during the movie, she decides to have surgery to have them removed. The movie has a comedic theme, so she makes light of the situation which occurs post-operatively: a loss in vocal range. With her new-found bass notes accessible, she propels the group to a victory at competition with her ability to sing the male part in an all-female group. The movie ends, everyone is happy, end of story.\nIn real life, any type of voice disorder can be life-changing for individuals who use their voices in a professional context. Vocal nodules, although common, require intervention in most cases, especially in professional voice users like teachers or entertainers. Vocal nodules are two areas of lesion (bilateral, or both sides) at the front portion of the vocal folds. They are caused from overuse of the vocal mechanism, and the severity can depend on genetics, dehydration, vocal demands and poorly coordinated vocal subsystems. Some physicians term a unilateral (one sided) lesion as a \"node\" only adding to confusion, but for the purposes of this blog we are talking about bilateral vocal nodules.\nThe mid-anterior 1/3 junction of the vocal folds is the area where the vocal folds collide the hardest and create the most movement during phonation, or sound production. This area is also where we find nodules. If a person develops vocal nodules, is it because of vocal loading? Possibly, but this study found no correlation. We also know that teachers are at a greater risk for voice disorders. So what makes a person more susceptible? We speculate it has a lot to do with genetic predisposition paired with this heavy vocal use/phonotrauma.\nNodules, unlike other vocal lesions, are sometimes described as swellings and can usually respond to voice rehabilitation and decrease greatly or be eliminated entirely with no surgery necessary. Degree of improvement and estimated length of time vary with severity of nodules. The harder, and more fibrous, the more recalcitrant the nodules may be. As science continues researching different treatment methods, we find that surgery to the vocal folds is not always the right choice for a certain vocal disorder. It seems that in modern medicine, a quick fix is what every patient wants. A pill for this, a surgery for that.\nWhen vocal nodules form, it is because of a repetitive behavior. If they are surgically excised with no treatment to eradicate the initial cause, they have a likely chance of returning. You also run the risk of scar tissue forming following surgery to the delicate membranes of the vocal fold tissues.\nWith the subspecialty of vocologists in the SLP world, many well-qualified professionals can provide treatment for decreasing vocal overuse and rebalancing vocal subsystems. This can often improve quality of life and vocal stamina so much that phonosurgery is not even necessary. A study even compared the difference in outcomes between traditional voice therapy recipients and intensive programs, with both groups resulting in better outcomes. Those who do choose to have nodules surgically removed, have a lower chance of recurrence if they participate in voice rehabilitation with a qualified SLP.\nSo if your patient, loved-one, or even you are suffering from vocal fold nodules, like Chloe, you should seek the help of a qualified otolaryngologist and voice team to help you make the best decision based on your specific case.\nKristie Knickerbocker, MS, CCC-SLP, is a speech-language pathologist and singing voice specialist in Fort Worth, Texas. She rehabilitates voice and swallowing at her private practice, a tempo Voice Center, and lectures on vocal health to area choirs and students. She also owns and runs a mobile videostroboscopy and FEES company, Voice Diagnostix. She is an affiliate of ASHA Special Interest Group 3, Voice and Voice Disorders, and a member of the National Association of Teachers of Singing and the Pan-American Vocology Association. Knickerbocker blogs on her website at www.atempovoicecenter.com. She has developed a line of kid and adult-friendly therapy materials specifically for voice on TPT or her website. Follow her on Pinterest, on Twitter and Instagram or like her on Facebook.","The word reflux literally means “backflow.” Laryngopharyngeal reflux, or LPR, is the backflow of stomach contents up the esophagus and into the throat. The injurious agents in the refluxed stomach contents (refluxate) are primarily acid and activated pepsin, a proteolytic enzyme needed to digest food in the stomach. The damage caused by these materials can be extensive. The above picture displays a diffusely inflammed larynx secondary to LPR. Specific findings include laryngeal hyperemia, posterior commissure hypertrophy, pseudosulcus vocalis, and thick endolaryngeal mucus.\nLPR is different than gastroesophageal reflux disease (GERD). Patients with GERD are usually seen by a gastroenterologist. They typically suffer from heartburn and many pertsons with GERD have esophagitis. Although some persons with LPR do suffer from heartburn or esophagitis (12%), most persons with LPR do not. The reason for this is that the refluxate spends very little time in the esophagus and does most of its damage in the larynx. The anatomic abnormality in patients with LPR is thought to exist at the level of the upper esophageal sphincter. Esophageal motility and esophageal acid clearance are usually normal. The esophagus is very well equipped to handle small amounts of reflux and little, if any esophageal injury occurrs in patients with LPR. Because patients with LPR do not suffer from heartburn, the diagnosis may be difficult to make for some clinicians. Referral to a specialist may be necessary.\nSymptoms caused by refluxed stomach contents are numerous and include hoarseness, cough, and chronic throat clearing. LPR can also affect the lungs and may exacerbate asthma, emphysemsa, or bronchitis. The table below displays some of the symptoms caused by LPR.\nWe have validated a 9-item reflux symptom index (RSI) to assess the initial severity of LPR symptoms as well evaluate patient response to treatment. A RSI greater than 10 may indicate significant reflux. Please feel free to complete the RSI below.\nReflux Symptom Index (RSI)\nA RSI > 10 could indicate significant laryngopharyngeal reflux\nThe tissue injury to the larynx caused by LPR has previously been poorly described. The laryngeal findings of LPR are summarized below. After evaluating these images, it is easy to see how the voice and swallowing mechanism can be severely effected by LPR.\nThe diagnosis of LPR may be made by any combination of history, physical examination and 24-hour pH probe testing. A reflux symptom index (RSI) greater than 10 may be indicative of significant LPR. Physical findings of LPR are displayed above. In some patients the history and physical examination findings may be equivocal. 24-hour pH testing may be indicated. For this diagnostic test a small catheter is placed through the nose into the throat and esophagus for a 24 hour period. The catheter has multiple sensors on it to detect the presence of acid in the esophagus and throat (drop in pH < 4). The patient wears the catheter with a small computer recording device on his/her waist home and comes back to the office the next day to have the readings interpreted and the catheter removed. This test is very useful in patients with recalcitrant LPR, those failing medical therapy, and those considering surgical intervention such as fundoplication.\nTreatment for LPR includes any combination of behavioral modification, pharmacotherapy (medications), and surgery. Behavior modification includes weight reduction, avoidance of food high in fat and caffeine and elevation of the head of the bed.\nMedical therapy for LPR includes nonprescription antacids and H2 antagonists such as Maalox, Mylanta, Pepcid and Zantac. Gum chewing increases salivary production and may help neutralize regurgitated stomach acid. Although these medications are often effective at treating GERD, they are often ineffective at treating LPR. Proton pump inhibitors (Prilosec, Prevacid, Aciphex, Protonix, Nexium) are more potent medications than antacids and H2 blockers. In sufficient quantities they can result in complete acid supression. Relatively high doses over an extended period of time (6 monthhs or greater) may be required to reverse the tissue injury to the larynx.\nSurgical options for treating LPR are usually reserved for medical treatment failures as well as younger individuals with severe LPR who face a lifetime of expensive medical therapy with unknown long term consequence. Surgical options include minimally invasive procedures such as radiofrequency ablation of the lower esophageal sphincter as well as endoscopic Nissen Fundoplication which is a procedure where the surgeon wraps the stomach around the distal esophagus to create a tight valve. It has proven to be very successful in preventing reflux into the esophagus as well as the pharynx (throat) and larynx. Please see our section on reflux therapy.\nEsophagopharyngeal reflux (EPR) is the regurgitation of esophageal contents back into the larynx and pharynx. Gastroesophageal reflux disease (GERD) is the disorder caused by the regurgitation of GASTRIC contents into the esophagus. The hallmark of GERD is heartburn. LPR is the disorder caused by the regurgitation of GASTRIC contents into the larynx and pharynx. Persons with GERD and LPR usually respond well to medications that reduce the acid content of the refluxed materials (H2-blockers/proton pump inhibitors). Patients with EPR present with symptoms very similar to persons with LPR. They do not, however, respond well to traditional anti-reflux therapy. The problem with EPR is that of bolus transport and esophageal emptying. Most patients with EPR have a disorder of esophageal motility. Some of the ingested food sticks in the esophagus and regurgitates back into the throat causing throat clearing, cough, excessive mucus, etc… Treatments for EPR are similar to treatments for esophageal dysmotility. Treatment for EPR is often less successful than treatmment for LPR or GERD. Medications that reduce the acid content (H2-blockers/PPIs) do not stop static esophageal contents from being regurgitated back into the upper airway. Behavioral modifications are crucial and alginates (Gaviscon) have shown some success in keeping the food contents from regurgitating out of the esophagus. persons with a diagnosis of LPR who fail medical therapy should be considered for a diagnosis of EPR. A dynamic video-fluoroscopic swallow evaluation and ambulatory impedance testing are the only ways to diagnosis EPR.\nThe following video clips are fluoroscopic and endoscopic images of reflux:"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:d7803a0d-d2ed-480f-b92d-da4c9ce10c95>","<urn:uuid:f4333482-123b-41dc-af39-e91cdac03a7a>"],"error":null}
{"question":"How do the diagnostic criteria differ between EDNOS and anorexia nervosa?","answer":"Anorexia nervosa has specific diagnostic criteria including significantly low body weight, intense fear of gaining weight, and disturbance in body weight perception. In contrast, EDNOS is characterized by eating issues that don't meet the requirements of defined disorders like anorexia, often involving unusual combinations of disordered eating behaviors like both fasting and purging, or having symptoms suggesting an eating disorder but with body types and BMI that don't align with traditional diagnostic criteria.","context":["The Deadliest Eating Disorder Out There\nPeople are aware of eating disorders such as anorexia and bulimia, but it is the more unknown disordered eating problem EDNOS that is the most deadly.\nMore awareness is needed so that the people who do suffer from this can receive both help and support.\nHad you heard about EDNOS before?\nEveryone thinks of eating disorders and the problems they can cause, but many overlook the even more deadly disordered eating. This is when your habits don't meet the requirements of an eating disorder such as anorexia or bulimia. But in fact disordered eating contains the most deadly, and the majority of people haven't even heard of it.\nAccording to the National Association for Anorexia Nervosa and Associated Disorders around 53% of people with disordered eating suffer from Eating Disorder Not Otherwise Specified, or EDNOS. The mortality rate for EDNOS is the highest of them all at 5.2% of sufferers who die from it.\n“The problem is people think that EDNOS means ‘eating disorder that’s not as bad,’” says Carolyn Costin, MFT, Executive Director of Monte Nido and Affiliates, a treatment center for eating disorders. “EDNOS is actually quite lethal, because it is underdiagnosed and undertreated,” Costin says.\nEDNOS is so deadly because people who suffer from it usually exhibit an unusual combination of disordered eating issues, for example both fasting and purging. Or they have body types and BMI that mean that although their symptoms may suggest an eating disorder their bodies do not. This makes it all the more difficult to diagnose and so oftentimes people don't receive the help they should get.\nTake a look at the signs below, and seek help if you identify with any of them—your life could depend on it.\nYou may have EDNOS if:\nYour diet is rigid\nDaily food intake is ritualistic, and your dieting rules are rigid; maybe you only allow yourself to eat after 5 p.m., or eat the same six foods everyday.\nYour diet interferes with your life\nYou won’t go out to dinner, because you aren’t comfortable eating any of the meals on restaurant menus, or you skip out on plans to fit in a workout.\nYour diet raises eyebrows\nThe people closest to you mention you’ve lost too much weight, say you work out too much or point out strange food habits, like avoiding specific restaurants or food groups.\nYour diet is at the forefront\nYou spend most of the day thinking about food; what you can eat, when you can eat next, and what’s in each dish. You may spend hours researching menus and totaling up calories.\nYour diet isn’t a choice\nCould you change your diet behavior? Is what you eat truly a choice? If you’ve gone vegan in the name of better health, but find you actually can’t make yourself eat a cookie, you may have EDNOS. “Some people feel obligated in their brains to eat certain foods and avoid others,” Costin says. “It’s a driven, obsessive-compulsive behavior. Asking yourself if you can eat that cookie is a good strategy. I need to see that you can allow yourself to eat a certain food.”\nHOW TO GET HELP:\nIf you notice any of these behaviors, seek help. Check out EDreferral.com for treatment centers and eating-disorder professionals in your area, and see NationalEatingDisorders.org for more information. Also, take the pressure off labels. “Think about it as disordered eating, if that’s helpful,” says Costin. “Don’t worry about diagnosis or criteria. Just begin to talk to someone.”\nOriginal article can be found here: http://blog.womenshealthmag.com/thisjustin/the-deadliest-eating-disorder/?cm_mmc=twitter-_-womenshealth-_-content-scoop-_-deadliesteatingdisorder - Jenna Birch - 20/11/12","What is Anorexia Nervosa?\nAnorexia nervosa is a devastating illness, affecting millions of people each year. Anorexia nervosa is defined by the DSM5 (Diagnostic and Statistical Manual Version 5) as:\n- Restriction of dietary intake relative to dietary energy requirement leading to a significantly low body weight in the context of age, sex, and physical health\n- Intense fear of gaining weight or becoming fat\n- Disturbance in the way in which one's body weight or shape is experienced, and persistent lack of recognition of the seriousness of the current low body weight.\nNinety percent of those diagnosed with anorexia nervosa are women. Estimated to affect 1% of adolescent females in the US, anorexia nervosa has one of the highest death rates of any mental health condition; 20% of whom die from suicide. Individuals with anorexia have a premature death rate that is more than 20 times higher than their peers who don't have an eating disorder.\nAnorexia nervosa is often associated with other mental health conditions such as depression and anxiety. In addition to mental health conditions, people affected by anorexia may also develop digestive conditions (e.g., impaired gastrointestinal motility resulting in bloating, abdominal pain and constipation), heart complications (e.g. irregular heart rhythm, fainting), kidney disease, infertility, and osteoporosis.\nHow is Anorexia Nervosa treated? Can it be treated?\nTreatment of anorexia nervosa and other eating disorders is best accomplished by an experienced multidisciplinary team including a physician, registered dietitian, and psychotherapist. Treatment is focused on understanding how an individual ended up with an eating disorder, how to get rid of the eating disorder, and how to not return to the eating disorder later in life. Medications have a limited role in the treatment of anorexia nervosa. There are no FDA (Food and Drug Association) approved medications for the treatment of anorexia nervosa, but a majority of those affected by this disease are taking psychotropic medication aimed at addressing mood disturbance and associated eating behaviors.\nSince there is not an “anorexia-be-gone” pill, the primary treatment is provided by the dietitian and psychotherapist. Dietitians focus on helping their patient develop a healthy relationship with food, eating and body image, encouraging sufficient dietary intake and guiding appropriate weight gain. The therapist addresses the underlying causes of the eating disorder. A common thread for many affected by anorexia nervosa is the need for control. When something, or some things, are out of control, the one thing someone can control is their eating and body size, shape and weight.\nBehaviors and symptoms\nEarly recognition and early intervention/treatment for anorexia nervosa is associated with better outcomes. Knowing early signs and symptoms of anorexia nervosa can help loved ones recognize the person at risk and get them into appropriate treatment. Behaviors and symptoms of anorexia nervosa include the following: skipping meals, eliminating food groups (e.g. not eating dairy, fat, meat, gluten containing foods), increased exercise, rigid eating – eating the same thing every day, refusal to eat in restaurants or outside the home. Commonly reported symptoms include: abdominal pain and/or bloating, decreased appetite, constipation, fatigue, amenorrhea (lack of menstrual periods), hair loss, dry skin, light headedness, and fainting.\nOur society’s obsession with the female form, and especially tall, thin, willowy women is another driver for anorexia nervosa. Endless pictures of scantily clad celebrities online, on social media, and in magazines create unrealistic body image standards for women and girls. Efforts that promote healthy lifestyle and healthy body image in the media, at home, and in schools, can go a long way at reducing the pressure on young women to achieve unhealthy body size, shape and weight."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:408fa517-83ff-4a30-9cd1-1c1fb981bb43>","<urn:uuid:d9e78ae6-6bda-4308-9c69-d37aaddee804>"],"error":null}
{"question":"Hello, I am planning a trip to Namibia and would like to know how far is Kalahari Red Dunes Lodge from Windhoek International Airport?","answer":"The Kalahari Red Dunes Lodge is located 240km from Windhoek International Airport, making it an ideal stopover for self-drive tourists on either the first or last day of their holiday in Namibia.","context":["Kalahari Red Dunes Lodge is situated on a 4,000ha private game reserve, 200km south of Namibia's capital city of Windhoek, near the small town of Kalkrand. As it is only 240km from Windhoek International Airport, this is an ideal stopover for self-drive tourists on either the first or last day of their holiday in Namibia. The town of Mariental is a further 70km south of the lodge.\nIndividual travellers, families or small groups wishing to experience privacy and luxury amongst red sand dunes in the Kalahari Desert without having to drive too far off the beaten track, should head for this lodge. An unusual feature of the The Kalahari Red Dunes Lodge is that it is situated in a nature reserve characterized by 2 deserts. The Kalahari Desert can be identified by infinite chains of red sand dunes that alternate with green valleys. The Great Karoo is home to enormous grass steppes and dry river courses lined with abundant water banks.\nFacilities include a restaurant, bar and lounge enclosed in a lapa with fire place, a swimming pool with a shaded decking, a viewing deck also with a fire place, free wireless LAN Internet and a safe to store your valuables at reception. The pool and shaded deck are actually situated in a dry lake. A 120m board walk connects the main building with the chalets which are strategically placed around this 'vlei'. A variety of Namibian wildlife can often be observed from the privacy of the chalets.\nEuropean meals with African flavours are enhanced by the lodge's home-grown herbs and fruits. Seasonal Kalahari truffles are also available. Breakfast can be enjoyed on the large, teak terrace. Buffet meals can be served in either indoor or outdoor dining areas with an open fireplace to ward off those chilly Namibian winter mornings and evenings. For those seeking a more romantic setting dinner can be taken 'between the red dunes of the Kalahari Desert'. A large selection of good to excellent South African wines can be ordered to accompany your meal as well as an inviting glass of cool Camelthorn Draft Beer, which can be drank under the tree of the same name.\nThe goings on of the Kalahari Desert can be experienced from the comfort and safety of your accommodation. Traditional African stoned/thatched roofs and canvas walls maintain a cool interior even in the hotter months. Features include teak floors, natural stone tiles in the bathrooms, teak terraces and board walks, individual private outdoor shower, generous spacing allowing for maximum spacing and a 'picture window' for observing animal activity.\nThere are 12 twin chalets (including 1 disabled chalet) each equipped with a private terrace, en-suite showers, fridge, tea/coffee station, mosquito nets, hair dryers, Wi-Fi connection and air-conditioning. Each stilted guest house is named after the largest species roaming the reserve. Paved, barrier-free, illuminated paths lead to the main building. The layout of the individual rooms is as follows\nNyala: The only guest room with a 'wide-angle scenic view'. Glass windows in the canvas run along the entire length of the building enabling guests to follow the course of the dunes. This chalet has the largest living space and affords the the most spectacular sunset view of the 12 rooms. There is no view of the waterhole.\nDistance from the main building: 300m.\nImpala: This chalet overlooks a tree savanna inundated with seasonal shiny golden yellow high grass to one side and the red sand dunes of the Kalahari desert on the other. Distance from the main building: 240m\nBlue Wildebeest & Black Wildebeest: These are 2 separate houses linked by a board walk, ideal for a family or small group. Alternatively the houses can also be booked separately by locking the doors to the board walk. Both houses offer breathtaking sunset views over the grass savannah and camelthorn trees. Distance from the main building: Blue: 180m. Black: 160m.\nSpringbok: As this guest house is elevated on the edge of the vlei it affords a spectacular panoramic view of the surrounding tree savanna, dry lake and steppe. An open shower has views of the magnificent savannah landscape. Distance from the main building: 100m.\nEland: This spacious guest house features a particularly beautiful bathroom. French windows offer spectacular views and you can observe waterhole wildlife activity from the comfort of your bed. Additional outdoor shower. Distance from the main building: 150m.\nGiraffe: Features include the largest bathroom, open and outside showers of all 12 rooms. It is set amongst ancient Kalahari Acacia bushes, where giraffe feed between the shrubs. There is a great view over the vlei and the waterhole, as well as the red sand dunes on the opposite sides. Distance from the main building: 200m.\nOryx: The position of this guest house offers spectacular wildlife viewing as well as affording extra privacy. Antelope can be observed through the 'picture windows' as well as from the comfort of your bed. There is an additional hidden outdoor shower. Distance from the main building: 300m.\nRed Hartebeest: This guest house is ideal for game viewing in and around the waterhole on one side and and the dunes on the other. Warthogs, zebras and kudu regularly pass by for a drink. There is an additional outdoor shower. Distance from the main building: 350m.\nZebra: The front terrace of this guest house is located under a large camelthorn tree, a location which not only sets this room apart from the others but gives the impression of being actually inside the vlei itself. The outdoor shower, obscured from view by an overhanging tree, adds to the ambiance. Distance from the main building: 480m.\nKudu: The very first guest house built for the lodge which still holds a special place for those involved with the lodge. It is the only guest house with steps leading to the terrace. Ideal for those who want to enjoy the quiet and solitude of the Kalahari Desert. Distance from the main building: 450m.\nOstrich: This is the furthest and therefore the most remote and secluded of the 12 guesthouses. Outstanding views of the immediate environment have been enhanced by a number of additional windows that have been installed recently. Many guests opt for a candle-lit dinner complemented by a bottle of fine red wine on the wooden terrace instead of walking to the main building. Distance from the main building: 500m.\nSpecies of animal that freely roam the private game reserve at Kalahari Red Dune Lodge include: Hartmann’s mountain and plains zebra, giraffe, blue and black wildebeest, eland, nyala, springbok, kudu, steenbok, oryx, red hartebeest, blesbok and impala. Some smaller creatures include pangolin, porcupine, aardvark and warthog. Amongst the many species of birdlife which include ostrich, waterfowl visit during the rainy season.\nActivities and excursions are either by customized 4x4 safari vehicles or guided and unguided tours on foot. All trips are accompanied by experienced and knowledgeable guides.\nGame drives: Enjoy the Kalahari Desert from the safety and comfort of a morning or afternoon safari. The leisurely drive gives ample opportunities to observe the many species of mammals that live on the reserve. The energetic can opt to climb some small dunes of around 30m high. Experience the vegetation and wildlife of the pristine wilderness environment as nature intended.\nSundowner drive: A great way to finish your day in the Kalahari red dunes is to participate on a sundowner drive in an open off-road car under expert guidance. This is definitely one of the most dramatic hours of the day in the desert.\nJogging: Join Namibia's fastest marathon runner (2 hours and 15 minutes) on one of the The Kalahari Red Dunes Lodge own jogging trails. One of the lodge's bushman residents trains in the early morning and evening. Distances of up to 20km have been set up for those keen on keeping up their fitness whilst on holiday.\nHiking: Another great way to explore the Kalahari Desert is to take a guided or unguided walk around the private reserve. All trails are clearly marked and drinking water is available at designated stops. Distances range from between 5-20km and last from 2hrs to all day. Tour guides can provide advice and assistance to set up a hike of a suitable distance and duration catering to your own fitness and requirements.\nMountain biking: Kalahari Red Dunes Lodge have 2 mountain bikes available for guests to ride on original bike trails in the private nature reserve. Crossing the Kalahari Desert on a modern mountain bike entails a bit of hard work but is great fun and healthy exercise at the same time. Experience the breathtaking vastness of the camelthorn savannah from a rather unusual mode of desert transport.\nVisit to the Protection of the Devil’s Claw Site: The Devil's Claw is a rare plant that produces healing ingredients for rheumatic and arthritic diseases. This has resulted in the roots being harvested out of the dry Kalahari sand almost to extinction and has recently been classed as an endangered plant species. The name is derived from the way this plant spreads its seeds. The Devil's Claw Project aims to provide a certain amount of water, falling as rain, to enable the plants to sprout and produce seeds in October not just March.\nOnly 25 kilometers west of Mariental this lodge promises an interesting safari experience. With over 19 game species including white rhino on the property, those seeking wildlife in this arid area are unlikely to be disappointed.\n10 bedroom guest house near the main B1 road in Mariental.\nAuob Country Lodge is the “Green Oasis” in the heart of the Kalahari Desert.”\nExcellent lodge in the Kalahari Desert, offers accommodation in units made of straw bales or wood. Bagatelle proves to be consistently popular with guests.\nInterested in gliding? Then this is the lodge for you.\nOn the private Intu Afrika Kalahari Game Reserve.\nSmall self catering establishment in the pretty Kalahari town of Stampriet.\nCome and let the warm colours of the opulent Kalahari Desert mesmerise you, as you partake in our fully equipped Camping2Go experience.\nTends to cater for larger groups, but the low rates make it attractive for those looking to save some money.\nA small well run lodge near the scenic village of Stampriet.\nClose to the Mata Mata border, the lodge is situated on a large well stocked game park. This is an excellent place to view Kalahari black maned lions.\nOnly a few kilometers from Mariental this magnificent game lodge is a green oasis in the Kalahari Desert. A wildlife breeding program means several rare buck species can be found on the lodge's game farm.\nA wonderful owner managed guest house in the village of Stampriet. An eclectic mix of local antiques & warm hospitality enhance your stay.\nThe meerkat or suricate is a small mammal which inhabits the Kalahari - we do not know why this lodge is named after them. Perhaps if you stay here and find out you can tell us and then we can make this slightly more descriptive.\nA tented lodge, built on the small red dunes of the Kalahari Desert.\nThe third lodge on the Intu Afrika Kalahari Game Reserve (along with Suricate & Camethorn Lodges). The Kalahari is absolutely magnificent and really should be a part of any visit to Namibia.\nThese are honest reviews, both good and bad, from our travellers who visited this property.\nRoom not clean, no hot water second day, few guys of the staff not friendly but great animal tour. Lodge almost empty..\nExceptional lodge - staff very good, food excellent, lodges first class, game drives terrific - no complaints whatsoever.\nAlso very nice, small but cosy. We liked it there although after Gocheganas it first seemed to be too small, it was still very nice\nlike for all the other lodges, you should make people aware that at night it can be FREEZING, so people should bring their ski clothes.............\nwe were afraid it could be quite similar to Bagatelle but we were quite happy with it, we had a walk there in the morning, was nice. A bit too close to the road.\nliked this place very much. partly due to the meerkat Toffee that the staff feeds so its semi trained. It would come sit in the kids laps. highlight of the trip for the kids.\nIt was OK. Food was acceptable but certainly nothing special (pork and vegetables). Bike paths were not that well marked so we got lost in the heat of the day. Staff were friendly.\nGreat place for first real nights on first trip to Namibia. A comfortable and welcoming lodge with real feel of Africa without being too far away or presenting any driving challenges. We loved it\nExcellent value, nice touches such as free wine/beer in fridge and a little carved elephant on the pillow! Tame meerkat was very cute. Good food, but lodge was very quiet and no activities were available.\nGood service and we enjoyed the affections of Doffy the meerkat. We couldn`t do the afternoon sundowner drive as it was full ( taken by non resident family we think). The management need to communicate activity options more clearly.\nThis was also very good - walkways to the restaurant from rooms was what was needed (Wolvedans should do something similar). Not much to see by way of animals but a friendly meerkat (something of a hotel pet) was amusing. A nice place to stop of at.\nFrom Windhoek, drive 190 km south on the B1 towards Mariental. The entrance to Kalahari Red Dunes Lodge is 8 km south of Kalkrand - and is clearly marked from the road.Download Map\nOur interactive Itinerary Builder allows you to plan your trip to Botswana or Namibia, selecting multiple properties on an easy-to-use map. Compatible properties can be booked immediately, and those without online availability can be sent to our reservations team for processing.\nSorry, we can’t seem to find any matches for your search. Have a look at our popular searches below."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:f9ccef07-6826-4db1-9d50-f1098d39d9cd>"],"error":null}
{"question":"Hey moon enthusiasts! 🌙 Can someone explain how the Moon's distance from Earth varies and what effect this has on tides? Would love to understand the connection!","answer":"The Moon's distance from Earth varies as it moves between perigee (closest approach) and apogee (farthest point). Currently, for example, the Moon is 387,753 km away from Earth and will move closer over the next 8 days until reaching perigee at 358,850 km. This variation in distance affects the tides significantly - lunar tides are highest during perigee when the Moon is closest to Earth. This occurs about once per month as the Moon completes its orbit. The tide-generating force depends on both the mass of an object and its distance, so when the Moon is closer to Earth during perigee, it produces stronger tidal forces resulting in higher tides.","context":["Gibbous ♐ Sagittarius\nPrevious main lunar phase is the Full Moon before 5 days on 25 March 2024 at 07:00.\nMoon rises in the evening and sets in the morning. It is visible to the southwest and it is high in the sky after midnight.\nMoon is passing about ∠8° of ♐ Sagittarius tropical zodiac sector.\nLunar disc appears visually 3.8% narrower than solar disc. Moon and Sun apparent angular diameters are ∠1849\" and ∠1921\".\nNext Full Moon is the Pink Moon of April 2024 after 24 days on 23 April 2024 at 23:49.\nThere is medium ocean tide on this date. Sun and Moon gravitational forces are not aligned, but meet at very acute angle, so their combined tidal force is moderate.\nThe Moon is 19 days old. Earth's natural satellite is moving from the middle to the last part of current synodic month. This is lunation 299 of Meeus index or 1252 from Brown series.\nLength of current 299 lunation is 29 days, 9 hours and 20 minutes. It is 19 minutes longer than next lunation 300 length.\nLength of current synodic month is 3 hours and 24 minutes shorter than the mean length of synodic month, but it is still 2 hours and 45 minutes longer, compared to 21st century shortest.\nThis New Moon true anomaly is ∠1.4°. At beginning of next synodic month true anomaly will be ∠17.2°. The length of upcoming synodic months will keep increasing since the true anomaly gets closer to the value of New Moon at point of apogee (∠180°).\n6 days after point of apogee on 23 March 2024 at 15:44 in ♍ Virgo. The lunar orbit is getting closer, while the Moon is moving inward the Earth. It will keep this direction for the next 8 days, until it get to the point of next perigee on 7 April 2024 at 17:53 in ♓ Pisces.\nMoon is 387 753 km (240 939 mi) away from Earth on this date. Moon moves closer next 8 days until perigee, when Earth-Moon distance will reach 358 850 km (222 979 mi).\n4 days after its descending node on 26 March 2024 at 04:07 in ♎ Libra, the Moon is following the southern part of its orbit for the next 9 days, until it will cross the ecliptic from South to North in ascending node on 8 April 2024 at 12:20 in ♈ Aries.\n18 days after beginning of current draconic month in ♈ Aries, the Moon is moving from the second to the final part of it.\n12 days after previous North standstill on 17 March 2024 at 14:45 in ♊ Gemini, when Moon has reached northern declination of ∠28.526°. Next day the lunar orbit moves southward to face South declination of ∠-28.559° in the next southern standstill on 1 April 2024 at 08:58 in ♑ Capricorn.\nAfter 9 days on 8 April 2024 at 18:21 in ♈ Aries, the Moon will be in New Moon geocentric conjunction with the Sun and this alignment forms next Sun-Moon-Earth syzygy.","Predicting the Tides\nKnowing when and how much the tides will rise and fall each day is important to beachcombers, mariners, fishermen, and the people who operate seaside industrial and commercial facilities. Miscalculating the arrival and size of the tides can have expensive, even deadly, consequences.\nPredicting the tides is complicated because the tides are affected by many factors. In this activity, you’ll have a chance to consider some of the most important and universal influences, those due to the movements of the sun, the moon, and the earth. In reality, a number of local and transient factors, such as the shape of the coastline, the flow of currents, and the weather, must also be taken into account.\nInstructions: Observe the relationship between the lunar day and the time, then answer the questions below.\nOver the course of what is called a lunar day, a spot on earth that is directly beneath the moon rotates once until the moon is again exactly overhead. Because the earth spins in the same direction that the moon orbits the planet, the cycle is slightly longer than a regular day -- it takes 24 hours and 50 minutes.\n- How much time passes between one high tide and the next?\nThe tides are caused mainly by the gravitational attraction between the moon and the earth, so the spacing between tides will depend on the length of the lunar day. Since the lunar day is 24 hours and 50 minutes long and the earth rotates through two tidal bulges in that time, high tides will be spaced 12 hours and 25 minutes apart.\n- How much time passes between low tide and the next high tide?\nHigh tides are 12 hours and 25 minutes apart and are separated by a low tide. So low tide must come 6 hours and 12.5 minutes after one high tide and before the next.\nPosition of the Sun and Moon\nThe height of the tides varies over the course of a month. The highest highs and lowest lows, called spring tides, occur when the moon and the sun are aligned. Moderate highs and lows, called neap tides, happen when the sun and the moon are at 90° to one another.\n- Explain how spring and neap tides are created.\nThe tides are created by the pull of the moon and the sun. When those bodies are aligned with one another, their gravitational forces act in the same direction and reinforce one another, creating the maximum possible tidal bulges, called the spring tides. When the sun and moon are at 90o from one another, relative to Earth, their tidal forces are also pulling in different directions, so the neap tides are minimized.\n- How many spring and neap tides occur each month? Why?\nThere are 2 spring and 2 neap tides each month. The moon rotates around the earth once in a month, so in that time it will be aligned with the sun twice, and at 90° to the sun twice.\n- Why does the distance from the earth to the moon or the sun affect the tides?\nThe tide generating force depends on the mass of an object and its distance. As the distance between the earth and the moon or sun changes, the tidal force each produces will vary.\n- When will lunar tides be higher, at perigee or apogee? How often does each occur?\nThe lunar tides will be highest when the moon is closest to the earth, a point in the moon’s orbit that is called perigee. It takes the moon a month to complete an orbit, so perigee will happen about once a month.\n- When will solar tides be higher, at perihelion or aphelion? How often does each occur?\nThe solar tides will be highest when the sun is closest to the earth, a point in the earth’s orbit that is called perihelion. It takes the earth a year to complete an orbit around the sun, so perihelion will happen once a year.\nBe the Captain\nClick the image above to test different scenarios of time of year, moon phase, and orbital phase, to see which tidal levels permit safe travel. Then answer the following questions:\n- Describe the conditions that made a safe trip possible.\nTidal ranges are greatest (higher high and lower lows) when the gravitational forces of the sun and moon are at their maximum and working in the same direction. This will happen when the sun is at its closest point to earth (during perihelion in early January) and so is the moon (at perigee), and when the two are in a line with Earth (during the full and new moons).\n- Your sister ship will have to wait to make the same attempt until you unload your cargo and clear the dock. If you leave on a high tide that crests at noon, when should your fellow captain make his move?\nIf the dock becomes clear at noon, the subsequent low tide will follow 6 hours and 12.5 minutes later. So the other captain should try to pass under the bridge just after 6 p.m."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:97f039d4-55c3-4c55-be85-3d1ff724cd47>","<urn:uuid:3b47dbdc-8192-493b-8862-490baee36301>"],"error":null}
{"question":"What are basic scaffold types and minimum safety inspection rules?","answer":"The three main types of scaffolds are suspended scaffolds, supported scaffolds, and aerial lifts. For safety inspections, OSHA requires that a competent person must inspect scaffolds before each work shift and after any event that could affect the structure. This competent person must be trained in scaffold safety. Additionally, a competent person must supervise whenever a scaffold is assembled, modified, moved, or dismantled.","context":["- 1 How is a float scaffold supported?\n- 2 Can you climb a scaffold?\n- 3 What is allowed for accessing scaffold?\n- 4 What is the purpose of cross braces in scaffolding?\n- 5 What is the maximum load for a single point scaffold?\n- 6 What is the maximum distance allowed between the planks of scaffolding?\n- 7 Do scaffold boards have to be tied down?\n- 8 How high can you go with scaffolding?\n- 9 Can you erect scaffold in the rain?\n- 10 What are the 3 types of scaffolds?\n- 11 Can scaffolding be permanent?\n- 12 What is the minimum height for scaffolding?\n- 13 Is cross bracing necessary?\n- 14 What is a chevron brace?\n- 15 What is bracing In structures?\nHow is a float scaffold supported?\nA float, or ship, scaffold is a suspension scaffold consisting of a braced platform resting on two parallel bearers and hung from overhead supports by ropes of fixed length.\nCan you climb a scaffold?\nClimb on any portion of the scaffold frame not intended for climbing. Always use a fixed ladder, internal access stairway, or built-in ladder to access the working platform. Never climb with any materials or tools in your hand, they should be hoisted up to the scaffold separately.\nWhat is allowed for accessing scaffold?\nDirect access to or from another surface shall be used only when the scaffold is not more than 14 inches (36 cm) horizontally and not more than 24 inches (61 cm) vertically from the other surface. Cross braces on tubular welded frame scaffolds shall not be used as a means of access or egress. 1926.451(f) “Use.”\nWhat is the purpose of cross braces in scaffolding?\nCross bracing between joists or rafters strengthens the members by preventing sideways deflection. This bracing is known by many names such as herringbone strutting, blocking, bridging, and dwanging.\nWhat is the maximum load for a single point scaffold?\nCheck that the maximum intended load for single-point adjustable suspension scaffolds is 250 pounds.\nWhat is the maximum distance allowed between the planks of scaffolding?\n(1) The maximum distance between brackets to which scaffolding and guardrail supports are attached shall be no more than 10 feet 6 inches. (2) Not more than three employees shall occupy a 10 feet 6 inch span of scaffold planking at any time.\nDo scaffold boards have to be tied down?\nTG20 recommends boards which are nominally 38mm thick and less than 2.13m long, should not be used unless they are fixed down to prevent tipping. Boards which are less than 1.6m long may be supported on two transoms but should be fixed down at both ends.\nHow high can you go with scaffolding?\nConstruction scaffolding safety is paramount. OSHA further states that scaffolds more than 125 feet in height above the base must be designed by a professional registered engineer. These scaffold height restrictions reflect the hazards and structural stress when working at such heights.\nCan you erect scaffold in the rain?\nDuring rough weather, a scaffold can get extremely slippery and should not be used. It is also not a good idea to use the scaffold in bad weather such as when it is raining, snowing or in strong winds.\nWhat are the 3 types of scaffolds?\nWorkers who use scaffolds can be divided into three groups:\n- Suspended Scaffolds.\n- Supported Scaffolds.\n- Aerial Lifts.\nCan scaffolding be permanent?\nExperts say employees need to understand that scaffolds are not permanent structures and care must be taken when working on all stages of scaffolding – from their construction to the work that takes place on them.\nWhat is the minimum height for scaffolding?\nIn the general industry, the height requirement for scaffolding is 4 feet above a lower level. For construction work, the height requirement is 6 feet above a lower level. All workers 10 feet above a lower level must have fall protection.\nIs cross bracing necessary?\nDiagonal bracing is really important if you’re working with roof trusses on a room addition. Many a carpenter has been killed or seriously injured when roof trusses suddenly collapse as they’re erected. Wind can easily push them over if they have no bracing.\nWhat is a chevron brace?\nChevron braces are a com- mon. configuration for providing lateral-load re- sistance in steel-framed buildings.\nWhat is bracing In structures?\nA bracing system is a secondary but essential part of a bridge structure. A bracing system serves to stabilize the main girders during construction, to contribute to the distribution of load effects and to provide restraint to compression flanges or chords where they would otherwise be free to buckle laterally.","Discusses the main causes of injuries and deaths when using scaffolds and describes steps that can be taken to minimize the hazards.\nEach year, more than 60 workers are killed by falls from scaffolds, about 1 in 5 of the fatal falls in construction. Besides problems with planks and guardrails, the main causes of injuries and deaths on scaffolds are poor planning for assembling and taking them apart, missing tie-ins or bracing, loads that are too heavy, and being too close to power lines. Also, falling objects can hurt people below scaffolds.\nProtect YourselfScaffolds are supported (usually by posts/beams and legs) or suspended (by ropes).\n- OSHA says a scaffold must be designed by a qualified person.* Supported scaffolds must be able to support their own weight and at least 4 times the maximum intended load .\n- OSHA says a competent person* must inspect a scaffold before each workshift and after anything happens that could affect the structure. The competent person should be trained in scaffold safety.\n- A competent person must supervise if a scaffold is assembled, changed, moved, or taken apart.\n- Power lines: Keep scaffolds 10 feet or more from power lines (or 3 feet, if lines are less than 300 volts), unless you are sure the power lines are de-energized.\n- Weather: You cannot work on a scaffold in high winds or a storm unless a competent person says it is safe and you use personal fall-arrest or a windscreen. (If you use a screen, the scaffold must be secured against the expected wind force.) OSHA says you must not work on a scaffold that has ice or snow on it — except to get ice or snow off the scaffold.\n- If a scaffold is more than 2 feet above or below a level, there must be a way to get on or off — such as a ladder, ramp, or personnel hoist. The access must not be more than 14\" from the scaffold.\n- Put a standing scaffold on a firm foundation (with base plates attached to feet)— for instance, with one piece of wood under each pair of legs (across the shortest distance), extending at least 1 foot past each leg.\n- Uprights must be vertical and braced to prevent swaying; platforms must be level.\n- A scaffold that is more than 4 times higher than its base is wide must be tied to supports.\n- Most scaffold platforms and walkways must be 18\" wide or more. If a work area is less than 18\" wide, guardrails and/or personal fall-arrest must be used.\n- Ten-foot planks must extend at least 6\" past the end supports, but not more than 12\"; no more than 1\" between planks or between planks and uprights.\n- Wood planks must be unpainted, so any cracks will show.\n- For supported scaffolds, check at least these points:\n- Completely planked platforms\n- Proper access\n- Complete guardrails\n- Proper ties to buildings, where required.\n- Supporting outrigger beams must be able to support at least 4 times the intended load. To keep a scaffold from falling to the ground, it must be attached to the roof, tied to a secure anchorage, or secured with counterweights. The suspension ropes and rigging must support at least 6 times the intended load.\n- Counterweights must be attached to secure and strong places on a building so they won’t move. Do not use bags of sand or gravel, masonry blocks, or roofing materials that can flow or move.\n- Do not use gas-powered equipment or hoists. Hoists must have automatic brakes for emergencies.\n- A 1-point or 2-point suspended scaffold must be tied or secured to prevent swaying.\n- OSHA says if a scaffold is more than 10 feet above a level, workers must have fall protection.\n- A competent person must decide if fall protection is feasible when you assemble a scaffold or take it apart.\n- On most scaffolds, guard rails must be on all open sides and ends. On supported scaffolds and some other scaffolds, guardrails or personal fall protection is enough. On most suspension scaffolds, both are needed. Use a harness, not a body belt for personal fall protection.\n- You do not need a guard rail on the working side when the platform is less than 14\" from the work (18\" for plastering and lathing). The open side of an outrigger must never be more than 3\" from the face of the building.\n- On supported scaffolds most of the time, the top rail must be 38\" to 45\" above the platform. A top rail must be strong enough to hold 200 lb. (or 100 lb. on single-point and two-point suspension scaffolds). A mid-rail must be about halfway between the platform and the top rail; most mid-rails must be able to hold 150 pounds. If mesh, screens, or panels are used, a top rail is needed (unless mesh was designed and installed to meet guardrail requirements).\n- Scaffold walkways must have no more than a 9.5\" gap between planks and a guardrail.\n- Don’t let junk collect on the scaffold. You can trip and fall.\nThere must be a 3 1/2\"-high toe board to prevent things falling off a scaffold. If things on the scaffold are taller than 3 1/2\" — above the toeboard — other systems, like debris nets, can be used to catch falling tools or materials. If things can fall off a scaffold, people must be prevented from walking under or near the scaffold.\n- The employer must have a qualified person provide safety training for each worker who uses a scaffold. A competent person must give safety training to any worker who assembles, takes apart, moves, operates, repairs, maintains, or inspects scaffolds.\n- If the worksite changes or the type of scaffold or safety equipment changes, workers using scaffolds must be retrained.\n* OSHA says a qualified person...by extensive knowledge, training, and experience can...solve...problems related to the subject matter.... A competent person is...capable of identifying existing and predictable hazards...and has authorization to take prompt measures to eliminate them. More information on scaffold safety is in the OSHA Construction Standards in the Code of Federal Regulations, CFR 1926.450-454."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:794b238c-32d8-4a6f-900b-3d8e1dd747cb>","<urn:uuid:97e7ef63-252b-4d92-ae85-c465bf048db5>"],"error":null}
{"question":"How do the filtering processes for homemade liqueurs compare with the methods for detecting spoilage in lemon juice, considering quality control aspects?","answer":"For homemade liqueurs, filtering involves a multi-step process: first using a regular strainer, then restraining fruits and nuts while squeezing out juice, and finally using coffee or paper filters in a funnel, replacing filters as needed until no residue remains. For lemon juice, quality control involves checking for changes in smell, color, or taste. Spoiled lemon juice may have a darker color or lack its characteristic citrus taste and smell. For bottled lemon juice, signs of spoilage include leaks or bulging caps. Any lemon juice left at room temperature for extended periods should be discarded due to contamination risk, as consuming spoiled juice can cause food poisoning.","context":["Recipe (click to expand)\n|1 c White granulated sugar |\n1/2 c Water\nSugar syrup is used to make homemade liqueurs. To make, the ratio is 1 part sugar to 2 parts water. Boil together for about 5 minutes at a full boil and be sure the sugar is dissolved. The syrup >>MUST<< be cool BEFORE adding the alcohol mixture as heat evaporates the alcohol. PROPORTIONS: One cup syrup plus three cups 80 proof vodka equals 60 proof liqueur. Two cups syrup plus three cups 80 proof vodka equals 48 proof liqueur. If a 100 proof vodka is used, increase the sugar syrup by 1/8 cup. For a “creme de” liqueur, double the amount of syrup called for in the recipe. The greater the amount added, the lower the alcoholic content. Sugar syrup should be adjusted to personal preference and to the outcome of the liqueur’s taste since variation can occur. See recipes for the following Liqueurs: Banana, Blueberry, Cherry, Cranberry, Orange, Papaya, Pear, Peach, Apricot, Raspberry, Plum, Pineapple, Chocolate, Hazlenut, Irish Cream, Coconut, Coffee, Orange and Coffee Bean Cordial, Almond, Almond Tasty, Tea, Vanilla Cream, Vanilla Pecan, Ginger, Licorice, Cimmamon, Peppermint, Spicy Herbal. NOTE: Health food stores will have the best selection for many of the ingredients. Frozen, canned or dry fruits may be used BUT flavors will often not be as full. Herbs, nuts, and extracts may be added and/or substituted in recipes creating an endless variety of combinations. Try a few basic recipes before experimenting to develop a feel for proportions. Liqueurs should mature as indicated in the recipe before drinking. Storing tends to round out the taste and flavor. Be sure to keep a record of ingredients, amounts, time aged, etc. for troubleshooting and to assure you can repeat the recipe. Batches may vary for a variety of reasons, such as the freshness of fruit, aging time, etc. TIPS/INFO: ~ Herb and spice flavorings are very potent so begin with a small amount – 1/4 teaspoon to 2 teaspoons\n~ Nuts and herbs MUST be crushed or broken to release full flavor ~ Be sure to scrape off all the white rind on orange or lemon peels or a bitter taste will result ~ Blot peels on paper towels to dry off oils and water ~ Ripeness of fruit can affect the final outcome of taste ~ If too weak, add more flavoring and resteep or try 1/4 teaspoon extract ~ To sweeten, the ratio is approximately 1 ounce to 4 ounces ~ If sour or bitter, add more sugar syrup ~ If too sweet, add a bit of lemom and resteep for a week ~ To thicken, add glycerine (1 or 2 teaspoons per quart) which is available at most drugstores and winemaking shops ~ Strain and then filter liqueur once it has aged. To strain, first use a regular strainer and then restrain the fruits and nuts. Squeeze out as much juice as possible. FINALLY, filter the strained juice to achieve a clean finsihed product. Place a coffee filter or a paper filter in a funnel and pour juice slowly, stirring to prevent clogging. Replace filter as required and repeat process if any residue is apparent.","Lemon juice is a useful ingredient added in various dishes and recipes. Even when used in small amounts, it can add great flavor to your dishes. Also, it has been noted as an effective part of many weight loss plans.\nSome people like to purchase lemon juice from the local stores in bulk, as it is considered a staple item in many households. However, there are others who enjoy squeezing fresh lemons and extracting its juice for their consumption.\nBut, what do you do with extra lemon juice? Likewise, you may also be asking yourself – does lemon juice go bad?\nClick to View Post Navigation\nProper Storing Technique for Lemon Juice\nUnfortunately, lemon juice can go bad, especially when it is not handled and stored properly.\nIf you are thinking of purchasing lemon juice in bulk, you should learn how it is properly stored. Here are some important notes to consider when storing this type of juice.\nHow to Store Fresh Lemon Juice\nFresh lemon juice offers the best taste. In handling fresh juice, you should immediately store it in the fridge right after extraction if you are not going to use it yet.\nThe flavor of the juice will not be altered for about two to four days. After this period, it will gradually lose its flavor.\nEven though the fresh lemon juice is acidic, it still does not contain any preservatives. Thus, its taste will only last for about a week and a half.\nIf you intend to keep it for a longer time, you may want to consider freezing or preservatives. Since using preservatives is not healthy, you can choose to freeze it instead.\nProper Handling and Storing Bottled Lemon Juice\nCommercially available or bottled lemon juice already comes with preservatives that extend its shelf life. Because of this, this type of lemon juice can be stored for a long time without compromising its flavor.\nWhen using bottled juice, you should always check its label and look for the best before the date indicated on the container.\nThis time does not mean that it will go bad after the mentioned date. Instead, the date means that the taste, as well as the quality of the juice, should be okay up to that date. After the indicated period, it will gradually lose its flavor.\nWhen storing unopened bottled juice, you may keep it in the pantry as refrigerating it is not necessary. However, if it has already been opened, you can store it in the refrigerator for up to six months.\nFreezing Lemon Juice – Is It Possible?\nTo extend the shelf life of fresh or bottled juice, you may freeze it. It is not advisable, however, that you store the entire bottle because if you need to use it, you will need to thaw the entire bottle.\nOnce thawed, it is not recommended that you freeze it back again.\nTo remedy this problem, you can freeze juice using freezer bags or an ice cube tray instead of the entire bottle. This way, you can thaw the juice in manageable quantities.\nWhen it is stored in the freezer, it can last for another three to five months.\nDetermining the Shelf Life of Fresh and Bottled Lemon Juice\nFresh lemon juice does not last as long as the bottled ones. However, it does taste better and can be stored in the fridge using the right methods to extend its shelf life.\nRefrigerated fresh juice can last up to a week before it will start to lose its flavor and overall quality. However, freezing fresh lemon juice can extend its shelf life up to three to six months.\nOn the other hand, bottled juice already contains preservatives. Thus, it can last up to a few months without spoiling. In fact, it can last up to 12 to 18 months if unopened and stored properly in the pantry.\nHow to Determine Spoiled Lemon Juice\nThe first thing that you need to note when identifying spoiled lemon juice is that it should be stored either in the freezer or the fridge unless it is unopened.\nWhen placed at room temperature, it can become contaminated, especially when you are handling the fresh juice. If you have left the juice at room temperature for quite some time or that you are in doubt about its quality, you should discard it. You should never attempt to taste or consume it because drinking spoiled lemon juice can cause food poisoning.\nWhen checking for spoiled juice, you should look for any changes in smell, color, or taste. If it has a darker color or it does not have any citrus taste and smell, it has probably gone bad.\nIf you notice any leaks or bulging caps on unopened bottled juice, you should discard it, as it may already have gone bad. You should never attempt to consume it even with small portions of the juice.\nThe Bottom Line\nLike any other types of juices, lemon juice can go bad. However, there are various ways on how you can extend its shelf life.\nWith proper handling and storage, you can make use of extra lemon juice for a longer period.\nBoth fresh and bottled juices should be refrigerated once opened. Bottled ones can be stored in the pantry away from direct sources of light and heat and considering it has not been opened yet.\nFreezing lemon juice is also an option. However, this must be done using ice cube tray or small freezer bags. This way, you can thaw the amount you will need and not the entire bottle of juice. Once thawed, it not advisable to freeze it again.\nNow that you know the answer to the question – does lemon juice go bad? You can store your extra lemon juice properly so you can use it later for your other recipes."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:b1ad0552-42fc-4eee-92f6-1f4c9f795a2b>","<urn:uuid:85066922-3731-446c-9e22-ac9ce82d1dc1>"],"error":null}
{"question":"I trade options regularly - what's the difference between covered and naked call options, and how do they compare in terms of risk management potential?","answer":"Covered and naked call options differ significantly in their risk profiles and management potential. A covered call option is when the seller owns the underlying stock, providing protection since they can deliver the shares if the option is exercised. This strategy can generate additional income and offset potential stock price declines. The seller's profit is limited to the stock's rise to the strike price, but they're protected against losses. In contrast, a naked call option is when the seller doesn't own the underlying stock, making it very risky since there's no limit to how high a stock's price can go. When exercised, the naked option seller must buy shares at the current market price to deliver to the option holder, potentially leading to substantial losses. Due to these risks, naked option sellers typically charge higher fees to compensate for potential losses.","context":["The option buyer has the right, but not the obligation, to buy a financial instrument at a specified strike price\nA call option, commonly referred to as a “call,” is a form of a derivatives contract that gives the call option buyer the right, but not the obligation, to buy a stock or other financial instrument at a specific price – the strike price of the option – within a specified time frame. The seller of the option is obligated to sell the security to the buyer if the latter decides to exercise their option to make a purchase. The buyer of the option can exercise the option at any time prior to a specified expiration date. The expiration date may be three months, six months, or even one year in the future.\nThe seller receives the purchase price for the option, which is based on how close the option strike price is to the price of the underlying security at the time the option is purchased, and on how long a period of time remains till the option’s expiration date. In other words, the price of the option is based on how likely, or unlikely, it is that the option buyer will have a chance to profitably exercise the option prior to expiration. Usually, options are sold in lots of 100 shares. The buyer of a call option seeks to make a profit if and when the price of the underlying asset increases to a price higher than the option strike price.\nOn the other hand, the seller of the call option hopes that the price of the asset will decline, or at least never rise as high as the option strike/exercise price before it expires, in which case the money received for selling the option will be pure profit.\nIf the price of the underlying security does not increase beyond the strike price prior to expiration, then it will not be profitable for the option buyer to exercise the option, and the option will expire worthless or “out-of-the-money.” The buyer will suffer a loss equal to the price paid for the call option. Alternatively, if the price of the underlying security rises above the option strike price, the buyer can profitably exercise the option.\nFor example, assume you bought an option on 100 shares of a stock, with an option strike price of $30. Before your option expires, the price of the stock rises from $28 to $40. Then you could exercise your right to buy 100 shares of the stock at $30, immediately giving you a $10 per share profit.\nYour net profit would be 100 shares, times $10 a share, minus whatever purchase price you paid for the option. In this example, if you had paid $200 for the call option, then your net profit would be $800 (100 shares x $10 per share – $200 = $800).\nBuying call options enables investors to invest a small amount of capital to potentially profit from a price rise in the underlying security, or to hedge away from positional risks. Small investors use options to try to turn small amounts of money into big profits, while corporate and institutional investors use options to increase their marginal revenues and hedge their stock portfolios.\nHow Do Call Options Work?\nSince call options are derivative instruments, their prices are derived from the price of an underlying security, such as a stock. For example, if a buyer purchases the call option of ABC at a strike price of $100 and with an expiration date of December 31, they will have the right to buy 100 shares of the company any time before or on December 31.\nThe buyer can also sell the options contract to another option buyer at any time before the expiration date, at the prevailing market price of the contract. If the price of the underlying security remains relatively unchanged or declines, then the value of the option will decline as it nears its expiration date.\nInvestors use call options for the following purposes:\nCall options allow their holders to potentially gain profits from a price rise in an underlying stock while paying only a fraction of the cost of buying actual stock shares. They are a leveraged investment that offers potentially unlimited profits and limited losses (the price paid for the option). Due to the high degree of leverage, call options are considered high-risk investments.\nInvestment banks and other institutions use call options as hedging instruments. Just like insurance, hedging with an option opposite your position helps to limit the amount of losses on the underlying instrument should an unforeseen event occur. Call options can be bought and used to hedge short stock portfolios, or sold to hedge against a pullback in long stock portfolios.\nBuying a Call Option\nThe buyer of a call option is referred to as a holder. The holder purchases a call option with the hope that the price will rise beyond the strike price and before the expiration date. The profit earned equals the sale proceeds, minus strike price, premium, and any transactional fees associated with the sale. If the price does not increase beyond the strike price, the buyer will not exercise the option. The buyer will suffer a loss equal to the premium of the call option.\nFor example, suppose ABC Company’s stock is selling at $40 and a call option contract with a strike price of $40 and an expiry of one month is priced at $2. The buyer is optimistic that the stock price will rise and pays $200 for one ABC call option with a strike price of $40. If the stock of ABC increases from $40 to $50, the buyer will receive a gross profit of $1000 and a net profit of $800.\nSelling a Call Option\nCall option sellers, also known as writers, sell call options with the hope that they become worthless at the expiry date. They make money by pocketing the premiums (price) paid to them. Their profit will be reduced, or may even result in a net loss if the option buyer exercises their option profitably when the underlying security price rises above the option strike price. Call options are sold in the following two ways:\n1. Covered Call Option\nA call option is covered if the seller of the call option actually owns the underlying stock. Selling the call options on these underlying stocks results in additional income, and will offset any expected declines in the stock price. The option seller is “covered” against a loss since in the event that the option buyer exercises their option, the seller can provide the buyer with shares of the stock that he has already purchased at a price below the strike price of the option. The seller’s profit in owning the underlying stock will be limited to the stock’s rise to the option strike price but he will be protected against any actual loss.\n2. Naked Call Option\nA naked call option is when an option seller sells a call option without owning the underlying stock. Naked short selling of options is considered very risky since there is no limit to how high a stock’s price can go and the option seller is not “covered” against potential losses by owning the underlying stock.\nWhen a call option buyer exercises his right, the naked option seller is obligated to buy the stock at the current market price to provide the shares to the option holder. If the stock price exceeds the call option’s strike price, then the difference between the current market price and the strike price represents the loss to the seller. Most option sellers charge a high fee to compensate for any losses that may occur.\nCall Option vs. Put Option\nA call option and put option are the opposite of each other. A call option is the right to buy an underlying stock at a predetermined price up until a specified expiration date. On the contrary, a put option is the right to sell the underlying stock at a predetermined price until a fixed expiry date. While a call option buyer has the right (but not obligation) to buy shares at the strike price before or on the expiry date, a put option buyer has the right to sell shares at the strike price.","Covered Calls is one of the simplest and basic option trading strategies that is frequently used by beginners to experts option traders alike. It is an option strategy in which you own stock and sell At-The-Money or Out-of-The-Money call options in proportion to the shares owned.\nThe selling of call option is usually done on a monthly basis as a mean to collect rent while you retain the ownership of the underlying stock.\nCovered Calls = Long Stock + OTM Short Call\nOutlook: With this stock option trading strategy, your outlook is bullish to neutral.\nYou are expecting a mildly rise in the underlying stock price and/or a drop in volatility.\nRisk and Reward\nMaximum Reward :\nAdvantages and Disadvantages\nExiting the Trade\nStock price rises above the strike price\nStock price below the strike price but above the initial purchase price\nStock price plummets below the initial purchase price\nCovered Calls Example\nAssumption: XYZ is trading at $98 a share on Mar 20X1 and you bought 100 share of XYZ at $98. You would like to earn additional income (beside dividend) from XYZ and don’t mind selling the stock at a profit.\nIn this case, you may consider to sell one Apr 20X1 $105 strike call at $1.50 to earn an additional income. Note: commissions are NOT taken into account in the calculation.\nAnalysis of Covered Calls Example\n= Unlimited due to the potential decline of the stock price (although the stock cannot go beyond zero)\n= [Call Strike – Stock Price Paid] + Call Premium Collected\n= ($105.00 - $98 + $1.50) *100 = $850\n= Stock Price Paid less Call Premium Collected\n= $98 - $1.50 = $96.50\nCovered Call writing enable you to profit from a stock that is range bound, take advantage of contraction in volatility, share in some stock appreciation and entitlement to dividend declared. It is primary a bullish strategy but can also profit from a sideway market. Selling an at-the-money Covered Calls has the equivalent position of selling an at-the-money Naked Put strategy.\nAn option position is usually considered to be ”Covered” if there is a fully offsetting market position (in this case, a long stock position). For example, if you own 800 shares of the stock, XYZ, you can write up to 8 call options in a covered call transaction.\nA Buy Write (also known as covered call write) strategy is a version of covered calls options strategy in which the purchase of stock and sells of call option occur as part of the same transaction. For example, if a stock is trading at $98 a share and a call is selling at $1.50, you can enter a single order to execute the transaction at $96.50 a share or better. By entering the limit order in this manner, you can be sure that you will not be executed on one side of the transaction unless the other side is also executed.\nTime decay is benefiting you here as it reduces the value of the call options. The last month of an option’s life has the greatest amount of time value erosion occurring. Therefore, selling the premium every month over a period of time will generally earn you a higher return than selling premium a long way out. Provided that the stock does not hit the strike price at expiration date, you will be able to retain the full premium of the stock and start the whole process again the following month.\nIf you wish to retain your stock, then you should select the strike price that is further out of money. The further the call is out of the money, the lower the possibility of getting assigned and losing the stock. However, the premium earned is also lower.\nIf you are comfortable in selling your stock near the current value, you can consider to select the strike price that is at-the-money or in-the-money.\nIn this case, you will be able to earn a higher premium, but this also come with a higher possibility of stock being sold.\nDo note that an American Style Option can be exercised by the option buyer (holder) at any time before or on the expiration date. Thus if the stock price is above the call strike price, be prepared that you may be exercised and the stock will be sold… at a profit!!!\nThe strike price and time frame is an important ingredient in determining the potential risk and reward of a Covered Calls strategy. You should pick them according to your risk/reward tolerance and forecast outlook of the underlying stock. Having the patient to wait, knowledge to apply and discipline to follow through the option trading strategies with appropriate risk-reward parameters is important to your long term success in option trading.\nBull Call Spread"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:378172e9-03a6-401d-9aca-d50977a50e29>","<urn:uuid:700825b0-acb1-440a-af68-3daab55e88ae>"],"error":null}
{"question":"Between USS Charleston and USS Wharton, which ship remained in service longer based on their commissioning and decommissioning dates?","answer":"USS Wharton remained in service longer. USS Wharton served from its commissioning on December 7, 1940, until its decommissioning on March 26, 1947 (about 6 years and 3 months). USS Charleston served from its commissioning on December 26, 1889, until it was lost in a grounding accident on November 2, 1899 (about 9 years and 10 months).","context":["CHARLESTON's first duty was to join the South Pacific squadron as flagship. Later, she had the honor of carrying the body of the Hawaiian King Kalakaua back to Hawaii when he died abroad. In 1891, when tensions ran high during a revolution by British-backed rebels against the U.S.-backed government of Chile, the Chilean steamship ITATA left San Diego, California apparently to take supplies to the Chilean rebels. The American government ordered an extensive search for the vessel in which the CHARLESTON took a conspicuous part. The ITATA eventually steamed into Chile without being intercepted. The U.S. demanded that the ship and her contents be turned over to the U.S., an action that the CHARLESTON's Captain Remey stated made the U.S. and her navy \"very unpopular with the Insurgents on account of our action.\" The Insurgents won the rebellion, and the anti-American feeling which the CHARLESTON's commander spoke about boiled over when the crew of Winfield Scott Schley's BALTIMORE went ashore. Two crewmen were killed and a score others wounded.\nIn the latter part of 1891, CHARLESTON was assigned as flagship of the Asiatic Squadron, however during most of 1892 she was again serving with the South Pacific Squadron.\nIn February of 1893, CHARLESTON arrived in Hampton Roads, Virginia. About a month and a half later, she took part in the International Naval Review at the Columbian Exposition. From 1893 to 1896, CHARLESTON steamed around the coasts of South America, and eventually returned to the Asiatic Squadron. The CHARLESTON returned to the United States in July of 1896, and was decommissioned at San Francisco.\nWhen the Spanish American War broke out, CHARLESTON was hastily recommissioned on May 5, 1898. She was ordered to convoy the transports CITY OF PEKING, CITY OF SIDNEY, and the AUSTRALIA, containing 2,500 troops, destined for the Philippines. In addition, the CHARLESTON and her charges carried a new supply of ammunition for Dewey's understocked magazines; a new gun to replace one of the BALTIMORE's , which had been damaged; and sixty-seven additional navy crewmen. On its way across the Pacific, the small squadron stopped at Hawaii, where it was greeted with huge celebrations. The visited helped to further the efforts to have the small island nation annexed by the United States.\nCHARLESTON's next stop on her trip across the vast Pacific was less friendly, but sadly comical. She had been ordered to capture Guam from Spain. The invasion required little effort since Spain had neglected to inform her outpost on the small island that the U.S. and Spain were at war. Charleston captured the island without any bloodshed.\nCHARLESTON arrived in Manila Bay on June 30, 1898, almost to months after the Battle of Manila Bay. As the CHARLESTON and her small squadron approached, there was concern and speculation among the crews of Dewey's ship as they did not know if it was an American or a Spanish squadron that was approaching. The arrival f the squadron was the catalyst for extensive cheering all around. CHARLESTON joined in maintaining the blockade of Manila Bay.\nOn August 13, Dewey's squadron prepared for action against Manila, with the CHARLESTON taking up position to bombard the city's Luneta Battery, should it become necessary. After a few token shots from the assembled squadron, Manila surrendered by a pre-arranged signal.\nFollowing the conclusion of the Spanish American War, CHARLESTON remained in the Philippines and was involved in actions against the Filipino Insurgents. She took part in joint operations with the U.S. Army, and also in the Subic Bay expedition, which resulted in the capture of that strategic deep water harbor.\nOn November 2, 1899, CHARLESTON ran aground on a reef near Camiguin\nIsland, north of Luzon. She was a total loss. Her crew managed to escape\nto a nearby island, where they remained until being picked up by the HELENA\non November 12, 1899.\n|Classification:||Protected Cruiser C-2|\n|Laid down:||January 20, 1887|\n|Launched:||July 19, 1888|\n|Commissioned:||December 26, 1889|\n|Rig:||Two masted schooner|\n|Armament:||Two 8 inch breechloading guns|\n|Six 6 inch breechloading guns|\n|Four 6 pounder rapid fire guns|\n|Two 3 pounder rapid fire guns|\n|Two 1 pounder rapid fire guns|\n|Two Colt revolving Guns|\n|One field piece (for landing parties)|\n|Contractor:||Union Iron Works, San Francisco, CA.|\n|Length:||312 feet, 7 inches|\n|Beam:||46 feet, 2 inches|\n|Draft:||18 feet, 7 inches|\n|Maximum draft fully loaded:||21 feet, 8 1/2 inches|\n|Compliment:||20 Officers and 286 Enlisted Men under the command of Capt. Henry Glass|\n|Engine Type:||Twin screw, horizontal compound engines generating 6,666 hp..|\n|Coal bunker capacity:||757.70 tons|\n|Normal coal supply:||328 tons|\n|Armor:||3 inches on slopes and 2 inches on flats.|\n|Cost:||Cost: $1,017,000 (for hull and machinery).|\nDewey, George, Autobiography of George Dewey (Annapolis: Naval Institute Press, 1987, originally published in 1913 by Charles Scribner's Sons, New York) ISBN 0-87021-028-9.\nGoldberg, Joyce, The Baltimore Affair. (Lincoln: University of Nebraska Press, 1986).\nNaval History Department, Department of the Navy, Dictionary of American Naval Fighting Ships, Vol. 2, Washington DC: Government Printing Office, 1963.\nYoung, Louis Stanley, ed., The Bounding Billow, June 1898. (OLYMPIA's ship newspaper).","|USS Wharton (AP-7)|\n|Laid down:||8 October 1918|\n|Launched:||20 July 1919|\n|Completed:||24 September 1921|\n|Acquired:||8 November 1939|\n|Commissioned:||7 December 1940|\n|Decommissioned:||26 March 1947|\n|Struck:||4 April 1947|\n|3 battle stars (World War II)|\n|Fate:||Sold for scrapping, 21 March 1952|\n12,250 long tons (12,447 t) light|\n21,900 long tons (22,251 t) full\n|Length:||636 ft 2 in (193.90 m)|\n|Beam:||72 ft (22 m)|\n|Draft:||31 ft 3 in (9.53 m)|\n|Speed:||16.6 knots (30.7 km/h; 19.1 mph)|\n|Complement:||666 officers and enlisted|\n• 4 × single 5\"/38 caliber guns|\n• 8 × .50 cal. machine guns\nUSS Wharton (AP-7) was a troop transport and hospital ship in the service of the United States Navy during World War II. Originally built for the Munson Steamship Line as the cargo liner SS Southern Cross in 1921, she was acquired by the Navy as World War II approached and, once the United States became a combatant, she served as a troop transport and hospital ship in the Pacific Theatre. At war's end, she returned Stateside proudly with three battle stars. SS Southern Cross operated in the South American trade from 1921 until acquired by the Navy from the Maritime Commission on 8 November 1939. Two days later, the ship was renamed Wharton and designated AP-7. She was converted to a troop transport by the Todd Shipbuilding Corp., in the Robbins Drydock in Erie Basin at Brooklyn, New York. The transport was commissioned at the New York Navy Yard on 7 December 1940, Capt. Ernest L. Vanderkloot in command.\n- 1 World War II Pacific Theatre operations\n- 2 First wartime operations\n- 3 Invasion of the Marshall Islands\n- 4 Temporary duty as a hospital ship\n- 5 Running aground at Manus\n- 6 Assisting the wounded at Guam\n- 7 Supporting Invasion of the Philippines\n- 8 Supporting the Okinawa invasion\n- 9 End-of-War activities\n- 10 Bikini Atoll A-Bomb testing\n- 11 Post-War deactivation and decommissioning\n- 12 Awards\n- 13 References\n- 14 External links\nWorld War II Pacific Theatre operations[edit | edit source]\nWharton departed Brooklyn on 7 January 1941, bound for Guantanamo Bay, Cuba, where she conducted shakedown before proceeding on through the Panama Canal to her home port, Mare Island, California. Assigned to the Naval Transportation Service, Wharton transported service personnel and their families, as well as cargo, on triangular runs from San Francisco, San Diego, and Pearl Harbor. She also made one trip to Midway Island.\nFirst wartime operations[edit | edit source]\nWhen the Japanese struck Pearl Harbor, Hawaii, on 7 December 1941, Wharton was undergoing overhaul at the Mare Island Navy Yard, Vallejo, California. On 6 January 1942, the transport sailed from the west coast for her first wartime voyage to the Hawaiian Islands. A series of runs followed in which Wharton transported service families and dependents home to the west coast on her eastbound passages and troops and cargo to Hawaii on her westbound trips.\nFrom June through September, Wharton made three voyages to the Southwest Pacific theater — loading and unloading at such ports as Pago Pago, Samoa; Auckland, New Zealand; Espiritu Santo, New Hebrides; Nouméa, New Caledonia; Canton Island, and Suva, Fiji Islands, before returning to the west coast for an overhaul which lasted into October. The troop transport then began a series of trips to the Aleutians which lasted from December 1942 to February 1943, carrying troops from Seattle, Washington, to Kodiak and Dutch Harbor and returning with civilians, troops, and patients. For the remainder of the year, Wharton made five more trips to the Southwest Pacific, during which she revisited Pago Pago, Nouméa, Suva, Espiritu Santo, and Wellington, while adding Apia, British Samoa; Guadalcanal, Solomons; and Efate, New Hebrides; to her itinerary.\nInvasion of the Marshall Islands[edit | edit source]\nIn January 1944, Wharton joined Transport Division 30 for the Marshall Islands operation. Equipped with seven manned LCVP's, Wharton sortied from Pearl Harbor in Task Group 51.1 on 23 January 1944, bound for Kwajalein and Eniwetok, with 526 Army Headquarters troops embarked. The group operated off the island of Bigej in Kwajalein Atoll from 31 January to 2 February, during the shore bombardment phase of the operation and the initial landings, before moving into the lagoon and anchoring there on 2 February.\nTemporary duty as a hospital ship[edit | edit source]\nWharton remained in the lagoon until she headed for Eniwetok on the 15th. Following her arrival there two days later, the troop transport, while disembarking her troops and unloading her cargo, took on additional duty as a hospital ship. She received on board 85 patients for treatment and subsequently transferred them all to other facilities prior to sailing for Kwajalein on 25 February.\nRunning aground at Manus[edit | edit source]\nOn 29 February 1944, Wharton got underway for the Ellice Islands to embark the 11th and 58th Construction Battalions for transportation to the Admiralties. At 1700 on 17 April, while entering Seeadler Harbor at Manus, she ran aground due to an inaccurate chart and poor placement of buoys marking the channel. After the ship had been refloated at 0100 on the 18th, a quick check revealed no damage to her hull or machinery.\nWharton later transported 1,782 men of the Royal New Zealand Army from Green Island to Nouméa before sailing for Espiritu Santo and Guadalcanal. At the latter island — the scene of bitter struggles from August 1942 to February 1943 — the ship participated in training exercises with Transport Division 8. After two weeks of practice landings, Wharton sailed for Kwajalein with 1,587 troops of the 2nd Battalion of the 12th Marines and the 1st Battalion of the 3rd Marines embarked. At Kwajalein, she transferred the latter unit to LST's for the impending operations against the Japanese-held Marianas.\nShe got underway for Guam on 12 June and spent 17 days at sea before returning to Kwajalein, because fierce Japanese resistance on Saipan had forced Admiral Nimitz to postpone American landings on Guam. Underway again on 17 July, the transport made landfall off Guam four days later and soon disembarked her assault troops. That night, she retired to sea until midnight, when she reversed course to return to the beachhead for her role as casualty evacuation ship.\nAssisting the wounded at Guam[edit | edit source]\nOn the day that followed, she continued this pattern of operations. Although not designed for such work, Wharton performed yeoman service off the beaches. Two of the ship's lifeboats were kept ready in their davits for instant deployment, and litters containing casualties were brought alongside in landing craft and transferred to these boats which were then hoisted up to the promenade deck level to be rushed to emergency dressing stations in the passenger officers' wardroom spaces. During the landing operations, some 723 patients were logged into Wharton's sick bay, most of them coming on board by way of this improvised \"lifeboat elevator.\" Operating in company with USS Rixey (APH-3), Wharton returned to the transport area each morning for eight successive days to receive casualties and send an occasional beach party ashore. These latter groups worked on the off-shore reef, unloading supplies and ammunition from LCM's — which could not cross the coral to waiting amphibious tractors which carried the cargo to the beachhead. Working often in 24-hour stretches, these men on occasion came under enemy mortar fire. On 29 July, her part in the Guam operation completed, Wharton headed for Eniwetok with 519 patients embarked.\nFollowing the Marianas operation, Wharton returned to the United States, reaching San Francisco on 25 August. After two months of repairs, the ship resumed her transport duties and made a voyage to Guadalcanal, Espiritu Santo, and Nouméa before returning to the United States late in the year.\nSupporting Invasion of the Philippines[edit | edit source]\nOn 7 January 1945, Wharton got underway for the Philippine Islands, carrying troops and cargo in support of the operations to wrest the islands from the Japanese. She disembarked 1,386 troops and 131 tons of cargo at Samar on 14 February and, two days later, unloaded 134 tons of cargo and 869 more troops at Leyte Island. Underway for home on the 17th, the transport stopped at Ulithi before pressing on eastward and arriving at San Francisco on 12 March.\nSupporting the Okinawa invasion[edit | edit source]\nWharton next participated in the operations against Okinawa, arriving offshore on 19 May. The transport soon disembarked 2,118 troops (including 30 Army nurses) in LCM's sent from shore, as Wharton ordinarily carried no landing craft of her own. Several times, the ship went to general quarters and was screened by smoke, but she emerged from the campaign unscathed by kamikazes that had taken such a dreadful toll from American ships. On 22 May, the transport departed for the Caroline Islands, with 273 troops and 29 casualties embarked, and arrived at Ulithi on the 28th.\nWharton took part in no further combat operations and returned home — via Seeadler Harbor, Guadalcanal, Espiritu Santo, Nouméa, and Suva — to San Francisco on 25 June. The ship remained there until 3 August, when she moved to Seattle, Washington, before returning to Pearl Harbor.\nEnd-of-War activities[edit | edit source]\nHostilities had then ended, but the gigantic job of returning troops from the far-flung bases and islands nonetheless remained. Wharton conducted three voyages to the western Pacific — calling at Eniwetok, Guam, Saipan, Samar, Tacloban, and Puerto Princessa through the end of 1945 to pick up Army, Navy, and Marine Corps veterans and return them to the United States in \"Operation Magic Carpet\". Wharton made one more trip under \"Magic Carpet\" to Yokosuka, Japan, in February 1946.\nBikini Atoll A-Bomb testing[edit | edit source]\nIn the spring of 1946, Wharton participated in \"Operation Crossroads\" — transporting observers to Bikini Atoll for the atomic bomb tests which were to be conducted there in July. She remained there until the completion of her duties on 27 August. She made one round-trip cruise from San Francisco to Guam and one from San Francisco to the Far East, adding Yokohama and Sasebo, Japan; and Shanghai, China; to her list of ports of call.\nPost-War deactivation and decommissioning[edit | edit source]\nThe transport returned to the United States on 28 January, when she made port at San Francisco prior to heading north to Seattle, Washington, and arrived there on 9 February 1947. On 11 March, the Secretary of the Navy declared Wharton \"surplus to Navy needs\" and accordingly authorized her disposal. Decommissioned on 26 March 1947, Wharton was struck from the Navy List on 4 April 1947.\nAwards[edit | edit source]\nWharton was awarded three battle stars for her World War II service\nReferences[edit | edit source]\n- This article incorporates text from the public domain Dictionary of American Naval Fighting Ships. The entry can be found here.\n[edit | edit source]\n- Photo gallery of USS Wharton at NavSource Naval History\n|This page uses Creative Commons Licensed content from Wikipedia (view authors).|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:28e09509-6747-4921-bf98-2d1c75419c08>","<urn:uuid:f62725cf-223d-4bb3-8947-d88905ef46d3>"],"error":null}
{"question":"What are the key differences between rocks and stones in geological terms?","answer":"In geological terms, rocks and stones have distinct characteristics. Rocks are compacted masses of mineral matter that form in the earth's crust, while stones are generally smaller pieces that can be held in one hand. Rocks are typically layered and can be classified into three main types: Metamorphic (transformed by heat and pressure), Igneous (solidified from lava), and Sedimentary (formed through weathering processes). Stones, on the other hand, are combinations of extracted minerals like limestone or sandstone, with different structures and porosity levels than rocks. Scientifically speaking, stones are made out of rocks, and many little stones will make up a big piece of rock.","context":["Rock painting is a super enjoyable creative activity that is just as fulfilling when done alone, or together in a group. The kind of results that you can get from rock painting can be as simple or as complicated as you want it to, which means that beginners and experienced artists alike can enjoy the process of putting their designs onto a small, natural canvas.\nThe Difference Between Rock And Stone\nAnd when it comes to rock painting, the name itself gives it away – you need to have rocks, in order to participate in rock painting. “But hold on a minute – aren’t rocks and stones the same thing?” you might ask yourself. Well, technically, yes – and no. Here are the differences between rock and stone.\nWhat Is Rock\nThe word rock lends itself to imagery of big, towering pieces, with rough jagged edges and cliffs facing the open sea. However it can also basically mean a small piece that can be held in the hand rather than being lugged around using ropes and special tools.\nIn summary, a rock is made up of stone, and all kinds of other mineral matter that naturally occurs in the earth’s crust. They form in the crust and make their way into the earth’s surface in several ways, such as lava from volcanoes, or forming in deep underwater caves, or becoming fossilized deposits on the surface of the earth.\nTypes Of Rock\nWhen it comes to rock, there are 3 types that are generally known, and these are Metamorphic, Igneous, and Sedimentary.\nMetamorphic rocks are described as rocks that have become completely different from the initial rock they started out as. This is due to being subjected to high pressure, heat, and minerals as they go about their lifespan.\nIgneous rocks are basically solidified lava from volcanoes, where it starts out as hot, molten, mineral-rich substances and solidifies when it comes into contact with water or cools down with exposure to air.\nSedimentary rock is rock that has been weathered down to a particular shape and size thanks to naturally occurring geological processes such as erosion, precipitation, and dissolution. They basically start out as large rock pieces that slowly become smaller and smaller due to exposure to the changing weather patterns over the years – one of the msot famous examples of sedimentary rocks is our very own Grand Canyon, in Arizona state.\nWhat Is Stone\nStones are generally understood to be smaller rocks that can be held in one’s hand. However, it goes a little bit deeper than that. While it is true that stones and rocks are made out of the same thing, stones are actually combinations of different extracted minerals like limestone, or sandstone.\nThey are also not as layered as rocks can be, due to the fact that they have completely different structures and porosity levels as big rocks. In saying that however, the general understanding is that stones are the hard subtstances that combine to form the structure of natural rocks.\nTypes Of Stone\nThere are many different types of stone in the world, but the two most common ones are limestone, and sandstone, which is used in construction applications all over the world.\nLimestone is a sedimentary rock, and it is composed of calcium carbonate, although it may contain some amount of magnesium carbonate in some cases. It is used as an essential component in the making of concrete and cement, and in road building applications all over the world.\nAs its name suggests, sandstone is made out of tiny sand particles that are bound together into a cohesive solid mass thanks to the process of lithification which cements the entire stone together with the help of quartz, calcite, or clay. It is used mainly in medical applications and is a popular material in treating wounds and broken bones.\nSandstone has a very unique luster and pattern, because it is made out of compacted grains of sand that have been locked together over a very long period of time, and with the addition of other minerals such as quartz and calcite, many different layers and colors can be found in sandstone.\nIs It Rock Or Stone\nSo we now know a little bit more about rock and stone, but how different are they, really? Well, in a general sense of the word, a stone is easier to hold, move and throw than a rock.\nBut when it comes to a scientific difference – stones are made out of rocks, and many little stones will make up a big piece of rock. The former process is much easier as all you need to do is break up a large rock to get stones, however, the latter process will take a much longer time to do – at least a million years or so!\nSo if you’re holding a rock or a stone in your hand, chances are you’re holding a piece of the earth’s natural history – so embrace it and showcase your creativity on nature’s natural canvas by painting your best designs on it!\nSo What Is The Difference Between Rock And Stone\nThough the two terms are often used interchangeably, rocks and stones are different in more ways than one, and hopefully, this article sheds a little bit of light on those differences.\nGeologists use the word “rock” to describe any compacted mass of mineral matter, and which forms on the Earth’s crust. And they use “stone” to describe extracted material which is used in building purposes or any other application. Therefore, for a geologist, “stone” should be used in combination with prefixes, that form the words limestone, or sandstone for example.\nNo matter which term you choose to use, there’s no doubt that rock painting is an activity that goes deep into an almost primal human instinct that our earliest ancestors used to have when they painted on cave walls and rocks (and stones!). This is what makes rock painting such a fulfilling and enjoyable activity that can be done by children and adults of all ages, and is enjoyed worldwide."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:2c30d1d8-8ecd-4662-961b-84ee08df2d38>"],"error":null}
{"question":"What are the key differences between hereditary sarcoma risk factors and hereditary ovarian cancer risk factors?","answer":"Sarcoma and ovarian cancer share some hereditary risk patterns but have distinct genetic risk factors. For sarcoma, mutations in genes including TP53, ATM, ATR, BRCA2, and ERCC2 significantly increase risk, with multiple mutations leading to earlier cancer onset. For ovarian cancer, the main hereditary risk comes from BRCA1 and BRCA2 mutations, with BRCA1 carrying a 44% risk and BRCA2 carrying an 18% risk of developing ovarian cancer. Additional genes like MLH1, MSH2, MSH6, and PMS2 (associated with Lynch syndrome) can increase ovarian cancer risk by up to 15%. Both cancers are influenced by inherited genes, but their specific genetic risk profiles differ.","context":["Scientists have spotted new links between certain gene mutations in the body and the risk of developing cancer, even in genes only loosely associated with the disease.\nThey found that the more genetic variations you carry, the earlier you're likely to develop some forms of cancer, and that knowledge could one day help doctors diagnose cancers in advance, and provide more effective treatments earlier.\n\"This is the first time – in any cancer – that anyone has quantified the effect of multiple rare genetic mutations on cancer risk,\" explained lead researcher David Thomas from the Garvan Institute of Medical Research in Australia.\nWhile scientists know that genetics affect cancer risk, we're still only beginning to understand the complexities of how it works.\nMutations in certain genes, like BRCA1 and BRCA2, are known to be linked to the development of certain types of cancer, but this time, the researchers looked at a broader range of mutations.\nA total of 1,162 patients suffering from sarcoma – cancers of the bone and tissue – were included in the study, which discovered that numerous mutations in 'low-risk' genes can still add up to significantly increase a person's chance of developing the disease.\nThe researchers found that those who had mutations in two genes were substantially more at risk than those who had just one. And the risk factor increased again with mutations in three genes.\n\"Until now, we’ve been limited to single-gene thinking,\" said Thomas. \"So we tell patients, for instance, that carrying a BRCA1 mutation means their breast cancer risk is higher, or that their risk of sarcoma and other cancers is higher if they've got a particular mutation in the p53 gene.\"\n\"The study shows us that the landscape of cancer risk is far more complex than that,\" he added. \"We can now see that the risk for developing sarcoma is increased through the combined effect of multiple genes, and that the more mutations someone carries, the earlier the onset of cancer.\"\n\"In addition to TP53, ATM, ATR, and BRCA2, an unexpected excess of functionally pathogenic variants was seen in ERCC2,\" the authors write in The Lancet Oncology. Defects in these genes significantly increase the risk of developing sarcoma.\nThe study suggests that sarcoma is one of a select group of cancers – like breast and bowel cancer – where our susceptibility is influenced by the genes we inherit from our parents. But it also means that it should be easier to spot high-risk cases sooner, and get the right treatments ready.\nIf replicated in further studies, the findings could give medical experts a new set of genes to scan for - including those that were previously thought to be low-risk - and a reason to look out for combinations of mutations that could have a cumulative effect on a patient's risk of developing cancer.\nFamilial histories of cancer will also give researchers a head-start in identifying which patients might have health problems in the future.\n\"We've never been able to identify these at-risk individuals, and their families, before,\" said Thomas. \"Now we can. That means we can manage risk better, and help those people to get the care they need, when they need it.\"","Up to 20% of epithelial ovarian cancers are thought to be the result of inheriting a faulty gene from either your mother’s or father’s side of the family.\nMany women who have ovarian cancer or who have a relative with ovarian cancer want to find out if the cancer may be hereditary.\nWhat are genes?\nGenes are made up of DNA. They act as ‘chemical instructions’ that tell our body’s cells what to do. Genes determine things such as what colour hair and eyes we have and how tall we are. Genes also provide the recipe for building all the chemical substances in our bodies and allow the cells to function normally. Humans have between 20,000 to 25,000 pairs of genes in every cell of their bodies. One copy of each pair of genes is inherited from each of our parents. Sometimes changes can occur in genes that may stop the gene from working as it should. These changes are often called a ‘faulty gene’ or ‘mutation’. In some cases, these faulty genes can lead to disease.\nOvarian cancer in the family:\nMost women diagnosed with ovarian cancer do not have a history of ovarian cancer in their family. However, some women’s family history of ovarian cancer can increase their risk of developing the disease. You may have a family history by chance or because you have inherited a faulty gene that increases your risk of developing cancer. You are considered to have a strong family history of cancer if you have two or more close relatives on the same side of the family (father’s or mother’s relatives) who have or had cancer and one of the following applies:\n- The family members have all had ovarian cancer or different cancers (e.g. bowel or breast) that can be caused by the same faulty gene. The cancers were diagnosed when the relatives were younger than age 50;\n- You have a family member who has had genetic testing confirming they have a faulty gene;\n- You have Ashkenazi Jewish ancestry (who have a higher incidence of BRCA mutations than the general population); or\n- Your own cancer was diagnosed at an early age, or you have had more than one type of cancer.\nInheriting an ovarian cancer gene:\nOvarian cancer caused by inheriting a faulty gene is called ‘hereditary cancer’. Having a personal or family history of ovarian, breast, colon or endometrial cancer may mean you have inherited an increased risk of developing ovarian cancer.\nGenerally, the more relatives from the same side of the family who have had these related cancers, the greater your risk of having a hereditary cancer. However, it is still possible to inherit a faulty gene without having a family history of these cancers.\nInheriting a faulty BRCA1 or BRCA2 gene accounts for most cases of hereditary ovarian cancer. These genes are named for their connection to breast cancer (BReast CAncer genes 1 and 2) but can also be associated with other cancers, including cancer of the fallopian tube, peritoneum, prostate, pancreas and breast cancer in men.\nThe BRCA1 and BRCA2 genes normally help to prevent cancer, but when a woman inherits a faulty version of either gene, she is less protected against cancer. Women who inherit a faulty BRCA1 gene have about a 44% risk of developing ovarian cancer, while women who inherit a faulty BRCA2 gene have approximately a 18% risk of developing ovarian cancer up to the age of 80. This compares to less than 2% risk for women in the general population.\nMany women who have a faulty BRCA1 or BRCA2 gene do not have a known family history of ovarian or breast cancer. This can happen for many reasons including:\n- Other family members may have inherited a faulty gene but not have developed ovarian or breast cancer;\n- There may be few females in a family, making it difficult to see a pattern of family history; and/or\n- There may be little know about the family history (eg. a women is adopted)\nAlthough rare, inheriting faulty genes other than BRCA1 and BRCA2 can also increase your risk of developing ovarian cancer. Some of the other genes known to increase the risk of developing ovarian cancer include:\n- Lynch syndrome (also known as hereditary nonpolyposis colorectal cancer syndrome (HNPCC)) is a bowel cancer predisposition syndrome linked to faults in the genes MLH1, MSH2, MSH6 and PMS2. Women who inherit a faulty copy of one of these genes have up to a 15% risk of developing ovarian cancer, however, the risk varies depending on the specific faulty gene inherited.\n- RAD51C and RAD51D faulty genes (very rare).\nThere are also other rare genetic links to ovarian cancer, and ongoing research may uncover genetic links not currently known. Inheriting one of these gene faults increases a person’s risk of developing ovarian cancer but doesn’t mean that they will develop ovarian cancer.\nGuide to genetic testing and hereditary ovarian cancer\nLearn more by downloading our Ovarian Cancer Australia Genetic Testing Booklet"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:e47c971d-8268-4fd5-ab66-50bac2ac253c>","<urn:uuid:9aa6d7eb-6f25-40cc-adcb-2c39912075b6>"],"error":null}