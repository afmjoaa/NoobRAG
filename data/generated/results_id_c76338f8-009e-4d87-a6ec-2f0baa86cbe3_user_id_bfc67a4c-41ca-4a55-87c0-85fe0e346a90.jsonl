{"question":"Please outline the primary symptoms and transmission mechanisms of both mercury poisoning through fish consumption and phylloxera damage in grapevines, including the long-term implications for each.","answer":"For mercury poisoning through fish consumption, symptoms include fatigue, cognitive difficulties, vision and hearing problems, nausea, vomiting, and a metallic taste in the mouth. The toxin enters the food chain when bacteria transform mercury into methyl mercury in waterways, which is then absorbed by marine plants and small aquatic organisms, eventually accumulating in larger fish like shark, tuna, and swordfish. For phylloxera damage in grapevines, the bug uses a thin proboscis to feed on vine roots, similar to a mosquito. While the feeding itself isn't directly fatal, the chemicals excreted during feeding prevent the vine from healing, leading to yellowed leaves and black, rotting roots when thousands of phylloxera attack a single rootstock. The long-term implications differ: mercury contamination persists in environments like San Francisco Bay, where it will take over 100 years to recover and continues to affect human and wildlife health. For phylloxera, while the original crisis was resolved through grafting onto American rootstocks, this solution permanently altered the genetic makeup of European wines, with only a few regions like Argentina's Calchaquí Valley still maintaining pre-phylloxera vines.","context":["Did you know that Argentine malbec is one of the last truly “French” wines?\nMost European wines today, even those famous French ones, come from vines grafted onto American rootstocks. The practice dates back to a plague that changed the world of wine forever.\nMore on that in a moment. But first... Are “older” vines really better?\nThis week, we revisit Julien Miquel’s lesson on just how much vines change as they age… including the trap first-time winemakers often fall for… the potential payoff of waiting for the vines to grow old… and why many wineries replant before that payoff comes…\nBorn in the Plague of ‘65 (Continued)\nHow Phylloxera Destroyed European Wine\nHistorians guess that the bug probably entered France, brought over unknowingly on boats from the new world, sometime around 1863.\nIt would not be discovered until the end of the decade. By that time, French wine, as it had been known for hundreds of years, was mostly extinct. Thousands of acres of vines had died, leaving vintners to puzzle and mourn over yellowed leaves and black, rotting roots.\nPhylloxera is a yellowish aphid-like bug that uses a long, thin proboscis to suck sap out of vine roots, not unlike a mosquito on your arm. It is not the feeding that damages the vine, but the chemicals excreted from the bug in the process, which inhibit the vine from healing itself. Multiply that by several thousand microscopic phylloxera on a single rootstock and death is certain.\nIt takes time for the vine to wilt and die, by which time the bugs are long gone. In the early years of the European plague, scientists could not agree on whether the cause was external (a bug or fungus) or due to some inherited flaw (in 1866, Mendel had created the modern science of genetics by publishing his experiments on inherited traits in plants).\nThe epidemic spreads\nEven when phylloxera finally emerged as the culprit, vintners had no easy cure, which led to a series of desperate efforts including flooding vineyards with water (drowning their vines in the process), and transplanting their vines in plots by the sea (where several vineyards were lost to high tides). An impotent hysteria took hold and entire communities coated their vines in toxic carbon disulfide.\nIn France’s wine growing regions, the economy collapsed. Families were unable to pay their bills. Businesses failed. Train lines shut down.\nHow American Rootstock Saved the Day\nSalvation began in secret, a tip passed on strictement entre nous from one vigneron to the next... “le fléau ne touche pas aux Américains.” Rumor had it some French vintners were having success grafting their old French vines onto American rootstocks. The French are proud, but not proud enough to go broke.\nToday, according to journalist Levi Gadye, “nearly all French wine, including expensive French wine, comes from vines grafted onto American rootstocks.”\nTo wit, the vines producing today’s vintages are not, genetically speaking, the same kinds of vines that produced famous vintages like the 1846 Bourgogne, 1865 Montrachet, and 1870 Lafite Rothschild (look ‘em up)... the vintages that made France’s reputation.\nThose original vines, which include the pre-phylloxera variety of malbec, are known as France’s lost grapes.\nToday, they only persist in just a few places on Earth where phylloxera never managed to take hold.\nArgentina’s Calchaquí Valley is one of those places.\nAt the Bonner vineyard at Gualfín, those old pre-phylloxera malbec vines remain still, the last vestige of what was once the pride of France.\nUntil next time,\nThe Wine Explorer","Dr. Jane Hightower’s sick patients weren’t getting better, and she wanted to know why.\nSome of the California Pacific Medical Center physician’s well-heeled patients were coming into her clinic complaining of fatigue, or trouble thinking – an on-and-off feeling of not being well. Sometimes it was problems with vision, hearing, nausea and vomiting, or a metallic taste in the mouth.\nIn 1999, she began keeping a tally of what they ate. Fish, it turned out – a lot of it. Specifically large fish, like shark, tuna, swordfish, cod and ahi tuna.\nA possible cause began to emerge for their ailments: mercury, a potent neurotoxin that builds up in fish and can cause serious illness.\n“I have a Pacific Heights practice,” said Hightower. “They’re not fishing in Martinez. They’re fishing at Bryans and Whole Foods.”\nBut another at-risk population in the Bay Area, she said, are lower income folks, who do spend time fishing out on the piers in Martinez, Berkeley, Pinole and other East Bay cities every season not only for recreation, but to supplement the family dinner table. The striped bass, sturgeon and halibut they bring home can be loaded with mercury, which is widespread in the bay but impossible to detect with the naked eye.\n“Mercury is invisible and prevalent throughout the bay system,” said Sejal Choksi, executive director of San Francisco Baykeeper, an environmental group that works to reduce pollution in the bay.\nOnce known as “mad hatter disease” after the afflicted Victorian hatmakers who used mercury to produce the felt in their wares, the creeping symptoms of mercury include tremors, problems with vision, hearing, nausea and vomiting, as well as stranger effects like pathological shyness and irritability. The toxin can cause permanent damage to the central nervous system.\nAnyone with an immune-compromised system is at greater risk for deleterious effects of mercury, which is also neurotoxic to developing brains, making it especially dangerous for pregnant and nursing women, babies, and small children.\nMercury is found primarily around the bay in a red rock known as cinnabar. When it settles in waterways, bacteria transform it into a highly toxic form known as methyl mercury, which is easily absorbed by marine plants and the tiny aquatic organisms that eat them.\n“In wildlife, mercury in high concentrations can cause developmental problems, just as it does in humans,” said Choksi. “If you’ve got mercury impairing wildlife and their immune systems, then they’re more susceptible to infectious diseases; they can have cancerous growths. It’s pretty much the same as in the human population.”\nIt doesn’t take much to constitute a problem. Mercury pollution is measured in parts per billion – the amount contained in a drop of water in a backyard swimming pool.\n“So the amount you might find in an old thermometer is enough to cause significant contamination,” said Bruce Wolfe, executive officer with the San Francisco Bay Regional Water Quality Control Board, the state agency that oversees water pollution in the Bay Area.\nSo where does all this mercury come from? Mercury enters the bay watershed from a number of sources, including stormwater and wastewater runoff from local oil refineries and cement kilns. Significant quantities also drift through the air from coal-burning power plants in China.\nBut the biggest culprit can be found at very root of California’s history and prosperity. In the 19th century, Gold Rush miners also mined mercury in copious amounts in the cinnabar-rich hills just south of San Jose. To extract mercury, crushed ore was heated in furnaces and transformed into a vapor. As the gas cooled and condensed, it turned into a liquid form known as quicksilver, which is naturally attracted to gold. Sierra miners used it to separate gold from crushed rock.\nBy the early 1900s, miners had switched to cyanide to extract gold, but mercury still had many uses – in industry, medicine, dentistry (it was used for fillings) and common household products. Even though the mines in the Almaden Hills near San Jose closed decades ago, all that mining left behind a legacy — rocky deposits from the old furnaces are still leaching mercury into the surrounding creeks and rivers, which eventually drain into San Francisco Bay.\nRoughly 2,000 pounds of mercury enter the bay each year from all these different sources. The bay is slowly cleaning itself, washing an estimated 3,100 pounds a year out to sea. But at the present rate, it will take generations for the bay to flush out so much mercury that fish are no longer contaminated.\nTo speed up the process, in 2008 the regional water board launched an ambitious, multi-billion dollar cleanup plan called a Total Daily Maximum Load. The multifaceted plan aimed to reduce both the mercury entering the bay and the amount of the toxin that converts to its poisonous methylmercury form. The plan also provided for advanced monitoring to better understand how mercury makes its way through the watershed.\nSeven years after the TMDL plan went into effect, progress has been made in reducing urban wastewater runoff. Most of the contaminated South Bay mining waste sites have been, or are being, cleaned up, and efforts are underway to remove toxic sediment within the Guadalupe River and its tributaries and reservoirs.\nBut this accounts for only a small fraction of the total load entering the Bay. The greatest source is the legacy poison on the bay floor, which steadily erodes over time and is nearly impossible to clean up. Seven years after the TMDL went into effect, toxic levels in fish and wildlife remain as high as ever.\nThere is a tentative revision of the TMDL planned for 2018. In the meantime, the Water Board estimates that it will take more than 100 years for the Bay to recover. At a minimum, three generations will be impacted by the potent and long-lasting poison still lingering in the bay mud.\nEnvironmental groups say that’s too long to wait for cleaner waters. They want to see enforceable urban stormwater limits for mercury, an accounting of mercury pollution from crude oil refineries, and a full inventory of old mining sites.\n“This process gets you a lot of planning and paperwork but not tangible reduction of mercury in the bay,” said Choksi. “We want to see zero mercury in the bay and we want to see it soon.”\nClick here for the state’s advisory on eating fish from the San Francisco Bay.\nClick here to listen to tips from Dr. Jane Hightower about how to avoid mercury in your diet.\nClick here to learn more about mercury contamination in the bay."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:e2502817-2faa-4209-ab85-493be3cac905>","<urn:uuid:11be0c4a-b0a6-4593-9b3d-a97b9706f26e>"],"error":null}
{"question":"What are the key surface composition differences between Titan and Triton?","answer":"Titan's surface has hydrocarbons like methane and ethane, with a nitrogen-rich atmosphere that includes compounds like propane, carbon dioxide, and helium. Triton's surface, on the other hand, contains nitrogen, methane, carbon dioxide, carbon monoxide, and water ice. While both moons have methane, Titan's surface appears to have more diverse hydrocarbon compounds, while Triton uniquely shows evidence of water ice that can be measured.","context":["Huygens probe lands on Titan: a scientific leap for mankind\n14 February 2005\n“If I have seen further, it is by standing on the shoulders of giants”—Sir Isaac Newton\nOn January 14, 2005, the Huygens probe, a joint space mission between NASA, the European Space Agency (ESA) and the Italian Space Agency, landed on the surface of Titan, the largest moon of the planet Saturn. Huygens separated from the Cassini orbiter “mothership” on December 25, 2004, and landed successfully near the flat Xanadu region of Titan in an area described as resembling “shoreline” and almost earthlike (albeit with methane instead of water). One scientist observed that it landed on a surface with the texture of “creme brulee” that may once have been flooded.\nCassini-Huygens was initially launched on October 15, 1997, from Cape Canaveral in the United States. It was named after two seventeenth century European astronomers. Jean-Dominique Cassini (1625-1712), who was born in Italy and worked most of his life in France, studied Saturn’s rings, discovered their gaps and first proposed that the rings were composed of tiny particles. Christiaan Huygens (1629-1695), the great Dutch physicist, discovered Titan and collaborated with Cassini on many astronomical projects.\nThe mission, involving more than 22 years of preparation, had a number of scientific objectives centred on the exploration of the Saturn system, its distinctive rings and flybys of some of its dozens of moons. The landing on Titan was an integral part of the project. It was the first time a man-made object had landed on the moon’s surface, and is the most distant controlled-descent mission ever undertaken.\nOn January 21, Huygens’s initial data and its findings were outlined in a press conference at ESA head office in Paris. Aware of the magnitude of the landing, Professor David Southwood, ESA’s director of science, read from the poem “On First Looking Into Chapman’s Homer” by John Keats to sum up the exhilaration of uncovering a new world.\nCassini-Huygens is a product of international collaboration in space exploration, a cooperative enterprise that stands in stark contrast to the increasing tension in international relations in other spheres. ESA is responsible for managing the Huygens probe from its control centre in Darmstadt, Germany, while NASA’s Jet Propulsion Laboratory in Pasadena, California, designed, developed and assembled the Cassini orbiter. NASA’s Deep Space Network, also managed by JPL, provides communications support via the Cassini orbiter and then relays this information to the ESA’s control centre. The high-gain antenna on the Cassini orbiter was built by the Italian Space Agency, which also devised some of the radio system and parts of several of Cassini’s onboard instruments. The Huygens payload itself was a joint operation by teams of European scientists from various institutions and NASA.\nThe success of Cassini-Huygens can be measured not simply in terms of landing the probe upright on Titan but on the functioning of virtually all the scientific devices aboard the craft and the subsequent sending of their data back to Earth.\nThe Titan landing captured the public’s imagination. News regarding the fate of the Huygens probe was eagerly awaited by millions of people internationally. On January 15 alone, the ESA web site portal recorded 919,000 external visitors and 6.8 million page views. Between January 14 and January 21, visitors to the site downloaded a total of 6 terabytes of data. At its peak, the site was recording 3,000 separate hits per second. As a reflection of the spirit of international cooperation that launched and maintains the Cassini-Huygens project, the ESA also welcomed the many e-mails sent by the public.\nThe Cassini spacecraft will continue to orbit Saturn for the next four years, returning invaluable information about the Saturnian system back to earth at regular intervals.\nOn July 22, 2004, NASA released the first stunning images of Saturn rings taken by Cassini. The last single “eyeful” image of Saturn and its rings achievable with the narrow-angle camera on Cassini as it moved towards the rings of the planet images can be viewed at http://en.wikipedia.org/wiki/Image:Saturn-cassini-March-27-2004.jpg.\nFurther images are available at http://saturn.jpl.nasa.gov/multimedia/images/index.cfm.\nOn it way to Saturn, Cassini-Huygens also passed by Jupiter, the largest planet in the solar system, garnering much new scientific data and capturing the most detailed global colour photo of the planet ever produced (see http://en.wikipedia.org/wiki/Image:PIA04866_modest.jpg).\nThe Huygens probe had a special role within the mission. Equipped with six scientific multifunction instruments, it was designed to land on the surface of Titan and relay information gathered about the satellite back to Earth. Due to limited battery life, scientists expected a maximum of 90 minutes of data if the lander lasted that long on the surface of Titan. In the event, the probe performed flawlessly, relaying data to Cassini throughout its final 700-mile descent through the atmosphere, which lasted two hours, 27 minutes, and then another 60 minutes worth of data after it landed.\nTitan was chosen over any of the other 30 moons in the Saturn system because it is the only moon in the solar system with its own significant atmosphere. Titan’s atmosphere is 94 percent nitrogen and is the only dense nitrogen-rich atmosphere in the solar system apart from the Earth. The remainder of the atmosphere includes a fusion of hydrocarbons such as methane, ethane, diacetylene, methylacetylene, cyanoacetylene, acetylene, propane, and carbon dioxide, carbon monoxide, cyanogen, hydrogen cyanide, and helium.\nMany of the chemical compounds previously discovered on Titan are similar to those present on the early life of our own planet 4.6 billion years ago. It is in some ways a deep-frozen version of the Earth in formation. The initial findings of the mission and the ongoing analysis of the latter will allow scientists access to important insights into how celestial bodies are formed, what chemical and molecular compounds produce the basis for life, how life may evolve and the evolution of solar systems.\nTitan has fascinated astronomers since its discovery. In his pioneering work, Cosmos, US astronomer Carl Sagan, wrote more than two decades ago, “With abundant organic molecules on its surface and in its atmosphere, Titan is a remarkable and unique denizen of the solar system.” He added that “There is no strong evidence either for or against life on Titan. It is merely possible. We are unlikely to determine the answer to this question without landing instrumented space vehicles on the Titanian surface” (Cosmos, Book Club Associates, 1981, p.162).The mission’s findings\nThe majority of the data returned by the probe will be sifted over by scientists for the next weeks, months and years, but the images taken by its onboard camera and already released were of a quality even beyond that imagined by its designers. The findings regarding the topography and geography of Titan were also very significant in helping to understand this world some 2.2 billion miles away.\nThe Descent Imager-Spectral Radiometer (DISR) imaging system onboard the probe produced a remarkable series of 350 high-resolution photos of a surface bearing an uncanny resemblance to the geology and meteorology of the Earth.\nThe first images available to the public reveal a tight-knit network of narrow drainage channels that are located between brighter coloured highlands and “lowland” areas that are darker in tone. From the images, it appears that these converge into “river”-type systems before flowing into lakebed regions. Within these can be seen what can be described as offshore “islands” and “shoals.” Although these areas appear to be dry, data from the Gas Chromatograph and Mass Spectrometer (GCMS) and Surface Science Package (SSP) points strongly to the possibility that liquid methane flows on Titan’s sub-170°C-temperature surface. The SSP information reveals that beneath the crust of the surface, the “under soil” appears to be a sort of loose-sand type of material. This would be consistent with liquid methane falling on the surface for eons.\nIt appears that the dark material seen in the DISR on Titan’s surface firstly settles out of the deeply layered atmosphere. According to a theory arising from the Huygens images, the dark matter is then washed off high elevations by methane rain and coalesces in concentrated areas at the bottom of the drainage channels and riverbeds, contributing to the dark areas seen in the photos.\nDr. Martin Tomasko, the principal investigator for the DISR, said of the images that “We now have the key to understanding what shapes Titan’s landscape. Geological evidence for precipitation, erosion, mechanical abrasion and other fluvial activity says that the physical processes shaping Titan are much the same as those shaping Earth. Like dry riverbeds where I come from, those drainage channels may fill up again and again as methane rains down from the atmosphere and fills the seas along the shorelines”.\nScientists believe that Titan’s thick atmosphere is a result of hydrocarbons forming in Titan’s upper atmosphere as a result of the breakup of methane by the Sun’s ultraviolet light. This dense atmosphere blocks virtually all sunlight from reaching the surface of Titan, and the Huygens probe was therefore unable to detect the direction of the sun as it approached the moon’s surface. Its images were taken with three radar and infrared camera lenses at different altitudes that produced a spiral-type patterned image.\nData and images taken by Huygens indicate that liquid methane and other organic compounds periodically rain onto its surface. Scientists speculate that sections of Titan’s surface could be covered with a mushy layer of organic precipitate called tholin. Huygens also located the presence of argon 40 in the atmosphere. This is likely evidence of cryovolcanism—volcanic activity producing a mixture of water ice and ammonia—as opposed to molten lava produced by volcanoes on Earth. Triton—the largest moon of Neptune—is another satellite known to have cryovolcanism properties.\nTorrence Johnson, of NASA’s Jet Propulsion Laboratory, said of the findings that “We now have a laboratory up there, where nature has set up a world where you don’t have rocks; you have ice...you don’t have water; you have liquid methane. And it looks like the Mojave Desert.”\nOther instruments analysed wind speeds of up to 150 mph, and microphones picked up sounds of storms rumblings and squealing sounds. Results from the data released on February 10 show that the maximum wind speed of roughly 120 m/s (430 km/h) was measured at an altitude of about 120 km. The winds are weakest near the surface and increase slowly with altitude up to around 60 km.\nFurther images from the Cassini-Huygens mission can be viewed at the ESA web site.Life without water?\nOne of the most intriguing theories relating to Titan and other bodies in the solar system is the question: Does the existence of life depend on the presence of liquid water? There are several scientific opinions and hypotheses regarding this. François Raulin, one of the scientists on the Huygens mission, said, “We cannot say there is absolutely no chance for life. There is no chance for life on the surface because it is too cold and there is no liquid water.\n“However, models of Titan’s interior show there should be an ocean about 100 km deep at around 300 km below the surface. We have liquid water, organics not so far away; we have everything on Titan to make life.”\nIn article published in Nature magazine, January 31, writer Philip Ball argued that this presumption may not be so clear-cut. “Even on Earth, many of the chemical reactions of life take place without water, catalysed by enzymes with water-repellent pockets. And many enzymes work perfectly well in the oily, water-free environment inside cell walls.”\nBall cites the research of Steven Benner and his colleagues at the Department of Chemistry, University of Florida, who hypothesised in the Current Opinion in Chemical Biology magazine that water-free environments on other worlds might fulfill the basic prerequisite conditions for the formation of life.\nScientists are still attempting to understand why the elementary original biological life forms on Earth were not destroyed by contact with water. As a reactive substance, water can interfere with delicate chemical processes. Benner argues that the development of organic life in non-aqueous hydrocarbon liquids (such as the liquid methane thought to flow on Titan) would not face such an obstacle.\nHe stated that “If life is an intrinsic property of chemical reactivity then life should exist on Titan. We need to go back, with a lander that can survive for weeks, not minutes.”\nAnother issue fixating Titan observers is that of uncovering the source of the methane detectable in its atmosphere. Methane is constantly destroyed by UV light, so an important aspect of the research into Titan is to establish what replenishes it in the atmosphere. Methane disappears after 300 years, so whatever is replenishing it is still expected to be present locally on Titan.\nOne of the instruments onboard Huygens, the GCMS, was devised to provide data to help assist in resolving this quandary.The significance of Christiaan Huygens\nThe landing of the Huygens probe more than 300 years after Titan’s discovery by Christiaan Huygens is a significant milestone in the development of astronomy and science as a whole. The mission has once again brought the towering name of Huygens into the public vocabulary.\nHuygens is a pivotal figure in the history of astronomy and made a number of other groundbreaking scientific discoveries and contributions. In this respect, he was cast in a similar mould to Leonardo da Vinci.\nBorn in Den Haag, Huygens lived and worked within a climate of intellectual and cultural freedom in Holland. As Sagan explained, “The connection between Holland as an exploratory power and Holland as an intellectual and cultural centre was very strong. The improvements of sailing ships encouraged technology of all kinds. People enjoyed working with their hands. Inventions were prized. Technological advance required the freest possible pursuit of knowledge, so Holland became the leading publisher and bookseller in Europe, translating works written in other languages and permitting the publication of works proscribed elsewhere.\n“Growing up in this environment, the young Christiaan Huygens became simultaneously adept in languages, drawing, law, science, engineering, mathematics and music. His interests and allegiances were broad. ‘The world is my country,’ he said, ‘science my religion’ ”(Cosmos, p.142).\nA product of the scientific renaissance, Descartes said of Huygens, “I could not believe that a single mind could occupy itself with so many things and equip itself so well in all of them.”\nHuygens extended the work of Galileo in the field of telescopic science, constructing his own 5-metre-long version. He contributed to the theory of refraction, and as a result of his theory of the wave form of light he was able to calculate the refraction within the lenses and make refractors with lesser chromatic and spherical aberration.\nHuygens was the first person to measure the size of another planet and the first to draw part of the Martian surface based on his observations of the planet. He carried out the first systematic survey of Saturn (published in his work Systema Saturnium in 1659) and recognised that it was surrounded by rings that did not touch the planet. (Galileo had already discovered the rings of Saturn but had thought they were physically attached to it.) He also cited the difference of the polar and equatorial diameter of Jupiter and studied the inner brighter regions of the Orion nebula, including mapping its stars. That part of the nebula became known as the Huygens Region. A man of prodigious talent, Huygens made most of these discoveries while still in his twenties.\nHe also made breakthroughs in the science of marine navigation, whilst his invention of the “gunpowder engine” would later influence the invention of the steam engine. Following his study of the game of dice, he became known as the founder of the theory of probabilistics.\nTo paraphrase Sir Isaac Newton, a contemporary and admirer of Huygens, the achievement of the Cassini-Huygens mission both “stands on the shoulders of giants” and is itself a wonderful testament to scientific progress based on the international collaboration of mankind.","Today’s blog features a correction and some additional details on the new Triton map and movie blog posted a few days ago > stereomoons.blogspot.com/2014/08/triton-at-25.html. <\nFirst, a correction. The surface compositions of Triton and Pluto are indeed similar but not quite identical. Triton has nitrogen, methane, carbon dioxide and carbon monoxide on its surface, and probably some water ice, but of those ices Pluto does not have carbon dioxide or water ice that we can measure from Earth. What those differences may mean for geologic and atmospheric history no one can say as yet with confidence, but all the more reason for going to Pluto and someday back to Triton.\nAs a matter of personal opinion, I am sometimes asked which planets I’d like to see explored next. Europa is first on the list, but after that we have the ice giant planets Uranus and Neptune and their strange families of icy moons (including Miranda, Ariel, and Triton to name a few). These large bodies are distinct and different from the gas giants Jupiter and Saturn but have been visited only once, by Voyager 2 with instruments designed in the 1970s. What we could learn by going back has been amply demonstrated by the innumerable discoveries of Cassini at Saturn.\nTriton, whose surface may be younger than a few million years and may be geologically active today, is one of the most fascinating bodies on the Solar System. Its maximum surface temperature is only 35 degrees above absolute zero, and yet volcanoes and geysers have remade its surface, possibly within the lifetime of the human species. Even the Voyager scientists, who had become accustomed to surprises after the discoveries on Io, Ganymede, Titan, Miranda and the rest, were left almost speechless as Voyager made its final planetary visit. As Larry Soderblom exclaimed at the press briefing when he showed the first Triton images, “What a way to leave the Solar System!”\nT-shirt printed up to during the Neptune encounter 1989. The t-shirt and owner are now 25 years older.\nNeptune was fabulous too with its strange and dynamic cloud patterns and its odd, incomplete ring system. One of my first efforts in serious image processing was to reconstruct the Neptune ring high-phase-angle observations. These were the best images of the rings we got, but the long exposures saturated Neptune itself and created bright haloes that were difficult to suppress. Normally exposed Neptune crescent images were substituted but the heavy filtering required for the bright haloes also enhanced noise in the images. The end result was a montage showing a crescent Neptune and the entire ring system. This was done back in 1992 or 93, so I’m sure I or someone else could do a better job now. It is a composite of 5 (or 6?) different exposures taken at different times and distances from Neptune, but all the data are real.\n|Crescent mosaic of Neptune from Voyager 2 on departure, August, 1989.|\nTriton Map: Enhancement and 'Color'. The enhancement applied to the Triton map in the August 21 post was a modest contrast-stretch only; no differential color enhancement was applied. Surface brightness contrasts on Triton exist but are not as strong as on Pluto. The color does have a greenish cast in equatorial areas. This seems to be real, but there are ‘concerns’ with Triton’s color. First, the color images were sometimes smeared or noisy, due to long exposures under very low solar lighting intensity for which the cameras were not designed. This explains some of the splotchy color mottling that is apparent in a few areas. Secondly, there are some uncertainties in the photometric properties of Triton. Earth-based spectra of Triton obtained in the 1970’s and 80’s differ in the inferred visual color of Triton and it was not possible to get an exact color ‘calibration’ on Triton. We did our best, but the colors may not be only approximate, given the slightly different color sensitivity of the Voyager 2 camera.\nThe Triton map is suitable to drop into Google Earth or similar programs! You can now zoom and spin on Triton in any way you like.\nNeptune in the Movie. Several have asked why Neptune doesn’t appear in our movie. Several reasons, the most important of which is that we ran out of time for the August 25 anniversary. The second is that we compress almost 10 days of the encounter into 1 minute. Neptune would probably appear in 2, maybe 3 of those frames. We are looking into it. We know that Neptune and Triton do appear together in the sky about a day out from Triton, and again 6 days later, but do not appear in proximity to each other on the way in, apparently. We may attempt to add Neptune back in for a final version later this year."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:af4aa962-1f2d-4eac-b42d-b3e5ea6ff07f>","<urn:uuid:ed308921-dc2f-4441-bb4f-e01984f85367>"],"error":null}
{"question":"Why do metals like lead and mercury affect children differently than adults? I'm curious about how their bodies process these toxins! 🤔","answer":"Lead and mercury affect children differently than adults primarily due to developmental factors. For lead, children under 6 years old are at higher risk because they have an incomplete blood-brain barrier that allows lead to enter their developing nervous system, and their GI tract absorbs lead more efficiently. Similarly, mercury, particularly metallic mercury and methyl mercury, can cross the placenta and concentrate in the fetus, making them highly neurotoxic for developing children. Both metals can cause significant neurodevelopmental effects, with lead potentially causing lower IQ scores, behavioral changes, and loss of developmental milestones, while mercury exposure can lead to neurocognitive developmental deficits.","context":["Why do we screen for lead?\nThe goal of lead screening is to minimize the neurodevelopmental effects of lead poisoning through source control and early detection.\nLead is absorbed from the GI tract more efficiently in younger children, so they are at higher risk of symptoms owing to lead poisoning. Similarly, kids <6yo are more susceptible to the toxic effects of lead because they have an incomplete blood-brain barrier that permits the entry of lead into the developing nervous system.\n- The relationship between iron deficiency and elevated lead levels remains inadequately understood. Iron deficiency increases the rate of absorption of some divalent metals, including lead. Furthermore, children with iron deficiency anemia tend to present with higher lead levels.\nWhen the neurologic system is affected, children can experience multiple effects:\n- Behavioral changes\n- Lower IQ scores\n- Loss of language and developmental milestones\n- Hearing loss\n- Seizures and encephalopathy (in presence of severe toxicity)\n- Abdominal pain\n- Impaired vitamin D metabolism\nKey point: There is no safe lead level. Children are especially at risk from lead because of their small size and developing brains. Lead exposure can affect nearly every system in the body. Even low levels of lead in blood have been shown to negatively affect a child’s intelligence, ability to pay attention, and academic achievement.\nUniversal childhood lead screening is required by law in multiple states, especially in the northeast US, including Rhode Island!\nWho’s at risk?\nThere are many sources of lead:\n- Plumbing / drinking water\n- Consumer products (e.g., plastics, older toys, jewelry)\n- Certain foods/supplements (e.g., certain imported candies and herbs)\n- Certain occupations/activities (e.g., battery manufacturing, metal work, older home renovation)\nAs such, there are many populations at high risk for lead exposure: children <6yo, children with developmental delays (increased mouthing behaviors), houses built before 1978 (especially low-income), immigrants and refugees, international adoptees, pregnancy, and certain occupations, as above.\nWait… What happened in 1978?\n- In 1978, the federal government banned consumer use of lead-based paint. Despite this legislation, lead paint is still present in millions of homes, sometimes under layers of newer paint. If the newer paint is in good shape, then underlying lead paint is usually not a problem. Deteriorating lead-based paint (peeling, chipping, chalking, cracking, damaged, or damp) is a hazard and needs immediate attention.\nYou may have noticed that many states that require universal lead screening are located in New England, which has some of the country’s oldest homes. In fact, 80% of homes in Rhode Island were built before 1978.\nThe number of children with elevated blood lead levels has been steadily declining in all areas of Rhode Island over the past 20 years:\nNevertheless, the COVID-19 pandemic has exacerbated lead poisoning for multiple reasons, including children spending more time at home, less access to routine lead testing, delays in lead remediation, and shortages of chelation agents.\nAnother troublesome fact is that, compared to the remainder of the state, the core cities in RI (Central Falls, Pawtucket, Providence, Woonsocket) have twice the rate of children with elevated blood levels:\nRhode Island children with a history of lead exposure, even at low levels, have been shown to have decreased reading readiness at kindergarten entry and diminished reading and math proficiency in the third grade. The most significant declines in academic performance occurred among children with the highest blood lead levels living in the four core cities.\nStarting in 2015, an environmental inspection of a child’s home was offered whenever a single venous lead test was ≥15 µg/dL. The Rhode Island Department of Health sends certified lead inspectors to determine whether lead hazards are present and works with owners to make the properties lead-safe.\nPrimary & Secondary Prevention\nPrimary prevention is the removal of lead hazards from the environment before a child is lead exposed. It is the most effective way to ensure that children do not experience harmful long-term effects of lead exposure.\n- Certificates are required with lease agreements showing documentation of de-leading and inspection\n- A 2016 Rhode Island law requires testing of drinking water in all RI schools\n- Regulations for gasoline, paint, plastic, cookware, and manufacturing\nSecondary prevention includes blood lead testing, follow-up care, and referral. It remains an essential safety net for children who may already be exposed to lead.\n- Universal screening in Rhode Island with blood lead levels at the 1- and 2-year-old well child checks\n- Questionnaire screening after age 2yo:\nThe AAP/Bright Futures’ recommendations for preventive healthcare suggest that the risk for lead poisoning be assessed at 6, 9, 12, 18, and 24 months of age, and annually thereafter through 6 years of age. Screening is performed with a blood lead level (BLL), which may be capillary or venous. Patients who have elevated capillary sampling should have confirmatory venous blood testing.\n- In Rhode Island, for a child between 9-36 months of age, screen once between 9-15 months of age and again 12 months later, between 21-36 months of age.\nManagement depends on the lead level:\n- <5 mcg/dL:\n- Repeat the BLL in 6-12 months if the child is at high risk or risk changes during the time frame. Ensure levels are done at 1 and 2 years of age.\n- For children screened at age <12 months, consider retesting in 3-6 months because lead exposure may increase as mobility increases.\n- Perform routine health maintenance including assessment of nutrition, physical and mental development, as well as iron deficiency risk factors.\n- Provide anticipatory guidance on common sources of environmental lead exposure: paint in homes built prior to 1978, soil near roadways or other sources of lead, take-home exposures related to adult occupations, imported spices, cosmetics, folk remedies, and cookware.\n- 5-14 mcg/dL:\n- Perform steps as described above for levels <5\n- Re-test venous BLL within 1-3 months to ensure the lead level is not rising. If it is stable or decreasing, retest the BLL in 3 months. Refer patient to local health authorities.\n- Take a careful environmental history to identify potential sources of exposures (see above) and provide preliminary advice about reducing/eliminating exposures. Take care to consider other children who may be exposed.\n- Provide nutritional counseling related to calcium and iron. In addition, recommend having a fruit at every meal as iron absorption quadruples when taken with vitamin C-containing foods. Encourage the consumption of iron-enriched foods (e.g., cereals, meats).\n- Ensure iron sufficiency with adequate laboratory testing and treatment per AAP guidelines.\n- Perform structured developmental screening evaluations at child health maintenance visits, as lead’s effect on development may manifest over years.\n- 15-44 mcg/dL:\n- Perform steps as described above for levels 5-14 mcg/dL.\n- Confirm the BLL with repeat venous sample within 1-4 weeks.\n- Additional, specific evaluation of the child, such as a plain abdominal XR should be considered based on the environmental investigation and history (e.g., pica for paint chips, mouthing behaviors). Gut decontamination using whole bowel irrigation is suggested if leaded foreign bodies are visualized. Any treatment for BLLs in this range should be done in consultation with an expert.\n- >45 mcg/dL:\n- Follow guidance for BLL 15-44 mcg/dL, as above.\n- Confirm the BLL with repeat venous lead level. Timing of repeat BLL is determined by whether symptoms of lead poisoning are present and the height of the initial BLL.\n- Perform chelation therapy (managed with the assistance of an experienced provider). Hospitalize patients in whom lead safe housing cannot be assured and all patients with BLL >69 mcg/dL. Safety of the home with respect to lead hazards, isolation of the lead source, family social situation, and chronicity of the exposure are factors that may influence management.\nBlog post based on Med-Peds Forum talk by Laura Schwartz, PGY1","The heavy metal, mercury (Hg), is a known toxicant that is generated by anthropogenic activities. One of the most significant consequences of mercury pollution is that aquatic organisms can absorb mercury, convert it to methyl mercury and accumulate it in their tissues leading to increasing concentrations in the food chain. This means if you eat a lot of fish, particularly larger fish which are higher up the food chain, you may be ingesting a fair amount of methyl mercury.\nChronic mercury poisoning due to organic mercury ingestion is primarily a central nervous system problem, whereas inorganic mercury poisoning is essentially a renal problem. This is due to their differences in disposition and metabolism, i.e. the lipid solubility of organic mercury, its easy transport across the blood-brain barrier and its conversion in the brain (as well as in other cells) to the highly toxic mercuric ion by catalase. Moreover, unlike mercurous and mercuric ions, metallic mercury and methyl mercury (MeHg) are able to cross the placenta and be concentrated in the fetus, making them highly neurotoxic for the fetus. The NIEHS supports grants investigating the possible deleterious effects of inorganic (mercuric) and/or organic mercury on the brain, kidney and immune system in epidemiological as well as mechanistic studies.\nTwo studies supported by NIEHS are especially relevant since they are examining the effects of chronic low level MeHg in children exposed because of a marine diet. Both cohorts have been exposed to MeHg primarily pre- as well as post-natally.\nThis cohort resides in the Seychelles Island and is homogenous for a variety of cultural and socioeconomic factors that normally are confounders of the neurocognitive tests being used to measure effects. The project is a longitudinal study in which the MeHg exposure of a cohort of children has been followed prenatally to the current age of 66 months. The study established that the amount of MeHg found in mother's hair during pregnancy correlates well with the Hg level in prenatal brain as determined by the autopsy of the brains of 22 stillborns. The MeHg exposure levels, as measured in maternal hair at delivery, range from 0.5-27 ppm with a median of 6.8 ppm. The battery of tests done on these children (McCarthy Scales, Woodcock Johnson Achievement Test, Preschool Language Scale, Bender Gestalt, Achenbach Child Behavior Checklist, Children's Ravens, Digit Symbol),while better at picking up mental deficiency than neurocognitive deficits, are similar to the ones used in longitudinal lead studies. Thus far, the investigators have not measured any detrimental outcomes at age 5 ½ years that correlate with low level MeHg exposure, (Clarkson; P01ES05197)\nGrandjean (R01ES061123) is performing a longitudinal study in a cohort residing in the Faeroe Islands that is also homogenous for a number of factors that can be confounders for the outcome measures being used. Exposure was measured by MeHg concentrations in cord blood and maternal hair. The children have been followed to the current age of 82-84 months. The Hg in maternal hair ranged from 0.2-40 ppm with a median of 4.5 ppm in hair and 22.9ug/g in cord blood. While several of the test instruments were the same as those used in the Seychelles, others used only in the Faroes study were chosen because they were more suited to older children (California Verbal Learning Test, Boston Naming Test, WISC Block Design, Digit Learning, Mood Scale Tactual Performance, Computerized Psychological Test, Finger Tapping, Hand Eye Coordination, Continuous Performance Test, Evoked Potential). The tests measured neurocognitive developmental deficits rather than mental deficiency. Whereas most of the test scores for the cohort are within the normal range, the results show a change in long-term recall measurements that correlates well with MeHg levels in cord blood but not as well with maternal hair Hg. The investigators maintain that the types of subtle changes they see on their test results indicate an effect of Hg in several areas of the brain.\nThere may be several reasons for the different results in the two studies:"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:5ed7d0cf-4876-48d5-ba5e-e3cecc490a85>","<urn:uuid:ef409362-4629-422d-a883-9099e50a2f34>"],"error":null}
{"question":"How Norman motte bailey castle and Welsh concentric castle different in size?","answer":"Motte and bailey castles were relatively small structures that could only house limited groups of troops, while Welsh concentric castles were much larger in scale. The Welsh concentric castles were mammoth structures with multiple walls, towers, and baileys, capable of housing many more soldiers. This size difference is exemplified by structures like Caernarvon Castle, which was so massive that it would cost approximately £40,000,000 to build today.","context":["The Normans were master castle builders. After 1066, England witnessed a massive castle building programme on the orders of William the Conqueror. First, motte and bailey castles were built. Once William had firmly established his rule in England, he built huge stone keep castles. By the time of Edward I, concentric castles were being built.\nCastles were a very good way for the Normans to expand their grip on the English people. The English population greatly outnumbered the Normans and the Normans had to create an atmosphere in which they were feared by the English, therefore, minimising the possibility of an uprising by the English.\nCastles were a sign of Norman power and might. They could be easily seen and as such acted as a deterrent. The castles warned the English that Norman soldiers lived in these castles and that any attempts to rise up against them would be met with force.\nThe castles also gave the Norman soldiers a safe place to live. They were, after all, invaders. William had built a temporary castle at Pevensey to house his troops when they landed in September 1066. This would have been a motte and bailey castle. These types of castles were quickly put up all over England after the Battle of Hastings to enforce Norman control.\nMotte and bailey castles:\nmade of wood quick to put up easy to repair big enough to house soldiers in safety had advantage of height as the castle was built on a motte; the Normans could see the English during the day a motte was a man-made hill you could keep animals in one as a food supply as they were high up, local peasants could easily see them\nBut motte and bailey castles had a number of weaknesses :\nwood is a weak building material; therefore these castles could not be big wood can rot with the rain; it generally weakens with age wood can burn the motte can collapse with the weight of the castle on it they were not big enough to house bigger groups of troops\nOnce William felt that the English had been tamed throughout England, he moved on to building more permanent castles – ones that would last for centuries. These are called square keep or stone keep castles. The most famous of these is the White Tower at the Tower of London. Rochester Castle in Kent is another fine example of a Norman square keep castle.\nThe White Tower, Tower of London\nmade of stone so they lasted longer. Stone would not rot so the castles were a lot stronger than wooden ones. because stone is strong, it is possible to build up so that you have a height advantage and can see for miles. also the walls can be made very thick therefore making them very strong. The walls at Rochester Castle in places are ten feet thick. These castles were much larger than motte and bailey castles and could keep more soldiers in them. They were very difficult to attack because of their size.\nBut square keep castles also had two major weaknesses:\nif the enemy went around you, what could you do? You would be left in your castle unable to do anything. If the enemy attacked you, it could decide to simply starve out by surrounding you. What could you do if this happened?\nAs time moved on and those with power felt more comfortable, they could afford to build bigger castles. These are known as concentric castles. These were bigger in all respects than square keep castles and the most famous king associated with them is Edward I who built numerous concentric castles in north-west Wales. He believed that this was a vulnerable part of his kingdom and that the Welsh could not be trusted. Hence he built these massive castles – by their standards – to demonstrate to the Welsh his power. Bigger castles housed more troops so the threat to the Welsh in that region was very obvious. Edward’s most famous castles can be found at Caernarvon, Beaumaris, Conway and Harlech.","King Edward employed the most brilliant architect and builder of the Medieval era to help with his ambitious projects - Master James of St. George. Another architect figures in references to the ' three Castles ' - his name was Ralph of Grosmont and he probably worked for Edward's father. King Henry III.\nKing Edward I strategy of building Welsh Castles\nKing Edward I decided on a strategy of building elaborate fortresses and Castles in Wales in order to crush and intimidate the Welsh population - History of King Edward I & the Welsh Medieval Castles. His Welsh castle building strategy started in 1278, following the first Welsh rebellion. In 1278 Edward commissioned the building of four major Castles in Wales - Flint, Rhuddlan, Builth and Aberystwyth. More Welsh Castles were built following the second rebellion of 1282 and the building of Caernarfon, Conwy, Harlech and Beaumaris Castles were also commissioned in Wales. Not only did King Edward I build the Welsh Castles he also integrated new townships at the same time. These fortified townships Welsh Medieval Fortified Townships were based on the Burghs, or Burhs, of King Alfred the Great and the Bastides of Gascony. King Edward I was able to keep his tight reign over Wales due to his massive power bases provided by his Welsh Medieval Castles and his purpose-built Welsh Fortified Townships.\nWelsh Concentric Castles\nThe Design and development of the Welsh Concentric Castles played a major role in the history of Welsh Medieval Castle Building. The design and building of Welsh Concentric Castles encompassed some, or all, of the following elements:\n- A Stronger central Keep or Main Tower featured in Welsh Medieval Castle Building and a round or circular shaped Keep was introduced\n- A High wall, complete with towers surrounded the Keep and the Inner Bailey in Welsh Castles\n- At least one lower, outer wall surrounded the Inner High Wall\n- Several Outer Walls and Outer Baileys were often added in the process of building Welsh Castles\n- Several Gatehouses were featured\n- Moats were often added which surrounded the whole Concentric Castle complex\nThe plans to build Welsh Castles were mammoth! The Welsh Medieval Concentric Castles were much bigger than the Norman Castles! The Welsh Castle Building programme introduced thicker, stronger and higher walls interspersed with towers and turrets! The Inner Walls were higher than Outer walls! Drawbridges were added! The Medieval interiors were far more comfortable! The Welsh Concentric Castles were very expensive! Caernarvon Castle cost King Edward I £27,000 - to build this massive Concentric castle today would cost around £40,000,000! The key facts about the Welsh Medieval Castle Building of Concentric Castles are as follows:\n- The Welsh Medieval Castles was Expensive!\n- Welsh Castles featured heavy defences\n- Round or Polygonal shaped Keeps or Towers were introduced\n- Walls were built at different heights and levels\n- The Various forms of defence such as the Barbican, Portcullis, Gatehouse, Moat, Crenellations, Murder Holes etc were added to Welsh Castles"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:7fc7eb97-6e50-41cd-92cb-3ecaa5acad75>","<urn:uuid:6b9b412e-15e7-4594-92be-cf8021b69d5b>"],"error":null}
{"question":"How to adjust Soldano SLO-100's feedback controls for maximum overdrive? 🎸","answer":"For maximum overdrive, set both the depth control and presence control to minimum resistance. This creates flat response in the phase inverter and power amp, maximizes negative feedback, and results in an accelerated transition to overdrive when the power tubes are pushed.","context":["The Soldano Super Lead Overdrive has always had a presence control in the feedback circuit. A depth/resonance control, on the other hand, was originally an optional feature.\n\"Historically, one of the most popular SLO 'mods' is the addition of a DEPTH control to the amplifier's power section. The Depth control is now standard on the SLO-100. The combination of the Depth and Presence controls provides a powerful EQ section that goes well beyond a typical tone stack, enhancing the tonal possibilities of the amp's sonic character.\" 1 -Soldano Custom Amplification\nThe depth control (circa 2007) is fed from the 4Ω tap of the output transformer secondary.\nAccording to the Phase Inverter Bass Response calculator, the 0.047μF coupling capacitors create a flat response over guitar frequencies while attenuating sub-audio signals.\nVoltage gain is approximately 27.\nNew! Guitar Amplifier Electronics: Fender Deluxe - from TV front to narrow panel to brownface to blackface Reverb\nThe power tubes are biased at -59V, so at full power the signal at their grids is 59V peak, 42V RMS. The SLO is designed to produce 100 watts, so the RMS voltage at the 4Ω tap is\nVoltage gain from the power tube grids to the 4Ω tap is\n20V / 42V = 0.48 (-6.4dB)\nThe forward (open-loop) gain from the phase inverter input to the 4Ω tap is therefore\n(27)(0.48) = 13 (22dB)\nThis is the gain without feedback.\nGuitar Amplifier Electronics: Basic Theory - master the basics of preamp, power amp, and power supply design.\nFeedback is maximum when the depth control is set to minimum resistance, the presence control is at maximum resistance, and when the frequency is high enough for the 0.1μF capacitors to act as short circuits. Under these conditions the feedback network between the 4Ω tap and the 12AX7 grid can be approximated by a simple voltage divider.\nThe feedback voltage \"gain\" is\n4.7kΩ / (4.7kΩ + 39kΩ) = 0.108 (-19dB)\nClosed-loop voltage gain is therefore2\nThis is 7dB less than open-loop gain.\nFundamentals of Guitar Amplifier System Design - design your amp using a structured, professional methodology.\nWith the depth control at maximum resistance, the break frequency for the 0.0047μF capacitor is\nHere is a SPICE AC analysis simulation3 from the phase inverter input to the 4Ω speaker tap for three settings of the depth control: minimum (zero resistance, blue), 50-percent rotation (10-percent resistance, red), and maximum (1MΩ, green).\nWith both controls at zero resistance, the 0.1μF capacitor above the presence control has a break frequency of approximately\nHere is the response with the depth control at minimum (zero resistance) and the presence control at minimum (25kΩ, green), 50-percent rotation (10-percent resistance, red), and maximum (zero resistance, blue).\nGuitar Amplifier Electronics: Circuit Simulation - know your design works by measuring performance at every point in the amplifier.\nHere is a simulation that steps both controls through the previously plotted knob positions, for a total of 9 combinations of control settings.\nSoldano's choice of parts values creates a broad palette of feedback control with a 7dB range. The crossover point for the two controls is at about 600Hz. With both controls at minimum, the phase inverter and power amp response is flat, negative feedback is at maximum, and there is a feedback-induced accelerated transition to overdrive.4 With controls at maximum, there is a slight amount of middle scoop and a more gradual transition into distortion as the power tubes are overdriven.\n1Soldano product description. Available at https://www.soldano.com/products/classic/slo-100-classic/ (Accessed May 17, 2020)\n2Richard Kuehnel, Guitar Amplifier Electronics: Basic Theory, (Seattle: Amp Books, 2018), pp. 142-153.\n3Richard Kuehnel, Guitar Amplifier Electronics: Circuit Simulation, (Seattle: Amp Books, 2019).\n4Richard Kuehnel, Guitar Amplifier Electronics: Basic Theory, (Seattle: Amp Books, 2018), p. 152.\nFrom system design concepts to individual stage operation, an all-new examination of Bassman electronics."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:9835ee6d-a74c-4a70-91ac-0b4512d4b0b4>"],"error":null}
{"question":"What is HV 2112? Is this a type of neutron star?","answer":"HV 2112 is a star that was discovered in 2014 as the strongest candidate for being a Thorne-Żytkow object, which is a red giant or supergiant star containing a neutron star at its core. While it shows some unusual properties suggesting it might be a TŻO, the discovering team noted that some of its chemical characteristics don't perfectly match theoretical models. The star was previously catalogued as an asymptotic-giant-branch star but observationally fits better as a red supergiant.","context":["A Thorne–Żytkow object (TŻO or TZO) is a type of star wherein a red giant or supergiant contains a neutron star at its core, formed from the collision of the giant with the neutron star. Such objects were hypothesized by Kip Thorne and Anna Żytkow in 1977. In 2014, it was discovered that the star HV 2112 was a strong candidate.\nA Thorne–Żytkow object is formed when a neutron star collides with a star, typically a red giant or supergiant. The colliding objects can simply be wandering stars. This is only likely to occur in extremely crowded globular clusters. Alternatively, the neutron star could form in a binary system after one of the two stars went supernova. Because no supernova is perfectly symmetric, and because the binding energy of the binary changes with the mass lost in the supernova, the neutron star will be left with some velocity relative to its original orbit. This kick may cause its new orbit to intersect with its companion, or, if its companion is a main-sequence star, it may be engulfed when its companion evolves into a red giant.\nOnce the neutron star enters the red giant, drag between the neutron star and the outer, diffuse layers of the red giant causes the binary star system's orbit to decay, and the neutron star and core of the red giant spiral inward toward one another. Depending on their initial separation, this process may take hundreds of years. When the two finally collide, the neutron star and red giant core will merge. If their combined mass exceeds the Tolman-Oppenheimer-Volkoff limit then the two will collapse into a black hole, resulting in a supernova that disperses the outer layers of the star. Otherwise, the two will coalesce into a single neutron star.\nThe surface of the neutron star is very hot, with temperatures exceeding 109 K: hotter than the cores of all but the most massive stars. This heat is dominated either by nuclear fusion in the accreting gas or by compression of the gas by the neutron star's gravity. Because of the high temperature, unusual nuclear processes may take place as the envelope of the red giant falls onto the neutron star's surface. Hydrogen may fuse to produce a different mixture of isotopes than it does in ordinary stellar nucleosynthesis, and some astronomers have proposed that the rapid proton nucleosynthesis that occurs in X-ray bursts also takes place inside Thorne–Żytkow objects.\nIt has been theorized that the evolution of TŻOs will result in neutron stars with massive accretion discs, as mass loss will end the TŻO stage, and the remaining envelope converts to being a disc. These neutron stars may form the population of isolated pulsars with accretion discs. The massive accretion disc may also result in the collapse of a star, becoming a stellar companion to the neutron star. The neutron star may also accrete sufficient material to collapse into a black hole.\nAs of 2014, the most recent candidate, star HV 2112, has been observed to have some unusual properties that suggest that it may be a Thorne–Żytkow object. The discovering team have noted that HV 2112 displays some chemical characteristics that don't quite match theoretical models, but emphasize that the theoretical predictions for Thorne–Żytkow object are quite old and theoretical improvements have been made since it was originally conceptualized.\nList of candidate TŻOs\n|HV 2112||01h 10m 03.87s||−72° 36′ 52.6″||Small Magellanic Cloud||2014||This star was previously catalogued as an asymptotic-giant-branch star, but observationally is a better fit for red supergiant status.|||\n|U Aquarii||22h 03m 19.69s||−16° 37′ 35.2″||Aquarius||1999||This star was catalogued as a R Coronae Borealis variable.|||\n|VZ Sagittarii||18h 15m 08.58s||−29° 42′ 29.6″||Sagittarius||1999||This star was catalogued as a R Coronae Borealis variable.|||\nList of candidate former TŻOs\n|Candidate former TŻO||Right Ascension||Declination||Location||Discovery||Notes||Refs|\n|GRO J1655-40||16h 54m 00.14s||−39° 50′ 44.9″||Scorpius||1995||The progenitor for both the companion star and the black hole in this system is hypothesized to have been a TŻO.|||\n- Thorne, Kip S.; Żytkow, Anna N. (15 March 1977). \"Stars with degenerate neutron cores. I - Structure of equilibrium models\". The Astrophysical Journal 212 (1): 832–858. Bibcode:1977ApJ...212..832T. doi:10.1086/155109.\n- Levesque, Emily M.; Massey, Philip; Zytkow, Anna N.; Morrell, Nidia (2014). \"Discovery of a Thorne–Żytkow object candidate in the Small Magellanic Cloud\". Monthly Notices of the Royal Astronomical Society: Letters 443: L94. arXiv:1406.0001. Bibcode:2014MNRAS.443L..94L. doi:10.1093/mnrasl/slu080. Lay summary – PhysOrg (4 June 2014).\n- Brandt, W. Niel; Podsiadlowski, Philipp (May 1995). \"The effects of high-velocity supernova kicks on the orbital properties and sky distributions of neutron-star binaries\". Monthly Notices of the Royal Astronomical Society 274 (2): 461–484. Bibcode:1995MNRAS.274..461B. doi:10.1093/mnras/274.2.461.\n- Vanture, Andrew; Zucker, Daniel; Wallerstein, George (April 1999). \"U Aquarii a Thorne–Żytkow Object?\". The Astrophysical Journal 514 (2): 932–938. Bibcode:1999ApJ...514..932V. doi:10.1086/306956.\n- Eich, Chris; Zimmerman, Mark; Thorne, Kip; Żytkow, Anna N. (November 1989). \"Giant and supergiant stars with degenerate neutron cores\". The Astrophysical Journal 346 (1): 277–283. Bibcode:1989ApJ...346..277E. doi:10.1086/168008.\n- Cannon, Robert; Eggleton, Peter; Żytkow, Anna N.; Podsialowsky, Philip (February 1992). \"The structure and evolution of Thorne-Zytkow objects\". The Astrophysical Journal 386 (1): 206–214. Bibcode:1992ApJ...386..206C. doi:10.1086/171006.\n- Cannon, Robert (August 1993). \"Massive Thorne–Żytkow Objects – Structure and Nucleosynthesis\". Monthly Notices of the Royal Astronomical Society 263 (4): 817. Bibcode:1993MNRAS.263..817C. doi:10.1093/mnras/263.4.817.\n- Levesque, Emily; Massey, Philip; Żytkow, Anna; Morrell, Nidia (30 May 2014). \"Discovery of a Thorne-Zytkow object candidate in the Small Magellanic Cloud\". Monthly Notices of the Royal Astronomical Society Letters 1406: 1. arXiv:1406.0001. Bibcode:2014MNRAS.443L..94L. doi:10.1093/mnrasl/slu080.\n- Foellmi, C.; Moffat, A.F.J. (2002). \"Are Peculiar Wolf-Rayet Stars of Type WN8 Thorne-Zytkow Objects?\". In Shara, Michael M. Stellar Collisions, Mergers and their Consequences. ASP Conference Proceedings. arXiv:astro-ph/0607217. Bibcode:2002ASPC..263..123F. ISBN 1-58381-103-6.\n- Mereghetti, Sandro (1995). \"A Spin-down Variation in the 6 Second X-Ray Pulsar 1E 1048.1-5937\". Astrophysical Journal (December 1995) 455: 598. Bibcode:1995ApJ...455..598M. doi:10.1086/176607.\n- Brandt, W. Niel; Podsiadlowski, Philipp; Sigurðsson, Steinn (1995). \"On the high space velocity of X-ray Nova SCO 1994: implications for the formation of its black hole\". Monthly Notices of the Royal Astronomical Society (15 November 1995) 277 (2): L35–L40. Bibcode:1995MNRAS.277L..35B."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:9563d9a9-8ef7-41c4-817d-e89b610a5039>"],"error":null}
{"question":"When did EPA announce the new water protection regulation?","answer":"On January 23, 2020, the Environmental Protection Agency and the Army Corps announced a new regulation that removes clean water protections against discharges of pollution into rivers, lakes, streams, and wetlands across the country.","context":["By Kelly Foster, Waterkeeper Alliance\nReversing more than 40 years of progress and settled law, on January 23, 2020, the Environmental Protection Agency and the Army Corps announced a new regulation that removes clean water protections against discharges of pollution into rivers, lakes, streams, and wetlands across the country.\nWhile the Clean Water Act is focused on protecting drinking water, fisheries, recreation and other important uses of our waters, the new regulation is focused only on protecting large, commercially navigable waters, the territorial seas, and a small subset of the waters that feed into them.\nThe regulation is a definition of “waters of the United States” under the Clean Water Act, and it determines whether toxic chemicals, radioactive waste, sewage, and other pollutants can be dumped into rivers, streams, lakes, and wetlands. Waters that meet the definition of “waters of the United States” are protected. Waters that fall outside it aren’t. That means the pollution prohibitions and controls designed to protect people and water quality simply do not apply — allowing uncontrolled discharges directly into the water.\nBecause everyone understands that clean water is vital to public health and wildlife, and pollution moves downstream, the Clean Water Act’s regulatory definition of “waters of the United States” has long protected traditionally navigable waters, territorial seas, interstate waters, and intrastate rivers, streams, lakes, wetlands, canals and other waters against pollution and destruction.\nThe new EPA and Army Corps regulatory definition is an extreme departure from that, and the impact on our nation’s waters will be dramatic if it is not overturned in court.\nThe regulation is not based on science and it will not protect drinking water, fisheries or recreational uses of the nation’s waters as required by the Clean Water Act. It eliminates protections for these, and many other, categories of waters:\n- Interstate waters that flow across state boundaries (unless protected by another category)\n- Rivers, streams and canals that flow in response to rainfall\n- Rivers, streams and canals that flow year-round or seasonally but do not connect in a “typical year” to commercially navigable waters or the territorial seas via surface flow\n- Lakes that do not contribute surface flow to commercially navigable waters or the territorial seas via surface flow in a “typical year”\n- Wetlands that do not physically touch or become flooded by an otherwise protected water\nThe agencies claim the rule is being adopted to provide regulatory certainty and predictability for American farmers, landowners, and businesses — but it provides nothing remotely akin to that because it creates arbitrary, non-scientific categories of protected waters.\nAlthough there is extensive data available on the hydrology and connectivity of our nation’s waters, EPA and the Army Corps say that “there are significant limitations to the extent to which currently available data can be used to identify the scope of all or even a subset of jurisdictional waters” and that they are “in the early stages” of their effort to develop data necessary to do so. In other words, the agencies do not know which waters are included in the regulatory definition they devised, and they are just now starting to try to figure that out.\nBecause the Clean Water Act would no longer be controlling all discharges of water pollution at their source as intended, we will not know where the pollution is coming from and we won’t be able to clean up downstream waters.\nEven worse, the agencies say they “bear the burden of proof” for determining if a water is jurisdictional and, if they lack data to make that determination, they will treat waters as “non-jurisdictional.” In response to comments pointing out problems with their definition, the agencies describe the shortcomings of the available data and types of complex, case-by-case evaluations they “may” undertake to make a decision. In other words, the agencies’ definition doesn’t provide regulatory certainty for anyone, including the agencies themselves.\nDespite the agencies’ lack of knowledge regarding what their own regulation means for our nation’s waterways, it is possible to get a sense of how many waterways will lose protection. The loss is dramatic, particularly in the West. For example, there are millions of miles of rivers and streams across the country that could lose protection solely based on frequency of flow, including the ephemeral streams that make up roughly 90 percent or more of all surface water in the arid Southwest. And at least 51 percent of the nation’s wetlands could lose protection solely because they do not physically touch a protected river, stream or lake.\nThese are significant and devastating losses, and we know it will be far worse than that. For example, we applied the rule to 12 watersheds across the country and determined:\n- A 14,605 square-mile-area New Mexico’s Rio Grande Basin could lose protection. Additionally, roughly 90 percent of the rivers and streams in the basin could lose protection, including a stream that receives discharges from Los Alamos National Laboratory upstream from a drinking water intake for the City of Santa Fe.\n- Streams and rivers throughout the Meramec and Lower Missouri River watersheds, including 1,083 miles of streams that go subsurface and feed into rivers and springs, could lose protection.\n- All of the waters in a roughly 5,185 square mile area of the Snake River basin that include waters important for recreation, tourism and trout fishing like the Big Lost River, Little Lost River, and Medicine Lodge Creek could lose protection.\nUncontrolled pollution discharged into these waters not only harms the receiving waters directly, but also causes pollution and harm to downstream waters. This is true without regard to whether the water exists because of rainfall, goes subsurface, or doesn’t physically touch a downstream water. And because the Clean Water Act would no longer be controlling all discharges of water pollution at their source as intended, we will not know where the pollution is coming from and we won’t be able to clean up downstream waters.\nThe Clean Water Act requires the agencies to maintain and protect the chemical, physical, and biological integrity of the nation’s waters. The Agencies have instead adopted a regulation that is a giveaway to industrial polluters and will allow widespread pollution and destruction of the nation’s waters. This endangers all of us. Waterkeeper Alliance is committed to overturning this dangerous regulation, and restoring broad water quality protections for our country’s water resources."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:75910c9e-a8ba-47dd-b94b-d4999f345c07>"],"error":null}
{"question":"What are the diverse ways of commemorating Juneteenth across different venues, and how do these celebrations contribute to cultural awareness and education?","answer":"Juneteenth commemorations take place across various venues and formats. In libraries, cultural programs like jazz performances connect visitors to African American musical heritage, with jazz being recognized as a uniquely American art form born from slave songs, work songs, and gospel traditions. Additionally, communities organize street festivals featuring live performances, art, vendors, and family activities. Cultural organizations like the Cleo Parker Robinson Dance host events focusing on Black culture, mental health for Black Americans, and advocacy. These celebrations serve multiple purposes: they honor the historical significance of emancipation, provide educational opportunities about ongoing inequities, and offer ways to support Black-owned businesses and engage with African American arts and culture.","context":["Discover more from Sebastopol Times\nJazz for Juneteenth at the Guerneville Library\nBob Jones enjoyed a lively jazz band on Saturday but he was among the fortunate few.\nAt 2 pm last Saturday afternoon, a fine jazz trio played a set of old standards in, of all places, the Maggie Boynton Room of the Guerneville Library. Though the Giants were playing the Pittsburgh Pirates, and my favorite golfer, Colin Morikawa, was leading the U. S. Open Tournament, which was played on the historic course in Brookline, Massachusetts, my wife and I got ourselves to the library just as the band began to play. Owing to a dearth of publicity, we were the only ones in the audience for the first half of the hour-long set.\nThe Sonoma County Library sponsors these cultural enrichment programs from time to time, and there is really nothing more at the heart of American culture than jazz music. It’s born in a mixture of African rhythms and European harmonies and comes to us through the long hard history of slave songs, work songs, chain gang songs, dark city blues and the gospel songs of Black churches. For all that, it often has a happy, hopeful sound. With its variations and improvisations, it’s little wonder jazz has been called the “sound of surprise.” It has also been called the “sound of freedom.”\nWhatever you call it, jazz is recognized around the world as the unique American art form. It’s important music, especially last Saturday, the day before Juneteenth (June 19th), which is now a national holiday commemorating the anniversary of the Emancipation Proclamation finally being acknowledged in Texas. President Lincoln had signed the Proclamation over two years and six months earlier, but it could not take effect until the end of the Civil War. If that’s not American culture, what is?\nLeading the group was Dave Rocha playing his trumpet and flugelhorn with precision and flare. His cheeks inflate like Dizzie Gillespie’s did, and he sounds to me like he may have listened to a lot of Gillespie in his time. Then there was Randy Vincent, one of the celebrated jazz guitarists in the Bay Area. He’s played with many jazz greats over the years, is on the jazz faculty at Sonoma State University, and is the guitarist of choice when the Santa Rosa Symphony plays Sinatra songs or other jazz-based programs. On stand-up bass was young Dylan Johan, who often plays at Main Street Station, Guerneville’s lively and long-standing live music venue. Dylan is also a luthier, one who builds, repairs, and refurbishes string instruments, and he gives lessons too.\nThese fellows know how to treat a jazz tune, giving each one its due, which takes about ten minutes per tune. So we had maybe seven tunes played in the hour or so of the concert, tunes like “Days of Wine and Roses,” Dave Brubeck’s classic “Take Five,” and Carlos Jobim’s haunting “Triste.” They set down the melody, then take turns improvising solos right in the tune’s groove, then they “trade fours,” each one taking four measures as they go through the song. Finally, they “go home” with the basic tune once again. Music, and jazz especially, builds up tensions and then resolves them. There’s something really satisfying about hearing a familiar musical phrase again after the little adventure into the tune’s possibilities. No wonder they call it “goin’ home.”\nBy the time the band was done, people who heard the music as they were passing by had come in to listen, making eight of us all together. Yep, we were the fortunate few in Guerneville last Saturday afternoon.\nYou can find upcoming events at Sonoma County Libraries here.\nIf you’d like to share an appreciation of a local event, contact us at firstname.lastname@example.org.\nBob Jones wrote “Keeping the Faith”, a column in local weeklies for fifty years. He was pastor of the Guerneville and Monte Rio Community Churches for twenty years, living in Guerneville since 1966. His column appeared in Sonoma West Times and News for its entire run.","A Resource Guide for Juneteenth\nWhat does this day commemorate? On June 19, 1865, approximately two months following the surrender of Confederate General Robert E. Lee at Appomattox, Virginia, Union General Gordon Granger arrived in Galveston, Texas. He told enslaved African-Americans that they were now free and that the Civil War had ended. General Granger’s announcement put into effect the Emancipation Proclamation, issued more than two and a half years earlier on January 1, 1863, by President Abraham Lincoln. This day marks the beginning of freedom - something that has yet to be won. Our definition of freedom is ever-expanding. President Joe Biden signed the legislation that made Juneteenth a federal holiday on June 2021, with tremendous progress in expanding that definition.\nIt has been a long journey since communities came together to demand justice, equity, and freedom during the George Floyd protests, which became the catalyst for many in the U.S. to educate themselves and others, rallying in support of justice, supporting black-owned businesses, and committing themselves to anti-racism. Now is the time to reflect on the past and renew our commitment to creating equitable communities for all.\nJuneteenth is a day to celebrate the freedoms provided by the Emancipation Proclamation. In the spirit of continuing the work to liberate marginalized communities, we ask you to explore events, books, and other mediums to educate yourself about the inequities that persist across the U.S. today.\nWe have included some ideas for engaging and educating yourself this Juneteenth, and we hope you find some on your own! We encourage everyone to reflect, learn, and grow in commemorating this holiday.\nAttend an Event:\nThis historic street festival returns to the Five Points neighborhood on June 17-18th with live performances, art, vendors, and fun for the entire family.\nCelebrate Juneteenth through culture and freedom, and commemorate the end of slavery and brave beginnings. This event is on Saturday, June 17th, from 1:00 – 5:00 PM in Roosevelt Park, Longmont. If you cannot make that time or want more time to celebrate, don’t fret! A second event will be held at the Longmont Theatre Company starting at 7:00 PM.\nCommemorate Juneteenth with Cleo Parker Robinson Dance at their incredible event inspired by culture, mental health for Black Americans, and advocacy. Also, enjoy some incredible performances and discussions about the Black Arts Movement.\nSupport local Black-Owned Businesses:\nWhy is this important to do? Check out this article.\nThe Third Reconstruction by Peniel E. Joseph - The Third Reconstruction delves into the racial awakening in 2020, which the author posits as the pinnacle of a Third Reconstruction. With profound historical parallels, the novel explores the connections and revelations from the First and Second Reconstruction. It traces this Third Reconstruction from the moment Barack Obama was elected to the emergence of Black Lives Matter and the ill-fated attack on the Capitol.\nWhy should you read it? Through a historical lens encompassing America's First and Second Reconstructions, this novel provides context and exploration of the 21st-century struggle for racial justice. Joseph skillfully weaves his personal experiences with impactful historical events, revealing how acknowledging and reflecting upon Black history can guide us in our future path.\nThe New Jim Crow by Michelle Alexander - The New Jim Crow is a stunning account of the rebirth of a caste-like system in the United States, one that has resulted in millions of African Americans locked behind bars and then relegated to a permanent second-class status—denied the very rights supposedly won in the Civil Rights Movement.\nWhy should you read it? Alexander shows that, by targeting black men through the War on Drugs and decimating communities of color, the U.S. criminal justice system functions as a contemporary system of racial control, even as it formally adheres to the principle of colorblindness. If you have watched The 13th on Netflix, this is an excellent resource to learn more.\nFour Hundred Souls by Ibram X. Kendi and Keisha N. Blain - Four Hundred Souls discusses four hundred years of African American history ranging from 1619 to today. Through various unique perspectives, the story is told through a range of historical documents and personal accords.\nWhy should you read it? The authors tackle racial assumptions and deflate them using each of their individual voices. Together, they reveal honest and unspoken foundations of institutional racism to expose an area in American history that has been neglected for so long. Through the history explored in the novel, there is a tangible sense of resilience, strength, rebellion, and endurance from the Black community.\nIn the Wake: On Blackness and Being by Christina Sharpe - Christina Sharpe interrogates literary, visual, cinematic, and quotidian representations of Black life that comprise what she calls the \"orthography of the wake.\" Activating multiple registers of \"wake\"—the path behind a ship, keeping watch with the dead, coming to consciousness—Sharpe illustrates how Black lives are swept up and animated by the afterlives of slavery, and she delineates what survives despite such insistent violence and negation.\nWhy should you read it? Sharpe’s poignant metaphor of anti-Blackness as the climate captures the reality of the pervasiveness of racism in Western culture. She writes about Black life in the wake of this violence, both past and present. Her use of metaphor also makes the theory that can seem intimidating much more accessible. This one will stay with you.\nThe Takeaway: 153 Years of Juneteenth - The truth is many Americans do not know about Juneteenth. Actress Jenifer Lewis, who plays Grandma Ruby on Black-ish, joins to discuss why Juneteenth being \"mainstream\" is essential.\nThe Daily: The History and Meaning of Juneteenth - Hear answers to and ideas as to why Juneteenth has reached its popularity and prominence at times when the struggles and pain for Black liberation seem at their worst. Additionally, listen to how the definition of freedom has changed to accommodate modern times.\nThe Peas in the Podcast: Merry Juneteenth - Hear the Peas discuss what Juneteenth is all about, the ways they celebrate, and the culinary past of the holiday.\nStill Processing - Hosted by two Black, queer culture writers from The New York Times, Jenna Wortham and Wesley Morris, who make sense of the internet, trends, social issues, and pop culture at large.\n1619- A NY Times Podcast on how slavery has transformed America, connecting past and present through the oldest form of storytelling, hosted by Nikole Hannah-Jones.\nSelma - Selma depicts the period after the Civil Rights Act of 1964 had been passed and made segregation illegal. Yet, discrimination was still very pertinent, especially regarding obstacles for Black people to vote. In an effort to hold a non-violent protest against these injustices, Dr. Martin Luther King Jr. organized a march from Selma to Montgomery, and their efforts culminated with the president signing the Voting Rights Act of 1965.\nWhere to watch: fuboTV or Paramount+\nThe Hate U Give – A teenage girl does her best to fit in as a Black girl attending a predominantly white school; yet, things take a turn when she is forced to stand up for herself and use her voice to fight against police brutality and injustices that the Black community faces daily. Maya Angelou passed away in 2014 but was able to participate in this joyful documentary that celebrates her life and her career's vast impact.\nWhere to watch: Apple TV or Amazon Video\nSay Her Name: The Life and Death of Sandra Bland - Say Her Name is yet another depiction of what an interaction with police can lead to for a Black individual.\nWhere to watch: Hulu and Apple TV\nThe Black Power Mixtape 1967–1975 - The Black Power Mixtape is a \"treasure\" of sorts that was found in a Swedish basement and offers never-before-seen interviews with leaders of the Black Power Movement.\nWhere to watch: https://www.youtube.com/watch?v=FWb5HVAAQz0"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:17d8355a-e0cd-48bc-8895-c78c6d91862b>","<urn:uuid:4d74d522-ed08-4d54-b610-d144ec58eefd>"],"error":null}
{"question":"How did John Lennon and Alexander Hamilton's tragic deaths compare? Both were prominent figures killed in shocking circumstances!","answer":"Both men were killed in high-profile shootings in New York. Alexander Hamilton died at age 49 after being shot in a duel with Aaron Burr in New York in 1804. John F. Lennon's death is referenced indirectly through the mention of a memorial statue erected in his honor featuring a revolver with a knotted barrel, created by Swedish artist Carl Fredrik Reutersward and unveiled in London's Trafalgar Square in 2000. Mark David Chapman later pleaded guilty to Lennon's murder and was sentenced to 20 years-to-life in prison.","context":["Music History: June 22\n2015 On the reality dating show The Bachelorette, Jared and Kaitlyn visit Christchurch Cathedral in Dublin, where they are serenaded by Noel Hogan and Dolores O'Riordan of The Cranberries, who perform \"Linger.\" The couple dance and make out as O'Riordan sings:\nWere you lying all the time?\nWas it just a game to you?More\n2010 Lynyrd Skynyrd releases Live from Freedom Hall, their eight live album. It features music performed June 15, 2007 at Freedom Hall in Louisville, Kentucky.\n2009 Blues bassist Nick Holt (of The Teardrops) dies of brain cancer at age 69.\n2007 Sarah McLachlan gives birth to her second child, daughter Taja Summer Sood.\n2004 Lynyrd Skynyrd releases Lynyrd Skynyrd Lyve: The Vicious Cycle Tour, their fifth live album. Featuring music from a July 11, 2003 performance at Antioch, Tennessee's Amsouth Amphitheater, it celebrates the band's thirty year anniversary.\n1990 Doo-wop singer Corinthian \"Kripp\" Johnson (of The Dell-Vikings) dies of cancer at age 54.\n1988 Robert Palmer releases \"Simply Irresistible\" in his native UK, where it peaks at #44. It fares much better in the US, where it lands at #2.\n1987 Fred Astaire dies of pneumonia at age 88. Shortly before his death, Astaire abdicated his throne as the king of song and dance and welcomed a new royal: Michael Jackson. He said: \"I didn't want to leave this world without knowing who my descendant was, thank you Michael.\"\n1977 Peter Laughner (guitarist for Pere Ubu) dies of acute pancreatitis at age 24 after years of drug and alcohol abuse.\n1970 Steven Page (former co-lead of Barenaked Ladies) is born in Scarborough, Ontario, Canada.\n1969 After a long battle with drug and alcohol abuse, Judy Garland dies of an overdose at age 47.\n1968 The Jeff Beck Group, with Rod Stewart as lead singer, plays America for the first time at a show in New York.\n1968 Mason Williams releases \"Classical Gas.\"\n1967 The Young Rascals records \"How Can I Be Sure?\"\n1964 Mike Edwards (lead singer, keyboardist of Jesus Jones) is born in Wiltshire, England.\n1963 The Surfaris release \"Wipe Out.\"\n1961 Pop singer Jimmy Somerville (of Bronski Beat) is born in Glasgow, Scotland.\n1961 Elvis Presley's Wild In The Country movie opens nationally.\n1959 Alan Anton (bassist for Cowboy Junkies) is born in Montreal, Canada.\n1957 Garry Beers (bass guitarist for INXS) is born in Manly, New South Wales, Australia.\n1956 Derek Forbes (former bass guitarist for Simple Minds) is born in Glasgow, Scotland.\n1955 Walt Disney's Lady and the Tramp premieres in theaters. The canine cartoon features music from Peggy Lee, including \"He's a Tramp,\" \"La La Lu,\" and \"The Siamese Cat Song.\" Lee also voices Darling (Lady's owner), Peg the dog, and the ornery Siamese cats.\n1953 Cyndi Lauper is born in Astoria, Queens, New York.\n1949 Alan Osmond (of The Osmonds) is born in Ogden, Utah.\n1948 Todd Rundgren is born outside of Philadelphia, Pennsylvania. In the '70s, he would become a top solo artist and one of the most celebrated producers in music, with Meat Loaf's Bat Out Of Hell his biggest commercial success.\n1947 Howard Kaylan (lead singer of The Turtles, Flo & Eddie) is born Howard Kaplan in the Bronx, New York.\n1944 Peter Asher (of Peter & Gordon) is born in London, England.\n1942 Jazz pianist Deodato is born Eumir Deodato de Almeida in Rio de Janeiro, Brazil.\n1939 Bobby Harrison is born in West Ham, England. The Procol Harum drummer will leave the band, along with guitarist Ray Royer, to form Freedom.\n1936 Kris Kristofferson is born in Brownsville, Texas.\n1934 Leon Rosselson, satirical singer and children's book author, is born in Harrow, Middlesex, England.\n1913 Pop singer Dotty Todd is born Doris Dabb in Elizabeth, New Jersey. She and her husband will form the '50s singing duo Art and Dotty Todd, known for the UK hits \"Broken Wings\" and \"Chanson D'Amour.\"\n1830 Composer/pianist Theodor Leschetizky is born in Lancut, Poland.\n2009 Chris Brown pleads guilty to assaulting Rihanna the night before the Grammy Awards. He avoids jail time, but is sentenced to five years' probation and about 1400 hours of community service. Rihanna asks that no restraining order be issued, but the judge implements one anyway, saying it could be rescinded after he undergoes a year of counseling.\n1998 Todd Rundgren marries Michele Gray on his 50th birthday. The wedding takes place in Hawaii, the 50th state.\n1991 N.W.A.'s second and final studio album Niggaz4life (also known as Efil4zaggin), hits #1 in the US, becoming the just the fourth rap album to top the chart. The previous rap chart-toppers are Licensed to Ill by Beastie Boys in 1987, Please Hammer, Don't Hurt 'Em by MC Hammer in 1990, and To the Extreme by Vanilla Ice later that year.\n1990 Billy Joel becomes the first rock act to play at Yankee Stadium when he performs at the first of two sellout shows.\n1981 Mark David Chapman pleads guilty to the murder of John Lennon six months earlier and is sentenced to 20 years-to-life in prison.","927King Constantine II of Scotland, King Hywel Dda of Deheubarth, Ealdred of Bamburgh, and King Owain of Strathclyde accept the overlordship of King Ethelstan of England, leading to seven years of peace in the north.\n1191During the Third Crusade, Saladin's garrison surrenders to Philip Augustus, ending the two-year siege of Acre.\n1470The Ottomans capture Euboea.\n1493Hartmann Schedel's Nuremberg Chronicle, one of the best-documented early printed books, is published.\n1527Le Cung Hoang cedes the throne to Mac Dang Dung, ending the Lê dynasty and starting the Mac dynasty.\n1536Dutch philosopher, Erasmus, dies suddenly in Basel, Old Swiss Confederacy, at age 69. He was a Renaissance humanist, Catholic priest, social critic, teacher, and theologian. Using humanist techniques for working on texts, he prepared important new Latin and Greek editions of the New Testament, which raised questions that would be influential in the Protestant Reformation and Catholic Counter-Reformation. He wrote On Free Will, The Praise of Folly, Handbook of a Christian Knight, On Civility in Children, Copia: Foundations of the Abundant Style, Julius Exclusus, and many other works.\n1543King Henry VIII of England marries his sixth and last wife, Catherine Parr, at Hampton Court Palace.\n1561Saint Basil's Cathedral is consecrated in Moscow, Russia.\n1562Fray Diego de Landa, acting Bishop of Yucatán, burns the sacred books of the Maya.\n1580The Ostrog Bible, one of the early printed Bibles in a Slavic language, is published.\n1712Academic and politician, Richard Cromwell, dies in Cheshunt, Hertfordshire, England, at age 85. He was Lord Protector of England, Scotland, and Ireland, and one of only two commoners to become the English head of state: the other was his father, Oliver Cromwell, from whom he inherited the position.\n1730Potter, Josiah Wedgwood, is born in England. He founded the Wedgwood Company.\n1776Captain James Cook begins his third and final voyage, to discover the Northwest Passage.\n1789In response to the dismissal of the French finance minister, Jacques Necker, the radical journalist, Camille Desmoulins, gives a speech that results in the storming of the Bastille in Paris, France, two days later.\n1790The Civil Constitution of the Clergy is passed in France by the National Constituent Assembly.\n1799Ranjit Singh conquers Lahore and becomes Maharaja of the Punjab (Sikh Empire).\n1801British ships inflict heavy damage on Spanish and French ships in the Second Battle of Algeciras.\n1804Former U.S. Secretary of the Treasury, Alexander Hamilton, dies after being shot in a duel with Aaron Burr in New York, New York, at age 49.\n1806Sixteen German imperial states leave the Holy Roman Empire and form the Confederation of the Rhine.\n1812The American Army of the Northwest briefly occupies the Upper Canadian settlement at what is present-day Windsor, Ontario.\n1817Henry David Thoreau, naturalist, author, and pacifist, is born in Concord, Massachusetts. He was a poet, philosopher, abolitionist, tax resister, development critic, surveyor, and historian. A leading transcendentalist, Thoreau is best known for his book, Walden (a reflection upon simple living in natural surroundings), and his essay Resistance to Civil Government (also known as Civil Disobedience), an argument for disobedience to an unjust state.\n1849Dolley Madison, wife of President James Madison, dies in Washington, D.C., at age 81. She was the fourth First Lady of the United States.\n1852Hipólito Yrigoyen, President of Argentina (1916-1922 and 1928-1930), is born Juan Hipólito del Sagrado Corazón de Jesús Yrigoyen Alem in Buenos Aires, Argentina.\n1854George Eastman, inventor of the Kodak camera, is born in Waterville, New York. He founded the Eastman Kodak Company and popularized the use of roll film, helping to bring photography to the mainstream.\n1859William Goodale, of Massachusetts, patents a paper bag manufacturing machine.\n1862The Medal of Honor is authorized by the U.S. Congress.\n1870Louis II, Prince of Monaco, is born Louis Honoré Charles Antoine Grimaldi in Baden, Grand Duchy of Baden, Germany.\n1884Studio head and film producer, Louis B. Mayer, is born Lazar Meir in Dymer, Kiev Governorate, Russian Empire. He co-founded Metro-Goldwyn-Mayer (MGM) studios in 1924. Under Mayer's management, MGM became the most prestigious film studio, accumulating the largest concentration of leading writers, directors, and stars in Hollywood. Mayer was a staunch conservative, at one time the chairman of California's Republican Party. In 1927, he was one of the founders of the Academy of Motion Picture Arts and Sciences (AMPAS), famous for its annual Academy Awards ceremonies.\n1886Lagoon Amusement Park opens in Farmington, Utah. Attractions include bowling, a Dancing Pavilion, music, a shady bowery and restaurants. In 1899, Shoot-the-Chutes, the park's first thrill ride, was added.\n1895Architect, Buckminster Fuller, is born. In the 1970s, his geodesic dome was popular as the ideal architectural form.\n1895Lyricist, Oscar Hammerstein, is born in New York, New York. He teamed up with Richard Rodgers, and as Rogers & Hammerstein they brought forth the stage and film productions of Oklahoma! and Carousel.\n1896Revere Beach opens in Revere, Massachusetts, four miles north of Boston. It is the first public beach in the United States.\n1899American rodeo champion, Everett Bowman, is born in Hope, New Mexico. During his 20-year rodeo career, he won the Rodeo Association of America (RAA) All-Around Cowboy championship twice, and was second three times. He also won eight titles in individual disciplines.\n1908Entertainer, Milton Berle, is born Mendel Berlinger in New York, New York. As the host of NBC-TV's Texaco Star Theater (1948-1955), he was the first major American television star and was known to millions of viewers as \"Uncle Miltie\" and \"Mr. Television\" during TV's Golden Age.\n1909Joe DeRita, of The Three Stooges, is born Joseph Wardell in Philadelphia, Pennsylvania. He was the sixth member of the Three Stooges, and the second to be billed as Curly, under the persona of \"Curly Joe.\"\n1910Charles Stewart Rolls, aviator and co-founder of Rolls-Royce, becomes Britain's first aviation victim when he crashes his Wright bi-plane near Bournemouth, England.\n1913Serbian forces begin their siege of Vidin, Bulgaria.\n1917The Bisbee Deportation occurs as vigilantes kidnap and deport nearly 1,300 striking miners and others from Bisbee, Arizona.\n1917Artist, Andrew Wyeth, is born in Chadds Ford, Pennsylvania. Wyeth was known for his Realist paintings of the landscapes and people of his hometown and summer home in Cushing, Maine. One of his best-known works, \"Christina's World,\" is part of the collection of the Museum of Modern Art in New York. One major influence, discussed at length by Wyeth himself, was King Vidor's film The Big Parade. He claims to have seen the film (which depicted family dynamics similar to his own) \"a hundred-and-eighty-times,\" and believes it had the greatest impact on his work. The film's director later made the documentary, Metaphor, where he and Wyeth discuss the effect of the film on his paintings Winter 1946, Snow Flurries, Portrait of Ralph Kline, and Afternoon Flight of a Boy Up a Tree.\n1918The Imperial Japanese Navy battleship, Kawachi, blows up at Shunan, western Honshu, Japan, killing at least 621 people.\n1920The Soviet-Lithuanian Peace Treaty is signed, with Soviet Russia recognizing the independence of Lithuania.\n1920Actress, Bea Richards, is born Beulah Elizabeth Richardson in Vicksburg, Mississippi. She appeared in the films Take a Giant Step, The Miracle Worker, Hurry Sundown, In the Heat of the Night, Guess Whos Coming to Dinner, The Great White Hope, The Biscuit Eater, Mahogany, Big Shots, and Drugstore Cowboy.\n1934Classical pianist, Van Cliburn, is born Harvey Lavan Cliburn, Jr. in Shreveport, Louisiana. A Texas native and Julliard graduate, Cliburn rose to fame in 1958 at age 23, after winning the first International Tchaikovsky Competition in Moscow, Russia. That year he was on the cover of Time magazine with the headline, \"The Texan Who Conquered Russia.\" Although Russia and the United States were battling at the time, Cilburn became a hero to the Soviets. RCA Victor signed him to an exclusive contract, and his subsequent recording of the Tchaikovsky Piano Concerto No. 1 became the first classical album to go platinum. It was the best-selling classical album in the world for more than a decade, eventually going triple-platinum. Cliburn won the 1958 Grammy Award for Best Classical Performance for this recording. In 2004, this recording was re-mastered from the original studio analogue tapes, and released on a Super Audio CD. Cliburn performed for royalty and every U.S. President since Harry Truman. He was given a Grammy Lifetime Achievement Award in 2004, and in 2011 President Barack Obama presented him with the National Medal of the Arts.\n1934Inventor and businessman, Ole Evinrude, dies in Milwaukee, Wisconsin, at age 57. He invented the outboard motor.\n1937Comedian and actor, Bill Cosby, is born.\n1943During World War II, German and Soviet forces engage in the Battle of Prokhorovka, southeast of Kursk, in the Soviet Union. It is one of the largest tank battles in military history.\n1943Christine McVie, keyboardist for Fleetwood Mac, is born.\n1944Actress, Denise Nicholas, is born.\n1945The U.S. stages the first test of a plutonium weapon, code-named Trinity, before dawn in the New Mexico desert.\n1948Israeli Prime Minister, David Ben-Gurion, orders the expulsion of Palestinians from the towns of Lod and Ramla.\n1948Celebrity fitness trainer, Richard Simmons, is born.\n1948Actor, Jay Thomas, is born Jon Thomas Terrell in Kermit, Texas. He is well known for his appearances on the TV shows Mork & Mindy, Family Ties, Cheers, and Murphy Brown. He appeared in the films C.H.U.D., Legal Eagles, Straight Talk, Mr. Hollands Opus, and Dragonfly.\n1949Simon Fox, drummer for the bands Be-Bop Deluxe and The Pretty Things, is born.\n1949John Wetton, of Uriah Heep and the supergroup Asia, is born.\n1949Douglas Hyde, the first President of Ireland (1938-1945), dies in Dublin, Ireland, at age 89.\n1950Eric Carr, drummer for KISS, is born Paul Charles Caravello in Brooklyn, New York.\n1951Film producer, Brian Grazer, is born. He co-founded Imagine Entertainment.\n1951Actress, Cheryl Ladd, is born.\n1952Philip Taylor Kramer, of Iron Butterfly, is born.\n1954Elvis Presley signs his first recording contract with Sun Records and quits his job as a truck driver.\n1956Actress, Mel Harris, is born.\n1956Singer, Sandi Patty, is born.\n1957U.S. Surgeon General, Leroy E. Burney, reports that there is a direct link between smoking and lung cancer.\n1960Orlyonok, the main Young Pioneer camp of the Russian SFSR, is founded.\n1960The first Etch-A-Sketch goes on sale. Over 50 million units were sold over the next 25 years.\n1961Pune, India, floods due to failure of the Khadakwasla and Panshet dams, killing at least 2,000 people.\n1962The Rolling Stones perform their first concert, at the Marquee Club in London, England.\n1963Sixteen-year-old Pauline Reade disappears on her way to a dance at the British Railways Club in Gorton, England. She is the first victim in the Moors murders.\n1964The Ed Sullivan Show re-broadcasts The Beatles' first live television appearance from February 9th.\n1965Robin Wilson, of The Gin Blossoms, is born.\n1967The Newark riots begin in Newark, New Jersey. Six days of rioting, looting, and destruction leaves 26 people dead and hundreds of others injured.\n1968Singer, Micky Dolenz, marries English fashion model, Samantha Juste.\n1969Apollo 11 is launched on its historic mission to land men on the Moon, with astronauts Neil Armstrong, Buzz Aldrin, and Michael Collins aboard.\n1969Elvis Presley appears on the cover of Rolling Stone.\n1970A fire consumes the wooden home of Norwegian composer, Geirr Tveitt.\n1971The Australian Aboriginal Flag is flown for the first time.\n1971Figure skater, Kristi Yamaguchi, is born.\n1973A fire destroys the entire sixth floor of the National Personnel Records Center of the United States.\n1973Actor, Lon Chaney, Jr., dies of heart failure in San Clemente, California, at age 67. The son of silent film actor, Lon Chaney, he is best known for the role of Larry Talbot in the 1941 film The Wolf Man. It was only after his father's death that Chaney started acting in films, beginning with an uncredited bit part in the film Girl Crazy in 1932. In 1935, he began using the name Lon Chaney, Jr.\n1975Sao Tome and Príncipe declare independence from Portugal.\n1976Television personality, Ted Mack, dies in North Tarrytown, New York, at age 72. He was the host of Ted Mack and the Original Amateur Hour on radio and television in the 1940s and 1950s.\n1979The island nation of Kiribati becomes independent from the United Kingdom.\n1979Singer, Minnie Riperton, dies.\n1982The U.S. government agency, FEMA, promises that survivors of a nuclear war will get their mail.\n1983Chris Wood, saxophonist for the bands Traffic and Ginger Baker's Air Force, dies.\n1988Film director and screenwriter, Joshua Logan, dies of supranuclear palsy in New York, New York, at age 79. His films include Mister Roberts, Picnic, Bus Stop, Sayonara, South Pacific, and Ensign Pulver.\n1989Lotte World Adventure opens in Seoul, South Korea. It consists of the world's largest indoor theme park (open year round), an outdoor amusement park called \"Magic Island,\" an artificial island inside a lake linked by monorail, shopping malls, a luxury hotel, a Korean folk museum, sports facilities, and movie theaters.\n1995Super-centenarian, Tane Ikai, dies of kidney failure in Nagoya, Japan, at age 116 (and 175 days).\n1996Journalist, John Chancellor, dies.\n1996Jonathan Melvoin, keyboard player for The Smashing Pumpkins, dies.\n1997Anthony Kiedis, of Red Hot Chili Peppers, suffers a badly broken wrist in a motorcycle accident in Los Angeles, California. Kiedis is injured when the car in front of him makes an unexpected U-turn in order to get a parking space.\n1999A plane carrying John F. Kennedy, Jr., his wife, and her sister, crashes off the Massachusetts resort island of Martha's Vineyard, killing all on board. Their bodies were not found until July 21st.\n2000A statue erected in the memory of John Lennon is unveiled in Trafalgar Square in London, England. The sculpture features a revolver with a knotted barrel created by Swedish artist Carl Fredrik Reutersward.\n2003Jazz musician, Benny Carter, dies from complications of bronchitis in Los Angeles, California, at age 95. He was an alto saxophonist, clarinetist, trumpeter, composer, arranger, and bandleader. Carter was a major figure in jazz from the 1930s to the 1990s.\n2004Ballerina, Betty Oliphant, dies in St. Catharines, Ontario, at age 85. She co-founded Canada's National Ballet School.\n2006The Lebanon-Israel war begins.\n2007U.S. Army Apache helicopters perform airstrikes in Baghdad, Iraq. Footage from the cockpit is later leaked on the Internet.\n2011Television producer and screenwriter, Sherwood Schwartz, dies of natural causes in Los Angeles, California, at age 94. He is best known for creating the TV sitcoms Gilligans Island and The Brady Bunch.\n2012The Turaymisah massacre kills 250 people during a Syrian military operation in a village within the Hama Governorate.\n2012A tank truck explosion kills more than 100 people in Okobie, Nigeria.\n2013Six people are killed and 200 others are injured in a passenger train derailment in Brétigny-sur-Orge, France.\n2013Electrical and sound engineer, Amar Bose, dies in Wayland, Massachusetts, at age 83. He founded the Bose Corporation. His research on acoustics led him to invent a stereo loudspeaker that would reproduce, in a domestic setting, the dominantly reflected sound field that characterizes the listening space of the audience in a concert hall. His focus on psychoacoustics later became a hallmark of his company's audio products. He was also a professor at the Massachusetts Institute of Technology (MIT) for over 45 years.\n2016The Permanent Court of Arbitration in the Hague rules in favor of the Philippines against China over territorial disputes in the South China Sea. China rejects the tribunal's ruling, declaring it null and void. Chinese President Xi Jinping says the South China Sea has been Chinese territory since \"ancient times.\"\n2016Restoration work at the Church of the Nativity in Palestine, reveals a hidden angel mosaic.\n2016Senator Bernie Sanders endorses Hillary Clinton for president at a rally in Portsmouth, New Hampshire, ending his own presidential campaign.\n2016AMC Theatres purchases the London-based Odeon & UCI Cinemas Group in a deal valued at about $1.21 billion. AMC has 385 theaters with 5,380 screens, most of them in the United States. Odeon & UCI has 242 theaters and 2,236 screens in the U.K. and Ireland.\n2016At least 20 people are killed and dozens more are injured after two trains collide head-on near Andria, in the province of Puglia, southern Italy.\n2017The Trump administrations cap of 50,000 refugees entering the U.S. for the 2017 budget year is reached, but it appears that some additional refugees will continue to trickle into the country.\n2017The U.S. Court of Appeals for the Ninth Circuit in San Francisco, California, hears a case on whether or not a Celebes crested macaque owns its selfie.\n2017Several major internet companies and activist groups post messages defending net neutrality.\n2017A giant iceberg, covering approximately 2,200 square miles, breaks away from the Larsen C Ice Shelf in Antarctica.\n2017Wildfires devastate the Italian provinces of Messina, Naples, Enna, and Rome. The Vesuvius National Park is completely destroyed by flames and ash. Italian police claim the fires are the work of arsonists.\nPHOTOS TOP TO BOTTOM: An illustration from Hartmann Schedel's Nuremberg Chronicle; Henry David Thoreau; Buckminster Fuller; Christina's World by Andrew Wyeth; Van Cliburn; Richard Simmons; Mel Harris; Elvis Presley on the cover of Rolling Stone; Minnie Riperton; John F. Kennedy, Jr.; and Amar Bose."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:a0a4080e-df4b-4295-9e42-6e6c207a5c19>","<urn:uuid:b15269e0-994e-4793-8f61-f958e7ea9991>"],"error":null}
{"question":"What role does personal experience play in the photographic work of Annarita Gentile compared to Mona Kuhn's approach?","answer":"Both photographers emphasize personal experience in their work but approach it differently. Annarita Gentile explicitly aims to reflect the world as she experiences it, combining her artistic work with her psychoanalytic career and focusing on understanding her own motivations and emotional perspectives. Her work process flows seamlessly from inspiration to composition. Mona Kuhn, on the other hand, approaches her work through minimalism and collaboration, as seen in her Acido Dorado series where she worked with a close friend and collaborator, Jacintha, to create images that blend figure, landscape, and abstractions. Her work focuses on exploring the mysterious aspects of human beauty and existence beyond the surface.","context":["Interview with Mona Kuhn\nImage shown on billboard above: © Mona Kuhn, Billboard location: Highland South of Waring, East Side, Facing North - Los Angeles, CA\nKELLY KORZUN: How did you come up with the idea of taking unused billboards and turning them into public art?\nMONA KUHN: It was Adam Santelli, TBC's Director, who came up with the idea and set this project into motion. Back in 2011 Adam received a call from an AD agency that was trying to unload remnant billboards to artists. It was during the recession, so these kind of deals were coming up once in a while. But even at a discounted rate, the boards were still too expensive for an artist to rent. However, a thought popped into Adam’s head: how wonderful would it be to exhibit artworks on billboards for a wide audience of people driving by everyday? So Adam tested the idea and rented one billboard to display his own artwork for a month. During that time, he observed curious people interacting with the billboard; pedestrians stopped by to look at the board, a couple of people even took selfies with it. It was really interesting to see the idea come to life. So in 2012 Adam founded The Billboard Creative, a non profit organization with one mission: to use remnant billboards and turn them into public art. What started as a test in 2011, became an exhibition of 15 billboards in 2014. In the Spring of 2015, Adam invited me to step in as an LA-artist and curator. It has since grown so much, this week we have 33 artwork billboards coming up in Los Angeles, with one mission, to stop traffic with art!\nImage shown on billboard above: © Jack Pierson, Billboard location: Santa Monica East of Vine, North Side, Facing West - Los Angeles, CA\nKK: The list of artists selected this year includes Ed Ruscha, Jack Pierson, Andrew Bush, Shane Guffogg, Kim McCarty, Panos Tsagaris and many others. What characteristics draw your attention to specific artists? Who should be encouraged to submit and exhibit at The Billboard Creative?\nMK: A billboard exhibition can be a challenging proposition. We’re competing for attention within a busy urban setting, with an audience mostly inside their cars commuting. My first step was to observe traffic and study audience behavior. There were two distinct situations observed: people would be either driving by swiftly, or completely stuck in a traffic jam. Considering the first scenario, my intention is to grab their attention by surprise with graphically strong artworks, pieces that are easy to read and understand in a relatively short amount of time. That was the case with artworks selected from artists such as Panos Tsagaris, Jack Pierson, Andrew Bush, Ed Ruscha, Carolyn Doucette, among others. But I also saw a need to reach out to an audience who might be stuck in a traffic jam, feeling somewhat impatient and helpless. I thought about artworks that had the power to transport my thoughts momentarily away from that jam and inspire me to mentally escape the traffic. Some of the works selected were the delicate watercolors from Kim McCarty, the handmade knitted sculptures from Thomas Chung and the emotional colors present in Robert Zuchowski's paintings. All works had a touch of sublime to me.\nKK: Where are the billboards located and how was this decided?\nMK: The locations and intersections for the billboards are pretty great. The billboard exhibition is concentrated in intersections around West Hollywood and Hollywood. I asked them to concentrate most locations by gallery or museum areas. It was not easy to guarantee space, as you can imagine, but it all worked out. Santa Monica and Highland (by Regen Projects), Beverly and La Brea, Sunset and Western, Fairfax in front of LACMA, Melrose by the gates of Paramount Studios. You can see the list online at www.thebillboardcreative.com. The two billboard companies facilitating TBC exhibitions are Clear Channel and Outfront; they're very artist-supportive and helpful!\nKK: How does ArtMoi compliment the billboard exhibition?\nMK: I thought it was important to provide a mobile map of the show. It’s an app anyone can download that shows the locations of the billboards and offers further info on the artists and their works. Similar to a museum audio guide, but outside of the conventional walls of an institution.\nImage shown on billboard above: © Carolyn Doucette, Billboard location: Hollywood West of Bronson, South Side, Facing West - Los Angeles, CA\nKK: In one of your interviews, you mentioned using Gauguin’s painting Where Do We Come From? What Are We? Where Are We Going? as the basis for your creative source — timeless and universal questions we all have. With the TBC initiative, what questions do you want to provoke in thousands of people during their daily commute?\nMK: My main goal was to stop traffic with art: to bring artwork from gallery and museum walls and into the streets; to interact with a much wider and egalitarian audience in hopes of touching a nerve here and there for a split second; to offer a surprise, a small seed for thought.\nKK: What were the greatest challenges faced while curating TBC?\nMK: When Adam Santelli from TBC invited me to curate the second Billboard Creative exhibition to be displayed all over intersections in LA proper, I had no idea we would receive a substantial amount of great artworks. I was impressed with the quality of the works submitted. It was also a very interesting process for me, from an artist’s point of view. The artworks selected where based on the criteria mentioned to you earlier, but we still had at least 100 great works that needed to be narrowed down to 33 billboard placements. The final selection was the hardest as all works were equally strong to me. It is interesting to know that I selected them based on the artwork only. I did not have the name of the artists together with the works. It was all based on the artwork standing on its own. The final selection was based on bringing a balance to the final group of 33 artworks. It was not an easy task, but I would do it all over again.\nImage shown on billboard above: © Kim McCarty, Billboard location: Melrose and Gower South East, Facing West - Los Angeles, CA\nKK: Starting with a single billboard, TBC has grown tremendously over the past years. What feedback have you received?\nMK: It will be interesting to see what feedback we receive this year. So far, we’ve received very positive feedback from the artist community. There is open and positive communication going on through social media. It’s fun to observe it taking on a life of its own.\nKK: Tell us more about TBC and the nonprofit organization’s objectives overall.\nMK: Nobody got paid for their efforts; it’s literally a labor of love. When they contacted me, their main interest was to have an artist curate other artists’ works — from artist, to artist and for artists type of thinking. In exchange for my time and advice, they offered to place one of my pieces on a billboard. So, I’ve a piece from the Acido Dorado series in this as well.\nImage shown on billboard above: © Ed Ruscha, Billboard location: Melrose West of Wilton, South Side, Facing East - Los Angeles, CA\nKK: What do you foresee in the future for TBC? Have you thought about bringing TBC to other cities?\nMK: Last year, TBC placed 15 contemporary artists’ works on billboards across Los Angeles. This year, we were able to guarantee placement for 33 artworks. We’ve been talking about bringing it to a sister city in the US, or possibly Cuba! It’s been an exciting project, great for artists’ exposure and I’m hoping we can expand it further — fingers crossed!\nKK: What about LA attracts artists?\nMK: It’s probably a combination of incredible light, available space for artist studios, reasonable rental prices and a growing artist community supported by critics, collectors, and institutions. I’m not sure what exactly brings them here, but whatever it is, it doesn’t seem to be available in NY any longer. We’ve been noticing a large amount of artists moving here from the east coast.\nKK: You were born in São Paulo and currently reside in LA, which is referred to as a \"desert city\" by many authors. In your latest body of work, Acido Dorado, you explore a close friend and collaborator’s, Jacintha’s, interactions with the American desert. What entices you about deserts?\nMK: In my own life and work, I would say I have a tendency for minimalism. What draws me to the desert is the incredible light and the vast landscape. It feels like an empty canvas waiting to be brought to life. It has an existential undercurrent that entices my imagination.\nKK: You describe Acido Dorado as \"a mix of California hedonism and surreal desert hallucination.\" In this series, your narrative shifted from nudes expressed in the physical body to abstracted expressions of the body. What triggered this shift?\nMK: I think it was a natural tendency and personal wish to push my work forward. It was a privilege for me to create images together with someone I knew for so many years. We are kindred spirits and continue each others’ sentences. Same for creating the work, I would think of someone and before mentioning it, Jacintha would be addressing my thoughts in her body language. It was a real interesting series for me, because most images were shot tangentially to the model, embracing reflections from the surrounding glass panels of the house. The minimal glass house offered a great setting to let go of existing standards and create something new — to find a balance in blending figure, landscape, and variations of abstractions. I’m now finalizing edits for the upcoming book. It will be published by Steidl and released by Fall 2016.\nImage shown on billboard above: © Andrew Bush, Billboard location: Fairfax North of 5th, West Side, Facing South - Hollywood, Los Angeles, CA\nKK: Your first monograph, Photographs, debuted with Steidl more than a decade ago. How do you feel your work has changed over the years?\nMK: Hard to say. I might not have an objective point of view as I’m too close to it. I would probably admit that the basis of my creative source has remained the same — the human being whose beauty (beyond the surface of the skin) and existence remain mysterious to me\nKK: What’s next? What projects are you currently working on?\nMK: Lately, I’ve been really interested in the intellectual and philosophical aspects of the creative community in the 20s, both in Europe and in Los Angeles. I’ve been studying and photographing at the Schindler House here in West Hollywood. Built by the Austrian architect Schindler, it’s considered an early, mid-century masterpiece. I’m interested not only in the architecture, but most importantly for me, in the social theory of that time. I think we still have much to learn and distill from that avant-garde era in LA.","Featuring Three Outstanding Artists in Photography\nAubrey J. Kauffman\nSaturday, March 9, 2019 | 6-9 PM\nPerkins Center for the Arts\n30 Irvin Avenue | Collingswoood, NJ\n[su_button url=”http://perkinsarts.org/wp-content/uploads/2019/01/Photography-37-Opening-Perkins-MYP-Comm-Final-2.28.19.pdf” target=”blank” background=”#bfb3e4″ size=”9″ text_shadow=”0px 2px 5px #000000″]PRESS RELEASE[/su_button]\nAbout the Artists:\nJohn Clarke’s interest in photography developed while he was an architectural student at Cooper Union in the late 1960s. The Cooper students were generally, very talented, poor, living in rundown lofts on the lower east side and struggling to find their way into the design world. The first year architectural students took all their classes with the art students, so they got a great introduction to freehand drawing, two and three dimensional design. At the suggestion of one of his design professors, John bought a used Nikon and began to shoot black and white film around New York City. Slowly photography began to be part of John’s architectural presentations.\nAfter receiving a master’s degree from Columbia University, John was offered a position as an assistant professor at the University of Virginia School of Architecture teaching first year year design. The subject of his photography shifted from urban landscapes to rural landscapes and traditional building structure. John’s photo medium changed from black and white film to color slides. The slides left no room for post processing. The crop and exposure you got at the time of taking the photo was the end of the story. You had to get the image right in the camera.\nFast forward some years, John moved to New Jersey and founded Clarke Caton Hintz, a high recognized, award winning architectural and planning firm based in Trenton. During the time John was practicing architecture, the world changed from analog to digital. When he started, architects drew everything by hand. Now, virtually everything an architect designs is drawn with the aid of a computer. The same dramatic change has occurred in photography. Architects and designers went from having vast color slide collections to using digital cameras, Lightroom and Photoshop to illustrate their design intentions.\nWhile in architectural practice, John specialized in the design of large scale, mixed use communities. This interest in urban design gave him a reason to travel extensively both in the U.S and abroad. Photography became critical to his urban design work and documenting his travels became a source of great enjoyment.\nSince retirement from architectural practice, John has devoted his artistic talents to fine art photography. His background as an architect is evident in the composition and structure of his photos. A life time of looking intensely at his surrounding is evident in the quality of his images.\nAnnarita Gentile – As a photographer, I aim to reflect the world around me as I experience it. That is saying a lot, to try to show in an image a personal experience. Some of this aim is accomplished through composition and editing are a result of an individual process and a lot of luck.\nWe carry emotional narratives deep within our internal world. The narrative holds the meaning to what we see. The mind reacts to an image in .33 seconds. Once we registered what we see, our own meaning is applied to the image.\nMy work as an artist coincides with my psychoanalytic career. I approach all of my endeavors with a desire to understand my own motivations and how my perspective is formed by my feelings. My emotional perspective and hopefully, expressed production is evident in both my artistic pursuits and professional hours.\nFor me, the creative process on a shoot occurs in a seamless process from the drive that comes from inspiration to the act of composition. Studio work is an attempt to continue the messaging by selecting certain images and editing which involves a variety of choices.\nThe message in this portfolio is one of glorious celebration through shapes and colors. For me, this work symbolizes a part of the story of the natural journey from hibernation, and germination, to the blossoming period shown here. What is expressed through the colors, shapes textures and the infinite possibilities of these flowers is a triumph and celebratory victory. And as brilliant as it is, there is some darkness and the sense that change is not far away. This is about the immediacy of the moment. The photos in this collection are flowers in Botanical Gardens in Pennsylvania and Maine, as well as various wooded locations.\nAubrey J. Kauffman is a photographer living and working in New Jersey. He received his BA in Media Arts from New Jersey City University and his MFA in Visual Arts from Rutgers University’s Mason Gross School of the Arts. He has taught photography at Mason Gross, Middlesex County College, Mercer County Community College and Community College of Philadelphia.\nHe was Guest Curator for “Landscapes: Social Political Traditional” at Rider University, in Lawrenceville, NJ, and was Co-Curator for “On Photography: Culture, History and the Narrative” with LaToya Ruby Frazier at the Mason Gross Galleries in New Brunswick.\nHis photography has been included in group exhibitions including: The Newark Museum, Newark, NJ; The Biggs Museum of American Art in Dover DE, The Griffin Museum of Photography in Winchester MA; The 38th Annual Wind Challenge Exhibition Series at the Fleisher Art Memorial in Philadelphia , PA and Expo 35 at the b.j. spoke gallery in Huntington, New York.\nHe has exhibited in solo shows at The New Jeresey State Museum, Trenton, NJ; Enfoco at 7th and 2ND Street Gallery, New York, NY; Southern Light Gallery in Amarillo, Texas; the Marguerite & James Gallery Hutchins Gallery at the Gruss Center of Visual Arts in Lawrenceville, NJ and the Rider University Art Gallery in Lawrenceville, NJ.\nHe was awarded the Brovero Photography Prize by Mason Gross. His work was named “Best in Collection” by Alpha Art Gallery in New Brunswick, NJ. He was awarded 3rd Place in the Urban Landscapes exhibit at the New York Center for Photographic Arts.\nHis work is represented in the permanent collections of the New Jersey State Museum in Trenton, NJ, Rider University in Lawrenceville, NJ and Johnson & Johnson’s Corporate Headquarters in New Brunswick, NJ.\nAt present he is a Contributing Producer for “State of the Arts” broadcast on PBS and a Contributing Journalist for US1 in Princeton, NJ."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:c026e398-9873-4134-9dac-ea4bf315bb95>","<urn:uuid:0e1e83d0-9d67-47e7-909c-8d447f8007b3>"],"error":null}
{"question":"How will the $6.875 million allocation help Indigenous youth in the justice system?","answer":"The $6.875 million will increase the capacity of the Family Well-Being Program, which provides needs-based services for young Indigenous people in the youth justice system who have complex mental health and substance use needs. The funding will also help recruit two community-based mental health and addiction liaisons to help Indigenous-led organizations better address the needs of Indigenous survivors of human trafficking.","context":["Ontario Increasing Mental Health Supports for Indigenous Peoples, Families and Communities\nMarch 04, 2021\nTORONTO — The Ontario government is investing over $12.8 million to immediately expand and enhance culturally appropriate mental health and addictions services for Indigenous peoples, families and communities across the province. This funding is part of the $176 million being invested in the government's mental health and addictions plan, Roadmap to Wellness. The plan is delivering high-quality care and building a modern, connected and comprehensive mental health and addictions system. Details were provided today by Christine Elliott, Deputy Premier and Minister of Health, and Michael Tibollo, Associate Minister of Mental Health and Addictions. \"Now more than ever, it is critically important to ensure that everyone, including Indigenous communities, can access the safe and effective mental health and addictions services they deserve - when they need them and where they need them,\" said Minister Elliott. \"Our government is committed to working with Indigenous communities and other health system partners to build a comprehensive and connected mental health and addictions system that people from every corner of the province can access.\" The government is making investments to expand and enhance community-based mental health supports and services in collaboration with Indigenous partners and through targeted programs focused on Indigenous children and youth, including:\n$6.875 million to increase the capacity of community-based and Indigenous-led supports, including the Family Well-Being Program, which provides needs-based services for young Indigenous people in the youth justice system who have complex mental health and substance use needs. The funding will also be used to recruit two community-based mental health and addiction liaisons to help Indigenous-led organizations better address the complex needs of Indigenous survivors of human trafficking;\n$1.4 million in enhanced community mental health and addictions services and programs in Indigenous-governed primary care teams;\n$1.412 million to help address gaps and barriers that Indigenous students and their families experience in the school system and support educational retention and success by:\nincreasing funding to Indigenous Graduation Coaches to increase outreach and support during the summer months;\nfunding the development of culturally appropriate cannabis training and resources for Indigenous students;\nfunding the development of a new strength-based initiative to support young Indigenous women and girls who have lived experience of violence, and/or who have witnessed violence in their families and communities; and\nfunding the implementation of the model for Trauma-Informed Schools as a system-wide model.\n$1.375 million annually over ten years to support the creation and implementation of 11 new Social Emergency Manager positions in Nishnawbe Aski Nation (NAN) and Grand Council Treaty #3 (GCT#3) First Nation communities, which will build capacity around social emergency prevention, mitigation, preparedness, response and recovery efforts;\n$1 million to expand the child and adolescent psychiatry program based in Thunder Bay, with satellite service locations across Northwestern Ontario; and\n$900,000 to support additional Indigenous focused mental health and addictions services and programs related to community safety and education.\n\"For far too long, Indigenous peoples and communities across Ontario have been faced with gaps and barriers to accessing effective mental health and addictions supports that meet their unique needs,\" said Associate Minister Tibollo. \"By expanding access for Indigenous communities to higher-quality and culturally appropriate mental health and addictions services, we're taking another important step in building a mental health and addictions system that fully supports people of all ages in their journey towards mental wellness.\" \"Supporting the health and well-being of Indigenous peoples across Ontario is an ongoing priority for our government,\" said Greg Rickford, Minister of Indigenous Affairs. \"These investments will help ensure Indigenous peoples, families and communities continue to have access to culturally appropriate and responsive mental health and addictions supports and services.\"\nTo enable Roadmap to Wellness, Ontario is investing $3.8 billion over 10 years to create new services and expand programs.\nOntario has invested $350 million in new annualized funding for mental health and addictions services since 2019-20. In October 2020, the government invested $176 million to help expand access to critical mental health and addictions services, create new supports and expand programs, building on the $174 million invested last year for mental health and addictions programs.\nIn response to the COVID-19 outbreak, the province invested up to $194 million in emergency funding for mental health and addictions services. The emergency funding for mental health and addictions has already helped more than 57,000 Ontarians continue to access services they need during this challenging time, including new supports such as virtual tools and counselling.\nTo find the right supports for you, visit COVID-19: Support for People.\nVisit Ontario’s website to learn more about how the province continues to protect Ontarians from COVID-19.\nRelated Topics Government Learn about the government services available to you and how government works. Learn more Health and Wellness Get help navigating Ontario’s health care system and connecting with the programs or services you’re looking for. Learn more"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:a3b42cbd-b019-4c9b-8d14-82d21b090421>"],"error":null}
{"question":"What are the key differences between an RFID man-in-the-middle attack and smart card PIN verification in terms of data protection?","answer":"In an RFID man-in-the-middle attack, attackers can intercept and copy sensitive information between a victim's card and the reader using hardware devices. However, with smart card PIN verification, the system performs a secure one-way transformation on the PIN that makes it impossible to determine the original input, and the PIN is never written to the host computer's working memory where it could be monitored by adversaries.","context":["In a previous blog post, we discussed what a radio frequency identification (RFID) access card is, what the risks associated with RFID cards, how to protect yourself when using access cards and why being careful when using RFID cards is important. In this blog post, we’ll discuss the types of attacks that can be performed against an RFID-based access control system, as well as a few ways to protect against such attacks.\nRFID cards are very simple devices, which makes them reliable for everyday use. However, it also makes them an easy target for attackers looking to gain access to a facility. In this post, we’re focusing on low-power RFID cards, which are commonly used in door access systems. There are a wide variety of attacks that can be performed against RFID access systems. The majority of attacks against RFID systems can be broken into three major categories: man-in-the-middle (MITM), cloning, and brute forcing.\nAn attack you may have heard about in the networking world is the MITM attack. An MITM attack is when an attacker is able to intercept and copy sensitive information between a victim and the victim’s intended recipient of the information. An MITM attack against an RFID system uses a hardware device to capture and decode the RFID signal between the victim’s card and a card reader. The malicious device then decodes the information and transmits it to the attacker so they can replay the code and gain access to the building. Many times, this hardware device is battery powered and simply placed on top of the legitimate card reader. When a user passes their RFID card over the reader, the attacker’s device copies the signals for later use by an attacker and allows the signals to go to the reader so that a user does not become suspicious by a door suddenly seeming inaccessible.\nAnother example of an MITM attack involves placing a small hardware device in line with a card reader and the controller, which is responsible for validating the credentials being read by the card reader. A controller connects to the access control server and stores a copy of valid cards in its internal storage. The controller is generally located near the doors for which it is responsible, such as above a drop ceiling. As seen in Figure 1 – ESPKey, these devices have five wire taps that connect into the wires running between the reader and the controller. The ESPKey is a mass-produced hardware device built to capture the communications across the wire and store it for later use by the attacker. These pieces of hardware are so small that, after the RFID cover is removed, they fit inside the RFID card reader housing, which obscures them from view.\nMany organizations struggle with how to prevent MITM attacks, since most end users would not typically notice if a card reader is suddenly a different shape or size due to an attacker having placed their own device inline, or identify that a cover has been removed and the wires have been trapped into.\nDepending on the type of RFID access control system your company uses, the system may support anti-tamper features such as using additional wires to create an electrical circuit. When the RFID reader is removed or opened, the circuit is broken. This alerts the controller that the system may have been tampered with and to shutdown the reader or take other actions. Look to make sure all the anti-tamper features of your system are in place and working. The anti-tamper controls should be tested on a regular basis along with other physical security controls.\nAnother option to assist in detecting tampering is to have security cameras that focus on each door, with the RFID reader in view. Almost all security camera systems now offer motion-sensing reporting. This allows for a large amount of uneventful time to be skipped on the recording, allowing a user to quickly view any possible tampering or suspicious activity.\nOne solution is to implement anti-tamper screws to secure the RFID reader housing. While anti-tamper screw drivers are available such that an attacker could acquire one, the screws still serve to increase the barrier to entry.\nAnother common technique attackers use to defeat RFID access systems is to clone (i.e. copy) a user’s RFID card without their knowledge. An attacker does not always need physical access to the RFID card to clone it. In fact, an attacker can capture the information stored on an RFID card from several feet away using off-the-shelf components and write the data to a blank compatible RFID card. Many times, these cloning devices are built using components from a large RFID reader that is used for parking garages or other areas where a user cannot get close to the card reader to scan their card.\nThese low-cost cloning devices can be used by an attacker as they walk past a member of your staff on the street or in a coffee shop. Once an attacker has copied the information from the victim’s RFID card, they can clone it on to a blank RFID card for use at your facility.\nWhen employees are in the office, it is generally preferred that they wear their RFID card out in the open, as it sometimes displays their identification. Protecting against long-range cloning attack can be difficult, but there are a few options to mitigate this type of attack in the office:\n- Separate identification details, such as photo IDs, from RFID cards. This way, an employee can wear their identification around the office and protect their RFID card inside an RFID-blocking sleeve or wallet.\n- If the identification details cannot be separated from the RFID card, have employees wear their credentials above their waist, such as clipped to their lapel. This makes it more likely that an employee would notice someone who is trying to clone the employee’s card.\nIf an attacker gets close to one of your employees in a public space or while they are at lunch, protecting their RFID card is significantly harder than it would be in the office, as your employees are less likely to be looking for anything out of the ordinary. The best solution for this scenario is for employees to leave their card secured off their person (e.g. in their vehicle), away from the eyes and reach of potential attackers. If an employee does not have the ability to leave their badge in a secure location, an RFID blocking sleeve should be used.\nAnother attack you may have heard of is a brute-force attack. When attacking something like a login portal, a brute-force attack would involve the attacker submitting randomly generated credentials to the login in the hopes of finding a match to gain access to the application. This same type of attack can be used against an RFID system. An attacker can use a hardware device to submit random combinations of RFID identifiers to the access control system in the hopes that one identifier will grant them access. This attack is not often used, as it is very time consuming and generally unsuccessful without a base level of information. RFID cards many times contain a facility code or other specific identifiers that cannot be quickly guessed. If an attacker captures that data from a known-valid card, the final identifier of another employee’s RFID credentials can be brute forced with significantly fewer guesses. This could allow an attacker to leverage information obtained from one employee’s card to brute force a higher level of access.\nBy adequately protecting RFID cards and readers using the best practices previously described can keep an attacker from capturing data from a valid card. If an attacker cannot obtain the facility code or other identifiers, brute forcing will be too time consuming to for the attack vector to be viable.\nAlternatives to RFID\nThere are options that offer more security than RFID systems, such as contactless smart cards or readers that leverage Bluetooth so a user’s access card can be stored in their mobile device. Contactless smart cards contain a small microprocessor that uses an asymmetric cryptographic function to send the credentials to the card reader. This is more secure than RFID, which simply broadcasts the credentials when power is present. Contactless smart cards can also be used to authenticate users into workstations or other systems. Using a mobile device for access control allows for a secure vendor-provided mobile app to manage tokens. It also lowers the risk of user’s losing, misplacing or leaving their access card at home, since most users have their mobile device with them at all times. As with most items in security, the question ultimately comes down to the level of resources an organization is willing to commit to security versus how much risk they are willing to accept.\nWe touched on just a few simple attacks that malicious actors can take against an organization’s RFID access control systems. Most of these attacks involve little cost or effort and can be very effective. It is a good idea to examine the risk profile of your organization and assess how many controls should be implemented around your RFID system. Training employees can go a long way toward helping secure your environment.","Secure and reliable Smart Card has played a key role in improving multifaceted digital security. A smart card is capable of storing and processing the data securely in a network of computers. The scope of smart cards is increasing day by day in diverse applications like banking, telephone services, and medical records systems etc. In this article we will try to understand what is a Smart Card, how Smart Cards work, its specifications, types, applications, advantages and disadvantages of Smart Cards.\nTable of Contents\n- 1 What is a Smart Card\n- 2 How a Smart Card Works\n- 3 Smart Card Architecture\n- 4 Types of Smart Card\n- 5 Applications of Smart Card\n- 6 Advantages of Smart Card\n- 7 Disadvantages of Smart Card\nWhat is a Smart Card\nSmart-Card is a secure portable storage device which is used in various applications requiring controlled access to sensitive information. It is in the size of a credit/ debit card, incorporated with one or more integrated circuit chips.\nIt functions as a microprocessor, memory and provides an input-output interface. The International Organization for Standardization (ISO) specifies certain voluntary international standards in many scientific and technological fields. However, till to date, ISO has not defined any standards for the devices termed as “Smart Cards.”\nFig. 1- Introduction to Smart Card\nThough it needs mention that ISO has set certain standards for what ISO calls an Integrated Circuit Card (ICC). Some of the fundamental characteristics of an ISO ICC (ISO 7816) are:\n- The ICC may contain one or more integrated circuits.\n- The length, width and the thickness of a card must be 3.370 inches, 2.125 inches, and 0.030 inches respectively which are the dimensions of a standard credit card.\n- The ICC provides spaces on the card for magnetic stripe and embossed data storage.\nA Smart-Card is similar to Integrated Circuit Cards except that it may not necessarily have magnetic stripe. The other Smart-Card related standards include ISO 14443 and ISO 15693 where the range of operation is defined. Smart Cards operate at 13.56 MHz and the distance ranges between 10 centimeters (3.94 inches) to 1 meter respectively.\nFig. 2 – Physical Components of a Contact less Smart Card\nImage Courtesy : embeddedsecuritynews\nHow a Smart Card Works\nThe Smart Cards which are issued to a user are programmed with unique information, such as a Personal Identification Number (PIN). The microcomputer of smart-card performs a secret one-way transformation on the PIN, which is a mathematical function (f) and the result (R) of this function R= f (D), where the input to the function D is impossible to determine.\nHence, the transformed unique PIN is stored in the smart card’s memory which is unreadable. The user’s PIN is never written onto the working memory of the host computer, which might be modified or monitored by an adversary.\nFig. 3 – Generalized Smart Card System\nTo access the computer system, a user must insert his/ her Smart-Card into a Smart-Card Reader and enter his unique PIN by means of a card reader’s keypad. When the contact pad on the smart-card comes in contact with the electrical connectors of the reader, the smart card’s microcomputer chip performs the one-way transformation on the entered PIN and compares it with the stored PIN.\nIf the two PINs match, then the information is exchanged between the smart-card and the host computer, which determines the user’s identity and the information which the user is entitled to access.\nSmart Card Architecture\nA Smart Card’s architecture basically consists of three elements. They are:\n- I/O System\n- Central Processing Unit (CPU)\nFig. 4 – Smart Card Architecture\nI/O (Input/ Output) System\nSmart Cards must have certain components to perform Input/output (I/O) functions. It has internal logic circuitry which works in conjunction with the microprocessor that controls the timing and flow of data transferred into and out of the smart card’s memories. It has a physical structure through which it can interface to a smart-card reader device, which is connected to host computers for the exchange of data.\nThe categories of physical interfaces depends on the type of smart cards i.e. the contact type and the contactless type. Interface of a Contact Smart-Card is a contact pad beneath which lies a chip module and the interface of a contactless type card includes a chip module and an antenna to communicate using radio waves.\nFig. 5 – Chip Module on Smart Card\nCentral Processing Unit (CPU)\nThe CPU or the microprocessor is the component which distinguishes the smart cards from other cards which are designed to simply store data. The microprocessor in association with the operating system enables the smart-card to “make its own decisions” concerning where the data is stored in its memories and under what circumstances it should transfer information through its input/output interface.\nThe microprocessor consists of three major components: the arithmetic logic unit (ALU), the control unit, and the bus.\nMemory (ROM, RAM, EEPROM)\nThe memories used in Smart Card’s microcomputers are manufactured from semiconductor materials. Semiconductor memories consist of matrices of cells formed by transistors to store information.\nTypes of Memory\nThe three types of semiconductor memory used in Smart cards are:\n- Read Only Memory (ROM)\n- Random Access Memory (RAM)\n- Electrically Erasable Programmable Read Only Memory (EEPROM)\nROM (Read Only Memory)\nSmart Card’s ROM is a semiconductor memory where the information stored is retained indefinitely without a continuous power supply to the memory. In this programming process, the ROM is often masked in such a way that it cannot be read or altered by the user.\nSemiconductor ROM is typically used for storing the Smart Card’s general operating system programs such as the program needed to start the Smart-Card when its power is turned on.\nRAM (Random Access Memory)\nAny information stored in RAM can be accessed only in a fixed amount of time i.e. the stored information in a smart card’s RAM is lost immediately if power to the memory is removed. RAM is the fastest type of memory, used only for temporary storage. The information in RAM is accessed in the range of tens to hundreds of nanoseconds (billionths of a second).\nEEPROM (Electrically Erasable Programmable Read Only Memory)\nSmart card’s EEPROM is a non-volatile memory which can be electrically erased and reprogrammed. EEPROM can be used for storing programs and data that needs modification periodically. Since EEPROM can be erased, a smart card containing EEPROM will not “expire” as its memory is filled up.\nTypes of Smart Card\nSmart Cards can be classified in two types. They are:\n- Contact Smart Card\n- Contact less Smart Card\nFig. 6 – Types of Smart Card\nContact Smart Card\nIn a Smart-Card with contact-type interface, the pins of the card reader’s connector must physically touch the contact pad on the Smart-Card during data transfer.\nContactless Smart Card\nA Smart-Card with a non-contact type interface does not require a physical connection for data transfer. This type of interface may be implemented using capacitive plates placed inside or on the surface of the card and the communication occurs via radio frequency signals.\nApplications of Smart Card\nThe field areas for applications of Smart Cards include:\n- Medical Health cards\n- Satellite TV\n- Access control systems\n- Electronic cash\n- Wireless (mobile) communications\n- Government identification\n- Ticketless travel systems\nAdvantages of Smart Card\n- Security: Smart cards are more secure as they are programmed with encryption and the user’s personal information and the transactions are safe.\n- Convenience: Smart cards are small in size and hence convenient to carry.\n- Economy friendly: Smart cards help in our economy by reducing transaction costs by eliminating paper.\n- Multifunctional: smart cards can be used for multi functions like paying bills, booking tickets, paying for food etc.\n- Reliable: Smart cards are more reliable than magnetic stripe cards.\nDisadvantages of Smart Card\n- It is prone to damage easily.\n- Smart cards are expensive to manufacture.\n- Availability of Smart-Card reader is necessary."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:775fbd15-60e6-40b3-b81c-fe4287b22d7f>","<urn:uuid:03f058c1-1e0f-4141-b1c5-84e058dc579a>"],"error":null}
{"question":"Compare the average sunshine hours per year between Shanghai and Yichang","answer":"Shanghai receives 1,778 hours of sunshine per year, while Yichang receives 1,567.5 hours of sunshine annually. Shanghai experiences more sunshine hours, with approximately 210.5 more hours of sunshine per year than Yichang.","context":["Buy Your own advertising\n.Download Adobe Acrobat Reader to open [PDF] files.\nEverything about Shanghai (15,8MB)\nEtymology of ShanghaiClick for the better image!\nThe city flowerIn 1986, the Standing Committee of the Shanghai Municipal People's Congress passed a resolution to adopt the white magnolia as the city flower.\nWhite magnolia is among the few spring heralding flowers in the Shanghai area. It is in full blossom in the early spring and before the Clear and Bright Festival, which usually falls on April 5 every year.\nThe flower has large, white petals and its eye always looks towards the sky. Therefore, the flower is hired to personify the pioneering and enterprising spirit of the city.\nThe city emblemDesign of the city emblem of Shanghai was approved by the Standing Committee of the Shanghai Municipal People's Congress in 1990.\nThe triangle emblem consists of graphics of a white magnolia flower, a large junk and a propeller.\nThe propeller symbolizes the continuous advancement of the city; the large junk, one of the oldest vessels plying the Shanghai harbor, represents the long history of the port; and the large junk is set against a background of a white magnolia flower blossoming in theearly spring, forecasting a bright future of the city.\nHistoryDuring the Song Dynasty (AD 960-1279) Shanghai was upgraded in status from a village (cun) to a market town (zhen) in 1074, and in 1172 a second sea wall was built to stabilize the ocean coastline, supplementing an earlier dike. From the Yuan Dynasty in 1292 until Shanghai officially became a city for the first time in 1297, the area was designated merely as a county (xian) administered by the Songjiang (??) Prefecture (Songjiang Fu).\nTwo important events helped promote Shanghai's development in the Ming Dynasty. A city wall was built for the first time during in 1554, in order to protect the town from raids by Wokou (Japanese pirates). It measured 10 meters high and 5 kilometers in circumference.\nDuring the Wanli reign (1573-1620), Shanghai received an important psychological boost from the erection of a City God Temple (Cheng Huang Miao) in 1602. This honor was usually reserved for places with the status of a city, such as a prefectural capital (fu), and was not normally given to a mere county town (zhen) like Shanghai. The honor was probably a reflection of the town's economic importance, as opposed to its low political status.\nDuring the Qing Dynasty, Shanghai became the most important sea port in the whole Yangtze Delta region. This was a result of two important central government policy changes. First of all, Emperor Kangxi (1662-1723) in 1684 reversed the previous Ming Dynasty prohibition on ocean going vessels, a ban that had been in force since 1525. Secondly, Emperor Yongzheng in 1732 moved the customs office (hai guan) for Jiangsu province from the prefectural capital of Songjiang city to Shanghai, and gave Shanghai exclusive control over customs collections for the foreign trade of all Jiangsu province. As a result of these two critical decisions, Professor Linda Cooke Johnson has concluded that by 1735 Shanghai had become the major trade port for all of the lower Yangzi River region, despite still being at the lowest administrative level in the political hierarchy.\nThe importance of Shanghai grew radically in the 19th century, as the city's strategic position at the mouth of the Yangtze River made it an ideal location for trade with the West. During the First Opium War in the early 19th century, British forces temporarily held Shanghai. The war ended with the 1842 Treaty of Nanjing, which saw the treaty ports, Shanghai included, opened for international trade. The Treaty of the Bogue signed in 1843, and the Sino-American Treaty of Wangsia signed in 1844 together saw foreign nations achieve extraterritoriality on Chinese soil, the start of the foreign concessions.\n1854 saw the first meeting of the Shanghai Municipal Council, created in order to manage the foreign settlements. In 1863, the British settlement, located to the south of Suzhou creek (Huangpu district), and the American settlement, to the north of Suzhou creek (Hongkou district), joined in order to form the International Settlement. The French opted out of the Shanghai Municipal Council, and maintained its own French Concession, located to the south of the International Settlement, which still exists today as a popular attraction. Citizens of many countries and all continents came to Shanghai to live and work during the ensuing decades; those who stayed for long periods - some for generations - called themselves \"Shanghailanders\". In the 1920s and 1930s, almost 20,000 so-called White Russians and Russian Jews fled the newly-established Soviet Union and took up residence in Shanghai. These Shanghai Russians constituted the second-largest foreign community.\nThe Sino-Japanese War concluded with the Treaty of Shimonoseki, which saw Japan emerge as an additional foreign power in Shanghai. Japan built the first factories in Shanghai, which were soon copied by other foreign powers to effect the emergence of Shanghai industry. Shanghai was then the most important financial center in the Far East.\nUnder the Republic of China (1911-1949), Shanghai's political status was finally raised to that of a municipality on July 14, 1927. Although the territory of the foreign concessions was excluded from their control, this new Chinese municipality still covered an area of 828.8 square kilometers, including the modern-day districts of Baoshan, Yangpu, Zhabei, Nanshi, and Pudong. Headed by a Chinese mayor and municipal council, the new city governments first task was to create a new city center in Jiangwan town of Yangpu district, outside the boundaries of the foreign concessions. This new city center was planned to include a public museum, library, sports stadium, and city hall.\nThe Imperial Japanese Navy Air Service bombed Shanghai on 28 January 1932, nominally in an effort to crush down Chinese student protests of the Manchurian Incident and the subsequent Japanese occupation of northeast China. The Chinese fought back in what was known as the January 28 Incident. The two sides fought to a standstill and a ceasefire was brokered in May. The Battle of Shanghai in 1937 resulted in the occupation of the Chinese administered parts of Shanghai outside of the International Settlement and the French Concession. The International Settlement was occupied by the Japanese on 8 December 1941 and remained occupied until Japan's surrender in 1945. According to historian Zhiliang Su, at least 149 \"comfort houses\" for sexual slaves were established in Shanghai during the occupation.\nOn 27 May 1949, the Communist Party of China controlled the People's Liberation Army and took control of Shanghai, which was one of only three former Republic of China (ROC) municipalities not merged into neighbouring provinces over the next decade (the others being Beijing and Tianjin). Shanghai underwent a series of changes in the boundaries of its subdivisions, especially in the next decade. After 1949, most foreign firms moved their offices from Shanghai to Hong Kong, as part of an exodus of foreign investment due to the Communist victory.\nDuring the 1950s and 1960s, Shanghai became an industrial center and center for revolutionary leftism. Yet, even during the most tumultuous times of the Cultural Revolution, Shanghai was able to maintain high economic productivity and relative social stability. In most of the history of the People's Republic of China (PRC), Shanghai has been the largest contributor of tax revenue to the central government compared with other Chinese provinces and municipalities.\nThis came at the cost of severely crippling Shanghai's infrastructure and capital development. Its importance to China's fiscal well-being also denied it economic liberalizations that were started in the far southern provinces such as Guangdong during the mid-1980s. At that time, Guangdong province paid nearly no taxes to the central government, and thus was perceived as fiscally expendable for experimental economic reforms. Shanghai was finally permitted to initiate economic reforms in 1991, starting the huge development still seen today and the birth of Lujiazui in Pudong.\nShanghai's Average Monthly Temperature and Precipitation in 2006\nShanghai has a humid subtropical climate (Koppen climate classification Cfa) and experiences four distinct seasons. In winter, cold northerly winds from Siberia can cause nighttime temperatures to drop below freezing, and although not usually associated with snow, the city can receive one or two days of snowfall per year.\nIn contrast, and in spite of being the peak tourist season, summer in Shanghai is very warm and humid, with occasional downpours or freak thunderstorms. The city is also susceptible to typhoons, none of which in recent years has caused considerable damage.\nThe most pleasant seasons are Spring, although changeable, and Autumn, which is generally sunny and dry. Shanghai experiences on average 1,778 hours of sunshine per year, with the hottest temperature ever recorded at 40 °C (104 °F), and the lowest at -12 °C (10 °F).\nThe average number of rainy days is 112 per year, with the wettest month being June. The average frost-free period is 276 days.","Yichang skyline at the Yangtze River\nLocation of Yichang City jurisdiction in Hubei\n|Municipal seat||Xiling District|\n|• CPC Party Secretary||Huang Chuping|\n|• Mayor||Li Lecheng|\n|• Prefecture-level city||21,227 km2 (8,196 sq mi)|\n|• Urban||4,232.4 km2 (1,634.1 sq mi)|\n|• Metro||4,192 km2 (1,619 sq mi)|\n|Elevation||58 m (191 ft)|\n|Highest elevation||2,427 m (7,963 ft)|\n|Lowest elevation||35 m (115 ft)|\n|Population (2010 census)|\n|• Prefecture-level city||4,059,686|\n|• Density||190/km2 (500/sq mi)|\n|• Urban density||330/km2 (860/sq mi)|\n|• Metro density||320/km2 (830/sq mi)|\n|Time zone||China Standard (UTC+8)|\n\"Yichang\", as written in Chinese\nYichang (Chinese: 宜昌) is a prefecture-level city located in western Hubei province, China. It is the second largest city in the province after the capital, Wuhan. The Three Gorges Dam is located within its administrative area, in Yiling District. At the 2010 census, its population was 4,059,686 inhabitants whom 1,350,150 lived in the built-up (or metro) area made of Yiling, Xiling, Wujiagang and Dianjun urban districts as Xiaoting District is not conurbated yet.\nIn ancient times Yichang was known as Yiling. There are historical records telling that in the year 278 BC during the Warring States period, the Qin general Bai Qi set fire to Yiling. In 222 AD Yichang was also the site of the Battle of Yiling during the Three Kingdoms Period.\nUnder the Qing Guangxu Emperor, Yichang was opened to foreign trade as a trading port after Qing and Great Britain signed Chefoo Convention, which was signed by Sir Thomas Wade and Li Hongzhang in Chefoo on 21 August 1876. The imperial government set up a navigation company there and built wharfs less than 0.5 kilometres (0.31 mi) in length. Since 1949, more than 50 wharves have been constructed at the port so that its wharf area is now over 15 kilometres (9.3 mi) long.\nIn October 1938,Yichang Retreat happened after Wuhan has been took by Japanese army.This retreat was commanded by a Chinese businessman Lu Zuofu.It helped China to transfer a huge number of technological and scientific materials.People treated it like an Eastern version of Dunkirk Evacuation.\nAdministratively, it is a prefecture-level city; its municipal government has jurisdiction over five counties, five urban districts, and three satellite county-level cities (Yidu, Dangyang, Zhijiang).\n- Xiling District (西陵区) - includes the city center\n- Wujiagang District (伍家岗区) - southeastern parts of the urban area, and suburbs\n- Dianjun District (点军区) - the part of the urban area southwest of the Yangtze (across from the city center), and suburbs\n- Xiaoting District (猇亭区)\n- Yiling District (夷陵区) - northern part of the urban area, and suburbs\n- Zhijiang City (枝江市)\n- Yidu City (宜都市)\n- Dangyang City (当阳市)\n- Yuan'an County (远安县)\n- Xingshan County (兴山县)\n- Zigui County (秭归县) - a county whose seat (Maoping) is some 50 kilometres (31 mi) west of downtown Yichang, next to the Three Gorges Dam\n- Changyang Tujia Autonomous County (长阳土家族自治县)\n- Wufeng Tujia Autonomous County (五峰土家族自治县)\n(2010 census) \n|Xiling District||西陵区||Xīlíng Qū||512,074||68.14||7,515.03|\n|Wujiagang District||伍家岗区||Wǔjiāgǎng Qū||214,194||84.03||2549.02|\n|Dianjun District||点军区||Diǎnjūn Qū||103,696||533.23||194.47|\n|Xiaoting District||猇亭区||Xiāotíng Qū||61,230||130.40||469.55|\n|Yiling District||夷陵区||Yílíng Qū||520,186||3,416.57||152.25|\n|Yuanan County||远安县||Yuǎn'ān Xiàn||184,532||1,741.06||105.99|\n|Xingshan County||兴山县||Xīngshān Xiàn||2,315.36||480.20||73.69|\n|Zigui County||秭归县||Zǐguī Xiàn||367,107||2,273.80||161.45|\nLike most prefecture-level cities, Yichang includes both an urban area (what's labeled on less detailed maps as \"Yichang\") and the surrounding country area. It covers 21,084 square kilometres (8,141 sq mi) in Western Hubei Province, on both sides of the Yangtze River. The Xiling Gorge (西陵峡), the easternmost of the Three Gorges on the Yangtze, is located within the prefecture-level city.\nThe central urban area of Yichang is split between several districts. On the right (northeastern) bank of the Yangtze are located Xiling District (where the city center is located), Yiling District (neighborhoods north of the center) and Wujiagang District (southern area). The city area on the opposite (southeastern) bank of the river is included into Dianjun District. All these districts, with the exception of the central Xiling, also include a fair amount of suburban/rural area outside of the city urban core.\nYichang has a four-season, monsoon-influenced, humid subtropical climate (Köppen Cwa), with cool, damp and generally overcast winters, and hot, humid summers. The monthly 24-hour average temperature ranges from 4.9 °C (40.8 °F) in January to 27.7 °C (81.9 °F) in July, while the annual mean is 16.85 °C (62.3 °F). Close to 70% of the annual precipitation of 1,140 mm (45 in) occurs from May to September. With monthly percent possible sunshine ranging from 24% in January to 49% in August, the city receives 1,568 hours of bright sunshine annually, and summer is the sunniest season.\n|Climate data for Yichang (1971−2000)|\n|Average high °C (°F)||8.6\n|Average low °C (°F)||2.0\n|Average precipitation mm (inches)||22.6\n|Average precipitation days (≥ 0.1 mm)||7.5||8.7||12.2||12.9||13.5||14.1||15.1||13.1||11.4||11.4||8.6||6.9||135.4|\n|Average relative humidity (%)||74||72||74||74||74||77||80||78||76||75||74||73||75.1|\n|Mean monthly sunshine hours||77.0||78.9||96.8||133.2||154.1||153.0||186.2||201.3||143.6||132.6||113.6||97.2||1,567.5|\n|Percent possible sunshine||24||25||26||35||37||36||43||49||39||38||36||31||34.9|\n|Source: China Meteorological Administration |\nYichang Sanxia Airport is located in the Xiaoting District of Yichang City, 26 km (16 mi) away from the city center and 55 km (34 mi) from the Three Gorges Dam site. The airport  is conveniently located, which borders Yihuang Highway in the north, Long River Golden Waterway in the south and Jiaozhi Railway in the east.\nRoads and bridges\n- China National Highway 318 runs east-west through most of the prefecture-level city, south of the center city\n- China National Highway 209 passes through the northwestern corner of the prefecture-level city (Xingshan County)\nSeveral provincial highways connect Yichang center city with most counties.\nSeveral bridges span the Yangtze River within the prefecture-level city of Yichang, including (upstream to downstream):\n- Xiling Bridge, connecting Letianxi and Sandouping in Yiling District, a few km downstream from the Three Gorges Dam.\n- Yiling Bridge, downtown Yichang (a few km downstream from the Gezhouba Dam). It connects the urban Xiling and Dianjun Districts.\n- Yichang Yangtze Highway Bridge, on the Hu-Rong Expressway, downstream of Yichang center city\n- Yiwan Bridge:A Railway Bridge for Yiwan Railway which connects Yichang to Chongqing by high speed trains,almost 5 km downstream from the Yiling Bridge.\nThere are several ferry crossings as well.\nThe Qing River in the southern part of the prefecture, with its cascade of dams, is an important waterway as well.\nYichang is served by several railway lines.\nThe Yichang East Railway Station, opened in the late 2010 in the eastern suburbs of Yichang, is presently the city's main train station. It is the junction point of two segments of the Shanghai-Wuhan-Chengdu Passenger Dedicated Line, one of China's new east-west rail mainlines. To the east, the Hanyi Railway (opened June 29, 2012) provides frequent service to Wuhan, with some trains continuing to Nanjing and Shanghai. To the west, the Yiwan Railway (Yichang-Wanzhou; opened December 2010) serves as the gateway to Hubei's southwestern panhandle (Enshi), with some service continuing to Chongqing and Chengdu.\nYichang has a population of 4,150,000 with urban population of 1,338,000. Yichang prefecture-level city, is home to many members of the Tujia ethnic group, who mostly live in several counties in the south-west of the prefecture.\nYichang also formed the border between the cultures of Ba in the west (an ancient state in the eastern part of what is now Sichuan Province) and the Chu State in the east (an ancient state in what is now Hubei Province and northern Hunan Province).\nSince 2002, Yichang City has been home of the China Three Gorges University (the result of the merger of the University of Hydraulic & Electric Engineering, Yichang and of Hubei Sanxia University), the largest comprehensive university in Hubei Province outside Wuhan, with over 20,400 full-time students.\n- China Three Gorges University\n- Three Gorges Vocational College of Electric Power\nThere are 170 secondary schools in Yichang enrolling 150,700 students. 53,900 of the citizens in Yichang hold a secondary school degree. There are 282 elementary schools being located in Yichang enrolling 156,900. 27,600 of the citizens hold secondary school degrees. 383 kindergartens located in Yichang with 78,500 children.\nYichang has long been a major transit port and distribution center of goods, and serves as the economic hub of western Hubei province and an intermediary between the major cities of Chongqing and Wuhan. Its primary industries are shipping and shipbuilding, taking advantage of its location on the Yangtze River.\nYichang prefecture is the site of many major hydroelectricity projects. The best known of them are the two huge dams on the Yangtze River: the Gezhouba Dam (located just upstream of Yichang central city) and Three Gorges Dam, which is 40 kilometres (25 mi) upstream. The Geheyan Dam and Gaobazhou Dam on the Qing River are important as well. Besides those, a huge number of medium-sized and small power plants operate on smaller rivers and streams within the prefecture.\n- Yichang Information\n- \"宜昌市2010年第六次全国人口普查主要数据公报\". Yichang Statistics Bureau. May 30, 2011. Retrieved 5 December 2013.\n- \"宜昌市土地利用总体规划（2006－2020年）\". The Bureau of Land Resources Yichang. Nov 18, 2013. Retrieved 5 December 2013.\n- 中国地面国际交换站气候标准值月值数据集（1971－2000年） (in Chinese). China Meteorological Administration. Retrieved 2010-05-04.\n- 3个月后宜昌火车站可进出动车 低站台改造成高站台.\n- Construction of Hanyi Railway to Kick off, Wuhan City Government web site, 2008-07-10\n- \"History of Yichang\" (in Chinese). Official website of Yichang Government. 2007-09-19. Archived from the original on 2008-04-21. Retrieved 2008-06-06.\n- Report on the Physical, Commercial, Social and General Conditions of Ichang and Neighborhood. H. A. Little. (Diplo. and Cons. Rpts. [London], Misc. Ser., 1908, No. 671, p. 24).— C. F. Langworthy.\n|Wikimedia Commons has media related to Yichang.|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:bb2d3662-c355-4afc-abe3-ee8efe6ecf78>","<urn:uuid:97280b74-93d0-45fc-be34-31e643c2e4fc>"],"error":null}
{"question":"Could you please explain what services CAAMA Music provides for Indigenous Australian musicians?","answer":"CAAMA Music is an Alice Springs-based company, owned and operated by indigenous Australians, that has been operating for over 30 years. They record, support, and promote indigenous Australian music, and are committed to working with indigenous Australians at the community level to train, develop, and nurture the talents and skills of artists and music industry workers through recording, performance, distribution, and publishing.","context":["Indigenous Resources - Links\nAboriginal and Torres Strait Islander users are advised that some of these websites may contain images and voices of people who have died.\nABC Online – Indigenous\nThe ABC Online Indigenous Gateway is designed to reflect current issues in the Indigenous community. It is a highly informative, dynamic and interactive entertainment space, showcasing creativity in a rich media environment. It draws together content from around the ABC.\nRadio National – Awaye!\nAWAYE! brings you diverse and vibrant Aboriginal arts and culture from across Australia and the best from indigenous radio broadcasters around the world.\nSBS – Living Black Radio\nSBS Living Black Radio aims to connect, inform and inspire Aboriginal and Torres Strait Islander communities around the nations through news, current affairs, and community information and profiles.\nAPRA - ATSI Music Office\nThe Aboriginal and Torres Strait Islander (ATSI) Music Office provides opportunities for ATSI songwriters and composers to develop their talents and build long-term sustainable careers in the local music industry.\nAPRA - Grants & Opportunities\nAPRA provides a list of grants and opportunities available to Australian musicians.\nACCELERATE is a tailored leadership initiative for talented Aboriginal and Torres Strait Islander people working in the creative industries.\nMinistry For The Arts – Indigenous\nThe Ministry for the Arts administers a range of Australian Government funding that supports Indigenous culture, languages and visual arts.\nAIME provides mentoring and educational services for Indigenous high school students to see them get through at the same rate as every Australian child.\nAustralian Youth Music Council – Indigenous\nThe Australian Youth Music Council (AYMC), formed in 2009, is committed to the development of young Australians in music across a diverse range of genres and fields. Their youth music database lists funding opportunities available to Indigenous musicians.\nDeadly Vibe - Deadly Sounds Radio Show\nDeadly Sounds radio show is a national weekly Aboriginal and Torres Strait Islander music program. The show is broadcast through the community radio network, as well as the National Indigenous Radio Service to almost 200 stations across Australia.\nAustralian Music Centre - Indigenous Australian Music\nThe Australian Music Centre (AMC) is the national service organisation dedicated to the promotion and support of both the artform of music and the creators and performers of contemporary classical, improvised jazz, experimental music and sound art in Australia. They provide examples of Indigenous and Indigenous-influenced works as well as other resources.\nCAAMA: Central Australian Aboriginal Music Association\nCAAMA Music is an Alice Springs-based company, owned and operated by indigenous Australians, that has been recording, supporting and promoting indigenous Australian music for more than 30 years. CAAMA Music is committed to working with indigenous Australians at the community level to train, develop and nurture the talents and skills of artists and music industry workers through recording, performance, distribution and publishing.\nSkinnyfish Music is based in Darwin and has been in operation for over 10 years. The driving philosophy behind the label is to work with and provide opportunities for Indigenous artists.\nDesert Pea Media\nDesert Pea Media is a not-for-profit, incorporated association established in 2002. For more than a decade they have been learning, building relationships and perfecting a process of working with young people and communities in regional and remote areas in Australia. DPM focuses on the process of storytelling to empower young people and to create important social and cultural dialogue.\nHeaps Decent is an initiative committed to finding and nurturing the creativity of underprivileged and Indigenous young people and emerging artists. By providing resources and opportunities, Heaps Decent supports the development of high quality Australian music with a unique identity.\nNG Media – Music\nNG Media is an Indigenous media organisation based in the remote desert of WA. NG Media’s vision is to empower Yarnangu to create and share their own stories through multi media.\nABMUSIC - Supporting Indigenous musicians in Western Australia\nABMUSIC is an Aboriginal Corporation formed in 1986 to support and nurture Indigenous musicians in Western Australia.\nMusic: Play for Life – Sources Of Financial Aid\nMusic: Play for Life provides information, advice and inspiration to Australians to encourage them to begin – and stick with – their music-making journey. They provide a list of sources of financial aid for musicians, including those specifically for Indigenous Australians.\nGoolarri Media - Music Department\nThe Goolarri Media Music Department offers support and assistance to new, emerging and established Indigenous musicians whilst acting as a resource base for information and administration support.\nBoomerang is an Indigenous festival featuring an array of music, dance, theatre, comedy, film and visual arts along with cultural knowledge exchanges and thought provoking conversations.\nAlice Desert Festival\nThe Alice Desert Festival is Central Australia’s premier annual arts festival, celebrating the desert and its rich cultural landscape.\nNational Indigenous Radio Service\nThe National Indigenous Radio Service Limited (NIRS) is a national program distribution service that delivers four radio channels of content produced by First Nations broadcasters via satellite distribution and via the internet.\nGadigal Information Service\nGadigal Information Service provides spaces for Aboriginal and other Indigenous people to develop their inherent story telling abilities.\nICTV: Indigenous Community Television\nICTV is an independent not-for-profit organisation. Our core purpose is to improve the livelihoods of Indigenous Australians through the creation of media distribution outlets that enable the active sharing of stories, culture, language and the provision of essential information.\nIndigiTUBE is an online community for sharing and accessing media made by and for Indigenous people in remote Australia.\nGurrumul Yunupingu Foundation\nThe Gurrumul Yunupingu Foundation was established in 2013 with a clear purpose to engage and support young Indigenous Australians – particularly in remote communities – through long term programs and activities that build on their natural strengths, assisting them to find pride and place as leaders in their communities, and giving them hope for the future.\nYothu Yindi Foundation\nThe mission of the Yothu Yindi Foundation is for Yolngu and other Indigenous Australians to have the same level of wellbeing and life opportunities as non-Indigenous Australians. The Foundation is a not-for-profit charitable public benevolent institution, with an all-Yolngu Board of Directors.\nMusicNT exists to support the growth and development of original contemporary music in the Northern Territory. MusicNT Inc. is the non-profit member based music organisation for the Northern Territory representing, developing and servicing the Territory’s original music industry. MusicNT is involved in the Bush Bands Bash and National Indigenous Music Awards.\nNational Indigenous Music Awards\nThe National Indigenous Music Awards (NIMAs) are recognised as one of Australia’s most prominent Indigenous music awards. The NIMAs showcase the rich musical landscape of Australia and highlight the music coming from all corners of the country. The NIMAs are a special celebration of Indigenous music. The Awards are a family friendly, not-to-be-missed event in the Darwin entertainment calendar and the Australian music calendar.\nBush Bands Bash\nThe Bush Bands Bash (BBB) has developed over the last ten years to become the peak Central Australian Indigenous music showcase event. Presented by MusicNT, the concert features six bands from the Northern Territory, Western Australia and South Australia, playing to a mixed Indigenous and non Indigenous audience of thousands. The BBB is preceded by a three day professional development and rehearsal intensive called the Bush Bands Business for all the bands participating in the Bash.\nThe Seed Fund is an Australian organisation, philanthropic in nature, we are not for profit and are privately owned. Established by musician John Butler through a donation to the Australian business arts Foundation's Australia Cultural Fund in 2005, we offer grants annually to bona-fide practicing artists and arts practitioners who are Australian citizens.\nClancestry – Pathways\nClancestry Pathways is a mentoring program that has been created to offer twelve early career Aboriginal and Torres Strait Islander song writing artists and media interns a hands on opportunity to spend a week in Brisbane with senior music and broadcasting industry professionals participating in workshops, discussions, media calls and recording sessions.\nNational Centre for Indigenous Excellence\nThe NCIE builds capabilities and creates opportunities for Indigenous Australians by delivering life-changing programs and promoting progressive thought leadership through its enterprises and facilities.\nThe University Of Adelaide – Aboriginal Studies In Music\nThe Centre for Aboriginal Studies in Music (CASM) is a specialist Australian Indigenous music centre located within the Elder Conservatorium of Music at the University of Adelaide.\nAustralia Council – ‘Protocols for producing Indigenous Australian Music’\nAustralia’s unique Indigenous artistic and cultural expression is rooted in thousands of years of heritage and continuing practice. This guide is designed to be an initial point of reference in planning a work with Indigenous music practitioners or using Indigenous cultural material."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:c05573f2-0f0d-4902-a5f6-5922307d45a2>"],"error":null}
{"question":"What was the total hard drive capacity of the first personal computer mentioned in the text, and what year was it purchased?","answer":"The first personal computer mentioned was purchased in 1993 and had a total hard drive capacity of 24Mb.","context":["|From typewrite to iPad--What an evolution and journey!|\nI've been running columns in Zambian national weekly newspapers non-stop since 1990, i.e. for twenty-four years. At one time I was writing three per week. In two of them I have used a pseudonym to hide my identity but in one of them I have used my real name.\nAs I have thought about this, I have been gripped by the changes that have taken place between 1990 and today. If they had taken place overnight, they would have been shocking but they took place slowly. So, it is the panoramic view that is breathtaking.\nWhen I began writing for the National Mirror newspaper in 1990, I was using a typewriter. For my younger readers, a typewriter was a machine we once used for producing print-like characters on paper. It has since been buried with the dinosaur.\nApart from the energy one exerted to push the mechanical keys and to push back the paper roller after every line, the challenge was that you could not squeeze in thoughts into your composition that occurred to you afterwards. Often I also had to re-type the whole article because of some errors made while typing.\nAfter typing the article, I used to get on my bicycle and ride across town to take it to the newspaper offices in time for my weekly deadline. At that time I was running two columns concurrently—one in my own name and the other in a pseudonym.\nBeing an itinerant preacher meant that sometimes I would have to consider the fact that the articles would be needed while I was away. Thankfully, there was the facsimile (shortened to fax) machine. If you are wondering what that is, it was a machine that scanned documents and transmitted them. It has also been buried with the dinosaur.\nThe fax machine was wonderful if I was travelling to foreign countries that were developed enough to have them. However, often my ministry took me to rural Zambia where they were rare. In such cases, I would write and deliver a number of articles to cover the period of my absence. This really stretched my creative capacity.\nWhen all was done, the final agony was when I would read the article in the newspaper only to find serious typographical errors. This was because in those days the newspaper copy typists had to copy word-for-word and they were not impeccable. Sometimes the sentences would say the exact opposite of what I wanted to say. It was agony, I tell you!\nThe Personal Computer\nThen the personal computer came to Zambia and I bade farewell to the typewriter. What a change this brought to my life! One of our deacons was running a project at the University of Zambia and had some five or six desktop computers in his office. He offered me the use of one at any time I wanted to use it.\nThis solved the problem of energy lost pushing the mechanical keys and the paper roller. It also solved the problem of failure to squeeze in thoughts and correct errors as I typed. At least now I could print only when the whole job was done.\nHowever, it now meant that each time I needed to work on the columns I would cycle to the office of the deacon, work on my articles, and print them out. Then I would cycle to the newspaper premises to drop off the script before cycling back home. It was an agonizing triangle across town. At least it kept me healthy.\nYou can well understand how delighted I was when I bought my first personal computer in 1993. Its total hard drive was 24Mb and it cost me an arm and a leg. It took very serious master bedroom negotiations to finally clinch the deal to get a slice from our savings as a family in order to purchase one. Felistas told me afterwards that she thought I was being extravagant. A pastor with a personal computer!\nWell, one of the main reasons for my \"extravagance\" was that I wanted to do my work as a columnist from my own home. So, I was now back to the situation where I could write the articles as soon as I was inspired. Sometimes inspiration came in the middle of the night. Also, now I only needed to cycle one way when delivering the articles.\nThankfully, before long, software for computers became available that enabled one to send a document from the computer using a telephone line and it arrived at its destination through the fax machine. That spelt the end of my cycling to the newspaper offices. I would only call to find out if the article had “arrived”. At that time, I thought that this was a great technological achievement.\nThe Electronic Mail\nThe next major blessing was the introduction of the electronic mail (shortened to email) in Zambia. At the touch of a button on my computer, my article could now arrive at the newspaper offices without me even leaving my seat. Although the fax machine did this, this time the sub-editors only needed to “cut and paste” my articles when they arrived in their inbox. That spelt the end of the typographical errors caused by copy typists.\nAt one time the editor for the newspaper with whom I was writing the two columns said to me, \"You should see the difficulties we have in re-writing some of the articles we get from our columnists. But for you, even when I'm going away, I just tell the sub-editors, 'When Pastor Mbewe's articles come, just cut and paste!'\"\nMy itinerant ministry still presented a challenge because up to that point my computer was a desktop. You can well understand my joy when the laptop computer became an option. I did not hesitate to begin bedroom negotiations and before long I had bought my first laptop, which weighed a ton but was at least portable.\nSince then, I have worked on reducing the weight of my laptop so that I can carry it around more easily and write my articles at the moment of inspiration. I now carry an iPad with me. My wife—yes, you read it correctly—recently urged me to buy one. It took one year of persuasion before I finally yielded in March 2012. Now, I am very glad I did.\nSo, as I pause on the eve of a quarter of a century of being a weekly columnist in my country, almost all my initial challenges are behind me. I can now compose my articles anywhere, even while on a queue in the bank. And I can now do it without exerting any physical energy and without re-writing the whole article. I can now send my articles from the comfort of my home or wherever I am on the planet at the touch of a button, and it will be published as it was written. Let’s face it, compared to the early nineties, this is paradise!"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:317c3bdf-685d-4476-84e1-2a2fc8821adc>"],"error":null}
{"question":"How do honey processed coffee and semi-dry wet milling compare in terms of water conservation? I'm really curious about eco-friendly coffee processing! 🌿","answer":"Both methods aim to reduce water usage but work differently. Honey processing is a hybrid approach between washed and natural processing, where only some mucilage is removed mechanically, requiring minimal water. Semi-dry wet milling significantly reduces water consumption from 1200 liters per 100 pounds of cherries (in traditional wet milling) to just 200 liters, mainly by manually propelling cherries into a floating tank and recycling water between processing steps. Both methods represent more environmentally conscious alternatives to traditional water-intensive processing methods.","context":["Honey Processing - An Introduction\nGeneral Processing Techniques\nThere are a number of standard processing techniques for coffee that you may be aware of. The two main ones are washed coffee and natural coffees. For washed coffees the skin and fruit (mucilage) of the coffee cherry is removed and the coffee cherry is washed down to it's parchment and it is then dried. For natural processing, the coffee is laid out to dry without removing any of the coffee fruit and when it has dried out completely it is then dry milled to remove the dried fruit.\nWashed coffee generally gives a sweeter and cleaner cup, it's the processing method that people in the US are most familiar with. However it does take a lot of water to process and sometimes in a competitive market the coffees aren't as standout as they might be by another processing method. Natural coffees on the other hand can have much more funky interesting flavors depending on the fermentation that happens in the coffee cherry while it dries. This can save on water but the fermentation process can be unpredictable and very hard to control for the farmer.\nOk, so thats the intro to coffee processing, where does Honey processed coffee come in? Sure, honey processing is a kind of a halfway point between these two techniques. The skin and some of the mucilage (the fruit of the coffee cherry) is removed mechanically when the cherry is picked. The cherry is then dried with the mucilage in tact and when it is sufficiently dried it is dry milled to remove the dried mucilage.\nSounds simple right? Not really. You've probably heard all about different color cherries from white, through yellow to red and black. What are all of these colors about, what do they represent? The simple and most straightforward answer is \"it depends\". There is no standard terminology or methodology for creating honeys. Nearly every farmer you speak to has a different process and technique. So, to give a little insight I'm going to describe some things I gleaned from a recent trip to El Salvador and Costa Rica.\nThe central principle in creating honeys is controlling the fermenting process of the mucilage on the coffee bean. The mucilage is high in sugar and so will ferment when exposed to the air and the heat. Increased heat will dry out the bean fast and stop the fermentation. On the other end of the scale, a long drawn out drying process at the ambient temperatures will prolong the fermentation process. There were two main techniques used to control the fermentation we came across in Costa Rica and El Salvador.\nDegree of Mucilage RemovalThe first technique was calibrating the demucilager to remove a certain portion of the mucilage and then drying as normal on the patio or raised bed until the bean was at the appropriate moisture content. So, leaving most of the mucilage on the cherry would result in more of a fermentation and taking the majority of the mucilage off the cherry would result in less fermentation. The spectrum usually goes from less fermentation to more fermentation, White honey, yellow honey, red honey, black honey. White is the least amount of fermentation with black being the most fermentation. So a white honey might leave 25% of the mucilage on while a black might leave all the mucilage but remove the skin. The other honeys are in between. Of course there is no standard between processors this is just a general rule of thumb and different producers have different names for the degree of fermentation.\nTime left before first turning\nThis technique is based around the amount and frequency of the turning of the coffee as it is drying. The processor removes a set proportion of the mucilage and then creates the different honeys by turning the coffee on different schedules. The process is straightforward. By exposing the drying beans to air and sun the bean will dry and the fermentation process will stop. On the other hand, by allowing the drying bean to sit without being disturbed the fermentation process will continue.\nFor lighter honeys (e.g. white honeys), the beans might sit for a day before their first turning and be turned regularly after that. For darker honeys (e.g. yellow and red), they can sit two, three or more days before they get turned for the first time. For black honeys, they can sit under shade to extend the fermentation process even more.\nGet in my mug\nWhen processing honeys there are lots of different ways to achieve similar goals. Hopefully we've shed some light on the different terms people use and the methods used to achieve the final product. There is no hard and fast terminology or methodology perhaps in the future people will settle on a standard technique - but I doubt it. Either way good producers will keep doing whats best for their coffee and we stand to benefit with tastier and tastier coffee in our mugs.","Every year, the trade show at the SCAA annual conference includes at least a few vendors selling the latest and greatest technology to filter, purify, ionize or otherwise ensure the quality of the water you put in your coffee. We are reminded that water is the principal ingredient in the coffee, after all. But you rarely hear anything at SCAA about the countless millions of gallons of water that are used to mill your coffee at origin. Increasingly, smallholder farmers are turning toward “semi-dry” wet mills like the one pictured here that dramatically reduce the amount of water needed for milling, leaving the balance for families to drink, cook, wash and farm with. As it turns out, the best water may be the water that doesn’t go into your coffee.\nIn standard wet milling processes, copious amounts of water are used to propel freshly picked coffee cherries into depulpers and through the channels that lead them to the tanks where they will ferment. After the beans are fermeted for just the right amount of time — a contested issue of no small consequence that merits another post on another day — more water is used to wash them. (Where that water goes and what it does to local water tables across the coffeelands is another issue of serious consequence worthy of its own post later, but the focus here is on the volume of water used in the wet milling process.)\nI have seen several estimates of the amount of water used during this process from different countries, and the most common figure seems to be about 1200 liters of water for every 100 pounds of fresh cherries. Those 100 pounds of cherries will produce about 16 pounds of export-ready coffee. These 16 pounds of export-ready coffee will lose about 20 percent of their volume in the roasting process, meaning that those 1200 liters of water will have been necessary to get just over 12 pounds of roasted coffee to market. That comes out to almost 100 liters for the last pound of fresh-roasted coffee you bought.\nIncreasingly, farmers — like those at Santa Anita de la Unión in Guatemala — are using a “semi-dry” wet milling process in which the cherries are propelled manually into a floating tank with a fixed amount of water that separates the quakers from the good beans before being passed to the depulper. This measure alone reduces considerably the amount of water needed for wet milling. But it is often combined with another measure — recycling the water from the depulping process for washing the beans after fermentation — that reduces water use even further. (As I have been led to understand, the water actually picks up bacteria in the depulping process that improve the quality of the washing process…Still looking for the research behind that and will update this post after I get a chance to review it.)\nThe most common estimate I have heard of the amount of water used in this process is 200 liters for every 100 pounds of cherries. That works out to less than 17 liters per pound of roasted coffee — a very favorable comparison indeed to the 100 liters used in traditional processes. What happens to the 1000 liters of water not used in “ecological” wet milling? It means more water for drinking. It means more water irrigation of coffee nurseries and other non-coffee crops that require it. It means more water for domestic uses, like cooking and cleaning. And it likely means significant conservation of limited water resources — no small achievement in the era of climate change."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:c9aba25a-d13f-488d-af5d-bb546d4a73a1>","<urn:uuid:1c19b2f6-b9f0-4d0f-9edc-729eb4b2471f>"],"error":null}
{"question":"How does the 'genuine link' requirement work between flag states and ships under UNCLOS?","answer":"The 'genuine link' requirement means that when a flag state grants its nationality to ships, it must demonstrate its connection with those ships by exercising effective jurisdiction and control in administrative, technical, and social matters. According to the International Tribunal for the Law of the Sea in 1999, the purpose of this requirement is to secure more effective implementation of flag state duties, not to establish criteria for challenging ship registration validity by other states.","context":["23 May 2021\nLondon. UK. Captain Michael Lloyd discusses the role of the UN Convention on the Law of the Sea 1982 (UNCLOS), flag States roles and responsibilities and the actions of the International Maritime Organisation (IMO).\nTHE UNITED NATIONS CONVENTION OF THE LAW OF THE SEA AND THE FLAG STATES\nIt is apparent to anyone who deals with Maritime affairs that as the flag states registrations grow, even extending to nations who have little experience of marine affairs or have marine administrations able to support their legal obligations, that not only is the United Nations convention on the Law of the Sea being ignored by many such states but this also affects the human rights of the crews and passengers on their registered ships.\nThe following is offered in support of this assertion.\nUNCLOS ARTICLE 94. Duties of the flag State.\nEvery State shall effectively exercise its jurisdiction and control in administrative, technical and social matters over ships flying its flag.\nIn particular, every State shall:\n(a) maintain a register of ships containing the names and particulars of\nShips flying its flag, except those which are excluded from generally accepted international regulations on account of their small size; and\n(b) assume jurisdiction under its internal law over each ship flying its flag and its master, officers and crew in respect of administrative, technical and social matters concerning the ship.\nEvery State shall take such measures for ships flying its flag as are necessary to ensure safety at sea with regards, inter alia, to:\n(a) the construction, equipment and seaworthiness of ships;\n(b) the manning of ships, labour conditions and the training of crews, taking into account the applicable international instruments;\n(c) the use of signals, the maintenance of communications and the prevention of collisions.\n- Such measures shall include those necessary to ensure:\n(a) that each ship, before registration and thereafter, at appropriate intervals, is surveyed by a qualified surveyor of ships, and has on board such charts, nautical publications and navigational equipment and instruments as are appropriate for the safe navigation of the ship\n(b) that each ship is in the charge of a master and officers who possess appropriate qualifications, in particular in seamanship, navigation, communications and marine engineering, and that the crew is appropriate in qualification and numbers for the type, size, machinery and equipment of the ship;\n(c) that the master, officers and, to the extent appropriate, the crew are fully conversant with and required to observe the applicable international regulations concerning the safety of life at sea, the prevention of collisions, the prevention, reduction and control of marine pollution, and the maintenance of communications by radio.\nIn taking the measures called for in paragraphs 3 and 4, each State is required to conform to generally accepted international regulations, procedures and practices and to take any steps which may be necessary to secure their observance.\nA State which has clear grounds to believe that proper jurisdiction and control with respect to a ship have not been exercised may report the facts to the flag State. Upon receiving such a report, the flag State shall investigate the matter and, if appropriate, take any action necessary to remedy the situation.\nEach State shall cause an inquiry to be held by or before a suitably qualified person or persons into every marine casualty or incident of navigation on the high seas involving a ship flying its flag and causing loss of life or serious injury to nationals of another State or serious damage to ships or installations of another State or to the marine environment. The flag State and the other State shall co-operate in the conduct of any inquiry held by that other State into any such marine casualty or incident of navigation.\nThe International Law Commission (ILC) was developed under the UN Charter as from 1947. The ILC held its first session in 1949, having as one mandates the codification of the Law of the Sea. This set the basis for the First United Nations Conference on the Law of the Sea.\nOne outcome of UNCLOS I was the adoption of the High Seas Convention 1958 whereby the “rules of the road” with respect to, inter alia nationality and registration of ships, the rights and obligations of the flag States over ships registered under its flag, were first laid down. These issues would be revisited throughout the discussions held under UNCLOS III up to the final provisions as currently laid down under the 1982 UNCLOS.\nAccording to Article 90 of 1982 UNCLOS, which is the same in substance as Article 4 of the 1958 HSC:\nEvery State, whether coastal or land locked, has the right to sail ships flying its flag on the high seas.\nFrom this right of Flag States to sail ships on the high seas is the prerogative of the flag States to exercise certain rights and duties upon those ships.\nHence, the flag State is sovereign in its decision to grant its nationality to ships. In the case of Lauritzen v Larsen, the US Supreme Court offers a comprehensive summary of the law of the flag:\n‘Each State under international law may determine for itself the conditions on which it will grant its nationality to a merchant ship, thereby accepting responsibility for it and gaining authority over it. Nationality is evidenced to the world by the ship’s papers and flag. The Unites States has firmly and successfully maintained that the regularity and validity of a registration can be questioned only by the registering State.’\nHowever, this right is not an absolute one. Indeed, this right to permit ships to fly under its flag has been qualified, as stated under Article 5 of the 1958 HSC:\n‘Each State shall fix the conditions for the grant of its nationality to ships, for the registration of ships in its territory, and for the right to fly its flag. Ships have the nationality of the State whose flag they are entitled to fly. There must exist a genuine link between the State and the ship; in particular, the State must effectively exercise its jurisdiction and control in administrative, technical and social matters over ships flying its flag.’\nThe jurisdiction is “in respect of administrative, technical and social matters concerning the ship,” vide Article 94 (1) Those are not so much matters “concerning the ship” as concerning the activities of the ship, or more accurately, the persons on board.\nWhen the flag State agrees to allow ships to fly its flag and thereby gives its nationality to such ships, it must also, at the same time, endorse the responsibility that is corollary to the prerogative of sailing ships on the high seas and having the exclusive jurisdiction on them. The flag State must demonstrate its connection with the ships – the genuine link – by exercising effective jurisdiction and control in administrative, technical and social matters over ships flying its flag.\nWhen a State assumes legal authority over a ship by grant of its flag, the State also assumes certain obligations.\nThe “genuine link” requirement proceeds directly from this principle. If the flag State is to perform its international duties as required by its ratification of UNCLOS, it must possess and exercise effective jurisdiction and control over its vessels. Unfortunately, this “genuine link” concept has become a concept of the law of the sea and of international law pertaining to ship registration, without any definition having been – on purpose – been assigned to it.\nIn 1999 the International Tribunal for the Law of the Sea (ITLOS) delivered the judgment in the M/V Saiga No. 2 Case (St Vincent and the Grenadines v Guinea) and it was therein reaffirmed that the genuine link was to be viewed in the context of the effective exercise of jurisdiction and control and not for determining whether a State is apt to allow ships to fly its flag.\nThe International Tribunal of the Law of the Sea (ITLOS), after considering Article 5 of the 1958 HSC, the deliberations of the ILC and UNCLOS I on the subject, and Article 94 of UNCLOS 1982, Stated that:\n‘The purpose of the provisions of the Convention on the need for a genuine link between a ship and its flag State is to secure more effective implementation of the duties of the flag State, and not to establish criteria by reference to which the validity of the registration of ships in a flag State may be challenged by other States.’\nArticle 94 (2) (b) requires the flag State to assume jurisdiction not only over ships flying its flag but also over the master, officers and crew of such ships. It can also be argued, a fortiori, that Article 94 (2) (b) also applies to all persons on board a ship, legally, such as passengers on a passenger vessel, or unlawfully, as in the instance of stowaways.\nRESPONSIBILITY FOR UNCLOS\nThere are three organisations concerned with the UN Law of the Sea.\n- The Division of Ocean Affairs and Law of the Sea at the UN (DOALOS)\n- The International Maritime Organisation (IMO)\n- The International Law of the Sea Tribunal (ITLOS).\nTo establish which organisation, the IMO or the UN has responsibility to govern the United Nations Law of the Sea, we wrote to both DOALOS and the IMO asking who had this responsibility and, primarily, who had jurisdiction over the Flag States ensuring their implementation of the Law of the Sea convention.\nResponse from the IMO\n‘The UN Convention on the Law of the Sea provides the legal impetus and basis for many, if not all the IMO treaties. However, no IMO treaty is tied to UNCLOS; each are independent treaty instruments of their own accord. Neither the Division of Oceans of the Law of the Sea nor the IMO has oversight or enforcement authority for UNCLOS, or any IMO treaty. Neither body has an operational arm. Instead, implementation of UNCLOS and IMO instruments are the responsibility of the contracting States themselves, either through Articles 5 and 26 “pact sunt servanda” of the Vienna Convention on the Law of Treaties, 1969, the terms of the treaty itself, (see, e.g., Article 1 of SOLAS 74), or both. In short, it is for the Contracting States to meet their treaty obligations; neither the DOALOS nor the IMO can force them to do so.’\nResponse from the Division of Ocean Affairs and Law of the Sea, UN\n‘As a general rule, secretariats of intergovernmental organisations provide services to and assist States which are members of these organisations. As far as this Division is concerned, Member States of the United Nations have not conferred on it “the responsibility of ensuring the compliance of the Flag States with their responsibilities under UNCLOS.’\nFrom this can be seen that there is no department either at the UN or the IMO responsible for the implementation or Jurisdiction of the UN convention of the Law of the Sea. (UNCLOS).\nTHE VIENNA CONVENTION\nThe 1969 Vienna convention on the Law of Treaties has several provisions dealing with Treaty compliance and domestication.\nARTICLE 62. FUNDAMENTAL CHANGE OF CIRCUMSTANCES\n- A fundamental change of circumstances which has occurred with regard to those existing at the time of the conclusion of a treaty, and which was not foreseen by the parties, may not be invoked as a ground for terminating or withdrawing from the treaty unless:\n(a) The existence of those circumstances constituted an essential basis of the consent of the parties to be bound by the treaty; and obligations still to be performed under the treaty.\nSince the ratification of UNCLOS by a number of these island states, the circumstances have completely changed. For example, the number of ships under the Bahamian Flag has increased from single figures to now over 1000 with over 100 of those being cruise ships. The addition of the largest cruise fleet in the world now means that the Bahamas flag State is responsible for the social and judicial care of not just the crews, but the additional hundreds of thousands of passengers on these ships. The Bahamian state clearly cannot possibly fulfil their obligations therefore article 6 (a) can be invoked. The change of circumstances will invoke Article 62 of the Vienna treaty, and this then releases them from the Vienna convention and makes them liable to arbitration by the UNCLOS Tribunal.\nAn equally pertinent fact is the human rights record of a number of these states show that they fall well below that required for a state committed to fulfilling human rights on their registered ships under article 94 of UNCLOS.\nThe following are extracts from one such recent report.\n“The most serious human rights problems were mistreatment of irregular migrants (compounded by problems in processing them); an inefficient judicial system, resulting in trial delays and an increase in retaliatory crime against both witnesses and alleged perpetrators; and the perception of impunity on the part of law enforcement and immigration officials accused of using excessive force.”\nOther human rights problems included substandard detention conditions; corruption; violence and discrimination against women; sexual abuse of children; and discrimination based on ethnic descent, sexual orientation, or HIV status.\nCountry Reports on Human Rights Practices for 2015, United States Department of State • Bureau of Democracy, Human Rights and Labor.\nThese contraventions places those on board their registered ships with no protection UNCLOS is formulated to support. It also contradicts the responsibility that is corollary to the prerogative of sailing ships on the high seas and having the exclusive jurisdiction on them.\nThe constitution of this state includes the following;\nWhereas every person in The State is entitled to the fundamental rights and freedoms of the individual, that is to say, has the right, whatever his race, place of origin, political opinions, colour, creed or sex, but subject to respect for the rights and freedoms of others and for the public interest, to each and all the following, namely\n(a) life, liberty, security of the person and the protection of the law.\nTherefore All ships registered in such state are protected by the Nations Constitution however in common with most flag states, Their registered ships ships do not carry any information regarding the common law of the State and there is no attempt to give those on board the protection of the National Law.\nAgain in common with most flag states, there is no trained police force to deal with marine crime.\nIMO Resolution A912 (22) Annex 1 States that a Flag State should;\n- Provide for the enforcement of its national laws, including the associated investigative and penalty processes.\n- Take appropriate action against ships flying its flag that fail to comply with applicable requirements.\n- Ensure the availability of sufficient personnel with maritime and technical expertise to carry out its flag state responsibilities including;\nThe development and enforcement of necessary national laws, the reporting of casualties and incidents as required by the respective instruments to which the flag state is a party.\nMost Flag States have not tried to comply with this resolution. Their national laws are not enforced on their ships, and they do not ensure that there are sufficient responsible personnel to enforce their laws on their ships.\nIMO Member State Audit Scheme\nThen there is the IMO Member State audit scheme. The scheme is a move in the right direction, however, as with all audits, much depends on those making such an audit and the open disclosure of the audit finding, or failing that a league table of the Flag States. If the intention is that they make an accurate audit, then those employed for such an audit must be free of any financial interests in the ship, the owners and the Flag State and declare the same. How can the IMO impose such a declaration when the Flag State delegates to the IMO refuse to do the same? While classification societies would seem to be an obvious choice for auditing, we must remember that many of the Class surveyors have little shipboard experience and the societies are not always free of such financial involvement. If the IMO established a separate Audit department under the auspices of the organisation, this would improve the audit strategy and have the trust of those at sea.\nThe rapid expansion of these flag registrations with the comparative recent inclusion of growing large fleets of cruise vessels places these States in breach of UNCLOS and their own conventions and constitutions on human rights, thus depriving the millions of crew and passengers of their human rights to just and appropriate judicial rights while on board their registered ships,\nMany of these states are also in clear breach of Article 62 of the Vienna Convention, which the IMO states prevents any jurisdiction by the IMO of this State. This then removes the protection afforded by this Convention.\nIf these states cannot fulfil the obligations under their constitutions on board their registered vessels, there is no guarantee of the security or protection of the law on board their vessels.\nIt is a matter of concern that both the UN and the IMO declare they have no jurisdiction of UNCLOS. If this remains the case, regardless of the constant breaches and failures of many flag states to fulfil their obligations, then UNCLOS becomes a futile convention, and from this we must question the purpose and capabilities of the IMO.\nNB: OP-ED. The opinions expressed are those of the author and do not necessarily reflect those of Human Rights at Sea."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:aeb2ce3d-405e-4a83-b669-0ff9807fc7cf>"],"error":null}
{"question":"Comment est-ce que les systèmes de victoire dans Guardians Chronicles et Monarch demonstrent different approaches to winning?","answer":"In Guardians Chronicles, victory is determined through newspaper reports that chronicle the heroes' success or failure in completing scenario objectives against Doktor Skarov, resulting in either outright success, partial success, or failure. Monarch's victory condition is more straightforward - the sister whose court accumulates the most crowns through strategic card combinations and banner choices becomes the Queen. These different victory systems reflect their narrative focuses - Guardians Chronicles emphasizes storytelling through mission outcomes, while Monarch focuses on strategic court-building.","context":["Guardians Chronicles is an epic semi-cooperative board game of superheroes and villains. In the first boxed set, Episode 1, the players, as four brave heroes of the Liberty Patrol, attempt to stop the dark schemes of one of their worst enemy: evil Doktor Skarov. With one player playing the villain, safely retreated in his lair, the other players have to cooperate to enter his base and evade all his Acolytes and traps. Only by joining forces and working together will they succeed in stopping Dr. Skarov’s madness. Guardians Chronicles provides an intense, immersive game experience, thanks to its abundance of material (including miniatures of heroes, villains and Acolytes!) and simple yet comprehensive game system.\nGuardians Chronicles is intended to be the first of a series of games telling the adventures of the Liberty Patrol against ever darker threats and enemies. As of the time of writing this I personally haven't seen anything new which is a shame as this game has definitely got legs.\nHOW TO PLAY THE GAME\nAt the beginning of the game, the player playing Skarov creates his base by arranging 9 double-sided game board tiles into a 3x3 grid, with his control room being in the center. Each player takes his or her character sheet, miniature and 7-10 action cards. These characters enter the grid on one of the side tiles and need to move around the square – facing Acolytes and traps along the way – in order to achieve whatever objectives set for the current game, such as thwarting a nuclear missile attack.\nEach turn, each hero player plays 1 or 2 action cards; each card can be played either as a special power or as modifiers to the hero’s basic features – movement, attack, defense and mental. Each hero player has also four actions in a round, that can be taken in any order; the available actions are to move across the base, to attack an enemy, or to use a special power on a played action card or on the hero’s character sheet. The villain player then receives a number of action points depending on the heroes’ actions, and uses these to activate Professor Skarov, his Acolytes, or his robots, with these figures also performing move, attack, or special power actions.\nAs the players complete (or fail to complete) objectives, the newspapers report on who did what, and the sum of those reports determine who comes out on top. Depending on the scenario, the players must achieve a certain number of objectives to attain victory, while the evil Pr. Skarov attempts to thwart their efforts.\nWHAT DO YOU GET IN THE BOX?\n4 Heroes miniatures, each with a character sheet and a set of 7-10 action cards. 1 Dr Skarov miniature, with his character sheet\n3 Sisters Kinoichi miniatures with their character sheets 1 Supervillain miniature with his/her character sheet\n20 Androids & Gynoids miniatures 9 double-sided room tiles 20 Event cards\n4 Heroes dice 4 Villains dice 5 Neutral dice A heck of a lot of tokens!\nThe game comes with two comic-book style rules and and scenario booklets; A5 size, glossy and in full colour. The Rules can be found in storybook format throughout the Guardians Chronicles booklet #1 \"The Threat of Doktor Skarov\" whereas the second booklet contains the setup, goals, description and stories for six scenarios, growing from the initiation adventure which is short and sweet, and the five other tale parts that elongate the story through to its fruition with the possible end of Skarov.\nIf you are used to games having ABC style rules which show you how to setup each game with examples and directions then GUARDIANS CHRONICLES is going to be a very rude awakening for you as each scenario is complete on one comic-book page. There is a scenario title alongside the Scenario number, a photo-shoot of the boards (room tiles) required for the game (along with the title of the board and the positions of the extra dolors|) and then a few brief lines of text. There is no list of what miniatures you will need, just any points of interest on the map plus an entry and exit space. This is all very disconcerting for the average boardgame player, and even the avid comic-book reader may need some time to actually get their heads around the fact that this is the complete scenario - all you have to do now is play it.\nEvery scenario has the same Goal - to get a Good newspaper report. One player takes the control of the Acolytes under Doktor Skarov as well as the good (read \"evil\") Doktor himself, while the other players each control a super-hero. Every character, Good or Evil, has a character card (the Acolytes have one card per Acolyte type) which gives some detail and description of that specific Hero/Villain as well as Values for Speed (basically this is movement), Attack (number of Combat dice rolled), Defense (number of successful hits taken before damage ensues), Mental (Heroes only ability to avoid traps etc) plus Number of Actions, Health, Power, Type and Rank.\nThe Heroes are members of the elite LIBERTY PATROL and each has their own specific set of Power cards which can be used either for the Special Power itself or as a Modifier (adding to one or more of the character's stats). Hero Players begin the game as Rookies then progress to Normal (by flipping their ID card) and on to Veteran at which point they can add two special \"veteran\" cards to their set. Super Heroes also have a Weakness that may be used as an advantage by the Villains. Event cards can be used by Villains in similar ways to the Heroes Power cards, either for the Event itself or as a Modifier when butted against the Villains card to add or subtract points from the Villains abilities.\nThe area of adventure is made up from one or more gameboard tiles. Each of these tiles is different on each side, with rooms, corridors and other information (Control, Traps etc) clearly marked. There are separate tiles for Doors which are placed according to the scenario to allow entrance from gameboard tile to gameboard tile. Each Door (aka Air Lock) tile has an Open side (Green) and a Closed side (Red). On the Closed side there are two numbers which represent Mental and Attack requirements to open the Door. The Hero must be on the space directly in front of the door and then decide whether to open it using Mental power or Brute force (Strength). Other information on the gameboard tiles show any reinforcements (to the die roll) Heroes may get and a ? in a yellow diamond indicates how many dice to roll for a statistic check.\nAll Hero/Villain attacks are determined by die rolling, abilities/skills and modifiers. If a Hero or Villain gets hurt they are marked with Damage counters (Zap, Bam, Krak and Pow in good old comic-book style). The scenario ends when the Villain is beaten or the Villain escapes or the Villain surrenders. At this point The Guardian Chronicles Newspaper cards are arranged to report the action and depending on the overall view (Blue text is for Good and Red text is for Evil) a win can be an outright success, a partial success/partial failure or an out and out failure (aka Win, Lose or Draw). To fill in any blank spaces there are some grey adverts which give the Newspaper's front page a more realistic appearance. This is a great idea even though it is mainly only aesthetic. I would have liked a few more report cards just so that each game can still have the same result but be written up (reported) slightly different each time.\nAs well as playing through the scenarios in the booklet, players can make up their own scenarios or even simply randomly layout X number of gameboard tiles set up the pieces as shown on those tiles: Blue spaces are normal, Green spaces are where Heroes begin, Orange spaces are where the characters can interact with the environment around them and Purple are spaces where Doktor Skarov can activate one of the tiles in his base. White lines indicate walls and doors can be placed where corridors meet gameboard tile to gameboard tile or the corridor can be left open as a long passageway. Villains and Acolytes only appear on the tiles when a Hero has line of sight. Acolytes can attack without first having to move from the space where they appear.\nRepeating what I mentioned earlier, GUARDIAN'S CHRONICLES is a game that takes a while to get your head around. It has elements of other miniatures based action games but also has its own unique mechanics, as well as its own specifically unique approach to rules delivery and scenario setups. You don't need to be a comic-book super-hero fan but in this case it really does help if you are a regular reader of action comics because you will immediately accept the visuals presented to you in the booklets. The game generates an excitement in the players unlike most, if not any, other boardgames, a sort of adrenaline rush usually only enjoyed by playing electronic games, especially those online. This is a good first boxed set of games which could grow into a series in the way Carcassonne or Catan has over the years. I hope we can expect an annual update from IELLO.","MONARCH is a strategy game for 2 to 4 players, set in the mythical lands of Minervia. Players compete as sisters who must strategically assemble an impressive court and prove themselves ready to become the next Monarch.\nDecide when to tax or harvest the fertile lands. Attract wise advisors, magnificent beasts, and majestic regalia to glorify your court. Sabotage your sisters’ efforts by sending ‘Unwanted Guests’ to unsettle their courts.\nIn the world of MONARCH, strategy and surprise await players at every turn. Players must use inventive planning and keen judgment to navigate a world of beauty and mystery, and to discover their destinies … who will reign?\nSee the detailed website for the game with videos of the game’s creation and more at: http://www.playmonarch.com.\nEach sister aims to assemble a court of Court Cards: wise advisors, exotic animals, and symbolic regalia. Each of these Court Cards provides crowns, and the sister whose court contains the most crowns at the end of the game becomes the Queen.\nYour turn is very straightforward:\nThere are tricks to assembling a majestic court. Some cards don’t work together well: the Astronomer is worth nothing if in a court with the Fireworks because he will be unable to see anything! Other cards work very well together: the Beastkeeper is worth more crowns for each animal she shares a court with.\nIn order to recruit for your court you’ll need gold and food, which you get by taxing and harvesting the land that the sisters rule over. Over the course of the game you’ll improve the land, building Royal Goateries and Jewel Bazaars, which benefit everyone.\nWhen a sister knows what kind of ruler she will be, she can take up a banner to commit herself to a style of rulership: Wisdom, Bounty, Culture, Might, or Balance. Banners provide extra crowns and a special power to help its bearer succeed.\nMonarch features the atmospheric scratchboard art of Kate Adams, giving it a unique look. Each illustration is scratched by hand and then (delicately) digitally colored to produce the fantastic effect that sets the stage for the enchanting realm in which Monarch is played.\nKate Adams is Monarch’s illustrator, and is the artist that created the gorgeous scratchboard art featured in the game. Kate is a graduate of the Rhode Island School of Design, and has illustrated several books. This is her first board game project!\nLearn more about the process behind the artwork at playmonarch.com!\nMONARCH sets a new bar in game art with its astonishingly beautiful imagery, and the game has also been described as “mechanically brilliant” and “a welcome change of pace” by players. No one strategy in the game guarantees success, so the game is infinitely repayable.\nFans also tell us that having female protagonists “is a welcome change from the heavily male board game industry” and that MONARCH might be one of the first games out there to have a strong female point of view without being biased or girly.\nPlayers love the way the game functions as a “gateway” game so that both players new to strategy games as well as steadfast game players can find enjoyment in the game — a rare achievement. Players tell us that it is “tough to put away” and that Monarch’s unassuming yet deep gameplay keeps them coming back.\nA Game by Mary Flanagan Art by Kate Adams\nGame Design: Mary Flanagan, Max Seidman, Zara Downs\nArt Direction: Sarah Ettinger, Zara Downs\nIllustration: Kate Adams\nExecutive Producer: Mary Flanagan\nResearch: Geoff Kaufman, Mary Flanagan, Max Seidman\nArt: Kate Adams, Ed Flanagan, Sarah Ettinger, Zara Downs\nArt Direction: Mary Flanagan, Sarah Ettinger\nThanks to Myriad friends, relatives, and strangers\nNYC-Playtest group, Boston Festival of Independent Games attendees, Meaningful Play, IndieCade, and Gen Con attendees\nSpecial Thanks To:\nNaomi Clark, Angela Zhang, Farooq Ahmed, The Brown Foundation and Dora Maar House, Richard Garriott and Starr Long, Ryan LaFlamme, The Cardboard Republic, Cyrus Kirby, Fathergeek, Vincent Paone, Dad’s Gaming Addiction, Robert Kalajian Jr., Purple Pawn\nRichard Garriott de Cayeux as the Useless Emissary\nChristopher Egert as the Boorish Uncle\nDavid McDonald as the Drunk Juggler\nJonathan Skinner as the Insistent Peddler\nGame Production Team: Sukie Punjasthitkul, Danielle Taylor, Jenny Yeoh-Wang, Lucas Sanford-Long, Jinny Seo, Savannah Liu, Alannah Linkhorn, Emma Marsano\nAcknowledgments: Many thanks to Jenny Yeoh-Wang for her efforts during our Kickstarter campaign, to Jinny Seo for her work on the instructions, and to our many local playtesters!\nTypefaces: Monarch uses The Fell Types. The Fell Types are digitally reproduced by Igino Marini. www.iginomarini.com\nWarning: In compliance with the Consumer Product Safety Improvement Act of 2008 (CPSIA) we are notifying you that some of the products we sell may contain small parts or parts that may break off potentially causing a choking hazard to small children. Please supervise small children to ensure their safety."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:a02dc02c-5d02-4300-9b94-6df0b6232cf3>","<urn:uuid:2a9e8f60-dfa4-40d1-8a30-9238a844013b>"],"error":null}
{"question":"What are the recommended trick-or-treating time windows and healthy eating tips for Halloween? Please provide both official timing guidelines and nutrition advice.","answer":"The Westmont Police Department recommends trick-or-treating from 2-7 p.m. on Halloween, October 31. For healthy eating during Halloween, several tips are recommended: children should eat a good meal before trick-or-treating to avoid consuming treats during their trek, parents should set limits on candy consumption (e.g., one piece a day), and trick-or-treat bags should be size-appropriate rather than using large shopping or garbage bags. Additionally, parents can consider limiting trick-or-treating to a 2-3 block radius to manage the amount of treats collected.","context":["Choose alternatives to candy for trick or treaters\nIn a few nights, ghosts, goblins and witches will be knocking at your door; trick or treaters will be out in force.\nHere’s a scary fact. A startling 37 percent of Delaware children are overweight or obese, putting them at risk for illnesses such as type 2 diabetes, high cholesterol and high blood pressure.\nHalloween is all about the candy. In small quantities, sugary treats can fit into a healthy diet. But, in some households, Halloween results in a feeding frenzy of empty calories.\nOver-consuming candy not only leads to weight gain and obesity-related illnesses, but it might also result in unpleasant trips to the dentist’s office.\nIt might be wise to re-think what we’re doling out to our children. Or, at the very least, place more emphasis on the fun of donning costumes and visiting neighbors.\nIt’s not about being the “Food Police” of the neighborhood, or the house that’s egged annually – it’s about promoting moderation. The saying, “It takes a village” absolutely applies to solving the obesity epidemic.\nFollowing are some tips to make Halloween a little healthier for all involved:\n• Don't send your children trick-or-treating on an empty stomach. Make sure they eat a good meal beforehand to reduce the chance they consume their treats during their trek around the neighborhood.\n• Trick-or-treat bags that children carry should be appropriate to their size. Children don’t need to be carrying large shopping or plastic garbage bags.\n• Consider limiting the houses your children can visit to a two or three block radius. That way the moderate amount of treats will be manageable.\n• At your house, try handing out pretzels, boxes of raisins, 100% juice boxes, fig bars or packs of sugar-free gum. Other healthy ideas include cereal bars, pumpkin seeds, peanut butter crackers, baked chips, Goldfish or mini bags of popcorn.\n• Consider giving fun, non-candy alternatives instead of high sugar treats. Non-food items that can be used as “treats” include stickers, temporary tattoos, fun pencils, spider rings, glow sticks or bubbles.\n• If your child returns home with enough candy to feed a small army, suggest that they share with those who may not have received any candy on Halloween. Check into donating half of the candy to a local nursing home or shelter.\n• Separate their loot into favorites and non-favorites. Freeze some of the favorites for later. Take those non-favorites to work or church where they can be shared with many.\n• Agree in advance on how much they can eat and when. Set limits on how often the candy can be consumed, (e.g. one piece a day).\nMany parents fall off the ‘diet wagon’ around this time of year. If you yourself are trying to limit your intake of sweets, there are things you can do to stay focused on your healthy eating goals.\nIf you do purchase candy for trick-or-treaters, buy a type that is not your absolute favorite. In this way, you won’t be tempted to indulge in any leftovers.\nIf you end up with lots left over, consider giving it away. Having a bowl of candy on your kitchen counter is a sure fire way to sabotage your healthy eating goals. Out of sight, out of mouth.\nMarianne Carter is a registered dietitian and certified health education specialist. She’s the director of the Delaware Center for Health Promotion at Delaware State University.","Village of WestmontDate Issued: October 24, 2016\nOctober is packed full of Wicked West Fest fun! The Village of Westmont encourages everyone to have a fun & safe Halloween. Remember, the Westmont Police Department recommended hours for trick-or-treating are 2 to 7 p.m. on Halloween, Oct. 31. Following are some upcoming events and Halloween safety tips.\nZOMBIE PUB CRAWL Saturday, Oct. 28 - 2 to 6:00PMVarious Locations Throughout WestmontThis new event hosted by Westmont Special Events invites guests to take a ride on the Boogeyman Bus as we venture throughout the community visiting participating pubs. Each location will have food and beverage specials as well as a fun Halloween activity including a costume contest. This is a 21 and over event and there is a $15 fee that covers transportation and an event t-shirt. Sign up at westmontevents.com by Oct. 27, 10 a.m. For more information, contact us at email@example.com or call 630-417-0280.\nHALLOWEEN FUN FAIRTuesday, Oct. 31Westmont Community Center, 75 E. RichmondEnjoy a safe and warm evening as the whole family is invited to a fun-filled time as you trick or treat with us! There will be prizes galore while you try your luck on the carnival games. Laughter will be heard in every corner as the children jump in the Halloween bounce house. Monsters fairies, ghouls and pirates can join in on the “Parade of Costumes” to see if your name is drawn to win a special gift from the Park District. Don’t worry about dinner! Our team is ready to serve up hot, fresh pizza, popcorn and soda. What an entertaining way to spend Halloween!\nTRICK OR TREATING ON HALLOWEENTuesday, Oct. 31, 2-7 p.m.Halloween NightOn Halloween night, the Westmont Police Department recommends trick or treating from 2-7pm. BE SAFE! Be sure to follow typical Halloween safety tips such as wearing reflective clothing, be careful of masks and costumes that can impair your vision or ability to move, be careful when crossing the street, travel with groups, and have a parent check your candy.\nHAVE A SAFE HALLOWEENFollowing are a few Halloween Safety Tips promoted on the Centers for Disease Control (CDC) website to help ensure that everyone has a SAFE HALLOWEEN!\nS - Swords, knives, and similar costume accessories should be short, soft, and flexible.\nA - Avoid trick-or-treating alone. Walk in groups or with a trusted adult.\nF - Fasten reflective tape to costumes and bags to help drivers see you.\nE - Examine all treats for choking hazards and tampering before eating them. Limit the amount of treats you eat.\nH - Hold a flashlight while trick-or-treating to help you see and others see you. Always WALK and don't run from house to house.\nA - Always test make-up in a small area first so to avoid bad reactions. Remove it before bedtime to prevent possible skin and eye irritation.\nL - Look both ways before crossing the street. Use established crosswalks wherever possible.\nL - Lower your risk for serious eye injury by not wearing decorative contact lenses.\nO - Only walk on sidewalks whenever possible, or on the far edge of the road facing traffic to stay safe.\nW - Wear well-fitting masks, costumes, and shoes to avoid blocked vision, trips, and falls.\nE - Eat only factory-wrapped treats. Avoid eating homemade treats made by strangers.\nE - Enter homes only if you're with a trusted adult. Only visit well-lit houses. Don't stop at dark houses. Never accept rides from strangers.\nN - Never walk near lit candles or luminaries. Be sure to wear flame-resistant costumes."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:1367315a-ea49-4efd-9637-9d31cb1fa4df>","<urn:uuid:8f52bf54-5fc1-4417-9087-1e1282afdbf1>"],"error":null}
{"question":"What are the similarities between the water management challenges faced by the Neponset River after Hurricane Diane in 1955 and the current situation in the Colorado River Basin?","answer":"Both water systems faced serious management challenges that required government intervention. After Hurricane Diane in 1955, the Neponset River's privately owned industrial mill dams contributed to severe flood damage, leading the state to take control of the river corridor through eminent domain and implement a major flood control project that involved rebuilding dams and restructuring the river. Similarly, the Colorado River Basin is now facing a crisis that has prompted federal government intervention, with the Bureau of Reclamation implementing mandatory water use cuts in Arizona, Nevada, and Mexico under the Drought Contingency Plan, and announcing further cuts to California, as the Basin's two largest reservoirs reach dangerously low levels.","context":["The Neponset River, One of the First in New England to be Harnessed for Power\nAs a relatively small river located near Boston, it is not surprising that the Neponset was one of the first rivers in New England to be harnessed for water power.\nThese early dams tended to be significantly less permanent structures than their modern counterparts, apparently regularly washing out during spring floods, only to be promptly rebuilt.\nOver time, a whole series of dams were built on the Lower Neponset from “Lower Falls ” (now Lower Mills) to “ Upper Falls” (now the area near the Tileston & Hollingsworth Dam). Lower Falls and Upper Falls each had at least two dams at one time, as compared to the modern single dams. Each of the dams would have supported several mills on either side of the River.\nThese early dams helped the Neponset River earn a string of industrial “firsts,” including:\n- the country’s first paper mill,\n- first gunpowder mill,\n- and (most important of all!) the first mechanized chocolate production.\nThe first dam on the Neponset River, which was probably the second or third dam in the new world, was erected in 1634 by Israel Stoughton.\nDuring its heyday, around the time of the American Revolution, the Neponset River was arguably the center of American industrial production, and the Neponset River was more or less continuously impounded from Readville to Lower Falls by a series of at least seven dams. Over time, other larger rivers such as the Merrimack eclipsed the Neponset as the major engines of the American Industrial Revolution, but industrial development along the Neponset and its tributaries continued steadily through the 19th century.\n1800s & 1900s\nIndustrial activities along the Neponset River went through a period of consolidation, as the many smaller independent mills were taken over by a few larger industrial concerns. In the 1900s, industry began moving into the fossil fuel era and the River became less important as a source of power, though it was still critical to industry as a source of water and as a means to dispose of waste products.\nToday, virtually all heavy industry has left the Neponset. It has been nearly a century since the weight of falling water was the driving energy source in industrial production for this area.\nThere are still more than 100 dams on the Neponset and its tributaries, almost all of them vestiges of the water power era, and a testament to the diligence and entrepreneurial spirit of our forebears.\nHarling’s Mill Dam History\nThe mystery of the origin of this small earthen dam, located on the edge of Blue Hills Reservation, piqued the curiosity of Milton historian and long-time NepRWA member, Robert Mussey, who took it upon himself to research the site and piece together its history in 2017.\nIt turns out, the dam was owned and likely built by Thomas Harling, a well-known millwright, who constructed several mills including a powder mill in Stoughton that provided gunpowder to the American Revolutionary Army. Starting in 1782, this dam powered a sawmill and later a grist mill. Read more.\nThe Baker Dam and Tileston & Hollingsworth Dam\nThe Baker Dam is located within the Dorchester/Milton Lower Mills Industrial Complex, which is recognized by the National Register of Historic Places.\nThis Lower Mills Complex was added to the National Register in recognition of the distinctive architecture of many of the mill buildings, and in recognition of the role Lower Mills played in influencing the course of events in American History.\nUnlike the Baker Dam vicinity, the area around the Tileston and Hollingsworth (“T&H”) Dam does not carry any particular historic designation. Like the Baker Dam, the T&H Dam was built in the mid-1960s.\nBecause of its modern construction, the Baker Dam is not listed as a “contributing element” to the Lower Mills Industrial Complex.\nThat said, the dam and mill pond do contribute to the ambiance of the area, and thus any dam removal project would incorporate measures to protect and document adjoining historic resources and to more actively interpret the key role of water power as the driving force behind the River’s industrial period.\nWalter Baker Chocolate Company\nThe Walter Baker Chocolate Company eventually came to completely dominate the industrial scene in the Lower Mills area, constructing the network of attractive brick mill buildings that still dominate the architecture of both Dorchester and Milton Lower Mills today.\nThe Walter Baker Company closed the doors of its Neponset manufacturing facilities for good in 1965 and moved to Delaware. Nonetheless, many local residents still fondly remember the perfume of chocolate that permeated Lower Mills for more than a century.\nThe buildings created by the Walter Baker Chocolate Company are now being used for a variety of residential and commercial purposes.\nTileston and Hollingsworth Paper Company\nAt Upper Falls, the Tileston and Hollingsworth Paper Company ultimately came to dominate the industrial scene with facilities located on both sides of the River.\nTileston and Hollingsworth was succeeded by a number of other corporate names over the years, with the most recent incarnation being the Bay State Paper Company.\nBay State Paper continued making recycled corrugated cardboard at their plant on River Street in Hyde Park until roughly the year 2000, making the Neponset the site of the oldest continuously operated paper production in the United States. However, Bay State Paper succumbed to the larger changes in the global economy that have nearly eliminated the heavy industry that once existed along the shores of the Neponset River from Foxborough to Dorchester.\nThe mill since has been replaced with a shopping plaza.\nThe Aftermath of 1955’s Hurricane Diane\nIn 1955, Hurricane Diane inflicted heavy flood damage throughout Massachusetts, including along the Neponset River. It appears that poor design and/or improper operation of privately owned industrial mill dams on the Neponset River were likely contributing factors in the severity of the flood damage on the Neponset.\nIn the wake of Hurricane Diane, the state, acting through the Metropolitan District Commission, took virtually the entire river corridor of the Lower Neponset by eminent domain, including what appear (from MDC historic photographs) to have been five dams that were located on the Lower Neponset at the time.\nThese dams included the dam at upper falls (predecessor to the T&H Dam), two small dams just above and below Blue Hill Avenue, the Jenkins Dam, which was located just upstream of Central Avenue, behind what used to be the Star Market Plaza in the area of the River now known as the Braided Channel, and finally the Water Baker Chocolate Factory dam.\nThe MDC flood control project begun in 1962 removed the two small dams near Mattapan Square and the Jenkins Dam near the former Star Market. The T&H and Baker Dams were then demolished and rebuilt.\nIt appears that the T&H Dam was of a completely different design than its predecessor. The Baker Dam appears to have been rebuilt in the same general style as the original, though the crest of the dam was apparently lowered by at least three feet to improve its discharge capacity during storm events. It also appears from MDC historic photos that the “normal” water level at Baker was reduced by roughly three feet, again providing better flood protection.\nAt the same time, the Neponset River was straightened, deepened, widened, and partially relocated. Along the edge of the River, wetlands and floodplain areas were filled in and the banks of the River were raised and armored to create a deep flood control channel. A number of other miscellaneous structures such as small bridges also appear to have been removed at about this time, including a sizeable building suspended on a bridge between the Baker Dam and Adams Street. This structure would have completely blocked the view of the dam and the mill pond from the perspective of someone standing on Adams Street.\nAs discussed above, the Dorchester/Milton Lower Mills Industrial Complex was added to the National Register of Historic Places in the early 1980s. While the dams themselves are not considered significant by historians, certainly the buildings and the River’s industrial past are important.\nThe restoration of free-flowing river conditions and anadromous fish runs would approximate the appearance and ecological functions that the Neponset River provided to Native Americans and early colonists during the pre-industrial period. This would make Lower Mills unique in Massachusetts as an area with a rich visual representation of both the industrial and pre-industrial periods.\nBefore removing the dams, the River Restore Project would obtain appropriate permits from the Mass. Historic Commission. The project would be designed to ensure that no damage would occur to the adjacent historic buildings during the construction process. The footprint of the construction area would be minimized to reduce the potential for disturbing any historic artifacts which may remain below the riverbed. Finally, the project would include the installation of interpretive features that would recognize and highlight the area’s industrial heritage. There is currently no interpretive information installed onsite. As further discussed elsewhere, dam removal would also eliminate the substantial risk posed to the adjoining historic buildings if the Baker Dam were to fail.\nFor more information, contact NepRWA Executive Director, Ian Cooke at email@example.com.","Penn Club H2O\nHow recent legislation is supporting drought resilience in the Colorado River Basin (Part 1)\nThe Colorado River Basin – which supplies water to over 40 million people and irrigates 5.5 million acres of agricultural land in the western United States and northwestern Mexico – is experiencing historically low levels and flows.\nThe nearly-1,450-mile river, which has historically run from the Colorado Rockies to Mexico’s Sea of Cortez, no longer empties into the sea. The Basin recently caught the attention of the United Nations, which warned that Lake Powell and Lake Mead – the two largest reservoirs in the United States – are reaching dangerously low levels and may soon achieve “dead pool” status, meaning that water will no longer be able to flow downstream.\nThis poses significant risks to cities and areas in the seven states – Colorado, New Mexico, Utah, Wyoming, Arizona, California, and Nevada – and 30 Indigenous tribes who rely on the Basin for their water supply. The nation’s agriculture will also take a blow, as the Colorado is responsible for sustaining 15 and 13 percent of the nation’s crops and livestock, respectively.\nThere are also significant energy implications. Lake Powell, which is already operating at a quarter of its original size, could drop by another 38 feet by as early as July. At that point, surface levels would reach underwater openings through the Glen Canyon Dam, inducing whirlpools and shutdowns of hydroelectric turbines. This would impact 4.5 million people, many of whom rely on the low-cost power that Glen Canyon provides. A facility failure would force communities – including nonprofit rural electric operatives, Native American tribes, military bases, and small cities and towns – to source significantly more expensive power on the open market.\nThis summer, as the West continued to experience its most severe drought in at least 1,200 years, the Biden administration directed Basin states to formulate an agreement to cut water by 15 percent. After states failed to reach an agreement by the federal deadline in August, the Interior Department’s Bureau of Reclamation (BOR) announced a Tier 2 shortage, triggering water use cuts in Arizona, Nevada, and Mexico for 2023. In October, the BOR announced its intent to further cut water deliveries to California, Arizona, and Nevada.\nThese reductions apportionments have been guided by the Drought Contingency Plan (DCP), a set of agreements that states and the Bureau negotiated in 2019. The DCP has also directed the temporary movement of water from the Aspinall, Flaming George, and Navajo Reservoirs to Lake Powell, to prevent its waters from reaching levels that would curb hydroelectric operations. Additionally, the BOR is investigating potential upgrades to the dam to allow water to be released at lower elevations.\nThe strengthened measures taken under the DCP, as well as recent legislation, are likely to help effectively avoid the most severe cases projected for the Basin. Part 2 of this post will describe how these policies, including actions authorized under the Infrastructure Investment and Jobs Act and the Inflation Reduction Act, are offering robust solutions to the drought in the West.\nDisclaimer: All information, content and materials on this blog are for general information purposes only. Any opinion expressed by the author is not necessarily the opinion of Penn Club H2O or University of Pennsylvania."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:2823f90d-5697-4f60-a91b-60c111c72614>","<urn:uuid:d0cbbea6-1d23-492f-845d-91d5caaca6d1>"],"error":null}
{"question":"What are the key differences in training preparation between specialty cyclocross racers and time trial specialists?","answer":"Time trial specialists focus on steady-state training and threshold work, like Julia Shaw's power-based intervals at specific wattages above 10-mile time trial power. In contrast, cyclocross racers require a more comprehensive preparation approach, with a distinct emphasis on recovery between seasons (including 2 weeks completely off), followed by cross-training and a 10-12 week Foundation block. Cyclocross training includes technical skills practice, explosive power work, and high-intensity intervals targeting VO2 Max and anaerobic threshold. The cyclocross training plan must be carefully periodized to peak for winter races, while time trial training can be more consistently maintained throughout the season.","context":["We asked five top British pro racers for their most effective training session and found a selection that address the key factors of cycling fitness; skill, strength, stamina, aerobic and anaerobic power, speed and specificity\nThen we adapted each session for you to use. Some of them require some precision and familiarity with terms like anaerobic threshold, but we’ve tried to explain these as we go, while one particular session is best done using a power meter.\nFinally, two have been included because they demonstrate two overriding training principles, specificity and addressing weaknesses. You can train with all the gadgets and numbers in the world, but unless the work you do is specific to the demands of your objective you are limiting your potential.\nThe same goes for not improving your weak areas; identify and sort them out or they will undermine any result you are after.\n1 – Ian Stannard,\n“A four-hour ride but with two big efforts on a long climb in the Peak District. I do the climb a lot and know my times on it. I look at my average watts and time on the climb to see how I’m going, but I don’t ride it at my threshold all the way.\nWhat I do is ride just below then go over my threshold then back off to just below all the way up each time. The session tells me how I’m going because I’ve got power outputs and times to compare, but it’s also a session that Sky riders do a lot, going over threshold and holding it then backing off just enough to recover just under threshold.”\nThe threshold Stannard talks about is his anaerobic threshold, or the effort he can hold for one hour if he has to. It’s hard riding but sustainable, the maximum power a cyclist can produce aerobically. However, if this level of effort is exceeded for any length of time, processes in the body, which increased levels of lactate play a part in and is a marker of, cause it to slow down. Except, the thing is in a race sometimes you have to exceed this level, so racers must condition their bodies to meet that demand. This session does that.\nUnder-over threshold training like Stannard does is very effective and is used by Team Sky a lot. Either riding like Stannard at just under threshold then over then back again, or riding just under threshold then simulating an attack, but when they back off the riders don’t ease off as you would in normal interval training, they keep riding just below threshold pace, because that’s what they have to do in a race.\nThe team’s trainer Tim Kerrison calls the latter type of training ‘spiked efforts’. An attack coming when already riding at a high level creates a lot of lactate in the muscles, because the attack effort is anaerobic. But when the rider drops back to just under his threshold his body has to clear the lactate and recover while still maintaining a high pace. Chris Froome’s victory on Mont Ventoux in this year’s Tour de France was a perfect demonstration of this training in action.\nHe was already riding close to threshold on the mountain when he attacked the group containing Alberto Contador. But then Froome went over his threshold to catch Nairo Quintana, but having done that Froome had to continue riding at close to threshold with the Colombian while clearing lactate from his muscles. ‘Under-over’ or ‘spiked efforts’ training helped him do that.\nWhy you should do it too:\nTraining like this will condition a road racer to make and sustain attacks. The ability to ride over threshold pace, then clear lactate while still riding hard is also useful for cyclo-sportive riders who want to get a good finish time, because it helps them make it into faster groups when splits occur along the route.\nThis training is also good for time triallists, as modern thinking in time trials isn’t to ride the distance at constant effort, but to vary it around threshold, sometimes going over where the course demands, such as on climbs, and sometimes dropping under where the course allows, such as on descents.\nBe careful though. Team Sky riders only do it every other day, and even then only then only during big training blocks for specific races. And they are full-time pros with sophisticated back-up; once a week is enough for most.\nUse a turbo-trainer because you need to control the effort precisely. Alternatively this session works well on a long climb if you have one locally. The climb Stannard uses takes him about 13 minutes to ride. Warm up for 15 to 20 minutes, increasing your effort level throughout.\nStart the specific work by riding for five minutes at five per cent under your threshold then go over it by five per cent for one minute. Follow that with two minutes at five per cent under threshold and continue like this, going over and under, for up to 15 minutes. One of these intervals is enough until you get used to them. Complete the training session with some easy spinning.\n2 – Joanna Rowsell,\n“A good session we often do as part of our team pursuit training is an interval session where we do 20 seconds on, 40 seconds off. We do this quite a lot in Majorca up the climbs so even in the 40 seconds off you still have to work a bit so you don’t come to a complete standstill!\nThis is a good session for team pursuiting as it replicates the nature of the event, because the 40 seconds off are nowhere near completely off, so it’s like the team pursuit where you still have to get back on the line and ride quite hard after your turn.\nThe number of sets of these varies but the aim is to be consistent throughout the block of intervals. So if you do 5x20sec efforts you don’t go so hard in the first one that you have nothing left for the last one.”\nLike David Clarke’s (below), this session combines lots of things. The 20 seconds hard are a micro-interval, but the fact that they are done uphill so she has to make a reasonable effort during the 40 seconds is very specific to Rowsell’s Olympic event, the team pursuit.\nThe session is another good one for building the neuro-muscular pathways required for perfect pedalling. And because the 20-second intense bits are anaerobic efforts it improves your body’s ability to process lactate while still riding hard.\nWhy you should do it too:\nThis is another session that should go into all road race, criterium, cyclo-cross and track race training programmes. It replicates some of the crucial demands of each of those events. It’s also a useful one if you are a sportive rider and you feel you lack power on steep hills.\nFind a hill it takes at least six minutes to climb when riding hard. Then after a 15 to 20-minute progressive warm-up, ride up the hill for five minutes broken into 20 seconds going as hard as you can and 40 seconds riding easier. Stop and rest to recover at the top then freewheel back down the same side and do it again up to four times in a session.\n3 – Dave Clarke\n“This session is very good if you are short of time. In fact if you did this four or five times a week you would get really fit. It’s best done on a turbo- trainer but you can do it on the road. What you do is ride for half an hour at just under your anaerobic threshold.\nThen go straight into some three-minute intervals, where you ride as hard as you can for one minute and recover with easy spinning for the remainder of the three-minute interval. I do 10 of these intervals, but it’s best to start with five and work up to 10.”\nThis session combines two very effective forms of training; riding at an intensity called sweetspot, and short intervals that push up your maximum sustainable power output. Sweetspot is around five per cent under your anaerobic threshold as measured by heart rate or power output, and it’s an intensity you can ride at on a day-to-day basis.\nThat’s because you aren’t pushing the red line where your body starts producing lactate, which is what you risk doing when training at your anaerobic threshold. Threshold training is effective and has its place, but sweetspot is nearly as effective at pushing up your threshold power and can be repeated often, so you do more total training.\nThe other element, the one minute riding as hard as you can followed by two minutes easy, is a micro-interval and micro-intervals are great for building total power, for boosting VO2 max towards its genetic potential and for increasing efficiency.\nThe intensity of micro-intervals requires you to pedal perfectly which in turn teaches perfect pedalling. It’s so effective that many riders use micro-intervals to get used to new riding positions.\n“The intervals are so hard your body has no position but to adapt,” says Chris Boardman, who used to train implementing micro-intervals as short as 10 seconds repeated every minute on a turbo-trainer for one hour.\nWhy you should do it too:\nThe sweetspot element will help push up your anaerobic threshold from below, while the one-minute intervals not only help you access more of your VO2 max, they will help raise your anaerobic threshold from above.\nAll cyclists should do this one, no matter what their event. It addresses three performance factors, which underlines Clarke’s claim that you could realise a lot of your potential by doing little else but this session.\nJust copy Clarke’s session, but start by doing five of the one-minute hard in every three and build up to 10.\n4 – Graham Briggs,\n“Something I start doing about one month before the Tour Series races is a two-hour ride that has some five-minute intervals in that are like the effort you have to make in a criterium. I do five of them and each one starts with a 30-second sprint.\nThen I ride easy for one minute then I do three minutes as hard as I can, ending with another flat-out sprint. And I space the five out within the two hours.”\nCriterium racers have to be explosive and they need a sprint that can come off a high pace when races get really intense at the end. This is a well thought-out session that addresses both of those demands.\nWhy you should do it too:\nEven if you don’t specialise in circuit racing, most people’s first experience of road racing is on a closed road circuit, either an airfield or a purpose-built cycling circuit like the one at Hog Hill.\nRegardless of the overall ability and experience of the field, these races are always fast, and they always start especially fast. Sessions like this one of Briggs’s and the one below will help you cope with that.\nFind a circuit with four corners on flat, quiet roads of about one to two miles long. After a good 15-minute warm-up, sprint out of the first corner, keep the effort going when sat in the saddle along the straight then slow for the next corner and sprint out of that one.\nKeep the effort going to the next corner then repeat until you’ve sprinted out of all four corners. Then ride easy along the following straight and repeat the four-corner sprints another three times, with one straight ridden easy between each set of four corner sprints. This is a real circuit-race specific session.\n5 – Julia Shaw,\nMultiple time trial champion\n“This session is quite good on days when I’m not feeling very motivated or short of time, because it’s quite quick and there’s no time to think about anything other than the session and the clock. It also makes a nice change to most of my TT training which is more steady state stuff. I always feel good afterwards too, a nice little sharpener session.\nIt’s a repetitions session, but the reps are so short it has to be done with a power meter or a turbo with power readout.\n“Warm up for about 15 minutes then set one is 12 minutes of doing 10 seconds at 150 to 200 watts above 10-mile time trial power alternated with 20 seconds riding very easy or complete rest. So that’s 24 efforts. Set two is eight minutes of 20 seconds at around 80 to 100 watts above 10-mile time trial power alternated with 10 seconds very easy or rest.\nAnd set three is four minutes of 40 seconds at around 70 to 90 watts above 10-mile time trial power alternated with 20 seconds very easy or complete rest. Follow this with a 10-minute easy-pedalling cool-down.”\nThis training session combines a lot of what the others do into one quick session. It’s perfect for doing on a turbo when the weather is bad outside because there is a lot to focus on changing effort length and rest time, so that will make time on the turbo pass quickly. It’s a great pep-up session that will put real zip into your legs.\nIt will improve efficiency through having micro-interval elements, and it should have a positive effect on raising anaerobic threshold, VO2 max and the ability to clear lactate.\nWhy you should do\nThis is a very effective training session for a time triallist who knows his or her average power outputs for different distances. Using the specified power outputs would ensure progression. It would also be useful for road, track and off-road racers who could do the hard bits as hard as they can.\nThe 10-second intervals are great for building total power and efficiency through the micro-interval effect. The 20 and 40 seconds boost VO2 max and raise anaerobic threshold.\nJust copy Julia’s session directly. Time triallists would be best served by using power as a measure, provided they know their 10-mile performance average power output, but everybody else should go as hard as they can for the duration of each interval.\nJust remember to spread your effort equally through each interval and try to make the last one as intense as the first. Don’t put everything you’ve got into the first, spread your effort throughout the set instead.\nThis article was first published in the August 15 issue of Cycling Weekly. Read Cycling Weekly magazine on the day of release where ever you are in the world International digital edition, UK digital edition. And if you like us, rate us!","A Look at the Demands of Cyclocross\nPeople used to always tell me that ’cross races are like time trials. Now, time trialing is something I’m very good at, and when I first tried ’cross, it was certainly an eye-opener! I’m a decent mountain biker, and I had good form for my first ’cross race, but it certainly was not like a time trial—and I fell apart badly. If I had to succinctly describe a true ’cross race, it’s like riding off the front of a technical crit: much more fast-twitch-reliant than people realize.\nTime trials demand a steady effort from beginning to end, with very small jumps in wattage—the lactate threshold (LT) system is the primary engine here, with most TT power output falling into the LT or “SupraThreshold” zones. The best time trialists can even produce negative splits, meaning they can put out more power in the second half of the event. But ’cross is a completely different animal, chock full of violent accelerations, max efforts out of turns and up power climbs, and attacks—the average power output may be similar to a time trial in the end, but how you get there is quite another story!\nIn TTs, the start is key—start too hard and you can risk ruining your performance. In ’cross, a hard start is imperative, and then you need to be able to stay with the leaders for the remainder of the event.\nPrecisely because ’cross events are shorter, in my opinion they demand as much if not even more preparation than typical road or MTB events. The anaerobic engine is hit so damned hard during these races, with max efforts constantly required, that if you don’t prepare properly, you’ll never be able to perform to your true potential, or you’ll only last half the ’cross season, with the body just falling apart.\nRecovery Time Between Seasons\nI coach four professional ’cross racers, and I make sure to deliberately give each of them perhaps more recovery time than necessary after their December racing. Many riders take too little time from season to season, and they can really pay the price in the spring when things start to heat up—these athletes aren’t prepared and never really peak, or they just erode into an overtrained state and ruin their seasons. In December after your last cyclocross race, it’s critically important to recharge the batteries, perhaps more so mentally than physically.\nWe’ll use one of the athletes I coach, Laura Winberry of Elite Endurance, as our concrete example. She won the New Jersey State Cyclocross Championships in 2009, and after the race she had two weeks completely off. Nada, nunca, zilch. Then I prescribed her two weeks of light cross-training, with possible workouts including mountain ￼biking, hiking, trail running, the Stairmaster elliptical or rowing machines at the gym, rollerblading, swimming, running, basketball, rock climbing and yoga. The goal was to keep any of these workouts to an aerobic pace and finish feeling fresh.\nThen Laura went through a typical five-week transition and preparation period where she started completing light gym work—which is periodized and specific for her cycling goals—and plenty of pedaling efficiency and leg speed drills, combined with light aerobic riding.\nThe Meat & Potatoes: Foundation Training\nAfter this block, she’s ready for Foundation work, which is the longest block at 10 to 12 weeks. In my opinion, this is the most important block in any athlete’s annual training plan. Here, the gym work continues to progress, we start to introduce plenty of tempo intervals while also incorporating various forms of force work, which consists of pushing a big gear at a low cadence—like lifting weights on the bike. I also like to sprinkle in light endurance rides and group rides with specific objectives.\nWhen Laura and I first started, I administered a fitness test to establish heart rate training zones—the test typically consists of a max 8-minute effort, full recovery, then 16 minutes at your highest aerobic level. I’ve found Laura’s lactate threshold heart rate to be around 185 beats per minute. With this information, I can create HR zones for her: Recovery, Endurance, Tempo, UltraTempo, SubThreshold, Lactate Threshold, VO2 Max, Anaerobic Threshold, and Max.\nDuring Foundation work, I really like to stress the two “Sweet Spots,” which for most athletes are longer 15+ minute Tempo intervals at 84-88% of LTHR, then shorter, 10-12 minute SubThreshold intervals at 93-96% LTHR. I’ve found that spending time in these two training zones yields the most bang for the buck.\nA typical Foundation week for Laura looks like this:\nMonday – 50+min (minute) Recovery Ride, rolling terrain, aerobic pace. 4 x 7min Leg Speed Drills at 105-115 rpms.\nTuesday – 75+min ride, hilly terrain. 9 Uphill Grinds, 1m efforts at sub-max effort, 50-60 rpms, 4+min recovery in between efforts.\nWednesday – 90min ride, rolling terrain. 3 x 12min SubThresholds, 172-178 HR (93-96% LTHR). These are done at her absolute highest aerobic level, not an easy effort, but not overly hard—challenging and uncomfortable, but won’t blow her out.\nThursday – Gym. Most workouts include squats, leg presses, lunges and step-ups. I’m a big fan of core, so my athletes usually do 3-4 supersets of core work at the end of each gym workout, plus some core exercises on separate days.\nFriday – 45+min Recovery Ride, flat terrain. Ride at a natural cadence, HR under 127 (68% of LTHR). 8 Corner Accelerations: As you cruise out of a corner, jump from the saddle and accelerate 100% for 5 seconds. These are short, max efforts. Corner Accelerations help develop leg speed, out-of-the-saddle jumps, and leg torque.\nSaturday – Group Ride. Sit in. No max efforts. Goal is to finish as fresh as possible. Enjoy the day. OK to stand while climbing. It’s OK to drop to the back or off the back if the pace is too harsh. Ride time under 2hrs.\nSunday – 2.5+hrs Endurance Ride, hilly terrain. 132-154 HR (71-83% of LTHR) on the flats. 4 x 3+min PowerClimbs, 65-75 rpms, 172+ HR (93+% of LTHR). Full recovery in between climbs. Then finish with 25+m Tempo over rolling terrain, 156+ HR (84+% LTHR). 94+ rpms, pushing a challenging pace on the uphills.\n￼For the weekend warrior with only a couple of days available for training, the Tuesday and Wednesday rides are the most important workouts in the example given, and could be shifted around to accommodate a rider’s schedule. The other days could be used to add in volume whenever that saddle time can be fit in, with the gym day a good addition for those interested in full-body strength—an important attribute for a successful cyclocrosser.\nDuring this training block, the workload is steadily increased, and the athlete is in a gray zone—never recovered, never overtired, just slowly continuing to move forward. I give Laura a ton of longer “Sweet Spot” intervals, which really strengthen her aerobic engine. In the end, the aerobic engine is the cornerstone for success in this sport, something so few riders comprehend.\nLaura’s Foundation block takes her into late-April but, depending on the goals, dedicated cyclocrossers could certainly begin this phase later in the spring, continue to train through summer rides and races and save their peak performances all for cyclocross season. Many riders cut short their Foundation blocks, either riding too easy or too hard, and these riders have a hard time holding back, wanting to be king of the local spring group rides and doing other things to achieve peak form sooner. But trust me: good things come to those who wait, especially if ’cross is on your menu.\nRemember: early-season heroes can be summer and ’cross zeroes.\nGood Things Come to Those Who Wait\nNow that Laura has true foundation work in her legs, she’s ready to turn it up with an eight-week Build block, which commonly finishes with a month-long Peak and Taper block before her biggest races. Volume is not what changes so much here—it’s how we’re starting to rev her engine. In Foundation, we were doing plenty of longer aerobic intervals and plenty of steady force work. But now we turn it up, and her body will respond much better to the increased intensity.\nDuring Build training, we will be doing plenty of Lactate Threshold work, intervals typically 7 to 11 minutes in duration, performed at an intensity where the rider is right at threshold, an 8 on a scale from 1 to 10. We also will complete plenty of VO2 Max intervals. VO2 Max is also known as known as “maximal oxygen uptake” or “maximal oxygen consumption,” and these intervals are very tough, but are also crucial for any successful ’cross racer. Here, having a power meter really helps make sure you’re doing these correctly. [See Hunter Allen’s “Power Training” article in Issue 11] Anaerobic Threshold intervals are shorter, typically 30 to 90 seconds in duration, and they’re essentially max- effort intervals with shorter recovery, which make them even more fun!\nLaura is prepared for this: she can push harder, will recover better between workouts and, most importantly, mentally she is 100 percent ready to rock and roll at a time when other athletes are perhaps starting to get drained or are starting to go backwards. Laura is truly ready to reach for her best.\nStarting slower and steadier in your training is important for all endurance athletes, but it’s especially important for cyclocross racers because they will need to be in peak form in early-winter. If the athletes don’t dose their efforts properly during the year, their knife will just be too blunt for ’cross, because ’cross is a mean, mean animal, requiring sharp preparation with VO2 Max, anaerobic threshold and max power intervals. Those are very potent workouts, and if you’re not prepared, you can’t complete these workouts properly.\nAlso, I like to get the ’cross racer on the cyclocross bike at least once a week during the spring and summer, just to stay sharp. ’Cross is much more than just riding hard—you need to acquire the technical chops to be able to use your engine at max effort. I typically like to prescribe recovery rides where the athlete heads to a park, double track or mild wooded trails with the ’cross bike, hits “barriers” (garbage cans work great), practices run-ups, tight turns, stair climbs, off-camber descents—all at an aerobic pace, just going through the motions.\n￼Planning Your Peaks\nI recommend two to three peaks a year for the cyclocross racer, preferably two. Many riders want a May-July-autumn peak, but I actually like to talk them into a June peak, then a full build and peak for ’cross. Remember, for most athletes, the second peak is the strongest. Even for riders who don’t target summer racing disciplines and only care about cyclocross competitions, it’s still a good idea to “come up for air” and take a break from big blocks of training. That means they’ll have great form—so it’s a good time to mix it up in a summer race, kill your local training buddies or just head somewhere cool and push the pace.\nBecause of our thorough preparation, Laura responds very well during Build and Peak training. I’ve coached her for many years, she’s been doing the right things at the right times, and now she’s a professional athlete. It’s beautiful seeing her respond so well to the training stress. With new athletes I coach, sometimes the gains don’t come as quickly, or I have to progress them more slowly, and this is because of their lack of true aerobic conditioning prior to our relationship.\nLaura had a tremendous 2010, earning eight top-10s in Pro cross country MTB races. This year, MTB Nationals are in July, and after that we’re shutting it down. This is a huge key for the ’cross athlete: knowing when to turn off the training, and doing it soon enough. Many riders fail to address this, not shutting it down at all, or shutting it down too late and not giving themselves enough time to prepare for a true ’cross peak, leading to mediocre performances.\nIn July, Laura will have two weeks off, and then I plan to run her through another nine-week Foundation cycle. She might not be flying for the early ’cross races, but in the past she still has always held her own with the solid Foundation work in her legs.\nThe key for the smart ’cross athlete is to be able to progress through the ’cross season. So many riders come out flying early on, enjoying road or MTB form only to fade away as the season is well underway. The best ’cross racers typically come into form by early-October, continuing to improve until the last races of the year, which are usually the most important.\nYou Can Never Plan Too Far Ahead\n’Cross Nationals are on January 8th, 2012, so we designed Laura’s plan to have her ready to rock at the country’s biggest event. We take that race date, then work backwards from there, making sure we leave no stone unturned. Through mid-October to late-November, Laura will be progressing through true Build work, able to hit her VO2 Max and Anaerobic Threshold intervals at 100 percent, recovering well, continuing to race and get stronger. Early- December will include two Peak weeks, where she’ll be pushing harder than ever, and then a solid two- to three-week taper for Nationals.\nI recommend such a long prep and careful selection of peaks for ’cross because in the fall you need to be completely ready to race and train: much easier said than done. Road racing requires more lactate threshold intervals, sprint work and endurance work, whereas true ’cross prep will include much more white-hot, full-metal training, and this needs to be very carefully prepared for—too much of this arduous training, or completing it too soon, and you run the risk of overtraining, running flat or not completing the season.\nThe Proof is on the Podium\nThe training program worked very well in 2010 as Laura took podiums at the monstrously popular Oregon Cross Crusade events. She then had the best race of her life at Cyclocross Nationals, taking 34th after starting near the back. As we all know, having a good start is critical in ’cross, and had Laura started in 34th, I know she could’ve placed top- 15, which would’ve been unbelievable. Laura reported having her best legs ever, and she was one of the few not to get lapped by Katie Compton. Laura impressively finished in front of many local pros who had beaten her all year, not far off a top-20—and this wasn’t by mistake. She was at her best when it truly counted—at Nationals, she has gone from 54th in 2009 to 34th in 2010. What will 2011 bring? We plan to race all the big UCI races, something we have never done before, seeing where we can take this dream.\nFor all you ’cross racers out there, I highly recommend planning out your season before it starts so you can truly be at your best for your favorite racing, something so few riders can actually do. If you continue to train efficiently, not wasting any days and continuing to move forward, there is no limit to what you can accomplish."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:782c7868-d69a-4042-93a4-581352160d60>","<urn:uuid:ac07938e-3a35-4808-bf5c-26df6c976d59>"],"error":null}
{"question":"Please compare time efficiency of mediation versus litigation process. How much faster is mediation? What factors make litigation slower?","answer":"Mediation is significantly faster than litigation. While it can take up to a year to get a court date and multiple years if a case is appealed, mediation provides a more timely way of resolving disputes. In litigation, there are numerous factors that cause delays, such as competition from many other cases, adjournments, and unwillingness of parties. Additionally, litigation involves many rules and procedures that must be followed, making it more time-consuming. In contrast, mediation is more efficient because parties can determine their own time and pace, and their case is likely to be the only one being handled at that time, allowing for faster resolution.","context":["People in disputes who are considering using mediation as a way to resolve their differences often want to know what the process offers. While mediation can not guarantee specific results, there are trends that are characteristic of mediation. Below is a list of some of the benefits of mediation, broadly considered. Mediation generally produces or promotes:\nMediation is generally less expensive when contrasted to the expense of litigation or other forms of fighting.\nIn an era when it may take as long as a year to get a court date, and multiple years if a case is appealed, the mediation alternative often provides a more timely way of resolving disputes. When parties want to get on with business or their lives, mediation may be desirable as a means of producing rapid results.\nMutually Satisfactory Outcomes\nParties are generally more satisfied with solutions that have been mutually agreed upon, as opposed to solutions that are imposed by a third party decision-maker.\nHigh Rate of Compliance\nParties who have reached their own agreement in mediation are also generally more likely to follow through and comply with its terms than those whose resolution has been imposed by a third party decision-maker.\nComprehensive and Customized Agreements\nMediated settlements are able to address both legal and extra-legal issues. Mediated agreements often cover procedural and psychological issues that are not necessarily susceptible to legal determination. The parties can tailor their settlement to their particular situation.\nGreater Degree of Control and Predictability of Outcome\nParties who negotiate their own settlements have more control over the outcome of their dispute. Gains and losses are more predictable in a mediated settlement than they would be if a case is arbitrated or adjudicated.\nPeople who negotiate their own settlements often feel more powerful than those who use surrogate advocates, such as lawyers, to represent them. Mediation negotiations can provide a forum for learning about and exercising personal power or influence.\nPreservation of an Ongoing Relationship or\nTermination of a Relationship in a More Amicable Way\nMany disputes occur in the context of relationships that will continue over future years. A mediated settlement that addresses all parties' interests can often preserve a working relationship in ways that would not be possible in a win/lose decision-making procedure. Mediation can also make the termination of a relationship more amicable.\nWorkable and Implementable Decisions\nParties who mediate their differences are able to attend to the fine details of implementation. Negotiated or mediated agreements can include specially tailored procedures for how the decisions will be carried out. This fact often enhances the likelihood that parties will actually comply with the terms of the settlement.\nAgreements that are Better than Simple Compromises or Win/Lose Outcomes\nInterest-based mediated negotiations can result in settlements that are more satisfactory to all parties than simple compromise decisions.\nDecisions that Hold Up Over Time\nMediated settlements tend to hold up over time, and if a later dispute results, the parties are more likely to utilize a cooperative forum of problem-solving to resolve their differences than to pursue an adversarial approach.","METHODS AND ADVANTAGES OF ALTERNATE DISPUTE RESOLUTION (ADR)\nIt is one thing to know the concept of Alternate dispute resolution; it is another to know the right methods to apply or seek in a particular dispute and to know the advantages of Alternate dispute resolution. What then are the methods that one may seek in ADR and what are the advantages of ADR?\nThe main methods of alternative dispute resolution methods available for settling disputes in Nigeria are Negotiation; Mediation; Conciliation and Arbitration.\nNegotiation is a problem-solving process in which the parties to a dispute or an imminent conflict voluntarily come together either personally or by their representatives, to discuss their differences and attempt to reach a joint decision or resolution of the conflict, on their own and without the involvement of a third party. Negotiation is different from other types of alternative dispute resolution mechanisms as no third party is involved.\nMediation is an alternative dispute process in which a neutral and impartial third party called the mediator is invited by the disputing parties to facilitate the resolution of the dispute by the self-determined agreement of the disputants. The mediator facilitates communication, promotes understanding, focuses the parties on their interests, and uses creative problem-solving techniques to enable the parties to reach their own mutual settlement/agreement. The mediator is usually jointly procured by both parties and the process is voluntary as the parties are not under any obligation to accept the suggestions of the mediator.\nConciliation as an alternative dispute method involves a neutral third party who can give an opinion or suggestion. It is a system of ADR where a third party known as the conciliator uses his best endeavours to bring the disputing parties to a voluntary settlement of their dispute. Conciliation is regulated by the Arbitration and Conciliation Act (ACA) Laws of the Federation of Nigeria (LFN) 2004.\nArbitration is the most initiated method of ADR where parties to a dispute submit to a third party called an arbitrator or arbitral tribunal for the resolution of their dispute. The decision of the arbitrator or arbitral panel called an award, is binding on the parties and enforceable by the courts. Arbitration is regulated by the Arbitration and Conciliation Act (ACA) Laws of the Federation of Nigeria (LFN) 2004 and also regulated by the Lagos State Arbitration Law, 2009.\nThe use of ADR is advantageous to litigation in the sense that it is cheaper than litigation. ADR can be more expensive than litigation but in long term, it is cheaper than litigation. In ADR, all the expenses are borne by the parties while in litigation; some of the expenses are not borne by the parties.\nIt is faster as compared to litigation where there is a competition of so many litigants with different cases, but in ADR, the parties' case is likely to be the only one. ADR is less time-consuming unlike instituting a court action which can be time-consuming from factors such as adjournments, the unwillingness of parties, etc.\nThe courtroom where litigation is carried out is usually tense. For the lawyers, it is difficult, there are a lot of rules and procedures which must be followed, and also for the layman, it is extremely difficult. An ADR session is more of a business meeting where coffee can even be served. Hence the layman is likely to prefer such an environment.\nThe parties to the dispute can determine the Coram. This implies that they determine the mediator or arbitrator or conciliator who will preside over their case, but where they fail to agree, there are provisions of the law for such appointments to be done either by the court or an agency.\nADR processes are parties driven. Parties can determine the time, venue, and pace in the ADR process, unlike in litigation where parties are not involved. It is controlled by the court.\nPreservation of the relationship between the parties- Most ADR has a win-win situation on both sides of parties to the dispute, as it preserves the pre-dispute relationship that existed between the parties before the dispute. ADR also helps preserve the privacy of the parties. In litigation, the process must be held in public except under certain conditions thus in private.\nWRITTEN BY: CHAMAN LAW FIRM TEAM\nTEL: 08065553671, 08024230080"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:75c7ca57-cdeb-4b0a-95af-046f7dd5888a>","<urn:uuid:f10be73e-a774-46d2-9e45-29355a68ffb6>"],"error":null}
{"question":"How does the energy storage in electromagnetic waves compare to heat emission in infrared radiation?","answer":"In electromagnetic waves, the energy is stored in both electric and magnetic fields that are perpendicular to each other. For infrared radiation specifically, the energy manifests as heat, which is produced by the motion of atoms and molecules in an object. The higher the temperature of an object, the more its atoms and molecules move, resulting in more infrared radiation being produced. Any object above absolute zero (-273.15 degrees Celsius) emits infrared radiation, with warmer objects emitting more infrared energy than cooler ones.","context":["Teachers Guide to the Infrared\nOur eyes are detectors which are designed to detect visible light waves (or visible radiation). There are forms of light (or radiation) which we cannot see. Actually we can only see a very small part of the entire range of radiation called the electromagnetic spectrum .\nThe electromagnetic spectrum includes gamma rays, X-rays, ultraviolet, visible, infrared, microwaves, and radio waves. The only difference between these different types of radiation is their wavelength or frequency. Wavelength increases and frequency (as well as energy and temperature) decreases from gamma rays to radio waves. All of these forms of radiation travel at the speed of light (186,000 miles or 300,000,000 meters per second in a vacuum).\nInfrared lies between the visible and microwave portions of the electromagnetic spectrum. Infrared waves have wavelengths longer than visible and shorter than microwaves, and have frequencies which are lower than visible and higher than microwaves.\nInfrared can be used as a way to measure the heat radiated by an object. This is the radiation produced by the motion of atoms and molecules in an object. The higher the temperature, the more the atoms and molecules move and the more infrared they produce. Any object which has a temperature i.e. anything above absolute zero (-459.67 degrees Fahrenheit or -273.15 degrees Celsius or 0 degrees Kelvin), radiates in the infrared. Absolute zero is the temperature at which all atomic and molecular motion ceases. Even objects that we think of as being very cold, such as an ice cube, emit infrared. When an object is not quite hot enough to radiate visible light, it will emit most of its energy in the infrared. For example, hot charcoal may not give off light but it does emit infrared which we feel as heat. The warmer the object, the more infrared it emits. We experience infrared radiation every day. The heat that we feel from sunlight, a fire, a radiator or a warm sidewalk is infrared. Although our eyes cannot see it, the nerves in our skin can feel it as heat. The temperature-sensitive nerve endings in your skin can detect the difference between your inside body temperature and your outside skin temperature. We also commonly use infrared rays when we operate a television remote.\nNote: To help your students understand that the Sun does indeed put out infrared light, you might want to have them perform The Herschel Experiment, in which they will have the opportunity to discover the existence of infrared light in sunlight for themselves.\nHow do infrared cameras work?\nThermal infrared imagers are detector and lens combinations that give a visual representation of infrared energy emitted by objects. Thermal infrared images let you see heat and how it is distributed. A thermal infrared camera detects infrared energy and converts it into an electronic signal, which is then processed to produce a thermal image and perform temperature calculations. Thermal imaging cameras have lenses, just like visible light cameras. But in this case the lens focuses waves from infrared energy onto an infrared sensor array. Thousands of sensors on the array convert the infrared energy into electrical signals, which are then converted into a false-color image.\nWhat is false color?\nSince we cannot see infrared light with our eyes, infrared cameras create visible \"false color\" representations in which different temperature ranges are assigned a different color. Infrared cameras often have several color scales to choose from. A false color image is one in which the colors are not the \"true colors\" of the object being imaged. The colors in the image do accurately represent variations in the brightness of the object at the observed wavelengths, but they are often dubbed \"false\" since they do not represent the visible light, or naked eye, appearance.\nWhat do the colors in an infrared image represent?\nAnything which has a temperature puts out infrared light. In the infrared images shown in these lesson plans, different colors are used to represent different temperatures. You can find out which temperature a color represents by using the color-temperature scale show to the right of most of the images. The temperatures are in degrees Fahrenheit.\nWhat specifically do infrared images reveal?\nInfrared is a type of light that we cannot see with our eyes. Our eyes can only see what we call visible light. Infrared light brings us special information that we do not get from visible light. It shows us how much heat something has and gives us information about an object's temperature. Everything has some heat and puts out infrared light. Even things that we think of as being very cold, like an ice cube, put out some heat. Cold objects just put out less heat than warm objects. The warmer something is the more heat it puts out and the colder something is the less heat it puts out. Hot objects glow more brightly in the infrared because they put out more heat and more infrared light. Cold objects put out less heat or infrared light and appear less bright in the infrared.\n||By using special infrared cameras, we can get a view of the infrared world. These cameras are very useful and have even helped save people's lives. In the infrared, you can \"see\" in the dark. Even if the Sun is down and the lights are off, the world around us still puts out some heat. The infrared picture to the right shows deer in a forest during a dark night. Notice how we can clearly see the heat from the deer, especially from areas not covered with thick fur like the ears, face and legs. The trees and the ground put out less heat than the deer, but can still be seen through an infrared camera.|\nWarm-blooded animals, like people, try to keep the same body temperature during both the day and the night. Their body temperatures do not change when it gets dark or cold outside and their heat remains about the same. This makes infrared cameras very useful for finding people who are lost at night or lost at sea. The warm body heat from a person will cause them to glow brightly in the infrared, even in the dark or floating in a cold sea. Police can use infrared cameras to find criminals hiding in the dark and firefighters also use infrared cameras to find the hot spots in a fire.\nInfrared cameras are also a good way to study warm-blooded animals at night, and are used to study how animals use fur, feathers and blubber to keep themselves warm. They are also useful for showing the difference between warm and cold-blooded animals. To learn more about warm and cold-blooded animals visit our Infrared Zoo website.\nAnother interesting fact about infrared light is that it can travel through thick smoke, dust or fog, and even some materials.\nBecause infrared light can travel through thick smoke and visible light cannot, infrared cameras are used by firefighters to find people and animals in smoke filled buildings. The infrared body heat from people and warm-blooded animals can travel through the smoke and cause them to show up clearly through an infrared camera. Many people and their pets have been saved by firefighters using infrared cameras. Also, because infrared light can travel through thick fog, it is very useful to have infrared cameras on ships and airplanes to help in navigation.\nInfrared cameras are also used by satellites in space to measure the temperature of the oceans, to study the Earth's weather during both the day and night, and to study the infrared light from outer space.\nTo learn more about the everyday applications of infrared imaging visit our web site Seeing Our World in a Different Light\nInfrared light is only one of the types of light that we cannot see with our eyes. There are many more, such as X-rays, gamma-rays, ultraviolet light and radio waves. Each of these different types of light brings us new information that we cannot get by using our eyes alone. We are very lucky that we live in a time when we have technology that allows us to \"see\" all of these types of light.","In electromagnetic waves, the amplitude is the maximum field strength of the electric and magnetic fields ((Figure)). The wave energy is determined by the wave amplitude. Energy carried by a wave depends on its amplitude.\nWhat does the energy of electromagnetic wave depend on?\nThe energy of an electromagnetic wave depends on its frequency and wavelength. The higher the frequency and the shorter the wavelength, the stronger the energy propagated.\nWhat is the most important source of electromagnetic wave?\nThe most important source of electromagnetic waves on Earth is the sun. Electromagnetic waves travel from the sun to Earth across space and provide virtually all the energy that supports life on our planet.\nWhat determines the type of electromagnetic wave?\nRadiation and Temperature\nWhat determines the type of electromagnetic radiation emitted by the Sun, stars, and other dense astronomical objects? The answer often turns out to be their temperature. At the microscopic level, everything in nature is in motion.\nWhat interferes with electromagnetic waves?\nThe electromagnetic energy from the source propagates through the path and interferes with the operation of the receptor. All three must exist to have an EMI problem. … The three most common EMI problems are radio frequency interference, electrostatic discharge, and power disturbances.\nWhere is energy stored in electromagnetic waves?\nThe E and B fields, along with being perpendicular to each other, are perpendicular to the direction the wave travels, meaning that an electromagnetic wave is a transverse wave. The energy of the wave is stored in the electric and magnetic fields.\nWhat is energy carried by electromagnetic waves called?\nElectromagnetic waves are waves that consist of vibrating electric and magnetic fields. They transfer energy through matter or across space. The transfer of energy by electromagnetic waves is called electromagnetic radiation. … The two vibrating fields together form an electromagnetic wave.\nWhat are three sources of electromagnetic waves on earth?\nSources of Electromagnetic Radiation\n- solar radiation, in other words natural radiation that originates from the sun.\n- terrestrial radiation, in other words natural radiation emitted by the Earth’s surface.\n- artificial radiation originating from a remote sensing system.\nWhat is the ultimate source of electromagnetic waves?\nThe ultimate source of electromagnetic waves is moving charged particles. These travel at the speed of light and are composed of electric and magnetic…\nHow is electromagnetic waves created?\nElectromagnetic waves are formed when an electric field (shown in red arrows) couples with a magnetic field (shown in blue arrows). Magnetic and electric fields of an electromagnetic wave are perpendicular to each other and to the direction of the wave.\nWhat are the 4 main properties of electromagnetic waves?\nLike other waves, electromagnetic waves have properties of speed, wavelength, and frequency.23 мая 2019 г.\nWhat are the 7 types of waves?\nThough the sciences generally classify EM waves into seven basic types, all are manifestations of the same phenomenon.\n- Radio Waves: Instant Communication. …\n- Microwaves: Data and Heat. …\n- Infrared Waves: Invisible Heat. …\n- Visible Light Rays. …\n- Ultraviolet Waves: Energetic Light. …\n- X-rays: Penetrating Radiation. …\n- Gamma Rays: Nuclear Energy.\nWhat are the 7 types of electromagnetic waves?\nThe electromagnetic spectrum includes, from longest wavelength to shortest: radio waves, microwaves, infrared, optical, ultraviolet, X-rays, and gamma-rays.\nDo Humans give off electromagnetic waves?\nHumans give off mostly infrared radiation, which is electromagnetic radiation with a frequency lower than visible light. … “Thermal radiation” is all the electromagnetic waves given off by an object because of its temperature, and includes radio waves, infrared waves, and even visible light.\nWhat can stop electromagnetic waves?\n5 Tips to Safeguard Against Electromagnetic Radiation\n- Disable Wireless Functions. Wireless devices — including routers, printers, tablets, and laptops — all emit a Wi-Fi signal. …\n- Replace Wireless With Wired Devices. …\n- Keep EMF Sources at a Distance. …\n- Use Your Smartphone Safely. …\n- Prioritize Sleeping Areas.\nCan electromagnetic waves affect the brain?\nElectromagnetic waves, particularly RF-EMFs emitted by mobile phones are absorbed into the brain to such an extent that it can affect the activity of neurons (Kleinlogel et al., 2008; Hinrikus et al., 2018). … Glucose metabolism in the brains that were exposed to RF-EMF increased rapidly."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:b00d9ff2-21de-416d-a93b-3e7eddfec969>","<urn:uuid:ab115dc6-72f5-46a2-b5ba-7df49c3fa0ac>"],"error":null}
{"question":"What are the key differences between the religious inclusivity practices of the modern Knights Templar organization and the symbolic representation rules in Eastern Orthodox iconography?","answer":"The modern Knights Templar and Eastern Orthodox iconography demonstrate contrasting approaches to religious inclusion and representation. The International Knights Templar accepts members from multiple Christian denominations (about 50% Roman Catholic and others Eastern Orthodox and Protestant) and even allows non-Christians as associate members, reflecting their philosophy of outreach and understanding world religions. In contrast, Eastern Orthodox iconography follows strict symbolic rules that are specifically Christian, where icons must follow Byzantine artistic traditions with specific symbolic meanings - such as using particular colors (like deep red and royal purple symbolizing Christ's blood) and requiring important religious figures to face viewers directly regardless of perspective. This demonstrates a more doctrinally rigid approach to religious representation compared to the Templars' inclusive membership policy.","context":["The aura of the warrior monks who founded the Knights Templar nearly 900 years ago has stirred controversy and fed the appetite of conspiracy theorists for years.\nIn Dan Brown's 2003 novel, \"The Da Vinci Code,\" which became a film starring Tom Hanks, the knights were depicted as a cultish society linked to the Vatican and concealing church secrets, including the location of the Holy Grail.\nToday there are dozens of Knights Templar organizations worldwide that have spawned from the medieval military order, and the new face of one of the largest groups is Tinley Park Village Clerk Patrick Rea.\nRea, 69, a retired Army Reserve brigadier general, was unanimously elected in November in Lisbon, Portugal, as grand master of the International Knights Templar. Now in the group's No.2 post, Rea will begin an eight-year term as its leader next fall.\nThe organization of about 5,500 members was founded in 1804 and follows in the Christian philanthropic tradition of the original Knights Templar, but the group still is plagued by misconceptions.\n\"Most of the time it's amusing, some of the time it's embarrassing, and a little bit of the time, I have fun with it,\" Rea said.\nPeople have called Rea asking if he knows the location of the Holy Grail, a cup Jesus is said to have used during the Last Supper.\n\"Three years ago I said yes, and there was sort of a gasp on the other end of the telephone line,\" Rea recalled. \"(He) said, 'Where is it?'\"\nRea told the caller the Holy Grail was under a rail station in Tinley Park. Then he told the police chief to be on the lookout for someone digging around the tracks. And with that, Rea belted out a laugh.\nWarrior monks founded the medieval Knights Templar in the early 1100s to protect Christians visiting the Holy Land from bandits. They amassed enormous wealth as pilgrims donated land and money to them, said Helen Nicholson, a reader in medieval history at Cardiff University in Wales. About 200 years later, they were accused of heresy and blasphemy, among other claims, so royalty could seize their wealth, Nicholson said. Many were tortured into confessions. Some were burned at the stake. The knights eventually were found innocent but were disbanded. Experts disagree on where the knights' treasure went, if any ever existed.\nThe International Knights Templar claims no direct lineage to and does not share the original knights' mysterious past.\nRea's Templars hold public meetings, and roughly half of the members are from the United States and the other half from about 30 other countries, he said. About 50 percent of members are Roman Catholic, and the others a mix of Eastern Orthodox and Protestant religions. Women, called Dames, also are members, though most Templars are men. Non-Christians can be associate members, a nod to the group's philosophy of outreach and understanding world religions.\nTemplars don white capes with a red cross on the left shoulder, but mainly in ceremonies in churches for new members, Rea said.\nTemplars must be 21 years old, proven leaders -- that includes soldiers to PTA presidents -- and recommended by three people in the order. Charity and peacekeeping are the group's main objectives.\n\"Mostly this is a giving situation,\" said Rea, who became a Templar 17 years ago. \"What you're able to do is influence international issues by meeting with international officials and supporting the churches as they try to carry out their missions.\"\nThe members of this group range from a who's who in royalty and the military to local bishops and village workers. Tinley Park Mayor Ed Zabrocki is a Templar. So is Metropolitan Christopher, who leads the Serbian Orthodox Church in North and South America.\nRea, who has been dubbed a count of a province in Spain, includes dukes and princesses among his friends. Because of his Templar ties, many members who come to Chicago often stay in Tinley Park.\nAs grand master, his role will be to maintain and develop relationships between religious leaders around the globe, a duty he has performed for years. He held a reception of worldwide church heads a year ago to honor a late Palestine Liberation Organization cabinet member.\n\"I'd be foolish to say that there isn't a little risk\" when traveling to potentially dangerous lands, said Rea, a retired banker who served under President George W. Bush as a Small Business Administration regional administrator.\nPrincess Renate zu Windisch-Graetz, a Dame and former German consul in Chicago, said Rea stood up in her wedding and years later planned her husband's funeral.\n\"If your car breaks down, he has somebody who has another car, and if you're hungry, he'll find a family who has too much food,\" she said.\nBesides sending delegates to United Nations conferences to offer their expertise, Templars also start philanthropic projects with their annual $100 dues, Rea said.","The Icon of the Eastern Orthodox Church – Research Paper\nObjectively speaking, an icon is a two-dimensional work of art found in the Eastern Orthodox religion, often portraying religious figures such as Jesus Christ, the Virgin Mary, and various saints. Obviously, icons (sometimes spelled ikons) are revered in this tradition, but their precise significance is often hard to understand.\nThe very concept of religious images is, in fact, a broad area of concern, one that did not begin even with Christianity (Gerhard 8).\nHowever, the case within this specific tradition is a very unique one. In Eastern Orthodoxy, icons are religious works of art, which, although possessing a long history and complexity of manufacture, are centrally concerned with portraying a symbolic message and serving as a tool of worship rather than exhibiting any aesthetic value.\nThe origin of religious concern for representative images does not lie with the Eastern Orthodox faith, nor did it begin with Christianity at all. The Mosaic law of Judaism contained a tenet which read, “Thou shalt not make unto thee any graven image, or any likeness of any thing that is in heaven above, or that is in the earth beneath, or that is in the water under the earth” (Exodus 20:4). Although the English translation appears quite clear, in ancient Judaism, this commandment was a constant subject of argumentation, as many interpreted the word “image” as closer to “idol” than any literal image (9).\nThe developing Christian world, however, was nurtured in a land influenced by more than Jewish tradition. The Greek attitude toward images and even image worship was quite favorable. Paintings and statues of their mythical gods and heroes covered classical Greece, while even Rome adopted the Greek imagery into the culture of its own people (12). In addition, the Syrian civilization introduced to the Mediterranean world its own artistic style of frontal poses and large facial features (Cavarnos 14). Israel, the birthplace and location of the ministry of Jesus, was the cradle of Christianity and was centrally Jewish, which usually rejected images unconditionally. However, Christianity was quickly becoming an expanding church, and its increasing acceptance forced Christians throughout the Old World to evaluate their stand on representative images (Gerhard 14).\nAmong the Orthodox tradition, there exists a legend of the first icon, which began with Christ. John Stuart explains:\nTradition has it that Abgar, King of Edessa, who was afflicted with leprosy, heard tell that Christ could restore him to health. He accordingly sent one Ananias as an ambassador to Palestine with instructions to find Our Lord and return with him to Edessa. When Ananias finally caught up with him, Christ was addressing a great throng of people. Being unable to approach nearer, Ananias began to sketch the face of Christ, although needless to say, with very little success. But Christ was aware of what Ananias was doing. When he had dismissed the crowds, he took a piece of linen; soaking it in water, he pressed it firmly to his face and then handed it to Ananias. When the latter had taken the towel into his hands, he saw that Christ’s features were clearly imprinted upon it.\nChrist declined to go to Edessa but promised to send a disciple after his death. And Edessa was to become, in fact, the first Christian state. Meanwhile, Ananias was instructed to take the towel to King Abgar, as a substitute for Christ’s presence. (31)\nEventually, with the increasing influx of complete Mediterranean culture in the Christian world, images gained greater acceptance. In the Byzantine area (the region around Constantinople named for the old name of the city, Byzantium), the Christian imagery was mostly affected by the Hellenistic (Greek and Roman) and Syrian culture (Cavarnos 14).\nThe central Hellenistic influence in Christian iconography was the art of mosaics. Early Christians used this technique to decorate the walls, floors, domes, etc of their churches. Syrian art effectively gave rise to the use of frescoes in Christian churches. The third type of icon—the panel icon—is the most widely used in Russia and most other regions of the Orthodox faith. It consists of a picture painted on a chalk-covered wooden panel treated with an egg solution, or tempera (17).\nThe actual process of creating a panel icon is very complex. First, the icon-maker must go search for the correct type of wood. Cypress was used in Greece; birch and oak were often sought after in Russia, as well as was a good, sturdy pine from Siberia (Gerhard 208). After carving the panel into the correct size and shape with an axe or two-handed plane, it is stored away to remove its moisture. This process normally takes five or six years. After this period, gesso, or chalk, is ground onto its surface to prepare the panel for the next step. This step involves the draughtsman, who sketches the basic outline of the picture in charcoal. When this is completed, he removes the charcoal and paints the outline in a black-colored paint. After the fundamental outline of the image is complete, the surface is gilded with an egg-paste mixture to prepare it for the actual pigmented paint (Stuart 42).\nOn the icon, the first sections painted are the background (such as buildings and nature) and the clothing of the subjects involved. Normally, gold ornamentation follows, which involves painting on sticky resin followed by the application of light gold sheets, after which the sheets are polished. Next, the icon-painter begins painting the subjects’ faces. These comprise the most precise skill on the part of the painter, who must endow the faces with the very spirit and life force of the subject in the picture. A layer of varnish, normally comprised of linseed or olive oil is applied. Finally, it is transported to a church for a blessing (Gerhard 210). The icon is then complete.\nThe Byzantine art style is fundamentally different from the classic western style of realistic sketches and Renaissance-type paintings. The icon painter, as a member of this Byzantine tradition, approaches art with symbols in mind, rather than a realistic concept of some natural object (Stuart 25). Much like a Chinese calligrapher wanting to depict a tree in a work of writing composes a specific character meaning “tree,” rather than drawing any actual tree that he may see or conceptualize, the icon painter creates specific symbolic paintings that illustrate the various religious ideas wishing to be expressed.\nTruly, iconography is more concerned with symbolism than physical appearances. The object of an icon is to capture the spirit and meaning of what the image is trying to portray. Constantine Cavarnos maintains that “True iconography is intended to take us beyond anatomy and the three-dimensional world of matter to a realm that is immaterial, spaceless, timeless—the realm of the spirit, of eternity. And hence the forms and colors are not those that one customarily observes around him, but have something unworldly about them” (38). Indeed, these metaphors elicit associations and can give an extended message than what is possible in a work concerned with physical beauty and perspective exactness.\nIt is of importance to note that the colors used in an icon are metaphorical rather than actual; icon colors often do not follow the color patterns in nature. Rather than making sure all the colors are in harmony with natural appearance, the icon painter will seek a harmony with the spiritual message in his art. Colors are very important for this harmony; each color symbolizes an aspect of the icon and gives a special meaning. For instance, deep red and royal purple are symbolic of the blood of Christ and are often used for the shoes of royal figures. Blue represents heaven and the ethereal. The greens and browns are usually used in familiar manners, representing the earth and vegetation—a reminder of our existence on this earth. From scarlet red comes vigor and vitality, a color used for the blood of martyrs and the cloak of St. George. Orange-red symbolizes the purification of the spirit. White suggests purity and colors the garments of Christ and his angels (28).\nTo give a specific example of the abstract nature of icon art, the faces of the characters depicted always are turned facing the viewer—the person giving their respects and their prayers. This rule holds true regardless of the character’s perspective position in their environment (Upensky 60). In fact, not only are the heads facing the viewer, the important figures in the image have their entire body turned outward in this manner. The rest, the less important, are normally subject to the laws of three-dimensional perspectives. Additionally, where those significant figures are generally depicted as stationary, the rest are again interacting with their environment and are often moving (65).\nSuperceding the hassle over the concern of the icon complying with the “hows” of natural laws and perspectives is the concern of why the natural laws work. This question of “why?” has always been a consideration for Byzantine religious artists. They do not comply with the classic paintings—those that depict photographically accurate settings; again, icons portray the religious nature and symbolism of their scenes (Stuart 36). A naturalistic painting may show Saint Peter as tall and powerful, completely in perspective with his environment, but an icon will depict him in an unrealistic-looking but completely symbolic and explanatory setting.\nIcons may be placed in any location, such as a home or shop, but the central location where they are situated is, of course, the church. When one enters an Orthodox church, immediately noticeable is the iconostasis—a giant screen, composed of wood or marble, that supports the panel icons. On top of the iconostasis is a large cross with the figure of the crucified Christ. In Eastern Orthodoxy, there is great significance given to the Virgin Mary and John the Baptist, whose icons are placed on the iconostasis to the right and left of Christ (Cavarnos 23). In most church buildings, icons cover most of the interior. As mentioned before, each icon portrays a religious message. When all the icons are displayed, the composite of the images inside the church gives the building an entirely new symbolism. The church is, in effect, a microcosm for the universe, where the iconographic messages reveal the universal plan of eternal salvation (Stuart 38).\nDuring church services, the icons are ritually given respect. The deacon of the church wields a censer and directs it toward the icons. This indicates to the congregation that they are to contemplate the icons and understand that the saints painted on the icons are participating in the service in a similar manner as the worshippers themselves (33).\nIcons in the Eastern Orthodox tradition serve several primary purposes. Most apparent to outsiders is their aesthetic value. They embellish and amplify the beauty of a church. Secondly, they instruct their faithful members in matters of doctrine, many times employing symbols that effectively surpass written doctrine (Cavarnos 30). Icons also remind these members of their faith. Their powerful message serves to remind and awaken the faith of the members of the church. In almost every instance, a saint or holy figure is portrayed on the icon. This serves to set an example for the members of the Eastern Orthodox faith. The righteous individual on the icon gives them a model with which to pattern their lives. This person on the image causes the member to be stirred up in faith and righteous zeal (32).\nSurpassing all other purposes, the icon is a conduit for prayer and worship (Stuart 29). Each member of the congregation is allowed to light a candle, come to an icon, and make the sign of the cross. They then will reverence the icon with a kiss and say a prayer (Ugolnik 45). The Eastern Orthodox Church makes it very clear, however, that its members are not worshipping the icon, but giving it “honorable reverence.” Worship is due only to God, and the icon is a medium through which that worship may be expressed (Cavarnos 33).\nThis worship is the ultimate fulfillment of Byzantine iconography. Even with its extensive history and stunning methods of artistry, the sacredness of the icon surpasses all aesthetic and external value. The symbolism of the holy icon is truly the center of Eastern Orthodox worship. It allows its members to transcend their visible physical reality and enter into the ultimate reality, where spiritual truth is juxtaposed with material truth (Stuart 39). It allows one to comprehend the mutual dependence of matter and spirit and truly gives a perspective of far greater significance than the visible temporal universe that one is commonly allowed.\nCavarnos, Constantine. Orthodox Iconography. Belmont, Massachusetts: The Institute for Byzantine and Modern Greek Science, 1977.\nGerhard, H.P. The World of Icons. New York: Harper and Row, Publishers, 1971.\nStuart, John. Ikons. London: Faber and Faber, 1975.\nUgolnok, Anthony. The Illuminating Icon. Grand Rapids, Michigan: William B. Eerdmans Publishing Company, 1989.\nUpensky, Boris. The Semiotics of the Russian Icon. Lisse: The Peter DeRidder Press, 1976."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:dd3c82b8-bb3f-4067-b9ae-1f746e4cbb38>","<urn:uuid:6970be19-af48-4ce8-9569-812e5f2bc72b>"],"error":null}
{"question":"What are the differing perspectives on mowing height and grass maintenance between standard landscaping advice and low-input lawn care methods?","answer":"Standard landscaping advice warns against cutting grass too short as it stresses the grass, recommending mowing at a higher setting and only cutting one-third of the grass length to prevent weeds and help develop better roots. The low-input approach is more specific, recommending setting the mower blade at exactly three inches and letting grass grow to four inches before mowing off one inch. Both approaches agree that mowing too low stresses the turf. However, they differ on grass clippings: while standard advice doesn't address this, the low-input method specifically recommends letting clippings lie on the lawn as a high-quality, free fertilizer, noting that thatch buildup is actually more common in intensively managed, highly fertilized lawns rather than low-input ones.","context":["Not everyone is into landscape design, but we can all tell when someone spends time taking care of their lawn because of their lush green grass with accents of flowers and beautiful trees. Landscaping seems to be simple, but not all lawns are proof of that. As simple as it may seem, there is a lot to learn to get a perfect lawn. Below are some ways to help you restore your landscape and have a beautiful lawn you can be proud of.\n1. Get rid of dry patches: it is virtually impossible to make your entire lawn colorful and lush. Unfortunately, dry patches in your lawn and dead flowers immediately draw attention and distract from the other landscaping. It is best to replace the dry areas with healthy grass or plants to improve the look of your lawn instantly. This is an easy form of landscape restoration that anyone can do.\n2. Create a focal point: when you create a focal point in your yard, it becomes more interesting and will draw attention to itself. Choose a specific plant or statue to make the focal point, then create the rest of your design to draw focus to this point.\n3. Add interest with landscape movements: bring life and interest into your landscape with movement. This can be done with flowers that attract animals or swaying plants. Bringing movement and activity to your landscape design can improve your yard more than you would expect. In The Woodlands, TX, plants that attract hummingbirds are a great idea.\n4. Plant in the right spot: before planting anything, it is important to know the optimal amount of water and sunlight the plant needs, as well as its growth rate, needed space, and full-grown size. This will help you ensure that your landscape design will thrive throughout the years.\n5. Mowing at the right height: mowing your grass to the best height is a topic that is widely disputed. When you cut your lawn short, the grass is stressed out too much. It is best to keep your lawn healthy by raising the mower to a higher setting and only cutting a third of the grass length. This will help prevent weeds and help the grass develop better roots. Your local landscaping company should follow the same guidelines.\n6. Using fertilizers: if you want to grow a strong lawn, fertilizer is necessary. Try to find a fertilizer that includes micronutrients to give your lawn what it needs to stay healthy. Fertilizers act like multivitamins for humans. In Tomball, TX, the soil requires regular fertilization and lime every few years to keep the soil pH levels balanced.\nBy using the tips above, your lawn can look green and lush and be the envy of the neighborhood. Simply remember to get rid of any dry patches, create a focal point, add interest with landscape movements, plant in the right spot, mow your grass at the right height, and use fertilizers as recommended. If you need further help with your lawn, talk with your local professionals.","Bulletin #2166, Steps to a Low-Input, Healthy Lawn\nBy Frank Wertheim, Extension Educator, University of Maine Cooperative Extension.\nReviewed by Barb Murphy, Extension Educator, University of Maine Cooperative Extension; Amy Witt, Horticultural Professional, University of Maine Cooperative Extension; Kate Garland, Horticultural Professional, University of Maine Cooperative Extension; and Gary Fish, Maine Board of Pesticide Control.\nTable of Contents:\n- What are low-input practices and why follow them?\n- De-thatch in spring\n- Test your soil\n- Adjust your soil pH\n- Build your soil’s organic matter and nutrient levels\n- Add compost\n- Fertilize, if you choose\n- Mow high\n- Skip or decrease watering\n- Aerate your lawn\n- Overseed your lawn\n- Find seed sources for resilient grasses\n- Enjoy fewer grubs — and a word about moles\n- Relax about weeds\nLow-input lawn-care practices involve reducing the number of pesticides (mainly weed and insect killers) and fertilizers that you put on your lawn. Over 6.2 million pounds of yard-care pesticides were brought into Maine in 2007. This number has increased seven-fold since1995 and coincides with an explosion of yard-care companies in Maine. During the same period, there has also been a sharp increase of homeowner/tenant use of lawn care multi-step programs containing fertilizers and pesticides. Misuse of lawn-care pesticides and fertilizers negatively affects our water quality. At risk are lakes, streams, and eventually the ocean—the endpoint of all watersheds. The goal of a low-input lawn is to create an ecologically diverse lawn that will look green and healthy without intensive fertilizer and pesticide treatments. Follow these basic principles to create and maintain a healthy lawn while reducing or eliminating fertilizers and pesticides.\nGive your lawn a good raking with a flexible-toothed rake in early spring to remove thatch. Save what you rake up for your compost pile. Removing thatch helps your lawn breathe and allows for new shoots to fill in open spaces. You may wish to lightly overseed after de-thatching to introduce new grasses in the bare areas (see “Overseed your lawn” below).\nThe Analytical Laboratory and Maine Soil Testing Service at the University of Maine conducts soil tests. Review University of Maine Cooperative Extension Bulletin #2286, Testing Your Soil. To get a copy of this bulletin, as well as a soil-test box and form, contact your local UMaine Extension County Office, or call 800.287.0274 (in Maine). The test results will tell you about your soil pH, nutrient levels, and the percentage of organic matter. The report will give you recommendations for optimal plant health. If you prefer, organic fertilizer recommendations can be requested when you send in your soil sample.\nThe pH of the soil (acidity level) for lawns should be in the range of 6.0 to 6.5. Most lawns in Maine have soils that are too acidic (pH is too low). A soil pH of 5.5 or lower favors weed growth more than grass growth. Herbicides can be used to kill weeds; however, if the pH of your soil is not optimal the weeds will simply regrow. Adjusting the pH to within the range of 6.0 to 6.5 will help create an environment that allows the desirable grasses to outcompete and crowd out the weeds. Lime or unleached wood ash can be used to raise soil pH: your soil test results will give you recommendations in terms of pounds of lime or wood ash per thousand square feet needed to reach the desirable range. Occasionally, lawn pH is too high. This is often the case when homeowners add lime or wood ash several years in a row without having a soil test. Elemental sulfur or aluminum sulfate is used to lower soil pH. These amendments may be applied at almost any time of the year.\nOptimal topsoil depth for grasses is twelve inches, but that amount of soil is unrealistic. Lawns should be grown in at least four to six inches of topsoil. If your topsoil falls short of that, you can build it over time by top-dressing your lawn with mixed compost and loam, up to a half inch a year. Mixed compost and loam, blended to about 50 percent each, is available from many of Maine’s commercial compost facilities.\nIf you do decide to top-dress your soil with mixed compost and loam, you may also want to overseed the lawn lightly to introduce species with reduced fertilizer and pesticide needs. Overseed just before spreading the compost/loam mix to encourage good seed germination. This can be done any time from early spring through early fall, though you will get better seed germination results in late summer/early fall (August-September).\nIf your topsoil depth is inadequate, another way to boost your soil organic matter and nutrient levels and improve the vitality of your lawn is to top-dress with a good-quality compost. Spread two yards of compost per five thousand square feet of lawn, raking it out as evenly as you can to a depth of no more than a half inch. Many garden centers sell compost in bulk, and some even have spreaders you can borrow or lease to help with the job.\nIf you add compost every year, you will need to test your soil to monitor your phosphorus level, which can become excessive with repeated compost applications. Excessive phosphorus can create a risk for runoff into freshwater bodies, where phosphates can contribute to algal blooms.\nToo much compost (added several years in a row) can also cause a rich soil layer to develop at the surface, which may cause the grassroots to stay very shallow. If layers begin to develop, you may need to till the soil and reseed the lawn.\nMost lawns will do just fine if fertilized only once a year, especially if you seed new grass varieties that have been developed to thrive in a lower-nutrient environment. Lawns older than 10 years don’t need to be fertilized because they naturally recycle nutrients. Many people choose to skip fertilizing altogether and keep their lawn health robust by using grass varieties with low fertilizer needs, maintaining the correct pH (6.0 to 6.5), and ensuring that their lawn has adequate soil organic matter. If you choose to fertilize, apply fertilizer between Labor Day and Columbus Day according to your soil test results. Because Maine’s soils are usually rich in phosphorus, use phosphorus-free fertilizer, unless you have a soil test that indicates inadequate phosphorus levels in the soil.\nSet your mower blade at three inches and mow regularly with a sharp blade. Try not to cut off more than one-third of the grass blade in each mowing, e.g., let the grass grow to four inches and then mow off one inch. Most people mow their grass too low, which stresses the turf, making it turn brown and become more susceptible to drought, insects, and diseases. Let the clippings lie on the lawn, as they are a high-quality, low-cost fertilizer and do not contribute to thatch. Thatch build-up is more common in an intensively managed, highly fertilized lawn. It will not build up to a point where it will cause problems in a low-input lawn.\nIf you don’t water your lawn, it will naturally brown and go dormant in the heat of the summer. It will green right up in the fall when rains return. An added benefit is that Japanese beetles will look for someplace else—a lush, over-fertilized and over-watered lawn—to lay their eggs, perhaps resulting in reduced or tolerable levels of grub-feeding damage in your lawn.\nIf you choose to water (when rains do not provide an inch per week), do not water more than twice weekly. Water deeply enough (about a one and one-half inch each time) to train the roots to grow deeper and form healthier plants that will be more resistant to drought and disease.\nAerate your lawn once every one to three years, in late August or early September. A core aeration machine pulls out tiny plugs from the soil, which helps the lawn breathe. In addition, the soil plugs left behind help break down thatch. You can rent an aeration machine, or have a landscaper aerate for you. A low-input lawn can be aerated less often than a highly managed lawn, as thatch build up will become less of an issue. Again, thatch is rarely a problem in low-input lawns.\nOverseeding your lawn is a great way to introduce new turf-grass species that have been adapted to grow well in a low-input lawn environment. Overseeding works really well if grass seed is spread just after aeration. Many of the seeds will fall into the tiny holes left behind by the aeration machine where it is cool and moist, facilitating good seed germination.\nSeed is also the best defense against weeds. Any time you find a bare spot or remove a weed, be sure to reseed those areas. A light sprinkling of a fast-germinating grass type, like perennial ryegrass, is a good choice to fill the gaps before a new weed has a chance to take over. This can be done in the spring, summer, or fall, though the best time to seed a lawn is late summer to early fall (August–September), as weed pressures are reduced at that time of year and soil temperatures are still warm enough for quick seed germination.\nVisit the Maine.gov’s Maine Yardscaping (for a healthy Maine) website to find a list of newly developed grass species that thrive in a low-input lawn environment. This resource also lists endophyte-enhanced grasses that are naturally resistant to surface-feeding insects and tolerate drought conditions.\nThere are several species of large, C-shaped white grubs that feed on and damage turf roots, such as Japanese beetle, June beetle, European chafer, and Asiatic garden beetle grubs. Beneficial nematodes, available through some garden centers and catalogs, have shown promising results in grub control. Another biological control organism, which is marketed as milky spore, is a microbial disease that has been licensed for control of Japanese beetle grubs. Milky spore is not very effective in Maine and has not been documented to give adequate grub control. It is also very expensive to apply. The good news is that many low-input lawn practitioners find that a minimally fertilized or unfertilized lawn attracts fewer grubs, to begin with, and can tolerate a low population with little or no damage to the lawn.\nMany people incorrectly assume that mole damage is a result of a high grub population in a lawn, while in reality, moles feed primarily on earthworms. Using a pesticide (organic or chemical) to reduce grub populations will not reduce mole activity. Earthworm activity is very beneficial in creating a healthy lawn, and a small amount of mole activity will provide some free lawn aeration. Generally, the mole holes and mounds that appear in spring after snowmelt can simply be raked over. In a couple of weeks, the signs of them often disappear, and new grasses can take over any bare spots as grass plants send out new tillers and fill in. You also could spread grass seed over bare spots to help this process.\nBy following these practices, your turf-grass will thrive in a low-input and healthy environment, and in time will be able to outcompete or crowd out many weed species. Best of all, you won’t need to use any herbicides. You can hand-pull a few dandelions or other so-called weeds if they bother you — but think about the beneficial effects that diverse species of plants in your lawn can have on the environment for your family, your pets, and wildlife.\nKeep your lawn healthy the low-input way, and relax!\nFor more information, visit: Maine.gov’s Maine Yardscaping (for a healthy Maine) website.\nInformation in this publication is provided purely for educational purposes. No responsibility is assumed for any problems associated with the use of products or services mentioned. No endorsement of products or companies is intended, nor is criticism of unnamed products or companies implied.\nCall 800.287.0274 (in Maine), or 207.581.3188, for information on publications and program offerings from University of Maine Cooperative Extension, or visit extension.umaine.edu.\nThe University of Maine is an EEO/AA employer, and does not discriminate on the grounds of race, color, religion, sex, sexual orientation, transgender status, gender expression, national origin, citizenship status, age, disability, genetic information or veteran’s status in employment, education, and all other programs and activities. The following person has been designated to handle inquiries regarding non-discrimination policies: Sarah E. Harebo, Director of Equal Opportunity, 101 North Stevens Hall, University of Maine, Orono, ME 04469-5754, 207.581.1226, TTY 711 (Maine Relay System)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:ee893ed2-a873-4bb8-84fb-9fd1e2ceecce>","<urn:uuid:5ff1b9a9-aa7d-485c-af58-3cb0a45e0ff7>"],"error":null}
{"question":"Which film directors mentioned in both The Dead Don't Die and Tales of Hoffmann were influenced by George Romero's work?","answer":"George Romero's work influenced both Jim Jarmusch's The Dead Don't Die, which paid homage to Romero's zombie films (especially Night of the Living Dead), and George A. Romero himself was influenced by The Tales of Hoffmann, stating he got an effects idea for his film Creepshow from the 'Olympia' segment of Hoffmann.","context":["In Jim Jarmusch's The Dead Don’t Die, zombies take over the small town of Centerville. When alarmed calls about missing livestock start coming into the local police station, the town’s three cops (Bill Murray, Adam Driver, and Chloë Sevigny) find themselves mired in a mystery that involves shifting weather patterns, mysterious animal behavior, and the dead coming back to life. With “the greatest zombie cast ever disassembled”—which includes Steve Buscemi, Danny Glover, Rosie Perez, Iggy Pop, RZA, Carol Kane, Selena Gomez, and Tom Waits—The Dead Don’t Die “conjures a giddy apocalypse with no way out,” exclaims The New Yorker. While inspired by George Romero’s 60s zombie classic Night of the Living Dead, Jarmusch and his team give the story a decidedly modern feel. To shoot the movie, Jarmusch turned to his longtime collaborator Frederick Elmes (with whom he created Broken Flowers and Paterson). Having previously shot David Lynch’s Blue Velvet and Ang Lee’s The Ice Storm, Elmes has proven himself a master of style and tone. \"Fred is one of our greatest living cinematographers, extremely focused and innovative, with simple, beautiful ways of enhancing what appears on screen,\" says Jarmusch.\nWith The Dead Don’t Die, Elmes uses his decades of experience to bring an old genre back to life. We talk to him about his zombie inspirations, recreating the low-budget look of 60s horror, and what made The Dead Don’t Die so much fun to make.\nHow did you get involved in shooting The Dead Don’t Die?\nAs a cinematographer, when I find a director with whom I communicate well, see eye-to-eye, and have fun, I will pretty much follow him anywhere. On the last movie when Jim said, \"I have a script about a bus driver who’s a poet who lives in Paterson, New Jersey,\" I was a little skeptical. But then I decided it would be fun to explore the poetry and we made Paterson. When he talked to me about The Dead Don't Die, of course, I was in.\nDid you have ideas going into it about how to shoot a zombie movie?\nTo be honest, I was not a big zombie film fan. Of course, I was familiar with the George Romero films. I remember seeing them when they came out, but I have not been following zombies much in the past few years. I was really counting on the fact that Jim would take it someplace interesting. He loves films of different genres and doing the homework to take them someplace new. When we started to come up with ideas, we talked a lot about Romero. We did our best to pay homage to someone whom we both really respect as a filmmaker. But we also did it our way.\nWhat kind of films did you watch for homework?\nWe watched lots of the George Romero films, especially Night of the Living Dead. We started collecting images that felt like part of the world of our zombie film. They were not necessarily from Romero films. Sometimes they would include zombies and sometimes pictures of odd clouds or weird weather, things that would fit a story where the world is tilting upside down and things are going wrong because of us humans. These images were effective as touchstones, not as things to imitate. We could return to them to remind ourselves about the mood we wanted. Even after we started principal photography, we gathered images—odd weather patterns, a strange light in the trees, a storm starting up. We collected them to use later for visual effects.\nWhen you started work on The Dead Don’t Die, was there a specific creative challenge for you?\nThere is a creative challenge in every story and that makes it interesting for me. I often feel that I need to tie my hands in some way or try something new to give the film a different twist. In most films, I am careful to choose lenses and optics that all match pretty well. For this film, I chose to use optics that were mismatched, that flared in interesting and odd ways. And if they didn't flare enough, we added something that made them flare even more. Nothing quite fit.\nYou also chose to shoot the film day for night?\nYes. This is not a big budget film, but there are a lot of zombie scenes that take place at night. To light the areas in which all the zombie conflict occurs could have been challenging for our budget and schedule. When Jim and I spoke, this stumbling block proved to be a bit of inspiration. We both came upon the idea of shooting day for night. In early zombie films that were made on a shoestring budget, filmmakers would often shoot night scenes during the day to save time and money. As a technique, it has a particular look, one that is a staple of many B movies. We decided this was worth exploring. I did some tests and we found a way to make day-for-night shooting work for us. The bonus is that we are getting this interesting visual style as well.\nJarmusch is hailed as one of the great American independent filmmakers. It seems fitting that this technique pays homage to an earlier generation of independent filmmakers.\nIt did work out that way. We both love the Romero films and they served as a great touchstone for creating the style for this film.\nCan you talk about other stylistic choices you made?\nOf course, there has to be some gore and blood, especially during the first encounters with the zombies. But after that, we decided to make them dry zombies. When our heroes have to kill the zombies, they aren't bloody anymore. There's just black powder that comes out when their heads are chopped off. I think that is a nice twist on the zombie tradition. We worked with an effects company called Chimney to achieve that look.\nThe film has so many great actors who seem to be having a great time with the story. What was the production like?\nReally fun. We really did have a good time. Visual effects can be really difficult to work with, but we all knew that we were making a comedy with Jim’s sensibility and sense of humor. The people doing the special effects and prosthetics makeup did such a wonderful job. It was just so much fun to be around them.","|Director: Michael Powell & Emeric Pressburger\n|Screenplay: Michael Powell & Emeric Pressburger (based on the opera by Jacques Offenbach)\n|Stars: Moira Shearer (Stella, Olympia), Ludmilla Tchérina (Giulietta), Anne Ayars (Antonia), Pamela Brown (Nicklaus), Léonide Massine (Spalanzani, Schlemil, and Franz), Robert Helpmann (Lindorf, Coppelius, Dapertutto, and Dr Miracle), Frederick Ashton (Kleinsach and Cochenille), Mogens Wieth (Crespel), Robert Rounseville (Hoffmann), Lionel Harris (Pitichinaccio), Philip Leaver (Andreas), Meinhart Maur (Luther)\n|MPAA Rating: NR\n|Year of Release: 1951\nWith The Tales of Hoffmann, Michael Powell and Emeric Pressburger set out to do something that had never been done before: turn an opera into a film. Mind you, this is a far different endeavor than simply recording an opera on film, something that had been done since the beginning of cinema (“canned theater” of all kinds was an early staple of the movies). Rather, they took an opera and transformed it visually, using every trick imaginable -- cinematic, theatrical, and even right-before-your-eyes sleight-of-hand trickery -- to reimagine it as cinematic spectacle. The result is a testament to both their creativity and the inherent limitations of trying to transform one medium into another.\nThe Tales of Hoffmann is a cinematic rendition of an unfinished 1880 opera-ballet by Jacques Offenbach that was based on the works of 19th-century German writer E.T.A. Hoffmann. Offenbach used creative license to insert Hoffmann into the stories, making him the main character that binds the various tales together. He also used elements of the supernatural, which makes this work a rarity in serious opera.\nThe three “tales” of Hoffman each explores his “folly of love,” depicting him at a different stage of life in which he falls for and is ultimately heartbroken by a different woman. The first is a mechanical doll named Olympia (Moira Shearer, star of Powell and Pressburger’s 1948 film The Red Shoes) that is literally destroyed before Hoffmann’s eyes; the second is Giulietta (Ludmilla Tchérina), a bewitching courtesan dressed in black (never a good sign) who seduces and destroys Hoffmann; and finally there’s Antonia (Anne Ayars), the dying daughter of a famous composer.\nEach story contains in it a kernel of truth about the sometimes destructive nature of love, whether it be passion for the unattainable or the weakness of a man seduced, yet they remain slightly at arm’s length, ever quite attaining intimate power and passion. Part of this is the nature of opera itself, especially as it is worked out on the screen -- relentlessly formal, highly choreographed, and self-consciously melodramatic, it presents itself so firmly as “art” that it takes a strong will to get past the gaudy surface and into the emotion. Opera is an acquired taste, thus the many pretensions of the form itself tend to get in the way of those viewers who have not cultivated it (including myself).\nOn a purely aesthetic level, though, The Tales of Hoffmann is a monumental achievement. Powell and Pressburger, masters of color and composition, turn each gliding frame into a visual feast, gorging on lusciously saturated Technicolor, exquisite production design, and outlandish costumes and make-up. Some of the film’s imagery is immediately unforgettable, especially the more macabre moments, such as Giulietta walking daintily across what appears to be a sea of charred bodies or the moment when Olympia’s mechanical body is torn limb from limb.\nThere is no sense of realism in the film, not even of a dream-state variety; no, The Tales of Hoffmann is a theatrical production through and through, making no attempts to hide its curtains and formal staginess and even the theatrical special effects, such as the black velvet used to mask the parts of Olympia’s body that have been torn away. Yet, despite the canned theatricality, Powell and Pressburger manage to make it exquisitely cinematic, using camera movement and angles and such filmic techniques as double exposure and fast and reverse motion to achieve imagery that would be impossible on-stage.\nYet, in the end, The Tales of Hoffmann never quite satisfies because it doesn’t transcend its stagebound origins. There is something noble and moving about Powell and Pressburger’s ambitions to create a hybrid art between stage and screen, one that is not fully one nor the other, yet it is the film’s interstitial nature that ultimately disappoints.\nIt doesn’t help either that Robert Helpmann’s Hoffmann makes for such a bland and uninvolving central character. Although Helpmann was a star of the New York City Opera, he has little in the way of screen presence, which combined with Hoffmann’s essentially passive nature makes him deadly dull. Part of this is related to the story’s emphasis on the nature of fate, but it saps the film of a central core of energy, which keeps its striking images from adding up to anything more grandiose than themselves.\n|The Tales of Hoffmann Criterion Collection Special Edition DVD|\nEnglish Dolby Digital 1.0 Monaural|\nAudio commentary by director Martin Scorsese and film music historian Bruce Eder\nNew video interview with director George A. Romero\nThe Sorcerer’s Apprentice (1956), a short musical film directed by Michael Powell\nGallery of production sketches and paintings\nGallery of archival production and publicity photographs\nOriginal theatrical trailer\nEssay by film historian Ian Christie\n|Distributor||The Criterion Collection|\n|Release Date||November 22, 2005|\n|Criterion’s new high-definition transfer was made from the British Film Institute’s 35mm restoration internegative, roughly the same source as their earlier laser disc edition (which was taken from a composite print made from the internegative). In addition to the generational improvement of the transfer, the DVD image has also been further restored digitally, removing most traces of dirt and scratches. The result is a lovely, if not entirely perfect, image that nicely recreates the slightly muted colors of the Technicolor palette. Some of the image is a little soft, and there are a few times when it seems like the three Technicolor strips didn’t quite line up, which is a frequent occurrence with older films due to inevitable shrinkage. Overall, though, the image looks about as good as we could expect, and it does justice to Powell and Pressburger’s magnificent imagery.\n|Considering the fact that the entire film is wall-to-wall music, the soundtrack is of vital importance, and this one doesn’t disappoint. Even in monaural, the soundtrack shines quite brightly. It was transferred at 24-bit from the 35mm restoration optical tracks and then further improved via digital restoration, resulting in a clean, hiss-free soundscape.|\n|For anyone with reservations about the importance and artistic merits of The Tales of Hoffmann, Criterion provides strong testimony from a couple of unexpected sources. The first comes via an audio commentary recorded in 1992 for the laser disc edition by filmmaker Martin Scorsese, one of the film’s most intense admirers, and film historian Bruce Eder. Eder is more measured and scholarly in his commentary, while Scorsese waxes poetic about his fascination with the film and its effect on his work (including Taxi Driver and GoodFellas). Even when Scorsese lapses into basically narrating what’s happening on screen, he does it with such enthusiasm that it’s worth listening to.\nThe most unexpected bit of testimony, though, comes from filmmaker George A. Romero, best known for his zombie films starting with 1968’s classic Night of the Living Dead. In a newly recorded 15-minute video introduction, Romero discusses the film’s importance and it’s lasting influence on his work, as well (who would have thought he got an effects idea for Creepshow from the “Olympia” segment of The Tales of Hoffmann?).\nOther supplements on the disc include several extensive stills galleries of production designer Hein Heckroth’s sketches and paintings (which are sumptuous art in their own right) and archival production and publicity photographs. A particularly neat new inclusion is the 1956 short musical film The Sorcerer’s Apprentice directed by Michael Powell, which demonstrates his continuing desire to marry music and film.\nOverall Rating: (2.5)\nThoughts? E-mail James Kendrick\nAll images copyright © The Criterion Collection"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:130e8aeb-9591-4149-ba1b-89c5ee2ed14d>","<urn:uuid:20f86418-5874-4225-aa7f-b4002a26754b>"],"error":null}
{"question":"How do you determine which methodology to use between quantitative vs qualitative research for a study?? Can u provide a detailed comparison of when to use each one!","answer":"The choice between quantitative and qualitative methodology depends on several factors. Consider your research question and whether the data would be more meaningful in numeric form (quantitative) or descriptive text (qualitative). Qualitative methods are better suited when you don't know much about a topic and need an exploratory approach to gain a wide perspective. Quantitative methods are more appropriate when you need to measure frequency or quantity, asking questions about 'how many' or 'how often.' Also consider your study participants - if you need specific pre-defined answers, use quantitative methods with scaled responses. If you want detailed experiences without parameters, use qualitative methods with open-ended questions. Often, using a mixed methodology approach combining both methods can enrich the data.","context":["Limitation in research methods refers to the variables or influences the researcher can't control. These uncontrollable variables often mean a lack of adequate information on the given research subject.Continue Reading\nResearch Methods and Design\nWhen conducting any form of research, there are multiple things that can determine the design of a specific research project. The research question, the ethics involved in the research, the methodology of the project and the budget the researcher has available are all major parts of how a research project is designed and carried out.\nThere are two types of research methods: qualitative and quantitative. Both research methods involve gathering information on a subject. Qualitative research is used most often in the social sciences to study people, behavior, language and culture. Quantitative research methods are used in scientific research and in some disciplines, such as economics. This kind of research involves quantifying or measuring the subject or data relating to the subject.\nLimitation in Research Methods\nAll research has some limitations because there are always certain variables that the researcher is unable to control. Sometimes these limitations are more or less significant, depending on the type of research and the subject of the research. Some possible occurrences of limitation in research methods include a lack of available or reliable data, lack of prior research on the subject, the sample size available or the measure used to collect the data.\nWhile limitations in research methods can cause problems in the research, most often the research project can continue despite the limitations present. There are instances wherein limitations can render a certain research project unusable or unreliable, particularly when there isn't enough information or variables to obtain an accurate interpretation of the data being researched. Often in qualitative research, certain limitations stop the findings from being applied to the larger population, making the research findings unusable or unable to be used for larger control groups.\nIn additions to limitation in research methods, there can also be limitations of the researcher conducting the study. True, accurate research is meant to be unbiased to offer an accurate representation of a certain group or groups of data. When a researcher has a bias that would skew an interpretation of the research, it is considered a researcher limitation. Lack of proper access to information, experiences and familiarity with the subject matter can all be researcher limitations that can affect a research project or method.\nTypes of Research Studies\nIn addition to the different methods of research, there are varying research studies. Any research method or study can have limitations to some extent. Limitations will vary depending on the type of research study and what is being studied.\nMany research studies fall into one of a few common categories. Correlation research examines the covariation of multiple variables, such as the covariation of heart disease among those diagnosed as obese. True experiments are defined as studies wherein all variables are attempted to be controlled, aside from the variable that is the focus of the study. These studies are often laboratory studies and include traditional control group studies and double-blind studies.\nQuasi-experiments are another type of research study similar to true experiments. The major difference between true and quasi-experiments is that quasi-experiment research uses groups that are naturally formed, rather than bringing groups together for the purpose of the research study.Learn more about Social Sciences","An SNJ Associates Series: Research Methodology\nIssue 1: Quantitative Versus Qualitative Approaches\nLet’s start at the beginning…\nWe are very excited today to launch the first issue in our new series examining quantitative, qualitative and mixed methodology approaches to completing research. This series is created and presented to our site visitors, who are new or beginning to explore how research is done. At SNJ Associates, we are focused on health and well-being research with a specific interest in social epidemiology. There are many different approaches in both quantitative and qualitative research methodologies and we will emphasize those approaches that are common to the health and well-being research.\nWe will mention, where warranted how other types or approaches in research methodology fit in the grand scheme of what we are discussing, but we will not go into detail about methodologies that are more common to other disciplines. For example, ethnographic research is a very common approach used in the social sciences for anthropology research where a researcher may put together a summary of a particular culture or cultural phenomenon by immersing themselves in the culture for quite some time thus, we may mention how ethnographic methodology fits within the larger classification of research methodology but we will not discuss the specifics of ethnographic research. If you are looking for information on a particular methodology that is not covered in our series, please contact us and we will do our best to point you in the right direction.\nIn order to get started, this post is going to present two distinct approaches to completing research known as quantitative and qualitative methodology and specifically compare both methodologies from a general perspective to help all our readers get a sense of each distinct method. As we proceed through the series, we will go into the detail for each method and also cover the mixed-methodology approach, which is a combination of both the quantitative and qualitative methods combined together.\nWhat is the difference between quantitative and qualitative research?\nQuantitative research approaches generate numerical data or information.\nFor example, in the quantitative approach, a study would record a piece of data in some form of a numerical format. The data could be a birth-date, a blood pressure reading or perhaps a number on a pain scale from 1-10. Quantitative methods use various mathematical models and statistics to understand and interpret the research results. Quantitative research focuses on counting, recording and capturing data and then use various statistical (or mathematical) models to interpret the study data in order to make conclusions about the overall study findings. Common data collection tools used in quantitative methods are questionnaires, surveys, measurements, and other options with a goal to collect or measure information in some form of numerical data. Researchers using quantitative methodology approaches purposely remain very objective and distant themselves as not influence the outcome or results of the study.\nQualitative research generates text, themes, and descriptions.\nQualitative research approaches generate data or information that record experiences and/or perspectives that use language, images, or observations that commonly capture human behaviour. Qualitative research generates text, themes, and descriptions. For example, a qualitative method would record a piece of data in some sort of non-numerical format. The data could be an observation of the researcher, an open-ended interview where participants are free to provide whatever information they would like in response to an open-ended question or use an image such as a photograph. The main objective of the qualitative research is exploratory in nature and attempts to provide a detailed description of the research topic of interest. Examples of data collection tools used in qualitative research include individual in-depth interviews (structured and unstructured), discussion groups or focus groups, narratives from people sharing their experiences, or the content analysis of some pre-existing text or images. A key characteristic of the qualitative method is that researchers themselves use a subjective approach to collect information and immerse themselves in the process.\nThe Proverbial Question: When To Use Quantitative Method & When To Use Qualitative Methods?\nThis is a very difficult question to answer definitively. The reality is there is a lot of chatter across disciplines and among researchers about when to use which research methodology. It is important to understand that each approach has unique and compelling strengths along with specific weaknesses depending on what it is the researcher is trying to accomplish. A great way to think about whether a quantitative or qualitative methodological approach is best for your research is to always think from the end and importantly you must consider your research question (if the concept of a research question is also new to you read our previous posts What is Research? and Creating and Editing a Research Question).\nLook at your research question and think about whether it makes sense to have the data for the study in numeric form or descriptive text. Also, if you do not know a lot about your topic and you are trying to figure out where the research should go or what questions need answering in your topic area then an exploratory approach using qualitative methods may provide a wide perspective of results for you to consider. Conversely, if your research question lends itself to asking how many, or how often something occurs, you can see that counting and numerical data will make sense.\nIt is also pertinent to think of your study participant. Is it reasonable to have them provide details of their experience without too many parameters or prompts from you or would you prefer participants to answer specific pre-defined questions that you need to focus on for your topic and in-line with your research question and/or hypothesis? In the first instance you may simply use an open-ended unstructured questionnaire and in the latter example, you may have a number of choices of answers that make up a scale.\nOf course, our discussion here is an over-simplified and somewhat academic explanation for the purpose of learning. Always use common sense and logic before you get all caught up in the plethora of arguments surrounding which research methods to use and under what circumstances. The reality is that in most research there is a benefit to using a mix methodology approach where both quantitative and qualitative methodologies are used within the same study in order to enrich the data."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:601a7272-f97c-42ae-b090-b9f17bedd04d>","<urn:uuid:52797117-7732-4167-aa7b-8b1249599482>"],"error":null}
{"question":"Do thought experiments vs real experiments give different conclusions about quantum mechanics?","answer":"Both thought experiments and real experiments have been crucial but complementary in quantum mechanics. Thought experiments like Schrödinger's cat, Wigner's friend, and Frauchinger & Renner's work have been essential in identifying conceptual problems and inconsistencies in quantum interpretations, particularly the Copenhagen interpretation. Meanwhile, real experiments, such as those by Freedman, Clauser, and Aspect, have confirmed actual quantum phenomena like nonlocality that Einstein questioned. Rather than conflicting, these approaches work together - thought experiments often identify theoretical problems that guide real experimental work, while physical experiments verify or challenge the conceptual insights from thought experiments.","context":["Misconceptions and assumptions concerning quantum mechanics\nI get somewhat frustrated every time I read another blog post, book review, or journal article that claims Einstein was wrong about quantum mechanics (QM). It must make for good headlines and is almost cliché. First, these articles often give the misleading impression that Einstein was the only physicist who had concerns with quantum mechanics during its development and exposition. That simply is not true. Many physicists (Schrödinger, de Broglie, Podolsky, Rosen, and several other major figures) had concerns. Additionally, the relatively small fraction of physicists that are active today in the foundations and interpretations of quantum mechanics continue to debate the meaning, the implications, and the completeness of the theory with great vigor. There is not yet a general consensus among experts as to the answers to some of the most fundamental questions about the implications of quantum theory in its present form.\nFor decades, there has been a common misconception among many physicists that the conceptual problems with QM were already resolved or that any remaining questions were purely philosophical. Contributing to this state of affairs, many textbooks focused solely on the computational aspects. If interpretations or foundations were discussed at all, the focal point was on the Copenhagen interpretation. There was little or no discussion of other viable formulations, and the solutions to conceptual problems that these formulations offered. The prevailing interpretation of QM does not give a clear answer to the question “what, if anything, is objective reality”. Some alternatives, such as de Broglie-Bohm mechanics, do. According to de Broglie-Bohm mechanics, particles are objective point-like objects with deterministic trajectories. These trajectories are guided by wave functions, which also objectively exist.\nAlternatives to conventional quantum mechanics\nI am not at all claiming that de Broglie-Bohm mechanics in its current form is the final word. And I am not claiming that we need to immediately replace our existing paradigm with it, without further consideration or modification. However, de Broglie-Bohm mechanics has not been properly vetted by generations of physicists. I think failure to fully consider and evaluate such approaches may be blinding us to the way ahead. The prevailing, fractured conceptual understanding of QM may be holding us back from making the next theoretical and technical leap in our quest to understand the universe.\nThe venerable John S. Bell had this to say about de Broglie’s wave theory (see Speakable and Unspeakable in Quantum Mechanics):\n“Is it not clear from the smallness of the scintillation on the screen that we have to do with a particle? And is it not clear, from the diffraction and interference patterns, that the motion of the particle is directed by a wave? De Broglie showed in detail how the motion of a particle, passing through just one of two holes in screen, could be influenced by waves propagating through both holes. And so influenced that the particle does not go where the waves cancel out, but is attracted to where they cooperate. This idea seems to me so natural and simple, to resolve the wave-particle dilemma in such a clear and ordinary way, that it is a great mystery to me that it was so generally ignored”\nAnd this about Bohmian mechanics:\n“In 1952 I saw the impossible done. It was in papers by David Bohm. Bohm showed explicitly how parameters could indeed be introduced, into nonrelativistic wave mechanics, with the help of which the indeterministic description could be transformed into a deterministic one. More importantly, in my opinion, the subjectivity of the orthodox version, the necessary reference to the “observer,” could be eliminated. … But why then had Born not told me of this “pilot wave”? If only to point out what was wrong with it? … Why is the pilot wave picture ignored in text books? Should it not be taught, not as the only way, but as an antidote to the prevailing complacency? To show us that vagueness, subjectivity, and indeterminism, are not forced on us by experimental facts, but by deliberate theoretical choice?”\nEPR and quantum entanglement\nThe famous “EPR paper”, so-named due to its authorship: A. Einstein, B. Podolsky, and N. Rosen, “Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?”, laid out some of Einstein’s main concerns. These included lack of an objective physical reality in which deterministic properties of observables exist regardless of measurement. And nonlocality, in which a measurement process carried out on one of a pair of entangled particles can seemingly affect the other particle’s properties, instantaneously and without regard to distance. Einstein continued to voice his objection to this fundamental property of quantum mechanics: “because it cannot be reconciled with the idea that physics should represent a reality in time and space, free from spooky actions at a distance.” (Max Born, ed., The Born-Einstein Letters: Friendship, Politics and Physics in Uncertain Times (Macmillan, 1971), p. 178).\nAfter Einstein’s death, the phenomenal John Bell figured out how to quantify the “spooky” part of the intrinsically probabilistic behavior of a pair of entangled particles. See his papers in “Speakable and Unspeakble in Quantum Mechanics”. Years later, experimentalists such as Freedman, Clauser, and Aspect, confirmed that Nature really does make use of this spooky action at a distance, or nonlocality. But to what end?\nAlthough nonlocality has subsequently been confirmed experimentally, it is ludicrous to criticize Einstein for his concerns about a theory that included it. It would be a sad day for science if such a huge paradigm shift swept over the community without raising a few hairs. Additionally, physicists still do not understand how the nonlocality is achieved, nor its implications.\nThe quantum measurement problem\nA related issue is wave function collapse and the “measurement” problem. The measurement problem manifests itself in the fact that there are two rules for how a quantum state evolves in time. The Schrödinger equation tells us how the wave function (or more generally, the state vector) evolves in time when a quantum system is not being “observed” or “measured”. With the Schrödinger equation, you can calculate the probabilities for possible outcomes to different measurements, and how those probabilities change over time. This evolution of the state vector while no one is looking is continuous. However, instantaneous collapse of the state vector into a particular eigenstate occurs upon measurement. Why the discontinuity in the descriptions of the two processes? What constitutes a measurement? What are the dynamics for wave function collapse? Does this mean that wave functions (or state vectors) are approximations to some more complete description of quantum systems?\nThe collapse postulate is ad hoc, based on the fact that we never observe superpositions of quantum states. The core of the measurement problem is the inability of QM to explain the abrupt transition from linear evolution of the wave function, to non-unitary wave function collapse. Steven Weinberg summarizes it thusly: “during measurement the state vector of the microscopic system collapses in a probabilistic way to one of a number of classical states, in a way that is unexplained and cannot be described by the time-dependent Schrödinger equation.”\nSo, objective reality is not understood, nonlocality is not understood, wave function collapse is not understood. We could go on. My impression, based on trends in the literature, is that more and more of the community of physicists is recognizing the holes that remain in our conceptual understanding of the quantum world. As more and more theoretical and experimental physicists struggle with these issues, perhaps we will get closer to a breakthrough.\nHere is a YouTube video with a quick introduction to entanglement: Quantum Entanglement – The Weirdness Of Quantum Mechanics. And a ScienceDaily article on quantum entanglement, including links to additional background information on quantum mechanics.\nComrade on the quest\nTo my delight, just as I finished writing and editing this post, I found the following article on the electronic preprint archive, arXiv.org. Submitted today by Pablo Echenique-Robba, who apparently shares many of my views on the current state of QM:\nAbstract: If you have a restless intellect, it is very likely that you have played at some point with the idea of investigating the meaning and conceptual foundations of quantum mechanics. It is also probable (albeit not certain) that your intentions have been stopped on their tracks by an encounter with some version of the “Shut up and calculate!” command. You may have heard that everything is already understood. That understanding is not your job. Or, if it is, it is either impossible or very difficult. Maybe somebody explained to you that physics is concerned with “hows” and not with “whys”; that whys are the business of “philosophy” — you know, that dirty word. That what you call “understanding” is just being Newtonian; which of course you cannot ask quantum mechanics to be. Perhaps they also complemented these useful advices with some norms: The important thing a theory must do is predict; a theory must only talk about measurable quantities. It may also be the case that you almost asked “OK, and why is that?”, but you finally bit your tongue. If you persisted in your intentions and the debate got a little heated up, it is even possible that it was suggested that you suffered of some type of moral or epistemic weakness that tend to disappear as you grow up. Maybe you received some job advice such as “Don’t work in that if you ever want to own a house”. I have certainly met all these objections in my short career, and I think that they are all just wrong. In this somewhat personal document, I try to defend that making sense of quantum mechanics is an exciting, challenging, important and open scientific endeavor. I do this by compulsively quoting Feynman (and others), and I provide some arguments that you might want to use the next time you confront the mentioned “opinions”. By analogy with the anti-rationalistic Copenhagen command, all the arguments are subsumed in a standard answer to it: “Shut up and let me think!”","Thought experiments have been the bread and butter of modern physics since its inception. Galileo used a thought experiment to argue that all objects fall at the same rate regardless of mass, Isaac Newton used a thought experiment to argue for the absolute nature of space, Maxwell used a thought experiment to argue the nature of thermodynamics, and Einstein’s original paper that introduced the special theory of relativity was purely a thought experiment.\nQuantum mechanics has a long history of thought experiments, most geared towards pointing out weaknesses or oddities in particular interpretations of quantum mechanics. The newest addition to this history of thought experiments in quantum mechanics adds to this tradition by arguing that the common understanding of quantum mechanics is incorrect.\nIn a new paper published in Nature, physicists Daniela Frauchinger & Renato Renner present a thought experiment meant to point out an inconsistency in the orthodox interpretation of quantum mechanics. The particular thought experiment presented by the authors is a modification of one given by Eugene Wigner in 1961, which itself was a modification of the infamous Schrödinger’s cat thought experiment. Frauchinger & Renato’s setup involves two scientists making measurements on two friends who are each making measurements on an isolated quantum system. Their argument, in a nutshell, is that if the orthodox interpretation of quantum mechanics is correct, then the two outside observers will reach contradictory conclusions about the state of an experimental system. Contradictions are a no-go in physics so, therefore, something must be wrong with the orthodox interpretation and we should replace it with another.\nSchrödinger’s Cats, Wigner’s Friends, And QM Weirdness\nIn 1935 Erwin Schrödinger presented the following thought experiment: Say you have a box with a cat in it. Inside the box along with the cat are a vial of cyanide and a hammer rigged to break the vial, releasing the gas and killing the cat. The vial/hammer apparatus is itself wired to a Geiger counter, set up to detect the radioactive decay of a cesium isotope. If the atom spits out a beta particle, the hammer will break the vial killing the cat. If the atom does not spit out a beta particle, nothing will happen and the cat remains alive. You leave the box alone and come back an hour later, wondering whether the cat is alive or dead.\nWell, according to the orthodox interpretation of QM, also known as the Copenhagen interpretation, the answer is actually neither. The mathematical framework of QM describes the above set up as being in a superposition, a mixture of classical states: one in which the atom decayed and the cat is dead, and one in which the atom did not decay and the cat is alive. Before one actually opens the box to look, the cat is in a superposition of alive/dead. When an actual observation is made, the superposition “collapses,” causing the system to pick one definite state. Thus, the Copenhagen interpretation holds that observation of a quantum system causes that system to collapse from a superposition of multiple possible states into one definite state. (It is interesting to note that Schrödinger himself thought his hypothetical situation proved that the orthodox interpretation was absurd).\nIn 1961, Eugene Wigner offered a modification of Schrödinger’s gedankenexperiment. Wigner’s thought experiment replaces the cat in the box with a fellow scientist in a lab who themselves is measuring a quantum system S. Outside the lab is Wigner himself who is observing the entire system of the lab; his friend plus system S. The friend in the lab makes a measurement on an electron and records that it has a spin of -1/2. From the perspective of the friend in the lab, the wave function of system S has collapsed and given him a definite measurement. However, from the perspective of Wigner outside the lab, the entire lab, which includes both his friend and system S, is still in a superposition of two states, one where the electron was measured with a spin -1/2 and his friend observed -1/2, and one where the electron was measured with a spin 1/2 and his friend observed 1/2. It is only after his friend in the lab tells him the result of his experiment that the entire system of the friend plus S collapses into a definite state. From the perspective of the friend inside the lab though, the electron has already taken on a definite state as soon as he measured it. Many have held that Wigner’s thought experiment proves that QM is not applicable at all scales of reality.\nFrauchinger & Renner’s modification to Wigner’s thought experiment is meant to highlight an inconsistency in the orthodox interpretation by deriving an outright contradiction from the principles of the Copenhagen interpretation. Essentially, the thought experiment shows how four individuals each with a different piece of information following rules dictated by QM will result in contradictions. In the pair’s setup, there are two friends F and F each inside of labs L and L making measurements, each being observed by scientists W and W respectively. F flips a coin, and depending on the result, polarizes a particle S to have a certain spin. She then communicates this spin result to F who uses her knowledge of quantum mechanics to determine the outcome of F’s coin flip. So far so good, as F and F are in agreements about the outcome of the coin flip.\nNow, W and W enter the picture. Depending on the initial measurements made by F and F, W and W will observe L and L as being in particular superpositions. Depending on the result of the initial coin flip and the message sent from F to F, a situation will arise where W and W can, according to the mathematical rules of QM, be absolutely certain about the outcome of the initial coin flip. The only problem is that W and W will disagree about that outcome as being heads or tails. In other words, the rules of the orthodox interpretation require that W and W both be 100% certain about the occurrence of mutually exclusive outcomes, a blazing contradiction if ever there was one.\nFrauchinger & Renner point out that a contradiction arises only if one assumes a “single world” interpretation of QM; that there is only one reality where only one outcome can definitely occur. In a previous paper, Frauchinger & Renner have argued along similar lines that single world interpretations of QM will inevitably end up producing contradictions. According to “many-worlds” interpretations of QM, there is no collapse of wave functions; for every possible value of some variable, there is a branch of the universal wave function where that outcome actually occurs. So if a many worlds interpretation is true, then the apparent contradiction derived above is no true contradiction after all. W and W’s observations are consistent as they each describe a different branch of the wave function, a branch where different outcomes occurred. Frauchinger & Renner argue that considerations like their thought experiment compel us to adopt a many-worlds interpretation, as it is the only one that can reconcile the contradictions apparent in the orthodox view.\nMany-worlds interpretations of QM have gained a lot of popularity in recent years but are understandably still handled with some apprehension in the scientific community. The entire premise of the many-worlds interpretation seems impervious to experimental testing, as any possible experimental result could be explained away by referencing the branching nature of the universal wave function. However, strict logical and a priori analyses like that given by Frauchinger & Renner seem to give a kind of evidence for a many-worlds interpretation, on pain of reality being genuinely inconsistent; something no scientist would want to believe."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:4dd90863-a7db-448f-9232-913eab236e36>","<urn:uuid:4b14a53d-4291-4f59-b3bd-26d176f7b010>"],"error":null}
{"question":"What role do automated assistance systems play in deep foundation operations, and how do performance tests help validate foundation design parameters? Please elaborate on both aspects.","answer":"Automated assistance systems play a crucial role in deep foundation operations through features like cruise control for main functions, automated drilling cycles, and satellite-guided positioning for precise drilling point location. The system includes automatic recognition of attachments, real-time calculation of load moments and ground pressure distribution, and integrated concrete pump control from the operator's cabin. Regarding performance testing's role in validation, it enables more aggressive geotechnical design by verifying actual safety factors, which can lead to reduced foundation costs. While most projects rely on conservative safety factors due to soil heterogeneity, performance testing becomes necessary and cost-effective for unusual geologic materials or when empirical design information is unavailable. Tests can either prove a pile's capacity to sustain ultimate design loads or provide detailed load-deformation data for more efficient design.","context":["You are here\nThe handling of deep foundation machines is particularly demanding, especially since a lot of the work is performed outwith the operator’s field of vision. The Liebherr control system has numerous useful functions and various assistance systems to simplify each piling and drilling application. They ensure quick and precise working cycles, increase safety on the jobsite and minimize wear on the machine.\nAll machine functions are carried out using the two joysticks. Furthermore, several movements can be made simultaneously.\nThe most important machine data are displayed on the control monitor with touchscreen. These vary depending on the configuration of the machine and the operation mode.\nRemote control makes the assembly and disassembly of the machine easier. Navigation and alignment from various perspectives outside the operator’s cabin bring huge advantages with respect to safety.\nIf the attachment is fitted with a system for attachment recognition it is recorded by the control system in the carrier machine.\nChanges in the leader position or swinging the uppercarriage lead to significant changes in the machine’s centre of gravity. Centres of gravity, load moments and ground pressure distribution under the crawler are calculated in real time.\nThe focus here is on zero accidents.\nThe operator can save the leader inclination. At the touch of a button, the leader can be set to the desired inclination at the piling or drilling point for each new working step. This saves time and ensures precise results.\nThanks to the latest satellite technology the operator can move the machine to the planned drilling point with pinpoint precision.\nCruise Control for all main functions: depending on the mode of operation, the operator can preselect defined values for the rope crowd system, as well as the speed and torque of the rotary drive. After activation, the drilling assistant functions similarly to a cruise control in a car: the set values are held constant by the machine control system.\nThe installation of cast-in-place piles using continuous flight augers, full displacement tools or double rotary drills belong to the most efficient methods in deep foundation work. Our specially designed assistant system automates the continuous drilling and extraction of the drilling tools and ensures a high-quality result.\nA range of useful operator assistance systems are also available for the most common drilling method, Kelly drilling, in order to optimize the drilling cycles.\nThe operator is able to monitor the complete filling process of the auger from the cabin.\nThe amount and intensity of the left-right movements to empty the auger can be preselected. This protects both man and machine.\nWhen lowering the Kelly drilling tool in free fall, the control system ensures that the rope is always held taut by the winches. This avoids undesired loosening of the ropes.\nDuring Kelly drilling, one of the most difficult challenges for the operator is the correct locking of the Kelly bar. An indication on the control monitor provides the remedy.\nShould the pull force of the crowd winch not be sufficient, the main winch can be connected.\nObstacle recognition enables the timely recognition of unexpected obstacles in the soil when carrying out sheet piling work. This protects both the basic machine and its attachments.\nThanks to an integrated solution, the main parameters of the concrete pump can be controlled from the control panel in the operator’s cab of the deep foundation machine. This means the machine operator has control of the concreting process, which leads to safer and more efficient jobsite assignments.\nManual locking and unlocking of casing drivers is very time-consuming and laborious. Automatic casing driver provides the remedy. Operation is integrated in the control system allowing the operator to open and close the locking pins from the cabin. Power is supplied by compressed air or electro-mechanically in battery operation.\nThe diagnosis monitor observes the vital functions of your machine. Sensor signals, electrical control and the hydraulic pressure of valves and pumps of all main components are displayed on the diagnosis monitor:\nThis means errors can be quickly identified and so standing time kept to a minimum.\nIf you have any further questions, please contact our support team.","More feature stories by year:\nReturn to: 2002 Feature Stories\nCLIENT: LAW COMPANIES GROUP, INC.\nFebruary 2002: Structural Engineer\nMost structural engineers have undoubtedly questioned the merits of merging sophisticated structural analysis with foundation recommendations from geotechnical consultants that appear to be little better than general \"rule of thumb\" values with large and vague factors of safety.\nThe necessity of less precise foundation recommendations lies chiefly in the heterogeneity inherent in natural soil and in the often empirical nature of geotechnical design. Whereas the engineering properties of construction materials are relatively well defined and predictable, the engineering properties of soil and rock are usually expected to vary from location to location.\nNumerous geotechnical design methodologies are based partly on theory and partly on empirical test results. Although local experience and understanding of the origins of geologic materials at project sites can help validate the applicability of specific design methodologies, without performance testing, the geotechnical engineer often has no recourse but to rely on conservative factors of safety that attempt to account for various uncertainties.\nSite-specific performance tests are typically not cost-effective in most projects and using large factors of safety instead is usually a more economical way of mitigating the risk of uncertainties. However, for certain projects, performance testing of foundations may prove cost-effective and sometimes necessary. Performance testing enables more aggressive geotechnical design because actual factors of safety can be verified. More aggressive geotechnical design usually results in a reduction of the cost of foundations. In addition, performance testing may be necessary for project sites with unusual geologic materials or materials unlike those for which empirical design information is available.\nModern pile foundations are used in areas where less costly shallow spread?type foundations are not deemed feasible (pile foundations are usually used to control anticipated settlement or to extend to competent bearing materials). Because pile foundations are often used to support heavier and/or critical structures on marginal geologic materials, performance testing of pile foundations (pile load testing) is relatively common. Pile load tests are generally performed to either prove that piles are capable of sustaining the design load or to gain more detailed information that will enable a more efficient design.\nTYPES OF PILE LOAD TESTS\nStatic and dynamic pile load tests can be performed on drilled or driven piles to evaluate either axial or lateral capacities. Static tests consist of loading piles and measuring deflection. Dynamic tests attempt to obtain static pile capacities generally using stress wave analyses of pile deflection caused by dynamic loads. The typical means and methods used in static tests and various dynamic pile load test methods, which are generally easier to perform and more economical, are discussed in the sections below.\nAs mentioned earlier, pile load tests are generally performed to either prove that piles are capable of sustaining the ultimate design load (\"proof test\") or to gain more detailed information that will enable a more efficient design (\"load-deformation test\"). For a proof test, a test pile is loaded to the ultimate design load (allowable design load times the factor of safety) and the deflection is measured at the pile head. If the deflection is within allowable levels, the test has \"proved\" that the pile is acceptable. Proof tests are generally performed during construction as the piles are installed.\nLoad-deformation tests, on the other hand, are usually performed during the design phase of projects prior to actual construction. For these tests, a pile is typically tested to failure and deformation (and often stress) is measured at several points along the pile shaft and at the pile tip as well as at the pile head. The detailed load-deformation data obtained allows more efficient design by reducing the factor of safety through better understanding of the site-specific properties.\nSTATIC PILE LOAD TESTS\nConventional static pile load tests in drilled or driven piles consist of constructing a reaction frame around the test pile and incrementally loading the pile, usually with a hydraulic jack. The reaction frame is anchored by at least two reaction piles. The test load is measured with load cells and pile head deformation is measured with strain gauges and surveying equipment.\nFor load deformation tests, strain gauges imbedded within the pile may be used to determine the load distribution along its length. Uplift and lateral load tests are performed by modifying the reaction frame and loading (jacking) the pile in the desired direction. Although costly and time-consuming, conventional load test generally provide the most reliable performance data because the loading method is similar to service loading.\nFor drilled piles, load tests using Osterberg cells may be a more cost-effective alternative to conventional static load tests. Osterberg cells are in essence large-diameter hydraulic jacks with built-in load cells that are cast within the pile with twin reaction plates similar in diameter to the drilled pile at the top and bottom of the cell. Movement is measured using strain gauges and reference rods isolated from strain (sleeved) extending from the top of Osterberg cells to the ground surface. Strain gauges are also used to measure the opening of the cell.\nOsterberg cells are typically not used for uplift testing because conventional uplift tests are generally less expensive in most cases. However, Osterberg cells are cost-effective for compression and lateral load tests because reaction piles or anchors are not required.\nSingle cells are typically used for compression proof tests. A load cell is cast near the bottom of the pile and expanded to obtain load and deflection data. Some interpretation of the data is required because the test loading is differently from service loading. During the test, the cell is expanded near the bottom of the shaft, causing uplift above the cell and settlement below the cell.\nBecause the cell loads are resisted by shaft resistance above the cell and pile end bearing below the cell, load-deformation data for the pile tip and pile shaft can be obtained independently. Multiple cells can be cast within a test pile to isolate end-bearing and shaft friction effects or to evaluate directional effects of shaft friction.\nDYNAMIC PILE TESTS\nThe currently used dynamic pile testing methodology was developed from research funded by the Ohio Department of Transportation and the Federal Highway Administration at the Case Institute of Technology in Cleveland, Ohio. Using measurements of strain and acceleration and the principles of wave mechanics, dynamic test methods are used to estimate static pile capacity, inspect pile integrity, and evaluate pile-driving systems. There are two types of dynamic pile testing: large-strain methods and low-strain methods.\nLow-strain methods are typically performed using hand-held hammers that measure pile top velocities and are used mainly to inspect integrity and length of concrete piles. Anomalies in the velocity record are used to evaluate pile integrity. Whereas low-strain methods to inspect pile integrity are limited to depths of about 20 times the pile diameter, large-strain methods can usually be used to evaluate the entire length of piles.\nLarge-strain methods are used almost exclusively for driven piles to evaluate the driving system as well as for estimating static axial pile capacity. Strain gauges and accelerometers are installed near the top of the piles and measurements are taken during pile driving. Large-strain dynamic pile testing is typically performed during the indicator pile program (the indicator pile program is a field test of the selected driving hammer and system to evaluate the driving criteria, driveability, and production rate). Because the cost of installing the strain gauges and accelerometers and monitoring the measurements is relatively inexpensive compared to the total cost of the indicator pile program, dynamic pile testing is a cost-effective way of optimizing the driving system and estimating static pile capacity. For driven piles, optimization of the driving system may be as important as estimating pile capacities.\nThe measurements of strain are converted to force and the measurements of acceleration are converted to velocity for input into dynamic resistance equations to estimate static pile capacities. The most popularly used dynamic resistance equation is the Case Method (Goble et al., 1975).\nA specific hammer blow can be analyzed using the Case Method and a soil model to estimate the shaft friction, end bearing, dynamic damping factors, and soil stiffness. A computer program called CAPWAP® for Case Pile Wave Analysis Program from Goble, Rausche, Likins and Associates, Inc. can be used to perform this analysis. The compression and uplift static pile capacities can then be estimated.\nAlthough dynamic testing can used to estimate static pile capacity for drilled piles, mobilizing a pile-driving hammer and rig is usually not cost-effective.\nPSEUDO-STATIC LOAD TESTS\nTest methodologies that combine the expediency of dynamic methods with loading similar to conventional load tests include the Statnamic® test and the Pile Load Tester. Although both methods are similar to dynamic tests in that test piles are impact loaded, these methods prevent wave propagation effects by spreading the transmitted energy over a longer period. Similarly to static load tests, these methods generate load-deformation (settlement) curves.\nCompression and lateral pile capacities can be evaluated with the Statnamic test method. The test method consists of accelerating reaction masses in the direction opposite to the test load direction by igniting propellant fuel. A load cell measures the load and the deformation of is measured using surveying equipment. For safety reasons, reaction masses are enclosed within a metal casing filled with gravel or another materials used to dampen the return fall of the reaction masses.\nPile Load Tester\nA pile load tester can only be used to evaluate compression pile capacities. For this test method, a large mass is dropped on top of the test pile. The mass with the coiled springs is dropped onto an anvil resting atop the test pile. On completion of the upward stroke (bounce), the mass is caught in its highest position by hydraulic clamps. The load is measured using a load cell and deformation is measured using surveying equipment.\nThe impact of the falling mass is softened and the energy transmission time is extended over a longer time period by the use of heavy coiled springs attached to the bottom of the mass. The springs enable the introduction of a slow-rising, long lasting blow to the pile without causing dynamic effects (wave propagation) present during dynamic load testing; wave propagation complicates interpretation. The springs spread the impact wave over about 200 to 400 milliseconds.\nMore detailed and precise geotechnical foundation recommendations can be developed using the pile load testing methods described above. The additional investment required to procure the more precise information often pays large dividends in material costs savings. At the very least, proof testing of pile foundations can provide additional peace of mind that the expected capacities in design are in fact available in the field.\nReturn to: 2002 Feature Stories"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:8cefdfa2-d561-4db0-8817-daffde655d6c>","<urn:uuid:612a169f-9930-4520-87f6-3042d0f8b651>"],"error":null}
{"question":"如何计算 Asset Turnover vs Inventory Turnover? What's the calculation method for both?","answer":"The Inventory Turnover Ratio is calculated as Cost of Goods Sold divided by Average Inventory. When exact cost of goods sold data isn't available, sales figures are sometimes used instead. The average inventory should ideally be calculated using all 12 months' opening balances, but yearly opening and closing inventory averages are often used as a practical alternative. The Asset Turnover Ratio, on the other hand, is calculated as Total Sales divided by the average of Initial and Final Assets [(Initial Assets + Final Assets)/2]. Both ratios measure efficiency but focus on different aspects - inventory turnover looks at inventory management specifically, while asset turnover examines how effectively a company uses all its resources to generate sales.","context":["Inventory turnover ratio is an important financial ratio to evaluate the efficiency and effectiveness of inventory management of the firm. This ratio indicates how many times inventory is sold and replaced in a financial year. In other words, the ratio gives the frequency of conversion of inventory into sales in a given financial year.\nThis ratio also talks of the effective utilization of the working capital, especially the capital that inventories block. Optimum utilization of working capital may reduce the working capital requirement and thereby save interest cost to the firm.\nTable of Contents\nHow to Calculate Stock / Inventory Turnover Ratio?\nInventory turnover ratio is a simple relationship between average inventory and cost of goods sold. With these data in hand, the calculation of inventory turnover is very simple which is as follows:\nFormula for Inventory Turnover Ratio\nStock / Inventory Turnover Ratio = Cost of Goods Sold / Average Inventory\nThe dark side of the calculation is non-availability of required data i.e. Cost of Goods Sold and Average Inventory.\nThe cost of goods sold is normally not a part of financial statements which is a practical difficulty for an analyst. Analysts normally use sales figure in lieu of the cost of goods sold. Logically speaking, the ratio should not give correct result in that case and the reason is that the sales are based on market value and inventory is based on cost. So the two figures are not comparable to each other.\nAverage inventory should be taken as the average of opening inventory balance of all 12 months. This method will smoothen the seasonal effect in inventory levels and normalize the data. Like the cost of goods sold, availability of such detailed data for analysis is difficult many a times and therefore in the absence of that, an average of yearly opening and closing inventory is taken for the calculation.\nInterpretation of the Ratio\nStock/inventory turnover ratio indicates how frequently the inventory is replaced. The ratio provides an absolute figure. Let’s understand with an example as to what it conveys. If the result of the ratio is 4, it means the complete investment in inventory is sold 4 times a year or we can say it is sold every 3 months in a year.\nNormally, higher this ratio better is the inventory management. It is quite simple to understand. We have invested say ‘x’ amount of working capital in inventory. Interest cost on ‘x’ would remain fixed for the whole year irrespective of how many times that money is used to purchase inventory. So, it is obviously desirable to have higher ratios. Higher frequency of turnover would mean effective utilization of working capital funds.\nWhat is Desirable – A Higher or a Lower Stock / Inventory Turnover Ratio?\nJust like every other thing in life, a balance is also required here. Too high or too low of such ratio is not considered a good sign. Let’s see how.\nVery High Inventory / Stock Turnover Ratio: Normally a higher ratio would be recommended as that would mean effective rolling up of working capital. At the same time, very high of such ratio would have a different meaning also. That may signal very low level of inventory being maintained. Too low inventory means too frequent orders. The manager should make sure that the additional ordering cost incurred should not outperform the savings of interest on working capital.\nVery Low Inventory / Stock Turnover Ratio: Needless to explain, a very low turnover ratio of inventory will not utilize the fixed interest cost incurred on investment in inventory as explained in the above example.\nBenchmark or Ideal Ratio\nBenchmark for inventory turnover ratio depends on the industry. A ratio which is considered good in one industry may be bad for the other. For example, FMCG goods would normally have higher inventory turnover ratio because the goods are cheap and are consumed very fast and on the top they are perishable also. On the other hand, big machinery which is costly in nature would always have a lower inventory turnover ratio. The best way to benchmark this ratio is to compare the concerned company ratio to the average of its respective industry in which it falls.Last updated on : June 30th, 2018","What is Asset Turnover Ratio\nThe ratio of a company’s sales or revenues to the value of its raw materials assets is known as the Asset Turnover Ratio.\nIt serves as a gauge on how well a business uses its resources to generate money. As a result, the Asset Turnover Ratio can be used to scale a business’s performance.\nIt is in terms of its ability to resources and how much value it can generate from them. The performance of the company improves as the ratio rises.\nYou might also like: What Is The Difference Between Stressed Assets And NPAs\nFormula to calculate Asset Turnover Ratio\nAsset Turnover Ratio = Total Sales / [(Initial Assets + Final Assets)/2]\nA company’s average asset holdings at the start and end of a fiscal year can be used to compute the Asset Turnover Ratio.\nIt is calculated with the total amount of assets serving as the denominator. For businesses in some industries compared to others, the ratio may be larger.\nWhat is ROA (Return On Asset)\nReturn on Assets depicts how much profit a corporation may make from its assets. To put it another way, Return on Assets (ROA) gauges how effectively a company’s management generates revenue from the assets or financial resources that appear on its balance sheet.\nThe greater the ROA, which is displayed as a percentage, the better a company’s management is at controlling its financial sheet to produce profits.\nFormula to calculate ROA\nROA = Net Income / Total Value of the Asset\nDifference Between Asset Turnover Ratio and ROA\nDifference in calculating returns\nThe Asset Turnover Ratio is used to check the performance of the company in terms of the use of raw materials to produce finished goods.\nEvery company indeed needs raw materials to produce its final good. And the difference in the net income from selling the final goods to the difference in the cost of raw material used is the Asset Turnover Ratio.\nOn the other hand, Return on Asset (ROA) is used to check the total income generated from the overall asset owned by the company. This evidently includes fixed costs like the cost of machinery, other investments for building the business, etc.\nThe ratio of the net income to the total value of these assets is the ROA. The ROA tells the user how much money in the assets have gone to start/run the business.\nDifference based on the types of assets used to compare\nFor calculating the Asset Turnover Ratio, assets pertaining to the raw materials and\nother purchases that, subsequently, are used to prepare the final goods are used. These assets may or may not reflect in the balance sheet of a company.\nWhile, for calculating the ROA fixed assets such as the cost of manufacturing plants, machines, and tools are used. These are all the assets that are displayed on the balance sheet of the company.\nDifference in interpreting these financial figures\nHigher the Asset Turnover Ratio, the better the outcome the company makes, therefore, from its raw materials assets.\nAn increasing asset turnover ratio depicts that the company is not only growing its annual sales but also optimizing its overall available assets.\nOn the other hand, companies with low ROA typically use more assets to generate their earnings. Businesses with a high ROA typically use fewer assets to produce their earnings.\nA rising ROA moreover tends to indicate that a company is increasing its profits with each investment in the company’s total assets.\nA declining ROA may consequently indicate that a company might have made poor capital investment decisions. And is therefore not generating enough profit to justify the cost of purchasing those assets.\nA declining ROA could also indicate that the company’s profits are shrinking due to declining sales or revenue.\nDifference between Asset Turnover Ratio and ROA with an example\nConsider a bottle manufacturing company that has the following particulars:\n- A machine worth 10 lakhs.\n- A plant worth 2 crores.\n- Raw materials worth 50 lakhs at the start of the financial year and 15 lakhs at the end of the financial year.\n- The company has made a net return of Rs. 6 crores in the financial year.\nAsset Turnover Ratio = Total Sales / [(Initial Assets + Final Assets)/2] = 6 Cr. / [(50 lakhs + 15 lakhs)/2] = 18.46\nTotal value of asset = Value of plant + value of machine = 2Cr. + 10 lakhs = 2.1 Cr.\nROA = Net Income / Total Value of the Asset = 6 Cr. / (2.1 Cr.) = 2.85\nFrom the above example, we understand that the bottle company has a great Asset Turnover Ratio which means it can convert its raw material assets to a high-value product.\nThe Return on Assets of 2.85 depicts that the company uses a large number of assets to keep the bottle business running.\nEssential indicators for assessing a company’s profitability are Asset Turnover Ratio\nand ROA. They display the net income of a company in proportion to their respective assets.\nPlease Note: When comparing various companies, investors should remember that this is not the only important metric to consider."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:aaab45d7-ae7a-4e49-a226-aa062bf2f537>","<urn:uuid:9994537e-96d1-42f6-a354-9dbe9e471068>"],"error":null}
{"question":"What were the casting decisions and controversies in MacMillan's ballet production, and how does this compare to Shakespeare's original characterization of Romeo and Juliet? ¿Qué diferencias hay entre ambas interpretaciones de los personajes principales?","answer":"In MacMillan's ballet, the original casting choice of Lynn Seymour and Christopher Gable was overturned for 'bureaucratic reasons' in favor of Fonteyn and Nureyev, primarily due to their box office appeal. This caused significant disappointment and led to Seymour leaving the Royal Ballet temporarily. In Shakespeare's original work, the characters were portrayed quite differently from each other: Romeo begins as a naive youth languidly pining for Rosalind before maturing through his love for Juliet, while Juliet is depicted from the start as having greater maturity and a tragic sense of existence despite their young ages. In the ballet, MacMillan and his original dancers envisioned Juliet as the headstrong character making decisions, while Romeo was 'swept off his feet by love,' showing how different interpretations evolved across different art forms.","context":["Romeo and Juliet (MacMillan)\n|Romeo and Juliet|\nRoyal Opera House, London\n|Original ballet company||The Royal Ballet|\nKenneth MacMillan had previously choreographed the balcony scene for Lynn Seymour and Christopher Gable to dance in September 1964 for Canadian Television. This scene provided an essential part of the ballet's overall structure. Seymour stated that the balcony scene pas de deux only took three rehearsals to fully choreograph. This experience made him seem a good candidate to choreograph the entire ballet for Covent Garden, when the Soviet Union refused to allow Leonid Lavrovsky's classic production to tour to London. MacMillan prepared his version with the blessing of Frederick Ashton. MacMillan only had five months to choreograph the full ballet as The Royal Ballet hoped to perform Romeo and Juliet in its upcoming American tour. He, Seymour, and Gable planned the ballet around the characters and their pas de deuxs. They envisioned Juliet as the headstrong character, making decisions, while Romeo was \"swept off his feet by love\". Nicholas Georgiadis designed the set and costumes with specific intent regarding the characters and feel of the performance. The imposing, large set designs were utilized to emphasize how small and vulnerable Juliet was in comparison and position her and Romeo as helpless against the society they live in. MacMillan and Georgiadias were inspired by Italian Quattrocento paintings and architecture; Shakespeare, and Franco Zeffirelli's 1960 Romeo and Juliet production. MacMillan also took inspiration from Cranko's Romeo and Juliet to include the rowdy harlots in the market scenes.\nKenneth MacMillan's Royal Ballet production of Sergei Prokofiev's Romeo and Juliet premiered at the Royal Opera House, Covent Garden on 9 February 1965. Though MacMillan had conceived the ballet for Lynn Seymour and Christopher Gable, for \"bureaucratic reasons\" Margot Fonteyn and Rudolph Nureyev danced the opening night, to MacMillan's disappointment. The casting change was disheartening not only to MacMillan, but to the entire company, contributing to MacMillan and Seymour's eventual move away from the Royal Ballet and Gable's transition away from dancing entirely. Mainly, Fonteyn and Nureyev were given the leading roles because of their fame and box office draw. The impresario for the American tour, Sol Hurok said that the ballet would only be included and profitable in the US if Fonteyn and Nureyev were given the title roles. Fonteyn and Nureyev brought new life to the characters, as did the set and costume designs by Nicholas Georgiadis; Fonteyn, considered to be near retirement, embarked upon a rejuvenated career with a partnership with Nureyev. Lynn Seymour left the Royal Ballet for three years after this slight to dance with the German Opera Ballet in West Berlin, but she returned in 1970 to dance many principal roles.\nThe first production of Romeo and Juliet was met with overwhelmingly positive critical and box office response. Fonteyn and Nureyev received 43 curtain calls, eventually needing the safety curtain to descend in order to encourage the audience to leave the theater. Critics agreed across the board that the ballet was a fantastic addition to the Royal Ballet's repertoire as well as an accomplishment for MacMillan. The Observer, The Daily Mail, and the Sunday Telegraph were a few of the magazines and papers to review the performance. Andrew Porter with The Financial Times, who was the first critic to discuss the last minute casting change, noted that the ballet could not be fully understood until Seymour performed the role designed for her.\nLynn Seymour and Christopher Gable danced the lead roles in the second cast, also receiving rave reviews, though not the same level of overt audience appreciation. They were followed by three other pairings in the first tour and many more throughout the decades since.\nThe first five performances of Romeo and Juliet have remained highly lauded by critics. Alastair Macaulay spoke of Fonteyn and Nureyev's performance as \"If there was a single moment in my life that turned me into a ballet obsessive, that was it\". In the New York Times in 2007. He also lauded Seymour's rebellious Juliet.\nRomeo and Juliet has become a staple of the Royal Ballet's Repertoire. MacMillan went on to restage the ballet for other companies around the world such as The Royal Swedish Ballet, American Ballet Theatre, and the Birmingham Royal Ballet. The Birmingham Royal Ballet also included a new set and costume design by Paul Andrews.\nThe film was one of a series of movies financed between Rank and the NFFC. It received some strong reviews but was a box office disappointment. Since then it has been live streamed and recorded multiple times, the most recent of which being the 2012 filmed production of the ballet starring Lauren Cuthbertson and Federico Bonelli, filmed by Ross MacGibbon. A 90-minute abridgment by writer-producers (and dancers) Michael Nunn and William Trevitt for BBC television was broadcast in 2020 on PBS Great Performances.\n- Margot Fonteyn, Juliet\n- Rudolph Nureyev, Romeo\n- David Blair, Mercutio\n- Desmond Doyle, Tybalt\n- Anthony Dowell, Benvolio\n- Derek Rencher, Paris\n- Michael Somes, Lord Capulet\n- Julia Farron, Lady Capulet\n- Leslie Edwards, Escalus, Prince of Verona\n- Georgina Parkinson, Rosaline\n- Ronald Hynd, Friar Laurence\n- Franklin Whyte, Lord Montague\n- Betty Kavanagh, Lady Montague\n- Jann Parry, p274\n- \"Romeo and Juliet Balcony Pas de Deux\"\n- Jann Parry, p275\n- Jann Parry, p276\n- \"Romeo and Juliet\"\n- Jann Parry, p285\n- Macaulay, Alastair. \"Sex, violence, and Kenneth MacMillan\" in Reading dance: a gathering of memoirs, reportage, criticism, profiles: p. 422\n- Kavanaugh, 328\n- \"Romeo and Juliet\"\n- \"Lynn Seymour\"\n- \"Romeo and Juliet\"\n- Macaulay, 2007\n- \"Romeo and Juliet\"\n- Kavanaugh, 329\n- Petrie p 7-8\n- Petrie p 12\n- MacGibbon, 2012\n- \"Romeo and Juliet\". Kennethmacmillan.com. Retrieved 15 October 2014.\n- Gottlieb, Robert. Reading Dance: A Gathering of Memoirs, Reportage, Criticism, Profiles, Interviews, and Some Uncategorizable Extras. Pantheon, 2008.\n- Parry, Jann. Different Drummer: The Life of Kenneth MacMillan. London: Faber & Faber, 2009. ISBN 978-0-571-24302-0\n- Petrie, Duncan James (2016). \"Resisting Hollywood Dominance in Sixties British Cinema : The NFFC/Rank Joint Financing Initiative\" (PDF). Historical Journal of Film, Radio and Television.\n- Kavanagh, Julie. Nureyev: The Life. VINTAGE, 2008\n- MacGibbon, Ross, dir. Romeo and Juliet. 1965; London, UK: Royal Opera House, 2012. DVD\n- \"Romeo and Juliet Pas De Deux.\" Kenneth MacMillan. MacMillan Estate. Accessed 7 June 2020.\n- \"Romeo and Juliet.\" Kenneth MacMillan. MacMillan Estate. Accessed 7 June 2020.\n- Macaulay, Alastair. \"Confessions of a 'Romeo' Fiend\". The New York Times, The New York Times, 1 Apr. 2007\n- The Editors of Encyclopædia Britannica. \"Lynn Seymour\". Encyclopædia Britannica. Encyclopædia Britannica, inc., 4 March 2019","Summary: the Literary character ROMEO and JULIET\nROMEO and JULIET (eng. Romeo and Juliet) — heroes of the tragedy by W. Shakespeare “Romeo and Juliet” (1595), who became forever a symbol of the beautiful but tragic love between two young creatures separated by irreversible age-old feud family clans to which they belong: the Montagues (Romeo) and the Kapu-Letty (Juliet). These names are mentioned in “the divine Comedy” by Dante. Subsequently, the story of two lovers repeatedly developed in the Italian literature of the Renaissance; the names of Romeo and Juliet for the first time arise in the “History of two noble lovers” Luigi da Porto (C. 1524), where the action takes place in Verona. From da Porto story moved on to other writers, in particular to Matteo Bandello (1554), whose Novella was the basis for the poem of Arthur Brooke’s “Romeo and Juliet” (1562), which, in turn, became the main, if not only, source of Shakespeare’s tragedy. However, as always in Shakespeare old bottles poured new wine. Brooke, portraying his lovers ‘ characters are not without compassion, prone to dreary moralizing and preaching obedience, moderation, and humility before the hostile circumstances. For him, the love of Romeo and Juliet if not a sin, or at least some redundancy and confusion, for what befalls them deserved punishment. Quite differently approached this story Shakespeare. It renes-Sunny the ideal of a great love, appearing above family prejudices, above the centuries old hatred, seemingly insurmountable dividing the two young scions of the warring clans, and today is perceived modern, no discounts on those four centuries that separate us from the inception of the play. The action of Shakespeare’s tragedy laid in five days, during which all events occur of a play: from initial — and fatal! — meeting of Romeo and Juliet at the ball in the house Ka-poletti to their sad death in the family vault of the Capulets. Shakespeare’s characters are very young, however, the depth affected their feelings makes them precocious adults. However, in this sense, they are quite different. Romeo in the beginning of the play is naive, he languidly ripped apart from love in a kind of Rosalind. (Unlike Brooke, making her an active participant and build around it and Romeo long-term effect, Shakespeare brings it to the stage at all.) Around Romeo the whole company the same as he, and the young men (Mercutio, Benvolio), and he spends his time like his: reeling idly, languidly sighing and doing nothing. Juliet from the very beginning, from the first his appearance is striking not only with the cleanliness and charm of blossoming youth, but grown-up depth, a tragic sense of existence. She is more Mature than Romeo. He’s loving Juliet gradually realize how everything that happens between them is serious and difficult and how many obstacles are in their way, and as if coming to her, turning from an ordinary young Lovelace, in passionately loving and ready to do anything for this love “not a boy, but husband.”The love of Romeo and Juliet is not just a violation of the prohibitions family is an open challenge to their centuries-old tradition of hatred is the hatred with which for many generations were born and died many Montagues and the Capulets, on which rested almost the foundations of the state of Verona. So afraid of all the impudence and the depth of killing Romeo and Juliet feelings, because try to separate them. For their love, their Union undermines, violates something that cannot be broken. Despite his youth and carelessness, in spite of boyish daring Romeo and girlish spontaneity Juliet, they almost from the start know pre-acercandose finals. “My soul full of dark presentiments!” says Juliet, looking after a runaway in Romeo’s banishment. The power and transcendence of their passion, the finality of adopted decisions and reckless determination to everything, including death, shocking even the one who seemingly understands them, and not only sympathize with them, but also strongly contributes to, the father Laurence: “These violent delights end is terrible, // And death is waiting for them in the midst of the celebration.”The first performance of the play took place presumably in London Kurtina. Among the famous performers of the role of Romeo in the English theatre — David Garrick (1750), Charles Kemble (1805), C. macredie (1810), E. keen (1817), in 1882, the tragedy was staged in the Lyceum theatre, headed by Henry Irving (Irving — Romeo, E. Terry — Juliet), in 1884 the role of Juliet was played by Stella Patrick Campbell. In the XX century an outstanding performer of the role of Romeo was A. Mo-Issy (directed by M. Reinhardt, 1907). In the English theatre Romeo John Gielgud, Juliet of Adele Dixon (1929); Romeo and Mercutio — J. alternately.Gielgud and Laurence Olivier, Juliette — Peggy Ashcroft (1935). In 1940, L. Olivier and Vivien Leigh played the show in new York. Famous performer of the role of Juliet in the 1970s, was Dorothy Tutin.On the Russian stage in the role of Romeo, as in many other roles competed by P. S. Mo-Chalov (little theatre, 1824) and V. A. Karatygin (theatre of Alexandria, 1841). In 1881, Juliet was played by M. N. Yermolov (Romeo — A. P. Lensky). Famous were the performances of Chamber theatre, 1921 staged by A. Y. Tairov (Juliet A. Koonen, Romeo – N.M.Tsereteli) and the Theater of the Revolution, 1935 staged by Popov (Juliet M. I. Babanova, Romeo M. F. Astangov), Theater on Malaya Bronnaya, 1969, staged by Anatoly Efros (Juliet O. M. Yakovleva, Romeo A. D. Grachev).The story of “lovers of Verona” and continued in the operas of Vincenzo Bellini (1830) and Charles Gounod (1867) Overture-fantasy, and the scenes-duets Tchaikovsky (1869), a dramatic Symphony for soloists and orchestra, H. Berlioz (1839). Outstanding performers of the operatic versions of Shakespeare’s characters was Adelina Patti, A. V. Nezhdanova (Juliet) and L. V. Sobinov, Sergei Lemeshev (Romeo). For the Russian audience the way Juliet is inextricably linked with the name of G. S. Ulanova danced this role in Prokofiev’s ballet (1940, choreography by L. M. Lavrovsky). Also known ballet embodiments Shakespeare plot set to music by Tchaikovsky, Berlioz (the latter in M. Bejart ballet, 1978). The most famous adaptation is owned by F. Zeffirelli (1968). A modernized version of the story of Romeo and Juliet, transferred to the XX century — the movie musical “West side story” (1961).\nLit.: Morozov M. M. Shakespeare Theatre. M., 1984; L. E. Pinsky’s Shakespeare: the Basic principles of drama. M., 1971."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_language_proficiency_implied","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:f7572c46-866e-43d6-a9b1-71d539daa1f9>","<urn:uuid:03e7d498-2fa1-4915-b617-e6d4e4300f89>"],"error":null}
{"question":"How do divine happiness and human happiness compare in terms of their completeness and limitations?","answer":"Divine happiness is perfect and complete, while human happiness has significant limitations. God's happiness is singularly perfect because He is happiness itself and experiences supreme pleasure in Himself without any negative elements. In contrast, human happiness, especially in this life, is diminished by weariness, interruptions to contemplation, errors, doubts, and various misfortunes. Additionally, human happiness depends on external goods - such as friends, wealth, and power - and can be endangered by lacking certain advantages like being extremely ugly or losing children or good friends through death. Even the most excellent human beings can have their happiness affected by misfortune, while God's happiness is absolute and self-contained.","context":["We finish Book One today. Hooray! This is a good time to remind you to review, review, review. All of Book One was one, long sustained argument, an unbroken thread. You can’t just start at the end and hope to understand what the words and terms mean. Review!\n IT follows from this that God is His own happiness.\n For His happiness is His intellectual operation, as we have shown: and it was proved above that God’s act of intelligence is His substance. Therefore He is His own happiness.\n Again. Happiness, since it is the last end, is that which everyone wills principally, whether he has a natural inclination for it, or possesses it already. Now it has been proved that God principally wills His essence. Therefore His essence is His happiness.\nNotes Case in point about reviewing. “Substance” means essence or nature here. Don’t forget that we proved God’s existence and essence (substance, nature) are one and the same. This is how Aquinas can speak of willing toward an end.\n Further. Whatever a person wills he directs to his happiness: for happiness is what is not desired on account of something else, and is the term of the movement of desire in one who desires one thing for the sake of another, else that movement will be indefinite. Since then God wills all other things for the sake of His goodness which is His essence, it follows that He is His own happiness, even as He is His own essence and His own goodness.\n Moreover. There cannot be two sovereign goods: for if either lacked what the other has, neither would be sovereign and perfect. Now it has been shown above that God is the sovereign good. And it will be proved that happiness is the supreme good since it is the last end. Therefore happiness and God are one and the same. Therefore God is His own happiness.\nNotes We also proved, again starting at Chapter 13, that God has to be one essence. (That He is three persons we haven’t come to yet.) Since He is one, there can only be one sovereign good.\n FURTHERMORE, from what has been said we are able to consider the excellence of the divine happiness.\n For the nearer a thing is to happiness, the more perfectly is it happy. Hence, although a person be called happy on account of his hope of obtaining happiness, his happiness can nowise be compared to the happiness of one who has already actually obtained it. Now that which is happiness itself is nearest of all to happiness: and this has been proved to be true of God. Therefore He is singularly and perfectly happy.\nNotes A simpler argument you’d be hard-pressed to find.\n Again. Since joy is caused by love, as was proved, where there is greater love there is greater joy in possessing the thing loved. Now, other things being equal, every being loves itself more than another: a sign of which is, that the nearer a thing is to one, the more is it naturally loved. Therefore God rejoices more in His own happiness, which is Himself, than the other blessed in their happiness, which is not themselves. Therefore His happiness sets His desire more at rest, and is more perfect…\n Again. Weariness, and the various occupations which in this life must needs interrupt our contemplation wherein especially consists human happiness, if there be any in this life; errors, doubts, and the various misfortunes to which the present life is subject–all these show that human happiness, especially in this life, cannot bear comparison with the happiness of God…\nNotes To which we can only say: Amen.\n False and earthly happiness is but a shadow of that most perfect happiness. For it consists of five things, according to Boethius, namely pleasure, wealth, power, honour and renown. But God has the most supreme pleasure in Himself, and universal joy in all good things, without any admixture of the contrary. For wealth He possesses in Himself an all-sufficiency of all good things, as we have proved above. For power He has infinite might. For honour He has supremacy and governance over all things. For renown He has the admiration of every intellect which knows Him in any degree whatever.\nNotes Whatever else you think of the arguments above, and because we all agree there is such a thing called “happiness”, is Boethius right? How much can we distinguish between wealth and power? If you have power, do you need wealth? If you have honor do you need renown? Our culture obviously treasures renown and disparages honor. Anyway, as The Philosopher said, all these point towards one happiness, which is, of course, God.\nFinally, here are the words St Thomas uses to close Book One:\nTO HIM THEREFORE WHO IS SINGULARLY HAPPY, BE HONOUR AND GLORY FOR EVER AND EVER.","The Human Good\nThe principal idea with which Aristotle begins is that there are differences of opinion about what is best for human beings, and that to profit from ethical inquiry we must resolve this disagreement. He insists that ethics is not a theoretical discipline: we are asking what the good for human beings is not simply because we want to have knowledge, but because we will be better able to achieve our good if we develop a fuller understanding of what it is to flourish. In raising this question—what is the good?—Aristotle is not looking for a list of items that are good. He assumes that such a list can be compiled rather easily; most would agree, for example, that it is good to have friends, to experience pleasure, to be healthy, to be honored, and to have such virtues as courage at least to some degree. The difficult and controversial question arises when we ask whether certain of these goods are more desirable than others. Aristotle’s search for the good is a search for the highest good, and he assumes that the highest good, whatever it turns out to be, has three characteristics: it is desirable for itself, it is not desirable for the sake of some other good, and all other goods are desirable for its sake.\nAristotle thinks everyone will agree that the terms “eudaimonia” (“happiness”) and “eu zên” (“living well”) designate such an end. The Greek term “eudaimon” is composed of two parts: “eu” means “well” and “daimon” means “divinity” or “spirit.” To be eudaimon is therefore to be living in a way that is well-favored by a god. But Aristotle never calls attention to this etymology, and it seems to have little influence on his thinking. He regards “eudaimon” as a mere substitute for eu zên (“living well”). These terms play an evaluative role, and are not simply descriptions of someone’s state of mind.\nNo one tries to live well for the sake of some further goal; rather, being eudaimon is the highest end, and all subordinate goals—health, wealth, and other such resources—are sought because they promote well-being, not because they are what well-being consists in. But unless we can determine which good or goods happiness consists in, it is of little use to acknowledge that it is the highest end. To resolve this issue, Aristotle asks what the ergon (“function,” “task,” “work”) of a human being is, and argues that it consists in activity of the rational part of the soul in accordance with virtue (1097b22–1098a20). One important component of this argument is expressed in terms of distinctions he makes in his psychological and biological works. The soul is analyzed into a connected series of capacities: the nutritive soul is responsible for growth and reproduction, the locomotive soul for motion, the perceptive soul for perception, and so on. The biological fact Aristotle makes use of is that human beings are the only species that has not only these lower capacities but a rational soul as well. The good of a human being must have something to do with being human; and what sets humanity off from other species, giving us the potential to live a better life, is our capacity to guide ourselves by using reason. If we use reason well, we live well as human beings; or, to be more precise, using reason well over the course of a full life is what happiness consists in. Doing anything well requires virtue or excellence, and therefore living well consists in activities caused by the rational soul in accordance with virtue or excellence.\nAristotle’s conclusion about the nature of happiness is in a sense uniquely his own. No other writer or thinker had said precisely what he says about what it is to live well. But at the same time his view is not too distant from a common idea. As he himself points out, one traditional conception of happiness identifies it with virtue (1098b30–1). Aristotle’s theory should be construed as a refinement of this position. He says, not that happiness is virtue, but that it is virtuous activity. Living well consists in doing something, not just being in a certain state or condition. It consists in those lifelong activities that actualize the virtues of the rational part of the soul.\nAt the same time, Aristotle makes it clear that in order to be happy one must possess others goods as well—such goods as friends, wealth, and power. And one’s happiness is endangered if one is severely lacking in certain advantages—if, for example, one is extremely ugly, or has lost children or good friends through death (1099a31-b6). But why so? If one’s ultimate end should simply be virtuous activity, then why should it make any difference to one’s happiness whether one has or lacks these other types of good? Aristotle’s reply is that one’s virtuous activity will be to some extent diminished or defective, if one lacks an adequate supply of other goods (1153b17–19). Someone who is friendless, childless, powerless, weak, and ugly will simply not be able to find many opportunities for virtuous activity over a long period of time, and what little he can accomplish will not be of great merit. To some extent, then, living well requires good fortune; happenstance can rob even the most excellent human beings of happiness. Nonetheless, Aristotle insists, the highest good, virtuous activity, is not something that comes to us by chance. Although we must be fortunate enough to have parents and fellow citizens who help us become virtuous, we ourselves share much of the responsibility for acquiring and exercising the virtues.\nAnyone interested in reading Aristotle’s Nicomachean Ethics book here are your choices:\nThe Nicomachean ethics of Aristotle"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:4a6705b3-bf73-41e1-8f59-daa059a96931>","<urn:uuid:94391d29-8e0b-4b23-a6bc-2aa378e998bc>"],"error":null}
{"question":"Can someone explain the difference between implicit memory tests vs forensic interviews with kids?","answer":"Implicit memory tests and forensic interviews are quite different approaches to working with children. Implicit memory tests involve word completion tasks where children respond with the first word that comes to mind, often showing effects of previously studied word lists. In contrast, forensic interviews are conducted when children are witnesses or victims of alleged crimes, using specific safe techniques like body diagrams, photos, drawings, and sketch plans to help facilitate children's recall of actual events. While implicit memory tests focus on word associations and memory patterns, forensic interviews are designed to help children accurately communicate their real-life experiences.","context":["Humans readily establish false memories. If you give adults a study list of words like hot, snow, warm, winter, ice, wet, chilly, weather, heat, freeze, shiver, frost, and then test them later, they will “remember” related words like cold that weren’t actually on the list. They will be as sure that cold was on the original list as they are about all the words that really were there.\nSmall children, age 5 to 7, by contrast, are very unlikely to make this type of error. They can memorize the words on the list, but they won’t generate false memories. By the time they are 11 or so, kids begin to generate false memories at about half the rate adults do. Researchers speculate this is because children haven’t formed as many connections between related items and concepts, and so simply don’t associate words like cold and weather as readily as adults do.\nAnother, related phenomenon is implicit memory. If you give adults a study list of words, then ask them to complete a word completion puzzle (What’s the first word you can think of that follows this pattern: C_L_ ?), they will reply disproportionately with words on the list, and also with the related words that were not listed.\nThe task can be made explicit by asking participants to reply only with words from the study list. Again, they will falsely “remember” related words that they were never shown.\nKristen Diliberto-Macaluso of Berry College wanted to see if young adolescents also showed a similar pattern with implicit memory, so she conducted two experiments with fourth- and fifth-graders (“Priming and False Memories from Deese-Roediger-McDermott Lists on a Fragment Completion Tests with Children,” American Journal of Psychology, 2005).\nShe gave the kids two types of word lists to study. One type was similar to the list shown above, where all the words were related to a “lure” word (cold, in our example). In the second type of list, the lure word was actually included in the list itself. Next she gave the kids the word completion test, asking them to respond with the first word that came to mind. Whether or not the lure was included in the list, the kids responded the same. About a third to a half the time, they answered with either a lure word or a word that was on the list, compared to around 15 percent of the time for a group of kids that had not studied the list at all.\nNext, with a new group of kids the same age, she showed them the same lists of words and gave the same test, but asked that they respond only with words they had studied before. So in this case, when the lure word was not included in the list, if the response given was the lure word, then it was an example of a false memory. Over forty percent of the time, they did show false memory. However, when the lure word was included in the list, they (correctly) responded it was there about twice as often compared to the kids who had not seen the list. So, when the task was made explicit, fourth- and fifth-graders showed some false memory, but also had accurate memory for the lure words.\nOverall, the false memory effect was about twice as big as the implicit memory effect for these children. The fact that the false memory effect was still smaller than accurate memory for the lure words suggests that these children’s memories aren’t fully mature. As we grow older, it seems, we are more able to make generalizations, but these generalizations are also more likely to lead us to error.","We are interested in memory development and the impact of different information processing and behavioural factors on what children can recall.\nJuror Beliefs and Understanding Children’s Testimony\nHow do jurors understand abuse disclosure by children? How does the way children response to questions by investigators and lawyers impact jurors’ evaluations of child credibility and reliability? How do juror beliefs of children’s capabilities at different ages influence their views of children’s testimony? How do children use interviewing aids to communicate with interviewers and answer questions?\nThese are just some of the questions considered in our research lab under our research investigating juror beliefs and understanding of different aspects of children’s testimony. Aspects such as, how children disclose abuse, respond to questions, or use different types of interview aids (e.g. non-anatomical body position dolls) to communicate, as well as more general issues relating to memory and memory development and its influence on the reliability of testimony. By understanding these issues better, we can support the courts to ensure fairness in proceedings involving children. Findings from our studies will also contribute to evidence-based guidance on the use of interviewing aids to promote communication during investigations.\nChildren’s Memory for Changing Events\nIn this study, we focus on how children between 6 to 14-years remember their experiences of the COVID-19 pandemic. Dr Deirdre Brown is working in collaboration with researchers from universities in Canada (Dr Heather Price), Australia (Dr Sonja Brubacher) and the UK (Dr Charlie Lewis and Dr Michael Lamb) to compare children’s experiences and memory across countries who each had different experiences and responses to the pandemic.\nThis research will help us understand how children remember and experience events that change over time. Children are often asked to talk about their real-life experiences—in class, at home, at the doctor, or in legal settings. These situations can sometimes be difficult for children, and research like this gives us information about what to expect from children and how we can best support them to talk about their experiences.\nThe GRACIA Project\nGround Rules Application and Comprehension in Adults.\nFollowing up previous research examining children’s changing understanding and use of “ground rules” in interview settings across childhood. Ground rules are taught during interviews to help children signal when they don’t understand a question, know the answer, or when an interviewer makes a mistake. Results from our previous research show, even at 12 years, children show poor competency with the rules. This study looks to examine competency in adults. Do adults do better?\nGround Rules and Children’s Interviews.\nSupported by a Marsden Fund grant, the GRACI project is undertaking a series of studies with children aged 3-12 years in the Greater Wellington Region. These studies investigate children’s understanding and use of “ground rules”, such as saying “I don’t know” in an interview setting when they do not know the answer. We explore how children’s understanding of ground rules changes with age, and test ways of teaching the rules that are informed by cognitive research.\nFor a summary of our results from our first study please click here.\nMemory: Age-Related Changes in Errors.\nThe MARCIE project is a series of studies, supported by a Marsden Fund grant, examining the finding that false memories can be more common in older children and adults than they are in younger children. Our research is investigating whether developmental patterns of false memories demonstrated in lab based tasks (e.g., recall of word lists or pictures) occur in the same way when children recall personally experienced events.\nClick here for a summary of result for this project.\nForensic Interviews with Children\nOur research examines safe techniques for conducting forensic interviews with children when they have been witness to, or victims of, an alleged crime. We are investigating such issues as whether using aids such as body diagrams, photos, drawings, sketch plans, or mental context reinstatement in an interview may help to facilitate children’s recall. We are also interested in the abilities of different groups of children (e.g., those with developmental delays or disorders) to remember and talk about what they know. Additionally, we are conducting research that aims to enhance the effectiveness of evidence-based interviewer strategies and to develop processes that can help interviewers engage in self-supervision and evaluation."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:a9e06ada-e756-418c-9c34-3701ec95a8fc>","<urn:uuid:cce62c7b-ca3c-4cdd-b657-2bd3f311b772>"],"error":null}
{"question":"How do the concepts of Samadhi in traditional yoga philosophy compare with the final stages of Patanjali's eight limbs?","answer":"In traditional yoga philosophy, Samadhi is described as a state where the body and senses are at rest while the mind remains alert, leading to the experience of pure consciousness and unutterable joy. The separation between self and non-self dissolves. According to Patanjali's eight limbs, Samadhi represents the eighth limb where the practitioner merges with the object of their meditation. However, Patanjali's system goes further with nirbija-samadhi (seedless contemplation), where all thought seeds are eliminated, leading to the absolute separation of human spirit from worldly matter, enabling infinite expansion and supernatural capabilities.","context":["VIII. Samadhi (Union with the Divine)\nThe final step in the eight-fold path of Yoga is the attainment of Samadhi. Samadhi means “to bring together, to merge.” In the state of samadhi the body and senses are at rest, as if asleep, yet the faculty of mind and reason are alert, as if awake; one goes beyond consciousness. During samadhi, we realize what it is to be an identity without differences, and how a liberated soul can enjoy pure awareness of this pure identity. The conscious mind drops back into that unconscious oblivion from which it first emerged.\nThus, samadhi refers to union or true Yoga. There is an ending to the separation that is created by the “I” and “mine” of our illusory perceptions of reality. The mind does not distinguish between self and non-self, or between the object contemplated and the process of contemplation. The mind and the intellect have stopped and there is only the experience of consciousness, truth and unutterable joy.\nThe achievement of samadhi is a difficult task. For this reason the Yoga Sutra suggests the practice of asanas and pranayama as preparation for dharana, because these influence mental activities and create space in the crowded schedule of the mind. Once dharana has occurred, dhyana and samadhi can follow.\nThese eight steps of yoga indicate a logical pathway that leads to the attainment of physical, ethical, emotional, and psycho-spiritual health. Yoga does not seek to change the individual; rather, it allows the natural state of total health and integration in each of us to become a reality.xviii\nYoga Mind, Body & Spirit, by Donna Farhi\nLight On Yoga, by B.K.S. Iyengar\nYoga Mind & Body, Sivananda Yoga Vedanta Center\nWith many different types of yoga being practiced today, it may be difficult to figure out which style benefits your mind and body the most. It’s important to find out which type of yoga meets your needs. Here are some of the practiced styles of YOGA!\nHatha originated in India in the 15th century. This type of yoga is slow-paced, gentle, and focused on breathing and meditation.\n• Purpose: To introduce beginners to yoga with basic poses and relaxation techniques\n• Benefits: Relieves stress, provides physical exercise, and improves breathing\n• Good for: Beginners and people wanting to learn the basics of yoga\nMuch like Hatha, Vinyasa covers basic poses and breath-synchronized movement. This variety of Hatha yoga emphasizes on the Sun Salutation, a series of 12 poses where movement is matched to the breath.\n• Purpose: To link the breath with movement and to build lean muscle mass throughout the body\n• Benefits: Helps improve strength and flexibility, tones the abdominal muscles, and reduces the risk of heart disease, high blood pressure, and type 2 diabetes\n• Good for: Beginners and advanced yogis alike seeking to strengthen their bodies\nAshtanga yoga metaphorically focuses on eight limbs. Considered a form of power yoga, Ashtanga is fast-paced and intense with lunges and push-ups.\n• Purpose: To help improve one’s spiritual self\n• Benefits: Relieves stress, improves coordination, and helps with weight loss\n• Good for: Fit people looking to maintain strength and stamina, and those who want to get in touch with their spiritual side\nIyengar covers all eight aspects of Ashtanga yoga and focuses on bodily alignment. Different props like straps, blankets, and blocks are used to assist in strengthening the body. Standing poses are emphasized, and are often held for long periods of time.\n• Purpose: To strengthen and bring the body into alignment\n• Benefits: Helps improve balance, speeds up recovery from an injury, and builds up body strength\n• Good for: Beginners who want to learn the correct alignments in each pose and those with injuries, balance issues, and chronic medical conditions like arthritis\nAlso known as hot yoga, Bikram is practiced in a 95 to 100 degree room. It’s typically a series of 26 poses that allows for a loosening of tight muscles and sweating.\n• Purpose: To flush out toxins and to deeply stretch the muscles\n• Benefits: Speeds up recovery from an injury, enhances flexibility, and cleanses the body\n• Good for: Beginners and advanced yogis alike who want to push themselves and those with physical injuries\nThese are only a few of many styles of yoga.\nAs described in the “Bhagavad-Gita” and the “Yoga Sutra”, the four types of yoga in Hinduism are Jnana yoga, Bhakti yoga, Karma yoga and Raja yoga. Each of these is practiced by yogis as a way of disconnecting from the temporary existence, or “Atman”, and focusing instead upon the eternal consciousness, or “Brahman”.\n1. Jnana Yoga\nThis type of yoga concentrates upon identity through the pursuit of knowledge of the practitioner’s self, “Atman”, versus the eternal essence of the universe, Brahman. The first step of Jnana yoga is education, through which the yogi studies sacred texts such as the “Upanishads” or the “Vedantas”, familiarizing herself with the concepts of Atman and Brahman. Next, the yogi studies what constitutes her temporary identity—or this life—versus her eternal soul. Finally, the practitioner separates her temporary self from her eternal soul. For example, rather than thinking “I,” the yogi thinks in the third person, “her”.\nBhakti yoga focuses upon the yogi’s devotion of a particular Hindu god or goddess of his choosing. For example, a practitioner may choose to follow Ganesh, the Hindu elephant god of wisdom and education . The yogi then devotes his whole self to this god, much like a devout Christian dedicates his life to following Jesus. The practitioner may present gifts to Ganesh at a Hindu temple, chant his name throughout the day or focus on ways Ganesh influences his day-to-day living.\nPractitioners of karma yoga attempt to end the cycle of karma, or the result of accruing good and bad deeds throughout one’s life. Each of these deeds influences the outcome of the yogi’s next life. With karma yoga, the practitioner seeks to end the cycle of death and rebirth. To achieve this, the yogi separates her temporary self from her eternal self, as in Jnana yoga, but instead spends her life in devotion to a chosen god or goddess, as in Bhakti yoga. According to the Philosophy Department at Lander University, “Every act done without thought of self diminishes self-centeredness and brings one closer to the divine.”\nThe final version of Hindu yoga, Raja yoga, constitutes meditation on and the removal of the practitioner’s consciousness of the temporary self, and instead focuses upon awareness of the eternal universe. This differs from Jnana yoga in that it prioritizes meditation over learning. Through Raja yoga, the practitioner shifts the mind completely from outside distractions as well as bodily influences such as breathing or heartbeat. Without interference, the yogi devotes his concentration fully on a higher realm of consciousness and the unity of Atman and Brahman.\nBenefits of Yoga\nStress relief: The practice of yoga is well-demonstrated to reduce the physical effects of stress on the body. The body responds to stress through a fight-or-flight response, which is a combination of the sympathetic nervous system and hormonal pathways activating, releasing cortisol – the stress hormone – from the adrenal glands. Cortisol is often used to measure the stress response. Yoga practice has been demonstrated to reduce the levels of cortisol. Most yoga classes end with savasana, a relaxation pose, which further reduces the experience of stress.\nPain relief: Yoga can ease pain. Studies have shown that practicing yoga asanas (postures), meditation or a combination of the two, reduced pain for people with conditions such as cancer, multiple sclerosis, auto-immune diseases and hypertension as well as arthritis, back and neck pain and other chronic conditions.\nBetter breathing: Yoga includes breathing practices known as pranayama, which can be effective for reducing our stress response, improving lung function and encouraging relaxation. Many pranayamas emphasize slowing down and deepening the breath, which activates the body’s parasympathetic system, or relaxation response. By changing our pattern of breathing, we can significantly affect our body’s experience of and response to stress. This may be one of the most profound lessons we can learn from our yoga practice.\nFlexibility: Yoga can improve flexibility and mobility and increase range of motion. Over time, the ligaments, tendons and muscles lengthen, increasing elasticity.\nIncreased strength: Yoga asanas use every muscle in the body, increasing strength literally from head to toe. A regular yoga practice can also relieve muscular tension throughout the whole body.\nWeight management: While most of the evidence for the effects of yoga on weight loss is anecdotal or experiential, yoga teachers, students and practitioners across the country find that yoga helps to support weight loss. Many teachers specialize in yoga programs to promote weight management and find that even gentle yoga practices help support weight loss. People do not have to practice the most vigorous forms of yoga to lose weight. Yoga encourages development of a positive self-image, as more attention is paid to nutrition and the body as a whole. A study from the Journal of Alternative Therapies in Health and Medicine found that regular yoga practice was associated with less age-related weight gain. The lifestyle study of 15,500 adults in their 50’s covered 10 years of participants’ weight history, physical activity, medical history and diet.\nImproved circulation: Yoga helps to improve circulation by efficiently moving oxygenated blood to the body’s cells.\nCardiovascular conditioning: Even a gentle yoga practice can provide cardiovascular benefits by lowering resting heart rate, increasing endurance and improving oxygen uptake during exercise.\nPresence: Yoga connects us with the present moment. The more we practice, the more aware we become of our surroundings and the world around us. It opens the way to improved concentration, coordination, reaction time and memory.\nInner peace: The meditative effects of a consistent yoga practice help many cultivate inner peace and calm.\nPitta Type People with a pitta dosha display an inherent fire/agni elemental character. They are…\nII. Niyama (Personal Observances)Niyama means “rules” or “laws.” These are the rules prescribed for personal…\nExample of Vata increasing Lifestyle and Foods So if we engage in either lifestyles or…","Yoga Sutras of Patanjali: The 8 Limbs of Yoga Explained\nThe Yoga Sutras of Patanjali are one of contemporary yoga’s favourite sources of inspiration and guidance on how to live a balanced and ethical life both on and off the mat. While the complete Yoga Sutras (written sometime in the first four centuries CE) consists of 195 aphorisms that yoga scholar David Gordon White calls “a Theory of Everything,” most of modern yoga’s attention is focused on the 31 verses that describe the ‘eight limbs’ of yoga, which form a practical guide on the subject of how to attain liberation from suffering. A study of the history of the Yoga Sutras reveals that much of our understanding of this ancient work has been filtered through numerous commentaries on the original verses. Our version of the eight limbs acknowledges the context of their creation and then finds ways to apply them in contemporary life.\nBarbara Stoler Miller’s Yoga: Discipline of Freedom: The Yoga Sutra Attributed to Patanjali is the translation and commentary upon which our interpretations are based.\nWhat are the 8 Limbs of Yoga?\n1. Yama (Restraints)\nThe yamas are five ethical precepts that outline a code of conduct that should be observed when interacting with the world around us. They offer guidance on how to act toward others. They are:\nAhimsa probably had a very straightforward meaning to the original audience of the Yoga Sutras and its interdiction against violence is one that is, unfortunately, still very relevant today. In addition, some contemporary yogis interpret ahimsa as a directive toward a vegan diet on the basis that ‘all living beings’ are entitled to be treated with kindness and non-violence.\nTelling the truth is a moral baseline we can probably all get behind and it’s certainly one that’s not outdated. In fact, in the age of institutionalized lying when ‘alternative facts’ (aka lies) are condoned in the most public sectors of society, it is more important than ever to speak the truth and support others who do so.\nIn Patanjali’s day, this was undoubtedly primarily an injunction against taking someone else’s property. While that continues to be good advice (not to mention the law), there are now so many more ways to steal, some of which may not be as obvious. Intellectual property, logos, pictures from the internet: whatever it is that doesn’t belong to you, leave it be. Originality is certainly a good choice for the modern yogi wishing to practice asteya.\nBrahmacharya is probably the yama that requires the most massaging to fit into a contemporary yogi’s lifestyle. Yes, it’s highly likely that the original intent was a total prohibition on sexual activity. Yoga certainly wouldn’t be the first school of thought to promote celibacy for its practitioners. Does that mean that’s how we have to practice it today? Fidelity, constancy, and having honest open relationships with our partners work as alternatives for today’s yogi householders.\nNow, here’s one that (unfortunately) really stands the test of time, no modern filter necessary. Coveting what other people have, jealousy, envy, and greed are all words for the green-eyed monster that has apparently been with us since the beginning. It’s a tough one to get past. One thing that can help is to name the sensation when it arises so that we’re aware that it’s happening and are then able to realize that we don’t have to become attached to it.\n2. Niyama (Observances)\nIf the yamas are outward looking toward society, then the niyamas are inward practices to improve the self. They are:\nPurification of the body and mind are specified in the Yoga Sutras as a necessary step in detaching from the physical world in preparation for meditation. For us, this might mean identifying and releasing thought patterns that have the ability to distract us from our purposes. If we can clear away thoughts that dwell on negativity or meanness toward ourselves or others then there’s less clutter up there when it comes time for inner focus.\nContentment is a real challenge for many people so it’s well worth examining why it’s so damn hard to feel happy with ourselves. The culture of always wanting more, of status, of constant striving to out-do is so pervasive that it actually takes a bit of effort to realise that it’s not compulsory. Existing in a state of constant dissatisfaction and comparison isn’t the only way. A practice of expressing gratitude can help us feel better about the good things we do (already) have in our lives.\nOne of the translations of tapas is heat, so it is often interpreted as encouraging practices that stoke our inner fire. Miller explains that asceticism was though to produce the heat of tapas. Purification through self-discipline is described in Patanjali’s work. In contemporary yoga, tapas might be observed through the daily practice of postures or meditation which require self-control to maintain.\nSvadhyaya is sometimes translated as self-study, which implies that it means introspection, however, that doesn’t seem to be the original intent. Rather, it meant the study, memorization, and repetition of sacred prayers and mantras, which was and continues to be a common practice in Hinduism. In modern times, we may choose to interpret this as an exhortation to be diligent students of the world, whether through formal or personal education.\nIshvara Pranidhana (Dedication to God/Master)\nThis can be a tricky one since many modern practitioners bridle at the suggestion that God is a prescribed part of our practice. It’s interesting to note that the meaning of Ishvara in the original text is also open to interpretation. It could have meant a master, a teacher, or an unspecified god. Submission to a teacher is in line with the guru-student relationship that was an established tradition within yoga in India. However, surrender to a guru doesn’t sit that well with many Western students. For our purposes, we can perhaps think of it as a necessity to acknowledge that yoga is a spiritual practice. It affects the whole person, whose constituent parts are mind, body, and spirit.\n3. Asana (Posture)\nWhile it might seem like we’re getting onto more familiar ground here, asana also had a very different meaning in its original context. While we now use this term to refer to any part of a postural practice (all yoga poses), it’s original meaning was simply a comfortable seat. Patanjali’s work has no other asana instruction other than the necessity of finding a posture in which to engage in the practices of pranayama and meditation (see below). In terms of the eight-limbed path, it seems that once we have established that we are right with the world and with ourselves, we can turn our attention to the business of calming and focusing the mind. Of course, asana is now quite often the point of entry for people into yoga. Liforme yoga mats support the pursuit of asana by incorporating useful alignment lines.\n4. Pranayama (Breath Control)\nOn the subject of breath control, Patanjali instructs that the practitioner should regulate the inhalations, exhalations, and retentions of the breath in a cyclical manner. All other breathing exercises we now practice came from sources outside of the Yoga Sutras. Since the eight limbs are concerned with preparing for meditation, any breath that is centering and brings us in contact with the present moment helps ready the body and mind to turn the focus inward.\n5. Pratyahara (Withdrawal of the Senses)\nIsolating consciousness from the distractions offered by engagement with the senses is the final physical preparation for the meditation practices outlined in the final three limbs. This can be in itself a form of what we would call mindfulness in which sensory input such as sounds, sights, or smells are noticed as external and then allowed to pass without capturing our attention.\n6. Dharana (Concentration)\nDharana is the first stage in the inner journey toward freedom from suffering. During this type of meditation, practitioners concentrate all of their attention on a single point of focus such as the navel or on an image in their mind.\n7. Dhyana (Meditation)\nIn this stage, the practitioner meditates on a single object of their attention to the exclusion of all others. While we are accustomed to a type of meditation that attempts to clear the mind of all thoughts and images, this doesn’t seem to have been a requisite part of the method described by Patanjali. As long as the attention is focused, the object is not specified.\n8. Samadhi (Pure Contemplation)\nWhen dhyana is achieved, the practitioner enters a state of samadhi in which they merge with the object of their meditation. Although this has been interpreted to mean union with the divine or with the entire universe, Patanjali’s explanation does not go this far.\nBeyond the 8 Limbs\nThere is actually a further step in attaining liberation from suffering in Patanjali that doesn’t make it into most contemporary teaching. This state is called nirbija-samadhi, which Miller translates as seedless contemplation, in which the seeds are thoughts that beget other thoughts. While we might logically conclude that this is the cosmic union we associate with the culmination of the eight limbs, David Gordon White explains that the goal of the Yoga of Patanjali is actually the absolute separation of the human spirit from the matter of the world. When this happens, the spirit has the ability to expand infinitely and is capable of what we would call supernatural acts.\nThe application of the eight limbs has transformed tremendously from the time of their recording by Patanjali to our present moment. When these contexts are so radically different, it wouldn’t make sense to expect the limbs to fit seamlessly into contemporary yoga. However, this doesn’t mean that they have no place at all in our canon. There are many lessons about how to treat others and ourselves, as well as the value of deep contemplation that are still relevant and are a profound complement to today’s physical practices, even a millennium and a half after their recording.\nMiller, Barbara Stoler. Yoga: Discipline of Freedom: The Yoga Sutra Attributed to Patanjali. University of California Press, 1996.\nWhite, David Gordon. The Yoga Sutra of Patanjali: A Biography. Princeton University Press, 2014."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:f926f423-0822-4099-adb0-411f429c9413>","<urn:uuid:ab176410-e6ed-48f0-bad4-0401f032b232>"],"error":null}
{"question":"Could you compare the business models of Gyo Greens and MiniCrops in terms of their customer base and sales channels?","answer":"Gyo Greens sells to approximately 30 local restaurants, participates in a weekly farmers' market, and opens to the public one Tuesday per week for direct sales. MiniCrops, on the other hand, produces microgreens for over 100 food businesses across London, ranging from cafes to high-end restaurants, and also sells directly to the public through their Borough Market stall and website.","context":["Avid Gardener’s Aquaponics Hobby Evolves into Commercial and Educational Enterprise\nAugust 23, 2016 | Vanessa Caceres\nAquaponics farms often amaze visitors with the symbiotic connection between aquaculture and hydroponics that results in picture-perfect produce. Yet many aquaponics operations focus solely on training and education. Gyo Greens in Ponte Vedra Beach, Florida, has a focus on both the business and educational realm, to further spread the message about the importance of eating locally and naturally.\nOwner Helga Tan Fellows, who spent much of her career in engineering and manufacturing, began Gyo Greens after traveling frequently for her job and seeing aquaponics operations elsewhere. An avid gardener, she thought aquaponics could be a fun hobby—yet her husband said it would probably be a bigger undertaking than just a hobby.\nThe idea behind Gyo Greens (named for the Japanese word for fish, gyo) began in 2013, and the farm opened in 2014. The farm sits on an acre of land, and the aquaponics operation is in a 3,000-square-foot greenhouse with about 800 tilapia and koi fish in tanks. The farm employs two people full-time and three part-time. It also relies on a number of interns and volunteers from the University of North Florida in Jacksonville.\nSince its beginning, Gyo Greens has had a close relationship with local chefs, and the farm now sells produce to 30 or so restaurants in the area. Chefs sometimes rely on what’s grown by Fellows and staff—one item that’s been a hit is edible flowers. “They can be hard for chefs to find, and even when they’re packaged, they don’t always look nice,” Fellows says. Gyo Green’s ability to grow fresh, vibrant edible flowers have made them a popular addition to local plates. Other times, chefs request certain items; because of Gyo Green’s smaller size and quick turnaround time of a couple of weeks, it can usually help meet those requests. Pea shoots, red vein sorrel, and microgreens are chef-chosen items that Gyo Greens often grows.\nSometimes, Gyo Greens staff will grow other items for their own enjoyment, such as tomatoes, and they’ll share the bounty. But that also means they have to let buyers know not to expect those items regularly.\nThere’s also the education hat that the folks at Gyo Greens must wear. Growing up around parents who were university professors, the farm’s educational role is important to Fellows. The farm regularly hosts students—they’ve had more than 800 visit so far and are on track for 1,000 students by year’s end—and local residents who are curious to learn how an aquaponics farm works. Often, it’s a completely new concept. Other times, visitors may be aware of hydroponics but not aquaponics.\nSome children are even in awe just to see where food comes from in the first place, beyond the store shelves. “Some students don’t even believe it,” she says. Yet then they go home and encourage their parents to visit. That awe and enthusiasm helps to spread the word about why aquaponics is, increasingly, an environmentally sustainable way to grow healthy food around the globe, Fellows says.\nGyo Greens also participates in a weekly farmers’ market held at a nearby community center, and the farm opens to the public one Tuesday a week during most months of the year. Residents can come by and pick their own greens “live.”\nThe farm work is not without its challenges; because Gyo Greens grows seasonally in a relatively small space, it is limited by what or how much can be grown. “If Mother Nature is not kind, I don’t have production,” Fellows says. Sometimes, certain items may not have grown as planned, and Gyo Greens needs to inform the buyer.\nGetting produce delivered in a timely fashion is also tricky, but Fellows says that is a challenge that all farm businesses face.\nFellows says that Gyo Greens breaks even financially, and any amount of leftover money is invested right back into the farm. “You have to be cautious to do this. You need all of the logistics in place,” Fellows says. She believes that the farm’s dual role as an education center and a for-profit business—versus just a training or education facility—means it’s extra important to keep everything working efficiently.\nWith an eye on grants, Fellows is considering in the future use of an electric car for deliveries that would sport the Gyo Greens logo; she’s also looking into grants to support the use of solar panels on the farm.\nFellows is passionate about her commitment to sharing with others why it’s important to eat healthy. “We grow, sell, and teach. We want to continue that and go beyond it,” she says.","BY NICK MACMAHON | 25 MAY 2019\nMiniCrops is a ‘vertical farm’, in Deptford, South London, that grows over 80 types of microgreens in a controlled environment using LED lights and a hydroponic growing system. Microgreens are edible plants that are harvested at an early stage of growth. Plants are considered microgreens once they have grown at least two sets of true leaves and are about 2 inches high. Each type of plant grows differently, but generally, they are grown for about 2 weeks before they are ready to be harvested.\nYou probably have come across microgreens before, in fine dining restaurants, delicately placed on top of a dish, functioning for mostly aesthetic purposes. But, as Marie, who runs MiniCrops with her husband Jamie, tells me, these little leaves are as flavourful as their mature counterparts and also packed full of nutritional benefit. Their aim is for microgreens to be valued for more than just their visual appeal. MiniCrops is one arm of Vertical Future, Jamie and Marie’s start-up that is focussed on developing technology to create more sustainable food systems in urban environments. They have a vision for the future where we can produce more food locally and not rely so heavily on traditional farming practices, cutting down on growing costs, transport costs and the environmental costs of intensive farming. And produce can be grown all year round. With climate change and depleting soil health causing strife for the British farming industry, this could be a potential way to offset the food production burden while we try to combat our agricultural and environmental woes.\nThe ‘vertical farm’ in Deptford consists of a couple of rooms with big shelves of plants at different stages of growth, all bathed in an intense purple light from LED lights. The plants are not grown in a traditional soil medium but are instead grown using a hydroponic system. Your first thoughts at the idea of ‘hydroponics’ may draw scepticism, the term can often conjure ideas of dodgy marijuana growing operations. But the reality is far less shady and much more wholesome. When plants are grown in soil, they grow in part by absorbing nutrients from the soil through their roots, usually, these nutrients come from decaying organic matter in the soil (like compost) or from the addition of nutrients through fertilisers. The soil is just a medium that holds the nutrients and the plants in place. Plants can be grown in many different mediums. As long as they can receive adequate nutrients and light, they will happily grow. With hydroponic growing systems, the roots of the plant sit in a bath of flowing water and nutrients are added to the water when required. This system means the growing process is much easier to control, resulting in more efficient growing, healthier plants and a higher yield from harvest.\nCurrently, MiniCrops are able to produce microgreens for over 100 food businesses all over London, from cafes to high-end restaurants, as well as selling to the public from their stall in Borough Market.\nThey have a long list of microgreens for sale, including standard herbs like coriander, basil, parsley, etc, as well as edible flowers and lesser-known leaves from plants like mustard, radish and broccoli. Jamie and Marie, are continually trialling new and different microgreens, some are successful and some, not so successful.\nIf you're interested in trying some microgreens you can purchase from their website. They offer a sampling selection of their range if you want to try the different microgreens on offer."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:92728fcd-bfb5-43d0-b430-9f6ff246101e>","<urn:uuid:97f02a8e-ed3f-431b-b7df-2febfeeaf17f>"],"error":null}
{"question":"What role do both fungi and bison play in maintaining healthy soil ecosystems?","answer":"Both fungi and bison are crucial for maintaining healthy soil ecosystems, but in different ways. Fungi, through mycorrhizal relationships, form vast networks of thin filaments (hyphae) that help plants absorb water and nutrients, while receiving carbohydrates from plants in return. About 90% of plant species engage in these beneficial relationships. Bison, on the other hand, contribute to soil health through their grazing, trampling, and movement patterns. They till the soil with their hooves, work dung into the soil, and help maintain biological diversity. This activity is crucial for building soil, deepening plant roots, and enabling permanent carbon sequestration. Both organisms are essential for creating and maintaining healthy, productive soil systems.","context":["All orchids, including this Colorado native orchid, Coralroot, Corrallorhiza maculata, are completely dependent on on mycorrhizal fungi to begin their life cycle and and this reliance continues to varying degrees throughout their life. Photo credit: SPD\nUnseen, unheard, and certainly under-appreciated, beneath the ground we walk on lies a living world that is critical to the health and the future of both plants and people. This underground world is not just dirt. It’s a complex ecosystem at work feeding plants and sequestering four more times the carbon than all of our terrestrial plants, even when rainforests are included. Healthy soil inhibits erosion and produces plant growth that is more robust, and importantly, more nutritious. We’ve got to stop treating our soil like dirt!\nThis productive ecosystem is made up of non-living elements like minerals and humus (animal and plant parts in all stages of decomposition) as well bacteria, fungi, and\nliving creatures, tiny ones you’ve heard of like springtails, centipedes, mites, and insect larvae; and tiny ones you haven’t, like, symphylids and diplurans, and then the larger ones like moles, salamanders, ants, and toads, all of them contributing to soil health.\nOne gram (about 1/5 teaspoon) of healthy, non-poisoned soil could contain one hundred million bacteria, one million actinomycetes, and one hundred thousand fungi; if strung together, their filaments or hyphae would measure about 16 feet (5 meters) in length.\nClimate-Wise Landscaping, Reed and Stibolt\nPlant roots in a mycorrhizal relationship. Photo courtesy Wilhelm Zimmerling PAR, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons\nNew technologies have given researchers expanded understanding of how important the fungal relationships called mycorrhizae are in developing healthy, resilient plants. The word ‘mycorrhiza’ comes from the Greek words ‘mukès’ (fungus), and ‘rhiza’ (roots). So we now have fungus roots, which about sums it up. Mycorrhiza is a network of fungi that form an association with the roots of a plant. About 90% of all plants species are engaged in this relationship. The plant benefits from an increased intake of water, minerals, and nutrients from mycorrhiza, and the fungus, which can’t photosynthesize under there, gains carbohydrates from the plant. The word mycorrhiza is used to refer at different times to both the relationship itself, and to the group of fungi that are involved. The plural form is ‘mycorrhizae.’\nHere in CO we might be especially interested in the ways mycorrhizae assist plants in acquiring more water and becoming more drought resistant. Because mycorrhizal hyphae, (threadlike filaments) are thinner\nthan plant roots, they are able to absorb minute drops of water which are clinging more tightly to soil particles under high pressure underground. The collective group of thin hyphae, known as the mycelium, gives each plant a vastly increased area of contact with the soil from which to gain access to both water and nutrients. Mycorrhizae have a vast array of methods for collecting, changing, and exchanging food – another fascinating study to explore.\nSoil Health Is Reaching the General Media\nTwo well-known, general-interest publications have raised the question of soil viability recently. Time magazine’s first issue in June devotes an article to what they call ‘soil extinction,’ The Future of Our Planet Rests In the Quality of Our Soil. George Monbiot, writing for The Guardian in May, gives us The Secret World Beneath Our Feet and claims that soil is the world’s most neglected ecosystem. Both articles raise the important connection between the collective health of the world’s soil and the problem of feeding the world without devouring it. It’s now clear that we must begin to preserve and foster this hidden life form, soil, instead of depleting it in the ways that many of our farming and forestry practices are currently doing. Detrimental practices such as:\n- Over-fertilization, especially of nitrogen\n- Disturbance, especially plowing\n- Landscape-wide use of pesticides and herbicides\n- Compaction and erosion\nnegatively affect the underground food web, destroying rather than promoting the health of the soil we depend on to grow abundant, healthy, and nutritious plants, and to store carbon below ground where it helps plants instead of harming people.\nWhat Does This Mean for Us?\nWhat can we do, each of us, as gardeners, landscape managers, voters, and community influencers?\nFirst and foremost: knowledge is power. Understanding the issues gives us the means of improving practices to promote soil health and of explaining to others why soil health is important.\nThe Colorado Department of Agriculture has developed helpful guidelines based on the STAR program, originally conceived of to improve methods of commercial farming and livestock operations. However, the five basic principles are excellent guidelines for all gardeners, and interestingly, they are also ones recommended in the two articles referenced above. STAR’s Five Prrinciples of Soil Health:\n- Soil Armor (controlling wind and water erosion)\n- Minimize Soil Disturbance\n- Plant Diversity\n- Continual Live Plant/Root\n- Livestock Integration\nFunds will be made available this year, including some grants, for Colorado’s “Agricultural Soil Health Program.”\nMany home gardeners are interested in boosting soil health with additives. The Colorado Extension mentions that bagged and bulked purchased soil amendments are not regulated and many are high in salts, including manure and manure-based composts, which should be used with caution. Plant-based composts are typically higher in price but more effective in soil improvement. The Extenstion Service will also test your soil and give specific recommeendations.\nThere is another good source of information for home gardeners in a book recommended by Doug Tallamy this way:\nRead this book carefully. Everything you need to know help heal our relationship with the planet earth and empower you to make a much-needed difference is within these pages.\nSoil sequesters four more times the carbon than all of terrestrial plants!\nThis a highly readable, visually appealing, and practical guide for anyone landscaping in containers, condos, or large gardens. With sections on soil; lawn; trees and shrubs; materials for hardscape; design and more, information is both accessible and Climate-Wise. Buy it from the authors ~\nClimate-Wise Landscaping, Practical Actions for a Sustainable Future; Reed and Stibolt\nWe read everyday about so many things that seem to be out of our ability to control. But we CAN help the underground food web in the places we walk and influence. Soil, it’s so much more than dirt!\nColorado Native Plant Society","“The Incredible Shrinking Bison”  discussed how the increase of CO2 emissions has contributed to the rise of the Great Plains’ average temperature, and how the resulting warming trend has affected the bison. The bison, on the other hand, as a key species to the survival of the plains, can also have an indirect, mitigating effect on the CO2 levels in the atmosphere.\nThe predominate conversation around atmospheric CO2 has centered on the elimination of CO2 production. There is, however, another conversation underway—one involving the removal of CO2 from the atmosphere. The process of capturing and storing atmospheric carbon dioxide is known as carbon sequestration. It is one method of reducing the amount of carbon dioxide in the atmosphere, and consists of two types: geologic and biologic. Geologic carbon sequestration involves the storing of carbon dioxide in underground geologic formations. The CO2 is usually pressurized until it becomes a liquid, and then it is injected into porous rock formations in geologic basins .\nBiologic carbon sequestration refers to storage of atmospheric carbon in vegetation, soils, woody products, and aquatic environments. For example, by encouraging the growth of plants—particularly larger plants like trees—advocates of biologic sequestration hope to remove CO2 from the atmosphere. Within biologic carbon sequestration there are several means by which CO2 is removed from the atmosphere. These include peatland, wetland, forestry, agriculture, carbon farming, deep soil, and ocean-related. But of all the terrestrial (as opposed to aquatic) methods, the forests receive the lion’s share of the world’s attention. Forgotten are the grasslands which also harbor much of the wetlands. For North America the grasslands of the Great Plains and prairies, which occupy approximately one-third of the continent, are critical to carbon sequestration. And key to the grasslands’ vitality is the North American Bison .\nGrasslands quickly process carbon from the atmosphere and store this carbon in the root structures, which extend 8 to 15 feet into the ground, which can store 22.5 million tons of carbon. These roots can hold the carbon for decades, and process 1.7 million tons of carbon per acre to the soil annually. This storage accumulates over time and moves carbon from the atmosphere to the ground continuously creating massive carbon deposits over the course of centuries. Prairies have the ability to store as much carbon below the ground as forests can store above the ground. When carbon is stored below ground it remains locked there and unable to enter the atmosphere. Compared to forests, grasslands are more reliable. In times of drought and forest fires, the carbon stored in the wood and leaves returns to the atmosphere. During a grass fire, however, carbon is not released since it is stored in the roots underground .\nThough the Great Plains and prairies occupy a vast swath of the North American continent, this does not translate into a great CO2 scrubber. The conversion of this ecosystem into cropland has significantly reduced the ability of this region to sequester carbon . Compared to native or natural vegetation, cropland soils are depleted in soil organic carbon (SOC). When soil is converted from its native state the SOC content in the soil is reduced by approximately 30 to 40% . Further, the crops replacing the native grasses are annuals with comparatively shallow root structures which are less effective in storing carbon and holding soil. With less carbon stored and moved to soil, and increased possibility of soil loss, the effectiveness of the plains and prairies in atmospheric CO2 removal is significantly decreased.\nShort of returning the croplands back to the natural state of the region, there are agricultural methods aimed at sequestering atmospheric carbon into the soil and in crop roots, wood and leaves. These methods are collectively referred to as carbon farming. Besides removing CO2 from the atmosphere, increasing the soil’s carbon content—whether by reverting to the natural condition, or by carbon farming—aids plant growth, increases soil organic matter which improves agricultural yield, improves soil water retention capacity and reduces fertilizer use which is a source of the greenhouse gas nitrous oxide (N2O) .\nCarbon farming or recovering the native perennials, however, is not the complete answer. The ecosystems of the plains and prairies were dependent on the large herds of bison moving over the grasslands. The grazing, trampling and recovery patterns associated with the bison were key in building soil, maintaining biological diversity and deepening plant roots, which are crucial elements in permanent carbon sequestration . The bison not only provided nutrients for plant life, but tilled the soil with their hooves, working up and trampling dung into the soil, enabling plant-life to take hold, flourish and consequently become a significant carbon sink.\nThough sequestration, as used here, is a technical term, the concept is quite familiar. When we hear the word “sequester,” the common association is with juries as in jury trials. When a jury is sequestered, it is removed and kept apart from contact with the public. The purpose is to ensure undue influence on, or tampering with, the deliberations of the jury, and ensure a just verdict. As the jurors file out of the courtroom at the end of the defense’s and prosecution’s final presentations, if the judge has ordered they be sequestered, we see the tangible form of a removal to protect the integrity of the trial by jury justice system considered critical to our legal well-being. The notion of using an act of removal in the protection of our well-being is only part of the meaning of sequestration. What is being removed and where it is being kept are equally important. Originally, “to sequester” meant “…to put in the hands of a trustee…” . In regard to carbon sequestration the trustee is the earth itself, or more specifically, in the context of the bison and the grasslands of North America, it is the Great Plains ecosystem. When we think of ecosystems, we tend to think of the land, the flora and the fauna. Often missing in our consideration is the air above. The bison—a keystone species in regard to the flora and fauna and the land—is a crucial element of the trustee, instrumental in the process of CO2 removal and the mitigation of the warming trend plaguing the Great Plains.\n Schuette, Keith. “The Incredible Shrinking Bison.” November 17, 2020.Bison Witness. Bisonwitness.com\n “What is Carbon Sequestration?” USGS.gov. What is carbon sequestration? (usgs.gov). Retrieved 4/24/21\n Schuette. “Dung Cake and Feces Pie: Yum!” April 26, 2019. Bison Witness. Bisonwitness.com\n Davidson, William, “The Great Plains: America’s Carbon Vault” (2016). Op-Eds from ENSC230 Energy and the Environment: Economics and Policies. 73. https://digitalcommons.unl.edu/ageconugensc/73\n Lavelle, Jocelyn. Soil carbon sequestration to combat climate change—a real solution or just hype? – Sustainability (colostate.edu). Colorado State University—School of Environmental Sustainability. Retrieved 4/30/21.\n 42% of the Great Plains has been converted to cropland, leaving 53% intact. The remaining 5% holds water or has been converted to human use. Understanding Grassland Loss in the Northern Great Plains. 2018. World Wildlife Organization.\n Poeplau, Christopher; Don, Axel (February 1, 2015). “Carbon sequestration in agricultural soils via cultivation of cover crops – A meta-analysis”. Agriculture, Ecosystems & Environment. 200 (Supplement C): 33–41. doi:10.1016/j.agee.2014.10.024.\n “Carbon Farming | Carbon Cycle Institute”. http://www.carboncycle.org. Also, “Carbon Farming: Hope for a Hot Planet – Modern Farmer”. Modern Farmer. 2016-03-25. And Velasquez-Manoff, Moises (2018-04-18). “Can Dirt Save the Earth?. The New York Times. Retrieved 4/30/21.\n Wright, Pam. Bison: The Latest in Carbon Capture Tech.12/24/2017/by Regeneration International. Retrieved 4/30/21.\n Webster’s Unabridged Dictionary of the English Language. 2001. Random House."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:5052c241-604a-4bc7-a221-5934fe32e9fd>","<urn:uuid:44bf5635-90c3-42a9-a623-614aec397f7b>"],"error":null}
{"question":"How do the water retention properties of clay soil compare to those of sandy soil, and which of these soil types is most similar to the Congo River's characteristics in terms of water capacity?","answer":"Clay soil has poor drainage and becomes sticky when wet, while sandy soil is free draining with large particles. When comparing these to the Congo River, clay soil shares more similarities in terms of water capacity, as the Congo River is the second largest river in the world by water discharge, suggesting significant water retention capabilities. The sandy soil's free-draining nature makes it quite different from both clay soil and the Congo River's water-holding characteristics.","context":["Overview of soil types and drought resistant planting\nHere we have some great ideas and information to help you use less tap water in your garden. As always, we welcome your comments and photos and if you have experience or expertise in any of these topics, we could feature your article as a guest author.\nWhen wildlife areas are established they can develop with little need for watering and weeding. Wild flowers can create colour and texture throughout the year if a variety of suitable seeds are planted. This will provide a valuable habitat for insects and birds.\nLeaving some lawn uncut is great for bugs, beetles and foraging birds.\nA pond and a rocky area will attract amphibians and reptiles if you are lucky.\nA pile of old wood is a perfect home for a wide range of insects and will soon establish a web of wildlife activity. Your own mini zoo !\nSend us photos of your wildlife area for inspiration to others in the POWER communities.\nOur project partners in Jerusalem have some inspiring vertical garden examples such as the photograph below. More photos from Jerusalem community gardens can be found here .\nVisit the Jerusalem pages and join their discussions so we can compare great ideas for saving waters in their community gardens. Click here to see their pages or go to https://jerusalem.baseform.com/ to browse their information.\nThis vertical edible garden is a lettuce farm.\nCopyright Steve Keenan\nThe vertical garden below is outside the Timelab, Brusselspoorstraat, Ghent.\nMaking use of waste streams is always a clever way to be sustainable. In the example below, plastic bottles have been used to make a vertical garden.\nPlastic bottles can also be used to build a greenhouse.\nWater Saving behaviour\nTry to water your garden early in the morning or after the sun goes down.\nWater the roots of the plants rather than the foliage.\nUse water saving gel or beads in containers so they do not dry out so quickly.\nConsider a smart flow meter for timing irrigation systems.\nWater butts can collect rainwater and allow you to reuse some of the 85,000 litres that fall on your roof every year.\nSaving rain water for watering plants and washing cars is a great way to save water. Milton Keynes Council will provide some new houses with a free water butt and all MK residents can apply for low cost water butts with a choice of 100 litres or 190 litres.\nClick here , enter your MK postcode, see what is on offer and start saving water as soon as your water butt is installed.\nWater Butts at getcomposting.com\nOther types of water butts are available, a quick web search or visit to the Garden Centre will provide you with many options to suit the style of your house and garden.\nIf you use rain water for cleaning your car, you have the added bonus of no white limescale marks left on your car if you are in a hard water area.\nTell us what other water subjects you would like to see on these POWER Community pages and send us your articles, comments and photos.\nLook forward to hearing from you.\nThe best use of any land is to work with nature and conserve or elaborate on what types of plant are already established. In a garden it is a good idea to plant the right species for the natural growing conditions. This will reduce the need for soil conditioning and intensive watering. Less work with controlling the soil conditions means you have more choices of how you spend your time in your garden.\nThere are several factors to consider when planning a sustainable garden and there is a wealth of information on the web from well established and trusted sources. You will find links to these at the bottom of the page.\nBefore you choose which plants you would like to cultivate, there are a few considerations about what would be suitable for your patch of land.\nAs always on these pages, let us know if you would like to see more detailed information on any of the subjects and get involved by sharing your knowledge and experience. It would be great to see photos of your gardens too.\nA good starting point is to assess your soil type. Finding out the water retention properties will help you choose which plants will thrive in your garden.\nCharacteristics of soil fall broadly into six categories:\nChalk: Alkaline, free draining, usually over chalk or limestone bedrock, soil is often stony and poor in some nutrients.\nClay: Small particles, hard when dry, sticky and lumpy when wet, poor drainage, heavy to cultivate and reasonably high in nutrients.\nLoam: Good for most plants, drains well and holds moisture, easy to cultivate and high nutrient content.\nPeat: Acidic, retains water, dark and high organic content, poor nutrient content.\nSand: Often acidic, large particles so feels gritty, free draining, easy to cultivate and often poor in nutrients.\nSilt: Heavy soil, drains well but holds moisture, easy to cultivate, reasonably rich in nutrients.\nHaving a good idea of which type of soil you have is a good first step. Next stage of your research will be finding out if your soil is alkaline or acidic.\nSoils in the UK are usually between pH 4.0 and 8.5. Acidic soils are between pH 1 and 7, alkaline are between 7 and 14. A pH of 6.5 to 7 is good for most plants,\nUsually you will have acidic soil if you are in a soft water area and alkaline soil if you are in a hard water area.\nA soil test kit will determine the pH in a few simple steps. Kits are not expensive and easy find. You could also have a look round and see what plants are thriving there already.\nIt is expensive to change the pH of soil on a large scale but it is possible to raise the pH by adding lime. Lowering pH is not practical, it is best to grow plants in containers if soil is too acidic for the plants you would like to cultivate.\nMore on choosing plants will follow shortly.\nThe Royal Horticultural Society (RHS) website has advice and an extensive list of trees, shrubs and flowers that are tolerant of drought conditions.\nThese are their top five:\nAbelia × grandiflora\nBuxus sempervirens 'Elegantissima' (v)\nCalifornian lilac 'Gloire de Versailles'\nspurge 'John Tomlinson'\nYou may view the full list of drought tolerant plants from the RHS here\nA rain garden is a good option for reducing your water consumption and will save time with the watering can or hosepipe.\nThe idea of rain gardens is not new but is becoming a popular option for mindful garden remodelling.\nRain gardens are low maintenance once the groundwork has been laid. The ground needs to be lower than the surrounding landscape, have free draining and absorbent soil and plants that can tolerate occasional waterlogging.\nRain garden in Leicester\nSedges and grasses such as Carex and Mischanthus will thrive in your rain garden and provide insects with overwinter protection. Planting flowers that attract bees, butterflies and other pollinators will contribute to your positive impact on the environment. Well researched and creative planting could provide you with colourful displays in every season.\nThere are many ideas for where and how to build a rain garden along with other ideas on rainwater harvesting at the rain garden network site where there is also advice on managing school and community gardens.\nA rain garden alliance has been created in the USA, click here for a look at their website.\nWould you be interested in creating a water garden alliance here on the POWER platform? This would be a space where we can share ideas, advice, photographs and experience\nKeeping your garden drought resistant is good for wildlife and the balance of natural biological systems. Hedgehogs are in decline nationally so an added bonus of a rain garden is the provision of a habitat they can visit and keep the slug and snail populations in check.\nSign in to the POWER water communities today, make a comment and start to explore how we can create our own water garden alliance.\n(Images, unless otherwise stated https://www.pexels.com/search/garden%20/)\nHave viewed this issue\nFollow this issue\nShares of this issue","Interested to know about fun facts about rivers? Of all the bodies of water in the world, few are as impressive as the great rivers. Crucial to the development of some of the world’s most noteworthy cities, these rivers are the thoroughfares from which much of civilization was built. Here is a list of the ten longest and most important rivers in the world.\nThe Amur River is the tenth longest river in the world. It originates from western Manchuria and flows eastward to form the border between China and Russia. From there it courses to the southwest in a 400 kilometer arc.\nIn terms of water discharged, the Congo is the second largest river in the world. Located in Africa, the Congo River also has the distinction of being the world’s deepest rivers, measuring 220 meters at its deepest point. Its length has been measured at more than 4,700 kilometers.\nLocated in the southern section of Central South America, Parana River runs through Brazil, Paraguay and Argentina. Its length has been measured at over 4,800 km. One of the most important rivers in the region, Parana River is rivaled only by the Amazon River in terms of sheer length.\nOb River is located in the western Siberian region of Russia. Like the Yenisei, it is one of the three major rivers in Siberia and flows into the Arctic. The river is also noteworthy for having the longest estuary in the world as its gulf.\nThe Yellow River is second only to the Yangtze as the longest river in China. it is also the world’s sixth-longest river with a length that has been estimated at more than 5,464 km. The Yellow River starts out at the Bayan Har Mountain range of Qinghai Province in the western section of the country, and it meanders through nine Chinese provinces before emptying into the Bohai Sea.\nOf all the river systems that flow into the Arctic, the Yenisei River has the distinction of being the largest. One of the three Siberian Rivers that wind into the Arctic Ocean, the Yenisei River starts out in Mongolia and courses throughout much of the central portion of Siberia.\nThe Mississippi is the main river of North America’s largest river system. Its entire length is located in the United States, beginning in the northern section of Minnesota and winding south to the Mississippi River Delta. Its length has been measured at more than 6,275 kilometers.\nThe Yangtze River has the distinction of being Asia’s longest river. It is also the world’s third longest river, with an impressive length of more than 6,300 kilometers. The Yangtze starts out from the Qinghai-Tiber glaciers and empties out into the East China Sea at Shanghai province.\nThe largest river in the world in terms of volume of water discharged is the Amazon. It is also the world’s second longest river at 6,400 kilometers, and its drainage basin spanning a vast expanse of 7,050,000 square kilometers is the largest in the world.\nThe Nile is the longest river in the world, with a length of about 6,650 kilometers. In recent years, the status of the Nile as the world’s longest river has been the subject of contention, due to issues with regard to the true source of the Amazon and therefore, its actual length. At present however, the Nile is still widely considered to be the longest river in the world."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:237f6361-bb3d-40ed-9e36-7ebc64f36a7a>","<urn:uuid:b1a574e8-ffd0-4d0b-b0b4-90e49dfd1a0f>"],"error":null}
{"question":"What is the purpose of break-even analysis in financial management?","answer":"Break-even analysis uses information from income statement and cash flow statements to determine how much sales must be achieved to cover all fixed and variable expenses. It helps in projecting when you'll make a profit, deciding product pricing, and setting sales goals.","context":["Finance is an umbrella term for the motion of money from one company to another (or individual) to pay for goods or providers and repaid with curiosity. Past Investing is a vegan and cruelty-free funding platform providing entry to funding merchandise which adhere to vegan rules and speed up our transition to a kinder, cleaner and healthier world. Find out how managers combine interest rates and projected interest rate fluctuations when making monetary choices that may embrace additional company debt. Additional, you will be taught the determinants of bond yields, and clean vs. soiled prices. Finance includes managing the firm’s money. The monetary manager must resolve how a lot money is needed and when, how greatest to make use of the obtainable funds, and methods to get the required financing. The financial manager’s responsibilities include financial planning, investing (spending money), and financing (elevating cash). Maximizing the worth of the agency is the primary objective of the monetary supervisor, whose decisions typically have long-time period results.\nGetting started is straightforward, whether or not you have already got an account with us or are new to HL. Should you’re new you’ll be able to open an account first and choose your funds later. Or, you can start by building your fund portfolio after which opening an account to carry it in. Make investments from as little as Â£25 a month or with a Â£one hundred lump sum. So you’ve got decided to begin investing Congratulations! Whether you are simply starting out by yourself, in the middle of your profession, approaching retirement age, or within the midst of your golden years, this means you’ve begun to consider your financial future, and how you may prudently manage your capital so that it can work for you. With accumulation items revenue is retained within the fund and reinvested, growing the worth of the models. Generally, for buyers who wish to reinvest earnings, accumulation items provide a more handy and cost-efficient way of doing so.\nFinancial controls exist to help make sure that monetary transactions are recorded and maintained precisely, and that personnel don’t unintentionally (or deliberately) corrupt the monetary administration system. Controls vary from very primary (eg, using a checkbook and cash register tapes to extra advanced, eg, yearly monetary audits). The break-even evaluation uses info from the income statement and money circulation statements to compute how much sales a lot be achieved in order to pay for all your mounted and variable expenses. Mounted bills are expenses that you simply’d have whatever the stage of gross sales of products or services (eg, sales, hire, insurance coverage, upkeep, and so on.). Variable bills are incurred according to the level of gross sales of services or products (eg, gross sales commissions, gross sales tax, freight to ship merchandise, etc.). Break-even evaluation can help you when projecting while you’ll make a profit, deciding how a lot to charge for a product, setting a sales purpose, and so forth.\nTheÂ Swedish National Financial Management Authority develops efficient financial management for central authorities companies, and analyses and makes forecasts of central authorities finances. The ESV is a central administrative company under the Ministry of Finance. If you are inexperienced in monetary administration, then it is best to get an accountant initially to help you set up your bookkeeping system, generate monetary statements and do some basic monetary evaluation. However do not rely on an accountant to utterly take over your responsibility for financial administration! The accountant will help you set up a bookkeeping system, generate financial statements and analyze them, but it’s important to understand financial knowledge to the extent you can perceive the effects of your management choices, the present situation of your corporation and how choices will effect the financial condition of what you are promoting in the future.\nStep one is to know the place you at the moment are and seeing how you got there. Keep observe of all bills for at the very least a month and put them into categories. The place you spend, especially those little cash purchases, generally is a surprise. Seeing the place you spend and on what makes it much easier to decide on the place to cut again. Sit down with all the household and talk about where spending will be minimize. Focus on your weak spot shopping for, impulse buys, or must have newest toys. Be honest. This is not a time for accusation, it is a time for mapping your family’s future happiness. Set a funds and see the way it goes for a month, again monitoring every buy. No person gets it right the primary time. You will in all probability discover extra methods of saving, but just as typically folks go overboard and funds too tight the primary time around. A great price range takes months. Take the time, it’s price it each now and will certainly be value it sooner or later."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:e348afda-4866-43db-b39e-f9aa0e33e49b>"],"error":null}
{"question":"Why was it advisable to use separate process behavior charts for each production line when monitoring sand temperature?","answer":"It was advisable to use separate charts because they were two different processes - while both lines had similar amounts of variation, Line 2's average temperature was approximately 8.5 degrees (about 1 standard deviation) lower than Line 1.","context":["Brain Teasers: Is Repair of Parts Too Costly?\nSituationA manufacturer of computer parts, such as hard drives and CD/DVD drives, will repair or replace all parts that fail within the first year. Turn-around time for this service is guaranteed at 24 hours. Typically, a replacement part is sent out the day the failed part is received. The replacement part may be new or a refurbished part that was returned earlier by another customer. Returned parts are sent to diagnostics and rework.\nJuan manages the department that handles all returns, replacements and repairs. He is under pressure to reduce the costs in his department. These costs include labor, new units from production and some materials for repairs. To study the costs in detail, Juan has decided to focus on the time to find and repair returned units, the percentage of returned units that cannot be repaired and the number of new units used for returns. His challenge is to minimize the costs associated with his department while providing the best customer service.\nAvailable DataJuan decided to concentrate on the part with the highest volume of returns-computer hard drives because the major costs are associated with the labor to find and correct the component failure regardless of the component type. He has received data for the past 13 weeks on the following measures for hard drives: number of returned parts, time to identify the failure and repair the returned parts, number of new parts shipped as replacements, percentage of parts that cannot be repaired and percentage of returned parts that work correctly. These data are summarized in the table, \"Returns Department Data for Hard Drives.\"\nQuestions1. What is the behavior of the returns and repair processes for hard drives?\n2. How does understanding process behavior help Juan to evaluate possible ways to reduce costs?\n3. Based on the data available, what might Juan work on first to reduce costs?\n4. What additional data and analyses could help Juan take actions to reduce costs in his department?\nAnswers to September Brain TeaserAs a new Six Sigma Black Belt for a sand casting manufacturer, Vicky spent the first few weeks reviewing the results of completed Six Sigma projects. She focused on the control plans that typically use process behavior charts for critical measures to ensure that project gains are sustained. Vicky has noticed that the limits used on some process behavior charts have not been updated to reflect current process behavior. She selected the chart for sand temperature to discuss with the corporate quality director.\nA: To recreate the process behavior chart for sand temperature that Vicky was given, use the control limits provided and plot the data for the three shifts on July 19-20 in subgroups of size 2. See the chart, \"Sand Temperature for July 19-20 Using Historic Limits.\"\nQ: What conclusions can be made about the behavior of sand temperature with the current central line and limits?\nA: Using the limits provided, the July 19-20 data show two signals of exceptional variation: a point below the lower control limit on the average chart during the swing shift and a point above the upper control limit on the range chart during the day shift. Based on these historic limits, sand temperature is not predictable. It shows a decrease in the average for swing shift and an increase in variation during day shift. Vicky has noticed other signals with previous data, but as far as she can tell, there has been no effort to identify and remove the exceptional causes.\nAn additional issue regarding sand temperature is that of the two lines. In reality, these are two different processes and Vicky needs to analyze the data from each line separately to find out if both lines have the same average and variation.\nIt turns out that both lines have similar amounts of variation, but the average for Line 2 is approximately 8.5 degrees or about 1 standard deviation lower than Line 1. In the future, it is advisable to use separate process behavior charts for real-time control for each line since they are separate processes.\nQ: If the intent in the control plan for sand temperature is to have a real-time response and action plan, what specific situations need to be addressed?\nA: The first level of response is to notice the presence of a signal on the chart as soon as the signal appears and then determine appropriate immediate action. If the cause of the exception is easily identified, then take immediate action to remove the cause of the exception. If the cause of the exception is not obvious, take action as needed to bring the process back into a predictable state. The second level of response is to find the cause of the exceptional variation and take actions to remove that cause from the process.\nCauses of exceptional variation in the average sand temperature can be a simple as an incorrect setup or as complex as a malfunction in the performance of the temperature equipment. Regardless, control plans with real-time responses to data plotted on a process behavior chart require the users to take appropriate actions to remove the causes of the exceptional variation in the process. Some of these actions may be included as part of the control plan.\nFor the July 19-20 data, it is appropriate to compute limits for each shift because day and swing shifts had different signals. These separate sets of limits show that day shift has much higher variation than the other two shifts while swing shift has an average that is about 15 degrees below the average for the other two shifts. See the chart, \"Sand Temperature with Limits by Shift.\" From this analysis of the data, Vicky can begin a search for the causes of the exceptional variation.\nA: As a first action, Vicky should propose that she lead a team of four to five people to review all of the control plans from Six Sigma projects, including a review of the way process behavior charts are currently set up. Members of this team should include several leaders of the Six Sigma projects and several people who are responsible for using the control plans. The goal of this review team would be to make appropriate changes in the control plans so that real-time responses and actions will lead to finding and eliminating the causes of exceptional variation to ensure ongoing predictable processes."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:b3f5fbe9-fa02-42aa-8a3f-f2b716304984>"],"error":null}
{"question":"How serious is anorexia nervosa in terms of health risks and mortality?","answer":"Anorexia nervosa is an extremely serious condition with one of the highest death rates of any mental health condition. People with anorexia have a premature death rate more than 20 times higher than their peers without eating disorders, with 20% dying from suicide. The condition can lead to numerous health complications including digestive problems (like impaired gastrointestinal motility, bloating, abdominal pain and constipation), heart complications (including irregular heart rhythm and fainting), kidney disease, infertility, and osteoporosis. It also frequently co-occurs with other mental health conditions such as depression and anxiety.","context":["What is Anorexia Nervosa?\nAnorexia nervosa is a devastating illness, affecting millions of people each year. Anorexia nervosa is defined by the DSM5 (Diagnostic and Statistical Manual Version 5) as:\n- Restriction of dietary intake relative to dietary energy requirement leading to a significantly low body weight in the context of age, sex, and physical health\n- Intense fear of gaining weight or becoming fat\n- Disturbance in the way in which one's body weight or shape is experienced, and persistent lack of recognition of the seriousness of the current low body weight.\nNinety percent of those diagnosed with anorexia nervosa are women. Estimated to affect 1% of adolescent females in the US, anorexia nervosa has one of the highest death rates of any mental health condition; 20% of whom die from suicide. Individuals with anorexia have a premature death rate that is more than 20 times higher than their peers who don't have an eating disorder.\nAnorexia nervosa is often associated with other mental health conditions such as depression and anxiety. In addition to mental health conditions, people affected by anorexia may also develop digestive conditions (e.g., impaired gastrointestinal motility resulting in bloating, abdominal pain and constipation), heart complications (e.g. irregular heart rhythm, fainting), kidney disease, infertility, and osteoporosis.\nHow is Anorexia Nervosa treated? Can it be treated?\nTreatment of anorexia nervosa and other eating disorders is best accomplished by an experienced multidisciplinary team including a physician, registered dietitian, and psychotherapist. Treatment is focused on understanding how an individual ended up with an eating disorder, how to get rid of the eating disorder, and how to not return to the eating disorder later in life. Medications have a limited role in the treatment of anorexia nervosa. There are no FDA (Food and Drug Association) approved medications for the treatment of anorexia nervosa, but a majority of those affected by this disease are taking psychotropic medication aimed at addressing mood disturbance and associated eating behaviors.\nSince there is not an “anorexia-be-gone” pill, the primary treatment is provided by the dietitian and psychotherapist. Dietitians focus on helping their patient develop a healthy relationship with food, eating and body image, encouraging sufficient dietary intake and guiding appropriate weight gain. The therapist addresses the underlying causes of the eating disorder. A common thread for many affected by anorexia nervosa is the need for control. When something, or some things, are out of control, the one thing someone can control is their eating and body size, shape and weight.\nBehaviors and symptoms\nEarly recognition and early intervention/treatment for anorexia nervosa is associated with better outcomes. Knowing early signs and symptoms of anorexia nervosa can help loved ones recognize the person at risk and get them into appropriate treatment. Behaviors and symptoms of anorexia nervosa include the following: skipping meals, eliminating food groups (e.g. not eating dairy, fat, meat, gluten containing foods), increased exercise, rigid eating – eating the same thing every day, refusal to eat in restaurants or outside the home. Commonly reported symptoms include: abdominal pain and/or bloating, decreased appetite, constipation, fatigue, amenorrhea (lack of menstrual periods), hair loss, dry skin, light headedness, and fainting.\nOur society’s obsession with the female form, and especially tall, thin, willowy women is another driver for anorexia nervosa. Endless pictures of scantily clad celebrities online, on social media, and in magazines create unrealistic body image standards for women and girls. Efforts that promote healthy lifestyle and healthy body image in the media, at home, and in schools, can go a long way at reducing the pressure on young women to achieve unhealthy body size, shape and weight."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:d9e78ae6-6bda-4308-9c69-d37aaddee804>"],"error":null}
{"question":"Can you explain difference between Kyo ware pottery making and Kurinuki technique? How they make bowls? I want to learn! 😊","answer":"Kyo ware and Kurinuki use very different pottery-making techniques. Kyo ware primarily uses three methods: lathe casting (using a potter's wheel with centrifugal force), hand forming (using fingertips and bamboo spatula), or molding (pouring clay mixture into plaster molds). In contrast, Kurinuki involves carving out a shape from a single block of clay using tools like clay knives, needles, and spatulas, working from the inside out. While Kyo ware requires multiple steps including kneading, casting, drying, planing, and multiple firings with glazes, Kurinuki is more direct, focusing on the carving process to create organic shapes and unique textures.","context":["Kyo ware/Kiyomizu ware Kyo yaki Kiyomizu yaki\nMany kinds, small quantity handmade production\nwe produce pottery as sophisticated and delicate as the town of Kyoto\nWhat is Kyo ware/Kiyomizu ware ?\nKyo-ware/Kiyomizu-ware are ceramics and porcelain produced in the Kyoto area. Originally, Kyo-ware was a general term for all pottery produced in Kyoto, while Kiyomizu-ware referred to pottery produced on the road leading to the Kiyomizu temple. Kyo-ware is also known as Kyoto-ware. Today, Kyo-ware designs a large variety of potteries made in specific areas of Kyoto. Kiyomizu-ware is one of the many Kyo-ware categories and refers to potteries produced around the Kiyomizu temple.\nKyo-ware and Kiyomizu-ware are interesting because they are not just one type of pottery. Many distinct techniques are used to create different kinds of potteries but as long as they are produced in certain areas of Kyoto, they are considered Kyo-ware or Kiyomizu-ware. Each kiln also has its unique traditions and specialties.\nKyoto is known as a traditional city that perpetuates many long-established arts. Several types of tea ceremonies, flower arrangements or incense-smelling ceremonies during which the smell of the incense is tasted with traditional Kyoto cuisine or sweets are among the most famous traditions. Kyo-ware and Kiyomizu-ware were developed together with these cultures and that is why they fit so well in such historic environments.\nEven today, when mass production has become the norm, Kyo-ware and Kiyomizu-ware are still making every piece by hand using traditional techniques.\nKyo-ware as we know it today was first created during the Nara and Heian periods (710-1185) and its production grew a lot as the tea ceremonies became more and more popular duing the Azuchi-Momoyama period (1573-1600).\nThe first highly skilled artisans appeared at the beginning of the Edo period (1603-1868), triggering the rapid development of modern Kyo-ware.\nFamous names like Ninsei NONOMURA a potter from the Hyogo prefecture who completed magnificent painted ceramics or Kenzan OGATA, the younger brother of painter Korin OGATA, created masterpieces using original designs in collaboration with his older brother. During the latter part of the Edo period (middle of the 19th century), Eisan OKUDA became famous for his beautiful fired porcelain. Master artisans such as Mokubei AOKI, Douhachi NINNAMI or Hozen EIRAKU's masterpieces are also a must-see.\nMoving into the Meiji period (1868-1912), advances were also made outside of Japan with the adoption of European porcelain production methods.\nKyo-ware and Kiyomizu-ware keep on using traditional techniques for making various types of high-quality potteries.\nGeneral Production Process\n- 1.Kneading the clay\nThe first process is to thoroughly knead the clay by hand. Kneading the clay is a very important step as, when it is done properly, it removes the air, ensures an even hardness and increases the viscosity.\nSince potter’s clay is no longer produced in Kyoto, it is imported from different regions in Japan. It is then mixed with kaolin, kibushi clay, silica and feldspar.\nThere are different casting methods such as lathe casting, hand forming or molding and all have different results.\nLathe casting is a method of casting where the kneaded clay is placed centrally on a disc-shaped rotating potter’s wheel, using centrifugal force while soaking the clay with water. Different types of potter’s wheel include hand potter’s wheel, kick potter’s wheel and mechanical potter’s wheel. This is a high-skilled method that usually requires many years of experience.\nHand forming is a method of casting where the clay is casted while twisting, using the fingertips and a bamboo spatula. This is the easiest method and it does not require the use of a lathe.\nWhen molding, the mud that was made by mixing base clay with water and silicic acid soda is poured into a plaster mold. This enables the casting of delicate forms and the production of many same-shape works.\n- 3.Drying and planing\nThe planing is done in one time, once cast pieces have reached a semi-dry state after drying away from the sunlight for several days. A stand called a \"chuck\" is installed on the potter’s wheel, and the cast piece is hung upside-down. The foot is trimmed and the whole body is finished using a metal plane or bamboo spatula while rotating the wheel.\nDecoration is then applied using finishing tools, and pieces are dried in the sunlight.\nThe bisque firing refers to firing the clay for the first time. This first firing is carried out at low temperature to reinforce the cast items and make it easier to decorate and glaze afterwards.\nThe undercoating is done before the glost firing. All the drawing is hand-made with specific brushes and different metal colorants such as asbolite which makes an astringent blue color, and iron oxide become the base of this step.\nColored glazes, transparent glazes and frosted glazes are applied to the work. Colors, transparency and luster appear afterwards, during the firing.\nThis process is as important as the molding as the charm of the finished work depends on it.\n- 7.Glost firing\nIt consists in fusing the glaze and the clay in a separate firing. Cast pieces that have been glazed are loaded into the kiln and baked at a high temperature.\nInstead of old-fashioned climbing kilns, gas/electric kilns are the mainstream today.\nDepending on the desired texture, either oxidation firing or reduction firing can be used.\nThis is the process of decorating after the glost firing (some items are not overglazed).\nDecoration and coloring are carried out with a fine brush, using all kinds of metal colorants. Gold and silver are also often applied.\n- 9.Overglaze firing\nAfter overglazing, the pieces are baked again at a low temperature. This process produces the colors, luster and prevents damages such as peeling. This is a very meticulous step and the work and temperature have to constantly be checked in order to make sure the glaze has dissolved.\nAfter firing, the kiln is cooled and the pieces are then removed from the kilns.\nMany kinds, small quantity handmade production With assiduity, we produce pottery as sophisticated and delicate as the town of Kyoto\nBusiness Hours9.30am to 5.30pm\nWe have a large variety of items, from the traditional-style Kiyomizu-ware first created right in front of the Sennyuji temple by Ninsei NONOMURA and Kenzan OGATA to modern Kyoto pottery.\nClosedThursdays / Around the New Year / August 7 to 16\nWhere to Buy & More Information\nKyoto Museum of Traditional Crafts\nClosedAround the New Year\nBusiness Hours9am to 5pm\nSee more Ceramic\n- Imari ware/Arita ware\n- Hasami ware\n- Kutani ware\n- Mashiko ware\n- Shigaraki ware\n- Bizen ware\n- Hagi ware\n- Koishiwara ware\n- Mino ware\n- Tobe ware\n- Tokoname ware\n- Karatsu ware\n- Kasama ware\n- Satsuma ware\n- Iga ware\n- Mikawachi ware\n- Agano ware\n- Otani ware\n- Obori-soma ware\n- Tsuboya ware\n- Aizu-hongo ware\n- Shodai ware\n- Echizen ware\n- Akatsu ware\n- Tamba-tachikui ware\n- Yokkaichi-banko ware\n- Izushi ware\n- Kyo ware/Kiyomizu ware\n- Iwami ware\n- Amakusa ceramics\n- Seto-sometsuke ware\nSee items made in Kyoto\n- Nishijin brocade\n- Kyo textiles\n- Kyo folding fans\n- Kyo doll\n- Kyo uchiwa fans\n- Kyo ware/Kiyomizu ware\n- Kyo laquerware\n- Kyo braided cords\n- Kyo woodworks & joinery\n- Kyo-komon textiles\n- Kyo Buddhist altar\n- Kyo embroidery\n- Kyo art preservation\n- Kyo Buddhist altar equipment\n- Kyo dyed textiles\n- Kyo-ishi craft\n- Kyo kimono-dyeing","DISCOVER THE ART OF KURINUKI\nCeramics is one of the oldest art forms in the world. Since prehistoric times, mankind has used clay to create utensils, decorative objects and works of art. The Kurinuki technique is one of the most unique and recognized ceramic techniques used in Japan. Through this technique, artisans can create unique and fascinating pieces of great beauty and simplicity. You will learn about a magical sample of Japanese ceramics, its history, characteristics and more. Join us!\nWHAT IS KURINUKI\nIt is a Japanese ceramic technique that involves carving the desired shape into a piece of clay. The name kurinuki can be literally translated as “to hollow”.\nA single lump of clay is used which is carved with the appropriate tools to achieve the desired shape. Instead of creating a work from individual pieces of clay, as is done in some other techniques, the piece is carved from a single block of clay. The result is frankly beautiful.\nTea bowl made with the Kurinuki technique. Made by\nSarah Maelle Ceramique.\nWHAT DOES THE KURINUKI TECHNIQUE CONSIST OF?\nThe Kurinuki technique begins with the selection of the right block of clay. The artisan must ensure that the clay is soft and moist enough to carve easily, but not too wet to prevent cracking during carving.\nOnce the clay is selected, it is cut into the desired basic shape and carved using different tools, such as clay knives, needles and spatulas. As the piece takes shape, small amounts of clay are removed to achieve the desired design.\nArtisans use this technique to create organic shapes and unique textures on the surface of the bowl. The Kurinuki process involves sculpting the clay from the inside of the bowl to the outside, rather than shaping the form from the outside to the inside, as is done in other ceramic techniques.\nFinally, the part can be smoothed and polished to obtain a smooth and uniform finish.\nArtist: Ewe Suchanek\nYUNOMI TYPE KURINUKI BOWL\nArtist: Chanoyu Ceramics\nSMALL YUNOMI STYLE CUP\nArtist: Clarochelle Ceramiste\nLEARN MORE ABOUT ITS ORIGIN AND USES\nThe Kurinuki technique dates back to medieval Japanese times, where it was used to make ceramic objects for the tea ceremony. During the Edo period (1603-1868), the technique was extended to the production of other everyday objects, such as bowls and plates. Despite the popularity of the technique, most objects produced with Kurinuki were made for personal use and were not widely marketed.\nDue to the special nature of this technique, each resulting piece is unique and no two pieces can be made alike. This uniqueness has led many artisans to embrace the Kurinuki technique as an art form to express themselves with unrepeatable creations.\nOne of the most popular applications of this technique is in the creation of Yunomi bowls, which are used in the Japanese tea ceremony.\nThese ceramic bowls have a cylindrical shape and are sometimes wider at the base than at the mouth. They are used for drinking tea and are held with both hands while drinking. Because of their ceremonial use, these pieces are of great cultural importance in Japan.\nAnother type of bowls that are made with Kurinuki are the Chawan, these are less cylindrical and wider.\nArita Porcelain: A priceless marvel of ceramicsWelcome to a journey full of charm that will take you through the fascinating history of Arita pottery. In this article, I invite you to explore the curious aspects that make this Japanese technique a...\nAlfred GuinaroanModeling and creating from the infinity of the raw material captivated me since childhood, a few years ago now, in a small mountain village in Barcelona. My parents are not Spanish, but they fell in love with the beauty of the area and there I was...\nThe Art of Kintsugi: The Inspiring Japanese TechniqueWe are going to explain the secrets of Kintsugi. A technique used in the repair of objects that has become a whole philosophy of life that more and more people are falling in love with. Since...\nKintsugi repair kit: EVERYTHING for this Art in gold.Kintsugi repair kits with gold or other materials such as silver, make it possible for you to practice this art at home, as they allow you to create an artistic piece from a broken object, with...\nNote: This article contains affiliate links that lead to the artists’ stores outside of the Ateologic website. If you buy something from them, we will receive a small commission that will help us to continue our site and in turn continue to support those artists. This of course does not affect the selling price."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:91ae0618-1628-41dc-a08f-cc579bf5c90c>","<urn:uuid:9d27e125-15d7-4ee2-9310-b40f74021697>"],"error":null}
{"question":"请问您能详细解释一下如何通过辅助住宅单位(ADU)来帮助老年人居住，以及这种模式如何与Nashville的Glastonbury Woods项目的创新管理方式相结合？","answer":"ADUs are self-contained apartments either within or adjacent to single-family homes that provide affordable housing options for elderly relatives. They allow seniors to age in place near family while maintaining independence. As for property management innovation, the Glastonbury Woods project implements an enhanced property management plus model that coordinates services and support to ensure tenants remain stably housed. This model has proven successful in promoting long-term housing stability for all residents through coordinated services and support systems.","context":["HOUSING THE HUDSON VALLEY as it appears in the Senior Gazette\nHousing the Hudson Valley, as it appears in the Senior Gazette, written by John C. Cappello, Esq., Partner, J&G and Joe Czajka, Senior Vice President of Research, Development & Community Planning and Executive Director Center for Housing Solutions and Community Initiatives, Hudson Valley Pattern for Progress\nRecent development and growth in the Hudson Valley, for the most part, have been commercial consisting of resorts and tourism destinations, many large warehousing and distribution centers, light manufacturing, and some retail. Locally, since the 2008 recession hit, the issue of housing has been left on the back burner.\nHowever, the times they are a changing. The pandemic, coupled with the emergence of technology, broadband issues aside, facilitates remote work and has led to a migration to the Hudson Valley from other larger Northeast cities. Prospective homebuyers looking to the Hudson Valley are engaging in bidding wars and sellers are often receiving more than the asking price for their homes. The result is skyrocketing home prices and an increasing demand for new residential development across the region.\nThis is good news for sellers, contractors, and trades people among others. The influx of new residents to the region will also bring increased support for existing businesses and bring new ideas and energy to our community as we emerge from the pandemic.\nHowever, as we plan to reap the benefits of this potential real estate boom it is essential that we appropriately plan to accommodate growth. This is especially important as it relates to our seniors looking to downsize while staying near family and friends in the Hudson Valley.\nThe population of the United States is getting older. Increased life expectancy from advances in medicine and technology is coinciding with the aging of baby boomers, one of the largest generations in American history, leading to an older country. This ongoing demographic shift has been colloquially dubbed “The Silver Tsunami.”\nThe median age in the United States has been steadily trending upwards since the 1970s and has increased every year for the last 10 years. The Mid-Hudson Valley mirrors this national demographic shift, and is home to an older population than the nation as a whole. In the United States, the median age is 38 years. With the exception of Orange County, every county in the study area has a median age above the national figure.\nPopulation projection models estimate a significant increase in the number of people age 65 and above by 2030. This aging of the population will have a significant impact on the Mid-Hudson Valley and raises the question whether the Valley is prepared for the coming changes. As the population grows older, there will be an increasing need for medical services and home health aides as well as affordable nursing homes to take care of the elderly. Additional technology to assist the elderly population in rural areas also needs to be addressed.\nAlthough we cannot precisely know how much the Mid-Hudson Valley’s older population will grow and the impact it will have, it is clear that a significant demographic shift has begun and deeper changes are on the horizon. Government leaders and policy makers must continue to analyze this shift and prepare for the multifaceted changes it may bring.\nIt is vital that our region maximize all the tools available in our efforts to provide a wide range of housing opportunities for those who have contributed so much to the fiber of our community. However, a cursory review of the homes for sale and available rentals demonstrates that there are too few housing opportunities available for seniors on fixed incomes at a cost that is affordable to them.\nFortunately, there are several organizations, planning groups, and developers focusing on the problem, providing education on the impact of a lack of housing opportunities, and developing new and innovative options to help to address our housing problems for all aspects of our community including seniors.\nLocally the Hudson Valley Pattern for Progress Center for Housing Solutions https://www.pattern-for-progress.org/the-center-for-housing-solutions/ provides a wealth of information on housing trends in the region as well as providing expert analysis and discussion on solutions to the problem of lack of adequate area housing opportunities.\nThe development of tiny or smaller homes, multi-family dwellings, conversion of large historic homes in our cities and villages to shared housing opportunities for seniors, and accessory dwelling units, are just a few of the examples that can and should be considered in Hudson Valley communities. All of these options are developed on smaller footprints with much less land disturbance than traditional large suburban single-family housing. In addition, by incorporating energy saving building design and alternative energy features, any adverse environmental impact can be further minimized resulting in a win-win for our region.\nAn Accessory Dwelling Unit (ADU) is a self-contained apartment that is found within the envelope of a single-family home, or as a separate structure adjacent to a home on an existing residential lot. ADUs provide an affordable housing option with benefits to the municipality, local employers, homeowners, families, and the aging population.\nThe ADU may be used as an affordable housing option for an elderly relative to safely age in place with their family members living within the same home or on the same property while retaining a level of independence\nTiny homes are small stand-alone homes providing 240-600 sq. ft. of self-contained living space. These homes can be aggregated as a community or used as an ADU on a lot containing a single family home. One innovative tiny home project was completed in Kansas City in 2019 by The Veterans Community Project where 49 “tiny houses” ranging in size from 240-320 sq. ft. were constructed on a five-acre plot to provide decent transitional housing for homeless veterans (see www.veteranscommunityproject.org for more info). This same model can certainly be replicated to provide housing for seniors.\nThere is no single solution to address the wide range of housing needs for seniors. The concepts described above are just a few possibilities. It is important, however, for all of us to come together as a community to start to address the need to provide for reasonable and sustainable housing for all those wishing to live in our region.\nThis is not intended to be legal advice. You should contact an attorney for questions regarding your specific situation.\nJohn C. Cappello is a partner practicing Land Use/Environmental and Municipal Law. He can be reached by phone at 845-764-9656 and by email.","FOR IMMEDIATE RELEASE\nAugust 29, 2022\nMedia Contact: Community Solutions: Lauren Barnes, firstname.lastname@example.org\n- Nashville/Davidson County CoC and Community Solutions announced the acquisition of a property that implements an innovative model of social impact investing that has been supported by leaders like the MacArthur Foundation.\n- The mixed-income property joins a portfolio of properties across the United States that are supporting local efforts to address the affordable housing supply gap and reduce homelessness.\n- The property will employ an enhanced property management model that has been used in other communities to ensure tenants can stay stably housed through services and support.\nNASHVILLE, TN— Today, the Nashville/Davidson County CoC and Community Solutions, a nonprofit dedicated to ending homelessness, announced the acquisition of Glastonbury Woods. The 144-unit Nashville property will join a growing portfolio of mixed-income properties aimed at increasing affordable housing units and reducing veteran homelessness. These properties are harnessing an innovative housing and financing model used to support communities participating in Built for Zero, a movement of more than 100 communities working to measurably and equitably reduce homelessness.\nJohn Cooper, Nashville Mayor, said: “Nashville is deeply committed to implementing a true housing-first model that will get our unhoused neighbors — in particular those who have bravely served our country — off the street and into stable housing so they can begin rebuilding their lives. The new supportive permanent housing units created by this innovative development is an important step toward accomplishing that goal, and I’m grateful to the Nashville/Davidson County Coc, Community Solutions and all of the partners involved for making this worthy project happen.”\nNashville/Davidson County CoC has been participating in Built for Zero since 2018. As part of that work, it uses community-wide collaboration, a high standard of data and systems change to achieve progress toward functional zero, a milestone for making homelessness rare and brief for a population. The community’s Built for Zero efforts are currently focused on veteran homelessness, with a goal of moving towards ending homelessness for all.\nDaniel L. Dücker, Executive Director VA Tennessee Valley Healthcare System, said: “Our team is excited to be a part of this new journey and working alongside key community partners to better serve Veterans affected by homelessness. We have a sacred obligation to serve those who swore an oath for our country. Veterans deserve affordable housing, and I’m glad to see our Homeless Veteran Program, Community Solutions and Metro Nashville working together to address a nationwide crisis.”\nSally Lott, Metro Homeless Impact Division, said: ”Thanks to our quality, by-name data, we know that as of August 17, 173 veterans experiencing homelessness were on Nashville’s real-time, by-name list. Of those veterans, more than 100 currently have a housing resource, such as a housing voucher or subsidy, and are looking for an available unit. However, there is not enough supply to move the qualified veterans into housing. Glastonbury Woods will implement a model that is being used to help close the supply gap and provide local, permanent housing and services that will support the individual needs of tenants so they remain housed. As tenants turn over, the open units will be matched with veterans using the by-name data.”\nThe mixed-income property joins a portfolio of properties across the United States that are supporting local efforts to address the affordable housing supply gap and reduce homelessness.\nThe property was acquired using social impact investing, which has opened up a critical pathway to addressing the housing gaps needed to get to zero. The model has been deployed in other large cities such as Atlanta, Baltimore, Denver, Jacksonville and Sante Fe. The traditional tax credit financing model used to develop affordable housing is slow and often unable to keep up and adapt to the changing needs within a community. In comparison, social impact financing delivers projects in less time with less cost while creating greater flexibility to meet the changing needs of a community over time.\nDavid Foster, Manager of the Community Solutions Large Cities Housing Fund, said: “Through our Built for Zero initiative, we work with communities that are proving it is possible to reduce homelessness when they harness a data-driven, systems-focused approach. In the course of working toward zero, many communities — particularly large cities with tight housing markets — need the means to create permanently affordable housing in a way that is faster and more adaptable than many traditional approaches allow. Thanks to this social impact investment model, we will be able to help many large cities accelerate their progress, while continuing to scale a model that offers cities across the country a way to crack this critical challenge for ending homelessness.”\nIn order to ensure this funding supports overall reductions in homelessness, 50 percent of units will be leased through close partnership with the homeless response system. The buildings will be leased with a 50/50 mix of units for people exiting homelessness and units for middle income individuals. In Built for Zero communities, these systems are designed to know everyone experiencing homelessness by name, in real time. By increasing direct access to units, communities will be able to promptly connect units with those in greatest need.\nThe building will implement approaches proven to promote long-term housing stability for all of its residents. In addition to being a mixed-income property, Glastonbury Woods will be managed by Enfield Management using Community Solution’s enhanced property management plus model, that coordinates services and support to all tenants to ensure they can stay stably housed.\nUnlike many approaches, this model is designed to create permanently affordable housing. At the end of a ten-year investment hold period, buildings will be refinanced and transitioned to non-profit ownership. This will ensure long-term affordability and mission-alignment.\nCommunity Solutions is a nonprofit committed to creating a lasting end to homelessness that leaves no one behind. It leads Built for Zero, a movement of more than 100 communities in the United States working to measurably and equitably end homelessness. Using a data-driven methodology, these communities have changed how local systems work and the impact they can achieve. To date, 14 communities have reached a milestone known as functional zero, a milestone for ending homelessness for a population. Learn more at www.community.solutions or follow us at @CmtySolutions. Media Contact: Lauren Barnes, email@example.com"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_language_proficiency_implied","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:da19cb75-0228-46b7-a434-cf62ae7e79b6>","<urn:uuid:e6057968-0b66-43b2-8e89-4c392d086eb6>"],"error":null}
{"question":"Could you please explain how children develop language skills between birth and 2 years, and what communication disorders might affect this development?","answer":"Children develop language skills gradually from birth. From 0-3 months, babies coo and gurgle. By 9-12 months, they understand simple words and use gestures to communicate. Between 12-15 months, they begin using consistent sounds for objects and understand 25+ words. By 18-24 months, they combine words like 'car go' or 'want juice.' As for communication disorders, children may show either expressive language disorder (difficulty producing speech) or mixed receptive-expressive language disorder (difficulty both understanding and producing speech). Some children with these disorders may not speak at all or have a limited vocabulary for their age, while others might have trouble understanding simple directions or naming objects.","context":["Helping Your Child Learn to Talk\nLearning to talk is a process that starts at birth, when your baby experiences how voices can sound. By two years, most babies have a large vocabulary and can put words together to express their needs and ideas. Let’s see how this process unfolds and what you can do to encourage your baby’s ability to communicate.\nFrom birth to three months, your baby listens to your voice. He coos and gurgles and tries to make the same sounds you make. You can help your baby learn how nice voices can be when you:\n- Sing to your baby. You can do this even before he is born! Your baby will hear you.\n- Talk to your baby. Talk to others when she is near. She won’t understand the words, but will like your voice and your smile. She will enjoy hearing and seeing other people, too.\n- Plan for quiet time. Babies needs time to babble and play quietly without TV or radio or other noises.\n- Hold your baby close so he will look in your eyes. Talk to him and smile.\n- When your baby babbles, imitate the sounds.\n- If he tries to make the same sound you do, say the word again.\n- Play games like Peek-a-Boo or Pat-a-Cake. Help her move her hands along with the rhyme.\n- Give him a toy and say something about it, like “Feel how fuzzy Teddy Bear is.”\n- Let her see herself in a mirror and ask, “Who’s that?” If she doesn’t respond, say her name.\n- Ask your baby questions, like “Where’s doggie?” If he doesn’t answer, show him where.\nBetween nine and twelve months, your baby will begin to understand simple words. She stops to look at you if you say “no-no.” If someone asks “Where’s Mommy?” she will look for you. She will point, make sounds, and use her body to “tell” you what she wants. For example she may look up at you and lift her arms up to show you she “wants up.” She may hand you a toy to let you know she wants to play. You can help your baby “talk” when you: Show him how to wave “bye-bye.”\n- Tell him “Show me your nose.” Then point to your nose. He will soon point to his nose. Do this with toes, fingers, ears, eyes, knees and so on.\n- Hide a toy while she is watching. Help her find it and share in her delight.\n- When he points at or gives you something, talk about the object with her. “You gave me the book. Thank you! Look at the picture of the baby rolling the ball.”\nBetween twelve and fifteen months, babies begin to use words. This includes using the same sounds consistently to identify an object, such as “baba” for bottle or “juju” for juice. Many babies have one or two words and understand 25 or more. He will give you a toy if you ask for it. Even without words, he can ask you for something—by pointing, reaching for it, or looking at it and babbling. You can help your child say the words she or he knows when you:\n- Talk about the things you use, like “cup,” “juice,” “doll.” Give you child time to name them.\n- Ask your child questions about the pictures in books. Give you child time to name things in the picture.\n- Smile or clap your hands when your child names the things that he sees. Say something about it. “You see the doggie. He’s sooo big! Look at his tail wag.”\nBetween fifteen and eighteen months, your child will use more complex gestures to communicate with you and will continue to build her vocabulary. She may take your hand, walk you to the bookshelf, point to a book and say “buk” to say, “I want to read a book with you.” You can help your child talk with you when you:\n- Talk about what your child wants most to talk about. Give him time to tell you all about it.\n- Ask about things you do each day—“Which shirt will you pick today?” “Do you want milk or juice?”\n- Build on what your child says. If he says “ball,” you can say, “That’s your big, red ball.”\n- Introduce pretend play with your child’s favorite doll or toy animal. Include it in your conversations and your play. “Rover wants to play too. Can he roll the ball with us?”\nBetween eighteen months and two years, your baby will be able to follow directions and begin to put words together, such as “car go” or “want juice.” She will also begin to do pretend play which fosters language development. You can spur your child’s communication skills when you:\n- Ask your child to help you. For example, ask her to put her cup on the table or to bring you her shoe.\n- Teach your child simple songs and nursery rhymes. Read to your child. Ask him to point to and tell you what he sees.\n- Encourage your child to talk to friends and family. She can tell them about a new toy.\n- Engage your child in pretend play. You can talk on a play phone, feed the dolls or have a party with the toy animals.\nBetween two and three years, your child’s language skills will grow by leaps and bounds. He will string more words together to create simple sentences, such as “Mommy go bye-bye.” He will be able to answer simple questions, such as “Where is your bear?” By 36 months he will be able to answer more complicated questions such as, “What do you do when you are hungry?” He will do more and more pretend play, acting out imaginary scenes, such as going to work, fixing the toy car, taking care of his “family” (of dolls, animals.)\nYou can help your child put all his new words together and teach him things that are important to know when you:\n- Teach your child to say his or first and last name.\n- Ask about the number, size and shape of the things your child shows you.\n- Ask open-ended questions that don’t have a “yes” or “no” answer. This helps them develop their own ideas and learn to express them. If it’s worms, you could say: “What fat, wiggly worms! How many are there?...Where are they going? Wait, watch and listen to the answer. You can suggest an answer if needed: “I see five. Are they going to the park or the store?”\n- Ask your child to tell you the story that goes with a favorite book. “What happened to those three pigs?” Reading spurs language development. Take him to storytime at your local library. Your toddler will enjoy sharing books with you as well as peers.\n- Do lots of pretend play. Acting out stories and role-playing create rich opportunities for using, and learning, language.\n- Don’t forget what worked earlier. For example, your child still needs quiet time. This is not just for naps. Turn off the TV and radio and let your child enjoy quiet play, singing and talking with you.\n(Note: This information was adapted, with permission, from , by C.E. Morrisset Huebner and P. Lines, 1994, Washington, D.C.: U.S. Department of Education, Office of Educational Research and Improvement.)","In this section\nWhat are communication disorders?\nThere are several different types of communication disorders, including the following:\n- Expressive language disorder - Expressive language disorder identifies developmental delays and difficulties in the ability to produce speech.\n- Mixed receptive-expressive language disorder - Mixed receptive-expressive language disorder identifies developmental delays and difficulties in the ability to understand spoken language and produce speech.\nWhat causes communication disorders?\nCommunication disorders may be developmental or acquired. The cause is believed to be based on biological problems such as abnormalities of brain development or possibly by exposure to toxins during pregnancy, such as abused substances or environmental toxins such as lead. A genetic factor is sometimes considered a contributing cause in some cases.\nWho is affected by communication disorders?\nFor unknown reasons, boys are diagnosed with communication disorders more often than girls. Children with communication disorders frequently have other psychiatric disorders as well.\nWhat are the symptoms of communication disorders?\nThe following are the most common symptoms of communication disorders. However, each child may experience symptoms differently.\nYoung children with communication disorders may not speak at all, or may have a limited vocabulary for their age. Some children with communication disorders have difficulty understanding simple directions or are unable to name objects. Most children with communication disorders are able to speak by the time they enter school, however, they continue to have problems with communication.\nSchool-aged children often have problems understanding and formulating words. Teens may have more difficulty with understanding or expressing abstract ideas.\nThe symptoms of communication disorders may resemble other problems or medical conditions. Always consult your child's physician for a diagnosis.\nHow are communication disorders diagnosed?\nMost children with communication disorders are first referred for speech and language evaluations when their delays in communicating are noted. A child psychiatrist is usually consulted, especially when emotional or behavioral problems are also present. A comprehensive evaluation also involves psychometric testing (testing designed to assess logical reasoning abilities, reactions to different situations and thinking performance; not tests of general knowledge) and psychological testing of cognitive abilities.\nTreatment for communication disorders:\nSpecific treatment for communication disorders will be determined by your child's physician, special education teachers and speech, language and mental health professionals based on:\n- Your child's age, overall health and medical history\n- Extent of the disorder\n- Type of disorder\n- Your child's tolerance for specific medications or therapies\n- Expectations for the course of the disorder\n- Your opinion or preference\nA coordinated effort between parents, teachers and speech, language and mental health professionals provides the basis for individualized treatment strategies that may include individual or group remediation, special classes or special resources. Two approaches are usually considered. Remedial techniques are used to increase communication skills in the areas of the deficit. A second approach helps the child build on their strengths to circumvent the communication deficit.\nPrevention of communication disorders:\nSpecific preventive measures to reduce the incidence of communication disorders are not known at this time. However, early detection and intervention can address the developmental needs and academic difficulties to improve the quality of life experienced by children with communication disorders."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:378be187-32ca-4fb1-ba12-4799426d9b1e>","<urn:uuid:946ac77c-e81d-4c9e-bd49-d9d9b1823e79>"],"error":null}
{"question":"How do the monitoring parameters differ between North Bay's Water Treatment Plant and PureWaterSF when ensuring water quality?","answer":"Both facilities monitor water quality but test for different parameters. North Bay's plant must comply with regulations by monitoring drinking water standards and preparing annual reports as required by O. Reg. 170/03 Section 11. PureWaterSF conducts more extensive monitoring, including total dissolved solids, total organic carbon, turbidity, and ultraviolet absorption, while also performing advanced analytics like bioassays and non-target analysis to detect trace compounds such as pharmaceuticals and personal care products.","context":["Water & Wastewater\nThe construction of North Bay's Water Treatment Plant began in April 2006 and started up February 17, 2010. The Plant was built to comply with new requirements for municipal drinking water systems after the outbreak of waterborne diseases in Walkerton in the summer of 2000, which included, among other things, new minimum levels of treatment for viruses, Cryptosporidium, and Giardia. The new regulation also established a procedure for disinfection which states that all drinking water systems that obtain water from a raw water supply which is surface water must include filtration.\nThe plant operates using a multi-barrier approach to meet these treatment goals. The primary barrier in this plant is Pall Corporation's Aria Microfiltration system. This membrane filtration system is made up of 11 parallel membrane racks, each equipped with dozens of pressure vessels that house thousands of hollow-fibre membranes. These membranes provide an effective barrier to physically separate the various contaminants in North Bay's drinking water.\nThe secondary treatment barrier is the UV disinfection system, which inactivates any organisms like Cryptosporidium and Giardia that are present in the water using high intensity light. The water is then injected with chlorine to kill off any viruses and bacteria that are able to bypass the previous systems. The raw water for the plant is drawn from an intake pipe that extends 300m off the shore into Delaney Bay, approximately 21.5 m below the water surface. An average of 42 million litres (ML) of water run through this plant every day, with a maximum daily flow of 79.5 ML.\nThe Water Filtration Plant pumps water directly to Ellendale Reservoir located at the end of Ellendale Drive. This is a 18,200 cubic meter concrete reservoir that provides water pressure to the majority of the City drinking water distribution mains. Ellendale Reservoir is also equipped with pumps that provide water to residents at the top of Airport Hill and fill the Airport Standpipe.\nThe Airport Road Standpipe and Booster Pumping Station was built in 2009 and is located at the intersection of Airport Road and Airport Way. The Standpipe is 26.2m high and 13.7m in diameter with a capacity of almost 4,000 cubic meters. The facility is equipped with 9 pumps to provide water pressure to the Airport Hill area. This standpipe also provides additional water storage for the City and fire protection in the Airport Hill area.\nCanadore Pumping Station\nThe Canadore Pumping Station is a facility located at the corner of Gormanville Road and McKeown Avenue. The facility is equipped with 4 pumps with the purpose of maintaining pressure at Canadore College and Nipissing University Campus.\nBirch's Road Standpipe\nThe Birch's Road Standpipe and Re-chlorination Station is a 11,775 cubic meter steel standpipe equipped with sodium hypochlorite for re-chlorination of the drinking water. This standpipe provides additional storage capacity to the City's distribution system as well as fire protect for the West Ferris area.\nWASTEWATER TREATMENT PLANT\nThe North Bay Wastewater Treatment Plant is located on Memorial Drive and is used to treat all of North Bay's Wastewater/Sewage. The original sewage plant was built in 1961-2. It provided secondary treatment for 18,160 cubic meters/day. The plant was expanded in 1973 to a capacity of 36,320 cubic meters/day. In 1984 the plant was expanded again to its present capacity of 54,480 cubic meters/day. Phosphorus removal was included in the 1984 expansion and upgrade.\nThe North Bay Wastewater Treatment Plant is a conventional activated sludge facility which uses the following treatment processes: raw sewage pumping, sewage grinding and screening, grit removal, primary settling, aeration, final settling, chemical phosphorus removal and chlorination for effluent disinfection. The effluent water is also de-chlorinated before being discharged to Lake Nipissing.\nThe sludge removed from primary settling is anerobically digested and is thickened by centrifugation. Dewatered sludge is hauled from the Wastewater Treatment Plant and utilized at the Marsh Drive Landfill Site as topping material, part of the landfill site closure for several years. Sludge is also hauled to the Merrick Landfill Site as sections are closed and again used as a topping material.\nNorth Bay Water Treatment Plant and Distribution System Reports\nThe City of North Bay is now required to post Annual Reports for its Water System on its web site in compliance with O. Reg. 170/03 Section 11 (10) and the Safe Drinking Water Act, 2002. Prior to June 2003 the City was required to prepare and post Quarterly Reports for its Water System. Water Quality Reports have been prepared since June 2000.\nQuality Management System Policy\nThe Corporation of the City of North Bay Quality Management System Policy The City of North Bay owns, operates and maintains the North Bay Water Treatment Plant and the City of North Bay Distribution system. The City of North Bay Water and Waste Water Operations shall:\n- Provide consumers with a supply of safe drinking water\n- Strive to protect public health, the environment and property in the operation of the drinking-water system\n- Maintain and continually improve upon its Quality Management System\n- Operate and maintain the drinking-water system in compliance with all applicable legislation and regulations\n- Communicate this policy to the Owner, the Operating Authority Personnel and the Public","Purpose of the PureWaterSF Research Project\nThe PureWaterSF project is a research project that explores how we can treat and reliably produce purified water on a small (building) scale using wastewater generated onsite. For this project, the SFPUC will be taking approximately 80% of the recycled water currently produced by the constructed wetland treatment system called the Living Machine™ at the SFPUC headquarters. The PureWaterSF process will further purify this water, bringing it to a level that is expected to meet or exceed drinking water standards.\nData from this process will be collected and analyzed, and the water produced will be returned to the building’s non-potable (non-drinking water) system for toilet flushing. This project is intended for research only, with the goal of collecting data that can inform a broader, statewide dialogue on purified water use. The project will also adhere to and help inform future California potable reuse regulations.\nback to top\nThe goal of this research project is to demonstrate how advanced water purification and monitoring technologies can reliably convert building-sourced wastewaters into a high-quality supply to meet diverse end uses. Several objectives help us achieve this goal:\n- Examine reliability of a water purification system at building-scale\nThe research examines the reliability of a purification system measuring common parameters such as chlorine, pH, turbidity (how clear the water is), and temperature. This information is regularly collected using real-time monitoring and provides valuable information about the reliability of these systems at a building level.\n- Create a research baseline through advanced water quality analytics\nThe project follows recommendations from state experts to use specific water quality analytics to address knowledge gaps in the industry. These analytics include nontarget analyses (NTA), which measure substances we have not typically measured or created targets for before, and biological assessments, which can test the overall level of bioactivity in water samples. Data from this research can help inform statewide regulatory deliberations.\n- Promote transparent science through outreach and communication\nThe project focuses on promoting transparent scientific practices through outreach and communication by using: factsheets, a digital wall display, a digital tour video, in-person tours and this website. All of these components work toward fostering a greater understanding of purified water in our communities. Public feedback will further inform future work by the SFPUC.\n- Provide new opportunities with on-site operator training\nPureWaterSF provides a unique opportunity for operators to receive onsite training with a building-scale water purification system at the SFPUC headquarters. Operator feedback will help inform planning and system development.\nIf you would like to learn more about purified water research in San Francisco, sign up for our email list here!\nWe'd like to know what you think about PureWaterSF, click here to take a short survey.\nRegister here to tour the PureWaterSF Research Project at 525 Golden Gate, SF.\nback to top\nLiving Machine System Schematic\nThe Living Machine™ is a constructed wetland system providing on-site non-potable water reuse at the SFPUC Headquarters (SFPUC HQ). It collects and treats the building’s wastewater and reuses this water for toilet flushing. The system has a capacity of 5,000 gallons per day.\nThe Living Machine™ has several main system components that move and treat the building’s wastewater as follows:\n- Primary Tank: wastewater is first sent to a primary treatment tank where sewage is settled and screened using a trash and a settling chamber to separate larger solids. The filtered wastewater then flows to the Equalization and Recirculation Tanks.\n- Equalization and Recirculation Tanks: filtered wastewater is then sent to the Equalization Tank which holds back the wastewater and acts as a buffer until it can be sent to the Recirculation Tank. The Recirculation Tank doses the wetlands with a steady flow of wastewater throughout the day.\n- Tidal Flow Wetlands: The Tidal Flow Wetlands are located outside the SFPUC headquarters along Golden Gate Avenue. These are designed to mimic natural tidal wetlands. Water from the Recirculation Tank fills the wetland planter boxes from the bottom up, and then water is drained by gravity back to the Recirculation Tank. Gravel media in these planters enables the growth of a healthy biofilm that is home to a diverse population of microorganisms which feed on nutrients in the wastewater. The planters are filled and drained 12 times a day.\n- Polishing Vertical Flow Wetlands: at the end of the 12 cycles, the effluent is sent to the Vertical Flow Wetlands where remaining organic material and nitrogenous compounds are removed.\n- Disinfection: The water is then sent through a disinfection process where it is filtered to remove solids and reduce turbidity, sent through an ultraviolet unit to deactivate bacteria and viruses, and sent through a chlorination tablet feeder to prevent growth in the building’s recycled water pipes.\n- Recycled Water Tank: After the above treatment process is complete, the water is stored in the Recycled Water Tank and is used for toilet and urinal flushing.\nTreated water held in the Recycled Water Tank is also now being used as source water for the PureWaterSF research project where the water undergoes advanced treatment up to potable standards and is analyzed for research purposes before being returned to the building’s non-potable system. Please see the Living Machine™ link for further information.\nDid You Know ...\n- The Living Machine is one of the first buildings in the nation with onsite treatment of grey and black water to be recycled for toilet-flushing?\n- The Living Machine reduces the SFPUC headquarters’ water use by about 65%, saving 800,000 gallons of water per year?\n- Wetlands are often less expensive to build than traditional wastewater and stormwater treatment options, have low operating and maintenance expenses and can handle fluctuating water levels (USEPA, 2006).\nPureWaterSF System Schematic\nThe PureWaterSF system will add an advanced water treatment system onto the existing engineered wetland system of the SFPUC’s Living Machine™. The PureWaterSF system takes this already treated water and purifies this to generate (approximately) 1,296 gallons per day of highly purified water at a rate of about 0.9 gallons/minute. This high-quality water meets drinking water standards using the most advanced purification processes available including ultrafiltration, reverse osmosis, and ultraviolet light with advanced oxidation.\n- Ultrafiltration: After initial water quality sampling and testing, the water taken from the Living Machine™ first goes through ultrafiltration (UF) which involves passing recycled wastewater through very fine hollow fiber membranes and removing particulate matter, bacteria, and protozoa. After passing through the membrane, the filtered water mostly contains dissolved salt and organic molecules. Sampling: UF effluent is sampled for chloramines, free chlorine, nitrate, TOC, DOC, UV254, and turbidity.\n- Reverse Osmosis: The next step is reverse osmosis (RO) where the water is pushed through a semi-permeable membrane at high pressure to remove impurities such as viruses, dissolved salts, pesticides, and most organic compounds. It is the same process used to desalinate seawater. Sampling: RO permeate is sampled for TOC, nitrate, nitrite, turbidity, pH, temperature, free chlorine, and UV254.\n- Ultraviolet Light with Advanced Oxidation: The final step is ultraviolet light with advanced oxidation which exposes the water to ultraviolet (UV) light combined with sodium hypochlorite to disinfect any pathogens and to further reduce chemicals to non-detectable levels. Sampling: The finished water is sampled for free chlorine and UVT.\nThe SFPUC’s living machine has treated building wastewater for non-potable reuse since 2012. The machine treats roughly 5,000 gallons per day, saving roughly 800,000 gallons per year (over 60% reduction in total water use). Through the PureWaterSF project, roughly 80% of the Living Machine effluent will be purified to a level comparable to drinking water standards. The purified water will continue to be fed into the building’s non-potable distribution system.\nDid You Know ...\n- Advanced purification processes are already being used to recycle and reuse water on spaceships, and cruise ships? Even at Disneyland!\n- In California alone, there are 9 other purified water projects underway including in Santa Clara, Los Angeles, Orange County, and San Diego?\n- By 2027, the volume of recycled water produced in the United States is projected to increase 37% from 4.8 billion gallons per day to 6.6 billion gallons per day (WaterReuse, 2018)?\nDownloadable Fact Sheets on the project are available here:\nPureWaterSF System Performance & Reliability\nEnsuring Reliable System Performance: Water testing is conducted at every step to ensure that each element of our system is efficiently and effectively removing the microorganisms it was designed to remove. This testing assesses the system’s performance in terms of the overall reliability of the system, and how well the system is able to continuously achieve water quality standards. Grab samples will be taken at regular intervals and analyzed for conventional water quality parameters, such as pH, chlorine, and hardness, as well as for potential contaminants, such as pharmaceuticals, bacteria or viruses.\nAt the end of the approximately 30-minute process, we are able to confirm that all the treatment goals are achieved, and we compare the purified water to drinking water standards.\nUsing Advanced Analytics to detect “unknown unknowns” in our water: We then go one step further to gain a more holistic understanding of the water we are producing. We run a test that can indicate any trace of compounds such as pharmaceuticals and personal care products, which are ordinarily very difficult to detect. For this testing we use advanced data analytics, which includes bioassays (biological assessments) and non-target analysis (NTA) to measure biological effects of various trace level chemicals found in our water system. With this testing, we are trying to go beyond understanding what's been removed toward a better understanding of what remains in the water.\nReal-Time Monitoring: While the system runs, it conducts a continuous real-time monitoring to assess system performance and overall reliability. This real-time monitoring assesses the following standard measurements of water quality:\n- TOTAL DISSOLVED SOLIDS - TDS are inorganic salts and organic matter that are dissolved in water. TDS is an indicator of general water quality. The EPA sets a secondary drinking water standard for TDS at 500 mg/L. An elevated level of TDS is not a health hazard.\n- TOTAL ORGANIC CARBON - TOC is a measure of the level of organic molecules or contaminants in purified water. TOC in itself has no health effects but provides a medium for the formation of toxic disinfection by-products.\n- TURBIDITY - Turbidity is the measure of relative clarity of a liquid. Material that causes water to be turbid include clay, silt, finely divided inorganic and organic matter algae, soluble colored organic compounds, plankton, and other microscopic organisms.\n- ULTRAVIOLET ABSORPTION (UVA) - UVA represents the amount of light absorbed by constituents within water (light energy that does not reach the detector). UVA is commonly used as an indicator of general water-quality, or the potential for disinfection by-product formation."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:1c57d428-c6d1-46cd-ba4c-11fc852edf06>","<urn:uuid:6a3272c1-2ecb-4298-b9f3-96c3b5351984>"],"error":null}
{"question":"list pros/cons: friction stir vs shielded metal arc welding for aluminum-steel joints","answer":"For aluminum-steel joints: Friction stir welding produces high-strength and stable hybrid joints without fragile intermetallic compounds, allows simultaneous butt and overlap welding, and enables deep-drawing of the welded material. Shielded metal arc welding, while able to weld all engineering materials, has limitations with low melting and highly reactive metals, making it difficult to effectively join aluminum to steel. The process requires edge preparations for thick plates and preheating for some alloy steels.","context":["Joining Technology Modified Friction Stir Welding Creates Deep-Drawable Steel-Aluminum Hybrid Sheets\nThe Materials Testing Institute of the University of Stuttgart has developed a method based on friction stir welding which can be used to combine aluminum and steel sheets of different thicknesses.\nThe seam is so stable that the hybrid blanks can even be deep-drawn. According to the researchers, this is a good opportunity to produce lightweight and resilient components that offer new approaches to automotive engineering. The State Agency for Lightweight Design Baden-Württemberg presents this innovation in its monthly Thinking for June 2019.\nFriction Stir Welding is Like Baking a Marble Cake\n“When friction stir welding aluminum to steel, it's like baking a marble cake - the light and dark dough should form a bond, but must not be mixed to such an extent that only brown, mixed dough is produced,\" explains Martin Werz of the Material Testing Institute (MPA) at the University of Stuttgart. The mixed dough from the cake analogy is called intermetallic phases in aluminum-steel compounds, which are actually brittle, the expert explains. Friction stir welding, however, is a special joining process in which a rotating tool (the \"stirrer\", if you like) moves along the gap to be joined with a lot of force (hence the friction) and thus connects the blanks.\nSimultaneous Butt and Overlapping Welding\nThe scientist has succeeded in modifying the process and developing new tools for friction stir welding, which enables the high-strength welding of aluminum and steel sheets of different thicknesses. If steel and aluminum are welded using the well-known arc welding process, fragile intermetallic compounds occur. “Friction stir welding, on the other hand, produces high-strength and stable hybrid blanks,\" specifies Werz. These are also called \"Hybrid Tailor Welded Blanks”. The special feature of the MPA process is that the sheets can be butt welded and overlap welded simultaneously, thus achieving a larger cross-sectional area, which ensures greater strength and consequently also greater formability, explains Werz.\nWeld Seam Withstands Even Complex Deep-Drawing Effects\n“We've done several tensile tests. The weld seam has held, and the material of the specimens has already yielded far away from the seam - that's the way it should be,\" emphasizes Werz. The seam is so stable that the hybrid blanks can also be formed by deep drawing without the seam failing. “Even with complex geometries such as curves, the weld seam holds, says Werz. The researcher sees an area of application for the high-strength aluminum-steel hybrid structures above all in the automotive sector, where the advantages of thin sheets of high-strength steels and aluminum sheets with a slightly higher thickness can be exploited in one component. \"The result are components that are joined together to conserve resources and are significantly stiffer to buckling,\" he explains.\nFriction Stir Welded Hybrid Sheets Are Less Likely to Get a Dent\nWerz defines: “Dent stiffness is the resistance of a component to a load in the elastic area that acts perpendicular to the surface - that is, the material yields like a spring and returns to its original shape when the load is relieved, without leaving a permanent \"dent\".\nUntil now, hybridization in body design has only been achieved by assembling components made of different materials with extra fasteners, such as rivets. This causes additional material and time expenditure. And MPA development can already combine aluminum with steel in individual components. \"This opens up additional degrees of freedom in structural optimization that reduce weight on the vehicle,\" Werz is certain.\nIt also Works with Copper and Aluminum as Joining Partners\n“In addition to the welding process, we have also developed other parts of the process chain for our new process,\" notes Werz. This includes, for instance, a novel, energy-efficient heat treatment method and a special forming method which can take into account the difference in thickness of friction stir welded hybrid blanks. \"In addition, the technology we developed could also be used for welding copper and aluminum sheets of different thicknesses. This could become a new approach for manufacturing pool connectors for e-mobility,\" Werz imagines. The advantage: One could take advantage of the specific electrical resistances of the two metals when selecting the sheet thickness: For example, combining somewhat thicker but cheaper aluminum sheets with thinner copper sheets.\nBody-in-White Weight Reduced by 10 %\n“According to current estimates, it can be assumed that the use of appropriate hybrid circuit boards in automotive design will reduce the weight of the bodyshell by around 10 % while maintaining safety,\" predicts Werz. \"If we consider the entire service life and mileage of a passenger car, the weight reduction noticeably reduces fuel consumption and emissions,\" adds Dr. Wolfgang Seeliger, Managing Director of Leichtbau BW GmbH, during the Thinking June 2019.\nThis article was first published by MM MaschinenMarkt.\nOriginal by Peter Königsreuther / Translation by Alexander Stark","There are a number of welding processes available; however, their application is dictated by the mechanical properties, type of welded joints, their quality required in the service condition, cost and availability of the machine and operators skill.\nBelow discussion gives a comparative study of the different joining processes, their applicability to different types of materials and helps the welders in selecting suitable welding process.\n1. Shielded Metal Arc Welding\nShielded metal arc welding process is widely used in many industries. All engineering materials can be welded. however, low melting and high reactive metals will be difficult to weld. this process is easy to operate and plates of thickness ranging from 1 mm to 25 mm can be easily welded. Preheating will be required in some alloy steels. welding can be done in flat, inclined, vertical and overhead position. Edge preparations are essential in welding thick plates.\nManual arc welding is commonly used in the erection of structural works like storage tanks, bridge etc. In open breezy conditions, flux cored self-shielded welding is better suited. Heavier plates are usually grooved weld.\nTIG welding process is extensively used for welding cupronickel (70:30 alloy) for water pipe and condenser tubes. while welding carbon and alloy steel pipes by MMA (Manual Metal Arc) process for steam, power plants, backing rings are rarely used for piping in oil refineries and chemical plants.\n2. Submerged Arc Welding\nWith Submerged arc welding (SAW), carbon and alloy steels and copper alloys can be welded; generally applied for plate thickness above 10 mm. Best suited for automatic welding in boilers, pressure vessels, shipbuilding where high-quality welds for larger thickness plates are required. This process is generally used for flat and horizontal positions. Not suitable for cast iron.\n3. Oxy-acetylene Gas Welding\nOxy-acetylene gas welding process can be used for carbon steel, copper, aluminum, bronze welding, Sheet metal welding. Small diameter pipe welding can be effectively carried out. Control of the flame is important, Plates of thickness up to 8 mm – 10 mm can be welded. Red brass and yellow brass are preferably welded by the oxy-acetylene process to minimize vaporization of zinc.\n4. Gas metal arc welding (TIG and MIG)\nAll engineering material except zinc can be welded using gas metal arc welding (GMAW) process The thickness of the plates ranges from 1 mm to 6 mm. TIG welding process is applied to all non-ferrous and alloy steel welding and also for root pas in pipe welding. Welding equipment is more complex and costly. difficult to weld small corners and, out-door applications are limited. MIG welding process in semi-automatic or fully automatic form is used for non-ferrous and stainless steel pressure vessel parts. In the manufacture of boiler units, a large number of tube butt welds have to be made with the tubes positioned at any angle from horizontal to vertical, with restricted access. In such cases, automated orbital TIG welding with automatic cold wire feed is used. titanium alloy tubes with wall thickness 1.6 mm and below are normally welded by TIG process without filler wire. For heavier pipes, filler metals are used.\n5. Spot, Projection and seam welding\nThese processes meant for sheet metals are widely applied in automobile parts, tube manufacturing parts and sheet metal industries. all engineering metals can be welded. precautions are necessary in the case of copper and aluminum alloys which are good thermal and electrical conductors.\nFlash or induction welding is used for tubular joints in boiler construction. At the site, such welds are made by TIG for the root pass and manual metal arc welding for subsequent passes. Seam welding is normally limited to sheets up to 5 mm thick. Baffles and other interior parts are spots welded in place. A typical application of projection welding is in the manufacture of honeycomb panels. Propeller and drive shafts are commonly made of resistance welded tubing with the end forging are welded by submerged arc or MIG/CO2 process.\n6. Electro-slag Welding\nElectro-slag welding (ESW) process is for thick section welding, 5 cm and above, of alloy steels, This is mainly used for pressure vessel parts, steel plant types of equipment, large shafts etc. Both Electro-slag welding and Submerged-arc welding (SAW) are best suited for thick plates; however, ESW is more specialized in its application and less flexible compared to SAW.\n7. Electron and laser beam welding\nStainless steel, nickel base alloys, titanium and zirconium and other reactive metals up to 10 to 25 mm can be welded. Special applications are in electronic industries, nuclear and aerospace industries. The process is rather costly. Laser welding has the ability to make tiny spot welds. So it is applied in micro electronic circuits. The Laser beam can weld metals on silicon and germanium."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:1fc3ef9a-66c4-403e-86de-fa08de4fdfd2>","<urn:uuid:6aa14a5a-367f-4c9e-ad25-90a4a5ba8efd>"],"error":null}
{"question":"How does fresh mozzarella differ from traditional shredded mozzarella when melting on a pizza?","answer":"Fresh mozzarella melts differently due to its moisture content and surface area. It provides a much creamier texture and flavor compared to traditional shredded mozzarella. To ensure proper melting, it's recommended to slice or tear fresh mozzarella very thin so it melts right into the pizza.","context":["Fresh mozzarella sets your pizzeria apart\nScott Gittrich, president of Toppers Pizza, doesn’t mind his work commute.\nThat’s because since 1998, Whitewater, Wisconsin-based Toppers Pizza, which has 70 locations across 11 states, has used a local cheese company as its primary supplier and manufacturer for its mozzarella.\nLocated in Belgium, Wisconsin, the manufacturer receives milk from more than 130 local dairy farmers — the same farms Gittrich drives past.\n“When I hit the road I see the cows that are churning out the milk that ultimately becomes our cheese,” he says.\nToppers Pizza purchases an average of 40,000 pounds of mozzarella per week, with an excess of more than 160,000 pounds per month.\n“When I first got into the business, I didn’t have the knowledge and understanding of the delicate balance involved in crafting the perfect cheese. So, I leaned on Jeff (Jeff Hiller, president at Cedar Valley Cheese) and his team’s expertise,” Gittrich says.\nDeciding to bring fresh mozzarella production in-house or purchasing it from a supplier can be a make-or-break business decision. For Gittrich, it was an easy one. “As we expand, it’s good to know that our cheese partner is right down the road,” he says.\nJames Schroeder, chef /operating partner at Piezzetta Restaurant in Baltimore, Maryland, also purchases fresh hand-pulled mozzarella from a supplier.\n“We were in the process of opening a new restaurant with a new staff and decided that consistency was paramount,” he says. “Then we found a product that we really liked.”\nTwice weekly, shipments of plastic wrapped mozzarella arrive. “Because the cheese is wrapped instead of stored in liquid it’s a bit dryer, and I really like that,” says Schroeder.\nHe also finds fresh mozzarella melts differently than traditionally shredded mozzarella. “The moisture content and surface area is significantly different. The fresh mozzarella has a much creamier texture and flavor,” says Schroeder, who prefers to slice or tear fresh mozzarella very thin so it melts right into a pizza.\nMichael Pasquarello, chef/owner at Bufad in Philadelphia, Pennsylvania, purchases fresh mozzarella simply because “If I don’t think I can make it better, I will buy it from someone who can,” Passquarello says. He uses a fior di latte mozzarella from a top-of-the-line manufacturer.\n“The cheesemakers are consistent while still having that small production quality,” he says.\nSome operators prefer making their own fresh mozzarella. For example, Fabrizio Cavallini, chef at Monello in San Diego, California, makes 20 mozzarellas twice a week. “We take pride in our Milanese culture. This was another perfect way to show off our culture,” he says.\nHis fresh mozzarella appears in a Caprese salad, pizza and in “carrozza,” which is a mozzarella sandwich dipped in yolks and lightly fried.\nPedro Arreaza, market sous chef at FarmTable Kitchen (part of Locale Market), based in St. Petersburg, Florida, assures that fresh mozzarella is not hard to make.\n“It’s a good idea to make it fresh, not only for the art of making mozzarella, but also because it looks really cool to customers,” he says. “People are more attracted to mozzarella when they see it being created. A lot of people have never seen that process done before.”\nFor his fresh mozzarella, Arreaza uses an all-natural curd from a supplier. He cuts the curd with a chitarra, a string tool shaped like a guitar. Then he adds salt and uses two stages of water. The first stage brings the curd to temperature. Then he drains about 90 percent of the water and leaves a bit of the brine in it. The final stage is stretching the mozzarella.\n“Once you add that second stage, it gets super soft and stretchable,” Arreaza says. “You can work the mozzarella together. I usually use a big wooden spoon to be able to pick it up and stretch it out. Once the mozzarella gets all bubbly, it is telling you that it is ready to be shaped.”\nArreaza has an ice bath waiting to shock the mozzarella. He adds a bit of salt to the ice bath to incorporate seasoning into the cheese.\nHe shapes the mozzarella into balls or logs wrapped in plastic wrap, making sure there isn’t too much air in the cheese. For logs, rolling the mozzarella naturally forms a log shape.\n“I tie the ends and submerge it in the ice bath for five to 10 minutes so it keeps its log shape. When they slice it for pizza, we want to have a nice, sliced round that melts well and gets a good color in the oven,” Arreaza says.\nIf you’re indecisive about whether to purchase or make your own fresh mozzarella, Pasquarello offers this recommendation: Make your own and buy some that inspires you. Then compare the two.\n“Don’t even think about making it for your customers until you can make it better than your favorite producer,” he says.\nMelanie Wolkoff Wachsman is a freelance writer in Louisville, Kentucky. She covers food, business and lifestyle trends."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:5156a588-a534-4516-b118-b1dd691d9ea3>"],"error":null}
{"question":"Compare Dogen's approach to environmentalism in his poetry vs Sotoshu's modern environmental initiatives - what's the key philosophical difference?","answer":"The key philosophical difference is that Dogen's environmental approach focused on the inherent unity and non-separation between humans and nature, as shown in his poetic expressions like 'each grass and each form itself is the entire earth' and how elements like 'clouds, rain, wind and water' receive Buddhist teachings. In contrast, Sotoshu's modern environmental initiatives, as part of their 'human rights, peace and environment' activities since 1991, take a more practical approach focused on sustainable development and environmental protection as explicit goals to be achieved through conscious effort.","context":["Since 1991 Sotoshu has been engaged in a variety of activities under the banner of “human rights, peace and environment”. And since in 2015 all the members of the UN signed the agreement of the Sustainable Development Goals (SDG’s) with the purpose of “Leaving no one behind”, Sotoshu has great interest in encouraging practitioners of this tradition, from the Bodhisattva's own vows, to commit in a practice that reflects these goals of including all beings in a better world.\nAlthough all the 17 points of the SDGs are of vital importance to build fair, inclusive and respectful societies, the sixteenth point, “Peace, justice and solid institutions”, is one of the aspects that has touched the most our Zen Temple Magnanimous Mind, Daishinji. In our commitment to offer a practice that helps alleviate so much suffering in our country, we have launched campaigns to make our practice known as a transformational alternative to relate to life in a healthy way and modify how we relate to other beings and to life in general.\nIn Colombia we have experienced great suffering for decades, due to social injustice, economic imbalance, insecurity, lack of educational resources, war and drug trafficking, among others. But the violence is not limited to the political struggle, the interests of criminal organizations or the armed conflict. We can see it in the way we treat each other, racism, classism; in general, contempt for others and everything that is different. Having been born in a country that experiences so much suffering, when I first met Soto Zen in the mid-80s, I understood very early that this practice, as passed down from Shakyamuni Buddha, offers powerful elements to help us liberate other beings from suffering and to find relief to our own dissatisfaction. To arouse the aspiration for enlightenment involves decentering attention from our own need for gratification and taking care of others, just like a mother who takes care of all her children equally.\nDuring the celebration of 110th anniversary of the arrival of Sotoshu in South America, held in Lima, Peru, in 2013, the group of teachers signed the commitment to hold a Latin American Zen Encounter that would include practitioners of various traditions, to promote the teachings of Zen Buddhism, to have a positive impact in our countries. Thus, in 2016, we held the Third Latin American Zen Encounter in Bogotá. At that time, the Colombian government was signing a peace agreement after more than 50 years of armed struggle with the FARC guerrillas. We proposed the Encounter as a concrete and positive response to alleviate the suffering of so many years of struggle and we offered our practice as a tool for the consolidation of a lasting peace and the construction of a healthy society.\nAt a global level, we are experiencing a historical moment of chaos after the recent pandemic, the economy hardship and numerous wars: there is a lot of uncertainty and a lot of fear. We think things have never been this bad. But if we look at the history of mankind, since immemorial time, the poisons of the mind have led nations to invade others out of greed or hatred. Already in Buddha's time there were numerous wars. In fact, ancient texts say that Shakyamuni Buddha himself not only preached non-violence and peace, but also went to the battlefield to prevent a war between the kingdom of Maggadha and the Vajji tribe, who disputed the hegemony of the waters of the Rohini River. Shakyamuni's words prevented King Ajjatasstru from attacking the Vajji. But in addition to border issues, Buddha influenced the internal condition of the kingdoms, addressing the sovereigns and proposing more benevolent policies that ended the abuses towards the people. The Master was no stranger to the suffering caused by some inhuman sovereigns, who took advantage of the misery of the people to enrich themselves, excessively increasing taxes and imposing severe punishments. Shakyamuni, in person, concerned himself with improving relations between the King and his people, wrote “The Ten Duties of the King”*1 in order to prevent the people from becoming corrupt, degenerate and unhappy due to bad government.\nThese are early evidences of how Buddhism has been concerned with bringing peace in a concrete way, beyond the walls of the temples themselves. However, we must understand that peace is not something external like weather conditions. Producing lasting peace is only possible through a joint and sustained effort, committing ourselves individually to transform our own way of relating to life. This is the Buddhist principle of non-violence, ahimsa, which not only means that no one should be harmed, but also it is our obligation to strive to promote peace by avoiding any warlike confrontation and everything that implies violence or the destruction of lives, including respect for animals and for nature. It is not possible to achieve peace abroad if society is not made up by individuals who are at peace with their own existence; individuals who, from their understanding, include others, and are tolerant of diversity and respectful towards others' ideas.\nDogen Zenji says that our practice of zazen is itself the dharma gate of ease and joy. But our practice is not limited to the sitting position. We must strive to express our understanding of this awakening in everyday life. To the extent that we act manifesting our certainty of the laws of existence to which we have awakened in our practice, we can act in opposition to egocentric tendencies and creatively influence the development of a healthy and peaceful society. Master Dogen gives us concrete tools to actualize our vows in everyday life. In the Tenzo Kyokun “Instructions for the Cook”, he talks about the importance of producing the three minds: magnanimous mind, joyful mind, and nurturing mind. It is about the attitudes that as Bodhisattvas we must seek to include others in a joyful way with a heart of a grandmother. Additionally, in the Shobogenzo chapter Bodaisatta Shishobo, he tells us about the Bodhisattva’s Four Embracing Dharmas, or attitudes to alleviate suffering. He invites us to be generous, careful with speech, to perform kind actions and to recognize the value of others. When our actions are directed by thinking that we can affect others in a positive way instead of causing them suffering, we displace self-focused attention and direct it to “everything else”. Thus, we can recognize the interconnectedness with everything and awaken to the incessant flow of reality. To build fair, balanced and peaceful societies, we must find peace by recognizing others and assuming responsibility for the consequences of own actions.\nThus, our vote as the Soto Zen Community of Colombia is to offer this practice in our country so that more people can find the dharma gate of ease and joy and creatively contribute to the construction of a respectful, tolerant, generous, inclusive and nonviolent society. Thus, we express our commitment to promote the construction of nations with solid, fair and peaceful institutions.\n*1 Rahula, Walpola. “What the Buddha Taught”. Grove Press. N.Y. 1974. Pp. 85\nRev. Densho Quintero is a Soto Zen priest, Dharma heir of Shohaku Okumura Roshi. In 2013 he was appointed Sotoshu missionary teacher. At present, Densho is the head Teacher of (Magnanimous Mind) Daishin Temple of the Colombian Soto Zen Community in Bogota.\nComunidad Soto Zen de Colombia Daishinji (妙法山大心寺）\nAddress: Carrera 22 # 82-19 – Barrio El Polo Bogotá, Colombia","Calligraphic Drawings for\nZen Master Dogen's Ecological Healing of the Earth\nPage 1 | Page 2 | Citation Sources\nAll artwork by Sarah L. Whitworth\nSee Introduction to Dogen's Gender Inclusive Zen\nD-B - Dogen's poem, ON A PORTRAIT OF MYSELF:\nCold lake, for thousands of yards, soaks up sky color.\nEvening quiet: a fish of brocade scales reaches bottom, then goes\nFirst this way, then that way: arrow notch splits.\nEndless water surface, moonlight brilliant.\nD-B - Butterfly above Water -- Citation from Dogen's BAIKA:\nThis is the time for humans and heavenly beings\nto turn towards attaining the way,\nas the old Buddha's dharma wheel is turned\nto the extreme limit of the entire world.\nEven clouds, rain, wind and water,\nas well as grass, trees, and insects,\ndo not fail to receive the benefit of this teaching.\nHeaven and earth, and land\nare vigorously turned by this dharma wheel.\nD-U - The Entire Earth -- Citation from Dogen's UJI:\nThere are myriads of forms|\nand hundreds of grasses throughout the entire earth,\nand yet each grass and each form itself\nis the entire earth.\nThe study of this\nis the beginning of practice.\nD-BSH - Billowing Leaf -- Citation from Dogen's BODAISATTA SHISHO-HO:\n||To launch a boat or build a bridge|\nis an act of giving.\nIf you study giving closely,\nyou see that to accept a body\nand to give up a body\nare both giving.\nMaking a living and producing things\ncan be nothing other than giving.\nTo leave flowers to the wind,\nto leave birds to the seasons,\nare also acts of giving.\nD-KS - True Self/True Earth - Citation from Dogen's KEISEI SANSHOKU:\nA certain monk who was a disciple of Chang-sha Ching Chi'en asked him,\n\"How can I unite the mountains, streams\nand the great earth\nThe master replied, \"How can you unite yourself\nwith the mountains, streams and great earth?\"\nWhat is meant here is that if you are not anything other than your true self, then whether you speak of yourself being united with the mountains, streams and great earth, [or the mountains, streams and great earth united with yourself], there should not be any difference between what unites and that with which one is united.\nD-BW - Earth Buddha -- Citation from Dogen's BENDO-WA:\n||There are those who, attracted|\nby grass, flowers, mountains and waters,\nflow into the Buddha Way.\nAnd there are those who, grasping\nearth, rocks, sand and pebbles,\nmanifest the Buddha's seal.\nIn fact although the boundless\nwords of the Buddha\noverflow among myriad things,\nthe turning of the great dharma wheel,\ninside a single particle.\nD-YY - Things As They Are -- Citation from Dogen's YUIBUTSU-YOBUTSU:\nBeing unstained is like meeting a person|\nand not considering what he or she looks like.\nAlso it is like not wishing for more color or brightness\nwhen viewing flowers or the moon.\nSo when you want spring or autumn\nto be different than it is\nnotice that it can only be as it is.\nOr when you want to keep spring or autumn as it is\nreflect that it has no unchanging nature.\nD-SK - Balancing a Whirlwind -- Citation from Dogen's SANSUI-KYO:\nTo say that the world|\nis resting on the wheel of space or on the wheel of wind\nis not the truth of the self or the truth of others.\nSuch a statement is based only on a small view.\nPeople speak this way because they think\nthat it must be impossible to exist\nwithout having a place on which to rest.\nBuddha said, \"All things are ultimately liberated.\nThere is nowhere that they abide.\"\nYou should know that even though all things\nare liberated and not tied to anything,\nthey abide in their own phenomenal expression.\nD-KS - Kitchen Chair -- Citation from Dogen's KOBUTSU-SHIN:\nThe \"ancient mind\" is so called|\nbecause it is the mind's antiquity.\nBecause the mind's Buddha\nshould always be ancient,\nthe ancient mind is chairs\nand bamboo trees.\nmore drawings & citations...pg.  2 - NEXT > >\ncitations from the writings\nof Zen Master Dogen (1200-1253)\nadapted (with line breaks added) from:\nMOON IN A DEWDROP\n(citation from Baika)\n(citation from Uji)\n(citation from Bodaisatta Shisho-ho)\n(citation from Bendo-wa)\nedited by Kazuaki Tanahashi, Northpoint Press, 1985\nTHE ESSENTIAL TEACHINGS OF ZEN MASTER DOGEN\n(citation: On a Portrait of Myself)\nedited by Kazuaki Tanahashi, Shambhala, 2000\nFLOWERS OF EMPTINESS\n(citation from Kobustu-Shin)\ntranslated by Hee-Jin Kim, Mellen Press, 1985\nHOW TO RAISE AN OX\n(citation from Keisei Sanshoku),\nFrancis Dojun Cook, Zen Center of Los Angeles, 1978\nTHE ESSENCE OF DOGEN\n(citation from Shoji)\nCommentary by Masanobu Takahashi, translated by Yuzuru Nobuoka\nKegan Paul Internation, 1983\nTREASURY OF THE TRUE DHARMA EYE\n(citation from Yuibutsu-Yobutsu)\nedited by Kazuaki Tanahashi, Shambhala, 2010\n|Webpage and Dogen Portrait (top): earlywomenmasters.net|\nink drawings by Sarah L. Whitworth | See PAGE 2"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:552f52a3-792d-496c-8f94-a9e19557c09e>","<urn:uuid:2bc67811-4cd9-4634-aeff-139407317894>"],"error":null}
{"question":"Why did both postcolonial writers and Ivan Izquierdo move from their home countries to new places? I want to know if there are similar reasons!","answer":"Both postcolonial writers and Ivan Izquierdo relocated due to political circumstances and the search for freedom of expression. In postcolonial contexts, writers moved to transform and redirect imperial control while maintaining control over self-representation. Similarly, Izquierdo moved from Argentina to Brazil in the early 1970s due to the Argentine dictatorship, as well as personal reasons (his wife being Brazilian). After moving to Porto Alegre in 1978, he established himself at Brazilian institutions where he could freely pursue his scientific research, training 42 Ph.D. students and publishing over 500 scientific papers.","context":["Grant Hamilton interviews cultural and literary critic Bill Ashcroft about his new book on utopia and postcolonial writing. They discuss the concept of utopia and why it finds its way so forcefully into the literature of previously colonized nations.\nBill Ashcroft, Utopianism in Postcolonial Literatures (London: Routledge, 2016) 238pp.\nBill Ashcroft is an Australian Professorial Fellow in the University of New South Wales, Australia. He is author and co-author of sixteen books, including the seminal text The Empire Writes Back (1989), and is one of the leading figures in Postcolonial Studies. Here we were able to ask him some brief questions about his latest book as part of the HKRB Interviews series with writers of new books in critical theory.\nGrant Hamilton: For those of us who have been reading your work for a number of years now, it is clear that you have had a very considerable interest in the notion of transformation. How does this feed into your newest work, Utopianism in Postcolonial Literatures?\nBill Ashcroft: My interest in transformation stems from a long-standing uneasiness with the habit of postcolonial theory to see the relationship between the colonizer and colonized as purely hierarchical, the only response of postcolonial societies being one of opposition. This tended to frame postcolonial subjects as cyphers identifiable only by their subjection to imperial domination, without agency and without any recourse to a self-articulated future. In fact, the response of postcolonial societies has been much more subtle and the critical demonstration of this is the appropriation and abrogation of the English language. Postcolonial writers appropriated the language of the colonizer while abrogating its dominance and centrality. This led to a transformation of English, which has underpinned the radical innovation of postcolonial literatures. The transformation of language and literature into a locally relevant discourse is just one example of the transformative cultural power of postcolonial societies. In all kinds of cultural spheres these societies found that the most effective form of resistance to the tide of imperial control lay not in trying to dam it up but to redirect it into discourses over which those societies could maintain control, particularly the control over self-representation. Utopianism is crucial here because transformation can only be driven by the possibility, indeed the certainty, of change. Utopia is an unachievable place but it lies there shimmering in the imagination as a way of driving the utopian belief that things can be better and that freedom is possible. The idea of perfection has given the term ‘utopia’ the character of a dream or an illusion, but the utopian spirit persists in postcolonial societies as the very definition of the possibility of a better world. As Ernst Bloch puts it: utopia may be a fantasy but without hope we cannot live. So postcolonial utopianism arises from the fact that successful resistance is transformative, and transformation rests on the belief in an achievable future.\nBill Ashcroft, for the HKRB by Roy Christopher\nGH: In the introduction to your book, you reference Hungarian sociologist Karl Mannheim’s extraordinarily insightful observation that “utopias are ideas” that are “incongruous with the state of reality within which [they] occur.” To me this simply means that utopias are always untimely – that they are expressions of ideas that are not of their time. If this is so, doesn’t the explosion of utopian writing and thinking in the twentieth century tell us all we need to know about the condition of the contemporary world?\nBA: Mannheim made this point about both ideologies and utopias. His most important insight was that ideologies work to sustain the present state of things, while utopias serve to bring about change. It is no accident that from Bloch to Jameson it has been Marxists who have driven the fascination with utopianism in the 20th century because we have entered the period of neo-liberal capitalism in which no option to the dominance of markets nor to the radical inequality in the world is deemed possible. The ideology of capitalism works to sustain the status quo and it is a crucial and strategic utopianism that serves to bring about change. I think that postcolonial utopianism is critical here, not only because of the imperialistic nature of global capital, but also because it demonstrates the power of transformation. As Jameson says, it’s easier to think of the end of the world rather than the end of capitalism.\nGH: One of the most fascinating aspects of utopia that you discuss here is its wonderfully intricate temporality. If nothing else, as you say, the delicate relationship between the past, present, and future in utopian thinking foregrounds the significance of the postcolonial urge to contest (Eurocentric) history. But, given that our late capitalist world makes meta-narratives like history untenable, to what extent is the explosion of utopianism that you trace through postcolonial literatures something of an inevitability rather than a considered critical response to material reality?\nBA: Despite the end of history thesis I don’t think that History has lost its power, principally because there is a deep collusion between the modernizing narratives of citizenship, the ‘public sphere’ and the nation-state. Despite the apparent subservience of the nation-state to global capitalism and the success with which capital evades state taxes, global capital relies on the support of the nation-state and the state rests upon the history without which it struggles for identity. Furthermore, as Ashish Nandy says “Historical consciousness now owns the globe […] Though millions of people continue to stay outside history, millions have, since the days of Marx, dutifully migrated to the empire of history to become its loyal subjects.” This is where the circularity of postcolonial time becomes so important. The universality of Eurocentric history (and remember what Chakrabarty says, that all history is ultimately the history of Europe) cannot be prevented, but it can be circumvented. Circular time, developed from oral forms of story telling lies at the base of this. Among other things the postcolonial habit of seeing the future in the past identifies revolution as a revolving through time rather than a revolt against history. The concept of a spiral into the future that we find in so much postcolonial narrative perfectly captures the utopian hope without which resistance could not take place. Importantly, it demonstrates the way the future emerges from the past in postcolonial literatures. The future, or the “In-Front-Of-Us,” as Ernst Bloch puts it, is always a possibility emerging from the past, not as nostalgia but as renewal. It is amazing to discover how widespread this is in postcolonial societies, the circularity of time present in the various languages themselves as well as cultural narratives, which draw their hope for the future from the power of the past.\nGH: I was struck when reading the opening of chapter one by the observation you make about America as something of an absent presence in English literature until the eighteenth century. Why do you think America was so roundly ignored by English writers following its discovery?\nBA: One can only speculate about this, but it is obviously tied up with the progress of English expansion, which didn’t really come until the early seventeenth century. Even then it didn’t appear in the literature until the eighteenth. The cause must first lie in England’s overriding obsession with Europe and its various alliances and enmities. But another reason for the absence of America is that Utopia began a fascination with islands, which were particularly interesting to a maritime power because islands raised the issue of the ‘law of the seas’ and the question of the oceans as a ‘free domain’. If it is not claiming too much for More’s Utopia, the book asserted the dominance of islands in the English imagination at the emergence of what Lefebvre calls ‘historical space’. Thus the absence of America is countered by the reality of Britain as an island and its future invested in the oceans. All the utopias that followed More’s were set either on islands or in a particular circumscribed space. It is arguable that even though Robinson Crusoe is set on an island it really cemented the concept of colonization as ‘improvement’, even though long before the actual settlement of colonies.\nGH: Later in your book, you say that the Caribbean archipelago has been “the most fertile and resourceful generator of postcolonial future thinking.” What is it about the islands and its people that accounts for this seemingly insatiable appetite for the future promised by utopianism?\nBA: The initial reason for this lies in the strategies of control by which the colonizing powers instituted slavery in the islands. Work gangs were composed of people from various African language groups to prevent the possibility of insurrection. However, what occurred was the development of hybrid creoles of various kinds in what has been called the ‘creole continuum’. This provided the basis for a transformation of the dominant language, as poets and novelists began to produce their work, which is unmatched in any other colonial region. But there is another more subtle reason that is tied up with the nature of archipelagic space. Obviously islands are open in ways that a mainland cannot be, but the Caribbean – which has a regional imaginaire (often referred to as the West Indies) – generates remarkable forms of fluidity and openness in everything from language and literature to history and myth, including effects such as carnival, politics, religion, folklore and food. We can see this in the literature, particularly in the work of the major poets such as Derek Walcott and Kamau Brathwaite, where the concept of flow and archipelagic interaction affect both their poetry and their talk about poetry. The theoretical dimension of this can be seen in Brathwaite’s concept of ‘tidalectics’, which talks in terms of ebb and flow rather than the European notion of dialectics\nGH: By way of bringing this conversation to a close, I’d be delighted to know which writers you think best capture the force of utopianism in their writing – and which new writers those of us interested in postcolonial writing and utopian literatures should keep an eye out for in the future.\nBA: Once you recognize the importance of hope, of the significance of a belief in the possibility of change, utopianism can be found everywhere, in all colonized, subaltern literatures. Perhaps the most overtly and consistently utopian writer is the Angolan poet Agostinho Neto, particularly his volume Sacred Hope. But the best place to keep and eye out for the spirit of utopianism is in those literatures that seem to be the cry of the most oppressed. In this I would include most African writing, Palestinian literature, Chicano writing and perhaps most interestingly, Aboriginal literature. That literature most often classed as the literature of resistance and rebellion, of passionate cultural critique, is always buoyed up by the power of hope for the future. It is extraordinary that this utopian hope is so often drowned out in commentary by the drama of insurgency. But without hope, transformative resistance could not occur.\nGrant Hamilton is Associate Professor of English literature at the Chinese University of Hong Kong. He teaches and writes in the areas of contemporary world literatures and literary theory. His latest books include The World of Failing Machines (Zero Books, 2016) and A Companion to Mia Couto (James Currey, 2016), co-edited with David Huddart.\nRoy Christopher is the featured illustrator on this post. Roy marshals the middle between Mathers and McLuhan. He was assistant editor of Paul D. Miller a.k.a. DJ Spooky’s Sound Unbound: Sampling Digital Culture and Music (MIT Press, 2008), and his first book is Follow for Now: Interviews with Friends and Heroes (Well-Red Bear, 2007). He is currently a Visiting Assistant Professor in the Communication Department at the University of Illinois-Chicago. He holds a Ph.D. in Communication Studies from the University of Texas at Austin. His research interests lie mainly in figurative language use and media theory. He is currently working on books about both. As a child, he solved the Rubik’s Cube competitively. He writes regularly at http://roychristopher.com\nPlease support the HKRB and look out for more interviews and reviews by following our Facebook page.","|Ivan Antonio Izquierdo|\nDr. Ivan Izquierdo\nBuenos Aires, Argentina\n|Residence||Buenos Aires, Argentina\nPorto Alegre, Rio Grande do Sul\n|Institutions||Universidad Nacional de Córdoba\nUniversidade Federal do Rio Grande do Sul\nPontifícia Universidade Católica do Rio Grande do Sul\n|Alma mater||University of Buenos Aires|\n|Known for||Study of memory in mammals|\n|Notable awards||Ordem Nacional do Mérito Científico\nOrdem de Rio Branco\nDoctor honoris causa, University of Buenos Aires\nDr. Ivan Antonio Izquierdo is a renowned Argentine Brazilian scientist and a pioneer in the study of the neurobiology of learning and memory. Born in 1937 in Buenos Aires, Argentina, Izquierdo has graduated in Medicine (1961) and completed his Ph.D. in Pharmacology (1962), both in the University of Buenos Aires (UBA). For nearly a decade, Izquierdo taught at National University of Cordoba (UNC), in Argentina, but, due to a number of reasons, both political (the Argentinian dictatorship) and personal (his wife, Ivone, is Brazilian), he moved to Brazil in the beginning of the 1970s, and has lived in Porto Alegre since 1978. For more than 20 years, he has worked in the \"Center of Memory\" of the Biochemistry Department of the Health Basic Sciences Institute (ICBS) at the Federal University of Rio Grande do Sul (UFRGS), where he has had an enormous influence on young scientists: he has trained 42 Ph.D. students, most of whom hold academic research positions in universities in Brazil and elsewhere. Recently, he moved to the Pontificial Catholic University of Rio Grande do Sul (PUCRS) where he continues with his research.\nIvan Izquierdo has made several key contributions to the understanding of the cellular basis of brain processes underlying memory storage and retrieval. His research work is focused in the biological mechanisms of memory processes, employing multiple experimental approaches that range from behavioral psychobiology to neurochemistry, pharmacology, neurophysiology and experimental neurology, usually employing intracerebral microinfusions of drugs and assaying its effects upon different brain receptors, cellular processes, and, in particular, behavioral performance in different tasks. He was among the first to reveal the roles of epinephrine, dopamine, endogenous opioid peptides and acetylcholine in modulating memory consolidation and state-dependent memory retrieval. Later he has investigated benzodiazepine and GABAergic influences on memory. Some of his main achievements include the molecular bases of memory formation, retrieval, persistence and extinction in the mammal brain, the endogenous state dependency, and the functional discrimination between short and long-term memory.\nOver the years, Ivan Izquierdo has published more than 500 scientific papers in refereed journals and was, for years, one of the most cited scientists in Brazil (and Latin America): 13 of his papers have been cited over 100 times, and since 1958 his papers have received over 10,000 citations. He has also published 17 books, 6 of which are fiction / chronicle, a recent, parallel avenue of personal interest.\nMember of several Academies of Sciences in Brazil and abroad - he was elected Foreign Member of the National Academy of Sciences, USA, on May 1, 2007 - and has earned more than 30 important national and international awards, including the highest civilian badge of honor of Brazil, the Ordem do Barão do Rio Branco\" (2007). In Argentina, Izquierdo is the eighth person since 1821 to be named Honorary Professor of the University of Buenos Aires: the other seven were Nobel Laureates.\n- Trivedi, B. P. (2010). \"Profile of Ivan Izquierdo\". Proceedings of the National Academy of Sciences 107 (34): 14947–14949. doi:10.1073/pnas.1010117107. PMC 2930525. PMID 20696922.\n- Izquierdo, I.; Medina, J. H. (1997). \"Memory Formation: The Sequence of Biochemical Events in the Hippocampus and Its Connection to Activity in Other Brain Structures\". Neurobiology of Learning and Memory 68 (3): 285–316. doi:10.1006/nlme.1997.3799. PMID 9398590.\n- Izquierdo, I. N.; Barros, D. M.; Mello e Souza, T.; De Souza, M. M.; Izquierdo, L. A.; Medina, J. H. (1998). \"Mechanisms for memory types differ\". Nature 393 (6686): 635–636. doi:10.1038/31371. PMID 9641675.\n- Izquierdo, I. N.; Bevilaqua, L. R. M.; Rossato, J. I.; Bonini, J. S.; Medina, J. H.; Cammarota, M. N. (2006). \"Different molecular cascades in different sites of the brain control memory consolidation\". Trends in Neurosciences 29 (9): 496–505. doi:10.1016/j.tins.2006.07.005. PMID 16872686.\n- Bekinschtein, P.; Cammarota, M. N.; Igaz, L. M. L.; Bevilaqua, L. R. M.; Izquierdo, I. N.; Medina, J. H. (2007). \"Persistence of Long-Term Memory Storage Requires a Late Protein Synthesis- and BDNF- Dependent Phase in the Hippocampus\". Neuron 53 (2): 261–277. doi:10.1016/j.neuron.2006.11.025. PMID 17224407.\n- Rossato, J. I.; Bevilaqua, L. R. M.; Izquierdo, I.; Medina, J. H.; Cammarota, M. (2009). \"Dopamine Controls Persistence of Long-Term Memory Storage\". Science 325 (5943): 1017–1020. doi:10.1126/science.1172545. PMID 19696353.\n- Da Silva, W. C.; Cardoso, G.; Bonini, J. S.; Benetti, F.; Izquierdo, I. (2013). \"Memory reconsolidation and its maintenance depend on L-voltage-dependent calcium channels and CaMKII functions regulating protein turnover in the hippocampus\". Proceedings of the National Academy of Sciences 110 (16): 6566. doi:10.1073/pnas.1302356110.\n- New Members Chosen By Academy (The National Academies NEWS, May 1, 2007)\n- ORDEM NACIONAL DO MÉRITO CIENTÍFICO - Brazilian Academy of Sciences (in portuguese)\n- Profile of Ivan A Izquierdo - Brazilian Academy of Sciences (in portuguese)\n- Curriculum Vitae of Ivan A Izquierdo (in portuguese)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:8129843b-e7a4-410b-a9be-05393c660ebd>","<urn:uuid:67d82c9f-561f-417f-9425-7f187fa6d21b>"],"error":null}
{"question":"How does PyroLance fight fires effectively, and what safety responsibilities do employees have when handling hazardous substances?","answer":"PyroLance fights fires by propelling ultra-high pressure water or foam through solid materials like steel, brick, and concrete, allowing firefighters to control fires from outside hazard zones. It uses small water volumes efficiently and can penetrate materials quickly (e.g., brick wall in 30 seconds, plate steel in 55 seconds). As for safety responsibilities, employees must make proper use of control measures, wear and store PPE correctly, remove PPE before eating/drinking, maintain personal hygiene, report defects in control measures, and comply with provided training when handling hazardous substances.","context":["PyroLance tackles interior fires by propelling high pressure liquid through solid materials like steel and brick.\nTechnology being displayed to civil defence teams throughout the UAE and during Intersec exhibition.\nA revolutionary firefighting tool that blasts liquid through solid structures to tackle interior fires has been introduced to the UAE by Concorde-Corodex Group, the UAE-based provider of a wide range of services including fire-fighting equipment.\nThe PyroLance is a handset that can propel an ultra-high pressure stream of water or foam through materials including brick, marble, concrete and steel plate, allowing fire crews to safely control fires before entering a burning structure.\nThe niche technology is being tested by fire experts and civil defence teams throughout the UAE, and will undergo live demonstrations at this month’s Intersec 2016, the region’s largest fire safety exhibition.\nCorodex Agencies and Corodex Trading – two companies within the Concorde-Corodex Group – will be the sole distributors and suppliers of PyroLance in the UAE, Oman and Qatar, and the first to introduce the US-manufactured system to these countries.\nMahmoud Awad, Managing Director of Concorde-Corodex Group said: “Concorde-Corodex Group is thrilled to once again be introducing a new and innovative product to the region.\n“PyroLance is a game-changing system that will have a huge impact on regional firefighters’ ability to control fires in enclosed spaces – which are notoriously dangerous and difficult to extinguish – while keeping them out of harm’s way.”\nThe key advantage of the PyroLance system is that it gives firefighters the ability to engage fires and cool burning structures through hardened barriers like concrete walls or steel bulkheads, keeping them outside the hazard zone.\nThe US Navy uses it to control high heat fires in confined spaces within submarines or ships before entering the vessel.\nIn comparison, conventional firefighting operations require direct line of sight between the firefighter and the fire, and introduce large amounts of oxygen, which places firefighters in life-threatening situations such as the notorious ‘backdraft’ or ‘flashover’.\nPyroLance also allows firefighters to control blazes using very small volumes of water, resulting in a highly efficient method of firefighting that reduces manpower requirements, water consumption and collateral destruction.\nIn order to fully display its capabilities, a series of demonstrations are being held throughout the region to control a flammable liquid fire inside a compartment through a 10mm steel barrier using water and firefighting foam.\nA live demo will be held four times a day (at 11:00, 13:00, 15:00 and 16:30) on each day of the Intersec exhibition, which runs from January 17-19 at the Dubai International Convention and Exhibition Centre.\n“With the correct training, PyroLance will provide firefighters throughout the region with a safer means of fighting fires in a range of hazardous environments and a surgical tool to access fires where conventional means fail,” said Mr Awad.\n“The live demos are a high-effective and dramatic means of displaying the power and versatility of this incredible tool.”\nFor a video demonstration of the PyroLance technology, visit: http://bit.ly/1kLxEYq\nPyroLance Piercing time\n- 6 mm aluminum: 10 seconds\n- Brick wall: 30 seconds\n- 19mm double plywood: 30 seconds\n- Concrete block: 35 seconds\n- 19 mm plate steel: 55 seconds\nFor more information, go to www.corodex.com","COSHH – A Guide to Employers’ and Employees’ Responsibilities\nEmployee Responsibilities under COSHH\nEmployee responsibilities within the COSHH (Control of Substances Hazardous to Health) Regulations of 2002 include:\n- Making use of control measures and facilities provided by the employer\n- Ensuring equipment is returned and stored properly\n- Reporting defects/insufficiencies in control measures\n- Wearing and storing personal protective equipment (PPE)\n- Removing PPE that could cause contamination before eating or drinking\n- Making proper use of washing, showering and bathing facilities when required\n- Maintaining a high level of personal hygiene\n- Complying with any information, instruction or training that is provided\nEmployer Responsibilities Under COSHH\nUnder COSHH regulations, employers’ responsibilities include:\n- Implementing control measures to protect workers from hazardous substances.\n- Preventing or adequately controlling exposure to hazardous substances.\n- Providing employees with suitable and sufficient information, instruction and training, and appropriate protective equipment where necessary.\n- Ensuring that control measures are maintained, kept in full working order, and in a clean condition where appropriate.\n- Drawing up plans and procedures to deal with accidents and emergencies involving hazardous substances.\n- Ensuring that any employees exposed to hazardous substances whilst at work are under suitable health surveillance.\n- Ensuring that substances do not exceed the Workplace Exposure Limit (WEL).\n- Carrying out a COSHH risk assessment.\nNaturally, workplaces with higher risks, such as catering or a hair salon, will require more action than, say, an office. But as an employer, you should be assessing what risks may be posed by hazardous substances, no matter where you work.\nThat way, you can identify if there are risks and if so take action to reduce them to a minimum.\nCOSHH Risk Assessment\nA COSHH risk assessment is essentially the same as a standard risk assessment in terms of the process, but your assessment of the workplace will focus solely on hazardous substances.\nIf you’re unfamiliar with risk assessments, here’s a breakdown of the main 5 steps:\n- Identify the hazards.\n- Decide who might be harmed and how.\n- Evaluate the risks and decide on precautions.\n- Record your findings and implement them.\n- Review your assessment and update if necessary.\nRisk assessments will also involve frequently monitoring the workplace’s processes and the level of exposure to substances.\nWorkplaces are active and constantly changing, so a one-off check won’t be sufficient in minimising the risks posed by hazardous substances. You have to remain constantly vigilant and alert to the dangers.\nRecap: What is COSHH?\nCOSHH stands for the Control of Substances Hazardous to Health Regulations (2002). It exists to ensure that both employers and employees do all they can in a workplace to minimise people’s exposure to hazardous substances and work in ways that are safe.\nThis means that all hazardous substances need to be identified and precautions need to be taken to ensure that workers know how to use and handle them safely.\nThe importance of controlling hazardous substances cannot be overstated. In 2012/13, around 35,000 workers reported that they had breathing or lung problems caused by work, and the most common type of reported skin disease was contact dermatitis.\nAnd it’s estimated that around 13,000 deaths occur each year due to occupational lung disease and cancer – fatal conditions that will have developed over a prolonged period of exposure to dusts and chemicals at work.\nAs an employee or employer, you can prevent statistics like this from increasing. If you fulfil your workplace duties, you can prevent dangerous levels of exposure and meet COSHH requirements.\nRecap: What is a Hazardous Substance?\nSimply put, a hazardous substance is any mixture or substance that is toxic, irritant, or corrosive – whether it’s a liquid, gas, vapour, fume, or dust.\nThey cause harm to the body via routes of entry:\n- By coming into contact with skin or eyes.\n- By being inhaled.\n- By being ingested through the mouth.\n- By entering the body through cuts or punctures in the skin.\nAlthough there are certain industries that will be at greater risk, hazardous substances could exist in any workplace. They are often used directly in work activities, produced by work activities, or already present in your workplace’s premises.\nExamples of hazardous substances include:\n- Chemicals, e.g. cleaning chemicals or bleach.\n- Fumes, e.g. from paint or vehicles that exhaust.\n- Gases, e.g. ammonia from refrigerators.\n- Dusts and powder, e.g. from flour.\nIt’s worth noting that even seemingly innocent substances can be harmful, and that includes natural materials like wood dust or flour.\nWhile many hazardous substances can cause immediate harm, such as a corrosive liquid being spilled onto someone’s skin, the main danger posed by hazardous substances is prolonged exposure. For example, if someone is in the presence of or uses a dangerous chemical for a long time, they could develop breathing difficulties or skin conditions.\nExamples of ill-health caused by hazardous substances includes:\n- Occupational asthma.\n- Occupational dermatitis.\n- Occupational cancers.\n- Skin irritation.\n- Infection from bacteria.\n- Injury or death as a result of exposure to toxic fumes.\nWhat to Read Next:\nSubscribe for the latest Hub updates! Tell us what you're interested in hearing about:"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"short"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_language_proficiency_implied","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:fb965518-8b0d-42cb-94c2-79ba82895e62>","<urn:uuid:e2c99559-4fd5-48cf-884f-dca2baae7e40>"],"error":null}
{"question":"I am wondering what is the real impact of workplace accidents in world economy. Could you explain with numbers and examples how serious this problem is?","answer":"Workplace accidents and injuries have a staggering impact on the global economy and human life. Every 15 seconds, a worker dies from a work-related accident or disease, and 153 people experience a work-related injury. Annually, 2.78 million deaths occur due to work, meaning almost 7,700 persons die daily from work-related diseases or injuries. Additionally, there are 374 million non-fatal work-related injuries and illnesses each year. In economic terms, the total cost of illnesses, injuries and deaths amounts to 3.94 percent of the global gross domestic product (GDP), or about USD 2.99 trillion. This economic impact is nearly equal to the combined GDP of the 130 poorest countries in the world.","context":["by Elizabeth Gasiorowski-Denis\nWhether it’s a failure to protect workers against toxic chemicals, or a sleep-deprived employee getting into a fatal car accident, millions of people are hurt or killed at work each year. Now, with the arrival of the world’s first international standard on occupational health and safety, such incidents can be prevented. Uncover why ISO 45001 has the potential to be a real game changer for millions of workers (and workplace health hazards) around the world.\nThe next time someone tells you “my job is killing me,” remember that it may not just be a figure of speech. Every 15 seconds, a worker dies from a work-related accident or disease, and 153 people experience a work-related injury. And now there’s new data that workplace accidents are on the rise, amounting to some 500,000 more injuries than just three years ago.\nAccording to recent calculations by the International Labour Organization (ILO), 2.78 million deaths occur due to work yearly. This means that, every day, almost 7, 700 persons die of work-related diseases or injuries. In 2014, the figure was estimated to be only 2.3 million, a discrepancy that may be attributed to increasing life expectancy and new data utilized in recent calculations. Additionally, there are some 374 million non-fatal work-related injuries and illnesses each year, many of these resulting in extended absences from work. This paints a sober picture of the modern workplace—one where workers can suffer serious consequences as a result of simply “doing their job”.\nAlong with a growing (and enormous) cost for workers and their families, occupational health and safety (OH&S) has staggering impacts on economic and social development. The United Nations agency unveiled estimates showing that, worldwide, the total cost of illnesses, injuries and deaths was 3.94 percent of the global gross domestic product (GDP), or about USD 2.99 trillion, in direct and indirect costs of injuries and diseases.\nBut there’s more. The economic impact of failing to invest in worker safety and health is nearly equal to the combined GDP of the 130 poorest countries in the world, ILO Director-General Guy Ryder said at last year’s XXI World Congress on Safety and Health at Work in Singapore. Indeed, the scale of the challenge is huge.\nSupply chain complexities\nOH&S has grown increasingly complicated with many of today’s businesses crossing national boundaries. The dispersed nature of supply chains creates escalating levels of risk for multinational businesses, making OH&S both critical and complex. Consider this. Without effective OH&S in their supply chains, management potentially has a significant blind spot in their enterprise management structure, from which substantial legal, financial and reputational exposure could emerge. An organization must therefore look beyond its immediate health and safety issues and take into account what the wider society expects of it. What’s more, it also has to think about its contractors and suppliers, since the way they do their work might affect their neighbours in the surrounding area.\nClearly, OH&S in the supply chain isn’t easily achieved; it requires a solid foundation and continual improvement over time. This is where ISO 45001 comes in. ISO 45001 is the world’s first International Standard for occupational health and safety. It provides governmental agencies, industry and other affected stakeholders with effective, usable guidance for improving worker safety in countries around the world. By means of an easy-to-use framework, it can be applied to both captive and partner factories and production facilities, regardless of their location.\nNearly a hundred experts participated in the development of ISO 45001—led by ISO project committee ISO/PC 283, Occupational health and safety management systems – together with dozens of organizations including the Institution of Occupational Safety and Health (IOSH), the world’s largest professional body for people responsible for safety and health in the workplace. IOSH acts as a champion, supporter, adviser, advocate and trainer for safety and health professionals working in organizations of all sizes. Having been closely involved in the development of ISO 45001 as an organization in liaison to ISO/PC 283, IOSH is now helping its 46 000 members around the world to transition to the new standard.\nRichard Jones, head of policy and public affairs at IOSH, is a foremost expert on OH&S and has contributed as a liaison body leader to the development of ISO 45001. For him, it all comes down to workplace health and safety transcending national and economic boundaries. “In our increasingly globalized world, with the development of extended and complex supply chains and growth in migrant and vulnerable workers, ISO 45001’s emphasis on health and safety management in supply chains should mean that contracting, procurement and outsourcing are more responsibly managed, potentially saving many lives.” This could have far-reaching ramifications, with organizations extending their risk management as far into their supply chains as they have control or influence.\nWith outsourced processes and subcontractors featuring highly in the standard, organizations can choose to leverage the ISO 45001 management systems approach as a solution to identify, control and continually improve opportunities to reduce or eliminate safety and health risk to workers in the supply chain.\nMany employers recognize that successfully managing OH&S risk not only prevents injury, ill health and death, it supports livelihoods, businesses and communities. And the systems approach used by ISO 45001 can help more organizations achieve this.\nBut what does that look like in practical terms? In order for an OH&S to be strong and healthy, everyone in the organization must feel that he or she shares some responsibility for maintaining a safe environment. This includes employees all the way up to executives.\nCompanywide engagement is one of the key benefits of ISO 45001. The new standard recognizes the value of worker consultation in the development of better OH&S practices and places greater emphasis on employees actively participating in the development, planning, implementation, and continual improvement of the OH&S management system.\nTop management must take an active role, promote a positive culture and communicate what needs to be done and, more to the point, why it’s important. Senior leaders need to demonstrate that they are actively involved and taking steps to integrate the OH&S management system into the overall business processes. “ISO 45001 means more focus on leadership and worker participation as well as ensuring the system takes into account the ‘world’ the organization operates in and the internal and external factors affecting it – known as its context,” Jones said. “It means that top management must take a visible, directing role and be actively involved in the system’s implementation and ensuring its integration with other business systems.”\nAccording to Jones, the system needs to be proportionate to the organization’s risk profile and complexity. For example, in smaller organizations, effective worker participation can be more direct and straightforward to achieve, without the need for formal committee structures and so forth. And there may be additional drivers for improvement, he says. “Client organizations will increasingly require demonstration of good OH&S from those supplying their goods and services, so that they can ensure they are compatible with their own system.”\nSo what responsibilities do companies have to protect their employees? Employers have a duty to either reduce exposure or equip employees with preventative skills and tools to minimize risk. In other words: prevention pays. It’s not surprising, therefore, that the motto of the XXI World Congress 2017 was “A Global Vision of Prevention”.\nPrevention is key to tackling the burden of worker safety, and is considered to be more effective (and less costly) than treatment and rehabilitation. In line with the World Congress motto, ISO 45001 takes on a risk-based approach to managing OH&S.\nDavid Smith, Chair of ISO/PC 283 that developed ISO 45001, says businesses need to ensure they manage all their risks to survive and to thrive. “OH&S is a key aspect, which every business has to manage proactively,” he says. “Apart from the devastating impact on people, poor OH&S management can have many negative effects on organizations, such as the loss of key employees, business interruption, claims, insurance premiums, regulatory action, reputational damage, loss of investors and, ultimately, the loss of business.”\nSmith says that the risk-based approach to managing OH&S contained in ISO 45001 advocates taking a preventative angle to OH&S in order to identify what activities and processes could harm those working on behalf of the organization and others (i.e. visitors, members of the public, etc.) and to meet any legal compliance requirements. He adds that identifying the hazards at work is a prerequisite to eliminating or minimizing those that pose a significant risk.\nThe ongoing assessment of risks and opportunities is also a common element in ISO 9001 (quality management) and ISO 14001 (environmental management), which use a similar risk-based framework and the Plan-Do-Check-Act model. Effective application of these measures should address concerns that can lead to long-term health issues and absence from work, as well as those that give rise to accidents, says Smith. They are among the reasons why ISO 45001 is considered a significant improvement on OHSAS 18001, which will be replaced by the new ISO standard during a three-year migration period.\nA company culture\nOf course, any conversation on OH&S has to include the companies. Because when an employee is injured, companies lose out on that person’s experience and knowledge, as well as their labour of course. Multiply this out over several hundred (or thousand) employees and the costs can become quite severe.\nIdeally, every work setting would enhance your health and life. Many companies can and do work towards this goal, including the LEGO Group, a children’s toy manufacturer based in Denmark. With 16,836 employees (2016 LEGO Annual Report), the company recognizes the importance and value in keeping its employees healthy and safe, and will soon be making the transition to ISO 45001.\nLEGO’s Senior Integrated Management System Manager, Sofka Ane Brændgaard, explains: “We want to achieve certification to ISO 45001 because especially the new chapters regarding leadership commitment and defining the interested parties match perfectly with our company and our approach to all our stakeholders. We have already implemented this into our management reviews.” She asserts that LEGO will use ISO 45001 the same way it uses all other standards: “We see ISO standards as a tool for us to focus on processes and to bring the right value for our customers and consumers.”\nAs part of its OH&S, the company engages employees in many ways, including the creation of a proactive safety committee that raises awareness of issues such as ergonomics hazards and an internal blog where employees report safety risks, with improvements made in response to their reports and suggestions.\n“Being certified according to ISO 45001 will demonstrate that we take the health and safety of our employees, and all those working on behalf of LEGO Group, seriously, and this is fully in line with our LEGO Brand Framework and our Partner, People & Planet promises,” Brændgaard said. “We are a low-risk company and we do not compromise with health and safety, and ISO 45001 is one of the tools we will use to ensure the best possible work conditions.”\nISO 45001 adopts a high-level structure (Annex SL), meaning that it has the same structure as other ISO management system standards such as ISO 9001 and ISO 14001. This will make it easier for organizations, if they so wish, to integrate their related systems, either partially or fully, with each other—so, for example, quality, environment or security with health and safety. This can offer greater efficiency by using common processes.\n“For us it will be a significant improvement working with three standards with the same high-level structure and the same approach,” explains Brændgaard. “To be certified according to all three standards makes it easier for us, because we basically have an integrated management system where we do not distinguish between the standards; and the quality, environment, and health and safety processes are all merged into our business processes,” she says.\nBest in class\nImagine dedicating countless years to honing your professional skills and abilities, only to have all that work crumble down like an avalanche. That’s what having an injury is like for most workplace accidents.\nSignificantly reducing the incidence of injuries and occupational diseases is not that simple, however. It can be an arduous task and it will not happen overnight, but progress is certainly feasible. Enthusiasts of ISO 45001 believe organizations that implement the standard will be better positioned to control risks related to OH&S issues, improve their overall safety performance, and provide solid evidence to buyers and consumers of their commitment to the health and safety of their employees.\nBuilding OH&S in the current global environment is an opportunity, not a burden. Companies taking it seriously communicate to workers and the community that their time and well-being is valued, and are secured from loss of lives, property and even their entire business.\nNo doubt there will be more accidents in the future, but together we can succeed in turning the tide on the epidemic. Smith believes that ISO 45001 should make us all feel more reassured about our health and well-being in the workplace. “The new ISO 45001 should give increased credibility to the management of OH&S,” he says. “Wide adoption of the standard should reduce the horror stories in the media of poor OH&S management leading to the loss of life, injury and large-scale disasters.” Soon, by taking sensible precautions and implementing ISO 45001, we can all breathe a little easier at work.\nThis article first appeared on the ISO website and is published here with permission. Please visit the ISO Website www.iso.org for more information."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"}],"user_categories":[{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_language_proficiency_implied","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:3421c928-f2e5-4560-b51e-4b8b142a9449>"],"error":null}