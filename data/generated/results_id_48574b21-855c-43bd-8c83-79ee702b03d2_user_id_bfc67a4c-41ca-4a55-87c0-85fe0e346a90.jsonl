{"question":"What were the key statistics and policy changes during the 2014-2015 European migrant crisis in the Western Balkans?","answer":"In 2015, approximately 764,000 people transited through the Western Balkans region, a dramatic increase from under 45,000 in 2014. During this period, nations erected border fences to counter mass movement. For several months in 2015, passage was restricted to only citizens of Syria, Afghanistan, and Iraq, who were considered 'genuine' refugees. The borders were subsequently closed in March 2016, leaving thousands of people stranded in the region.","context":["Post by Sanja Milivojevic. Sanja is a Senior Lecturer in Criminology at La Trobe, Melbourne, and Associate Director of Border Criminologies. Sanja publishes in English and Serbian on a range of topics, in particular borders and mobility, security technologies, surveillance and crime, gender and victimisation, and international criminal justice and human rights. Her latest book Border Policing and Security Technologies is published by Routledge (2019). This is the fourth installment of Border Criminologies’ themed series on Transforming Borders From Below organised by Marie Segrave and Nancy A. Wonders. The series includes short posts written by international scholars who discuss and develop ideas contained in articles published in a special issue of Theoretical Criminology on Transforming Borders From Below: Theory and Research from across the Globe.\nThis post is based on my article in the Theoretical Criminology Special Issue: Transforming Borders From Below (and to a lesser extent my monograph Border Policing and Security Technologies: Mobility and Proliferation of Borders in the Western Balkans). Both publications consider the role technology, and in particular smartphones and social media play in enabling safe passage of illegalised border crossers, documenting their journeys, and changing social narratives around mobility. The publications are based on research I conducted in the Western Balkans as one of the main transit routes during what is now known as European migrant ‘crisis.’ The peak of the ‘crisis’ was in 2014-2015, but its impact was felt across Europe and responded to in very different ways.\nThe article in Theoretical Criminology specifically builds on the work of Stefania Milan, to develop an analysis of the way that men and women on the move transform borders from below. In Ancient Greek mythology, Prometheus stole the fire from the Greek Gods and gave it to the people in order to enable the progress of humankind. Stefania Milan holds that groups and individuals can ‘steal the fire’ from the elites, state agencies and other narrative-setters, by reclaiming technology to convey their own messages. She argues that to do so, groups and individuals need to create autonomous means of communication, innovative platforms that will be immune to gatekeepers’ interventions. I, however, argue that this process largely occurs on existing platforms, such as social media and smartphones.\nDuring the ‘crisis', states on the Western Balkans migratory route – especially FYR Macedonia (now called Republic of North Macedonia) and Serbia emerged as buffer zones in which thousands of non-citizens were temporarily housed, immobilised, and then gradually filtered towards Western Europe where they sought asylum and access to labour markets. Faced with some 764,000 people that transited through the region in 2015 (compared to under 45,000 in 2014), nation-states erected fences along territorial borders to counter the mass movement of people. For several months in 2015 the passage was allowed only for citizens of Syria, Afghanistan and Iraq (considered to be ‘genuine’ refugees), only to be followed by the closure of borders in March 2016. Thousands of men, women and children are still stranded in the region. In order to overcome emerging obstacles on their way, they have been relying on mobile technology and social media.\nThe idea that technology can be used by border regulators to track and govern border crossers has been prominent in public and policy debate for quite some time now. At the same time, technology is increasingly used by border crossers to:\n- Enable their migratory projects and limit their reliance on people smugglers;\n- Communicate with family and supporters across vast geographical distances;\n- Citizen-witness border violence and reach global audience;\n- Contribute to border knowledges via digital trail;\n- Communicate their stories by recording and transmitting words, images, videos and in doing so “steal the fire” from official truth-tellers (state agencies, media, and supra-national organisations).\nSmartphones are, thus, often more important than food or shelter. Staying in touch with family, friends, and smugglers is essential, as a lack of access to information can mean the end of the journey or even death. As my study in the Western Balkans confirms, technology provides more credible migration-related information. Border crossers reclaim technology by crafting unique means of communication in existing digital spaces, and by leaving a digital trail - an active memory of their voyages that serves a variety of purposes.\nDigital scrapbooking is an important feature of the journey. ‘Khandan’ from Iran showed me her smartphone with hundreds of photos and videos of her family’s journey through Greece and Macedonia. Featured in the photos and videos were cattle wagons in which they travelled through Greece, places where they rested and hid from police, and other happy and not so happy memories from the 14-hour on-foot trip across Macedonia she took with her children. Importantly, ‘citizen-witnessing’ of border violence can make people feel safer and assist in achieving accountability for human rights violations, as witnessed in the case of Petra László. However, it is not just records of abuses and harms that have the potential to re-humanise the issue: it is experiences, stories of survival, photos of families and friends hugging and smiling, and jokes people share along the way that can challenge the narrative of the ‘dangerous migrant’. Technology can help in this quest; we have seen that in cases of Aylan Kurdi and Omran Daqneesh. Stories and images by border crossers shared on social media have the potential to tell, perhaps even more powerfully, their tales of suffering, pain, survival, and hope.\nAs technology users, we engage with snippets of information from our networks, and identify what is important to know. We value information, based on where it comes from. Immediacy between the influencer and the social media user, and a number of posts shared by people we trust on social media can potentially have a greater value than the information we access in the traditional media. Emotionally charged reports that originate from those that experience borders, shared by our community of friends and networks on smartphones and social media, can indeed be singled out as more trustworthy and honest account of illegalised migration. In this context, ‘stealing the fire’ means breaking the monopoly of official truth-tellers, through mass self-communication. When border crossers share their photographs and voices in the new digital knowledge commons, they transform bordering strategies, by dismantling the security narratives. Such a quest for social change that will ultimately re-humanise border crossers is even more important given that the ‘crisis’ is far from over. In the book I further these arguments and explore the role security technologies play in both enabling and resisting migratory regimes. Finally, given the lack of attention to the topic in academia, I call for further engagement with technology in border criminologies.\nHow to cite this blog post (Harvard style)\nMilivojevic, S. (2019) ‘Stealing the Fire’, 2.0 Style?: Smartphones and Social Media in the Era of Illegalised Mobility. Available at: https://www.law.ox.ac.uk/research-subject-groups/centre-criminology/centreborder-criminologies/blog/2019/05/stealing-the-fire-20 (Accessed [date])"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:091d5b82-ae8b-41e1-974f-e27f6d67231b>"],"error":null}
{"question":"在展会展位和零售店中，产品展示如何利用视觉营销策略来吸引顾客？(How do trade show booths and retail stores utilize visual merchandising strategies to attract customers?)","answer":"Trade show booths focus on immediate visual impact through branded graphics, custom-printed banners, and tension fabric displays, while incorporating interactive elements like product demonstrations and sensory engagement. They can use unique approaches like building set-pieces, incorporating living elements, or creating oversized product models. Retail stores, on the other hand, emphasize visual merchandising through strategic store layouts, zoning strategies, and carefully designed window displays. They focus on creating semi-separate areas using furniture layout and merchandise displays, combined with clear, readable signage to guide customers through the store efficiently. Both environments use these strategies to create unique customer experiences and influence customer behavior, but trade shows focus on quick engagement while retail stores aim for longer customer interaction.","context":["You don’t get long to make a first impression. It takes only seconds for someone to walk past your trade show booth, so that’s all you’ll have to attract their attention. Effective product displays help make your case for you by highlighting what’s great about your products.\nMake Your Trade Show Product Display the Best with These 8 Tips\nWhat makes a product display work? If your exhibit display isn’t getting the results you want, you can add new elements, such as tension fabric displays, banner stands, and other display accessories. But if you don’t add new elements with care, you may end up with an overcrowded, messy display.\nThere’s no single element that spells the difference between success and failure. Instead, think about the big picture: What do people see when they walk past your booth? And how are you using trade show displays to make your products look their best? If you think your booth could use some improvement, there are many display solutions and trade show accessories that can help your products work harder.\n1. Use the display to build your brand.\nShowing off your products might be your main goal, but there’s no reason you can’t use one or more display systems to highlight your brand at the same time. Product displays can incorporate branded graphics, product information, and other content. This emphasizes the connection between your brand and your brand’s products. And it provides answers to common visitor questions at the same time.\nSome display options include:\n- Use branded graphics on custom-printed banners, cloth tension displays, and other structural elements – Almost any flat structural surface can do double-duty as an information display.\n- Branded carpeting – Show off your company logo on the trade show flooring at the entry points to your booth, or in front of the displays that showcase your flagship products.\n- Branded countertops – Display your company logo and product information on demonstration countertops. When there’s no demonstration in session, this can serve as another information display.\n- Make the little things count – Smaller elements, such as sign holders, sign frames, and stands, can contribute to your branded message. While you may not use them to display your company logo, if they’re in your logo colors, they’ll add to the overall look.\n2. Use lighting to showcase flagship products.\nIf you have one or two products that you feel really represent your brand—or that you’re trying to push to trade show attendees—use display elements to highlight them. This works particularly well if they’re also valuable products. Combine eye-catching lighting with your product locked in a display case, and your product will really stand out. Group smaller products in light boxes or backlit displays, both to draw attention and to help people see them more clearly.\nSpotlighting effects for highlighting specific products is best done with a smaller number of single-color lights. White usually works great for spotlighting, but a color that’s strongly associated with your brand may work too. Another option is to use LED displays to highlight products and display information.\nWant your lighting to act as a more general attention-grabbing device? Go for something more colorful, with a large number of lights. For instance, add track lighting around the perimeter of the trade show exhibit, or mount a light display in the vertical space above the main booth structure. If you already have a hanging sign above your booth, lighting could be an effective way to make it pop.\n3. Keep the display in proportion with the product.\nWhen you’re creating a product display, take size into account. Large products tend to look best if they’re arranged singly or in small groups. If items are large enough to sit on the floor, group each one with a kiosk or graphic that provides information.\nIf your display includes multiple small products, arrange them in clusters to better show off the variety. Wall-mounted display options work well for small items. Then you can then use the interior of the booth space for demonstrations and meetings.\nTabletop displays can also work well for most product sizes. If you’re holding product demonstrations, a tabletop display can double as a demo counter too.\n4. Leave plenty of room for movement.\nThe rule of negative space applies in building effective trade show product displays just as it does in art and graphic design. Your product displays will be more eye-catching and engaging if they don’t have to compete for attention. Space out your displays around your trade show booth, and make sure there’s room for movement in between each one.\nIf your trade show booth is feeling a little cramped, consider whether changing up one or two displays might help it feel more spacious. For instance, if you mostly have floor and tabletop displays, converting one or more into hanging displays or wall-mounted displays would free up floor space.\n5. Highlight what makes you unique.\nSometimes it’s not necessarily the product that a display needs to highlight. What makes products like VR headsets, computers, kitchenware, etc. special is how people use them, not exactly the products themselves. If your product falls into that category, build your displays to include custom-printed graphics that depict people using and enjoying the product. This approach also works if you’re providing a service, rather than a product. Well-designed graphics can convey what you do, and what makes your service the best option.\nPro Tip: Graphics are great. Human interaction is better. You could allow visitors to actually interact with your product or plan for a product demonstration (see #7).\n6. Use the perimeter of the space.\nIt’s important that your trade show booth isn’t overstuffed with displays and other elements. But it’s also important to use the different zones in your booth in appropriate ways. Although the perimeter of a trade show booth is often overlooked, this part of the space can be put to good use to draw in foot traffic. People walking past your exhibit are looking at what’s going on either side of them. If they see something interesting in your display in those split-seconds, they’ll consider stopping. Use the perimeter for engaging content, such as a looping video clip or slideshow presentation, to hook people as they walk by. For instance, you might add monitor kiosks around the edge of your booth to display presentations and other promotional content.\n7. Include a demonstration.\nAn engaging product demonstration is another effective way to draw in foot traffic. A product demo ensures that your booth looks active and engaging to passersbys, and it showcases what’s cool about your products, allowing you to give more details than is possible on a graphic.\n8. Promote your trade show exhibit in other channels.\nIt’s not enough to sit and wait for people to happen by. The most effective trade show booths are the ones that actively engage people using a variety of different channels. Social media is too important to ignore, so be sure to stay active during the show. Use the show’s official hashtag for each tweet or post, so that attendees have an additional chance to discover you. And, be sure to use the Stories feature on each platform you post on, to help your followers stay up-to-date with your activity.\nYou can use social media to:\n- Highlight the products you’re showcasing in your booth with photos and video clips.\n- Livestream your product demonstrations on Facebook or Instagram – Let people know when demos are scheduled. Attendees who see clips on social media might decide to attend the next scheduled demo.\nIf you use monitor kiosks in your booth, another option is to use them to display your social media content. For instance, alternate your presentation or slide show display with a quick look at your Twitter feed—or the event feed, if your own isn’t lively enough.\n4 More Unique Ways to Display Products\nWhile there are tried-and-true elements—like lighting—that work well in product displays, there’s nothing wrong with thinking outside the box! When you go the extra mile to create something impressive, you’ll be repaid with a busy booth that helps you pull in traffic and generate leads. Try something like this:\n- Build a set-piece – Showing is always more effective than telling, so build a booth that shows people your products in action. Use customized display elements and graphics to create an environment that mimics a place where people might buy or use your products.\n- Engage the senses – Product displays are much more interesting when they let people do more than look. Let people touch and handle the product, and even smell or taste if it’s appropriate.\n- Incorporate a living element – Add a living wall of plants or foliage, or use a display of fruit or flowers, to add a tactile element that engages the senses.\n- Scale up – Do you have a signature product that’s strongly associated with your brand? Or, do you manufacture products that are too small to attract the attention of people passing by the booth? Consider having some large-scale copies of the products made. Oversized items tend to trigger a sense of wonder that’s hard to replicate, making them great attention-grabbers. Larger-than-life models are also a useful way to help people visualize small or complex items.\nYakima Chief Hops, a family-owned hop farm in the Pacific Northwest, and our team at ProExhibits put a lot of thought into how to most effectively display their products. They asked us to create several different trade show booths—for use in Europe, Asia, and North America—that all focused on interactivity and engaging the senses while showcasing their primary product—hops—and providing room for taste-testing.\nTo do this, ProExhibits custom designed an exhibit display that mimics a bar environment, with an interactive hops station alongside the bar. Each booth that ProExhibits devised includes two defined custom display areas for trade show product displays: one for hops, and one for beer brewed using those hops. At the hops station, visitors can see, touch, and smell the hops. The beer station incorporates pouring taps, stools, and other elements common in a typical bar environment.\nThe end result has been a set of highly engaging and successful booths and a brand that’s very pleased with the splash it’s making in the global market.\nGreat Displays Help You Compete and Win\nThere’s no such thing as a quiet trade show. It’s full of brands competing for attention and visitors whose attention is constantly being grabbed every which way. Engaging product displays can make all the difference in the success of your trade show booth by ensuring that the few seconds you get to compete focus on the right things.","The deliverance of commodities from a supply chain to the buyers is a primary function of a retailer. Which can be successfully achieved by creating a value in delivering a unique customer experience. How customer will experience the product or the merchandise is determined by how the store design will guide them to interact with it. So, the store design has to have the direct reflection of the brand which will also plays an important role in staying in competition with the E-Commerce trend.\n- HOW THE STORE WILL STAND OUT FROM THE COMPETITORS.\n- HOW TO CREATE CONVENIENCE AND EXPERIENCE TO ENCOURAGE THE CUSTOMERS TO COME INTO THE STORE.\n- VISUAL MERCHANDISING STRATEGY.\nIt is the core retail strategy, it how the store speaks, it is the way how the store communicates with the customers, through its visual graphics and presentation if the merchandise. Visual merchandise is everything which helps to create a unique customer experience such as a designed entrance, strategically placed the furniture, fixture, promotional graphics and product display combine with the store layout to influence on customer behavior and make the customer’s journey efficient, unique and memorable.\nIt could be the second most important strategy of retail store design, customers also respond to where products are placed. A zoning strategy combines visual merchandising with your store layout design to highlight high-value products or the products you want featured. Creating zones using creative furniture layout, merchandise displays, and instructional signage develops semi-separate areas. The product displays should act as speed breaker to keep the customer in the zone and slow them from leaving the area. More time the customer spend in the store, more product they will see and\nProper lighting is more than just making sure the customer can see and interact with the merchandise. When done well, light can help structure and influence the customer’s mood while shopping. Store design should include such lighting solutions to highlight or focus specific areas of the store to draw in customer’s attention and create an environment that works in sync with the retail brand and the merchandise offered.\nSignage serve multiple purposes for retailers. They are the graphic representation of the retailer’s brand and merchandise and at the same time signage also provides the product information for specific merchandise, help customers navigate the store layout efficiently, and create the desired price perception. From a strictly visual perspective, it’s key to have clear readable signage from the outside that leads customers in the store. From there, the journey of customer will start.\nAlong with the store layout design, displays set the stage for the customer’s overall experience while roaming around the store. In general, displays come in all shapes and sizes, which includes tables, racks, or gondolas.Selection of the type and placement of displays plays a crucial role in the overall retail design. The strategic placement of display, space management and store design lead the influence on customer flow and in store environment.\nWindows welcome customers from the outside and draw them into the store where layout design and the various elements of visual merchandising go to work. The window display requires careful attention to lighting, size of display units, type of merchandise featured, and signage. Because the customer has yet to enter the store, a window display must combine all of the visual merchandising elements to successfully pick the customer’s interest and promote the store’s brand."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:f937d31e-f722-49f9-9fb4-cc47413d39b5>","<urn:uuid:6999b94e-feac-44a7-b68e-e526136effd9>"],"error":null}
{"question":"How fast did global warming occur at the end of ice ages compared to current warming?","answer":"At the end of ice ages, global warming was a gradual process taking about 5,000 years, with temperature changes of 4°C to 7°C. This is much slower than the current rate of global climate change. For comparison, the approximately 80-ppm rise in CO2 concentration at the end of past ice ages generally took over 5,000 years, while a similar rise has occurred much more rapidly in the past century.","context":["Frequently Asked Question 6.2\nIs the Current Climate Change Unusual Compared to Earlier Changes in Earth’s History?\nClimate has changed on all time scales throughout Earth’s history. Some aspects of the current climate change are not unusual, but others are. The concentration of CO2 in the atmosphere has reached a record high relative to more than the past half-million years, and has done so at an exceptionally fast rate. Current global temperatures are warmer than they have ever been during at least the past five centuries, probably even for more than a millennium. If warming continues unabated, the resulting climate change within this century would be extremely unusual in geological terms. Another unusual aspect of recent climate change is its cause: past climate changes were natural in origin (see FAQ 6.1), whereas most of the warming of the past 50 years is attributable to human activities.\nWhen comparing the current climate change to earlier, natural ones, three distinctions must be made. First, it must be clear which variable is being compared: is it greenhouse gas concentration or temperature (or some other climate parameter), and is it their absolute value or their rate of change? Second, local changes must not be confused with global changes. Local climate changes are often much larger than global ones, since local factors (e.g., changes in oceanic or atmospheric circulation) can shift the delivery of heat or moisture from one place to another and local feedbacks operate (e.g., sea ice feedback). Large changes in global mean temperature, in contrast, require some global forcing (such as a change in greenhouse gas concentration or solar activity). Third, it is necessary to distinguish between time scales. Climate changes over millions of years can be much larger and have different causes (e.g., continental drift) compared to climate changes on a centennial time scale.\nThe main reason for the current concern about climate change is the rise in atmospheric carbon dioxide (CO2) concentration (and some other greenhouse gases), which is very unusual for the Quaternary (about the last two million years). The concentration of CO2 is now known accurately for the past 650,000 years from antarctic ice cores. During this time, CO2 concentration varied between a low of 180 ppm during cold glacial times and a high of 300 ppm during warm interglacials. Over the past century, it rapidly increased well out of this range, and is now 379 ppm (see Chapter 2). For comparison, the approximately 80-ppm rise in CO2 concentration at the end of the past ice ages generally took over 5,000 years. Higher values than at present have only occurred many millions of years ago (see FAQ 6.1).\nTemperature is a more difficult variable to reconstruct than CO2 (a globally well-mixed gas), as it does not have the same value all over the globe, so that a single record (e.g., an ice core) is only of limited value. Local temperature fluctuations, even those over just a few decades, can be several degrees celsius, which is larger than the global warming signal of the past century of about 0.7°C.\nMore meaningful for global changes is an analysis of large-scale (global or hemispheric) averages, where much of the local variation averages out and variability is smaller. Sufficient coverage of instrumental records goes back only about 150 years. Further back in time, compilations of proxy data from tree rings, ice cores, etc., go back more than a thousand years with decreasing spatial coverage for earlier periods (see Section 6.5). While there are differences among those reconstructions and significant uncertainties remain, all published reconstructions find that temperatures were warm during medieval times, cooled to low values in the 17th, 18th and 19th centuries, and warmed rapidly after that. The medieval level of warmth is uncertain, but may have been reached again in the mid-20th century, only to have likely been exceeded since then. These conclusions are supported by climate modelling as well. Before 2,000 years ago, temperature variations have not been systematically compiled into large-scale averages, but they do not provide evidence for warmer-than-present global annual mean temperatures going back through the Holocene (the last 11,600 years; see Section 6.4). There are strong indications that a warmer climate, with greatly reduced global ice cover and higher sea level, prevailed until around 3 million years ago. Hence, current warmth appears unusual in the context of the past millennia, but not unusual on longer time scales for which changes in tectonic activity (which can drive natural, slow variations in greenhouse gas concentration) become relevant (see Box 6.1).\nA different matter is the current rate of warming. Are more rapid global climate changes recorded in proxy data? The largest temperature changes of the past million years are the glacial cycles, during which the global mean temperature changed by 4°C to 7°C between ice ages and warm interglacial periods (local changes were much larger, for example near the continental ice sheets). However, the data indicate that the global warming at the end of an ice age was a gradual process taking about 5,000 years (see Section 6.3). It is thus clear that the current rate of global climate change is much more rapid and very unusual in the context of past changes. The much-discussed abrupt climate shifts during glacial times (see Section 6.3) are not counter-examples, since they were probably due to changes in ocean heat transport, which would be unlikely to affect the global mean temperature.\nFurther back in time, beyond ice core data, the time resolution of sediment cores and other archives does not resolve changes as rapid as the present warming. Hence, although large climate changes have occurred in the past, there is no evidence that these took place at a faster rate than present warming. If projections of approximately 5°C warming in this century (the upper end of the range) are realised, then the Earth will have experienced about the same amount of global mean warming as it did at the end of the last ice age; there is no evidence that this rate of possible future global change was matched by any comparable global temperature increase of the last 50 million years."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:3504e0be-1f20-4313-b40b-aa594b9e43e5>"],"error":null}
{"question":"How do the sculptural techniques and artistic influences differ between the Roman terracotta statuette of Mên and the Cypriot limestone worshipper statue, particularly in terms of their three-dimensional execution and cultural inspirations?","answer":"The Roman terracotta statuette of Mên was created using a two-part mold technique resulting in a hollow form with a circular vent hole on the back. It shows a more stylized approach with disproportionately large eyes and simplified details. In contrast, the Cypriot limestone statue was sculpted in the round from a single block, but appears very flat with little three-dimensional volume when viewed from the side. This flatness was partly due to the friable nature of the limestone. Regarding cultural influences, the Mên statuette reflects Roman Imperial period aesthetics, with some features like the god's straight hair reminiscent of Alexander the Great. The Cypriot statue shows a fusion of Oriental and Greek influences, incorporating elements of archaic Greek sculpture like the slight smile and posed stance with left leg forward, while maintaining the rigid form characteristic of Middle Eastern artistic traditions passed through Phoenician influence.","context":["- Identification and Creation\n- Object Number\n- The Moon God Mên\n- Work Type\n- sculpture, statuette\n- 3rd century CE\n- Creation Place: Ancient & Byzantine World\n- Roman Imperial period\nLevel 3, Room 3700, Ancient Mediterranean and Near Eastern Art, Roman Art\nView this object's location on our interactive map\n- Physical Descriptions\n- 17.2 x 10 x 3.4 cm (6 3/4 x 3 15/16 x 1 5/16 in.)\n- [Sotheby's London, 17 May 1965, Lot 193], sold; to The Alice Corinne McDaniel Collection, Department of the Classics, Harvard University (1965-2012), transfer; to the Harvard Art Museums, 2012.\n- Acquisition and Rights\n- Credit Line\n- Harvard Art Museums/Arthur M. Sackler Museum, Transfer from the Alice Corinne McDaniel Collection, Department of the Classics, Harvard University\n- Accession Year\n- Object Number\n- Asian and Mediterranean Art\n- The Harvard Art Museums encourage the use of images found on this website for personal, noncommercial use, including educational and scholarly purposes. To request a higher resolution file of this image, please submit an online request.\n- This intact terracotta statuette depicts the moon god Mên on horseback. Mên sits on the back of the horse, turning his upper body to the right. He wears a Phrygian cap, a cloak over an elaborate tunic or segmented cuirass, and trousers. In his extended right hand is an offering bowl or patera. The ends of a crescent moon are visible behind his shoulders. The horse is shown with its left foreleg raised. It wears a simple bridle; there is a decorative band, perhaps part of a harness, across the chest, but no indication of a saddle. The horse's mane is wavy, in contrast to its tail, which is banded, and the hair of the god, which is depicted in straight strands in a style reminiscent of Alexander the Great. The statuette is rather stylized, with details like the eyes disproportionately large, and other details greatly simplified. Horse and rider are on a rectangular base, shown with a molded band at the top and bottom, perhaps in imitation of life-sized equestrian statue bases. The back of the statuette is relatively featureless, with only the folds of the cloak and details of the horse harness and statue base depicted.\nThe statuette is hollow and was made with a two-part mold; a circular vent hole is visible on the back.\n- Mên was a lunar deity worshipped in ancient Asia Minor (modern Turkey), who had a variety of roles, from god of healing to protector of tombs, and was also associated with fertility and the military. He is often shown with a crescent moon behind his shoulders, as here, and a pinecone, although the precise meaning of this attribute is not clear (compare 1964.126).\nThis terracotta was probably a votive offering; it may have been modeled after a marble equestrian statue of the god with a similar composition known to have been in Galatia (Turkey).\n- Publication History\nUlrich W. Hiesinger, \"Three Images of the God Men\", Harvard Studies in Classical Philology (Cambridge, MA, 1966), Vol. 71, pp. 303-310, 307-308, pl. IV, a-b\nJohn Crawford, Sidney Goldstein, George M. A. Hanfmann, John Kroll, Judith Lerner, Miranda Marvin, Charlotte Moore, and Duane Roller, Objects of Ancient Daily Life. A Catalogue of the Alice Corinne McDaniel Collection Belonging to the Department of the Classics, Harvard University, ed. Jane Waldbaum, Department of the Classics (unpublished manuscript, 1970), T1, p. 33 [D. W. Roller]\nE.N. Lane, Corpus Monumentorum Religionis Dei Menis 1: The Monuments and Inscriptions, Leiden (Brill, 1971), p. 89, no. 139, pl. 64.\nLexicon Iconographicum Mythologiae Classicae (LIMC), Artemis (Zürich, Switzerland, 1999), Vol. 6, Men 99.\n- Exhibition History\nRoman Gallery Installation (long-term), Harvard University Art Museums, Cambridge, 09/16/1999 - 01/20/2008\n32Q: 3700 Roman, Harvard Art Museums, 11/01/2014\n- Subjects and Contexts\nGoogle Art Project\n- Related Works\nThis record has been reviewed by the curatorial staff but may be incomplete. Our records are frequently revised and enhanced. For more information please contact the Division of Asian and Mediterranean Art at firstname.lastname@example.org","© 2000 RMN / Franck Raux\nNear Eastern Antiquities\nThis votive statue represents a local dynast bearing propitiary offerings. The wreath of leaves and flowerbuds on his head refer to a religious festival celebrating the annual death and rebirth of plants. The slight smile on the face, the style of the torso, the folds on the garment and the overall rigid form of the statue reflect the influence of archaic Greek sculpture.\nA statue designed as an ex-voto\nThis statue is a rare example of an almost complete sculpture of a worshipper, dating from the 5th century BC, of the type given in offering to shrines in central Cyprus, Golgoi and Idalion in particular. The statue represents a local dignitary who is holding symbolic offerings - a small box of incense in his right hand and what was probably a bird in his left hand, although only the marks where the piece was broken off remain. The wreath of plants he wears on his head is a typical religious attribute in Cypriot statuary. It refers to religious festivals celebrating the cycle of fertility, death, and rebirth in Nature. The statue was designed as an ex-voto. The constant presence of the effigy in the shrine represents the perpetual religious devotion of the worshipper and brings him the permanent protection of the deity.\nA typical piece of Cypriot art\nCypriot art stands at the crossroads of the Orient and the Mediterranean spheres of influence. The techniques of monumental sculpture were brought to the island in the 7th century BC by its Eastern neighbors. From the late 6th century BC, Cypriot sculpture reflects the increasing influence of the Ionian, and later the Athenian, styles. A number of aspects of this statue, sculpted in the round, reveal the influence of archaic Greek sculpture. The slight smile, the pointed nose, the carving of the torso, the broad neck and shoulders, the puffed-out chest, and the pose of the sculpture - standing with the left leg forward - are all typical of Greek kouroi. The style of the folds in the tunic, or chiton, and the Ionian cloak or himation, resemble the garments worn by antique korai, particularly in the way the himation goes under the right arm and over the left shoulder and forms a number of flat vertical folds down the front of the torso, finishing in a series of zigzagging drapes. The rigid style of the statue as a whole can be partly explained by the difficulty of carving the friable limestone and the necessity of sculpting the statue from a single block. This rigid aspect is also shared by the Kore of Samos (MA686), a pillar statue inspired by Middle Eastern art, reflecting the Oriental canon which the Phenicians passed on to the Greeks. However, there are important differences between the two works. This statue is very flat and gives very little impression of three-dimensional volume when viewed from the side. Color, also used in Greek statuary, plays a vital role in bringing life to the rather flat, uniform surface of the sculpture. The traces of red pigment at the base of the Idalion worshipper's neck indicate that it was originally painted. Pale blue and red were used to touch up the eyes, the hair, and the garments. Yellow was used exclusively for jewelry. The delicate, porous, opaque surface of the limestone meant that colors were easy to apply and quickly absorbed.\nBibliographyCaubet Annie, Hermary Antoine, Catalogue des Antiquités du musée du Louvre : sculptures, musée du Louvre, département des Antiquités orientales, Paris, Éditions de la Réunion des musées nationaux, 1989.\nCaubet Annie, Hermary Antoine, Karageorghis Vasos (sous la dir. de),\nArt antique de Chypre au musée du Louvre : du chalcolithique à l'époque romaine, Paris, Éditions de la Réunion des musées nationaux, 1992, Athènes, Kapon, 1992.\nSpiteris Tony, Art de Chypre, des origines à l'époque romaine, Paris, Éditions Cercle d'Art, 1970.\nCypro-Classical (second quarter of 5th century BC)\nLimestone, traces of polychromy\nH. 1.53 m; W. 0.40 m; D. 0.17 m\nGift of Guillaume-Rey, 1860 , 1860\nLevant: Cyprus, 9th–1st century BC\nThe Louvre is open every day (except Tuesday) from 9 a.m. to 6 p.m."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:f8f083d7-d14f-4506-9f54-f45e236405ed>","<urn:uuid:ff7410fe-1ca6-476e-9ee6-bf89b7039650>"],"error":null}
{"question":"How is profit uncertainty measured in automotive market analysis?","answer":"In the analysis of the automotive market, profit uncertainty is proxied by measuring profits' variance. The profit estimates themselves are obtained through a structural model that takes into account both product demand and supply factors.","context":["Profitability, uncertainty and multi-product firm product proliferation: The Spanish car industry\nThis article studies how product introduction decisions relate to profitability and uncertainty in the context of multi-product firms and product differentiation. These two features, common to many modern industries, have not received much attention in the literature as compared to the classical problem of firm entry, even if the determinants of firm and product entry are quite different. The theoretical predictions about the sign of the impact of uncertainty on product entry are not conclusive. Therefore, an econometric model relating firms’ product introduction decisions with profitability and profit uncertainty is proposed. Firm’s estimated profits are obtained from a structural model of product demand and supply, and uncertainty is proxied by profits’ variance. The empirical analysis is carried out using data on the Spanish car industry for the period 1990-2000. The results show a positive relationship between product introduction and profitability, and a negative one with respect to profit variability. Interestingly, the degree of uncertainty appears to be a driving force of entry stronger than profitability, suggesting that the product proliferation process in the Spanish car market may have been mainly a consequence of lower uncertainty rather than the result of having a more profitable market\n|Date of creation:||Sep 2012|\n|Date of revision:||Sep 2012|\n|Contact details of provider:|| Postal: |\nWeb page: http://www.pcb.ub.edu/xreapEmail:\nMore information through EDIRC\nPlease report citation or reference errors to , or , if you are the registered author of the cited work, log in to your RePEc Author Service profile, click on \"citations\" and make appropriate adjustments.:\n- Appelbaum, Elie & Katz, Eliakim, 1986. \"Measures of Risk Aversion and Comparative Statics of Industry Equilibrium,\" American Economic Review, American Economic Association, vol. 76(3), pages 524-29, June.\n- Helen Weeds, 2002.\n\"Strategic Delay in a Real Options Model of R&D Competition,\"\nReview of Economic Studies,\nOxford University Press, vol. 69(3), pages 729-747.\n- Weeds, Helen, 2002. \"Strategic Delay in a Real Options Model of R&D Competition,\" Review of Economic Studies, Wiley Blackwell, vol. 69(3), pages 729-47, July.\n- Weeds, H., 2000. \"Strategic Delay in a Real Optimna Model of R&D Competition,\" The Warwick Economics Research Paper Series (TWERPS) 576, University of Warwick, Department of Economics.\n- Toivanen, Otto & Waterson, Michael, 2000. \"Empirical research on discrete choice game theory models of entry: An illustration,\" European Economic Review, Elsevier, vol. 44(4-6), pages 985-992, May.\n- repec:rje:randje:v:37:y:2006:3:p:619-640 is not listed on IDEAS\n- Michael J. Mazzeo, 2002. \"Product Choice and Oligopoly Market Structure,\" RAND Journal of Economics, The RAND Corporation, vol. 33(2), pages 221-242, Summer.\n- Geroski, P A & Murfin, A, 1991. \"Entry and Intra-industry Mobility in the UK Car Market,\" Oxford Bulletin of Economics and Statistics, Department of Economics, University of Oxford, vol. 53(4), pages 341-59, November.\n- Günter J. Hitsch, 2006. \"An Empirical Model of Optimal Dynamic Product Launch and Exit Under Demand Uncertainty,\" Marketing Science, INFORMS, vol. 25(1), pages 25-50, 01-02.\n- Anna Matas & Josep-Lluis Raymond, 2009. \"Hedonic prices for cars: an application to the Spanish car market, 1981-2005,\" Applied Economics, Taylor & Francis Journals, vol. 41(22), pages 2887-2904.\n- Katja Seim, 2006. \"An empirical model of firm entry with endogenous product‐type choices,\" RAND Journal of Economics, RAND Corporation, vol. 37(3), pages 619-640, 09.\n- Berry, Steven & Levinsohn, James & Pakes, Ariel, 1995. \"Automobile Prices in Market Equilibrium,\" Econometrica, Econometric Society, vol. 63(4), pages 841-90, July.\n- Ghosal, Vivek, 1996. \"Does uncertainty influence the number of firms in an industry?,\" Economics Letters, Elsevier, vol. 50(2), pages 229-236, February.\n- Richard Schmalensee, 1978. \"Entry Deterrence in the Ready-to-Eat Breakfast Cereal Industry,\" Bell Journal of Economics, The RAND Corporation, vol. 9(2), pages 305-327, Autumn.\n- Dixit, Avinash K, 1989.\n\"Entry and Exit Decisions under Uncertainty,\"\nJournal of Political Economy,\nUniversity of Chicago Press, vol. 97(3), pages 620-38, June.\n- Geroski, Paul A & Mazzucato, Mariana, 2001. \"Advertising and the Evolution of Market Structure in the US Car Industry,\" CEPR Discussion Papers 2860, C.E.P.R. Discussion Papers.\n- Berry, Steven T, 1992. \"Estimation of a Model of Entry in the Airline Industry,\" Econometrica, Econometric Society, vol. 60(4), pages 889-917, July.\n- Bresnahan, Timothy F & Reiss, Peter C, 1991.\n\"Entry and Competition in Concentrated Markets,\"\nJournal of Political Economy,\nUniversity of Chicago Press, vol. 99(5), pages 977-1009, October.\n- Bhargava, Alok & Sargan, J D, 1983. \"Estimating Dynamic Random Effects Models from Panel Data Covering Short Time Periods,\" Econometrica, Econometric Society, vol. 51(6), pages 1635-59, November.\n- Francisco Requena-Silvente & James Walker, 2005. \"Competition and product survival in the UK car market,\" Applied Economics, Taylor & Francis Journals, vol. 37(19), pages 2289-2295.\n- Sven-Olov Daunfeldt & Matilda Orth & Niklas Rudholm, 2010. \"Opening Local Retail Food Stores: A Real-Options Approach,\" Journal of Industry, Competition and Trade, Springer, vol. 10(3), pages 373-387, September.\n- María Moral & Jordi Jaumandreu, 2007. \"Automobile demand, model cycle and age effects,\" Spanish Economic Review, Springer, vol. 9(3), pages 193-218, September.\n- Folta, Timothy B. & Johnson, Douglas R. & O'Brien, Jonathan, 2006. \"Uncertainty, irreversibility, and the likelihood of entry: An empirical assessment of the option to defer,\" Journal of Economic Behavior & Organization, Elsevier, vol. 61(3), pages 432-452, November.\nWhen requesting a correction, please mention this item's handle: RePEc:xrp:wpaper:xreap2012-16. See general information about how to correct material in RePEc.\nFor technical questions regarding this item, or to correct its authors, title, abstract, bibliographic or download information, contact: ()The email address of this maintainer does not seem to be valid anymore. Please ask to update the entry or send us the correct address\nIf references are entirely missing, you can add them using this form."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:cca377f5-dda7-436e-96f6-8e0f70f41976>"],"error":null}
{"question":"How do the structural complexities of Thai consonants compare to the genetic basis of speech disorders like verbal dyspraxia?","answer":"The Thai language's structural complexity with its 44 consonants arranged in three classes (low, mid, and high) represents a learned linguistic system, while verbal dyspraxia represents a genetic speech disorder. Thai consonants involve complex rules where the same letter can have different sounds depending on its position in a syllable, but this is a feature of the language system that can be learned by anyone. In contrast, verbal dyspraxia is caused by a specific genetic mutation in the FOXP2 gene on chromosome 7, which affects the language areas of the brain and results in problems with articulation and other linguistic symptoms. This genetic condition impacts basic speech ability regardless of the language being spoken, whereas Thai consonant complexity is simply a structural feature of that particular language that any person without speech disorders can master through learning.","context":["Language and genetics\nGenetic methods have revolutionized research into many aspects of languages, including the tracing of their origins. Gene variants underlie individual language skills. Genetic predisposition might favour the evolution of structural features of languages.\nHumans have a unique natural ability to develop highly complex linguistic systems — an ability that lies in our genes but is also shaped by our different environments. We can learn languages from others and use them to share our thoughts, feelings and desires; languages are the foundation of society, culture and science. So it is perhaps not suprising that all aspects of language — including structure, global distribution, acquisition, processing in the brain, role in thought and actions, and links with culture and education — can be considered to be important subjects of research.\nWhat is so special about our genetic make-up that allows us to use language? How does this ability relate to other higher cognitive functions, like human memory and mathematical or musical ability? Until recently, it has been hard to even pose these questions. The past few years, however, have seen the rapid development of methods to analyse genes quickly and relatively cheaply. At last we can begin to study the genetic basis of human cognition and, hence, language. Three examples of ongoing research are described here.\nThe human genome does not ‘create’ languages; however, it does direct the organization of the human brain and some peripheral organs that are prerequisites for the language system, and is probably responsible for the significant differences in language skills between individuals. At the extremes are people with extraordinary gifts for learning many languages and undertaking simultaneous interpretation, and people with severe congenital speech disorders1.\nExciting early results have identified a gene underlying one form of speech disorder known as verbal dyspraxia2. This serious impairment is characterized by problems in articulation, along with other linguistic symptoms. Genetic studies of an English family with verbal dyspraxia have shown that the condition results from a mutation in the gene, known as FOXP2 (Fig. 1) – located on chromosome 7, which affects the language areas of the brain via several intermediate steps. Although this speech deficit is rare, it now seems that the same genetic mechanism could play a role in other, much more common congenital speech pathologies.\nHowever, FOXP2 is not a ‘language gene’ — that is a term coined by the media. The same mutation also affects the liver for example, and the non-mutated gene is found in many other animals, such as the mouse, which do not speak. Rather, it is one of many genetic components important in the development of language ability3. Nevertheless, its discovery was the first small breakthrough in understanding the genetic basis of human language4.\nLANGUAGE AND POPULATIONS\nAnthropologists believe that modern humans originated in Africa. Is there a link between the spread of languages and the genetic differences between the peoples who speak them?\nRecent research using modern scientific methods has thrown up some surprises. One of the most interesting shows how genetic and linguistic classifications of populations can diverge. Most European languages belong to the Indo-European group. Two notable exceptions are Basque, which is relatively isolated, and the Finno-Ugric languages, in particular Finnish. Modern Finns have been found to be genetically close to Indo-Europeans, but genetically different from their Saami neighbours whose language is also Finno-Ugric5.\nOne study is examining the effect of contact between prehistoric populations with different sociocultural backgrounds in different locations, particularly Africa and Siberia, on language and genetics. The types of contact that occurred are unknown, so it is hard to assess their consequences using only linguistic methods. Molecular genetic analyses can help spot a bottleneck, or founder effect, that might indicate a mixing of different populations, or reveal discrepancies between genetic and language relationships indicative of recent language drift6.\nAnother study is addressing the development and spread of languages over larger geographical areas. The traditional methods of comparative historical linguistics, based primarily on similarities in vocabulary, can make sense of language evolution over only the past few thousand years at most. The new project adapts the widely used methods of evolutionary genetics — namely, the construction of phylogenetic trees (Fig. 2) — with the phonological, morphological and syntactic features of language as raw data, primarily to study the sophisticated languages and peoples of Melanesia (an area covering most of the islands north and northeast of Australia)7.\nThe methods were developed and tested on a small well-researched subgroup of Austronesian languages and are now being applied to the much more complex relationships between the Papuan languages spoken in the same area. The results suggest that these languages derive from a common phylum that is much older than the Australian languages, which arrived in the area only 3,000 years ago8.\nLanguages are not inborn. There are approximately 7,000 languages in the world today, and learning any one of them is a lengthy process that takes around a decade. There is no reason why a Chinese child growing up in Germany should learn to speak German any worse than a German child or a child of any other nationality. A specific genetic predisposition, however, might influence the evolution of particular structural features of a language within a group of genetically similar individuals, for example whether the language is tonal or non-tonal.\nChinese is perhaps the most well-known of the tonal languages, in which a single syllable can convey different meanings according to whether it is spoken in a consistent tone or a rising, rising–falling or falling tone. The distribution of tonal and non-tonal languages corresponds closely with the distribution of two alleles, or forms, of the abnormal spindle-like microcephaly-associated (ASPM) and microcephalin genes9,10. Of course, alleles by themselves do not directly lead to the evolution and use of tonal languages; children with different forms of the genes will still be able to learn tonal languages. A particular genetic predisposition in a population, however, might favour the emergence of languages with particular structural characteristics. It is now possible to study whether there might also be a genetic predisposition to other structural properties, like poverty or richness of inflexion.\nScience historians are familiar with the power of new technologies to revolutionize science. We are standing before an advance that will feel particularly close to home. Over the next decade or so, we can expect new genomics technologies to further our understanding of one quintessential aspect of being human: language.\nThe languages of the world, which form part of and are the main bearers of cultures, are highly diverse. The capacity to develop, learn and use them, however, belongs to our shared genetic heritage. These aspects of language are researched intensively at the Max Planck Institutes for Psycholinguistics, Evolutionary Anthropology, and Human Cognitive and Brain Sciences.","Learning a new language can be daunting to say the least, but learning a new language that has absolutely no Latin or Germanic foundation – like Thai - can be, for us native English-speakers, downright frustrating.\nI’m going to give you a primer on the language and what, in general terms, to expect, and I’ll also provide you with some suggestions to get you going along the right path.\nI want to stress that there is nothing to be afraid of. Though the Thai language may appear to be a very tall mountain to climb, with persistence and patience it can be done. There’s a lot of information here, and it’s going to seem overwhelming, but in reality the Thai language is highly structured with few exceptions to the rules.\nLearn and memorize the rules and you’ll be well on your way to living the expat life happily and fluently!\nIt’s all about the tones\nThai is a tonal language. Unlike English where the intent of a sentence is determined by inflection (questions usually rise at the end, statements usually fall, etc…) Thai has a very specific set of tone rules. This is the single most important thing you need to understand about the language.\nThere are five tones in Thai: mid, low, falling, high, and rising. Every syllable has a tone associated with it based on certain rules (don’t worry about the rules for now).\nA mid-tone has a monotone sound in the natural register of your voice.\nA low tone is also somewhat monotone-sounding but requires you to lower the pitch of your voice/make it deeper.\nA falling tone starts a little bit higher than your mid tone and lowers in pitch at the end.\nA high tone gets higher in register at the end of the syllable.\nA rising tone sounds like a high tone but starts lower and is a bit more dramatic.\nThis is, of course, an oversimplification, and I strongly suggest that you listen very closely to Thai natives to hear the distinctions.\nThe bottom line is that you must understand the importance of tones. If you mispronounce the tone of a syllable or word you could, for example, say the word for “horse” when you meant to say the word for “dog.”\nThere are many Thai language learners that will tell you not to worry about tones and to just start with vocabulary. I completely disagree with this, and my suggestion is to be aware of how important the tones are and to be sure to learn them from the onset of your Thai language education.\nConsonants in the Thai language\nThere are 44 consonants in the Thai language. Consonants are arranged into three groups called “classes”: low, mid, and high. Each of the 44 consonants belongs to one of these groups, and is one of the determining factors for a syllable’s tone.\nA few of the consonants – and this goes for some vowels, too – have sounds that we English speakers are not familiar with and may prove awkward to learn at first. For example:\nDT – This sound is not something we naturally produce in English. It’s a combination of a “D” and “T” sound.\nNG – Think of the word “singing.” The Thai NG sound is produced similarly to the first “ng” in singing.\nSeveral of the consonants have the same sound but are written differently. For example, the letter “s” in Thai can be written four different ways:\nซ, ศ, ษ, ส\nConsonants also have a unique feature in that their sound changes depending on whether or not they are found at the beginning or end of a syllable. Using our letter “s” example, when one of those four characters is used at the beginning of a syllable, the “s” sound is used. However, if one of those same characters is used at the end of a syllable, they are pronounced with a “t” sound. (Thai does not have an ending “s” sound for a syllable, so “t” is used instead.)\nVowels in the Thai language\nVowels, admittedly, are a bit of a pain in the butt to wrap your head around. Not only do some of the vowels have sounds that are – like some consonants – difficult to reproduce for us, but vowels can be found before, after, on top of, or below a consonant, as well as in several combinations thereof. Here are some examples:\nThis syllable is pronounced /nai/. The first character, ใ, is actually the vowel. Yes, that’s right; in this case the vowel “ai” comes before the consonant “n.”\nThis is the word for “good” and is pronounced as /dii/ (“dee”). The vowel is above the consonant in this case.\nThis is a fun one. /rao/ is the word for “we,” and the vowel is actually the first and third character. The “r” sound is sandwiched in between the vowel!\nThe word for “ear” is /hǔu/ (pronounced with a rising tone). The vowel is the small u-shaped symbol underneath the consonant “h.”\nLastly, here is a hard one:\nThis is the word for “alone” - /diiao/. The vowel is a combination of everything except for the ด. Yes, this vowel is to the left, above, and to the right (with two characters) of the consonant.\nHave I scared you yet? Probably. They scared me at first. But as I mentioned at the beginning, persistence is the key. Just remember that there is only one vowel sound per syllable.\nTone marks in the Thai language\nAs if the information already provided isn’t intimidating enough to have you scouring the web for English language expat groups and media sources, the Thai language also has four symbols called tone marks, which are used to determine a syllable’s tone. The good news here is that when a tone marker is present you can ignore all of the other factors that determine a syllable’s tone. The four tones marks are:\n่ mái èek\n้ mái too\n๊ mái dtrii\n๋ mái jàt-dtà-waa\nDon’t worry about the dotted circles; they are just there to represent where a consonant should be. All tone markers go above the corresponding consonant.\nAny last words?\nYes, a few things, but since this is just a primer I won’t drown you in detail. There are a few more quirks like consonant clusters and other symbols that come into play, but for now I think I’ve given you enough to warrant a few mind-numbing margaritas.\nAs a consolation prize of sort:\nSorry to have to do this to you, but I should also mention that written Thai has no spaces in between words. Yes, that’s right, Thai looks like one huge run on sentence. There are spaces in between sentences, but not in between the words in a sentence. For example:\n/kun wâai-náam dâi mǎi/\nCan you swim?\nHere are the individual words separated out as if it were English:\nคุณ ว่าย น้ำ ได้ ไหม\nUnfortunately, we don’t get the luxury of having Thai written the English way.\nIt’s also important to know that Thai is also, in some cases, gender specific. Men will use certain words for something and women will use certain words for the same thing. As you start to learn the language, be aware of this so you don’t walk around saying words a woman would normally use when you are a man (and vice versa). Though it’s not the end of the world, it could cause for some unexpected chuckles.\nAny suggestions for tackling Thai?\nBe patient – This is a marathon, not a sprint. As complex as Thai may seem, it’s really not. Just go step by step and take your time.\nMake a friend – There is nothing more valuable than finding a few Thai people and becoming friends. I assume this will happen by default, but the point here is to start speaking Thai to them right away. You’ll find that a few things happen:\nYou make instant friends. (Thai people LOVE when they see you making the effort.)\nThey will start to help you with your Thai. At first you may need to nudge them a little bit, but once the friendship has been established they will most often be eager to help you.\nWrite, Read, Speak – Learn to do all three at once. Children’s books are a great place to start. But don’t neglect one for the other two. Just learning how to speak may seem like the thing to do, but it’s really not.\nDO NOT try to learn Thai from the newspapers – One of the interesting quirks about Thai is that speakers will always try to shorten everything being said or written. Because of that, newspapers and magazines will often be very difficult to understand. Trust me; the last thing you want to do is talk like a newspaper!\nLearn from the right people – If you are a 60-year old man, you probably don’t want to be learning to speak Thai exclusively from a 22-year old girl. Not only will you probably start to use woman-specific words, but you’ll also be picking up all of her slang. In essence, you’re going to sound pretty strange!\nListen, listen, listen! Get a TV and watch Thai programming, a lot. At least an hour a day if you can. Don’t worry about trying to figure out what they are saying, just listen. You’ll absorb the pronunciation the same way a child learns.\nHave fun. You’re going to hear the Thai word sanuk (“fun”) a lot. Thai people are all about having fun, so you should too!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:86853453-3933-469d-b71f-79a600c7d002>","<urn:uuid:32a4c2eb-734c-4260-ae63-83e1f7256e2c>"],"error":null}
{"question":"How do monitoring and retention challenges compare between Jenkins build systems and consumer-facing software products? Can you explain the key differences in how these systems track and analyze user/build retention?","answer":"Jenkins build systems and consumer-facing products face distinct monitoring and retention challenges. Jenkins systems struggle with monitoring multiple servers simultaneously, require longer-term storage of test results, and need specialized views for comparing builds across platforms and time periods. Their retention focuses on maintaining test history and build data for extended periods, sometimes years, especially for performance tests. In contrast, consumer-facing products measure retention through user actions (like logins or messages) or dollars spent within specific timeframes after sign-up. They analyze retention through cohort analysis using triangle retention charts, focusing on daily, weekly, or monthly active users. While Jenkins systems need customized views for different team members (developers, FV team, SV team), consumer products segment users based on engagement levels and behavioral characteristics to understand and improve retention patterns.","context":["As we support more and more tests, projects and Jenkins servers, monitoring builds health and triaging tests daily is quickly becoming an overwhelming task. We are currently maintaining 6+ Jenkins servers both internally and externally.\nWe encounter 4 main challenges that have motivated us to develop TRSS:\nMultiple Jenkins servers to monitor\nEven though we use Jenkins plugins at each particular Jenkins server for sending build status messages, without a build status overview it is hard to triage failure.\nNeed for longer-term storage of test results\nSecondly, we may want to keep results for a longer period of time for some tests, so we can compare the results with history runs. For example, we may want to keep performance test results for months or even years. Jenkins server often has limited storage and we can only store limited number of builds.\nNeed for specialized views like side-by-side comparison\nThe third problem is that we do not have a tool to view/compare test results. Some type of tests is best to compare result with previous releases, previous builds or different platforms within the same build. Additionally, some type of tests are best displayed in graph to see the trends.\nDesire for customized views (tailored by each user)\nLast but not the least, different users may be interested in different builds. For example, developers may want to only monitor their own personal builds. The FV team maybe only interested in functional test builds. The SV team maybe only interested in system test builds. A project manager may want to know overall test builds status.\nWe wanted a tool to monitor multiple Jenkins servers and display different type of test build results and history (test log files, compare test result across builds/platforms, display trends, etc.) And it needs to be highly customizable per user.\nTo solve the issues listed above, we have started creating a thin-layer service called the Test Result Summary Service (TRSS). You can find the source in https://github.com/AdoptOpenJDK/openjdk-test-tools.\n1) Personalized Dashboard:\nTRSS can monitor multiple Jenkins servers in real-time. User can add/remove builds, add/remove/rearrange the panels/widgets. User’s modification is stored in each user’s browser local storage, so everyone can have their own customizable view and store their configuration without interfering with others.\n2) Test Result View\nOther than monitor multiple Jenkins servers in real-time. TRSS also stores test history data.\nDownstream builds that are launched by above parent build pipelines:\nList of all tests within the build. In this view, TRSS displays test name, test result, test duration and test result history. Columns can be sorted or filtered (to only show FAILED tests or to sort them to the top of the list).\nFrom above view, we easily tell cmdLineTester_gcsuballoctests_0 failed. All Platforms shows cmdLineTester_gcsuballoctests_0 test result for all platforms and JDK version in the build.\nDeep history shows cmdLineTester_gcsuballoctests_0 test execution history on Linux s390.\nTRSS also displays the test output (as one would see in an individual Jenkins server console view of the test build). Below is cmdLineTester_gcsuballoctests_0 test output.\n3) Test Compare\nTRSS can compare any test output (regardless of test type, build, platforms, etc). With information for Jenkins server, build name, build name and test name, TRSS can search database and compares test output side by side. This is an extremely simple but effective way to speed triage by comparing a passed build to a failed one and quickly identifying differences.\nTRSS uses node.js as server and React as client. It actively monitors multiple Jenkins servers and their jobs. TRSS parses the jobs outputs and store parsed data into MongoDB. If needed, it also stores links to Artifactory for extra data (i.e., logs, core files, erc).\nIf special data is needed for display (i.e., new measurement), user can easily add parser code to TRSS server and client so that different type of tests can be parsed and displayed.\nIn the multi-server, multi-project scenario, TRSS is a lightweight and customizable open-source solution to monitor, display, compare and triage test results and store history test data. The tool itself is project-agnostic and can be generally applied to any Jenkins-based builds or projects.\nWe are still in the early development stage. TRSS is the stepping stone for us to create/integrate with other microservices. For future enhancement, we may tie into Watson Analytics and try out cognitive triage experiments. If you are interested in helping build and improve this project, please engage us in the AdoptOpenJDK #testing Slack channel. 🙂","WHAT IS RETENTION?\nWouldn’t it be nice if every new user continued to engage with your product forever? That’s retention—a measure of the people who tried your product and liked it enough to return.\nMany consumer-facing businesses define retention in terms of the percentage of users who take a given action (such as logging in, sending a message, etc.) within a certain period of time following sign-up. Subscription and SaaS businesses tend to define retention in terms of dollars spent within a certain period of time after the customer’s first spend.\nIn any case, retention is a good way to measure product-market fit and by far the best lever for product growth. Without retention, a growing product will eventually be left with no users. Retention affects every significant metric and is discussed in the context of other product concepts in our blog post on product health.\nWhile retention is framed primarily as the percentage of users returning to the product itself, it is also useful to understanding specific product features and subpopulations of users. For example, you can examine how retention varies by geography, gender or behavioral characteristics (e.g., daytime vs. nighttime use) to paint a clearer picture of your users. Similarly, at the feature level, you can examine how users interact with individual features and then use that knowledge to guide prioritization and the product roadmap.\nBefore you invest in acquiring new users through marketing or paid channels, you should understand how to strengthen and stabilize retention for early users. If retention is weak, few users will stay long-term, and you will churn through the total addressable market with little to show for it—at great expense.\nRetention is generally depicted by plotting the percentage of users who return to either the product or a core feature over time. There are three archetypal retention curves (see Figure 1).\nFlattening curves This archetype suggests that a percentage of users who sampled the product found value in it and continued to return to it over time. Not all flattening curves are equal, however. The higher the level at which the curve flattens, the higher the long-term retention and the healthier the product. In Figure 2, the curve 2 flattens at a higher level, indicating a healthier product.\nDeclining curves When a product has not achieved product-market fit, the retention curve will continuously decline, eventually reaching very few or zero users. In this situation, it is important to focus on changing the product to find a value proposition for a core set of users and then expanding from that set. As shown in the case of BranchOut, applying growth-hacking techniques at the top of the funnel without fixing underlying weak retention will lead to a “leaky bucket” outcome, in which users simply pass through your product.\nSmiling curves When a product is truly exceptional, its retention curve will actually rise as product development and network effects propel churned users to return during a Hyper Growth phase. In these situations (see Figure 3), users eventually return to the product eventually after initially churning away.\nFor most products, including those with smiling retention curves, retention will eventually trend to zero as the product is disrupted by competition, shifts in user behavior and other factors. For games in particular, the time frame of these shifts tends to be relatively short as users move on—for example, Angry Birds was extremely popular in the early part of this decade, amassing tens of millions of monthly users, but currently has only a few hundred thousand.\nRetention is measured relative to two factors: time frames and events.\nDepending on the vertical of your product, a daily, weekly or monthly time frame may be most meaningful. An e-commerce or travel product might expect users to come back once per quarter, whereas a social app or game would expect daily usage. Measuring retention against these expected time frames is key; to look at monthly retention for a product with a natural weekly frequency, for example, would lead to an inaccurate account of product health.\nWhen considering events as they relate to retention, it’s also important to define what constitutes meaningful activity. Is a monthly active user anyone who simply logs in at least once per month? Anyone who has a five-minute session in a month? Purchases an item? Posts a message?\nFor example, a ridesharing app such as Uber or Lyft would define an event as a completed ride, rather than an app open. Content streaming services such as Spotify and Netflix might define an event as beginning to listen to, or view, a piece of content. For a messaging app, it might be when a user writes or reads a message.\nIn addition to product-level retention, you may also want to define feature-level retention, where the event is defined as using a particular feature of the product. For example, Amazon could measure how its Wishlist feature is used to help prioritize feature development and the product roadmap.\nTriangle retention chart Retention by temporal cohort is a useful visualization to monitor frequently. The most common way to visualize temporal cohort retention is with a triangle retention chart (Figure 4). Each row of the chart corresponds to a temporal cohort, with the size of the cohort, in users or dollars, listed in the first column (0). Subsequent columns (1–22) show the percentage of that cohort remaining after a given period of time.\nBy assigning colors to certain percentage values, you can quickly identify changes in retention, which will typically appear as horizontal, diagonal or vertical features.\nHorizontal features identify cohort-specific traits. For example, if you were to run an acquisition campaign or expand to a new market expansion in a given month, you might see a horizontal feature emerge showing improved or diminished retention particular to that cohort. In Figure 4, the February 2016 cohort is significantly larger than previous or subsequent cohorts (perhaps as a result of an experimental acquisition campaign or a referral feature), and retention for that cohort is relatively poor.\nDiagonal features are usually a result of product feature releases, news or other events that affect overall usage. For example, the #DeleteUber campaign affected every Uber cohort, not just the ones who started using the service in January 2017 (when the campaign began to trend). Diagonal features may also indicate product outages or breakage: when AWS had service outages in early 2017, many companies’ retention charts exhibited a diagonal feature for that day, as users couldn’t access their products.\nVertical features are commonly seen in subscription businesses that have annual plans, as well as in those that offer trials. For example, a dollar or transaction retention chart for Amazon Prime would likely show a significant vertical feature every 12 months, when portions of cohorts renew their yearly memberships.\nIn addition to helping visualize retention, the first column of a triangle retention chart can give you a sense of your new user growth: Is it increasing? Do you see more users signing up on the weekends? You may also see the impact of exogenous events as a suppressed or increased new user sign-up in the first column.\nSince total retention is the weighted average of your cohort retentions, it is especially important to track any cohorts that are dramatically larger than others. For example, if in January the product acquires 10 times the number of total users acquired in December, your overall retention is more or less determined by the January cohort.\nComposing time frames As discussed above, it is important to choose the appropriate time frame when measuring retention. For monthly, quarterly or annual products, however, there may be a long delay between implementing a product change or updating an acquisition strategy and understanding the impact on retention.\nIn these instances, we can break down long-term retention of a cohort (364 days in the equation below) into multiple ratios. This equation can be understood from left to right as a funnel of users, where D1/D0, or the “D1 retention rate,” is the fraction of your cohort retained for one day, and so on. (D0 is the number of installers in a cohort and D1 is the number in that cohort who still use the product after one day.)\nIf D7/D1 stays relatively constant for all cohorts, but the D1 retention rate appears to be declining, focus your attention on improving D1 retention, as this will likely be the biggest lever for long-term retention. Likewise, if D1 retention is flat but D7/D1 is declining, focus on finding new ways to engage users in the first week rather than the first day. Ultimately, your goal is to increase long-term retention, but it is important to monitor these fractions, as well, as they are early indicators of future retention trends.\nHOW TO IMPROVE RETENTION\nTactics for improving retention vary widely based on the circumstances of the product, technology and user base. Once you have decided on the right retention metric, your goal will depend on your type of retention curve, as defined in Figure 1:\n- Declining curves: Flatten the retention curve of each cohort.\n- Flattening curves: Elevate the long-term retention of flattened curves.\n- Smiling curves: Celebrate!\nThe techniques below will help you improve retention for different segments of your population, but the unifying theme across all populations is to increase engagement. As we discuss in a previous post, engagement drives retention. (We will offer additional guidance on engagement in a future post.)\nEngage retained users Retaining existing users is key to growth and is accomplished primarily through engaging them—by providing value in the product. Your most important users are the “super users” who are most engaged and thus best retained. Understanding how this group interacts with the product is the best way to improve overall retention.\nTo identify your super users, first hypothesize which features are core to the product’s value proposition, which is frequently referred to as the product’s “magical moment.” PayPal’s magical moment is a successful transaction; for Amazon, it is a seamless delivery experience. Once you’ve identified your “magical moment,” segment your users based on how, and how frequently, they engage with it. (We plan to cover this topic in more detail in a future post on exploratory analysis.) The most frequent users of any particularly valuable feature are your super users: they watch the most videos, share the most content, create the most messages, etc.\nOnce you’ve identified these users, examine their prior behavior. What features did they use early on? Did they encounter the magical moment a certain number of times before they reached a “tipping point” and became truly hooked on the product? For example, Facebook famously discovered that connecting to seven friends in 10 days greatly improved retention—which led to a product strategy that encourages users to reach that milestone.\nEarly on, you should focus on building a product that will delight super users. Then, once you have identified their key behaviors and engagement tipping points, you should use those insights to create a playbook for motivating less-engaged users to behave similarly, which will ultimately drive better retention.\nRemove friction for new users The most efficient way to improve retention is to bend the shape of the retention curve as early as possible. For most products, especially new ones, the curve is fairly steep for the first several days, weeks and months. Users churned during this period represent the vast majority of all churned users, so driving new user engagement (and thus retention) early on is especially valuable.\nTo improve retention among new users, it is important to understand the sign-up (or acquisition) funnel. For example, how many people viewed an advertisement for the product, and on which channels? How many then clicked on that ad? How many then created an account, and how many were retained 7 days later? 24 days later? 84 days later?\nStudying the drop-offs in users at each stage will help you understand the efficacy of your acquisition channels (paid and unpaid) and identify any problems in sign-up and onboarding flow. For example, a significant drop-off between sign-up and account confirmation suggests an issue with confirmation email delivery. As another example, when the team at Poncho, a weather chatbot, studied and revised the number of questions in their sign-up flow, their seven-day retention increased from 60 percent to 80 percent. To further isolate points of significant drop-off, filter your data by channel, device, etc. Removing these sources of friction helps new users arrive at the “magical moment” as quickly as possible, which will dramatically improve retention in this group.\nA well-designed onboarding guide that clearly communicates your product’s value proposition and guides new users toward the tipping point of engagement will also strongly influence retention—not only for new users, but for all users.\nBenchmark your product To establish the “correct” level of long-term retention for your application, set benchmarks based on similar products in your genre. For example, a game developer might compare their product to other games of the same type.\nTable 1 shows the difference in 30-day retention rates between several successful casual puzzle games (7–10 percent) versus well-known strategy games (more than 30 percent). A casual game that has 20+ percent D30 retention and a 35 percent D30/D1 ratio would be well ahead of top casual games such as Angry Birds. But a social or strategy game with the same metrics would be significantly behind the leaders in its genre.\nEngagement drives retention Because engaged users are less likely to churn, engagement metrics such as the ratio of daily active users (DAU) to monthly active users (MAU) correlate with and drive retention. Similarly, slipping engagement metrics are leading indicators of problems with downstream retention. If engagement declines, act quickly to remedy the situation before retention is affected.\nReduce churn early Monitoring and acting on changes in early retention (D1, D7, D28, etc.) are crucial to achieving strong long-term retention. For most products, users churn early; stanching this outflow will lead to better retention over longer time frames.\nNewer cohorts retention depends strongly on the product type, phase of the product and its market penetration For most products, the earliest adopters of the product are generally the most excited about the product and retain the best. Until the product achieves product market fit, the later cohorts generally retain worse than the earliest adopters for whom the product fits a more immediate need. As the product starts to do better achieving strong product market fit and enters the growth and hyper-growth phases, the retention of users improves again as more people begin to see the value of the product. As such, the cohort retention of products may vary a lot depending on the phase of growth.\nMoreover, products with network effects will likely see retention correlate across cohorts. Early on, when there are few users, users in cohorts may churn as there are few relevant connections (social products) or content available (professionally and user generated content products). In the growth and hyper growth phase for network-driven products, more users are drawn to the product and generate more content increasing retention and in turn resurrection from older cohorts. For non-social products, the retention of newer cohorts may not be correlated with how well older cohorts are doing.\nFor both network-driven and non-network-driven products, cohort retention will fall once penetration is very high — the marginal user at this point will be at the periphery of the core user.\nRetention can be applied at a feature level The retention characteristics of your product may not mimic those of individual features. For example, a product might have excellent retention overall, while retention of its messaging and image-upload features is significantly lower. Wide variations are not uncommon between individual features. To ensure your product reaches its full potential, you should recognize this reality and analyze the retention of individual features as well as of the product itself.\nRetention can be used to understand how well your product is growing overall, to evaluate its use among subsets of users and to determine how specific features are performing. Ultimately, retention is driven by increased engagement and removing friction. Exposing users to your product’s magical moment as early and as frequently as possible will reinforce your product’s value proposition and drive them to return to the product, as well as to engage more deeply and more frequently. This will first increase short-term retention and later manifest in better long-term retention, putting your product on the road to sustainable growth.\nRetention is a measure of the people who tried your product and liked it enough to return; as such, it underpins all significant metrics.\nThink of retention as a funnel. Breaking down the long-term retention of a cohort into multiple ratios can help you identify the early indicators of long-term retention as well as the biggest levers for long-term retention.\nTechniques for improving retention vary by user population. Retained users should be increasingly engaged, while new users should experience minimal onboarding friction. Exploratory data analysis will help identify precise levers for each population.\nFollow us on Medium for weekly updates.\nThis work is a product of Sequoia Capital's Data Science team. Jamie Cuffe, Avanika Narayan, Chandra Narayanan, Hem Wadhar and Jenny Wang contributed to this post. Please email firstname.lastname@example.org with questions, comments and other feedback."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:b66ea949-55ce-4857-9eb7-6124725860d8>","<urn:uuid:65dfa081-0a87-4646-afe7-f37412d9be35>"],"error":null}
{"question":"How do local regulations affect home-based businesses, and what are the recommended types of insurance coverage for different business activities conducted from home? 运营家庭企业需要遵守哪些当地法规，不同类型的家庭企业又需要什么保险？","answer":"Local regulations affecting home-based businesses include zoning laws that may restrict multiple employees or customer traffic, limitations on business-dedicated space (e.g., Miami-Dade County's 200 square feet limit), signage restrictions, and HOA rules that might prohibit certain or all businesses. Some localities require specific licenses, like Chicago's regulated business license requirement. Regarding insurance, different business activities require specific coverage: professional service providers need Professional Indemnity insurance, online businesses should consider Cyber Liability Insurance for data breaches and hacking protection, and all home businesses need Public Liability insurance for third-party injuries. Business Insurance is also recommended to protect equipment and stock, while Personal Accident insurance can provide income protection if the owner is temporarily unable to work.","context":["It is easy for just about anyone to start a business from home. Whether people have left an office job because of downsizing or retirement, or have chosen to start a sideline activity for extra income, working from home reduces startup costs and may provide personal benefits (e.g., managing child care or parental care responsibilities). Technology enables an entrepreneur working in a home office to connect with customers, clients, and other business associates around the world. The Small Business Association’s Office of Advocacy reported in March 2014 that 52% of all businesses in the United States are home based (“Frequently Asked Questions,” http://bit.ly/2q14K9O). The ease of starting a home business does not, however, detract from the various legal, tax, and financial concerns that must be addressed.\nWhile zoning laws can be behind the times, they do not necessarily preclude operating a business from home. Issues arise when—\n- there are multiple employees or a constant stream of customers, which may disturb the neighbors, create parking problems, or raise other concerns;\n- there are noises or odors connected to the business; or\n- the business is a type restricted from a residential area.\nThere may be restrictions on the amount of space that can be dedicated to business use. For example, Miami–Dade County restricts home office space to 200 square feet.\nEven when a business can operate from a home, there usually are restrictions on signage. It is therefore essential to check with the city or town about zoning restrictions and related rules.\nEven if local zoning rules do not bar a home office, the terms of a homeowners association (HOA) may restrict having certain businesses, or any at all, within the community. Again, a review of covenants, conditions, and restrictions in the HOA agreement will show what is or is not permissible. For example, there may be a bar on commercial vehicles, which would preclude a limousine or moving business, but not necessarily an insurance or interior decorating business. Similar restrictions may be imposed on owners of cooperative apartments.\nEven if businesses are permitted to operate from the home, there may be other building or commercial codes that come into play. For example, Massachusetts’s Department of Public Health restricts the types of food that can and cannot be prepared in a residential kitchen for sale outside the home (e.g., in a catering business).\nA person operating a business from home should not assume that his homeowners policy covers business-related liability. If, for example, a business client is injured in the home office, this incident may be excluded from a basic homeowners policy. Similarly, if a fire destroys a home, office equipment may not be covered. It is essential for a home-based business to have a separate business owner’s policy (BOP) to cover liability to third parties, as well as damage or destruction to equipment or inventory in the home. Alternatively, it may be possible to adjust an existing homeowners policy to cover these concerns.\nSome localities require businesses, even if home based, to obtain a license to operate. For example, Chicago has a regulated business license requirement for home occupations. There may be fees for such a business license (e.g., $250 for two years in Chicago).\nThe costs of a home office can be deductible, effectively converting personal expenses into a business write-off [Internal Revenue Code (IRC) section 280A]. The following two tests must be satisfied to be eligible for a home office deduction.\nCondition 1: qualified use.\nThe home office must be used for one of the following:\n- The principal place of business. Essentially, this means where business revenue is earned, as well as the place where substantial administrative tasks are performed, such as ordering supplies, scheduling appointments, and keeping the books, as long as there is no other location for the business. For example, a plumber who does work at customer locations can take a home office deduction if the space is used for administration of the business.\n- A place to meet or deal with customers, clients, or patients in the ordinary course of business. Thus, an accountant with an office in town who uses her home office to physically meet with clients meets this test. Using a home office solely to make phone calls or send email does not satisfy this requirement.\n- A separate structure (e.g., greenhouse, freestanding garage) used in connection with the business.\nCondition 2: regular and exclusive use.\nThe space in the home must be used regularly and exclusively for business. The home office space cannot serve a dual purpose, such as a den used for business during working hours and for watching television with the family after business hours (with the exception of day care businesses). In one case [Bulas v. Comm’r, T.C. Memo. 2011-201 (2011)], the costs related to a bathroom built for an accountant’s clients could not be deducted because his children and personal guests used the bathroom occasionally. Such incidental use, however, may not necessarily violate the second condition. In another case [Miller v. Comm’r,T.C. Summary Opinion 2014-74 (2014)], a taxpayer who used part of a studio apartment as a home office was allowed a deduction even though she had to pass through the office space to get to the bedroom area.\nTypically, a home office is a spare bedroom or converted attic created as a workspace. A home office can, however, be any part of a residence, including a garage, a freestanding greenhouse, or a barn. The space does not have to be a full room or even a partitioned area to qualify. It may be helpful to take a photo of the space to show that it is, indeed, used only for business.\nDeducting actual costs.\nThe costs of a home office can be figured in two ways: actual costs or an IRS-set simplified method. Under the actual cost method, expenses related to a home office are either indirect costs or direct costs. Indirect costs are those applicable to the whole residence (e.g., home mortgage interest and property taxes, rent, utilities, homeowners/renters insurance, monthly security alarm charges). The portion of these costs taken into account is based on the square footage of the business space; for example, if 10% of the home is used for business, then 10% of the rent is taken into account in calculating the home office deduction.\nFor personal expenses that are deductible as itemized deductions (e.g., mortgage interest), the portion related to the home office is part of the business write-off; the balance is taken into account on Schedule A of Form 1040 as a personal write-off.\nIf the home is owned (not rented), the home office deduction includes an allowance for depreciation. The amount of depreciation is based on the lower of the adjusted basis of the home or its fair market value at the time the space is converted to business use (exclusive of the land).\nDirect costs are those exclusively related to the business space. For example, repairs to a spare bedroom used as a home office are direct costs that become fully deductible as part of the home office deduction.\nInstead of tracking all home-related expenses and categorizing direct and indirect costs, the home office deduction can be figured using a simplified method (Revenue Procedure 2013-13). The deduction under the simplified method is figured by multiplying the square footage of the home office (up to a maximum of 300 square feet) by $5. This method allows a homeowner to fully deduct home mortgage interest and real estate taxes as personal itemized deductions, even though these expenses are essentially factored into the home office deduction.\nThe election to use the safe harbor deduction can be made on an annual basis. Once it is used for a particular year, however, the election is irrevocable.\nGross income requirement.\nWhichever method is used to figure the home office deduction, the amount of the deduction cannot exceed the gross income earned by the business. Thus, for startups, the home office deduction may be limited or barred entirely due to this gross income requirement. Any deduction calculated under the simplified method that is limited by the gross income requirement cannot be carried over and is lost forever. The amount limited under the actual expense method can be carried over and claimed in a future year to the extent of gross income from the business, whether or not in the same residence.\nSpecial issues for owner-employees.\nIf a business is incorporated, how should home office costs be handled? There are three ways to do this:\n- Claim a home office deduction. Use of the home office must be for the convenience of the employer, but an owner-employee of the business obviously satisfies this test when there is no other location. Despite qualifying for the deduction, however, there may be little or no tax advantage to it. The deduction is claimed by the owner-employee as an unreimbursed employee business expense, so only miscellaneous itemized deductions in excess of 2% of adjusted gross income are actually allowed. What’s more, the deductions are also subject to the phase-out of itemized deductions for high-income taxpayers.\n- Rent the home office to the corporation. If an owner-employee rents part of the home to the corporation, the corporation deducts the rent; the same rent is, however, taxable to the owner-employee, and no home office deduction is allowed [IRC section 280A(c)(6)]. While this may not be optimal, the rental payment is preferable to a salary increase to cover home office deduction costs because no employment taxes are due on the rental payment.\n- Use a reimbursement arrangement. An owner-employee can obtain reimbursement for the costs of a home office under an accountable plan; the costs of the home office become deductible by the corporation, while the owner-employee is not taxed on the reimbursement. If the reimbursement covers mortgage interest and property taxes on the home, the owner-employee cannot take deductions for these amounts. Requirements for an accountable plan are found in IRS Publication 463, Travel, Entertainment, Gift, and Car Expenses (http://bit.ly/2rwHTof).\nSome businesses operate from mobile homes or recreational vehicles (RV), and owners may try to claim a depreciation for them as well as other business expenses for operating them. This may be difficult to do, as the following cases illustrate:\n- Cartwright v. Comm’r, T.C. Memo 2015-212. An orthopedic surgeon used an RV as a place from which to respond to “stat” pages within five minutes when he was on call from the hospital. The Tax Court limited depreciation and an IRC section 179 deduction to modest business use, rather than the amount that the doctor had claimed. The RV was used primarily for recreational purposes.\n- Jackson v. Comm’r, T.C. Memo 2014-160. An insurance agent used an RV to meet clients and sell insurance, and it was agreed that about 2/3 of the mileage was for business driving. Nonetheless, the Tax Court disallowed a home office deduction because the RV was also used for personal purposes (i.e., no space within the RV was exclusively used for business). While use of the RV was “appropriate and helpful” to the business, a home office deduction for its costs was barred (although some RV costs were deductible).\n- Dunford v. Comm’r, T.C. Memo 2013-189. A consultant who used an RV to travel around the United States could deduct interest on the loan to buy the vehicle, but not other business deductions. The Tax Court ruled that he had blended purposes—personal and business—for the travel, but that the dominant motive was personal (to be near his children and to winter in a warmer climate).\nHOME BUSINESS CHECKLIST\n- ___ Do zoning laws permit running a business from home?\n- ___ Do city/town ordinances restrict signage?\n- ___ Does the HOA bar or limit a home-based business?\n- ___ Has the requisite insurance been acquired?\n- ___ Does the office qualify for the home office deduction?\n- ___ Has the impact of the home office deduction on a future sale of the residence been considered?\nAudit risk for the home office deduction.\nThere continues to be a prevailing belief that claiming a home office deduction is an audit red flag, even though there are no IRS audit statistics or IRS warnings on this point. Individuals using a home office who meet eligibility requirements and can substantiate their costs should probably take the deduction.\nWhile a home-based business owner may deduct office costs annually, there can be a financial impact when the home is sold. Gain on the sale of a principal residence is usually tax free up to $250,000 ($500,000 on a joint return) if certain conditions are met (IRC section 121). If the homeowner has been deducting the actual costs for a home office, however (including depreciation), gain on the sale is taxable at 28% to the extent of depreciation claimed after May 6, 1997 (IRC section 1250). This is referred to as “unrecaptured depreciation.” There is no unrecaptured depreciation if the home office deduction is based on the IRS’s simplified option.\nStarting a business from home can create income and tax savings; however, many legal, tax, and financial issues come into play. All of these issues should be addressed before business operations begin, and CPAs should advise interested individuals of them.","Home Businesses face unique challenges and an often complex web of insurance needs. Sorting it out can be daunting, and the consequences of getting it wrong can be dire. Here, we’ll attempt to break down the major insurance types and weigh up their relevance to your business.\nPublic Liability… The ‘Must Have’ Insurance\nThis protects your business against the financial risk of being liable for causing injury, damage, loss or death to a third party.\nYou have a ‘duty of care’ to keep any visitors, such as clients or suppliers, free from harm on your premises. Any breach of this responsibility could result in a claim, and whilst you may see your home office or garage as a safe place, any seemingly innocuous slip, bump or fall could cripple your business financially. Essential.\nProfessional Indemnity… If You Sell Professional Services\nThis protects professionals against legal costs and claims for damages arising from any act, omission, or breach of duty in the delivery of a service.\nThis is a critical consideration for those providing a professional service from home. Accountants, massage therapists and beauticians are among the professionals that need to allow for the chance of a client lodging a claim. Whether the case is valid or not, Professional Indemnity insurance will protect against court costs and any compensation claims.\nPersonal Accident… Look After Your Most Important Asset\nIf you’re temporarily unable to work due to an accident, this cover provides up to 85% of your income (up to $3,000 per week) until you’re back on your feet.\nAccidents do happen, and a simple injury could put you out of action and unable to earn an income for a considerable amount of time. For a more comprehensive income protection plan you also have the option of including Illness insurance, which would pay you the same benefit if you fell ill and were unable to work. Premiums for both are generally tax deductible.\nBusiness Insurance… Protect Your Stuff!\nBusiness Insurance provides financial cover for the premises and contents against loss, damage or theft, as well as financial loss arising from business interruption.\nThe type of cover you choose here will depend on the nature of your business and the equipment you wish to insure. Protect your workplace premises, furniture, tools, machinery and stock with a policy that includes a fair valuation of all your essential business assets.\nCyber Liability Insurance… Especially If You Operate Online\nCyber Liability Insurance covers you against the expense and legal costs of data breaches or hacking, including the theft or loss of client information.\nAs online activity and operations become increasingly prevalent in business, hacking and data breaches become more numerous and progressively more sophisticated. Small businesses, especially, face a unique set of risks due to the absence of robust security systems that larger firms can afford, and are highly targeted by cyber criminals. Expenses could include the cost of business interruption, forensic investigation and data recovery, extortion and crisis management, as well as mandatory notifications and other legal costs.\nThe insurance types highlighted above could be extended to include ‘Management Liability’ to protect against legal costs of mismanagement or misconduct breaches, as well as ‘Tax Audit’ to cover accountant’s fees in the event of an audit. Of course, business owners should also consider their statutory workers compensation requirements, and appropriate personal insurances such as Life, Disability, Trauma, and Income Protection.\nOperating your business from home can be incredibly rewarding, but ignoring your insurance needs could endanger everything you’ve worked for. Protect yourself, your assets and your income with a balanced, comprehensive set of insurance policies so that your business can cope with whatever the future may hold.\nBizCover™ Pty Ltd (ABN 68 127 707 975; AR 338440) is a corporate authorised representative of Mega Capital Pty Ltd (ABN 37 098 080 418; AFSL 238549). This is general advice only."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:b80fa710-b27a-459c-9ab3-935c4fe01ca4>","<urn:uuid:619f7046-48ac-4904-a941-0f61429fc895>"],"error":null}
{"question":"Did Vikings have access to both sunstones and magnetic compasses for navigation?","answer":"No, Vikings did not have access to both navigation tools. While there is evidence of Vikings using sunstones (mentioned as 'solar stones' in medieval texts) for navigation through cloud cover, there is no evidence that Vikings possessed magnetic compass technology. The magnetic compass was not invented in Europe until around 1300 CE, after the Viking age. Vikings relied primarily on celestial bodies, marine life, and coastal features for navigation, potentially supplementing these methods with sunstones when conditions were cloudy.","context":["For half a century, historians have wondered if Viking sailors travelled long distances under dense cloud cover under the guidance of a crystal called a sunstone.\nConclusive evidence might be forever buried in the past, but a new study details the kinds of conditions ancient mariners might have used this tool, demonstrating it was possible for Vikings to navigate through fog using little more than a polarising rock and some mathematical know-how.\nResearch conducted by Eötvös Loránd University in Hungary evaluated several types of polarising crystal under a range of meteorological conditions throughout the year to test a hypothesis first proposed back in 1967.\nAccording to Danish archaeologist Thorhild Ramskou, Vikings managed to pinpoint the Sun's position through cloud cover by holding up a birefringent material – such as crystallised calcium carbonate called Iceland Spar – to filter the polarised light.\nSunlight passing through the translucent object might then be used in conjunction with a solar compass to work out the relative time and direction, which would aid in determining a position on a map.\nIt was a convenient solution to the mystery surrounding the journey of ancient Scandinavian seafarers to destinations as far away as North America.\nUnder perfect conditions the Sun, stars, marine life, and coastal features could be enough to mark off the milestones needed to navigate such epic treks across the expanse of an ocean.\nThe thing is, the conditions up around the icy North Atlantic aren't always ideal. If the rolling expanses of fog don't make life inconvenient for the navigator, the frequent cloud cover will certainly create problems.\nThat might be less of an issue if they'd had magnetic compasses to point to the poles, but there's no evidence Vikings possessed such technology.\nThere is mention of objects called \"solar stones\" in various medieval texts, however.\nWhile historical writings hint at their use in locating the Sun through the clouds, they don't tend to provide many details on exactly how they were used.\nRamskou was the first modern academic to suggest these objects were crystals that could detect the Sun's precise position based on their refraction of polarised light.\nAs sunlight hits materials in the atmosphere, such as drops of water vapour, it scatters, making it all but impossible to tell the Sun's position.\nLuckily the orientation of the scattered light is slightly different to the sunlight that slips through the clouds. By rotating a polarising filter in front of the eyes, it's possible to map the sky's brightness and trace the Sun's location.\nBirefringent materials split incoming light into two, giving a sort of double image. The intensity of each image will vary, depending on the angle and polarisation of the light source.\nIt's not quite as simple as holding up a rock to unveil the Sun hiding behind the fog, requiring some careful calibration and a keen eye.\nThe hypothesis has plenty of supporters, even if it's a little short on hard evidence. No confirmed samples of sunstone have been uncovered, for instance, and only a single fragment of a potential Viking-age solar compass has ever surfaced.\nTo help fill in a few details on what is a highly speculative proposal, the Hungarian researchers tested three types of birefringent crystal under 1,080 variations of Sun angle and degrees of cloud cover set under laboratory conditions in a planetarium.\nCalcite, cordierite, and tourmaline crystals were all up to the task of determining the angle of the Sun's elevation, especially at times close to dawn and dusk. On average, calcite was found to be the most accurate.\nAt some times of the year, such as summer solstice or spring equinox, and at particular elevations and cloud covers, tourmaline and cordierite produced in smaller uncertainties.\nThese results highlight the ideal conditions sunstones could have been used, and the degree of uncertainties they'd produce.\nIn short, if the Vikings used birefringent crystals at all, they would have found them most useful when the Sun was relatively low in the sky near summer solstice, perhaps around early to mid morning, when it's obscured by low level fog or cloud cover.\nThat's far from proof the Norse navigators used them at all. The data was also collected on solid ground inside a room, and not out on the rolling seas.\nBut nothing in the research rules out the possibility at least, adding a degree of credibility to the hypothesis that Vikings ruled the icy Atlantic waves with a sword in one hand and a gem in the other.\nThis research was published in the Proceedings of the Royal Society A.","A compass (or mariner's compass) is a navigational instrument for finding directions on the earth. It consists of a magnetized pointer free to align itself accurately with Earth's magnetic field, which is of great assistance in navigation. The cardinal points are north, south, east and west. A compass can be used in conjunction with a chronometer and a sextant to provide a very accurate navigation capability. This device greatly improved maritime trade by making travel safer and more efficient. An early form of compass was invented in China in 271 C.E. and is one of four great inventions of ancient China. The familiar mariner's compass was invented in Europe around 1300.\nMore technically, a compass is a magnetic device using a needle to indicate the direction of the magnetic north of a planet's magnetosphere. Any instrument with a magnetized bar or needle turning freely upon a pivot and pointing in a northerly and southerly direction can be considered a compass. A compass dial is a small pocket compass with a sundial. A variation compass, a specific instrument with a delicate construction, is used by observing variations of the needle. A gyrocompass or astrocompass can also be used to ascertain true north.\nPrior to the introduction of the compass, directions at sea were determined primarily by the position of celestial bodies. Navigation was supplemented in some places by the use of soundings. Difficulties arose where the sea was too deep for soundings and conditions were continually overcast or foggy. Thus the compass was not of the same utility everywhere. For example, the Arabs could generally rely on clear skies in navigating the Persian Gulf and the Indian Ocean (as well as the predictable nature of the monsoons). This may explain in part their relatively late adoption of the compass. Mariners in the relatively shallow Baltic made extensive use of soundings.\nDue to the place of its first appearance, most scholars credit at present the invention of the compass to China. Since there has been frequently confusion as to when a compass was introduced for the first time, it may be appropriate to list the important events leading up to its invention in chronological order:\nThere is much debate on what happened to the compass after its first appearance with the Chinese. Different theories include:\nThe latter two are supported by evidence of the earlier mentioning of the compass in European works rather than Arabic. The first European mention of a magnetized needle and its use among sailors occurs in Alexander Neckam's De naturis rerum (On the Natures of Things), probably written in Paris in 1190. Other evidence for this includes the Arabic word for \"Compass\" (al-konbas), possibly being a derivation of the old Italian word for compass.\nIn the Arab world, the earliest reference comes in The Book of the Merchants' Treasure, written by one Baylak al-Kibjaki in Cairo about 1282. Since the author describes having witnessed the use of a compass on a ship trip some forty years earlier, some scholars are inclined to antedate its first appearance accordingly. There is also a slightly earlier non-Mediterranean Muslim reference to an iron fish-like compass in a Persian talebook from 1232.\nThere have been various arguments put forward whether the European compass was an independent invention or not:\nArguments that support independent invention:\nArguments against independent invention:\nIn the Mediterranean the practice from ancient times had been to curtail sea travel between October and April, due in part to the lack of dependable clear skies during the Mediterranean winter (and much of the sea is too deep for soundings). With improvements in dead reckoning methods, and the development of better charts, this changed during the second half of the thirteenth century. By around 1290 the sailing season could start in late January or February, and end in December. The additional few months were of considerable economic importance; it enabled Venetian convoys, for instance, to make two round trips a year to the eastern Mediterranean, instead of one.\nAround the time Europeans learned of the compass, traffic between the Mediterranean and northern Europe increased, and one factor may be that the compass made traversal of the Bay of Biscay safer and easier.\nIn 1936 Tuomas Vohlonen of Finland invented and patented the first successful portable liquid-filled compass designed for individual use.\nA magnetic rod is required when constructing a compass. This can be created by aligning an iron or steel rod with Earth's magnetic field and then tempering or striking it. However, this method produces only a weak magnet so other methods are preferred. This magnetised rod (or magnetic needle) is then placed on a low friction surface to allow it to freely pivot to align itself with the magnetic field. It is then labeled so the user can distinguish the north-pointing from the south-pointing end; in modern convention the north end is typically marked in some way, often by being painted red.\nFlavio Gioja (fl. 1302), an Italian marine pilot, is sometimes credited with perfecting the sailor's compass by suspending its needle over a fleur-de-lis design, which pointed north. He also enclosed the needle in a little box with a glass cover.\nModern hand-held navigational compasses use a magnetized needle or dial inside a fluid-filled (oil, kerosene, or alcohol is common) capsule; the fluid causes the needle to stop quickly rather than oscillate back and forth around magnetic north. Most modern recreational and military compasses integrate a protractor with the compass, using a separate magnetized needle. In this design the rotating capsule containing the magnetized needle is fitted with orienting lines and an outlined orienting arrow, then mounted in a transparent baseplate containing a direction-of-travel (DOT) indicator for use in taking bearings directly from a map. Other features found on some modern handheld compasses are map and romer scales for measuring distances and plotting positions on maps, luminous markings or bezels for use at night or poor light, various sighting mechanisms (mirror, prism, etc.) for taking bearings of distant objects with greater precision, 'global' needles for use in differing hemispheres, adjustable declination for obtaining instant true bearings without resort to arithmetic, and devices such as inclinometers for measuring gradients.\nThe military forces of a few nations, notably the United States Army, continue to utilize older lensatic card compass designs with magnetized compass dials instead of needles. A lensatic card compass permits reading the bearing off of the compass card with only a slight downward glance from the sights (see photo), but requires a separate protractor for use with a map. The official U.S. military lensatic compass does not use fluid to dampen needle swing, but rather electromagnetic induction. A 'deep-well' design is used to allow the compass to be used globally with little or no effect in accuracy caused by a tilting compass dial. As induction forces provide less damping than fluid-filled designs, a needle lock is fitted to the compass to reduce wear, operated by the folding action of the rear sight/lens holder. The use of air-filled induction compasses has declined over the years, as they may become inoperative or inaccurate in freezing temperatures or humid environments.\nOther specialty compasses include the optical or prismatic hand-bearing compass, often used by surveyors, cave explorers, or mariners. This compass uses an oil-filled capsule and magnetized compass dial with an integral optical or prismatic sight, often fitted with built-in photoluminescent or battery-powered illumination. Using the optical or prism sight, such compasses can be read with extreme accuracy when taking bearings to an object, often to fractions of a degree. Most of these compasses are designed for heavy-duty use, with solid metal housings, and many are fitted for tripod mounting for additional accuracy.\nMariner's compasses can have two or more magnetic needles permanently attached to a compass card. These move freely on a pivot. A lubber line, which can be a marking on the compass bowl or a small fixed needle indicates the ship's heading on the compass card.\nTraditionally the card is divided into thirty-two points (known as rhumbs), although modern compasses are marked in degrees rather than cardinal points. The glass-covered box (or bowl) contains a suspended gimbal within a binnacle. This preserves the horizontal position.\nLarge ships typically rely on a gyrocompass, using the more reliable magnetic compass for back-up. Increasingly electronic fluxgate compasses are used on smaller vessels.\nSome modern military compases, like the [SandY-183 http://www.orau.org/PTP/collection/radioluminescent/armycompass.htm](the one pictured) contains the radioactive material Tritium (3H) and a combination of Phosphorous. The SandY-183 contained 120mCi (millicuries) of tritium. The name SandY-183 is derived from the name of the company, Stocker and Yale (SandY).\nSmall compasses found in clocks, cell phones (e.g. the Nokia 5140i) and other electronic gear are Solid-state electronics usually built out of two or three magnetic field sensors that provide data for a microprocessor. Using trigonometry the correct heading relative to the compass is calculated.\nOften, the device is a discrete component which outputs either a digital or analog signal proportional to its orientation. This signal is interpreted by a controller or microprocessor and used either internally, or sent to a display unit. An example implementation, including parts list and circuit schematics, shows one design of such electronics. The sensor uses precision magnetics and highly calibrated internal electronics to measure the response of the device to the Earth's magnetic field. The electrical signal is then processed or digitized.\nA bearing compass is a magnetic compass mounted in such a way that it allows the taking of bearings of objects by aligning them with the lubber line of the bearing compass.\nLike any magnetic device, compasses are affected by nearby ferrous materials as well as by strong local electromagnetic forces. Compasses used for wilderness land navigation should never be used in close proximity to ferrous metal objects or electromagnetic fields (batteries, car bonnets, engines, steel pitons, wristwatches, and so forth.)\nCompasses used in or near trucks, cars or other mechanized vehicles are particularly difficult to use accurately, even when corrected for deviation by the use of built-in magnets or other devices. Large amounts of ferrous metal combined with the on-and-off electrical fields caused by the vehicle's ignition and charging systems generally result in significant compass errors.\nAt sea, a ship's compass must also be corrected for errors, called compass deviation, caused by iron and steel in its structure and equipment. The ship is swung, that is rotated about a fixed point while its heading is noted by alignment with fixed points on the shore. A compass deviation card is prepared so that the navigator can convert between compass and magnetic headings. The compass can be corrected in three ways. First the lubber line can be adjusted so that it is aligned with the direction in which the ship travels, then the effects of permanent magnets can be corrected for by small magnets fitted within the case of the compass. The effect of ferromagnetic materials in the compass's environment can be corrected by two iron balls mounted on either side of the compass binacle. The coefficient <math>a_0</math> representing the error in the lubber line, while <math>a_1,b_1</math> the ferromagnetic effects and <math>a_2,b_2</math> the non-ferromagnetic component.\nFluxgate compasses can be calibrated automatically, and can also be programmed with the correct local compass variation so as to indicate the true heading.\nThe simplest way of using a compass is to know that the arrow always points in the same direction, magnetic North, which is roughly similar to true north. Except in areas of extreme magnetic declination variance (20 degrees or more), this is enough to protect from walking in a substantially different or even opposite direction than expected over short distances, provided the terrain is fairly flat and visibility is not impaired. In fact, by carefully recording distances (time or paces) and magnetic bearings traveled, one can plot a course and a return to one's starting point using the compass alone.\nHowever, compass navigation used in conjunction with a map (terrain association) requires a different compass method. To take a map bearing or true bearing (a bearing taken in reference to true, not magnetic north) to a destination with a protractor compass, the edge of the compass is placed on the map so that it connects the current location with the desired destination (some sources recommend physically drawing a line). The orienting lines in the base of the compass dial are then rotated to align with actual or true north by aligning them with a marked line of longitude (or the vertical margin of the map), ignoring the compass needle entirely. The resulting true bearing or map bearing may then be read at the degree indicator or direction-of-travel (DOT) line, which may be followed as an azimuth (course) to the destination. If a magnetic north bearing or compass bearing is desired, the compass must be adjusted by the amount of magnetic declination before using the bearing so that both map and compass are in agreement. In the given example, the large mountain in the second photo was selected as the target destination on the map.\nThe modern hand-held protractor compass always has an additional direction-of-travel (DOT) arrow or indicator inscribed on the baseplate. To check one's progress along a course or azimuth, or to ensure that the object in view is indeed the destination, a new compass reading may be taken to the target if visible (here, the large mountain). After pointing the DOT arrow on the baseplate at the target, the compass is oriented so that the needle is superimposed over the orienting arrow in the capsule. The resulting bearing indicated is the magnetic bearing to the target. Again, if one is using 'true' or map bearings, and the compass does not have preset, pre-adjusted declination, one must additionally add or subtract magnetic declination to convert the magnetic bearing into a true bearing. The exact value of the magnetic declination is place-dependent and varies over time, though declination is frequently given on the map itself or obtainable on-line from various sites. If not, any local walker club should know it. If the hiker has been following the correct path, the compass' corrected (true) indicated bearing should closely correspond to the true bearing previously obtained from the map.\nBecause the Earth's magnetic field varies at different latitudes, compasses are often balanced during manufacture. Most manufacturers balance their compass needles for one of five zones, ranging from zone 1, covering most of the Northern Hemisphere, to zone 5 covering Australia and the southern oceans. This balancing prevents excessive dipping of one end of the needle which can cause the compass card to stick and give false readings. Suunto has recently introduced two-zone compasses that can be used in one entire hemisphere, and to a limited extent in another without significant loss of accuracy.\nOriginally, many compasses were marked only as to the direction of magnetic north, or to the four cardinal points (north, south, east, west). Later, mariners divided the compass card into 32 equally spaced points divided from the cardinal points.\nThe 360-degree system later took hold, which is still in use today for civilian navigators. The degree dial spaces the compass markings with 360 equidistant points. Other nations adopted the 'grad' system, which spaces the dial into 400 grads or points.\nMost military defense forces have adopted the 'mil' system, in which the compass dial is spaced into 6400 units (some nations use 6000) or 'mils' for additional precision when measuring angles, laying artillery, and so forth.\nSome different compass systems:\nAll links retrieved June 11, 2013.\nNew World Encyclopedia writers and editors rewrote and completed the Wikipedia article in accordance with New World Encyclopedia standards. This article abides by terms of the Creative Commons CC-by-sa 3.0 License (CC-by-sa), which may be used and disseminated with proper attribution. Credit is due under the terms of this license that can reference both the New World Encyclopedia contributors and the selfless volunteer contributors of the Wikimedia Foundation. To cite this article click here for a list of acceptable citing formats.The history of earlier contributions by wikipedians is accessible to researchers here:\nNote: Some restrictions may apply to use of individual images which are separately licensed."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:7e43b7f3-790f-4e02-86f9-15254200b307>","<urn:uuid:1b8c6216-856b-465d-bc9b-cd1ad598cd9d>"],"error":null}
{"question":"What common thread connects Gandhi's first acts of civil disobedience in 1893 with the emerging understanding of scientific theories and their acceptance in society during that time period?","answer":"In 1893, Gandhi committed his first act of civil disobedience in India and arrived in South Africa where he would lead non-violent peaceful protests. During this same period, science was establishing itself as a process of seeking truth through evidence and data rather than through dogma. Just as Gandhi pursued social change through peaceful resistance, science was described as a non-aggressive force that 'does not attack - it explains.' Both represented systematic approaches to achieving change - Gandhi through non-violent civil disobedience and science through the methodical gathering of evidence. The scientific process was described as self-correcting and non-dogmatic, with no sacred works that cannot be challenged, similar to how Gandhi's approach focused on peaceful demonstration of truth rather than violent opposition.","context":["By Harry Keller\nEditor, Science Education\nFor nearly 150 years since Darwin first published The Origin of Species in 1859, the controversy has continued. Despite mountains of evidence collected from many branches of science, some still fight vigorously against teaching evolution in our school science classes.\nI maintain that those fighting against this teaching are harming our society but may just be helping out science education. I refer here to what’s happening in the United States, which seems to be the country most affected by this controversy as well as being the one in which I live.\nAnswering why the anti-evolution forces are harming our society and how they might end up helping improve science education requires some digging. Society depends on technology to support our standard of living and on the creation of new technologies for export to fund our ability to buy technology. More and more of these technologies are biological in nature. Research into biology and medicine moves forward best when we understand the underlying principles of life. A framework upon which to set ideas and to imagine new ideas helps immensely in both research and development of new technologies and new products.\nIf you study well the advances in biology and medicine in recent decades, you will see that the concepts inherent in evolution have played an important role. If our students leave school without this important framework, then they are ill-prepared to participate in the advancement of science. If, even worse, they leave school opposing science and its precepts, then they may work to retard scientific advances. Evolution, as a concept and framework, has become the underpinning, tying together previously disparate aspects in all of our life sciences.\nRight now, the world is on the verge of eradicating polio. One of three strains has already been destroyed, and only a few countries still harbor reservoirs of the remaining two and possibly only one. While this effort has been largely one of vaccinating everyone, development of new vaccines rests on medical research that depends on understanding how life works. Evolution is a crucial component. The speed with which we find cures for cancer, Alzheimer’s disease, and Parkinson’s disease are likely to depend on scientists who use evolutionary theory in their work.\nOur society suffers directly from not having more scientists who understand and use evolution in their work. It also suffers indirectly from a populace in which many have been educated to be suspicious of science. Science is just a way of thinking, of going about the business of finding out. No one should be suspicious of science. You can suspect individual scientists as they’re just as human as the rest of us, but do not lump all who seek enlightenment in our natural world through time-tested processes together. Know that most scientists seek knowledge, not power.\nBefore discussing the impact on science education, I’ll detour through some thoughts about the evolution controversy itself. Too many people characterize it as science against religion. They have it exactly backward. Science does not fight religion, although some scientists have seen fit to do so. They do not represent science. Actually, no one does.\nScience is a process, a way of thinking that has been proven to work well when we seek to extract nature’s secrets. Finding out about how the universe works is hard work. We are often fooled by our desire to see patterns even when they don’t fit all the facts. Changing attitudes and long-held beliefs can take a long time. Few people realize today that in 1980 half of geologists did not accept the theory of plate tectonics. Yet, this theory is routinely taught in today’s classrooms without controversy.\nWhat actually happens in the evolution-religion controversy is that religion attacks science, never the reverse. Science does not attack — it explains. Some scientist makes some discovery and publishes it. Some person somewhere reads about it and decides that the discovery is a heresy. It’s not as though God speaks to us and says that. It’s a fallible human being who makes the decision. Generally, it involves the interpretation of some sacred work. We wouldn’t have so many denominations of Christianity (most of the anti-evolutionists in the U.S. are Christians) if the sacred works were unambiguous. Indeed, we see many different translations of the Bible, which also indicates a certain ambiguous nature to this work.\nA small minority of Christians have decided that teaching evolution undermines their religion. They have become very vocal and very influential. Many say they agree just to avoid the wrath of those few who are so incensed. Many actually are swayed by the fervor of those who have taken it upon themselves to interpret their Bible.\nBut science doesn’t care. The words of Sergeant Friday, “Just the facts, ma’am,” are all that science cares about. Like good detectives, scientists follow the evidence and are not supposed to allow their prejudices to interfere. They’re human, too, and do get confused on occasion by what they expect. However, the system of science is self-correcting. When scientists publish, others check their publications. They can review the evidence. They can even collect their own data for comparison. Science is not dogmatic, cannot afford to be dogmatic. Science has no sacred works that cannot be challenged.\nSome say that evolution is “just a theory.” Yes, but it’s a scientific theory. What they miss is that, in science, a theory is the pinnacle, the top level, to which an idea can be promoted. Once a scientific idea becomes a theory, it has no higher level to achieve. Over time, such theories will be buttressed by more and more data, evidence that the denotation of theory is appropriate. Sometimes, as with Newton’s theory of universal gravitation and the precession of Mercury’s orbit, data do not match up. The error, in this case, was very small and required many repeated measurements with improved precision before scientists were certain something was awry. They sought many explanations within Newton’s law without success. Only Einstein, with his general relativity theory, was finally able to explain the discrepancy. However, Newton’s theory is still used widely for almost everything.\nSimply, we base theories on data that necessarily originate in some domain. Scientists collect more data from within that domain and also seek data from outside of the domain to see whether the theory holds there too. If so, all’s good. If not, then, as with Mercury’s precession, some new theory must be found to explain the new data. The old theory still holds for data in the old domain. However, the new theory may profoundly affect our view of the universe.\nIf theories are at the top, what’s a scientific law? It’s a horse of a different color, a totally different concept. A law is not an explanation but rather an inductive result that tells us how to predict. The universal gravitation law tells us that the attraction between two masses is proportional to each of the masses and inversely proportional to the square of the distance between their centers. The universal gravitation theory says that all masses, whether on the Earth or in the heavens, obey the same law. We cannot be sure that this theory is correct for extremely distant objects, billions of light-years away, but it seems to be. Some data suggest that it may not be so, but without more data and more precision, we cannot be certain one way or the other.\nPlate tectonics attracted much opposition. So did the meteor theory of dinosaur extinction. Yet, these now have become accepted, although much science is being done to ferret out the details.\nAll of these ideas lead naturally to the nature of science. Some statements above hint at it. Science uses data from the real world to induce ideas. These ideas then are used to deduce conclusions about what will happen in a given situation. The process involves much cross checking among scientists because they are taught to trust no one when it comes to scientific data, hypotheses (what an idea becomes before becoming a theory), and theories. Use your own brain and, if possible, your own data before accepting any idea.\nAll scientists know, as a part of their very being, that measurement is imprecise. No matter how well you make a measurement, you can always do better. You never reach absolute precision. You also never reach absolute certainty. This is an enormous strength of science. However, as with Jiujitsu, people seek to use it as a weakness. You’ll hear some say that scientists don’t know everything, and scientists are the first to admit it because they’ve learned over long experience that it’s true. This, however, does not mean that they know nothing. Others say that scientific measurements are subject to error. Of course, they are. Scientists are trained to estimate and report the errors inherent in their measurements. These are included in their analyses before making conclusions. And so it goes.\nAll of these ideas lead to my initial statement regarding the evolution controversy possibly helping science education. Today, many recognize that our science classes are doing an inadequate job of teaching the nature of science. It’s not really possible to discuss the theory of evolution in the face of religious objectors without understanding the nature of science. Students in the classroom must be acquainted with the nature of science before discussing the major theories — including evolution.\nAfter all, I’m sure that an excellent case could be made for a religious objection to plate tectonics. Some would maintain that it’s simply contrary to the Bible. Others would sidestep the issue by saying that continents may move, but God moves them or decides how they’ll move.\nEvolution controversy could help science education by convincing teachers, and those who teach them, that learning about the nature of science is crucial to learning science. Bringing the nature of science into every discussion of scientific theory and every laboratory investigation will improve the quality of science education considerably. You may not find questions on state tests about it, but understanding the nature of science comprises an important part of scientific thinking skills that will become, for those who have them, a valuable thinking tool throughout life.\nFor more on this topic, look up Carl Sagan’s “baloney detection kit” on your favorite search engine.\nFiled under: Uncategorized","From Wikipedia, the free encyclopedia\nThis article is about the year 1893.\n|Centuries:||18th century – 19th century – 20th century|\n|Decades:||1860s 1870s 1880s – 1890s – 1900s 1910s 1920s|\n|Years:||1890 1891 1892 – 1893 – 1894 1895 1896|\n|1893 in topic:|\n|Archaeology – Architecture – Art – Literature – Music|\n|Australia – Brazil - Canada – France – Germany – Mexico – Philippines – South Africa – US – UK|\n|Rail Transport – Science – Sports|\n|Lists of leaders|\n|Colonial Governors – State leaders|\n|Birth and death categories|\n|Births – Deaths|\n|Establishments and disestablishments categories|\n|Establishments – Disestablishments|\n|Ab urbe condita||2646|\n|British Regnal year||56 Vict. 1 – 57 Vict. 1|\n|Chinese calendar||壬辰年 (Water Dragon)\n4589 or 4529\n— to —\n癸巳年 (Water Snake)\n4590 or 4530\n|- Vikram Samvat||1949–1950|\n|- Shaka Samvat||1815–1816|\n|- Kali Yuga||4994–4995|\n|Japanese calendar||Meiji 26\n|Julian calendar||Gregorian minus 12 days|\n|Minguo calendar||19 before ROC\n|Thai solar calendar||2436|\n|Wikimedia Commons has media related to 1893.|\n- January 2 – Webb C. Ball introduces railroad chronometers, which become the general railroad timepiece standards in North America.\n- January 13 – The Independent Labour Party of the UK has its first meeting.\n- January 15 – The Telefon Hírmondó service started on 15 February 1893, with around 60 subscribers at Budapest.\n- January 17 – The U.S. Marines intervene in Hawaii, resulting in overthrow of the government of Queen Liliuokalani of Hawaii.\n- January 21 – The Cherry Sisters first perform in Marion, Iowa.\n- February 1 – Thomas A. Edison finishes construction of the first motion picture studio in West Orange, New Jersey.\n- February 19 – The SS Naronic is believed to have sunk due to a storm.\n- February 23 – Rudolf Diesel receives a patent for the diesel engine.\n- February 24 – American University is established by an Act of Congress in Washington, D.C.\n- March 4 – Benjamin Harrison is succeeded by Grover Cleveland, as President of the United States.\n- March 10 – Côte d'Ivoire becomes a French colony.\n- March 20 – In Belgium, Adam Worth is sentenced to 7 years for robbery (he is released in 1897).\n- April 1 – The rank of Chief Petty Officer is established in the United States Navy.\n- April 6 – The iconic Salt Lake City Temple of The Church of Jesus Christ of Latter-day Saints is dedicated after 40 years of construction.\n- April 8 – The first recorded college basketball game occurs in Beaver Falls, Pennsylvania between the Geneva College Covenanters and the New Brighton YMCA.\n- April 17 – Riots of Mons during the Belgian general strike of 1893, The day after, Belgian parliament approved Universal suffrage.\n- April 17 – Alpha Xi Delta founded\n- May – The Free Presbyterian Church of Scotland is formed.\n- May 1 – The 1893 World's Fair, also known as the World's Columbian Exposition, opens to the public in Chicago, USA. The first United States commemorative postage stamps are issued for the Exposition.\n- May 5 – Panic of 1893: A crash on the New York Stock Exchange starts a depression.\n- May 9 – Edison's 1½ inch system of Kinetoscope is first demonstrated in public at the Brooklyn Institute.\n- May 10 – The United States Supreme Court legally declares the tomato to be a vegetable.\n- May 23 – Gandhi arrives in South Africa where he will live until 1914 -- he led non-violent peaceful protests on behalf of Indiah immigrants in Transvaal, and generally had a deeper experience of non-violent activities during these years.\n- June 6 – Prince George, Duke of York (later George V) marries Mary of Teck.\n- June 7 – Gandhi commits his first act of civil disobedience in India.\n- June 17 – Gold is found in Kalgoorlie, Western Australia.\n- June 20 – The Wengernalpbahn railway in Wengen, Switzerland (Canton of Bern) is opened.\n- June 20 – Lizzie Borden acquitted of murdering her parents.\n- June 22 – The flagship Victoria of the British Mediterranean Fleet collides with Camperdown and sinks in 10 minutes; Vice-admiral Sir George Tryon goes down with his ship.\n- July 1 – U.S. President Grover Cleveland is operated on in secret.\n- July 6 – The small town of Pomeroy, Iowa, is nearly destroyed by a tornado; 71 people are killed and 200 injured.\n- July 11\n- July 12\n- July 25 – Completion of the Corinth Canal in Greece.\n- August 15 – Ibadan area becomes a British Protectorate after a treaty signed by Fijabi, the Baale of Ibadan with the British acting Governor of Lagos, George C. Denton.\n- August 27 – The Sea Islands Hurricane hits Savannah, Charleston, and the Sea Islands, killing 1,000–2,000.\n- September 7\n- September 11\n- September 19\n- Swami Vivekananda delivers an inspiring speech on his paper at the World Parliament of Religions in Chicago.\n- New Zealand becomes the first country in the world to grant women the right to vote.\n- The Russian ironclad Rusalka disappears in a storm en route from Tallinn to Helsinki; her hulk is eventually discovered in July 2003, off Helsinki.\n- September 21 – Brothers Charles and Frank Duryea drive the first gasoline-powered motorcar in America on public roads in Springfield, Massachusetts.\n- September 23 – The Bahá'í Faith is first publicly mentioned in the United States at the World Parliament of Religions in Chicago.\n- September 27 – The World Parliament of Religions holds its closing meeting in Chicago.\n- September 28 – The Portuguese sports club Futebol Clube do Porto is founded.\n- October 10 – The first car number plates appear in Paris, France.\n- October 23 – The Internal Macedonian Revolutionary Organization (IMRO) is founded by Bulgarians in the town of Thessaloniki. Its aim is to liberate the region of Macedonia from the Ottoman Turks.\n- October 28 (October 16 O.S.) – In Saint Petersburg (Russia), Pyotr Ilyich Tchaikovsky conducts the first performance of his Symphony No. 6 in B minor, Pathétique nine days before his death.\n- October 30 – The 1893 World's Fair, also known as the World's Columbian Exposition, closes.\n- November 7 – Colorado women are granted the right to vote.\n- November 12 – The Durand Line is established as the boundary between British India and Afghanistan by a memorandum of understanding signed by Sir Mortimer Durand, Foreign Secretary of British India, and Abdur Rahman Khan, Amir of Afghanistan.\n- November 15 – FC Basel football club is founded in Switzerland.\n- December 4 – First Matabele War: The Shangani Patrol of British South Africa Company soldiers is ambushed and annihilated by more than 3,000 Matabele warriors.\n- December 5 – Plural voting is abolished in New South Wales.\n- December 16 – Antonín Dvořák's Symphony No. 9 \"From the New World\" receives its premiere at Carnegie Hall, New York City.\n- Carl Anton Larsen becomes the first man to ski in Antarctica.\n- Arthur Conan Doyle surprises the reading public by revealing in the story The Adventure of the Final Problem, published in this month's Strand Magazine, that his character Sherlock Holmes had apparently died at the Reichenbach Falls on May 4, 1891.\n- The American Council on Alcohol Problems is established, along with the Anti-Saloon League and the Committee of Fifty for the Study of the Liquor Problem.\n- Physicist Wilhelm Wien formulates Wien's displacement law.\n- France conquers Laos.\n- A general strike occurs in Belgium.\n- American Temperance University is opened.\n- Millbank Prison in London is demolished.\n- In the U.S., the National Sculpture Society (NSS) is founded.\n- The Football Club Dulwich Hamlet is founded.\n- The Athletic Club Královské Vinohrady, later Sparta Prague, is founded.\n- T.M.I.: The Episcopal School of Texas is founded.\n- Colored High becomes the first African-American high school in Houston, TX; its name is later changed to Booker T. Washington High School.\n- The Ardabil Carpet is brought to London.\n- Evergreen Park, Illinois is founded.\n- Sudbury, Ontario, Canada is incorporated as a town.\n- St Hilda's College, Oxford is founded.\n- William Ewart Gladstone introduces a bill to give Ireland self-government but it fails to pass.\n- Small anti-Semitic parties secure 2.9% of votes in Germany.\n- Before 1893 – 8,000 Chinese arrive in Cuba.\n- 71.2% of the working population of São Paulo is foreign-born.\n- The National Education Association releases final report from the Committee of Ten\n- January 4 – Yone Minagawa, Japanese supercentenarian (d. 2007)\n- January 5 – Paramahansa Yogananda, Indian guru (d. 1952)\n- January 10 – Vicente Huidobro, Chilean poet (d. 1948)\n- January 12\n- January 15 – Ivor Novello, Welsh actor and musician (d. 1951)\n- January 22\n- January 27 – Soong Ching-ling , one of the Soong sisters, wife of Chinese president Sun Yat-sen (d. 1981)\n- February 3 – Gaston Julia, French mathematician (d. 1978)\n- February 10 – Jimmy Durante, American actor, singer, and comedian (d. 1980)\n- February 12 – Omar Bradley, American general (d. 1981)\n- February 13\n- February 16\n- February 19 – Sir Cedric Hardwicke, English actor (d. 1964)\n- February 21 – Andrés Segovia, Spanish guitarist (d. 1987)\n- February 24 – Tokushichi Mishima, Japanese inventor, engineer (d. 1975)\n- February 28 – Ivan Vasilyov, Bulgarian architect (d. 1979)\n- March 1 – Mercedes de Acosta, American poet, playwright, costume designer, and socialite (d. 1968)\n- March 3\n- March 11 – Wanda Gag, American children's author and artist (d. 1946)\n- March 14 – Arthur C. Davis, American admiral (d. 1965)\n- March 18 – Wilfred Owen, English soldier and poet (d. 1918)\n- March 19 – Jose Maria Velasco Ibarra, former President of Ecuador (d. 1979)\n- March 22 – Kleber Claux, French-born Australian anarchist and nudist (d. 1971)\n- March 26 – Palmiro Togliatti, Italian communist leader (d. 1964)\n- March 31 – Herbert Meinhard Mühlpfordt, German historian (d. 1982)\n- April 1 – Cicely Courtneidge, British actress (d. 1980)\n- April 3 – Leslie Howard, English actor (d. 1943)\n- April 6– Alfred Gerstenberg, German Luftwaffe general (d. 1959)\n- April 9\n- April 12 – Robert Harron, American actor (d. 1920)\n- April 15 – Maximilian Ritter von Pohl, German army and air-force officer (d. 1951)\n- April 18 – Georges Boulanger, Romanian violinist (d. 1958)\n- April 20\n- April 21 – Matsuji Ijuin, Japanese admiral (d. 1944)\n- April 23 – Allen Dulles, American Central Intelligence Agency director (d. 1969)\n- April 29 – Harold C. Urey, American chemist, Nobel Prize laureate (d. 1981)\n- May 3 – Konstantine Gamsakhurdia, Georgian writer and public benefactor (d. 1975)\n- May 8\n- May 16 – Clement Martyn Doke, South African linguist (d. 1980)\n- May 26 – Norma Talmadge, American actress (d. 1957)\n- May 23 – Ulysses S. Grant IV, American geologist and paleontologist (d. 1977)\n- June 7 – Gillis Grafstrom, Swedish figure skater (d. 1938)\n- June 14 – Siggie Nordstrom, American model, actress, entertainer, socialite and singer (d. 1980)\n- June 24\n- June 26 – Big Bill Broonzy, American blues singer and composer (d. 1958)\n- June 29 – Aarre Merikanto, Finnish composer (d. 1958)\n- June 30 – Walter Ulbricht, German Communist politician (d. 1973)\n- July 1 – Mario de Bernardi, Italian aviator (d. 1959)\n- July 3 – Mississippi John Hurt, American musician (d. 1966)\n- July 4 – Norman Washington Manley, Jamaican statesman (d. 1969)\n- July 9 – George Geary, English cricketer (d. 1981)\n- July 12 – John Gould Moyer, American naval officer, 31st Governor of American Samoa (d. 1976)\n- July 20 – George Llewelyn Davies, inspiration for Peter Pan (d. 1915)\n- July 25 – Dorothy Dickson, American-born actress and socialite (d. 1995)\n- July 28 – Rued Langgaard, Danish composer and organist (d. 1952)\n- July 30 – Fatima Jinnah, Pakistani Mother of the Nation (d. 1967)\n- August 4 – Fritz Gause, German historian (d. 1973)\n- August 6 – Wright Patman, American politician (d. 1976)\n- August 14\n- August 15 – Leslie Comrie, New Zealand astronomer and computing pioneer (d. 1950)\n- August 17 – Mae West, American actress, playwright, screenwriter, and sex symbol (d. 1980)\n- August 18 – Frank Linke-Crawford, Austro-Hungarian fighter pilot (d. 1918)\n- August 22\n- August 24 – Haim Ernst Wertheimer German-born Israeli biochemist, recipient of the Israel Prize (d. 1978)\n- August 25 – Henry Trendley Dean, American dental researcher (d. 1962)\n- August 30 – Huey Long, Louisiana governor and senator (d. 1935)\n- September 6 – Claire Lee Chennault, American aviator and general, leader of the Flying Tigers (d. 1958)\n- September 10\n- September 12 – Frederick William Franz, President of Jehovah's Witnesses (d. 1992)\n- September 13 – Larry Shields, American musician (d. 1953)\n- September 16 – Albert Szent-Györgyi, Hungarian physiologist, Nobel Prize laureate (d. 1986)\n- September 18 –\n- September 30 – Lansdale Sasscer, U.S. Congressman (d. 1964)\n- October 1 – Marianne Brandt, German industrial designer (d. 1983)\n- October 9 – Mário de Andrade, Brazilian writer and photographer (d. 1945)\n- October 14 – Lillian Gish, American actress (d. 1993)\n- October 15 – King Carol II of Romania (d. 1953)\n- October 16 – Harry Donenfeld, American publisher (d. 1965)\n- October 18 – Georges Ohsawa, Japanese founder of Macrobiotics (d. 1966)\n- October 23 – Gummo Marx, American comedian and actor (d. 1977)\n- October 26 – Oliver P. Smith, American general (d. 1977)\n- November 3 – Edward Adelbert Doisy, American biochemist, recipient of the Nobel Prize in Physiology or Medicine (d. 1986)\n- November 5 – Raymond Loewy, French-born American industrial designer (d. 1986)\n- November 8\n- November 10 – John P. Marquand, American novelist (d. 1960)\n- November 22 – Raymond Collishaw, Canadian World War I fighter ace (d. 1976)\n- November 24 – Fern Andra, American actress (d. 1974)\n- December 1 – Henry J. Cadbury, American biblical scholar and Quaker (d. 1974)\n- December 3 – Walter Stuart Diehl, American naval officer and aeronautical engineer (d. 1976)\n- December 7 – Fay Bainter, American actress (d. 1968)\n- December 8 – Pierre Etchebaster, French real tennis player (d. 1980)\n- December 23 – Ann Pennington, American actress and dancer (d. 1971)\n- December 24 – Ruth Chatterton, American actress (d. 1961)\n- December 26 – Mao Zedong, Chinese leader (d. 1976)\n- December 29 – Berthold Bartosch, Bohemian animator (d. 1968)\n- January 2 – John Obadiah Westwood, British entomologist (b. 1805)\n- January 7 – Jožef Stefan, Slovenian physicist, mathematician, and poet (b. 1835)\n- January 11 – Benjamin Franklin Butler, American lawyer, politician, and general (b. 1818)\n- January 17 – Rutherford B. Hayes, 19th President of the United States (b. 1822)\n- January 23 – Lucius Quintus Cincinnatus Lamar, U.S. Supreme Court justice (b. 1825)\n- January 27 – James G. Blaine, Speaker of the United States House of Representatives, US Senator, and US Secretary of State\n- February 1 – George Henry Sanderson, Mayor of San Francisco (b. 1824)\n- February 18\n- February 20 – P.G.T. Beauregard, American Confederate general (b. 1818)\n- March 16 – William H. Illingworth, American photographer (b. 1844)\n- March 17 – Jules Ferry, French premier (b. 1832)\n- March 18 – Bandō Kakitsu I, Japanese kabuki actor (b. 1847)\n- March 30 – Jane Sym-Mackenzie, second wife of Canada's second prime minister (b. 1825)\n- April 8 – August Czartoryski, Polish prince (b. 1858)\n- April 19 – John Addington Symonds, English poet and literary critic (b. 1840)\n- June 7 – Edwin Booth, American actor (b. 1833)\n- June 14 – Jakob Frohschammer, theologian and philosopher (b. 1821)\n- June 19 – William Starke Rosecrans, California congressman and Register of the U.S. Treasury (b. 1819)\n- June 21 – Amasa Leland Stanford, Governor of California (b. 1824)\n- June 22 – George Tryon, British admiral (b. 1832)\n- June 23 – Sir Theophilus Shepstone, South African statesman (b. 1817)\n- July 2 – Georgiana Drew Barrymore, actress-comedienne (b. 1856)\n- July 6 – Guy de Maupassant, French writer (b. 1850)\n- July 16 – Antonio Ghislanzoni, Italian politician and journalist (b. 1833)\n- August 6 – Jean-Jacques Challet-Venel, member of the Swiss Federal Council (b. 1811)\n- August 7 – Alfredo Catalani, Italian composer (b. 1854)\n- August 20 – Baron Alexander Wassilko von Serecki, Governor of the Duchy of Bucovina and member of the Herrenhaus (b. 1827)\n- October 6 – Ford Madox Brown, English painter (b. 1821)\n- October 8 – John Willis Menard, African-American politician (b. 1838)\n- October 10 – Lip Pike, American baseball player (b. 1845)\n- October 17 – Patrice de Mac-Mahon, Duke of Magenta, French general and politician, first president of the Third Republic (1875-1879) (b. 1808)\n- October 18 – Charles Gounod, French composer (b. 1818)\n- October 22 – Duleep Singh, ruler of Punjab (b. 1838)\n- October 23 – Alexander, Prince of Bulgaria, first prince of Bulgaria (b. 1857)\n- October 30 – Sir John Joseph Caldwell Abbott, Canadian politician (b. 1821)\n- November 6 – Pyotr Ilyich Tchaikovsky, Russian composer (b. 1840)\n- November 22 – James Calder, 5th President of Pennsylvania State University (b. 1826)\n- December 20 – George C. Magoun, American railroad executive (b. 1840)\n- The Year-book of the Imperial Institute of the United Kingdom, the colonies and India: a statistical record of the resources and trade of the colonial and Indian possessions of the British Empire (2nd. ed. 1893) 880pp; online edition"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:6cce8894-5955-4327-9b22-e954049d48bd>","<urn:uuid:ad24828b-c477-4d5e-91fc-d44f198ce6f0>"],"error":null}
{"question":"What are the key differences between using ITIL Framework and Supply Chain Risk Management Maturity Model for assessing organizational maturity?","answer":"The ITIL Framework and Supply Chain Risk Management Maturity Model differ in several key aspects. The ITIL Framework is heavily focused on IT service processes and requires accounting for additional factors like strategy, personnel management, tools, and culture to achieve well-rounded improvements. In contrast, the Supply Chain Risk Management Maturity Model provides specific maturity levels (pre-compliant, compliant, secure, resilient) that focus on security and resilience improvements, with clear progression from basic compliance to strategic risk management. While ITIL can be applied in whole or part for service-oriented IT teams, the Supply Chain model specifically guides organizations in improving their supply chain security and economic viability through defined key process areas.","context":["A service management roadmap is primarily useful for coordinating and implementing service improvements. A scorecard-based service management roadmap is one way to measure and then manage your continuous service improvement (CSI) activities. A scorecard-based approach uses a holistic source of inputs for CSI efforts and creates a very versatile output.\nI recommend using Microsoft Excel, or any other spreadsheet tool, to create your scorecard. The flexibility and availability of support for the functions make this approach ideal for the iterative development of your scorecard. You can also create your roadmap with a purpose-built project management software tool. I recommend a five-step process for building a scorecard-based roadmap:\n- Select or create a scorecard and a scoring method\n- Define your goal (or target) scores and assign weight to the scorecard elements\n- Assess the current performance level\n- Analyze the current performance levels and prioritize the results\n- Build your roadmap by defining and sequencing initiatives to achieve the goal (or target) levels\nThis approach his ideal for service managers and their leaders who want to create a service improvement roadmap to illustrate and guide their improvement efforts.\nSelect or Create, and Modify a Scorecard\nThe best way to select a scorecard for roadmapping is to start by determining the right framework to use. Consider the likelihood that there is an existing, widely accepted framework or model that can serve as a basis for your scorecard. It can be useful to leverage a set of benchmarked data as the basis for your scorecard because you can then track the progress of your continuous improvement initiatives against those same benchmarks. I’ll list some of the recommended frameworks and maturity models for support teams.\nHDI Support Center Standard (HDI SCS). The HDI Support Center Standard is a mature and well-thought-out resource to help identify best practices for your support center. The HDI SCS is best employed as a scorecard for help desks, support centers, or other frontline support teams. Unmodified, it has less relevance for next-level support and engineering teams or development teams. It represents the unique perspective of the support center” in the form of a rubric. That is to say, it has a built-in scoring method. The HDI SCS is extremely well-balanced because it accounts for the enabling factors and results of service excellence, including leadership and personnel management, among others.\nITIL Framework. The Information Technology Infrastructure Library (ITIL) framework describes best practices for the provisioning of IT services. The ITIL framework can be employed, as a whole or in part, to use as a scorecard for any service-oriented information technology teams, including next-level support and engineering teams. Be aware that the ITIL framework is heavily focused on processes. Using it to achieve well-rounded improvements requires your scoring mechanisms to account for other factors such as strategy, personnel management, tools, and culture.\nPeriodic Service Satisfaction Surveys. Many support teams employ transactional customer satisfaction surveys. These are short questionnaires sent to end users that are triggered by a service transaction, usually tracked in an incident or request ticket.\nPeriodic service satisfaction surveys are less commonly employed. They are conducted periodically (e.g., annually) and are sent with context to decision-making stakeholders as well as end users. Service satisfaction surveys measure how well a service organization’s results are aligned with the business needs of those receiving the service.\nInitial results from a first service satisfaction survey become the baseline of your scorecard. The results from follow-on survey are used to track the results of your improvement initiatives.\nTo be useful for roadmapping, a scorecard must have these elements:\nElements (or Factors) to Score. These are the elements of the scorecard that you apply your scores to. They are what you are measuring. In the HDI SCS, these are activities in categories of Enablers and Results. For an ITIL-based scorecard, these are the ITIL processes, or possibly the ITIL process steps. For a periodic survey, these would be the survey questions.\nScoring Method. This is the set of descriptive definitions for different levels of performance related to the elements of the scorecard, with associated numerical value for different levels. This is how you are measuring. This can be a scale, such as 1 to 5, or it can be evaluative (poor, ok, good, great). But you must have numerical values associated with the different levels so that you can use mathematical functions for weighting and prioritizing.\nGoals or Target Levels. This provides a way to set the level of performance you are trying to achieve for each element or factor that you score. Achieving the highest level of maturity for every element on your scorecard may not be affordable or may not be suitable for what the stakeholders want. The difference between your current level of performance and each goal or target level is called a gap. Gaps are one useful way to prioritize improvement plans.For survey-based scorecards, there are alternatives to setting goals or target levels that are directly based on the scoring method. You can measure the percentage of favorable responses or ask respondents to assign a relative importance rating with each survey rating. The difference between the percentage of favorable responses and a target level, or the difference between a survey rating and its associated relative importance, are also gaps.\nWeighting Mechanism. In addition to being able to score each element, a good scorecard provides a way to assign more or less importance to each element or to categories of elements.\nInitiatives for Service Improvements Associated with Specific Elements. Each element or factor, with its performance level, gap, and weighting, provides an opportunity to link service improvement initiatives to the scorecard. It is these initiatives that form the actions contained on your roadmap.\nWhen your completed scorecard is combined with comparative data elements such as organization goals, gap calculations, and weight factors, it becomes a tool for both assessing and prioritizing areas that need improvement. You build your roadmap by linking initiatives for service improvements to the gaps and priorities. The first example below shows a single scorecard element (from the HDI SCS). The elements (or factors) to score have a definition of what the element is, with descriptions for each maturity level and a space for notes or links to evidence that supports the rating.\nThe next example shows an excerpt from a scorecard summary section that is used for setting custom weightings for the HDI SCS Leadership category.\nThe HDI Support Center Standard has a built-in scoring method that includes detailed descriptions of different levels of maturity for each of its activities. The ITIL body of knowledge includes a Process Maturity Framework, or you can adopt the very similar Capability Maturity Model Integration. The CMMI maturity framework is well-rounded and can also be applied to strategies and models that come from outside of your support organization.\nScoring methods for survey-based scorecards rely on combining the evaluative results from the survey with either target scores or assessments of relative importance. Combining target scores or relative importance with survey results facilitates a gap analysis technique that helps prioritize improvement initiatives.\nCarefully choose your scoring method because as I like to say, “How you measure it is how you manage it.” If possible, pick a well-regarded scoring method that has already been accepted within your organization or one that is likely to be readily accepted by others.\nHow you measure it is how you manage it.\nDefine Your Goals and Assign Weights\nOnce you have chosen a scoring method, it is simple to record your goals for each scorecard element. As noted above, this provides a way to set the level of performance you are trying to achieve for each element or factor that you score.\nWeighting the scorecard creates a way to make different parts of the scorecard count more than others. Adjusting the weighting of your scorecard periodically is a good way to keep it aligned with changing priorities over time, as opposed to choosing a different scorecard when priorities change.\nAssess the Current Performance Level\nIf you are using a periodic survey as your framework, the survey results are your completed assessment, and you can move on to the next step. If you are using the HDI SCS or ITIL framework, for example, you must perform an assessment of your current performance level.\nYour scorecard is an assessment tool. To maximize fairness, validity, and reliability you must apply good practices for conducting assessments. The principles and details of these good practices are outside of the scope of this article. However, to provide a general approach here I recommend that service managers look within your own organization for expertise in conducting assessments (imagine if you called your Internal Audit folks and invited them to help you), study up on good practices to conduct assessments (this is a career-enhancing skill to have), or hire an experienced consultant to perform the assessment in partnership with you. If you want to study up, I recommend Conducting Assessments: Evaluating Programs, Facilities, Agencies and Organizations by Dr. Bob Frost to learn about and apply good practices for conducting assessments.\nService managers must first decide if they are going to perform an internal or an external assessment. External assessments are conducted by a person or team from outside of the organization and when the assessment requires an emphasis on objectivity and credibility. Internal assessments (a.k.a., self-assessments) are performed by a person or team that works for the organization and when the emphasis is on pursuing cost-effective continuous improvement.\nIf the knowledge, skills, and ability to perform the assessment exist within the organization, an internal assessment is a good way to start. Performing an internal assessment first allows service managers to validate the scorecard elements and the scoring method. This approach also allows the service manager to determine if it is worthwhile to invest in an external assessment.\nYou will want to train your assessors on the scorecard’s elements, the context of its model or framework, and the scoring method. The internal assessors should also be trained in the principles of performing high quality assessments. To actually do the work of performing an assessment, Dr. Frost outlines these steps:\n- Enlist a qualified assessment leader\n- Define and scope the assessment, plan the timeline, and identify stakeholder interests\n- Enlist qualified assessors\n- Specify criteria and standards, build assessment tools\n- Train assessor teams\n- Prepare for evidence collection\n- Collect data/evidence\n- Analyze data/evidence (and fact check)\n- Collect and document lessons-learned\nOne of the principles of high quality assessments is to separate each stage; establish criteria for your assessment first, then gather evidence, and evaluate the evidence. Developing criteria first helps determine what evidence is required. Premature evidence collection can improperly influence the criteria. Each stage should be monitored by a sponsor-level person supervising the entire assessment.\nCapturing evidence for how each scorecard rating was assigned is strongly recommended. For standards- or framework-based scorecards, the evidence should be things like links to documented policies and procedures, or to key performance indicators, or even meeting notes—anything that sheds light on the specific reasons for a specific rating.\nWhile the responses from a survey are a form of evidence reflecting the point of view of the respondents, you may need to investigate the characteristics of the customer’s experience that formed the basis of their response. Reports related to those type of investigations become supporting evidence for the survey results.\nNumerical-based evidence is quantitative. Comparison- or attribute-based evidence is qualitative. Both kinds of evidence are important for assessments. Not all quantitative evidence is created equal. And many times, the most fruitful qualitative evidence is unstructured. Therefore, as Dr. Frost notes, all evidence should be analyzed systematically and purposefully.\nAnalyze Current Performance Levels\nOnce you’ve collected your ratings and evidence, analyze the current performance levels to understand where the assessment results demonstrate strengths and uncover improvement opportunities. If you’ve used a spreadsheet tool for your scorecard, you will be able to graph, chart, or use conditional formatting to visually summarize your results.\nHeat maps are extremely useful as a visual aid for analysis. Ranking that incorporates the identified gaps and the assigned weighting is very useful for prioritizing the areas that need improvement. Please note that priority and sequence are not always the same thing. Analyze the scorecard and derive a prioritized list of scorecard elements to apply your improvement efforts to. Use your experience to plan the sequence of improvement efforts, factoring in effort, impact, and your organization’s ability to undergo changes.\nThe figure below shows the use of the heat map function in Excel to visually analyze the HDI SCS Leadership category.\nBuild Your Roadmap\nBuild your roadmap by defining and sequencing improvement efforts that will achieve the goal (or target) levels. When you have specific areas from your scorecard to target for improvement, it may be a good idea to get input from your peers or from your professional network on changes to make that have a high likelihood of success. The list of improvement efforts and their sequence become the basis of your roadmap.\nAs noted in this continuous improvement toolkit website, a service improvement roadmap serves the same purpose as a roadmap in your car when you’re trying to drive to a destination; you need to know and understand where you are now, and you need to find the way to go to achieve our target (destination). To gain the improvements, each roadmap item is then broken down into a project or action plan and executed.\nAt a minimum, your service improvement roadmap should include a timeline and service improvement initiatives or activities placed along that timeline. The Initiatives or activities can be grouped into categories. For example, by support team, by process, or by level of effort. At a more advanced level, your service improvement roadmap can be augmented with budget information or can identify key stakeholder groups. The example below shows a basic roadmap organized by ITIL process.\nThe next example shows a service improvement roadmap depicted as a Gantt chart that is grouped by the complexity of improvement initiative (Quick Hit, Operational, Tactical, Strategic).\nThis example shows a service improvement roadmap for Collaboration Tools and includes the names of a series of interrelated projects on a timeline with each project’s estimated budget.\nUse Your Service Improvement Roadmap\nThe example below shows the results from a series of measurements over several 90-day periods, with graphs for showing the effect of scorecard results from service improvement initiatives.\nYour service management roadmap is primarily useful for coordinating and implementing service improvements. Coordination includes communication both inside and outside your support team. The service improvement changes or initiatives on the map must be planned and executed in detail. Make sure to employ organizational change management practices for your improvement initiatives. Strongly consider employing project and program management techniques as part of coordinating and implementing service improvements.\nThese kinds of roadmaps are versatile because they can be used as a communications instrument, to track your progress, and as a catalyst for increasing the value delivered by your support organization.\nThe same scorecard you used to build your service improvement roadmap is also a way to measure the success of your service improvement efforts. In addition to the required scorecard elements noted above, consider adding an historical measures section to your scorecard where you can capture periodic measurements over time. A set of periodic measurements based on reassessments can be used to show progress.\nGet your service management content in person at Service Management World!\nBill Payne is a results-driven IT leader and an expert in the design and delivery of cost-effective IT solutions that deliver quantifiable business benefits. His more than 30 years of experience at companies such as Pepsi-Cola, Whole Foods Market, and Dell, includes data communications consulting, messaging systems analyst, managing multiple infrastructure support and engineering teams, medical information systems deployment, retail and infrastructure systems management, organizational change management, and IT service management consulting. Leveraging his experience in leading, managing, and executing both technical and organizational transformation projects in numerous industries, Bill currently leads his own service management consulting company. Find him on\n, and follow him on Twitter","Capability Maturity Models\nA Capability Maturity Model, or just “maturity model” for short, addresses a common organizational challenge that many business functions, including security, face: how to move from an initial less-established state to a more stable well-established state (no backsliding) that includes ongoing improvement. The concept of a Capability Maturity Model (CMM) was developed at Carnegie Mellon University in its Software Engineering Institute (SEI), and funded by the U.S. Air Force, in response to its need to assess the capabilities of companies developing critical defense systems to consistently deliver a product of acceptable quality on schedule.\nCapability maturity models are collections of best practices that help organizations improve their processes. The SEI has taken the process management premise, “the quality of a system or product is highly influenced by the quality of the process used to develop and maintain it,” and has defined CMMs that embody this premise, beginning with a CMM for software development. Since then, several additional CMMs have been developed by the SEI, and several dozen have been developed by other organizations for various domains including architecture, human resources, information security, construction and project management.\nThe purpose of a maturity model is not to guide your actions (i.e. provide step-by-step instructions), but to guide your thinking in a way that leads to actionable ideas for stable improvement.\nSupply Chain Risk Management Maturity Model\nFigures 1 and 2 (on page 22) depict the basic elements of the Supply Chain Risk Management Maturity Model: the maturity levels and the key process areas. The maturity levels provide a stepping-stone path to achieving higher supply chain security and resilience, with a resulting higher level of economic viability for your company.\nThe maturity levels (described below) are general enough to apply to any company, yet specific enough that any company’s position can be clearly identified. Instead of defining specific processes, maturity models identify key process areas to be addressed using processes refined, defined or developed as appropriate for the specific business.\nLevel 1 — Pre-compliant: Pre-compliant companies are not yet meeting C-TPAT security or other compliance criteria, nor have they established supply chain security prevention or response standards or practices. In some cases, limited prevention measures such as personnel checks and freight protection practices are in place. The firm’s economic viability is at risk. The probability of a business disruption is high, as is the likely impact — and these firms are less competitive than their C-TPAT-compliant rivals.\nLevel 2 — Compliant: C-TPAT-compliant companies carry out security or other mitigation measures as a response to externally imposed regulations. Aside from being compliant, companies at this level are primarily reactive and see security as a cost of doing business. There is a lower risk of compliance violation, but still high probability and impact of disruptions. These firms may enjoy C-TPAT benefits of lower inspections and shorter border delays, but they are not leveraging their security investment.\nLevel 3 — Secure: Secure companies see externally imposed security standards as inadequate, and have instituted a more rigorous approach to protect the brand, employees, physical assets and shareholders. At this level, the focus is on preventing a disruption from occurring. Security is seen as part of the business model. These firms are leveraging their C-TPAT investments and are working with suppliers and customers to understand the system risks and vulnerabilities; however, the impact of a disruption is still high.\nLevel 4 — Resilient: Resilient companies see risk management as an element of a business strategy that changes the way the enterprise operates and increases competitiveness. Recognizing that disruptions are not entirely preventable leads to additional focus on rebounding quickly from incidents. The company adds flexibility and, where necessary, redundancy in the supply chain to detect and respond proactively to potential risks and crises. These firms have reduced their risk of non-compliance, are less prone to security breaches and have mitigated the consequences of disruptions. They are leveraging their security investments, and security plays an integral role in serving the business purpose. As such, these firms have prepared themselves for ultimate economic viability.\nUsing the Maturity Model\nUsing the maturity levels, you can identify where your supply chain’s current level of maturity is. No organization’s supply chain is 100-percent at a single level only. Usually, some processes are at a higher or lower level of maturity than others; however, a general determination can be made as to which maturity level best represents the state of supply chain security.\nOne way to use the maturity model is to identify the gap between the current maturity level and the next level up, for each key process area. For example, this could mean identifying what must be accomplished to move from the Pre-Compliant to the Compliant level.\nHowever, it is important to note that the maturity model is not intended to restrict or limit process improvement to “the next level up” if a critical process belongs at a high maturity level — regardless of the levels of other processes. The value of the model in such an instance is that it provides a perspective by which to understand the relative state of specific processes in relation to others. This facilitates the consideration of related or supporting processes that may also need to be advanced as well. Without such a framework for thinking, capability gaps (and their related vulnerabilities) could remain unseen.\nThe 2002 West Coast port labor dispute is an example of the economic impact of widespread supply chain delays. While the dispute remained unresolved, cargo ships lined up in the Pacific for as far as the eye could see, unable to offload their goods. The resulting impact to American companies has been estimated to have reached $2 billion a day.\nBarry Brandman is president of Danbee Investigations (www.danbeeinv.com), a Midland Park, N.J., company that provides investigative, loss prevention and security consulting services to many of the top names in the logistics industry. He is the author of “Security Best Practices: Protecting Your Distribution Center From Inventory Theft, Fraud, Substance Abuse, Cybercrime and Terrorism.” Danbee’s clients have found that implementing supply chain security — and particularly C-TPAT compliance — has significant financial benefits.\n“Many of America’s largest importers have embraced the C-TPAT program and strengthened their supply chain security,” Brandman says. “Not only has this reduced their exposure to smuggling and cargo theft (itself a multi-billion dollar problem annually), but most C-TPAT-certified companies have also reaped significant financial benefits. To begin with, their risk of shipment delays caused by security inspections has dropped drastically. In addition, their participation in C-TPAT makes them eligible for expedited clearance via Customs’ FAST (Free and Secure Trade) program at the Mexican and Canadian borders, and has given them added leverage in negotiating insurance premiums.”\nIf you haven’t already done so, take a look at the maturity levels in Figure 1 and assess where your supply chain security program currently stands. It shouldn’t take more than a minute or two. Armed with that assessment, what thoughts do you have now about improving the state of your company’s supply chain security?\nRay Bernard, PSP, CHS-III is the principal consultant for Ray Bernard Consulting Services (RBCS), providing security consulting services for public and private facilities. (www.go-rbcs.com). For the rest of Mr. Bernard's bio, please see Convergence Q&A on page 14.\nWilliam Tenney is Group Manager of Global Security at Target Corp. He can be reached at William.Tenney@target.com"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:66911203-9e58-4270-b22f-08b1aa8580a2>","<urn:uuid:8c8ba4b5-6000-48a1-81b0-f644c4331cb5>"],"error":null}
{"question":"How much horsepower do solar racing cars typically have compared to regular consumer vehicles?","answer":"Solar racing cars typically have very low horsepower, ranging from about 2 to 8 horsepower. This is significantly less than regular consumer automobiles, which average between 100 to 150 horsepower.","context":["Solar-powered vehicles are becoming more common today. Solar cells power cars, boats, airplanes and satellites in space. Solar racing is a growing sport with competitions around the world. Even some toys get their power from solar panels.\nFrom the most basic toy solar racer to the most advanced solar-powered satellite, the foundational elements date back more than a century. The first dry cell battery was invented in 1895. Electrically powered cars debuted in 1900 and the solar panel was invented in 1941. With each of these developments, mankind made steady progress in harvesting the sun’s energy and converting it to power.\nHarnessing solar energy\nSolar-powered vehicles get the energy they need to move from the sun. Typically, the vehicles have a large solar panel mounted on top. The color of the panel is often black, as this assists with its ability to absorb sunlight. Black objects, as opposed to any other color, absorb the greatest amount of light that falls upon them. Usually, this means black objects simply get hotter in the sun, but with solar racers the energy is converted into electricity using solar cells. These panels are connected to the car’s electric battery for excess electrical storage and engine for fuel.\nAt its most basic level, a solar cell turns solar radiation into electricity. A typical silicon solar cell is made up of single or polycrystalline structures. The atomic makeup of silicon is altered to create P-type (atoms missing electrons) and N-type (atoms containing electrons) silicone crystals using phosphorus and boron to create interactive layers of materials that will react to sunlight.\nWhen placed in the sun, photons from solar radiation strike the top layer of silicon and create an electron and a hole, prompting an imperceptible exchange of electrons switching between both P-type and N-type molecules. This steady exchange creates of current through which power is generated and voltage created. These solar panels are then connected to devices like batteries to store the electricity generated for use in a vehicle like solar racers.\nThe design of solar racers\nBecause a solar racer relies on sunlight-based power, most vehicles are designed with a broad surface for capturing the sun’s rays. The design is mainly necessary because of the inefficiencies of solar panels. In a perfect world, a solar panel could convert all of the light falling on the car into energy. However, even the best of today’s solar cells can only convert around one-quarter of the sun’s power into electricity.\nThe end result is a very low-horsepower vehicle with a typical motor output of about 2 to 8 horsepower. The typical consumer automobile retains an average of 100 to 150 horsepower in comparison, which means these vehicles must be designed as light as possible. The typical weight of a two-seated racer is around 400 pounds, allowing it to retain maximum speeds of nearly 90 miles per hour.\nSolar racing as a sport\nThe sport of solar racing is quite popular in sunny regions, the most popular race being the World Solar Challenge in Australia. Vehicles powered by solar energy are designed for endurance races to cover the 3,000-kilometer race (1,864 miles) in the least amount of time.\nColleges and universities in the United States often build and race solar cars. While the races typically don’t cover such grand distances as the one in Australia, they still serve as excellent learning experiences and prove a popular competition among academic departments at institutes.\nOther solar-powered devices\nMany vehicles use solar energy beyond road-faring technology. For example, planes powered by solar panels continue to grow in popularity due to the capabilities they provide. The ideal outcome is to design a vehicle capable of maximizing solar energy conversion for virtually endless flights. By reaching altitudes of more than 80,000 feet (24,380 meters), more sunlight can be captured and converted for even greater electrical output. [Images: Cross-Country Flight in a Solar-Powered Plane]\nNASA's Juno spacecraft, which is on its way to explore Jupiter, is the first solar-powered spacecraft to explore the outer solar system. It has three large solar arrays, each of which is the size of a tractor-trailer.\nSolar racer toys\nEven more popular are the use of solar-powered remote control toys like planes and cars. Rather than relying on wall-charged batteries, these devices have tiny solar panels installed on their surfaces to draw upon the energy of the sun and thus create a power source.\nSolar racer toys employ the same principles of solar powering used for full-size cars. Across these devices are large, flat (sometimes curved) solar panels attached to a small battery. The cars operate much like any other remote control car, though their power source is dependent on the presence of a sun and thus suffers on cloudy days.\nMost solar racer toys require some assembly and teach children how something as simple as sunlight can be used to power everyday devices. As the mankind continues to branch out, renewable energy becomes a more popular and important power source to consider due to its clean and frequent availability."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:b9296708-2804-4085-ada8-a3bac4f8c0d8>"],"error":null}
{"question":"What are the key features of the original gravity gun in Half-Life 2, and how did the ZDCMP2 mod expand on physics-based weapons?","answer":"The gravity gun in Half-Life 2, officially called the 'zero-point energy field manipulator', had two main functions: a primary trigger that could push objects away and a secondary trigger that could attract and hold objects in midair. Players could use it to scale barriers, create cover, or launch objects as weapons against enemies. The ZDCMP2 mod expanded on physics-based combat by introducing new weapons like the dark claw, which fires rebounding projectiles that home in on monsters, and the soulrender, a powerful charging weapon that can rival the BFG9000 in power.","context":["A gravity gun is a concept in video games, particularly first-person shooters using an advanced physics engine, whereby players can directly manipulate objects in the world, often allowing them to be used as projectiles against hostile characters. A gravity gun is usually manifested as an in-game weapon, available from the player's inventory or weapon selection. The concept was first popularized by the gravity gun found in Valve Software's Half-Life 2; however, a similar concept was used by developers id Software during the production of the earlier game Doom 3, eventually leading to the introduction of a physics-based weapon in the expansion pack Resurrection of Evil. Later games have been influenced by the success of these physics-based weapons, adopting their own styles of comparable abilities or weapons.\nHalf-Life 2 gravity gun\nValve Software's Half-Life 2 made significant use of physics in the game, powered by Havok physics engine. Although the player can pick up and throw objects early in the game, this ability is somewhat limited in scope. Around the middle of the game, the player acquires the gravity gun, properly named as the \"zero-point energy field manipulator\". Alyx Vance explains that the gravity gun is designed for handling hazardous materials, but is mostly used for heavy lifting. The gravity gun significantly increases the player's ability to manipulate objects in the game. Like most other weapons in the game, the gravity gun has two trigger functions. The primary trigger causes the gun to emit a small discharge which emits energy to the targeted object. The distance which the object is forced is dependent on its weight and distance from the gun. The secondary trigger attracts the targeted object to the gun and holds it in midair a few inches away, negating its weight and allowing the player to carry it with them. Using the secondary trigger again will drop the item, while the primary trigger will launch it with considerable force.\nBy combining these functions, players can use the gravity gun to scale barriers and obstacles, create cover against enemy characters, or launch the objects at enemy characters, causing them considerable damage. Certain types of objects, such as saw blades, fuel barrels and hydrogen tanks are intentionally designed by Valve to be used as gravity gun ammunition. The gravity gun, however, cannot manipulate heavier objects and enemy characters until the late stages of the game, when the device becomes temporarily infused with dark energy.\nThe gravity gun was very well received by critics, who considered it one of the defining features of Half-Life 2's entertainment value. Planet Half-Life calls the gravity gun \"the next level in interactive gaming.\" Electronic Gaming Monthly describes Half-Life 2's gravity gun as the \"thinking man's death tool,\" which lets players \"toy with gravity to kill foes with everyday objects.\" Call of Duty series military adviser Hank Keirsey stated that \"the weapon is not very practical\". He does, however, discuss its historical precedents, further stating that \"The ancients learned very early how to use gravity to their advantage — but this usually involved rolling rocks down hills or pouring boiling oil down the castle walls. Those that failed to respect gravity suffered.\"\nDoom 3 grabber\nAlthough Half-Life 2 was the first game released to feature a gravity gun, id Software had previously conceived a similar idea during the development of the earlier title Doom 3. id Software designer Matt Hooper noted that \"we actually used it as a tool throughout development where we'd grab physics objects and place them around the world\". The tool was used to create \"damaged\" rooms in Doom 3; instead of constructing a ruined room, the designers would code a pristine room and use the device to \"damage\" it realistically. Although used to assist the development of Doom 3, the gravity gun was not implemented in the final game. Hooper explained that \"we talked about that quite a few times, but we had such a big arsenal of weapons, and so many other cool things going on, that it was just one of those things that never made it in\". However, Nerve Software revived the code for the weapon five months after the release of Half-Life 2 in Doom 3's expansion pack, Resurrection of Evil.\nThe device is noted in the Doom 3 storyline as an \"ionized plasma levitator\", created by the Union Aerospace Corporation for moving hazardous materials and a forerunner to tractor beams. Usually referred to as the \"grabber\", the player obtains the device early on in the course of Resurrection of Evil. The grabber operates differently from Half-Life 2's gravity gun, using only a single trigger function. Once the grabber is aimed at an appropriate object, it locks on, allowing the player to lift the object with the trigger. When the player releases the trigger, the object will be propelled forward with force, turning it into an impromptu weapon. One key ability of the grabber is its capacity to lock on to the fireball projectiles cast by some hostile non-player characters, allowing players to turn the attack against their foe. However, unlike the gravity gun in Half-Life 2, the grabber cannot hold objects for as long as the player wishes; if they wait too long to launch the object, the grabber will start to overload and disengage, dropping the object gently on the ground. Critics often compared the grabber directly with Half-Life 2's gravity gun, some noting that the device was far more combat-focused in operation than the gravity gun; in particular, the ability to turn projectiles cast by enemies against them was praised. However, the grabber was considered somewhat \"awkward\" to use, requiring a \"finesse\" that \"is rarely something the player has time for in a close-quarters situation\".\nInfluence on later games\nVarious later video games have included gameplay features that allow players to use the game's physics to their advantage in combat. In some cases, these are manifested as weapons or devices. For instance, the Aperture Science Handheld Portal Device in Portal displays a limited capacity to move objects around the game world, while Crytek's Crysis allows the player to throw objects and enemy characters considerable distances through the use of an experimental nanosuit. In other games, however, it can be represented in a different manner. In Arkane Studios' Dark Messiah of Might and Magic a psychokinesis spell allows for similar functions as Half-Life 2's gravity gun, Destroy All Humans! portrayed a similar gravity usage, known as PK, while 2K Games' BioShock displays the concept as a telekinesis plasmid that the player uses to alter their character's DNA. In EA's third-person horror shooter Dead Space, the player character acquires a 'Kinesis' module, which allows the player to grab and throw objects similar to Half-Life 2's gravity gun.\n- ↑ \"Half-Life 2 preview\". Edge (124). June 2003. \"The physics engine within Source is derived from Havok, which opens up a wealth of possibilities for object interaction – particularly when you consider that later in the game, Freeman receives an energy-beam weapon that lets him move huge objects...\"\n- ↑ Valve Corporation. Half-Life 2. PC. Level/area: Black Mesa East. (2004) \"Alyx Vance: Its designed for handling hazardous materials, but we mainly use it for heavy lifting. I've found it handy for clearing minefields.\"\n- ↑ \"Half-Life 2 review\". Edge (143). December 2004. \"Tearing a radiator from a wall and using it to swat a parasitic headcrab, while all the furniture in a room goes tumbling around you, is truly a gaming epiphany.\"\n- ↑ The Gravity Gun: The Next Level in Interactive Gaming. Planet Half-Life (2007-07-03). Retrieved on 2007-12-17.\n- ↑ Electronic Gaming Monthly features seven notable video game weapons and for each of them divides the profiles into sections headed as \"The Gun,\" \"Keirsey says...Practicality,\" \"Historical precedents,\" and \"Lethality level.\" See Evan Shamoon, \"Gun Show: A real military expert takes aim at videogame weaponry to reveal the good, the bad, and the just plain silly,\" Electronic Gaming Monthly 230 (July 2008): 49.\n- ↑ 6.0 6.1 Accardo, Sal (2005-01-05). Doom 3: Resurrection of Evil Preview. GameSpy. Retrieved on 2008-11-09.\n- ↑ Nerve Software. Doom 3: Resurrection of Evil. PC. Level/area: Black Mesa East. (2005) \"UAC narrator: The prototype ionized plasma levitator was designed to transport hazardous materials without physical contact... With further research and development, uses for this technology would include heavy lifting and the ability to create tractor beams, thereby making low gravity docking procedures much safer for pilots.\"\n- ↑ 8.0 8.1 ROE Weapons. Planet Doom. GameSpy. Retrieved on 2008-11-12.\n- ↑ Accardo, Sal (2005-03-04). Doom 3: Resurrection of Evil Review. GameSpy. Retrieved on 2008-11-12.\n- ↑ Shoemaker, Brad (2005-03-05). Doom 3: Resurrection of Evil for PC Review. GameSpot. Retrieved on 2008-11-12.\n- ↑ McNamara, Tom (2005-03-04). Doom 3: Resurrection of Evil Review. IGN. Retrieved on 2008-11-12.","The ZDoom Community Map Project \"Take 2\"\n|The ZDoom Community Map Project \"Take 2\"|\n|Perimeter of dig site|\n|This mod received one of the 2013 Cacowards on Doomworld!|\nZDoom Community Map Project: Take II, abbreviated to ZDCMP2, is a single map for ZDoom designed by a large number of mappers. It is one of the largest levels ever made. Like the previous project, each mapper was assigned a set of dates to work on the map, each one continuing where the last mapper finished. It took over two years to build, with a final release on 25 May 2014. The map makes extensive use of ZDoom features, such as 3D floors (including swimmable water), and portals. The second release candidate, released on 9 December 2013, won one of the 20th Annual Cacowards as well as the Mordeth award.\nThroughout the level, the player will come across data logs of the since deceased base personnel, the contents of which can be viewed by pressing a key defined by the player in the \"ZDCMP2 Options\" menu. Many of the personnel are named after the developers of the level, though some are named after characters from popular culture. There are 21 data logs to be found in total. The player also has their own data log, which they can use to view their current objectives. This uses a separate key binding, and again, the player must define it themselves.\nData logs essentially serve the same purpose as the PDAs in Doom 3. They play a large part in telling the story of the level, and also drop hints, telling the player what to watch out for, or what they need to do.\n- Zombie scientists: Added to the zombie roster are scalliano's iconic scientist zombies. They can only attack with melee and move very slowly, so pose very little threat. They come in two varieties: Males, who are armed with an axe and have 20 health; and females, who carry a knife, and have 15 health, meaning they can be potentially killed with a single pistol shot. Neither scientist drops anything when killed.\n- Rapid fire trooper: A low-tier zombie that fits perfectly between the sergeant and the trooper. Like the trooper, he shoots with an assault rifle, but at a much higher rate, faster than the player's own pistol. Like the sergeant, the rapid fire trooper has only 30 health, so can easily be taken care of. They drop the rifle when killed, and can be identified by the distinctive brown colour on their body armour. They are among the first monsters encountered in the level.\n- Flesh spawn: One of the more grotesque enemies in the level, the flesh spawn is a small, spherical airborne demon, completely featureless aside from a large mouth where its face would be located. Judging by the similar projectile, its ability to fly, and its blue blood, the flesh spawn is most likely some form of cacodemon larvae. Fortunately, it has just 30 health, so every weapon can make short work of it. Nearly always encountered in large swarms.\n- Shadow: A small humanoid demon that maintains a crouched position. Their skin is black, but also slightly transparent. They are often found in dark areas, where they are extremely difficult to spot, and their presence is easier to identify by their iconic growling. Their position is also given away by the fast-moving red projectile that they throw at the player. They have 80 health, so a single shotgun blast may not always be enough to take one of these down. As you'd expect, shadows drop nothing when killed.\n- Soul harvester: Visually, the soul harvester appears to just be an imp with grey skin. However, in combat, it functions slightly differently. It takes some time to create its projectile - a yellow sphere showing the face of a demon - then launches it at the player, where it will follow the player, and due to its very small turning circle, it is rather difficult to avoid. With 100 health, it should take two shotgun blasts to kill one of these. They are one of the few monsters that appear continuously throughout the level.\n- Grell: A brown airborne demon, very similar in appearance to the Doom 3 cacodemon. They spit a poisonous green projectile that on impact will give a green tint to the player's screen, and will slow the player down for three seconds. They are encountered solely in hellish settings, making their first appearance rising out of the portal inside the dig site. They have 300 health.\n- Hell warrior: A medium-sized demon with orange skin and a lions mane. They appear to be related to the Hell knight and baron of Hell. They launch a yellow version of the baron's projectile, and if necessary, take cover behind their shield, which is also capable of shooting a green projectile.\n- They have 400 health, slightly less than that of the Hell knight.\n- Vore: The vore is a three-legged monster taken directly from Quake. It functions identically to its original counterpart, throwing purple spiked bombs that home in on the player, exploding on impact. Like the projectile of the soul harvester, \"voreballs\" have a small turning circle, so avoiding them can prove challenging. The vore is tougher than its original counterpart however, with 600 health.\n- Cybruiser: A devastating combination of the baron of Hell and the cyberdemon. This dark grey baron has had its right arm removed and replaced with a very powerful rocket launcher, and like the cyberdemon, fires three rockets at a time. At 1250 health, they are slightly tougher than the standard baron.\n- Bruiser demon: A giant baron-like demon, easily identifiable with its bright orange torso and black legs, and by its distinctive roar. The bruiser demon has three different attacks, it can either launch a spread of seven small fireballs, a single large one, or send three lines of fire towards the player along the ground.\n- Bruiser demons only appear in Hell, and even there, they are rarely encountered, but when they are, they will be in pairs. They have 1500 health, making the rocket launcher or plasma gun a favourable weapon for taking them down.\n- Angel of Death: A tall, brown, hoofed demon with a skeletal face and a grey, hooded cloak, first encountered as the eponymous specimen in specimen containment. The angel is armed with two machine guns, of which the bullets rebound off walls, and mounted on its chest is a small explosive cannon.\n- Rifle: Weapon slot 2. Dropped by the rapid fire troopers, the rifle is a bridge between the pistol and the chaingun. It fires two bullets at a time at a slightly slower rate than the pistol. It has an alternative fire where it will shoot one shotgun shell as a slug. The shell attack takes very long to reload, and since the shotgun is received early on in the map, and the chaingun not long after, the player is unlikely to use the rifle past the first few minutes of the map. However, its complete lack of spread (in both modes) makes it useful as a sniping weapon.\n- AA-12 Automatic Shotgun: Weapon slot 3. The AA-12, when found, will replace the default shotgun. It does the same amount of damage, but has a much higher rate of fire, making it a very powerful weapon. In New Game ++ mode, it replaces the normal shotgun.\n- Nailgun: Weapon slot 4. Hailing from Quake, the nailgun is a decent alternative to the chaingun. The nails that it will launch at the enemy are more powerful than the chaingun's bullets, but the nails also travel as a medium speed projectile, taking longer to reach their target. The nailgun's rate of fire is also slightly lower than that of the chaingun. Ultimately, this makes the nailgun a very good close quarters weapon against mid-high tier monsters, but at longer distances, the chaingun is the weapon to use.\n- Flamethrower: Weapon slot 5. Retrieved from the weapon lab, the primary purpose of the flamethrower is to burn through the vines that are encountered about midway through the map. However it can be used as a very effective weapon against monsters, as it has a very high rate of fire - no pun intended!\n- If a larger number of monsters are being faced, the player can use the flamethrower's alternative attack, which will eject the fuel that is used as ammo, and then ignite it all in one go. One thing to note is that this can also be triggered by enemy projectiles, so unintentionally premature ignition can occur. The player can not be damaged by the normal attack, but can be damaged by igniting the petrol. If the player's napalm ammo is under 50, they can use a fuel station to bring their ammo up to 100 on ITYTD, and 50 on other difficulties.\n- Dark claw: Weapon slot 6. The dark claw can first be found in the research annex, not far from the dig site. The player should take caution when picking it up, as it will be already firing purple projectiles in every direction that rebound off any surface it impacts. These projectiles are actually the primary attack of the dark claw, and addition to rebounding off surfaces, they will also home in on the nearest monster. The claw also has a secondary fire, which shoots a red beam, which drains enemy health and transfers a fraction of it to the player. The claw uses souls for ammo, and happens to belong to the final boss. It is based on a life-draining weapon of the same name that was outlined in the Doom Bible, but was not implemented in Doom itself.\n- Soulrender: Weapon slot 7. An extremely powerful weapon. On ITYTD, the soulrender is given to the player just before the final boss fight, but if the player is on a different skill level, they will have to find the secret area containing it. Using souls for ammo, the soulrender needs to be charged up to a certain extent to fire. The progress of the charge can be seen on the weapon as white beams that light up when that charge is complete, with each beam representing a different stage in the charge. At least one beam needs to be lit to fire the soulrender, at which it will fire a white projectile that may or may not be orbited by a number of smaller white projectiles, depending on how much it is charged. At full power, the soulrender rivals the BFG9000 in power, though be aware that it will take over five seconds to charge it fully.\n- Grenades: You will be required to bind a key to use grenades. Pressing that key will throw the grenade, where it will wait a few seconds before detonating, resulting a powerful explosion. Alternatively, you can hold the key down to cook the grenade, then throw it for a smaller delay before the explosion. If you cook the grenade for too long, it will explode in your hand, dealing 200 damage.\nNew game +\nWhen you finish the level, a credits sequence will begin to play. When this finishes, the level will restart at a higher skill level, and an information box will appear at the top of the screen, telling you that you have started New Game +. This is an optional challenge for experienced players, where there are some significant differences:\n- As you would expect, there are more monsters. Initially there are 1262 monsters in the map, opposed to 1069 on ultra-violence. Most of these additional monsters are flesh spawns, but watch out for particularly nasty changes:\n- Three angels hide behind the doors to the dig site, bringing the angel count in the area to seven.\n- The central junction contains three cyberdemons.\n- There are two abaddons.\n- In addition to the ones already existing, many types of monster have had their numbers increased as some stock monsters have been replaced with a tougher monster that is related in some aspect, for example, all barons in the level have become cybruisers.\n- Ammo pickups give 50% more than their usual amount. Additionally, soul harvesters will drop ammo for the dark claw and soulrender upon death.\nIt is even possible to go on a New Game ++ after finishing the level twice; however a definitive game over is reached after finishing the level thrice. The monster placement and gameplay changes of New Game ++ are mostly the same as in New Game +, with some additions:\n- Fast monsters are on.\n- Ammo pickups give double their normal amount.\n- Mancubi are replaced by vores.\nBoth of these skill settings are available from the menu as invisible options below Ultra-Violence on the difficulty selection screen.\nAreas / screenshots\nThe level contains the following number of things on each skill level. Does not yet account for Thing_Spawn. Custom things are italicised.\nWeapons and ammo\nItems, keys, other\nThe level uses several different music tracks, which play at different points as the player progresses through the map.\n- MUSIC1.ogg: \"2012 (ZDCMP2 Remix).\" The first track heard in the level, this track plays up until the player burns through the vines in the first main room. Also known as \"2012 (Judgement Day),\" this music was originally composed by James Paddock (Jimmy) for his Rainbow Season EP. Paddock then created a remix of the song specifically for the mod (\"ZDoom 2012\"), which was then edited by Henri Vuortenvirta (Icytux), who replaced the MIDI instruments with high-quality VSTis, and recorded live guitar and bass for the in-game track. Both MIDI files can be found in the PK3 along with the OGG.\n- Organic.it: \"Organic,\" originally composed by Alexander Brandon for Unreal Tournament. This track plays while the player is in the simulation room.\n- MUSIC2.ogg: \"ZDoom Colab.\" This track plays when the player enters the engineering bay, and plays across this entire section of the level, up until the dig site. It is based on a guitar riff by dj-jo, mixed with a slower-tempo rendition by Icytux of \"2012\", and featuring some further tweaks by Xaser.\n- MUSIC3.ogg: \"Destructive Step,\" originally from Devil May Cry 2. This track plays when the player begins the Hell section of the level - after jumping into the pit found at the dig site.\n- MUSIC5.ogg: \"Eternal,\" originally from Devil May Cry 2. This track plays in the vicinity of the final gate.\n- MUSBOSS1.ogg: \"Darkness Instinct,\" originally from Devil May Cry 2. This track plays during the fight with Abaddon's bodyguards.\n- MUSBOSS2.ogg: \"Ragnarok,\" originally from Devil May Cry 2. This track plays when the final boss, Abaddon, spawns following the defeat of the first two bodyguards.\n- MUSIC4.ogg: \"Blasphemy,\" originally from Devil May Cry 2. Despite being named MUSIC4 in-game, this track plays after MUSIC5. In fact, it is the last music track in the map, as it accompanies the escape sequence after the player has defeated the final boss.\n- VICTORY.ogg: Upon beating the level on Ultra-Violence or lower, this short melody will play alongside a brief cutscene.\n- D_RUSTED.ogg: \"Rusted Flesh,\" originally composed by Xaser for TurboCharged Arcade! Upon beating the level on New Game + or New Game ++, this will accompany a slight twist to the ending cutscene.\n- Title and intermission screens: Sample of \"Oil Fields,\" originally composed by David Arnold for Quantum of Solace.\n- Credits sequence: \"Nine One One ZDmix,\" a remix by Xaser of a composition by Jeroen \"WAVE\" Tel.\n- HITLER.mid: \"I'm Hitler,\" originally composed by Xaser for TurboCharged Arcade! This track plays upon activating the Hitlercube easter egg.\n- MUSBONUS.ogg: A sample of \"Chacarron Macarron\" by El Chombo and Andy Val Gourmet. This track plays upon activating the Cran World easter egg.\n- Alex Meyers (Apothem) - Scripting\n- Blue Shadow - Testing, support\n- Captain Toenail - Mapping, coding\n- Chronoseth - Mapping\n- Deathknight - Testing, quality control\n- dj-jo - Music\n- DTDSphere - Mapping\n- Dusk - Mapping, coding, textures\n- Gez - Mapping, quality control, textures\n- Ghastly - Coding, quality control\n- Gothic - Mapping\n- Grymmoire - Mapping\n- Henri Vuortenvirta (Icytux) - Music\n- Infirnex - Mapping\n- James Paddock (Jimmy) - Mapping, music\n- Chris Kassap (lupinx-Kassman) - Mapping\n- Andrew Rehberger (Malinku) - Mapping\n- James Cresswell (Phobus) - Mapping, quality control\n- Pyroscourge - Mapping\n- ShadesMaster - Mapping\n- Fraser Low (TheDarkArchon) - Mapping, coding\n- Daniel Gimmer (Tormentor667) - Project lead, mapping, graphics, textures\n- Björn Ostmann (Vader) - Mapping, graphics\n- Xaser - Mapping, coding, quality control, music\n- zrrion the insect - Mapping"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:c43be7cf-dcda-424c-bccd-61da915287f4>","<urn:uuid:a76f8eec-697e-435b-b41e-2120e8ad6772>"],"error":null}
{"question":"What challenges do marine fisheries face regarding species distribution and sustainability, and how does ICES support sustainable management through its training programs?","answer":"Marine fisheries face challenges due to climate-induced changes in species distribution, with northward expansion of species ranges and potential southern range contractions. This affects local fisheries, where southern areas may lose access to resources while northern areas may benefit. Sustainable production requires communication between stakeholders, diversification of exploited species, and transnational cooperation. ICES supports sustainable management through specialized training courses, including 'Introduction to Management Strategy Evaluation' and 'Introduction to Stock Assessment.' They also organize workshops on topics like estimation of commercial catches and stakeholder engagement strategy, helping to ensure sustainable harvesting of marine resources.","context":["ICES Newsletter - April 2021\nFEATURE–Tributyltin: the story of a hidden bottom-up killer of the Crangon crangon population – A retrospective analysis in an ecosystem context.\nKris Cooreman, ILVO and member of the Working Group on Biological Effects of Contaminants presents a population-level endocrine disruption by TBT that may have interfered unnoticed for the past 60 years of Crangon crangon’s life history and almost the entire history of its recorded fisheries.\nTraining the next generation of editors\nICES Journal of Marine Science launches an Editorial Mentorship Programme to train early career researchers in scientific publishing and journal editing.\n30 years advancing zooplankton ecology\nCreated in 1991, ICES Working Group on Zooplankton Ecology continues today with the same drive.\nA transparent advisory process\nICES publishes a new advisory framework with the basis for both advice requests on fishing opportunities and ecosystem, environmental, and broader scale advice.\nNominations open for ICES Outstanding Achievement Award\nRecognize your colleague!\nICES Outstanding Achievement Award honours scientists who have made especially notable contributions to ICES.\nDeadline for nominations: 3 May!\nIn Eye on the Experts, we meet some of the early career scientists that are members of ICES expert groups and find out what they do.In this episode,we meet Fedor Lishchenko, member of the Working Group on Cephalopod Fisheries and Life History.\nLatest ID Leaflets\nNo. 194Acartiidae Sars G.O, 1903\nCopepods of the family Acartiidae are abundant marine zooplankton with a worldwide distribution.\nIn ICES area and the Ponto-Mediterranean region, 21 species and 1 variety have been described.\nNo. 64ICES Survey Protocols – Manual for acoustic surveys coordinated under ICES Working Group on Acoustic and Egg Surveys for Small Pelagic Fish (WGACEGG).\nSmall pelagic fish account for more than 30% by weight of the total landings of capture fisheries around the world. SPF populations of both marine and inland ecosystems are crucial for ensuring global food security. SPF also play an important role in the transfer of energy in food webs through mid-trophic levels, so understanding processes affecting the dynamics of their populations, their role in marine ecosystems and how these shape robust management practices continues to be a high priority.\nThe international symposium on “Small Pelagic Fish: New Frontiers in Science for Sustainable Management” will highlight the state-of-the-art in these and other topics related to the ecology and sustainable management of small pelagic fish. The symposium complements collaborative research conducted by the joint ICES/PICES Working Group on Small Pelagic Fish and is relevant to the goals of the UN Decade of Ocean Science for Sustainable Development, particularly “to bolster scientific research for a sustainably harvested ocean ensuring the provision of food supply.”\nClick here to find out more about all upcoming ICES symposia.\nICES Training courses 2021\nIntroduction to Management Strategy Evaluation\n23–27 August 2021, online courseRegistration deadline: 6 August 2021\nIntroduction to Stock Assessment\n27 September - 1 October 2021, online course\nRegistration deadline: 13 September 2021\nIntroduction to large-scale tag-recapture campaigns and their potential role in the management of fisheries resources\n4-8 October 2021, online course\nRegistration deadline: 20 September 2021\nUpcoming workshops ICES workshops are open to all interested individuals.Click on the workshop name for more informatiions\nWorkshop on the production of swept area estimates for all hauls in DATRAS for biodiversity assessments (WKSAE_DATRAS)31 May–4 June 2021\nWorkshop on Estimation of Commercial Catches I – Ratio estimators (WKRATIO) 31 May–4 June 2021\nWorkshop on Age reading of Sea bass (Dicentrarchus labrax) (WKARDL2)\n6–10 June 2021\nThird Workshop on Populating the RDBES data model (WKRDB-POP3)\n14–18 June 2021\nWorkshop on Stakeholder Engagement Strategy (WKSHOES)\n22–24 June 2021\nWorkshop 2 on the identification of clupeid larvae (WKIDCLUP2)\n1–3 September 2021\nWorkshop on estimation of MOrtality of Marine MAmmals due to Bycatch (WKMOMA)\n26–27 September 2021\nExplore our #oceansofdata\nHow’s herring doing in the North Sea?\nDive into our stock assessment database to find data behind our advice on fishing opportunities from 2014 onwards.\nIn Other Words\nWhat are vulnerable marine ecosystems?Laura Robson, Chair of the Working Group on Deep-water Ecology explains:\nA vulnerable marine ecosystem (VME) refers to a group of marine species that are particularly vulnerable to human impacts, such as from deep-sea fishing activity. When aggregations of these species occur together, they form a habitat for other species, such as fish and crustaceans, which creates an ‘ecosystem’.\nThe vulnerability of this ecosystem depends on a number of factors which are used to determine whether a habitat is listed as a VME or not. These factors or ‘criteria’ include:\nICES Working Group on Deep-water Ecology has prepared a list of VMEs which includes habitat-types such as deep-water coral reefs; coral gardens; deep-sea sponge aggregations and fields of soft corals called ‘sea-pens’. This list is used by the Regional Fisheries Management Organisation for the North-East Atlantic (NEAFC), to develop conservation and management measures to ensure deep-sea fishing activity in this area avoids damage to these ecosystems. Each year, ICES provide advice to NEAFC on areas where VME have been found in North Atlantic waters, and these areas are often closed to bottom trawling activity.\nA coral garden VME at Anton Dohrn Seamount in the Rockall Trough in the northeast Atlantic. Image: NERC funded DeepLinks project – University of Plymouth, University of Oxford, JNCC and BGS (2016).\nCOVID-19 pandemic effects on ICES work\nThe health and safety of our staff and community are our primary concern. As the COVID-19 pandemic continues, ICES Bureau has agreed to an extension of the precautionary measures. This means that expert groups will continue to operate through online meetings until at least 31 July 2021.\nInternational Council for the Exploration of the Sea (ICES)Conseil International pour l'Exploration de la Mer (CIEM)H. C. Andersens Boulevard 44-46, DK 1553, Copenhagen Denmark Tel: +45 3338 6700 Fax: +45 3393 4215 Email: email@example.com Web: www.ices.dk","By: Gaitlyn Malone, SRC Intern\nAs the world’s climate continues to change, economic, social, and environmental changes will undoubtedly occur along with it. One sector that is expected to be economically affected by climate warming is seafood production (Breitburg et al., 2018). Seafood production, which includes both farmed and captured fish, shellfish, and seaweed in marine and freshwater, will experience changes since the warming of an environment has the ability to change both a species’ distribution and life history characteristics (Pecl et al., 2017; Cochrane et al., 2009). Therefore, it is crucial to work towards being able to predict and understand the extent of these changes in order to prepare for the future.\nA recent study (Blanchet et al., 2019) examined the effects of climate change on seafood production within each European country in order to identify potential challenges and opportunities within the sectors of marine fisheries, marine aquaculture, and freshwater production. To do so, the researchers combined information on the target species’ temperature preferences, life history characteristics, and production volume to determine their biological sensitivity (BS) and the maximum temperature (Tmax) that they were experiencing. They then determined the adaptive ability of seafood production in each country or sector by determining the number of species that the country/sector exploits and those species’ temperature ranges. A country or sector that exploits a higher number of species will be more likely to adapt in response to climate change. A species with a wide temperature range would also potentially be more adaptable since they are able to withstand a variety of temperatures.\nOverall, seafood production was found to generally be more vulnerable within the marine fisheries and aquaculture sectors. The freshwater sector varied greatly based on country. Within the marine sector, northern countries tended to be more sensitive to warming than southern countries since seafood production in these areas are more dependent on cold-water species with a high BS. Southern countries tended to rely on warmer water species that had a lower BS. The main challenge facing these marine fisheries is due to changes in species distribution. In response to warming, there has been a northward expansion of the range of several species, which in some cases has included a contraction of their southern range. This change in distribution has the ability to affect local fisheries and management, who in southern areas may lose access to their resources, while northern areas may benefit. Aquaculture taking place in temperate zones was also predicted to be at risk from warming conditions, since increasing temperatures have the ability to reduce oxygen levels in the water and increase the metabolic costs for organisms. Disease is also likely to increase in these systems since pathogens may spread more readily. The low amount of species diversity in aquaculture also makes it particularly susceptible to rising temperatures.\nUnder warming conditions is not impossible to continue producing sustainable seafood, however efforts must be made to adapt to climate change. Therefore, the authors suggest that there must be communication between stakeholders, diversification of exploited species, and transnational cooperation in order to meet these goals.\nBlanchet, M.-A., Primicerio, R., Smalas, A., Arias-Hansen, J., Aschan, M. 2019. How vulnerable is the European seafood production to climate warming?. Fisheries Research 209, 251-258.\nBreitburg, D., Levin, L.A., Oschlies, A., Gr.goire, M., Chavez, F.P., Conley, D.J., Gar.on, V., et al., 2018. Declining oxygen in the Global Ocean and coastal waters. Science 359 (6371).\nCochrane, K., Young, D.C., Soto, D., Bahri, T., 2009. Climate change implications for fisheries and aquaculture: overview of current scientific knowledge. FAO Fisheries and Aquaculture Technical Paper 530, 212.\nPecl, G.T., Ara.jo, M.B., Bell, J.D., Blanchard, J., Bonebrake, T.C., Chen, I.-C., Clark, T.D., et al., 2017. Biodiversity redistribution under climate change: impacts on ecosystems and human well-being. Science 355."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:cdb2e51f-544c-4f64-864e-39e7fe3ffb0a>","<urn:uuid:15b67a19-5005-450e-8ce4-8018dcb10f65>"],"error":null}
{"question":"What is the relationship between tree roots and urban heat islands, and how can trees be strategically used to address both foundation damage and city temperatures?","answer":"Tree roots can cause foundation damage in areas with expansive clay soil by consuming moisture and causing differential settlement. However, trees can also be beneficial in urban areas as a solution to reduce heat islands. For foundation protection, root barriers should be installed 30 inches deep minimum between trees and structures. Meanwhile, trees can help reduce urban heat by providing important shading effects and cooling through evaporation. Specifically, they can be strategically planted to shade buildings (especially roofs and south-, east-, and west-facing walls), roads, and parking lots, which helps reduce surface temperatures and energy use for air conditioning.","context":["The act of cutting off the roots of trees that are growing near a building and installing a barrier to prevent their reestablishment in the area where they are not desired is called installing a root barrier, a root wall, or root capping. The need for root barriers is related to the fact that expansive clay soil shrinks as it dries out. Any structure that expansive clay soil is supporting will move downward as the soil dries and shrinks. If the soil dries on one side of the structure and not the other, the soil shrinks where it has dried and remains expanded where it has not dried, causing the structure to experience differential settlement. Differential settlement can cause serious damage to a structure.\nA root barrier is usually installed between concrete foundations or flatwork and adjacent trees within their mature height from the foundation and where there is expansive clay soil to prevent tree roots from consuming moisture from the soil under the area of concern (figure 1). The barriers are installed so that they intersect imaginary radial lines extending from the trunk of the tree to the edges of the foundation. Root barriers can prevent damage to flatwork concrete such as walks and drives or to concrete slab on grade foundations. In some cases it is possible that differential settlement that has occurred because of shrinking soil can be reversed. The soil under a structure will swell or expand as it becomes rehydrated and in doing so will lift the portion of the structure that has experienced differential settlement back to near the level of the structure where differential settlement has not occurred.\nRoot barriers can be made with any impermeable durable material that can withstand burial in soil for an extended period of time. Current information is that root barriers need to be installed to a depth of 30 inches minimum and they must extend above the surface of the soil enough to prevent roots from growing over the top (figure 2). There are root barrier materials that are permeable to moisture but will not allow roots to grow through them because of the chemical makeup of the barrier. It is our opinion that permeable root barriers should only be used under special conditions since the impermeable barriers hold moisture at the locations where it is desired.\nLarge trees with tap roots, such as pecan trees, may affect soil volume to a depth greater than the 30 inches indicated above. There is evidence that large pecan trees dry soil to the “water table” which causes it to shrink for a great depth. Where pecan trees have been removed to construct a building, the soil where the pecan tree was removed has swelled, causing significant damage to the interior of the structures. Pecan trees existing near a building have caused less differential movement during extended dry periods than other trees, probably because the tap root obtains a large amount of the trees’ water requirement from the “water bearing strata” usually found within 20 feet of the surface. Root barriers between pecan trees and similar type trees do have the effect of reducing shrinking of the soil on which a building rests.\nWhen there is a desire to improve the out-of-levelness of a structure by rehydration of the supporting soil and there are large trees involved, there must be a root barrier installed. Releveling in this case can be accelerated by the installation of a foundation watering system . The watering system should be arranged to supply water uniformly around the foundation of a structure during extended dry periods. The moisture level of the soil should be maintained at an optimum condition so that there is no ponding water or overly saturated soil. This condition at present appears to be a subjective judgment on the part of the watering system operator. The moisture provided must be enough to prevent the soil from shrinking during extended dry periods, but free water should not be allowed to accumulate at the perimeter or underside of a foundation.\nInstallation of a root cap, root barrier, or root wall should be undertaken by a qualified tree expert if there is concern for the health of the tree whose roots are to be cut. Most tree experts in the Houston area have installed root walls and are familiar with their effect on trees. If a root barrier is installed between a tree and a structure where the tree is surrounded by large areas of flatwork concrete, or other buildings, there may be insufficient moisture for the tree to continue to live.\nThe installation of root barriers should always be implemented as part of a foundation maintenance program. General guidelines for care and maintenance for foundation on expansive clay soil can be found by reviewing our Foundation Care Document.","Are cities getting hotter? As cities add roads, buildings, industry, and people, temperatures in the city rise relative to their rural surroundings, creating a heat island. These urban heat islands may be up to 10-15°F under optimum conditions. With increasing urban development, heat islands may increase in frequency and magnitude. Los Angeles, California, for example, has been 1˚F hotter every decade for the past 60 years. These heat islands have impacts that range from local to global scales and highlight the importance of urbanization to environmental change.\nWhat is an urban heat island?\nAn urban heat island is the name given to describe the characteristic warmth of both the atmosphere and surfaces in cities (urban areas) compared to their (nonurbanized) surroundings. The heat island is an example of unintentional climate modification when urbanization changes the characteristics of the Earth’s surface and atmosphere.\nAre there different types of urban heat islands?\nThere are three types of heat islands:\n- canopy layer heat island (CLHI)\n- boundary layer heat island (BLHI)\n- surface heat island (SHI)\nThe first two refer to a warming of the urban atmosphere; the last refers to the relative warmth of urban surfaces. The urban canopy layer (UCL) is the layer of air closest to the surface in cities, extending upwards to approximately the mean building height (Figure 1). Above the urban canopy layer lies the urban boundary layer, which may be 1 kilometer (km) or more in thickness by day, shrinking to hundreds of meters or less at night (Figure 1).1 It is the BLHI that forms a dome of warmer air that extends downwind of the city. Wind often changes the dome to a plume shape.\nSchematic depiction of the main components of the urban atmosphere.\nHeat island types vary in their spatial form (shape), temporal (related to time) characteristics, and some of the underlying physical processes that contribute to their development. Scientists measure air temperatures for CLHI or BLHI directly using thermometers, whereas the SHI is measured by remote sensors mounted on satellites or aircraft. 2,3\nWhat are the characteristics of heat islands?\nOverall spatial form (shape) of the heat island\nThe isotherms, or lines of equal temperature, form a pattern that resembles an “island” loosely following the shape of the urbanized region, surrounded by cooler areas (Figure 2). There is often a sharp rise in the canopy-layer air temperature at the boundary of rural—suburban areas, followed by a slow and often variable increase towards the downtown core of the urban area where the warmest temperatures occur. The boundary layer heat island shows much less variability than the other heat island types and a cross-section shows its shape resembles a simple dome or plume with warmer air transported downwind of the city.\nUrban heat island characteristics.\nHeat island intensity\nHeat island intensity is a measure of the strength or magnitude of the heat island. At night, the intensity of the canopy layer heat island is typically in the range of 1° to 3°C, but under optimum conditions intensities of up to 12°C have been recorded.4 The BLHI tends to maintain a more constant heat island intensity both day and night (~1.5° to 2°C). The SHI is usually most distinct during the day when strong solar heating can lead to larger temperature differences between dry surfaces and wet, shaded, or vegetated surfaces.\nSurface characteristics and the heat island\nThe nature of the surface is a strong factor on the spatial patterns of surface and canopy layer air temperature in the city. The temperatures are higher in more densely built up areas, and lower near parks or more open areas (Figure 2). Surface temperatures are particularly sensitive to surface conditions: during daytime, dry, dark surfaces that strongly absorb sunlight become very hot, while lighter and/or moist surfaces are much cooler.2,3 Shading of the surface also helps control the temperature. (For visual examples of the surface heat island, see the “learn more” link, EPA Heat Island Pilot Project, at the end of the article.)\nTemporal form of the heat island\nAll heat islands form because of the differences in the rates of warming and cooling of cities relative to their surroundings.\n- CLHI: the heat island intensity increases with time from sunset to a maximum somewhere between a few hours after sunset to the predawn hours. During the day the CLHI intensity is typically fairly weak or sometimes negative (a cool island) in some parts of the city where there is extensive shading by tall buildings or other structures and a lag in warming due to storage of heat by building materials.\n- SHI: is strongly positive both day and night due to warmer urban surfaces. Daytime SHI is usually largest because solar radiation affects surface temperatures.\n- BLHI: is generally positive both day and night but much smaller in magnitude than CLHI or SHI.\nHow do heat islands form and how are they controlled?\nA number of factors contribute to the occurrence and intensity of heat islands; these include\n- geographic location\n- time of day and season\n- city form\n- city functions\nWeather, particularly wind and cloud, influences formation of heat islands. Heat island magnitudes are largest under calm and clear weather conditions. Increasing winds mix the air and reduce the heat island. Increasing clouds reduce radiative cooling at night and also reduce the heat island. Seasonal variations in weather patterns affect heat island frequency and magnitude.\nGeographic location influences the climate and topography of the area as well as the characteristics of the rural surroundings of the city. Regional or local weather influences, such as local wind systems, may impact heat islands; for example, coastal cities may experience cooling of urban temperatures in the summer when sea surface temperatures are cooler than the land and winds blow onshore. Where cities are surrounded by wet rural surfaces, slower cooling by these surfaces can reduce heat island magnitudes, especially in warm humid climates.5\nTime of day/season: Daytime impacts were discussed in the section called “Temporal form of the heat island.” Seasons play a role, too. Heat islands of cities located in the mid latitudes usually are strongest in the summer or winter seasons. In tropical climates, the dry season may favor large heat island magnitudes.\nCity form comprises the materials used in construction, the surface characteristics of the city such as the building dimensions and spacing, thermal properties, and amount of greenspace. Heat island formation is favored by\n- relatively dense building materials that are slow to warm and cool and store a lot of energy\n- replacement of natural surfaces by impervious or waterproofed surfaces, leading to a drier urban area, where less water is available for evaporation, which offsets heating of the air\n- lower surface reflectivity to solar radiation — dark surfaces such as asphalt roads absorb more sunlight and become much warmer than light-colored surfaces\nCity functions govern the output of pollutants into the urban atmosphere, heat from energy usage, and the use of water in irrigation. Anthropogenic heat, or heat generated from human activities, primarily fossil fuel combustion, can be important to heat island formation.6 Anthropogenic heating usually has the largest impact during the winter season of cold climates in the downtown core of the city.7 In select cases, very densely developed cities may have significant summertime anthropogenic heating that results from high energy use for building cooling.7\nHow do heat islands impact cities?\nHeat islands have a range of impacts for city dwellers,4 including\n- human comfort: positive (winter), negative (summer)\n- energy use: positive (winter), negative (summer)\n- air pollution: negative\n- water use: negative\n- biological activity (e.g., growing season length): positive\n- ice and snow: positive\nSummer heat islands can increase the demand for energy for air conditioning, which releases more heat into the air as well as greenhouse gas emissions, degrading local air quality.8 Higher urban temperatures in the daytime BLHI may increase the formation of urban smog, because both emissions of precursor pollutants and the atmospheric photochemical reaction rates increase.9,10 Heat islands may also directly impact human health by exacerbating heat stress during heat waves, especially in temperate areas, and by providing conditions suitable for the spread of vector-borne diseases.11,12\nBiological solutions for alleviating urban heat islands?\nThe understanding of the physical mechanisms underlying heat island formation provides a basis to develop controls that may promote or alleviate heat islands, but in some cases the application of these controls is difficult. For example, widespread change of the urban surface geometry by spacing buildings is usually not feasible. However, other strategies are possible— for example, using white or other light-colored roofs and pavement.\nA biologically related solution is to use vegetation to reduce urban heat. Vegetation provides important shading effects as well as cooling through evaporation. Some examples include:\n- Planting trees around individual buildings to shade urban surfaces to reduce their temperature, especially roofs and south-, east-, and west-facing walls. The reduction in surface temperature also leads to substantial reductions in energy use for air conditioning.\nTrees can also be used to shade roads and parking lots, which would otherwise become very hot during the day and which store heat for later release at night. Shading of vehicles in parking lots can reduce evaporative emissions from gasoline, which contribute to increased levels of urban ozone.\n“Green roofs” use living vegetation on roofs in order to help reduce heat accumulation of buildings. For example, the city of Chicago has more than 80 municipal and private green roofs as of June 2004, including the first municipal green roof in the country, the City Hall rooftop garden. A green roof is much cooler than a traditional roof because a significant fraction of the absorbed energy is used to evaporate water rather than to heat the roof and the overlying air.\nCreation of greenspace such as parks can be used to assist in cooling of neighborhoods,13,14 and an overall greening of the city can lead to a cooler urban atmosphere.15\nThese strategies can provide cost benefits. A building owner benefits from reduced energy consumption costs. Residents downwind of the urban area benefit from air quality improvements because:\n- pollutants are deposited on trees\n- greenhouse gas and pollutant emissions from air conditioning use are reduced\n- emissions of volatile organic compounds that contribute to urban smog are lessened\n- the rate of ozone formation is potentially reduced\nThe US Environmental Protection Agency has undertaken the Urban Heat Island Pilot Project as part of the Heat Island Reduction Initiative. Pilot cities include Baton Rouge, Chicago, Houston, Sacramento, and Salt Lake City.\nDo urban heat islands affect global climate?\nUrban heat islands themselves are not responsible for global warming because they are small-scale phenomena and cover only a tiny fraction of the Earth’s surface area. However, there are some urban to global scale connections that are worth noting:\nApproximately half of the world’s population currently lives in cities, and this value is expected to increase to 61% by 2030.16 The high rate of urbanization, particularly in the tropics, means that increasing numbers of people will be exposed to impacts resulting from heat islands in the future.\nUrban areas have historically been the site of some of the earliest established observation stations that are used to help construct the global surface temperature record used to document large scale climate changes. The effects of urbanization, and consequently urban heat islands, on these stations over time can lead to some “contamination” of the temperature record. The ability to fully remove these influences remains the subject of some debate since changes can occur independently of population17 and current techniques used to remove urban effects may be inadequate.17-19\nMost greenhouse gas emissions that contribute to global climate change come from urban areas. These emissions therefore contribute to both local and global scale weather and climate modification.20 Further urbanization will increase emissions originating from cities. Investigation of the larger scale impacts of urban emissions is seen as an important area of future research.20\nThe climate modifications that have occurred in large cities over the past century show similarities in terms of the rates and magnitude expected with projected future climate changes. Therefore cities may serve as a model for assessing the impacts of, and adaptation strategies to, climate change on both local and global scales.4\nThese factors underscore the importance of urban climates not only to the local environment but also to the state of the environment for the planet as a whole.\n© 2004, American Institute of Biological Sciences. Educators have permission to reprint articles for classroom use; other users, please contact firstname.lastname@example.org for reprint permission. See reprint policy."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:8e58b71a-addd-443c-a416-035fa8eb9a28>","<urn:uuid:57936910-cc8f-43d8-bd9e-a24d5cb65413>"],"error":null}
{"question":"How do formaldehyde and nucleotide excision repair (NER) differ in their roles in DNA damage and repair?","answer":"Formaldehyde and nucleotide excision repair (NER) represent different aspects of DNA damage and repair mechanisms. Formaldehyde acts as a DNA-damaging agent that, if left unchecked, can harm DNA. However, cells have two tiers of protection against formaldehyde: the enzyme ADH5 that detoxifies it, and DNA repair mechanisms. In contrast, NER is itself a repair mechanism that specifically recognizes and fixes DNA damage caused by bulky lesions. The NER process involves multiple proteins working together to recognize distortions in DNA structure, remove damaged segments through precise incisions, and restore the DNA through repair synthesis using the undamaged strand as a template.","context":["Cell growth requires the synthesis of molecules, such as nucleotides to make DNA and amino acids to make proteins. One essential building block of these is the one carbon unit. This is produced by the one carbon (1C) cycle, which requires the vitamin folate and the amino acid serine (the main source of the 1C unit). 1C metabolism is important for human health, and folate deficiency causes birth defects, nerve damage and anaemia. However, recent research by KJ Patel’s group in the LMB’s PNAC Division, in collaboration with Alexei Vazquez at the CRUK Beatson Institute in Glasgow and Chris Chang from the University of Berkeley, has shown that folate is also a source of formaldehyde – the well-known preservative and toxin – which if left unchecked damages DNA. Conversely, detoxification of formaldehyde can result in the production of essential molecules needed for cell growth. Thus, folate and formaldehyde have two faces: a beneficial side because they provide some of the chemical building blocks for cells to live and grow, and a dangerous side because they damage DNA.\nPrevious work from KJ Patel’s lab had shown that mammals are continuously producing the toxin formaldehyde. They further showed that when the protection against this molecule is removed in mice then the levels of endogenous formaldehyde rise leading to overwhelming DNA damage and rapid death. Our cells possess two tiers of protection against this endogenously produced formaldehyde: the first tier consists of an enzyme called alcohol dehydrogenase 5 (ADH5) that detoxifies it, the second tier or essential backup is DNA repair which fixes the damage done to chromosomes by formaldehyde. In this most recent work the scientists uncover where and how in our bodies some of this formaldehyde comes from. They further show that as the cell processes formaldehyde using tier 1 protection, it essentially converts this violent reactive chemical into a molecule that is eventually used to make DNA.\nGuillermo Burgos Barragan and Niek Wit from KJ’s group, assisted by Alexie Vasquez’s lab, used a combination of genetics, biochemistry and metabolic analysis to show that tetrahydrofolate (THF), the active form of folate, and other folate derivatives can cause DNA damage by decomposing to produce formaldehyde. Using powerful gene editing technology they created cells where the 1C cycle is inactivated, and using these cells they confirmed that the release of formaldehyde following THF exposure was because of the decomposition of the vitamin rather than its role in stimulating the 1C cycle. The 1C cycle is essential for cellular life and the cells that Guillermo Burgos Barragan and Niek Wit created where this cycle does not function do not grow unless they are provided the end products of the cycle in their growth medium. However, if these factors are removed and replaced with just formaldehyde then remarkably these defective cells are able to grow. This is because the tier 1 protection enzyme ADH5 converts the toxic formaldehyde into formate, a much less reactive chemical that cells use to make some of the building blocks of life that the normal 1C cycle was previously capable of making. Furthermore, using a combination of formaldehyde isotope labelling with mass spectrometry, this formaldehyde can be traced into the creation of the bases that make DNA.\nThis new research has several implications. Formaldehyde, which is apparently ubiquitous in our environment and lifestyles, is a well-known toxin to humans. However, most of this chemical comes from within our bodies and this work identifies how and where some of this formaldehyde is coming from. Moreover, this endogenously produced formaldehyde is harnessed by our cells to produce some of the building blocks of life – a process by which a dangerous reactive toxin is converted into a benign and useful chemical. Finally, targeting the physiological source of 1C units has been believed to be a promising target in cancer cells, however this study now suggests that such cells may be able to bypass such approaches by using the new formaldehyde cycle discovered in this work.\nThis work was funded by the MRC, Cancer Research UK and the Wellcome Trust.\nPaper in Nature\nKJ’s group page\nAlexei Vazquez’s group page\nChris Chang’s group page\nMRC Press Release\nPrevious Insight on Research article: A fundamental protection mechanism against formalin in mammals is revealed","nucleotide excision repair\nWednesday 19 November 2003\nDefinition: Nucleotide excision repair is a DNA repair mechanism. It is a process carried out by mammalian cells that involves the recognition, removal and resynthesis of the restored DNA following DNA damage by bulky lesions.\nNucleotide excision repair (NER) is one of several DNA repair mechanisms by which damaged bases are removed from the genome. The process incorporates the excision of such bases as part of an oligonucleotide fragment, in contrast to base excision repair (BER), by which damaged or inappropriate bases are excised as a free base, or mismatch repair (MMR), by which mispaired bases are excised as single nucleotides.\nNER in human cells is a complex biochemical process that requires several proteins (See components). The human proteins required for NER assemble in an ordered, stepwise fashion at sites of base damage that are substrates for NER.\nThis assembly generates a large multiprotein complex, sometimes referred to as the nucleotide excision repairosome.\nStudies in yeast, an informative model for many aspects of NER in humans, indicate that some of this complex might be preassembled in cells not deliberately exposed to DNA damage. However, the conclusions of these studies have proved controversial.\nThe repair complex is a versatile ’NER machine’ that can recognize many types of base damage that often bear little, if any, structural or chemical similarity, incise (nick) DNA at precise distances on either side of the base damage exclusively on the damaged DNA strand, and excise oligonucleotide fragments that include the base damage.\nEukaryotic cells can repair many types of DNA damage. Among the known DNA repair processes in humans, one type - nucleotide excision repair (NER) - specifically protects against mutations caused indirectly by environmental carcinogens. Humans with a hereditary defect in NER suffer from xeroderma pigmentosum and have a marked predisposition to skin cancer caused by sunlight exposure.\nDNA constantly requires repair due to chemical damage that can occur to bases, and nucleotide excision repair (NER) and base excision repair (BER) are mechanisms by which the cell can prevent unwanted mutations caused by base damage.\nWhile the base excision repair (BER) machinery recognizes specific lesions in the DNA and can correct only damaged bases that can be removed by a specific DNA glycosylase, the nucleotide excision repair enzymes recognize distortions in the shape of the DNA double helix.\nRecognition of these distortions leads to the removal of a short single-stranded DNA segment that includes the lesion, creating a single-strand gap in the DNA, which is subsequently filled in by DNA polymerase, which uses the undamaged strand as a template.\nSteps of the NER system\nThe essential features of nucleotide excision repair.\n1. Nucleotide excision repair (NER) operates on base damage caused by exogenous agents (such as mutagenic and carcinogenic chemicals and photoproducts generated by sunlight exposure) that cause alterations in the chemistry and structure of the DNA duplex .\n2. Such damage is recognized by a protein called XPC, which is stably bound to another protein called HHRAD23B.\n3. The binding of the XPC-HHRAD23 heterodimeric subcomplex is followed by the binding of several other proteins, as XPA, RPA, TFIIH and XPG. XPA and RPA are believed to facilitate specific recognition of base damage. TFIIH is a subcomplex of the RNA polymerase II transcription initiation machinery which also operates during NER.\nIt consists of six subunits and contains two DNA helicase activities (XPB and XPD) that unwind the DNA duplex in the immediate vicinity of the base damage.\nThis local denaturation generates a bubble in the DNA, the ends of which comprise junctions between duplex and single-stranded DNA.\n4. The subsequent binding of the ERCC1-XPF heterodimeric subcomplex generates a completely assembled NER multiprotein complex.\n5. XPG is a duplex/single-stranded DNA endonuclease that cuts the damaged strand at such junctions 3’ to the site of base damage. Conversely, the ERCC1-XPF heterodimeric protein is a duplex/single-stranded DNA endonuclease that cuts the damaged strand at such junctions 5’ to the site of base damage.\nThis bimodal incision generates an oligonucleotide fragment 27-30 nucleotides in length which includes the damaged base.\n6. This fragment is excised from the genome, concomitant with restoring the potential 27-30 nucleotide gap by repair synthesis. Repair synthesis requires DNA polymerases or , as well as the accessory replication proteins PCNA, RPA and RFC. The covalent integrity of the damaged strand is then restored by DNA ligase.\n7. Collectively, these biochemical events return the damaged DNA to its native chemistry and configuration.\nMutations in genes on the nucleotide excision repair pathway (NER system) are associated with diseases, such as xeroderma pigmentosum, Cockayne syndrome and trichothiodystrophy, that involve skin cancer and developmental and neurological symptoms.\nThese mutations cause the defective repair of damaged DNA and increased transcription arrest but, except for skin cancer, the links between repair and disease have not been obvious.\nWidely different clinical syndromes seem to result from mutations in the same gene, even when the mutations result in complete loss of function.\nThe mapping of mutations in recently solved protein structures has begun to clarify the links between the molecular defects and phenotypes, but the identification of additional sources of clinical variability is still necessary.\nNucleotide-excision repair diseases exhibit cancer, complex developmental disorders and neurodegeneration.\nCancer is the hallmark of xeroderma pigmentosum (XP), and neurodegeneration and developmental disorders are the hallmarks of Cockayne syndrome and trichothiodystrophy.\nA distinguishing feature is that the DNA-repair or DNA-replication deficiencies of XP involve most of the genome, whereas the defects in CS are confined to actively transcribed genes.\nMany of the proteins involved in repair are also components of dynamic multiprotein complexes, transcription factors, ubiquitylation cofactors and signal-transduction networks. Complex clinical phenotypes might therefore result from unanticipated effects on other genes and proteins.\nThe fact that these three different diseases (XP, CS and TTD) may be mutated in the same genes (as is the case of XPB, XPD and XPG) is intriguing.\nThe clinical symptoms of these genetic disorders are distinct specially concerning the increased frequency of skin tumors, observed in XP but not in CS or TTD patients.\nThese different symptoms may simply express differences in the abilities of the mutated cells to perform either DNA repair or transcription, depending on the mutation on the gene.\nHowever, recent data have shone some light onto this very interesting question. Working with cells derived from XPG patients associated or not with CS, Cooper et al. (1997) have found evidence that the developmental CS defects may be due to a defective preferential repair of active genes by oxidative damage.\nOn the other hand, Ahrens et al. (1997) have found that the high risk of cancer in XPD patients may be due to a decreased immunological response to UVB irradiation, not found on cells from TTD patients (mutated in the same XPD gene).\nThe author propose that the XPD protein might have a transcriptional role controlling the expression of immunological relevant genes. Thus, mutations that affect this control (such as those found in XP patients, but not in TTD) may increase the skin cancer risk.\nPathology (nucelotide excision repair diseases)\nIn these diseases, the nucleotide-excision repair pathway (NER) does not remove UV-induced DNA lesions efficiently.\ngermline mutations in ERCC1 have been reported in (cerebrooculofacioskeletal syndrome 4) (cerebro-oculo-facio-skeletal syndrome 4) (COFS4). (17273966)\nJaspers NG, Raams A, Silengo MC, Wijgers N, Niedernhofer LJ, Robinson AR, Giglia-Mari G, Hoogstraten D, Kleijer WJ, Hoeijmakers JH, Vermeulen W. First reported patient with human ERCC1 deficiency has cerebro-oculo-facio-skeletal syndrome with a mild defect in nucleotide excision repair and severe developmental failure. Am J Hum Genet. 2007 Mar;80(3):457-66. PMID: 17273966\nThe NER pathway\n< object width=\"425\" height=\"350\"> < param name=\"movie\" value=\"http://www.youtube.com/v/9hEAr8On0ow\"> < /param> < param name=\"wmode\" value=\"transparent\"> < /param> < embed src=\"http://www.youtube.com/v/9hEAr8On0ow\" type=\"application/x-shockwave-flash\" wmode=\"transparent\" width=\"425\" height=\"350\"> < /embed> < /object>\nDisorders of nucleotide excision repair: the genetic and molecular basis of heterogeneity. Cleaver JE, Lam ET, Revet I. Nat Rev Genet. 2009 Nov;10(11):756-68. PMID: 19809470\nde Boer J, Hoeijmakers JH. Nucleotide excision repair and human syndromes. Carcinogenesis. 2000 Mar;21(3):453-60. PMID: 10688865"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:b6184d3c-4045-4215-a8b2-ef8622d50aa3>","<urn:uuid:588de907-98fc-4462-835f-58d1a3af63d5>"],"error":null}
{"question":"What's the key difference in sugar content between sugarcane and sugar beet, and how does this compare to the amount of sugar that remains in molasses during the processing stage?","answer":"Sugarcane contains approximately 20% sugar while sugar beet contains about 17% sugar. During processing, the molasses (which is the juice left over after crystallization) contains roughly equal amounts of sugar and nonsugars, with some sugar remaining in it because it's not economically feasible to remove it further.","context":["A nonreducing disaccharide composed of GLUCOSE and FRUCTOSE linked via their anomeric carbons. It is obtained commercially from SUGARCANE, sugar beet (BETA VULGARIS), and other plants and used extensively as a food and a sweetener. Sweetening agent and food source assimilated by most organisms. Also used in food products as a preservative, antioxidant, moisture control agent, stabiliser and thickening agent. Widespread in seeds, leaves, fruits, flowers and roots of plants, where it functions as an energy store for metabolism and as a carbon source for biosynth. Annual world production is in excess of 90 x 106 tons mainly from the juice of sugar cane and sugar beet which contain respectively ca. 20% and ca. 17% of the sugar Sugar is the generalised name for a class of chemically-related sweet-flavored substances, most of which are used as food. They are carbohydrates, composed of carbon, hydrogen and oxygen. There are various types of sugar derived from different sources. Simple sugars are called monosaccharides and include glucose (also known as dextrose), fructose and galactose. The table or granulated sugar most customarily used as food is sucrose, a disaccharide (in the body, sucrose hydrolyses into fructose and glucose). Other disaccharides include maltose and lactose. Chemically-different substances may also have a sweet taste, but are not classified as sugars. Some are used as lower-calorie food substitutes for sugar described as artificial sweeteners. Sugars are found in the tissues of most plants but are only present in sufficient concentrations for efficient extraction in sugarcane and sugar beet. Sugarcane is a giant grass and has been cultivated in tropical climates in the Far East since ancient times. A great expansion in its production took place in the 18th century with the setting up of sugar plantations in the West Indies and Americas. This was the first time that sugar became available to the common people who had previously had to rely on honey to sweeten foods. Sugar beet is a root crop and is cultivated in cooler climates and became a major source of sugar in the 19th century when methods for extracting the sugar became available. Sugar production and trade has changed the course of human history in many ways. It influenced the formation of colonies, the perpetuation of slavery, the transition to indentured labour, the migration of peoples, wars between sugar trade-controlling nations in the 19th century, and the ethnic composition and political structure of the new world. The world produced about 168 million tonnes of sugar in 2011. The average person consumes about 24 kilograms of sugar each year (33.1 kg in industrialised countries), equivalent to over 260 food calories per person, per day. Sugar provides energy but no nutrients—empty calories. Since the latter part of the twentieth century, it has been questioned whether a diet high in sugars, especially refined sugars, is bad for health. Sugar has been linked to obesity and suspected of being implicated in diabetes, cardiovascular disease, dementia, macular degeneration and tooth decay. Numerous studies have been undertaken to try to clarify the position but the results remain largely unclear, mainly because of the difficulty of finding populations for use as controls that do not consume sugars.","Basic Processing Overview\nThree flow diagrams are included in this basic processing overview. The simplified process flow diagram shows the path the beets take through the factory to become end products. It also shows where some of the other expensive raw materials and supplies are used. The diffusion flow diagram shows where the water insoluble nonsugars are separated from the rest of the beet. The sugar end flow diagram shows all the product flows on the sugar end.\nThe bar graph shows the composition of the beets, some intermediate products, and the end products, in terms of sugar, water, water soluble nonsugars, and water insoluble nonsugars. A nonsugar is any substance that is not sugar (sucrose) or water. Water soluble means that a substance will dissolve in water. Sugar is water soluble because it will dissolve in water. Sulfate, phosphate, sodium, and potassium will all dissolve in water, so they are water soluble nonsugars. Cellulose, a main component of sugarbeets, will not dissolve in water, so it is a water insoluble nonsugar.\nThe bar graph also shows how much intermediate or end product results from processing each 100 tons of beets. The bars for the intermediate products correspond directly with the lines between the processes on the flow diagram. For example, 100 tons of clean, sliced beets entering diffusion (along with several tons of water), yields two intermediate products, 44 tons of wet pulp and 110 tons of raw juice. As the wet pulp travels through the pulp presses, the pulp dryer, and the pellet mills, it becomes pressed pulp, dry pulp, and pellets. As the raw juice travels through carbonation and evaporation, it becomes thin juice and thick juice, which is the input for the crystallization process.\nMaking sugar from sugar beets involves four basic processing steps: diffusion, carbonation, evaporation, and crystallization. All of these steps are separation processes.\nDiffusion involves the separation of the water insoluble nonsugars from the rest of the beet. Most of the soluble components of the beet are dissolved in water and form raw juice. The raw juice is removed through a screen and what is left is the insoluble portion of the beet, the wet pulp.\nCarbonation involves the separation of some of the water soluble nonsugars from raw juice. Only about 28% of the water soluble nonsugars are actually removed in this step, but many others are destroyed or converted into compounds that are easier to process in later steps.\nEvaporation involves the separation of water from thin juice. Over 100 tons of water must be evaporated for every 100 tons of beets sliced. To evaporate that much water, tremendous amounts of heat must be supplied. The heat is supplied by coal and carried to the evaporators in the form of steam. The coal for evaporation costs the company more than any other process supply. The quadruple effect evaporator block diagram shows the evaporation process with thin juice entering the system and thick juice being the final product in this stage of operations.\nCrystallization involves the separation of sugar from the thickened juice. The juice left over after crystallization is called molasses. It contains the remaining nonsugars and about an equal amount of sugar, which, economically, is not feasible to remove.\nBecause these processes and products are referred to so many times in terms of the amounts of sugar, water, water soluble nonsugars, and water insoluble nonsugars they contain, special names have been given to the ratios of the amounts of one of these components to the other or others. Percent sugar is one of these terms and its name pretty much explains what it means. It is the percent of the total weight of a substance that is sugar. If the average percent sugar of beets is 17.00, that means there are 17.00 tons of sugar in each 100 tons of average cleaned beets. If pellets average 5.80 percent sugar, there are 5.80 tons of sugar in each 100 tons of average pellets produced. Percent sugar is measured with an instrument called a polarimeter.\nAnother important ratio is the percent of the total weight of a substance that is dry (not water). Depending on what substance is being tested and what method is being used to measure it, this ratio is called percent solids, percent dry substance, refractometer dry substance (RDS), or degrees Brix. When the dry substance of a juice is being measured, and all the solids are soluble, an instrument called a refractometer is usually used. Most juices’ dry substance are expressed in RDS. When measuring the dry substance of a material where the solids are not soluble, an evaporative method is usually used and the answer is expressed as percent solids or simply, dry substance. The evaporative method is used on pulp and pellets, and is performed by weighing a substance, evaporating all the water away, and then weighing the remaining dry substance.\nPercent moisture is the percent of the total weight of a substance that is water. It is measured by the same methods as percent dry substance and is equal to 100 minus the dry substance.\nPurity is the percent of the dissolved solids in a solution that is sugar. The key word in this definition is dissolved. Water insoluble nonsugars do not dissolve in water, so purity is not affected by water insoluble nonsugars. Purity then, is the ratio of the weight of sugar in a substance to the weight of sugar plus water-soluble nonsugars in the substance, expressed as a percent. If one hundred tons of beets contain 17.00 tons of sugar and 2.54 tons of water-soluble nonsugars, the purity is 17.00 divided by the quantity of 17.00 plus 2.54 or, 87.00 percent. The purity of a juice can be calculated if the RDS and the percent sugar is known. Since percent sugar indicates the relative weight of the sugar, and RDS indicates the relative weight of dissolved solids, purity equals the percent sugar divided by the RDS. An example is thick juice, which might be 50 percent sugar and have an RDS of 55. The purity is 50 divided by 55 or 90.9 percent purity."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:e97c338d-0545-41a0-adc1-f65fbbf6ca07>","<urn:uuid:9b4be01f-f207-4879-b2d4-21d71e2c4406>"],"error":null}
{"question":"What are the implications for genetic diversity in both intermittent stream invertebrates and tropical rainforest plants when their dispersal mechanisms are disrupted?","answer":"In both ecosystems, disruption of dispersal mechanisms threatens genetic diversity. For intermittent stream invertebrates, frequent drought refuges providing strong connectivity through stream flow or continuous terrestrial vegetation are critical to maintain genetic diversity, adaptability, and population persistence. Most invertebrate species are limited to relatively short dispersal distances (km). Similarly, in tropical rainforests, the disruption of animal-mediated seed and pollen dispersal can affect genetic and ecological diversity within and among plant populations, with anthropogenic forces potentially disrupting these crucial dispersal processes.","context":["Drought survival strategies, dispersal potential and persistence of invertebrate species in an intermittent stream landscape\nChester, E.T., Miller, A.D., Valenzuela, I., Wickson, S.J. and Robson, B.J. (2015) Drought survival strategies, dispersal potential and persistence of invertebrate species in an intermittent stream landscape. Freshwater Biology, 60 (10). pp. 2066-2083.\n*Subscription may be required\nIntermittent stream systems create a mosaic of aquatic habitat that changes through time, potentially challenging freshwater invertebrate dispersal. Invertebrates inhabiting these mosaics may show stronger dispersal capacity than those in perennial stream systems. To relate different combinations of dispersal and drought survival strategies to species persistence, we compared the distribution and dispersal potential of six invertebrate species across all streams in a montane landscape where drying is becoming increasingly frequent and prolonged. Invertebrates were collected from seventeen streams in the Victoria Range, Grampians National Park, Victoria, Australia. The species analysed were as follows: the caddisflies Lectrides varians Moseley (Leptoceridae) and Agapetus sp. (Glossosomatidae); the mayflies Nousia AV1 and Koorrnonga AV3 (Leptophlebiidae); the water penny beetle Sclerocyphon sp. (Psephenidae); and a freshwater crayfish Geocharax sp. nov. 1 (Parastacidae). These species were widespread in the streams and varied in their dispersal and drought survival strategies. The distribution of each species across the Victoria Range, their drought responses and within-stream habitat associations were determined. Hypotheses of the dispersal capacity and population structure for each species were developed and compared to four models of gene flow: Death Valley Model (DVM), Stream Hierarchy Model (SHM), Headwater Model (HM) or panmixia (PAN). Molecular genetic methods were then used to infer population structure and dispersal capacity for each species. The large caddisfly Lectrides resisted drought through aestivation and was panmictic (PAN) indicating strong dispersal capacity. Conversely, the small caddisfly Agapetus relied on perennially flowing reaches and gene flow was limited to short distances among stream headwaters, resembling the HM. Both mayflies depended on perennial surface water during drying and showed evidence of gene flow among streams: Koorrnonga mainly dispersed along stream channels within catchments, resembling the SHM, whereas Nousia appeared to disperse across land by adult flight. Sclerocyphon relied on perennial water to survive drying and showed an unusual pattern of genetic structure that indicated limited dispersal but did not resemble any of the models. Geocharax survived drought through aestivation or residence in perennial pools, and high levels of genetic structure indicated limited dispersal among streams, resembling the DVM. Despite good knowledge of species' drought survival strategies, the population structure of four species differed from predictions. Dispersal capacity varied strongly among species; most species were poor dispersers and only one species showed panmixia. Therefore, intermittent stream species may not necessarily be better dispersers than those in perennial streams. Species showing strong drought resistance strategies differed in dispersal capacity. Knowledge of life-history characteristics, distribution and refuge use does not necessarily enable successful prediction of invertebrate dispersal pathways or population structure. Dispersal among intermittent streams may be restricted to relatively short distances (km) for most invertebrate species. Thus, frequent drought refuges (perennial water) that provide strong connectivity to subpopulations through stream flow (hydrological dispersal), or continuous terrestrial vegetation (flight dispersal), will be critical to maintain genetic diversity, adaptability and population persistence.\n|Publication Type:||Journal Article|\n|Murdoch Affiliation:||School of Veterinary and Life Sciences|\n|Publisher:||Blackwell Publishing Ltd|\n|Copyright:||© 2015 John Wiley & Sons Ltd.|\n|Item Control Page|","In tropical rainforests the vast majority of plant species rely on animals to disperse their seeds and pollen. Our lab seeks to provide new answers to the long-standing questions of how and why different animals vary in the dispersal services they provide, and what the consequences are for plant species and communities. These questions are of fundamental importance for evolutionary ecologists because seed and pollen dispersal determine patterns of genetic and ecological diversity within and among plant populations. They also have important conservation consequences, since better understanding these relationships will help predict how global change may upset these mutualisms.\nOur research combines genetic analyses of dispersed seeds and pollen; various approaches to animal tracking including radio-telemetry and GPS tags; and field-based observation and experimentation to address these questions in the Chocó rainforests of northwest Ecuador. Here, we have generated a longitudinal data set of molecular and field data, with a particular focus on seed dispersal of the canopy palm tree Oenocarpus bataua by long-wattled umbrellabirds, a large, lek-breeding bird.\nPh.D. student Luke Browne is expanding the work in Ecuador by assessing the the influence of frugivores in creating lasting spatial and genetic patterns in Oenocarpus. He is also interested in understanding and predicting what happens when pollen and seed dispersal is disrupted by anthropogenic forces. In Peruvian cloud forest, Ph.D. candidate Jenny Hazlehurst is researching how interactions between hummingbirds (which provide pollination services) and flowerpiercers (which rob nectar from the base of flowers without providing pollination services) affect pollination biology of the plant Oreocallis grandiflora.\nBrowne, L., K. Ottewell, and J. Karubian. 2015. Short-term genetic consequences of habitat loss and fragmentation for the neotropical palm Oenocarpus bataua. Heredity. doi: 10.1038/hdy.2015.35. PDF\nKarubian, J. and R. Durães. Impacts of mating behavior on plant-animal seed dispersal mutualisms: a case study from a Neotropical lek-breeding bird. In Sexual Selection: Insights from the Neotropics (eds. R. Macedo and G. Machado). Elsivier Press. Pp. 365-390. PDF\nKraul, C. 2013. Ecology in Action. Tulanian Magazine. PDF – News piece on work in Ecuador\nScofield, D.G., P.E. Smouse, J. Karubian and V.L. Sork. 2012. Using alpha, beta, and gamma diversity to characterize seed dispersal by animals: social behavior matters. American Naturalist. PDF\nKarubian, J., L. Browne, C. Bosque, T. Carlo, M. Galetti, B.A. Loiselle, J.G. Blake, D. Cabrera, R. Durães, F.M. Labecca, K.M. Holbrook, R. Holland, W. Jetz, F. Kummeth, J. Olivo, K. Ottewell, G. Papadakis, G. Rivas, S. Steiger, B. Voirin, and M. Wikelski. 2012. Seed dispersal by Neotropical birds: emerging patterns and underlying processes. Neotropical Ornithology. PDF\nOttewell, K., E. Grey, F. Castillo, and J. Karubian. 2012. Direct parentage analysis reveals non-leptokurtic pollen dispersal in the insect-pollinated tropical palm Oenocarpus bataua. Heredity. doi: 10.1038/hdy.2012.40 PDF | Commentary | Podcast\nKarubian, J., R. Durães, J. Storey, and T.B. Smith. 2012. Mating behavior drives seed dispersal in the long-wattled umbrellabird Cephalopterus penduliger. Biotropica 44: 689-698. PDF *Recipient: 2013 Award for Excellence in Tropical Biology & Conservation\nKarubian, J. 2011. The Long-wattled Umbrellabid: the feathered gardeners of the Choco. Terra Incognita 72: 8-18. (July 2011) PDF\nKarubian, J., V.L. Sork, T. Roorda, R. Durães, and T.B. Smith. 2010. Destination-based dispersal by the long-wattled umbrellabird Cephalopterus penduliger homogenizes genetic structure of a tropical palm. Molecular Ecology 19: 1745-1753. PDF | Cover Page\nKarubian, J. 2010. Pompadours in the palms. Natural History Magazine. 119: 28-32. (February 2010) PDF\nKarubian, J. 2009. The secret life of the Long-wattled Umbrellabird. El Commercio Newspaper, Ecuador (May 10, 2009) PDF\nKarubian, J. and R. Durães. 2009. Effects of seed disperser social behavior on patterns of seed movement and deposition Oecologia Brasiliensis 13(1): 45-57. PDF"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:0940a752-0961-4985-a917-6fd12c4cee37>","<urn:uuid:053a413d-a742-4cf9-a2d4-799ebf40067a>"],"error":null}
{"question":"How do the themes of 'chosen ones' in The Lottery and The Red Badge of Courage compare in terms of their characters facing death?","answer":"While both stories deal with characters facing death, they approach it very differently. In The Lottery, the 'chosen one' is randomly selected through a community ritual and faces certain death by stoning from their own townspeople. In contrast, Henry Fleming in The Red Badge of Courage faces possible death in battle as a Union soldier in the Civil War, but his situation involves the opportunity for heroism - he transforms from being afraid of death to becoming courageous in battle. The Lottery presents death as an inevitable outcome of being chosen, while The Red Badge of Courage presents it as a risk that can be faced with bravery.","context":["I want to talk today a little bit about The Lottery by Shirley Jackson. Shirley Jackson is one of our great literary figures in terms of dark and horror fiction, and her short story – The Lottery – rocked the literary world when it first released in 1948. The Lottery first appeared in The New Yorker, and its surprise ending shocked so many readers that they unsubscribed from The New Yorker out of fear. But what we can take away from this is how intense great writing can be, and how important the short story is because of its ability to pack a punch in a matter of pages. Whether the audience’s reaction is positive or negative does not matter as long as the audience is moved in some way.\nBut I will save my discussion on the importance of short stories for another day. The purpose of today’s writing discussion is, indeed, the plot of The Lottery by Shirley Jackson, and how it has influenced modern literature.\nFor those who have not read this short story, I will summarize it for you. But I do encourage you to read the 8-page short story above!\nBeware SPOILERS ARE AHEAD.\nThe Lottery by Shirley Jackson is about a small town that holds a lottery every year. During the lottery, the townspeople all come together and draw a paper from a box. In the end, the person with a piece of paper that has a black dot on it is “the chosen one”. But in this story, being the chosen one is a death sentence. Immediately after the lottery ends, the chosen one is stoned to death by the townspeople.\nNow, there is not a lot of explanation in the short story about why the town uses this lottery method, other than the fact that it has been done for generations in the surrounding towns and that it is a tradition.\nBut what about this story caused such a stir? Well, think about the time period when this story was published America was on the brink of the 1950s and World War 2 had just ended three years prior. The country was trying to get back to a sense of normal with a focus on a just society and a stable family oriented community. Jackson rocked the boat by writing this story that portrayed a society trying to stick to tradition and keep a stable community, but she portrayed death as a constant in this society in such a gruesome manner. The story was about how a community painstakingly tried to stick with tradition and their rules and regulations, despite the repercussions. This shocked America at the time because it was during this period that America was trying hard to stick to their community values and traditions despite the effect that the war had on the country. This scared The New Yorker’s readers because The Lottery proposed that sticking with tradition and certain rules and regulations were not beneficial for society when the country was trying to return to values that had been a part of society pre-war. The moral of this thesis is that the effect of writing depends very much on the current state of the society when the story is published.\nWhile Jackson’s The Lottery did question society at the time, it also opened up the concept of “the chosen one” in literature. Since The Lottery, this concept has been used in numerous areas of literature since to question society as it changes. This concept has also been used to examine where our society might go in the future.\nSome of the best examples of this derivation from The Lottery are found in The Giver by Louis Lowry and The Hunger Games Trilogy by Suzanne Collins. Both of these works examine alternate societies as well as our future society, and they focus on a concept similar to The Lottery.\nIn The Giver, individuals are chosen to perform specific roles in the community when they come of age, and they are placed into families instead of choosing for themselves. This book focuses on a society where individuals generally do not have a lot of control over their lives and the government chooses for them. It also focuses on the character of the Giver who holds the truths of the old world and the beauty and pain that used to exist. The Lottery influenced The Giver by having Lowry question society and the control that the government has over the population. It also brought to light another “chosen one” whose fate was to bear the weight of the tradition and history of the town.\nIn The Hunger Games Trilogy, the concept of “the chosen one” is used again, but it is more closely related to The Lottery. In the society that is the setting for The Hunger Games Trilogy, individuals are chosen in 12 different districts by drawing names. These 12 are then forced to take part in The Hunger Games and fight to the death. The last one alive ends up being the victor, but they are forced to live with the memories and nightmares of what happened in The Hunger Games, as well as what they did during the games to survive. Being chosen in this context is, again, much like in The Lottery, because it is essentially a death sentence. But Collins took the lottery concept further by having society tell the population that in order to survive, they need to kill one another. Instead of targeting the population directly, such as in The Giver, the society in The Hunger Games taught the population that in order to survive they need to be out for themselves. This is precisely why The Hunger Games Trilogy has had such a lasting effect on our current society. Today, people are taught that they need to work hard to be successful, no matter who they step on. The Hunger Games Trilogy reflected this but in a more gruesome matter. Just like how The Lottery, reflected how in the late 1940s society was trying to stick with a tradition that had lasted pre-war but was lethal post-war: focusing on the “perfect” family lifestyle and fighting for the country when so many had been lost in the violence of war.\n“The chosen one” concept is not something that is new or entirely original, but it is one of the most important concepts in literature. This concept has been used to portray how our society runs as well as where it is going. It has helped us to see society in a different way and to question the rules and regulations that we live by.\nMy challenge for you is to write a story using “the chosen one” concept to portray how you feel about society, or where it is going. We are living in a very heated time, and sometimes it is best to portray how we feel through writing and literature. Feel free to leave a comment sharing your story or thoughts!\nI look forward to seeing what you come up with! Please let me know how you feel about “the chosen concept” in the comments below.\nFOR BOOK REVIEWS, FILL OUT THIS FORM: Book Review Request Form\nFOR BOX REVIEWS, EMAIL: firstname.lastname@example.org","Essay: the red badge of courage by stephen crane four main characters (and one-sentence description of each) henry fleming (the youth) – henry, the main character of the novel, was at first very excited to go to war joining the army against his mother’s wishes, but he finds war frightening and he becomes a coward to later become a hero. Stephen crane's red badge of courage as bildungsroman in the red badge of courage, by stephen crane, the main character henry fleming joins the army as a young fledging and ultimately matures to a courageous soldier ready for battle. Character analysis: the red badge of courage in stephen crane’s novel, the red badge of courage, henry fleming is a young union soldier in the civil war. Detailed analysis of characters in stephen crane's the red badge of courage learn all about how the characters in the red badge of courage such as henry fleming and wilson contribute to the story and how they fit into the plot.\nWhich of the following statements is true of wilson and henry in stephen crane's the red badge henry fleming, the main character of stephen the red badge of courage characters & analysis . Complete list of in stephen crane's the red badge of courage learn everything you need to know about henry fleming, wilson, and more in the red badge of courage. The red badge of courage by stephen crane is an anti-war novel the novel, based on the chancellorsville battles, the american civil war is a classic novel from seventeen century henry fleming, the main character, is a young man who is enlists into the army. All characters henry fleming (the welcome to the litcharts study guide on stephen crane's the red badge of courage created by the original team behind sparknotes .\nLitcharts assigns a color and icon to each theme in the red badge of courage, which you can use to track the themes throughout the work red badge is a study of courage and fear, as seen in the shifting currents of henry's thoughts and actions during the battle. The red badge of courage, by stephen crane (1871-1900), is a novel about the american civil war, and is probably the modern trope codifier for war is hell henry fleming, a young soldier of 304th regiment, joined the union army with wide-eyed ideas about the glory of battle and service to his . For a discussion of the stylistic devices that help crane convey with realism the process of henry fleming's development, consult the edsitement lesson the red badge of courage: a new kind of realism.\nThis study guide consists of approximately 79 pages of chapter summaries, quotes, character analysis, themes, and more - everything you need to sharpen your knowledge of the red badge of courage henry, the protagonist of the novel, is a naive, young farm boy from new york state whose dreams of . Stephen crane’s novel the red badge of courage is one of the best books covering the american civil war the experiences and feelings of the young, untried soldier henry. The red badge of courage by stephen crane outlines the effects of war on a union soldier, henry fleming, from his dreams of being a soldier, to his enlistment, and through several battles of the civil war.\nName: _____ character analysis in the red badge of courage in stephen crane’s novel henry is facing a part of himself that he knew nothing about it had of himself was here of no avail. The red badge of courage study guide contains a biography of stephen crane, literature essays, a complete e-text, quiz questions, major themes, characters, and a full summary and analysis. The red badge of courage by stephen crane home / literature / the red badge of courage / characters / henry fleming (the youth) character analysis henry’s . Essay on the red badge of courage, by stephen crane in the novel of “the red badge of courage”, the author, stephen crane used henry fleming to be his subject for how situational surrounding can affect one’s behaviors and characters.\nThe red badge of courage stephen crane buy character analysis henry fleming, a union soldier about the red badge of courage character list summary and . This one-page guide includes a plot summary and brief analysis of red badge of courage by stephen crane the red badge of courage by stephen crane follows a young soldier, henry fleming, during a battle in the civil war.\nFree barron's booknotes-the red badge of courage by stephen crane-character analysis/henry fleming/the youth-free summary notes booknotes plot synopsis essay topics book reports theme paper study guide downloadable notes. Character analysis based on the red badge of transcript of character analysis of henry fleming taken from the novel the red badge of courage by stephen crane. The red badge of courage is a novel in which henry fleming, “the youth,” struggles with the question of whether he will fight or run when he sees his first real battle after it begins, he . Stephen crane’s the red badge of courage covers two days of intense battle scene the third person limited narration reflects the feelings and fears of the young henry fleming the story."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:b1f05732-445f-4c21-9de0-59c97dae6b6d>","<urn:uuid:83084d68-b562-4f4f-97c0-6c691ae9252f>"],"error":null}
{"question":"How does water hardness affect modern appliances and dishwashing in home? Like washing machine and dishwasher?","answer":"Hard water accelerates wear and reduces the expected lifespan of appliances. The problem has become more significant since phosphates were removed from laundry and dishwashing detergents, as these phosphates previously helped soften hard water. This has impacted cleaning effectiveness so much that some manufacturers are now building water softeners into dishwashers. Soft water leads to reduced detergent usage and requires lower water temperatures, resulting in less corrosion.","context":["Taking the mysteries out of water treatment\nProblem water can create issues that lead to unwanted, additional service calls for your business.\nPlumbers are already pumping, pressurizing and heating water, but how much do they know about water quality and how to properly treat water to solve problems in the modern home?\nWater in the residences and businesses where your customers live and work touches the pipes, plumbing fixtures, and hot water heaters, as well as dishwashers and washing machines. Something as basic as elevated hardness could easily cause problems for your customers, especially if they have high-efficiency appliances and low-flow fixtures in their household.\nProblem water can create issues that lead to unwanted, additional service calls for your business. But, when you take the mysteries out of the water and gain an understanding of the science behind how to treat it, you’ll become a much better contractor — and your customers will benefit from having a local water quality expert.\nArming yourself with knowledge is the first step in becoming familiar with the best practices of water treatment. Here’s a high-level explanation of two of the most common factors in water quality: hardness and corrosion.\nWater is considered “hard” when it contains metal ions, or minerals, which are dissolved in groundwater. That includes calcium, magnesium and iron. Although hardness levels vary greatly by region, most homes with private wells have hard water, and many homes on municipal water do, too. In fact, more than 80% of households in the U.S. have hard water.\nThe biggest issue with hard water is the deposit it leaves behind. This causes excessive soap scum, clogs pipes and fixtures, wears down appliances, and creates many other headaches for homeowners.\nWater softeners remove hard minerals through an ion exchange process. Water softening resin is charged with sodium, which is exchanged for the calcium and magnesium that is retained inside the softener. This creates the soft water that is ideal for cleaning and bathing.\nWhen it comes to iron, typical softening may not do the trick. In some cases, ferrous iron, which is dissolved and colorless in the water, needs to be oxidized so it turns into a particle (ferric) and can be filtered out of the water.\nPlumbers have certainly witnessed their fair share of problems caused by corrosive water. Certain properties of water increase its corrosiveness, which negatively impacts plumbing and appliances:\nTemperature. Raising the temperature of water allows oxygen to escape, which can cause corrosion and pitting in copper and iron piping.\nPressure. Lower water pressure combined with hot water will magnify corrosion.\nTotal dissolved solids (TDS). This is the measure of all organic and inorganic matter in water. TDS levels above 2,000 cause corrosion through electrolysis. TDS levels below 80 cause corrosion from an appetite to dissolve more minerals.\nPotential of Hydrogen (pH). Pure water is neutral, but it can become acidic or basic depending on what chemicals are mixed with it. Acidic water (low pH) can cause pinhole leaks in pipes as well as blue/green staining. Basic water (high pH) leads to build-up and clogging of pipes.\nWe are only scratching the surface of water chemistry here. Once you have a deeper understanding of the science, you need to know how to test and measure water quality. Then, you must learn how to treat the water with the right equipment and most effective media.\nThat’s where the real opportunity lies, because water treatment in the typical household is no longer a luxury — it is a necessity.\nWater challenges in the modern home\nIn just a few years, the demand for in-home water treatment has increased noticeably, and much of that is because of the pursuit for more efficient and environmentally friendly homes.\nFixtures and appliances are being designed to use significantly less water. For example, toilets went from using 1.6 gpf to 1.26 gpf, and some use as little as 1 gpf.\nLow-flow fixtures help homeowners conserve water. However, if there’s just a little bit of calcium buildup in the tiny holes of a low flow showerhead, suddenly the homeowner isn’t getting enough water to rinse their hair. The same goes for a low-flow toilet. When there is lime scale buildup in the toilet’s trap, it won’t flush the way a homeowner expects.\nThe Water Quality Association (WQA) has conducted conclusive research on how hard water and soft water affect appliances like water heaters. The results were clear: Hard water accelerates wear and reduces the expected lifespan of appliances. Soft water, on the other hand, leads to reduced detergent usage and requires lower water temperatures, which means less corrosion.\nDetergent is yet another issue. Due to environmental concerns, phosphates were removed from laundry and dishwashing detergents. Those phosphates helped soften hard water, making detergent more effective at cleaning dishes and laundry.\nAfter the detergent formula changed, many people thought their dishwashers and washing machines weren’t working. It’s gotten to the point where some manufacturers are building water softeners into dishwashers.\nOf course, a more permanent, all-encompassing solution is to have a whole-house water softener installed. Making a recommendation like this is an opportunity for plumbers to establish themselves as helpful experts. If you start selling and installing water treatment equipment, it’s also a new revenue stream. As a plumber, you’re already having conversations with people directly related to water quality. Why not help them fix it?\nBut, first thing first. Find resources and experts to help you learn about the science and art of treating water so you can advise your customers with confidence."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:f856015b-4260-4f51-bc41-7d21e1582eed>"],"error":null}
{"question":"How do traditional artisans like Jesús Jimenez Hernandez create alebrijes compared to Pedro Linares' original paper mache technique?","answer":"While Pedro Linares originally created alebrijes using paper mache and paint after being inspired by fever-induced dreams of colorful creatures, modern artisans like Jesús Jimenez Hernandez make them differently. Hernandez creates alebrijes by carving figures from a single piece of wood, spending about two hours sanding each piece before painting it with bright colors. Both techniques result in vibrantly colored, fantastical animal-like creatures, though the materials and processes differ.","context":["As I mentioned in my last post, I love the culture and art of Latin America. It is Hispanic Heritage Month and I thought it would be fun to share three of my favorite Latin American art forms along with projects that you can do inspired by those types of art.\nAs an art teacher, I have done all of these art projects with students of all ages and I can say with confidence they are always a success. Kids and adults will learn a lot about the countries where these artworks are created and they will learn some fun ways to make their own art inspired by Latin American artists.\nMolas are a type of textile worn by the Kuna people of Panama. Molas are made with layers of fabric, which are then cut away to reveal the various colors beneath. Many molas are symmetrical meaning the shapes and/ or colors are repeated on each side. Many, however, are not symmetrical and the artisans use asymmetry instead.\nTake a look at some samples of Molas here and then make your own! You can use brightly colored paper, scissors, and glue to design your own interpretation of a mola. The Kuna people use animals, plants, and geometric shapes to inspire their designs and you can do the same.\nOther Helpful Mola Related Links:\nAlebrijes are brightly painted folk art sculptures from Mexico originally created by artist Pedro Linares. When Linares was sick with a fever, he dreamt of a brightly colored animal-like creatures called alebrijes. When he recovered, he began to create this creatures using paper mache and paint. To this day, his family continues to make this art form.\nUsing air dry clay and tempera or acrylic paint, you can make your own alebrijes. Form the clay into an animal or animal-like creature of your choice (use the shape animal drawings as a guide). Follow the directions on the package to let the clay dry. Paint the clay with lots of bright colors and fun patterns. You can even use marker to add fine detail.\nOther Helpful Alebrije Links:\nArpilleras are brightly colored fabric tapestries from Chile, which became popular in the 1970's and 1980's. Due to political unrest, news of what was happening in Chile was not able to get out of the country. Women, called arpilleristas, would meet in secret to stitch their stories into fabric. The artworks were then smuggled out of the country to be shared with the world outside. The artworks were sold abroad and the money was sent back to the artists. There is more to this story and you can read it here.\nYou can create your own arpillera inspired fabric collage by using scraps of old fabric or an inexpensive fabric material like this. Once you have your materials, you have to decide what story to tell. The arpilleristas of Chile often told stories about their struggles and hardships, but they also shared stories of family, friendship, and culture. They almost always included the Andes Mountains in their artworks to show that the artwork was created in Chile.\nOnce you have selected the story you want to tell, you can start cutting pieces and gluing them into position. Think about what landmarks you should include, so that your viewers know where the story is taking place. You can also add stitching with a needle and thread, but that is always optional. Arpilleristas included a lot of detail in their textile artworks, so make sure you include a lot of detail when you share your story.\nOther Helpful Arpillera Links:\nI've given you lots of ideas, artist names, recommended materials, as well as additional links to continue your education. Please share any artworks you make with me! Do you have a favorite Latin American art form that I missed? Please share it in the comments below!","Photos of women in their small businesses around Mexico.\nOn cold winter days in New York, I’ve been looking at thousands of photos I took in Mexico last year. While the lovely warm colors of the landscapes and sky and flowers and buildings infuse me with warmth, the photos of women working in small businesses are most compelling. Their faces, their aprons, their hands tell their stories.\nI took these pictures for Pro Mujer, a non-governmental organization that provides small loans and health care to women in Latin America. I published a few of the pictures here last year, but I want to share more images of these hard-working, lovely women. They live on on the outskirts of Mexico City and around the states of Hidalgo, Pachuca, Puebla, and Oaxaca.\nClick on an image to enlarge it and see the caption and to scroll through all the images.\nFlores Ramirez Brigida runs a tienda (a little store) in Colonia Benito Juarez, outside of Puebla.\nMaria Blanca Martinez Tapia at her tienda, Colonia Benito Juarez, Puebla.\nMaria Concepción has a tienda in her home, Colonia Volcanes, in the state of Puebla\nMaria Concepción by her wedding photo, Colonia Volcanes, in the state of Puebla\nJesús Jimenez Hernandez makes alebrijes in her home workshop in Arrazola, south of Oaxaca. She sands each carved figure, like the fish in her hands, for about two hours before painting. She’s proud that the figures are made from a single piece of wood.\nJesús Jimenez Hernandez shows an alebrije she painted.\nAn alebrijes made by Jesús Jimenez Hernandez.\nJesús Jimenez Hernandez in her open-air alebrije workshop in her home in Arrazola, where many women paint these fanciful figures.\nSisters Isabel Gomez Santiago and Gloria Ines Gomez Santiago paint alebrijes in Arrizola, a small town outside of Oaxaca. This is Isabel using a hypodermic needle to make dots.\nIsabel Gomez Santiago shows how she uses a hypodermic needle to paint dots.\nGloria Ines Gomez Santiago paints alebrije. She is quick and sure in her strokes.\nGloria Ines Gomez Santiago with a partially painted alebrije in her workshop.\nAlebrijes in the workshop of Isabel Gomez Santiago and Gloria Ines Gomez Santiago, sisters who paint the figures in Arrizola, a small town outside of Oaxaca, Oaxaca.\nMaximina Morales Morales, in her roadside stand in Zaachila, a small town south of Oaxaca, makes tortillas using a comal and wood fire.\nMaximina Morales Morales cooks food on an open fire at her roadside stand in Zaachila, outside of Oaxaca.\nTortilla maker Maximina Morales Morales, with her daughter and family.\nMaximina Morales Morales in her roadside stand in Zaachila.\nAngelina Garcia, Plasticos, “Juquilita,” in San Agustin de Las Juntas outside of Oaxaca\nDelia Gema Vicente Lopez makes tortas at “Comedor Santy,” Fonda, San Agustin De Las Juntas south of the city of Oaxaca.\nA Pro Mujer client has come to make a payment on her micro-loan in San Sebastian Tutla outside of Oaxaca.\nAt San Sebastian Tutla, a, woman has come to make a payment on her loan. The women pay with stacks of coins and small bills.\nFarmer in Chilcuahutla Hidalgo, Maria del Carmen Sandoval\nJustina Reyes in her restaurante de mariscos, “La Langosta Enamorada,” in El Rosario neighborhood southeast of Oaxaca.\nAraceli Ramirez Guzman at her Lavandería at Gomez Sandoval outside of Oaxaca\nErika de la Luz Alvino Calihua sells Tupperware from her home in San Andres Cholula, in the state of Puebla\nLazara Cristobal Medina, runs a tienda, Recauderia a Vale, in Colonia Benito Juarez, state of Puebla.\nIvonn Ena Paz Delgado makes and sells her hand-made clothing, San Sebastian Tutla.\nIvonn Ena Paz Delgado demonstrates how she makes her complicated machine-stitched embroidery.\nIvonn Ena Paz Delgado in her store/studio.\nSome of the machine-stitched embroidery by Ivonn Ena Paz Delgado.\nMargarita Gomez prepares to make tortillas.\nMargarita Gomez, tortillas, El Rosario, southeast of Oaxaca in a roadside stand, Working with wood fire and comal, she makes handmade tortillas in a very traditional way.\nMargarita Gomez makes tortillas over a wood-fired clay oven. Her fingers are smooth and delicate but she can flip the hot tortillas somehow.\nGabriela Gonzalez Lopez sells fresh produce and chickens at a crossroads near her farm in Ixmiquilpan.\nGabriela Gonzalez Lopez and her husband Esteban, in their greenhouse in Ixmiquilpan in the state of Hidalgo, north of Mexico City. They’re showing some ripening tomatoes and the seed packet with the type they grow: Number 7705, a hybrid (from Nunhems, Bayer Crop Science). GMO. Oh well.\nMaría Elena Neri Flores and her son at her tienda in Tecámac across from a school. She sells her sewn goods including school uniforms and snacks.\nMaría Elena Neri in her home sewing studio. The orange dress is a costume, but mostly she sews school uniforms.\nPollería in Tecámac.\nJosefa Gomez Sanchez cuts up chickens in her pollería in Tecámac, North of Mexico City.\nFor the photos of Pro Mujer women I published here last year, here’s the link:\nMujeres at Work, more photos"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:1d617a9d-2101-4bbe-8b53-ce131c101848>","<urn:uuid:4fe678ca-7f0b-48a8-9fa5-b5c10a8c4c13>"],"error":null}
{"question":"What pioneering achievements connected Elinor Smith and Bobbi Trout to recognizable American brands?","answer":"Both aviators achieved recognition through American brands, but in different ways. Elinor Smith became the first woman to appear on a Wheaties cereal box in 1934. Bobbi Trout, on the other hand, secured corporate sponsorship from the Sunset Oil Company, which painted their logo on her aircraft for promotional purposes.","context":["\"Elinor Smith, One of the Youngest Pioneers of Aviation, Is Dead at 98\"\nMarch 26th, 2010\nThe New York Times\nMarch 26th, 2010\nThe New York Times\nIn the days of rickety open-cockpit biplanes seemingly held together by baling wire, 8-year-old Elinor Patricia Ward got her first flying lesson — at her kitchen table in Freeport, N.Y., on Long Island.\n“My earliest memory was at dinner with Dad using a knife to show us how the controls of a plane worked,” she told The New York Daily Mirror in 1942.\nWithin weeks Elinor’s father, Tom Ward, took her to a makeshift airfield on a potato farm, where a pilot strapped her into the rear seat for a fast flight, for a fee. Mr. Ward was a vaudeville song-and-dance man who hated trains and, while on the road, had hired pilots to take him from town to town. (There was another Tom Ward on the vaudeville circuit, so he changed the family name to Smith.)\nThat first flight sealed Elinor Smith’s fate. Ten days after she turned 16, Elinor received her pilot’s license, becoming one of the youngest pioneers of aviation. Soon, she was breaking records, doing daredevil stunts and making headlines as the “The Flying Flapper of Freeport.”\nOn March 19, Elinor Smith Sullivan died at a nursing home in Palo Alto, Calif., her son, Patrick, said. She was 98.\n“I remember so vividly my first time aloft that I can still hear the wind swing in the wires as we glided down,” she wrote in her autobiography, “Aviatrix” (Harcourt Brace Jovanovich, 1981). “By the time the pilot touched the wheels gently to earth, I knew my future in airplanes and flying was as inevitable as the freckles on my nose.”\nTom Smith took flying lessons, then bought an open-cockpit Waco 10 biplane. Elinor insisted on taking lessons. She took her first solo flight when she was 15. Within two years, she was carrying passengers on short flights from Roosevelt Field over Long Island. Then, on Oct. 21, 1928 — after being baited by boys at her high school — she took off alone, headed west, then south and swooped under the four East River bridges.\n“Miss Smith was informed here that the Department of Commerce might ‘ground’ her for her stunt,” The New York Times reported the next day, “but she said that she would rather take that chance than disappoint a number of persons who had expected her to carry out her plan.” She was grounded for 10 days.\nPublicity soon propelled Elinor, a blue-eyed, 5-foot-3, curly blond teenager, onto the list of pioneering women in aviation, among them Bobbi Trout, Katherine Stinson, Pancho Barnes , Fay Gillis Wells, Louise McPhetridge Thaden and Amelia Earhart.\nOn planes provided by corporate sponsors, she began setting records. In January 1929 she set the women’s solo endurance record at 13 ½ hours. Then, three months later she reset it with a 26 ½-hour flight. In 1930, she set the women’s altitude record at 27,419 feet. Within a year, she reset the altitude record at 32,576 feet.\nThat flight, in a Bellanca monoplane, nearly cost her her life. As The World-Telegram reported on March 11, 1930: “The altimeters on the ship registered 30,000 and 32,000 yesterday when she was forced by motor trouble and waning gas supply to return to Roosevelt Field, where she narrowly averted an accident in making a dead-stick landing. At about 30,000 feet, as the motor sputtered, she lost consciousness. A mile lower she recovered. The plane, without her guiding hand, had glided slowly down.”\nIn 1934, Miss Smith became the first woman to appear on a Wheaties cereal box.\nShe was born on Long Island on Aug. 17, 1911, one of three children of Thomas and Agnes Ward. Her husband of 23 years, Patrick H. Sullivan II, who had been a New York State assemblyman, died in 1956. In addition to her son, she is survived by three daughters, Patricia Sullivan, Pamela Sullivan and Kathleen Worden; five grandchildren; and four great-grandchildren.\nMiss Smith took a long time off from flying after she married. But nine years ago, at the age of 89, she was invited to the National Aeronautics and Space Administration’s Ames Research Center in Sunnyvale, Calif., where she participated in a simulated landing of the space shuttle.\nAlways vivid in her memory was that day almost 84 years ago when she first soloed.\nShe was about to climb into a Farman Pusher biplane, she recalled in an interview for a 1998 PBS documentary, “Daredevils and Dreamers.” She thought it was to be just another flying lesson before she went off to school in Wantagh, a nearby town.\n“I was scared silly because Russ” — her teacher — “hadn’t told me I was going to solo that day,” she said on camera. Waving her arm in imitation of her instructor’s direction, she said he suddenly jumped out of the cockpit and simply told her, “Go.”\nFor a moment she was stunned, then realized that he thought she was ready. “I made three landings,” she said. “Then it was time to go back to Wantagh because I had to go to school.”\nBessie Coleman...first African American female pilot","By Di Freeze\nEvelyn “Bobbi” Trout, up until recently the last living participant of the inaugural “Powder Puff Derby,” passed away on Jan. 24, 2003.\nEvelyn Trout was born on Jan. 7, 1906, in Greenup, Ill, and lived in various parts of Colorado, Missouri, Canada, and California.\nThe tomboy, who gave herself the nickname of “Bobbi” when she faced teasing from family and friends after bobbing her hair, as stage and screen star Irene Castle had done, developed a passion for aviation when she saw a plane fly overhead on a spring afternoon in 1918. She took her first airplane ride at Rogers Field in Los Angeles in December 1922, in a Curtiss Jenny.\nShe took flying lessons at Burdett Air Lines Inc., School of Aviation, owned by “Pop” Burdett. Her first lesson was on New Year’s Day, 1928, in one of Burdett’s five Curtiss Jennies. She soloed in April 1928, and was soon flying an International K-6, a four-place biplane her mother purchased from Burdett.\nTrout had the opportunity to meet Charles Lindbergh, at the National Air Races & Aeronautical Exposition, held that year at what was known as Mines Field, but is now Los Angeles International Airport.\nThat same year, after her aircraft was displayed on the roof of the May Company during an exhibition, she found a sponsor, the Sunset Oil Company, and the company logo was painted on the craft. Later, she began demonstrating aircraft, as well as working on some, for R.O. Bone, the builder of the Golden Eagle.\nOn Dec. 14, 1928, she flew a Golden Eagle in the official dedication of Los Angeles’ Metropolitan Airport, now Van Nuys Airport. On Jan. 2, 1929, in a flight out of Metropolitan of 12 hours and 11 minutes, she broke an earlier 8-hour endurance record set by Viola Gentry.\nAfter Elinor Smith had bettered her record by one hour, on Feb. 10, 1929, she set out from Mines Field, returning 17 hours, 5 minutes and 37 seconds later, holding five new records, including the first all-night flight by a woman and the new women’s solo endurance record. One headline read, “Tomboy Stays in Air 17 Hours to Avoid Washing Dishes.”\nOn June 16, flying a new 90-hp Golden Eagle Chief, Trout climbed the aircraft to 15,200 feet, shattering the existing light class aircraft altitude record.\nOn Aug. 18, 1929, Trout, flying a newly revamped 100-hp Golden Eagle Chief, and other women including Amelia Earhart took off from Clover Field in Santa Monica, Calif., heading toward Cleveland, Ohio, in the first Women’s Transcontinental Air Derby, during the prestigious National Cleveland Air Races.\nTheir eight-day course would be navigated by dead reckoning and road maps, and would result, when conversation between Trout, Earhart and others later turned to how to stay in touch, in the creation of the Ninety-Nines.\nOnlookers at the race included Wiley Post, Howard Hughes and Will Rogers who, after seeing several of the women checking compacts and powdering noses, dubbed the race the “Powder Puff Derby.”\nOn Nov. 27, 1929, with Elinor Smith, while flying a Sunbeam biplane, Trout took off from Metropolitan Airport to attempt the first refueling endurance flight by women. The task was accomplished through a Curtiss Carrier Pigeon, which refueled the plane three and a half times, during a period of 42 hours and three and a half minutes.\nOn Jan. 4, 1931, Trout went aloft for another refueling endurance flight with starlet Edna May Cooper. They were in the air for 122 hours and 50 minutes.\nDuring the thirties, Trout instructed and took up photography. Later, during the WWII years, she founded a rivet-sorting company and deburring service. Following that, she opened a real estate office, took a turn at offset printing and opened a life insurance and mutual funds office.\nHer thrill seeking throughout the years included motorcycle riding and driving around north San Diego County in her red Porsche 914.\nTrout’s numerous honors include being awarded the OX5 Pioneer Woman of the Year Award (1976), induction into the OX5 Aviation Pioneers Hall of Fame (1984) and nomination into the Women in Aviation’s Hall of Fame (1993), and receiving the Howard Hughes Memorial Award for her lifetime contributions to aviation (1997)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:5c1cb0d8-c5d5-44b6-8b3f-5e84b6d17621>","<urn:uuid:d77eee2f-8a6b-4d59-a550-61711b03a80a>"],"error":null}
{"question":"请问医生在远程医疗平台上如何确保病人信息安全和HIPAA合规？临床规范是什么？","answer":"Regarding security and compliance, physicians must confirm patient identity by matching ID with photo, and never share PHI using non-HIPAA compliant tools. They should never work in open areas where screens are visible to others. For clinical protocols, physicians must provide detailed treatment explanations, check messages daily, treat patients in order of platform entry, and complete one consultation at a time. They should thoroughly document decisions and follow state-specific requirements for establishing patient-physician relationships. Additionally, any cell phone used must have encryption enabled, use multifactor authentication, and connect only through secure networks. Email transmission of ePHI is prohibited and remote wiping capabilities should be available if devices are lost.","context":["PHYSICIAN CODE OF CONDUCT\nDate of Last Revision: 1/27/2019\nThe Ro mission is to help as many people as possible with their healthcare needs and ultimately improve the way that people interact with the medical system when addressing certain health conditions. This document serves as the universal code of conduct for physician use of the Ro platform. Our goal is to align the values and philosophies of Ro HQ and the physicians who practice on the Ro Platform. This Code of Conduct will continue to be updated based on feedback from affiliated physicians in order to ensure patients are always receiving the highest quality of care.\nBEST PRACTICES ON THE PLATFORM\n- Telemedicine is a new experience for many patients. They may ask questions that seem obvious (e.g., “How does telemedicine work?”). Please be sensitive to their concerns and work with them to determine the best course of treatment.\n- Always provide a detailed explanation to a patient whether you find it appropriate to write a prescription or not. Patients are coming to the Ro Platform because they are in need of your guidance and care.\n- The Ro Platform will automatically follow up with patients who receive treatment plans after 2 weeks, 1 month, and every 3 months thereafter. If you think that a patient needs additional follow up, you can automate follow ups in the messaging system or contact the Ro Medical Ops Team.\n- Always thoroughly document your decisions. For example, if you approve a patient for treatment, and the Ro system flagged one or several of their responses as a potential contraindication or risk, please make sure to document your rationale (e.g., you spoke to them via phone, video, or message and received additional clarifying information).\n- The physicians with the highest rate of patient satisfaction check their messages at least once per day. If you will be unavailable for more than 48 hours, please give the Ro Medical Ops one week notice so that we can ensure your patient’s receive timely responses to any question. In case of an emergency, please try to notify us as soon as possible.\nCONDUCT EXPECTATIONS ON THE PLATFORM\n- ID & Photo Match: The first step by any physician is to confirm the identity of the patient and ensure that the image uploaded matches the patient’s government ID. This is also double-checked by automated software.\n- Personal Information: After you’ve confirmed the ID matches the Face Photo, confirm that the basic information entered during the online visit (i.e., first name, last name, DOB) matches the information on the government ID.\nFollow State Protocols:\n- The Ro Platform will always require you to confirm that you established a patient-physician relationship according to the state-specific requirement. Never provide any medical advice or treatment until you have adequately established a patient-physician relationship. When in doubt, please contact the Ro Medical Operations team or Ro’s General Counsel.\nTreat “Oldest” First:\n- Please always treat patients who entered the Ro Platform first. We pride ourselves on providing timely service to our patients. This can only be done if those who have been waiting longer are served first.\nOne at a time:\n- If another physician has started to treat a patient, do not attempt to provide additional treatment unless specifically asked for a second opinion.\n- In addition, physicians should complete only one consult at a time before moving on to the next patient. Each consultation requires your undivided attention.\nSAFETY, SECURITY & PRIVACY\n- Always pay attention to reported medications and be alert to drug interactions. Please make sure to always check a patient’s previous plans on the Ro Platform before making a treatment decision.\nWhen There’s Doubt, There is No Doubt:\n- When in doubt about a specific drug interaction, please contact the Ro Medical Ops team, who will route your question to one of Ro’s clinical directors.\n- If anything is unclear from the visit, please follow up with the patient. It is always better to be 100% certain that you have all the necessary information.\n- Never create a prescription for a patient if you are unsure if it’s safe. It is always better to get a second opinion or refer the patient to his/her in-person primary physician when in doubt.\nPay Attention to Underlying Causes:\n- Our patients’ mental health is as important to us as their physical health. Always follow up with patients who provide answers concerning their mental health. Please refer to the Emergency Plan located in the Roman Manuals and Protocols folder for guidance on how to respond if a patient is experiencing a medical emergency.\nConsistently Review Protocols:\n- Please reference the condition-specific Physician Protocols regularly. They contain the most important points on safe practices on the Ro Platform and should serve as a continuous reference for physicians. Most importantly, all medical decisions should be made solely at your discretion according to the standard of care.\n- Never share your Ro physician app password with anyone.\n- Never share any patient information with anyone outside of Ro and only share information that is required for someone to complete their job.\n- Never share PHI using any software tool that is not HIPAA compliant. You may use password protected links to patient charts in Asana and email.\n- Never work on the platform in open areas where someone may be able to see your screen and see PHI.\nETHICAL EXPECTATIONS FOR PLATFORM PHYSICIANS\nRo-affiliated physicians are expected to uphold the highest ethical standards called upon by the medical profession.\nDo No Harm:\n- First, do no harm. The practice of medicine is a calling. Always put your patients’ safety first. Patient safety is the first and primary priority. You will always be compensated the exact same, regardless of whether a prescription is written.\n- Patients that come through the Ro Platform should never be self referred to your own practice. If a referral is needed, please refer them to their primary healthcare provider or other outside physician.\nSound Body & Sound Mind:\n- Never engage in the practice of medicine on our platform while under the influence of alcohol or other mind-altering substances.\nKeep Ro Informed:\n- In case of a board complaint, hospital administrative action, malpractice suit or judgement, or any other administrative or disciplinary action against you (including a criminal charge or conviction related or unrelated to the practice of medicine), please promptly notify the Ro Medical Operations Team.\nOwner, Roman Pennsylvania Medical, P.C.\nClinical Director, Ro","Given the Health Insurance Portability and Accountability Act’s (HIPAA) extensive protections and restrictions regarding electronic protected health information (ePHI), cell phones present a challenging grey area to navigate. However, implementing a HIPAA-compliant cell phone policy and appropriate security controls will help your healthcare organization properly adhere to regulations.\nHIPAA-Compliant Cell Phone Policies and Usage\nAchieving and maintaining HIPAA compliance can easily be threatened by healthcare personnel’s cell phone usage. At first consideration, cell phones and their various security risks would seem opposed to HIPAA compliance but the right implementations can help any healthcare entity with their efforts.\nEnsuring HIPAA-compliant cell phone usage requires:\n- Understanding ePHI as it relates to HIPAA compliance and potential breaches\n- Knowing what telecommunication methods to monitor\n- The beneficial policies and security measures healthcare entities should implement\nA HIPAA compliance and cybersecurity expert can advise your compliance program. Further, a managed security services provider (MSSP) will provide many of the cybersecurity measures and training programs healthcare personnel should implement.\nUnderstanding ePHI and HIPAA Compliance\nImplementing HIPAA policies and security measures with respect to cell phones first requires understanding the ePHI that must be safeguarded. The Department of Health and Human Services (HHS) refers to and summarizes the HIPAA Privacy Rule’s demarcation of ePHI as “individually identifiable health information” covering:\n- Physical or mental health or conditions (whether past, present, or future)\n- Provisioned healthcare and any payments thereof\n- Demographic data (when not individually identifiable)\n“De-identified health information” doesn’t count as ePHI. To be considered de-identified, the data must neither identify an individual nor provide a reasonable basis to do so via one of two methods:\n- A statistician’s formal determination\n- All specified identifiers related to the individual and their relatives, household members, and employers must be removed to the extent that a given healthcare entity “has no actual knowledge that the remaining information could be used to identify the individual.”\nHIPAA-Permissible ePHI Uses and Disclosures\nAn individual’s ePHI may only be used or disclosed (i.e., made known or accessed by an unauthorized party) with their written consent or in the following circumstances without it:\n- To the individual\n- For conducting the individual’s treatment, payment, and healthcare operations\n- Following a clear opportunity provided to the individual to agree, acquiesce, or object\n- As a result of or incidental to permissible uses and disclosures—so long as reasonable safeguards have been adopted and the shared information was kept as minimal as possible\n- For public interest and benefit purposes, although rigid circumstances and procedures must be met to remain compliant\n- As part of limited data sets, if it is de-identified information that also meets additional criteria:\n- Used and disclosed for research, healthcare operations, or public health purposes\n- The individual has given consent in a data use agreement\n- Specified safeguards have been implemented to protect the identifiable portions of the information\nUnderstanding HIPAA’s Definition of ePHI Breaches\nEnsuring HIPAA-compliant cell phone usage also requires understanding what the regulations define as constituting a “breach.” Your organization cannot prevent security issues it doesn’t understand.\nHHS and the Breach Enforcement Rule define a breach as “an impermissible use or disclosure under the Privacy Rule that compromises the security or privacy of the protected health information.” Thus, any ePHI accessed, acquired, or interacted with by unauthorized personnel, without receiving an individual’s written consent, or outside the six circumstances described above constitutes a HIPAA breach.\nThis definition of breach does allow for specific exceptions:\n- If the covered entity or business associate responsible demonstrates that the probability that the ePHI has been compromised is low—based upon conducting a risk assessment that includes the following factors:\n- The nature and extent of the used or disclosed ePHI, notably, the types of identifiers and chance of an individual’s identification\n- The unauthorized party that used the ePHI in question or to whom the disclosure occurred\n- If the ePHI was actually used or viewed\n- If the use and disclosure risks have been mitigated appropriately\n- If the acquisition, access, or use of ePHI by a covered entity’s employee or a business associate acting under their authority was unintentional, made in good faith, and within their authoritative scope\n- If an authorized person made the disclosure to another person that is generally authorized to access individuals’ ePHI within the scope of their responsibilities due to:\n- Being employed by the same healthcare entity\n- Being employed by the healthcare entity’s business associate\n- Operating as part of an organized healthcare arrangement in which the healthcare entity participates\n- If the party to whom ePHI is disclosed is unable to retain the information in any capacity\nAre Cell Phones HIPAA-Compliant?\nGenerally, HIPAA regulations specify:\n- The security standards that must be upheld to safeguard ePHI\n- Entities’ responsibility to regularly conduct risk analysis for determining the necessarily implemented administrative, technical, and physical measures\nWhile unprotected cell phone access to or transmission of ePHI would significantly risk a HIPAA breach, the regulations do not explicitly prohibit cell phone or other specific technology usages outright. However, inadvertent use or disclosure and data or device theft that do constitute HIPAA breaches exponentially increase if ePHI is accessed on a cell phone or discussed over unsecure lines of communication.\nSo long as the appropriate security controls and processes are in place, cell phone use does not constitute a HIPAA breach.\nAre Cell Phone Conversations HIPAA-Compliant?\nBoth phone call conversations and faxed documents do not factor as ePHI, per the HIPAA Privacy Rules’ definitions under 45 CFR § 160.103. However, a phone conversation may constitute the disclosure of PHI if any discussion of identifiable health information falls outside of the HIPAA permissible circumstances listed above.\nWith the use of a second cell phone line app, HIPAA-compliant telecommunications may be more easily achieved. These services provide a secondary line for phone calls, texting, and voicemail personnel to interact with inside a segmented window on an existing device.\nAs an organizational policy, your entity’s representative on a phone or web-conferencing call should always identify themselves and confirm the other person’s identity. This practice helps ensure that the entity’s representative confirms their authorization to discuss PHI and that they are speaking to the individual whose information is being discussed (or someone acting in an official and recognized capacity as the individual’s representative).\nSecurity Controls and Policies for HIPAA-Compliant Cell Phone Usage\nHIPAA requires healthcare entities and their business associates to implement and maintain technical, administrative, and physical safeguards. The first two categories directly apply to cell phone usage. While there are ultimately no realistic physical safeguards that may be adopted for cell phones, certain technical measures (e.g., passcodes and authentication, encryption) will virtually eliminate physical security and compliance risks.\nHealthcare entities should consider technical safeguards ranging from activating (or deactivating) native device capabilities to implementing additional security measures. In addition, some technical safeguards may also be provided as native to cell phone applications and services.\nAdministrative safeguards consist of the mobile device policies that healthcare entities should enact and enforce. These policies should establish behavior expectations that oversee personnels’ cell phones usage.\nDevice-Native Technical Safeguards for HIPAA-Compliant Cell Phone Usage\nMany cell phones come equipped with native capabilities that healthcare professionals and business associates should activate or deactivate as part of organization-wide HIPAA compliance.\nNative security capabilities to enable include:\n- Passcodes – All cell phones and other portable devices that may be locked with pass- or pin codes should have the security feature enabled. Locking devices will certainly not deter all potential attempted and unauthorized access instances but provides an immediate barrier to protecting any stored ePHI.\n- Device Encryption – Android and iOS cell phones natively provide device encryption capabilities. Device-level encryption methods render firmware, software, and stored data unreadable without the associated cryptographic key. Device-level encryption is critical for HIPAA-compliant cell phone use, as it provides entities with a security measure that enforces two of the specified exceptions to incidents that constitute data breaches:\n- The ability to demonstrate that the probability ePHI was compromised is low.\n- The party to whom ePHI was disclosed (accidental or otherwise) will not be able to retain the data in any capacity (e.g., reading it on the screen, transferring it to another device) without the cryptographic key.\nDeactivation as a Technical Safeguard\nWhile most technical safeguards and security measures native to devices—or to the IT resources and storage they access—will need to be enabled, automatic backup and file sharing capabilities should be deactivated.\nThese capabilities do provide benefits in personal device usage. However, this functionality constitutes a HIPAA violation if ePHI is automatically backed up to any personal and unsecure storage locations (e.g., Google Drive, a cell phone carrier’s cloud storage) or shared.\nAs with many HIPAA violations, automatic backups would most likely lead to inadvertent noncompliance. Unfortunately, HIPAA penalty enforcement does not consider whether an incident that qualifies as a violation was intentionally or inadvertently committed.\nMultifactor Authentication (MFA) and Stored Login Credentials\nMultifactor authentication (MFA) requires users accessing a given IT resource (e.g., system, application, cloud service) to provide at least one additional method of identity verification as part of the login process. Generally, personnel provide a standard username and password combination before receiving a prompt for additional verification. This capability should be activated for any IT resource capable of interacting with or storing ePHI that provides MFA.\nMFA methods for IT resources accessed via mobile device include:\n- One-time passwords (OTPS) – OTPS may enforce MFA via various methods, including:\n- “Authenticator” applications – These applications display a randomly generated pin code that remains a valid credential for identity verification for a set duration (e.g., 30 seconds). After the duration concludes, a new random pin code is displayed.\n- SMS or Email – This MFA method will send the user the OTP via SMS or email for manual input.\n- Biometric identification – These methods include:\n- Fingerprint scanning\n- Facial recognition\nIn addition to enforcing MFA, any cell phone that stores or interacts with ePHI should not also store login credentials for any IT resource. If a hacker obtains access to the cell phone, stored credentials allow them to immediately access apps, services, cloud storage, and more without enforcing any additional security measures.\nImplemented Technical Safeguards for HIPAA-Compliant Cell Phone Usage\nSome technical safeguards that healthcare entities should implement will not be native to cellphones. The safeguards include:\n- Virtual private networks (VPNs) or virtual private clouds (VPCs) – VPNs and VPCs provide secure network and cloud connections to protect any ePHI data transmitted to or from a cell phone.\n- Remote wiping or disabling – Should a cell phone be lost or stolen, these capabilities allow an entity’s security team to delete ePHI (and other data) or prevent any access to it.\n- Firewalls and antivirus – Mobile device-specific implementations of standard security measures should be enforced on cell phones to prevent viruses, malware, phishing, and other common intrusion methods.\nAdministrative Safeguards for HIPAA-Compliant Cell Phone Usage\nAs important as technical safeguards are for protecting ePHI that cell phones interact with or store, your organization must also construct, promulgate, and enforce official policies to help ensure HIPAA compliance. A HIPAA cell phone policy should include specifications for:\n- Secure network and internet connections – Healthcare personnel’s cell phones should never connect to any entity IT environments or interact with ePHI over public or unsecure networks.\n- Email restrictions – ePHI should never be transmitted via email.\n- Cell phone cameras – While cell phone cameras provide an efficient and easy means for uploading images or providing a reference to colleagues, personnel should never take photos of anything that constitutes PHI.\n- Contacts – Storing patient contact information on a phone constitutes a HIPAA compliance violation waiting to happen. Similarly, any patient that stores healthcare provider contact information on their cell phone may cause a HIPAA violation. Since entities cannot control their patients’ cell phone contacts, they should consider adding a disclaimer (to be verified as binding by appropriate legal counsel) amongst signed forms.\n- Updates and Other Configurations – Cell phones should be configured to automatically install all available updates upon their release (e.g., operating systems, applications, threat signatures). Further, policies should prohibit any changes to HIPAA-specific and general cybersecurity configurations that the entity deems necessary.\n- Security awareness training – Healthcare entities should regularly provide their personnel with regular training to educate them on security practices and IT-related HIPAA compliance efforts. Advanced security awareness training may include elements such as phishing simulations to help personnel better recognize indicators of malicious activity.\nEnsure HIPAA-Compliant Cell Phone Usage\nAs with other HIPAA compliance efforts, ensuring that healthcare personnel’s cell phone usage adheres to regulations requires extensive technical and administrative safeguards to protect ePHI. While cell phones are not inherently HIPAA-compliant or noncompliant, interacting with or storing ePHI on mobile devices presents a far greater likelihood for violations to occur.\nWithout conscientious effort, healthcare personnel may inadvertently violate HIPAA-compliant cell phone practices.\nTo establish, assess, or remediate your organization’s cell phone policies and security implementations for HIPAA compliance, contact RSI Security today. As a HIPAA (and HITRUST) compliance and cybersecurity expert, we can help your organization maintain regulatory adherence."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:70b36d15-6cdd-4830-8c11-85a48f8c73d9>","<urn:uuid:73324921-150a-4a27-b2b6-a9782e42207a>"],"error":null}
{"question":"Which location has older historical roots - Bangkok's Yaowarat district or Hanoi's Temple of Literature?","answer":"Based on the information provided, Hanoi's Temple of Literature is older than Bangkok's Yaowarat district. The Temple of Literature was built in 1070 under King Ly Thanh Tong and was Vietnam's first university. While the exact founding date of Yaowarat (Bangkok's Chinatown) is not explicitly stated, the documents only mention recent developments like the MRT subway line and modernization efforts, suggesting it is not as old as the Temple of Literature which has nearly a millennium of history.","context":["Yaowarat: The Soul of Chinatown\nThe changes are coming to Yaowarat, Bangkok’s Chinatown, so better get there soon. Then again, the opening of the MRT subway line into one of the last vestiges of old Bangkok will probably encourage more of us to make the long journey from places like Thonglor and Ekamai. I don’t get there enough, despite my love of the narrow old alleys full of rusted auto parts, funky street eateries, and new retro bars and cafés; it’s just too far to deal with the traffic. Yet when I do make the trip, I’m reminded of just why I enjoy Bangkok so much.\nUntil the MRT heads right into the heart of Charoenkrung, your nearest access point by public transit remains Hualamphong, which you probably want to pay respects to now as well, as Bangkok’s main railway station is to be turned into a rail museum, as a new central terminal is being built up at Bang Sue. From here, it’s a short walk down to Wat Traimit and the Chinatown Gate, entry into the heart of Yaowarat.\nIf you haven’t already been, it’s well worth the visit to check out the Yaowarat Chinatown Heritage Center, located at Wat Traimit. The small museum has been extremely well planned, and follows the migration of Chinese immigrants to the present day Thai-Chinese, showing all the hardships that the early migrants had to face, featuring a mix of fascinating old photos with a series of life-size models and replicas.\nWhile the impressive temples and shrines along with all the neon lights at night make for some nifty photos, face it, you’ve come all this way across town for something else; that being to eat and drink. In terms of unique street eats, the area around Yaowarat is pretty unrivalled. I’m not a supporter of bird’s nest and shark fin, so I usually skip all those places, and if I’m in Chinatown early enough, I make a beeline for Khao Raat Gaeng Jek Pui. More popularly known as “musical chairs rice and curry”, this street stall is some 75 years old, and is tucked into an alleyway against a wall of faded shophouse doors and old posters. The curries served at lunch here are the reason why people line up down the block and deal with the fact that there are no tables to eat at. The stall is known by the musical chairs moniker because there are only stools to sit on, and the minute someone gets up from one, his seat will be immediately snatched by someone else. By late afternoon, almost all the food is sold out.\nIf you get nixed at Jek Pui, or actually need a real table to sit at, move up a notch and head to Nai Mong Hoi Tod, where foodies in search of Bangkok’s best fried oyster and mussel crepes flock to indulge in semi-street food nirvana (there is actually a small shop here with a handful of tables). The eatery has received a Shell Suan Shim food award for its oyster crepes, and it really is worth making the trek for. You can choose either regular (which is more like an omelet) or extra crispy.\nThere are plenty of places to eat seafood around Yaowarat. Longstanding restaurants like Hua Seng Hong, Siang Ping Loh, or Tang Jai Yoo, which Anthony Bourdain and Chef McDang have heaped praise on, packed with families getting their fill of stewed goose feet and entire roast suckling pig. The corner of Yaowarat and Soi Padungdao is the scene of seafood bedlam each evening, as both tourists and locals sit out on the corner at Lek and Rut and T & K, two institutions that serve an array of giant prawns, crab, and fish, at prices that are no longer a bargain.\nThe atmosphere is pretty good here, but if you really want atmosphere, head over to Faikeaow Yaowarat, a small street restaurant and site of Chinatown’s beset theatrics, other than taking in a Chinese opera performance. Staples here are the usual tom yum goong, along with entire sea bass pla kaprong neung manao, cooked in a lemon and chili soup base. Yet everyone shows up here for the veggies. Pak bung fai daeng, or stir-fried morning glory, is usually cooked very briefly over a very high flame in a wok, to bring out the best taste, and at Faikeaow Yaowarat, the chef has taken this to far new heights. If we were in another country, there is a good chance the place would be closed down and the chef jailed for being a pyromaniac, but here, just off of Yaowarat, every five minutes the guy lights up half the street in a display pretty much on par with the annual Chinese New Year fireworks show.\nAfter all the flame, you’ll undoubtedly need some cooling off, so wander over to Soi Nana (no, not the red-light one), a small lane that was formerly full of crumbling shophouses which now is home to a wonderful retro bar scene. The top picks here are Teens of Thailand, where thick wooden doors hide a funky speakeasy that is a gin lover’s delight. Have a Thai iced tea gin and tonic or one infused with chrysanthemum made by the superb mixologists, and admire the old movie posters on the wall while talking to your new neighbor.\nJust around the corner, there is the hip Tep Bar, where they make their own upscale ya dong (white spirits), served as a tasting set with three different shots, all accompanied by a group of traditional Thai instrument musicians on weekends. This entire street oozes charm, and is a positive indication of what the future of Yaowarat might look like.\nIf you get the urge for a staycation after a long night out, Shanghai Mansion is Yaowarat’s latest ode to boutique. The design is Chinese Art Deco, and the hotel resembles something out of 1930s Shanghai. Claw bathtubs and old photos grace the charming rooms, and there is a vintage jazz bar upstairs to add to the mood.\nYaowarat Chinatown Heritage Center – Wat Traimit, Tel. 02 623 3329\nKhao Raat Gaeng Jek Pui – Corner of Mangkon Rd and Charoen Krung, Tel. 02 222 5229\nNai Mong Hoi Tod – 539 Soi Prapachai, Tel. 089 773 3133\nFaikeaow Yaowarat – Yaowarat Soi 11, Tel. 097 232 8553\nTeens of Thailand – 76 Soi Nana, Tel. 081 443 3784\nTep Bar – 69-71 Soi Nana, Tel. 098 467 2944\nShanghai Mansion – 479-481 Yaowarat, Tel. 02 221 2121","At over 1,000 years old, Hanoi is not only home to precious historical and spiritual relics, but also remained deeply connected to its culture and unique characteristics. The old quarters feature ancient architecture across dozens of city streets, historic monuments throughout the city will help paint the picture of Vietnam’s history, and sprinkled throughout the city are culinary wonders that would melt a foodie’s heart.\nRelax, and don’t let yourself get lost in the capital! Let’s start a list of places to visit in Hanoi, as recommended by locals!\nHo Chi Minh complex: This structure has become an important memorial site, remembering Ho Chi Minh’s life between the years of 1954 and 1969. At the site there is a mausoleum, fish pond, garden, and even the road where he exercised every morning. The historic stonework symbolizes simplicity, humility, and love for countrymen.\nOne Pillar Pagoda: One Pillar Pagoda is located in the park behind Ong Ich Khiem street near the Ho Chi Minh complex, open weekdays in the summer but closed Mondays and Fridays in winter, there is no entrance fee for tourists. The One Pillar Pagoda was originally built on the orders of King Ly Thai Tong (1028 – 1054) and was completely rebuilt in 1955 after being affected by the war. The One Pillar Pagoda was erected on a small lake with only a single stone pillar, built almost entirely of wood. The large and curved roof is designed to simulate a lotus flower rising from the bottom of the lake.\nTemple of Literature: The Temple of Literature is the first university in Vietnam, considered a historical and cultural relic of Hanoi. Built in 1070 under King Ly Thanh Tong, the Temple is a place of worship for practitioners of Confucianism, including Chu Van An, who was a highly respected teacher in Vietnamese education.\nTran Quoc Buddhist Pagoda: The Tran Quoc Pagoda is one of the oldest pagodas in Hanoi and all of Vietnam. It is located on a peninsula to the south of West Lake, near the end of Thanh Nien Street, Ba Dinh District, Hanoi. Home to over 1,500 years of culture, history and religion, Tran Quoc has been listed in the top 16 most beautiful Buddhist temples in the world by Daily Mail (UK).\nHoa Lo Prison: The Hoa Lo Prison was built by the French colonialists in 1896 under the name “Maison Central”, as a place to detain revolutionary fighters against colonialism. Hoa Lo was one of the most permanent structures in Indochina at the time. From 1963 to 1975, this place was also used to detain American pilots who were shot down by the Vietnamese during the war of the North.\nNgoc Son temple: The Ngoc Son Temple is a shrine located on Ngoc Island of Hoan Kiem Lake, built in the 19th century. During the reign of the 18th Tu Duc (1865), Nguyen Van Sieu repaired the shrine, added more land, built stone embankments around, built Tran Ba temple, and finally a bridge that connected it to the east coast. The bridge is now affectionately called The Huc bridge.\nWater Puppet show: The Thang Long Water Puppet Theater was established in 1969 and is one of the most famous water puppet show venues in Vietnam. Since 1990 the theater has regularly held international tours and has participated in many art festivals around the world.\nThe Old Quarter: The Old Quarter is a long-standing urban area, dating back to the Ly dynasty of Hanoi, located on the east side of the Thang Long royal citadel and stretching to the Red River. Today, the streets still retain traditional markets such as Hang Ma, which specializes in the trade of gold and silver, and Hang Thiec which specializes in the sale of tin and iron appliances. Going through the old town, visitors will see tall, tall houses resembling tubes where residents advertise for their businesses on the very front of their houses.\nWest lake: The walking street along Hoan Kiem Lake (Sword Lake) includes the following streets: Trang Tien, Hang Bac, Ly Thai To, Hang Trong, Hang Gai, Hang Dao. Standing on the banks of the lake, you can see the equally magnificent Hanoi Post Office, which is also a prominent symbol of the capital. The three historical legacies of Sword Lake, Turtle Tower, and Post Office can be said to have been closely linked to each other.\nHanoi cuisine is a culmination of food that spans across both regions, and centuries. A tourist’s culinary experience can begin humbly with sticky rice, traditional noodles for breakfasts, and end with luxurious meals for dinners. From street food to the highest level of cuisine in the most famous restaurants, what are the must-try food in Hanoi?\nVisiting the capital, you can find yourself overwhelmed by the idyllic beauty of the old quarter, famous sights, and especially thousands of specialties, unique souvenirs. Enjoy your shopping in Hanoi at these popular markets and malls.\nNight markets: The Night Market in the Old Quarter is the most famous market in Hanoi, a destination for shopping and sightseeing for both Vietnamese and foreign guests. The market runs from Hang Dao street through Dong Xuan market, to Hang Khoai and Hang Giay. This market sells an assortment of items from clothing and jewelry, to decorations and handicrafts at affordable prices.\nNight Market in Dich Vong – Cau Giay: In the daytime, this market sells necessities as usual but in the evening, the market opens more stalls featuring coloring clothing. The food is also priced modestly, as students are frequent patrons of this market.\nDong Xuan Market: Dong Xuan, one of the largest markets in Hanoi, is a large market building with hundreds of stalls along narrow paths.\n- Vincom Mega Mall Royal City in 72A Nguyen Trai, Thuong Dinh Ward, Thanh Xuan District, Hanoi.\n- Vincom Center Ba Trieu in 191 Ba Trieu Street, Hai Ba Trung District, Hanoi.\n- Metro Thang Long in Pham Van Dong Street, Tu Liem District, Hanoi.\n- Big C Thang Long Supermarket in 222 Tran Duy Hung, Cau Giay District, Hanoi.\nThuong Tra Quan: Located in a former Soviet-style colonnade in Hanoi, Thuong Tra Quan is the space for visitors to enjoy the most exquisite Vietnamese teas, prepared in a traditional teapot.\nÔZÙ by Tadioto: Situated on Ly Dao Thanh Street (Hoan Kiem District), this hidden gem contrasts the noise of the central area. ÔZÙ is quiet and peaceful with green space, small ethnic items, and hot drinks.\nFine Art Museum: The Vietnam Fine Arts Museum is located at 66 Nguyen Thai Hoc street, Ba Dinh district, Hanoi, attracting a large number of domestic and foreign visitors with the quality in the collection of artifacts, artworks, and historic buildings.\nTour with a local\nHa Noi is beautiful and attractive but also mysterious and challenging for tourists to explore. Along with old landmarks which have withstood the test of time, there are many hidden gems offering subtle cultural experiences. All of which our insiders are deeply familiar with as Hanoians. Locals have mastered their capital: they understand Hanoi’s history and can talk about its diverse culture inspirationally. With a guide from Inspitrip, you can expect a truly in-depth tour of the city!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:443346b5-0adf-48ef-9b6b-17af34bf7b8e>","<urn:uuid:c3a81a7a-79be-4687-91da-57e99b041fae>"],"error":null}
{"question":"Which project shows more international collaboration - Hummingbird's agricultural monitoring system or the AIDA asteroid mission?","answer":"The AIDA asteroid mission demonstrates more extensive international collaboration compared to Hummingbird's agricultural monitoring system. AIDA is a joint international collaboration involving multiple organizations including the European Space Agency (ESA), the German Aerospace Center (DLR), Observatoire de la Côte d'Azur (OCA), NASA, and Johns Hopkins University Applied Physics Laboratory. Additionally, its components involve teams from Portugal, Poland, Ireland, Sweden, Finland, Czech Republic, Germany, and Romania, with even potential Japanese Space Agency involvement. In contrast, while Hummingbird has expanded internationally with operations in Ukraine, Russia, Australia, Brazil, and North America, it appears to be primarily a London-based company working with ESA Space Solutions, showing a more limited scope of international collaboration.","context":["Original Article on ESA Space Solutions\nWhen SME Hummingbird was created in 2016, it had a clear mission: “Measure sustainability, optimise food production and push the boundaries of science and technology through sophisticated modelling and predictive analytics”. Through ‘Project Hawking’ with its remote sensing platform, Hummingbird is now solving challenges in yield losses, inefficient inputs, unsustainable practices and poor decision making.\nBefore Project Hawking, Hummingbird Technologies Ltd., an artificial intelligence (AI) business based in London, were identifying crop health issues and forecasting the occurrence of possible diseases and weed pressures in the field by using UAV (unmanned aerial vehicle) imagery processed by its AI algorithms. This imagery was also used to produce variable rate fertiliser and other chemical application maps.\nIngenuity struck with Project Hawking, a collaboration funded and supported by ESA Space Solutions, where Hummingbird started adding satellite observation points throughout the growing season to the process. Hummingbird was now able to build an extensive time series of data to apply its proprietary machine learning techniques..\nThe added dimension of satellite data\nThis deep, new layer of intelligence complemented the existing UAV platform, enabling increased accurately geo-referenced UAV and ground truthed (information gained via direct observation rather than inference) captured imagery during the image acquisition.\n“The first step was for Hummingbird to build the system architecture necessary to process satellite data from ESA as well as other higher resolution commercial imagery,” says Olivier Becu, Technical Officer at ESA. “Next they needed to adapt their existing front-end to display the generated high-value information to customers”.\nHummingbird started to train AI algorithms with the thousands of satellite images they collected and matched with existing datasets. The aim was to develop a processing chain delivering satellite-derived vegetation index maps. Data and imagery were collected from the various satellite providers and processed using the platform, with analysis of crop health, yield and rate of change provided. This included vital data such as the identification of disease and disease prevalence as well as soil type mapping by reflectance data.\nWith Hummingbird’s Crop Identification tool, you can determine the planted area of Canola, Cereals, Pulses and Maize / Soybean in-season. (Image credit: Hummingbird Technologies Ltd.)“Project Hawking cuts farm costs and improves yields by using satellite data to provide predictions in macro analytics and targeted agro-chemical applications, with the aim of reducing blanket agrochemical input. This reduces the negative environmental effects of agrochemical overuse, promotes responsible stewardship, and reduces the natural resistance build-up in crop diseases,” Alexander Jevons, Hummingbird Technologies Ltd.\nIn a matter of months, Hummingbird was set up with multiple satellite data sources delivering timely optical measurements and radar data at various geographical resolutions. Over the course of 2019, Hummingbird made its AI/satellite derived maps available to a set of trial users as part of a pilot project. This project involved large farm management company Velcourt and Cranfield University for scientific support.\nThe fruit of this pilot was a freemium satellite offering that gives users access to basic satellite analysis with the ability to upsell higher resolution analysis where needed. By the end of 2019, more than 5000 farmers across the world had requested access to the data. Many of these farmers have now subscribed to the commercially available Hawking service.\nFor almost all of the stages of crop development, Hummingbird can support the farmers to achieve more with less: seeding, fertilising, treating and forecasting yield for all major crops. Hummingbird has now launched commercial operations in Ukraine and Russia, Australia, Brazil and North America.\n“As a result of Project Hawking and ESA funding Hummingbird has conducted a successful raise of £8.2m and grown the company to over 60 people globally with three international subsidiaries,” Alexander Jevons, Hummingbird Technologies Ltd.\nESA Space Solutions\nESA Space Solutions aims at reaching commercial exploitation of space assets, data and capabilities addressing incubation, proving technical feasibility and business development. This includes the development of operational services for a wide range of users through the combination of different systems, and support in creating viable companies as well as to existing companies.","|Mission type||Dual asteroid probes|\n|Operator||European Space Agency, NASA|\n|Start of mission|\n|Launch date||Hera: October 2023 (proposed)|\nDART: July 2021 (may be delayed)\n|(65803) Didymos orbiter|\n|Orbital insertion||September 2026|\n|(65803) Didymos impactor|\n|Impact date||October 2022 (may be delayed)|\nThe Asteroid Impact and Deflection Assessment (AIDA) mission is a proposed pair of space probes which would study and demonstrate the kinetic effects of crashing an impactor spacecraft into an asteroid moon. The mission is intended to test whether a spacecraft could successfully deflect an asteroid on a collision course with Earth. The concept proposes two spacecraft: Hera (built by ESA) would orbit the asteroid, and Double Asteroid Redirection Test (DART) (built by NASA) would impact its moon. Besides the observation of the change of orbital parameters of the asteroid moon, the observation of the plume, the crater, and the freshly exposed material will provide unique information for asteroid deflection, science and mining communities.\nInitially, Hera's role was to be realized by a much larger spacecraft called Asteroid Impact Mission (AIM). In December 2016 the European Space Agency cancelled the development of the AIM spacecraft after Germany decided to fund the ExoMars project only. NASA has continued on with the development of the DART spacecraft, replacing AIM's role of monitoring the effects of the impact with ground-based telescopes.\nAs DART is currently planned to launch in 2021, Hera would only arrive at Didymos a few years after DART's impact. To maximize scientific outcome, the AIDA team proposes to delay DART's launch so that Hera will arrive at the asteroid first, enabling it to witness DART's impact. While most of the initial objectives of AIDA would still be met if Hera arrives after DART, as a drawback data from direct observation of the impact and ejecta formation will not be obtained.\nThe AIDA mission is a joint international collaboration of the European Space Agency (ESA), the German Aerospace Center (DLR), Observatoire de la Côte d'Azur (OCA), NASA, and Johns Hopkins University Applied Physics Laboratory (JHU/APL). The project was formed by joining two separate studies, DART, an asteroid impactor developed by NASA, and a monitoring spacecraft - ESA's Hera (formerly AIM).\nThe μLidar instrument on board Hera will be provided by a consortium of teams from Portugal, Poland, and Ireland. Two CubeSats will be deployed by Hera while at Didymos. The APEX (Asteroid Prospection Expolorer) CubeSat was developed by Sweden, Finland, Czech Republic and Germany. The Juventas CubeSat is developed by GomSpace and GMV's Romanian division. Along with monitoring DART's impact, Hera itself may also carry an impactor. As proposed by the Japanese Space Agency, this instrument will be a replica of the Small Carry-on Impactor (SCI), an explosively formed penetrator on board the Hayabusa2 asteroid sample return mission. The SCI would hit the asteroid's moon at a speed lower than that of DART. By performing a secondary impact, a comparison of the effects posed by two collisions of different nature on the same asteroid can be realized, helping validate numerical impact algorithms and scaling laws.\nAIDA would target 65803 Didymos, a binary asteroid system in which one asteroid is orbited by a smaller one. The primary asteroid is about 800 m (2,600 ft) in diameter; its small satellite is about 150 m (490 ft) in diameter in an orbit about 1.1 km from the primary. Didymos is not an Earth-crossing asteroid, and there is no possibility that the deflection experiment could create an impact hazard.\nUnder the original proposal, AIM would have launched in October 2020, and DART in July 2021. AIM would have orbited the larger asteroid and study the composition of it and its moon. DART would then impact the moon on October 2022, during a close approach to Earth. AIM would have studied the asteroid's strength, surface physical properties and its internal structure, as well as measure the effect on the asteroid moon's orbit around the larger asteroid. Since the AIM orbiter was cancelled, the effects of the impact by DART will be monitored from ground-based telescopes.\nThe impact of the 300 kg (660 lb) DART spacecraft at 6.25 km/s will produce a velocity change on the order of 0.4 mm/s, which leads to a significant change in the mutual orbit of these two objects, but only a minimal change in the heliocentric orbit of the system. AIDA would provide a great benefit obtaining the size of the resulting impact crater in addition to the momentum transfer measurement, as the effects of porosity and strength of the target are needed to calculate the momentum transfer efficiency.\n- an asteroid framing camera to obtain information on the dynamics of a binary asteroid and physical characteristics\n- a laser altimeter to measure the shapes of the two bodies and constraining the mass of the asteroid's moon\n- a CubeSat for spectral imaging that supports the science and technology objectives of Hera and the AIDA mission\nDART is a 300 kg (660 lb) impactor that hosts no scientific payload other than a 20-cm aperture CCD camera to support autonomous guiding to impact the target body through its center.\nAn optional impactor and high-frequency radar may also be carried by Hera.\n- an asteroid lander (based on the German MASCOT heritage) for in-situ measurements\n- a thermal infrared imager to discriminate different surface properties like rocks or granular surfaces\n- a monostatic high frequency radar to obtain information on the structure of the asteroid's surface\n- a bistatic low frequency radar (on the orbiter and on the lander) that allows a view inside the asteroid and obtain data on its inner structure\n- two interplanetary CubeSats  out of five proposals currently under investigation that support the science and technology objectives of the AIM and AIDA mission. One of the proposed 3U CubeSats under development was DustCube.\n- deep-space optical communication\nBoth AIM and DART were initially approved for preliminary design in February 2015, but in December 2016 the ESA component, the AIM orbiter was not funded in order to help pay for additional expenses of the ExoMars rover. ExoMars rover has been in development since at least 2005 when over half a billion Euros was authorized for it.\nGermany offered to cover 35 million of the 60 million needed for the AIM portion to continue, however, this was not enough to continue development. Nevertheless, NASA has continued with the DART mission to (65803) Didymos, and will measure the effects of the impact from ground-based telescopes. Following AIM's cancellation, ESA director Jan Wörner stated his intentions to revive the mission in some form. Etienne Schneider, Luxembourg's deputy prime minister expressed regret at AIM's cancellation, and commented that his country would continue to advocate for the realization of the mission.\nAs of March 2018, Hera proposal is in Phase B1, where upon the preliminary design is being drawn up. A system requirement review (SRR) is scheduled to be conducted in January 2019, followed by a preliminary design review (PDR) in May 2020.\nIn 7 January 2019, the Hera team announced the selection of APEX and Juventas as CubeSats to be carried by the spacecraft.\n- Asteroid impact avoidance\n- B612 Foundation\n- Don Quijote, AIDA's predecessor proposal\n- The Spaceguard Foundation\n- Bergin, Chris (January 7, 2019). \"Hera adds objectives to planetary defense test mission\". NASASpaceFlight.com. Retrieved 2019-01-11.\n- Course corrector. Adam Hadhazy, Aerospace America. October 2017.\n- Carnelli, Ian (11 October 2017). \"The Hera Mission Study\" (PDF). ESA. Retrieved 2018-06-11.\n- \"AIDA study\". ESA. 19 December 2012. Archived from the original on 20 October 2014. Retrieved 2014-09-19.\n- AIDA mission rationale Archived May 11, 2015, at the Wayback Machine. ESA, 25 May 2012.\n- Michel, Patrick; Kueppers, Michael; Sierks, Holger; Carnelli, Ian (26 April 2017). \"European component of the AIDA mission to a binary asteroid: Characterization and interpretation of the impact of the DART mission\". Advances in Space Research (Article) (published 18 December 2017). 62 (8): 2261–2272. doi:10.1016/j.asr.2017.12.020. Retrieved 2018-06-11.\n- ExoMars Rover Gets Funding Despite Schiaparelli Mars Lander Crash. Alixandra Caole Vila, Nature World News. 7 December 2016.\n- NASA presses ahead with asteroid mission despite ESA funding decision. Jeff Foust, Space News. 13 December 2016\n- Asteroid Impact & Deflection Assessment (AIDA) study Archived 2015-06-07 at the Wayback Machine.\n- Carnelli, Ian (31 January 2018). \"Status of AIM/Hera\" (PDF). ESA. Retrieved 2018-06-11.\n- \"CubeSats joining Hera mission to asteroid system\". Space Daily. January 8, 2019. Retrieved 2019-01-11.\n- \"AIDA: Asteroid Impact and Deflection Assessment Mission Under Study at ESA and NASA\" (PDF). Observatoire de la Côte d'Azur. February 2015. Retrieved 2015-03-29.\n- Cheng, A.F.; Michel, P.; Reed, C.; Galvez, A.; Carnelli, I. (2012). DART: Double Asteroid Redirection Test (PDF). European Planetary Science Congress 2012. EPSC Abstracts.\n- Cubesat Companions for ESA's Astroid [sic] Mission. Source: ESA. November 2, 2015.\n- Preliminary orbital analysis for a CubeSat mission to the Didymos binary asteroid system. Advances in Space Reearch, vol. 62, issue 8, pp 2290-2305. 15 October 2018. doi:10.1016/j.asr.2017.12.014\n- Foust, Jeff (February 15, 2017). \"NASA presses ahead with asteroid mission despite ESA funding decision\". SpaceNews. Retrieved 2018-06-11.\n- Andone, Dakin (July 25, 2017). \"NASA unveils plan to test asteroid defense technique\". CNN. Retrieved July 25, 2017.\n- Henry, Caleb (February 15, 2017). \"Luxembourgian minister unwilling to let ESA asteroid mission die without a fight\". SpaceNews. Retrieved 2018-06-10."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:bdde2593-6bc6-4c98-ab56-160a13f8122e>","<urn:uuid:c872c479-5a6b-43aa-a34f-8e9b9aece8d7>"],"error":null}
{"question":"Historical reason why bread scoring developed - purpose then vs now?","answer":"Historically and currently, the primary purpose of scoring bread remains functional rather than decorative. Scoring creates intentional weak spots that allow trapped gases to escape in a controlled manner during baking. Without scoring, the gases from fermentation would burst out randomly at the seams during baking, like a tire blowing out, resulting in poor rise and appearance. While modern bakers may create intricate designs, the fundamental purpose is still to allow proper expansion and gas release during oven spring, providing structure to the final loaf.","context":["Learn how to score sourdough bread before baking with these 7 tips! Scoring your sourdough bread with a bread lame is essential to the baking process. Slashing the dough with a sharp razor after the final proof and before baking allows the dough to expand in the oven and let the gasses release. This post helpful guidance for scoring bread with ease so that the cuts are smooth rather than ragged, and you can create the beautiful loaf of sourdough that you were hoping for.\nYou’ve made it through both the bulk fermentation and the final rise of your sourdough bread recipe. Now it’s time to score it, slashing the dough with a bread lame to allow it to expand while baking!\nIf you’ve been having issues getting clean cuts when trying to score sourdough, these tips will help you achieve the finished look you were expecting. First, I suggest starting with my beginner sourdough bread recipe and practicing on several bakes.\nMuch of proper scoring has to do with practice, confidence, and swift movements. And remember, a simple score can be just as a beautiful as one that is very intricate. Although it may seem that the purpose of scoring sourdough is to add an artistic look to the loaf like you see on my Rye Sourdough, there’s actually more to its importance.\nThe Purpose of Scoring Sourdough Bread\nWhen making sourdough, gases are trapped instead the dough during fermentation and are what leavens the bread via your sourdough starter. But eventually, those gases need to escape.\nWhen the dough hits the heat of the oven it will start to rise rapidly, springing up and pushing against the tight surface. Without scoring, that energy would have nowhere to go besides bursting outwards at the seams, like a tire blowing out. It won’t rise as well either.\nBy scoring the dough, the gases have somewhere to escape and the bread can get a lovely rise just as we had hoped. Scoring will also give structure to how the end loaf will look.\nHOW TO SCORE SOURDOUGH BREAD VIDEO:\nTop 7 Tips for Scoring Sourdough Bread:\nCold dough is MUCH easier to score. 90% of the time I do the final rise overnight in the refrigerator, which gives the loaf better flavor from the increased fermentation time, but also allows me to score the dough cold, straight from the fridge. Cold dough holds its shape better when it comes out of the banneton, and the blade guides through it much easier than warm dough. No dragging will be present, unless you’ve overproofed your dough.\nDo not use a knife to score sourdough, use a bread lame. A regular knife does not move as swiftly through the dough, and drags. It’s also difficult to be precise with the cuts, as a knife blade is much longer and harder to maneuver.\nMake sure to score deep enough, from 1/4 inch to 1/2 inch deep, erring on the later. This ensures the score doesn’t fuse back together when the dough expands in the oven. Pull the blade towards you while gliding the blade into the surface of the dough and continue to pull the blade through the length of the cut.\nMake confident, swift cuts with your sharp bread lame. One of the mistakes I see sourdough beginner’s is scoring very slowly, trying to be careful and create a beautiful design. In doing so, the lame drags and they struggle to get a decent score that will allow the bread to expand in the oven. Instead, the taut surface responds best to quick, assertive cuts, so worry less about the design, and more about opening up the dough.\nDip the razor blade into water before scoring. This will help the blade glide and create smooth cuts, rather than dragging and leaving ragged marks.\nIf you want an “ear” on your sourdough, score at a shallow 45 degree angle to create a lip that will open up as the bread bakes. You’ll also need proper fermentation and enough strength in shaping to achieve the elusive ear.\nOnce the dough is scored, get it into the oven right away. If you let it sit, the dough will start to deflate and lose some of its strength because it has been cut open.\nVisual Guide: How to Score Sourdough Bread\nMy Favorite Bread Lame:\nOver the years I’ve tried many different bread lames, and the Monkey Wire Shop “UFO” bread lame is the best by far. You’ll see it in the above photos, a round wooden disk with razor attached. It makes scoring much easier compared to a lame with a longer handle.","Scoring Bread made with high-hydration dough\nScoring hearth loaves made with high hydration doughs is a challenge. Expressions of frustration with this in TFL postings are not rare. Much good advice regarding how to accomplish nice scoring of wet, sticky dough has been offered, but it is scattered. So, I thought I would share my own advice on this subject in one place.\nThese two bâtards are San Joaquin Sourdoughs. (For the formula and procedures, please see San Joaquin Sourdough: Update. Today's bake was different only in that I used just 100 g of 100% hydration starter.) The effective hydration of this dough is 74.5%. It is a sticky dough and a good test of one's shaping and scoring abilities. Yet, as you can see, it is possible to get nicely shaped loaves from this dough with cuts that bloom nicely and form impressive ears.\nThe key points in achieving this are the following:\nA Key Point\nGluten must be well-developed by mixing and fermentation. Good dough “strength” is important for crumb structure, but also for successful shaping. It is even more critical in wet doughs, because these tend to spread out and form flat loaves if their shape is not supported by a good, strong sheath of gluten.\nPre-shaping and shaping can add to dough strength through additional stretching of the dough in the process of forming the loaves. A wet dough like this needs to be tightly shaped. This is a challenge, because it also has to be handled gently. Rough handling will result in excessive de-gassing and a dense loaf. It will also tend to make the dough stick to your hands more. When it sticks, it tears and makes weak spots in the loaf surface which are likely to burst during oven spring. The goal is to form the tight gluten sheath by stretching the dough and sealing the seams while avoiding downward pressure on the dough pieces being shaped. “An iron hand in a velvet glove.” Dough sticking to your hands can be decreased by lightly flouring your hands, wetting them or oiling them. However, the most helpful trick is to touch the dough lightly and as briefly as possible each time.\nThe loaves need to have lateral support during proofing. This is to prevent them from spreading out. Support can be provided by a banneton (proofing basket) or on baker's linen or parchment, where folds in the couche material, sometimes reinforced with rolled up towels or the like under the material, provide the support. (I suppose the “ultimate support” is provided by a loaf pan.)\nThe ideal material to support proofing loaves is absorbent. Baker's linen, cloth-lined bannetons and floured, coiled cane brotformen all absorb some moisture from the surface of the loaves in contact with them. This makes that surface a bit less sticky and easier to score without the cut edges sticking to the blade excessively. (I do not want the loaf surface so dry it forms a “skin.”) I like to proof loaves with the surface I am going to score on the absorbent material. This means baguettes and bâtards are proofed smooth side down (seam side up). Note that baking parchment is not absorbent, so, while advantageous for other reasons, it is not ideal for this purpose.\nLoaves should not be over-proofed. A greatly over-proofed loaf may actually collapse and deflate when scored. Short of that, it will still have less oven spring and bloom. This is a relatively greater problem with high-hydration doughs which are more delicate to start with. I find the “poke test” as reliable as any other criterion for when a loaf is ready to bake. However, it is not quite as reliable with very wet doughs. Neither is the degree of dough expansion. You just have to learn through experience with each formula when it is perfectly proofed.\nLoaves should be scored immediately after transferring to a peel and immediately before loading in the oven. Letting high-hydration doughs sit too long on the peel is asking them to spread out, especially if they have been scored ,which disrupts the supportive gluten sheath.\nThe wetter the dough, the shallower the cuts. This is not as critical for boules, but, for long loaves like baguettes and bâtards, if you want good bloom, and especially if you want good ear formation, The cuts need to be very shallow (about 1/4 inch deep) and at an acute angle (30-45 degrees). A deeper cut creates a heavy flap that will collapse of its own weight and seal over, rather than lifting up to form an ear as the cut blooms open. The cuts made on the loaves pictured here were barely perceptible on the unbaked loaf surface. Resist the temptation to re-cut!\nMinimize dough sticking to the blade and getting dragged, forming a ragged cut. The cuts need to be made swiftly and smoothly, without hesitation. A thin, extremely sharp blade is best. Some find serrated blades work well for them. I find a razor blade on a bendable metal handle works best for me. The cuts are made with the forward end of the blade only, not the whole length. Some find oiling or wetting the blade lessens sticking. I have not found this necessary.\nHumidify the oven with steam during the first part of the bake. This delays firming up of the crust which would restrict the loaf from expanding (oven spring) and the cuts from opening (bloom).\nMost of these points apply to scoring in general. I have indicated where there are differences or special considerations applying to high-hydration doughs.\nFinally, a mini-glossary:\nScoring refers to the cuts made on the surface of the loaf prior to baking. The primary purpose of scoring is to create an artificial weak spot and direct expansion of the loaf to it so the loaf doesn't burst at some random point. Secondarily, the scoring pattern influences the final shape of the loaf. And lastly, the pattern of cuts can be decorative and, if unique, can serve as a “signature” for the baker.\nOven spring is the expansion of the loaf when exposed to oven heat.\nBloom refers to the opening up of the scoring cuts during oven spring. The French term for this is grigne.\nEar, when pertaining to bread, is a flap of crust that separates from the surface during oven spring and bloom.\nFor additional information regarding scoring and a more basic introduction to this topic, please see The Scoring Tutorial Also, excellent examples of shaping and scoring can be found in videos on youtube.com, particularly those made by Ciril Hitz, and on the King Arthur Flour web site. I have not found any that address the peculiar challenges presented by higher-hydration doughs, however."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:302aea3c-e96e-442e-aa9d-6b729a21f02e>","<urn:uuid:c3a9deae-0662-469d-a8ca-6bb91994637a>"],"error":null}
{"question":"How do the environmental concerns in African science fiction compare with the current challenges faced by novella publishers in the speculative fiction market?","answer":"African science fiction portrays environmental devastation as a key concern, with toxic shantytowns, nuclear wastelands, and environmental destruction being common themes, particularly reflecting how developing nations have borne the costs of technological progress through resource extraction. Meanwhile, in the current speculative fiction market, novella publishers face significant structural challenges - submission windows are very short and infrequent, competition is intense, and even established magazines that accept novellas publish them rarely. While environmental devastation shapes the creative vision of African SF writers, practical market constraints shape how longer-form speculative stories reach readers.","context":["A new anthology of science fiction by African writers taps into real and modern anxieties.Aman Sethi\nOnce the Resident Welfare Association in my residential colony made the link between cellphone radiation and cancer, they responded by shutting down some of the transmission towers. I returned to my parental home in South Delhi to find my father making calls by catching stray signals from the balcony.\nThe residents, he told me, welcomed the move until someone suggested that cellular handsets compensated for weak signals by powering up their inbuilt mobile antennae, subjecting the user to more, rather than less, radiation.\nApparently the modern condition is to exist in a state of constant irradiation, the nature of which — malignant or benign — is now routinely discussed by my parents and their friends. After several weeks of dropped calls, a majority are willing to believe that cellular radiation is mostly harmless but there is always the creeping unease of the unexplained, yet correlated fact: Whatever happened to all the sparrows in our neighbourhood? What killed them?\nAfroSF, an intriguing new anthology of science fiction by African writers (currently available as an E book online), taps into such peculiarly real and modern anxieties in a set of 22 fictional variations of the technological encounter: i.e. the point where the engine of progress appears to stall and misfire. Many of the contributors are first-time authors, which makes AfroSF a handy manual to the dystopic visions of some of the continent’s emerging futurists. The texts are diverse, but a few themes persist through the collection like a viral strain.\nThe future, as gleaned from AfroSF, is a bleak and uniquely third world dystopia instantly familiar to most Indian readers. The Earth is mostly unlivable, cities have been reduced to a set of toxic shantytowns, the countryside is a nuclear wasteland and power is concentrated in the hands of an opaque cabal of faceless bureaucrats and shadowy oligarchs. Artificial intelligence is omniscient, malevolent and on the brink of evolving into a new life form.\nShorn of the gadgetry and paranoia common to most sci-fi, visions of the future — much like reminiscences of the past — are invariably reflections of our present.\nThe emphasis on environmental devastation is not surprising, given that the developing world — and Africa in particular — has paid much of the price for most of today’s technological marvels. Entire nations have been laid waste in the search for the uranium, copper, tantalite, aluminium, rare earth and oil that provide the raw materials and energy consumed by the server-farms and transmission networks that undergird our online lives.\nIn “The Rare Earth”, a story by Biram Mboob set in the near future in Kivu in the Democratic Republic of Congo, a secretive messiah promises to free his people even as Indian and Chinese companies battle for minerals. While in “Notes from Gethsemane”, by Tade Thompson, a radioactive pit in the heart of Lagos is the backdrop for the tale of two brothers struggling to survive in a tough neighbourhood. Right through the anthology, characters routinely slip on gasmasks, hide behind protective shields, and live in claustrophobic climate-controlled enclaves.\nThe state’s urge to accurately identify, surveil and control its citizens is another frequent concern. In “Home Affairs”, Sarah Lotz describes a South Africa in which concerns about corruption have meant that all clerks have been replaced by seemingly incorruptible robots. Falling foul of the robot could rob you of your identity and all accompanying entitlements.\nIn “Proposition 23”, a novella by Efe Okogu, all citizens are connected to each other via a neuro that makes them visible to the state and allows them to log into some sort of online matrix. Undesirables are simply disconnected from the neuro network and thereby deprived of work, food, housing, healthcare, and eventually life.\nIn “The Foreigner”, by Uko Bendi Udo, a young boy of Nigerian and alien parentage must fight a callous bureaucrat to gain Nigerian citizenship and his inheritance.\nThe primacy of individual identities, and the consequent fear of its loss, is understandable in the context of the modern regime of targeted entitlements adopted by most developing countries. A government department set up by a software mogul, established by executive action rather than parliamentary debate, to collect the biometric information of all citizens, would fit right into AfroSF but in fact exists in the “real world”. It’s called the “The Unique Identification Authority of India”, and its sole task is to gather biometric data in exchange for ID numbers.\nOnce granted a unique identification number, citizens may access the shrinking bouquet of entitlements offered by the State, but what happens if the system refuses to recognise you? Apparently, that happens too — in about 15 percent of cases, according to the findings of a parliamentary committee.\nYet, too many of the stories fall into the “thinly veiled social critique” genre, rather than embracing the opportunity to free themselves from the shackles of the everyday.\nPerhaps the greatest poverty of our times is the absence of a truly radical imagination of the future; particularly at a time when dissent has been sanitised and co-opted by legions of earnest young men and women spouting an NGO-speak of “pilot projects”, “eligible beneficiaries” and “relevant stakeholders”.\nThe authors also seem to be writing to a fixed word count that proves inadequate to the task of fleshing out a strange and alien world.\nStories begin with a moment of dissonance, develop a premise and end in a flash of incomprehension, rather than following the premise through to its conclusion.\n“Azania”, by Nick Wood, is one of the few exceptions to this general rule and is perhaps the collection’s best piece as a consequence.\nThe writing is intimate, hallucinatory, and lush, and describes a genuinely unsettling encounter between a lost spaceship and strange new world, the loneliness of outer space and the angular dynamics between a crew that has been cryogenically frozen for 12 long years. At each step in the narrative, Wood chooses the more difficult option and fortunately pulls through; the ending has the satisfying click of a well-crafted door, beyond which lies a universe of possibilities.\nAfroSF, Science Fiction by African Writers, edited by Ivor W. Hartmann.","The next update of Aswiebe's Market List will be after 6/15/2022. Permanent link to this newsletter in the archives: https://aswiebe.com/marketlist/may-2022/\nThoughts in Passing\nThis (theoretically May) update is going out a couple of days late, so it’s extra large. More new markets! More useful links! So the timing seems right to talk about extra large stories: novellas.\ntldr; Be patient, keep an eye on current submission calls (YES, I will list novella calls in this market list when I see them), and consider the advantages and disadvantages of publishing in a magazine.\nHow long is a novella? A novella is 17,500 – 39,999 words long, as defined by the Nebula Award categories.\nSelling a novella is hard. Here are some options for science fiction, fantasy, and horror novellas, both publishers and magazines. There are a few publishers known for publishing novellas, but their unagented submission windows tend to be very short and far between, and there’s a lot of competition. Other publishers who occasionally publish novellas will often have special novella calls, but information about their novella publishing schedule is not even listed on their website the rest of the time. There are several magazines who accept novella-length submissions, but although they are open to the idea, they do not publish many novellas, they don’t pay royalties, and your novella will only be distributed as part of that magazine’s issue. (Yes, self-publishing a novella is always an option–there are special challenges there too!–but this is about selling it to a publisher.)\nPUBLISHERS – OPEN\nPressfuls Novellas wants fantasy, horror, adventure, romance, and crime/mystery, pays 35% royalties.\n(Pressfuls Magazine appears defunct, but they’re still publishing longer works.) https://pressfuls.com/submit-a-story/\nMidnight Bites ANTHOLOGY SERIES wants novelette and novella horror, 10k – 25k words themed and unthemed, pays $50 plus 25% royalties. Currently seeking carnie horror and medical horror. https://cronegirlspress.com/submissions/\nPUBLISHERS – UPCOMING SUBMISSION CALLS\nNeon Hemlock wants SF, fantasy, horror, weird fiction, and slipstream, especially queer. Pays royalties, or advance plus royalties. Award-winning. Open June 12th to 25th 2022 for trans women writers and writers of color. Open to all writers October 11th to 24th 2022. https://www.neonhemlock.com/submissions\nUnited Faedom Publishing wants novelettes, novellas, and novels, pays $75 for novelettes and ? for others. OPENS JULY 2022. https://unitedfaedompublis.wixsite.com/unitedfaedompub/novelettes-and-novellas\nInterstellar Flight Press has a one-time call for horror novellas including SF horror and fantasy horror, pays 30-40% royalties plus possible advance. Open to submissions 10/1/22 – 12/1/22. https://www.interstellarflightpress.com/submissions.html\nPUBLISHERS – CURRENTLY CLOSED UNTIL ??\nTor.com (novellas) wants fantasy and SF, pays pro rates of advance + royalties or higher royalty-only rate. Award-winning. CURRENTLY CLOSED. Unclear if/when they will reopen for unagented novella submissions, but it’s been a couple of years. https://www.tor.com/fiction-submissions-guidelines/\nNightfire (Tor) wants horror novels and novellas, pays pro rates of advance + royalties or higher royalty-only rate. CURRENTLY CLOSED. Unclear if/when they will reopen for unagented novella submissions. https://tornightfire.com/nightfire-slush-submission-guidelines/\nUncanny (novellas) wants SF/F, pays $.10/word. Publishes 1 novella a year depending on funding. Award-winning. CURRENTLY CLOSED – LOOK FOR THEM TO OPEN NEXT YEAR. https://www.uncannymagazine.com/submissions/\nQueen of Swords Press wants novels and novellas of around 40k words, set in fantastical worlds, especially with a queer focus. Pays royalties. CURRENTLY CLOSED. https://queenofswordspress.com/about-queen-of-swords-press/submissions/\nStelliform wants science fiction, fantasy, quiet horror and literary works with speculative elements, pays 2¢ CAD per word advance (up to $2000), plus royalties. CURRENTLY CLOSED. https://www.stelliform.press/index.php/submissions/\nWyldblood Press wants speculative fiction (science fiction, fantasy or horror) novellas and novels, pays royalties. CURRENTLY CLOSED. https://wyldblood.com/guidance-submissions/\nMagazines that accept short novellas (up to the 20-25K word range) include Asimov’s, Reckoning, Pulp Literature, Clarkesworld, The Magazine of Fantasy and Science Fiction (F&SF), and sometimes Escape Pod (reprints only).\nMagazines that accept full length novellas or have no wordcount limit include Analog, Cosmic Roots and Eldritch Shores, Beneath Ceaseless Skies, and ParSec. Be cautious about submitting to places that don’t list a maximum wordcount; they don’t always expect or accept novellas.\nKeep an eye out for anthology calls with no word limit whose guidelines explicitly mention novellas, like Sovereign: An Anthology of Black Fantasy Fiction (2023), due 7/16/22.\nJune’s update will be shorter, and I’ll talk about where to sell flash fiction!\n(Do you have a writing question? Send it to me, either by replying to this email or by using the contact form on my website, and it may get answered in the next newsletter.)\nWhat I’ve been up to lately, writing-wise:\nI’ve started work on a new novel, working title Desolation Station Salvage. I love this stage. Everything is shiny and new, and all kinds of fun random ideas are popping up as I write.\nI’m looking forward to in-person convention 4th Street Fantasy in a couple of weeks, where I’ll be on panels discussing ambiguous endings and PoV.\nThings Shiny or Useful\nArchive of all shiny or useful links: https://aswiebe.com/marketlist/shiny-or-useful-writing-links/\nThe Indie Files: Make the Most of New Book Announcements: https://www.sfwa.org/2022/05/18/indie-files-new-book-announcements/\nHow to Write a Depressed Character That Won’t Depress Your Reader: https://horrortree.com/how-to-write-a-depressed-character-that-wont-depress-your-reader/\nWork of Art: Business Skills for Artists Toolkit: https://springboardforthearts.org/professional-growth/work-of-art-program/\nIngramSpark Academy’s How to Self-Publish: https://www.ingramspark.com/how-to-self-publish-course\nIngramSpark Academy’s How to Build an Author Platform: https://www.ingramspark.com/author-platform-course-description\nFrom Panic to Process: What Taking Criticism Actually Means: https://www.uncannymagazine.com/article/from-panic-to-process-what-taking-criticism-actually-means/\nThree Agent Types to Avoid and the One You Won’t See Coming: https://nelsonagency.com/2021/02/three-agent-types-to-avoid-and-the-one-you-wont-see-coming/\nAll the Writing Talent in the World Won’t Save the Wrong Story: https://nelsonagency.com/2022/04/all-the-writing-talent-in-the-world-wont-save-the-wrong-story/\nUpcoming Virtual Conventions/Workshops\n(Any registration fees are noted.)\nCymera (£50), June 3-5, 2022: https://www.cymerafestival.co.uk/\nWestercon (?), July 1-4, 2022: http://westercon74.org/\nChiCon 8 / WorldCon ($30), Sept 1-5, 2022: https://chicon.org/\nThe Nebula Conference ($150) is over for 2022, but purchasing a membership now still gets access to recorded panels and year-round special events: https://membership.sfwa.org/event-4563942\nAward-winning Neon Hemlock will be open for speculative fiction novella submissions June 12 – 25, 2022 for BIPOC and trans women authors, October 11 – 24, 2022 for all. Pays royalties, or advance plus royalties.\n:Genres: Science Fiction, Fantasy, Horror, Supernatural, Slipstream, & Weird. Hybrid work or difficult to categorize novellas are also welcome.\nStandalone works, although they may be connected to other series or work.\nWe are particularly interested in work that explores some element of queer experience, broadly speaking.Neon Hemlock\nBasics: speculative fiction, 17,500-40,000 words, pay ?, no reprints, due 6/12/22-6/25/22 and 10/11/22-10/24/22.\nMarket List Updates\nTo see all the details about these new listings and what they’re looking for, as well as hundreds of other listings, go to Aswiebe’s Market List and download the latest version of the spreadsheet. Note: going forward, limited demographic market listings will be italicized.\n|Name||What they want||Pay Per Word USD (originals)||Flat Pay USD (originals)||Website||Notes|\n|Uncanny||SF/F||$0.100||https://uncannymagazine.com/submissions/||Fast response time. ONE-TIME SUBMISSION CLOSURE UNTIL ?|\n|Worlds of Possibility (Julia Rios)||SF and fantasy, with a sense of hope||$0.100||https://worldsofpossibility.moksha.io/publication/worlds-of-possibility/guidelines|\n|Augur Magazine||Literary SF/F, fabulism, slipstream||$0.088||http://www.augurmag.com/submissions/||80% Canadian. ONE-TIME SUBMISSION PERIOD: Opens 6/30/22|\n|Metastellar||Fantasy, SF, and horror flash fiction||$0.080||https://www.metastellar.com/write-for-us/flash-fiction-story-submission/||ONE-TIME SUBMISSION WINDOW 10/1/22 – 10/31/22. NOTE: submission gives right of publication, even without a contract signing|\n|Pseudopod (Podcast)||Horror and dark fantasy||$0.080||http://pseudopod.org/submissions/||An Escape Artists publication. ONE-TIME SUBMISSION PERIODS: 3/1/22-7/31/22 (2022 anthologies and collections), 8/12/22-8/21/22|\n|Gargantua (Air and Nothingness Press) ONE-TIME ANTHOLOGY – DUE 12/1/22-1/31/23||All genres, flash fiction, themed to massive engineering megastructures||$0.080||http://aanpress.com/submissions.html|\n|Monstrous Futures (Dark Matter Ink) ONE-TIME ANTHOLOGY – DUE 6/1/22-6/30/22||Near-future dark SF||$0.080||https://darkmattermagazine.shop/pages/dark-matter-presents-monstrous-futures|\n|World of Juno, The (Space Wizard Science Fantasy) ONE-TIME ANTHOLOGY – PITCH DUE 6/1/22||Shared world science fiction||$0.080||https://spacewizardsciencefantasy.com/submissions/||Note the 150-word story pitch is due 6/1/22. The story itself is due 7/14/22.|\n|Crack in the Code (Mocha Memoirs) ONE-TIME ANTHOLOGY – DUE 9/30/22||SF themed to robots, AI, or cyborgs going off-programming||$0.080||https://mochamemoirspress.com/write-for-us/|\n|Asimov’s Science Fiction||Character-oriented SF, borderline fantasy, slipstream, surreal. No sword & sorcery.||$0.080||http://www.asimovs.com/contact-us/writers-guidelines/|\n|Baffling Magazine (Neon Hemlock)||All speculative flash fiction||$0.080||https://www.bafflingmag.com/submissions|\n|Campfire Macabre Vol 2 (Cemetery Gates Media) ONE-TIME ANTHOLOGY – DUE 6/1/22-8/15/22||Horror flash fiction, themed to When We Were Getting High, My Last Trick ‘r Treat, Body Grotesquerie, Ominous Visitors from Deep Space, or Out in the Fields, Forests, and Lakes||$0.080||https://cemeterygatesmedia.com/submissions/|\n|Solarpunk Magazine||Solarpunk||$0.080||https://solarpunkmagazine.com/submissions/||ONE-TIME 2022 Submission periods: 6/20-7/4/22 Solarpunk at Work, 9/1-9/14 and 11/1-11/14 general solarpunk.|\n|Cast of Wonders Podcast||Clean YA SF/F/H||$0.080||http://www.castofwonders.org/submissions/||ONE-TIME 2022 SUBMISSION PERIODS: 06/15/22 – 06/30/22 (Young Authors), 08/01/22 – 08/31/22 (Flash Fiction Contest) ### Query first for > 6,000 words.|\n|Constellation / Constelación Magazine||Spanish or English speculative fiction, themed||$0.080||https://www.constellationmagazine.com/submissions||ONE-TIME CLOSURE until mid-September 2022|\n|Dark Matter Magazine||Science fiction and sci-fi horror||$0.080||https://darkmattermagazine.com/submission-guidelines/||NOTE: This is NOT the same publication as Dark Matter Zine.|\n|Podcastle (Podcast)||Fantasy fiction||$0.080||http://podcastle.org/guidelines/||An Escape Artists publication. Original fiction up to 6,000 words, reprints up to 17,000. ONE-TIME SUBMISSION THEME: Indigenous Magic (#ownvoices) 7/1/22 – 7/31/22|\n|Librarian, The (Air and Nothingness Press) ONE-TIME ANTHOLOGY – DUE 6/30/22||Speculative fiction, themed to a helpful traveling librarian||$0.080||http://aanpress.com/submissions.html|\n|Galaxy’s Edge||SF and Fantasy||$0.070||https://www.galaxysedge.com/submissions/||Submissions open early on Mondays when they’re taking submissions, then close when they hit their quota. May be closed to submissions even if Moksha says they’re open, if there is no submission type to select. Long response time.|\n|Fiends in the Furrows III, The: Final Harvest ONE-TIME ANTHOLOGY – DUE 7/31/22||Folk horror||$0.060||https://www.nosetouchpress.com/call/|\n|Dracula Beyond Stoker||Horror inspired by Dracula, themed issues||$0.050||https://www.dbspress.com/submissions|\n|Planet Scumm||SF and weird fiction||$0.050||https://www.planetscumm.space/submit||RIGHTS: Also takes audio rights. ONE-TIME SUBMISSION PERIOD: opens 7/8/22|\n|Apparition Lit||Speculative fiction, themed. Separate monthly flash fiction contest.||$0.050||https://apparitionlit.com/submissions/||Submission periods: 2/15 – 2/28, 5/15 – 5/31, 8/15-08/31 (ONE-TIME 2022 THEME: Nostalgia), 11/15 – 11/30, with a 1-week extension each period for BIPOC.|\n|Story Unlikely||All genres, including bizarro and speculative fiction||$0.050||https://www.storyunlikely.com/#submit|\n|Old Moon Quarterly||Weird sword-and-sorcery||$0.050||https://www.oldmoonpublishing.com/what-we-want|\n|Hidden Villains: Arise (Inkd Publishing) ONE-TIME ANTHOLOGY – DUE 6/1/22-8/31/22||All speculative fiction, themed to the title||$0.050||https://inkdpub.com/submissions/|\n|Ember: A Journal of Luminous Things||All genres for all age groups, especially children ages 10-18||$0.020||https://emberjournal.org/submission-guidelines/|\n|Utopia Science Fiction||SF, especially hard SF||$0.010||https://www.utopiasciencefiction.com/submit|\n|Dread Imaginings||Quiet horror||$0.010||https://dreadimaginings.com/submissions/|\n|Tales to Terrify PODCAST||Horror and dark fantasy||$0.010||https://talestoterrify.com/submissions/|\n|We’re Here: The Best Queer Speculative Fiction (Neon Hemlock) ANNUAL ANTHOLOGY – DUE 12/31||Queer speculative fiction published this year.||$0.010||https://www.neonhemlock.com/submissions||Reprints only from the current year.|\n|Rakehell||Swashbuckling tales, all genres||$0.010||https://rakehellmagazine.com/submissions/|\n|Reader Beware! (DarkLit Press) ONE-TIME ANTHOLOGY – DUE 8/1/22||YA horror themed to 80s-90s nostalgia||$0.010||https://darklitpress.com/reader-beware/|\n|Cosmic Horror (Eerie River Publishing) ONE-TIME ANTHOLOGY – DUE 9/15/22-11/15/22||Cosmic horror themed||$0.008||https://www.eerieriverpublishing.com/open-submission|\n|Folk Horror (Eerie River Publishing) ONE-TIME ANTHOLOGY – DUE 7/1/22||Themed to folk horror||$0.008||https://www.eerieriverpublishing.com/open-submission|\n|It Calls From Below (Eerie River Publishing) ONE-TIME ANTHOLOGY – DUE 8/1/22-9/1/22||Horror themed to the underground||$0.008||https://www.eerieriverpublishing.com/open-submission|\n|Phantasmical Contraptions and More Errors (JayHenge Publishing) ONE-TIME ANTHOLOGY – DUE 7/31/22||Steampunk, dieselpunk, biopunk, etc.||$0.005||http://www.jayhenge.com/callforstories.html||Still open to subs 1/9/22|\n|Professor Feiff’s Compleat Pocket Guide to Xenobiology for the Galactic Traveller on the Move (JayHenge Publishing) ONE-TIME ANTHOLOGY – DUE 7/31/21||Themed to alien flora and fauna||$0.005||http://www.jayhenge.com/callforstories.html|\n|Sapiens Plurum & Future of Life Institute Short-Fiction Contest ANNUAL CONTEST – DUE 4/22 – 6/1||SF, themed to optimistic SF. ONE-TIME 2022 THEME: Inventing Beautiful Futures||$1,000.00||https://sapiensplurum.org/|\n|riddlebird||Literary fiction, including literary genre fiction||$100.00||https://www.riddlebird.com/submission-guidelines|\n|Etherea Magazine||All speculative fiction, especially F/SF.||$71.88||https://ethereamagazine.com/submissions/||Length: 500 – 1,000 words and 2,000 – 5,000 preferred|\n|Paranoid Tree||Flash fiction, all genres||$50.00||https://www.paranoidtree.com/|\n|Taco Bell Quarterly||Literary, all genres, themed to Taco Bell||$50.00||https://tacobellquarterly.org/submission-guidelines/|\n|Consultations of Sherlock Holmes, The (Belanger Books) ONE-TIME ANTHOLOGY – DUE 9/15/22||Mysteries themed to traditional Sherlock Holmes||$50.00||https://www.facebook.com/AuthorDerrickBelanger/posts/3294508860834029|\n|Detective and the Clergyman, The (Belanger Books) ONE-TIME ANTHOLOGY – DUE 10/15/22||Mysteries themed to traditional Sherlock Holmes partnering with traditional Father Brown||$50.00||https://www.facebook.com/AuthorDerrickBelanger/posts/3294508860834029|\n|Sherlock Holmes: Adventures in the Realms of H.P. Lovecraft (Belanger Books) ONE-TIME ANTHOLOGY – DUE 11/15/22||Mysteries themed to traditional Sherlock Holmes in a Lovecraftian world||$50.00||https://www.facebook.com/AuthorDerrickBelanger/posts/3294508860834029|\n|Horrifying Tales of Wonder (House Blackwood) PODCAST||Themed to weird fiction set in the 1880s-1940s||$50.00||https://www.houseblackwood.net/horrifying-tales-of-wonder/|\n|Midnight Bites ANTHOLOGY SERIES||Novella and novelette horror, themed and unthemed||$50.00||https://cronegirlspress.com/submissions/||ONE-TIME THEMES OPEN UNTIL FULL: carnival horror, medical system horror|\n|Tales from Brackish Harbor (Quill and Crow Publishing) ONE-TIME ANTHOLOGY – DUE 6/1/22||Shared world Gothic cosmic horror||$40.00||https://www.quillandcrowpublishinghouse.com/brackish-harbor|\n|Extremely Bizarre (Planet Bizarro) ONE-TIME ANTHOLOGY – DUE 7/1/22||Extreme horror with bizarro elements or vice versa||$36.75||https://www.planetbizarro.com/submissions|\n|On the Premises Mini-Contest RECURRING CONTEST||Themed contests with very limited wordcounts.||$35.00||https://onthepremises.com/current-contest/||Mini-contest submission periods vary|\n|Along Harrowed Trails (Timber Ghost Press) ONE-TIME ANTHOLOGY – DUE 8/31/22||Horror set in the Old West||$35.00||https://www.timberghostpress.com/along-harrowed-trails.html|\n|Fear Forge Quarterly Anthology||Horror and dark fantasy, themed||$30.00||https://www.horrorsmithediting.com/opencall||ONE-TIME WINTER QUARTER 2022 THEME OPEN UNTIL FULL: forges|\n|Bloodless (Sliced Up Press) ONE-TIME ANTHOLOGY – DUE 7/31/22||Horror, themed to no mention of blood||$30.00||https://sliceduppress.com/submissions/|\n|Solarpunk Magazine Micro Fiction Contest – MONTHLY CONTEST||Solarpunk with a monthly theme||$25.00||https://solarpunkmagazine.com/monthly-micro-fiction-contest/||ONE-TIME 6/17/22-6/23/22 THEME: solarpunk, no special theme|\n|Dismember the Coop ONE-TIME ANTHOLOGY – DUE 7/1/22 – 8/31/22||Horror themed to the music of Alice Cooper||$25.00||https://www.facebook.com/groups/1030647144551138/posts/1030647424551110/||Paid charity anthology.|\n|Short Reads (Black Hare Press)||Dark fiction||$25.00||https://www.blackharepress.com/submissions/|\n|Space Horror (Ladies of the Fright) ONE-TIME ANTHOLOGY – DUE UNTIL FULL||SF horror||$25.00||https://www.ladiesofthefright.com/blog/2022/5/4/space-horror-submission-guidelines|\n|Et Sequitor Magazine||All genres, themed: continuing from the previous story||$25.00||https://www.etseqmag.com/Submissions.php|\n|Their Ghoulish Reputation (Dark Lake Publishing) ONE-TIME ANTHOLOGY – DUE UNTIL FULL||Folk horror||$25.00||https://darklakepublishing.com/migrate/folk-horror-anthology-submission/|\n|Tales From the Ruins: A Post-Apocalyptic Anthology (Black Beacon Books) ONE-TIME ANTHOLOGY – DUE 7/31/22||Themed to Post-apocalyptic fiction||$21.31||https://blackbeaconbooks.blogspot.com/p/submissions.html|\n|Still of Winter (Unsettling Reads) ONE-TIME ANTHOLOGY – DUE 7/1/22 OR UNTIL FULL||Creepy stories themed to a tree in winter||$20.00||https://unsettlingreads.squarespace.com/submissions-stillofwinter|\n|Sprawl Mag, The||Speculative fiction||$15.50||https://www.thesprawlmag.ca/guidelines|\n|Fall Into Fantasy (Cloaked Press) ANNUAL ANTHOLOGY – DUE 7/10||Fantasy||$15.00||https://www.cloakedpress.com/fallfantasy/|\n|Hexagon Magazine||All speculative fiction (SF/F/H)||$11.87||https://hexagonmagazine.ca/submit/|\n|Framework of the Human Body (Bell Press Books) ONE-TIME ANTHOLOGY – DUE 6/15/22||Literary, weird fiction, and speculative fiction, themed to the human body||$11.86||https://bellpressbooks.com/submissions/|\n|Love Letters to Poe||Gothic flash fiction themed to Poe stories||$5.00||https://loveletterstopoe.com/submit-a-story/|\n|Interstellar Flight Press Novellas||ONE-TIME THEME 10/1/22-12/1/22: Horror novellas||https://www.interstellarflightpress.com/submissions.html|\n|Neon Hemlock Novellas||Science fiction, fantasy, horror, slipstream, and weird, especially queer stories||https://www.neonhemlock.com/submissions||2022 SUBMISSION PERIODS: June 2022 PoC and trans women, October 2022 all authors.|\n|Valravn (Raven Canticle Press) ANNUAL ANTHOLOGY – DEAD MARKET||Fantasy, horror, SF, and espionage/thriller, especially with horror elements||$0.100||https://www.ravencanticlepress.com/submissions/|\n|Lamplight – DEAD MARKET||Dark literary, horror, dark spec-fic, and noir||$0.060||http://lamplightmagazine.com/submissions/|\n|Kanstellation Magazine – DEAD MARKET||General fiction and SF, themed||$30.00|\n|Fabled Journal – DEAD MARKET (no longer accepting submissions)||Myth, folklore, gothic, paranormal, and historical flash fiction.||$10.00||https://www.fabledcollective.com/journal-submissions.html|\n|Asylum Diaries, The – DEAD MARKET||Cosmic horror or body horror||$9.63|\n- To unsubscribe, simply reply to this email with “unsubscribe” in the subject line.\n- If you need to update your name, just fill out the newsletter subscription form again. Use the same email address.\n- If you need to change your email address, please unsubscribe from your old email. Then fill out the newsletter subscription form.\n- Feel free to share this newsletter with others by whatever means you like, as long as you include all of it."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:e023a8de-5392-4e5b-a570-0bed89dd46ff>","<urn:uuid:742cfc44-b70f-4da1-adc6-35fdb29ff18a>"],"error":null}
{"question":"What are oligosaccharides in breast milk and why they important for babies?","answer":"Oligosaccharides are complex structures of sugars that are the third most common component in breast milk, after lactose and lipids. They are important because they promote the growth and development of healthy gut bacteria, which helps lower the risk of intestinal infections in infants. While these sugars are also present in cow's milk, they are less common and have a different composition, which is why formula manufacturers must use genetic modification of bacteria to produce sufficient oligosaccharides.","context":["While most health experts today recommend breastfeeding babies over formula-feeding, not all mothers are able or willing to do so.\n“In the first few months of life, when the baby is completely dependent on milk, there is no real substitute for breast milk, ” says Nurit Argov-Argaman from the Department of Animal Sciences at Hebrew University of Jerusalem. “This is because breast milk has short-term positive effects on health and development during infancy, but some of the effects are long-lasting and extend into adulthood.” That is why Argov-Argaman co-founded the startup Bio Milk, which operates at the intersection of biotech and food tech to develop technology to produce cultured cow and breast milk.\nBio Milk CEO Tomer Aizen says the company is developing a process that will allow the production of cultured human breast milk, which will include all of the complex composition found in natural breast milk secreted from the mother’s body.\n“Indeed, this represents the breast milk alternative that’s as close as what nature has to offer,” he tells NoCamels.\nThere are many infant formulas on the market, but none of them come close compositionally to real breast milk. Experts say that in addition to feeding the baby, breast milk helps build an infant’s immune system and lowers the risk of infections.\n“The compounds on the market address the baby’s nutritional needs, but they lack the specific compounds that improve the baby’s immune system because the formulas are based on cow’s milk, which is less adapted to a baby’s digestive system,” says Einat Talmon, a breastfeeding consultant and author of The Israeli Breastfeeding Guide.\nA decade ago, scientists made a breakthrough in the field when they began to understand how to separate human milk from complex structures of sugars called oligosaccharides, the third most common component of breast milk, after lactose and lipids. These sugars are important because they encourage the growth and development of healthy gut bacteria that effectively lower the risk of intestinal infections in infants.\nAlthough these sugars are also found in cow’s milk, they are noticeably less common and differ in composition. Therefore, in order to replicate human breast milk, formula manufacturers must genetically modify bacteria so that they can produce sufficient oligosaccharides, and this is a complicated process.\nAs part of their process, Aizen says Bio Milk scientists also separate oligosaccharides and include them in the newly created cultured breast milk.\n“We understand that our ability to technologically replicate breast milk in laboratory conditions is very limited. There are still many unknown factors regarding breast milk,” says Argov-Argaman. “We do not yet fully understand the role and significance of all the elements found in real breast milk for the health of the baby. Not only does the composition vary from woman to woman, but it also varies with the passage of time, whether it be a few hours or a few weeks. Its composition is uniquely adapted to the baby.”\nBreast milk outside the mother\nBiomilq, an American company with a similar name to the Israeli company, has already raised USD 3.5 million from Bill Gates’ investment firm, Breakthrough Energy Ventures. This company provides some serious competition to its Israeli counterpart, as they have developed their method of lab-engineered breast milk by extracting cells from the mammary gland, the organ that produces milk in a woman’s body. They do this by performing a minimally invasive biopsy on a woman to create their own custom-made milk.\nThe company has also discovered a way to multiply these cells as a substrate that includes nutrients and minerals. The milk-producing cells undergo rigorous testing to ensure its consumption safety and that it reflects the properties of authentic breast milk.\nThe company estimates its product will be available to the public by 2025. Aizen says the process of engineering breast milk that was developed by Israeli company Bio Milk is more convenient and less expensive than BioMilq’s process because “we take from the mammary gland to develop cells, then reproduce those cells over and over again. Bio Milk’s process does not require having to go back to the mother.”\nBio Milk currently holds patents for the production of cultured milk from animals within laboratory conditions, but now the company has set its sights on producing cultured breast milk.\n“The best way to make breast milk accessible is through the production of breast milk outside the mother,” says Argov-Argaman. “At Bio Milk, we use the same tissue and try to grow the cells in the lab so that we continue to develop and produce milk like a breastfeeding mother.”\n“The technology for the production of cultured breast milk is similar to the production of cultured milk from other animals. It requires a long and comprehensive regulatory process,” she adds.\nIn October, they raised an initial round of NIS 12 million (USD 3.7 million) from private investors. Bio Milk is in the final stage of becoming a publicly listed company. When this happens, they will receive an additional NIS 7 million (USD 2.18 million) in capital, according to Aizen. They hope to release the first sample of cultured cow’s milk for testing in 2021 and breast milk in 2022.\nBetter for the environment?\nIn addition to potentially providing important health benefits, the efforts of Bio Milk and other similarly oriented companies may prove to be cleaner environmentally compared to formulas derived from cow’s milk\nLivestock agriculture is responsible for 14.5% of global greenhouse gas emissions. The dairy cattle industry emits the equivalent of 2.128 million tonnes of carbon dioxide (2.128 gigatonnes CO2) per year in the form of methane and nitrous oxide in addition to CO2.\n“There is usually a correlation between the cost of production and the product’s environmental consequences,” says Hagit Ulanovsky, an expert in health and environmental risk management at SP Interface. “And we currently do not have the ability to environmentally assess the effects of these evolving products compared to those on the market because there are new technologies,” she adds.\n“It is important to note that the decision whether to breastfeed or not is first and foremost a personal decision of the mother,” Ulanovsky adds. “Women should be given the legitimate option not to breastfeed. Therefore, the production of a better, healthier, and safer formula can strengthen the mother’s free choice.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:b579a0a1-341b-486d-b000-f8ecdab04e38>"],"error":null}
{"question":"How does the structural support mechanism differ between a paper fir tree centerpiece and a towel origami cat when it comes to maintaining their final shape?","answer":"The paper fir tree and towel cat use different methods for structural stability. The fir tree maintains its shape through sharp creases and strategic folding of the paper, with the final step involving arranging the flaps to form the tree shape. In contrast, the towel cat's stability is achieved through a more complex system: it uses multiple towels with the body created from rolled bath towel sections that are folded under for support, while the head is formed by precise rolling and folding of a separate towel with specifically created ear points. The cat's design also incorporates a tail made from a hand towel positioned between body rolls, demonstrating a more elaborate support system compared to the simpler paper tree structure.","context":["This origami fir tree is simple to make and has many uses as winter holiday décor. Make one to decorate a mantle or to put inside a holiday pop-up greeting card. Put two or more together to make a holiday centerpiece. You can decorate this tree any way you like – glitter, beads, ribbon, paint, etc. are all options. Make your fir tree green and decorate it like a conventional holiday tree or make one in white and with silver embellishment.\nThe first thing you’ll need for this project is paper. Use any paper you happen to have on hand for practice. Once you have successfully completed a tree, then move on to other types of decorative paper. There are only two conditions for the paper that you use. First, the paper has to be cut into a perfect square. The model will not fold correctly otherwise.\nTurn a standard sheet of rectangular copy paper into a square by folding one short edge over to lie completely along a long edge. Cut off the excess strip of paper to get your square. Second, the paper that you use should be heavier than a standard sheet of loose-leaf notebook paper. For this project, a heavier holiday gift wrapping paper would work nicely. Experiment to find a paper that works best for you.\nYou’ll also need an appropriate, well-lit place to work. In order to achieve the most accurate folds and sharpest creases possible (crucial elements in the success of your project), you should fold against a hard, flat, stable surface. Avoid soft or cushioned surfaces like beds, pillows, or carpets. Use a hard floor, table, or hardback book instead. Also, keep a ruler or pencil on hand. You’ll find that running the edge of either of these objects (or something similar) over each crease as you work will give you even sharper creases.\nFollow the directions carefully and only move on to the next step once you are sure that you have successfully completed the previous steps.\nFollow the directions carefully\n- Position a square of paper on your work surface so that its points are facing up and down, left and right. If you are using two-sided paper, the color you want for the exterior of your tree should be face down.\n- Bring the left point over to meet the right point. Crease and unfold.\n- Bring the top point down to meet the bottom point. Crease and unfold.\n- Re-position the square so that its edges are now facing up and down, left and right.\n- Bring the top edge down to meet the bottom edge. Crease and leave folded.\n- Grasp the edges of the resulting rectangle between thumb and forefinger and gently push inward. The model should collapse along pre-existing crease lines to form a multi-layered triangle.\n- Bring the left point of the triangular-shaped model (both layers) over to meet the right point. Crease and leave folded.\n- Set the model upright on its base and arrange the flaps to form the fir tree.","Towel animals are fun to fold and make cute surprises for visitors to your home. Once you learn how to make a few of these fun creatures, you are sure to impress your family and friends with them.\nTowel Origami Swan\nA towel swan is the perfect introduction to towel origami. To get started, you'll need a white bath towel, a white hand towel, and a smooth folding surface.\nSpread the bath towel out so one of the long sides is facing you. Start rolling the left and right sides of the towel towards the mid point of the towel.\nKeep rolling until you reach the middle of the towel. Rotate your shape 90 degrees.\nThe point becomes the beak of the swan. Gently shape the towel back on itself to make a swan shape. Roll the hand towel lengthwise. Fold it in half, and put it on top of the body of the swan. This provides the support needed to prop up the neck of your creation, which gives it a more realistic looking appearance. Without the extra towel, your swan is easily mistaken for a duck.\nFolded Towel Cat\nCat lovers will enjoy making this towel origami folded cat. You will need one bath towel and two hand towels. The towels should all be the same color.\nTo get started, open a large bath towel wide on the floor. From one of the shorter ends, begin to roll the towel up until you reach the center. Repeat with the other side, making tight rolls. They should meet in the center.\nHolding both rolls in your hands, turn the end closest to you under so the bottom third is underneath the rest of the length. This will be the body of your cat.\nPosition a hand towel in front of you so that the shorter edges are closest to your body. Fold it in half lengthwise. Begin to roll the towel into a cone shape, starting at the upper right hand corner and stopping about half of the way down the towel. Try to keep the roll as tight as possible.\nNext, take the unfolded edge and begin to roll it towards the center. Now, you should be rolling the towel towards the other roll. Continue to roll until they come together.\nPick up both rolls together and check that the hand towel is tightly rolled up. Position the cone shape with the large end down in between the rolls of the first towel. Position the cone at the end of the towel right above where you folded it under. This should help to hold it in place. This completes your cat's tail.\nTake a third bath towel and fold in half. Take the edge with the flaps and fold towards the middle. However, extend the fold about 2/3 of the way over. Pick up the towel by placing your fingers at both points on the edge, where you just folded it. This will allow the extra portion to fold back, behind the original fold.\nLay the towel on the floor again. Then pick up one of the corners and fold inward, creating a triangular shape. It should extend past the folded edge. You are creating the cat's ears here. Do the same thing on the opposite end.\nStart on one side of the towel and begin to roll towards the middle. Do the same on the other edge so that it meets in the middle. Pick up this third towel and tighten up the folds as necessary. Then, lay it on top of the first towel towards the middle. The ears should be pointing back towards the cone, which is the cat's tail.\nWhen completed, you end up with a cat that looks as though he is sitting with his front legs stretched out in front of him.\nA towel elephant is one of the most popular animals found on cruise lines and at luxury resorts. You will need one bath towel and one hand towel for this design. Both towels should be the same color.\nLay your bath towel out in front of you horizontally. Fold the left side over about six inches, then fold this folded end over another six inches. Repeat this process on the right side. This step is important because it creates the weight at the bottom of your elephant's feet, which is needed to make your finished model stand upright.\nRoll the top and bottom ends in towards the middle so you have a long scroll shape.\nFold this shape in half and stand it upright to make your elephant's legs. The flat side of the towel should be facing inward.\nPosition the hand towel in front of you horizontally. Roll the left and right rides in to the middle at an angle in the same way you did to form the base of your towel origami swan. This will form the head and trunk of your elephant.\nFlip the rolled towel over. Turn the pointed end up to make a trunk for your elephant. Fold the top layer of the end with the two rolls down to form a face for the elephant. Adjust the folds on the far left and right to make ears.\nPlace the the hand towel on top of the bath towel to complete your towel origami elephant.\nInventing Your Own Towel Animal Designs\nOnce you've folded these animals, try your hand at a cute towel bunny complete with accessories. Since many towel animal designs use the same basic folding techniques, you can then try inventing your own designs after folding these animals. Your signature creation is sure to bring a smile to your guest's face!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:facf39b8-161d-4bad-83e1-05e03e16418b>","<urn:uuid:62e05490-9bfb-4a9e-a7db-4990d08becc2>"],"error":null}
{"question":"What are the cost-saving options for wedding photo books, and what legal requirements must be met regarding copyright permissions?","answer":"For cost savings on wedding photo books, individuals can design layouts themselves and submit print-ready files to the publisher, avoiding design costs of $200-$600. However, regarding legal requirements, you must either purchase the negatives from your photographer or obtain a signed release allowing you to use the images in printed form. Copyright laws prohibit publishing houses from printing your book without proof of image ownership or a photographer's signed release. As demonstrated in the Brandy Melville case, using photos beyond specifically agreed-upon usage rights can result in copyright infringement and legal damages.","context":["How much should one budget for a wedding album? The only price I’ve seen was $1800 and that seemed VERY high to me.\nDawna Smith Custom Photo Book & DVD Services\nThe $1,800 price that the photographer quoted you sounds like a mid size custom wedding photo book, probably a 9.5×13 book with a minimum of 40 pages. Not knowing the size of the book, cover choice, or how many pages and images were included, the price could actually be considered average.\nListed below is some helpful information regarding the difference between albums and books, and what to expect when producing just one book.\nWedding albums are different than wedding photo books. You place already printed photos into an album, whereas digital photo books are graphically designed using your images, then the design is printed, and sewn and bound into a personalized book.\nSome albums, depending on the quality of the cover can be as high as $400 or more. Some photographers just sell you the album and give you the prints. Others take extra time and enhance the images graphically using software, then print the images and artfully arrange the prints within the album.\nA personalized photo book, depending on the quality desired, can range from $50 to several thousand. What makes the difference in price is the quality of materials used in the process, and if you require graphic design or photo restoration services. If you’re on a strict budget and don’t mind having a book where the pages can be “dog eared”, similar to what you get in a book store, then there are several companies that allow you to upload low resolution images to their site using templated software. The end result is a cloth covered hard back book printed on 85 or 100 pound weight paper, similar to those children’s books where you can personalize the book with the child’s name.\nHigher end custom designed wedding photo books are usually printed as double page spreads using high quality photographic lab paper (archive life 200+ years), which is flush mounted on board to help protect the prints, and then are sewn and bound into a book. The pages are about the thickness of a credit card. They are designed and sewn in such a manner that the book lies flat, similar to a magazine, without any image loss in the center of the page. These books can range from 8×12 up to 16×20 in size.\nKeep in mind that these types of books usually include more graphic design elements, photo enhancements, and are crafted to last for a couple hundred years. The old adage “you get what you pay for” definitely applies to wedding photo books and good photographers.\nSome individuals save money on their wedding photo books by designing the layouts themselves and submit print ready image files to the publisher. This cuts out the design cost, which can range from $200 to $600 just for the graphic design portion. If you are able to design your own book, it’s definitely one way to save some serious dollars. Check with the publisher to see if they offer this option. Keep in mind that if you want to design your own layout using a professional photographer’s images, you’ll have to either purchase the negatives from your photographer or get a signed release from your photographer allowing you to use the images in printed form. Copyright laws prohibit a publishing house from printing your book unless you can prove that you own the images or have a signed release from your photographer.\nPeople often don’t realize what it takes to create a coffee table photo book, like the kind you see at a book store. An author can spend literally several years developing the book, including the time the images were first taken, the production process of choosing the images and writing the text, and the final product.\nNext time you are at a book store, check out some of the coffee table photo books. Notice how they often have text descriptions included adjacent to the image, or perhaps they have designed the book with special graphic design elements. See how the binding is actually sewn to help hold the pages together, ensuring longevity with a quality binding. Keep in mind that the books in the store are NOT produced using photographic paper, but regular offset paper.\nThe author most likely spent many thousands of dollars having their book graphically designed and the text typeset, and then a separate design created for the dust jacket cover. During and after the final design and typeset, an editor had to read and check for type placement as well as ensuring that all graphic design elements had been included as agreed. The editor has to make sure that the pictures presented in the book are as good as or better than what was supplied.\nAfter all that, the author or publishing house has to cough up the money for a minimum run of 5,000+ books and hope that book stores pick up the product for sale to individuals.\nPublishers have always been able to produce just one book, but it has never been cost effective for an author. Usually the cost of the initial production is averaged out over the sale of 5,000 to 20,000 books. With the advent of digital publishing, brides can now have just one book produced of their wedding, but they must realize that the cost to do so is still pricey and cannot be averaged out over the retail sale of their wedding book…unless the bride is a famous movie star!!\nSadly, we tend to be an “instant society” where we want things done now and at the lowest possible price. It takes more than a click of a button to create a quality photo book. Having a wedding photo book produced can take from 8 to 12 weeks, depending on your design preferences. If you design your own, you are still looking at the time it takes you to design plus 4 to 6 weeks for just print and binding services.\nTry to allocate an adequate portion of your wedding budget to your memories, such as your photographer, videographer, album or book. Often, brides spend more money on food and beverages than they do for their photographer or printed images.","Do You Have All the Rights Required to Publish the Photos Purchased by Your Business?February 28th, 2017\nBy Pascal Lauzon, Partner, Lawyer and Trademark Agent\nYou arrange for someone to take photos of your business for your website. Can you reuse these photos on your company’s Facebook page? What about your personal LinkedIn profile? It all depends on the scope of the rights you acquired from the photographer.\nThe owner of a copyright (in this case, the photographer) can definitely authorize another party to use their work (i.e., the photos of your business), but they can also impose “limitations relating to territory, medium or sector of the market or . . . scope.” In today’s digital era, the “material forms” available to publish works is almost infinite, with new forms arising on a regular basis. Meanwhile, the rights we have (or think we have) can be insufficient and lead to unfortunate scenarios involving copyright infringement.\nIn Chung v. Brandy Melville Canada Ltd., 2016 QCCQ 2735, the clothing retailer, Brandy Melville, hired a photographer to take photos of one of its employees who would act as a model to promote their clothes. However, discussions between the photographer and the company only took place between the photographer and the employee he was hired to photograph. Brandy Melville was under the impression—and this is what it had asked of its employee—that the company would acquire all of the rights to the photos produced as a result of the photo shoot. But in the conversations that transpired between the employee and the photographer, it was agreed that the photos in question could only be used on the company’s Instagram and Facebook accounts. Since he was working for free, the photographer’s objective was to attract attention to his photos in hopes that they would be published in major fashion magazines one day, in return for royalties.\nBrandy Melville later reused the photos on a promotional postcard it handed out to customers. Following a lawsuit for copyright infringement instituted by the photographer, the Court ruled that this use was clearly unauthorized and in violation of the photographer’s copyright. It ordered the company to pay the photographer $5,000 in damages.\nWithout a clear contract detailing the rights that allow the client to freely reproduce or use a photo, or any other type of work protected by copyright, problems can arise. In discussions with an author who is being commissioned to create something (such as a photo, text, logo, etc.), the client can presume that it will be entitled to use the work within the strict framework of the uses that have been specifically discussed. Anything beyond that is risky. But if discussions are entrusted to an employee who does not understand the company’s potential intentions regarding the work that is commissioned, the risk is considerably greater.\nCopyright law presents a number of subtleties, and the many platforms that can be used to distribute works each have their own distinct features. Are you about to undertake a project? To make sure you acquire all of the rights you may need someday, contact our team of specialists."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:9187c7b7-b88a-4fd5-bf2c-591f5bc6f2af>","<urn:uuid:82f4b1e8-30d3-4710-b5c5-e4678cfde714>"],"error":null}
{"question":"What is the historical significance of the oldest drawings discovered in the Czech Republic's Kateřina Cave?","answer":"The lines and geometrical images found on the walls of the Kateřina Cave in the Moravian Karst protected nature reserve date back to around 4,200 BC in the early Stone Age, making them the oldest drawings on present-day Czech territory. While their meaning remains unclear, researchers at Palacký University in Olomouc recently confirmed that these drawings are indeed prehistoric rather than modern creations.","context":["The oldest drawings on present day Czech territory are lines and\ngeometrical images created on cave walls by hunters in the early Stone Age,\nmeaning around 4,200 BC, Právo reported on Tuesday, citing new\nResearchers have been examining the drawings, which are on the walls of the Kateřina Cave in the Moravian Karst protected nature reserve. The meaning of the drawings is unclear, they say.\nArchaeologist Martin Golec of Palacký University in Olomouc said his team only recently ascertained that the drawings were in fact prehistoric and were not made in the modern age.\nA team of Czech divers and land surveyors are the first in Europe to have succeeded in scanning a flooded cave system. Using film footage from the water-filled Chýnov cave in south Bohemia, they created a detailed and accurate three-dimensional map. The main advantage of the so-called videogrammetry is its simplicity and speed.\nA rescue team was able to free a speleologist trapped in the Nová Drátenická cave in Moravský kras (Moravian Karst) on Sunday. The man’s legs were pinned in an apparent cave-in; a spokesman for the fire brigade confirmed his rescue as complex, as the man was located several hundred metres away from the cave opening. Once freed, the person was taken by helicopter to Brno’s Teaching Hospital. The injuries to his legs were described as serious.\nA team of explorers recently found the world’s deepest underwater cave located in the eastern part of the Czech Republic. A Czech-Polish expedition, led by the legendary Polish diver Krzysztof Starnawski, descended deep into the flooded limestone cave called Hranice Abyss and found it to be far deeper than previously thought. According to their measurements, the cave is 404 meters deep, 12 meters deeper than the previous record holder, 392-meter-deep Pozzo del Merro in Italy.\nA team of explorers has just confirmed that Hranice Abyss, located in the eastern part of the Czech Republic, is deepest underwater cave on the planet. A Czech-Polish expedition, led by the legendary Polish diver Krzysztof Starnawski, descended deep into the flooded limestone abyss Hranicka Propast this week and found it to be far deeper than previously thought. The underwater cave is 404 meters deep, making it the deepest underwater cave in the world, 12 meters deeper than the previous record holder, 392-meter-deep Pozzo del Merro in Italy. News of the discovery appeared in the National Geographic which co-funded the expedition.\nSlovakia’s Mountain Rescue Service has confirmed that a Czech speleologist died in Slovakia at the weekend in a cave-in at a recently discovered natural cave near Banská Bystrica. The man lost consciousness when he was buried under debris in the collapse; colleagues attempted artificial resuscitation but the man’s injuries proved too severe. Some twenty members of the Mountain Rescue Service were called to the scene. The site, known as Jeskyni ztraceného prstenu (Cave of the Lost Ring) was found in June.\nParamedics took part in a six-hour rescue operation in a cave in Moravský kras on Saturday evening to save a speleologist who was injured at the bottom of the cave. The man, who explored the cave with a team of colleagues, bruised his ankle some 25 metres under ground. The rescuers had to widen one the cave's tunnel to be able to bring the man out and then they had to carry him through difficult and snowy terrain to a site accessible by ambulance.\nThe region of Broumov with its picturesque rock formations has long attracted tourists and climbers. Now, scientists have revealed that the area has far more to offer - a vast network of sandstone caves hidden below ground. Spanning more than 27 kilometres, the caves are the most extensive underground sandstone labyrinth in Europe. Research work in the area started two years ago and cave explorers have only now finished mapping the whole space. Earlier today I spoke to Petr Kuna from the nature reserve of Broumov and asked him to tell me something\nThe Czech Republic’s most famous angler has caught a fish weighing 190 kilograms! A giant bomb shelter which was to have served as the operational headquarters of the Czechoslovak communist leadership in the event of a Third World War has become a public attraction. And, a cat is a better companion than you might think. Find out more in Magazine with Daniela Lazarová."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:32464646-35c1-412f-8550-7cd3b12f7f07>"],"error":null}
{"question":"Are cameras installed in commercial airplane bathrooms for surveillance?","answer":"No, there are no cameras in commercial airplane bathrooms. While flight attendants monitor the bathrooms for safety, visual surveillance equipment is never installed inside the lavatory. This is protected by Federal Aviation Administration (FAA) regulations that explicitly prohibit the use of cameras in airplane bathrooms.","context":["Airplane bathrooms have always been a source of curiosity for many travelers. The small, cramped space leaves little room for privacy. This leads to the common question – are there cameras in airplane bathrooms? Read on as we uncover the truth about cameras in those tiny airplane lavatories.\nIf you’re short on time, here’s a quick answer to your question: No, there are no cameras in commercial or private airplane bathrooms. While airplane bathrooms are monitored by flight attendants for safety, visual surveillance equipment is never installed inside the lavatory.\nWhy People Wonder if There Are Cameras\nHave you ever wondered if there are cameras in airplane bathrooms? It’s a question that has crossed the minds of many travelers. Let’s explore the reasons why people have this curiosity and concern.\nCuriosity About the Enclosed Space\nAirplane bathrooms are small, enclosed spaces that can feel quite private. This sense of privacy can make people wonder if there are hidden cameras monitoring their every move. The idea of being watched in such an intimate setting can be unsettling for some.\nWhile it may seem like an invasion of privacy, it’s important to note that the vast majority of airlines prioritize passenger safety and comfort. They adhere to strict regulations and policies that prohibit the installation of cameras in airplane bathrooms.\nConcerns Over Safety and Security\nAnother reason why people wonder about cameras in airplane bathrooms is the concern over safety and security. Air travel is heavily regulated and monitored to ensure the safety of passengers. However, there have been instances of misconduct by individuals, which has fueled these concerns.\nIt’s important to remember that airlines have robust security measures in place to prevent any unauthorized access to passenger areas, including bathrooms. These measures include regular inspections, surveillance cameras in public areas, and strict access control protocols.\nSuspicion of Being Watched\nIn today’s digital age, where privacy breaches are a growing concern, it’s not surprising that some individuals are suspicious of being watched everywhere, including airplane bathrooms. With the prevalence of smartphones and other recording devices, the fear of being secretly recorded has become more prominent.\nHowever, it is crucial to differentiate between legitimate concerns and unfounded paranoia. Airlines are committed to maintaining the privacy and security of their passengers, and the installation of cameras in airplane bathrooms would be a violation of these principles.\nRegulations Prohibiting Bathroom Cameras\nThe Federal Aviation Administration (FAA) has strict regulations in place to ensure the safety and privacy of passengers on board aircraft. One of these regulations explicitly prohibits the use of cameras in airplane bathrooms.\nThis rule is in place to protect the privacy of passengers and to prevent any potential misuse of recorded material.\nThe FAA regulations also extend to electronic devices that have the capability to record. This means that even if a camera is not specifically installed in the bathroom, passengers are still not allowed to use their personal devices to record in these private areas.\nIt is important to note that violating FAA regulations can result in serious consequences for both passengers and airlines. Any individual found to be using a camera in an airplane bathroom may face legal action and potential bans from flying.\nIn addition to the FAA regulations, airlines themselves also have policies in place to prevent the use of cameras in airplane bathrooms. These policies are in line with the industry standards and are aimed at ensuring the comfort and safety of passengers.\nAirlines typically include clear language in their terms and conditions, stating that the use of cameras in bathrooms is strictly prohibited. This information is often communicated to passengers through safety briefings and announcements made by the flight crew.\nPassengers are encouraged to report any suspicious behavior or potential violations of this policy to the flight crew or airline staff. This allows the airline to take appropriate action and maintain the integrity of their policies.\nMonitoring and Safety Features\nWhen it comes to air travel, safety is of utmost importance. Airlines have implemented various monitoring and safety features to ensure the well-being of their passengers. One common concern among travelers is whether there are cameras in airplane bathrooms.\nLet’s take a closer look at the monitoring and safety features in place.\nLocked Door Indicators\nPrivacy is a top priority in airplane bathrooms. To address concerns about cameras, airlines have installed locked door indicators. These indicators provide a clear visual signal to flight attendants when the bathroom is occupied.\nThis allows them to ensure the privacy of passengers while maintaining the overall safety of the aircraft. So rest assured, you can use the bathroom without worrying about being monitored.\nAirplane bathrooms are equipped with smoke detectors, just like other areas of the aircraft. These detectors are essential for ensuring the safety of passengers in case of a fire or smoke-related incident. They are designed to detect any signs of smoke or fire and alert the flight crew immediately.\nThis allows for prompt action to be taken, ensuring the safety of everyone on board.\nFlight Attendant Monitoring\nFlight attendants play a crucial role in maintaining the safety and security of the aircraft. They are responsible for monitoring various aspects, including the bathrooms. While there are no cameras in airplane bathrooms, flight attendants regularly check on them to ensure cleanliness, restock supplies, and address any maintenance issues.\nTheir presence and vigilance contribute to a safe and comfortable flying experience for passengers.\nCase Studies and Examples\nRecent Incidents Involving Bathrooms\nWhile there have been occasional reports of hidden cameras in public restrooms, including airplane bathrooms, it is important to note that such incidents are extremely rare. Airlines prioritize passenger safety and privacy, and any violation of this trust is taken very seriously.\nHowever, there have been a few isolated incidents that have raised concerns among passengers.\nOne example of a recent incident involving airplane bathrooms occurred in 2017 on a United Airlines flight. A passenger discovered a hidden camera in the first-class bathroom and reported it to the flight attendants.\nThe airline immediately launched an investigation and found that the camera was placed there by a maintenance worker for personal use. The employee was promptly terminated, and United Airlines issued a public apology to the affected passenger.\nAnother incident took place in 2019 on a British Airways flight. A passenger noticed a small camera lens hidden behind an air vent in the bathroom and reported it to the cabin crew. The airline investigated the matter and found that the camera was not functional and had been left there accidentally during routine maintenance.\nNevertheless, British Airways took the incident seriously and implemented additional security measures to prevent similar occurrences in the future.\nPassenger Concerns and Complaints\nDespite the rarity of incidents involving hidden cameras in airplane bathrooms, passenger concerns and complaints about privacy remain. The enclosed nature of airplane bathrooms can make some travelers feel vulnerable, especially when they are aware of the possibility of hidden cameras.\nIt is important for airlines to address these concerns and reassure passengers of their commitment to ensuring privacy and safety.\nMany airlines have taken proactive measures to alleviate passenger concerns. For instance, some airlines have installed tamper-proof seals on bathroom doors to provide visual reassurance that the space has not been tampered with.\nAdditionally, flight attendants receive training on how to identify and respond to any suspicious activity in the cabin, including potential privacy violations.\nPassengers are also encouraged to report any concerns they may have regarding privacy to the flight crew. Airlines take these reports seriously and conduct thorough investigations to ensure the safety and well-being of their passengers.\nIt is worth noting that the Federal Aviation Administration (FAA) and other aviation regulatory bodies have strict regulations in place to protect passenger privacy. These regulations include regular aircraft inspections and maintenance checks to detect and prevent any unauthorized recording devices from being installed in airplane bathrooms.\nExpert Opinions on Bathroom Privacy\nPilot and Flight Attendant Views\nWhen it comes to bathroom privacy on airplanes, pilots and flight attendants have differing opinions. Some pilots argue that installing cameras in airplane bathrooms could enhance security measures and help prevent potential threats.\nThey believe that having constant surveillance in these confined spaces would act as a deterrent for illegal activities. However, flight attendants emphasize the importance of passenger privacy and argue that cameras in bathrooms would be a violation of personal space.\nThey argue that passengers should be able to use the restroom without feeling like they are being watched.\nAccording to a survey conducted by the Flight Attendants Association, 80% of flight attendants believe that cameras in airplane bathrooms would be an invasion of privacy. They argue that passengers have the right to use the restroom without feeling monitored, and that the presence of cameras could lead to increased anxiety and discomfort among passengers.\nIt is important to note that, as of now, there are no regulations or requirements for cameras in airplane bathrooms. The decision ultimately rests with the airlines themselves, who must consider the opinions of both pilots and flight attendants, as well as the concerns of passengers.\nTravel Advocate Perspectives\nTravel advocates, who work to protect the rights and interests of passengers, also have strong opinions on the issue of bathroom privacy on airplanes. They argue that installing cameras in airplane bathrooms would be a violation of personal privacy and could potentially lead to abuse or misuse of the footage.\nThese advocates believe that passengers should have a reasonable expectation of privacy when using the restroom on an airplane. They argue that this expectation is rooted in the basic principles of human dignity and respect.\nFurthermore, they argue that the installation of cameras could create a chilling effect, deterring passengers from using the bathroom when necessary due to fear of being watched.\nAccording to a statement from the Air Travelers Association, “Passengers deserve the right to use the restroom in peace and privacy. Installing cameras in airplane bathrooms would be a clear violation of this right and would undermine the trust between airlines and their customers.”\nWhile there are varying opinions on the matter, it is evident that bathroom privacy on airplanes is a topic of concern for both aviation professionals and passengers. Ultimately, the decision regarding the installation of cameras in airplane bathrooms should take into account the opinions and rights of all stakeholders involved.\nWhile airplanes have many safety and security measures, cameras in lavatories would be a major breach of privacy. Strict aviation regulations prohibit their installation and use. Flight crew are responsible for monitoring the facilities during flights.\nUltimately, evidence and expert opinions show there are no cameras watching passengers in airplane bathrooms."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:b876b57f-924a-47d9-b25b-cffd8bd73ba3>"],"error":null}
{"question":"How do the operating costs of wave energy compare to wind power, considering their potential as baseload power sources?","answer":"Based on the available information, wave energy and wind power have different operating cost profiles. Mean Sea Level's wave energy project is targeting a levelised cost of energy below R1/kWh for their commercial plant, with a key advantage being its near baseload character with high availability factor. In comparison, wind turbines have very low operating costs of less than 0.01 $/kWh, but they lack the baseload characteristics of wave energy, as indicated by their 'minutes' ramp time and no minimum run time requirements. Wave energy's ability to provide consistent power makes it potentially more valuable for baseload generation, despite potentially higher operating costs.","context":["Construction of 1 MW wave-energy pilot project under way in Hermanus\nPhoto by: Mean Sea Level\nA South African wave-energy start-up is building a pioneering 1 MW pilot project, based on its patented homegrown design, which will supply clean electricity to a large-scale Hermanus abalone farm, in the Western Cape.\nMean Sea Level (MSL) is developing the first-of-its-kind project with equity investments from the Industrial Development Corporation, angel investors and aquaculture group Abagold, which produces 500 t of abalone yearly.\nConstruction of the R30-million pilot plant has also received grant funding secured from EEP Africa, a multidonor fund that provides early-stage financing to innovative clean-energy projects.\nAbagold is a shareholder in MSL and the company’s founder, Pierre Hugo, has been central to the identification and the co-design of the wave energy converter (WEC) solution being deployed.\nThe plant, which is 25% completed, is being built on land leased from Cape Nature and will neighbour the site occupied by Abagold, supplying electricity to drive its pumps and blowers. A full environmental impact assessment was, thus, required ahead of the construction.\nOnce proven, MSL plans to construct a larger 3.5 MW commercial wave-power plant at an adjacent sea-front site on the same property.\nMSL CEO and engineer Marius Hugo, who is also Pierre’s son, tells Engineering News Online that the world-first solution has been developed in response to Abagold’s search for a clean alternative that is able to consistently match the abalone farm’s 3 MW, around-the-clock electricity requirement.\nThe abalone farm currently sources its electricity from the local Overstrand municipality.\nThe WEC design has been developed using lessons garnered over three decades of aquaculture experience, which have proven critical in determining not only the most suitable marine civil construction techniques, but also the nature of the construction materials, which have to be able to withstand the hostile and corrosive conditions.\nIn 2014, MSL was established by Abagold and Marius Hugo with the aim of developing the technology and building the first two converters for Abagold.\nThe “simple” solution, Marius Hugo explains, exploits the classical principle of “overtopping”, whereby the wave is captured in a dam as it overtops the lip of the slope. The captured water’s gravity, or potential energy, then feeds back into the sea through a hydroelectric turbine to generate electricity.\nPractically, the solution involves building a dam next to the ocean, with the wall facing the oncoming waves having the energy converter slope. The waves run up and over the wall, or through non-return valves in the wall.\nThe water is then captured in the common buffer dam, behind the wall, at a hydraulic head above mean sea level. The head is then released through low-head turbines into a turbine stabilisation dam, which only allows water to flow back to the ocean.\nThe overtopping design has been optimised to convert a maximum amount of kinetic energy to potential energy through what Hugo describes as novel multilevel nonreturn valves with momentum splitting edges on the wall slope and a common buffer dam.\n“Our WEC design requires an energetic coastline, ideally with a solid rock ocean bed on which to construct the converter dam. Looking at the global wave energy resource map, all regions rated with wave energy resources above 20 kW/m could be suitable.\n“South Africa is particularly well endowed with wave-energy resources, with almost all of our coastline being viable. The south coast, in particular, can go up to 60 kW/m,” Hugo explains.\nBuilding the converter on-shore lowers the overall cost of the solution, as it negates the requirement for device mooring, underwater cabling, ships, dry-docks and, to a lesser extent, divers.\nThe power offtake agreement for the pilot project, which is scheduled to begin producing electricity from mid-2020, has been set at a discounted rate to Abagold’s current power costs.\nThe offtake agreements for the 3.5 MW project will be set on commercial terms, but Hugo says it will be far more cost competitive than the pilot, which is burdened with the full research and development costs.\n“For the commercial plant, we are targeting a levelised cost of energy, or LCOE, of below R1/kWh.”\nHugo says a key factor in achieving a low LCOE, is the high availability factor of the wave-energy resource, which is considered to be near baseload in character.\nHugo is optimistic that MSL’s first two projects will help identify and negate the technical and environmental constraints for including wave energy in future editions of South Africa’s Integrated Resource Plan, which outlines the technologies that will be considered for inclusion in utility-scale procurement programmes.\nHe is also confident that the second project will go some way to moving the economic constraints currently associated with wave-energy power stations, which have been prohibitively expensive when compared with variable renewable energy technologies such as wind and solar photovoltaic.\nThe pilot site is being constructed using locally developed technology, as well as domestic expertise, materials and manufacturing.\n“In the process, some of us were quite far from our comfort zones, including the team that needed to learn to swim.\n“But through a combination of hiring and training, we have built an exceptional team, which is striving towards a world first,” Hugo enthuses, adding that he is hopeful that the technology could even spawn an entirely new industry for the country.","Basic economics of power generation, transmission and distribution\nIn most industrialized countries, electric power is provided by generating facilities that serve a large number of customers. These generating facilities, known as central station generators, are often located in remote areas, far from the point of consumption. The economics of central station generation is largely a matter of costing. As with any other production technology, central station generation entails fixed and variable costs. The fixed costs are relatively straightforward, but the variable cost of power generation is remarkably complex. We will examine each of these in turn.\nThe fixed costs of power generation are essentially capital costs and land. The capital cost of building central station generators vary from region to region, largely as a function of labor costs and \"regulatory costs,\" which include things like obtaining siting permits, environmental approvals, and so on. It is important to realize that building central station generation takes an enormous amount of time. In a state such as Texas (where building power plants is relatively easy), the time-to-build can be as short as two years. In California, where bringing new energy infrastructure to fruition is much more difficult (due to higher regulatory costs), the time-to-build can exceed ten years. Table 5.1 shows capital cost ranges for several central-station technologies. Although the ranges in Table 5.1 are quite wide, they still mask quite a bit of uncertainty in the final cost of erecting power plants.\nOperating costs for power plants include fuel, labor and maintenance costs. Unlike capital costs which are \"fixed\" (don't vary with the level of output), a plant's total operating cost depends on how much electricity the plant produces. The operating cost required to produce each MWh of electric energy is referred to as the \"marginal cost.\" Fuel costs dominate the total cost of operation for fossil-fired power plants. For renewables, fuel is generally free (perhaps with the exception of biomass power plants in some scenarios); and the fuel costs for nuclear power plants are actually very low. For these types of power plants, labor and maintenance costs dominate total operating costs.\nIn general, central station generators face a tradeoff between capital and operating costs. Those types of plants that have higher capital costs tend to have lower operating costs. Further, generators which run on fossil fuels tend to have operating costs that are extremely sensitive to changes in the underlying fuel price. The right-most column of Table 5.1 shows typical ranges for operating costs for various types of power plants.\n|Technology||Capital Cost ($/kW)||Operating Cost ($/kWh)|\n|Coal-fired combustion turbine||$500 — $1,000||0.02 — 0.04|\n|Natural gas combustion turbine||$400 — $800||0.04 — 0.10|\n|Coal gasification combined-cycle (IGCC)||$1,000 — $1,500||0.04 — 0.08|\n|Natural gas combined-cycle||$600 — $1,200||0.04 — 0.10|\n|Wind turbine (includes offshore wind)||$1,200 — $5,000||Less than 0.01|\n|Nuclear||$1,200 — $5,000||0.02 — 0.05|\n|Photovoltaic Solar||$4,500 and up||Less than 0.01|\n|Hydroelectric||$1,200 — $5,000||Less than 0.01|\nBecause of the apparent tradeoff between capital and operating cost, comparing the overall costs of different power plant technologies is not always straightforward. Often times, you will see power plants compared using a measure called the \"Levelized Cost of Energy\" (LCOE), which is the average price per unit of output needed for the plant to break even over its operating lifetime. We will discuss LCOE in more detail in a future lesson - it is an extremely important (and often-used) cost metric for power plants, but it has its own problems that you will need to keep in the back of your head.\nIrrespective of technology, all generators share the following characteristics which influence the plant's operations:\n- Ramp rate\nThis variable influences how quickly the plant can increase or decrease power output, in [MW/h] or in [% of capacity per unit time]\n- Ramp time\nThe amount of time it takes from the moment a generator is turned on to the moment it can start providing energy to the grid at its lower operating limit (see below), in [h]\nThe maximum output of a plant, in [MW]\n- Lower Operating Limit (LOL)\nThe minimum amount of power a plant can generate once it is turned on, in [MW]\n- Minimum Run Time\nThe shortest amount of time a plant can operate once it is turned on, in [h].\n- No-Load Cost\nThe cost of turning the plant on, but keeping it \"spinning,\" ready to increase power output, in [$/MWh]. Another way of looking at the no-load cost is the fixed cost of operation; i.e., the cost incurred by the generator that is independent of the amount of energy generated.\n- Start-up and Shut-down Costs\nThese are the costs involved in turning the plant on and off, in [$/MWh].\n|Technology||Ramp Time||Min. Run Time|\n|Simple-cycle combustion turbine||minutes to hours||minutes|\n|Combined-cycle combustion turbine||hours||hours to days|\n|Nuclear||days||weeks to months|\n|Wind Turbine (includes offshore wind)||minutes||none|\n|Hydroelectric (includes pumped storage)||minutes||none|\nThe minimum run time and ramp times determine how flexible the generation source is; these vary greatly among types of plants and are a function of regulations, type of fuel, and technology. Generally speaking, plants that are less flexible (longer minimum run times and slower ramp times) serve base load energy, while plants that are more flexible (shorter minimum run times and quicker ramp times) are better-suited to filling peak demand. Table 5.2 and Figure 5.3 show approximate (order-of-magnitude) minimum run times and ramp times for several generation technologies. It is important to realize that, in some sense, these are \"soft\" constraints. It is possible, for example, to run a nuclear plant for five hours and then shut it down. Doing this, however, imposes a large cost in the form of wear and tear on the plant's components.\nThe cost structure for transmission and distribution is different than for power generation, since there is basically no fuel cost involved with operating transmission and distribution wires (and their associated balance-of-systems, like substations). At the margin, the cost of loading a given transmission line with additional electricity is basically zero (unless the line is operating at its rated capacity limit). Capital cost thus dominates the economics of transmission and distribution."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:8a55e47e-0585-4568-8652-1f8a8e8899cb>","<urn:uuid:f0adad7d-89e2-4843-84d4-1efb3fae8547>"],"error":null}
{"question":"What are European and Asian traditions for ensuring good fortune in the New Year?","answer":"In Europe, Germans drop melted lead into cold water and interpret the results for fortune-telling, with special kits sold for this purpose. In Switzerland and Austria, people dress in fantastic costumes for Saint Sylvester's Eve. In Asia, various customs exist: Vietnamese people release carp fish into rivers as they believe the New Year god travels to heaven on its back to report on family behavior. Japanese people hang straw ropes across their homes for happiness and good luck, while in the Philippines, children jump at midnight to grow taller. Many Asian cultures also hold sunrise celebrations and honor ancestors for good fortune.","context":["My New Year PSP Tubes here..all rar files\nNew Year's Eve here in\nmy home town Sydney\n- Not all countries\ncelebrate New Year at the same time, nor in the same way. This\nis because people in different parts of the world use different\ncalendars. Long ago, people divided time into days, months, and\nyears. Some calendars are based on the movement of the moon,\nothers are based on the position of the sun, while others are\nbased on both the sun and the moon. All over the world, there\nare special beliefs about New Year.\n- In ancient Egypt,\nNew Year was celebrated at the time the River Nile flooded,\nwhich was near the end of September. The flooding of the Nile\nwas very important because without it, the people would not have\nbeen able to grow crops in the dry desert.\n- At New Year, statues\nof the god, Amon and his wife and son were taken up the Nile by\nboat. Singing, dancing, and feasting was done for a month, and\nthen the statues were taken back to the temple.\n- Babylonia lay in\nwhat is now the country of Iraq. Their New Year was in the\nSpring. During the festival, the king was stripped of his\nclothes and sent away, and for a few days everyone could do just\nwhat they liked. Then the king returned in a grand procession,\ndressed in fine robes. Then, everyone had to return to work and\nbehave properly. Thus, each New Year, the people made a new\nstart to their lives. The celebration of the new year is the\noldest of all holidays. It was first observed in ancient Babylon\nabout 4000 years ago. In the years around 2000 BC, Babylonians\ncelebrated the beginning of a new year on what is now March 23,\nalthough they themselves had no written calendar. The Babylonian\nnew year celebration lasted for eleven days. Each day had its\nown particular mode of celebration, but it is safe to say that\nmodern New Year's Eve festivities pale in comparison.\nOther traditions of the\nseason include the making of New Year's resolutions. That tradition\nalso dates back to the early Babylonians. Popular modern resolutions\nmight include the promise to lose weight or quit smoking. The early\nBabylonian's most popular resolution was to return borrowed farm\nThe Romans continued to observe the new year on March 25, but\ntheir calendar was continually tampered with by various emperors so\nthat the calendar soon became out of synchronization with the sun.\nIn order to set the calendar right, the Roman senate, in 153 BC,\ndeclared January 1 to be the beginning of the new year. But\ntampering continued until Julius Caesar, in 46 BC, established what\nwas come to be known as the Julian Calendar. It again established\nJanuary 1 as the new year. But in order to synchronize the calendar\nwith the sun, Caesar had to let the previous year drag on for 445\nAlthough in the first centuries AD the Romans continued celebrating\nthe new year, the early Catholic Church condemned the festivities as\npaganism. But as Christianity became more widespread, the early\nchurch began having its own religious observances concurrently with\nmany of the pagan celebrations, and New Year's Day was no different.\nNew Years is still observed as the Feast of Christ's Circumcision by\n- The New Year has not\nalways begun on January 1, and it doesn't begin on that date\neverywhere today. It begins on that date only for cultures that\nuse a 365-day solar calendar. January 1 became the beginning of\nthe New Year in 46 B.C., when Julius Caesar developed a calendar\nthat would more accurately reflect the seasons than previous\nThe Romans named the\nfirst month of the year after Janus, the god of beginnings and\nthe guardian of doors and entrances who was always shown as\nhaving two heads. He looked back to the last year and forward to\nthe new one. He was always depicted with two faces, one on\nthe front of his head and one on the back. Thus he could look\nbackward and forward at the same time. At midnight on December\n31, the Romans imagined Janus looking back at the old year and\nforward to the new. The Romans began a tradition of exchanging\ngifts on New Year's Eve by giving one another branches from\nsacred trees for good fortune. Later, nuts or coins imprinted\nwith the god Janus became more common New Year's gifts. The\nRoman New Year festival was called the Calends, and people\ndecorated their homes and gave each other gifts. Slaves and\ntheir masters ate and drank together, and people could do what\nthey wanted to for a few days.\nthe early Christians denounced the practice as pagan, the popularity\nof the baby as a symbol of rebirth forced the Church to re-evaluate\nits position. The Church finally allowed its members to celebrate\nthe new year with a baby, which was to symbolize the birth of the\nThe use of an image of a baby with a New Years banner as a symbolic\nrepresentation of the new year was brought to early America by the\nGermans. They had used the effigy since the fourteenth century.\n- The Celts were the\npeople who lived in Gaul, now called France, and parts of\nBritain before the Romans arrived there. Their New Year festival\nwas called Samhain. It took place at the end of October, and\nSamhain means 'summer's end'.\n- At Samhain, the\nCelts gathered mistletoe to keep ghosts away, because they\nbelieved this was the time when the ghosts of the dead returned\nto haunt the living.\nThe Jewish New Year,\nRosh Hashanah, is celebrated on the first two days of the Jewish\ncalendar's first month, Tishri, which falls in September or October.\nThe Jewish New Year is heralded by the rabbi blowing a shofar, or\nram's horn, in the synagogue. The Islamic year starts anew every 354\ndays. Because there are no adjustments, like Leap Year, to make each\ncalendar year correspond to the earth's cycle around the sun, the\nfirst month of the Islamic calendar, Muharram, is not in the same\nseason every year.\n- It is a holy time\nwhen people think of the things they have done wrong in the\npast, and they promise to do better in the future.\nSpecial services are\nheld in synagogues, and an instrument called a Shofar, which is made\nfrom a ram's horn is played. Children are given new clothes, and New\nYear loaves are baked and fruit is eaten to remind people of harvest\n- The Muslim calendar\nis based on the movements of the moon, so the date of New Year\nis eleven days earlier each year.\n- Iran is a Muslim\ncountry which used to be called Persia. The people celebrate New\nYear on March 21, and a few weeks before this date, people put\ngrains of wheat or barley in a little dish to grow. By the time\nof New Year, the grains have produced shoots, and this reminds\nthe people of spring and a new year of life.\n- Most Hindus live in\nIndia, but they don't all celebrate New Year in the same way or\nat the same time.\n- The people of West\nBengal, in northern India, like to wear flowers at New Year, and\nthey use flowers in the colours of pink, red, purple, or white.\nWomen like to wear yellow, which is the colour of Spring.\n- In Kerala, in\nsouthern India, mothers put food, flowers, and little gifts on a\nspecial tray. On New Year's morning, the children have to keep\ntheir eyes closed until they have been led to the tray.\n- In central India,\norange flags are flown from buildings on New Year's Day.\n- In Gujarat, in\nwestern India, New Year is celebrated at the end of October, and\nit is celebrated at the same time as the Indian festival of\nDiwali. At the time of Diwali, small oil lights are lit all\nalong the roofs of buildings.\n- At New Year, Hindus\nthink particularly of the goddess of wealth, Lakshmi.\n- On New Year's Eve,\nBuddhist temples ring out the old year by letting passers by each\nring a huge bell once until it has rung 108 times, one time for\neach kind of evil in the world. On New Year's Day, it is\ntraditional to make a pilgrimage to a Shinto shrine or a\n- In Vietnam, the New\nYear is called Tet Nguyen Dan or Tet for short. It begins\nbetween January 21 and February 19, and the exact day changes\nfrom year to year. They believe that there is a god in every\nhome, and at the New Year this god travels to heaven. There he\nwill say how good or bad each member of the family has been in\nthe past year.\n- They used to believe\nthat the God travelled on the back of a fish called a carp, and\ntoday, they sometimes buy a live carp, and then let it go free\nin a river or pond. They also believe that the first person to\nenter their house at New Year will bring either good or bad\n- In Japan, New Year\nis celebrated on January 1, but the Japanese also keep some\nbeliefs from their religion, which is called Shinto. To keep out\nevil spirits, they hang a rope of straw across the front of\ntheir houses, and this stands for happiness and good luck. In\nJapan, New Year's is celebrated for three days, starting on\nJanuary 1. Everyone receives new clothes and little work is\ndone. The moment the New Year begins, the Japanese people begin\nto laugh, and this is supposed to bring them good luck in the\n- The Chinese New Year\nis celebrated some time between January 17 and February 19, at\nthe time of the new moon, and it is called Yuan Tan. It is\ncelebrated by Chinese people all over the world, and street\nprocessions are an exciting part of their New Year. The Festival\nof Lanterns is the street processions, and thousands of lanterns\nare used to light the way for the New Year.\n- The Chinese people\nbelieve that there are evil spirits around at New Year, so they\nlet off firecrackers to frighten the spirits away. Sometimes\nthey seal their windows and doors with paper to keep the evil\n- In Europe, New Year\nwas often a time for superstition and fortune-telling, and in\nsome parts of Switzerland and Austria, people dress up to\ncelebrate Saint Sylvester's Eve.\n- In AD 314, there was\na Pope called Saint Sylvester, and people believed that he\ncaptured a terrible sea monster. It was thought that in the year\n1000, this sea monster would escape and destroy the world, but\nsince it didn't happen, the people were delighted. Since then,\nin parts of Austria and Switzerland, this story is remembered at\nNew Year, and people dress up in fantastic costumes, and are\n- In Greece, New\nYear's Day is also the Festival of Saint Basil. Saint Basil was\nfamous for his kindness, and Greek children leave their shoes by\nthe fire on New Year's Day with the hope that he will come and\nfill the shoes with gifts. The tradition of using a baby to\nsignify the new year was begun in Greece around 600 BC. It was\ntheir tradition at that time to celebrate their god of wine,\nDionysus, by parading a baby in a basket, representing the\nannual rebirth of that god as the spirit of fertility. Early\nEgyptians also used a baby as a symbol of rebirth.\n- In Scotland, New\nYear is called Hogmanay, and in some villages barrels of tar are\nset alight and rolled through the streets. Thus, the old year is\nburned up and the new one allowed to enter.\n- Scottish people\nbelieve that the first person to enter your house in the New\nYear will bring good or bad luck, and it is very good luck if\nthe visitor is a dark-haired man bringing a gift. This custom is\nThe song, Auld Lang\nSyne is sung at midnight on New Year's Eve, and this custom is now\ncelebrated all over the world. \"Auld Lang Syne,\" the\ntraditional New Year's song, was written by a Scottish poet, Robert\nBurns, 200 years ago.\nNew Years Eve is nearly always humid, with fine weather and many of\nus gather all around the foreshores of our beautiful harbour eat,\ndrink, dance, sing and wait till fire\n- AULD LANG SYNE\n- mostly written\nby Robert Burns\n- Should auld\nacquaintance be forgot,\n- And never bright to\n- Should auld\nacquaintance be forgot\n- And auld lang\n- For auld lang syne,\n- For auld lang syne,\n- We'll take a cup of\n- For auld lang syne\n- And surely ye'll be\n- And surely I'll be\n- And we'll take a cup\nof o' kindness yet\n- For auld lang syne.\n- We twa run about the\n- And pu'd the gowans\n- but we wandered\nmoney a weary foot\n- Sin auld lang syne.\n- And there 's a hand,\nmy trusty fiere,\n- And gie's a hand o'\n- And we'll tak' a\nright gude-willie waught\n- For auld lang syne.\nIn the Middle Ages,\nChristians changed New Year's Day to December 25, the birth of\nJesus. Then they changed it to March 25, a holiday called the\nAnnunciation. In the sixteenth century, Pope Gregory XIII revised\nthe Julian calendar, and the celebration of the new year was\nreturned to January 1.\nThe Julian and\nGregorian calendars are solar calendars. Some cultures have lunar\ncalendars, however. A year in a lunar calendar is less than 365 days\nbecause the months are based on the phases of the moon. The Chinese\nuse a lunar calendar. Their new year begins at the time of the first\nfull moon (over the Far East) after the sun enters Aquarius-sometime\nbetween January 19 and February 21. The Chinese celebrate the\nholiday by exchanging gifts, having parades, and exploding\nfirecrackers. One of twelve animals, such as a tiger, a rooster, or\na dog, is associated with each new year.\nAlthough the date\nfor New Year's Day is not the same in every culture, it is always a\ntime for celebration and for customs to ensure good luck in the\ncoming year. In France, families gather and exchange gifts and\ngreeting cards. Children often present their parents with homemade\ngifts to wish them Bonne Annee. In Italy, a piece of mistletoe is\nhung over the front door to bring good luck to the entire household.\nIn Scotland, people bring delicious cakes and cookies to parties. It\nis believed that the first person to enter a house will receive good\nIn the United\nStates, the New Year's celebrations that are familiar to today\nwere originated in the 1750s by the Dutch in New Amsterdam.\nDuring the Middle\nAges, the Church remained opposed to celebrating New Years. January\n1 has been celebrated as a holiday by Western nations for only about\nthe past 400 years.","NEW YEAR’S TRADITIONS AROUND THE WORLD\nIn America, most of us celebrate the New Year on January 1st, according to the Gregorian calendar. But some parts of the world have different traditions.\nFor those celebrating the passing of a year at midnight on December 31st with kisses continuing into January 1, do we remember that it was Julius Cesar who, in 46 BC, decided to honor the pagan god Janus by taking that day as the commencement of each new calendar year? Hence the name “January.” Janus was considered the god of beginnings, ends, passages and time, and was always depicted with two faces, one towards the past, and one facing forward to the future.\nFriends, families and lovers meet for a feast, some Champagne, firecrackers, funny hats and a kiss under the hanged mistletoe, while sincerely vowing to follow good resolutions.\nTraditions to bring good luck for the New Year are as old as the celebrations and come from all corners of the world.\nMany cultures count a tall, dark and handsome man crossing the threshold as a sign of good luck, but if the first person to enter the house is a red headed woman…the year is sure to be stressful. What single girl would argue with that one!\nOthers involve housecleaning…brushing the bad luck of the past out with the dust. Holding a piece of silver or gold as the New Year begins is said to increase the chances of prosperity in the coming year…some place a silver coin over the doorway or a penny on the windowsill.\nThe youngest boy in the household lighting a candle at dusk to burn through the night until morning light is another Celtic tradition — that may be an urban version of lighting bonfires or a carryover of the Samhain of lighting tapers in the windows to chase away evil spirits.\nIn the Philippines, children jump up and down at midnight to make sure they will grow tall. In Asia, sunrise celebrations and honoring of the ancestors and elders brings luck.\nGermans drop melted lead into cold water and take turns interpreting the results. This tradition has become so popular that kits are sold that include the lead pellets and suggestions for discerning what it all means!\nAn Irish tradition involves banging on the door and walls with Christmas bread to chase the bad luck out and bring good spirits to the household with the promise of bread enough in the New Year. This is probably related to the tradition of banging pots and pans in Iran, or the ancient tradition of using firecrackers to welcome in the Chinese New Year.\nThen there are the foods! Chiacchiere, or honey drenched balls of fried dough, always ensure a sweet year in Italy.\nGrapes, one for each month, make for a lucky year in Spain and many Latin countries (in Portugal it’s raisins!). Eating kind of greens (the color of money), or anything that forms a circle – such as donuts or pretzels – also make for good fortune in the coming year.\nThese ancient holiday traditions are as varied as the lands where they are from, but they all have one thing in common: sharing warm personal wishes with friends and family for much happiness, health and prosperity in the New Year\nChristmas Island is the first place on Earth to enter into a new year, followed by New Zealand, and a tiny bit of Russia, but Sydney, Australia is the first large city to welcome the New Year, smack in the middle of their summer, often with a bonfire on the beach, as of course, their weather allows it. The magnificent fireworks display on the landmark harbour is a famous event of the continent.\nFifteen hours later, New York celebrates with the drop of the crystal ball at Times square, with a bevy of freezing celebrities trying their best to sing in the misty weather. The new mayor will deliver a few words of self-satisfaction to thousands of proud New Yorkers.\nThe last city to hit the divide in time is Honolulu, Hawaii. In China and some other Asian countries, the New Year celebration does not fall on the same date each year, but is always somewhere between January 21st and February 20th , and depends on the movements of the moon and the sun. The next one will be on January 31st, and will start the Year of the Horse. Traditional red lanterns will hang from front doors and the family celebration includes a copious diner and an exchange of red envelops containing money.\nSince the communist party has made religion illegal, several permitted “philosophies” are followed by the Chinese people: Buddhism, Taoism, Islam, Protestantism and Catholicism, though not the Roman Catholic kind.\nRosh Hashanah is regarded by most Jewish people of the world as their New Year. In that calendar, the day falls on the first day of the seventh month, meaning that it is also a fluctuating date, ranging from September 5th to October 5th. Honey, apples, peas and fish are the staples of the New Year’s diner.\nHijri, or Islamic New Year, does not fall on the first of January either, as the Muslim year is only 354 days long. Technically, the 2014 Islamic New Year is in the month known as Muharram, and was October 25th, based also on a lunar calendar. It is now the year 1436, since the very first year of the Islamic calendar began only in 610 AD, and with the days starting at sunset, it makes for a complicated scheme to calculate the exact beginning of each New Year, depending of the country celebrating it.\nIn Iran, the Persian New Year is Norouz, Nowruz, or No-Rooz, on March 20th, the first day of Spring. The tradition calls for a renewal of wardrobe and a cleansing of houses and last 13 days. Bonfires are lit and one is supposed to jump over it to gather its energy. This is often accompanied by loud banging on metal pots. Each family shares the seven lucky objects representing the seven original immortals protecting them, and the tables are often covered with pastries, candles, eggs, apples, lentils, red fish and dry fruits.\nThe Gregorian Calendar was defined by Pope Gregory XIII, who, in the XVI century (16th) commissioned the civil calendar still in use today. Before that was the Julian calendar, introduced by Julius Caesar, and earlier the Roman calendar was in use. Astronomer Christopher Clavius believed the Julian Calendar was too long (at 365 days and six hours), so he convinced the good pope to change it to adjust to the real length of a year (at 365 days, five hours and 49 minutes). Petty, you think? But if you multiply by years, decades, centuries and millenniums, then we have a difference!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:1c4272e2-197b-4966-9553-75212f106bd4>","<urn:uuid:30d615e0-a159-4bb5-9bab-a9e69c76ab80>"],"error":null}
{"question":"Which infections show more severe symptoms: dengue fever or West Nile virus?","answer":"Both infections can cause severe symptoms, but they manifest differently. For dengue, patients can develop dengue hemorrhagic fever (DHF) with symptoms including thrombocytopenia, hemorrhagic manifestations, and plasma leakage that can lead to hypotensive shock (DSS) and potentially death without proper treatment. For West Nile virus, while 70-80% of infected people are asymptomatic, less than 1% develop serious neurologic illness such as encephalitis or meningitis, with some neurologic effects being permanent. About 10% of those who develop neurologic infection due to WNV will die.","context":["Dengue is a significant community ailment in subtropical and tropical locations worldwide. The DENV nonstructural proteins NS4B and subgenomic sfRNA hinder the RNAi pathway by inhibiting the RNAse Dicer. During heterotypic supplementary DENV infections subneutralizing antibodies can enable viral uptake through Fcγ receptors and down-regulate signaling cascades initiated via the design identification receptors TLR3 and MDA5/RIG-I hence reducing the antiviral condition DBU from the cell. The DENV NS2B/3 proteins cleaves individual STING/MITA interfering with induction of IFN-α/β. Finally DENV NS2A NS4A and NS4B complicated together to stop STAT1 phosphorylation while NS5 binds and promotes degradation of individual STAT2 thus stopping formation from the STAT1/STAT2 heterodimer and its own transcriptional induction of ISGs. Right here we discuss the web host innate immune system response DBU to DENV as well as the systems of immune DBU system evasion DENV is rolling out to manipulate mobile antiviral responses. Launch Four dengue trojan serotypes (DENV-1 -2 -3 -4 trigger dengue fever (DF) aswell as more serious disease manifestations typically known as dengue hemorrhagic fever (DHF) and dengue surprise symptoms (DSS)1. DF can be an severe febrile disease with headaches retro-orbital discomfort myalgia arthralgia allergy hemorrhagic manifestations and/or leukopenia. The hallmark top features of DHF contain thrombocytopenia hemorrhagic manifestations and signals of plasma leakage that may result in hypotensive surprise (DSS) and without suitable treatment death. The condition was lately reclassified into dengue with and unexpectedly signs and serious dengue2. Bhatt and mosquitoes which continue steadily to broaden geographically facilitated by elevated global trade and travel unplanned urbanization poor waste materials and water administration aswell as individual behavior and ecology5. No industrial vaccine or particular antiviral treatment is available for dengue though DBU they are areas of significant research and advancement efforts. Dengue is DBU certainly a individual disease without known pet reservoirs as well as the trojan has evolved DBU effectively to evade individual immune system responses specifically innate antiviral immunity. This review targets mechanisms from the innate intracellular antiviral DENV and response evasion within infected cells. The dengue trojan life routine DENV is certainly a positive-strand RNA enveloped flavivirus whose 10.7 kb genome includes a 5′ type I m7G cap structure and encodes a polyprotein that’s post-translationally cleaved by web host and viral proteases into three structural proteins (C capsid; pr/M membrane; E envelope) and seven nonstructural protein (NS1 NS2A Rabbit Polyclonal to BRS3. NS2B NS3 NS4A NS4B NS5). In human beings DENV mainly infects immune system cells from the myeloid lineage including monocytes macrophages and dendritic cells aswell as hepatocytes as proven in individual autopsy tissue by immunohistochemistry6 7 8 9 10 in peripheral bloodstream mononuclear cells (PBMC) through the severe phase of infections by stream cytometry11 and in epidermis explants12. Though many reports can be found of DENV infections of endothelial cells and in mosquito cells was discovered to work with DC-SIGN whereas trojan propagated in individual dendritic cells used L-SIGN to infect focus on cells36 40 Furthermore to DC-SIGN and L-SIGN the mannose receptor portrayed on individual macrophages was discovered to bind the carbohydrate moieties in the DENV envelope proteins41. DENV provides been proven to bind to a genuine variety of cell surface area substances. DENV can complex with high temperature surprise proteins (HSP) 90 and HSP70 on the top of mammalian cells42 43 and p74 on the top of mosquito cells44 amongst others. Pursuing heat surprise treatment web host cells were discovered to have elevated HSP appearance viral uptake and trojan result43 44 In cells missing selectin-type receptors latest studies show that DENV utilizes the transmembrane receptors TIM and TAM two receptors involved with phosphatidylserine-dependent removal of cells going through apoptosis45. TIM binds DENV directly whereas TAM interacts with DENV via two bridge protein Gas6 and Advantages45 indirectly. Finally during supplementary DENV infection using a heterotypic serotype the adaptive immune system response can action to improve viral infections via.","West Nile Virus\nMosquito Control and why it's Important to YOU\nWhat is West Nile Virus (WNV)?\nWNV is a mosquito-borne virus that can cause fever, encephalitis (inflammation of the brain), or meningitis (inflammation of the lining of the brain and spinal cord).\nHow do people get WNV?\nWNV is most commonly spread through the bite of an infected mosquito. WNV can be spread through blood transfusions, organ transplants, and from mother to baby during pregnancy, delivery, or breastfeeding but this is very rare. It is not transmitted from person to person, or from person to animal.\nWhat are the symptoms of WNV?\nMost people (70-80%) infected with WNV do not develop any symptoms.\nIf present, WNV symptoms usually appear 2-14 days after the mosquito bite. Approximately 1 in 5 people infected will develop a fever and possibly headache, body aches, joint pain, vomiting, diarrhea, or rash. Most people with these symptoms recover completely, but fatigue and weakness can last for weeks or months.\nLess than 1% of people infected will develop serious neurologic illness such as encephalitis or meningitis (inflammation of the brain or surrounding tissues). Recovery from severe illness may take weeks or months. Some of the neurologic effects may be permanent. Only about 10% of people who develop neurologic infection due to WNV will die.\nSerious illness can occur in people of any age. However, people over 60 years of age are at the greatest risk for serious illness. People with certain medical conditions, such as cancer, diabetes, hypertension, kidney disease, and people who have received organ transplants are also at greater risk for serious illness.\nSee your health care provider if you have symptoms of WNV.\nWho is at risk for WNV infection?\nAnyone living in an area where mosquitoes are infected with WNV is at risk. WNV has been detected in all states except Alaska and Hawaii. The risk of infection is highest for people who work outside or participate in outdoor activities because of greater exposure to mosquitoes.\nIs there a vaccine or treatment for WNV infection?\nThere is no vaccine or specific treatment for WNV infection.\nPeople with mild symptoms of WNV infection usually recover on their own. Over-the-counter pain relievers can be used to reduce fever and relieve some symptoms. People with severe illness usually need to be hospitalized to receive supportive treatment, such as intravenous fluids, pain medication, and nursing care.\nHow can I prevent WNV?Make you and your home a Bite-Free Zone to prevent WNV and other mosquito-borne diseases.\nWhat is the Chester County Health Department doing to prevent WNV?\n- Provides educational materials. Call 610-344-6490 to request materials.\n- Provides community education. Request a presentation or participation at a community event\n- Responds to complaints of standing water- Chester County Health Department enforces County regulations requiring property owners to dump and drain sources of standing water (ex. tires, pools, containers) which mosquitoes use for breeding. Citations may be issued for failure to comply.\n- Identifies bodies of water containing mosquito larvae.\n- Sets mosquito traps to collect and test adult mosquitoes for WNV – Traps are placed in highly populated areas, known mosquito breeding areas, and in areas where a resident has previously been identified as having a confirmed case of WNV infection. Traps are also placed in response to complaints from residents regarding high levels of mosquito activity.\n- Uses U.S. Environmental Protection Agency-approved products (Bti, Bs, or Methoprene) to kill mosquito larvae in bodies of standing water that cannot be drained.\n- Uses U.S. Environmental Protection Agency-approved products (Permanone or DeltaGard) to kill adult mosquitoes in areas that have high mosquito activity and multiple mosquito samples testing positive for WNV- Spraying is done as a last resort after exhausting all other mosquito control strategies.\n- The Chester County Health Department uses a truck-mounted sprayer to apply 1.5 ounces of the mosquito control product per acre of land. Sprays are conducted after sunset, when mosquitoes are most active and bees have returned to their hives. Sprayers are turned off near bodies of water and apiaries to protect aquatic life and bees. The Chester County Health Department also notifies beekeepers and residents who are listed as hypersensitive in a designated spray area prior to conducting a spray. People who are concerned about exposure to mosquito control products can reduce their potential for exposure by staying indoors with children and pets when their neighborhood is being sprayed. Because the mosquito control spray becomes inactive in just a few hours or with sunshine, it is not necessary to wash off outdoor furniture or playground equipment before use.\n- The Chester County Health Department is a member of the Environmental Protection Agency’s Pesticide Environmental Stewardship Program. This program requires participants to affirm that environmental stewardship is an integral part of their integrated pest management (IPM) practice, use current, comprehensive information regarding the life cycle of mosquitoes within their IPM program, educate the community on the benefits of IPM, and demonstrate a commitment to pesticide risk reduction activities.\n- Investigates reports of WNV illness in residents.\nHow can I find out when a mosquito control spray is being conducted in my neighborhood?\nThe Chester County Health Department notifies residents of sprays at least 48 hours ahead of time through the following channels:\n- News releases sent to the media, legislators, municipalities, etc.\n- Public Health Updates- E-mail updates that residents can sign up for.\n- Chester County Health Department website.\n- Chester County Health Department Facebook and Twitter.\n- Residents in a designated spray area who are listed as hypersensitive are contacted directly by the Chester County Health Department.\nPeople who are concerned about exposure to mosquito control products can reduce their potential for exposure by staying indoors when their neighborhood is being sprayed.\nFor more information, call 610-344-6752 or email firstname.lastname@example.org.\n- Prevent Mosquito-Borne Diseases\n- West Nile Virus Brochure- English, en Español\n- Zika Virus\n- Centers for Disease Control and Prevention- Avoid Mosquito Bites\n- Centers for Disease Control and Prevention- West Nile Virus\n- Penn State Extension- Pennsylvania Pesticide Hypersensitivity Registry\n- Penn State Extension- West Nile Virus\n- Pennsylvania's West Nile Virus Control Program"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:f4c3078e-3ccf-432b-8a77-71703c17a015>","<urn:uuid:6a411dea-76df-44fc-ae19-1e2dd7a03721>"],"error":null}
{"question":"What are the comparative health implications of using ionizing air purifiers versus heat recovery ventilators (HRVs) for improving indoor air quality in residential spaces?","answer":"Ionizing air purifiers can actually be harmful as they create ozone, which is a powerful lung irritant, and are not recommended for improving indoor air quality. In contrast, heat recovery ventilators (HRVs) provide a safe and effective means of ventilation by incorporating a heat exchanger that transfers heat between outgoing and incoming air streams without allowing them to intermingle. HRVs provide controlled, balanced ventilation throughout the home while minimizing energy loss, making them a healthier choice for maintaining good indoor air quality compared to ionizing purifiers.","context":["The quality of our indoor air becomes more important as people spend increasing amounts of time indoors. Adverse health effects from poor IAQ can be mild and irritating (runny nose, headache), or they can be much more serious (asthma attack). If you suspect that the IAQ in your home is poor, the first step is to try and identify the possible source of the pollutant.\nCommon Indoor Air Quality Pollutants\nVolatile Organic Compounds (VOC's)\nEnvironmental Tobacco Smoke (ETS)\nMolds (fungi), bacteria, and dust mites are some of the main biological pollutants indoors. These are generally airborne particulates that can be inhaled and cause an allergic-type reaction, such as nasal congestion, sneezing, watery eyes, and a runny nose. They can also trigger asthma attacks. Molds and bacteria are often found in wet areas of the home, where there is excess humidity or a water leakage has occurred. For information on cleaning up a mold problem, refer to this Fact Sheet.\nThe Breathe Easies Videos\nVolatile Organic Compounds (VOC's)Carbon Monoxide\nThe term Volatile Organic Compounds (VOC's) encompasses many different chemicals which can come from a variety of different sources indoors. These sources can include household cleaners, paints, solvents, or other chemicals found in the home or garage. For these types of VOC’s, proper usage and storage should be taken to minimize your exposure. Typically, these compounds have an odor associated with them, making them easier to detect.\nFormaldehyde is a very common VOC because of its widespread use as a preservative in a variety of products such as paneling, particle board, furniture, and carpeting. Formaldehyde can take up to two years to completely off-gas in some cases, so residents of a newly built or remodeled home may notice some symptoms. Exposure can cause symptoms such as eye, nose and throat irritation, skin rashes, couching, headache, nausea, and sever allergic reactions. Some types of VOC's can cause damage to the kidneys and central nervous system, and others have been linked to cancer.\n^ Top of page\nCarbon Monoxide is the most dangerous of the potential IAQ pollutants, as it can be fatal in high levels. At lower levels it can cause headaches, dizziness, nausea, confusion, and disorientation. Other combustion by-products (gases or particles that come from burning fuels) can damage the respiratory tract and cause eye, nose, and throat irritation. Any appliances that burn fuels can introduce combustion by-products. These appliances should be properly installed (particularly vented to the outside) and maintained. Such appliances can include furnaces, boilers, fireplaces, space heaters, and automobiles.\nALERT- Put generators outside: Never use a generator inside homes, garages, crawlspaces, sheds, or similar areas. Deadly levels of Carbon Monoxide can quickly build up in these areas and can linger for hours, even after the generator has shut off.\nThese inhalable particles can range in size, and be organic/biological (mold, pollen, pet dander, skin flakes) or inorganic (wood, carpet fibers, byproducts from fuel combustion or tobacco smoke). Typically, a whole house filter can help keep levels down if it is properly maintained. For sensitive individuals (e.g., asthmatics or those with severe allergies), additional steps may be needed to control exposure. Health symptoms are typically an allergic reaction, such as nasal congestion, sneezing, watery eyes and runny nose. They can also trigger an asthma attack.\nStand-alone air purifiers can help with additional filtration if they use a filter, similar to a furnace. They will only work for a small area, and the filter needs to be changed on a regularly. The 'ionizing' or 'electrostatic' purifiers can create ozone, itself a powerful lung irritant, and are not recommended.\nIn most cases, it isn’t necessary to test. Knowing the sources of common pollutants, as well as the symptoms they cause, can often help a resident diagnose a suspected problem. Often, a thorough visual inspection can help as well. While there are companies in Nebraska that will offer a variety of tests, it can be very expensive, and at times, inconclusive.\nFor example, knowing a home has a high level of VOC’s may not help to determine the source for removal. Also, having a mold spore count for your home doesn’t tell you if those numbers are elevated or not, as there is not currently a state or federal standard.\nThere are some instances where testing can be beneficial, but they are limited. Radon or Carbon Monoxide testing is necessary to know if those toxins are at dangerous levels or not. If a legal action has been initiated, or if negotiating a claim with an insurance company, testing may be necessary.\nImproving Your Home's Indoor Air Quality (IAQ)\nThere are ways to improve your IAQ. They typically fall into one of three categories: Source Control, Ventilation, or Preventative Maintenance.\nPerhaps the best way to keep good IAQ is to control the sources of pollutants. Ensure that chemicals are correctly stored and used to minimize potential health problems. Use products in a well-ventilated area, and only for their intended use. Also, practice preventative maintenance (see below) to help reduce the need for such products.\nThere's a reason why 'Dilution is the Solution to Pollution'. One way to keep toxin levels low is to ventilate your home, either by 'general ventilation', which is removing toxins from a larger area, or by 'spot ventilation', which is removing toxins from a localized area.\nBringing in fresh air into a home for general ventilation is difficult to maintain year-round in Nebraska. With energy costs high and on the rise, homes are being constructed air-tight. During heating or cooling seasons when a house is closed up, the air can quickly become stale, and toxins can build-up. Most homes do not have an active way to bring in fresh air, meaning that little or no fresh air comes in, unless the windows are open.\nMany homes have 'spot ventilation', meaning fans that exhaust air from specific places, such as bathrooms, oven hoods, or clothes dryers. This type of ventilation has fans turned on only when the pollutant is being produced.\nWhen radon gas is a problem in the home, a permanently installed radon mitigation system is the answer, something a licensed professional can help you with. An added benefit of a radon mitigation system can be reduced moisture levels in the home. Visit the Nebraska Radon Program's homepage or call us for more information.\nPracticing preventative maintenance can keep your indoor air clean and healthy. Examples of preventative maintenance are to keep combustion equipment inspected on a yearly basis, and install a carbon monoxide detector. Quickly attend to spills, leaks, and stains to prevent mold. Keep your home clean and clutter free. Remove food waste to control dust, dander, and pets. Change your furnace filter on a regular basis (at least quarterly, if not more often) to control airborne particulates. Conduct a radon test and install a radon mitigation system, if necessary. Do not allow smoking in your home or vehicle. Keep chemicals stored properly. For example, knowing a home has a high level of VOC’s may not help to determine the source for removal. Also, having a mold spore count for your home doesn’t tell you if those numbers are elevated or not, as there is not currently a state or federal standard.\nDHHS- Indoor Air Quality Program\nPO Box 95026, Lincoln, NE 68509-5026\nDocuments in PDF format require the use of Adobe Acrobat Reader\nwhich can be downloaded for free from Adobe Systems, Inc.\nEnvironmental Health Page\nPublic Health Page","Energy-efficient homes require careful attention to indoor air quality\nVentilation systems do two different tasks: spot ventilation and whole-building ventilation.\nSpot ventilation is for specific, non-continuous tasks such as removing moisture generated from cooking or bathing.\nWhole-building ventilation provides a healthy indoor environment.\nThree accepted practices are used to meet the delivered or mechanical ventilation: supply-only ventilation, exhaust-only ventilation, and balanced air ventilation. Each method is effective, but it’s crucial that the ventilation methods match the climate zone to ensure good building durability, safety, and indoor air quality. (Images courtesy Building America Solution Center).\nHeat recovery ventilators and energy recovery ventilators work by balanced ventilation, throughout the home and continuously, without the energy penalties associated with regular exhaust fans.\nSupply-only ventilation will create a positive pressure in the conditioned space relative to the outdoors. This strategy typically depends on building envelope leaks to remove the stale air. If a supply-only ventilation system is drawing 80 cfm of outdoor air into the home while the air handler is operating, then at the same time 80 cfm must be exiting the building somewhere. That “somewhere” is the many leaks in the building envelope between indoors and outdoors.\nIn humid climates where the conditioned indoor air is dryer than the outdoor air, this can be a good strategy. It will help keep building envelope materials dry while providing ventilation air that is both filtered and dehumidified. In cold, dry climates where indoor air is more humid than the outdoor air (in high-performance buildings), supply-only ventilation would be a poor strategy.\nExhaust-only ventilation is the reverse of supply-only ventilation: stale air leaves the building from a known location (through exhaust fans ducted to the outdoors) and outdoor air enters the building from an unknown location. For every cubic foot of air exhausted out of the building, a cubic foot of air has to come into the building from somewhere. Again, that “somewhere” is the many air leaks in the building envelope that connect the conditioned space to unconditioned space or directly to the outdoors. With this strategy, the outdoor air entering the building is neither filtered nor conditioned. The target ventilation rate is met by operating a quiet exhaust fan at a specific flow rate for a scheduled runtime each hour.\nThis strategy works well in cold, dry climates because the air outdoors is generally drier than the air indoors (in tightly built homes). Unlike older, leaky homes, newer high-performance homes are built to be more airtight. They tend to accumulate more moisture—water vapor in the indoor air comes from cooking, bathing, and clothes washing. Exhaust-only ventilation is needed to safely remove this moisture before condensation becomes an issue.\nMake-up air moving through the envelope helps to keep building materials dry in cold, dry climates. Exhaust-only ventilation would be a poor strategy in humid climates, where water vapor outdoors is typically higher than indoors. Heat recovery ventilators and energy recovery ventilators provide balanced ventilation throughout the home. They can be set to operate continuously without the energy penalties associated with regular exhaust fans because they have a heat exchanger that transfers heat between outgoing and incoming air streams.\nBalanced ventilation is designed to provide both supply and exhaust. The best means for providing this balanced system is with a heat recovery ventilator (HRV) or an energy (or enthalpy) recovery ventilator (ERV). Both provide a controlled way of ventilating a home while minimizing energy loss because they incorporate a heat exchanger that uses conditioned air from the outgoing exhaust air to pre-condition the fresh incoming air. The heat exchanger transfers heat but does not allow the intermingling of outgoing and incoming air.\nHere, incoming and outgoing air volumes are balanced and air is evenly distributed throughout the house. These are whole-house systems; they can share the central furnace’s air handler and duct system or have their own duct system.\nThe main difference between an HRV and an ERV is the way the heat exchanger works. With an ERV, the heat exchanger transfers water vapor along with heat energy, while an HRV only transfers heat. See the manufacturers’ specifications for determining which model is best in which climate and install it according to the directions for best performance, especially in regard to ERVs in humid climates. Research shows that most ERVs can recover about 70 to 80 percent of the sensible energy in the exiting air. In summer, ERVs seem to perform best during peak outdoor conditions and lose efficiency during low-temperature, high-humidity conditions.\nThe ventilation information contained in this article is a product of the Building America Solution Center, which provides building-science–based knowledge on a variety of residential design and construction topics for new and existing homes. Additional guidance on selecting, designing, and installing ventilation systems, can be found here at the U.S. Department of Energy's website."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:938eafea-9f7b-4ea8-b5f7-62fe027020d5>","<urn:uuid:85bbe5e7-20e3-4019-b768-179ff9f93105>"],"error":null}
{"question":"Which came first historically: the domestication of sweet fruits like figs and dates, or the discovery of maple syrup by Native Americans?","answer":"The domestication of sweet fruits like figs and dates came first, being among the earliest plants cultivated during the Agricultural Revolution around 5,000-12,000 years ago. The discovery and use of maple syrup by Native Americans came much later, with the first written records of Indigenous peoples using maple sap appearing in the 16th century when documented by European explorers like Jacques Cartier in 1540 and Andre Thevet in 1557.","context":["From Hunter-Gatherers to Farmers\nUntil the invention of farming, all the people on the planet lived on wild plants and animals. Anthropologists tell us that these long-ago ancestors lived in small clans of twenty to forty people and moved from camp to camp throughout the year in search of food. They timed their journeys to coincide with the annual migration of game and the ripening of wild nuts, seeds, fruits, and vegetables. By necessity, all their food was local, organic, and seasonal. Because they hunted or foraged all their food, they are referred to as hunter-gatherers.\nOur distant relatives continued to dine at nature's café until roughly five thousand to twelve thousand years ago. Then, for reasons not fully understood, groups of people in a handful of areas around the world broke ties with the past and began to raise their own food. In addition to hunting for wild game, they began to tame wild goats, pigs, and sheep so they could have a ready supply of meat. They milked the goats and sheep and turned their milk into cheese and fermented drinks.\nThey also began to create the very first gardens. In the beginning, gardening was a simple affair. The first farmers gathered seeds and cuttings from wild plants and grew them in one location to make them easier to tend and harvest. For many generations, the farmers raised too little food to meet all their needs, so they continued to gather wild plants. As the centuries passed, however, our ancestors became such skilled farmers that they were able to stop wandering in search of food and settle down in the first permanent settlements. Our species had made the epic transition from being hunters and gatherers to being herders and gardeners. The Agricultural Revolution — the great-grandmother of all food revolutions — had begun.\nWe Are the Food Makers\nAs we humans set off on our excellent adventure in agriculture, all the other creatures on the planet remained true to their original diets — and do so to this day. Zebras, lemurs, elephants, eagles, rodents, weasels, bats, wombats, and the great apes eat the same food today as they did eons ago, provided we've left them enough habitat. Although animal handlers report that captive chimpanzees prefer M&M's to bananas, the chimps have yet to make any candy. Out of an estimated seven million species of animals, we alone had the intelligence, dexterity, and ability to plan for the future that allowed us to walk away from our native diet and create a brand-new menu that was more to our liking.\nTherein lies the problem. Starting with the very first gardens, our farming ancestors chose to cultivate the wild plants that were the most pleasurable to eat. As a rule, the chosen plants were tender, low in bitterness and astringency, and high in sugar, starch, or oil. Plants that were bitter, tough, thick-skinned, dry, devoid of sugar, or too seedy were left behind in the wilderness. Why go to the trouble of cultivating plants that are unpleasant to eat?\nArchaeologists have gathered detailed evidence about those earliest food choices. Wild figs and dates were two of the first plants to be cultivated, and they are among the sweetest of all native fruits. Although hunter-gatherers had consumed only small amounts of grain, the first farmers made starchy cereal grains a central part of their diet. Farmers in the Middle East grew wheat, barley, and millet. African farmers raised pearl millet and sorghum. Corn was king throughout the Americas, and rice became the staple crop of Asia. The era of carbs had begun.\nOil-rich plants were also highly favored. Archaeologists have unearthed the charred remains of an olive orchard in Palestine that was in production seven thousand years ago. Sesame seeds were domesticated for their oil about five thousand years ago. Oil-rich avocados were one of three staple crops in some parts of Mexico three thousand years ago.\nThen as now, people knew what they wanted to eat — sweet, starchy, and fatty food. Because of our ancestors' extraordinary efforts, they were able to produce an abundant supply of these \"must-have\" plants within a short walking distance of their dwellings. For the first time in our long history on the planet, we humans no longer had to eat bitter or fibrous food or spend hours every day processing our food to make it fit to eat. We were creating the food supply of our dreams.\nWe now know that one of the consequences of cultivating the sweetest and mildest-tasting wild plants was a dramatic loss in phytonutrients. Many of the most beneficial bionutrients have a sour, astringent, or bitter taste. Unwittingly, when our ancestors rejected strong-tasting fruits and vegetables, they were lowering their protection against a long list of diseases and troubling conditions. Throughout our history of agriculture, our ability to transform our diet has far exceeded our understanding of the way those changes impact our health and well-being.\nBy the time of the Roman Empire, 250 generations of farmers had already played a role in reshaping the human diet. The differences between wild plants and our man-made varieties had, even then, become marked. The roots of domesticated beets, carrots, and parsnips were twice as large as the roots of their wild ancestors, and they contained less protein, more sugar, and more starch. Most domesticated fruits were several times larger than wild fruits, and they had thinner skins, more sugar, less fiber, more pulp, and fewer antioxidants. Cultivated greens were less bitter and, as a direct consequence, had fewer health-enhancing phytonutrients.\nBy the end of the nineteenth century, people around the world had created hundreds of thousands of new varieties designed to satisfy their needs and wishes. In the twentieth century, science-based breeding techniques speeded up the process. A plant breeder could start out with an idea for a new variety of plum or corn and make it a reality in just ten years, not several generations. Now, plant geneticists can insert foreign genes into corn or beets or potatoes and create a new variety in a matter of hours.\nTo this day, the nutritional content of our man-made varieties has been an afterthought. A plant researcher for the United States Department of Agriculture (USDA) can spend years perfecting a new variety of blackberry or apple without ever measuring its phytonutrient content or its effect on blood sugar. If the variety is attractive, pleasing to eat, productive, and disease resistant, it is considered a triumph. Meanwhile, our bodies hunger for the nutrients that we have left by the wayside.\nFrom Eating on the Wild Side by Jo Robinson. Copyright 2013 by Jo Robinson. Excerpted by permission of Little, Brown & Co.","The Maple Moon or Moon of the Worm\nMarch is a month of transition between winter and spring, often with an unpredictable season almost all its own. The temperatures in Upstate New York can range from an unusually warm 80 F down to sub zero Fahrenheit. This pulsating tension between the cold winter and warmer weather patterns and increasing daylight coincides with the vernal equinox, the Pascal Moon, and the Easter season to the European mind.\nBefore the French explorers of the 16th century and English, French, and Dutch settlers of the 17th century, the indigenous peoples knew the full moon near the equinox as the Worm Moon. This was when the worms started bringing castings to the surface, and robins started to reappear after their winter's absence.\nThere were other names for the moon by some tribes. The Crow Moon honored the late winter flocking of crows. In the far north, the Crusty Moon recognized the particular hard crusting of snow in late winter. Some tribes came to call it Sap or Maple Moon. This latter name evolved from the rising flow of the sap as days start to warm and winter changes to spring in fits and starts.\nEarly origins of Maple\nThe exact origins of the discovery of maple sap and its distillation, or processing, into syrup is impossible to determine with any firm historical accuracy. While a few authorities think the processing of the sap was taught to the Indians by the Europeans, they are in the minority. Most historians believe that various indigenous tribes had a knowledge of this sweet prior to contact with the Europeans. Lack of firm archeological proof and a lack of written records from the various tribes leave the debate open to conjecture and dispute, though there is much to support that the Indians did know about, and use this sweet, albeit in a much cruder fashion than is common today.\nMaple trees observed during his explorations of Quebec were written about by Jacques Cartier in 1540. Recognition of the Indians using the refined sap as sugar and syrup dates from about 1557 in writings of Andre Thevet. Details of collection and distillation of sap by the Micmac Indians of eastern Canada were noted by Marc Lescarbot in 1606.\nBefore the Europeans came, the eastern woodlands were populated by numerous tribes with similar customs. From eastern Canada, Quebec, and New England to the Great Lakes states, they celebrated many of the same moons and seasonal festivals, and ate mostly the same types of game. These varied but slightly from region to region. They often, however, spoke distinct languages in various language groups.\nIndian Legends on the Origins of Maple Syrup\nThere is a common myth, with many tribal variations, that the Creator originally made life too easy for his People, with maple trees having a syrup that flowed year round. One day, Glooskap (this name has many variations) arrived at a village and found it strangely quiet. No children or dogs came to greet him, the gardens were over grown with weeds, and the cooking fires were dead. He found the villagers lying in the maple grove, with the delicious sap running into their mouths from the trees.\nGlooskap had special powers. Using a birch bark bucket, filled with water from lake, he rose above the trees and filled the trees with water until the sap ran thin. Then he encouraged his People of the village with a fiery speech. In this exhortation, he berated them for being lazy, and said as punishment the Creator was going to have the sap run only in the late winter. But, he urged them to take heed that when this happened, they would still be able to enjoy this special sweet, though only at this special time of year.\nAnother legend tells that an Algonquin or Iroquois Indian chief, Woksis, discovered this sweet sap in the following manner. One day, at the time the time of the melting snow, as he prepared to go hunting in a meager season of want and little game, he took his ax out of a maple tree where he had struck it a few inches into the bark the night before. His squaw happened to have a wooden or birch bark basket underneath, which collected the sap. Thinking that her warrior husband had filled it already with water, the squaw Moqua used the sap to cook some meat, most likely venison, though one source says moose meat. Upon his return, he was surprised by the sweet odor of the cooking meat. When eaten, the meat was sweet. They soon realized that this sweetness came from the sap of the maple tree.\nWhile details are sketchy, this evolved into an annual festival of sorts, celebrated in traditional ways by the Onondagas in Central New York as recently as the 1940s. While this time of year was usually called the Worm Moon, some tribes began to call it the Maple Moon.\nSoon they began to have a maple festival to celebrate this sweet that was available only during this time of change from winter to spring. Maple sap and syrup became a major source of sweetening, rivaling honey. Both of these sweets were an important food to the Iroquois., comprising about 12% of their diet.\nIndian Methods of Sap Collection and Syrup Production\nLacking metal working capabilities prior to the European contact, the Iroquois methods of obtaining and evaporating the sap were crude. They hacked or gouged the tree with hatchets or axes, which often killed the tree. They used bowls, of ceramic or white birch bark to collect sap. Different bowls of pottery or wood, usually troughs of hollowed out trunks, were used for boiling the sap. They placed hot stones from the fires into the containers of sap. This brought the sap to a boil. The hot stones were periodically replaced to continue the process. Occasionally, if conditions were ideal, they froze the sap, peeling off the frozen surface daily. They threw away the ice and ate the residue underneath.\nMaple season was fleeting and unpredictable, and it remains so to this day. High quality syrup production requires warm days to about 45 F or so alternating with nights below freezing. If days are exceptionally warm, or too many nights remain above freezing, the quality of the sap collected and the syrup produced suffers. There are large variations of the sap run, from nine days to 57 days, the average being 37 days of collection.\nEuropean Adaptations and Expansion of Maple Production\nDuring the almost two centuries of contact the Iroquois and Algonquins had with the French, English, and Dutch, the Europeans learned about this maple production, and started to make improvements with their superior technologies. The fickleness of nature cooperating by providing sufficiently warm days and sub-freezing nights resulted in the attempts at moving maple syrup production into Virginia by Thomas Jefferson and Benjamin Rush, among others, to be modestly successful at best, and finally abandoned. Maple production was much better quality and more reliable in New England, New York, and Quebec. While maple syrup production has occurred at one time or another in some 30 (present) US states, it was, and is, more common and of better quality in the north.\nBy the time of American Independence and subsequent dispersal of most of the Indians from the northeast, the Europeans had evolved methods of improved production of the maple sap and its sweet products that only very gradually changed over the next century and a half. It became a northeastern tradition of the short transitional season between winter and spring that provided a sweet loved by most Americans to this day.\nThe Maple Weekends in March in New York that have become increasingly popular in recent years owe their existence to the accidental discovery of this tasty treat by an Indian chief several centuries ago. As such, it is an important part of our historical heritage, as well as the specific natural conditions in our region that make it possible.\nReferences - Books\nLawrence, James M., and Martin, Rux. Sweet Maple: Life, Lore & Recipes From the Sugarbush. Shelburne, Vermont: Chapters Publishing Ltd., 1993. Co published by Vermont Magazine, Montpelier, Vermont, 1993.\nKlees, Emerson. Legends and Stories of the Finger Lakes Region. Rochester, NY: Friends of Finger Lakes Publishing, 1995\nSchery, Robert W. Plants for Man. Englewoods CLiffs, N.J.: Prentice-Hall, Inc., C.1952, 4th printing 1959.\nThe Old Farmers's Almanac, editions for 2008, 2009, 2010. Yankee Publishing, Dublin, NH.\nReferences - Internet\nThe Natural world Full Moon Names and Dates\nWakarusa (Indiana) Maple Syrup Festival\nOne Iroquois Legend\nA Sure Sign of Spring in New York State\nMaple Syrup production is largely restricted to the northeastern United States and eastern Canada. This is the natural range of sugar and black maple, the two most commonly tapped species. Silver and red maple sap is higher in water content and provides a poorer quality end product.\nThere is little doubt that the Iroquois and other woodland Indians knew about the maple sap. There are several legends of just how they discovered this sweet, an important seasonal addition to their diet. As they lacked metal tools prior to European contact, their means of collection and refining maple sap were crude.\nThe European settlers gradually improved upon Indian methods of collecting and refining sap in many ways. These evolved into \"traditional\" ways of producing syrup that were pretty standard for perhaps a century or more. Only in the latter half of the 20th century did most producers go \"hi-tech\" in production methods that are commonly used today. However, some small producers and museums still produce small amounts of syrup using largely pre-mechanized methods. This is largely for the benefit of tourists and visitors, placing the methods of production in historical context.\nMaple Producers and Festivals in New York State\nNew York State is the second leading producer of maple syrup, second only to Vermont. According to statistics from the New York State Maple Producers Association, about 1500 producers statewide, with nearly 1.5 million taps made 332,000 gallons of syrup in 2008. The average cost per gallon of finished syrup was $33.50 in 2007. The final value of the crop was about $7.5 million, with an impact of $30 million on the New York State economy.\nAccording the published statistics in the Utica Observer-Dispatch of March 18, 2009, maple syrup production in selected counties was as follows in 2005:\nOneida County: 32 producers with 2,100 gallons of syrup.\nHerkimer County: 19 producers with 1,400 gallons of syrup.\nLewis County: 141 producers with 30,000 gallons of syrup.\nMany small maple sugar producers have in recent years had small scale maple festivals at this time of year. Producers and historical museums often sponsor special events and demonstrations. The Farmer's Museum in Cooperstown has Sugaring Off Sundays, with breakfast (pancakes and maple syrup, of course) and maple syrup production demonstrations. The Herkimer Home outside Little Falls had its 34th annual maple celebration on the first weekend in April 2009. Other museums or producers have had such programs usually in late March and early April.\nNew York State Maple Producers Association.\nWhat began in the late 1990s as a one day event promoting maple products by a small group of Wyoming County maple producers has evolved into a festival celebrated across New York State. This effort has been coordinated by the New York State Maple Producers Association. Over 100 large and small producers from over 40 counties participate on the last two weekends in March. Typically, there are pancake breakfasts, sales of syrup and candy, and demonstrations on past or current production methods. A list of participating producers is available from their web site listed in references below.\nWith this regional agricultural product, the maple industry in New York State is on the verge of expanding quite rapidly. Such coordination of an industry that is historically and commercially important is important to its success as an industry. If people in this area are committed to promoting tourism, whether to local residents or outside visitors, this is a model to be studied as largely successful in the general field of local agriculture.\nThere is discussion of local maple producers banding together even more and forming a cooperative in Northern New York for bottling and packaging of their maple products. This would provide the largely rural maple producers a more effective means of getting their products to market, as well as providing jobs to an area with limited employment.\nThe American Maple Museum\nIn Crohgan, New York (northeast of Lowville on State Route 812), this museum is one of the few maple oriented places that is open outside of maple sap season. The museum presents one of the largest collections of vintage equipment used in maple production over the years. They open Memorial Day to late June on Friday, Saturday and Monday, and daily except Sunday July 1 to around Labor Day. Their web site is a good source of information on all aspects of historical and current maple sap collection and processing.\nThe maple industry in New York State is on the verge of tremendous expansion. If such a cooperative comes into existence, it could expand the impact of maple sugar products on the local and regional agricultural economy. In any event, the maple sap season of late February to mid April is a seasonal activity which clearly marks the transition from winter to spring in the Upper Mohawk Country of New York State.\nNew York State Maple Producers Web Site, Maple Weekend http://www.mapleweekend.com/index.html\nUtica Observer-Dispatch, March 18, 2009\nMaple Museum, Croghan\nLawrence, James M., and Martin, Rux. Sweet Maple: Life, Lore & Recipes From the Sugarbush. Shelburne, Vermont: Chapters Publishing Ltd., 1993. Co published by Vermont Magazine, Montpelier, Vermont, 1993\nDISCLOSURE OF MATERIAL CONNECTION: The Contributor has no connection to nor was paid by the brand or product described in this content."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:42882770-f3b3-470b-87e5-dd9d2e2277d8>","<urn:uuid:2f6f3abd-3f65-49a8-8fda-8fb7eecf0a4c>"],"error":null}
{"question":"What role did family networks play in American business expansion historically, and how does this compare to modern cryptocurrency's approach to decentralization and democratization?","answer":"Historical family networks played a crucial role in American business expansion, as evidenced by Abraham Katz's story where family connections facilitated business opportunities. He initially stayed with Gump family cousins in Baltimore to learn English and bookkeeping, and later his nephews Jake and Ike Katz's success in Stillwater, Oklahoma influenced his business decisions. The family network even helped evaluate new opportunities, with his son Lester being sent to survey the situation in Oklahoma. In contrast, modern cryptocurrency represents a different approach to business expansion through decentralization and financial democratization. It operates on a peer-to-peer network that enables secure, fast, and anonymous transactions without relying on family or traditional business networks. The cryptocurrency industry aims to revolutionize the financial industry by providing financial democratization while balancing this with environmental sustainability concerns.","context":["I’ve learned a lot more information about Abraham Katz and his family since connecting with my fourth cousin Marsha and her father Henry. They also generously shared some family photographs with me. What a blessing it has been!\nAccording to family history notes written by Abraham’s grandson Henry in September, 1988, when Abraham arrived in the US, he lived in Baltimore with a family named Gump who were cousins of his mother (Rahel Katzenstein). I knew this had to be the same Gumps who were married to my Mansbach cousins, the children of Hannchen Katzenstein Mansbach, who was a sister of both Rahel Katzenstein Katz, Abraham’s mother, and my great-great-grandfather Gerson Katzenstein.\nAnd sure enough, I went back to look at the research I’d done about the Gump family, and there was Abraham, living with Gabriel and Henrietta (Mansbach) Gump in Baltimore on the 1870 census:\nAccording to the family history notes written by Henry Katz, Abraham lived with the Gumps in Baltimore for about two years and learned English and bookkeeping. Then he left for New Orleans where there was another family member. The family does not know the name of that family member (there were no Gumps then living in New Orleans), but family lore is that Abraham was searching for an older brother who had fought in the Civil War and might have gone to New Orleans to look for him. He never found that brother, and I have no records regarding this brother. (More on that in a later post.) While in New Orleans, Abraham chased after a man who was attempting to steal from the family’s business and injured his knee, an injury that affected him for the rest of his life.\nAfter some time in New Orleans, Abraham moved to Horse Cave, Kentucky, married Amelia Nahm, and had ten children, as I’ve described in an earlier post. Here is a photograph of the family home in Horse Cave and one of Amelia:\nThe family history notes described Abraham’s business in Horse Cave:\nHe carried dry goods, hardware, buggies, and Studebaker wagons. A water well was in the center of his store. He would barter with the farmers for their products. He would store eggs and dairy products in a basket in the well. He later established a second store.\n(Henry Katz family history notes, September 30, 1988)\nAccording to the family history notes, when Abraham and Amelia moved their family from Horse Cave to Louisville sometime before 1900, it was to be closer to an established Jewish community. All ten children were living at home in Louisville in 1900, as seen in this census record:\nIn Louisville, Abraham operated a dry goods store as well as a glove factory, according to the family history notes.\nThanks to the generosity of Abraham’s great-granddaughter Marsha, I now have a photograph of Abraham and Amelia and nine their ten children. As best I can tell from the ages and birth order of the children, either Lester or Sidney is missing from this photograph. Since the youngest child, Milton, was born in 1901 and appears to be about five years old in the photo, I am guessing that this photograph was taken in about 1906—before the family left Kentucky.\nMy guess is that the back row standing are the two oldest sisters, Rachel and Blanche, with either Lester or Sidney between them. In the front row from left to right would be Henrietta, Abraham, Ben, Bertha, Florence, Milton, Sigmund, and Amelia:\nUPDATE! Thank you so much to Ava Cohn, aka Sherlock Cohn, the Photo Genealogist, upon whose expertise I have relied before. Ava advised me that the clothing styles date this photograph as more like 1900-1901. Thus, the “missing” child would have been Milton, who wasn’t yet born. I now think that I was wrong in my identification of the children in the photograph. Looking at the ages of the children again, I now think that in fact they should be identified as follows:\nBack row: Rachel, Lester, Blanche. Front row: Henrietta, Abraham, Sidney, Bertha, Florence, Sigmund, Benjamin, and Amelia. Thank you, Ava!\nWhen a recession hit the region around 1908, Abraham’s business was affected, and he faced labor problems in his glove factory. The family history notes go on to describe how Abraham decided to leave Louisville:\nDuring this time his nephews Jake and Ike Katz [to be discussed in a later post] … were enjoying good business in their store in Stillwater, Oklahoma. Oklahoma had become a state in 1907, and things were booming. … Abe sent Lester [his oldest son] to Oklahoma to visit his cousins in Stillwater to survey the situation to see if the family would not be better off in a new state.\n(Henry Katz family history notes, September 30, 1988)\nLester reported back favorably, but as of 1910, Abraham, Amelia, and eight of their ten children were still living in Louisville, and Abraham was still a merchant in the dry goods business. The children at home ranged in age from 27 down to eight.\nAs for the two sons who were not living at home, Sidney, as noted in an earlier post, was living with his uncle Samuel in Omaha (mislabeled as his son):\nAnd Lester was living in Stillwater, Oklahoma, working as a salesman in a dry goods store. Also boarding with Lester in Stillwater was Lafayette Rothschild, who was Samuel Katz’s brother-in-law and also working as a salesman in a dry goods store. Both Lester and Lafayette were probably working in the Katz Department Store belonging to Jake Katz.\nNot long after the 1910 census, Abraham Katz and his family moved to Oklahoma, settling in Sapulpa, a town about 15 miles from Tulsa.\nWhy Sapulpa? Between 1900 and 1910, the population of Sapulpa had exploded, going from 891 people to 8,283 people; by 1920, it was up to 11,634 people. During that time, industry had begun to develop in Sapulpa, including brick and glass manufacturing. Presumably, Abraham and his nephew Jake saw this as a growing community in need of a dry goods store.\nThere was no established Jewish community in Sapulpa, but Tulsa was only 15 miles away and had an overall population of 72,075 in 1920 and two synagogues; a Reform synagogue was formed in Tulsa in 1914 and an Orthodox one in 1916. There were also synagogues during that time in other cities in Oklahoma. Nevertheless, it must have been somewhat of an adjustment for the Katz family after living in Louisville, which had an overall population of 234,891 in 1920 and a big enough Jewish community to support eight synagogues.\nThe move was a successful one, and Oklahoma continues to be home for many of Abraham and Amelia’s descendants. Here is a photograph of the Katz family home in Sapulpa:\nBetween 1910 and 1920, many of the Katz children married and moved out of the family home. More in the next post.","As the world becomes more conscious of sustainability, the environmental impact of industries and businesses is under the microscope. Cryptocurrency is one of the newer and rapidly evolving industries that has been called out for its high energy consumption and carbon footprint. However, the cryptocurrency sector is also built on innovation, decentralization, and financial democratization. The challenge is to balance these two seemingly opposing goals – sustainability and innovation. In this article, we will explore the environmental concerns of cryptocurrency and ways to mitigate its impact while continuing to promote its benefits.\nRead more: Silvergate Collapse Dragging Down Bitcoin Volume\nCryptocurrency is a digital currency that uses encryption techniques to regulate the generation of units of currency and verify the transfer of funds. It is decentralized and operates on a peer-to-peer network that enables secure, fast, and anonymous transactions. Cryptocurrency has gained popularity in recent years, with bitcoin being the most well-known example. However, the process of generating cryptocurrency, known as mining, requires significant computational power, which consumes a massive amount of energy.\nThe amount of energy consumed by cryptocurrency mining has sparked concerns about its environmental impact. According to a 2021 report by the Cambridge Center for Alternative Finance, the annual energy consumption of bitcoin mining alone is estimated to be around 128.84 TWh, which is more than the energy consumption of Argentina. The high energy consumption of cryptocurrency mining has led to an increase in greenhouse gas emissions, as the majority of the energy used comes from non-renewable sources like coal and natural gas.\nThe Environmental Impact of Cryptocurrency\nCryptocurrency mining is a highly energy-intensive process that requires specialized computer equipment and software. The process involves solving complex mathematical problems to verify transactions and add new blocks to the blockchain. The first miner to solve the puzzle is rewarded with a certain amount of cryptocurrency.\nTo mine cryptocurrency, miners need to use powerful computers, which consume a considerable amount of energy. The energy consumption of cryptocurrency mining is a function of the computing power used and the time it takes to solve the problem. As the difficulty of the problem increases, more computing power is required, which leads to a higher energy consumption.\nThe high energy consumption of cryptocurrency mining has a significant impact on the environment. Most of the energy used to power cryptocurrency mining comes from non-renewable sources like coal and natural gas. The combustion of fossil fuels leads to the release of greenhouse gases like carbon dioxide, which contributes to global warming and climate change. The increase in greenhouse gas emissions from cryptocurrency mining is a concern as it undermines global efforts to reduce carbon emissions.\nMitigating the Environmental Impact of Cryptocurrency\nThe environmental impact of cryptocurrency mining can be mitigated by adopting sustainable practices. Some of the ways to reduce the energy consumption of cryptocurrency mining are:\nUsing renewable energy sources: One of the most effective ways to reduce the environmental impact of cryptocurrency mining is to use renewable energy sources like solar, wind, and hydroelectric power. Some cryptocurrency mining companies are already using renewable energy to power their operations. For example, the cryptocurrency mining company, Square, has committed to becoming carbon neutral by 2030.\nDeveloping energy-efficient mining equipment: Cryptocurrency mining companies can reduce their energy consumption by developing energy-efficient mining equipment. For example, some companies are developing ASICs (application-specific integrated circuits) that are designed to consume less energy than traditional computer processors.\nImplementing proof-of-stake consensus mechanism: Another way to reduce the energy consumption of cryptocurrency mining is to implement the proof-of-stake consensus mechanism. Proof-of-stake is an alternative to proof-of-work, which is the current consensus mechanism used by most cryptocurrencies. Proof-of-stake does not require miners to solve complex mathematical problems to verify transactions. Instead, it relies on a random selection process to choose a validator who is responsible for verifying transactions. Validators are required to hold a certain amount of cryptocurrency, which acts as a stake. If a validator acts maliciously, their stake is forfeited. The proof-of-stake consensus mechanism is less energy-intensive than proof-of-work, making it a more sustainable alternative.\nCarbon offsetting: Cryptocurrency mining companies can offset their carbon emissions by investing in renewable energy projects or purchasing carbon credits. Carbon offsetting is a way to neutralize the carbon emissions associated with cryptocurrency mining by investing in sustainable projects that reduce carbon emissions.\nBalancing Sustainability and Innovation\nCryptocurrency has the potential to revolutionize the financial industry by providing financial democratization and decentralization. However, this cannot come at the expense of the environment. The challenge is to balance sustainability with innovation. The cryptocurrency industry needs to take responsibility for its environmental impact and take steps to mitigate its carbon footprint. It is essential to recognize that sustainability and innovation are not mutually exclusive goals, but rather complementary.\nSustainability is a key factor in the long-term success of cryptocurrency. As the world becomes more conscious of the environment, consumers are looking for sustainable products and services. The cryptocurrency industry needs to recognize this trend and take steps to reduce its carbon footprint. By adopting sustainable practices, the cryptocurrency industry can attract a more environmentally conscious audience.\nCryptocurrency has the potential to transform the financial industry by providing financial democratization and decentralization. However, the high energy consumption of cryptocurrency mining has sparked concerns about its environmental impact. To balance sustainability and innovation, the cryptocurrency industry needs to take responsibility for its carbon footprint and adopt sustainable practices. By using renewable energy sources, developing energy-efficient mining equipment, implementing proof-of-stake consensus mechanism, and carbon offsetting, the cryptocurrency industry can mitigate its environmental impact. Sustainability is not a trade-off for innovation, but rather a complementary goal that is essential for the long-term success of the cryptocurrency industry."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:810c3e0d-8ad2-481b-83ea-9778bd3d4f4f>","<urn:uuid:16d423b7-32cb-493a-822d-c068233478c4>"],"error":null}
{"question":"What are the main market drivers for green energy versus high molecular weight polyisobutylene industries? Present the comparison in terms of government initiatives and transportation sector influence.","answer":"In the green energy sector, the primary market driver is government initiatives promoting clean energy sources through subsidies, restrictions on conventional power projects, and target-based growth. Countries like China and India have set specific targets to meet significant energy requirements from green energy projects. For high molecular weight polyisobutylene, the main driver is increasing demand from the transportation sector, particularly in improving fuel efficiency and meeting environmental regulations. The material plays a crucial role in enhancing fuel combustion properties, reducing emissions, and providing essential sealing and adhesive capabilities in vehicles, including specific applications in electric vehicles (EVs). Both industries are significantly influenced by environmental regulations and sustainability goals, but while green energy focuses on power generation alternatives, polyisobutylene concentrates on improving existing transportation technologies and supporting the transition to EVs.","context":["Publishing: November 2021 | Report Code: PE10105 | Available Format: PDF\nGreen Energy Market Overview\nMajor trend being witnessed in the global green energy market is increased investment in the development of power projects associated with clean and green energy. Owing to the limited availability of the conventional fuels such as oil, gas, and coal along with associated pollution released by consumption of these fuel sources, a large number of countries are investing in clean energy sources including solar energy, hydropower, wind energy, biofuels, and geothermal energy. These resources are abundant in nature and are environment-friendly. Owing to their advantages, there has been a rising trend of increased investments in the green energy projects.\nOn the basis of type, the green energy market is categorized into solar photovoltaic (PV), wind energy, hydroelectric power, biofuels, and geothermal energy. Globally, hydroelectric power is one of the largest sources of green power as it fulfills about 15–21% demand for electricity, depending on capacity factors.\nSolar PV system is a combination of inverters such as string inverters, micro inverters, and central inverters which stores the power generated from PV cells. However, wind energy can be further subcategorized on the basis of type of wind energy turbines into horizontal axis wind turbines and vertical axis wind turbines. Focus on promoting clean energy sources is expected to result in further deployment of clean energy projects, thereby boosting the green energy market in the coming years.\nBiofuels green energy market is further categorized into biodiesel and bioethanol. During the forecast period, bioethanol had larger market share, and the U.S. and Brazil were the largest producers of bioethanol. However, biodiesel production was dominated by Europe, where Germany and France were the largest biodiesel producers, globally. Geothermal energy in another green energy source that is primarily used for either electricity generation or direct usage. Energy conservation systems in geothermal energy are flash steam, binary cycle, and dry steam.\nBased on region, the green energy market is categorized into Europe, North America, Asia-Pacific, Latin America, and Middle East and Africa. Among all the regions, Asia-Pacific held a significant share in the market, driven by growing large scale development of solar powered projects in countries such as China, India, Japan, and other APAC countries across the tropic of cancer. The large-scale deployment of solar projects is expected to boost the market during the forecast period.\nGreen Energy Market Dynamics\nMajor driver identified in the green energy market is governments’ initiatives to promote the green energy sources. Owing to advantages of green energy projects as cleaner power sources, countries across the world are opting for various initiatives such as subsidies to green energy projects, restricting the expansion conventional power projects, and target-based growth of these projects. Countries such as China and India aim to meet a significant proportion of energy requirements from green energy projects, which in turn, is boosting the market growth.\nMajor restraint identified in the green energy market is the intermittent nature of certain green energy sources including solar energy and wind energy. Owing to their intermittency, the solar and wind power projects cannot be used as per their full capacity as power load factor of such projects reduce to climatic conditions. Moreover, the intermittent nature of these projects also affects the grid stability, thereby acting as a major restraint.\nAggressive biodiesel initiatives and emergence of new feedstocks are the opportunities for the green energy market. Some of the factors contributing to the growing focus on the clean sources are rising need for energy security, climate change, and environmental issues caused by burning petrol-based products. Moreover, opting for biofuels results in long-term cost reduction as these fuels are clean, more efficient, and renewable in nature. Owing to such benefits, the biodiesel and other biofuels offer growth opportunity in the market.\nGreen Energy Market — Competitive Landscape\nThe green energy market is characterized by both multinational corporations and domestic companies. Also, companies engaged in producing advanced green energy technologies are start-ups backed by venture capitalist firms as well as the government agencies. Some of the major players operating in the global market are Yingli Green Energy Holding Co. Ltd., Hanwha Q Cells GmbH, National Hydroelectric Power Corporation (NHPC) Ltd., Suntech Power Holdings Co. Ltd., Archer Daniels Midland Company, Aventine Renewable Energy Inc, JA Solar Holdings Co. Ltd., Suzlon Energy Ltd., U.S. Geothermal Inc., Kyocera Solar Inc., Enphase Energy Inc., Trina Solar Ltd., Calpine Corporation, and First Solar Inc.\nThe study provides the historical as well the forecast market size data for various countries, including the U.S., Canada, France, Germany, the U.K., Italy, Spain, Japan, China, India, Brazil, Saudi Arabia, and South Africa.\nGet a bespoke market intelligence solution\nOur dedication to providing the most-accurate market information has earned us verification by Dun & Bradstreet (D&B). We strive for quality checking of the highest level to enable data-driven decision making for you\nOur insights into the minutest levels of the markets, including the latest trends and competitive landscape, give you all the answers you need to take your business to new heights\nWith 24/7 research support, we ensure that the wheels of your business never stop turning. Don’t let time stand in your way. Get all your queries answered with a simple phone call or email, as and when required\nWe take a cautious approach to protecting your personal and confidential information. Trust is the strongest bond that connects us and our clients, and trust we build by complying with all international and domestic data protection and privacy laws","Global High Molecular Weight Polyisobutylene Market Overview\nHigh Molecular Weight Polyisobutylene Market Size was valued at USD 2.02 Billion in 2022. The High Molecular Weight Polyisobutylene industry is projected to grow from USD 2.09 Billion in 2023 to USD 3.15 Billion by 2032, exhibiting a compound annual growth rate (CAGR) of 16.26% during the forecast period (2023 - 2032). Increasing demand for PIB in the transportation industry, increasing demand from the rubber industry, growing demand from the adhesive and sealant industry, and increasing demand from the lubricants and fuel additives industry, are the key market drivers enhancing the market growth.Source: Secondary Research, Primary Research, MRFR Database and Analyst Review\nHigh Molecular Weight Polyisobutylene Market Trends\nIncreasing demand for PIB in transportation industry is driving the market growth\nA prominent factor driving the market's growth is the rising demand for Polyisobutylene (PIB) in the transportation sector. A versatile synthetic polymer called PIB is at the center of innovation in the automobile industry, where its special qualities are being used to tackle major problems the sector is facing.\nA significant revolution is taking place in the transportation sector, especially the automotive industry, as a result of factors like strict environmental restrictions, the pursuit of higher fuel efficiency, and ongoing improvements to vehicle performance. In this setting, PIB has emerged as a useful addition that tackles numerous important facets of contemporary vehicle operation and design.\nParticularly noteworthy is PIB's capacity to improve fuel efficiency. PIB alters the combustion properties of gasoline and diesel fuels, resulting in a more controlled and effective burn. This not only leads to lower pollution emissions but also improves fuel efficiency. As fuel economy continues to be a key priority for both automakers and regulators, PIB's contribution to accomplishing these objectives has increased its significance in the sector.\nBeyond its mechanical uses, PIB is essential for enhancing the sealing and adhesive capabilities of several vehicle parts. Effective sealants and adhesives are used by automotive makers to guarantee component integrity, minimize noise and vibration, and improve overall safety. The high elongation and adhesion characteristics of PIB-based sealants and adhesives make them perfect for use in window seals, gaskets, and other crucial interfaces inside the vehicle structure. This improves the performance of the car while simultaneously improving passenger safety and comfort.\nThe popularity of EVs has highlighted the importance of PIB in the transportation sector. Even though EVs are fundamentally different from conventional internal combustion engine cars, they nevertheless need reliable lubrication and sealing products. Due to its adaptability, PIB can meet the special needs of EVs, including lubricating parts of electric drivetrains and maintaining seals in battery enclosures. Due to its versatility, PIB is a sought-after material in this changing environment as the EV market grows. Thus, driving the High Molecular Weight Polyisobutylene market revenue.\nHigh Molecular Weight Polyisobutylene Market Segment Insights\nHigh Molecular Weight Polyisobutylene Application Insights\nThe High Molecular Weight Polyisobutylene market segmentation, based on application, includes lubricants, stretch films, adhesives, and sealants. The lubricants segment dominated the market in 2022. The development of lubricants with lower friction coefficients and higher thermal stability is a result of the push for fuel-efficient automobiles and fewer emissions. By minimizing energy losses within engines, lubricants play a crucial part in reaching these objectives.\nHigh Molecular Weight Polyisobutylene end use industry Insights\nThe High Molecular Weight Polyisobutylene market segmentation, based on end use industry, includes transportation, industrial and food. The transportation category generated the most income in 2022. The transportation sector is looking for greener solutions as a result of rising environmental awareness and stricter emissions standards. Electric cars (EVs), hydrogen fuel cell technologies, biofuels, and other environmentally friendly transportation options have all advanced more quickly as a result of this factor. To fulfill emissions standards and lessen their carbon impact, automakers and other sectors of the transportation industry are investing in greener technologies.\nFigure 1: High Molecular Weight Polyisobutylene Market, by end use industry, 2022 & 2032 (USD Billion)Source: Secondary Research, Primary Research, MRFR Database and Analyst Review\nHigh Molecular Weight Polyisobutylene Regional Insights\nBy region, the study provides the market insights into North America, Europe, Asia-Pacific and Rest of the World. The North America High Molecular Weight Polyisobutylene Market dominated this market in 2022 (45.80%). With large car manufacturing and consumption, North America is a major market for the automobile industry. Its use as a viscosity modifier and fuel efficiency enhancer in lubricants and fuels used in automobiles may be what stimulates demand for HMW PIB in the area. The demand for such additives may rise as the automotive industry develops and prioritizes fuel economy and emissions control. Further, the U.S. High Molecular Weight Polyisobutylene market held the largest market share, and the Canada High Molecular Weight Polyisobutylene market was the fastest growing market in the North America region.\nFurther, the major countries studied in the market report are The U.S., Canada, German, France, the UK, Italy, Spain, China, Japan, India, Australia, South Korea, and Brazil.\nFigure 2: HIGH MOLECULAR WEIGHT POLYISOBUTYLENE MARKET SHARE BY REGION 2022 (USD Billion) Source: Secondary Research, Primary Research, MRFR Database and Analyst Review\nEurope High Molecular Weight Polyisobutylene market accounts for the second-largest market share. It has been at the forefront of environmental legislation and sustainability initiatives. Demand for additives like HMW PIB may rise as a result of the area's commitment to advancing eco-friendly technologies and reducing greenhouse gas emissions. It complements the European Union's objectives to reduce emissions thanks to its capacity to improve fuel efficiency and cut emissions. Further, the German High Molecular Weight Polyisobutylene market held the largest market share, and the UK High Molecular Weight Polyisobutylene market was the fastest growing market in the European region.\nThe Asia-Pacific High Molecular Weight Polyisobutylene Market is expected to grow at the fastest CAGR from 2023 to 2032. Demand for consumer items, such as chewing gum and adhesives, which utilise HMW PIB-based materials, has been pushed by the growing middle class in nations like China and India. The need for these products can help the HMW PIB market expand as customer preferences change. Moreover, China’s High Molecular Weight Polyisobutylene market held the largest market share, and the Indian High Molecular Weight Polyisobutylene market was the fastest growing market in the Asia-Pacific region.\nHigh Molecular Weight Polyisobutylene Key Market Players & Competitive Insights\nLeading market players are investing heavily in research and development in order to expand their product lines, which will help the High Molecular Weight Polyisobutylene market, grow even more. Market participants are also undertaking a variety of strategic activities to expand their footprint, with important market developments including new product launches, contractual agreements, mergers and acquisitions, higher investments, and collaboration with other organizations. To expand and survive in a more competitive and rising market climate, High Molecular Weight Polyisobutylene industry must offer cost-effective items.\nManufacturing locally to minimize operational costs is one of the key business tactics used by manufacturers in the High Molecular Weight Polyisobutylene industry to benefit clients and increase the market sector. In recent years, the High Molecular Weight Polyisobutylene industry has offered some of the most significant advantages to medicine. Major players in the High Molecular Weight Polyisobutylene market, including CHEMSPEC, LTD., BASF SE, TRiiSO, OJSC \"Efremov Synthetic Rubber Enterprise\", Naxant, Connect Chemicals, KEMAT Polybutenes, Lanxess AG, Daelim, FERRO-PLAST S.r.l., and SpecialChem and others, are attempting to increase market demand by investing in research and development operations.\nBASF SE (BASF) is a company that produces chemicals. It manufactures, markets, and sells chemicals, polymers, crop protection products, and performance items. The company's product line includes solvents, adhesives, surfactants, fuel additives, electronic chemicals, pigments, paints, food additives, fungicides, and herbicides. The company works with a wide range of industries, including those related to building, woodworking, agriculture, electronics and electrical, paints and coatings, transportation, home care, nutrition, and chemicals. In partnership with international customers, partners, and researchers, BASF carries out R&D. The company's operations are supported by a network of production facilities. It can be found all over the world, including in North America, Europe, Asia, South America, Africa, and the Middle East. The BASF corporate headquarters are in Ludwigshafen, Germany.\nLanxess AG (Lanxess) is a producer of specialty chemicals. Plastics, specialized chemicals, additives, and chemical intermediates are all created, produced, and sold by this company. The company's products are used in a variety of industries, including agrochemicals, automotive, construction, aromas and tastes, pharmaceuticals, tire chemicals, electrical, electronics, leather processing, and water treatment. To do R&D, it works with academic institutions and research facilities. Among its well-known brands are Rhenogran, Aktiplast, Aflux, Vulcuren, Perkalink, and Rhenoshape. The company's operations are supported by a network of production facilities. Latin America, North America, Europe, and the Asia-Pacific region are all home to it. Lanxess has its headquarters in Cologne, North Rhine-Westphalia, Germany.\n.Key Companies in the High Molecular Weight Polyisobutylene market include\nHigh Molecular Weight Polyisobutylene Industry Developments\nAugust 2022: King Salman Energy Park (Spark), a brand-new megaproject in Saudi Arabia, and Mubarak A. AlSuwaiket and Sons Oil & Gas Services Company (MASO&G) have signed a contract to establish a manufacturing plant at a cost of SR 40 million (US$ 10.65 million) within Spark. According to the contract, MASO&G will build the facility on 40,000 square meters of land in Spark and create corrosion protection tapes from highly reactive polyisobutylene, a viscous material that is friendly to the environment. A production and service facility for oil tools and equipment will be established by MASO&G.\nAugust 2022: New moisture protection for solar panels, SolarGain Edge Sealant LP03 from Quanex, can be applied during final manufacture. The sealant is a desiccant-integrated polyisobutylene adhesive.\nJanuary 2022: A provider of speciality chemicals, Nelson Brothers, unveiled its NB5-2628 co-emulsifier. The business provides polyisobutylene, PIBSA-based emulsifiers, polyisobutylene succinimides, and other related chemical derivatives to clients worldwide.\nJuly 2023: BASF SE and InterPuls introduced Ultrason P 3010.\nHigh Molecular Weight Polyisobutylene Market Segmentation\nHigh Molecular Weight Polyisobutylene Application Outlook\nHigh Molecular Weight Polyisobutylene end use industry Outlook\nHigh Molecular Weight Polyisobutylene Regional Outlook\n- North America\n- Rest of Europe\n- Australia and New Zealand\n- Rest of Asia-Pacific\n- Rest of the World\n- Middle East\n- Latin America\n|Market Size 2022\n||USD 2.02 Billion\n|Market Size 2023\n||USD 2.09 Billion\n|Market Size 2032\n||USD 3.15 Billion\n|Compound Annual Growth Rate (CAGR)\n|Market Forecast Period\n|Market Forecast Units\n||Value (USD Billion)\n||Revenue Forecast, Market Competitive Landscape, Growth Factors, and Trends\n||Application, end use industry, and Region\n||North America, Europe, Asia Pacific, and the Rest of the World\n||The U.S., Canada, German, France, UK, Italy, Spain, China, Japan, India, Australia, South Korea, and Brazil\n|Key Companies Profiled\n||CHEMSPEC, LTD., BASF SE, TRiiSO, OJSC \"Efremov Synthetic Rubber Enterprise\", Naxant, Connect Chemicals, KEMAT Polybutenes, Lanxess AG, Daelim, FERRO-PLAST S.r.l., and SpecialChem.\n|Key Market Opportunities\n||Expanding use in medical applications.\n|Key Market Dynamics\n||Growing demand from the personal care and cosmetics industry.\nFrequently Asked Questions (FAQ) :\nThe High Molecular Weight Polyisobutylene market size was valued at USD 2.02 Billion in 2022\nThe market is projected to grow at a CAGR of 16.26% during the forecast period, 2023-2032.\nNorth America had the largest share in the market\nThe key players in the market are CHEMSPEC, LTD., BASF SE, TRiiSO, OJSC \"Efremov Synthetic Rubber Enterprise\", Naxant, Connect Chemicals, KEMAT Polybutenes, Lanxess AG, Daelim, FERRO-PLAST S.r.l., and SpecialChem\nThe Lubricants category dominated the market in 2022.\nThe Transportation had the largest share in the market.\nKey Questions Answered\nRequest Free Sample\n- ✅Global Market Outlook\n- ✅In-depth analysis of global and regional trends\n- ✅Analyze and identify the major players in the market, their market share, key developments, etc.\n- ✅To understand the capability of the major players based on products offered, financials, and strategies.\n- ✅Identify disrupting products, companies, and trends.\n- ✅To identify opportunities in the market.\n- ✅Analyze the key challenges in the market.\n- ✅Analyze the regional penetration of players, products, and services in the market.\n- ✅Comparison of major players’ financial performance.\n- ✅Evaluate strategies adopted by major players.\nWhy Choose Market Research Future?\nSpeak to Analyst\n- ✅Vigorous research methodologies for specific market.\n- ✅Knowledge partners across the globe\n- ✅Large network of partner consultants.\n- ✅Ever-increasing/ Escalating data base with quarterly monitoring of various markets\n- ✅Trusted by fortune 500 companies/startups/universities/organizations\n- ✅Large database of 5000+ markets reports.\n- ✅Effective and prompt pre- and post-sales support."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:f43dda42-3d19-4fad-ab16-7631625f5808>","<urn:uuid:ebe9c315-ccc1-44d9-ba6d-daaf11c52289>"],"error":null}
{"question":"How did the historical development of Chinese philosophy compare with the evolution of the Silk Road trade routes?","answer":"Chinese philosophy developed over three thousand years through distinct periods (Pre-Han, Han through Tang, Song through Early Qing, and modern era) as outlined in philosophical traditions. Similarly, the Silk Road's development followed historical phases, starting with small-scale trade as early as 1500 BCE, reaching its peak during the Han and Tang dynasties, and then declining during the Song and Ming periods. While Chinese philosophy maintained continuous development through these eras, the Silk Road's importance fluctuated significantly, particularly diminishing when maritime trade became more prominent. This shows how philosophical development remained relatively stable while trade routes adapted to political and practical circumstances.","context":["The History of chinese language Philosophy is a finished and authoritative exam of the routine and thinkers that experience formed chinese language philosophy over the past 3 thousand years. a superb group of foreign members supply seventeen available entries organised into 5 transparent components:\nIdentity of chinese language Philosophy\nClassical chinese language Philosophy (I): Pre-Han Period\nClassical chinese language Philosophy (II): From Han via Tang\nClassical chinese language Philosophy (III): From Song Through Early Qing\nModern chinese language Philosophy: From overdue Qing Through twenty first Century\nThis extraordinary assortment is key examining for college kids of chinese language philosophy, and may be of curiosity to these trying to discover the lasting value this wealthy and complicated philosophical culture.\nThe tale of the search for a real-life Shangri-La within the darkest center of the Himalayas– a century-long obsession to arrive the sacred hidden middle of 1 of the world's final uncharted realms.\nAt the a long way japanese finish of the Himalayas in Tibet lies the Tsangpo River Gorge, referred to as “the nice romance of geography” through the 19th century's golden age of exploration. the following the strong Tsangpo funnels into an impenetrable canyon 3 miles deep, walled off from the surface international by means of twenty-five thousand foot peaks. just like the earthly paradise of Shangri-La immortalized in James Hilton's vintage 1933 novel Lost Horizon, the Tsangpo River Gorge is a shelter respected for hundreds of years by way of Tibetan Buddhists–and later in Western imagination–as a sanctuary in instances of strife in addition to a gateway to nirvana.\nThe Siege of Shangri-La tells the tale of this fabled land's exploration as either a geographical and non secular destination–and chronicles the invention on the finish of the final millennium of the reality in the back of the myths and rumors approximately it. Veteran journalist Michael McRae strains the gorge's exploratory heritage from the clandestine missions of surveyor-spies known as pundits and botanical expeditions of naturalists within the early 20th century to the new investigations of students, adventurers, and pilgrims looking the \"Hidden Falls,\" of the Tsangpo, which purportedly opponents Niagara in dimension and serves because the gateway to paradise. every one explorer's narrative offers expanding facts of why the gorge has been mythologized in japanese and Western lore as one of many world's such a lot attractive blanks at the map–and a ultimate try of human will.\nTaking readers on a guided travel of the gorge's panorama, actual and metaphysical, McRae provides an insightful examine the pursuit of glory and enlightenment that has performed out during this mysterious land with occasionally disastrous outcomes. The Siege of Shangri-La is an engaging trip throughout the internal recesses of a distant, mystical global and the minds of these who've tried to arrive it.\nThe acclaimed translation of the whole fiction of the daddy of recent chinese language literature\nLu Xun is likely one of the founding figures of contemporary Chiense literature. within the early 20th century, as China got here up opposed to the realities of the fashionable international, Lu Xun effected a shift in chinese language letters clear of the ornate, obsequious literature of the aristocrats to the obvious, expressive literature of the hundreds. His celebrated brief tales gather a powerfully unsettling portrait of the superstition, poverty, and complacency that he perceived in overdue imperial China and within the progressive republic that toppled the final dynasty in 1911. This quantity offers Lu Xun's whole fiction in bracing new translations and contains such recognized works as \"The actual tale of Ah-q,\" \"Diary of a Madman,\" and \"The Divorce.\" jointly they reveal a contradictory legacy of cosmopolitan independence, polemical fractiousness, and concerned patriotism that keeps to resonate in chinese language highbrow existence today.\nFor greater than seventy years, Penguin has been the top writer of vintage literature within the English-speaking international. With greater than 1,700 titles, Penguin Classics represents a world bookshelf of the easiest works all through heritage and throughout genres and disciplines. Readers belief the sequence to supply authoritative texts more advantageous through introductions and notes through uncommon students and modern authors, in addition to updated translations by means of award-winning translators.\nNo nation on the earth has suffered a extra sour historical past nowa days than China. within the moment half the 19th century, it was once considered as doomed to extinction. Its imperial rulers, heading an anachronistic regime, have been introduced low through huge, immense revolts, transferring social strength styles, republican revolutionaries, Western incursions to \"split the chinese language melon\" and a disastrous defeat by way of Japan.\nThe presence of predatory foreigners has usually been blamed for China's problems, however the a lot larger reason got here from inside of China itself. within the early 20th century, the empire was once succeeded through warlordism on an important scale, inner divisions, incompetent rule, savage battling among the govt. and the Communists, and a fourteen-year invasion from Japan. 4 years of civil warfare after 1945 resulted in the Maoist period, with its purges and repression; the disastrous nice step forward; a famine that killed millions; and the Cultural Revolution.\nYet from this lengthy trauma, China has emerged amazingly within the final 3 a long time as an monetary powerhouse set to play an important international political function, its destiny posing one of many nice questions for the twenty-first century because it grapples with huge, immense inner demanding situations. knowing how that transformation took place and what China constitutes at the present time capability knowing its epic trip in view that 1850 and spotting how the prior affects the current.\nJonathan Fenby tells this turbulent tale with brilliance and perception, spanning a distinct old landscape, with a unprecedented forged of characters and a succession of big occasions. As Confucius stated, to determine the longer term, one needs to snatch the past.\nBy Alison Lurie\nWINNER OF THE PULITZER PRIZE\nVirginia Miner, a fifty-something, single tenured professor, is in London to paintings on her new ebook approximately children’s folks rhymes. regardless of sporting a U.S. passport, Vinnie feels primarily English and really appears to be like down on her fellow americans. yet even with that, she is drawn right into a mortifying and oddly enjoyable affair with an Oklahoman vacationer who clothes extra Bronco Billy than Beau Brummel.\nAlso in London is Vinnie’s colleague Fred Turner, a good-looking, flat broke, newly separated, and carefully depressing younger guy attempting to specialise in his personal examine. as an alternative, he's distracted by means of a gorgeous and unpredictable English actress and the realm she belongs to.\nBoth American, either overseas, and either achingly lonely, Vinnie and Fred play out their pressured alienation and dizzying romantic liaisons in Alison Lurie’s Pulitzer Prize-winning novel. well written, poignant, and witty, Foreign Affairs is still an everlasting comedian masterpiece.\n“A greatest comedy, very shiny, brilliantly written in a convinced and unique demeanour. the easiest booklet through one in all our most interesting writers.”\n“There isn't any American author i've got learn with extra consistent excitement and sympathy. . . . Foreign Affairs earns an analogous shelf as Henry James and Edith Wharton.”\n“If you have the capacity to learn just a couple of reliable novels a yr, make this one among them.”\n“An creative, touching book.”\n“A perfect jewel.”\nBy Iris Chang\nThe Horse That Leaps Through Clouds: A Tale of Espionage, the Silk Road, and the Rise of Modern China\nBy Eric Enno Tamm\nOn July 6, 2006, author Eric Enno Tamm forums that very same educate, purpose on following in Mannerheim’s footsteps. at the start banned from China, Tamm devises a canopy and retraces Mannerheim’s path around the Silk highway, learning either eerie similarities and seismic variations among the center Kingdoms of a century in the past and today.\nAlong the best way, Tamm deals piercing insights into China’s earlier that elevate troubling questions about its destiny. Can the Communist get together really open China to the surface international but maintain Western rules equivalent to democracy and freedom at bay, simply as Qing officers mistakenly believed? What can reform in the course of the past due Qing Dynasty train us in regards to the awesome transformation of China at the present time? As Confucius as soon as wrote, “Study the prior when you might divine the future,” and that's accurately what Tamm does in The Horse That Leaps via Clouds.\nBy Bruce J. Dickson\nIn Wealth into strength, Bruce Dickson demanding situations the concept that monetary improvement is resulting in political switch in China, or that China's inner most marketers are supporting to advertise democratization. as a substitute, they've got turn into companions with the ruling chinese language Communist celebration to advertise financial progress whereas conserving the political established order. Dickson's learn illuminates the Communist Party's technique for incorporating China's capitalists into the political procedure and the way the shared pursuits, own ties, and customary perspectives of the get together and the non-public quarter are making a kind of 'crony communism'. instead of being power brokers of swap, China's marketers may perhaps turn out to be a key resource of help for the party's schedule. in response to years of study and unique survey information, this publication may be of curiosity to all these drawn to China's political destiny and within the courting among financial wealth and political energy.\nBy Tang Bao Lin\nChen Duxiu used to be the prime determine within the New tradition flow and the co-founder of the chinese language Communist celebration. The get together, in spite of the fact that, basically stated his contribution on the early level of the party’s improvement whereas negating his later accomplishments.\nHaving spent 30 years in learning and writing approximately Chen Duxiu, Tang Baolin, the writer of this encyclopaedic maserpiece showcased the lifestyles and occasions of Chen Duxiu – his particular character, his complex courting with the occasion and China’s revolution. It provides readers a well-rounded Chen Duxiu.","The Silk Road : 丝绸之路\nEurope and Asia at the time of the Roman and Han dynasties\nThe Silk Road or Silk Route evokes an exotic vision of China; the imagination immediately conjures up camels carrying rare and exotic treasures thousands of miles through the desert landscapes of Central Asia.\nIt was of great importance in the Han (200BCE); Tang and Yuan dynasties. Trade did begin at a much earlier date but on a much smaller scale as Chinese silk has been found in Afghanistan from 1500BCE. The Silk Route fell into decline during the Song and Ming dynasties when trade by sea from southern ports became safer and more profitable than the overland route. There is more than one road, so it should be thought of as a network of roads as it has several branches, starting in both India and the Middle East and ending at the Chinese capital (for a long while this was at Luoyang, Henan province). There was also an overland route through Tibet to Bangladesh, from Chengdu to Hanoi and over the mountains of Yunnan into Burma. The name ‘Silk Road’ can only be traced back as far as the 19th century to the German geographer Baron von Richthofen ➚, it was not known by this name in China. The trade along the route was much more significant to the Indians, Europeans than to the Chinese, it carried only a small fraction of Chinese trade. The most exotic and expensive goods, silk, that could only be brought from China is reflected in the road's name.\nThe map above shows the Silk Road at about 100CE, when the Roman Empire extended into Asia Minor and the Han Empire had conquered much of modern China (except for Fujian). At the beginning of the Han dynasty explorer Zhang Qian ➚ spent 13 years on an eventful trek to the west where he married into the Xiongnu tribe ➚ (the Xiongnu had withstood Chinese expansion to the north-west). Zhang eventually brought back tantalizing news of advanced civilizations beyond China's borders. His journey into Parthia and India encountered traces of the Greek Empire that had been founded by Alexander the Great 356-323BCE ➚. Emperor Wudi's curiosity was piqued and he sought to find out more, including the exploration of a southern route into India through Yunnan. This first contact proved that China was not alone in developing an urban-based civilization. The Silk Route was first used to import horses into China, which were needed to improve the effectiveness of Han cavalry against the skilled horsemen of the northern frontier tribes. With the new horses General Ban Chao ➚ was able to subjugate them. Thereafter more tales and rumors of the great, far away Roman Empire reached China. They learned such things as the Romans drank from glasses rather than earthenware cups. The Han dynasty name for Rome was Da Qin 大秦 ‘Great Qin’ named after the Qin dynasty itself, apparently called ‘great’ due to their taller stature. Trade along the Silk Road between the two great empires grew rapidly. The Romans developed such a veracious appetite for silk that Emperor Tiberius introduced a ban to try to stem the outflow of gold. At this time it was the Sogdians ➚ centered at Samarkand who were the main traders along the route.\nSilk Road cities\nAlong the Silk Route are many ancient trading posts: Bakhara; Kashgar; Tashkent; Kunduz; Samarkand ➚; Turpan; Tehran. The fortunes of these great cities ebbed and flowed as different peoples came into ascendency; Central Asia remained an area in flux for many centuries. Most chroniclers emphasize the long route to the Mediterranean and yet it was the trade with India which was more important. It was from India that many would say the most precious cargo was imported: Buddhist religion. The grand western entrance into China was the Jiayuguan Gate, Gansu 嘉峪关 at the western end of the Great Wall of China. The Great Wall gave protection to travelers from attacks by tribes to the north on their passage deep into China through Lanzhou and on to the ancient capitals at Luoyang and Chang'an. When the Tibetan kingdom reached the height of its power in the Tang dynasty, Tibetans controlled the southern strands of the route. It was at Dunhuang, famous for its caves full of Buddhist paintings and scrolls, that the route divided - one route to the north of the inhospitable Taklamakan Desert to Central Asia and the other to the south with a branch to India.\nThe traditional caravan that traveled the route was made up of a hundred camels roped together. They generally managed thirty miles a day, hoping to reach the next oasis in good time for sunset. Bells hung around the necks would enable any camels that broke free to be located and alerted caravans to each other's presence from afar. As well as their prodigious skill in storing water, camels were invaluable for finding new sources of underground water that they could sense and paw at the ground to allow a temporary well to be dug. Knowledge of the exact route and weather conditions was passed down through generations of cameleers, to stray from the Silk Road was almost certain death. The journey was so long and arduous that they would normally make only one trip each year. To make a decent living they had to transport only the most precious of goods.\nPerils of the Silk Road\nThere are only a few passes through the mountains into western China and even then climbing up to 9,843 feet [3,000 meters] was no mean achievement for the hardy traders and their beasts of burden. In the deserts of Taklamakan it was water that was the crucial commodity. Only limited amounts of water could be carried and these would last only a few days. An ancient civilization built the Karez (or Qanat ➚) water system to take the melt-water from the mountains and channel it underground down to the towns fringing the desert. The system at Turpan ➚ is the most impressive where melons and grapes can be grown with no direct water supply. These irrigation systems were already in place two thousand years ago in the Han dynasty.\nThe Mongol conquest of China caused the whole of the route through Central Asia to come under Mongol control and trade flourished. The route had always been subject to raids by bandits who would kill the porters and steal their precious cargo. The Silk Road into China at this time is described in the travels of Marco Polo. Trade was carried in stages by local tribesmen, Parthians; Bactrians and Sogdians of Central Asia, who zealously maintained their role as middlemen. Only very few ever made the complete trek along the whole route. The lack of direct contact denied first hand knowledge in Europe of China and just as importantly China of Europe. However some Chinese inventions did make their way along the route including gunpowder; the abacus and silk. In return China grew fond of using wooden chairs rather than simple stools.\nAs the name ‘Silk Road’ implies, silks were the most important goods transported as they were light; non-perishable and valuable. Silk was the ideal cargo for long distance journeys by land. At the time of Diocletian ➚ the price of silk is estimated to be $0.5 million per pound - more than its weight in gold. Apart from silk, China exported grain, lacquer-work, bronzes, decorated metalwork, diamonds, pearls and rhubarb (then believed the only reliable cure for constipation ➚). While in return imports of spices (from India and Central Asia); glass; coral (for ornamentation) woolen textiles; rhino horn; hides; ivory; fruit; amber; tortoiseshell; purple cloth and horses came into China. Exotic birds and animals if they survived the long, grueling journey commanded a high price too. Diseases were a less welcome import and export – the Black Death ➚ that killed 100 million people came along the silk road from Mongolia.\nDecline of the Silk Road\nThe decline of the Silk Route started when northern China was conquered by the Jin and Xixia kingdoms during the early Song dynasty. The Southern Song dynasty had to rely on the sea to the south for trade as the overland silk road to the north was blocked off.\nAlthough the Silk Road re-emerged as the main overland transport route during the Mongol dynasty when this fell in 1368 the overland route was no longer as safe. Central Asian kingdoms and their trading cities along the route had been devastated by the Mongol conquests. Northern barbarian tribes resumed their threat to the northern Chinese Silk route and more significant of all, advances in maritime technology allowed for safe and more profitable transport by sea as maps and compasses made the long distance sailing trips more practical. Even in Roman times there had been small scale but significant maritime trade via Sri Lanka and Arabia. By the start of the Ming dynasty the sea routes had become well established. This was one reason why the center of Chinese civilization moved south from the Yellow to the Yangzi River valley.\nSilk Road re-discovered\nAfter many of the silk road cities had been abandoned and buried in sand for centuries it was the turn of explorer-adventurers in the late 19th century to enter a race to rediscover them. There was great interest in Europe and America about the distant, exotic history of Central Asia. Museums paid handsome rewards for ‘rediscovered’ (effectively stolen) treasures as they attracted many visitors. The explorers included Aurel Stein ➚ (UK); Paul Pelliot ➚ (France); Sven Hedin ➚ (Sweden); Albert von le Coq ➚ (Germany); Count Otani Kozui ➚ (Japan) and Langdon Warner ➚ (US). Some of the most prized relics were found at Dunhuang, Gansu.\nBelt and Road initiative\nIn the last few years the Chinese government has begun an ambitious program to bring economic development along the line of the original Silk Route (as well as sea routes), not just in China but to Central Asian states as well. It is called the Belt and Road Initiative ➚ and was launched in 2015. Just like the ancient Silk Road the new over-land route will offer cost-effective transportation from China all the way into the heart of Europe."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:eea94643-cc68-4e91-9aec-0534e29b6d86>","<urn:uuid:c7deb035-2d0a-4d36-9c98-5394e2d53014>"],"error":null}
{"question":"Could you explain the two main ways entropy manifests in the universe - at both the cosmic scale and in everyday processes - and provide a structured comparison of their characteristics?","answer":"Entropy manifests in two key ways: 1) At the cosmic scale, entropy represents an irreversible process of increasing disorder across the entire universe, where energy becomes less and less useful as it disperses. The universe itself must eventually die due to this continuous increase in entropy. 2) In everyday processes, entropy appears as the natural tendency for things to move from order to disorder - for example, heat flowing from hot to cold bodies, or mixed gases remaining mixed rather than spontaneously separating. In both cases, entropy always increases because that state is overwhelmingly more likely. This principle is formalized in the Second Law of Thermodynamics, which states that the entropy of an isolated system must increase over time. Engineers can calculate this using the Clausius inequality (∫dQ/T ≤ 0) to determine whether processes will occur spontaneously.","context":["Jim Al-Khalili - Arthur Eddington - Peter Atkins - Brian Cox TV - Jacob Bronowski TV - Robert Hewison - Anton Chekhov - Rudolf Arnheim - Lord Byron - Vaclav Havel - Freeman Dyson - Erwin Schrodinger - Stephen Hawking - Morgan Freeman TV - Christopher Hitchens -\n48,728. How did humans acquire the power to transform the planet like this? Looking at the Earth at night reveals to us just how successful we’ve been in harnessing and manipulating energy, and how important it is to our existence. Energy is vital to us all. We use it to build the structures that surround and protect us. (Energy & Physics & Entropy & Laws of Science) Order and Disorder With Jim Al-Khalili I: Energy, BBC 2012\n48,729. Energy is essential to life itself. (Energy & Physics & Entropy & Laws of Science) ibid.\n48,730. What exactly is energy? And what makes it so useful to us? (Energy & Physics Entropy & Laws of Science) ibid.\n48,731. Scientists would come up with a strange set of laws that would link together everything from engines to humans to stars. (Energy & Physics & Entropy & Laws of Science) ibid.\n48,732. Almost no-one had understood the fundamental nature of the steam engine; very few were aware of the cosmic principle that underpinned it. (Energy & Physics & Steam & Entropy & Laws of Science) ibid.\n48,733. Left alone energy always seems to go from being concentrated to being dispersed. (Energy & Physics & Entropy & Laws of Science) ibid.\n48,734. The second law of thermodynamics and it turned out to be stranger and more beautiful, more universal ... All things that gave off heat were in some way connected together. All things that gave off heat were part of an irreversible process that was happening everywhere. A process of spreading out and dispersing, a process of increasing entropy. It seemed that somehow the universe shared the same fate as a cup of tea. (Energy & Physics & Universe & Entropy & Laws of Science) ibid.\n48,735. Entropy – why was it always increasing? (Energy & Physics & Entropy & Laws of Science) ibid.\n48,736. Entropy was in fact a measure of the disorder of things. (Energy & Physics & Entropy & Laws of Science) ibid.\n48,737. The universe itself must one day die. (Energy & Physics & Universe & Entropy & Laws of Science) ibid.\n48,738. Hydrogen is the most abundant element in the universe. (Energy & Physics & Hydrogen & Entropy & Laws of Science) ibid.\n2,429. The law that entropy always increases, holds, I think, the supreme position among the laws of Nature. If someone points out to you that your pet theory of the universe is in disagreement with Maxwell’s equations – then so much the worse for Maxwell’s equations. If it is found to be contradicted by observation – well, these experimentalists do bungle things sometimes. But if your theory is found to be against the second law of thermodynamics I can give you no hope; there is nothing for it but to collapse in deepest humiliation. (Science & Entropy & Nature & Theory & Laws of Science) Arthur Eddington, The Nature of the Physical World, 1928\n2,860. Everything disperses. Collapse into disorder is the spring of the universe. (Universe & Entropy) Professor Peter Atkins, Oxford University, Horizon: What is One Degree? BBC 2011\n5,626. The energy itself becomes less and less useful – it becomes ever more disordered. (Life & Energy & Entropy) Professor Brian Cox, Wonders of Life I: What is Life? BBC 2013\n5,627. This descent into disorder is happening across the entire universe. (Life & Entropy) ibid.\n58,149. Entropy always increases. Why is that? Because it’s overwhelmingly more likely that it will (Universe & Space & Entropy) Brian Cox’s Adventures in Space & Time IV, BBC 2021\n71,429. The second law of thermodynamics ... Entropy ... Entropy always increases because it is always more likely. (Entropy & Time & Laws of Science) Professor Brian Cox, Wonders of the Universe 1/4: Destiny, BBC 2011\n5,844. Entropy is a measure of disorder. (Evolution & Entropy & Humanity) Jacob Bronowski, The Ascent of Man 10/13: World Within World, BBC 1973\n71,430. The turn of the century raises expectations. The end of the millennium promises apocalypse and revelation. But at the close of the twentieth century the golden age seems behind us, not ahead. The end game of the 1990s promises neither nirvana nor Armageddon, but entropy. (Entropy & Future) Robert Hewison, Future Tense, 1990\n71,431. Only entropy comes easy. Anton Chekhov\n71,432. Entropy theory is indeed a first attempt to deal with global form; but it has not been dealing with structure. All it says is that a large sum of elements may have properties not found in a smaller sample of them. Rudolf Arnheim, In Entropy and Art: An Essay on Disorder and Order, 1974\n71,433. I had a dream, which was not all a dream.\nThe bright sun was extinguish’d, and the stars\nDid wander darkling in the eternal space,\nRayless, and pathless, and the icy earth\nSwung blind and blackening in the moonless air;\nMorn came, and went – and came, and brought no day. (Entropy & Darkness) Lord Byron, Darkness\n71,434. Just as the constant increase of entropy is the basic law of the universe, so it is the basic law of life to be ever more highly structured and to struggle against entropy. (Entropy & Laws of Science) Václav Havel\n71,435. The total disorder in the universe, as measured by the quantity that physicists call entropy, increases steadily as we go from past to future. On the other hand, the total order in the universe, as measured by the complexity and permanence of organized structures, also increases steadily as we go from past to future. (Entropy & Laws of Science) Freeman Dyson\n71,436. Thus the device by which an organism maintains itself stationary at a fairly high level of orderliness (= fairly low level of entropy) really consists in continually sucking orderliness from its environment. (Entropy & Laws of Science) Erwin Schrödinger, What is Life?\n96,076. The second law of thermodynamics: it states that the entropy of an isolated system always increases, and that when two systems are joined together, the entropy of the combined system is greater than the sum of the entropies of the individual systems. (Entropy & Laws of Science) Stephen Hawking, A Brief History of Time p112\n96,086. The increase of disorder or entropy with time is one example of what is called the arrow of time, something that distinguishes the past from the future, giving a direction to time. (Entropy & Time) ibid. p161\n115,660. The end of life: it’s a reality that terrifies us and motivates us. Now cutting edge science embarks on a bold mission to extend human life … Will death remain inevitable or can we live for ever? (Universe & Life & Death & Immortality & Entropy) Morgan Freeman’s Through the Wormhole s2e9, Can We Live For Ever? Science 2011\n115,661. Anything and everything in the universe has the tendency to go from order to disorder … Nothing is immune to the power of entropy. (Universe & Life & Death & Immortality & Entropy) ibid.\n9,372. Death is our ultimate destination: a place from which no-one ever returns. But what if death wasn’t the end? (Death & Immortality & Entropy) Morgan Freeman’s Through the Wormhole s3e6, Can We Resurrect the Dead? Science 2012\n9,373. What if we could grow the dead back to life? ... Can we cultivate a garden of resurrected humans? (Death & Immortality & Entropy) ibid.\n2,158. It’s good to know we’re born into a losing struggle ... Everything is governed by entropy and decline and annihilation and disaster. (Life’s Like That & Entropy) Christopher Hitchens v Rabbi David Wolpe, Boston 2010","Second law of thermodynamics is law of nature, unarguably one of the most valuable find of mankind. But this topic is somewhat confusing for most of the students and engineers. This video is aimed at describing 2nd law in an engineer’s point of view.\nSummary of the above lecture along with application of 2nd law in engineering life are described below.\nUses of Second Law\nWe will start our discussion by going through uses of 2nd law. They are listed below.\nDirection of a Process\nMaximum Possible Thermal Efficiency\nMost important use of second law is to determine direction of a process. First law of thermodynamics tells the user only about energy transfer, it does not specify in which direction energy transfer will happen for a given condition. Consider following examples.According to first law hot tea can gain heat, mass can go up and mixed gas can become unmixed spontaneously. It is 2nd law of thermodynamics which comes in between and tells in which direction a process is possible spontaneously.\nFig.1 Second law is used to determine in which direction above processes will happen spontaneousl\nWell, you could argue that you can find out direction of all this processes without using second law (from your intuition). Then what about following process, a chemical reaction.\nFig.2 Second law can even check whether the chemical reaction above is spontaneous or not\nCan you say in which direction reaction will go spontaneously from your intuition ? Using 2nd law you can predict even this, you can predict whether the blue atoms and yellow atoms combine together to form a new molecule spontaneously.\nAnother main use of 2nd law is in determining maximum possible thermal efficiency of a given system. 2nd law of thermodynamics puts a limit for maximum performance a system can achieve. For example you can find whats the maximum thermal efficiency possible for a car engine or refrigerator just by knowing its heat interaction temperatures\nClassical Statements of 2nd Law\n2nd law has got 2 classical statements, they are self-similar.\nAccording Clausius statement heat cannot flow from a hot body to cold body without any external work.This is depicted in following figure.\nClausius statement does not permit the process shown here\nAccoriding to Kelvin-Planck statement a heat engine cannot produce work without rejecting some heat to the surrounding. This is depicted in following figure.\nFig.4 Kelvin-Planck statement does not premit the process shown in figure\nClausius Inequality – 2nd Law in a Useful form for Engineers\nClausius and Kelvin-Planck are 2 classical statements of 2nd law, but they are not in a form which is directly useful for engineers.Most useful form of 2nd law is Clausius inequality, It states that cyclic integral of dQ/T along boundary of a cycle will always be less than or equal to zero.\nHere temperature T should be in Kelvin.Right hand side of this equation becomes zero when there is no irreversibility present in the cycle, irreversibilities like friction or vertices. Consider following example, a power production cycle.\nClausius inequality applied on a power plant cycle\nHere there are 2 heat interactions in the cycle, one at condenser represented by ‘c’ next is at boiler represented by ‘b’. Assuming there are no irreversibilities present and heat interactions are in uniform temperature, then Clausius inequality reduces to\nConcept of Carnot Engine\nWhen heat interactions are happening at uniform temperature and irrevesibilities in cycle are zero, such cycle will give maximum possible thermal efficiency.This cycle is known as Carnot cycle. In this aspect the power cycle we just discussed above is an example of Carnot cycle. So thermal efficiency of such a cycle can be written as\nOr 2nd law states that a cycle which gives thermal efficiency more than Carnot efficiency is impossible. If somebody approaches you claiming a very high efficiency engine, with efficiency greater than Carnot efficiency you can send him back immediately.\nSecond Law for a Process – Concept of Entropy\nIf you want to apply 2nd law for a process the statements derived above which are for cycles are not useful. Consider following cyclic processes, 1st cycle passes through paths A & B and 2nd cycle passes through paths A & C.\nFig.6 Two cyclic processes used to define 2nd law for a process, here process A same for both the cycles\nIf there is no irreversibitly in the cycle Clausius inequality for the first cycle cycle can be written as\nSimilarly Clausius inequality for 2nd cycle can be written as\nComparing these two equations one can write\nSo irrespective of path taken integration of the quantity dQ/T for a reversible process remains same. This is exactly how a property is defined, properties are independent of path taken. We will call this property entropy, denoted by S.So for a reversible process change in entropy can be represented as\nSecond Law for an Irreversible Process\nOne can extend 2nd law equation derived for reversible process to an irreversible. In this case a term called entropy production should be added to the equation. Entropy production signifies degree of irreversibilities during the process. So entropy change equation for an irreversible process is\n<[>So there could be 2 components for entropy change in an actual process.\n- Entropy transfer – due to heat interaction\n- Entropy production – due to effect of irreversibilites\nValue of entropy transfer can be either positive or negative, but value of entropy production is always positive.\nIncrease of Entropy Principle\nConsider following case, where system is losing some heat to surroundings. We can approach this problem in 2 ways.\nFig.7 Two approaches in solving same problem, second approach states that entropy transfer of universe is zero\nIn first approach we consider object as system, so system is losing some entropy due to entropy transfer. In second approach we are considering the object and surrounding of the object together as system, means we are considering the universe together. In such an approach there will not be any heat loss from it. Whatever heat interactions are happening is within the universe. So there is no entropy transfer from universe. The general entropy change equation will be simplified as\nSince entropy production term is always positive, from above equation it is clear that change of entropy of universe always positive or entropy of universe always increases. This is increase of entropy principle. We will do a sample problem to demonstrate increase of entropy principle.\nConsider the following case, a hot tea which is in a surrounding whose temperature is less than temperature of tea. Now the question is whether the tea will gain heat or lose heat ?\nFirst assume the tea is gaining 10J of heat, then change in entropy of universe is\nSubstituting values in it\nThis shows that entropy change of universe is negative, that is against 2nd law of thermodynamics. But if the tea loses 10J of heat this will lead to increase in entropy of universe, which means this is a feasible process.\nConcept of Gibbs Free Energy\nWhile using increase of entropy principle engineer has to calculate entropy change of surrounding also.In order to over come this difficulty a new property is introduced – Gibbs free energy.\nFig.9 Use of Gibb’s free energy change in determining whether this chemical reaction is spontaneous or not\nConsider the example shown above, here we want to determine whether the given chemical reaction will occur spontaneously. For this purpose we have to determine entropy change of universe as we did in earlier case. Here entropy change of system and enthalpy change of system are given, so entropy change of surrounding is given by\nSo entropy change of universe is\nThis process is spontaneous if\nSince T is always positive we can write process is spontaneous if\nWe will call L.H.S of this equation as another property called Gibbs free energy. So in short a process is spontaneous if\nMost of the time it is also convenient to talk in terms of Gibbs free energy. When Gibbs free energy change of system is less than zero it implies entropy change of universe is greater than zero.\nIndustrial Applications of 2nd Law\nSecond law of thermodynamics is extensively used in industry to determine direction of a process or a reaction. Most common method to check whether a reaction is spontaneous is to find out change in Gibbs free energy. If this term is negative for a reaction then the process is spontaneous.\nDoes Entropy Mean Disorder?\nThe discussions we have done so far were in macroscopic point of view. But there exists a whole different field of thermodynamics where things are viewed microscopically, called as Statistical thermodynamics.Boltzman relation is considered to be one of the pillar statement of statistical thermodynamics, at the same time it is one of the most controversial too. According to this entropy, S and thermodynamic probability, w are related by the relation\nThe term thermodynamic probability, w deserves special attention. It represents total number of possible microscopic states available to a system, it often referred to as disorder of the system. So according to Boltzman relation as disorder of the system increases entropy increases, or if during a process disorder of the universe increases that process is spontaneous.But always remember statistical thermodynamics is not free of controversies, especially Boltzman relation. For an engineer thermodynamics in classical point of view is enough for his needs."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:de9537cf-61f4-4ed1-b8f0-c71a9803f1d2>","<urn:uuid:fcfc0825-a775-449b-bebc-950eea195c9a>"],"error":null}
{"question":"What advantage does t'blade's thermal design provide for ice skating?","answer":"The t'blade system achieves up to 40% better gliding characteristics compared to traditional ice skate blades due to its thermal properties. The small metal mass (around 5.5g) allows the contact area to warm up faster and to a higher degree, while the plastic acts as an insulator. This creates a surface temperature up to 4 degrees Celsius higher in the ice contact area, resulting in a perfect water film for superior gliding.","context":["What is t’blade?\nThe t’blade system describes a blade system for ice skates. It is based on unique innovative technology and is a relatively “young” product. The development took place as a result of urgent need to create a blade system which does not require a time-consuming and cost-intensive sharpening process and at the same time offers superior gliding characteristics.\nThe original idea for the t’blades is based on the simple and quick exchange of the runners, as soon as the running surface respectively the edges of the blade are worn (similar to the razor principle & and the replacement of the razor blades). The runners, which are made nearly completely of plastic, are equipped with a thin metal band which represents the actual running surface.\nIn addition to the runner described above, the t’blade system also consists of the blade holder and a stabilizer which serves to fasten the runner.\nWhich advantages does t’blade offer over conventional ice skate blades?\nManufacturing the runners by machine achieves precision which cannot be achieved by sharpening a blade by hand – the absolutely constant\nrocker form as well as the exact hollow radius profile.\nAdditionally, the combination of plastic and metal provides huge advantages:\n- Due to the very small metal mass (approx. 5.5g), the contact area (gliding area) of the runner can warm up faster and to a higher degree. In connection with the highly polished gliding area, this results in up to 40% better gliding characteristics when compared with traditional ice skate blades. The t in t’blade describes exactly these thermal characteristics which are improved by the plastic in the runner acting as an insulator. In addition, the t-blade blade is the lightest ice skate blade on the market.\n- By using a stainless and fracture-resistant spring steel. the metal band of the runner has an enormous edge hardness of 54 HRC (570 HV) which achieves a useful life 4 times longer than traditional steel blades. (Heat generation during the traditional sharpening process significantly reduces edge hardness – by approx. 30 %.)\n- Additionally, good maneuverability, high cornering speed, and maximum braking deceleration are achieved. The elastic recovery effect of the runner also provides better acceleration behavior.\n- By using fibrous plastic (glass or carbon fiber) a maximum rigidity and resistance against fracture of all components in temperatures of up to -25?(-13°F) is achieved.\nWhat does the t in t’blade stand for?\nThe “t” in connection with the red flame stands for the superior thermal characteristics of the t’blade blade system. Through the globally unique technology of our ice skate blade, an up to 4 degree Celsius (7.2 degree F) higher surface temperature is achieved (without adding externally generated heat) in the ice contact area of the gliding surface (metal strip).\nThe thus generated, localized heating of the runner gliding surface results in a perfect water film with the resulting known and superior gliding characteristics of the t’blade blade system.\nCan / must t’blade runners be sharpened ?\nNo! The t’blade runners cannot be sharpened like traditional ice skate blades. This would result in melting the plastic in the area of the metal strip. Should the runner no longer offer sufficient edge support, it can at any time be replaced simply and quickly with a new runner.\nYour t’blade dealer carries replacement runners. For fixing smaller “dents” and irregularities in the metal strip, we recommend using a grinding stone.\nHow long does a t’blade runner last?\nThe t’blade runner, on average, has a 4-5 times longer useful life than a conventional ice skate sharpening. Despite the fact that the metal strip (running strip) is made of especially hard spring steel, an unintentional edge contact (concrete, goal post) will inevitably lead to defects. We, therefore, recommend treating the runner with the same care as any other ice skate blade.\nWhy do I need different hollows respectively gliding surface lengths?\nThe many different hollows and gliding surface lengths allow every user to react to the varying temperatures of the ice surface in accordance with his/her skating abilities and body weight. A shorter rocker (S) provides better maneuverability, a longer one (L) provides more linear stability.\nDepending on the condition of the ice, a very deep hollow radius (9,11) ensures better edge support; a shallower radius (13,15,…) better gliding ability.\nThe rule of thumb says: The harder the ice surface, the smaller (9,11) the hollow radius that should be selected. The softer the ice surface, the larger (15,18) the hollow radius.\nI am trying the t’blade system for the first time. Which runner should I use?\nWe generally sell all our blade systems and ice skates with a factory-installed M-13 runner. This has been established as a standard and offers both, beginners and advanced skaters, good edge support and sufficient gliding characteristics. The majority of our users fares quite well with this arrangement.\nFor new t’blade users, we recommend more a slightly deeper hollow radius (11,9), in order to get used to the special running characteristics of the t’blade system. Due to the mechanical production of our runners, these have an extremely smooth surface, which offers very good gliding characteristics, but may require initially a brief settling-in phase for some users.\nWhy are t’blades noisier than traditional steel blades?\nThrough the high plastics content in the runner, an enormous flexibility is achieved in comparison to a conventional steel blade which, for example, is indicated by high cornering speeds and an improved acceleration behavior. The elastic recovery effect – that is, the distortion of the runner – leads, in particular during high loads (skating curves), to a clearly audible sound.\nDo I need a certain body weight to skate on t’blades?\nNo. It is true that a heavier user respectively player can better exploit certain advantages of our system, such as extremely tight curve radii. This is simply due to his/her higher body weight and the fact that he/she can thus exert more pressure on the t’blade system and the extremely flexible runner.\nWhen skating curves, the flexibility of the runner produces an additional steering effect which permits a higher cornering speed and an undreamed of maneuverability on the ice. It is wrong, however, to assume that lighter users or players cannot use the t’blade system. They are just not yet able to make a 100% use of all of the system’s advantages. Based on the excellent system stability, the t’blade blade can take user weight loads of a maximum of 120 kg (264 lbs.).\nWhich is my system size (blade length)?\nOur blade systems have millimeter data and are organized into the following sizes: 248-256-264-272-280-288-300. Should you already use a t’blade system, you can find the appropriate size information\n- directly on the runner. for example M-11-272: The last numbers (272) identify the system length\n- as small numbers on the rear, inner side of the stabilizer\n- on the blade holder (on the projected area of the stabilizers).\nFrom which shoe size on can I use t’blades?\nCurrently, the smallest t’blade system length is the blade system size 248mm. This corresponds approximately to the European shoe size 36.5.\nCan I install my t’blade runner system by myself?\nIn order to ensure correct and professional mounting, we recommend having the t’blade blade system mounted by trained personnel at your specialized retailer’s only.\nWhat does the designation M-11-272 on the runner mean, for example?\nThe designation M-11-272 identifies, in sequence, the gliding surface length (M), the hollow radius (11), and the system size of the runner (272mm). Altogether, our runners are available in three gliding surfaces (S,M,L) and six hollow radii (9,11,13,15,18,21). You can find a detailed description in the blade system area (runner).\nWhy do I need the t’blade system wrench?\nThe system wrench is needed for replacing the runner. With the system wrench, you can loosen respectively tighten the special stabilizer screws.\nCan I change my t’blade runner everywhere?\nYes, with the t’blade blade system you are completely independent. The only thing required for the simple and quick replacement of the t’blade runner is the included system wrench. Thus, you are never dependent on the sharpening skills of others and will be back in the game, respectively on the ice “in a jiffy”. For our t’blade pros we recommend using the steel bit as an inset in the cordless screwdriver for an even faster replacement.\nWhat does the t’blade blade system consist of?\nThe entire t’blade blade system (holder, stabilizer, runner) consists of – with the exception of the clips – an especially reinforced glass fiber plastic material. Additionally, the system is available as a carbon variant (holder made of carbon fiber-reinforced plastic).\nWhat is the difference between a standard holder and a carbon holder?\nIn contrast to our standard holder, the carbon holder is not reinforced with glass fiber, but with carbon fiber. Apart from an additional weight saving, it offers the user better transfer of force and is also torsionally extremely stiff.\nThe carbon holder’s surface is finished with an elegant carbon film and available in the system sizes 256-300mm. The carbon holder can, of course, be freely combined with all system parts (stabilizer, runner, clip) of the standard system.\nShould I test different hollows and gliding surfaces?\nWe recommend that. The t’blade blade system has been designed to offer every user optimal skating conditions at any time. Our product pages (blade systems) show a runner description which identifies the characteristics of the different runner types.\nAre all runners available in the colors white and black?\nNo. In principle, all runner variants are only offered in the color white (standard). In addition, variants M-11 and M-13 are also available in the color black. Less common variants (e.g., M-18, S-15, or L-15) may possibly still be available in black.\nIs there a difference between white and black runners?\nNo. Manufacturing as well as all material and running characteristics of the white and black runners are absolutely identical, only the color of the plastic material varies.\nWhere can I purchase t’blades?\nYou can purchase the complete t’blade product line at your local ice hockey retailer’s. Should he not have the desired t’blade product in stock, he can order the product(s) directly from us. Please note that delivery make take several days/weeks, depending on product and season. We would, therefore, ask you to order the desired articles from your retailer in good time.\nFor the “on-line” generation, our retailers naturally offer numerous Web shops, just use the common search engines for this purpose.\nWhat color options exist?\nGenerally, there are countless possible combinations. Please visit our product pages (blade systems) for your individual combination of holder, stabilizer, clip and runner.\nCan I freely select the color combinations?\nIn principal, all color combinations can be freely selected. In addition to the standard colors (colored plastic) we also offer metallic variants. These are covered by a metallic finish. Please note that all metallic stabilizers will only be sold with the clip in the same color. Naturally, clips in other colors may be purchased separately.\nCan one test the t’blade blade systems?\nRegrettably, we are currently not offering a t’blade test campaign. However, we will always keep you informed about campaigns in our NEWS section.\nI am a player / referee in a club – is there a possibility of getting sponsored?\nThe t’blade company supports the players (juniors and seniors) of the German national team as well as DEL-,2. Bundesliga (national league) players and referees Please contact us in this regard.\nDoes the t’blade system have disadvantages when compared with conventional steel blades?\nOther than a certain settling-in phase, no. If you have read our whole FAQ section, you will certainly agree with us in this respect.\nI have lost screws/nuts from the stabilizer. Where can I get some?\nScrew sets (1 set = for 1 pair of stabilizers), consisting of screws, nuts, and retaining washers can be reordered from your t’blade retailer or our Web shop at any time.\nMy t’blade system is defect. What do I do now?\nShould, contrary to expectations, any part of the system (holder, stabilizer, runner) break, we recommend immediate replacement to ensure skating safety. Holders, stabilizers, and runners can be purchased in pairs from your local retailer and should also be replaced in pairs.\nWhat are the holes in the edge of the sole of the t’blade holder needed for?\nThe holes serve for the easy installation of the t’blade holders on the ice skate boot and permit an accurate positioning of the blade system. The blade holder is fastened to the sole of the shoe by rivets or RMS screws.\nCan t’blades be used for figure skating?\nNo. The t’blade blade was developed for ice hockey and leisure sports and, therefore, does not possess the required technical prerequisites for figure skating (toe picks and extended rear section).\nAre skate guards needed?\nWe recommend to our users the use of a t’blade blade guard, as our t’blade runner’s edges are very sharp due to the special spring steel. This guard not only protects the user from injuries, but also protects the blade. In addition, our blade guard has a rubberized rocker which is optimally suited for moving around outside the ice surface (e.g., on concrete).\nI would like to place a link on your Website. Am I permitted to do so?\nCertainly. We are delighted to have raised your interest in t’blade. You can find the appropriate banners and buttons for your Web page, including the appropriate source code, in our download section. Should your page be interesting for us (fan page, information page, etc.), you can also send us an e-mail with a reference to your page and the corresponding banner, if applicable. We will then incorporate this page in our link list.\nI have additional questions! Where can I find additional information?\nShould you (as a retailer or consumer) have questions about specific t’blade products, feel free to send us an e-mail to the following address: email@example.com\nSubscribe to our Ice Hockey and Power Skating Channel"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:d28da705-6756-4c7b-ab2e-b2b6dce764d3>"],"error":null}
{"question":"What role do environmental forces play in the engineering challenges faced by Dubai's Burj Al Arab hotel versus Amsterdam's floating structures?","answer":"Both structures face different environmental challenges requiring specific engineering solutions. The Burj Al Arab was designed with a double curve membrane and PTFE coated fiberglass with air gaps to withstand wind pressures, plus expansion joints to handle horizontal stresses. The hotel's foundation needs to cope with horizontal loads of 15-35% of vertical loading in marine conditions. Amsterdam's floating structures, meanwhile, must primarily deal with changing water levels and wave action. In sheltered inlets, floating homes work well, but experts note that building further out to sea remains challenging due to wave effects, particularly during extreme weather events. The structures become more stable against waves as they get larger - a principle that influenced the design of both projects.","context":["The Amsterdam street that Monique Spierenburg lives on is a portrait of 21st century prosperity. Potted olive trees line balconies, and windows afford glimpses of minimalist kitchens and airy rooms decked with art. Spierenburg shows a visitor around her three-story house, pausing to point out her husband's woodworking shop and their sauna. Recently she had the painters in, but midjob they downed tools and ran out in fright. \"The house was moving,\" she shrugs.\nOr rather, bobbing. Like neighboring dwellings, Spierenburg's house floats. Amsterdam has a history of watery habitations, of course, its houseboats having long attracted free-spirited types. But the floating houses in the neighborhood of IJburg are aquatic life 2.0: they're not boats, but buildings with plots of water instead of earth. Kids wear life vests when they play on the jetties that serve as streets. Gardens grow on pontoons moored next to the houses, which rise and fall with water levels but are anchored to piles so that they don't float away unless the owners want to, in which case tugboats can move them elsewhere. \"Normally you think of a house being stable,\" Spierenburg laughs. \"It changed our vision of what a house is.\"\nAltering preconceptions on a broader scale is now the aim of a whole cadre of Dutch water architects and engineers. Floating buildings, they argue, could help tackle three of the gravest problems facing the planet: rising seas, growing urbanization and ever greater numbers of people. With the planet's population set to hit 9 billion by 2050, the world is going to need more housing, mostly in urban areas. Cities have always been built near water: about 90 of the world's 100 biggest cities are built on coasts or rivers. But they're going to have to learn to live with lots more water in the coming century, when seas are forecast to rise up to 60 cm. With 200,000 people moving from rural to urban spaces every day, they will also be more crowded, which means flooding will wreak even more havoc than it does now. According to Koen Olthuis, one of the architects involved in IJburg and founder of architecture firm Waterstudio: \"For the climate-change generation of architects, the key task will be learning to work with water, rather than against it.\"\nOver the centuries, the Dutch have mastered doing both. Nearly half of the country is below sea level, so it survives thanks to elaborate improvisations, from a system of dikes to building on man-made forests of wooden underwater piles. The past decade has brought a new approach: building floating structures on platforms of polystyrene and concrete. The country now has hundreds of floating structures, ranging from four-bedroom houses to small-scale office buildings to a floating prison, currently docked near Amsterdam. The projects are getting bigger: next year, Waterstudio begins work on a floating apartment complex called the Citadel complete with underwater parking as part of a waterscape development in South Holland. \"Floating structures are already part of our urban planning,\" says Hans Ovink, director of national spatial planning at the Netherlands' Ministry for Infrastructure and the Environment.\nThe Dutch aren't the only people building on water Dubai has famously fashioned islands shaped like a palm tree and a map of the world from sand dredged out of the Persian Gulf but nobody is doing it quite as extravagantly as the Dutch. Dutch Docklands, a water-development company founded by Olthuis and hotel developer Paul van de Camp, has partnered with the Maldives, a country of 1,190-odd islets, to build a floating golf course, a convention center and 43 private islands in the Indian Ocean. When van de Camp proposed the developments to the Maldives President, \"it was like in the '60s, when you said, 'We'll go to the moon.' \" Work on the $500 million golf course begins in January 2012, with the entire project due for completion in 2015. After that, there are plans for an even more ambitious phase of island development: a floating city, with 20,000 affordable homes for Maldivians.\nHow green are these visions? Very, insist their champions. The port of Rotterdam boasts a floating exhibition center designed by the Delft-based water-management firm DeltaSync. Made of three geodesic domes, it uses solar power and local water and energy sources, thus using 60% less energy than comparable structures. The mobility of floating structures is another green benefit, argues Olthuis. On land, unwanted buildings are left derelict or torn down. Floating ones can be recycled by being towed to new locations for a fresh purpose. The ocean's breezes and water can also be harnessed for heating and cooling. Docked near a building yard outside the Dutch town of Hoorn is a three-story model home built by the De Peyler construction company, which has sold about 20 of them at around $470,000 each. The water the house sits on helps cool and heat it. Flexible pipes anchored to the land provide drinking water and electricity; another pipe removes waste. \"The technology is here,\" insists De Peyler's Nick Capel, striding around the third floor's master bedroom. \"You are standing on it.\"\nSkeptics see the floating projects as novelties rather than serious solutions to urban congestion. The Maldives development is \"an interesting experiment,\" says Erik Swyngedouw, professor of geography at Manchester University. \"But it's one thing to build floating houses. It's another thing to do it on a large scale, to get energy and food in, and to get all the garbage out.\" And while building floating structures in sheltered inlets or at former ports is accepted practice, building further out to sea remains another issue altogether. \"At the moment, it's not possible to make very large or very high structures without taking into account the effect of the waves,\" says Han Meyer, chairman of urban design at Delft University of Technology's Faculty of Architecture. \"When the weather is calm, it's nice to live in a floating home, but you really have to think about what happens when there are extreme weather events.\"\nOlthuis' solution is to think big. \"A large structure reacts less to normal waves than a small one,\" he says. Although it will be partly protected because it's in a lagoon, the Maldives golf course he has designed will be supported on rigid floating structures surrounded by semirigid ones to absorb any energy from the waves. \"The golfers will not feel the difference from a land-based course,\" Olthuis claims. So confident are he and van de Camp of the success of their Maldives project, they have begun scouting water rights in cities around the world, from New York City and London to Rio de Janeiro and Hong Kong, purchasing tracts of water near developed areas (nondisclosure agreements prevent them from saying more). \"He who controls the water, controls the development on it,\" says van de Camp. His bet: that floating technology will turn rising seas into prime real estate.","Burj Al Arab is the world’s tallest iconic and most luxurious hotel. This building has received numerous recognitions around the world, and is mainly known by its design which resembles the shape of a sail boats mast.\nThis 321 meter high building was built on a man-made island only 280 meters from the coast, giving all visitors a 360o view of the bay. Construction began in 1993. Engineers created a surface with a layer of rocks, which is circled with a honey-comb pattern which protects the surface and foundation from erosion. The building contains more than 70 000 m2 of concrete and 9 000 tons of steel. It took only two years to construct the building and three years to construct the foundation on beach sand, making this a geotechnical wonder.8\nGeotechnical Engineering entails to obtain information of the physical properties of the soil and rock on a proposed site known as site exploration. This information combined with the mechanics of soil can assess the risks presented by the site conditions that must be concluded in the design process of foundations, earthworks and retaining walls.\nBurj Al Arab has one of the rarest and most interesting foundations, earthworks and retaining wall phenomena’s. This include building an island 280 meter off coast as a foundation for this 321 meter high sea shore wonder.1 Throughout this report we will look at which soils are found in Dubai, as well as the properties thereof including the construction of this hotel foundation.\nIf you need assistance with writing your essay, our professional essay writing service is here to help!Essay Writing Service\nConstructing the Burj Al Arab hotel\nThe design of the Burj Al Arab has been constructed with a specific geometry which supports the sail boat like design by protecting the building from changing wind loads. The outermost wall of the building has been constructed by the use of PTFE coated fibreglass which contains air gaps at regular intervals. This double curve membrane design is able to withstand wind pressures easily.3\nAdditional cables have been provided onto the structure to prevent any deflection in materials. On the full height of the building expansion joints were provided on the right side of the building to ensure the building can withstand the wind load pressures as well as the horizontal stresses that may occur during construction and operation. The material that was used for this sail boat like structure is not only robust but it also protects the buildings’ interior from the sun by using light defusion.3\nAfter seventy thousand cubic meters of concrete and ninety thousand tons of steel, this great engineering wonder is noted as the heart of Dubai. This spectacular feature of the Burj Al Arabhotel, with its two hundred and two rooms, is located 280 meter off shore from the coast of Dubai and recognised as the best in the world. 2\nConcept Architect: Tom Willis-WrightimagesCAHJ41BO.jpg\nConstruction Engineer: WS Atkins and Partners Overseas – Multidisciplinary Consultancy.\nInterior designers: Khuan Chew, Design Principal of KCA International (London).\nLocation: Jumeirah Beach Road, Jumeirah, Dubai, United Arab Emirates.\nType/Structure: Luxury 7 stars* rating hotel/resort\nSize: 321m x 280m (1,053 ft)\nMedium: steel, glass, cement, steel cables, piles\nFrom: Antonino Terranova. The Great Skyscrapers of the World. Special gatefold edition, page 269-279.\nFigure 1: Burj Al Arab hotel\nDubai’s Soil Profile\nThe topography of Dubai (which lies within the Arabian Desert) is different from the southern portion of the UAE. Its landscape consists of sandy desert patterns consisting mostly out of crushed shell and coral and is clean and white, whereas gravel dominates in the southern regions of the country. 2 When looking at the soil properties of Dubai, it’s weak and will most probably move outwards in the case of any construction on it. See figure 1 Dubai soil map. 3\nStudies also show that Dubai’s possibility of a tsunami is minimal, due to the Persian Gulf water that is not deep enough to trigger a tsunami. Thus Dubai is classified as a stable zone, whereas the nearest seismic fault line is 120 km from the UAE, making it unlikely for Dubai to be hit by a seismic impact.2\nFigure 2: Dubai soil map.\nThe moment when Dubai laid focus on the development of this world wonder, they knew it would be an engineering challenge. Many elements must be taken in consideration in geotechnical engineering to build the world’s 15th tallest building on seabed, where its properties are known as a collapsible soil due to a lack of silt and clay.\nThe collapse phenomenon can be defined as a soil which can withstand somewhat large stresses, with little settlement at low in situ moisture content which will show signs of a decrease in volume and associated settlement with no increase of load if the moisture content rises. Therefore the change in volume goes hand in hand with the change in the soil structure.\nIt is thus evident that a number of conditions need to be met before collapsing begins: 6\nThe soil must have a collapsible fabric in its structure. This is where the specified soil has a high void ratio and yet has relatively high shear strength at low moisture content due to a coating (Colloidal) around each grain.\nPartial saturation is essential. This is where collapse settlement will not occur in soils which are located under the water table.\nIncrease of moisture content. This could be seen as the cause for the collapse to take place. With the increase of moisture the colloidal coating loses its strength and thus forces the grains to a denser state with reduction in void ratio.\nSubjected to an imposed load greater than their overburden pressure before collapse can take place. This is only applied to certain collapsible soils.\nThe typical problem associated with a collapsible soil to a building is that although it is dependent on the increase of the moisture content, collapse can take place years after construction has taken place. 6 Large magnitude settlements can occur beneath lightly loaded structures as well as collapse settlement is regularly localised due to defects in foundation, drainpipe leakage and where ponding occur during rainfall.\nThe engineering properties which most affect the cost of a construction are strengthening compressibility. Both can be enhanced by reducing the voids in the soil. Water must be displaced from the saturated soils in order to reduce the void volume. This can take months if the permeability of the type of soil present is low.\nThe following engineering solutions to the mitigation of the collapse problem are listed below: 6\nAvoidance by stopping the triggering mechanism (increase in moisture). This can be made possible by ensuring that water does not penetrate the collapsing soil horizons.\nDesign for collapse. This could be possible in certain scenarios to design a structure which could withstand the predicted collapse settlement.\nChemical stabilisation. This is to make use of a stabilising agent which could reduce the settlement.\nPiled or pier foundation. This is used only when the soil comes from a transported origin which means that the bedrock is covered with a shallow layer, making it possible to rather build on piers or piles.\nRemoval and compaction. This could be done by removing the collapsible soil to a certain depth and replace it through compacting the removed soil in layers.\nIn situ densification by surface rolling. Surface rolling can be done by making use of an impact or vibrating roller for compaction.\nBeach sand is one of many soils that have a collapsible grain structure, where its surface contains large quantities of calcium carbonate which in more defined terms are remains of microscopic plants and animals that thrive on nutrients in the water surface, where it ultimately settles to the floor.\nThe strength and the behaviour of this soil are thus dependent on the calcareous particles which it contains. These grain particles’ is well rounded due to it being rotated and shaped by the waves and is poorly graded (i.e. having a narrow particle distribution). This contributes to the high void ratio, meaning that the soil is very loose and can be seen as not a good bonding material. 6\nTable 1: Transported soil and possible engineering problem.\nTransported Soil Type\nAgency of transportation\nProblem to anticipate\nCollapsible grain structure\nTests to be performed on beach sand\nA large amount of data can be generated from soil, but it can all be wasted if the most important step of sampling is not carried out properly. Thus, in order for an analysis to be of significance to a proposed project, it should represent the bulk material of the site. Additionally, soil samples must be taken in abundance and at random, to ensure that the overall characteristics of the soil are effectively represented. See table 2 for properties beach sand.\nThe following tests were used in classifying beach sand (collapsing soil structure):3\nParticle size distribution. This test is performed to measure the particle size distribution of the soil sample by passing it through a set of sieves. This is in order to produce a grading curve for the soil, which is used to find out its classification. The solid particles in a soil can have different shapes and sizes, and these characteristics thus have a significant effect on its engineering behavior. By making use of this test one can clearly note whether the soil is well or poorly graded. As for beach sand it is known to be a collapsible soil due to it having a poorly graded grain structure and affected by an increase in moisture.\nOur academic experts are ready and waiting to assist with any writing project you may have. From simple essay plans, through to full dissertations, you can guarantee we have a service perfectly matched to your needs.View our services\nAtterburg limits. This test makes use of three separate tests namely Liquid limit test, Plastic limit test and Shrinkage limit test. This test is used to determine a relationship between the soils consistency and its moisture content. If the soil has low moisture content, it would aim to break before deformation takes place, whereas if the moisture content is too high, the soil will deform more easily. This test is of great importance due to it having an impact on settlement underneath a proposed structure. The test can be used to distinguish between the presence of silts and clays. This is important as silt has much less cohesion than clay.\nDry density. This can easily be determined in a laboratory by measuring its physical dimensions and by weighing them. The dry density of a collapsible soil lies between 900-1600 kg/m3.\nOedometer test. When a structure is build on a soil it produces settlement due to compression within the soil profile, which depends on the soil’s properties such as self-weight and also the type of load the soil is experiencing. This test makes use of a series of loads in order to measure the corresponding settlement of the soil. By knowing the soil’s stress and strain properties will allow the prediction in settlement and swelling of the soil.\nCollapse Potential test. This test is used to determine the collapse parameters in order to design accordingly. The CP (Collapse Parameters) is given in percentage, to determine the level of severity.\nTriaxial test. This test is similar to the unconfined compression test, except that the sample is surrounded by a waterproof membrane and installed in a pressure chamber (cell). This test is thus performed to estimate the stress and strain parameters of the specific soil.\nPermeability. This test is used to determine the ease of which water can flow through a soil profile, which is important for geotechnical engineers in projects.\nTable 2: Soil properties of silt sand.9\nBulk Density (Mg/ M3)\nDry Density (Mg/ m3)\nLiquid limit (%)\nPlastic limit (%)\nEffective cohesion (kPa)\nAngle of friction (deg)\nConstruction of Burj Al Arab Foundation\nConstructing a building on sea, an artificial island is needed to design and build the foundations. As many elements need to be taken into account to build an off shore structure, it is therefore important to ensure the protection of the foundation. This can only be done by evaluating all apposed loads to a structure. Seafloor stability regards to the bearing capacity and the sliding resistance thereof must be evaluated for static and combined static, operational and environmental (Like horizontal, vertical loading and overturning moments of the environment which have a return period of up to 15 seconds) loads. Structures with more or less a 150 meter depth could experience horizontal loads of 15-35% of the vertical loading, whereas the overturning moment can be ranging from 100 to 500 million kN/m.8 The change in vertical load during a storm can range from 10 – 40 % of the static vertical load. This means that the foundation needs to be strong to be able to obtain these loadings. Luckily these loadings were much less when Burj Al Arab was constructed, due to it only being 7 meters in depth.8IslandConstruction1.jpg\nFigure 3: Piling of the Burj Al Arab hotel\nThe first step in constructing the island was to place 230 concrete piles (see Figure 3), each one 40 meter in length, which was drilled into the sea bed. The foundation is therefore held in place by the friction of the sand and silts along the length of the piles, rather than the conventional bedrock. The surface was then made by using large rocks that were put together in a specific concrete pattern (honey-comb pattern) which serves as a shield to minimise erosion to the foundation.\nMaking the platform on which the building would be constructed, tube files and sheet files were drilled deep into the sea to support various boundary rocks. Once this was completed the sea water was displaced to fill the inside with concrete slabs as seen on table 3. IslandConstruction2.jpg\nThe structure was then surrounded with a temporary concrete structure to protect the island and the base of the structure, which was filled with a concrete plug slab. Lastly the concrete walls was made where the main basement floor of the building was build (See Figure 4).3\nFigure 4: Burj Al Arab Excavated Basement\nTable 3: Foundation of the Burj Al Arab\nThe Burj Al Arab being a geotechnical wonder is due to its size as well as its ability to withstand the environment and the impacts thereof. This building is only carried by a sandy soil which contains broken shells. Its ability under shear strength and pressure is very low, especially since it is located 280 meters of shore. Thus the building stands only on piles which are held into place by just the friction between the soil and the piles, making this project one of the most remarkable foundation types in history. The design of this foundation on this type of soil is breaking barriers in the building industry, making Dubai a leading country in development.\nDue to South Africa not being a first world country it is impossible for us to be compared to a city which encourages ultimate engineering in structural, hydraulic and geotechnical engineering. Therefore we cannot compare the infrastructures of their country with ours. South Africa could always strive to be a first world country by focusing on infrastructure as well as the inequality of societies. This would encourage tourism and affect the economy positively.\nCite This Work\nTo export a reference to this article please select a referencing stye below:\nRelated ServicesView all\nDMCA / Removal Request\nIf you are the original writer of this essay and no longer wish to have your work published on UKEssays.com then please:"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:5f620516-347a-4b04-af43-f1cbd566ca67>","<urn:uuid:c03a22c6-b8cb-4901-a631-3e39e83ec2a6>"],"error":null}
{"question":"What are the key differences between how the American Physical Society and the Australian Medical Association address conflicts of interest in their ethical guidelines?","answer":"The APS and AMA have different approaches to conflicts of interest. The APS requires full disclosure of any professional relationship or action that may result in a conflict of interest, and states that activities should be avoided or discontinued when objectivity cannot be maintained. The AMA's approach is more specific to medical practice, requiring doctors to disclose any direct financial interests when referring patients to institutions or services, and emphasizing that professional duties to patients must be placed above commercial interests of practices or institutions.","context":["The Constitution of The American Physical Society states that the objective of the Society shall be the advancement and diffusion of the knowledge of physics. It is the purpose of this statement to advance that objective by presenting ethical guidelines for Society members.\nEach physicist is a citizen of the community of science. Each shares responsibility for the welfare of this community. Science is best advanced when there is mutual trust, based upon honest behavior, throughout the community. Acts of deception, or any other acts that deliberately compromise the advancement of science, are therefore unacceptable. Honesty must be regarded as the cornerstone of ethics in science.\nThe following are minimal standards of ethical behavior relating to several critical aspects of the physics profession.\nThe results of research should be recorded and maintained in a form that allows analysis and review. Research data should be immediately available to scientific collaborators. Following publication, the data should be retained for a reasonable period in order to be available promptly and completely to responsible scientists. Exceptions may be appropriate in certain circumstances in order to preserve privacy, to assure patent protection, or for similar reasons.\nFabrication of data or selective reporting of data with the intent to mislead or deceive is an egregious departure from the expected norms of scientific conduct, as is the theft of data or research results from others.\nPublication and Authorship Practices\nAuthorship should be limited to those who have made a significant contribution to the concept, design, execution and interpretation of the research study. All those who have made significant contributions should be offered the opportunity to be listed as authors. Other individuals who have contributed to the study should be acknowledged, but not be identified as authors. The sources of financial support for the projects should be disclosed.\nPlagiarism constitutes unethical scientific behavior and is never acceptable. Proper acknowledgment of the work of others used in a research projects must always be given. Further, it is the obligation of each author to provide prompt retractions or correction of errors in published works.\nPeer review provides advice concerning research proposals, the publication of research results and career advancement of colleagues. It is an essential component of the scientific process.\nPeer review can serve its intended function only if the members of the scientific community are prepared to provide thorough, fair and objective evaluations based on requisite expertise. Although peer review can be difficult and time-consuming, scientists have an obligation to participate in the process.\nPrivileged information or ideas that are obtained through peer review must be kept confidential and not be used for competitive gain.\nReviewers should disclose conflicts of interest resulting from direct competitive, collaborative or other relationships with any of the authors, and avoid cases in which such conflicts preclude an objective evaluation.\nConflict of Interest\nThere are many professional activities of physicists that have the potential for a conflict of interest. Any professional relationship or action that may result in a conflict of interest must be fully disclosed. When objectivity and effectiveness cannot be maintained, the activity should be avoided or discontinued.\nIt should be recognized that honest error is an integral part of the scientific enterprise. It is not unethical to be wrong, provided that errors are promptly acknowledged and corrected when they are detected. Professional integrity in the formulation, conduct and reporting of physics activities reflects not only on the reputations of individual physicists and their organizations, but also on the image and credibility of the physics profession as perceived by scientific colleagues, government and the public. It is important that the tradition of ethical behavior be carefully maintained and transmitted with enthusiasm to future generations.\nPhysicists have an individual and a collective responsibility to ensure that there is no compromise with these guidelines.\n©1995 - 2017, AMERICAN PHYSICAL SOCIETY\nAPS encourages the redistribution of the materials included in this newspaper provided that attribution to the source is noted and the materials are not truncated or changed.","Code of Ethics\nAMA Code of Ethics - 2004. Editorially Revised 2006\nMembers are advised of the importance of seeking the advice of colleagues should they be facing difficult ethical situations.\nThe AMA Code of Ethics articulates and promotes a body of ethical principles to guide doctors' conduct in their relationships with patients, colleagues and society.\nThis Code has grown out of other similar ethical codes stretching back into history including the Hippocratic Oath.\nBecause of their special knowledge and expertise, doctors have a responsibility to improve and maintain the health of their patients who, either in a vulnerable state of illness or for the maintenance of their health, entrust themselves to medical care.\nThe doctor-patient relationship is itself a partnership based on mutual respect and collaboration. Within the partnership, both the doctor and the patient have rights as well as responsibilities.\nChanges in society, science and the law constantly raise new ethical issues and may challenge existing ethical perspectives.\nThe AMA accepts the responsibility for setting the standards of ethical behaviour expected of doctors.\n1. The Doctor and the Patient\n1.1 Patient Care\n- Consider first the well-being of your patient.\n- Treat your patient with compassion and respect.\n- Approach health care as a collaboration between doctor and patient.\n- Practise the science and art of medicine to the best of your ability.\n- Continue lifelong self-education to improve your standard of medical care.\n- Maintain accurate contemporaneous clinical records.\n- Ensure that doctors and other health professionals upon whom you call to assist in the care of your patients are appropriately qualified.\n- Make sure that you do not exploit your patient for any reason.\n- Avoid engaging in sexual activity with your patient.\n- Refrain from denying treatment to your patient because of a judgement based on discrimination.\n- Respect your patient's right to choose their doctor freely, to accept or reject advice and to make their own decisions about treatment or procedures.\n- Maintain your patient's confidentiality. Exceptions to this must be taken very seriously. They may include where there is a serious risk to the patient or another person, where required by law, where part of approved research, or where there are overwhelming societal interests.\n- Upon request by your patient, make available to another doctor a report of your findings and treatment.\n- Recognise that an established therapeutic relationship between doctor and patient must be respected.\n- Having initiated care in an emergency setting, continue to provide that care until your services are no longer required.\n- When a personal moral judgement or religious belief alone prevents you from recommending some form of therapy, inform your patient so that they may seek care elsewhere.\n- Recognise that you may decline to enter into a therapeutic relationship where an alternative health care provider is available, and the situation is not an emergency one.\n- Recognise that you may decline to continue a therapeutic relationship. Under such circumstances, you can discontinue the relationship only if an alternative health care provider is available and the situation is not an emergency one. You must inform your patient so that they may seek care elsewhere.\n- Recognise your professional limitations and be prepared to refer as appropriate.\n- Place an appropriate value on your services when determining any fee. Consider the time, skill, and experience involved in the performance of those services together with any special circumstances.\n- Ensure that your patient is aware of your fees where possible. Encourage open discussion of health care costs.\n- When referring your patient to institutions or services in which you have a direct financial interest, provide full disclosure of such interest.\n- If you work in a practice or institution, place your professional duties and responsibilities to your patients above the commercial interests of the owners or others who work within these practices.\n- Ensure security of storage, access and utilisation of patient information.\n- Protect the right of doctors to prescribe, and any patient to receive, any new treatment, the demonstrated safety and efficacy of which offer hope of saving life, re-establishing health or alleviating suffering. In all such cases, fully inform the patient about the treatment, including the new or unorthodox nature of the treatment, where applicable.\n1.2 Clinical Research\n- Accept responsibility to advance medical progress by participating in properly developed research involving human participants.\n- Ensure that responsible human research committees appraise the scientific merit and the ethical implications of the research.\n- Recognise that considerations relating to the well-being of individual participants in research take precedence over the interests of science or society.\n- Make sure that all research participants or their agents are fully informed and have consented to participate in the study. Refrain from using coercion or unconscionable inducements as a means of obtaining consent.\n- Inform treating doctors of the involvement of their patients in any research project, the nature of the project and its ethical basis.\n- Respect the participant's right to withdraw from a study at any time without prejudice to medical treatment.\n- Make sure that the patient's decision not to participate in a study does not compromise the doctor-patient relationship or appropriate treatment and care.\n- Ensure that research results are reviewed by an appropriate peer group before public release.\n1.3 Clinical Teaching\n- Honour your obligation to pass on your professional knowledge and skills to colleagues and students.\n- Before embarking on any clinical teaching involving patients, ensure that patients are fully informed and have consented to participate.\n- Respect the patient's right to refuse or withdraw from participating in clinical teaching at any time without compromising the doctor-patient relationship or appropriate treatment and care.\n- Avoid compromising patient care in any teaching exercise. Ensure that your patient is managed according to the best-proven diagnostic and therapeutic methods and that your patient's comfort and dignity are maintained at all times.\n- Where relevant to clinical care, ensure that it is the treating doctor who imparts feedback to the patient.\n- Refrain from exploiting students or colleagues under your supervision in any way.\n1.4 The Dying Patient\n- Remember the obligation to preserve life, but, where death is deemed to be imminent and where curative or life-prolonging treatment appears to be futile, try to ensure that death occurs with dignity and comfort.\n- Respect the patient's autonomy regarding the management of their medical condition including the refusal of treatment.\n- Respect the right of a severely and terminally ill patient to receive treatment for pain and suffering, even when such therapy may shorten a patient's life.\n- Recognise the need for physical, psychological, emotional, and spiritual support for the patient, the family and other carers not only during the life of the patient, but also after their death.\n- Recognise that a potential donor is entitled to the same standard of care as any other patient.\n- Inform the donor and family fully of the proposal to transplant organs, the purpose and the risks of the procedure.\n- Exercise sensitivity and compassion when discussing the option to donate organs with the potential donor and family.\n- Refrain from using coercion when obtaining consent to all organ donations.\n- Explain brain death to potential donor families. Similarly explain that continued artificial organ support is necessary to enable subsequent organ transplantation.\n- Ensure that the determination of the death of any donor is made by doctors who are neither involved with the transplant procedure nor caring for the proposed recipient.\n- Recognise the important contribution donor families make in difficult circumstances. Ensure that they are given the opportunity to receive counselling and support.\n2. The Doctor and the Profession\n2.1 Professional Conduct\n- Build a professional reputation based on integrity and ability.\n- Recognise that your personal conduct may affect your reputation and that of your profession.\n- Refrain from making comments which may needlessly damage the reputation of a colleague.\n- Report suspected unethical or unprofessional conduct by a colleague to the appropriate peer review body.\n- Where a patient alleges unethical or unprofessional conduct by another doctor, respect the patient's right to complain and assist them in resolving the issue.\n- Accept responsibility for your psychological and physical well-being as it may affect your professional ability.\n- Keep yourself up to date on relevant medical knowledge, codes of practice and legal responsibilities.\n2.2 Advertising (editorially revised in November 2006)\n- Confine advertising of professional services to the presentation of information reasonably needed by patients or colleagues to make an informed decision about the availability and appropriateness of your medical services.\n- Make sure that any announcement or advertisement directed towards patients or colleagues is demonstrably true in all respects. Advertising should not bring the profession into disrepute.\n- Do not endorse therapeutic goods in public advertising.\n- Exercise caution in endorsing non-therapeutic goods in public advertising.\n- Do not have any public association with products that clearly affect health adversely.\n- Ensure that any therapeutic or diagnostic advance is described and examined through professional channels, and, if proven beneficial, is made available to the profession at large.\n2.3 Referral to Colleagues\n- Obtain the opinion of an appropriate colleague acceptable to your patient if diagnosis or treatment is difficult or obscure, or in response to a reasonable request by your patient.\n- When referring a patient, make available to your colleague, with the patient's knowledge and consent, all relevant information and indicate whether or not they are to assume the continuing care of your patient during their illness.\n- When an opinion has been requested by a colleague, report in detail your findings and recommendations to that doctor.\n- Should a consultant or specialist find a condition which requires referral of the patient to a consultant in another field, only make the referral following discussion with the patient's general practitioner - except in an emergency situation.\n3. Professional Independence\n- In order to provide high quality healthcare, you must safeguard clinical independence and professional integrity from increased demands from society, third parties, individual patients and governments.\n- Protect clinical independence as it is essential when choosing the best treatment for patients and defending their health needs against all who would deny or restrict necessary care.\n- Refrain from entering into any contract with a colleague or organisation which may conflict with professional integrity, clinical independence or your primary obligation to the patient.\n- Recognise your right to refuse to carry out services which you consider to be professionally unethical, against your moral convictions, imposed on you for either administrative reasons or for financial gain or which you consider are not in the best interest of the patient.\n4. The Doctor and Society\n- Endeavour to improve the standards and quality of, and access to, medical services in the community.\n- Accept a share of the profession's responsibility to society in matters relating to the health and safety of the public, health education and legislation affecting the health of the community.\n- Use your special knowledge and skills to minimise wastage of resources, but remember that your primary duty is to provide your patient with the best available care.\n- Make available your special knowledge and skills to assist those responsible for allocating healthcare resources.\n- Recognise your responsibility to give expert evidence to assist the courts or tribunals.\n- When providing scientific information to the public, recognise a responsibility to give the generally held opinions of the profession in a form that is readily understood. When presenting any personal opinion which is contrary to the generally held opinion of the profession, indicate that this is the case.\n- Regardless of society's attitudes, ensure that you do not countenance, condone or participate in the practice of torture or other forms of cruel, inhuman, or degrading procedures, whatever the offence of which the victim of such procedures is suspected, accused or convicted.\n1. Canadian Medical Association (1996). Code of Ethics of the Canadian Medical Association.\n2. World Medical Association International Code of Medical Ethics, as amended by the 35th World Medical Assembly, Venice, Italy, October 1983.\n3. World Medical Association Declaration on the Rights of the Patient, as amended by the 47th WMA General Assembly, Bali, Indonesia, September 1995.\n4. World Medical Association Declaration of Helsinki, as amended by the 52nd WMA General Assembly, Edinburgh, Scotland, October 2000.\n5. World Medical Association Statement on Human Organ & Tissue Donation and Transplantation, adopted by the 52nd WMA General Assembly in Edinburgh, Scotland, October 2000.\n6. World Medical Association Declaration with Guidelines for Continuous Quality Improvement in Health Care, as adopted by the 49th World Medical Assembly, Hamburg, Germany, November 1997.\nFor a printable copy please click here."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:1355e430-0ed4-43f4-b48d-ae6fefdf0509>","<urn:uuid:a4ab1f3e-5faf-4535-9053-e3f573d23060>"],"error":null}
{"question":"What features does a secured disposable finger-mounted toothbrush share with napkin collections in terms of single-use design and disposability?","answer":"While both items are designed for single use, they have different approaches to disposability. The finger-mounted toothbrush described in the patent is specifically engineered to be discarded after one use, featuring a mounting ring, bristle base, and dental floss lanyard to prevent accidental swallowing. Meanwhile, napkin collections, as exemplified by Helena Vnouckova's 16,000+ collection, preserve and archive disposable napkins rather than using them for their intended single-use purpose. The key difference is that while both are designed as disposable items, one is engineered specifically for safe single use and disposal (the toothbrush) while the other becomes a preserved collectible item (napkins) despite its originally intended disposable nature.","context":["Some people collect stamps, others collect comic books. The people on this list, however, collect things that are far, far stranger. Behold, Neatorama's guide to the 25 Strangest Collections on the Web:\n1. Graham Barker's Navel Fluff Collection\nGraham Barker's Navel Fluff Collection\nSome people see navel fluff or bellybutton lint as life's little annoyances. Not Graham Barker: he began collecting them since 1984, and now has the world's largest collection of navel fluff according to Guiness Book of World Records:\nIt was on the 17th of January 1984 that I found myself under-occupied in a youth hostel in Brisbane. The night was steamy and stormy - too wet outside and too hot inside to do very much, and my attention drifted to my belly button. There it was ... fluff! I must have seen it before that night, but this occasion was the first time I ever picked it out and wondered about it. I became curious about how much navel fluff one person could generate (enough to stuff a cushion, maybe?), and the only way to find for sure was to collect it and see. My first piece of navel fluff was stored in an empty film canister, and the collection had begun.\n2. Air Sickness Bag Virtual Museum\nLike its name implies, the Air Sickness Bag Virtual Museum is all about vomit bags. Indeed, it catalogs more than 2,000 photos of air sickness bags from all over the world.\nIn addition to airplane air sickness bags, the website also has a collection of bus sickness, sea sickness, and even space sickness bags!\nThough most are underwhelming in terms of design, some are actually quite artistic. Virgin Atlantic airlines even held a \"Design for Chunks\" project in 2004, where artists submit their designs to be put as a limited edition barf bags!\nBefore you check out the website, I'll leave you with a few of the more unusual bags from the Visitor's Favorite section:\nFrom left to right: Brooklyn Artist Sarah Nicole Phillip's Little Brown Barf Bag, a parody of Bloomingdale's Little Brown Bag; The Space Shuttle Sickness (\"Emesis\") Bag; Barf Bag One, unfortunately only a gag gift and not the real thing.\n3. Joseph W. Lauher's Handcuffs\nIf you want to collect handcuffs, then Joseph W. Lauher is your man, and handcuffs.org is the website to see. Indeed, Joseph has the largest collection of handcuffs (with focus on vintage ones), leg irons, nippers, and thumbcuffs on the Web: Link\nWhat's a nipper and a thumbcuff? Well, a nipper is a handcuff that locks only one hand, but has a handle for keeping the cuffed person under control (Photo to the left is a 1888 nipper made by Thomas & Smith).\nA thumbcuff, like its name implies, cuffs both of the person's thumbs.\n4. Bob Toelle's Fish Posters\nBob Toelle collects posters - but not any poster, just the ones about fish - and he's got a lot of it. Currently, Bob has more than 700 fish posters from around the world: Link\n5. Medical Antiques by Douglas Arbittier, M.D.\nAmputation set by Ferris & Co., Bristol (c. 1885)\nDr. Douglas Arbittier collects old medical equipments, and specializes in cased surgical sets. His collection includes a lot of amputation saws, and bloodletting artifacts (leech jar, anyone?).\nWhen you visit his website, keep what Dr. Arbittier said in mind: \"be thankful you live in today's medical world ...\": Link\n6. Barney Smith's Toilet Seat Art\nTexan artist Barney Smith has an unusual choice of art medium: toilet seats! For the past 30 years, Barney had created over 700 artistically decorated toilet seat lids. Check it out here: Link\n7. Sergei Frolov's Soviet Calculators\nW.T. Odhner Arithmometer (1890)\nSergei Frolov has a fantastic collection of over 150 Soviet-made calculators, as well as vintage computers, watches and slide rules. I'm particularly fond of the old mechanical arithmometers, as shown above: Link\n8. Phil Miller's Sugar Packets\nPhil Miller is a sucrologist - meaning that he collects sugar packets and sugar cube wrappers. Indeed, Phil has been collecting since 1978 when he started with the Presidents of the United States sugar packets, and he hasn't looked back since. Life must be sweet if you collect sugar packets ... Link\n9. The Asphalt Museum\nThe Asphalt Museum is actually a real museum in a real building in Sacramento, California, but it's weird enough that we'll just have to include it on this list. It has a large collection of (you guessed it) everything asphalt.\nThe museum was founded by Scott Gordon and Marie Vans in 1991, while both attended Colorado State University.\nIn addition to asphalt \"samples\" from famous (like Route 66, Highway I, and the ancient Roman road Appian Way) and not-so-famous roads, the museum also has a recipe on how to make your own asphalt: Link\n10. Gideon Weiss' Back Scratchers\nGideon Weiss must've had one really itchy back when he started collecting back scratchers. His online collection has grown to include 236 of the strangest back scratchers I've ever seen: Link\n11. Michael Lewis' Moist Towelettes\nMichael Lewis welcomes visitors to his website with these warm words: \"Welcome to the exciting world of Moist Towelette Collecting.\"\nThough I'm not sure just how wet naps would rank in the excitement scale, Michael's collection sure is something: Link\nDon't miss the \"Awards\" section!\n12. Nancy Alford's Mangles\nWhat is a mangle? You'll be forgiven if you don't know what it is: a mangle is a cast iron contraption with two wooden rollers, a spring, and a side wheel with handle. Its function is to wring clothes dry after you wash them, so obviously it's now obsolete with the invention dryers and all ...\nA few years ago, Nancy Alford was in a local department store when she saw, and fell in love with, a mangle. For her sixteenth wedding anniversary, Nancy wanted (and got) - you guessed it, a mangle. Her husband thought she was mad.\nSince then, she has collected so many of them that they had to build a new house (which she aptly named Mangleten) to fit all her mangles. Link\n13. Victor Paul Taylor's Scratchcard Collection\nVictor Taylor is a lotologist (yes, a made up word meaning someone who collects lottery tickets). He has a particular interest in \"Instants\" Scratchcards, produced by Camelot for the UK National Lottery. As far as I can tell, none of the scratchcards have been scratched, so he's sitting on a potential goldmine worth bazillions!\nCheck out his incredibly detailed collection, which starts with the 1995 issues: Link\n14. Lydia's AOL CDs\nYounger Neatorama readers may not be familiar with AOL CDs, but the rest of us surely remember getting spammed with tons of these discs from America Online.\nIn the late 1990s and early 2000s, AOL produced over a billion CDs (with over 1,000 distinct designs) for its direct mail campaign. The strategy was a huge success: AOL became the largest dial-up Internet Service Provider in the world (for a while anyway). After its fateful merger with Time Warner and the decline of dial-up as a mean of accessing the web, the company stopped producing the discs in 2006.\nBut fear not. Lydia of Lydia's AOL Disks shares with us her collection of over 2,500 unique AOL diskettes and CDs. Check it out here: Link\n15. Museum of Burnt Food\nThe Museum of Burnt Food is dedicated to accidentally burnt food, er ... carbonized culinary masterpieces (no intentionally burned artwork there!). The museum was founded by harpist Deborah Henson Conant, who recounted this tale:\nThe museum was founded in the late 1980's one night when Deborah put on a small pot of Hot Apple Cider to heat, then received an unexpected . . . fascinating . . . and very long phone call. By the time Deborah returned to the kitchen, the Cider had become a \"Cinder\" and thus the first, and perhaps still the most impressive, exhibit: \"Free Standing Hot Apple Cider\" was born.\nSINCE THEN, countless other works have entered the museum, such as \"Thrice Baked Potato,\" \"Why Sure, You Can Bake Quiche in the Microwave,\" the indestructible \"Mmmm……Soy Pups,\" and the lovely matching set of Pizza Toast.\nDeborah has a tip on kitchen decorating, which I think everyone should heed: \"Never scrimp on fire extinguishers and smoke alarms.\" She would know now: Link\n16. Steve Salcedo's Street Sign and Traffic Light Collection\nFrom left to right: Auto Club of Southern California Stop Sign (c. 1940); Children \"Wanted Alive\" sign, the equivalent of \"Slow - Children at Play\" sign (c. 1950); \"T\" Intersection with Marble Reflector (c. 1940); Eagle 4-way 12\" Beacons (c. 1930)\nSteve Salcedo's fascination with street signs and traffic lights began when he received a bulletin board about traffic signs when he was just a small boy. Two years later, his collection was well under way.\nCurrently, Steve has over 350 street signs in his collection - all legal (rescued from street departments before they were scrapped, purchased from antique stores, flea markets, etc.): Link\n17. The Chocolate Wrappers Museum\nIn 1996, Martin Mihál's began collecting empty chocolate wrappers from around the world with a sizeable collection of 674 wrappers. A decade later, his collection grew to an astounding 38,579 wrappers! Martin has over 8,700 wrappers from Germany alone and even a few wrappers from far-flung countries like Oman and Uzbekistan.\nSo, the next time you eat a chocolate, think of Martin before you throw away the wrapper! Link\n18. Becky Martz's Banana Labels\nIn 1991, Becky Martz first noticed banana labels when she put two bunches of bananas in the fruit bowl together. She noticed that the \"Dole\" labels actually weren't quite the same: one said Guatemala and the other said Honduras. Later that year, she noticed a particularly festive Chiquita label and decided that she wanted to collect banana labels.\nToday, Becky has more than 7,000 different banana labels and even branched out to collect asparagus and broccoli bands.\nIf you think that this is a strange hobby, well, ... it is. But Becky isn't alone: there are others like her in the world, and they even have their own Banana Sticker Collector Convention. Check out Becky's collection here: Link\n19. Museum of Talking Boards\nThe Museum of Talking Boards is all about collecting Ouija boards. The site is quite neat: it explains the history of the board, theory as to how it works, as well as things you should never do or ask.\nAnd, of course, it has a fantastic gallery of over 80 antique talking boards.\nThe board above is the original Ouija board, created by Elijah Bond and Charles Kennard and produced in 1891 by Kennard Novelty Company.\nVisit the Museum of Talking Boards here: Link\n20. Scott Weed's Date Nails\nDate Nail is exactly that: a marked nail hammered into poles and bridge timbers to identify or date them.\nScott Weed of Nailhunter, who has a huge collection of these nails, wrote that \"unlike most collectibles, Date Nails can still be found in the wild. With a couple of tools, some spare time and transportation, the world of Date Nail is open to everyone.\"\nIndeed, but for now, I presume all of you will just satisfy yourself with visiting his website: Link\n21. Dr. Val Kolpakov's Toothpaste Collection\nDr. Val Kolpakov is a practicing dentist in Saginaw, Michigan, so it's only natural that he has an unnatural affinity to toothpaste.\nStarting in 2002, Dr. Val began collecting toothpaste from around the world. His website, Toothpaste World, categorizes toothpastes according to location, brand name, and year of production. Right now, he has over 1,400 items: Link\nI'd be remiss if I didn't share with you a toothpaste trivia from Dr. Val's website. Here's the world's oldest known formula for toothpaste:\nThe world's oldest-known formula for toothpaste, used more than 1,500 years before Colgate began marketing the first commercial brand in 1873, has been discovered on a piece of dusty papyrus in the basement of a Viennese museum.\nIn faded black ink made of soot and gum arabic mixed with water, an ancient Egyptian scribe has carefully described what he calls a \"powder for white and perfect teeth\".\nWhen mixed with saliva in the mouth, it forms a \"clean tooth paste\".\nAccording to the document, written in the fourth century AD, the ingredients needed for the perfect smile are one drachma of rock salt - a measure equal to one hundredth of an ounce - two drachmas of mint, one drachma of dried iris flower and 20 grains of pepper, all of them crushed and mixed together.\nThe result is a pungent paste which one Austrian dentist who tried it said made his gums bleed but was a \"big improvement\" on some toothpaste formulae used as recently as a century ago.\n22. Weird Fortune Cookie Collection\nEver got a strange fortune from a fortune cookie? Well, it belongs in the ever-growing collection at Weird Fortune Cookie Collection. Seriously, head on over there and browse their gallery (preferably after a nice little Kung Pao Chicken meal): Link\n23. British Lawnmower Museum\nBritish Anzani Lawnrider (c. 1960)\nThe tireless curators of the British Lawnmower Museum, Brian and Sue Radam, dedicate their lives to preserving the best example of British engineering prowess: the lawnmower!\nThe lawnmower was invented in 1827 by English engineer Edwin Beard Budding, who wanted a superior alternative to the scythe. He took a machine designed to cut the knap off cloth and used it to cut grass instead. At the time, people thought that he was mad, so he tested his invention in the middle of the night so no one could see him!\nThe British Lawnmower Museum's now has over 200 vintage lawnmowers and part of 400 others: Link\n24. Helena Vnouckova's Napkins\nNapkins: you use and throw them away, but Helena Vnouckova collects them. A lot of them - in fact, she has over 16,000 napkins from around the world (with sets of Christmas themed napkins, company napkins, and even airline napkins): Link\n25. Museum of Hoaxes\nI'm going to end this long list with Neatorama pal Alex Boese's excellent website: Museum of Hoaxes.\nAlex Boese probably has the strangest collection of them all: he collects stories about and examples of scams and hoaxes! In 1997, Alex created the Museum of Hoaxes as research notes for his doctoral dissertation, and the website quickly became popular. So much so that Alex the \"hoaxpert\" wrote three books which we have featured on Neatorama before: The Museum of Hoaxes, Hippo Eats Dwarf, and Elephants on Acid And Other Bizarre Experiments.\nIf you haven't seen it before (perhaps you've been living under a rock), then definitely check out the Museum of Hoaxes: Link - you won't be disappointed!\nI'll be the first to acknowledge that this is but a short list of unusual collections you can find on the Web. For more weird things people collect, check out MuseumStuff's Unusual Museums and Strange Collections, and Unusual Museums of the Internet at RingSurf.\nIf you or someone you know has an unusual collection we should list here, please let me know in the comment section!","|Publication number||US6116252 A|\n|Application number||US 09/344,844|\n|Publication date||Sep 12, 2000|\n|Filing date||Jun 28, 1999|\n|Priority date||Jul 2, 1998|\n|Publication number||09344844, 344844, US 6116252 A, US 6116252A, US-A-6116252, US6116252 A, US6116252A|\n|Inventors||John J. Stelmach|\n|Original Assignee||Stelmach; John J.|\n|Export Citation||BiBTeX, EndNote, RefMan|\n|Patent Citations (17), Referenced by (24), Classifications (8), Legal Events (5)|\n|External Links: USPTO, USPTO Assignment, Espacenet|\nThis Non-Provisional Application claims the benefit of U.S. Provisional Application Ser. No. 60/091,591 filed on Jul. 2, 1998. This invention relates to a disposable toothbrush which is mounted on the user's finger and then secured with a lanyard of dental floss to the user's wrist to provide a means for preventing accidental swallowing of the toothbrush while brushing and for flossing the teeth after brushing.\nIt is desirable to brush one's teeth after every meal. However, as many meals are not eaten at home, it is often necessary that people brush their teeth away from home. Accordingly, many people find themselves carrying a wet toothbrush in their purse or trying to fit a standard size toothbrush in a carrying case inside their pockets. This makes brushing one's teeth away from home inconvenient. Disposable tooth brushes, which must be inexpensive enough to encourage people to buy them and discard them after brushing, have been proposed to solve this problem. Various designs are known in the art, including disposable toothbrushes made to attach to a finger. These disposable toothbrushes enjoy an advantage over others because the absence of a handle makes the toothbrush more compact and easier for a person to carry, for a store to stock, or a vending machine to vend. For example, it is known to insert tooth cleaning bristles in the end portion of a paper, fabric, or elastic finger cot or sheath. U.S. Pat. Nos. 5,348,153 and 1,894,413 teach disposable toothbrushes of this type. A finger-mounted toothbrush affixed to the finger using a strip of adhesive tape is also known in the art. U.S. Pat. Nos. 2,921,590 and 2,915,767 teach inventions of this design. Also known in the art are tooth cleaning bristles mounted on bases attached to finger rings. See U.S. Pat. Nos. 3,105,260 and 3,720,975. Each of the these finger mounted toothbrushes suffer from a common problem. That is, they can slide off the finger, which may cause the user to choke, gag, or even swallow the toothbrush.\nThe toothbrush of the present invention overcomes the above-mentioned problem by providing a lanyard of dental floss, a first end of which is attached to the toothbrush and a second end of which is looped around the user's wrist, thus securing the toothbrush to the user's hand and thereby preventing swallowing of the toothbrush. The lanyard of dental floss creates the additional benefit of providing a convenient source of dental floss for the user of the present invention. Thus, the lanyard not only prevents swallowing, but also promotes dental hygiene.\nIt is an object of this invention to provide a compact, finger-manipulated toothbrush.\nIt is another object of this invention to provide an inexpensive toothbrush that can be disposed of after a single use.\nIt is another object of this invention to provide a disposable toothbrush with bristles optionally impregnated with a dental paste or powder.\nIt is another object of this invention to provide a disposable toothbrush with a lanyard of dental floss affixed thereto which is structured to be secured to the user's hand to prevent swallowing of the toothbrush, and which provides a convenient source of dental floss for flossing the user's teeth.\nOther objects of the invention will become apparent hereinafter.\nFor the purpose of illustrating the invention, there is shown in the drawings a form which is presently preferred; it being understood, however, that this invention is not limited to the precise arrangements and instrumentalities shown.\nFIG. 1 is a perspective view of the disposable toothbrush showing the mounting ring 1, bristle base 2, tooth cleaning bristles 4, passage 3 and the dental floss lanyard 5.\nFIG. 2 is a side elevational view of the disposable toothbrush of the present invention showing the toothbrush mounted on the user's index finger and secured to the user's wrist by means of the dental floss lanyard.\nFIG. 3 is a top view of the disposable toothbrush showing the adjustable mounting ring 1 and the dental floss lanyard 5.\nFIG. 4 is a side elevational view of an alternative embodiment of the present invention wherein the bristle base forms a continuous curve with the mounting ring. This Figure shows the mounting ring 1 extending across the entire width of bristle base 2; however, the mounting ring can be formed to any desired width.\nFIG. 5 shows an alternative embodiment of the present invention wherein the bristle base forms a continuous curve with the mounting ring. Bumps 7 molded on that portion of the bristle base and mounting ring with which the user's finger comes in contact facilitate the user's grip on the toothbrush.\nAs shown in FIG. 1, the toothbrush of the present invention comprises a mounting ring 1. The shape of mounting ring 1 and the material from which it is made enable mounting ring 1 to be fitted to a variety of finger sizes. At the uppermost point of mounting ring, a space of variable size is optionally left between the two halves of the mounting ring, allowing for even greater flexibility in the finger size that the mounting ring can accommodate.\nIn a preferred embodiment of the invention shown in FIGS. 1 and 3, mounting ring 1 and bristle base 2 are made of a polyethylene plastic material, but other materials will be known to persons skilled in the art.\nAs shown best in FIGS. 1 and 3, mounting ring 1 is affixed to the top surface of bristle base 2. Preferably, mounting ring 1 and bristle base 2 are molded as one piece so that the surface of mounting ring is continuous with the top surface of bristle base. In the preferred method of manufacture, the mounting ring 1 and bristle base 2 are molded as one piece of polyethylene or other plastic or rubber material. Bumps 7, shown in FIG. 1, can be molded with the mounting ring and bristle base. Bumps 7 function to enhance the user's grip on the toothbrush.\nTooth cleaning bristles 4 are fixed in the bottom surface of bristle base 2. In a preferred embodiment of the invention, tooth cleaning bristles 4 are made of a polyethylene plastic material. As a final step in the manufacture of the disposable toothbrush, the tooth cleaning bristles 4 are optionally impregnated with a dental paste or powder.\nAs shown in FIGS. 1, 2 and 3, a dental floss lanyard 5 is inserted through the passage 3. As shown in FIG. 2, the lanyard 5 is a loop of sufficient length to be fitted around the user's wrist 6 and used for flossing after brushing, but sufficiently short to secure the toothbrush to the user's hand and prevent the swallowing of the toothbrush. The diameter of the dental floss should be such as to provide sufficient strength for flossing. Waxed dental floss is preferred, but other types of dental floss can also be used with the present invention.\nFIGS. 4 and 5 show another embodiment of the disposable toothbrush of the present invention wherein bristle base 2A is concave to fit the contour of a user's finger. In this embodiment, the mold can then be fashioned so that mounting ring 1A extends outward and upward from either side of bristle base 2A. This embodiment of the invention has the advantage of producing a disposable toothbrush with a profile lower than a flat bristle base. FIG. 4 and FIG. 5 show the embodiment of the invention where the bristle base is curved. Additionally, bumps 7A, as shown in FIG. 5, can be added to the finger side of the bristle base, enhancing the user's grip on the toothbrush.\nTo use the invention, lanyard 5 is fitted around the user's wrist. The user's finger is then inserted in mounting ring 1. Dental powder or paste is either added or already present in the tooth cleaning bristles 4. After brushing, the dental floss lanyard 5 is used to floss the teeth. After brushing/flossing, the entire apparatus may be discarded.\n|Cited Patent||Filing date||Publication date||Applicant||Title|\n|US1157413 *||Jan 20, 1915||Oct 19, 1915||John Bertram Nesper||Tooth-cleaner.|\n|US1894413 *||Jun 23, 1931||Jan 17, 1933||Clifford Johnson John||Toothbrush|\n|US2915767 *||Apr 24, 1958||Dec 8, 1959||Vaughan Frank C||Disposable toothbrushes|\n|US2921590 *||Jun 7, 1956||Jan 19, 1960||Holton Howard F||Disposable and dispensable tooth brush|\n|US3105260 *||Jan 23, 1961||Oct 1, 1963||Allen Smith||One-piece disposable toothbrush|\n|US3720975 *||Feb 12, 1971||Mar 20, 1973||S Nelson||Toothbrushes|\n|US4292705 *||May 21, 1979||Oct 6, 1981||Stouffer James F||Tongue toothbrush|\n|US4617694 *||Sep 21, 1984||Oct 21, 1986||Team, Inc.||Finger-mounted device for cleaning teeth|\n|US5097852 *||Sep 9, 1991||Mar 24, 1992||Wu Tzung I||Dental sanitary appliance|\n|US5184719 *||Jun 30, 1992||Feb 9, 1993||Gordon Chester D||Tamper resistant, disposable toothbrush and flossing device|\n|US5213428 *||May 5, 1992||May 25, 1993||Elisabetta Molari||Biodegradable toothbrush|\n|US5287584 *||Jun 23, 1992||Feb 22, 1994||Practical Products Ltd.||Toothbrush|\n|US5348153 *||Oct 4, 1993||Sep 20, 1994||Cole William L||Disposable individual gelled instant toothbrush|\n|US5487201 *||Aug 13, 1993||Jan 30, 1996||Hansen; Bryan C.||Disposable tooth and gum cleaning device|\n|US5647385 *||Apr 7, 1995||Jul 15, 1997||Dynaproducts Inc.||Automated dental cleaner|\n|US5819765 *||Jun 14, 1994||Oct 13, 1998||Mittiga; Maria Ida||Finger glove comprising areas prepared for oral hygiene|\n|US5875513 *||Feb 27, 1995||Mar 2, 1999||Reinold; Josef||Finger-mounted toothbrush|\n|Citing Patent||Filing date||Publication date||Applicant||Title|\n|US6336242 *||Mar 15, 2000||Jan 8, 2002||Chun-Lin Tseng||Card type paper toothbrush|\n|US6874194 *||Jul 25, 2002||Apr 5, 2005||Gerome C. Harris||Safety fingertip toothbrush|\n|US6921409 *||May 10, 2001||Jul 26, 2005||James R. Richard||Tongue cleaning device|\n|US6941607 *||Jan 20, 2003||Sep 13, 2005||Michael E Berglass||Jewelry toothbrush|\n|US7014463 *||Jul 8, 2004||Mar 21, 2006||Dominic Savoia||Dental hygiene accessory|\n|US7595022||Jul 22, 2005||Sep 29, 2009||Twist Engine, Inc.||System for providing a chemical to a fluid|\n|US7713501||Sep 15, 2008||May 11, 2010||Twist Engine, Inc.||System for providing a chemical to a fluid|\n|US7815383||Feb 15, 2007||Oct 19, 2010||William Thomas Hall||Compact portable toothbrush|\n|US7895695 *||Apr 24, 2002||Mar 1, 2011||S K G Italia S.P.A.||Tooth-cleaning device|\n|US8398323 *||Aug 18, 2010||Mar 19, 2013||Paul Kotturan||Dental appliance|\n|US8662091 *||Oct 29, 2010||Mar 4, 2014||Amorepacific Corporation||Makeup utensil set for disabled individuals|\n|US20010041903 *||May 10, 2001||Nov 15, 2001||Richard James R.||Tongue cleaning device|\n|US20050032023 *||Jul 8, 2004||Feb 10, 2005||Dominic Savoia||Dental hygiene assessory|\n|US20050172435 *||Apr 24, 2002||Aug 11, 2005||Michele Bernini||Tooth-cleaning device|\n|US20050231686 *||Jun 26, 2003||Oct 20, 2005||Sis Ag, Surgical Instrument Systems||Device for detecting measurands in an eye|\n|US20070017878 *||Jul 22, 2005||Jan 25, 2007||Priegel Jack C||System for providing a chemical to a fluid|\n|US20090008339 *||Sep 15, 2008||Jan 8, 2009||Twist Engine, Inc.||System For Providing A Chemical To A Fluid|\n|US20090288262 *||Feb 15, 2007||Nov 26, 2009||William Thomas Hall||Compact Portable Toothbrush|\n|US20100306945 *||Jan 2, 2009||Dec 9, 2010||Thomas Methfessel||Device for cleaning the oral cavity|\n|US20110290274 *||Dec 1, 2011||Will Miles||Flossing Toys and Methods of Making and Using the Same|\n|US20120045733 *||Aug 18, 2010||Feb 23, 2012||Paul Kotturan||Dental Appliance|\n|US20120216824 *||Oct 29, 2010||Aug 30, 2012||Amorepacific Corporation||Makeup utensil set for disabled individuals|\n|USD738044||Apr 30, 2013||Sep 1, 2015||Larry Willis Miles, Jr.||Flossing device|\n|EP1234524A2 *||Feb 20, 2002||Aug 28, 2002||Eberhard E. Dr. Saetzler||Dental hygiene device|\n|U.S. Classification||132/309, 15/167.1|\n|International Classification||A46B15/00, A46B5/04|\n|Cooperative Classification||A46B5/04, A46B15/0071|\n|European Classification||A46B15/00C7A, A46B5/04|\n|Sep 29, 2003||FPAY||Fee payment|\nYear of fee payment: 4\n|Oct 17, 2007||FPAY||Fee payment|\nYear of fee payment: 8\n|Apr 23, 2012||REMI||Maintenance fee reminder mailed|\n|Sep 12, 2012||LAPS||Lapse for failure to pay maintenance fees|\n|Oct 30, 2012||FP||Expired due to failure to pay maintenance fee|\nEffective date: 20120912"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:d50d675c-1c69-4551-8c2b-7b1ddfe8a8f0>","<urn:uuid:43731898-e66c-4dd3-af7a-b324c9b9e012>"],"error":null}
{"question":"What's the key difference between evaluating predictions through probability estimates versus measuring actual user behavior outcomes?","answer":"The key difference is that probability estimates (like predicting a 79% chance of price increases) are essentially impossible to verify in real life since you cannot replicate the same forecasting situation many times. In contrast, measuring actual user behavior outcomes through metrics like bounce rates and conversion paths provides concrete, verifiable data about how users interact with a system. While probability estimates require simulations of multiple scenarios, behavior tracking shows what users actually did and what paths they took to convert, making it more practical for real-world performance evaluation.","context":["My article on whether we can trust airfare prediction models is published today at FiveThirtyEight, the new data journalism venture launched by Nate Silver after he moved to ESPN.\nThis topic was originally conceived as a chapter of Numbersense (link) but I dropped it. As I have noted in my review of Nate Silver's book, he has a keen interest in evaluating predictions, and not surprisingly, he encouraged me to get this piece done.\nPutting Big Data to the Test\nJust like Google Flu Trends (link), Oren Etzioni's Farecast has been held up as a Big Data success story. I have been a Farecast user for years, and though I use the tool, I've always wondered how accurate are those predictions. If you're a user, you've probably wondered as well. I have also complained that Big Data practitioners are too lax in offering quantitative evidence for their Big Data projects--it's a bit ironic when we tell others to use data and throw away their gut feelings.\nOne of the reasons for this oversight is that it is hard work to evaluate predictions properly. In this post, I will cover how I designed the evaluation strategy.\nThe first rule of evaluation is to check your ego at the door. The goal of evaluating a predictive model is to measure how well it performs. It is tempting for the evaluator to reinvent the wheel, devise a new way of predicting, and prove its superiority--but that is not evaluation. The evaluator is like a quality-control analyst, or a code reviewer.\nAssumptions, Assumptions, Assumptions\nOne of the core messages of Numbersense (link) is that every analysis has assumptions, often called \"theory\". People who think their analyses contain no assumptions are usually ones who haven't thought carefully about their models. Making \"no assumptions\" is itself an assumption. In the same way, evaluating models require assumptions, and lots of them! Bear this in mind as you keep reading.\nWhat to Compare to\nIn my article, I explained why the right comparable is the most realistic alternative strategy for purchasing air tickets if one were to not use Kayak/Farecast. This is one of my most important assumptions and it took me a while to figure this out.\nAt first glance, you might think a \"natural\" comparable would be the actual price trajectory for a given route for a given travel period. In other words, consider when the algorithm recommended buying and when it recommended waiting and judge it based on whether the algorithm led you to the lowest price during your search.\nUsing such a metric is to commit a form of hindsight bias. You have to remember that any algorithm (or human) must make the decision to buy or wait when the future prices are not known yet. In addition, we expect that there will be substantial price volatility in the future. If we were able to re-run history many times, the price paths would be different and the algorithm's performance would also vary. When we are staring at the realized price path (ex-post), it is easy to forget about the underlying volatility.\nA worse problem with judging the algorithm against the lowest possible prices is that there may be no way to get to that lowest price! Remember to check your ego, you are the evaluator, not the modeler. The question is are you able to find an existing alternative solution that would lead you to those lowest prices without cheating and using future price data?\nDon't Compare to Imaginary Toys\nInstead of the theoretical maximum (i.e. the model that always finds the best possible price), let's consider the existence of a Best Realizable Model (BRM). Let's suppose its performance will be 70% of the theoretical maximum. Then, in theory, we can compare Kayak/Farecast to this BRM.\nThe catch is we don't know anything about BRM. In particular, we don't know if it performs at 70% or 30% of the theoretical maximum. If Kayak/Farecast gets to 25% of ideal and BRM 70%, then Kayak/Farecast is pretty poor. But at the same 25%, if BRM performs at 30%, then Kayak/Farecast is impressive.\nNeither the theoretical maximum nor the Best Realizable Model should be used in this evaluation, simply because they are not real strategies, and just imaginary toys.\nDon't Bow to Random\nAt the other extreme, modelers like to compare their algorithms to the \"random\" strategy. In the case of airfare prediction, one such strategy might be picking a random number of days before departure and taking the lowest fare on that day. The random strategy is throwing a die, and using no skill at all. This is unsatisfactory because it creates too low a bar.\nCompare to Next Best Alternative\nIn my view, a far better approach is to figure out what you'd have done in the absence of the predictive model. In my case, I typically wait till two weeks before departure, and so that is the comparable.\nSome readers have commented that they tend to buy three or four weeks before departure, and one pointed to an analysis claiming that 54 days is exactly the right moment to get the cheapest fare. This takes us back to the point raised earlier, that every evaluation strategy makes assumptions. If we do an analysis starting 30 days out, a different reader will object, saying he or she typically purchases 21 days out. (Remember, though, the earlier you start this exercise, the longer you have to track day-by-day wait or buy recommendations.)\nAnother \"obvious\" (until you think about it) evaluation criterion is to focus on the probability estimates themselves, rather than the outcomes they produce. The probability estimates are given in the form \"there is 79% chance that the fare would go up by $20 or more in the next seven days.\" These forecasts are, of course, given for every route, for every departure date, and for every date of search.\nIt may take more than a moment's thought but such probability estimates are essentially impossible to verify. The forecast statement basically asserts that if the same forecasting situation arises many many times, they would be right about 79% of the time. But we can't in real life replicate the same forecasting situation many many times.\nOne way around this is to forget about real life, and check the probability estimates by simulating many future worlds. A major problem of this approach is that even if you can show that the probability estimates are good relative to those simulations, the travelers who use these forecasts still may not save money. Again, it lacks the \"what would you otherwise have done\" dimension.\nAs you dig deeper, you'll find more tricky issues. One is the continuous time (24/7) nature of online travel search. If you need to measure whether \"the fare went up $20 or more in the next seven days,\" you'd have to be monitoring fares continuously over those seven days. To make things even more complicated, in each of those seven days, for the same itinerary, Kayak/Farecast is updating its prediction in a rolling 7-day window.\nOne other consideration I'd like to cover. Nate Silver is famous for predicting all 50 states correctly. Remember though that anyone who has the slightest knowledge of US politics can predict 40 out of 50 states--where he demonstrated his skill was in those swing states.\nNow in the context of airfare prediction, if it were true that prices are much cheaper two or three months prior to departure, then people who would be purchasing in those time frames do not really need an algorithm to help them. It is important to test predictive models under situations in which they are most likely to demonstrate their skills. I would therefore recommend that you evaluate airfare predictions closer to the departure date when you'd need it most.\nAs you can see, evaluating predictive analytics is filled with challenges. But as I demonstrate here, it can be done. It should be done.","Having your website reach the performance levels you desire isn’t easy. It takes constant monitoring and measurement of visitor data to optimize web usage. This is where Web Analytics comes in. Not only is web analytics useful for measuring website traffic but it is also an effective tool for both business and market research.\nBy tracking user behavior, we can begin to see how they are interacting with our website and how we can begin to communicate more effectively to our audiences. In this article we’ll take a closer look at how Web Analytics can be utilized and what effect this has on the design process.\nWhat is Web Analytics?\nEvery time a visitor reaches your site, the web server records this transaction. This data is then processed by Web Analytics software to produce detailed reports and charts. This software is most commonly available in web-based applications such as the popular Google Analytics, which allows you to see what’s going on with your website through cold hard data.\nWeb Measurement is the process by which Web Analytics is utilized. While hits were popular in the early days of the internet, analytics have become much more sophisticated over the years. Basic metrics – such as visits, bounce rate, referrers, and conversions can be measured after determining the outcome you want your website to accomplish.\n2. Bounce Rates and Exit Rates\nBounce Rates and Exit Rates are two metrics to analyze in determining whether or not you’ve grabbed the attention of your users successfully. Exit rates will tell you how many people left the website through a particular page, while bounce rates tell you how many people left the website without visiting a second page.\nThe potential drawback to measuring user behavior using bounce rate is when your website is intended to find what they are looking for on the entry page, as opposed to sites with well-defined conversion steps requiring multiple page views. In the latter case, bounce rate is a good metric to use in indicating conversion success.\nWhere the visitor came from is a good metric in understanding why some visitors convert. A referrer is a website that sends you traffic. In addition to search engines, referrers send you traffic as well. Seek out those in your industry or network to build positive, meaningful relationships – whether it be through social network activity, blog conversations, or even writing articles in your niche. More conversions may end up coming from human referrals than search engines, as these individuals are likely in your industry and can see the need for your product or service moreso than the rest.\n4. Call to Action Clicks\nYour design should appeal and inspire your target audience to take action. Does the design make them feel like they are getting value from your services and, more importantly, are they clicking on the call to action buttons? Crazy Egg provides heat map reports to easily understand what users do on your site and where they are clicking. Heat Map reports let you see what’s hot and what’s not so you can make changes that increase conversion. Alternately, you can use A/B testing to help test different designs and determine which is the most effective.\nIf you’ve gotten this far, you know you’ve satisfied most of your visitors and gotten their attention. The crucial step now is to get them to convert. A conversion is a term used by marketers to describe the final outcome of a site visit. Don’t thwart your visitors from completed the intended action. This means optimizing your web forms for your users and making the form submission or checkout process as user-friendly as possible.\nThe metric for measuring conversions is Funnels and/or Paths taken. Kiss Metrics allows you to track funnels and paths to conversions. If you’re on a tight budget, Google Analytics’ goal and funnel-tracking can also be used\nMany useful tools are available to help you monitor user behavior. Here are a few of the most popular:\nGoogle Analytics is an enterprise class web analytics tool. It’ll give you insight into your website’s traffic and marketing effectiveness through user session metrics, including bounce rate and keyword frequency, amongst others.\nKISS Insights is a tool that allows designers to place a small survey bar across the bottom of their websites. Curious visitors can take a peek and are then presented with a simple survey in which they can evaluate the experience design of your website.\nCrazy Egg tells you where people are clicking on your site and which areas on a site page could use improvement. Crazy Eggs creates reports that allow you to visualize where people are clicking on site pages. This information is valuable for increasing conversions, for example, people purchasing your products and services or subscribing to your newsletter.\nWith Web 2.0 and Analytics, a culture of improvement has been laid before us. We can gauge more accurately how visitors are interacting with your content. With these tools, the ability to improve the experience your online customers have is at your fingertips. In some cases, you no longer have to guess or wonder why your site is getting the results it is. How is web analytics working for you?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:cb61bc43-c07e-4f66-bad0-955555113be8>","<urn:uuid:1f1b53c8-3d4b-4df1-87cf-4b66e3190916>"],"error":null}
{"question":"What are the data acquisition challenges in mass spectrometry, and how do TMT reagents help overcome sample comparison limitations?","answer":"Mass spectrometry data acquisition requires multiple analytical preprocessing steps to obtain abundance and mass pairs for each detectable molecule, with proper statistical methods needed for optimal preprocessing and analysis. TMT reagents address sample comparison limitations by using amine-reactive NHS-ester groups that efficiently label peptides from multiple samples (up to six) with identical chemical structures but unique mass reporters, enabling simultaneous analysis and quantification of proteins from different samples in a single mass spectrometry experiment.","context":["Mass spectrometry is a powerful tool with much promise in global proteomic studies. abundance pairs directly. For both FT- and TOF-based mass analyzers, a mass-calibration transformation is usually applied in order to ultimately obtain a set of and abundance pairs. The purpose of this article is usually to provide an overview of mass-spectrometry data, in particular how and abundance values are generated, and to spotlight areas that deserve attention from the statistical community after the and abundance pairs are generated. Although recent research has focused on improving mass-spectrometry technologies, insufficient attention has been given to proper statistical methods for optimally preprocessing and analyzing the acquired data. Thus, herein we aim to (1) provide an introduction to the resulting data and the multiple analytical actions that are required to obtain abundance and pairs for each detectable molecule and (2) discuss places where statistical methods can play an important role in improving the quality of inferences derived from the data. We begin in Section 2 with a description of bottomCup versus topCdown proteomics and explain why the proteomics community makes samples more complicated by digestion of a protein to multiple peptides, that is, smaller chains of amino acids. In Section 3, we discuss data acquisition and the analytical preprocessing that is required to obtain buy Valrubicin and abundance pairs from the data obtained from a mass analyzer. We have chosen to provide examples from the FT-based technology with which we are the most familiar; however, the general analytical preprocessing actions described herein apply to other mass analyzers. For a more thorough discussion of TOF-based technology, see the 2003 special edition on proteomics in domain name, the next step is data reduction via peak detection, which is discussed buy Valrubicin in Section 4. Section 5 introduces alignment, and Section 6 provides a discussion on how peptides and proteins are identified. Section 7 discusses important statistical considerations for experimental design buy Valrubicin and analysis. 2.?BOTTOMCUP VERSUS TOPCDOWN PROTEOMICS Proteomics in the broad sense implies the identification and quantification of proteins and peptides present in a tissue or cell at a single point in time or under a set of conditions. Top down (protein level) and bottom up (peptide level) are 2 techniques that have been broadly utilized for this task (Physique 1). In a topCdown approach, accurate mass and high-resolution mass spectrometers are required. When using a topCdown approach, the protein sample is fractionated prior to introduction into the mass spectrometer and one or more of the charge says of a single intact protein are isolated in the gas phase (Kelleher, 2004). In order to identify the corresponding protein, fragmentation of the intact protein is subsequently performed around CD244 the isolated ion by tandem MS (e.g. using electron capture dissociation or infrared multiphoton dissociation) in order to determine the amino acid sequence. Although some exceptions exist, this methodology only works well on abundant proteins and on proteins with molecular weights less than 30 kDa (Han focused solely on TOF data. Herein, we primarily focus on FT-ICR and FT-orbitrap technology, which has the advantage of extremely high resolving power, mass-measurement accuracy, precision, and wide dynamic range. buy Valrubicin 3.1. Obtaining frequency and abundance pairs An FT-ICR steps the rotational frequency of ions as they orbit in the magnetic field of a superconducting magnet. Ions are introduced into an ICR cell and are subsequently excited. Ions of comparable orbit together as a packet and induce an electrical current that is detected by.","Amine-reactive Thermo Scientific TMT* Isobaric Mass\nTagging Kits and Reagents enable quantitative tandem\nlabeling of proteins extracted from cells and\ntissues for identification and analysis by mass\nEach isobaric Tandem Mass Tag* Reagent is composed of an amine-reactive NHS-ester group, a spacer arm and an MS/MS reporter. The reagents label peptides prepared from cell-based or tissue samples, and make a structure M-F-N-(R)-peptide, either two samples for the duplex kit or six samples for the sixplex kit. For each sample, a unique reporter mass results in the MS/MS spectrum, providing a simple means of identification.\nChanges in protein expression and post-translational modifications are essential mechanisms of biological regulation and disease. Advancements in mass spectrometry (MS) instrumentation, bioinformatics and quantification methods, such as label-free quantification, metabolic labeling and chemical tagging, now enable researchers to identify and quantitatively analyze thousands of proteins in a given sample with a high degree of accuracy.\nIsobaric chemical tags are tools that enable concurrent identification and quantitation of proteins in different samples using tandem mass spectrometry. This procedure is somewhat like the iTRAQ quantitative proteomics analysis. They are small chemical molecules with identical structure that covalently attach to the free amino termini of lysine residues of peptides and proteins, thereby labeling various peptides in a given sample\nFigure1. Structure of a Tandem Mass Tag\nEach member has a unique mass and reports\nsample-specific abundance of a labeled peptide\nduring MS/MS analysis.\nCleavable linker: Preferentially fragments under\ntypical MS/MS conditions to release the mass\nMass normalizer: Each member has a unique mass that\nbalances the mass reporter, ensuring the same\noverall mass for all tags in a set.\nReactive group: Reactive NHS ester provides\nhigh-efficiency aminespecific labeling of\nTandem Mass Tags\nconsist of TMT0 (zero), the TMT2 two-plex set and\nthe TMT6 six-plex set\nThe TMT0 tag allows testing and optimization of\nsample preparation, labeling, fractionation and MS\nfragmentation for peptide identification and\nreporter detection without using the more costly\nisotope-labeled compounds. The TMT2 reagent set\nallows two-plex protein profiling for small studies.\nThe TMT6 reagent set allows six-plex protein\nprofiling for multiple conditions, including time\ncourses, dose responses, replicates or multiple\nsample comparisons. Each TMT tag is based on the\nsame chemical structure, eliminating the need to\nmodify labeling conditions or HPLC separation\nconditions between experiments.\nFigure2. The TMT family of isobaric tag reagents\nTMT0 has no isotopic substitutions and is\nused for method development.\nA pair of isobaric mass labels with a single\nisotopic substitution per tag is used for simple\npairwise comparisons of relative protein expression.\nA six-plex of isobaric mass labels each with five\nisotopic substitutions per tag is used. Used for\ncomplex analyses including multi-plex patient\nscreening, time-course analysis or dose escalation\nDuring the MS/MS\nanalysis, each isobaric tag produces a unique\nreporter ion signature that makes quantitation\npossible. In the first MS analysis, the labeled\npeptides are indistinguishable from each other;\nhowever, in the tandem MS mode during which peptides\nare isolated and fragmented, each tag generates a\nunique reporter ion. Protein quantitation is then\naccomplished by comparing the intensities of the six\nreporter ions in the MS/MS spectra.\nFigure3. Procedure summary for MS experiments with TMT Isobaric Mass Tagging Reagents\nAs many as six\ndifferent samples can be mass-labeled and analyzed\nin a single mass spectrometry experiment.\nsummary for TMT Reagent experiments for mass\nabundance of the target protein or peptide fragment\nin six different samples is easily measured by\ncomparing the signature mass peaks generated by the\ndifferent mass tags.\nFigure5. Protein Profiling with TMT Tags\ntandem mass tagging enables protein\nidentification and quantitation from multiple\nsamples of cells, tissues or biological fluids\nconsistent chemistry allows efficient\ntransition from method development to multiplex\nquantitation, enabling biomarker discovery\namine-reactive NHS-ester activated reagents ensure efficient labeling of membrane and post-translationally modified proteins\nexpandable system allows concurrent\nmultiplexing of up to six different samples in a\noptimized fragmentation and fully supported\nquantitation with Proteome Discoverer* 1.0 for all\nThermo Scientific LC MS/MS platforms, such as LTQ\nXL* and LTQ Orbitrap* XL Systems\nProtein identification and quantitation from\nmultiple samples of cells, tissue or biological\nProtein expression profiling of normal vs.\ndisease states or control vs. treated\nMultiplex up to six different samples\nconcurrently in a single experiment\nQuantitative analysis of proteins for which no\nantibodies are available\nIdentification and quantitation of membrane and\npost-translationally modified proteins\nIdentification and quantification of hundreds to\nthousands of proteins in a single experiment\net al. (2003).\nTandem mass tags: a novel quantification strategy\nfor comparative analysis of complex protein mixtures\nby MS/MS. Anal. Chem.75 (8), 1895-1904.\net al. (2008). Relative\nquantification of proteins in human\ncerebrospinal fluids by MS/MS using 6-plex\nisobaric tags. Anal. Chem. 80(8), 2921\nNilsson, C.L. et al. (2010). Quantitative\nphosphoproteomic analysis of the\nSTAT3/IL-6/HIF1alpha signaling network: an\ninitial study in GSC11 glioblastoma stem cells.\nJ. Proteome Res. 9:430-43."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:717a890d-ff43-4cb6-ae3f-ca17d86907e3>","<urn:uuid:04ae6799-6a15-4a9a-bfdc-e0441caaa80d>"],"error":null}
{"question":"Latest active time comparison: nocturnal raccoons vs rutting deer?","answer":"According to the documents, raccoons are mainly active during the night, only becoming inactive when temperatures drop below freezing. In contrast, during the rutting period (particularly during the seeking and chasing phases in October-November), deer are active throughout both day and night, with bucks actively searching for and chasing does, making up to 6-12 scrapes per hour at peak activity.","context":["Home | What's New? | Find a Rehabilitator | OWREN Courses | OWREN Conferences | Wildlife Rehabilitation | Wildlife Help Pages | About OWREN | Publications | Wildlife Health News | Contact Us | Shop OWREN Online | Links\nThere is virtually\nnowhere that raccoons won’t be able to adapt to living.\nFun to watch (from a distance)\nespecially with their youngsters in tow, their intelligence and\ncuriosity gets them into conflicts with human beings more often than\nThey are omnivores and will\neat plant matter and animals.\nNatural foods for them will\ndepend on the area they live in. Where available, grubs, fruits,\nberries, insects, small rodents, amphibians, turtles, crayfish, birds,\neggs, and vegetables are all edible to a raccoon.\nIn urban areas and cities,\nfood sources are dumpsters, composters, and trash bags.\nThey will find water in\npools, ornamental ponds and leaky outside faucets.\nThey breed from Jan-May,\ngenerally have litters of 3-5 on average but can have up to 8 kits.\nGestation takes 56-60 days and\nmom runs a solo show once they are born. Only the female provides care\nfor the kits.\nShe begins to wean them at 6\nweeks of age, and by 6-8 weeks they are mobile and following her on\nFemales are among the most\ndedicated and protective to their kits of most mammal species. She does\nnot tolerate being separated from her kits very well and prefers to keep\nthem together under her watchful eyes.\nSome raccoons will give birth\nlater in the season if they were too young when the first mating season\nrolled around, or if they have lost their kits through disease or\nThese late born raccoons are\ngenerally born from June – August and will have a harder time surviving\ntheir first winter with mom.\nThey are mainly active during\nthe night, and remain active year round. Not true hibernators however,\nthey do enter a state of torpor when temperatures dip below freezing and\nwill den in communal dens together to keep warm. These are the only\ntimes raccoons are inactive.\nThe life span of raccoons in\nthe wild is estimated at three to five years especially in urban areas.\nThey have amazing ability to\nuse their paws and amazing dexterity at opening things, turning\ndoorknobs, prying things open, taking nuts off of bolts and gaining\naccess to buildings or food sources and they can dig.\nRaccoons also have an amazing\nIn urban areas they will den\nin hollow trees, ground dens, chimneys (resemble the inside of a hollow\ntree) in unused sheds, attics, under stairs and decks, open garages,\nunder porches, in brush piles. They easily adapt.\nThey are normally very\nsolitary animals, but can be territorial with ‘their space’.\nYoung kits may or may not\nremain with their mother for their first winter. Males tend to wander\noff in the fall, females may remain with the mother until she has\nanother litter the following spring.\nIn urban areas they have a\nsmaller home range and those ranges usually overlap with other\nraccoons. They are less territorial and more tolerant in built up areas\nof other raccoons than they would be in country areas with bigger\nThey are also very vocal and\nhave a range of over 50 different communication sounds that they make.\nBabies purr, and the ‘3 Stooges, whoop-whoop-whoop’ sound sometimes\nheard, is a locator call from a kit to its mother and siblings.\nKeeping Safe Around Raccoons\nRaccoons will not attack unless\nthey are cornered.\nShould you get between a\nmother and her kits, she will respond by being aggressive to get you to\nback away. It’s best to allow her to make a safe escape from you.\nAlways give her an ‘out’ to get away and she will do that.\nBecause they live in such\nclose proximity to humans, city raccoons have lost some of their fear of\nhumans as predators.\nBeing so entertaining has also\ncreated a problem with human beings who purposely feed wild raccoons.\nThese individuals unknowingly condition these animals to think of humans\nas a source of food. Please - don’t feed wildlife!\nRaccoons are often victims of\ncanine distemper, a virus they acquire from unvaccinated dogs. This\nvirus cause them to lose their fear of humans, to appear confused,\ndisoriented and to walk sometimes in broad daylight, totally\nuncoordinated, swaggering, dragging their back ends along behind them\nand will sometimes sit and have a ‘thousand yard stare’ on their\nfaces. Because the virus attacks their brain, in the end stages it may\ncause aggression and is very difficult to differentiate from rabies -\neven for professionals with years of experience.\nIn the early stages canine\ndistemper may manifest as a very bad upper respiratory infection, with\ncopious amounts of mucous being discharged from their eyes and noses.\nIt is contagious to other raccoons and to unvaccinated dogs. Should you\nsee a raccoon with these symptoms, call your local animal control\nofficer or humane society for assistance. Another good reason why it is\nimportant for your domestic pets to be properly cared for and to receive\ngood veterinary care and routine vaccinations!!\nRabies in Raccoons\nSince the initial entry of\nraccoon strain rabies in the province along the New York border in\nEastern Ontario (2000), the Ministry of Natural Resources has done an\neffective job in keeping rabies out of the provinces' raccoon\npopulation. In Ontario, the MNR has maintained air drop baits, hand\ndropped baits, and through Trap, Vaccinate, Release (TVR) programs along\nthe border areas, helps to maintain a healthy population of vaccinated\nIn short these efforts have\nprevented wildlife rabies from grabbing an uncontrolled foothold in the\nprovince. These efforts can be disrupted if individuals engage in\ntrapping and releasing wildlife outside the area they originated in.\nThe ministry advises that the removal of raccoons from one area will\nopen up territory for unvaccinated raccoons to move in and potentially\nIf you are bitten by any\nanimal, wash the wound with copious amounts of soap and water, contact a\ndoctor, and report the bite to your local Public Health Department (see\nlistings in your telephone directory). If possible, have someone keep\nthe animal in sight so that it can be captured or confined.\nFor more up to date and\naccurate information about rabies visit the Ontario Ministry of Natural\nResources Rabies Research and Development Unit website.\n(Note: As the MNR url's change frequently, search\nGoogle for 'MNR, Rabies, Ontario' for the current url.)\nGot grubs on the lawn?\nSprinkle your lawn with soap flakes and water it thoroughly.\nTry mixing some bone meal in\nwith your garden soil to keep them out.\nSome folks use diluted Tabasco\nsauce sprinkled over their fruits and vegetables to discourage wildlife\nfrom eating them.\nLight up the area. Raccoons\ndo not like being in the limelight. They prefer to forage in the dark.\nMylar strips that blow in the\nbreeze can be used to deter them as can garden ‘gazing’ balls that show\nOthers have utilized motion\ndetection lights and motion detection water sprayers to discourage\nraccoons in their yards.\nKeep your home secure and\nrepair any damaged areas that allow access to the inside areas (see\ngeneral wildlife proofing)\nHave a contest to outwit the\nraccoons from opening your secured garbage containers. No doubt they\naren’t dexterous and intelligent but you can devise methods to prevent\nthem from accessing your containers.\nTry to deter them by spraying\nor sprinkling your outside trash storage area with strong smelling\nodours: ammonia or oil of mustard.\nEnsure you’re dealing with a\nraccoon. Use flour or cornstarch and sprinkle the area and look for the\ntell-tale paw prints.\nIf you can see the entrance,\nstuff a huge ball of newspaper or rags into the opening. If this is\npushed in or out, you know there’s someone living there.\nVery often you can hear them\nin attics. Hearing a loud fight that sounds positively spine chilling\nis generally an indication that there’s an adult there, most likely a\nmother with kits, whose space is being invaded by another adult.\nThe sound of chirping birds,\nwhich progressively grows louder and more persistent is the sound of\nbaby raccoons who are likely orphaned. One thing mother raccoons do\nwell is keep their kits quiet.\nThree key things must\nbe put in place simultaneously to evict them humanely. This effort must be\nkept up for 3-4 days to achieve success.\nUse a work light or flashlight\nto illuminate the area or den.\nIf you use electrical lighting\nplease ensure that your placement of the bulb will not start a fire.\nReplace the flashlight\nbatteries if they dim down\nPlace rags in empty margarine\ncontainers, dampen them with ammonia and place the covers back on them\nand punch holes in them for the odour to escape.\nPlace those at the entrance to\nthe den and around the den and in the den if you can toss them in there.\nBefore tossing ammonia\ncontainers in, make sure that the babies, if there are any, can move\naway from the container. These are strong odours and if a young baby\ncannot escape from it, they may die, so be judicious in where you place\nthem. Also keep in mind that very strong odours may also affect you, in\nyour living space, so use your judgement in how much to apply.\nUse just enough to annoy the\nanimals, not you.\nIf they have nested in your\nchimney or fireplace, DO NOT LIGHT A FIRE to smoke them out. It is\ninhumane to do this and you will either burn them or cause their death\nthrough smoke inhalation.\nIf you have a mother with\nbabies in your home, remember that these methods will convince her to\nmove out and take the babies, however it may take her more than one day\nto do this. Please have patience and allow her to get them all out.\nOnce you 'discover' her - she will want to get out of there more than\nyou want her to get out of there, so give it time.\nIt is generally best to not\nattempt to evict a mother who has kits under three weeks of age. If you\ncan wait patiently until they are at least that old, you will have a\nWhen you are certain they are\nout (check by leaving a dusting of flour in the area, checking for\nfootprints) then discourage them from moving back in by placing ammonia\nor bleach, or naphtha flakes in the den space, before you secure it up\nto prevent re-entry.\nAnytime you are dealing with\nraccoon feces, ensure you are wearing gloves and if possible or in areas\nof heavy accumulation, wear a facemask also.\nWear old clothing that you\nwill then dispose of. Scoop it up using a dustpan (you’ll throw that\nout also) and something like a piece of cardboard or a wooden board to\nDouble and even triple bag any\nfeces you shovel up and seal the bags tightly.\nThese need to either be burned\nor disposed of in a landfill.\nOnce the bulk of the debris is\nremoved, treat the entire area with boiling water and if possible,\nRinse and repeat with a second\napplication of boiling water only.\nIf you are dealing with\nattics, and soiled insulation, remove the soiled areas, check carefully\n(or have someone check for you such as an electrician) for any possible\ndamage to wiring) and replace the soiled insulation.\nRemoval By Trapping\nWhen live trapping appears to be the\nonly way to remove a problematic raccoon, please keep the following in mind:\nContact a reputable and reliable,\nexperienced professional nuisance wildlife removal company when the animal\nmust be removed from between walls or from crawl spaces or when the home\nowner is unable to remedy the problems.\nNuisance wildlife removal companies are not\nlicensed and may only have a license from the MNR as trappers. That’s\nrequired for them to remove the animal from your property. Their ethics or\nmethods of dealing with that problem are not under any regulations at all\nand this is where they differ.\nVery few of these companies offer humane\nContact your local authorized wildlife custodian\nor wildlife centre and ask them for a recommendation.\nContact the local Ministry of Natural Resources\nfor further assistance.\nWhatever it is that is attracting raccoons to\nyour property, is what needs to be eliminated. Without that being remedied,\nthere will never be a long term solution for wildlife conflicts.\nTrapping done by inexperienced homeowners, the\n‘guy next door’ with a trap and so on, won’t solve the problem. It seems\nlike an instant solution but it isn’t. Those who fail to check if the\nraccoon being removed is a lactating female, and if she may have babies in\nthe area will deliberately leave those babies behind to starve to death and\ndie. Imagine the smell of a litter of decaying bodies in your attic a month\nlater! You will be forced to deal with a second and more unpleasant\nTrapping by a reputable, humane company that will\nalso repair the entrance point to prevent re-entry is the only choice if all\nIt is illegal to use weapons within city limits\nto shoot animals, and it is illegal to use body gripping traps. Using\npoison can result in criminal charges and fines up to $5,000. None of those\nare viable options for a nuisance wild animal.\nwith the Fish and Wildlife Conservation Act, if you live-capture a nuisance\nanimal, and do not humanely kill it, you must, within 24 hours,\neither release it in close proximity to where you caught it (within 1 km of\npoint of capture for all adult wildlife) as directed by the Ministry of\nNatural resources, or, if it is sick, injured or immature, turn it over to\nan authorized wildlife custodian.\n[Up] [Wildlife Proofing] [Coyotes] [Foxes] [Raccoons] [Skunks] [Squirrels]","Volumes have been written about the whitetail deer rut. In an effort to simplify a rather complex subject, it can be broken down into seven basic stages. Understand what motivates deer during each of these, and your chances of closing a tag go way up! Photo Credit: Kevin Wilson\nCelebrated and studied ad infinitum, the whitetail deer’s annual cycle is constantly under appraisal. While we traditionally think of the rut as a November phenomenon – or later with some southern subspecies – the earliest stage actually begins as soon as bucks lose their velvet. Throughout the next four months deer advance through seven clearly identifiable phases. Adapt your hunt strategies for each, and success will follow.\nThe shedding of antlers and impending regrowth is an annual occurrence. Velvet antlers are highly vascular and grow rapidly to reach full potential by the end of August, which aligns with the earliest hunting seasons. Lasting less than a week, this change from velvet to hard antler marks the true beginning and earliest stage of the prolonged pre-rut. As soon as the velvet disappears, bucks begin making boundary scrapes and rubs throughout their home range. Even though the transition itself is brief, this pre-rut behavior continues through September and October until bucks step up their search for receptive does.\nIn agricultural areas, the year’s first scrapes begin to show up along field edges and tree lines. Likewise, a few rubs will be evident in similar areas. These are more territorial markers, but as things heat up from mid-October on, rubs and scrapes become focal communication tools.\nAs soon as their velvet disappears, bucks begin making boundary scrapes and rubs throughout their home range. Photo Credit: Kevin Wilson\nBy more contemporary description, the pre-rut heats up and younger bucks in particular start to move more near the end of October as both bucks and does visit and urinate in scrapes. Scrapes are almost always made under some type of overhanging branches. These are referred to as licking branches because bucks lick and rub their orbital glands on them to deposit scent. Urine and glandular secretions contain pheromones that indicate breeding readiness. Other deer visiting these sites detect the hormonally charged scents to identify which deer was there, and whether they were bucks or does.\nThe seeking phase is best described as the general two- to three-week period just before the majority of does go into estrus. Ask most hunters to define this phase, and they’ll probably say it’s the time when young bucks become eager to breed and begin moving more during daylight hours in search of receptive does. What many hunters don’t know is the pre-rut is actually a much longer, drawn-out occurrence – a time when bucks begin to move throughout their home range, mark territory, and inventory does.\nBy late October, the photo phase’s shorter days prompt bucks to prepare for breeding; they know that does will soon be receptive. This broadly defined seeking phase occurs approximately between Oct. 24 and Nov. 9. Survival of each species depends on the rut cycles, and it’s as guaranteed as the rising and setting of the sun. For bow hunters or in jurisdictions where gun hunting seasons allow, this is a great time to be in the deer woods. During the seeking phase, bucks eagerly respond to doe bleats, buck grunts, and rattling. The best strategy a stand or blind hunter can employ during this phase is setting up along a heavily used scrape line, or in a known funnel or transition zone.\nIf you believe in moon phase influences on deer behavior, the late Charles Alsheimer is perhaps the best-known authority. According to Alsheimer, the seeking phase peaks three to four days before and after the rutting moon, which he defines as “the second full moon after the autumnal equinox.” Through his research, he has identified that bucks will make as many as six to 12 scrapes per hour at the height of the seeking phase. In other words, bucks are on the move and your chances of encountering the highly secretive whitetail during this phase increase exponentially.\nGiven Alsheimer’s scientific explanations, the timing of the seeking phase and advancement into the chasing phase of the rut can vary by a few days. In general terms the seeking phase begins as early as the third or fourth week in October and transitions sometime around the second week in November. In slight contrast, my own research over the last 30 years suggests that moon phase plays a less significant role and that undisturbed does in any given area will, without exception, go into heat within a consistent 24- to 72-hour timeframe each and every year. Much like people, their estrus cycle can, of course, be manipulated slightly by imposing manmade influences like hunting pressure.\nAccording to famed whitetail authority Charles Alsheimer, bucks will make as many as six to 12 scrapes per hour at the height of the seeking phase. Photo Credit: Kevin Wilson\nSometimes difficult to differentiate, this pre-breeding period occurs immediately after the seeking phase and just prior to actual breeding. In layman’s terms, it’s when does are almost in estrus and bucks know it. During the chasing phase, bucks feverishly scour the woods, pursue and, quite literally, chase does around checking them for breeding readiness. Their purpose is to find and service a hot doe. Being in the woods at this time is magical. During the seeking and chasing phase and where healthy buck-to-doe ratios exist, rattling, grunting, and using doe bleat calls can be extremely effective in attracting curious, testosterone-driven bucks into close range. One of your best strategies involves locating and setting up over a primary scrape. These primary scrapes are often double or even triple the size of boundary scrapes and are visited regularly – usually daily – by both bucks and does in the area. Focus your efforts on a primary scrape from about Oct. 25 on, and your chances of encountering deer go way up.\nIn very general terms, the chasing phase typically occurs throughout the midwestern, central and eastern U.S, and across Canada through the second week in November. I usually anticipate the chasing phase to occur between Nov. 11 and 14. Bucks and does use scrapes as a primary communication tool and continue servicing them with increased frequency during this time. At this point, a select number of primary scrapes will be visited most frequently. Locate one of these primary scrapes and you'll greatly increase your odds of an encounter.\nLocating and servicing primary scrapes is key during the chasing phase. Photo Credit: Kevin Wilson\nThe breeding phase, or estrus period, is viewed as the peak of the rut. This is when buck movement breaks wide open. It’s when does go into estrus and are receptive to the breeding advances of eager bucks. Throughout western Canada, this peak whitetail estrus intensifies between Nov. 11 and 16. I know, for instance, that in many of the areas I hunt, this is invariably between Nov. 12 and 14.\nThe biggest challenge for hunters during the breeding phase is that when a buck locates a hot doe, he will usually stay close until that doe is bred. In fact, mature bucks especially will quite literally lock them down. In other words, they’ll shadow the hot doe and hold them in a secluded location. As breeding commences, with each day the lockdown phase becomes more pronounced. During this three- to five-day stretch it appears that bucks have all but vanished, and visible movement comes to an abrupt halt.\nEvery year, I witness this distinct period play out obviously between Nov. 17 and 23. The name of the game at this time is focusing on early-morning and late-evening transitional movement between bedding and feeding areas. Patience is a virtue for the stand hunter as bucks without does will still be on the move looking for does that have not yet been bred. Likewise, this period can present one of the best times to take a mature trophy whitetail as big bucks drop their guard and make breeding and traveling in search of does in estrus their top priority. Throwing caution to the wind, their sole purpose is breeding.\nRubs and scrapes become focal communication tools for whitetails from about mid-October on. Both bucks and does will visit scrapes with increased frequency leading up to and during the rut. Photo Credit: Kevin Wilson\nIf you don’t tag out by the end of the first round of breeding, don’t panic. A buck’s breeding instinct motivates him to continue his search for hot does throughout November and even into the early part of December. Approximately fourteen days after the first estrus, does that didn’t get bred will go into estrus a second time. I’ve witnessed this during many deer seasons, and it’s very obvious as long as you’re on top of the deer. The primary difference is that visible buck movement decreases as they localize travel to within proximity of the does that still need to be bred. Where I hunted last fall, the second whitetail estrus was most notable between Nov. 25 and 30. The second estrus can be a tricky time to hunt but if you move in tight to where does are feeding and bedding, you’ll no doubt increase your odds of getting a shot opportunity.\nThen, finally, the post-estrus stage brings an abrupt end to it all. With breeding accomplished, does almost seem to go into hiding. Bucks can be seen meandering here and there trying to locate any late does, but overall breeding is wrapped up, and within days both bucks and does transition into their winter survival patterns. The weather turns colder, there’s typically snow on the ground, and deer readily shift back into their bedding and feeding patterns, traveling only short distances to minimize energy expenditure. Where seasons allow, the best strategies for hunting the post-rut involve locating the best food source near prime thermal bedding cover. Hunt the food source and success will follow.\nPOST A COMMENT!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:c30332fa-a8d1-4d7c-9641-d22757e0c4ee>","<urn:uuid:eab0afc5-78e8-40e8-a47d-b3063bdc9e63>"],"error":null}
{"question":"How do natural and artificial lawns compare in terms of ground preparation and soil requirements?","answer":"Natural lawns rely on proper soil conditions and require regular maintenance of the existing ground, while artificial grass installation demands extensive ground preparation. For artificial grass, you must dig out the area to 100mm depth, add a MOT type 1 sub-base material (70-75mm), then add 20mm of sharp sand, and finally install a weed membrane. This layered foundation system is essential for proper drainage and stability. In contrast, natural grass grows directly in the soil, but its health depends on avoiding soil compaction and maintaining proper moisture levels for the specific grass type, with different requirements based on climate conditions and grass species.","context":["How to lay artificial grass\nLaying artificial grass is a simple way to brighten up your garden all year round. Simply clear your garden area, roll out the grass and tidy up the edges. Here’s how to lay artificial grass in a few short steps:\n- Clear the area where you’re laying artificial grass\n- Dig the area out to 100mm depth\n- Prepare the base material and protective layer against weeds\n- Roll out the artificial grass\n- Cut and tidy the edges\n- Join the rolls together\nWHY USE ARTIFICIAL GRASS?\nThe biggest benefit to laying artificial grass is that it will save you huge amounts of time and effort maintaining your lawn. It doesn’t need trimming, mowing, watering or fertiliser for starters. As it’s weatherproof, it’ll stay looking bright and green all year round, and will last years too.\nReplacing old and worn patio slabs or a natural lawn with the gorgeous greens of artificial grass is quick way to inject some class and character into your outdoor space.\nTOOLS AND MATERIALS FOR LAYING ARTIFICIAL GRASS\nHere’s a list of the tools you’ll need for installing a new grassy surface in the garden:\n- Turf cutter\n- Tape measure\n- Plank for compacting\n- Craft or Stanley knife\n- Always Green Jointing Tape (if a joint is required)\n- Ground pins\n- Hammer for compacting and pinning\n- Brush / broom\n- Granular sub-base material – MOT type 1 material\n- Geotextile membrane\n- Sharp sand or granite dust\n- Silica sand (kiln dried sand)\n- Tanalised timber and Pan Head screws (for timber restraint)\n- Always Green Aqua Bond (for concrete haunch restraint)\n- Weed membrane\nYou might also want to consider a pair of knee pads as the majority of work will be done on the ground.\nWhether you’re laying artificial grass on paving slabs, or rolling out in place of a natural lawn, the steps are much the same. Just ensure that the surface has been adequately prepared. No need to completely smooth out the surface – the odd lumps and bumps make it look more natural.\nLAYING ARTIFICIAL GRASS – STEP BY STEP\n- Clearing the area\nIf you’re laying artificial grass to replace natural grass, start by digging out the turf down to about 100mm using a spade or a turf cutter. This is to ensure that the finished product doesn’t stand unnaturally tall over surrounding paved areas, once the base layers are secure. If you’re edging the area, use a tantalised timber frame and secure with timber batons or use a concrete edging block/restraint with an internal concrete haunch of approximately 100mm.\n- Preparing the base\nA sub-base (graded to MOT Type 1) underneath the turf promotes proper drainage and provides a solid foundation to lay the artificial grass on top of – and make sure you remember the geotextile membrane underneath to prevent the sub-base sinking into the soil below. Cover the area with a sub-base and compact in two layers to a depth of 70-75mm using a compactor plate.\n- Levelling off\nSpread a layer of sharp sand to about 20mm depth using a shovel or sand spreader. Smooth out the sand evenly across the sub-base and press it down using a compactor or hammer and plank. Check the depths and add or remove sand as needed. Your lawn may appear more natural if you want to retain the odd dip or bump in the lawn, but the surface should be level overall.\n- Weeding out\nRoll out sheets of weed membrane over the sub-base as a bedding layer. This will prevent weeds from growing and reaching through the surface of the fake grass, which will help it to drain more efficiently. There should be some overlap between sheets of weed membrane – about 30cm.\n- Roll out the lawn\nRoll our your artificial grass making sure the pile is facing towards you or the main viewpoint allowing 5cm of extra grass on all sides. Try to avoid lining up the ends of the rolls exactly, as it will give a less natural appearance.\n- Cutting and tidying\nOnce the grass is unrolled, take a craft knife and trim the rough edges away from the grass rolls. Make sure the grass rolls are placed neatly together so nothing shows up from underneath. We’d recommend cutting through the latex backing cloth and not the grass itself, running the knife next to the stitch lines but avoiding cutting into the stitching wherever possible.\n- Glue together\nRemove 2-5 rows of stiches from both adjoining rolls of grass using a Stanley knife. Fold the edges back and lay Always Green jointing tape, ensuring its shiny side is laid face down. Apply Always Green Aqua Bond using a cartridge gun onto the jointing take in a zig zag pattern – and making sure each roll of grass has at least 5cm of adhesive in contact with the tape. Hold the grass back and press down on the tape to spread the adhesive. Try to keep the blades of grass from getting onto the glue. Sweep the edges of the joins to hide them from plain view.\n- Pinning it down\nIf you’re using a timber frame, secure the grass to it with Pan Head screws every 150-200mm, or you can glue the grass to the horizontal concrete haunch of the edging block. If not, use a hammer to bash in the ground pins 20-30cm apart around the edges. Brush these edges to disguise the appearance of the pins in the ground.\n- Sweeping success\nOnce the glue is dried, sweep off the surface with a broom to cast off loose blades of grass and dust or dirt. Infill the grass using silica sand and either a power or a stuff brush, ensuring your brushstrokes direct into the pile. Sand should be evenly distributed ensuing no excess appears on the surface of the turf. Don’t forget to leave it to settle and cure for 1-2 hours – more if it’s cold outside – before walking on it.\nFREQUENTLY ASKED QUESTIONS\nCAN I LAY WEED MEMBRANE BEFORE THE SAND?\nWhen it comes to the order of layering, some installations are done with steps 3 and 4 reversed – the sand is laid on top of the weed membrane, rather than the other way around. Either way should provide the same results.\nCAN YOU CUT ARTIFICIAL GRASS?\nA trim here and there may be in order to adapt it to your desired length to begin with. Cut it with fabric scissors if possible – and avoid using big clippers or lawnmowers.\nHOW LONG DOES ARTIFICIAL GRASS LAST?\nGood quality artificial grass should keep its green and luscious appearance for around 20-25 years, depending on how well you take care of it. Regular brushing of the surface will keep it looking glossy and healthy, while pets’ presents on the lawn should be hosed off to prevent bad smells and possible discolouration.\nIf you’re looking for further inspiration, why not check out our new artificial grass selection to find the products and tools that are right for you. If you’re in need of professional help for your next garden project, check out the UK database of Marshalls-approved garden and driveway installers.","The height at which you cut your grass is one of the most important factors when it comes to the overall health and appearance of your lawn.\nIn general, the best height to cut grass is around 2 to 4 inches tall. With that said, many factors should be considered when determining the best height to cut the grass on your lawn, including the climate you live in and your specific species of grass.\nThis article will outline how to determine the best height to cut your grass in different situations so that you can maintain a healthy lawn all year long.\nIdeal Length for Most Grass Types\nGenerally speaking, two to four inches is the best length for grass. You need to keep it short enough to allow water into the roots, but also long enough that it can shade the soil from too much sun. The two exceptions to this rule are Bermuda and Zoysia grasses; you can cut these grass types to one to two inches.\nDangers of Cutting Grass Too Short\nThere are two main concerns to consider about cutting your lawn too short: soil compaction and sun damage.\nCutting the grass too short can lead to compaction in the soil. This can cause runoff and affect how much water reaches your lawn’s roots, and will necessitate an aeration job to loosen the compacted dirt. The lack of protection from the sun also means that weed seeds have a greater chance of sprouting in your lawn.\nAlthough some people think you should cut your grass almost down to the dirt, this is a misguided notion. This only serves to cause damage to your grass and increase the potential for those nasty weeds.\nInstead, allow your grass to grow to the ideal length before you begin mowing, which will allow it to shade itself from the sun. It’s particularly important to let your grass grow as long as possible before mowing new grass for the first time.\nIf any weeds do sprout in your lawn, simply pull them out by hand, use a weed trimmer, or employ a post-emergent herbicide.\nBest Height for Different Climate Conditions\nIn climates with strong winds and little rain, two inches is often the best height to cut grass. This allows the grass to develop a strong root system that can better withstand wind damage while also protecting it from too much sun exposure.\nHowever, if you don’t water your lawn regularly due to drought water restrictions, then increase the height of your blade by one inch to allow more time for the moisture to reach the roots before evaporating off of the leaf blade.\nIn rainy climates, many people water their lawns unnecessarily. Doing this can cause soil compaction and lead to other issues. If your area receives a lot of rainfall, then simply allow the grass blades to curl over to protect the soil from getting washed away. There’s no need to have a perfectly manicured lawn during rainy weather, so leave it alone until conditions improve.\nYour Type of Grass Matters\nThe type of grass you have plays a role in determining how long your grass should grow. Refer to our grass identification guide for more thorough guidance on figuring out what type of grass you have on your lawn.\nKentucky bluegrass grows best when cut at three to four inches, while Bermuda grass only needs to get mowed at one inch. This is because bluegrass has larger leaves that are better suited for warmer climates. Bluegrass also grows most actively during the spring, which is when it needs to get cut more often.\nBermuda grass, on the other hand, has smaller leaves that grow in bunches. It thrives better in shady areas and can handle colder weather conditions. This means you should only need to mow once a week during the summer months.\nPerennial Ryegrass is another type of grass you can cut to three to four inches. It’s dormant in the winter and actively grows during the spring and fall seasons.\nSt. Augustine & Turf Type Fall Fescue\nCut St. Augustine and Turf Type Tall Fescue to four inches or more. They are both heat-loving grasses that need to get cut often during the summer.\nThree inches is a quality length for centipede grass. It thrives in warmer climates and needs to get cut often.\nKeep Buffalo grass cut down between two to four inches. This allows it to better handle the hot, dry conditions present in many parts of North America.\nWhen cutting Zoysia grass, remember that it’s a shade-loving species whose blades grow outward from the crown. Your best bet is to keep this type of grass at one inch.\nMowing Often is Beneficial to Your Lawn\nDon’t let too much time go by between each mowing session. Especially during the hottest summer months, you should mow every five days at least. When you do, the grass will stand up straighter and look healthier. The mower blades should break off any thatch buildup that may have accumulated over time.\nMow when the grass is dry so it can get evenly cut to size. If you’re dealing with a weed infestation, then don’t try to kill all of them at once. Pull the more visible ones by hand, then mow over any that remain, which will act as a deterrent against future weed growth.\nIf you can’t reach certain portions of your lawn with your usual mower blades, then consider getting another type of blade to cut those areas shorter. For example, invest in a detachable grass-cutting blade shaped like a scythe if you have trouble with spots of tall grass. Don’t be afraid to experiment with different heights. However, always do so based on your type of grass and the time of year.\nThe best time to mow your lawn is during mid-morning hours before temperatures get too high. Your lawn will spend the rest of the day converting fallen grass blades into healthy soil. Have you recently done some heavy lawn fertilization? If so, then you might need to mow more often for a while as the fertilizer does its thing.\nHow to Change a Mower’s Height\nEvery mower is a bit different. Check the manual to see how to raise or lower your mower’s blades, which are also known as the height-of-cut system. Typically, all you do is raise or lower the cutting bar so it sits at the desired height.\nAfter you do this, check to see if any other components need any adjustments before you start mowing. For example, some mowers have bumpers that touch the ground to help create a straight line of cut grass. If these no longer align properly, then make some adjustments to ensure your yard doesn’t end up looking lopsided.\nYou should also make sure your lawn mower blades are sufficiently sharp each time you mow – we have provided step-by-step guidance on this process in our article How to Sharpen Lawn Mower Blades. Change out your old blades for a new pair every season. If you have an older machine with all its parts still in good condition, then changing the blade will give it a new lease on life.\nHow to Measure the Height of Your Lawn’s Grass\nThe best method involves a simple ruler or measuring tape. Put on a glove and walk across your entire lawn from corner to corner, checking the height of the grass as you go.\nWrite down these measurements on a sheet of paper and keep this record for future reference. This becomes helpful if you ever need to adjust your mower’s blades or head out with a weed whacker to kill any overgrowth.\nLawn Mowing Tips\nNow that you know which height to cut your grass to, have the lawnmower height set properly, and are working with a sharp blade, use the following tips when mowing.\nMake sure you’re mowing in the right direction. If this means overlapping any previous lines of cut grass, then so be it. Just make sure to follow these general guidelines:\nWhen cutting Bermuda grass, for example, aim for a clockwise path that starts from the right side of the lawn. Mow in a counterclockwise fashion when cutting Zoysia grass, which begins on your left side. When mowing Bermuda grass for the third time in one season, change grain direction by 90 degrees to avoid putting stress on its roots.\nDon’t forget to use common sense. Is your mowing pattern giving you the desired look? If so, then you’re doing it correctly.\nShould You Leave Grass Clippings on the Lawn?\nIn the majority of cases, you should leave the clippings where they lay. They will decompose quickly and help fertilize your lawn as they do so. Lawn clippings also act as a no-effort organic fertilizer and mulch to protect the surface of the soil in your lawn.\nYou may have to remove clippings in the following situations:\n- You’re dealing with an insect infestation that left mounds of dry grass behind.\n- You are mowing too frequently, which could lead to overfertilization and fertilizer burn.\n- You’re mowing wet grass, which can make for an uneven cut.\nFor most people, however, leaving the clippings on the lawn is the best choice. If you choose to bag your clippings, see our article What to Do with Grass Clippings for a number of different ways they can be repurposed around your yard and home.\nHow Long Does it Take Grass Clippings to Decompose?\nIt depends on the type of grass, climate, weather conditions, and other factors. It can take anywhere from three to four weeks for clippings to decompose into the soil.\nAre Grass Clippings Organic?\nYes, grass clippings are organic. They will decompose into the soil just like any other organic matter you find in your yard.\nChoose Right for Your Grass Type\nThe ideal length for most grass types is between 3–4 inches. Cutting your lawn too short can damage or kill the roots of the blades, which leaves you with a more difficult time getting rid of weeds and pests. Set your mower to the desired height for your grass type, and enjoy your healthy lawn.\nSee our article How to Stripe a Lawn for guidance on how to turn your plain grass into a manicured, aesthetically pleasing lawn."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:9cc2197b-b733-421b-9099-87f59b475e00>","<urn:uuid:5ce29dc8-a372-4bb7-8edd-d3979142ac6f>"],"error":null}
{"question":"What are the key signs that indicate a bowler is using the wrong ball weight?","answer":"The main signs are: if the ball is dictating where the bowler's body is going, it's too heavy, causing the bowler to push the ball away with poor posture and chase the ball. If the bowler is dictating where the ball is going, the ball may be too light. Ideally, there should be a good balance between the ball swinging the bowler and the bowler swinging the ball for consistent target hitting.","context":["POUND FOR POUND: Preferences In Bowling Ball Weight Are Shifting…Again\nBy Bryan O’Keefe\nBecause it is not an exact science, ball weight has long been an interesting topic of discussion in bowling. And as bowling balls have changed over the years, so has the perception of weight preferences. Before the proliferation of reactive balls, most bowlers simply used the heaviest ball they could throw. The heavier the ball the more hitting power and driving power, and the more pin action. The lighter the ball, the more concern bowlers had about deflection.\nIt shouldn’t come as a surprise then that in the ’80s and ’90s, bowling ball companies were said to be producing three 16-pound balls for every one 15-pound ball. That all changed in the past decade with technical advances in bowling ball construction. Balls today are so powerful that the need to maximize ball weight for carry isn’t as critical. The combination of ball speed, ball weight and your ability to get the ball into its roll before it hits the pins is what maximizes your carry percentage.\nThe general shift down to 15-pound balls over the past 10 years had almost reversed the production levels of 15 and 16-pound balls. And it makes sense. Using a ball that’s one pound lighter eases a significant amount of strain on a bowler’s body over the course of a 30-week league session, a tournament or, in the case of the pro bowlers, a tour season. The slight drop in weight also allows the bowler to throw the ball harder, and that extra speed coupled with the advanced driving capabilities of today’s balls more than outweighs the benefits of throwing a heavier ball at a slower speed.\nRecently there has been some movement with elite bowlers moving back to 16-pound balls. There are several reasons this could be happening. For some bowlers a heavier ball will actually smooth out their swing. The added weight helps them keep the swing flatter on the downswing and at the release point. Some bowlers who go down in weight discover their swing gets a little steeper, or perhaps affects their timing. Going back to a heavier ball will slow things down. Additionally, bowlers will go down in weight as a way of protecting hand or wrist problems. Today, however, pro shops know so much more about properly fitting the ball to your hand that nagging wrist and hand injuries are fewer and farther between.\nWhat does all this mean for you? Generally speaking, these are simply factors to consider when going up or down in ball weight. Every bowler is different, but weight determination is based mostly on strength and pain.\nOf course, there are several ways to determine whether you should consider a change. Clearly, whatever weight you are currently using is what you’re most comfortable with and accustomed to. That doesn’t necessarily mean it is the ideal weight for you.\nA coach or teammate watching you throw should easily be able to determine if the bowler is dictating where the ball is going, or if the ball is dictating where the bowler is going. If the bowler is dictating where the ball is going, the ball may be too light. Conversely, if the ball is too heavy, it will dictate where the bowler’s body is going. If you’re not really strong enough to maintain a smooth, even swing you will tend to push the ball away. Your posture will also be out of whack, and your body will look like it is chasing the ball.\nIdeally, you want to have a good mix between the ball swinging you and you swinging the ball. You don’t want the ball taking your body into a different direction, but you don’t want to be manhandling the ball either. Either extreme will make it more difficult to hit your target with any consistency. The ball should swing naturally.\n— Bryan O’Keefe is Team USA Assistant Coach and Facility Manager at the International Training and Research Center.\nPermission granted by USBC/Luby Publishing"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:22559220-0df0-4347-963d-8e668092fe17>"],"error":null}