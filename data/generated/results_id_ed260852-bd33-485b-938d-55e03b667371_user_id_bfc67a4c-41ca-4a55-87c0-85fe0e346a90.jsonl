{"question":"I'm curious about treatments! What's the main difference between how regular anemia and beta thalassemia are treated nowdays?","answer":"Regular anemia and beta thalassemia have different treatment approaches. Regular anemia is typically treated with supplements of iron, vitamin B12, folic acid, or other vitamins and minerals, and sometimes with erythropoietin to stimulate bone marrow production. In contrast, beta thalassemia requires more intensive treatment consisting primarily of blood transfusions to correct anemia, combined with chelation agents to remove excess iron from the body. While these treatments can prevent premature death in beta thalassemia patients, they don't modify the underlying disease process and can have significant toxicity.","context":["Development of Minihepcidins for the Treatment of Beta Thalassemia\nBeta thalassemia is a rare, inherited blood disorder that causes severe anemia and damage to organs. The only current treatment is blood transfusions, and patients often must have many of these procedures. Repeated transfusions can cause too much iron to build up in the body. Patients with beta thalassemia also have reduced levels of a hormone called hepcidin, which helps the body use iron properly. A buildup of iron from transfusions combined with low levels of hepcidin can cause \"iron overload,\" which can damage the heart, liver and other tissues. The goal of this project is to produce a treatment that increases levels of hepcidin and lowers the damaging effects of iron in patients with beta thalassemia.\nPatients with beta thalassemia suffer from anemia, which is often severe, and iron overload, which causes damage to the heart, liver and endocrine tissues. Current treatment of beta thalassemia consists of blood transfusions to correct the anemia and chelation agents to remove iron from the body. Although this therapeutic approach can prevent premature death in childhood or early adulthood, it does not modify the underlying disease process. These treatments do not provide consistent, long-term benefits for patients and can confer significant toxicity.\nBeta thalassemia causes defects in red blood cell production by bone marrow as well as reduced red blood cell survival time. These factors contribute to the development of anemia and lead to reductions in the iron regulatory hormone hepcidin. Low hepcidin levels allow too much iron to be absorbed from the diet, resulting in severe iron overload. Excess iron in the developing red blood cells contributes to the failure of cell production. These events create a vicious cycle in which too much iron contributes to low red blood cell production, which in turn increases the amount of iron that can cause cellular damage.\nIncreasing the amount of hepcidin activity in the body is one approach to breaking the cycle of excess iron and red blood cell destruction in beta thalassemia. Increasing hepcidin can restrict the flow of iron to the developing red blood cell, reducing cell damage and death and improving the production of these cells. The increased hepcidin levels also can restrict the amount of iron absorbed from the diet and prevent the development of iron overload.\nThe investigator is developing minihepcidins, which are novel peptides that possess the biological activities of hepcidin and can be used to increase hepcidin activity. Studies in animal models of beta thalassemia have found that treatment with a minihepcidin can reduce red blood cell damage and rapidly decrease severity of anemia. If similar effects are seen in patients, minihepcidins could become a new type of disease-modifying agent for the treatment of beta thalassemia.\nMerganser Biotech LLC, Newtown Square, Pennsylvania\nBrian MacDonald, Ph.D.\nPublic Health Impact\nA disease-modifying therapy such as minihepcidin could transform the treatment of beta thalassemia by reducing or eliminating the need for transfusions and chelation therapy. It may also provide consistent, long-term improvements in the quality of life of these patients as a result of reducing the level of anemia.\nApproved studies are ongoing.\n- Formulation development\n- Pharmacokinetic/absorption, distribution, metabolism, and excretion (PK/ADME) studies\n- Investigational New Drug (IND)-directed toxicology","DefinitionAnemia is a condition in which the body does not have enough healthy red blood cells. Red blood cells provide oxygen to body tissues.Other types of anemia include:Anemia due to B12 deficiencyAnemia due to folate deficiencyAnemia due to iron deficiencyAnemia of chronic diseaseHemolytic anemiaIdiopathic aplastic anemiaMegaloblastic anemiaPernicious anemia\nSickle cell anemiaThalassemia\nCauses, incidence, and risk factorsAlthough many parts of the body help make red blood cells, most of the work is done in the bone marrow. Bone marrow is the soft tissue in the center of bones that helps form blood cells.Healthy red blood cells last between 90 and 120 days. Parts of your body then remove old blood cells. A hormone called erythropoietin made in your kidneys signals your bone marrow to make more red blood cells.Hemoglobin is the oxygen-carrying protein inside red blood cells. It gives red blood cells their red color. People with anemia do not have enough hemoglobin.The body needs certain vitamins, minerals, and nutrients to make enough red blood cells. Iron, vitamin B12, and folic acid are three of the most important ones. The body may not have enough of these nutrients because:Changes in the lining of the stomach or intestines affect how well nutrients are absorbed (for example, celiac disease)Poor dietSlow blood loss (for example, from heavy menstrual periods or stomach ulcers)Surgery that removes part of the stomach or intestines Possible causes of anemia include:Certain medicationsDestruction of red blood cells earlier than normal (which may be caused by immune system problems)Long-term (chronic) diseases such as chronic kidney disease, cancer, ulcerative colitis, or rheumatoid arthritisSome forms of anemia, such as thalassemia or sickle cell anemia, which can be inherited\nPregnancyProblems with bone marrow such as lymphoma, leukemia, multiple myeloma, or aplastic anemia\nSymptomsYou may have no symptoms if the anemia is mild. If the problem develops slowly, symptoms that may occur first include:Feeling grumpyFeeling weak or tired more often than usual, or with exerciseHeadachesProblems concentrating or thinkingIf the anemia gets worse, symptoms may include:Blue color to the whites of the eyesBrittle nailsLight-headedness when you stand upPale skin colorShortness of breathSore tongue\nSome types of anemia may have other symptoms.\nSigns and testsThe doctor will perform a physical examination, and may find:Heart murmurLow blood pressure, especially when you stand upPale skinRapid heart rateSome types of anemia may cause other findings on a physical exam.Blood tests used to diagnose some common types of anemia may include:Blood levels of iron, vitamin B12, folic acid, and other vitamins and mineralsRed blood count and hemoglobin levelReticulocyte countOther tests may be done to find medical problems that can cause anemia.\nTreatmentTreatment should be directed at the cause of the anemia, and may include:Blood transfusionsCorticosteroids or other medicines that suppress the immune systemErythropoietin, a medicine that helps your bone marrow make more blood cellsSupplements of iron, vitamin B12, folic acid, or other vitamins and minerals\nComplicationsSevere anemia can cause low oxygen levels in vital organs such as the heart, and can lead to a heart attack.\nCalling your health care providerCall your health care provider if you have any symptoms of anemia, or any unusual bleeding.\nReferencesBunn HF. Approach to the anemias. In: Goldman L, Schafer AI, eds. Cecil Medicine. 24th ed. Philadelphia, Pa: Saunders Elsevier; 2011:chap 161."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:663ab549-2bdc-4d3b-bc24-a8d8ae95f033>","<urn:uuid:10df68be-8e7d-47c7-92f6-9a945355d1cd>"],"error":null}
{"question":"How has Japan's household composition changed in recent years, and what's the trend for single-person households?","answer":"Single-person households have significantly increased, now accounting for one-third of all households in Japan. Traditional multi-generational family homes have sharply declined. Additionally, households with only couples, and single-parent households are rising, though the total number of households and people per household are expected to decrease gradually.","context":["When considering the problem of housing in the future, it is essential to know the current state of declining birth rates and the surging aging population. How is the Japanese population actually keeping up with the transition?\nThe total population peaked at 120.806 million in 2010 and has been gradually declining. Although the overall number is decreasing, the wider age group is composed of people of 75 years old or older, while the working-age population (15 ~ 64 years old) is decreasing (from the Ministry of Internal Affairs and Communications “Census”).\nWhen you look at the graph of the “population pyramid”, where the vertical axis is the age, there are two relevant bulges. One is the layer of “baby boom generation” born in 1947-1949, and the other is the layer of baby boom juniors who are their children. When considering the transition of the population, the generation of the baby boomers who supported the post-war period became the elderly group at a later age and in 2025, all the layers indicating baby boom juniors will reach their 50’s, significantly impacting the social structure.\nMoreover, speaking of the relationship between population and housing, single-person households, households with only couples, and single-parent and child households are on the rise, but the number of people per household and the number of households themselves are expected to decrease gradually. There is however a slight difference between the metropolitan area and the region (the difference between the city and the region is mentioned in the book “The 50 conditions necessary for future apartments”).\nThe increase in single-person households, accounting for a third of the total, has also been pointed out in recent tax surveys. The families of large families with many generations living together, which were often seen before, have fallen sharply, and it can be said that the shape of Japanese families is also changing.\nIf the structure of the family changes, the homes that are required will consequently change as well. In retrospect, aiming for expansion and growth was one of the virtues in the postwar high economic landscape.\nThe young generation aims at a high income and stable life, moving to a city with the goal of attending “a good university” and joining a “good company” in mind, and live in their own home without returning to their parents’ residence. Parents who are left behind will remain as a household of a couple, as it is difficult for them to leave a home that they are attached to, although a lot of people also choose to become single-person households by not wanting to become a burden to their children. However, in reality, a senior citizen might not be able to manage a large house that once was lived by a family and they might not even not what to do with it.\nThe sense of values has changed, and the form of residence has also changed\nIn the past, “building your house independently” or “living up in the hills of the suburbs” were considered one of the achievements in life. Of course, it is still one of the housing options, but since the bubble era and the subsequent Lehman shock, diversification of values has progressed, and everyone is less likely to pursue the same goal.\nIt would be unrealistic to have your own home without hesitation if, in the midst of a downturn in the economy, you are affected by the downsizing or are in a state of temporary employment. In addition, the marriage age of both men and women has increased, a declining birthrate has progressed, and the rate of unmarried life has also risen.\nIf the perception of values changes, so does the housing. The tendency of living close to work has become higher, more people are emphasizing convenience and think “I want to live in a place with transportation” rather than having a large house in the suburbs. It is no longer an age where people share the same ideals and dreams.\nIt is also said that young people who did not know the bubble era, do not crave a life beyond their reach. If you live in an urban area, you can live without having a car, and it is known that we tend to prioritize what is “real” over the appearances and aspirations, for instance, choosing a share house for your rent.\nThis way, as the social structure and people’s thoughts are changing, the housing prospect is changing, and as a result, “vacant house” has also become a problem that is increasing throughout Japan.\nA growing number of vacant houses and apartments in decay\nEven though the number of households is increasing in statistics, Japan’s population is steadily decreasing. On the other hand, you may often see single-family homes and condominiums being built where there still is available space. If new construction continues in addition to the existing housing market, it is natural for the number of vacant houses to increase. These unoccupied housing issues began to draw much attention in the 2014 Survey on Housing and Land Statistics.\nThis survey is released every 5 years from the Ministry of Internal Affairs and Communications, but the number of vacant houses calculated based on the 2013 data has reached 8.2 million units. Since the number of units is 60,630,000 when there are about 52.45 million homes in Japan, the number of units per households is calculated to be about 1.16, and the rate of vacant homes is 13.5% (Figure 2 below).\nEven if you look at the transition of vacant houses in recent years, it has been rising steadily, and it is estimated that the day when the number will exceed 10 million units will be close. The problem of vacant houses involves various factors that can not be solved only through statistics.\nAfter the war, Japan started from a state of housing shortage of 4.2 million units, and the government actively supported the construction of housing as a national policy. With the aim of “one house per one household” and “one person, one room”, the construction of houses was actively promoted and in a 1973 survey, the quantitative shortage had been resolved at the national level.\nSince then, there have been issues concerning land prices dropping after the bursting of the bubble, but at the same time, construction of new housing has continued and the problem of vacant houses has become serious.\nIn brief, there is also a separate kind of vacant house. According to a survey by the Ministry of Internal Affairs and Communications, the term is divided into those that are temporarily vacant for “rental and for sale”, “secondary houses” such as villas, and “others” that are instead vacant for a long time. Although rental properties have a period of time in which they become vacant houses / vacant units (vacant rooms) by nature, the number for the “others” category has been increasing in recent years, accounting for 38.8% of the total.\nThe reason why empty houses are not good is that, if you lose the resident, they will soon start to age in various places, making the roof or damaged walls easy to collapse. In case of a fire, there is the danger that it will spread in an instant.\nThere are many old buildings that do not meet the current earthquake resistance standards, including RC apartment buildings or those that have not even been subjected to seismic reinforcement work, and if there is a major earthquake, there will be no resistance at all. Other than that, there are other aspects such as suspicious people entering a vacant property and making it a breeding ground for crime, deteriorating hygiene and landscape damage.\nThe reason the problems of the vacant house and vacant units are not solved\nIn the case of rental apartments, there are also problems unique to shared housing. Residents who place importance on living conditions and can afford to pay a certain amount of rent usually have a reasonable social status. These apartments are constantly maintained, and the apartments themselves are maintained beautifully and do not become slums.\nHowever, if the landlord does not refuse a potential tenant who wants to “secure the rent because it is cheap” based on the fact that he prioritizes paying the loan back, the property cannot be maintained adequately in terms of both economics, safety, and morals, resulting in a degrading apartment. From there this leads to a vicious circle of stagnation.\nAs additional reasons for the increasing number of vacant houses in one-person households, there is a chance that the owner who lived alone passed away or moved to a nursing home, etc. and even if you want to demolish the house, it may take several million yen just for dismantling costs, and you may not be able to find the funds to.\nFurthermore, you may think that it is better to leave the house unoccupied because of tax issues. In small residential land, in fact, property tax will be reduced to 1/6 if there is a building on the land, but this benefit will not be applied if it is empty land.\nAlso, you may not be able to build a new building in an empty lot. For instance, according to the current Building Standard Law, constructions cannot take place unless the area is facing public roads with a certain width and other specifications. Therefore, if you do not meet the conditions, the choice will probably tend towards not demolishing at all.\nMany of the issues related to these unoccupied houses have so far occurred in local governments where population decline is significant. Today, however, population decline is beginning to take place in the suburbs of the metropolitan area, where this should not have been so remarkable. Even if there is a demand for housing in the metropolitan area, there may be more vacant homes due to the tendency to move toward the central part and troubles of succession, etc., therefore, this does not mean that it should be better to just leave it as it is.\nIn order to cope with this problem, the government enacted the Act on Special Measures against Unoccupied Homes in November 2014, and in addition to the guidance and recommendations to promote appropriate management of “Specified Unoccupied Homes”, promote the use of the ruins, enabling also administrative commissions. If you do not follow the advice, the local government may be forced to demolish the property and charge the owner for the dismantling costs.\nFurthermore, the problem of the vacant houses often includes the concern of arranging the items left by the deceased and the problem of garbage. A variety of initiatives are currently underway, such as NPOs that provide management and advice in these regards, as well as vacant house banks.\nThe circumstances leading to an unoccupied house and its status also vary. It may be necessary to change your mindset to use it as a type of stock housing – a property sold for sale in an existing building, that is, a used property. The complication of vacant houses is the result of various issues that Japan has today.\nFrom original Japanese article by Kumazawa Shigeki and Yasui Hideo."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:8bfd4a3f-2a47-465a-85d6-a76d5528e030>"],"error":null}
{"question":"What was the evolution of medieval castle architecture, and how did it reflect both military and symbolic purposes?","answer":"Medieval castle architecture evolved from simple motte and bailey castles to more sophisticated stone keep and concentric castles. Early motte and bailey castles were wooden structures built quickly for immediate control, but had weaknesses like rotting and fire vulnerability. They were replaced by stone keep castles, like the White Tower in London, which were more durable and could house larger garrisons. Finally, massive concentric castles were built, exemplified by Edward I's Welsh fortifications. Beyond their military function, castles also served symbolic purposes. This is evident in cases like Pendragon Castle, where architectural archaism was deliberately used to symbolize continuation of power and ancestral prestige, showing how castles embodied both martial and status aspects.","context":["Heidi Richards, doctoral research at Durham University, looks at Pendragon Castle and how medieval romance literature impacted later medieval castle building.\nSince childhood, I’ve been fascinated by castle ruins, stories of King Arthur, and a golden age of chivalry that existed somewhere back in time between history and fantasy. Fast-forward twenty years, and I’m currently finishing my doctoral thesis looking at the impacts medieval romance literature had on late medieval English castles.\nFormer arguments in castle studies subjected castles into a martial vs. status dichotomy, but current research embraces the duality of these aspects of the castle, providing space to explore possible symbolisms built into castle architecture and wider landscapes.\nMy research explores the importance of romance literature and legend within medieval society’s most elite, and through wills, commissions, dedications, and gifts, we find that romances were highly valued. Of primary importance though, was Geoffrey of Monmouth’s (c.1138) Historia Regum Britanniae (History of the Kings of Britain). While not technically a romance, this work brought legendary heroes into an ancestral pseudo-history of the kings of Britain (including Constantine and King Arthur) and provided source material for romance narratives and characters. Many members of the elite alluded to this highly prestigious “ancestry” to legitimize and justify power, especially within the political propaganda and ambitions of Edward I.\nEdward I was indeed an Arthurian “enthusiast” (as he has been called in previous research). He hosted many “Round Table tournaments” (more theatrical than regular tournaments and usually included Arthurian role-playing) to celebrate significant events, such as his Welsh victory in 1284. He exploited his “Arthurian ancestry” in a grand ceremony at Glastonbury Abbey in 1278 to reinter Arthur and Guinevere’s bodies—essentially conducting a spectacular funeral for Arthur, during which he used “Arthurian” relics (including Arthur’s crown) to legitimize his “inherited” power. He also wrote a letter to Pope Boniface in 1301 to claim land in Scotland on the basis that it was once owned by his ancestor, Arthur. A grand feast was also held at Westminster in 1306, during which Edward I swore oaths on a swan, in typical romance style, and knighted Edward II along with 267 others.\nEvery effort was made to continue Edward I’s Arthurian prestige and chivalric legacy when Edward II succeeded the throne. On his deathbed, Edward I charged his closest barons with assisting Edward II as his reign began; one of whom was Robert Clifford, who organized an enormous, chivalric celebration for Edward II’s coronation in 1308.\nEdward II soon began to show that he was not the chivalric king his father was, staunchly contradicting the values of Edward I’s chivalric legacy. Records claim that he enjoyed working in the garden (which was uncustomary and inappropriate for a king), he didn’t like hunting, he didn’t participate in tournaments, and he thoroughly annoyed the barons with his infatuation over Piers Gaveston. As baronial unrest and tensions increased, we begin to see Arthurian allusions made by Edward II’s principal opponents—the same ones closest to Edward I.\nThis brings us to Pendragon Castle (Cumbria, previously Westmoreland), inherited by Robert Clifford as the “castle of Mallerstang,” along with other nearby castles, including Brough, Brougham, and Appleby. Clifford renovated Brougham and Pendragon Castles in preparation to host Edward I during the Anglo-Scottish wars in 1300, but whilst his other castles were renovated in contemporary architectural styles, Pendragon retained its archaic image. Architectural archaism was a trend in castle construction, used to symbolise continuation of power and ancestral prestige. In 1309, Clifford was granted a license to crenellate, changing the “castle of Mallerstang’s” name to Pendragon Castle.\nIn 1312, Guy Beauchamp, 10th Earl of Warwick, presided over the trial of Piers Gaveston, whose greatest crime, according to the commemorative Warwick ancestral “Rous Roll” (c.1484), was stealing King Arthur’s round table. The Earls of Warwick already had long-standing connections with Arthur and displayed romantic “relics” inherited from their “ancestors.” Robert Clifford and Thomas Lancaster also participated in Gaveston’s trial and execution, and in 1322, Lancaster signed a treasonous document to James Douglas in Scotland under the pseudonym “King Arthur.” In 1327 and 1328, Roger Mortimer, the lover of Edward II’s queen, Isabella, celebrated the marriages of his children by hosting multiple Arthurian themed Round Table tournaments in the style of Edward I, each lasting several days and sparing no expense.\nIn the wake of Edward I’s chivalric legacy, those who were closest to him (including Clifford, Warwick, Lancaster, and Mortimer) developed ways to emulate Arthurian prestige in their opposition to Edward II, and it is within this context that Pendragon Castle comes into view as one of several homages to King Arthur, Edward I, and the not-so-distant golden age of chivalry.","The Normans were master castle builders. After 1066, England witnessed a massive castle building programme on the orders of William the Conqueror. First, motte and bailey castles were built. Once William had firmly established his rule in England, he built huge stone keep castles. By the time of Edward I, concentric castles were being built.\nCastles were a very good way for the Normans to expand their grip on the English people. The English population greatly outnumbered the Normans and the Normans had to create an atmosphere in which they were feared by the English, therefore, minimising the possibility of an uprising by the English.\nCastles were a sign of Norman power and might. They could be easily seen and as such acted as a deterrent. The castles warned the English that Norman soldiers lived in these castles and that any attempts to rise up against them would be met with force.\nThe castles also gave the Norman soldiers a safe place to live. They were, after all, invaders. William had built a temporary castle at Pevensey to house his troops when they landed in September 1066. This would have been a motte and bailey castle. These types of castles were quickly put up all over England after the Battle of Hastings to enforce Norman control.\nMotte and bailey castles:\nmade of wood quick to put up easy to repair big enough to house soldiers in safety had advantage of height as the castle was built on a motte; the Normans could see the English during the day a motte was a man-made hill you could keep animals in one as a food supply as they were high up, local peasants could easily see them\nBut motte and bailey castles had a number of weaknesses :\nwood is a weak building material; therefore these castles could not be big wood can rot with the rain; it generally weakens with age wood can burn the motte can collapse with the weight of the castle on it they were not big enough to house bigger groups of troops\nOnce William felt that the English had been tamed throughout England, he moved on to building more permanent castles – ones that would last for centuries. These are called square keep or stone keep castles. The most famous of these is the White Tower at the Tower of London. Rochester Castle in Kent is another fine example of a Norman square keep castle.\nThe White Tower, Tower of London\nmade of stone so they lasted longer. Stone would not rot so the castles were a lot stronger than wooden ones. because stone is strong, it is possible to build up so that you have a height advantage and can see for miles. also the walls can be made very thick therefore making them very strong. The walls at Rochester Castle in places are ten feet thick. These castles were much larger than motte and bailey castles and could keep more soldiers in them. They were very difficult to attack because of their size.\nBut square keep castles also had two major weaknesses:\nif the enemy went around you, what could you do? You would be left in your castle unable to do anything. If the enemy attacked you, it could decide to simply starve out by surrounding you. What could you do if this happened?\nAs time moved on and those with power felt more comfortable, they could afford to build bigger castles. These are known as concentric castles. These were bigger in all respects than square keep castles and the most famous king associated with them is Edward I who built numerous concentric castles in north-west Wales. He believed that this was a vulnerable part of his kingdom and that the Welsh could not be trusted. Hence he built these massive castles – by their standards – to demonstrate to the Welsh his power. Bigger castles housed more troops so the threat to the Welsh in that region was very obvious. Edward’s most famous castles can be found at Caernarvon, Beaumaris, Conway and Harlech."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:b1fde8fe-d3b9-499c-9866-fcb6636b94b6>","<urn:uuid:7fc7eb97-6e50-41cd-92cb-3ecaa5acad75>"],"error":null}
{"question":"How do the strengths of Earth's and Mercury's magnetic fields compare in measurements?","answer":"Earth's magnetic field is substantially stronger than Mercury's. Mercury's dipole moment is estimated to range from about 2 to 6 X 10^12 T m^3, which is approximately 0.0004 times that of Earth's magnetic field. This difference is evident in field measurements, where Mercury's maximum field strength was observed at 400 nT at 327 km from the surface during Mariner 10's third pass. At Earth, the magnetosphere creates a larger protective bubble, though it experiences breaks that allow solar wind penetration through Kelvin-Helmholtz waves spanning 40,000 kilometers in diameter.","context":["By: Crystal Gammon, OurAmazingPlanet Contributor\nPublished: 11/01/2012 12:06 PM EDT on OurAmazingPlanet\nOur planet's protective magnetic bubble may not be as protective as scientists had thought. Small breaks in Earth's magnetic field almost continuously let in the solar wind — the stream of magnetic, energized plasma launched by the sun toward the planets — new research has found.\n\"The solar wind can enter the magnetosphere at different locations and under different magnetic field conditions that we hadn't known about before,\" Melvyn Goldstein, an astrophysicist at NASA's Goddard Space Flight Center, said in a statement.\nCharged particles in the solar wind can interrupt GPS signals and power systems, as well as create dazzling auroras.\nThe magnetosphere is the planet's first line of defense against the solar wind. Scientists knew that this plasma stream occasionally breached the magnetosphere near the equator, where the Earth's magnetic field is roughly parallel to the magnetic field in the solar wind. The new study, published Aug. 29 in the Journal of Geophysical Research, found that these breaks can happen under a wider range of conditions.\n\"That suggests there is a 'sieve-like' property of the magnetopause [the outer edge of the magnetosphere] in allowing the solar wind to continuously flow into the magnetosphere,\" Goldstein said.\nPlasma swirls break magnetic field\nThe European Space Agency's Cluster mission, a set of four satellites that fly in close formation through the Earth's magnetic field, gathered the data that show how the solar wind can get through. Equipped with state-of-the-art instruments for measuring electric and magnetic fields, the Cluster satellites fly in and out of the magnetosphere and document the microscopic magnetic interactions between the Earth and the sun.\nFrom 2006 Cluster observations, scientists found that huge swirls of plasma along the magnetopause could help the solar wind penetrate the magnetosphere when the terrestrial and solar wind magnetic fields were aligned. Those swirls of plasma are known as Kelvin-Helmholtz waves, and they can be 24,850 miles (40,000 kilometers) in diameter.\nAs Kelvin-Helmholtz waves slide past the magnetopause, they can create giant vortices, similar to how wind blowing across the ocean causes waves. The huge waves can spontaneously break and reconnect magnetic field lines, creating openings that let the solar wind slip through.\n'Not a perfect magnetic bubble'\nThe new findings suggest that these magnetic field line breaks can also occur where the terrestrial and solar wind magnetic fields are perpendicular, at high latitudes near the poles.\nThe alignments of the solar wind magnetic field and Earth's magnetic field are key factors. A perpendicular alignment makes the boundary between the two fields less stable and likely generates more Kelvin-Helmholtz waves — and more magnetic field breaches. [Video: Sun's Energy Shocks Earth's Magnetic Field]\n\"We found that when the [solar wind] magnetic field is westward or eastward, magnetopause boundary layers at higher latitude become most subject to Kelvin-Helmholtz instabilities, regions quite distant from previous observations of these waves,\" Kyoung-Joo Hwang, a researcher at NASA's Goddard Space Flight Center who led the study, said in a statement.\n\"In fact, it's very hard to imagine a situation where solar wind plasma could not leak into the magnetosphere, since it is not a perfect magnetic bubble,\" Hwang said.\n- Earth Quiz: Mysteries of the Blue Marble\n- Aurora Guide: How the Northern Lights Work (Infographic)\n- 50 Amazing Facts About Earth","Originally published in:\nEncyclopedia of Planetary Sciences, edited by J. H. Shirley and R. W. Fainbridge,\n476-478, Chapman and Hall, New York, 1997.\nMercury is the smallest of the terrestrial planets. Its radius of 2440 km places it between the Earth's Moon and Mars in size. It is of great importance to those studying planetary magnetic dynamos and to those studying planetary magnetospheres. Its importance to the magnetic dynamo problem stems from its being the smallest and most slowly rotating planet with a presently active magnetic dynamo. Its importance to the physics of planetary magnetospheres stems from its lack of a dynamically important atmosphere or ionosphere. Currents generated by the solar wind interaction, which usually close in the ionosphere, cannot close in the same way at Mercury as they do in other planetary magnetospheres. It is thought therefore that the Mercury magnetosphere may be more strongly coupled to the solar wind than is the case for other planetary magnetospheres.\nBecause of its small size and outward appearance, due largely to the absence of a significant atmosphere, it is most appropriate to compare Mercury with the Earth's Moon. Mercury rotates more slowly than the Moon, rotating with a period of 59 days compared with the Moon's 28-day period. Mercury also differs from the Moon in that its rotation is not synchronous with its orbital period. Mercury orbits the Sun every 88 days so that every 2 Mercurian years, the same side of the planet again faces the Sun. The slow rotation, close proximity to the Sun and lack of atmosphere causes a very high surface temperature ( 630 K) on the dayside of the planet and very cold temperatures on the nightside. The role of the atmosphere in controlling surface temperature can he appreciated by noting that Venus, with the most massive atmosphere of the terrestrial planets, has day and night temperatures that differ at most by a few degrees.\nA unique characteristic of the rotation of Mercury is that its rotation axis is aligned along its orbital pole. Every other planet in the solar system has a rotation axis that is tilted with respect to its orbital pole, affecting, and in most cases dominating, seasonal changes. This oddity may influence both atmospheric and internal processes.\nMercury, with a density of 5.4 cm-3, is much denser than the Moon (whose density is 3.3 g cm-3). In fact, it is much more dense than the Earth, when compared at constant internal pressure (5.3 g cm-3 versus 4.1 g cm-3 at 10 kbar). The high average density implies a metal-rich interior, perhaps 70% iron-nickel and 30% silicate. In the absence of measurements from the surface or from orbit, the interior properties of Mercury are constrained mainly by the total mass and size of the planet. Because of the relatively large density of Mercury, the core must occupy a larger fraction of the planet than is the case for the Earth. Moreover, since Mercury is smaller than the Earth, it should have cooled more rapidly and its solid inner core should be an even larger fraction of the radius of the liquid core than is the case for the Earth. Thus the remaining liquid core may be confined to a rather thin shell. As a result of these differences, it is possible that the dynamo that supports the magnetic field of Mercury differs substantially from the terrestrial dynamo. Only rudimentary constraints are presently available on the nature of the Mercury field.\nAs discussed elsewhere in this volume, a tenuous sodium and potassium atmosphere has been detected at Mercury. While various mechanisms have been proposed to explain this tenuous atmosphere, one possible source is outgassing of the planetary interior, suggesting in turn an internally active planet.\nMercury has been visited by only one spacecraft, Mariner 10, which made three passes by the planet between March 1974 and March 1975. The first and third passes were suitable for studying the planetary field. On the first pass the spacecraft crossed the darkside of the planet within 723 km of the surface, at which point the field strength reached a maximum of close to 100 nT. The characteristics of the field resembled those of a mini- magnetosphere, in which the solar wind is deflected above the surface of the planet around a distorted dipole field. In contrast, the lunar magnetic field is so weak that the solar wind impinges on the surface and is absorbed. The third Mercury pass also traversed the darkside of the planet, approaching within 327 km of the surface and observing a maximum field of 400 nT. Again the characteristics of the observed field resembled those expected in a miniature version of the Earth's magnetosphere.\nThese two passes provided weak constraints on the magnitude of the intrinsic magnetic field, its orientation and its harmonic structure, in part because the coverage of the planetary field was poor and in part because of the lack of concurrent observations of the solar wind number density and velocity. The strength of a planetary magnetic field is measured in terms of its magnetic moment, the product of the equatorial surface field and the cube of the planetary radius. Estimates of the dipole moment of Mercury range from about 2 to 6 X 1012 T m3, and the strength of the quadrupole moment and the tilt of the dipole moment are completely unconstrained. The dipole moment is known, however, to be pointed southward like the Earth's. Alternative sources to dynamo generation of the field have been proposed, such as remanent magnetization of an iron-rich crust, but it is difficult to obtain a strong enough field through these alternate mechanisms.\n|Fig. 1. Cross-section of the magnetosphere of Mercury in the noon-midnight meridian. Solid lines anchored in the planet represent the direction of the magnetic field. The Mercury magnetic field lines point into the planet in the northern hemisphere as they do on Earth.|\nThe weak magnetic moment of Mercury, about 4 x 10-4 of that of the Earth, combined with a solar wind pressure about seven times larger than the pressure at Earth, results in a very small planetary magnetosphere (in both absolute dimensions, and relative to the size of the planet). This magnetosphere is sketched in Figure 1 which shows the magnetic field lines in the plane containing the Sun and the magnetic dipole axis. The magnetic cavity deflects the solar wind at a distance of only 1.5 Mercury radii from the center of the planet. Since the solar wind moves faster (relative to Mercury) than the pressure wave needed to deflect the solar wind can propagate in the solar wind, a shock wave is formed in front of the magnetic cavity. This shock wave heats, slows and deflects the solar wind to allow it to flow around the magnetic cavity or magnetosphere. Similar bow shocks are found in front of all planetary magnetospheres. The energy dissipation that is required to heat the flow occurs through collisionless processes in which the electric and magnetic fields scatter the particles and the particles do not make direct collisions with each other. Thus these shock waves are often called 'collisionless' shocks. An important question for all planetary magnetospheres is the coupling of the energy flux in the solar wind to the planetary magnetosphere. In the Earth's magnetosphere, stresses are communicated from the solar wind to the ionosphere and atmosphere and hence the solid body of the planet by electrical current systems which flow along magnetic field lines and then close across the magnetic field in the lower ionosphere. Mercury has no dynamically significant ionosphere or atmosphere, so the coupling must be quite different than in the terrestrial case. Based on dynamic events observed on the first Mariner 10 flyby, the Mercury magnetosphere is thought to be dynamic, varying markedly in the course of minutes. Clearly the energy transfer from the solar wind is much greater than on the Earth. As in the terrestrial magnetosphere, it is thought that the magnetotail is an important site for energizing the plasma of the magnetosphere. However, very little is known about the Mercury magnetosphere.\nThis work was supported in part by the National Aeronautics and Space Administration under research grant NAGW-2573.\nConnerney, J. E. P. and Ness, N. F. (1988) Mercury's magnetic field and interior, in Mercury (eds F. Vilas, C. R. Chapman and M. S. Matthews). Tucson: University of Arizona Press, pp. 494-513.\nRussell, C. T. (1987) Planetary magnetism, in Geomagnetism, Vol. 2 (ed. J. A. Jacobs). London: Academic Press, London pp. 457-523\nRussell, C. T., Baker, D. N. and Slavin, J. A. (1988) The magnetosphere of Mercury, in Mercury (eds by F. Vilas, C. R. Chapman and M. S. Matthews) Tucson: University of Arizona Press, pp. 514-61."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:96f22312-1396-4630-ae99-1385aee2e39b>","<urn:uuid:29263d64-d701-48c0-94c5-532c56ee6c4c>"],"error":null}
{"question":"Having worked with both species, I wonder: what key post-birth care steps are different between puppies and piglets?","answer":"Puppies require immediate removal of the amniotic membrane if the mother doesn't do it, to allow breathing, and counting of placentas is important to prevent infection. Piglets require more extensive post-birth care: umbilical cord cutting with disinfected scissors, iron supplements (if raised on concrete), teeth clipping to prevent injuries, tail docking to reduce biting and infection, and ear marking for identification - all within the first few days of birth.","context":["What to Expect, What to Do, and When to Call the Vet\nPart One: An Overview of Pregnancy and Whelping\nBy Arliss Paddock\nThe arrival of new puppies into the world is a much-anticipated event, the focus of all your study, planning, and hopes as a breeder. As each pup is born, you wonder if this will be the one—will he be a Best in Show winner? An agility star or field champion? A stellar service dog? For the breeder, the birth of a litter is charged with excitement and the promise of new possibilities.\nBut it is not a situation to be entered into lightly or with inadequate preparation. It should not be entered into at all, in fact, without there having first been sober, clear-eyed consideration of whether this female should be bred. Hopefully, you asked important questions beforehand: Is she a truly superior representative of her breed, free of major faults of conformation or temperament, and screened clear of physical and genetic defects? Have I found a mate for her of outstanding quality, also screened clear of health and genetic defects, whose traits complement hers?\nSiberian Huskies. Photo by Mary Bloom.\nOnce you’ve confirmed that your bitch is worthy of breeding, it’s important to realize before proceeding the seriousness of potential risks that labor and delivery can pose for both her and the pups. Although most canine births occur without a hitch, life-threatening complications can arise, so it’s vital that as a breeder you have a thorough understanding of both the normal birth process and signs of possible trouble. Acquiring such knowledge requires more in-depth study than can be covered here, but here is a good starting place.\nIn this and the next issue of AKC Breeder, we will present an overview of what happens leading up to and during whelping, along with tips from experienced breeders to help you prepare for the big day.\nCan I calculate my bitch’s due date?\nGestation in the dog lasts from 62 to 64 days, counted from the exact date of ovulation—which could have occurred during a wide range of days during the breeding period, difficult to pinpoint without specific testing. Many bitches will stand to be bred for a large window of time around ovulation, and the stud dog’s sperm can survive in the reproductive tract for more than a week. What this adds up to is that a normal, “full term” whelping date can be anywhere from about 58 to 71 days after the breeding occurred.\nFor this reason, you should ensure that your contingency plans for the whelping, such as scheduling time off from work, cover the entire period during which labor could begin. (“I take vacation time when my girls are due,” notes Collie breeder Michelle McKim, of Indiana.) And you should try to have all your preparations—whelping box, whelping kit, and so on—in place well before the earliest-possible whelping date.\nYour pregnant female\nBefore the breeding, you will have addressed with your vet your bitch’s pre-pregnancy health care, such as nutritional recommendations, making sure that her heartworm preventative and all vaccinations are up to date, and having her dewormed.\nOnce your female has been bred, physical and even behavioral changes will soon be under way. By about the fourth week, your bitch’s appetite will begin to increase. At about 25–28 days of gestation, an experienced person can confirm pregnancy by palpating the bitch’s abdomen—but don’t try this yourself without the careful guidance of an expert, as improper technique could endanger the fetuses. Ultrasound imaging can also confirm pregnancy now.\nBy the fifth week some distension of her abdomen will probably become apparent, although this may occur later with larger breeds. A clear or light opaque discharge from her vulva is also likely at this time. (Any blood-tinged, dark, or foul-smelling discharge is reason to call the vet.)\nThe most dramatic changes, however, will occur during the seventh, eighth, and ninth weeks. During this period the fetuses grow rapidly, greatly stepping up the demands on the dam’s body. Her daily food ration should be increased gradually but significantly. Any strenuous physical activity such as herding or agility work should have been curtailed by the seventh week, but gentle exercise to keep her fit should be continued. As the ninth week approaches, milk production in her mammary glands may be apparent, but this varies widely among females—some will have no milk discernable at the time of whelping. With others, milk may drip from the teats several days before labor begins.\nNesting behavior, which may begin at any time during the pregnancy, will gradually become more intense as the whelping date approaches. (The timeframe for this varies, however, and it is not a sure sign of labor in itself.) Several days before the onset of labor, the bitch’s belly may “drop” somewhat so that her abdomen will appear more pendulous and distended, and her backbone may become more prominent.\nThe stages of labor\nLabor in the dog is generally described in three stages: Stage 1, which refers to the period when the cervix dilates and involuntary uterine contractions begin; Stage 2, when contractions greatly intensify, and a pup is delivered; and Stage 3, when the placenta is expelled. Stages 2 and 3 alternate as consecutive puppies are born. There are certain characteristics associated with each stage.\nThe onset of the labor sequence is signaled by a marked drop of a degree or more in temperature, 12 to 24 hours beforehand. For this reason, it is especially helpful to routinely take the bitch’s temperature several times a day during the last week of pregnancy so as to identify this drop and thus know when labor is imminent.\nDuring Stage 1 the bitch will pant, be very restless, and be disinterested in food. Though she may sleep intermittently, when awake she is likely to dig and scratch in the nesting area and shred any newspaper within her reach. She may pace, turn around several times and lie down, get up again, and repeat the behavior.\nAs Stage 1 progresses, her panting will become heavier and more constant. At this time a sudden clear, stringy, odorless discharge from the vulva may be noticed. This indicates that the mucus plug that sealed the cervix throughout the pregnancy has dissolved, and it means that the first pup will probably soon be delivered.\nSometimes a bitch will move from Stage 1 to Stage 2 very quickly, and sometimes not. “If Stage 1 labor goes on for more than 12 hours without progressing to Stage 2 labor, with obvious contractions, intervention is recommended,” Dr. Margaret Root Kustritz, of the University of Minnesota College of Veterinary Medicine, says. “Prolonged Stage 1 labor has been associated with increased incidence of stillbirths and neonatal death.”\nCoordinated abdominal contractions mark the onset of Stage 2. The bitch now focuses on making these very strong pushes toward her hind end. She may stand, crouch, or lie down in attempting to deliver the puppy. The first tangible sign of the delivery should be a dark, fluid-filled bag protruding from the vulva. This is protrusion of the amniotic sac that surrounds the pup. The sac may rupture as the pup passes through the birth canal.\nIf the puppy’s head emerges still covered by the membrane, and the bitch does not tear it away, you must do this—using clean fingers or a soft towel—so that the pup can begin to breathe. (In Part Two of this article, breeders will share advice regarding how to handle various situations as the puppy delivers.)\nStage 3 of labor is expulsion of the placenta. The placenta may come out immediately after the puppy, or it may come with the next one. It is common for two puppies to deliver in succession, followed by two placentas. It is important to count the placentas to make sure that all are expelled, as placentas retained for more than a few hours can lead to uterine infection.\nBitches will normally want to eat the placenta in an instinctive attempt to keep their “den” clean. Many breeders feel that eating it is beneficial for the dam, although this has not been proven. Kustritz notes that ingestion of placentas can cause gastroenteritis in some bitches.\nThe bitch may rest from 10 minutes to an hour between deliveries, but will resume her whelping position when more abdominal contractions begin. With a small litter, all the pups may be delivered within an hour of the onset of Stage 1; delivery of a larger litter can take much longer.\nHow can you know when all the puppies have been whelped? “Determination of whether or not the bitch has finished whelping can sometimes be difficult,” Kustritz says. “Palpation of the abdomen can be confusing, because the contracting uterus often feels like a round, firm puppy. Radiographs are definitive.”\nIn the next issue, we’ll look at how to determine when labor is not progressing normally, and what to do if so.\nNext Issue: Whelping Tips From Experienced Breeders\nArliss Paddock breeds and shows English Cocker Spaniels and is former managing editor of the AKC Gazette.","‘Farrow’ originally meant ‘young pig’. In the early 1400s it came to refer to the birth process in pigs. The sow’s litter is also called a ‘farrow’.\nThe most critical period in the life of a pig is from birth to weaning. On average, about two pigs per litter are lost during this time. Good management will reduce these losses, and it starts with the sow.\nThe average gestation period is 114 days (three months, three weeks and three days). In the weeks before farrowing, move the sow to the farrowing pen once a week for a short period, so that she gets used to it; this will reduce stress. Four to five days before farrowing, wash and disinfect her, then place her in the farrowing pen.\nCheck the udder for hard spots or lumps. The latter can be treated with an antibiotic.\nConstipation often occurs at this stage, but can be prevented by feeding the sow green feed, such as lucerne, or high-fibre feed (bran or pollard).\nPreparing the pen\n- The farrowing pen should be erected some distance from the other pens, and strict hygiene maintained at all times.\n- After the previous sow and her litter have been removed, clean the pen using a high-pressure spray, scrubbing brush, and good disinfectant, such as a 4% formalin solution. Leave the pen unoccupied for two to three days.\n- Remove soiled and wet bedding daily and replace it with dry bedding.\nIt’s crucial to supervise farrowing. Newborn piglets have three basic requirements: a suitable environment; adequate and regular nutrition; and absence of disease and crushing.\nWatch out for constipation in the sow and make sure she has discharged her afterbirth.\nCheck her temperature for fever to make sure she is not suffering from infection.\nIf she has insufficient milk, her litter may die of hunger. Agalactia (giving too little milk) and mastitis require immediate veterinary treatment.\n- Cut the umbilical cord a few days after the piglets’ birth using a disinfected pair of scissors. Leave a 2cm section.\n- Disinfect the sow’s navel with an iodine solution to prevent bacterial infection.\n- Piglets are born with low iron reserves and receive only a limited supply from the sow’s milk. If they are reared outside, they absorb iron from the soil or mud, which will provide their iron needs. If they are reared on a concrete floor, they can suffer from iron deficiency; this can cause anaemia, which results in poor appetite and slow growth. Administer iron supplements three to seven days after birth via an injection in the neck.\n- Piglets have sharp teeth. To prevent them from injuring each other or the sow’s teats, clip their teeth with a tusk clipper. Take care while doing so to avoid hurting the gums. Leave about half of the tooth in place.\n- Docking a piglet’s tail will reduce tail biting and infection when the animal is older. Leave an 80mm stub. Tails and teeth should be clipped before the piglets reach three days of age. Finally, earmark each piglet for identification purposes.\nSource: Majane, P. 2005. ‘Care of sow and piglets’. Department of Agriculture, Forestry and Fisheries in co-operation with ARC-Animal Nutrition and Animal Products Institute."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:e17be7e8-8636-43be-9f68-4ad15fc46783>","<urn:uuid:c0177be9-009d-4f5c-8aca-4c999213d094>"],"error":null}
{"question":"What is the most important scoring element in a Madison race - points or laps?","answer":"Laps are more important than points in a Madison race. While the race is scored like a points race with sprints every 5 minutes, lapping the field (passing over half the riders or the largest group) takes precedence over points in determining the winner. Almost every Madison race is won on laps rather than points.","context":["The basics - hand sling, on the track:\nAfter doing a few slings on the apron it is time to go out in the track and get use to the doing this at faster speeds. The goal here will be to get use to the speed. You should try to get use to doing slings at speed so that you know what it feels like to gain speed and lose speed very quickly. DO NOT try your first exchange as you enter a corner. You should do your first exchanges as soon after a corner as possible, note the picture at the top is great with Chauncey and Morgan finishing the exchange at the exit of the corner. This will allow rider one (who is going from 30 down to 15) to get off the track gracefully before the corner. The idea here is that rider one will be going at speed on the black line and rider two will be going about 15 on the blue line. To start you (rider two) will come down to the red line early and just wait with your left hand behind your back until you hear rider one yell \"hand\". At this time you should feel rider one's right hand grab yours and start passing underneath you very quickly. Make sure that your speeds are closer together at the start or you rider one will literally pull rider two off the track. As soon as rider one has passed the same thing as before will occur and rider two will start to gain speed then sling past rider one and now rider two drops to the black line while rider one drops to the apron. Now rider two becomes rider one and rider one becomes rider two and you do it again.\nThe basics - hand sling, the corners and timing:\nNow that you are use to doing this on the track you need to work on using the corners and timing it just right. The best exchange is one that uses the bank and limits the amount of energy wasted as rider two gets up to speed as well as ensures that rider one is not on the track very long. The basic idea is that exchanges occur every two laps, although anywhere between one and a half and two and a half is normal. This means that as soon as rider one slings rider two, the first rider drops to the apron, looks behind while going slow, then at the first sign of open track goes back up to the top of the track at the middle of either straight. As soon as the rider on the rail sees the rider leave the opposite straight (e.g. enter the corner - about 10 seconds) the rider on the rail (now rider two) starts to go toward the next corner on the blue line. By the time you enter the corner you should be at 15 mph and your partner will yell \"Red line\" if you have not started down to the red line yet. Notice that you will gain some speed just by dropping down and will likely be close to 20 mph now. Rider one will then yell hand as you are in the middle of the turn below an Alpenrose sign and you will do the exchange as you exit the corner. This is where the lap and half move comes in. If you are feeling good and can go up track right away (look before you go) you will have only taken half a lap to do the exchange and go the opposite rail that your partner was on while waiting for you. If you can't get up track right away or have a long exchange then you will find yourself not going up track till after the next corner and make it a two lap exchange (the average). If you are tired, then you might keep on the apron a little longer and not even go all the way up track and stop to wait and end up with a two and half lap exchange. Note that it is bad karma to ever let your partner pass you without doing an exchange, so if you ever see your partner pass you without exchanging then be prepared to explain yourself.\nThe basics - keeping it safe:\nAs you get use to where you do the exchanges and how quickly your partner comes up to you and how hard they sling you in you are ready for some more safety training. As you might have already noticed it is very hard to time things exactly right and exchanges happen all over the place. If you haven't noticed this in training, you will when you add more riders and do an actual race. So you need to practice doing exchanges all over the track especially in the corners. The hardest place to do an exchange is as you enter a corner. This means that rider one will lose some speed but not all their speed (especially if there is a bad exchange) right as they enter the corner. This means two things, first you should practice coming off the track in the corner and second you need to be very aware of your speed and where others are on the track. The best way to do this is to start on the apron at about 10-15 mph and then when you get to the apron go just above the black line then back to the apron. Repeat this about five to ten times each corner for a few laps. Then do some odd exchanges as you enter the corner and get comfortable going on and off the track in the corners. This is one exercise that you will find very useful the first time you need to do this in a real race.\nThe Rules - some rules before you race:\nThere are a few basic rules that you need to follow when doing a Madison. Never go under an exchange. This means if you are riding behind a rider and you see their teammate ahead on the blueline getting ready for an exchange and do not see your partner, then start going up track. You will need to go above both riders and will likely find yourself riding up to the blue line or higher as you pass both riders. The trick here is to make sure that you don't lose so much speed that a good exchange by the opposing team allows them to get a gap on you as go too high when passing. This also means that you can never pass in-between two riders who are exchanging as this will likely cause you to be disqualified and is even worse than going under an exchange. Also since teams must pass above, an exchanging team must stay low (rider one on the black, rider two on the red). This is all for safety as everyone knows that rider one is going to the apron hence the rule for no passing under an exchange and teams behind are passing above, hence rider two must stay on the red line then quickly drop to the black after the exchange. Always pass above, the one exception is if you are leading a rider who is about to exchange. You can then safely go underneath their teammate as they will exchange behind you and that is just fine. Also be aware of other teams that are exchanging at the same corner you are. This means that if you are rider one you should hold your position as you enter the corner before as teams will line up based on entry to a corner. If you are rider two, then you need to line up in the order that the riders enter the previous corner in. This will ensure the teams are lined up as the exchanges occur in the next corner. However as most riders know, corners are where exchanges take place so be prepared to jostle your position, and really hope that no one passes in the straight leading up to the exchange corner. Also be aware of speeds, as this will vary dramatically during the race. An exchange at 15mph is much different than an exchange at 35mph so be ready and listen to your partner who will likely be yelling fast or slow to let you know if you are not going the right speed.\nThe Rules - the rules to score:\nNow that you can safely ride a Madison it is time to learn how to win. A Madison is scored very much like a points race and has sprints every so often (normal is 5 minutes) and if you lap the field (pass over half the riders or the largest group) those laps are more important than points. So the same tactics that are used in a points race are used here but there is one obvious difference, you have a partner. Most tracks allow an exchange into the sprint, so unless you have one rider who is clearly better at sprinting, don't mess up your exchanges for the sprints unless you are really good. Only if you can figure out ahead when to do one and a half versus two lap exchanges to time the sprint should you attempt to get a certain rider in on a sprint lap as leaving someone in to long will normally cause a gap, then a lap, and as I said laps are much more important than points. So just keep exchanging and try for the sprints only if you know you won't lose a lap. A better strategy is often to time an exchange just after the points lap and attack the rider who tried to win the points. This will give you a gap and maybe enough to get a lap on the field.\nHaving a partner also gives you a weak link that other teams will try to exploit. You need to figure out who is stronger and who is faster. Likely other teams will try to time their exchanges so that they can attack someone they feel is weak, or who they know has a problem at the end of their two laps. Getting out of sync in your exchanges with the other teams, which always happens, can be a benefit or a negative. This will make it so that you have a rider who is near the end of their two laps with a fresh rider just getting thrown in. If your rider (or you) is also behind the exchange then you must go over wasting even more energy. If you are leading it out then a faster rider that you can't see might attack you. Either way you need to pay attention and always exchange as often and cleanly as possible. Almost every madison I have ever watched has been won on laps, and attacking at critical times or during a missed exchange are the easiest way to get your lap.\nSo if you are ready to have fun, get the best workout of you life and learn something everytime you go out on the track, then the madison is for you. It is not that scary once you get out there and do your first exchange, so just find someone who has done it before and go have fun.\n- Jamie Mikami"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:07040b04-e659-469c-b070-76169cab7e12>"],"error":null}
{"question":"What similarities exist between the way Hunt and Chagall used religious art to highlight contemporary suffering? Both artists seem to connect biblical themes to modern issues.","answer":"Both artists connected religious imagery to contemporary suffering, but through different approaches. Hunt tried to maintain a balance between visual realism and traditional religious symbolism through typology throughout his career, though this often puzzled his audience. Similarly, Chagall used religious imagery, specifically the crucifixion, but adapted it to highlight contemporary persecution - depicting Jesus as a Jewish martyr surrounded by scenes of Nazi violence against Jews in 1938. Both artists attempted to make religious art relevant to their times, with Hunt working to revive traditional symbolic approaches while Chagall explicitly connected Christian imagery to modern Jewish suffering. Their works demonstrate attempts to reconcile religious symbolism with contemporary meaning, though Hunt focused more on maintaining traditional iconographic elements while Chagall more directly adapted religious imagery for political commentary.","context":["Although they did not always approve of his intentions, many Victorian reviewers understood that Hunt employed elaborate pictorial symbolism. As the Art-Journal explained in its review of The Finding of the Saviour in the Temple, \"Mr. Hunt, like his admirer Mr. Ruskin, manifestly takes much pleasure in exercising his ingenuity in symbolic incidents, or mystical allusions\" (22 , 182). The critic then provided examples of the painter's symbolism in this picture, but since he had the assistance of both Hunt's key-plate and Stephens's elaborate explanations, one cannot draw any conclusions about his interpretative skill. Certainly, when the critics did not have such exegetical aids, they encountered grave difficulties with the paintings of Hunt and his associates. The 1869 Art-Journal, which reluctantly granted that Hunt's The Birthday had \"amazing power,\" commented upon what it took to be the painter's characteristically enigmatic manner: \"The lady bears in her hands birthday-presents mournfully, as if under the burden of dark misgivings: thus, as usual, the artist is suggestive of some hidden meaning; and the spectator stands aghast in wonder — scarcely in admiration\" (167). Of course, one can hardly blame the reviewer for being puzzled by the extremely personal allusions in this painting, which is in fact a portrait of Edith Waugh done not long after the death of her older sister Fanny, Hunt's first wife. According to family tradition, Edith bears some of her sister's possessions, and although Hunt did not marry her for many years, he already seems to have seen his first wife in a prefigurative relation to his second.\nNonetheless, contemporary criticism indicates that many of his contemporaries found themselves puzzled by Hunt's works even when there was no such personal reference. For instance, Ernest Chesneau's English School of Painting proclaimed The Afterglow in Egypt a particularly enigmatic, a quality he believed characteristic of much Pre-Raphaelite work (192. Chesneau's comments, quoted below, appear on 192-94). The French critic explained that Hunt's title inevitably led one to expect \"an extensive Eastern landscape, subsiding into shadowy twilight, whilst overhead the pale sky is lighted by the last gleams of the setting sun, which has just sunk below the horizon.\" To his surprise he found \"nothing of the kind in Mr. Hunt's work. A female figure forms his subject, some woman of noble birth, perphaps a wife of Pharaoh.\" He then wonders: \"Is she a daughter of the Nile? or is she not rather some goddess of harvest, an Egyptian Ceres?\" Proceeding on this last supposition, he offers an attractive reading of the picture as an emblem of the \"affluence of Nature,\" but he immediately doubts this interpretation, and from this doubt he draws conclusions about the iconographically puzzling quality of Pre-Raphaelite art. \"The Pre-Raphaelites,\" he tells us, \"involve themselves in such subtleties that one can never feel certain of their meaning.\" Admitting himself haunted by The Afterglow, he turns back to it to find another \"solution of the enigma\":\nPrincess and goddess, both have faded; and I am in the presence of the personification of modern Egypt. In the dull, black eyes, as frigid and lustreless as a lifeless coal; in the ominous stillness, and in these trappings suitable to a slave or a courtesan, I find a symbol of Egypt, deposed from the splendour of her ancient civilisation, and fallen from her high, intellectual culture, with nothing left to her but what the fertility of soil, the waters of the Nile and bountiful Nature continue to lavish upon her. Why does she turn her back to the river? except, indeed, it be to avert her gaze from the colossal remains of her former power lying ruined on the banks. Steadfast and gloomy, she stands under the weight of the heavy corn; steadfast and lifeless as a block of granite; her life has sunk to an animal, vegetating existence, with perhaps, in the far depths of her soul, a sparkle, a gleam of her former state.\nLeaving to his reader to find other solutions to \"this problem,\" Chesneau charges that the \"fault of this emblematic and ideal style of painting\" is that \"it possesses the slight defect of being at times unintelligible, or, what comes to the same thing, it may bear as many contradictory interpretations as there are interpreters.\" He stresses the deadness and lack of life in the figure, which is, in fact, quite sparkling with life, thus demonstrating Gombrich's view that interpretations of expression tend to fit prior interpretations of meaning. Of course, what is at issue here is not Chesneau's various interpretations of the painting — all of which, incidentally, Hunt denied (See Landow, \"'As unreserved as a studio chat.'\") — but the way this sympathetic and often ingenious critic found himself unsure how to approach a work he took to be characteristic of Pre-Raphaelitism.\nThe iconography of Pre-Raphaelite painting long puzzled the native critics as well, and not only when the painter's allusions were intensely personal. In its hostile review of Millais's exquisite Autumn Leaves at the 1856 Royal Academy the Art-Journal mockingly inquired:\nIn what vein of mystic poetry will the picture be read? The artist awaits the assignment of the usual lofty attributes. The work is got up for the new transcendentalism, its essences are intensity and simplicity, and those who yield not to the penetration are insensible to Fine Art . . . We are curious to learn the mystic interpretation that will be put upon this composition. \nThe reviewer's confidence that Autumn Leaves was a painting without meaning \"got up\" for a fraudulent \"new transcendentalism\" is merely one of the more hostile comments upon Pre-Raphaelite iconography. The Art-Journal's comment that the painter \"awaits the assignment of the usual lofty attributes\" clearly refers to Ruskin, and therefore much of the critic's animus was directed not so much at Millais himself as at those admirers of the Brotherhood who would take this painting \"as an essential sign of the divine afflatus\" (171). About this time the Art-Journal was conducting a particularly vigorous campaign against Ruskin [see note at left], for whose iconographical readings of contemporary and earlier painting the editors apparently had particular dislike. One especially violent attack was directed specifically at his typological interpretation of Tintoretto's Annunciation.. Nonetheless, despite the influence of art-politics, the critic's puzzlement when confronted by Pre-Raphaelite symbolism was genuine. Writers for the Art-Journal, like many other contemporary writers and reviewers, simply did not feel comfortable with these pictures, because they found them so continually puzzling and so essentially enigmatic.\nSo many Victorian critics found these works confusing because, as Hunt recognized at the beginning of his career, the old iconographic traditions, the old \"art-languages,\" were moribund. However much reviewers at mid-century resisted realistic styles of painting, their basic conceptions of art were in basic accord with realism, and as Kermit Champa has pointed out in Studies in Early Impressionism (1973), \"Realism inevitably emphasizes the visual importance of the image itself and isolates it from whatever literary values it may hope to convey. Realism ruptures the balance between literary and formal intention that stands as the highest ideal in Western painting from Giotto to Delacroix\" (1). What was so ambitious about Pre-Raphaelite painting was that it tried to maintain that traditional balance while yet moving closer to a pure visual realism. Hunt, more than any of his associates, tried to implement such a program throughout his entire career, relying upon typology as the source and inspiration of his major works. Even he had continual difficulties with such a conception of art, and one of the most painful parts of his correspondence appears in his attempts to explain that works which friends took to be symbolical were realistic, while those they took to be realistic were symbolical. Working without a living iconographic tradition, he continually created works which puzzled his contemporaries, because they did not know how to approach them.\nThe cause of his difficulties — and ours — was, as I have suggested, the triumph of realism and the attitudes on which such a conception of art is based. Nonetheless, we must recognize that William Holman Hunt was not quite the anomaly that such an historical over-view might suggest, for, in fact, we encounter a significant number of other nineteenth-century painters also engaged to revivify the symbolic potential of the visual arts. In the United States, for example, one finds Frederic Edwin Church, another artist influenced by Ruskin, who tried to endow his landscapes of both Americas with intricate political and other significances, resorting, like Hunt, to elaborate exhibition pamphlets. Earlier in the century there was Caspar David Friedrich in Germany, who, if Borsch-Supan's interpretations are correct, tried to work out an elaborate, and almost completely inaccessible personal symbolism.\nAs the recent works of Patricia Allderidge and David Greysmith have shown, in England there was also Richard Dadd, who combined a hallucinatory, hard-edge style with elaborate and often unintelligible symbolism. Indeed, as Allderidge points out, one of his most fascinating works, The Flight out of Egypt (1849-50), seems to combine a prefigurative allusion to the Holy Family with the events of an earlier time (82-83). Dadd's madness and his arcane beliefs naturally make any interpretation difficult, but it does seem plausible that the apparently irreconcilable activities function, like Hunt's, as part of a typological emblem. Turning to a much greater work, one perceives in Courbet's The Painter's Studio: A Real Allegory (1855) another attempt, like Hunt's, to retain a balance between realism, formal qualities, and symbolism. It is indicative of the degree to which iconographic traditions had been lost that Courbet's subtitle, A Real Allegory, should have so long remained puzzling to students of his work.\nWhat this perhaps bizarre congeries of nineteenth-century painters should suggest, I hope, is that there co-existed with, and sometimes within, the dominantly realistic tradition important attempts, like Hunt's, to create effective modern iconographies. Hunt and his Pre-Raphaelite associates drew largely upon typological symbolism for their chief inspiration, but their religious sources should not blind us to the fact that they take their place in a much broader attempt to reconcile realism and symbolism.\nAllderidge, Patricia. The Late Richard Dadd, 1817-1886, London, 1974.\nBorsch-Supan. Caspar David Friedrich, trans. Sarah Twohig. New York, 1974.\nChesneau, Ernest. The English School of Painting. Trans. Lucy N. Etherington. 3rd ed. London, 1887.\nGombrich, E. H. \"The Evidence of Images.\" Interpretation: Theory and Practice. ed. Charles S. Singleton. Baltimore, 1969. 35-109.\nGreysmith, David. Richard Dadd: The Rock and Castle of Seclusion London, 1973.\nHuntington, David C. The Landscapes of Frederic Edwin Church: Vision of an American Era . New York, 1966.\nLandow, George P. \"'As unreserved as a studio chat:' Holman Hunt's Letters to Ernest Chesneau.\" Huntington Library Quarterly (1975): 355-69.\nLast modified December 2001","Sermon - 21st August 2011\nSeeing Salvation: 10\nWhite Crucifixion - Marc Chagall\nScripture - Colossians 1:15-29\nRev Andy Braunston\nThe Painting - Discussion\nLook at the painting, either on the sheets you have or on the screen. What do you see?\n- Jesus on the cross\n- “King of the Jews” written above his head\n- Guy in green in bottom right leaving with his possessions on his back\n- Scroll of the Law on the ground on bottom right\n- Old man in blue on the left and another man holding the scrolls of the Law\n- A menorah at the foot of the cross\n- Destruction, flames at the top\n- Ghostly figures above the cross who can’t bear to watch.\n- A Lithuanian flag representing Lithuanian persecution.\nThe Red flags were an expression of wishful thinking that Stalin may send troops to liberate the Jews.\nIs there a central figure in the picture? Is it like other images of the crucifixion?\nNo – Jesus wears a Jewish prayer shawl. No – in other examples of a crucifixion Jesus is the central figure who suffers and others gaze on his suffering. Sometimes the suffering of Mary watching her son die is portrayed. But in this all are suffering, Jesus is one more Jew who is being persecuted.\nChagall was born and grew up in Tsarist Russia. As a Jew he was only allowed to be educated to primary level but his mother bribed the local school official to let him attend secondary school. He studied art during the Revolution and is most famous for his portrayals of Jewish life in pre-revolutionary Russia. By the 1930s he had moved to France – indeed he was in France when the Germans invaded and had to rely on the generosity of the American counsel in Marseille to get him, and his wife, out to safety.\nWhite Crucifixion was painted in 1938 and has a specific context. Chagall painted it to draw attention to a recent series of political events perpetrated by the ruling Nazis in Germany. Both as a Jew and as an abstract artist Chagall was a target of Hitler's art censorship policies. His dealer in Germany was forced to close his Berlin gallery, cease publication of its influential newsletter, and flee to the Soviet Union in 1932. In 1937, the Nazis undertook a systematic inventory of modern art in German museums, removing some 16,000 works unacceptable to their taste to use in propaganda campaigns, to destroy, or to sell outside the country. Four works by Chagall were among those included in the 'Jewish' room of the infamous 'Degenerate Art' exhibition staged in Munich at the end of 1937, which mocked deviations from Nazi Party art standards.\nMeanwhile, anti-Jewish policies in Germany escalated to an unthinkable level. Following the September 1935 laws to curtail the civil rights of Jews, the Nazis, in 1938, undertook a Jewish census and registered all Jewish businesses as preliminaries to plans for ethnic genocide. In June and August of that year the synagogues in Munich and Nuremberg were destroyed, and on November 9, the so-called Crystal Night took place where Jewish shops and businesses were attacked. The name “Crystal Night” comes from the amount of glass that was shattered from all those shop windows.\nIn reaction, Chagall conceived a painting of the martyrdom of the Jesus, the Jew, as a universal symbol for religious persecution. Instead of a crown of thorns, the Jesus on Chagall's picture wears a head-cloth and a prayer shawl around his loins. The round halo around his head is repeated by the round glow around the Menorah at his feet. Mourning his persecution, figures of the Hebrew patriarchs and the matriarch Rachel appear in the smoke-filled night sky – but some of these can’t bear to look.\nAll around the cross, Chagall has depicted a bleak snow scape with horrific scenes of contemporary Germany. In the background to the right, a soldier opens the doors of a flaming Torah ark removed from a pillaged synagogue, the contents of which litter the foreground. Both the flag above the synagogue and the soldier's armband originally were decorated with swastikas. One of the fleeing figures in the foreground at the left wears a sign which originally bore the inscription \"Ich bin Jude\" ('I am a Jew') but Chagall painted over these before fleeing France. In the background above is a ship full of refugees trying ineffectively to flee a burning village, destroyed before the arrival of a liberating People's Army from the Soviet Union carrying red flags; this last detail was wishful thinking, motivated by the antagonism of Stalin's government toward Hitler's before 1939.\nIncluded in an exhibition of Chagall's works in Paris in early 1940, the \"White Crucifixion\" was designed to raise awareness of the events in Hitler's Germany and their implications for humanity in general.\nSo this is a painting about suffering, and, in particular, the suffering of the Jewish people. Perhaps a contemporary artist might paint an Iranian Jesus surrounded by scenes of the repression of Iranian gay people, those who advocate democracy and women who work for equal rights there. Or perhaps there might be a Zimbabwean Jesus surrounded by symbols of the ruthless oppression of Mugabe.\nChagall as a Jew understands the universal nature of Jesus’ suffering and sees the persecution of God’s people as being an attack on God’s own self. For me it’s an illustration of Jesus’ words recorded in St Matthew where he says that however we treat the “least” of his sisters and brothers is a reflection on how we are actually treating him.\nOur reading continues this theme of suffering, and the suffering of Jesus. Paul sees his vocation as a Christian, and as a Christian leader, as entering into and sharing the sufferings of Jesus. To be a Christian is to participate in those sufferings. Paul seems to understand that those sufferings didn’t end on the cross but that the sufferings of Christ continue in his people.\nThe history of the Church has always included persecution and includes it now in lands where to be Christian is illegal. We have had victimisation, persecution and murder in MCC, particularly in our early years.\nChagall in his painting shows that the suffering of Jesus is also seen in the Jewish people, or perhaps he shows that the suffering of the Jewish people is also seen in Jesus.\nI’m always suspicious of the type of Christianity that implies that everything will be ok once we’re Christian, that implies there will be no more pain and that sees God as a kind of cosmic insurance policy. The witness of Scripture is that God is with us in our sufferings, that the way we treat others reflects how we treat Jesus and that God has an especial concern for the poor, the dispossessed and the persecuted.\nChagall, used his art to bring to the attention of the art world the despotic persecution of the Jews in Germany – 1938 was before the death camps but was an era of legal restriction, social alienation and state-sponsored persecution. In general the Western democracies didn’t intervene, didn’t allow many Jews to emigrate and worried about the effect of mass immigration if they did open their borders.\nSuffering still continues, Christ still suffers in his people. Part of our role and ministry as Christians is to draw attention to injustice and suffering – just as we do when we sign and ask others to sign petitions against the deportation of gay people to Uganda just as we did this week – and the petition work, the man in question has been allowed to submit new evidence to the Home Office. But we are also called to fight injustice, to protest against the misuse of power and to try and help heal the wounds of those who have been damaged.\nWe stand alongside those in need, those who are suffering – mentally, physically, those who suffer because of the actions of others as well as those who suffer because of their own actions. We stand alongside them and recognise the suffering of Jesus in the suffering of His people.\nChagall hoped, in his picture, that the Red Army would end the suffering of the Jewish people in Nazi Germany. Sadly he was wrong. We may hope in earthly powers and governments to make a difference – indeed we should lobby and vote for politicians who will make such a difference. But we also, as Christians, know that the final deliverance from suffering will not be seen this side of the grave. Jesus suffers on the cross with his people, and with Jesus we await the final day of resurrection."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:c4e244e1-7290-49b1-8d07-e05737dcba71>","<urn:uuid:a20c283f-8219-4780-8faf-5eb68ed90619>"],"error":null}
{"question":"What are the economic implications of pollinator conservation in the United States' agricultural sector versus organic food markets?","answer":"In the U.S. agricultural sector, pollination produces almost $20 billion worth of products annually, with pollinators being critical for fruit, nut, seed production, and about three-quarters of staple crop plants. In the organic food market, companies like Cascadian Farms (organic branch of General Mills) represent only 3% of total sales, but are taking steps toward pollinator conservation through campaigns like 'Bee Friendlier.' The contrast reflects broader economic tensions, as Americans' demand for abundant, cheap food has created a system reliant on pesticides, while the organic market represents a growing but smaller segment focused on pollinator protection through pesticide-free practices.","context":["What you may not know about me is that I am a lover of wildflowers.\nSeeing, smelling, identifying and just being amid native wildflowers are on my list of my favorite outdoor pursuits in Nebraska’s landscape.\nAnd you know what? Those wildflowers are more important than ever! No, scratch that. Indirectly, those native wildflowers are vital to all life on our planet Earth!\nAllow me to explain.\nFor one out of every three bites of food you eat, you need to thank a bee, butterfly, beetle, ant, wasp, bat, bird or other animal transferring pollen from one native wildflower to another!\nIn fact, these animals on the hunt for nectar, pollen or other floral rewards provide pollination services critical to fruit, nut and seed production, and moreover, for nearly three-quarters of the staple crop plants that feed human kind and for more than 75% of all flowering plants in the world!\nPollinators and their habitat contribute substantially to the U.S. economy and are vital to keeping fruits, nuts and vegetables in our diets. In the U.S., pollination produces almost $20 billion worth of products annually.\nNot only is pollinator habitat good for the bees, butterflies, bats, beetles and even small mammals but pollinator habitat is also excellent brood rearing habitat for pheasants, quail and grassland songbirds. Pollinator habitat – native flowering plants – attract soft-bodied insects that pheasant chicks, and other ground-nesting chicks, rely on for survival during the first 6-8 weeks of life.\nMonica Macoubrie, Wildlife Outdoor Education Specialist at the Nebraska Game and Parks Commission, said, “Pollinators are essential not only for plants, but are keystone species that help many other types of animals. If they disappear, we will lose a lot of the other animals that we enjoy seeing.”\nYes, there is a problem, a major problem. There continues to be a reduction in abundance of insect and other animal pollinators in many ecosystems worldwide due to habitat loss and the floral diversity of plants, as well as pesticides, herbicides, insecticides, pests, diseases, invasive species and climate change among other issues.\nMonarch butterfly populations have decreased dramatically in the last 20 years, while many commercial honeybee keepers are experiencing noticeable losses annually.\nWith National Pollinator Week coming up on the calendar from June 22-28, it is time once again to draw attention to the cycle and plight of these pollinators, and the diverse habitat they need to survive with native wildflowers having a huge impact. In honor of the role pollinators play in Nebraska’s economy and ecosystems, Gov. Pete Ricketts has proclaimed June 22-28, 2020, Nebraska Pollinator Week.\nIt is also a good time to ask each of ourselves this question: What have I personally done to help the pollinator problem, if anything?\nI am proud to say that I have done my part to develop a beautiful array of beneficial native wildflowers in the grassland acres on my brother’s southeast Nebraska farm that I help him manage. I have also assisted pollinators in my backyard with targeted wildflower plantings.\nMacoubrie pointed out that anyone can help pollinators. “Whether you live in a house, a rural area, or even an apartment, there is something that you can do for pollinators.”\n“As a Nebraskan, you can join the Nebraska Pollinator Week 2020 Challenge, head outside, look for pollinators, and be a part of a national citizen science program,” Macoubrie added.\nTo enter the challenge, visit nebraskapollinatorweek.org and complete the commitment form. Participants will be sent a package of pollinator resources. Participants then should head outside to look for pollinators and enter at least five species they find on iNaturalist, a web-based citizen science program.\nIn addition, the Nebraska Pollinator Week website also contains free resources, tutorials, lesson plans, and information about Nebraska pollinators. Discover more at nebraskapollinatorweek.org.\nHere are some other ways you can help the plight of the pollinators when it comes to native flower habitat:\n- Establish a diversity of plants native to your region.\n- Check out incentives for planting wildflower seed mixes in the USDA’s Conservation Reserve Program (CRP) or other habitat-related program.\n- Avoid using harmful pesticides, herbicides and insecticides.\n- Provide connected habitat of trees, shrubs, and perennials on your farm, ranch, and acreage or in your lawn or lot.\n- If you plant non-native plants, make certain they are not invasive. Remember that pollinators do not always use cultivars. For example, flowers that have many more petals than normal might not be accessible by the pollinators that would have visited the original native species. Likewise, nectar and pollen in cultivars might be altered enough to be no longer attractive to pollinators.\n- Have a water source that allows small pollinators to drink safely near plantings of native flowers.\n- Plan for blooms throughout the seasons. For example, Redbuds are early bloomers, while Goldenrods Gayfeathers and others bloom right up into November. Of course, many wildflowers and perennials bloom right through spring and summer!\n- Leave some bare patches of earth for digger bees, and set out bee boxes — help keep the cycle of pollinators going!\n- If you can, provide moist dirt areas by flower patches to invite butterfly puddling.\n- Keep a little untidiness in flowerbeds or natural areas — this provides shelter for pollinators!\n- Plant caterpillar host plants like the Milkweed. Monarch butterflies cannot survive without Milkweed; their caterpillars only eat Milkweed plants. Milkweeds are also a host plant for other specialized insects, and a nectar source for many pollinators.\nFor more information about pollinators, visit the Nebraska Game and Parks Commission website at www.OutdoorNebraska.gov","If you drive through California’s central valley in the next month, you will see and smell the incredible expanses of almond blooms. Carson & Bees is pollinating orchards in Williams, which helps the business and also helps the hives bulk up for the coming spring and summer honey-making season.\nHere’s a funny and timely article about the different pronunciations of California’s favorite nut: http://kvpr.org/post/i-say-almond-you-say-am-end-whos-right\nWe get a lot of questions about the quality of honey sold in grocery stores, and also people wondering why we charge so much more than what you can buy in a store. Here’s an interesting article on honey adulteration to answer some of those common questions:\nIt’s also worth noting that California honey tends to be more expensive than other regions of the country since we get so little rain in late spring and summer. Rain = flower nectar = honey production.\nCascadian Farms is the organic branch of General Mills, which represents 3% of the company’s total sales. Although as a major food producer General Mills uses a lot of pesticide – which has been directly linked to declining pollinator populations – a new campaign started by the Cascadian Farm branch called “Bee Friendlier” is an encouraging step in the right direction.\nAlthough the #1 thing you can do to help pollinators is plant flowers, they have to be organic! These days most everything is treated – often at the seed level – with pesticide. The pollen the bees gather is poisoned by the pesticide the plant’s seed was rolled in (or sprayed in the large warehouse nursery where it was born). The only surefire way to help and not further hinder pollinators is to plant seeds whose packaging clearly states that zero treatment has been applied.\nIt’s easy to demonize companies like General Mills for being huge food conglomerates that use pesticides, pay low wages, and destroy the land. But GM and companies like it are products of society, and they directly reflect consumer’s demands: Americans want abundant and cheap food, so the current food system is built accordingly. Now, however, we’re taking a collective pause to reexamine the implications of valuing cost over everything else, and there’s a slow but steady sea change happening.\nThis “bee friendlier” campaign is a part of that sea change. And so are we! Each of us decides what the system looks like based on where we spend our money. In Ukiah we’re blessed with a year-round farmers’ market, a socially conscious co-op, and a Friedman’s that carries organic seeds. If you could spend 10% of your food budget on local producers, plus a few dollars a year to plant organic flower seeds, you’ll make a bigger impact than you realize on the food system AND the health of your friendly backyard pollinators.\nIt’s no secret that bees are in trouble. All around the world, people are mobilizing to try to do something about it: hundreds of studies and thousands of people are focusing on how to help alleviate the stresses that are causing native and commercial bees alike to die off in alarming numbers. Europe has taken an important step in banning neonicotinoid pesticides, but here in the U.S. we aren’t doing as well. To wit:\nPesticide giant Syngenta just asked the EPA to raise the “acceptable” level for neonic residues by 40,000%. Say what??\nSyngenta is arguing that they need the increase so they can spray it rather than coat the seed in it, which might actually be good for bees – seed treatments affect the entire plant, whereas sprays “should” stick to the leaf. The big caveat here is that, for this to actually work for bees, it couldn’t be administered when the crop was flowering, nor while any other plant was flowering nearby. I personally have zero confidence in that scenario playing out – what does a Big Ag farmer care about some weeds flowering in his ditches? (Not to mention these crops are often sprayed while flowering anyway, despite very clear labels prohibiting it.)\nSo, what can we do? Three things.\n1) Submit a public comment to the EPA. Go here: http://www.regulations.gov, and in the search field enter the docket number EPA–HQ–OPP–2014–0008. Several seemingly identical search results are returned; click “comment now” on the uppermost one. The comment period closes on October 6.\n3) Buy organic seeds and plants. These days, even plants marked “bee friendly” are likely to have been treated with a pesticide, which creates toxic pollen. The only surefire way to provide SAFE forage is to buy organic.\nThanks for everything you do to help our pollinators!\nDid you know that June 16-22 is National Pollinator Week? It began seven years ago by a proclamation from the U.S. Congress, and is organized by the Pollinator Partnership. It is used as a time to bring awareness to bees, birds, butterflies, and bats.\nHere’s a fun fact: there are over 25,000 species of bees in the world. Most of them are solitary and live in the ground, making the honey bee’s “superorganism” style of living collectively rather rare. Here’s a sad fact: pretty much all of them are threatened.\nIn honor of pollinator week, we invite you to find a moment this weekend to stop and watch a bee at work. Find a flowery area and look closely at all the activity; you might be surprised by how many different types of bees you’ll see on the same bush.\nAlso, Carson & Bees will be giving out free sunflower seed packets – pollinated by our bees last year! – at the Redwood Valley Farmers Market this Sunday, June 22, from 9:30-12:30 at Lion’s Park. Come say hello.\nOn this gorgeous mother’s day, we here at Carson & Bees are moved by the flowers in bloom. With spring in full force there’s no time like the present to think about what bees and other pollinators eat, and that it’s all of our jobs to feed them.\nThere’s a wonderful blog called Honey Bee Suite. Blogmaster/beekeeper Rusty frequently posts about attracting pollinators to your yard, and I’m reposting one of those here. She disseminates her impressive knowledge in easy-to-digest and often humorous posts, so if you enjoy reading about bees I highly recommend you mosey on over to her side of the web.\nHere are fifteen easy ways to assure you will have a plentiful supply of pollinators all season long.\nPlant clover in your lawn. White Dutch clover planted in your lawn will attract dozens of pollinators. In addition, it fixes atmospheric nitrogen into a form the grass can use, resulting in a beautiful green lawn without the use of chemical fertilizers.\nPlant at least some native species. Native plants attract native pollinators. Check with your local extension office if you are unsure of what is native.\nPlant herbs. Herbs, especially those in the mint family, are very attractive to pollinators. This family includes thyme, oregano, sage, basil, peppermint, lavender, catnip and rosemary. As an added bonus, you get to use the herbs yourself.\nSelect plants with a wide range of bloom times. Native bees need food from spring until fall so plan to have something in bloom all season long.\nPlant larval host plants. Some plants are not considered especially attractive in the garden but are necessary to certain species of pollinators. Milkweed, for instance, is vital to the larval stages of Monarch butterflies. Plant them in an inconspicuous place if you prefer, but have them available for the pollinators.\nAvoid hybrid varieties. Many flowers that have been bread for beauty have lost the nectar or pollen that made them valuable to pollinators. Plants with double or triple rings of petals, or plants with unusual colors or variegated patterns are probably over-hybridized.\nLeave open patches of mud. Many ground-nesting bees need open patches of mud for their homes or for building materials.\nProvide a water source. It doesn’t need to be large or fancy. Just a wet spot under the end of a hose can help the insects.\nAvoid excessive mulch. Too much mulch blocks entry to the ground. Ground-burrowing insects often cannot penetrate a heavy layer of mulch.\nAdd sea salt or wood ash to a bare patch of earth. Pollinators are often seen collecting minerals from salty or ashy areas. Your patch needn’t be large and it shouldn’t be overworked. If the insects need it, they will find it.\nProvide nesting sites. Collections of reeds or holes drilled in blocks of wood provide great nesting sites. Tubes or blocks should be replaced periodically to limit disease build-up.\nLeave dead trees and reeds standing. If a dead tree can safely be allowed to stand, it should be left as habit for bees, birds, and small rodents. Dead and standing reeds are a favorite of wild bees.\nLeave an unmowed patch of grass and weeds in a protected spot. Tall grass provides protection, shade, and hunting grounds for many species of pollinators. Some pollinators—such as hover flies—feed on insects as well as nectar, so they do best in a place that provides an alternate food source.\nPut a flower pot on every porch . . . and encourage your friends to do the same. The more plants that are available, the healthier our pollinators will be.\nUse no pesticides. Until we reduce dependence on pesticides, items 1-14 are all for naught."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:ce527e4f-5853-43aa-8aeb-a9ac9f83dc15>","<urn:uuid:b7d0c30a-25f9-431a-b8be-449f3d8fb442>"],"error":null}
{"question":"I need help understanding how long symptoms last in chronic pain versus persistent depressive disorder. What is considered chronic in each case?","answer":"For chronic pain, symptoms that last longer than six months are considered chronic, and they may not go away. In contrast, for Persistent Depressive Disorder (PDD), symptoms must be present nearly every day for at least 2 years in adults (1 year for children or teens) to receive a diagnosis. In both conditions, symptoms tend to be long-lasting and can significantly impact quality of life. With PDD, someone may experience periods where symptoms subside, but they won't be free of symptoms for more than 2 months at a time. Similarly, with chronic pain, the ongoing signal continues to affect the nervous system and increases its reactivity to incoming messages, creating a persistent condition that requires long-term management.","context":["Recent Blog Articles\nPouring from an empty cup? Three ways to refill emotionally\nGive praise to the elbow: A bending, twisting marvel\nSneezy and dopey? Seasonal allergies and your brain\nThe FDA relaxes restrictions on blood donation\nApps to accelerometers: Can technology improve mental health in older adults?\nSwimming and skin: What to know if a child has eczema\nA muscle-building obsession in boys: What to know and do\nNatural disasters strike everywhere: Ways to help protect your health\nDementia: Coping with common, sometimes distressing behaviors\nScreening tests may save lives — so when is it time to stop?\nHarvard Health Blog\nI’m in pain, so why is my doctor suggesting a psychologist?\n- By Salim Zerriny, MD, Contributor, and\n- David Boyce, MD, Contributor\nPain makes us human. It is a bell, fine-tuned by evolution, that often rings in moments necessary for our survival. Because of pain, we can receive warnings that trigger the reflexes to escape potential danger.\nBut what happens when that bell continues to ring? How do we respond to a signal when it interferes with the other elements that make us human?\nPain that lasts longer than six months is considered chronic, and it may not go away. With chronic pain, the bell’s ongoing signal gets your nervous system wound up and increases its reactivity to incoming messages. This can be quite distressing and anxiety-provoking. Additionally, the feelings of frustration or sadness when pain doesn’t go away can make pain worse.\nWhat’s the link between emotion and my perception of pain?\nPain, depression, and anxiety travel through similar pathways along your nervous system and share many of the same biological mechanisms. One of the areas in the brain that receives pain signals — specifically, the limbic region — shares many of the same messengers as the mood signals. We know from research studies using neuroimaging that the parts of the brain controlling emotion and sensory features of pain are altered in people with chronic pain.\nThe connection between pain and emotion can also be seen with certain classes of medications. For example, some medications used to treat pain can cause side effects like euphoria, and medications originally developed for psychiatric conditions can be effective treatments for certain types of pain.\nThe medical community has come to appreciate a direct correlation between improvement in one’s emotional well-being and their experience of pain (and vice versa). Chronic pain increases the risk of depression and anxiety, and depression and anxiety strongly predict the development of chronic pain. This association is seen in conditions like fibromyalgia and irritable bowel syndrome, where behavioral and psychological treatment strategies have shown benefit in reducing symptoms.\nWhat can a psychologist help me address?\n- Pain catastrophizing: This is when you magnify the negative effects of pain and focus on feelings of helplessness while ruminating about the presence of pain in your life. Negative thoughts and beliefs about pain often lead to worsened emotional and social functioning and a decreased response to medical interventions for pain.\n- Fear of pain: Concern or worry about an injury drives avoidant or protective behaviors. The anticipation of an increased sensation of pain may limit you from engaging in physical activity or attending social outings. Pain-avoidant behaviors can lead to physical deconditioning and further decreased quality of life.\n- Pain acceptance: This is a challenging, but highly effective technique focused on developing an accepting attitude towards the pain. It involves doing your best to nonjudgmentally acknowledge the presence of pain and minimize unhelpful thoughts and behaviors that won’t make pain better.\n- Trauma: The link between prior trauma and chronic pain is becoming better understood. Psychological therapies can address ongoing physical and emotional stress responses linked to traumatic experiences.\nWhat type of therapies help with chronic pain?\nThere are multiple psychotherapeutic treatment options commonly used to help people manage chronic pain. Practicing meditation and becoming as active as possible have been shown to be effective methods that can be done on your own. Mental health professionals who specialize in working with people in pain can guide you with additional evidence-based treatments:\n- Cognitive behavioral therapy (CBT): talk therapy that helps to change your thoughts and behaviors related to pain and improve coping strategies. You can learn CBT techniques with a psychologist or as part of a therapeutic group, which may also provide a support network.\n- Mindfulness-based stress reduction (MBSR): a form of mediation where you learn to nonjudgmentally become aware of your thoughts and feelings and accept pain and other uncomfortable sensations as neither positive nor negative.\n- Hypnosis for pain (hypno-analgesia): a set of techniques intended to modify your thoughts, feelings and behaviors via subconscious suggestions aimed at altering your experience of pain. Hypno-analgesia differs from CBT, which is a conscious recognition of your emotions related to pain and a more self-directed, action-oriented approach.\n- Biofeedback: a technique where your body functions such as heart rate, muscle tension, and skin temperature are monitored to make you aware of your involuntary responses to stress. During biofeedback sessions you learn a variety of ways to control your physical reactions to stress and anxiety.\nWhere can you find help to manage the emotional aspects of pain?\nIt is always recommended that you have a primary care physician coordinating your care, and you doctor may be able to provide you with a referral to a pain specialist or psychologist. It is worth finding out what mental health services your health insurance covers as you navigate this process.\nAdditional resources for finding specialists in your area:\nAmerican Chronic Pain Association\nAmerican Pain Society\nWill my pain ever go away?\nThis question is surely at the top of every person’s mind if they are in pain. The difficulty in answering this stems from the variety and types of chronic pain syndromes, as well as individual variability. What has been shown to make a difference in people managing chronic pain is trying a variety of approaches, such as cognitive and behavioral techniques, staying active, practicing meditation, and working with your doctor to find effective medical and procedural interventions. The more of these interventions you try, the more likely you will find something that makes a positive impact.\nThe challenges of coping with a chronic pain condition cannot be understated. The negative emotions that come from it can be self-perpetuating, as one’s feelings of pain can lead to depression, and that very depression can lead to worsening pain. In coping with this cycle, the goal is to take whatever steps are possible to continue to lead a fulfilling life, including getting emotional and social support.\nOur understanding of pain continues to evolve, and with it may come improved personalized treatments and better understanding of chronic pain’s influence on the body and mind.\nAbout the Authors\nSalim Zerriny, MD, Contributor\nDavid Boyce, MD, Contributor\nAs a service to our readers, Harvard Health Publishing provides access to our library of archived content. Please note the date of last review or update on all articles.\nNo content on this site, regardless of date, should ever be used as a substitute for direct medical advice from your doctor or other qualified clinician.\nYou might also be interested in…\nPain Relief Without Drugs or Surgery\nPain relief takes many forms. This Special Health Report, Pain Relief Without Drugs or Surgery, looks beyond the standard approaches of drugs and surgery and explores alternate pain-relief strategies, from acupuncture and mind-body therapies to spinal manipulation, physical and occupational therapies, herbal remedies, mindfulness meditation, and music therapy among others. The report also provides specific treatments for 10 common pain conditions.\nFree Healthbeat Signup\nGet the latest in health news delivered to your inbox!","Mental Health and Conditions\nPersistent Depressive Disorder (PDD)\nTHC Editorial Team January 20, 2021\n- Symptoms of Persistent Depressive Disorder\n- Causes and Risk Factors of Persistent Depressive Disorder\n- How Is Persistent Depressive Disorder Diagnosed?\n- Treatments for Persistent Depressive Disorder\nWhat Is Persistent Depressive Disorder (PDD)?\nPersistent depressive disorder (PDD), also called dysthymia, is a low-level, chronic form of depression. Because this condition is ongoing, people with PDD tend to have no positive emotional point of reference for comparison and therefore may view their constant, low levels of depression as normal.\nAlthough PDD symptoms may not be as severe as those of major depression, the long-lasting nature of PDD tends to affect people’s overall quality of life. Someone with this condition may appear persistently gloomy, negative, or unable to enjoy life. PDD can affect an individual’s ability to engage in school, work, or other social situations.\nThis type of depression is a new entry in the most recent version of the American Psychiatric Association’s Diagnostic and Statistical Manual of Mental Disorders (5th edition; DSM-5). The PDD diagnosis was created by combining two former diagnoses—chronic major depression and dysthymic disorder—because it was established that there were no significant differences between the two conditions.1 Roughly 1.3% of adults in the United States will experience PDD at some point in their lives.2\nWhat Are the Symptoms of Persistent Depressive Disorder?\nSymptoms can begin at any age, but they often begin by or before early adulthood.1 At early stages, they may be subtle and often remain unnoticed by the individuals themselves. If symptoms begin during childhood or adolescence, they are more likely to be expressed as persistent irritability or negativity and may affect the individual’s functioning in school and social settings.3\nAlthough some symptoms are shared by most people with PDD, not every person will experience the same symptoms at all times. Symptoms tend to appear, subside, and recur. However, someone with PDD will not be free of symptoms for more than 2 months at a time.3 With PDD, chronic feelings of depression will be accompanied by at least two of the following long-term symptoms:1,3\n- feelings of hopelessness\n- pessimistic attitude\n- sleeping too much or too little\n- trouble concentrating\n- low self-esteem\n- lack of energy\n- changes in appetite resulting in weight loss or gain\n- difficulty making decisions\n- loss of interest in normal activities\n- decreased productivity\nBecause people with PDD live with symptoms for so long, they may be unaware of their condition; their symptoms may become normalized. When this occurs, people close to affected individuals may need to raise the issue with them and discuss possibilities for seeking help.\nPersistent Depressive Disorder and Co-occurring Disorders\nPDD may occur on its own or with another mental health condition. Those with PDD often develop anxiety, and they are also at an increased risk of developing a substance use disorder.4 Additionally, in the United States, 75% of the people diagnosed with this mood disorder are likely to experience a major depressive episode.5 This is often called double depression. However, unlike others who experience a major depressive episode, people with PDD will continue to experience typical symptoms associated with PDD once the episode has passed.\nCauses and Risk Factors for Persistent Depressive Disorder\nA combination of factors likely contributes to PDD, but its exact cause is unknown.1 Factors that trigger PDD include biological differences resulting in physical changes in the brain, imbalances in certain neurotransmitters that affect brain chemistry, genetic traits that occur in families, and traumatic life events.3\nResearch indicates that certain factors could increase a person’s risk of developing PDD. These include having a close relative with a depressive disorder, experiencing a traumatic life event or excessive stress, and having a history of other mental conditions.3\nHow Is Persistent Depressive Disorder Diagnosed?\nTo detect the presence of PDD, physical tests are conducted primarily to rule out other medical conditions, such as complete blood count; chemistry panels; urine, pregnancy, and hormone tests; and urine toxicology.1 Additionally, a psychiatric evaluation consisting of validated screening tools and questionnaires for depression is carried out. Current and past medical history and current medications are discussed as well.1\nDiagnosis requires an interview in which a clinician will assess the duration and severity of a patient’s symptoms. For a patient to be diagnosed with PDD, their symptoms must be present nearly every day for a period of at least 2 years for adults and 1 year for children or teens.\nBecause of stigma, some people may be reluctant to discuss mental health issues with their healthcare providers. Their physicians should reassure them that such conditions are common and that appropriate treatment will improve their quality of life.\nAdditionally, people with depression symptoms do not have to wait for 2 years to seek help. Treatments for other types of depression and related symptoms are effective even without a specific diagnosis of PDD.6\nTreatments for Persistent Depressive Disorder\nA combination of medication and psychotherapy is considered the gold standard for treatment of PDD. However, affected individuals often benefit from long-term continuation and maintenance therapy because of the strong chance of relapse associated with PDD due to its long-lasting nature.7 Additionally, certain lifestyle changes have been shown to be helpful for individuals with PDD.\nAntidepressants, such as selective serotonin reuptake inhibitors (SSRIs), serotonin-norepinephrine reuptake inhibitors (SNRIs), serotonin antagonist and reuptake inhibitors (SARIs), tricyclic antidepressants, and monoamine oxidase inhibitors (MAOIs), are commonly used to treat PDD.7 In some cases, certain antipsychotic medications have also been shown to be effective in treatment.7 It is important for patients to take medications as prescribed and not to cease treatment without a doctor’s approval. Because PDD is chronic, those affected may need to take medication long term. Also, depending on the medication, patients may need to avoid certain foods or herbs to reduce the risk of interactions or side effects.\nCognitive behavioral therapy (CBT) and psychodynamic therapy have been found to effectively treat and alleviate the symptoms of PDD.7 These types of therapies help people learn how to identify triggers that make symptoms worse, develop coping strategies in times of stress, and prevent symptoms from recurring.\nMost therapists will recommend that patients eat a healthy and balanced diet and avoid alcohol and other harmful substances that could make symptoms worse. Additionally, regular exercise has been shown to reduce symptoms of depression and is an important component of long-term self-care.3"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:d65bef8a-dbf9-4914-a60f-278c5d03e2f8>","<urn:uuid:d64c96b0-d586-4789-9969-4a69ed92d9e2>"],"error":null}
{"question":"个人辐射探测器和PicoR-Bio在安全检查应用中，哪个设备对操作人员的活动限制更大？求详细对比分析！","answer":"The PicoR-Bio has significantly more restrictions on operator movement than the Personal Radiation Detector (PRD). The PicoR-Bio requires the operator to maintain maximum possible distance from the device and avoid significant movements due to its high sensitivity - operator movements can create false readings. In contrast, the PRD is specifically designed to be worn on the belt and used while moving, allowing security personnel like customs agents and first responders to perform their duties normally while conducting passive screening. The PRD can be used casually without movement restrictions, making it ideal for security officers on airplanes, subways, and at public events where mobility is essential.","context":["Exploring settings where sensitive detection can make a difference.\nPreviously, we discussed the basics of sensitive radiation detection using the Personal Radiation Detector. Below are a few scenarios to illustrate how this kind of device can be used either on its own or as part of a larger radiation security plan. Since the PRD is a small, easily used instrument for detecting low levels of radiation, it excels in a variety of settings where radiation safety and security are a concern.\nOne of the most basic applications for a Personal Radiation Detector is a unit clipped to the belt of first responder, like a police officer, firefighter, or hazmat team member. A small detector can be attached to their belt, set in active search mode, and will quietly look for any faint traces of radioactive material. The main goal in this type of scenario is to provide a first alert to the presence of radioactive material, where it’s located, and potentially the strength of the source. This information can then be evaluated so that the second wave of responders are appropriately equipped, or even trigger the deployment of more specialized teams with more sophisticated equipment.\nIn the event of a radiological incident, such as a dirty bomb or an accident at a nuclear facility, the Personal Radiation Detector takes a back seat to more traditional survey equipment. However, despite being a more sensitive, low range device, it is still useful in establishing safe zones and in monitoring the boundaries of the affected area. This is especially valuable at established checkpoints for relief workers entering and exiting the incident zone.\nCustoms and Border Protection\nAnother common function for this type of device is in the hands of a Customs agent, either at an airport or a border control station. In addition to the usual Customs inspection for undeclared items, contraband, and other “typical” smuggled materials, they are frequently equipped with Personal Radiation Detectors as a security measure to ensure that neither people coming into the country, nor their baggage, contains radioactive material.\nIn this scenario, the Customs agent would be equipped with the PRDs clipped to their belt as a passive, stealthy monitoring device. Should anything register on the PRD, that person or piece of baggage could then be directed to a secondary screening station. Here, someone with a more sensitive device (an identifier, most likely) will be there to do a more thorough scan to determine if it’s something relatively innocent and explainable, like a medical isotope, or something of more immediate concern.\nThe role of the Personal Radiation Detector as a “first layer” of a larger screening process is common, and one where they tend to excel. They can easily be worn and used without alerting the public. This feature is very valuable for security officers on board airplanes, subways and passenger trains. They can very casually perform a first pass scan of other passengers and goods, and alert agents at screening stations at the destination to which individuals or baggage need to be pulled aside for further investigation or screening.\nThey also work well when paired with large-scale vehicle monitors or cargo container monitors, helping narrow down the exact location of detected material inside a larger space. In this setting, a PRD would act as a refined search tool, sweeping a car trunk, trailer or passenger compartment to find out exactly where a radioactive source might be hidden or secured.\nPart of a Complete Radiation Security Program\nThe ultimate evolution of this strategy sees the PRD integrated into a full radiation security program. Large public events, such as political conferences, festivals, or sporting events like the World Cup, where hundreds or even thousands of people will be passing through in a single day, provide a serious challenge. In this type of setting, the Personal Radiation Detector, worn by security personnel, works well in conjunction with stationary walk-by area monitors to identify potential threats or people that warrant further investigation, who can be directed to secondary screening points where they can be cleared through large-scale portal monitors and hand held identifiers.\nThe Personal Radiation Detector is a versatile device for radiation security, scalable for use from the most common, everyday scenarios to the largest, special case, situations of most concern.\nThey are designed with early detection and prevention in mind, and work very well in the roles described above, as the first barrier to entry for radiological threats.","Through-Wall Imaging device PicoR-Bio\nThrough-Wall Imaging device for motion detection over obstacles PicoR-Bio is designed to detect people over the walls, under the rubble and any optically opaque barriers (walls and floors of buildings, including concrete slabs, unlit rooms, piles of building materials, damaged structures and rock avalanches, etc.), both moving and stationary (by wiggling and breathing). The device allows the operator to see people in the room “through walls” to determine the distance to them in real time, also the operator can see whether they are moving or not.\nAreas of application:\n- detection of people behind walls, in rooms with closed doors for the assault teams of police, army, secret services, for intelligence;\n- detection of people under the rubble of buildings, snow avalanches caused by earthquakes and disasters.\nThe PicoR-Bio device was tested together with the Russian Ministry of Emergency Situations to detect people under the rubble caused by earthquakes and technogenic disasters. Together with the EMERCOM it has developed recommendations for the use of a mobile radar system detecting victims in the rubble. It was obtained a number of patents on the device, software, and methods of using it.\nThis device is connected to a PC (with Windows OS) via USB cable. The operator using SKI-Bio software can control the device parameters and see objects detected on a radargram in a real-time. Software also allows to record any signal for further analysis.\nPicoR-Bio is fully safe for the operator and detected objects. Its radiated power distributed in a wide frequency range is extremely small. During its work the device does not interfere with other radio equipment and is immune to interference itself.\nThe device has the ability to work pressed to or spaced from the wall or rubble surface.\nPicoR-Bio device uses ultrashort pulses of radio waves with high performance penetration through walls and floors (made of standard building materials, including bricks, blocks, concrete floors, including concrete, wood eams, plaster, wallpaper, as well as office furniture, glass, etc.) The only screening material is metal barriers.\nThe device comprises:\n- antenna module PicoR-2;\n- portable computer such as a laptop or a tablet PC based on Windows OS with the SKI-Bio software;\n- USB cable for data transmission and power of antenna module.\nAlso the device can be equipped with an optional unit anchor the computer to the operator's body.\nThe operation principle of the device is that the operator directs the antenna module to the wall (optimally pressed to the wall to reduce the signal reflected from it). Then he visually observe on the computer screen changes in the radiogram of the reflected signal when objects move behind the wall.\nOne of the conditions for correct device operation is no significant movements of objects in the rear hemisphere pattern of its antennas because due to its very high sensitivity the device may show operator movements as well. Therefore the operator should be on the maximum possible distance from the device, over some obstacles or not making any significant movements. In such cases \"false\" acquired data is easy to identify and ignore.\nTo verify and adjust the device, surveillance cameras can be placed in rooms, which are being scanned by the device. Thus you can always check the information being showed on the device and train the operator to interpret the radargramm data.\nKey benefits of Through-Wall Imaging device PicoR-Bio:\n- reliable detection of humans behind the walls and rubble of any standard building materials;\n- separate detection of objects in vicinity of each other (at a distance of 0.5 m);\n- simultaneous moving and stationary objects detection;\n- user-friendly interface that provides control of device parameters and intuitive interpretation the radargramm;\n- the ability to work pressed to or spaced from the wall;\n- immunity to interference and safety;\n- maximum object detection range - 20 m, no \"dead zones\";\n- product price is several times lower than other market offers.\n|Operating range with the possibility of the reference shift||up to 20 m|\n|Thickness of brick wall over which the person is detected||not less than 0,8 m|\n|Building materials through which the device can work||brick, concrete, reinforced concrete, stone, stucco wall, drywall, etc.|\n|Angle of view||60 deg. in the horizontal plane,\n80 deg. in the vertical plane\n|Size of antenna module||410 x 270 x 68 mm|\n|Weight of antenna module||1,8 kg|\n|Battery life (using tablet PC)||4 hours|\n|Operating temperature range||-20 ... +50 degrees|\n|Ingress protection of antenna module||IP66|\nDetection characteristics over obstacles\n(experimental and calculated data):\n|Building material||Thickness||Movements detection||Breathing/wiggling detection|\n|Air||-||20 m||7 m|\n|Reinforced concrete slab||25 cm||7 m||2 m|\n|Dense concrete||50 cm||1 m||-|\n|Double glazed windows||1 cm||5 m||1,5 m|\n|Brick||40 cm||7 m||2,5 m|\n|Sand||90 cm||5 m||1,5 m|\n|Snow (when coming avalanche)||3 m||3 m|\nPrice: on request"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:7c999743-8cc8-4a07-9939-331e811b97fd>","<urn:uuid:76b0cc81-915b-4830-bc8c-dd15d4f1f748>"],"error":null}
{"question":"What role does eye-tracking play in autism research, and how does virtual delivery affect behavioral assessment methods?","answer":"Eye-tracking is used to investigate visual orientation towards social stimuli in children with autism, serving as a research tool for understanding social development. When it comes to virtual delivery of assessments, the ability to observe behavioral cues is limited as teletherapy makes it more difficult for practitioners to pick up on nonverbal cues, which can impact the accuracy of clinical assessments.","context":["Dr. Paulina Buffle is a Research Associate in the Laboratory of Sensori-Motor Affective and Social Development at the University of Geneva. Her career as a scientist is driven by a particular interest in promoting early identification and intervention in young children with Autism Spectrum Disorder (ASD) and other neurodevelopmental disorders.\nDr. Buffle’s research involves Eye-tracking and behavioral paradigms in order to investigate visual orientation towards social stimuli in children, as well as participatory research to optimize and customize ASD detection procedures and case-management in pediatric settings.\nHer diverse clinical and research training, as well as exposure to different cultures during her professional practice, have raised interest in the cultural factor’s impact on ASD identification and intervention's processes (Autism in a Global Context). During her stay in Ecuador, Dr. Buffle has worked towards understanding the perceptions of autism symptoms in mainstream and professional settings. She has also disseminated knowledge on different evidence-based practices. She is currently working to understand the adaptability of early intervention in group contexts, as well as on the use of telehealth methods to improve access to services for individuals with ASD and their families.\nFluent in French, Spanish, and English, she is currently leading different projects in Switzerland and Ecuador.\nAdditionally, she is a certified professional in ADOS-2 and ADI-R, trained in different neuropsychological and developmental batteries, and provides clinical consultation in different countries.\nKeywords: Autism, ASD Diagnosis, ASD Intervention, Eye-tracking, Telehealth, Pediatric settings, Neurodevelopmental Disorders, Autismo en Ecuador, Autism in a Global Context.\nPalabras clave: Autismo, Diagnóstico, Intervención, Eye-tracking, Telemedicina, Contextos Pediátricos, Trastornos del Neurodesarrollo, Telesalud, Autismo en Ecuador, Autismo en un Contexto Global.\nLaboratory of Sensorimotor, Affective and Social Development (SMAS)\nUniversité de Genève\nUni Mail, 40 Boulevard du Pont-d'Arve\n1211 Genève 4\nPublication in scientific journals\nBuffle, P., Gentaz, E., & Vivanti, G. (2022). Perception, beliefs and causal attribution of autism early signs in Ecuadorian general population. Frontiers in Psychology, 3715. https://doi.org/10.3389/fpsyg.2022.915817\nBuffle, P., Naranjo, A., Gentaz, E., & Vivanti, G. (2022). Experiences and Attitudes on Early Identification Practices of Autism: A Preliminary Survey of Pediatric Professionals in Ecuador. Children, 9(2), 123.\nBuffle, P., & Naranjo, D. (2021). Identificación y diagnóstico tempranos del trastorno del espectro autista: una revisión de la literatura sobre recomendaciones basadas en la evidencia. [Early identification and diagnosis of autism spectrum disorder: a literature review on evidence-based recommendations: Narrative Review.] Ecuadorian Journal of Pediatrics, 22(3), Article 23:1-19. https://doi.org/10.52011/113\nBuffle, P., Cavadini, T., Posada, A., & Gentaz, E. (2021). A study on visual preference for social stimuli in typical Ecuadorian preschoolers as a contribution to the identification of autism risk factors. Scientific Reports, 11(1), 1-10. https://doi.org/10.1038/s41598-021-87888-3\nDukes, D., Van Herwegen, J., Alessandri, M., Bölte, S., Buffle, P., … Samson, A. C. (2021). February 16). Introducing the COVID-19 crisis Special Education Needs Coping Survey. https://doi.org/10.31234/osf.io/rtswa\nBuffle, P. (2020). Autism in Ecuador, in Volkmar F. Ed., The Encyclopaedia of Autism, NY, Springer. https://doi.org/10.1007/978-1-4614-6435-8_102532-1\nLejeune, F., Gentaz, E. (2017). El niño prematuro, desarrollo cognitivo y emocional. Translated by Paulina Buffle, Asociación Ecuatoriana de Pediatría.\nBuffle P., Gentaz E., (2019). Perception of autism screening tools in paediatric contexts: An exploratory study in an Ecuadorian sample. International Society for Autism Research (INSAR) Regional Meeting, Puerto Varas, Chile.\n3 questions à Paulina Buffle, docteur associée au BabyLab à l'UNIGE | Radio Lac, 11.10.2021\nAreas of interest and expertise\n- Autism Spectrum Disorders early diagnosis and intervention\n- Validation of culturally adapted tools of screening and diagnosis of autism\n- Use of Eye-Tracking for the evaluation of socio-cognitive abilities in clinical and typical populations\n- Telehealth for evaluation of certain aspects of neurodevelopmental disorders\n- Telehealth for families of individuals with neurodevelopmental disorders\n- Socio-cognitive development in typical and clinical populations\n- Neuro-cognitive development of individuals with autism\n- Neuro-cognitive development of pre-term new-born children\n- French, Spanish, English (fluent)\n- Italian, Portuguese (working knowledge)\n- German (basic school knowledge)","Teletherapy, or therapy conducted through videoconferencing or phone, has become increasingly popular in recent years, especially during the COVID-19 pandemic. As a result, many psychologists and psychotherapists may wonder whether teletherapy is as effective as traditional, in-person therapy. In this blog post, we will explore the research on the effectiveness of teletherapy and consider its benefits and limitations.\nThe Research on Teletherapy\nResearch on the effectiveness of teletherapy has been growing in recent years, and the findings suggest that it can be as effective as traditional, in-person therapy for many clients. A meta-analysis of 39 studies on the effectiveness of teletherapy for the treatment of mental health conditions found that it was as effective as traditional therapy for a range of disorders, including depression, anxiety, and PTSD (Cuijpers et al., 2019).\nSimilarly, a randomized controlled trial comparing in-person therapy to teletherapy for the treatment of depression found no significant differences in treatment outcomes between the two groups (Hubley et al., 2016). Additionally, a systematic review of the use of teletherapy for the treatment of PTSD found that teletherapy was an effective treatment option for this condition, with no significant differences in treatment outcomes between teletherapy and in-person therapy (Simpson et al., 2018).\nBenefits of Teletherapy\nTeletherapy has a number of benefits for both clients and therapists. These benefits include:\n1. Accessibility: Teletherapy can increase access to mental health services for those who live in rural or remote areas, have mobility issues, or have other barriers to accessing traditional, in-person therapy.\n2. Convenience: Teletherapy eliminates the need for travel, reducing the time and expense associated with attending in-person appointments.\n3. Flexibility: Teletherapy allows for greater flexibility in scheduling appointments, making it easier for clients to fit therapy into their busy schedules.\n4. Comfort: Many clients feel more comfortable participating in therapy from the privacy of their own homes, reducing anxiety and stress associated with attending in-person appointments.\n5. Cost-effectiveness: Teletherapy can be more cost-effective than in-person therapy, particularly when travel and other expenses are factored in.\nLimitations of Teletherapy\n1. Despite its benefits, teletherapy has some limitations that may impact its effectiveness for some clients. These limitations include:\n2. Technical difficulties: Teletherapy requires a reliable internet connection and the necessary technology (e.g., computer, smartphone, or tablet). Technical issues can disrupt therapy sessions and impact the quality of the therapeutic relationship.\n3. Limited nonverbal cues: Teletherapy can make it more difficult for therapists to pick up on nonverbal cues, which can impact the therapeutic relationship and the accuracy of clinical assessments.\n4. Limited therapeutic modalities: Some therapeutic modalities, such as touch-based therapies, are not possible through teletherapy, limiting the range of therapies available to clients.\n5. Privacy concerns: Teletherapy raises privacy concerns, particularly if sessions are conducted in public places or if the technology used is not secure.\nIn conclusion, the research suggests that teletherapy can be as effective as traditional, in-person therapy for many clients, and has a range of benefits. However, it also has some limitations that may impact its effectiveness for some clients. As such, psychologists and psychotherapists may want to consider teletherapy as an option for their clients, particularly for those who have difficulty accessing in-person therapy or who prefer the convenience and comfort of teletherapy. However, it is important to carefully consider the benefits and limitations of teletherapy and to ensure that clients have access to the necessary technology and support to participate in therapy effectively."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:c310cbd4-45ba-4bae-9c19-a788ac75fbd9>","<urn:uuid:9a953d8b-776c-4bb3-b1ee-2bbfa826492a>"],"error":null}
{"question":"Having studied aviation technology, I'd like to understand how the engine failure handling differs between Concorde's supersonic cruise and modern fighters with afterburners. What are the main operational procedures and safety considerations?","answer":"During supersonic cruise, Concorde handles engine failure by fully lowering the intake ramps and opening the spill door to dump excess air no longer required by the failed engine - this procedure reduces the chances of engine surges. For fighter jets with afterburners, engine management is focused on preventing component strain and failure during afterburner operation. The afterburner system requires precise calibration and maintenance of delicate tolerances, as even slight deviations can compromise engine performance. Prolonged afterburner usage can cause excessive strain on turbine blades and exhaust nozzles, potentially leading to catastrophic failures when these parts are subjected to increased heat and stresses beyond normal operating conditions.","context":["4 The Rolls-Royce/Snecma Olympus engines that are fitted to Concorde are a highly developed versionof the Bristol-Siddeley Olympus that was fitted tothe Vulcan bomber, which generated 11,000Lbs ofthrust.\n8 The Olympus engines are 2 spool engines. The inner shaft revolves within the outer shaft. The engine consists of14 compressor stages, 7 on each shaft, driven by theirrespective turbine systems. At supersonic speeds whenthe air approaches the combustion chamber is is very hotdue to the high level of compression of 80:1.\n9 The darker (black areas) are the areas more susceptible to heat and are thus constructed out of the nickel-alloy.To protect the later compression stages the last 4 stagesare constructed of a nickel-bassed alloy, the nickel alloyis usually reserved only for the turbine area.\n10 Concorde is the only civil airliner in service with a 'military style' afterburner system installed toproduce more power at key stages of the flight.The reheat system, as it is officially known, injects fuelinto the exhaust, and provides 6,000Lb of the totalavailable thrust per engine at take off.\n14 This hotter faster exhaust that is used on take off and is what is mainly responsible for the additional noise that Concordemakes. The reheats are turned off shortly after take offwhen Concorde reaches the noise abatement area.\n15 SUPERSONIC TRANSPORT CONCORDE MACH INLET FOR THESUPERSONIC TRANSPORT CONCORDE\n17 ramps spill doors delta vortex forming at low speed high angle of attackCCWrampsspilldoors\n18 AIR FLOW and INTAKESTo further improve engine system performance,the air flow through the engine area is changedat different speeds via a variable geometryintake control system. Altering this airflow changesthe amount of air available to theengine and the amount of air thatin itself is producing thrust viathe complex ramp and nozzleassemblies.\n20 The air intake ramp assemblies main job is to slow down the air being received at the engineface to subsonic speeds before it then entersthe engines.At supersonic speeds the enginewould be unstable if the air being feed to it was alsoat a supersonic speed so it is slowed down before itgets there.\n21 Subsonic Speeds (take off/subsonic cruise) At take-off the engines need maximum airflow,therefore the ramps are fully retracted andthe auxiliary inlet vane is wide open.The auxiliary inlet begins to close as theMach number builds and it completely closedby the time the aircraft reaches Mach 0.93.\n22 At slow speeds all the air into the engine is primary airflow SUBSONIC CRUISESecondaryExhaustbucketsAt slow speeds all the air into the engine is primary airflowand the secondary air doors are kept closed. Keeping themclosed also prevents the engine ingesting any of itsown exhaust gas.At around Mach 0.55 the secondary exhaust buckets beginto open as a function of Mach number to be fully open whenThe aircraft is at M=1.1\n23 Shortly after take off the aircraft enters the noise Abatement procedure where the re-heats are turned offand the power is reduced.\n24 The secondary nozzles are opened further to allow more air to enter, therefore quietening down the exhaust.The secondary air doors also open at this stage to allow airto by pass the engine.The ramps begin move into position at Mach 1.3which shock wave start to form on the intakes.\n25 SUPERSONIC SPEEDSAt the supersonic cruse speed of Mach 2.0 the ramps havemoved over half their amount of available travel,slowing down the air by producing a supersonic shockwave(yellow lines) at the engine intake lip.\n26 SUPERSONIC CRUISESome of the inlet fluid from the shock-boundary layerinteraction zone is removed in the ramp area\n27 Back to low speedsWhen the throttles are brought back to start the decentthe spill door is opened to dump out excess airthat is no longer needed by the engine, this allows the rampto go down to their maximum level of travel.As the speed is lowered the spill doors are closed and theramps begin to move backso by M=1.3 are again fully retracted.\n28 ENGINE FAILUREShould an engine fail andneed to be shut down during supersonic cruise,the ramps move fully down and thespill door opens to dump out excess air that is no longerrequired by the failed engine.The procedure lessens thechances of surges on the engine.\n30 THRUST REVERSALAfter touch down the engines move to reverse power mode.The main effect of this is that the secondarynozzle buckets move to the closed position directingairflow forwards to slow the aircraft down.\n32 ENGINE 4 ENGINE ROTATING STALL PROBLEM The main issue is that at slow airspeeds the enginesuffers vibrations on the low pressure compressor bladesfrom air vortices, that are created by the wing leading edgesections, entering it from both the air intake and fully openSpill door that moving in an anti-clockwise direction,which is the opposite direction to the engine's directionof rotation.The effect is not seen on engine No1, as the vortices travel inthe same direction as the aircraft.The No4 engine is limited on take off to 88% N1 at speedsbelow 60 Knots.\n33 Engine rotational direction is clockwise VORTICAL STRUCTURESOF FLOW at engine inletIS IN COUNTER CLOCKWISEDIRECTION14If you stand underneath or behind Concorde duringtake off it can be clearly seen that the no4 spill door isnot as open as the other three.The reheat flame on engine 4 is also not as bright or stableas the other three during the initial take off roll, until the aircraftis around 60 knts when it matches the others.","An afterburner, a distinctive feature of certain engines, is renowned for it’s remarkable inefficiency, as it voraciously devours fuel at a staggering rate of up to three times more than conventional engines. Consequently, pilots conscientiously restrict it’s usage during missions, usually reserving it for mere moments. Although the mechanism behind an afterburner may appear uncomplicated, it’s functionality relies on an intricate balance of delicately calibrated tolerances, demanding meticulous precision and skill.\nHow Long Can Fighter Jets Use Afterburners?\nFighter jets equipped with afterburners have the ability to tap into an immense power source, but it comes at a cost. The afterburner, a key feature of these engines, is notorious for it’s inefficiency. When engaged, it consumes fuel at an accelerated rate, up to three times higher than regular engine operation. As a result, pilots are careful to employ this feature sparingly, usually restricting it’s use to a matter of minutes during a mission.\nThe concept underlying an afterburner may be relatively straightforward, but it’s operation is anything but. The afterburner system introduces additional fuel into the exhaust stream, which then ignites, resulting in a sudden surge of power. This process demands intricate engineering and meticulous maintenance to ensure it’s reliability and accuracy. Even slight deviations in the afterburners delicate tolerances can cause a cascade of issues, potentially compromising the engines overall performance.\nFurthermore, prolonging afterburner usage can impose excessive strain on various components, such as turbine blades and exhaust nozzles. These parts are designed to withstand the intense forces generated under normal operating conditions. However, when subjected to prolonged afterburner use, they may succumb to the increased heat and stresses, leading to potentially catastrophic failures.\nThey reserve it’s deployment for critical moments or situations, where maximum thrust is necessary to achieve specific objectives. By doing so, they strike a balance between harnessing the incredible power of the afterburner and conserving precious fuel.\nMoving on to the next topic, it’s fascinating to explore the endurance of the F-16 in full afterburner. At low altitudes, the F-16 is capable of burning an astonishing amount of fuel, exceeding 64,000 pounds per hour. When operating at maximum capacity with external fuel stores, the U.S.-variant F-16 can sustain this level of performance for approximately 20 minutes before being forced to rely on emergency reserves, which would only provide an extra minute or so of full afterburner capability.\nHow Long Can F-16 Use Afterburner?\nThe F-16, renowned for it’s exceptional performance and versatility, is no stranger to the use of afterburners. These powerful engines enable the aircraft to achieve impressive speeds and climb rates, making it a force to be reckoned with in the skies. However, the duration for which an F-16 can utilize afterburners isn’t indefinite.\nWith maximum external fuel stores, a U.S.-variant F-16 can sustain full throttle operations for roughly 20 minutes. Subsequently, the aircraft would rely solely on emergency reserves, which would provide an additional minute or so under such intense conditions. This limited timeline highlights the need for prudent fuel management during missions requiring extensive afterburner usage.\nIt’s worth noting that the duration of afterburner usage can also be impacted by altitude. Conversely, at low altitudes, where the atmosphere is denser, the afterburners consume fuel at a faster rate, limiting the duration they can be utilized.\nStrategies for Fuel Management During Missions Requiring Extensive Afterburner Usage\n- Optimize fuel consumption\n- Monitor fuel levels constantly\n- Use afterburner sparingly\n- Implement precise throttle control\n- Consider pre-flight weight reduction\n- Incorporate efficient flight planning\n- Perform regular engine maintenance\n- Utilize air-to-air refueling if available\n- Employ tactics to minimize time spent in afterburner\n- Train pilots on fuel-efficient flying techniques\nWatch this video on YouTube:\nThe Boeing F/A-18E and F/A-18F Super Hornet, derived from the McDonnell Douglas F/A-18 Hornet series, are renowned carrier-capable, multirole fighter aircraft. The F/A-18E variant, designed as a single-seater, and the F/A-18F variant, built as a tandem-seater, are upgraded versions of their predecessors. These impressive aircraft can internally store up to 14,400 lbs of fuel. In terms of fuel consumption, the powerful GE F414 engine can burn around 36,000 lbs/hr of fuel in full afterburner mode. Therefore, it’s typical for an F/A-18E/F Super Hornet to have a total fuel burn of approximately 72,000 lbs/hr in such conditions.\nHow Much Fuel Does a F18 Burn Afterburner?\nThe F/A-18E Super Hornet, equipped with the GE F414 engine, is a formidable aircraft in terms of fuel consumption. It possesses a substantial fuel capacity, with 14,400 lbs of fuel stored internally. However, when engaging the afterburner, the fuel consumption reaches another level entirely.\nThe afterburner is a significant feature of the F/A-18E, as it provides an immense boost of propulsion. With the afterburner activated, the GE F414 engine burns approximately 36,000 lbs/hr of fuel. This extensive fuel burn showcases the immense power output of the afterburner and it’s impact on the aircrafts overall fuel consumption.\nHowever, it’s important to note that fuel consumption may vary depending on factors such as mission requirements, aircraft configurations, and flight parameters.\nWhen the afterburner is engaged, the engine burns approximately 36,000 lbs/hr of fuel, resulting in a typical total fuel burn of 72,000 lb/hr under maximum power output conditions. However, it’s crucial to consider various factors that can affect fuel consumption when assessing the overall efficiency of this advanced multirole fighter aircraft.\nIn conclusion, the utilization of an afterburner in an engine comes at a significant cost in terms of fuel consumption. Consequently, pilots are cautious and restrict it’s use to only a few minutes during a mission to mitigate the fuel consumption impact. Balancing the benefits of enhanced thrust with the inherent cost of increased fuel consumption remains a crucial consideration in the design and operation of afterburning engines."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:bbb0fb29-2273-4410-ad66-ece20b222dc3>","<urn:uuid:5e11055f-6713-4483-a2eb-970fbb674bda>"],"error":null}
{"question":"What steps lead people to help in emergency situations?","answer":"People are most likely to help in emergency situations through a three-step process: first, they must notice the incident; second, they must interpret it as an emergency; and third, they must assume responsibility for helping. Additionally, people are more likely to help if the person appears to deserve help, is a woman, or if the helper is unhurried, in a good mood, feeling guilty, or focused on others rather than being preoccupied.","context":["- Slides: 47\nSOCIAL PSYCHOLOGY CHAPTER 13\nSOCIAL PSYCHOLOGY • Social psychology – Is the scientific study of how we think about, influence, and relate to one another • Social psychologists – Use scientific methods to study how people think about, influence, and relate to one another – Study the social influences that explain why the same person will act differently in different situations\nSOCIAL PSYCHOLOGY • Social Thinking • When explaining others’ behavior, especially from an individualist Western cultural perspective – Fundamental attribution error committed by underestimating the influence of the situation and overestimating the effects of stable, enduring traits – Behavior more readily attributed to the influence of the situation – Explaining and attributing actions can have important real-life social and economic effects\nSOCIAL PSYCHOLOGY • Fundamental attribution error – Is tendency, when analyzing others’ behavior, to overestimate the influence of personal traits and underestimate the effects of the situation – Is most likely to occur when stranger acts badly – Has real-life and social consequences • Napolitan and colleagues (1979) – Students attributed behavior of others to personal traits, even when they were told that behavior was part of an experimental situation.\nSOCIAL PSYCHOLOGY • Question of attribution • Whether we attribute poverty and homelessness to social circumstances or to personal dispositions affects and reflects our political views.\nSOCIAL PSYCHOLOGY Attitudes Affect Actions • Attitudes are feelings influenced by beliefs, that predispose reactions to objects, people, and events. – Peripheral route persuasion uses incidental cues to try to produce fast but relatively thoughtless changes in attitudes. – Central route persuasion offers evidence and arguments to trigger thoughtful responses\nSOCIAL PSYCHOLOGY • Actions can modify attitudes. – Role playing includes acting a social part by following guidelines for expected behavior • Zimbardo’s Stanford Prison Experiment\nSOCIAL PSYCHOLOGY • Foot-in-the-door phenomenon – People agreeing to a small request will find it easier to agree later to a larger one – Principle works for negative and positive behavior • Attitudes follow behavior – Cooperative actions, such as those performed by people on sports teams, feed mutual liking. Such attitudes, in turn, promote positive behavior.\nSOCIAL PSYCHOLOGY • When attitudes do not fit with actions, tensions are often reduced by changing attitudes to match actions (cognitive dissonance theory). – We act to reduce the discomfort (dissonance) we feel when two of our thoughts (cognitions) clash. – Brain regions become active when people experience cognitive dissonance. – Through cognitive dissonance we often bring attitudes into line with our actions (Festinger).\nSOCIAL PSYCHOLOGY • Conformity and obedience – Chartrand colleagues (1999) • Demonstrated chameleon effect with college students • Automatic mimicry helps people to empathize and feel what others feel. • The more we mimic, the greater our empathy, and the more people tend to like us. • This is a form of conformity.\nSOCIAL PSYCHOLOGY • Conformity and Obedience • Solomon Asch and others have found that people are most likely to adjust their behavior or thinking to coincide with a group standard when • They feel incompetent or insecure • Their group has at least three people • Everyone else agrees • They admire the group’s status and attractiveness • They have not already committed to another response • They know they are being observed • Their culture encourages respect for\nASCH’S CONFORMITY EXPERIMENTS Which of the three comparison lines on the left is equal to the standard line? The photo on the right (from one of the experiments) was taken after five people, who were actually working for Asch, had answered, “Line 3. ” The student in the center shows the severe discomfort that comes from disagreeing with the responses of other group members.\nSOCIAL PSYCHOLOGY • People May Conform For Many Reasons • Normative social influence: To gain approval • Informational social influence: To accept others’ opinions as new information\nSOCIAL PSYCHOLOGY SOCIAL NETWORKING INFLUENCE • On the 2010 U. S. congressional election day, Facebook gave people an informational message that encouraged voting. The message had measurably more influence when supplemented with a social message that showed friends who had voted (Bond et al. , 2012).\nSOCIAL PSYCHOLOGY • Suggestibility and mimicry sometimes lead to tragedy. – Copycat violence threats after Colorado’s Columbine High School shootings\nSOCIAL PSYCHOLOGY Stanley Milgram’s Obedience experiments – People obeyed orders even when they thought they were harming another person. – Strong social influences can make ordinary people conform to falsehoods or exhibit cruel behavior. – In any society, great evil acts often grow out of people’s compliance with lesser evils. In a repeat of the earlier experiment, 65 percent of the adult male “teachers” fully obeyed the experimenter’s commands to continue. They did so despite the “learner’s” earlier mention of a heart condition and despite hearing cries of protest after they administered what they thought were 150 volts and agonized protests after 330 volts. (Data from Milgram, 1974. )\nSOCIAL PSYCHOLOGY • In social facilitation (Triplett), presence of others arouses people, improving performance on easy or well-learned tasks but decreasing it on difficult ones. – Performance can also be hindered because the most likely, but not necessarily the correct response occurs. • Home town advantage • Crowding effect • Home team advantage – When others observe us, we perform well-learned tasks more quickly and accurately. – But on new and difficult tasks, performance is less quick and accurate.\nSOCIAL PSYCHOLOGY • Social loafing – Tendency for people in a group to exert less effort when pooling their efforts toward attaining a common goal than when individually accountable • Causes – Acting as part of group and feeling less accountable – Feeling individual contribution does not matter – Taking advantage when there is lack of identification with group There is always that one person in the group project that doesn’t do work\nSOCIAL PSYCHOLOGY • Deindividuation – Involves loss of selfawareness and self-restraint occurring in group situations that foster arousal and anonymity – Thrives in many different settings Violent Anti-Trump Rioters\nSOCIAL PSYCHOLOGY Group polarization • Group discussions with likeminded others strengthen members’ prevailing beliefs and attitudes. • Internet communication magnifies this effect, for better and for worse If a group is like-minded, discussion strengthens its prevailing opinions. Talking over racial issues increased prejudice in a high-prejudice group of high school students and decreased it in a low-prejudice group (Myers & Bishop, 1970).\nSOCIAL PSYCHOLOGY • Groupthink • People are driven by a desire for harmony within a decisionmaking group, overriding realistic appraisal of alternatives.\nSOCIAL PSYCHOLOGY • Individual power • Power of the individual and the power of the situation interact. • A small minority that consistently expresses its views may sway the majority. Malala\nSOCIAL PSYCHOLOGY Social Psychology • Prejudice – Means “prejudgment” – Is an unjustified negative attitude toward some group and its members – Often targets different cultural, ethnic, or gender group\nSOCIAL PSYCHOLOGY • Prejudice Components –Beliefs –Emotions –Predispositions to action (to discriminate)\nSOCIAL PSYCHOLOGY • Prejudice is a negative attitude • Discrimination is a negative behavior. • Explicit prejudice in North America has decreased over time. – Support for all forms of racial contact, including interracial dating\nSOCIAL PSYCHOLOGY • Social roots of prejudice – Social inequalities: Have often developed attitudes that justify status quo – Just-world phenomenon: Good is rewarded and evil is punished. – Stereotypes: Rationalize inequalities.\nSOCIAL PSYCHOLOGY • Groups – Through social identities people associate themselves with others. – Evolution prepares people to identify with a group • Ingroup/Outgroup: Social definition of who we are—and are not • Ingroup bias: Favoring of our own group\nSOCIAL PSYCHOLOGY • Scapegoat theory – Proposes that when things go wrong, finding someone to blame can provide an outlet for anger • Research evidence (Zimbardo) – Prejudice levels tend to be high among economically frustrated people – In experiments, a temporary frustration increases prejudice\nSOCIAL PSYCHOLOGY • Implicit prejudice – Implicit racial associations • Implicit Association Tests results: Even people who deny racial prejudice may carry negative associations – Unconscious patronization • Lower expectations, inflated praise and insufficient criticism for minority student achievement – Race-influenced perceptions • Automatic racial bias – Reflexive bodily responses • Unconscious, selective responses when looking at faces\nSOCIAL PSYCHOLOGY • Forming categories – Humans categorize people by race: mixed-race people identified by minority identity – Similarities overestimated during categorization; creating “Us and They” – Overestimation also occurs; other-race effect or bias\nSOCIAL PSYCHOLOGY The Biology of Aggression • Biology influences aggression at three levels. – Genetic influences • Evidence from animal studies and twin studies; genetic Y chromosome genetic marker; MAOA gene • Alcohol associated with aggressive responses to frustration – Neural influences • Neural systems facilitate or inhibit aggression when provoked • Aggression more likely to occur with frontal lobe damage – Biochemical influences • Testosterone linked with irritability, assertiveness, impulsiveness, and low tolerance for frustration; alcohol effect\nSOCIAL PSYCHOLOGY Psychological and Social-Cultural Factors in Aggression • Adversive events – Frustration-aggression principle: Frustration creates anger, which can spark aggression • Other anger triggers – Hot temperatures, physical pain, personal insults, foul odors, cigarette smoke, crowding, and a host of others – Previous reinforcement for aggressive behavior, observing an aggressive role model, and poor self-control\nSOCIAL PSYCHOLOGY Psychological and Social-Cultural Factors in Aggression • Media portrayals of violence provide social scripts that children learn to follow. • Viewing sexual violence contributes to greater aggression toward women. • Playing violent video games increases aggressive thoughts, emotions, and behaviors\nSOCIAL PSYCHOLOGY • Psychological and Social-Cultural Influences on Aggression Do violent video games teach social scripts for violence? • Nearly 400 studies of 130, 000 people suggest video games can prime aggressive thoughts, decrease empathy, and increase aggression. • Some researchers dispute this finding and note other factors: Depression, family violence, and peer influence. • As a player of first-person shooter games, Breivik stirred debate when he commented that “I see MW 2 [Modern Warfare 2] more as a part of my training-simulation than anything else. ” Did his violent game playing contribute to his violence, or was it a mere coincidental association? To explore such questions, psychologists experiment.\nSOCIAL PSYCHOLOGY Prosocial Relations • Psychology of attraction • Proximity (mere exposure effect) • Physical attractiveness • Similarity of attitudes and interests WHAT DO WE MEAN BY “ATTRACTIVE”?\nSOCIAL PSYCHOLOGY • Modern matchmaking • Internet-formed friendships and romantic relationships are on average slightly more likely to last and be satisfying. • Nearly a quarter of heterosexual and two-thirds of same-sex couples met online.\nSOCIAL PSYCHOLOGY • Speed-dating • Men are more transparent. • Choices may be more superficial. • Women are more choosy than men.\nSOCIAL PSYCHOLOGY • Passionate love – Two-factor theory of emotion • Emotions have two ingredients— physical arousal and cognitive appraisal. • Arousal from any source can enhance an emotion, depending on how we interpret and label the arousal. – Sexual desire + a growing attachment = the passion of romantic love – Passionate love seldom endures • Companionate love – Passion-fed hormones (testosterone) give way to oxytocin that supports feelings of trust, calmness, and bonding – Attraction and sexual desire endure, without obsession of early-stage marriage – Equity is important key to satisfying and enduring relationship – Self-disclosure deepens intimacy\nSOCIAL PSYCHOLOGY • Altruism is an unselfish concern for the welfare of others. – People are most likely to help when they notice an incident, interpret it as an emergency, and assume responsibility for helping (Darley and colleagues). – Odds for being helped are also increased if the person appears to deserve help or is a women. – Similarity to self, unhurried or in a good mood, feeling guilty, focused on others and not preoccupied also raises likelihood of being helped.\nSOCIAL PSYCHOLOGY • Bystander affect – Tendency for any given bystander to be less likely to give aid if other bystanders are present – Occurs when there is a diffusion of responsibility\nSOCIAL PSYCHOLOGY Positive social norms encourage generosity and enable group living. • Socialization norm – Social expectation that prescribes how we should behave • Reciprocity norm – Expectation that people will respond favorably to each other by returning benefits for benefit (cost-benefit analysis; utilitarianism; social exchange theory) • Social-responsibility norm – Expectation that people should help those who depend on them\nSOCIAL PSYCHOLOGY • Conflict – Perceived incompatibility of actions, goals, or ideas in which people become enmeshed in potentially destructive processes that often produce unwanted results – Among these processes are social traps and distorted\nSOCIAL PSYCHOLOGY • Social trap – Situation in which conflicting parties, by each pursuing their self-interest rather than the good of the group, become caught in mutually destructive behavior • Mirror-image perceptions – Mutual views often held by conflicting people, as when each side sees itself as ethical and peaceful and views the other side as evil and aggressive\nSOCIAL PSYCHOLOGY • Enemy perceptions – People in conflict form negative, distorted images of one another (mirror-image perceptions) – “Us” versus “Them” develops – Vicious cycle of hostility emerges at individual or national level – Perceptions can become self-fulfilling prophecies\nSOCIAL PSYCHOLOGY Research indicates that in some cases contact and cooperation can be transformational. • Contact – Most effective when contact is free of competition and equal status exists – Across a quarter-million people studied in 38 nations, friendly contact with ethnic minorities, older people, and people with disabilities has usually led to less prejudice. – Contact is not always enough.\nSOCIAL PSYCHOLOGY • Promoting Peace • Cooperation • Communication • Conciliation"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:05f15efe-f4f9-40bc-af50-a06a9743e0dc>"],"error":null}
{"question":"I am preparing presentation about historic water sources. What happened with Aldgate Pump water in 1876?","answer":"In 1876, it was discovered that the water from Aldgate Pump had become contaminated because the underground stream was passing by new cemeteries, causing calcium from human bones to leach into the water supply.","context":["Remains of the Old London Bridge\nA bridge has spanned the Thames between the City of London and Southwark on the site of a natural causeway since the original Roman crossing was built in AD50. Since the conquest it has evolved over time and existed in countless different forms, one of the most famous being the medieval ‘Old London Bridge’ which was finished under the reign of King John in 1209 and survived until 1762. Though only 8m wide it was 270m long and by the Tudor era hosted a haphazardly placed row of more than 200 shops. Drawings depict comical ratios between the bridge foundations and seven-storey high buildings overhanging the river and encroaching on the street – making crossings last up to an hour!\nAt the end of the 18th century it was over 600 years old and congestion was becoming so serious the mayor ruled that all traffic from Southwark should keep to the west side and traffic from the City should keep to the opposite side; it is said this is the origin of driving on the left in Britain. The precariously stacked buildings of the old bridge have long since been demolished, yet a few fragments of the stonework remain scattered across the city. One of the best surviving examples is the old pedestrian entrance which now forms an arched pathway under the St Magnus the Marytr’s church tower.\nA water pump was first installed here upon an old well head in the sixteenth century and then in the eighteenth century replaced by the stone water pump seen today. Despite standing overlooked at a bustling junction in the financial district, Aldgate Pump remains a hidden statue to the areas gruesome past. Today the pump is no longer functional but in 1876, before being linked to the mains water supply, it was served by an underground stream. At first the people of Aldgate, unaware of the oncoming horror story, said the water contained healthy minerals but soon began to complain of an unusual taste which was quickly linked to the many recent deaths in the area. An investigation made the shocking discovery that, as the water was being channelled past the new cemeteries in the city; calcium had leached out from human bones and into the water! Yet by the 1920s the water quality had been turned around to the extent Whittard’s tea merchants even filled their kettles at the pump – declaring it the best water for tea tasting. Today the pump also resembles less grisly events such as marking the official point at which the East End starts and where mileages east of London are calculated from.\nAround 2000 years ago there was a 4km defensive wall built by the Romans around the settlement of Londinium. William I’s march on London 1000 years later found the enclosed City of London to be harder to conquer so eventually special privileges were granted to encourage peace with the city. For example, it is said the City of Westminster was expanded in an attempt to draw power and wealth west from the City of London. Today the City of London still holds special rules and customs – one is that the Queen has to ask permission before entering as the people ‘still retain their ancient privilege of being able to bar the Sovereign from entering their streets.’ The ancient wall was only maintained until the 18th century but around fourteen sections have survived and now sit in a disjointed arc above the Thames.\nThe oldest church in the City of London was founded by the Abbey of Barking in 675AD. It became known as ‘All Hallows Barking’ and then in 300 years ‘All Hallows-by-the-Tower’ due to its proximity to the Tower of London. In future decades it would survive explosions, fires and the Blitz but still continue its job as a church. In the 1500s it was popular with monarchs, such as Edward IV, who made it a royal chantry meaning executions at the Tower were sent for temporary burial at All Hallows and in 1797 John Quincy Adams, sixth president of the USA, was married at All Hallows. Over the years it has undergone many reconstructions to become a mix of architectural styles and despite its dramatic history still sits on Roman foundations against the surrounding walls of 21st century glass.\nABOUT THE AUTHOR"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:90db3033-f85b-482e-b206-e99f76e37e9e>"],"error":null}
{"question":"How did the defensive fortification systems of the Romans and Persians evolve from simple barriers to more complex strategic systems?","answer":"Both civilizations developed sophisticated defensive approaches beyond mere physical barriers. The Romans evolved from an early 'all potential foes need to be destroyed' mentality to a more nuanced Limes system that combined physical barriers with trade relationships, strategic deterrence of raids, and punitive expeditions. The Persian system similarly showed evolution in complexity, as seen in structures like the Gorgan Wall, which integrated multiple elements: a substantial mud-brick wall, strategically placed forts of varying sizes, and deep ditches. Both systems represented practical adaptations to the challenge of defending extensive borders with limited resources, moving beyond simple 'keep out' defenses to more comprehensive security strategies.","context":["The Limes Germanicus (simply known as \"Limes\" in Germany) was an ancient great wall of the Roman empire along its border with Germanic tribes.\nIt's of special interest because it's a quite unusual defensive / border security system. This line of defence was in practice incapable (and later on likely also not meant) of defeating attacks. Even the possibility of successful counterattacks on raiders before they did harm was small.\nThe Romans hadn't enough troops to set up a solid enough defence capable of doing that. It wouldn't have helped if they were able because they also would have had to sustain the effort for generations and the border provinces were simply not worth the effort.\nThey had to settle with much lower ambitions, and they've set up a border security strategy that was much, much more complex and efficient than a simple \"keep out!\" defence.\nThe strategy included four major elements:\n(1) mark the border to solidify the claim on land, control it\n(2) trade and ally with nearby tribes as the \"carrot\" part of \"carrot and stick\"\n(3) lower the expectation value for net raid profit with border security efforts\n(4) use punitive expeditions as the \"stick\" in \"carrot and stick\"\nThis worked quite well until the resources spent on border security diminished (archeologists learned that the garrisons were only in partial use in the late imperial phase) and the Germanic pressure reached a new level (the barbarian migration pressure re-emerged about two decades after the establishment of the border).\nThe limes earthworks and \"walls\" weren't capable of stopping many raiding party infiltrations. Their greater value was in the difficulties such a wall and ditch posed for the exfiltration (return) of said raiding party.\nThe border guards were at alert by the time of exfiltration, the raiders were hunted by Roman cavalry and they were in a hurry (unable to choose the best time and place for overcoming the obstacle), laden with booty and possibly even occupied with captives (new slaves).\nOnly really strong raiding parties had a good chance to return with livestock. Infiltration and exfiltration on horse was also difficult.\nThis lowered the expectation value for net raid profits (3).\nThe Romans had early on an \"all potential foes need to be destroyed\" attitude. Such a limited ambition border defence as the Limes Germanicus turned out to be was therefore a great step back towards humility and practicality.\nThey had to secure their long Northern border with strictly limited resources and have apparently developed a smart and effective strategy for the challenge.\nThe Limes Germanicus was therefore an example of a linear defence (or security concept) with low ambitions.\nThat strategy deserves attention today because we're at a similar position today: The continuous, uninterrupted front lines of WWI and even WW2 (in most theatres and at most times) are out of reach in modern warfare. POur combat troops strength would not suffice; the whole NATO could not man the former Eastern Front as densely with combat troops as did the Wehrmacht even as late as 1943. Most conflicts would happen in a smaller theatre than that, but also with smaller troop contingents. Talk and writing about \"empty battlefields\" (on the operational level of ground war!) and huge \"gaps\" between formations has become acceptable if not normal years ago.\nNo matter whether we intend to be on the operational offensive in every future war - we still needs good ideas about how to set up an effective operational defence with minimum resources as well.\nModern military theorists need to adapt to such relatively empty war zones (as known from ground wars pre-1854), and the many historical precedents are msot likely of value for that effort.\nThe Limes Germanicus is an interesting historical example for a static linear defence at relatively low cost.","The article below “Fortifications” by Wolfram Kleiss in the Encyclopedia Iranica was originally published on December 15, 1999 and last Updated on January 31, 2012. Kleiss provides an overview of the fortified passages and defenses of the Sassanians, some of which can be traced back to the Achaemenid era.\nThis article is available in the print volumes of the Encyclopedia Iranica (Vol. X, Fasc. 1, pp. 102-106).\nKindly note that the article below contains pictures and captions that do not appear in the Encyclopedia Iranica version.\nThe present article deals with the fortified passages and defenses that are implied under the term bārū. Certain passes in Persia still feature barriers going back to the Achaemenid period. An example is the stone wall at the Kotal-e Sangar in Fārs, which bars the way from Persepolis and Bīšāpūr to Ḵūzestān on the saddle (not a real pass) between the Mamassanī plain (plain of Deh-e Now) and the Fahlīān plain, and which is identical with the medieval and modern caravan route (today’s modern highway between Shiraz and Ahvāz). The rubble wall that by now has almost entirely disappeared was originally 1,230 m long and extended between both sides of the saddle’s rugged, steeply rising rock faces. The construction has been associated with a wall mentioned by Arrian (Anabasis 3.17), which the Uxians are said to have erected as a customs-barrier on the road between Ḵūzestān and Fārs, and around which Alexander had made a great détour on his expedition from Susa to Persepolis before taking it by surprise (Stein, pp. 39-44; Kleiss, p. 213, fig. 1).\nAnother wall (Kleiss, p. 214, Fig. 2) was built on top of the pass 36 km east of Farrāšband and 28 km west of the modern city of Fīrūzābād in the province of Fārs. It overlooks the road between the Sasanian settlements around Farrāšband and the Sasanian round city of Gōr (q.v.) with the bridge over the river west of Fīrūzābād, and is, at the same time, a barrier similar to the one in the Qalʿa-ye Doḵtar area north of Gōr (present-day Fīrūzābād, q.v.), a fortification at the northern access to the plain of Fīrūzābād (Huff). The barrier on the pass extends over a length of about 200 m in a fairly straight line from northwest to southeast in the shape of a ruined rubble wall that was once of considerable height. On the eastern side of the wall lies a heap of stones, the remains of a small halting-place or a tower, the exact measures of which are unknown. The dating of the barrier is unclear; perhaps it was built in the Sasanian period and continued being used in the Islamic period.\nThe Sassanian City of Firuzabad, known as Gur or Ardashīr-Xhwarra (located in Fars province, approx. 110 km south of Shiraz) (Source: CAIS). Gur is built as a perfect circle measuring at 1,950 meters in diameter and partitioned into 20 sections. The city was surrounded by a primary wall constructed of stamped clay, a ditch measuring at 35 meters width, as well as an inner-wall of defense.\nRoads over passes were rendered defensible without any specific effort at fortification, but only through the itinerary and the constructive protection of the pass, an example being the Kotal-e Doḵtar on the caravan road from Shiraz via Kāzerūn to Būšehr (Figure 3). The way up to this pass from the Kāzerūn plain could be blocked at any time at its serpentine curves and defended by means of traditional weapons (Nathusius, p. 160).\nThe most important fortification in Persia is the mud-brick wall mistakenly called Alexander’s Wall (Sadd-e Eskandar), which shields the fertile foot-hills leading to the plain of Gorgān against the Turkman steppes. This structure consists of a mud-brick wall stretching out like an embankment, and, adjacent to the wall, 33 forts of varying forms and sizes (120 x 120 m to 300 x 200 m) placed at different distances from one another (400 to 9,850 m). The Gorgān wall (Kiani) was built in the Parthian and Sasanian period as a rampart against attackers, and this function makes it comparable with the Roman limes, constructions in England and Germany, and with the Great Wall of China. The Turkmans call the wall Qïzïl Alan, and in Persian it is also called Sadd-e Pīrūz and Sadd-e Anūšīravān. The Gorgān wall is 175 km long, extending from the Caspian Sea to the Alborz and the north-eastern mountain chains of Persia. The remains of the wall end in the west, north of Gomīšān, at a distance of about 5 km from the Caspian Sea coast, which is due to the variation in the level of the Caspian (now 27 m under sea level) and the very flat level of the coastline. As far as is known, the eastern end of the wall joins the mountain-range at Piškamar, 58 km northeast of Gonbad-e Qābūs, its further prolongation to the east being questionable. The wall is at present 2 to 5 m high and about 10 m wide. A ditch 3 m deep and up to 30 m wide runs along the outer side of sections of the wall. The wall itself is constructed of unbaked bricks (50 x 50 x 10 cm) and baked bricks (40 x 40 x 10 cm). Excavations along the wall and in the forts belonging to it have produced Parthian gray ceramics, Parthian red ware, and glazed Islamic pottery.\nAn Iranian map of the Gorgan wall. The works of Dr. Kiani in 1971 were invaluable in helping lay the basis of mapping the structure. The Gorgan Wall is second only to the Great Wall of China in length. For more on this topic see: Farrokh, K. (2010). The Great Wall of Gorgan: One of the World’s Greatest Frontier Walls. Tehran Times International Daily, March 9, p.7.\nThe Gorgān plain is protected by two fortifications on its western border, at the narrowest part of the flat plain between the mountains and the Gorgān Gulf (Ḵalīj-e Gorgān), east and west of Bandar-e Gaz and south-east of the Caspian Sea. Extending between the foot-hills of the Alborz mountains and the Ḵalīj-e Gorgān coast, the defensive barrier, approximately 11 km long, is now barely recognizable as a very overgrown earth wall with a height of 1 to 3 m and a width of 2 to 2.50 m. The barrier begins near the ruined city of Tammīša (Ṭamīsa/Ṭamīs in Ar. sources) at the foot of the mountains. A further fortified wall running parallel to it is found 22 km to the west, between Bandar-e Gaz and Behšahr (qq.v.; Kleiss, pp. 215-16). The ruins of Tammīša, near the village of Sar Kalāta, prove to be of Sasanian to Saljuq origin (6th to 9th cents.), which is probably also true of both walls (Bivar and Fehérvári). The fortified wall near the ruined city of Tammīša at the foot of the Alborz mountains is built of clay and baked brick (36 x 36 x 10 cm). Excavations at the wall and in the Tammīša area produced glazed and unglazed Islamic pottery of the 9th to 15th centuries. In their strategic function, the walls of Tammīša correspond with the fortifications of Darband (q.v.; Turk: Derbent) in Daghestan on the western coast of the Caspian Sea (Bretanizkiĭ, p. 375, fig. 214; Ebn Bakrān, pp. 81-82). The latter, with their approximately 150 km long wall ascending the Caucasus heights, were to protect the Persian frontier against the tribes of the northern steppes. This construction is also mistakenly called Sadd-e Eskandar, but building details clearly show that the walls are of Sasanian origin and point to a comparison with the structure of the Taḵt-e Solaymān wall in Azerbaijan (Naumann, p. 35, fig. 15). The Darband fortification, which consists of five sections, is about 2,250 m long, from the coast to the western corner of the citadel (arg), and has an interior dimension of 240 to 250 m for the city area. The northern wall features a closer disposition of the towers than the southern wall. Four gates each face north and south, respectively, and the individual sections of the city are connected by additional gates.\nThe Wall of Derbent (also known as Krevar to locals) in Daghestan as it appears in winter. This is an enduring testament to Sassanian military engineering in the Caucasus (Source: Public Domain).\nIn its structure as a fortified barrier for the control of a coastline, Darband can be compared with the entire complex of the Byzantine-Turkish fortifications of Trabzon/Trebizond. Between the Black Sea and the Pontus mountains, it attains a length of about 900 m and is divided into three parts: the lower city (Aşağı Hisar), the central city (Orta Hisar), and the citadel (İç Kale; Sinclair, II, p. 48).\nThe Byzantine-Turkish defense walls at Trabzon (Source: Public Domain).\nThe position of the citadel of a fortified settlement in the center of the circumvallation is rare. An original example is the Sasanian to early Islamic citadel on the conical rock in the center of the round city of Dārābgerd (Figure 7). In Isfahan and Shiraz the citadels lie within the walled city; they do not connect with the city wall and have no direct connection with the environment outside the city wall (Figure 8).\nThe round city of Darabgerd (Source: CAIS).\nThe citadels belonging to fortified settlements are usually built on sites offering the most suitable terrain for fortifications. As a rule, they are built on heights within the area of the settlement. Most citadels are situated at the edge of the settlements, are structurally connected with the city walls and have gates leading both to the city and to the open country—as is the case with Herat, Bam, Kars, Van, Dāmḡān, or the old town of Tehran. The last wall built around Tehran in the 19th century surrounded the citadel (the Golestān Palace complex) as the center of the walled city.\nA. D. H. Bivar and G. Fehérvári, “ The Walls of Tammisha,” Iran 4, 1966, pp. 35-50.\nL. S. Bretanitskiĭ, Zodchestvo Azerbaidzhana XII-XV vv. i ego mesto v arkhitekture Perednego Vostoka Moscow, 1966.\nMoḥammad Ebn Najīb Bakrān, Jahān-nāma, ed. M.-A. Rīāḥī, Tehran, 1342 Š./1963.\nD. Huff, “Ausgrabungen auf Qaleh Dukhtar,” in AMI, N.S. 9, 1976, pp. 157-73.\nM. Y. Kiani, Parthian Sites in Hyrcania: The Gurgan Plain, AMI, suppl. vol. 9, Berlin, 1982.\nW. Kleiss, “Sperrbefestigungen in Iran und Vergleiche zu europäischen Beispielen,” Archäologische Mitteilungen aus Iran und Turan 30, 1998, pp. 213-14.\nA. Nathusius, Im Auto durch Persien, Dresden, 1926.\nR. Naumann, Die Ruinen von Tacht-e Suleiman und Zendan-e Suleiman, Führer zu archäologischen Plätzen in Iran 2, Berlin, 1977.\nT. A. Sinclair, Eastern Turkey: An Architectural and Archaeological Survey, 4 vols., London, 1987-90.\nA. Stein, Old Routes of Western Iran, New York, 1940."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:0b44d283-551b-4392-b21e-3e585e9251a3>","<urn:uuid:1c961a9c-617c-4794-8dbe-284c17225e1e>"],"error":null}
{"question":"what company did engineering work for cafe building in Kozhikode beach rd?","answer":"The structural engineering was done by Ramees Ali_RALAB, while the mechanical and electrical engineering was handled by Elmek Solutions.","context":["- Architects: Zero Studio\n- Location: Beach Rd, Kuttichira, Kozhikode, Kerala 673001, India\n- Project Team: Hamid mm, Hafeef Pk, Nidhin raj, Sameer, Issudheen, Shafeek Ahamed\n- Area: 300.0 m2\n- Project Year: 2018\n- Photographs: Ar Hamid MM\n- Structural Engineering: Ramees Ali_RALAB\n- Mechanical And Electrical Engineering: Elmek Solutions\n- Metal Fabrication: Mansoor\n- Electrical: Jibeesh\n- Landscaping: Banyan tree\nText description provided by the architects. All over the world, food aficionados are having a great time since cuisine these days isn’t exclusive to the region where it belongs to but has become a global concept. Learning from a worldwide chain of branded restaurants, cities and also small towns started to have their own regional versions for specialty eating spaces; bringing to the platter, local as well as foreign cuisine, and at times fusing together different varieties.\nSuch extravaganza in the menu, however, has become a norm and the food enthusiasts are now being offered much more than just a nice meal by the restaurateurs. Calling it by the name of ‘experience dining’, they put forward dining as a wholesome package. Thus, along with ‘what’ you are eating, ‘where’ you are eating has also become important in deciding your satisfaction level as a customer. This is where the ambiance of the space becomes highly important even to the extent that it can overshadow the food itself.\nDistinct from the many such ‘experimental’ food joints that have come up in the city as part of this trend; though relatively recent in these parts of the world, the client wanted a unique space for ‘experience dining’. This was to be done using the three available levels in an existing building, whose form was not doing much help. The café is set in a not so old building, literally a storehouse, nearby an old street with an enormous history, the Gujarati Street in Kozhikode, Kerala (India). It had very little to do with the past or present of its context; even being one of the few structures that lie within the permissible areas abutting the primary influence factor later in the design process, the beach.\nThe design involved reforming this building with no changes in the existing area or structural elements but in volume by altering the roof heights. The façade is enveloped in corrugated cement sheets and rest of the exterior reflects similar hues with exposed cement and glass finishes. The limited detail and ornamentation in the exterior, as well as interior, has been a conscious decision so that the sea, with its changing colors, remains the major focus of the design.\nBorrowed from the sea, shades of blue and yellow along with plain cement finish colors the flooring. Finishes and accessories (most of them being antique or obtained from the old buildings nearby) reminisce a bygone era, thus reconnecting the building with the past. The choice of furniture is mostly traditional – designed with a minimalistic approach to getting along with the concept of the interior. Notably, in the base level, old teak wood panels make up for seat and table tops, used without polishing off their patina, thus keeping the old world charm; also, they accentuate on simple lines in order to not obstruct the outside view.\nOf the three levels, the base level features a curved jali which orients the circulation and view towards the beach sands. The middle level offers an elevated scenic view of the beach waters filtered through the foliage of a tree. The third level houses a lounge space with a barrier-free view to the horizon. Though a standalone at first look; a closer observation reveals that the café, in its attempt to deliver dining as a full experience, has its ‘platter’ of design derived from the context itself."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:ed66a373-33d9-477e-a0d3-60431be4e600>"],"error":null}
{"question":"What happens to shareholders' voting rights when a company issues a stock dividend?","answer":"Stock dividends do not change shareholders' proportionate interest or voting rights in the company. Typically, a shareholder receives one vote for each stock owned, and this proportional voting power remains unchanged after a stock dividend is issued.","context":["It has no impact on the future allocation of dividends between preferred and common shares. From just prior to the stock split record date, through the stock split distribution date, two separate markets exist for IBM. The “regular way” market continued to trade at the higher, pre-split price.\n- By issuing a large quantity of new shares , the price falls, often precipitously.\n- As a result of the stock split and the cost adjustment, the stockholder now has two shares, each with a cost basis of $50 a share.\n- For each 100 shares held, shareholders receive another 5 shares.\n- Andy Smith is a Certified Financial Planner (CFP®), licensed realtor and educator with over 35 years of diverse financial management experience.\n- The market will analyze the information conveyed by these decisions and reflect it in the market price.\nMany corporations distribute cash dividends after a formal declaration is passed by the board of directors. Journal entries are required on both the date of declaration and the date of payment.\nThe service charge per sale is $15.00 plus brokerage commission (currently $0.10 per share). Sale requests are usually processed on the day of receipt, provided receipt is received before 12 p.m. Remember, you own 2,000 shares of Betty Joe’s Donuts at $12.50 per share for a total investment of $25,000. The current price https://www.bookstime.com/ of the stock is $20 x 2,000 which equals $40,000. Typically, the shareholder receives one vote for each stock he or she owns. Shareholders are able to vote on various issues, such as mergers, board of directors, and executive salaries. It’s important to note, voting does not require the shareholder’s presence.\nContact Investor Relations\nBoth stock dividends and stock splits are issued based on the company’s goals. A transfer agent for a publicly held company keeps records of stock held by registered shareholders, including shares held in certificate form. When stock changes hands, the transfer agent updates the record of ownership of the stock.\nIf the investor’s goals and the company’s goals are incompatible, the investor should consider investing in another company. For example, if the cost of one share of stock acquired prior to the record date for the 2 for 1 stock split was $100, the cost of that original one share is reduced by 50% as a result of the 2 for 1 stock split. That portion of the cost is then assigned to the one share received from the stock split. As a result of the stock split and the cost adjustment, the stockholder now has two shares, each with a cost basis of $50 a share.\nStockholders’ Equity Outline\nThe stock split does not change your proportionate interest in the company. Learn more about dividend stocks, including information about important dividend dates, the advantages of dividend stocks, dividend yield, and much more in our financial education center.\nThis study presents evidence which indicates that stock prices, on average, react positively to stock dividend and stock split announcements that are uncontaminated by other contemporaneous firm-specific announcements. In addition, it documents significantly positive excess returns on and around the ex-dates of stock dividends and splits. Both announcement and ex-date returns were found to be larger for stock dividends than for stock splits. While the announcement returns cannot be explained by forecasts of imminent increases in cash dividends, the paper offers several signaling based explanations for them. These are consistent with a cross-sectional analysis of the announcement period returns. The interesting thing to note here is that equity share capital and market capitalization are not affected because of the split. The increase in outstanding shares is compensated by the proportionate decrease in face value and stock price.\nFor example, cash dividend payments usually drop after a stock dividend but not always in proportion to the change in the number of outstanding shares. An owner might hold one hundred shares of common stock in a corporation that has paid $1 per share as an annual cash dividend over the past few years (a total of $100 per year).\n- See how corporations manage stocks regarding ownership, dividends, capital gains, and stock splits.\n- The existing IBM common stock certificates are still valid.\n- Stock dividend and stock split are two aspects that are confused easily due to many similarities between them.\n- It should be noted that this dilution is the immediate effect of a stock dividend.\n- Stock splits and stock dividends are economically the same.\nAdditionally, shareholders purchase stock hoping for capital gains. For example, if an investor purchases stock for $10 per share, then sells the stock for $15 per share, the investor’s capital gains are $5 (or $15 – $10) per share. Shares outstanding refer to a company’s stock currently held by all its shareholders, and they include share blocks and restricted shares. Therefore, a stock dividend and a stock split both dilute the stock’s price. A stock split is performed because a company’s stock is outperforming the company’s goals. Because a company does not want to encourage speculative bubbles that cannot be sustained by the market, it uses a stock split to decrease the price of stock and bring it into a more acceptable price range.\nBook entry allows share ownership without stock certificates. This system is similar to that used with investments in a mutual fund or a corporate dividend reinvestment plan. You do not need to be enrolled in a dividend reinvestment plan to have book entry ownership. The existing IBM common stock certificates are still valid.\nDifference Between Stock Dividend & Stock Split\nHence this action will drive the price up due to an increase in the demand. Unlike stock certificates, the book entry statement is not a negotiable document. While it is good practice to keep investment information in a secure place, if you lose your statement, Computershare can provide a duplicate statement on request. If you buy stock at the “regular way” price, you normally are entitled to receive the stock split shares. If you buy stock at the “when issued” price, you normally are not entitled to receive the stock split shares. IPO, an acronym for initial public offering, and going public are used synonymously. In other words, Betty Joe’s Donuts will go public and offer stock, a percentage share of the corporation, to the public.\nAssume that a board of directors feels it is useful if investors know they can buy 100 shares of the corporation’s stock for less than $5,000. In other words, they prefer to have the price of a share trading between $40 and $50 per share. If the market price of the stock rises to $80 per share, the board of directors can move the market price of the stock back into the range of $40 to $50 per share through a 2-for-1 stock split. The stock dividend increases the number of shares outstanding, just as a stock split does. With all other things remaining the same, the stock price will fall.\nLarge Stock Dividend\nA cost adjustment should be made each time the stock splits. A stock dividend is a dividend payment made to stockholders that is made in stock rather than cash. The last IBM stock split occurred in 1999 and the last stock dividend distribution occurred in 1967. View information on our 15 stock splits and 26 stock dividends. Stock dividend and stock split are two aspects that are confused easily due to many similarities between them. Both result in an increase in the number of outstanding shares in the company without affecting the total market value. On the declaration date of a small stock dividend, a journal entry is made to transfer the market value of the shares being issued from retained earnings to the paid-in capital section of stockholders’ equity.\nNo, but Apple stock can be purchased through just about any brokerage firm, including online brokerage services. How much the firm values flexibility; the greater the value of flexibility to a firm, the more inclined it will be to buy back stock. Show bioTammy teaches business courses at the post-secondary and secondary level and has a master’s of business administration in finance. Helpful articles on different dividend investing options and how to best save, invest, and spend your hard-earned money.\nWhat Does A Stock Split In The Form Of A Dividend Mean?\nFind our complete guide on all the dates that an investor should know when he is dividend investing here. Since the new shares are created after April 27, 2016, they will not be eligible for the dividend. Customized to investor preferences for risk tolerance and income vs returns mix. Harold Averkamp has worked as a university accounting instructor, accountant, and consultant for more than 25 years. He is the sole author of all the materials on AccountingCoach.com. The offers that appear in this table are from partnerships from which Investopedia receives compensation.\nWhen a stock is split, existing shareholders receive additional shares of stock, but the price of each share is reduced. The total dollar stock dividends vs stock splits amount of each shareholder’s stake in the company remains unchanged. Shareholders are investors who own a percentage of a corporation.\nWhen you sell shares at the lower “when issued” price you normally are entitled to receive the stock split shares on the shares you sold. Of course, shareholders expect something in return for purchasing stock in Betty Joe’s Donuts. Dividends are a percentage of the corporation’s profits paid to the shareholder, typically quarterly or annually. Investors are paid dividends based on the number of shares they own. If the company pays $.25 per share and you own 1,000 shares, you’ll receive $250. Corp has 10 million shares outstanding and are trading for $100. The company decides to do a 2 for 1 stock split, which brings the share outstanding to 20 million, reducing the share price to $50.\nFor example, say a firm has a market cap of $750 million, and there are 200 million shares outstanding at the stock price of $3.75 ($750/200). If there is a stock dividend declared of 0.2, the number of shares outstanding will increase by 20% to 240 million. If a company does not perform according to investor expectations, an investor will have a larger amount of his portfolio tied up in an investment that will not make as much money as expected, or might even lose money. Because stock dividends and stock splits increase the amount of stock an investor has, this disadvantage applies to both of them. The existence of a cumulative preferred stock dividend in arrears is information that must be disclosed in financial statements.\nFollowing a stock split, shares are more affordable to the investors due to the reduced share price. Stock splits are practised by many large scale companies such as Coca-Cola and Wal-Mart. If new shares issued exceeds 25% of the total number of shares outstanding prior to the stock dividend, this is classified as large stock dividend.\n- All dividends paid on ATCO Ltd. shares on or after January 1, 2006 are designated “eligible dividends” for Canadian income tax purposes unless ATCO Ltd. indicates otherwise.\n- You should have received your statement on or near May 26, 1999.\n- If the company pays a dividend, your dividends paid per share also will fall proportionately.\n- To date, three hundred thousand of these shares have been issued but twenty thousand shares were recently bought back as treasury stock.\n- A stock dividend occurs when the company uses the amount of money that would be paid as a cash dividend to purchase additional common shares for the shareholder.\nThe stock split on a 4-for-1 basis on August 28, 2020, a 7-for-1 basis on June 9, 2014, and split on a 2-for-1 basis on February 28, 2005, June 21, 2000, and June 16, 1987. Figure represents amount received by a corporation from the original issuance of capital stock that is in excess of par value; also called additional paid in capital.\nFor example, if an investor has 100 shares of a $50 stock, his investment totals $5,000. After a 2-for-1 stock split the investor will own 200 shares at worth $25 per share. A subsequent offering is the issuance of additional shares of stock after the issuing company has already had an initial public offering. A stock split is when a company increases the number of its outstanding shares of stock to boost the stock’s liquidity. With this new number of shares outstanding, the company’s market cap remains the same, but the share price will decrease to $3.13 ($750/240).\nA stock may split two for one, three for two, or any other combination. A reverse stock split occurs when a company reduces its number of outstanding shares, such as a one for two split. For a history of a company’s stock splits, check the company’s web site or contact its investor relations department. The management knows better about the company’s future than anybody else. A stock split decision in itself sends many signals about the company’s growth prospects.\nDividend & Stock Split History\nA stock dividend is considered to be small if the new shares being issued are less than 20-25% of the total number of shares outstanding prior to the stock dividend. A stock dividend is considered to be large if the new shares being issued are more than 20-25% of the total number of shares outstanding prior to the stock dividend. A stock dividend is considered to be small if the new shares issued are less than 20-25% of the total number of shares outstanding prior to the stock dividend. Rapidly growing companies often have share splits to keep the per share price from reaching stratospheric levels that could deter some investors. In the final analysis, understand that a stock split is mostly cosmetic as it does not change the underlying economics of the firm. One positive characteristic of the stock dividend and stock split is that ownership is not further diluted.\nUnlike an issuance of new shares, a stock split does not dilute the ownership interests of existing shareholders. When a company declares a stock split, its share price will decrease, but a shareholder’s total market value will remain the same."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:38f86846-8074-41df-8092-78629d5592ea>"],"error":null}
{"question":"Which had a longer life - Johnny Mercer or Alessandro Alessandroni?","answer":"Alessandro Alessandroni lived longer. He was born in 1925 and died in 2017 at age 92, while Johnny Mercer was born in 1909 and died in 1976 at age 67.","context":["The Mercer Family Collection\nJohnny Mercer was born in 1909 into a long-established Savannah (GA.) family. Mercer’s lyrics and writings recall his fond memories of a childhood and youth in Savannah and especially the family’s summerhouse in Vernon View. After prep school in Virginia, Johnny struck out for Broadway and New York’s tin pan alley and a show business career. During the 1920’s and 1930’s, Mercer sang and toured with the big bands. During this period, Mercer was lured to Hollywood where he had great success songwriting for motion pictures. Mercer became one of the most prolific and best-known lyricists of American popular song. Many have since become standards: Hooray for Hollywood, That Old Black Magic, And the Angels Sing, Moon River, Autumn Leaves, Satin Doll and Summer Wind are just a few examples of his lyrics. While Mercer sometimes wrote music, he usually worked with composers, including Hoagy Carmichael, Harold Arlen and Henri Mancini. In 1942 Mercer started Capitol Records with partners Buddy DeSlyva and Glenn Wallichs in order to provide a recording outlet for the singers, musicians and songwriters working in Southern California’s movie industry. After an active, productive career, Johnny Mercer died in Los Angeles California in 1976.\nNancy Mercer Keith Gerard, Johnny Mercer's niece donated the Mercer Family Collection to Lane Library's Special Collections in 2006. Nancy grew up in her Maternal Grandmother’s (Johnny’s mother, Lillian Cieucevich Mercer’s) home in Savannah. Pearce W. Hammond, Amanda Mercer (Johnny’s daughter) and other members of Savannah’s Friends of Johnny Mercer organization have also donated material to the Collection.\nThe Collection consists of photographs, letters and memorabilia from the Mercer Family and documenting Johnny Mercer’s life and the Mercer family in Savannah. Material in the Collection is listed in this Inventory, letters from Mercer and family photographs are described at the item level.\nAt the heart of the collection is a small set of letters home written by Johnny to his parents, George Anderson Mercer and Lillian Cieucevich Mercer. Collected by Johnny’s mother Lillian, the letters begin in the early 1930's when Johnny wrote home from New York as a struggling actor/lyrist. Letters dating from the 1940's and 1950’s reveal Johnny at the height of his career in Southern California. The letters reveal a humble, affectionate son and his thoughts of Savannah. The letters have been used in Gene Lees' published biography of Mercer, Portrait of Johnny. Some of the letters from the Collection are available digitally from the Friends of Johnny Mercer website.\nFun for study and display there are Capitol Records’ promotional items, including pajamas decorated with the record company’s hit song titles. The Collection also includes record albums and sheet music that recall popular music and the music industry from the 1920's through the 1970's.\nA selection of the family photographs from the Collection have been digitized and are available from the Special Collections’ Flickr site.\nSeveral members of the Friends of Johnny Mercer aided in establishing the Collection. Diane Thurman helped Nancy Gerard and special collections librarian Caroline Hopkinson sort and identify the many family photos in the Collection. David Oppenheim donated correspondence of Sadie Vimmerstedt to the Collection and shared copies from his files and media collection about Johnny Mercer.\nMercer descendent Pearce W. Hammond donated to the collection, including the transcription of his great-great grandfather, George A. Mercer’s civil war era diary. The original diary is in the Southern Historical Collection at UNC-Chapel Hill.\nMercer’s daughter Amanda donated two paintings by Mercer to the Collection.\nThe Mercer Family Collection is open to the public. To make an appointment to view and use the Collection during the many hours the Lane Library is open each week, please contact Caroline Hopkinson via e-mail Caroline.Hopkinson@armstrong.edu or phone: 912.344.3019.\nRecordings were made of Savannah-area family and friends of Johnny Mercer during 4 sessions in October 2007. Friends and family recounting stories of Mercer and of growing up in Savannah during the mid 20th century. The DVDs are available to view in Lane Library’s media services department (344.2967) Locator: DVD 845, discs 1 - 4\nDescriptions of the four Mercer Storytelling sessions:\nDisc 1. October 2, 2007, Nancy Mercer Keith Gerard (Johnny Mercer’s niece) and Steve Gerard (Nancy’s husband) conducted by Barbara Fertig and students in her Folklore course at the Special Collections of Lane Library, Armstrong Atlantic State University, Savannah GA 31419-1997. 1:08:59. Original recording housed in the Lane Library’s Special Collections.\nDisc 2. October 4th, 2007, Tom Coffey, Ralph Price, Connie Hartridge, Abraham Famble conducted by Barbara Fertig and students in her Folklore course at the Special Collections of Lane Library, Armstrong Atlantic State University, Savannah GA 31419-1997. 1:06:41. Original recording housed in the Lane Library’s Special Collections.\nDisc 3. October 9th 2007, Pearce W. Hammond and Anne Hancock Hammond conducted by Caroline Hopkinson and students of the Folklore course at the Special Collections of Lane Library, Armstrong Atlantic State University, Savannah GA 31419-1997. 0:42:27. Original recording housed in the Lane Library’s Special Collections.\nDisc 4. October 16th 2007, Dan O’Leary, David O’Leary and Stratton Leopold conducted by Barbara Fertig and students in her Folklore course at the Special Collections of Lane Library, Armstrong Atlantic State University, Savannah GA 31419-1997. 1:07:19. Original recording housed in the Lane Library’s Special Collections.\nThe Mercer storytelling project arose from a partnership between the Friends of Johnny Mercer organization and Armstrong Atlantic State University. Nancy Gerard recruited volunteers among friends and family to meet Armstrong students in Barbara Fertig (professor of History) course on Folklore. The students then did a course project based on the storytelling sessions. The interviews are not part of a formal oral history project, but record stories about Johnny Mercer and life in Savannah during the 1920’s-1960’s. Those interviewed, all life long residents of the area, recount stories of Johnny Mercer, the Mercer family and life in Savannah during the period. The sessions were conducted in the Florence Powell Minis Room of Lane Library’s Special Collections and videotaped by Armstrong’s CIS department.\nThe Johnny Mercer Educational Archives Maintained by Steve Taksler, this site is dedicated to the legacy of Johnny Mercer.\nInformation on the year-long celebration of Johnny Mercer's birth in 2009, is available at the Centennial Committee's website.\nJohnny Mercer Collections at Georgia State University This features a large archival collection of Mercer’s own records, and oral histories collected by the repository. The website includes databases of Mercer songs and sound recordings, and photographs.\nFriends of Johnny Mercer The Savannah organization dedicated to perpetuating the lyrics, music, life and memory of Savannah’s native son, John Herndon Mercer.\nJohnny Mercer Foundation “Our foundation’s most passionate goal is to initiate a series of dynamic new fun, hands-on educational programs designed to introduce the songs of Mercer, and Berlin, and Gershwin, and Ellington and all our great American songwriters to our children quick, before their ears change!”","Goodbye to Alessandro Alessandroni, the western world's most famous ‘whistle’\nThe composer, conductor and arranger Alessandro Alessandroni died in Rome. He had just turned 92 years-old. Celebrated for his 'whistle' which made many great soundtracks of the spaghetti western genre. 'For a Few Dollars More' is its 'booed' most iconic.\nLa Repubblica ·\nBy Valeria Rusconi and Ernesto Assante\nMarch 27, 2017\n\"It's very simple. I phoned Ennio Morricone and he told me: 'Sandro, come down here for a moment, in the room, we need you to whistle. Well, it was really a whistle, nothing more, but think about what happened next ... When we saw the film, I have to admit that no one thought it would make a penny\". And instead. Instead the 'whistling' really did change everything. Alessandro Alessandroni, the master - it is right to call him that - says the opening words of the most famous of his career and the most iconic of Western movies song that for a Fistful of Dollars, made up by Morricone, which made the film music of Sergio Leone - and practically made all the best western movies - even bigger. \"It was a great professional partnership, we had a wonderful collaboration,\" he told La Repubblica. Morricone, \"knew very well I could play the guitar and was the director of the choir and this was superb. And he knew very well that I could whistle. He had worked on A Fistful of Dollars and on other occasions. Why I chose him to whistle? by chance, I needed a whistle, I asked the musicians working with me who was able to whistle well and others I liked less. He had the courage to try\".\nThe composer, conductor and arranger Alessandro Alessandroni died in Rome, in the city that gave him birth on March 18, 1925, on March 26th. He had just turned 92 years of age. The announcement came on the official Facebook page of the composer: \"It is with great sorrow that I inform you of the death yesterday of the master Alessandro Alessandroni born in Rome on March 18, 1925, composer, multi-instrumentalist, arranger and choir director. There will be a memorial service at his home in Namibia with music and musicians directed by his son Alex Jr. Alessandroni\".\nAlessandroni approached music when he was still a boy. At the time he lived in the country of his mother, in the province of Viterbo. He was 11 years old and listened insistently, whenever he could to classical music. He began playing the guitar with assistance from a friend. The place is one of those details. He told in an interview to the blog Planet Hexacord: \"I started in the barber shop, because in small countries it is a reference point: there were the instruments, the guitar, the mandolin. They worked a little, but it sounded a lot. .. \". While he was attending the last year of high school he formed his first band, with whom he performed for local dance halls. Quick to learn, in a short time he become proficient on several instruments, which he alternates during his performances: as a teenager he already is able to play the guitar, the piano, the accordion, sax, flute, mandolin and sitar, one of the first Italians to try their hand on this complex stringed instrument. He obtained his diploma at the Conservatory in Rome, and found a job in the film production company Fonolux There he meets the great Nino Rota, his senior by 14 years, who wants him in his orchestra. Then came the whistle. It was almost by accident. Alessandroni, at some point, when Rota asked for a volunteer to whistle. Whistling become his new tool to play with and one of the moments that characterized the soundtracks of the Spaghetti Westerns. Music in effect: \"My whistle parts are on the staff,\" explained Alessandroni, \"and woe to miss the pitch, to make mistakes.\" That thought also by Federico Fellini, author of his soprannonme: Alessandroni for him was simply \"The Whistler\".\nIn 1962 he founded the octet I Cantori Moderni, a formation that takes the place of his previous group, the Caravels Quartet. With him, the band is formed by soprano Edda Dell'Orso, Augustus Garden, Franco Cossacks, Nino Dei, Enzo Gioieni, Gianna Spagnuolo and, not the least, his wife Julia De Mutiis.\nThe most important co-operation, long-lived and linked by a sincere esteem Alessandroni remains to this day one with Ennio Morricone: besides the famous whistle of For a Fistful of Dollars he also worked on For a Few Dollars More and The Good, the Bad and the Ugly. Alessandroni was used by all the most important Italian composers of the time, in the 1960s, such as Piero Umiliani, for which he sang along with his wife Giulia in great song Mah-na Mah-na, extracted from the soundtrack of Svezia inferno e paradiso by Louis Scattini (1968) and the master Armando Trovajoli. With the arrival of the seventies, for ARC of the RCA label which was dedicated to the ‘young Italian music’, between beats and 'world exotico', a public-disc collection of twelve songs in the race to the edition of 1969 of Canzonissima. Are recorded, of course, the tune and work on the Hammond organ solo is credited to Ron Alexander, his pseudonym.\nThe name of Alessandroni had become one of worship across the board, and had crossed generations and musical styles, especially he had conquered the library music enthusiasts. Among the last to want in their drive Baustelle, group of Montepulciano, who have chosen it for one of their best albums. \"Alessandro Alessandroni is the oldest guest,\" explained Francesco Bianconi, the singer, \"a wonderful eighty-four and played the sitar, accordion, acoustic guitar and he did blow the whistle\". The song title, not surprisingly, was Spaghetti Western. The Album, Amen.\nBorn: 3/18/1925, Rome, Lazio, Italy\nDied: 3/26/2017, Rome, Lazio, Italy\nAlessandro Alessandroni’s westerns – composer, musician, whistler, choir:\nA Fistful of Dollars – 1964 [guitar, whistle, choir]\nMassacre at Marble City – 1964 [choir]\nFor a Few Dollars More – 1965 [guitar, whistle]\nThe Good, the Bad and the Ugly – 1966 [guitar]\nSeven Dollars on the Red – 1966 [choir]\nAny Gun Can Play – 1967 [composer]\nPayment in Blood – 1967 [choir]\nWanted – 1967 [choir]\nOnce Upon a Time in the West – 1968 [whistle]\nThe Wild and the Dirty – 1968 [composer]\nEl Puro – 1969 [composer]\nRaise Your Hands, Dead Man, You're Under Arrest – 1971 [composer]\nZorro the Invincible – 1971 [composer]\nThe Crazy Bunch – 1974 [composer]\nWhite Fang and the Gold Diggers – 1975 [composer]\nWhite Fang and the Hunter – 1975 [composer]\nLucky Luke – 1991 [whistle]\nLucky Luke (TV) – 1991-1992 [whistle]"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:8440a41b-a467-43c3-ba77-6085815eaa41>","<urn:uuid:1a728149-280f-4449-aa0c-f52566e200f4>"],"error":null}
{"question":"How can a filmmaker use machine learning to streamline video editing tasks?","answer":"Filmmakers can use machine learning in two key ways for video editing: First, they can turn video footage of human actors into 3D wireframe models using a neural network called 'PosetNet', which is more cost-effective than using expensive motion capture equipment. Second, they can use machine learning segmentation models to automatically highlight different objects in each frame, making it easier to edit out unwanted elements from footage. These tools simplify traditionally manual and time-consuming editing processes.","context":["Machine learning can be a fantastic tool for creators, but integrating AI into your workflow is a challenge for those who can’t code. A new program called Runway ML aims to make this process easier by providing artists, designers, filmmakers, and others with an “app store” of machine learning applications that can be activated with a few clicks.\nSay you’re an animator on a budget who wants to turn a video of a human actor into a 3D model. Instead of hiring expensive motion capture equipment, you could use Runway to apply a neural network called “PosetNet” to your footage, creating wireframe models of your actor that can then be exported for animation.\nAn easy way to experiment with machine learning\nOr say you need to remove a coffee cup that was accidentally left in a shot on your high-budget fantasy TV drama. You could edit it out the traditional way, painting over the cup by hand, or you could run your footage through a machine learning segmentation model, which would automatically highlight different objects in each frame to make your job easier.\nExamples like these are just the tip of the iceberg for Runway, which co-founder Cristóbal Valenzuela describes as radically egalitarian tool. “Machine learning is a very exclusive technology,” Valenzuela tells The Verge. “But I want to make things more inclusive; to get people from different backgrounds sitting around the table and using these models.”\nRunway began as Valenzuela’s thesis project at the Tisch School of the Arts at New York University. After getting enthusiastic feedback from the AI art community, he decided to take the program mainstream, asking two school friends to come on board as co-founders and gathering seed money from NYC and Silicon Valley backers. The company was incorporated last December with a beta launch following this January.\nValenzuela straddles the fields of art and code and says he wants to bridge these two worlds, empowering non-coders to use machine learning models and, in turn, connecting researchers to the people who will benefit directly from their work.\nIn a blog post Valenzuela wrote last May, he compares the current AI art scene to painting in the 16th and 17th centuries. At that time, the act of simply storing and using paint was something of a craft secret, with painters relying on esoteric techniques involving pigs’ bladders and string. But with the invention of the paint tube in 1841, the craft became more accessible. It was also easier to conduct outdoors, leading to new styles and movements.\nDoing for AI what paint tubes did for portraiture\nAs 19th century painter Pierre-Auguste Renoir told his son: “Without colors in tubes, there would have been no Cézanne, no Monet, no Sisley or Pissarro, nothing of what the journalists were to call Impressionism.” In other words: accessibility begets creativity.\nBut what is the “paint tube” for modern artists? Valenzuela makes a convincing argument that it might be Runway — or, at least, a program that looks a lot like it.\nThe pigs’ bladders holding back progress in this case is the skill-set currently needed to use machine learning models. That means learning to use software like TensorFlow or PyTorch; it might mean buying a few pricey GPUs (because your current computer won’t run these systems), or connecting to an AWS instance instead. None of these tasks are beyond the reach of non-coders, but they certainly take time and create a bottleneck for users. By comparison, Runway’s model is the perfect paint tube: just click and go.\nThe company is not the first to make AI models easier to use of course. But earlier examples — like Lobe, which let users train AI systems using a visual interface before it was bought by Microsoft — have focused on business use cases, rather than creative ones.\nRunway’s target market is obvious when you load up its store front, which lets you browse a range of models that run the gamut from text generation to motion tracking.\nYou click to see the details of each model, click to add it to your workspace, set up your inputs and outputs, then start the system running. There are hooks to connect these outputs to other apps (so you can send ML-processed images to Photoshop, for example), and users can import new models directly from GitHub with just a few lines of code.\nThis latter point is one of the most important for Runway. It’s hard to understate just how fast-paced and collaborative the current AI art scene is, and how much individuals benefit from one another’s work and professional research. No sooner does a new model get released than it’s pounced on by the masses who use it in all sorts of unexpected ways.\nTake the AI text generation system called GPT-2, unveiled in February by research lab OpenAI. In the months since it was launched, GPT-2 has been turned into accessible web apps, it’s been used to help write a novel, and someone even created a subreddit populated entirely by chatbots mimicking other subreddits using it.\nIn short: this is a bubbling and energetic scene, and Runway wants to stay as connected to it as possible. Valenzuela says his team is constantly responding to users’ feedback, adding new models to the program and updating the software’s interface every month.\nIt’s this connection to the community and speed of updating that he says will also stop Runway from getting overrun by the industry’s established players. “We’re just four people on our team,” he says. “We like to ship things fast, to get people excited and get them using things.” And although corporate giants like Adobe certainly have a lot of interest in similar AI applications, they’re necessarily going to be slower to integrate them into products.\nThe reception Runway has received so far gives credence to Valenzuela’s comments.\n“I personally find it useful for trying out some models quickly,” says Mario Klingemann, an AI artist who recently sold his work at Sotheby’s. He says the program will be particularly useful for workshops and classes since it allows teachers to get a new machine learning model up and running in minutes.\nKlingemann has reservations too. He tells The Verge that the software is “too limited” for making his own art because it only offers pretrained models. That means if someone wants to customize the output of a generator system, like a generative adversarial network (GAN), they can’t train it on their own data. Valenzuela says this functionality will be added soon to the program, along with the ability to use the output of one model as the input of another.\nRobbie Barrat, another AI artist who’s renowned for his work with GANs, also praised the program, singling out its potential to democratize the AI art scene as particularly positive.\n“If Runway can lower the barrier for entry ... I’m all for it.”\n“Right now, it’s easiest for rich tech bros who work at Google or something, went to a fancy computer science school, and have access to huge GPU clusters at work to make artwork with neural networks,” Barrat tells The Verge. “If Runway can lower the barrier for entry and let a more diverse group of people easily create art with AI, I’m all for it.”\nBut Barrat agrees that the program’s simplicity is a limiting factor. People who want to use AI to do more than just simplify an existing step in their process will need more powerful programs than Runway, he says. “No matter how good it is as a tool, people who code will still be able to make a bigger range of things and ultimately have more control over what they produce.”\nBarrat and Klingemann also say price is a potential problem when it comes to training ML models on Runway. The software is free to download and comes with $10 of cloud credit, which is more than enough to get to know its potential. But after that, it costs users 5 cents per minute of computation. For artists like Klingemann and Barrat who need to train their own models, it’s likely cheaper to buy their own GPUs or connect to a cloud service. “I am not sure it will financially make sense to me,” says Klingemann.\nBut saying that Runway isn’t a perfect fit for all users is hardly a huge criticism. No one is surprised when their Swiss army knife can’t be used to dig a trench. And for Valenzuela, the primary mission isn’t catering to pros; it’s expanding the borders of AI art world.\n“These technologies are going to radically change the way we create content because algorithms are understanding text, video, and sound in the same way we do,” he says. “And if we put these tools in the hands of people who have never accessed these before, they’re going to start thinking of new ways to use them.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:96c36f3d-ca7e-4252-841d-b433ce71d1c4>"],"error":null}
{"question":"What role does OFDM play in modern telecommunications infrastructure, and how does signal intelligence address its security requirements in both wireless and optical implementations?","answer":"OFDM is a crucial modulation technique used in both wireless and optical communications, with particular importance in optical fiber and optical wireless systems. It has been adapted for use with LED-based indoor lighting to enable high-speed data communications. Regarding security, OFDM systems require comprehensive communication security measures including cryptosecurity, emission security, transmission security, and physical security. Signal intelligence techniques are employed to protect these systems, with particular attention to encrypted transmissions and the prevention of unauthorized interception. The most secure implementations utilize cable-based transmission, especially hardened and protected internal landlines, as these cannot be intercepted from the air like wireless signals.","context":["Jean Armstrong leads the optical/wireless research group at Monash University. Her research interests span the fields of telecommunication engineering, women in engineering and engineering education. Within the telecommunications community she is particularly well known for her many contributions to research on orthogonal frequency division multiplexing (OFDM).\nOFDM is a modulation technique which in the past was used for wireless and wired communication. In 2005 she showed how it could also be adapted to optical communications. Optical OFDM is now a key technology for both optical fiber and optical wireless communications.\nRecent research within her group has covered a range of topics (see publication list). The introduction of LEDs for energy efficient indoor lighting has provided outstanding opportunities both for very high speed data communications and for a completely new form of accurate indoor positioning with many potential applications including assistance for the visually impaired, asset tracking within hospitals and factories and accurate positioning systems for mobile robotics.\nOptics Express paper published describing new accurate visible light positioning technique Click here to go to paper\nAwarded ARC Discovery Grant for 2018-2020\nOFDM for Optical Communications paper reaches 1500 Google Scholar Citations\nAwarded the 2016 IET Mountbatten Medal Click here for IET website\nOFDM for Optical Communications paper selected for the special JLT issue: A Third of a Century of Lightwave Technology.\nOFDM for Optical Communications paper reaches 1000 Google Scholar Citations\nIEEE Globecom 2015 presented tutorial on\nOptical Wireless Communications with Maite Brandt-Pearce and Zhengyuan Xu\nMember of 2015 Australian Research Council (ARC) ERA Research Evaluation Committee\nClick here for ARC ERA website\nClass of 2015 Fellow of IEEE\nfor contributions to the theory and application of orthogonal frequency division multiplexing in wireless and optical communications Click here for FIEEE Class of 2015\nARC Discovery Grant for 2015-2017 ($384,700) with Dr Ahmet Sekercioglu for Accurate position estimation using intensity-modulated optical signals\nSecond part of Interview with Robyn Williams on The Science Show on ABC Radio National Click here for transcript, audio download and podcast\nIEEE Communications Society Best Tutorial Paper Award 2014 for \"OFDM for Optical Communications\" paper.\nAward made at ICC conference in Sydney on 11 June 2014.\nClick here for Monash Press Release\nInterview with Robyn Williams on The Science Show on ABC Radio National Click here for transcript, audio download and podcast\nPaper in IEEE Communications Magazine, December 2013 Feature topic on Visible Light Communications\nJ.Armstrong, Y. A. Sekercioglu, and A. Neild, “Visible Light Positioning: A Roadmap for International Standardization,” IEEE Communications Magazine, December 2013.\nReappointed to ARC College of Experts for 2014\nThree papers in top ten downloads from Journal of Lightwave Technology in July 2013\n1. S. D. Dissanayake and J. Armstrong, \"Comparison of ACO-OFDM, DCO-OFDM and ADO-OFDM in IM/DD Systems,\"\n4. Jean Armstrong, \"OFDM for optical communications\"\n7. T. Q. Wang, Y. A. Sekercioglu, and J. Armstrong, \"Analysis of an Optical Wireless Receiver Using a Hemispherical Lens With Application in MIMO Visible Light Communications,\"\nTutorial on Optical OFDM at ICC Conference, Budapest in June 2013\nProfessor Jean Armstrong","Good Signal Intelligence Research Paper Example\nCommunication Security (ComSec)\nCommunication security is an important section of modern telecommunication systems where signal intelligences and other methods are used to provide secure communication among peers to be connected. Signal intelligence falls into the category of cryptography where the encrypted signal is collected and analyzed for propagating secure communication. This research work will explain the requirements of communication security and will discuss how signal intelligence can be used in communication security. These solutions can be used practically in communication security of the military services.\nSignal intelligence is introduced and evolved by military services where signals from foreign communication systems are observed and analyzed . Signal intelligence has found its applications in the military services and it has become an important component of the battlefield today.\nThe rest of the document is formulated as follows. Next two sections will explain the basic concepts of communication security and signal intelligence. In the coming sections, we will explain common threats faced by communication system and their possible solutions while using signal intelligence.\nCommunication security is the field of keeping unapproved interceptors from getting to the information in a clear structure, while conveying information to the proposed receivers. In the United States Department of Defense culture, it is generally abbreviated as COMSEC. The field incorporates transmission security, cryptosecurity and physical security of COMSEC gear.\nCOMSEC is utilized to ensure both classified and unclassified movement on military communication systems, including many modes like video, voice and data. It is utilized for both wired and remote connections, and both analog and digital applications.\nVoice over secure internet protocol VOSIP has proven to be the true standard for securing voice communication, supplanting the requirement for Secure Terminal Equipment (STE) in a great part of the U.S. Department of Defense. USCENTCOM moved totally to VOSIP in 2008. COMSEC equipment is designed to provide security to the telecommunication using cryptography.\nCommunication Security has following major fields:\nCryptosecurity: The field of communication security that is related with the accessibility of highly trusted cryptosystems and their authentic use. This doesn’t only include the confidentiality, but its authenticity as well.\nEmission Security: The assurance that is possible with the help of all measures taken to preclude unapproved personal data that may be obtained from communication frameworks and cryptographic gear intercepts and investigation of trading off transmissions from cryptographic tools, data frameworks, and telecommunication systems\nTransmission Security: It is the field of communication security that results with the help of applications that are specifically designed to ensure the the transmissions from getting intercepted and exploited by other ways from cryptoanalysis like frequency hopping.\nPhysical Security: The part of communication security that results from all physical actions important to protect characterized equipment, material, and records from access of unapproved persons.\nThe most protected form of communication is through cable which can be over land or underwater. Correspondences or different signs transmitted through such links can't be grabbed out of the air. Interception of data from cable has included physically tapping of the links or utilizing \"induction\" gadgets that are set in the vicinity of the links and upkeep of equipment at the time of access. This may not be possible because of hardened and ensured internal landlines, the kind of landline that conveys much high-priority, secret commands and control interchanges. Undersea links are most defenseless since the messages transmitted by them are then transmitted by microwave hand-off once the link achieves land.\nSignal intelligence that is often abbreviated as SIGINT is the technique that is used to gather signals by intercepting. It can be communication between humans which is known to be communication intelligence abbreviated as COMINT. Other form can be the interception from electronic signals known as ELINT. Signal intelligence is the sub-domain of intelligence collection management. As delicate data is mostly encrypted signals intelligence frequently includes the utilization of cryptanalysis to decode the messages. Traffic analysis is the investigation of people communicating with each other and the amount of data shared is additionally used to determine information.\nHistory: the interception of the encrypted written information started soon after the evolution of writing. For example, Caesar Cipher is the basic encryption system\nThe interception for electronic signals started during the Boer Wars in early 1900. Some of the British radios were captured by the Boers and as no other country was transmitting other than Britain hence it was easy to interpret the transmission.\nIt has been observed that signal intelligence caused serious threats even in peacetimes. Events like USS Liberty Incwident, USS Pueblo incident and shooting down of flight 60528 has involved loss of lives.\nSIGINT has five major sub-domains classified as:\nCOMINT: By its name one can assume that it is the intelligence obtained by intercepting the communication of foreign governments or groups and then processing and analyzing it. It can be encrypted or plain transmission like voice or Morse Codes. Commonly the information gathered with the help of COMINT is the diplomatic communication from nations all over the world to their diplomatic establishments.\nELINT: is the electronic intelligence gathered from the electronic signals other than the communication signals. For example, ELINT was used in WWII in order to locate the radars with the help of signals emitted by them. The information required for electronic intelligence is signal strength, frequency and pulse lengths etc.\nRADINT: Radar intelligence is similar to electronic intelligence in which no electronic signal is intercepted from any other object but signals are transmitted by the radar itself and then information is gathered by receiving the same deflected signal. Intelligence that can be obtained include trajectory, flight paths, maneuvering and angle of descent.\nNon-imaging Infrared: is the intelligence obtained with the help of change in temperature. One can detect the absence or presence of any object or its motion with the help of non-imaging infrared intelligence\nLASINT: laser intelligence is the sub-domain that gathers information from the interception of laser transmissions.\nAbove explained techniques can be used in signal intelligence in order to analyze enemy transmission. Different techniques can be applied in different circumstances and a hybrid combination of these techniques can also be used. In order to have a brief introduction of real time issues of communication system, we have explained some common threats to be faced by the communication system in battlefield and possible solutions offered by signal intelligence are also explained.\nCommon Threats to Communication System\nCommunication system can face many challenges in the form of threats which include physical as well as logical attacks to the system. In this section, we will explain such common threats faced by the communication system. Communication security can have problems of external interruption, detection, monitoring or collection of secure information with the help of wireless signals. Signal intelligence involves collection of data which can be used for the benefits of a country after analyzing data with the help of signal intelligence tools as described in the above section. Signal intelligence can cover the communication going on wireless channels and it cannot be used for wired communication. Signal intelligence will also fail to work in an environment when enemy conducts an operation in radio silence where no radio transmission is used for communicating among different enemy groups. Geographical locations and terrain conditions also affect the performance of proper signal detection to be used by signal intelligence. Another main and common issue of signal intelligence is encrypted or cyphered signal used by the enemy. Such signals are to be deciphered in order to get useful information .\nMost common threats faced by signal intelligence are detection of wireless communication devices by the enemy, communication, monitoring, false communication, involvement in actual communication and creating noise in the communication medium between two entities. Detection of wireless communication devices can be used to find the location and identity of communicating entity. Communication monitoring can be used to extract useful information in terms of future plans and actions of the enemy along with the current status of logistics and capabilities. False communication, involvement can be used to distract the enemy from actual intentions and can be used to fail the actual plan. Noise creation or interrupting the communication medium can help to break the communication medium between enemy lines and can significantly affect the performance of enemy operations. Interrupting the communication medium with the help of noise is considered an easiest section of utilizing signal intelligence in communication security for damaging communication system of the enemy. For that purpose, electronic attacks are used. It must be kept in mind that both electronic attack and signal intelligence can’t be used at the same time. Electronic attack can ruin the signal to be used for signal intelligence and therefore there must be coordination between both operations .\nSolution to Threats with the help of Signal Intelligence\nSignal intelligence is the analysis of captured signal in order to get useful information hidden in the signal. In order to reveal such hidden information, deciphering or the decryption techniques are used as explained in the above sections. Some common threats faced by communication security are explained in the previous section. Signal intelligence can be used both for creating these threats as well as to overcome such issues in communication systems. Encryption and decryption techniques have been used for past few years in order to deal such issues of network security and communication security. Redundant bits are required in order to provide a high level of security for transmitting information that increases the overhead on actual data significantly. This overhead can be reduced with the help of signal intelligence by sending minimum required redundant or overhead bits with actual data.\nSignal intelligence is used for finding the location of the signal emitting entity with the help of intercepting the wireless signal. It is also used for future threat detection by locating the position of aircrafts or military convoy and can be used as a replacement of a radar system in some cases.\nIt is recommended to military personals to avoid extra communication through wireless channels in order to prevent from the vulnerabilities caused by signal intelligence. Enemy signals can be used to locate their position and find useful information from their communication.\nCommunication security is a common issue of today’s telecommunication networks and it faces several types of vulnerabilities while securely transmitting data from one place to another. Many possible solutions have been proposed for providing optimal communication security for telecom networks. Signal intelligence is a famous solution to the problem which deals with communication security while analyzing signal encryption and decryption techniques. This research work has explained the working of such techniques used by signal intelligence. Common threats to communication security and their solution provided by signal intelligence are explained in this paper.\nAgency, National Security. Signals Intelligence. Jan 15, 2009. https://www.nsa.gov/sigint/.\nRhodes, J. E. Signals Intelligence. US Marine Corps , 1999.\nSteve Topletz, Jonathon Logan, Kyle Williams. \"Realistic Probabilities In Modern Signals Intelligence.\" n.d.\nThe Chinese People’s Liberation Army Signals Intelligence and Cyber Reconnaissance Infrastructure. Project 2049 Institute, 2011.\nPlease remember that this paper is open-access and other students can use it too.\nIf you need an original paper created exclusively for you, hire one of our brilliant writers!\n- Paper Writer\n- Write My Paper For Me\n- Paper Writing Help\n- Buy A Research Paper\n- Cheap Research Papers For Sale\n- Pay For A Research Paper\n- College Essay Writing Services\n- College Essays For Sale\n- Write My College Essay\n- Pay For An Essay\n- Research Paper Editor\n- Do My Homework For Me\n- Buy College Essays\n- Do My Essay For Me\n- Write My Essay For Me\n- Cheap Essay Writer\n- Argumentative Essay Writer\n- Buy An Essay\n- Essay Writing Help\n- College Essay Writing Help\n- Custom Essay Writing\n- Case Study Writing Services\n- Case Study Writing Help\n- Essay Writing Service"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:3d1fd9c7-fbfd-4ed4-b75c-e042465089ab>","<urn:uuid:f0875a27-ab8b-48f5-a05f-ab5df6c46a56>"],"error":null}
{"question":"How did Senator Margaret Chase Smith demonstrate political dissent in 1950?","answer":"Senator Chase Smith spoke out against McCarthyism in 1950 before almost any other public figure, warning that the rights to think independently and hold unpopular beliefs were in danger. She did this as Senator Joseph McCarthy began his campaign of attacking dissenters whom he accused of Communist sympathies.","context":["The Right to Dissent is Crucial to American Democracy\nKey Concerns of Young Voters Highlighted\nWhat is the meaning of \"American democracy?\" What are the core values that underlie the American society and polity? These questions were addressed Tuesday during the first in a discussion series, underwritten by the Taube Philanthropies and organized by the Division of United States Studies, devoted to American democracy and values.\nDr. Donna Shalala, president of the University of Miami, suggested in her keynote address that the core values underlying American democracy reflect a philosophy of rights: the rights to religion, assembly, petition, press, and equality. Her emphasis, however, was on what she viewed as the key value: the importance of individual thought and the right to dissent.\nShalala traced dissent as it has been exercised throughout American history to the benefit of the American democracy and society. Citing George Mason, Alexis de Tocqueville, Langston Hughes, Margaret Chase Smith, and the eight senators profiled in John F. Kennedy's Profiles in Courage, Shalala commented that Kennedy's book was \"short and spare\" because legislators belong to \"an institution more apt to compromise\" than to value dissent.\nDissent, however, has served the United States well and has frequently evolved into orthodox wisdom in later years. Senator Chase Smith, for example, spoke out against McCarthyism in 1950 before almost any other public figure did so, warning that the rights to think independently and hold unpopular beliefs were in danger. She did so as Senator Joseph McCarthy began his campaign of attacking dissenters whom he accused of Communist sympathies. Shalala in effect updated Kennedy's volume by praising Senator Russell Feingold, the only senator to vote in 2001 against the USA PATRIOT Act. Perhaps, she hypothesized, \"terrorism\" has become the new \"communism.\"\nShalala, who also has served as U.S. Secretary of Health and Human Services, expressed both concern about American constitutional democracy in the years since 9/11 and faith in the activism of young people today.\n\"As a university president I have reason to hope for our democracy recovering its vitality,\" she stated. She cited the sharp increase in the youth voter turnout in recent primaries and elections and young people's interest in accessing political information through the Internet and text messages. The economy, the Iraq War, education, health care and global warming are key issues for eligible voters between the ages of 18 to 29. Their involvement is important, Shalala said, because \"democracy, like a garden, needs fresh infusions to stay vibrant.\" While democracy requires \"great and courageous individuals, in the end it is a collective act.\" For this country, it is an act built on a solid foundation of rights.\nA history of activism\nDemocracy also requires constant work and sacrifice, said Moses Boyd, principal of Integrated Solutions Group of the Washington Group. Arguing against the assumption that the Declaration of Independence and the Constitution guarantee American liberty, Boyd, a former Wilson Center Public Policy Scholar, noted that today's freedom rests on a history of activism and social movements: by African Americans and other racial and ethnic minorities, women, labor unions, sexual minorities, people with disabilities, and so on. The questions today are how the country can retain the civic engagement of young people caught up in the current election campaign, protect freedom of the press, and reform the educational system so that it conveys basic American values.\nPeter Levine, Director of The Center for Information and Research on Civil Learning and Engagement (CIRCLE), listed the pedagogical mechanisms that have proved successful in conveying American values to young people: teaching American history and government, discussing current events, mandating community service that is connected to academic studies, encouraging extra-curricular activities such as student governments and school newspapers, giving students a voice in running their schools, and organizing simulations of such phenomena as trials. Unfortunately, he said, those options are provided differently both among and within schools, with their being made available disproportionately to students who are headed to selective colleges and universities. More students must in fact be prepared for college as a step toward becoming active citizens, he argued, as only one out of 14 people with no college experience voted in recent primaries – but the rate for those people with college experience was one out of four.\nThe panelists agreed that today's young people have fewer expectations than do their parents of government acting in ways that will benefit them. The unanswered question is what that will do to their participation in civic life and in their adherence to and perpetuation of basic American values."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:b37111ca-b326-4cf8-b513-427e3bd66105>"],"error":null}
{"question":"What's the primary distinction between ancient Egyptian evergreen practices and Forestry England's current Christmas tree care recommendations?","answer":"Ancient Egyptians used green palm rushes in their homes during the winter solstice as a symbolic decoration to celebrate their sun god Ra's recovery from illness and represent the triumph of life over death. In contrast, Forestry England now provides specific scientific care instructions for Christmas trees, emphasizing the importance of temperature control and water maintenance. They recommend keeping trees away from radiators to avoid temperature fluctuations, placing them in stands with water wells, and checking water levels daily to maintain the tree's freshness throughout the holiday season.","context":["The history of Christmas trees goes back to the symbolic use of evergreens in ancient Egypt and Rome and continues with the German tradition of candlelit Christmas trees first brought to America in the 1800s. Discover the history of the Christmas tree, from the earliest winter solstice celebrations to Queen Victoria’s decorating habits and the annual lighting of the Rockefeller Center tree in New York City.\nHow Did Christmas Trees Start?\nLong before the advent of Christianity, plants and trees that remained green all year had a special meaning for people in the winter. Just as people today decorate their homes during the festive season with pine, spruce, and fir trees, ancient peoples hung evergreen boughs over their doors and windows. In many countries it was believed that evergreens would keep away witches, ghosts, evil spirits, and illness.\nIn the Northern hemisphere, the shortest day and longest night of the year falls on December 21 or December 22 and is called the winter solstice. Many ancient people believed that the sun was a god and that winter came every year because the sun god had become sick and weak. They celebrated the solstice because it meant that at last the sun god would begin to get well. Evergreen boughs reminded them of all the green plants that would grow again when the sun god was strong and summer would return.\nThe ancient Egyptians worshipped a god called Ra, who had the head of a hawk and wore the sun as a blazing disk in his crown. At the solstice, when Ra began to recover from his illness, the Egyptians filled their homes with green palm rushes, which symbolized for them the triumph of life over death.\nEarly Romans marked the solstice with a feast called Saturnalia in honor of Saturn, the god of agriculture. The Romans knew that the solstice meant that soon, farms and orchards would be green and fruitful. To mark the occasion, they decorated their homes and temples with evergreen boughs.\nIn Northern Europe the mysterious Druids, the priests of the ancient Celts, also decorated their temples with evergreen boughs as a symbol of everlasting life. The fierce Vikings in Scandinavia thought that evergreens were the special plant of the sun god, Balder.\nChristmas Trees From Germany\nGermany is credited with starting the Christmas tree tradition as we now know it in the 16th century when devout Christians brought decorated trees into their homes. Some built Christmas pyramids of wood and decorated them with evergreens and candles if wood was scarce. It is a widely held belief that Martin Luther, the 16th-century Protestant reformer, first added lighted candles to a tree. Walking toward his home one winter evening, composing a sermon, he was awed by the brilliance of stars twinkling amidst evergreens. To recapture the scene for his family, he erected a tree in the main room and wired its branches with lighted candles.\nWho Brought Christmas Trees to America?\nMost 19th-century Americans found Christmas trees an oddity. The first record of one being on display was in the 1830s by the German settlers of Pennsylvania, although trees had been a tradition in many German homes much earlier. The Pennsylvania German settlements had community trees as early as 1747. But, as late as the 1840s Christmas trees were seen as pagan symbols and not accepted by most Americans.\nIt is not surprising that, like many other festive Christmas customs, the tree was adopted so late in America. To the New England Puritans, Christmas was sacred. The pilgrims’s second governor, William Bradford, wrote that he tried hard to stamp out “pagan mockery” of the observance, penalizing any frivolity. The influential Oliver Cromwell preached against “the heathen traditions” of Christmas carols, decorated trees, and any joyful expression that desecrated “that sacred event.” In 1659, the General Court of Massachusetts enacted a law making any observance of December 25 (other than a church service) a penal offense; people were fined for hanging decorations. That stern solemnity continued until the 19th century, when the influx of German and Irish immigrants undermined the Puritan legacy.\nIn 1846, the popular royals, Queen Victoria and her German Prince, Albert, were sketched in the Illustrated London News standing with their children around a Christmas tree. Unlike the previous royal family, Victoria was very popular with her subjects, and what was done at court immediately became fashionable—not only in Britain, but with fashion-conscious East Coast American Society. The Christmas tree had arrived.\nBy the 1890s Christmas ornaments were arriving from Germany and Christmas tree popularity was on the rise around the U.S. It was noted that Europeans used small trees about four feet in height, while Americans liked their Christmas trees to reach from floor to ceiling.\nThe early 20th century saw Americans decorating their trees mainly with homemade ornaments, while the German-American sect continued to use apples, nuts, and marzipan cookies. Popcorn joined in after being dyed bright colors and interlaced with berries and nuts. Electricity brought about Christmas lights, making it possible for Christmas trees to glow for days on end. With this, Christmas trees began to appear in town squares across the country and having a Christmas tree in the home became an American tradition.\nRockefeller Center Christmas Tree\nThe Rockefeller Center tree is located at Rockefeller Center, west of Fifth Avenue from 47th through 51st Streets in New York City.\nThe Rockefeller Center Christmas Tree dates back to the Depression era. The tallest tree displayed at Rockefeller Center arrived in 1948. It was a Norway Spruce that measured 100 feet tall and hailed from Killingworth, Connecticut.\nThe first tree at Rockefeller Center was placed in 1931. It was a small unadorned tree placed by construction workers at the center of the construction site. Two years later, another tree was placed there, this time with lights. These days, the giant Rockefeller Center tree is laden with over 25,000 Christmas lights.\nChristmas Trees Around the World\nChristmas Trees in Canada\nGerman settlers migrated to Canada from the United States in the 1700s. They brought with them many of the things associated with Christmas we cherish today—Advent calendars, gingerbread houses, cookies—and Christmas trees. When Queen Victoria’s German husband, Prince Albert, put up a Christmas tree at Windsor Castle in 1848, the Christmas tree became a tradition throughout England, the United States, and Canada.\nChristmas Trees in Mexico\nIn most Mexican homes the principal holiday adornment is el Nacimiento (Nativity scene). However, a decorated Christmas tree may be incorporated in the Nacimiento or set up elsewhere in the home. As purchase of a natural pine represents a luxury commodity to most Mexican families, the typical arbolito (little tree) is often an artificial one, a bare branch cut from a copal tree (Bursera microphylla) or some type of shrub collected from the countryside.\nChristmas Trees in Great Britain\nThe Norway spruce is the traditional species used to decorate homes in Britain. The Norway spruce was a native species in the British Isles before the last Ice Age, and was reintroduced here before the 1500s.\nChristmas Trees in Greenland\nChristmas trees are imported, as no trees live this far north. They are decorated with candles and bright ornaments.\nChristmas Trees in Guatemala\nThe Christmas tree has joined the “Nacimiento” (Nativity scene) as a popular ornament because of the large German population in Guatemala. Gifts are left under the tree on Christmas morning for the children. Parents and adults do not exchange gifts until New Year’s Day.\nChristmas Trees in Brazil\nAlthough Christmas falls during the summer in Brazil, sometimes pine trees are decorated with little pieces of cotton that represent falling snow.\nChristmas Trees in Ireland\nChristmas trees are bought anytime in December and decorated with colored lights, tinsel, and baubles. Some people favor the angel on top of the tree, others the star. The house is decorated with garlands, candles, holly, and ivy. Wreaths and mistletoe are hung on the door.\nChristmas Trees in Sweden\nMost people buy Christmas trees well before Christmas Eve, but it’s not common to take the tree inside and decorate it until just a few days before. Evergreen trees are decorated with stars, sunbursts, and snowflakes made from straw. Other decorations include colorful wooden animals and straw centerpieces.\nChristmas Trees in Norway\nNowadays Norwegians often take a trip to the woods to select a Christmas tree, a trip that their grandfathers probably did not make. The Christmas tree was not introduced into Norway from Germany until the latter half of the 19th century; to the country districts it came even later. When Christmas Eve arrives, there is the decorating of the tree, usually done by the parents behind the closed doors of the living room, while the children wait with excitement outside. A Norwegian ritual known as “circling the Christmas tree” follows, where everyone joins hands to form a ring around the tree and then walk around it singing carols. Afterwards, gifts are distributed.\nChristmas Trees in Ukraine\nCelebrated on December 25th by Catholics and on January 7th by Orthodox Christians, Christmas is the most popular holiday in the Ukraine. During the Christmas season, which also includes New Year’s Day, people decorate fir trees and have parties.\nChristmas Trees in Spain\nA popular Christmas custom is Catalonia, a lucky strike game. A tree trunk is filled with goodies and children hit at the trunk trying to knock out the hazel nuts, almonds, toffee, and other treats.\nChristmas Trees in Italy\nIn Italy, the presepio (manger or crib) represents in miniature the Holy Family in the stable and is the center of Christmas for families. Guests kneel before it and musicians sing before it. The presepio figures are usually hand-carved and very detailed in features and dress. The scene is often set out in the shape of a triangle. It provides the base of a pyramid-like structure called the ceppo. This is a wooden frame arranged to make a pyramid several feet high. Several tiers of thin shelves are supported by this frame. It is entirely decorated with colored paper, gilt pine cones, and miniature colored pennants. Small candles are fastened to the tapering sides. A star or small doll is hung at the apex of the triangular sides. The shelves above the manger scene have small gifts of fruit, candy, and presents. The ceppo is in the old Tree of Light tradition which became the Christmas tree in other countries. Some houses even have a ceppo for each child in the family.\nChristmas Trees in Germany\nMany Christmas traditions practiced around the world today started in Germany.\nIt has long been thought that Martin Luther began the tradition of bringing a fir tree into the home. According to one legend, late one evening, Martin Luther was walking home through the woods and noticed how beautifully the stars shone through the trees. He wanted to share the beauty with his wife, so he cut down a fir tree and took it home. Once inside, he placed small, lighted candles on the branches and said that it would be a symbol of the beautiful Christmas sky. The Christmas tree was born.\nAnother legend says that in the early 16th century, people in Germany combined two customs that had been practiced in different countries around the globe. The Paradise tree (a fir tree decorated with apples) represented the Tree of Knowledge in the Garden of Eden. The Christmas Light, a small, pyramid-like frame, usually decorated with glass balls, tinsel and a candle on top, was a symbol of the birth of Christ as the Light of the World. Changing the tree’s apples to tinsel balls and cookies and combining this new tree with the light placed on top, the Germans created the tree that many of us know today.\nModern Tannenbaum (Christmas trees) are traditionally decorated in secret with lights, tinsel and ornaments by parents and then lit and revealed on Christmas Eve with cookies, nuts and gifts under its branches.\nChristmas Trees in South Africa\nChristmas is a summer holiday in South Africa. Although Christmas trees are not common, windows are often draped with sparkling cotton wool and tinsel.\nChristmas Trees in Saudi Arabia\nChristian Americans, Europeans, Indians, Filipinos, and others living here have to celebrate Christmas privately in their homes. Christmas lights are generally not tolerated. Most families place their Christmas trees somewhere inconspicuous.\nChristmas Trees in Philippines\nFresh pine trees are too expensive for many Filipinos, so handmade trees in an array of colors and sizes are often used. Star lanterns, or parol, appear everywhere in December. They are made from bamboo sticks, covered with brightly colored rice paper or cellophane, and usually feature a tassel on each point. There is usually one in every window, each representing the Star of Bethlehem.\nChristmas Trees in China\nOf the small percentage of Chinese who do celebrate Christmas, most erect artificial trees decorated with spangles and paper chains, flowers, and lanterns. Christmas trees are called “trees of light.”\nChristmas Trees in Japan\nFor most of the Japanese who celebrate Christmas, it’s purely a secular holiday devoted to the love of their children. Christmas trees are decorated with small toys, dolls, paper ornaments, gold paper fans and lanterns, and wind chimes. Miniature candles are also put among the tree branches. One of the most popular ornaments is the origami swan. Japanese children have exchanged thousands of folded paper “birds of peace” with young people all over the world as a pledge that war must not happen again.\nChristmas Tree Trivia\nChristmas trees have been sold commercially in the United States since about 1850.\nIn 1979, the National Christmas Tree was not lighted except for the top ornament. This was done in honor of the American hostages in Iran.\nBetween 1887-1933 a fishing schooner called the Christmas Ship would tie up at the Clark Street bridge and sell spruce trees from Michigan to Chicagoans.\nThe tallest living Christmas tree is believed to be the 122-foot, 91-year-old Douglas fir in the town of Woodinville, Washington.\nSince 1966, the National Christmas Tree Association has given a Christmas tree to the President and first family.\nMost Christmas trees are cut weeks before they get to a retail outlet.\nIn 1912, the first community Christmas tree in the United States was erected in New York City.\nChristmas trees generally take six to eight years to mature.\n100,000 people are employed in the Christmas tree industry.\n98 percent of all Christmas trees are grown on farms.\nMore than 1,000,000 acres of land have been planted with Christmas trees.\n77 million Christmas trees are planted each year.\nOn average, over 2,000 Christmas trees are planted per acre.\nYou should never burn your Christmas tree in the fireplace. It can contribute to creosote buildup.\nOther types of trees such as cherry and hawthorns were used as Christmas trees in the past.\nThomas Edison’s assistants came up with the idea of electric lights for Christmas trees.\nIn 1963, the National Christmas Tree was not lit until December 22nd because of a national 30-day period of mourning following the assassination of President Kennedy.\nTeddy Roosevelt banned the Christmas tree from the White House for environmental reasons.\nIn the first week, a tree in your home will consume as much as a quart of water per day.\nTinsel was once banned by the government. Tinsel contained lead at one time. Now it’s made of plastic.\nIn 1984, the National Christmas Tree was lit on December 13th with temperatures in the 70s, making it one of the warmest tree lightings in history.\n34 to 36 million Christmas trees are produced each year and 95 percent are shipped or sold directly from Christmas tree farms.\nThe best-selling trees are Scotch Pine, Douglas Fir, Fraser Fir, Balsam Fir and White Pine.","Forestry England’s guide to choosing the perfect Christmas tree\nChristmas comes but once a year and choosing your Christmas tree is undoubtedly one of the highlights of the festive season. But how do you choose the best Christmas tree for your family and keep it looking good throughout Christmas and into the New Year?\nForestry England’s Christmas tree expert Rob Lamb reveals his top tips to picking the perfect Christmas tree and how to look after it.\nChoose the best variety for you and your family\nFor trees that are grown in Britain, Rob recommends three species: Norway spruce, Nordmann fir and Lodgepole pine.\n“Each of these tree species is a bit different in size, shape and scent, so choosing one is really down to personal preference”, says Rob.\n“If you appreciate the traditional look and smell of Christmas then the Norway spruce is for you. Spruce is a magnificent scent that will make your home smell all Christmassy.\n“If you have young children the soft, big needles of the lodgepole pine is a great choice. Though it is a bit less common than other varieties, it’s a fantastic tree with lush green needles and a wonderful pine scent.\n“And for keeping needles off the carpet, you can’t beat the Nordmann fir. It’s has soft foliage and an even shape and extra strong branches make it a real joy to decorate.”\nOnce you have decided which tree is your perfect match, the real fun begins. Our British-grown Christmas trees are available across the nation’s forests – find your nearest location.\nBefore leaving the house to pick out your new tree, it’s a good idea to pull out your decorations to make sure you have everything you need. At the very least, Rob recommends finding your tree stand:\n“There’s little more frustrating when buying a Christmas tree than returning home with your tree only to realise you’ve misplaced your tree stand, or that it’s broken. Avoid awkward improvisations or unnecessary trips by doing a quick check that everything is in order before you leave.”\nDon’t have a stand or need a new one? Rob recommends choosing a Christmas tree stand that can keep the tree well-watered:\n“Your Christmas tree needs to be kept in water all the time, so finding a base with a good well that you can fill is important.”\nLocation, location, location\nTrees don’t like fluctuating temperatures or to be too hot, which can cause them to dry out very quickly. Rob’s advice: keep it cool.\n“Your tree’s natural habitat at this time of year is out in the cold air”, he says. “Minimise the shock of moving it inside and keep your tree happy by giving it some space away from the radiator.”\nRob also recommends checking your tree’s water supply every day and make sure the trunk is nicely submerged.\nMake it magical\nMost importantly, make choosing your tree even more magical by getting it from the heart of the forest.\n“I love visiting forests during winter. From cold, crisp, frosty mornings to chilly starlit evenings they are a magical place to be and the perfect place to pick your home-grown Christmas tree.”\nForestry England is opening Christmas tree sales centres across the country, offering high-quality real Christmas trees from the heart of the forest. All trees are grown in the UK and certified by Grown in Britain, and all Norway spruce trees are certified by both Grown in Britain and the Forest Stewardship Council (FSC).\nThere will also be a range of events from illuminated trails to stargazing for the whole family to enjoy, offering the perfect location for a Christmassy day out.\nTo find your nearest sales centre and find more information on events across England visit www.forestryengland.uk/christmas\nNotes to Editor\n- Photos can be downloaded here. Please credit: Forestry England/Crown Copyright\n- Forestry England manages and cares for the nation’s 1,500 woods and forests, with over 230 million visits per year. As England’s largest land manager, we shape landscapes and are enhancing forests for people to enjoy, wildlife to flourish and businesses to grow. For more information visit forestryengland.uk. Forestry England is an agency of the Forestry Commission.\n- Forestry England sells around Grown in Britain and potted Christmas Christmas trees across the country:\nChristmas tree sale centres:\n- Sherwood Forest, Nottinghamshire\n- Cannock Chase, Staffordshire\n- Delamere Forest, Cheshire\n- Dalby Forest, North Yorkshire\n- Guisborough Forest, North Yorkshire\n- Hamsterley Forest, Durham\n- Whinlatter Forest, Cumbria\n- Rothbury Forest, Northumberland\n- Bedgebury Pinetum, Kent\n- Queen Elizabeth Country Park, Hampshire\n- New Park, Hampshire\n- Moors Valley Country Park, Dorset\n- Wyre Forest, Worcestershire"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:39abe832-30e8-4211-ba52-864494fcdc0e>","<urn:uuid:1b10a0b9-3170-4033-8ac2-f03fdbc095f3>"],"error":null}
{"question":"As a nutritionist specializing in infant care, I'm researching honey safety and composition. What are the specific risks of giving honey to infants, and what unique nutritional properties does honey contain?","answer":"Honey should never be given to infants under 1 year old because it can contain Clostridium botulinum spores and toxins that cause infant botulism, a life-threatening paralytic disease. While older children and adults' mature digestive systems can safely process these toxins, babies between 3 weeks to 6 months are particularly vulnerable. Regarding nutritional properties, honey contains unique antimicrobial agents and antioxidants. It includes beneficial phytonutrients like caffeic acid methyl caffeate, phenylethyl caffeate, and phenylethyl dimethylcaffeate, which have shown cancer-preventing and anti-tumor properties. However, these benefits are largely eliminated when honey is extensively processed and heated.","context":["It is recommended to introduce whole egg into your child’s diet in the first year of their life – around six months of age, but not before four months.\nCan babies have raw eggs?\nRaw and lightly cooked eggs\nBabies can have eggs from around 6 months. If the eggs are hens’ eggs and they have a red lion stamped on them, or you see a red lion with the words “British Lion Quality” on the box, it’s fine for your baby to have them raw (for example, in homemade mayonnaise) or lightly cooked.\nAre raw eggs healthy for babies?\nBottom Line: Infants, pregnant women, older adults and other high-risk groups should avoid eating raw eggs. In these groups, Salmonella infection may lead to serious, life-threatening complications.\nCan a 6 month old have honey?\nThat’s why babies younger than 1 year old should never be given honey. These bacteria are harmless to older kids and adults. That’s because their mature digestive systems can move the toxins through the body before they cause harm. Infant botulism usually affects babies who are 3 weeks to 6 months old.\nCan I give scrambled egg to my 7 month old?\nYou can give your baby the entire egg (yolk and white), if your pediatrician recommends it. Around 6 months, puree or mash one hard-boiled or scrambled egg and serve it to your baby. … Around 8 months, scrambled egg pieces are a fantastic finger food.\nWhen can baby eat raw egg?\nFood containing raw or minimally cooked eggs can contain Salmonella which is why it’s advised to wait until your child is 12 months or older before serving runny eggs. When starting solids, make the introduction of different foods gradual, both in terms of quantity and the speed of feeding.\nCan 1 year old eat raw egg?\nWait until your child is over 1 year old. Raw or lightly cooked eggs, or egg products that contain raw eggs, including some salad dressings, cookie dough, cake batter, sauces and drinks (like homemade eggnog). … Tip: Use pasteurized egg products when making uncooked food that calls for raw eggs.\nHow many eggs can a baby eat in a week?\nHow many eggs can toddlers eat? The official scientific recommendation says to serve up to 7 eggs per week. This can mean one a day, or two to three a day if you don’t serve them daily.\nWhy can’t babies have strawberries?\nBerries, including strawberries, aren’t considered a highly allergenic food. But you may notice that they can cause a rash around your baby’s mouth. Acidic foods like berries, citrus fruits, and veggies, and tomatoes can cause irritation around the mouth, but this reaction shouldn’t be considered an allergy.\nCan 8 month old have salt in food?\nThere’s no need to add salt to your baby’s food. Babies need only a very small amount of salt: less than 1g (0.4g sodium) a day until they are 12 months. Your baby’s kidneys can’t cope with more salt than this.\nIs honey poisonous to babies?\nIs this true? Yes, babies younger than 1 year old should not be given honey. Clostridium bacteria that cause infant botulism usually thrive in soil and dust. They also can contaminate some foods — honey, in particular.\nHow do I give my 7 month old eggs?\nHard boil an egg, peel off the shell, and take the yolk out. Mash it together with breast milk, formula, (or whole milk if your baby is over 1 year old). As your baby begins eating more foods, you may also mash the yolk with avocado, banana, sweet potato, and other pureed fruits and vegetables.\nWhat kind of food can I give my 7 month old baby?\nBy now, your baby’s diet should include grains, fruits, vegetables, and meats, and they should be eating two to three meals a day. In addition to rice, barley, or oat cereal, you can introduce grain products your baby can grab, such as toast, crackers, and dry cereal. Avoid any colorful, sugary cereals.\nCan you give a 6 month old hard boiled egg?\nWHEN TO INTRODUCE EGG to BABY\nWhether you start baby on purees or are doing baby-led weaning, eggs are an amazing first food for baby! You can serve them from 4+ months of age.","Honey is the wonderfully rich golden liquid that is the miraculous product of honeybees and a naturally delicious alternative to white sugar. Although it is available throughout the year, it is an exceptional treat in the summer and fall when it has just been harvested and is at its freshest.\nHoney comes in a range of colors including white, amber, red, brown and almost black. Its flavor and texture vary with the type of flower nectar from which it was made. While the most commonly available honeys are made from clover, alfalfa, heather and acacia flowers, honey can be made from a variety of different flowers, including thyme, buckwheat, and lavender.\nHow Bees Make Honey\nThe fascinating process of making honey begins when the bees feast on flowers, collecting the flower nectar in their mouths. This nectar then mixes with special enzymes in the bees’ saliva, a process that turns it into honey. The bees carry the honey back to the hive where they deposit it into the cells of the hive’s walls. The fluttering of their wings provides the necessary ventilation to reduce the moisture’s content making it ready for consumption.\nThe History of Honey\nHoney has been used since ancient times both as a food and as a medicine. Apiculture, the practice of beekeeping to produce honey, dates back to at least 700 BC. For many centuries, honey was regarded as sacred due to its wonderfully sweet properties as well as its rarity. It was used mainly in religious ceremonies to pay tribute to the gods, as well as to embalm the deceased. Honey was also used for a variety of medicinal and cosmetic purposes. For a long time in history, its use in cooking was reserved only for the wealthy since it was so expensive that only they could afford it.\nThe prestige of honey continued for millennia until one fateful event in culinary and world history—the “discovery” of refined sugar made from sugar cane or sugar beets. Once these became more widely available, they were in great demand since they provided a relatively inexpensive form of sweetening. With their growing popularity, honey became displaced by sugar for culinary use. Since then, although honey is still used for sweetening, much of its use has become focused on its medicinal properties and its use in confectionary.\nHoney’s Nutritional Benefits\nIn addition to its reputation as Nature’s nutritive sweetener, research also indicates that honey’s unique composition makes it useful as an antimicrobial agent and antioxidant.\nThe health benefits of honey—like all foods—do depend on the quality of the honey. But in this case, the situation is even more extreme, because the pollen that collects on the bees’ legs as they move from plant to plant is only as healthful and as diverse as those plants. In addition, the processing of honey often removes many of the phytonutrients found in raw honey as it exists in the hive. Raw honey, for example, contains small amounts of the same resins found in propolis.\nPropolis, sometimes called “bee glue,” is actually a complex mixture of resins and other substances that honeybees use to seal the hive and make it safe from bacteria and other micro-organisms. Honeybees make propolis by combining plant resins with their own secretions. However, substances like road tar have also been found in propolis. Bee keepers sometimes use special screens around the inside of the hive boxes to trap propolis, since bees will spread this substance around the honeycomb and seal cracks with the anti-bacterial, anti-viral, and anti-fungal resins.\nThe resins found in propolis only represent a small part of the phytonutrients found in propolis and honey, however. Other phytonutrients found both in honey and propolis have been shown to possess cancer-preventing and anti-tumor properties. These substances include caffeic acid methyl caffeate, phenylethyl caffeate, and phenylethyl dimethylcaffeate. Researchers have discovered that these substances prevent colon cancer in animals by shutting down activity of two enzymes, phosphatidylinositol-specific phospholipase C and lipoxygenase. When raw honey is extensively processed and heated, the benefits of these phytonutrients are largely eliminated.\nSelecting and Storing Honey\nHoney is sold in individual containers or in bulk. It is usually pasteurized, although oftentimes at farmer’s markets you can find raw honey. Raw honey that has not been pasteurized, clarified, or filtered—provided it is of the highest nutritional quality and safety—is your best choice. Look for honey that states “100% pure.” While regular honey is translucent, creamy honey is usually opaque and is made by adding finely crystallized honey back into liquid honey. Specialty honeys, made from the nectar of different flowers, such as thyme and lavender, are also available. Remember that the darker the color, the deeper the flavor.\nIt is important to keep honey stored in an airtight container so that it doesn’t absorb moisture from the air. Honey stored this way in a cool dry place will keep almost indefinitely. One reason for this is that its high sugar content and acidic pH help to inhibit microorganism growth. Honey that is kept at colder temperatures tends to thicken, while honey that is kept at higher temperatures has a tendency to darken and have an altered flavor.\nTips For Cooking With Honey\nIf your honey has crystallized, placing the container in hot water for 15 minutes will help return it to its liquid state. Do not heat honey in the microwave as this alters its taste by increasing its hydroxymethylfurfural (HMF) content. To prevent honey from sticking to measuring cups and spoons, use honey that is in its liquid form.\nHoney makes a good replacement for sugar in most recipes. Since honey is sweeter than sugar, you need to use less, one-half to three-quarters of a cup for each cup of sugar. For each cup of sugar replaced, you should also reduce the amount of liquid in the recipe by one-quarter of a cup. In addition, reduce the cooking temperature by 25°F since honey causes foods to brown more easily.\nSome of our favorite ways to use honey include:\n- Using it in place of table sugar as a sweetener in your tea.\n- Drizzling apple slices with honey and sprinkling them with cinnamon.\n- To enjoy sweetened yogurt without excess sugar, mix a little honey into plain yogurt.\n- A delicious sandwich that is enjoyed by kids of all ages is a combination of peanut (or almond) butter, with bananas and honey.\n- In a saucepan over low heat, combine soymilk, honey and unsweetened dark chocolate to make a deliciously nutritious chocolate “milk” drink.\nSafety Concerns Related to Honey\nRemember that the quality of honey is a function of the plants and environment from which pollen, saps, nectars and resins were gathered. Other substances found in the environment—including traces of heavy metals, pesticides, and antibiotics—have been shown to appear in honey. The amount varies greatly.\nDo not feed honey-containing products or use honey as a flavoring for infants under one year of age; honey may contain Clostridium botulinumspores and toxins that can cause infant botulism, a life-threatening paralytic disease.\nSource: The World’s Healthiest Foods"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:1d8e5541-c8cf-4a11-b077-da40ea09919f>","<urn:uuid:2ec5e7fa-00bc-4843-a56e-78db1525a551>"],"error":null}
{"question":"Can you explain the fundamental principles of how food coloring works when trying to achieve red versus pink coloration?","answer":"Food coloring works through subtractive mixing principles, where the final color depends on how wavelengths of light are removed. When using red food coloring, it often appears pink because it gets diluted - for example, when adding red food coloring to white frosting, the red will always be diluted to a pink shade since it is a weak form of the color. It takes a large amount of red food coloring (a full 1-ounce bottle) to achieve a true red color, and even then, the white base color of frosting can prevent achieving a deep red due to the subtractive mixing process.","context":["The Dimensions of Colour\nBasics of Light and Shade\nBasics of Colour Vision\nAdditive Colour Mixing\nSubtractive Colour Mixing\nColour Mixing in Paints\nLightness and Chroma\nBrightness and Saturation\nPrinciples of Colour\nPART 5. SUBTRACTIVE COLOUR MIXING\n5.1 SUBTRACTIVE MIXING PROCESSES\n- Subtractive mixing in coloured filters\n- Subtractive mixing and coloured illumination\n- Subtractive mixing in traditional paint media\n- Subtractive mixing in digital painting\nAs we have just seen, if we pass beams of light through two separate coloured filters and then combine the beams, the resulting \"colour mixing\" (strictly, colour stimulus mixing) is classed as additive mixing. A different kind of \"colour mixing\" occurs if we instead overlap the two filters and pass a single beam through them together. Now the effect of the second filter is to remove light that has passed through the first filter, rather than to add to that light, and so the process is generally known as subtractive colour mixing. The resulting beam consists of those wavelengths that are transmitted by both filters, as opposed to either filter in the case of additive mixing (Fig. 5.1.1).\nFigure 5.1.1. Additive and subtractive mixing contrasted using ideal yellow and cyan filters. Adding cyan and yellow light gives greenish white light; successively removing light with cyan and yellow filters gives saturated green light.\nThe result of subtractive mixing of two filters is calculated by multiplying together the percentage of light energy passed on by both filters, for each wavelength of the visible spectrum. (This has led some to prefer the term multiplicative mixing). Thus if 20% of a particular wavelength is passed on by one filter and 50% of the same wavelength is passed on by the other, the subtractive result will be 20% of 50%, or 10%. If any wavelength is completely blocked by one or other filter, then that wavelength will be absent from the result. In the theoretical example of Fig 5.1.1, an ideal yellow filter transmits all light in the red-orange and green bands of the spectrum, but no blue-violet light, while the ideal cyan filter transmits all light in the green and blue-violet bands, but no red-orange light, and so subtractive mixing leaves only the spectral component that the two filters have in common: green.\nTake a moment at this point to make sure that you have completely eradicated from your mind the naive idea that green is \"made of\" yellow and blue. Subtractive mixing doesn't work like that. We get a green mixture from yellow and cyan because these components both are partly (so to speak) \"made of\" green. If any colour can be said to be \"made of\" yellow and blue, it's white!\nThe colour stimulus resulting from the interaction of a coloured object with a coloured light source is another example of subtractive mixing (Fig. 5.1.2). Here we think of the incident light as having had certain wavelengths removed compared to white light, and we multiply the percentage of each wavelength present with the percentage of that wavelength reflected by the object. How this stimulus is actually perceived, however, will depend on the degree to which the observer's vision adapts to the colour of the light source.\nFigure 5.1.2. Cyan coloured ball under yellow light. IMAGE: D. Briggs, Photoshop CS2.\nSubtractive mixing is important to artists using traditional paint media because of its role in the physical mixing and glazing of paints. Subtractive mixing is involved in mixing or glazing of physical colourants because most light will be influenced successively by particles of each component colourant (Figs 6.1.2, 6.1.3). Once again the result of the subtractive interaction is calculated by multiplying the percentages of light passed on by each colourant, wavelength by wavelength throughout the spectrum.\nBecause of the phenomenon known as metamerism, two colourants may be similar in colour, but have somewhat different spectral reflectance curves, and consequently the exact results of subtractive mixing of real colourants can not be predicted merely from their colour. This uncertainty should not be overstated, however. All common cyan and yellow colourants combined subtractively will make a green; only the precise appearance and spectral composition of that green will depend on the specific colourants used.\nSubtractive mixing in digital media is emulated by blending layers in Multiply mode, which multiplies the RGB values of a layer with the underlying RGB values. This blending operates on the nonlinear (perceptual) RGB values, but because it is a multiplication, the resulting colour is the same as if it were done on the linear (physical) RGB values. Subtractive mixing is simpler in digital media than in traditional media and in nature, in that there are only three bands of the spectrum to be considered. It gives a realistic representation of what subtractive mixing involving comparably coloured lights and materials might result in, but real-world subtractive mixing could give a somewhat different result because it depends on the actual spectra of the lights and materials involved. Unrealistic effects may result from subtractively mixing very bright and/or very saturated digital colours that are outside the range of real object colours.\nEven in a program such as Painter, which cleverly simulates the appearance and physical behaviour of artists' paints, colours nevertheless still mix by ideal subtractive rules (e.g. \"Monitor yellow\" and \"Monitor blue\" mix to make black or grey, while paints of similar hues would mix to a dull green).\nModified August 13, 2012. For original (2007) page see here.","- What two colors make red?\n- Does red and yellow make pink?\n- Why is my red food coloring pink?\n- Is red food coloring bad for you?\n- Does orange and pink make red?\n- Does pink and black make red?\n- What colors make hot pink?\n- What colors do you mix with brown to make red?\n- What color can I mix with pink to make red?\n- Is red primary color?\n- What color does red and green make?\n- What two primary colors make blue?\n- How do you make red look redder?\nWhat two colors make red?\nSecondary colors are colors you can make with two of these primary colors.\nSo mixing yellow and cyan makes green, cyan and magenta makes blue and magenta and yellow makes red, so there you have it..\nDoes red and yellow make pink?\nRed is a primary colour that cannot be made by blending. Orange is a blend of red and yellow. Pink is a blend of red and white. Magenta is a blend of red with purple, while purple is itself a blend of red and blue.\nWhy is my red food coloring pink?\nThe red will always be diluted to a pink shade since it is a weak form of the food color. (As in it takes a FULL 1 ounce bottle to make a red velvet cake red…that much in a batch of icing would thin it out into a glaze and still not be that red due to the white color of the frosting to start.\nIs red food coloring bad for you?\nThere is no conclusive evidence that food dyes are dangerous for most people. Nevertheless, they may cause allergic reactions in some people and hyperactivity in sensitive children.\nDoes orange and pink make red?\nThis means that they share something in particular (which is the color red!). This already suggests that mixing them together will create a new pigment that is somewhat reddish in color… and that is the color peach. Thus to answer your question orange and pink mixed together make peach.\nDoes pink and black make red?\nOriginally Answered: What color does pink and black make? The addition of black desaturates and darkens pink. The amount of black and pink used will affect the outcome since black is a more potent/powerful colour than pink. In general, you could probably just say mauve though.\nWhat colors make hot pink?\nA little bit of violet or blue will give you a hot pink. Add more to get a shade such as magenta.\nWhat colors do you mix with brown to make red?\nYou can create brown from the primary colors red, yellow, and blue. Since red and yellow make orange, you can also make brown by mixing blue and orange.\nWhat color can I mix with pink to make red?\nRed and black are the most powerful colors in all the colors. Pink is made with a bit of red in white. So to make red from pink you add a bit of black. Continue until you get what you want.\nIs red primary color?\nIn other words, if you’re talking about painting, then yes: Red, yellow and blue are your primary colors. If you’re talking about physics and light, though, your primary colors are red, green and blue. … These two theories are known as additive and subtractive color systems.\nWhat color does red and green make?\nyellowIf all three primary colors of light are mixed in equal proportions, the result is neutral (gray or white). When the red and green lights mix, the result is yellow.\nWhat two primary colors make blue?\nThe primary pigment colors are cyan, magenta, and yellow. Cyan absorbs red, yellow absorbs blue, and magenta absorbs green. Therefore, in order to get a blue coloration from pigments, you would need to absorb the red and green light colors, which can be achieved by mixing magenta and cyan.\nHow do you make red look redder?\nRed has less pigment than most other colors. If you want a brighter red, paint a base of light neutral grey (not blue-grey), then color that area with a vibrant orange, then paint the red over that."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:a89a18b2-a372-4d9d-bed6-6c03f4550177>","<urn:uuid:b5ff105f-edf0-4d0c-8ed7-615cc579d28d>"],"error":null}
{"question":"How did Donald Bennett contribute to the D-Day invasion of Normandy?","answer":"Lieutenant Colonel Bennett and his 62nd Armored Field Artillery Battalion landed with the second wave of invaders on the Normandy coast on June 6, 1944. He played a crucial role by reorganizing four infantry companies, four tanks, and an anti-aircraft unit that were in disarray near the landing beach. Under heavy fire, he led this makeshift force to secure a ridge and continued to provide front line infantry support with his artillery as the Allies advanced across France.","context":["|Born||9 May 1915|\n|Died||28 Nov 2005|\nContributor: C. Peter Chen\nww2dbaseDonald Vivian Bennett was born in Lakeside, Ohio, United States to English immigrants Louis Bennett and Mary Grills Jacka. His family moved to Genoa, Ohio, and then to Oak Harbor, Ohio. He attended Michigan State University on a football scholarship, but the academics of Michigan State did not interest him. He applied for the United States Military Academy at West Point in 1934, but failed to secure an admission. In the summer of 1934, he worked for New York Central Railroad, working on the tracks. After his sophomore year at Michigan State University, he returned home to Ohio in Jul 1935. Learning from his father that West Point had just expanded the class size, he attempted it again. With the nomination from his local Congressman, he was admitted this time. Unfortunately, while he performed well in other subjects, he failed math, and was thrown out. With his father's connections, he traveled to Washington, DC, United States to study under Mr. Sullivan, a former professor at West Point. After months of cramming, he returned in 1936 and graduated in 1940. He was married to Betty Deacon on 24 Jun 1940 shortly after graduation.\nww2dbaseOriginally thought destined for the Philippine Islands, Bennett found himself being sent to the Mojave Desert in southwest United States for a two-month long training in desert warfare. At Fort A. P. Hill in Virginia, United States, his unit was assigned the new M-7 Priest 105mm mobile artillery guns, a weapon so new that there were no printed manuals yet. Aboard converted ocean liner Santa Rosa, he was shipped to North Africa, landing on the invasion beaches only a handful of days after the initial landings. In Casablanca, he was placed in charge of a whore house maintained by the United States Army in order to keep troops content, then was assigned to be a part of the security team for Franklin Roosevelt and Winston Churchill during the Casablanca Conference. During this time, he worked closely with French Goum troops, who he came to respect; \"they were truly frightful and proficient killers\", he recalled. During the Allied invasion of Algeria, he commanded M-7 guns in support of George Patton's advance. On 9 May 1943, his unit reached Tunis, Tunisia.\nww2dbaseOn 7 Jul 1943, Bennett was sent to Bizerte, Tunisia to board a LST transport ship for the invasion of Sicily. He landed at Licata uneventfully. His battalion was ordered to race north to the northern coast, which it did, and en route the battalion took over 3,000 prisoners.\nww2dbaseOn 6 Jun 1944, Lieutenant Colonel Bennett and the 62nd Armored Field Artillery Battalion which he commanded landed on the Normandy coast with the second wave of invaders. He played a critical role in reorganizing four nearby infantry companies, four tanks, and an anti-aircraft unit, all of which were in disarray on or near the landing beach; with his makeshift force, he advanced and secured a ridge under heavy fire. As the Allies moved across France, he continued to lend front line infantry support from his artillery. While recalling his experiences during the break-out from Normandy, he noted in his memoir:\nww2dbaseAfter France, Bennett fought in the Low Countries, advancing against the German defenses at the Albert Canal near Fort Eben Emael and defending against the Ardennes Offensive. In the latter battle, he used shells equipped with proximity fuses; these shells, with their vacuum-tube radar mounted at the noses, exploded in the tree branches above the targeted areas about 30 yards above the ground. The results were deadly. Sprays of shrapnel rained down across a quarter acre of ground, killing nearly everything underneath. He recalled that the Germans were \"terrified\" of the carnage, and could not quite figure out why American artillery barrages suddenly became so effective.\nww2dbaseOn 2 Mar 1945, Bennett crossed the Roer River, and shortly after he was sent to London, England, Britain for a short leave. At Westminster Abbey for a Sunday religious service, he observed \"uniforms of those gathered there were from around the world, a dazzling display of the dying vestiges of the British Empire, combined with those of us from the New World and the grim survivors of occupied Europe.\" He also noted that several stained-glass windows were broken, presumably damaged during the Battle of Britain or during German rocket attacks.\nww2dbaseIn May 1945, Bennett and his unit reached the Elbe River, and by 7 May he was in Czechoslovakia, several hundred miles behind George Patton's Third Army spearhead. He continued to observe sporadic fighting, often from those of various Hitler Youth units. On the next day, his 30th birthday, he received word that fighting was to be over that night at midnight. \"There was no glory, only relief, only a wish to lay down our tools of death and to rest\", he said. \"I was never so old as I was on that night. All the years since then have been a gift.\"\nww2dbaseAs a member of the Allied occupation force, Bennett witnessed a \"betrayal of what we were supposedly fighting for\": Allied troops were told to turn all westward-traveling refugees back, leaving them in Russian occupied zone, with those soldiers whom these refugees were fleeing from. He witnessed first-hand the tensions between the Western Allies and the Russians that quickly built up after the end of the European War. He was notified that he would be sent to participate in the Pacific War, but Japan surrendered before he was shipped out.\nww2dbaseAfter the war, Bennett returned to the United States in Nov 1945 via Boston, Massachusetts. Remaining in the US Army, he gained rank consistently in the post-war years. He served as the superintendent of the United States Military Academy from 1966 to 1969. Between 1969 and 1972, he was the Director of the Defense Intelligence Agency. In 1972, he was named the commanding general of the US Army Pacific Command. He retired from active service in 1974 and passed away in Asheville, North Carolina, United States in Nov 2005. He now rests at West Point, New York, United States in the academy's cemetery.\nww2dbaseBennett's memoir was published in 2003 under the title Honor Untarnished.\nww2dbaseSources: Honor Untarnished, Wikipedia.\nLast Major Revision: Sep 2007\nDonald Bennett Timeline\n|9 May 1915Â||Donald Bennett was born.|\n|28 Nov 2005Â||Donald Bennett passed away.|\nDid you enjoy this article or find this article helpful? If so, please consider supporting us on Patreon. Even $1 per month will go a long way! Thank you.\nShare this article with your friends:\nStay updated with WW2DB:\nVisitor Submitted Comments\nAll visitor submitted comments are opinions of those making the submissions and do not reflect views of WW2DB.\nÂ»Â Conclusion of the Desert War\nÂ»Â Normandy Campaign, Phase 1\nÂ»Â Normandy Campaign, Phase 2\nÂ»Â Liberation of Belgium\nÂ»Â Battle of the Bulge\nÂ»Â Advance to the Rhine\nÂ»Â Honor Untarnished\n- Â» 1,107 biographies\n- Â» 334 events\n- Â» 39,319 timeline entries\n- Â» 1,159 ships\n- Â» 339 aircraft models\n- Â» 192 vehicle models\n- Â» 361 weapon models\n- Â» 120 historical documents\n- Â» 228 facilities\n- Â» 464 book reviews\n- Â» 27,895 photos\n- Â» 362 maps\nWinston Churchill, on the RAF\nPlease consider supporting us on Patreon. Even $1 a month will go a long way. Thank you!\nOr, please support us by purchasing some WW2DB merchandise at TeeSpring, Thank you!"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:3152a891-8227-487e-ae13-37ea133d84fd>"],"error":null}
{"question":"¿Qué barreras existen para la gestión sostenible de residuos electrónicos y qué riesgos ambientales presentan?","answer":"Several barriers exist for sustainable e-waste management: lack of available information, limited access to spare parts, increasingly difficult disassembly, and consumer unawareness of options. The repair industry is also shrinking in developed countries. The environmental risks include soil contamination with heavy metals and toxic chemicals, groundwater pollution, and ecosystem damage. These pollutants, including PCBs, PAHs, and heavy metals, contaminate local water sources and soil, affecting both environmental and human health in surrounding areas, particularly in informal recycling sites in the Global South.","context":["We are in the happy position to announce that Prof. Renato Passaro and ReTraCE ESR Kevin van Langen from the University of Parthenope (Naples, Italy), will be the leading guest editor and assistant guest editor respectively, in MDPI Sustainability‘s Special Issue on “Beyond the Recycling Economy: The E-Waste Reverse Supply Chain in the Transition to the Circular Economy Perspective”.\nWe would like also to inform anyone interested that this special issue is now open for submissions.\nSpecial Issue Information\nRoughly 20% of global Electronic and Electrical Equipment (EEE) ends up being recycled at the end of its lifecycle, and much of the rest ends up in a landfill as waste (known as WEEE or e-waste) (Baldè et al. 2017). This appears to be increasingly relevant if we consider the strong increase in e-waste generated (+21% over 2015-2019 on a global basis, with a record 53.6 mln tons in 2019, while another 81 tons is expected by 2030) as a result of the continuous rise in the volume of EEE placed on the market (+25% from 2013 to 2017 in the EU, amounting to over +1.8 mln tons of annual EEE put to market) (Global E-waste Monitor 2020; Eurostat). Unprocessed WEEE often ends up in landfills in the Global South and causes serious harm to the surrounding eco-systems and human populations, including bad labor conditions and many toxins entering the local groundwater (Awasthi, Li, 2017a, b). This problem is particularly relevant if we consider that 71% of countries worldwide are currently adopting policies or regulations on e-waste management (Global E-waste Monitor 2020). There is an increased awareness that to reduce the amount of WEEE we need to reduce, reuse, repair, remanufacture, repurpose, etc. global EEE, in line with the EU waste hierarchy (Directive 2008/98/EC), its evolution (zerowasteeurope.eu, 2019), and the principles of Circular Economy (CE), while also limiting the amount of EEE put to market and thus limit the amount ending up in landfills. In the transition to a circular economy, recycling should be considered the last option among the list of waste management options (but is still important) (Isernia, et al. 2019). Indeed, recycling WEEE is a very energy-intensive process, requires costly high-end facilities, and is not yet able to regain all materials embedded in WEEE (Ghisellini et al., 2016). Although recycling is better than landfilling, it is not capable of rendering the CE a valid approach aimed to decouple value creation from resource consumption (Bressanelli et al., 2020; Reike et al. 2018), since it only closes the loop between post-use and production stages (Bocken et al., 2016). Current case studies in the WEEE sector (Bressanelli et al., 2020; González et al., 2017) highlight the environmental and socio-economic benefits of the previously listed alternatives to recycling and of the extension of the EEE life cycle in terms of reduction of resource consumption and waste generation (www.astelav.com/it/progetto-ri-generation/; González et al., 2017).\nAs a tool for sustainable development, actions like repairing and remanufacturing can be done by high-skilled seniors workers and are often successfully done in tandem with re=education projects for unemployed people, fulfilling a socio-economic need. Furthermore, these options lower the economic and environmental footprints of new products. As Stahel (1981) said: “Do not repair, what is not broken; do not remanufacture something that can be repaired; do not recycle a product that can be remanufactured; replace or treat only the smallest possible part in order to maintain the existing economic value”. An additional contribution in this perspective can be provided by other options (reduce, refuse, rethink), which involve citizens’ and producers’ habits and behaviors and call for a rethinking of consumption models, product design, and business models to maintain the existing economic value of goods.\nHowever, many barriers still exist to enable these alternative WEEE management strategies. Information is often not available, nor are spare parts, disassembly is increasingly difficult, and consumers often do not know what their options are. In fact, the EEE repair industry is shrinking in developed countries (McCollough, 2009; Bovea et al., 2017; Sabbaghi et al., 2016, 2017). The supply of information and spare parts over long life cycles of products, distributed facilities that can disassemble products, the right to repair and eco-design regulation, and a decision-making system to optimally decide on an end-of-life strategy for products call for a complex and integrated closed-loop supply chain from design to reuse.\nSo far, limited attention in the extant literature has been devoted to strategies, initiatives, and policy measures to go beyond the limits of the recycling economy (Islam and Huda 2018b; Ismail and Hanafiah 2019).\nTherefore, the purpose of this Special Issue is to fill this gap by providing theoretical, conceptual, and empirical studies on CE approaches to WEEE management, measures, and initiatives aimed at reducing WEEE generation through the involvement of different stakeholders (e.g., consumer, producers, regulators, policymakers, service providers, and others). Specifically, the scope of this Special Issue is related to identifying those strategies, approaches, and methods employed to properly prevent or reduce the e-waste generation that mainly involve (W)EEE management strategies to keep products/parts in circulation. We also welcome papers that identify problems with the growing EEE waste stream, especially research from the Global South.\nPossible topics include, but are not limited, to the following:\nStrategies, methods, and approaches to prevent e-waste generation\nRole of stakeholders in the prevention of e-waste generation\nDevelopment of new consumption models and consumers’ habits\nCE approaches and strategies for e-waste reduction\nRole of technologies in e-waste prevention\nEco- and green design strategies\nTechnologies and practices for WEEE recovery and treatment improvements\nRole of WEEE closed-loop supply chain and reverse logistics\nPolicies and practices aimed at reducing the EEE waste stream\nCE-oriented Business models for the extension of EEE life cycle\nRole of regulation about the right to repair and eco-design\nBaldé, C.P., Forti, V., Gray, V., Kuehr, R., Stegmann, P., 2017. The global e-waste monitor 2017. United Nations University.\nBocken, N.M.P., de Pauw, I., Bakker, C., van der Grinten, B., 2016. Product design and business model strategies for a circular economy. J. Indu. Prod. Eng. 33 (5), 308e320. https://doi.org/10.1080/21681015.2016.1172124.\nBovea, M. D., Ibáñez-Forés, V., Pérez-Belis, V., Quemades-Beltrán, P. 2016. Potential reuse of small household waste electrical and electronic equipment: methodology and case study. Waste Management, 53, 204-217.\nBressanelli, GM, Saccani, N., Pigosso, D. C. A., Perona, M., 2020a. Circular Economy in the WEEE industry: a systematic literature review and a research agenda. Sustainable Production and Consumption 23, 174-188.\nBressanelli, GM, Saccani, N., Perona, M., 2020b. Circular business models in selected geographical contexts. An analysis of two cases. In: The Routledge Handbook of Waste, Resources and the Circular Economy. Routledge International Handbooks, DOI: 10.4324/9780429346347-42\nGhisellini, P., Cialani, C., Ulgiati, S., 2016. A review on circular economy: the expected transition to a bilance interplay of environmental and economic systems. Journal of Cleaner Production 114, 11-32.\nGlobal E-waste Monitor, 2020, http://ewastemonitor.info/\nGonzález, X.M., Rodríguez, M., Pena-Boquete, Y., 2017. The social benefits of WEEE re-use schemes. A cost benefit analysis for PCs in Spain. Waste Manag. 64, 202-213. https://doi.org/10.1016/j.wasman.2017.03.009.\nIsernia, R., Passaro, R., Quinto, I., & Thomas, A. (2019). The reverse supply chain of the e-waste management processes in a circular economy framework: Evidence from Italy. Sustainability, 11(8), 2430.\nIslam, Md T., Huda, N., 2020. Reshaping WEEE management in Australia: An investigation on the untapped WEEE products. Journal of Cleaner Production 119, 119496.\nIsmail, Hanafiah, M. M., 2019. Discovering opportunities to meet the challenges of an effective waste electrical and electronic equipment recycling system in Malaysia. Journal of Cleaner Production 238, 117927.\nMcCollough, J. 2009. Factors impacting the demand for repair services of household products: the disappearing repair trades and the throwaway society. International Journal of Consumer Studies, 33(6), 619-626.\nReike, D., Vermeulen, W.J. V, Witjes, S., 2018. New or Refurbished as CE 3.0? – Exploring Controversies in the Conceptualization of the Circular Economy through a focus on History and Resource Value Retention Options. Resource, Conservation & Recycling 135, 246-264. https://doi.org/10.1016/j.resconrec.2017.08.027\nSabbaghi, M., Esmaeilian, B., Cade, W., Wiens, K., Behdad, S., 2016. Business outcomes of product repairability: A survey-based study of consumer repair experiences. Resource Conservation & Recycling 109, 114–122.\nSabbaghi, M., W. Cade, S. Behdad, and A.M. Bisantz. 2017. “The Current Status of the Consumer Electronics Repair Industry in the U.S.: A Survey-Based Study.” Resources, Conservation and Recycling 116: 137–51. https://doi.org/10.1016/j.resconrec.2016.09.013.\nSimon J.M., A Zero Waste hierarchy for Europe, 2019. https://zerowasteeurope.eu/2019/05/a-zero-waste-hierarchy-for-europe/. Last Accessed 04/03, 2021.\nStahel, W., 1981. The product-life factor. In: Grinton Orr, S. (Ed.), An Inquiry into the Nature of Sustainable Societies: the Role of the Private Sector. HARC, Houston, TX, pp. 72-96\nUE, 2008, Directive 2008/98/EC of the European Parliament and of the Council of 19 November 2008 on waste and repealing certain Directives (Text with EEA relevance), available at: https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32008L0098. Last accessed: 04/03/2021.\nProf. Dr. Renato Passaro\nDr. Patrizia Ghisellini\nDr. Carmela Piccolo\nDr. Ivana Quinto\nMr. Sven Kevin van Langen\nAssistant Guest Editor\nManuscript Submission Information\nManuscripts should be submitted online at www.mdpi.com by registering and logging in to this website. Once you are registered, click here to go to the submission form. Manuscripts can be submitted until the deadline. All papers will be peer-reviewed. Accepted papers will be published continuously in the journal (as soon as accepted) and will be listed together on the special issue website. Research articles, review articles as well as short communications are invited. For planned papers, a title and short abstract (about 100 words) can be sent to the Editorial Office for announcement on this website.\nSubmitted manuscripts should not have been published previously, nor be under consideration for publication elsewhere (except conference proceedings papers). All manuscripts are thoroughly refereed through a single-blind peer-review process. A guide for authors and other relevant information for submission of manuscripts is available on the Instructions for Authors page. Sustainability is an international peer-reviewed open access semimonthly journal published by MDPI.\nPlease visit the Instructions for Authors page before submitting a manuscript. The Article Processing Charge (APC) for publication in this open access journal is 1900 CHF (Swiss Francs). Submitted papers should be well formatted and use good English. Authors may use MDPI’s English editing service prior to publication or during author revisions.\n- waste electrical and electronic equipment\n- circular economy\n- waste hierarchy\n- reverse supply chain management\n- closed-loop supply chain\n- long life extension","Adverse Human and Environmental Health Effects of Electronic Wastes: A Critical Review and Consequence Analysis\nIncrease in obsolete electronics is a direct consequence of rapidly changing technologies and an upsurge in the global demand for new electronic devices. This has led to large quantities of electronic products discarded as electronic waste (e-waste), creating enormous environmental health challenges impacting the management of the product life cycle (PLC) of the global product chain for manufactured electronics. The environmental health impacts of e-wastes vary widely across geography. Major contributors of e-waste production as well as major e-waste importing countries are identified in this study. The “Chemicals in Products (CiP)”, their fate and distribution in the environment, based on the local geology of the land use, and toxicological effects in the human body upon exposure, are investigated. The study outcomes present the need for recommended actions and prospective solutions for mitigating the associated hazards from CiP and the risks of potential adverse effects to humans and the environment. Effective handling and PLC management of e-waste can be achieved through proper implementation, permeable reactive barriers use in incinerators, oil-water solvent systems for contaminant removal and revision of existing regulations. These recommendations will help protect the health of children and adults in susceptible areas and improve electronic products management and environmental sustainability.\nElectronic Waste, Heavy Metals, Polycyclic Aromatic Hydrocarbons, Polychlorinated Biphenyls, Contamination, Exposure, Toxicology, Remediation\nUnited States Census Bureau - USCB (2017). U.S. and World Population Clock. Retrieved December 30, 2017 from https://www.census.gov/popclock/\nGSMA Intelligence (2017). Global Mobile Trends September 2017. Retrieved December 30, 2017 from https://www.gsmaintelligence.com/research\nPerez-Belis, V., Bovea, M. D., Ibanez-Fores, V., (2015). An in-depth literature review of the waste electrical and electronic equipment context: trends and evolution. Waste Manag. Res. J. Int. Solid Wastes Public Clean. Assoc. ISWA 33 (1), 3-29.\nAwasthi, A. K., Zeng X., Li J. (2016). Environmental pollution of electronic waste recycling in India: A critical review. Environmental Pollution 211 (2016) 259-270.\nKinhal, V. (2017). Highest e-waste generating countries in the world. World Atlas. Retrieved November 22, 2107 from http://www.worldatlas.com/articles/highest-e-waste-generating-nations-in-the-world.html\nWorldometers (2017) - Current World Population. Retrieved December 30, 2017 from http://www.worldometers.info/world-population/\nUnited Nations Environment Programme [UNEP]. (2015). Illegally Traded and Dumped E-Waste Worth up to $19 Billion Annually Poses Risks to Health, Deprives Countries of Resources, Says UNEP report. Retrieved November 22, 2017 from http://web.unep.org/newscentre/illegally-traded-and-dumped-e-waste-worth-19-billion-annually-poses-risks-health-deprives-countries\nSthiannopkao, S., Wong, M. H., 2013. Handling e-waste in developed and developing countries: Initiatives, practices, and consequences. Sci. Total Environ. 463-464, 1147-1153.\nBalde, C. P., Wang, F., Kuehr, R., Huisman, J., (2015). The Global E-waste Monitor 2014. Quantities Flows and Resources. United Nations University, IAS - SCYCLE, Bonn, Germany, pp. 1-41. Institute for the Advanced Study of Sustainability. Retrieved December 30, 2017 from http://i.unu.edu/media/ias.unu.edu-en/news/7916/Global-E-waste-Monitor-2014- small.pdf.\nPerkins, D. N., Brune-Drisse, M., Nxele, T., & Sly, P. D. (2014). E-waste: A global hazard. Annals of Global Health, 80 (4), 286-295. doi: 10.1016/j.aogh.2014.10.001\nLi, J., Zeng, X., Chen, M., Ogunseitan, O. A., Stevels, A. L. N., (2015). “Control-Alt- Delete”: rebooting solutions for the e-waste problem. Environ. Sci. Technol. 49 (12), 7095-7108.\nRobinson, B. H. (2009). E-waste: An assessment of global production and environmental impacts. Science of the Total Environment, 408 (2), 183-191. doi: 10.1016/j.scitotenv.2009.09.044\nZheng, H., Hu, G., Xu, Z., Li, H., Zhang, L., Zheng, J., He, D. (2015). Characterization and distribution of heavy metals, polybrominated diphenyl ethers and perfluoroalkyl substances in surface sediment from the dayan river, south china. Bulletin of Environmental Contamination and Toxicology, 94 (4), 503-510. doi: 10.1007/s00128-015-1479-7\nYuan, J., Chen, L., Chen, D., Guo, H., Bi, X., Ju, Y., Chen, X. (2008). Elevated Serum Polybrominated Diphenyl Ethers and Thyroid-Stimulating Hormone Associated with Lymphocytic Micronuclei in Chinese Workers from an E-Waste Dismantling Site. Environmental Science & Technology, 42 (6), 2195–2200. doi: 10.1021/es702295f\nZhang, Y., Luo, X., Mo, L., Wu, J., Mai, B., & Peng, Y. (2015). Bioaccumulation and translocation of polyhalogenated compounds in rice (Oryza sativa L.) planted in paddy soil collected from an electronic waste recycling site, South China. Chemosphere, 137 (Journal Article), 25–32. doi: 10.1016/j.chemosphere.2015.04.029\nZeng, X. L., Song, Q. B., Li, J. H., Yuan, W. Y., Duan, H. B., Liu, L. L., (2015). Solving e-waste problem using an integrated mobile recycling plant. J. Clean. Prod. 90, 55-59.\nZhang, Y., Huo, X., Cao, J., Yang, T., Xu, L., & Xu, X. (2016). Elevated lead levels and adverse effects on natural killer cells in children from an electronic waste recycling area. Environmental Pollution, 213, 143–150. doi: 10.1016/j.envpol.2016.02.004\nHe, K., Sun, Z., Hu, Y., Zeng, X., Yu, Z., & Cheng, H. (2017). Comparison of soil heavy metal pollution caused by e-waste recycling activities and traditional industrial operations. Environmental Science and Pollution Research, 24 (10), 9387. doi: 10.1007/s11356-017-8548-x\nUS Environmental Protection Agency [EPA]. (2017). Basic information about landfills. Retrieved November 29, 2017 from https://www.epa.gov/landfills/basic-information-about-landfills\nBreivik, K., Armitage, J. M., Wania, F., & Jones, K. C. (2014). Tracking the global generation and exports of e-waste. do existing estimates add up? Environmental Science & Technology, 48 (15), 8735.\nVos, S. (2012). Electronic waste disposal. Duke university: Nicholas school of the environment. Retrieved November 29, 2017 from http://sites.nicholas.duke.edu/loribennear/2012/11/15/electronic-waste-disposal/\nPickren, G. (2014). Political ecologies of electronic waste: Uncertainty and legitimacy in the governance of E-waste geographies. Environment and Planning A, 46 (1), 26-45. doi: 10.1068/a45728\nGallo, D. T. (2013). Broad Overview of E-Waste Management Policies in the U.S. Environmental Protection Agency. Retrieved November 29, 2017 from https://www.epa.gov/sites/production/files/2014-05/documents/overview.pdf\nDasgupta, D., Debsarkar, A., Hazra, T., Bala, B. K., Gangopadhyay, A., & Chatterjee, D. (2017). Scenario of future e-waste generation and recycle-reuse-landfill-based disposal pattern in india: A system dynamics approach. Environment, Development and Sustainability, 19 (4), 1473-1487. doi: 10.1007/s10668-016-9815-6\nWang, H., Yu, Y., Han, M., Yang, S., Li, Q., & Yang, Y. (2009). Estimated PBDE and PBB congeners in soil from an electronics waste disposal site. Bulletin of Environmental Contamination and Toxicology, 83 (6), 789-793. doi: 10.1007/s00128-009-9858-6\nUS Environmental Protection Agency [EPA]. (n.d.). PCBs questions and answers. Retrieved December 1, 2017 from https://www3.epa.gov/region9/pcbs/faq.html\nWilson, D. (2015). Toxins in WEEE (E-waste). University of Washington. Retrieved December 1, 2017 from http://ewaste.ee.washington.edu/students/impacts/\nHong, W., Jia, H., Ding, Y., Li, W., & Li, Y. (2016). Polychlorinated biphenyls (PCBs) and halogenated flame retardants (HFRs) in multi-matrices from an electronic waste (e-waste) recycling site in northern china. Journal of Material Cycles and Waste Management, doi: 10.1007/s10163-016-0550-8\nRabodonirina, S., Net, S., Ouddane, B., Merhaby, D., Dumoulin, D., Popescu, T., & Ravelonandro, P. (2015). Distribution of persistent organic pollutants (PAHs, me-PAHs, PCBs) in dissolved, particulate and sedimentary phases in freshwater systems. Environmental Pollution, 206, 38-48. doi: 10.1016/j.envpol.2015.06.023\nAgency for Toxic Substances and Disease Registry [ATSDR]. (2015). Public health statements for PCBs. Retrieved December 2, 2017 from https://www.atsdr.cdc.gov/phs/phs.asp?id=139&tid=26\nWang, Y., Luo, C., Wang, S., Cheng, Z., Li, J., & Zhang, G. (2016). The abandoned E-waste recycling site continued to act as a significant source of polychlorinated biphenyls: An in situ assessment using fugacity samplers. Environmental Science & Technology, 50 (16), 8623.\nLi, L., Li, Y., Richardson, J. B., Mark Bricka, R., Niu, X., Yang, H., & Jimenez, A. (2009). Leaching of heavy metals from E-waste in simulated landfill columns. Waste Management, 29 (7), 2147-2150. doi: 10.1016/j.wasman.2009.02.005\nKyere, V. N., Greve, K., & Atiemo, S. M. (2016). Spatial assessment of soil contamination by heavy metals from informal electronic waste recycling in agbogbloshie, ghana. Environmental Health and Toxicology, 31, e2016006. doi: 10.5620/eht.e2016006\nIsimekhai, K. A., Garelick, H., Watt, J., & Purchase, D. (2017). Heavy metals distribution and risk assessment in soil from an informal E-waste recycling site in Lagos state, Nigeria. Environmental Science and Pollution Research, 24 (20), 17206-17219. doi: 10.1007/s11356-017-8877-9\nBlanco, A., Salazar, M. J., Vergara Cid, C., Pignata, M. L., & Rodriguez, J. H. (2017). Accumulation of lead and associated metals (Cu and Zn) at different growth stages of soybean crops in lead-contaminated soils: food security and crop quality implications. Environmental Earth Sciences, 76 (4), 1–11. doi: 10.1007/s12665-017-6508-x\nWu, J.-P., Luo, Y., Luo, X.-J., Zhang, Y., Chen, S.-J., Mai, B.-X., & Yang, Z.-Y. (2008). Bioaccumulation of polybrominated diphenyl ethers (PBDEs) and polychlorinated biphenyls (PCBs) in wild aquatic species from an electronic waste (e-waste) recycling site in South China. Environment International, 34 (8), 1109–1113. doi: 10.1016/j.envint.2008.04.001\nTao, W., Zhou, Z., Shen, L., & Zhao, B. (2015). Determination of dechlorane flame retardants in soil and fish at guiyu, an electronic waste recycling site in south china. Environmental Pollution, 206, 361-368. doi: 10.1016/j.envpol.2015.07.043\nAckah, M. (2017). Informal E-waste recycling in developing countries: review of metal(loid)s pollution, environmental impacts and transport pathways. Environmental Science and Pollution Research, 24 (31), 24092–24101.\nGrant, K., Goldizen, F., Sly, P., Brune, M., Neira, M., van den Berg, M., & Norman, R. (2013). Health consequences of exposure to e-waste: a systematic review. Lancet Global Health, 1 (6), E350–E361. doi: 10.1016/S2214-109X(13)70101-3\nOlawoyin R. (2017). Exposure to Toxic Pollutants: Assessing Potential Human Health Risk. Professional Safety, 62 (2), 40-45.\nSong, Q., & Li, J. (2014). A systematic review of the human body burden of e-waste exposure in China. Environment International, 68 (Supplement C), 82–93. doi: 10.1016/j.envint.2014.03.018\nOlawoyin R, Heidrich B, Oyewole SA, Okareh OT, McGlothlin CW, (2014). Chemometric analysis of ecological toxicants in petrochemical and industrial environments. Chemosphere 112, 114–11\nBoston University School of Public Health [BUSPH] (2017). Exposure Assessment: Introduction to Basic Concepts. Retrieved December 30, 2017 from http://sphweb.bumc.bu.edu/otlt/mph-modules/exposureassessment/exposureassessment3.html\nXing, G. H., Chan, J. K. Y., Leung, A. O. W., Wu, S. C., & Wong, M. H. (2009). Environmental impact and human exposure to PCBs in Guiyu, an electronic waste recycling site in China. Environment International, 35 (1), 76–82. doi: 10.1016/j.envint.2008.07.025\nYang, Y., Xue, M., Xu, Z., & Huang, C. (2013). Health risk assessment of heavy metals (Cr, Ni, Cu, Zn, Cd, Pb) in circumjacent soil of a factory for recycling waste electrical and electronic equipment. Journal of Material Cycles and Waste Management, 15 (4), 556–563. doi: 10.1007/s10163-013-0120-2\nTao, X.-Q., Shen, D.-S., Shentu, J.-L., Long, Y.-Y., Feng, Y.-J., & Shen, C.-C. (2015). Bioaccessibility and health risk of heavy metals in ash from the incineration of different e-waste residues. Environmental Science and Pollution Research, 22 (5), 3558–3569. doi: 10.1007/s11356-014-3562-8\nChan, J. K. Y., Man, Y. B., Wu, S. C., & Wong, M. H. (2013). Dietary intake of PBDEs of residents at two major electronic waste recycling sites in China. Science of The Total Environment, 463–464 (Supplement C), 1138–1146. doi: 10.1016/j.scitotenv.2012.06.093\nFu, J., Zhou, Q., Liu, J., Liu, W., Wang, T., Zhang, Q., & Jiang, G. (2008). High levels of heavy metals in rice (Oryzasativa L.) from a typical E-waste recycling area in southeast China and its potential risk to human health. Chemosphere, 71 (7), 1269–1275. doi: 10.1016/j.chemosphere.2007.11.065\nLuo, C., Liu, C., Wang, Y., Liu, X., Li, F., Zhang, G., & Li, X. (2011). Heavy metal contamination in soils and vegetables near an e-waste processing site, south China. Journal of Hazardous Materials, 186 (1), 481–490. doi: 10.1016/j.jhazmat.2010.11.024\nLeung, A. O. W., Duzgoren-Aydin, N. S., Cheung, K. C., & Wong, M. H. (2008). Heavy Metals Concentrations of Surface Dust from e-Waste Recycling and Its Human Health Implications in Southeast China. Environmental Science & Technology, 42 (7), 2674–2680. doi: 10.1021/es071873x\nWu, C.-C., Bao, L.-J., Tao, S., & Zeng, E. Y. (2016). Dermal Uptake from Airborne Organics as an Important Route of Human Exposure to E-Waste Combustion Fumes. Environmental Science & Technology, 50 (13), 6599–6605. doi: 10.1021/acs.est.5b05952\nXing, G. H., Liang, Y., Chen, L. X., Wu, S. C., & Wong, M. H. (2011). Exposure to PCBs, through inhalation, dermal contact and dust ingestion at Taizhou, China – A major site for recycling transformers. Chemosphere, 83 (4), 605–611. doi: 10.1016/j.chemosphere.2010.12.018\nKim, K.-H., Jahan, S. A., Kabir, E., & Brown, R. J. C. (2013). A review of airborne polycyclic aromatic hydrocarbons (PAHs) and their human health effects. Environment International, 60 (Supplement C), 71–80. doi: 10.1016/j.envint.2013.07.019\nWang, J., Chen, S., Tian, M., Zheng, X., Gonzales, L., Ohura, T., Simonich, S. L. M. (2012). Inhalation Cancer Risk Associated with Exposure to Complex Polycyclic Aromatic Hydrocarbon Mixtures in an Electronic Waste and Urban Area in South China. Environmental Science & Technology, 46 (17), 9745–9752. doi: 10.1021/es302272a\nLuo, P., Bao, L.-J., Li, S.-M., & Zeng, E. Y. (2015). Size-dependent distribution and inhalation cancer risk of particle-bound polycyclic aromatic hydrocarbons at a typical e-waste recycling and an urban site. Environmental Pollution, 200 (Supplement C), 10–15. doi: 10.1016/j.envpol.2015.02.007\nGuo, Y., Huo, X., Wu, K., Liu, J., Zhang, Y., & Xu, X. (2012). Carcinogenic polycyclic aromatic hydrocarbons in umbilical cord blood of human neonates from Guiyu, China. Science of The Total Environment, 427–428 (Supplement C), 35–40. doi: 10.1016/j.scitotenv.2012.04.007\nZheng, J., He, C.-T., Chen, S.-J., Yan, X., Guo, M.-N., Wang, M.-H., Mai, B.-X. (2017). Disruption of thyroid hormone (TH) levels and TH-regulated gene expression by polybrominated diphenyl ethers (PBDEs), polychlorinated biphenyls (PCBs), and hydroxylated PCBs in e-waste recycling workers. Environment International, 102 (Supplement C), 138–144. doi: 10.1016/j.envint.2017.02.009\nWorld Health Organization [WHO]. (2010). Preventing Disease Through Healthy Environments. Retrieved on December 2, 2017 from http://www.who.int/ipcs/features/10chemicals_en.pdf?ua=1\nGuo, Y., Huo, X., Li, Y., Wu, K., Liu, J., Huang, J., Xu, X. (2010). Monitoring of lead, cadmium, chromium and nickel in placenta from an e-waste recycling town in China. Science of The Total Environment, 408 (16), 3113–3117. doi: 10.1016/j.scitotenv.2010.04.018\nLiu, J., Xu, X., Wu, K., Piao, Z., Huang, J., Guo, Y., Huo, X. (2011). Association between lead exposure from electronic waste recycling and child temperament alterations. Neuro Toxicology, 32 (4), 458–464. doi: 10.1016/j.neuro.2011.03.012\nWang, X., Miller, G., Ding, G., Lou, X., Cai, D., Chen, Z., Han, J. (2012). Health risk assessment of lead for children in tinfoil manufacturing and e-waste recycling areas of Zhejiang Province, China. Science of the Total Environment, 426, 106–112. doi: 10.1016/j.scitotenv.2012.04.002\nZhang, K., Schnoor, J. L., & Zeng, E. Y. (2012). E-waste recycling: Where does it go from here? Environmental Science and Technology, 46 (20), 10861–10867. https://doi.org/10.1021/es303166s\nUnited Nations Environment Management Group [UNEMG]. (2017). United Nations System-wide Response to Tackling E-waste. Retrieved November 22, 2017 from https://unemg.org/images/emgdocs/ewaste/E-Waste-EMG-FINAL.pdf\nOngondo, F. O., Williams, I. D., & Cherrett, T. J. (2011). How are WEEE doing? A global review of the management of electrical and electronic wastes. Waste Management, 31 (4), 714–730. doi: 10.1016/j.wasman.2010.10.023\nLong, Yuyang & Feng, Yi-Jian & Cai, Si-Shi & Hu, Li-Fang & Shen, Dong-Sheng. (2014). Reduction of heavy metals in residues from the dismantling of waste electrical and electronic equipment before incineration. Journal of Hazardous Materials. 272. 59–65. 10.1016/j.jhazmat.2014.02.048.\nBeiyuan, J., Tsang, D. C. W., Yip, A. C. K., Zhang, W., Ok, Y. S., & Li, X.-D. (2017). Risk mitigation by waste-based permeable reactive barriers for groundwater pollution control at e-waste recycling sites. Environmental Geochemistry and Health, 39 (1), 75–88. doi: 10.1007/s10653-016-9808-2\nYe, M., Sun, M., Wan, J., Fang, G., Li, H., Hu, F. Orori Kengara, F. (2015). Evaluation of enhanced soil washing process with tea saponin in a peanut oil–water solvent system for the extraction of PBDEs/PCBs/PAHs and heavy metals from an electronic waste site followed by vetiver grass phytoremediation. Journal of Chemical Technology & Biotechnology, 90 (11), 2027–2035. doi: 10.1002/jctb.4512"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:9516d08e-5677-47d0-bd40-d0626ed187bd>","<urn:uuid:292e510a-9722-4c47-9ed5-81cd75880cfd>"],"error":null}
{"question":"How do the timelines and decision-making processes compare between NWMO's deep geological repository project and OPG's cancelled Lake Huron storage facility?","answer":"The NWMO is currently on track with their site selection process, planning to select a single preferred site by 2024, after being founded in 2002 and working on site selection since 2010. Their process requires approval from multiple stakeholders including municipalities, First Nations, and Métis communities, with ongoing technical site investigations and social studies in South Bruce and Ignace areas. In contrast, OPG's Lake Huron storage facility project came to an immediate halt following a single decisive vote by the Saugeen Ojibway Nation in which 1,058 members voted against and 170 in favor. This demonstrates how Indigenous community approval can be a determining factor in these projects' progression.","context":["NWMO specialist shares findings on long-term repository safety\nThe NWMO’s Dr. Erik Kremer discusses findings from the seventh case study, which assesses the long-term safety of a deep geological repository in sedimentary rock formations, similar to those found in southern Bruce County.\nCanada’s plan for the safe, long-term management of used nuclear fuel calls for the fuel to be contained and isolated in a deep geological repository, in an area with informed and willing hosts. Understanding how a deep geological repository will respond over extended periods of time is key to our work and involves the publication of a series of case studies focused on long-term repository performance.\nDr. Erik Kremer, Section Manager of Siting Safety Assessment at the Nuclear Waste Management Organization (NWMO), recently shared findings from the seventh case study (Postclosure Safety Assessment of a Used Fuel Repository in Sedimentary Rock), at the July meetings of the community liaison committees in Huron-Kinloss and South Bruce.\n“The seventh case study illustrates how repository safety is assessed over the very long term. The case study considers normal evolution and disruptive scenarios, and concludes that a repository could be safely sited in the sedimentary rock formations found in southern Ontario,” said Dr. Kremer, whose day-to-day work focuses on the long-term safety of a deep geological repository.\nThese reports build on a series of postclosure safety assessments illustrating the long-term performance and safety of different repository designs within various geological settings. The seventh case study builds on existing work, including the sixth case study focused on crystalline rock.\n“Dr. Kremer’s presentation of the seventh case study offered a great opportunity for the South Bruce Community Liaison Committee and members of the community to learn why the Nuclear Waste Management Organization is confident in the design of the deep geological repository,” said South Bruce Mayor Robert Buckle. “Erik did a wonderful job explaining the robust scope of safety studies completed, the approach behind each test, and the results of those studies in easy-to-understand terms.”\nPostclosure safety assessments help build confidence in the long-term performance of a deep geological repository for Canada’s used nuclear fuel.\n“A deep geological repository must be able to safely isolate used nuclear fuel over very long periods of time. These case studies help us understand and illustrate the long-term safety of a repository,” added Dr. Kremer. “They also provide a platform for discussion with our siting communities, their regional partners, the regulatory authorities, and other experts in the field, as well as with repository programs all around the world.”\nThe NWMO collaborates with organizations in Canada and around the world to bring their expertise together and remain consistent with international best practice. Ultimately, the safety case will be subject to peer review, both national and international, and an independent regulatory review by the Canadian Nuclear Safety Commission (CNSC).\nThe NWMO is on track to identify a single, preferred site for a deep geological repository by 2023, in an area with informed and willing hosts. When the NWMO applies for a licence, the application to the CNSC will include a safety case, which will include results of site-specific geoscience investigations, a site-specific repository design, and a comprehensive safety assessment.\nNo licence will be granted until the NWMO can demonstrate that the health and safety of the public, the workers and the environment are protected.\nThe Nuclear Waste Management Organization (NWMO) is a not-for-profit organization tasked with the safe, long-term management of Canada’s used nuclear fuel inside a deep geological repository, in a manner that protects people and the environment for generations to come.\nFounded in 2002, the NWMO has been guided for more than 20 years by a dedicated team of world-class scientists, engineers and Indigenous Knowledge Holders that are developing innovative and collaborative solutions for nuclear waste management. Canada’s plan will only proceed in an area with informed and willing hosts, where the municipality, First Nation and Métis communities, and others in the area are working together to implement it. The NWMO plans to select a site in 2024, and two areas remain in our site selection process: the Wabigoon Lake Ojibway Nation-Ignace area in northwestern Ontario and the Saugeen Ojibway Nation-South Bruce area in southern Ontario.","Saugeen Ojibway Nation vote ends company's plans to store nuclear waste near Lake Huron\nCorrection: A previous version of this story incorrectly conflated site selection processes being conducted by Ontario Power Generation and the Nuclear Waste Management Organization.\nAn Ontario power company has announced it will no longer consider storing nuclear waste underground near Lake Huron.\nA vote by the Saugeen Ojibway Nation of Ontario Friday to stopped the development of a site sought by Ontario Power Generation. Of 1,232 ballots cast, 1,058 were against the site and 170 in favor.\n\"We were not consulted when the nuclear industry was established in our Territory,\" said a news release on the vote. \"Over the past forty years, nuclear power generation in Anishnaabekiing has had many impacts on our Communities, and our Land and Waters, including the production and accumulation of nuclear waste.\"\nThe release said that SON leaders will work with Ontario Power Generation \"to find an acceptable solution for the waste.\n\"We will continue to work with OPG and others in the nuclear industry on developing new solutions for nuclear waste in our Territory,\" said Chief Greg Nadjiwon of the Chippewas of Nawash Unceded First Nation. \"We know that the waste currently held in above-ground storage at the Bruce site will not go away. SON is committed to developing these solutions with our communities and ensuring Mother Earth is protected for future generations. We will continue to ensure that our People will lead these processes and discussions.\"\nOntario Power Generation, which operates the Bruce Nuclear Generating Station in Kincardine, said it would respect the Saugeen Ojibway Nation's decision.\n\"OPG will explore other options and will engage with key stakeholders to develop an alternate site-selection process,” OPG CEO and President Ken Hartwick said in a statement.\nHartwick touted nuclear power as key in the fight against climate change.\n\"To enjoy the benefits of this low-carbon, low-cost and reliable source of energy with peace of mind, we must manage the waste responsibly. Permanent and safe disposal is the right thing to do for future generations,\" Hartwick said.\nMichigan State Rep. Shane Hernandez, R-Port Huron, said the news was a pleasant surprise.\n\"I think it's an exciting announcement they're going to move on from that,\" Hernandez said. \"For Michigan and the entire Great Lakes region, this is our biggest natural resources and we have to make sure we're protecting it.\"\nNuclear Waste Management Organization process\nOn Jan. 24, the Nuclear Waste Management Organization announced it had signed agreements with landowners east of Lake Huron in South Bruce, Ontario, which would allow land access for studies for a waste storage site. Technical site investigations and social studies are currently being conducted in South Bruce and Ignace. The NWMO process is separate from that of Ontario Power Generation and is ongoing.\nIn a statement following the Saugeen Ojibway Nation's vote against the Ontario Power Generation plan, Canada's Nuclear Waste Management Organization said willingness is a key component to its process of storing spent nuclear fuel, which includes municipal and indigenous communities like SON. The organization recently signed agreements with landowners east of Lake Huron in South Bruce, Ontario, which would allow land access for studies for a site.\n\"As the results are fresh, it is too soon to speculate on next steps,\" the NWMO said in a statement provided by spokesperson Bradley Hammond. \"That said, over the coming weeks and months, we will do what we can to learn from this process to determine any insights that can be applied to Canada’s plan. That said, the outcome does not change our focus – we’re committed to delivering on our mandate and Canada’s plan remains on track.”\nThe organization has been working to select a 1,500 acre site since 2010, it had previously said it had hoped to complete the process by 2023.\nThe NWMO is a nonprofit founded by Canadian nuclear power producers in 2002, according to the organization's website. It is tasked with \"designing and implementing Canada's plan for the safe, long-term management of used nuclear fuel.\"\nIn January, southeast Michigan state representatives Gary Howell, R-Lapeer, and Shane Hernandez, R-Port Huron, issued statements against locations near Kincardine and Lake Huron. They said the Kincardine locations are too close to Lake Huron, and expressed concerns about drinking water and public health if something went wrong at the site.\nThey called on the United States Congress to do everything in its power to stop the development.\nSupport stories like these. Find our subscription offers here.\nJeremy Ervin covers environment, education and more. Contact him at (810) 989-6276 or firstname.lastname@example.org. Follow him on Twitter @ErvinJeremy."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:0aef7f00-1b98-48f8-bd9e-e4740f191c35>","<urn:uuid:363902a3-e52b-407a-80c7-38b3a0d564aa>"],"error":null}
{"question":"How can I detect and fix water leaks at home?","answer":"Leaking fixtures waste significant water - a single leaking tap can waste 2000 liters per month and increase water bills unnecessarily. You can detect leaks by using your water meter to check for unexpected usage. Most leaks in taps, toilets, showerheads and other water-using devices are easy to detect and repair with basic know-how and the right tools. To prevent water waste, it's important to promptly fix any leaking fixtures and report leaks from hydrants or tobies (main water shut-off valves).","context":["Why Save Water?\nWhy with a river the size of the Clutha flowing through our district, do we need to save water?\nWhile there is not necessarily a water shortage in the district, it costs money to treat and distribute water for domestic consumption. Saving water is good for our pockets and good for the environment.\nAs ratepayers we pay for both the water we use and the infrastructure needed to treat and pipe that water.\nReduced water use means lower total water production and wastewater treatment costs. Using only the water we actually need not only saves money now it also puts off the need for more infrastructure such as dams and reservoirs, pipelines, and water treatment plants and even the need to find new water sources to service a growing demand.\nSaving water also helps reduce wastewater treatment costs. The water used around your home including your washing machine, bathrooms and toilets, is discharged to the sewer for treatment and disposal at the wastewater treatment plant. Saving water also helps delay the need to increase wastewater treatment plant capacity and reduces the volume of wastewater treated and discharged into the rivers and waterways.\n- Pumping water from the source, treating it and piping it to your door is expensive. If we all use less water we can lower the cost of providing it.\n- Excessive summer water use means the water supply system has to work hard to keep up with demand. In some places excessive use can affect availability for fire fighting.\nEvery Drop Counts\nWhen it comes to conserving water, every drop counts. You can do your bit to help save water by:\n- Reporting leaks from hydrants, a toby (your main water shut-off valve) or anywhere else\n- Fixing leaking taps, toilets, showerheads and other water-using devices around your home or business.\n- Learn how to use your meter to check for water leaks. Most are easy to detect and repair with basic know-how and the right tools.\nFor water saving tips around your home, school or workplace check out the sections below.\nCouncil's Water Conservation Efforts\nCouncil is also working to reduce its water use by:\n- Installing more efficient watering systems on town reserves and gardens and using untreated bore water where possible\n- Providing public education campaigns promoting wise water use.\n- See more about our Water Conservation Garden located in Cromwell.\n- Read the Changing How We Use Water brochure Council recently produced in conjunction with Jo Wakelin from Otago PolytchnicCentral Campus, which gives great advice about landscaping with less water in Central Otago.\nSave Water at Home\nThere are many ways to save water around your home. Much of the water we use is wasted and a few small changes can help save water and we don’t mean by going short or without water. Try these:\n- Singing shorter songs in the shower: every minute that you don’t spend in the shower saves you seven litres of water. Reduce your shower by one minute, and you’ll save about 2500 litres of water a year.\n- Turning off the tap when brushing teeth or shaving: a running tap wastes 10 litres per minute.\n- Plug that sink when you’re preparing vegetables. It’ll save you up to 10 litres per minute.\n- No half measures in the kitchen or laundry: a full load of dishes or laundry uses less water and power than two half loads.\n- A scrape will do! Today’s modern dishwashers and detergent mean there’s no need to pre-rinse, just scrape and pop the dishes in the machine – give it a go, you might be surprised by the results.\nOther things you can do include:\nCheck for leaks\nLeaking taps, toilets, showerheads and other water-using devices are major wasters of water. Just one leaking tap can waste 2000 litres per month and increase your water bill unnecessarily. Most leaks are easy to detect and easy to repair with basic know-how and the right tools. Use your water meter to check for leaks.\nUse Water saving devices\nThere are many water saving devices you can buy that reduce your water use – flow regulators (to reduce the flow of water), dual flush toilets and water displacement devices that go in the cistern (‘gizmos’) for single flush toilets. Many devices aren’t very expensive.\nUse water wise appliances\nShop with the stars! Save water and money in the long run by choosing water wise appliances. Look for the stars. The more stars on the label the more water efficient the appliance. So if you’re replacing an old washing machine or toilet choose models with four stars or more. More information about water efficiency.\nSave Water at School\nSave water around your school. Look for water saving plumbing solutions and promote good water use habits. Water-saving mechanisms in schools educate young people about using water wisely and the need to protect the environment. What children see at school can influence behaviour at home.\n- Fix Leaks\nSchools can save water by promptly fixing all leaks. Students should be encouraged to notify teachers as soon as they detect a problem in a restroom or water fountain. A water audit of your school can find hidden leaks that can waste lots of water and money.\n- Install water-wise plumbing\nSchools can install waterless urinals, dual-flush toilets, and taps that turn off automatically after a set amount of time.\n- Promote Wise Water Use\nTalk to children about smart ways to use water such as hand washing techniques and turning taps off.\n- Incorporate water-wise landscaping\nUse plants that don't require much water in landscaped areas. In addition, water crystals can be added to soil to enhance water retention by as much as 40 per cent.\nHard surfaces should not be hosed except in exceptional circumstances. Where possible use a broom or a mop.\nSave Water at Work\nWater is a valuable resource yet all too often we take it for granted. Whether your business is large or small it can benefit from using water wisely. Using water wisely is part of planning for a sustainable future and demonstrates corporate responsibility.\nBenefits of saving water at work:\n- Save your business money. Saving water will have a direct and positive impact on your water bill. Reducing hot water use will also reduce the energy needed to heat water and therefore reduce your electricity/gas bill.\n- Be seen as environmentally friendly. Demonstrate to customers the importance your business places on caring for natural resources and the environment.\n- Water treatment uses energy. Save water and you’ll reduce your carbon footprint.\nFive tips for saving water at work\n- Install dual flush toilets\nA full toilet flush sends 12 litres of water down the drain. A dual flush toilet can use as little as three litres in a flush. If you have a single flush toilet, you could install a cistern displacement device, often called a “gizmo”. Depending on the size of the cistern, these devices can save one to two litres each time the toilet is flushed. If you do use one, make sure you check the manufacturer’s instructions to make sure the device is suitable for your toilet.\n- Repair dripping taps\nFixing these could save as much as 2000 litres of water a month. In most instances all that’s required is a new washer.\n- Install urinal controls\nOn average, an unmanaged cistern flushes four times an hour 24 hours a day. Sensor controlled urinals can reduce the amount of water used as the urinal only flushes after use.\n- Measure and monitor\nUse meter reads to compare your water use so that you can identify any unusual patterns.\n- Make your staff aware of how they can save water\nReporting leaking or dripping taps and using a plug in the sink when you rinse dishes are easy ways to save water in the workplace.\nSave Water in the Garden\nBeing water wise in the garden and outside your home or business means we reduce the amount of high quality drinking water used on lawns, plants and pavements. Sprinklers are the biggest cause of unnecessary water usage as the water often goes where it is not needed and it’s easy to over water.\nWater wise tips in the garden and outside\n- It’s a lawn not a lake! Even in the height of summer, more water is not necessarily better\n- If the grass springs back when you walk on it, there’s no need to water.\n- Install a rain barrel: rainwater is rich in natural minerals and plants love it. A rain barrel is a great way to cheer up your plants and keep your water bill down.\n- Use a bucket to wash your car. This uses up to 125 litres less water than a hosepipe does.\n- Simple mulch for your garden reduces the water that evaporates by up to 70 per cent and means less time spent watering.\n- Water in the early morning or evening to reduce water lost to evaporation.\n- Sweep paths and drive ways instead of washing them.\n- Use a watering can or a hose with a hand-held trigger to minimise wastage and direct water only where needed.\nFor more efficient irrigation\n- Check soil moisture - if your soil is moist 10cm below the surface, you don't need to water.\n- Water in cool, settled weather - water your garden on calmer days, in the cool of early morning or in the evening.\n- Aim low and slow - water close to the ground at a rate the soil can absorb.\n- Using a sprinkler - established plants should only need 30 minutes watering once or twice a week in dry weather.\n- Use mulch - mulch protects your soil from the drying effects of wind and sun, and can cut evaporation\nFor more information download our Changing How We Use Water: a guide to landscaping with less water in Central Otago brochure.\nAlternate Water Sources\nBrochures with More Tips"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:a4e3c33b-ca38-4bfe-ad73-a2a13dadcc68>"],"error":null}
{"question":"In research design, could you explain how test scores and exam performance differ when analyzed as dependent variables?","answer":"Test scores and exam performance serve as dependent variables but are analyzed differently. When studying test scores in relation to sleep, they are examined as simple outcome measures affected by the independent variable of sleep duration. However, when comparing exam scores like midterms versus finals, they require paired samples t-test analysis since they are repeated measures from the same subjects over time. This means the measurements are dependent and need special statistical handling to account for within-subject differences.","context":["Independent and dependent variable examples in a study to determine whether how long a student sleeps affects test scores, the independent variable is length of time spent sleeping while the dependent variable is the test score. The independent variable, also known as the manipulated variable, is the factor manipulated by the researcher, and it produces one or more results, known as dependent variables home research. The dependent variable is what is affected by the independent variable-- your effects or outcomes for example, if you are studying the effects of a new educational program on student achievement, the program is the independent variable and your measures of achievement are the dependent ones. Why is the independent variable labeled the independent variable because it is independent of research participants' actions – participants have no control over what condition or group they are assigned to.\nAfter you have described the research problem and its significance in relation to prior research, explain why you have chosen to examine the problem using a method of analysis that investigates the relationships between or among independent and dependent variables state what it is about the research problem that lends itself to this type of . An independent variable is a variable believed to affect the dependent variable this is the variable that you, the researcher, will manipulate to see if it makes the dependent variable change. Sociologists classify social phenomena being studied as independent and dependent variables understanding social research requires knowledge of the difference .\nA basis for which sociologists determine whether their independent and dependent variables reflect the results b a sociological research approach that seeks in-depth understanding of a topic or subject through observation or interaction this approach is not based on hypothesis testing. The outcome variable measured in each subject, which may be influenced by manipulation of the independent variable is termed the dependent variable in the example of quadriceps strengthening, the strengthening protocol used is the independent variable, and the maximal torque generated isometrically on an isokinetic dynamometer by the . The foundations of quantitative research are variables and there are three main types: dependent, independent and controlled the researcher will manipulate an independent variable in an effort to understand its effect on the dependent or controlled variable.\nResearch project paper and feasibility paper: week 2 as preparation for the final research paper, formulate a theory about the correlation between measurable independent variables (causes) and one measurable dependent variable (the effect). • independent variable – depth of the water • dependent variable – temperature • controlled variable – thermometer assignment lesson 4: concepts, variables, indicators and measurement dr racidon p bernarte based on your identify possible research topics, identify the major variables and the measurement scale to be used. The terms dependent and independent variable apply mostly to experimental research where some variables are manipulated, and in this sense they are independent from the initial reaction patterns,. Relationships between nurse staffing and patient outcome variables a research paper submitted to the graduate school in partial fulfillment of the requirements. Research papers will mention a variety of different variables, and, at first, these technical terms might seem difficult and confusing but with a little practice, identifying these variables becomes second nature because they are sometimes not explicitly labeled in the research writeup, it is .\nResearch plan concept paper/prospectus conduct and interpret an independent sample t-test variables in the analysis are split into independent and dependent . Project paper and feasibility paper: week 2 as preparation for the final research paper, formulate a theory about the correlation between measurable independent variables (causes) and one measurable dependent variable (the effect). In this example, the dependent variable is the age at which the child learns to speak and the independent variable is whether the child is first- or second-born researchers are interested in looking at how alcohol use influences reaction times while driving. This episode explains the difference between independent and dependent variables in psychology experiments written by chris mayhorn produced by bypass publi.\nSampling & variables of sampling techniques commonly used in research projects and will discuss dependent and independent variables of a research paper. Writing an apa paper 1 running head: writing an apa report 1989) methods in behavioral research identify the independent and dependent variables and the . Using general social survey (gss) investigating social relationships • identifying independent and dependent variables your paper is expected.","A paired samples t-test is performed when an analyst would like to test for mean differences between two related treatments or conditions. If the same experimental unit (subject) is measured multiple times, and you would like to test for differences, then you may need to perform a repeated measures analysis such as a paired t-test. A paired sample t-test is the simplest version of “within -subject” analysis or “repeated measures” analysis.\nRepeated measures can occur over time or space. For example, you may want to see if students improved their knowledge over the course of a term by checking for differences between mid-term and final exam scores. Since the same student is measured at two separate time points, the measurements are considered repeated over time.\nRepeated measures over space can be a little more difficult to understand. For example, you may want to check for differences in blood pressure between measurements taken on the right arm and left arm. Since the same study subject is measured with both treatment conditions in two locations, this would be considered a repeated measurement over space.\nA paired samples t-test is performed when each experimental unit (study subject), receives both available treatment conditions. Thus, the treatment groups have overlapping membership and are considered dependent.\nThe two-sided null hypothesis is that mean treatment differences are equal to zero. The alternative hypothesis is that the mean treatment difference is not equal to zero.\nμdiff = μ1 – μ2\nH0: μdiff = 0\nHa: μdiff ≠ 0\nPaired Samples T-test Assumptions\nThe following assumptions must be met in order to run a paired samples t-test:\n- The response of interest should be a continuous measure.\n- The difference between the two related treatment groups should be normally distributed.\n- The difference between groups contain no major outliers.\nPaired Samples T-test Example\nIn this example, we will test to see if there is a statistically significant difference in the reaction times of participants in a sleep deprivation study. Each evening, study participants were only allowed 3 hours of sleep per night. After waking, a series of tests were administered and average reaction times were recorded for each subject. We would like to check to see if there was a statistically significant difference in the reaction times of participants between day 1 and day 3 of the study. This data is a subset of a larger experiment.\nday1 = The reaction times on day 1\nday3 = The reaction times on day 3\ndiff = the difference of day 1 – day 3\nThe data for this example is available here:\nPaired Samples T-test SAS Code\nPROC TTEST includes QQ plots for the differences between day 1 and day 3. While this information can aid in validating assumptions, the Shapiro-Wilk Normality Test of group difference, should also be used to help evaluate normality. Thus, PROC UNIVARIATE SAS code has been provided to perform the Shapiro-Wilk test on the group differences.\nHere is the annotated code for the example. All assumption checks are provided along with the paired t-test:\n*Import the data; proc import datafile='C:\\Dropbox\\Website\\Analysis\\Paired T\\Data\\sleep.csv' out=work.sleep dbms=csv replace; run; *Produce descriptive statistics; proc means data=sleep nmiss mean std stderr lclm uclm median min max qrange maxdec=2; var day1 day3; run; *Test for the normality of the differences; proc univariate data=sleep normal; var diff; run; *Run the Paired T-test; proc ttest data=sleep plots=all; paired day1*day3; run;\nPaired Samples T-test Annotated SAS Output\nMany times, analysts forget to take a good look at their data before performing statistical tests. Descriptive statistics are not only used to describe the data but also help determine if any inconsistencies are present. Detailed investigation of descriptive statistics can help answer the following questions (in addition to many others):\n- How much missing data do I have?\n- Do I have potential outliers?\n- Are my standard deviation and standard error values large relative to the mean?\n- In what range most of my data fall for each treatment?\n- Variable – Each treatment level of our independent variable.\n- N – The number of observations for each treatment.\n- N Miss – The number of missing observations for each treatment.\n- Mean – The mean value for each treatment.\n- Std Dev – The standard deviation of each treatment.\n- Std Error – The standard error of each treatment. That is the standard deviation / sqrt (n).\n- Lower and Upper 95% CL for Mean – The upper and lower confidence intervals of the mean. That is to say, you can be 95% certain that the true mean falls between the lower and upper values specified for each treatment group.\n- Median – The median value for each treatment.\n- Minimum, Maximum – The minimum and maximum value for each treatment.\n- Quartile Range – The inner quartile range of each treatment. That is the 75th percentile – 25th percentile.\nPrior to performing the paired t-test, it is important to validate our assumptions to ensure that we are performing an appropriate and reliable comparison. Testing normality should be performed on the day differences using a Shapiro-Wilk normality test (or equivalent), and/or a QQ plot for large sample sizes. Many times, histograms can also be helpful. In this example, we will use PROC UNIVARIATE to produce our Shapiro-Wilk normality test for the daily difference, and PROC TTEST will produce our corresponding QQ plots.\nThe Shapiro-Wilk normality test on the difference between days:\n- Test – Four different normality tests are presented.\n- Statistic – The test statistics for each test is provided here.\n- p Value – The p-value for each test is provided. A p-value < 0.05 would indicate that we should reject the assumption of normality. Since the Shapiro-Wilk Test p-values are > 0.05 for each group, we conclude the data is normally distributed.\nPROC TTEST provides a QQ Plot of the differences between days. The vast majority of points should follow the theoretical normal line.\nSince the Shapiro-Wilk Test p-value is > 0.05, and the QQ Plot of the differences follows the QQ plot theoretical normal diagonal line, we conclude the daily difference is normally distributed.\nBoxplots to Visually Check for Outliers\nPROC TTEST will provide a horizontal box plot of the difference between days. This can help visually identify outliers. The boxplot below shows no points outside the whiskers of the plot. As a result, we conclude there are no major outliers present in our differences.\nPaired Samples T-test\nSo far, we have determined that the differences between days are normally distributed and we do not have major influential outliers. Our next step is to officially perform a paired sample t-test to determine if there is a statistically significant difference in activity scores between 1 day and 3 day. PROC TTEST will produce descriptive statistics on the differences as a part of the paired t-test output:\n- N – This column identifies the number of paired observations for which we are taking differences. More clearly, this will represent the number of subjects that were measured on days 1 and 3.\n- Mean– The average of the differences between days 1 and 3.\n- Std Dev – The standard deviation of the differences between days 1 and 3.\n- Std Err – The standard error of the differences between days 1 and 3.\n- Min, Max – The minimum and maximum difference.\n- 95% CL Mean – The 95% confidence interval around the mean difference. That is to say, you can be 95% certain that the true mean difference in activity scores between day 1 and day 3 falls between -31.66 and -5.32.\n- 95% CL Std Dev – The 95% confidence interval of the standard deviation across od the difference between days.\nPaired Samples T-test Results in SAS\n- DF – The appropriate degrees of freedom represent the number of paired observations (subject) with – 1. This pairs that were dropped due to missing values.\n- t Value – This is the t-statistic. It is the ratio of the mean difference to the standard error. This value is computed as follows: -18.5 / 6.24 = -2.96.\n- Pr > |t| – This is the p-value associated with the paired samples t-test. That is to say if the P value < 0.05 (assuming alpha=0.05) then there is a statistically significant difference between days 1 and 3. In essence, we are testing to see if the difference between days are different than zero. For our example, we have a p-value = 0.0087. Thus, we reject the null hypothesis that the mean difference between activity scores is equal to zero and we conclude that a difference between days exists.\nPaired T-test Interpretation and Conclusions\nA p-value = 0.0087 indicates that we should reject the null hypothesis that the average difference between day 1 and day 3 activity scores is equal to zero. Thus, we conclude there is a difference in activity over time between days. In a paired samples t-test, the challenge can be correctly interpreting the direction of the difference. It is important to note that day 3 was subtracted from day 1 as follows: diff = day 1 – day 3, and the mean difference was approximately -18.5. Looking back at our descriptive statistics we can see that the average activity score for day 1 was approximately 264.5 while the average for day 3 was 283. Thus, on average, study subjects performed activities 18.5 seconds slower after 3 days of sleep deprivation compared to 1 day after being sleep deprived. Furthermore, we are 95% that the true mean difference in activity scores between day 1 and day 3 falls between -31.66 and -5.32.\nWhat to do When Assumptions are Broken or Things Go Wrong\nThe lack of normality of group differences or the existence of major outliers can violate the paired sample t-test assumptions and ultimately impact the results. If this happens, there are several available options:\nPerforming a nonparametric Wilcoxon signed-rank test is the most popular alternative. This test is considered robust to violations of normality and outliers. The Wilcoxon signed-rank performs a similar comparison to that of a paired samples t-test only on ranks. This is the most well-known alternative.\nAdditional options include considering permutation/randomization tests, bootstrap confidence intervals, and transforming the data but each option will have its own stipulations.\nIf you need to compare more than two dependent groups, a single factor repeated measures analysis of variances (ANOVA) or nonparametric Friedman test would be appropriate.\nFurthermore, if you have one between-subject factor and one-within subject factor to consider simultaneously, then a repeated measure split-plot design and corresponding mixed model ANOVA would be appropriate.\nMissing values can severely impact a paired sample t-test because the entire row of data will generally be excluded. If you have a lot of missing data, one alternative would be to perform a single factor repeated measures mixed model ANOVA. This would allow for the computation of estimated marginal means to compensate for the uneven replication between groups.\nA paired samples t-test is not appropriate if each experimental unit (subject) only receives one of two available treatments. For example, if you would like to see if first-year students scored differently on an exam when compared to second-year students, then each subject only has one of two potential factor levels. If this is the case, then an independent samples t-test would be a more appropriate course of action.\nAdditional Resources and References\nSAS Version 9.4, SAS Institute Inc., Cary, NC.\nGregory Belenky, Nancy J. Wesensten, David R. Thorne, Maria L. Thomas, Helen C. Sing, Daniel P. Redmond, Michael B. Russo and Thomas J. Balkin (2003) Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: a sleep dose-response study. Journal of Sleep Research 12, 1–12.\nLittell, R.C., Stroup, W.W., and Freund R.J. (2002). SAS for Linear Models, Fourth Edition. Cary, NC: SAS Institute Inc.\nMitra, A. (1998). Fundamentals of Quality Control and Improvement. Upper Saddle River, NJ: Prentice Hall.\nLaplin, L.L. (1997). Modern Engineering Statistics. Belmont, CA: Wadsworth Publishing Company."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:7cfc1d42-6aa4-4f05-9ed2-277f6cf6d6e7>","<urn:uuid:81c29ebf-0080-42ad-a89c-8e629aa84214>"],"error":null}
{"question":"Do growth-related changes and knee injuries affect male and female young athletes differently?","answer":"Yes, there are notable differences. Growth spurts occur between ages 11-15 in girls and 13-17 in boys. Additionally, knee pain is particularly common in young female athletes due to muscle imbalance, manifesting as patellofemoral syndrome with pain in the front of the knee. Both groups experience increased injury risk during growth periods, with the injury rate increasing by 35% as dancers reach ages 14-16.","context":["Homemade chicken noodle soup made in the crock pot for a set-it-and-forget-it easy dinner. You can evan prep all the ingredients ahead of time and store them in the freezer to pull out on a day where you forgot to plan dinner. Just make sure you thaw the ingredients before adding it to the slow cooker to prevent it from staying at an unsafe temperature for too long.\n8 ounces whole-wheat egg noodles or other whole-wheat noodles\n3 pounds bone-in chicken breast, skin removed\n2 cups chopped onion\n1 cup chopped carrot\n1 cup chopped celery\n2 sprigs thyme\n8 cups low-sodium chicken broth\n2 teaspoons kosher salt\n2 cups frozen peas\n¼ cup chopped fresh dill, plus more for garnish\n2 tablespoons lemon juice\nThe adolescent dancer faces unique challenges due to physical and emotional changes that occur during pubertal development. Rapid growth periods can lead to reduced strength, impaired balance, and decreased flexibility, which can alter technical ability and increase the risk of injury.\nGrowth spurts in dancers usually occur between the ages 11-15 in girls and 13-17 in boys, and can last up to two years (IADMS 2000). As height increases, weight gain also occurs. A girl’s menstrual cycle begins during these growth phases and is essential for formation of bone. The pressure to stay thin during periods of weight gain in addition to being unaware of/ignoring nutritional needs results in an energy deficit and increases the likelihood of irregular periods (Delegate 2018). Bones grow at a faster rate than muscles and tendons, and limbs grow at a faster rate than the trunk. This affects strength, flexibility, and balance control in dancers. These changes can make movement feel awkward and may affect your ability to perform at the level that you are used to. Don’t be discouraged, these changes are temporary!\nThe injury rate increases by 35% as dancers reach ages 14-16. Body regions most commonly affected are the foot/ankle, lumbar spine, hips, and knees (Steinberg 2012, Delegate 2018).\nCommon injury types in adolescents:\nREDUCING INJURY RISK DURING GROWTH CHANGES:\n1)Education Committee (Kathryn Daniels, Chair). International Association for Dance Medicine & Science. November 2000 https://www.iadms.org/page/1\n2) Delegete, A. Health Considerations for the Adolescent Dancer. A webinar through the Harkness Center for Dance Injuries. Accessed September 23, 2018.\n3) Steinberg, N., Siev-Ner, I., Peleg, S., Dar, G., Masharawi, Y., Zeev, A., & Hershkovitz, I. (2012). Extrinsic and intrinsic risk factors associated with injuries in young dancers aged 8–16 years. Journal of sports sciences, 30(5), 485-495.\n4) Steinberg, N., Siev-Ner, I., Peleg, S., Dar, G., Masharawi, Y., Zeev, A., & Hershkovitz, I. (2013). Injuries in female dancers aged 8 to 16 years. Journal of athletic training, 48(1), 118-123.\nThe immune system provides protection from seasonal illness such as the common cold as well as other health problems including arthritis, allergies, abnormal cell development and cancers. Dancers are exposed to physical stress from training, which increases susceptibility to illness. Additionally, working in close proximity with other dancers increases exposure to infection. Nutrition plays an important role in maintaining immune function to protect against infection. Learn how to boost your immunity by including these nutrients in your eating plan.\nProteins form many immune cells and transporters. Try to consume a variety of protein foods including seafood, lean meat, poultry, eggs, beans and peas, soy products and unsalted nuts and seeds.\nVitamin A helps regulate immune function and protects from infections by maintaining healthy tissues in skin, mouth, stomach, intestines and respiratory system. Vitamin A is found in foods such as sweet potatoes, carrots, kale, spinach, red bell peppers, apricots, eggs or foods labeled \"vitamin A fortified,\" such as cereal or dairy foods.\nVitamin E works as an antioxidant to neutralize free radicals. Include vitamin E in your diet with fortified cereals, sunflower seeds, almonds, vegetable oils (such as sunflower or safflower oil), hazelnuts and peanut butter.\nVitamin C protects stimulates the formation of antibodies, which are necessary to fight infection. Citrus fruits such as oranges, grapefruit and tangerines, red bell pepper, papaya, strawberries, and tomato juice are good sources of vitamin C.\nZinc is critical for wound healing and aids the immune system. This mineral can be found in lean meat, poultry, seafood, milk, whole grain products, beans, seeds and nuts.\nOther nutrients, including vitamin B6, folate, selenium, iron, as well as prebiotics and probiotics, may also influence immune response.\nAcademy of Nutrition and Dietetics (2017). Protect Your Health with Immune-Boosting Nutrition. Retrieved at eatright.org.","BACK TO SCHOOL SPORTS – INJURY PREVENTION & SAFE RECOVERY FOR YOUNG ATHELETES\nBack to school is here. And while not all of our kids are going back to organized sports just yet, for those who are (and for young athletes that train year-round), it’s important to educate ourselves on common injuries, prevention, and recovery. The goods new is that most of these injuries are minor and have minimal recovery time!\nAnkle sprains may be the most common injury in all sports. A sprain, “roll,” or “turn” of the ankle is a twisting injury that damages supporting ligaments of the ankle. Most ankle sprains in young athletes heal quickly with a short period of immobilization, then an exercise program and short rest from sports. When considering this injury in children and teens, be aware of the non-displaced growth plate fracture of the fibula, which can look almost identical to an ankle sprain. Luckily, a brief period of immobilization is the treatment for this injury as well.\nKnee pain is particularly common in young female athletes. Knee pain is usually considered an overuse injury and referred to as “patellofemoral syndrome.” Pain in the front of the knee is usually due to pressure overload on the kneecap or “patella.” In young female athletes, this is often due to different degrees of muscle imbalance and high activity levels. A combination of physical therapy and strength training a few times a week is very successful in treating knee pain in young athletes.\nOsgood-Schlatter is a very specific type of knee pain. Osgood-Schlatter is caused by a traction injury on an apophysis (a special type of growth plate) at the top of the shin bone (tibia). The traction occurs during high activity levels on strong and tight, developing, muscles. This injury can cause a bump at the bottom of the knee, which may be painful and swollen. Recovery can include any combination of rest, stretching, ice, NSAIDs, and/or a supportive knee strap.\nLittle Leaguer’s Elbow is usually considered the classic overuse injury and includes any pain of the elbow due to excessive throwing. Young athletes typically recover with rest, stretching and attention to proper throwing form. In some rare cases, a young athlete may end up requiring surgery if this injury goes untreated, so visiting an orthopedic physician for an evaluation early is recommended.\nACL tears are another extremely common injury in young athletes. The anterior cruciate ligament (ACL) is a stabilizing ligament of the knee which can be torn during an uncontrolled twisting motion. ACL repairs almost always require surgery in the young and active population. Additionally, other structures in the knee, namely the shock-absorbing menisci, are often damaged during injury as well. Generally, these additional damaged structures also need surgery for repair. While there is a high rate of return to sports after ACL injuries, it can be up to 6-12 months before safely returning to play. Recent studies show that many ACL injuries can be prevented if muscles surrounding the knees are strong and flexible. ACL tear prevention includes exercises that increase muscle power, balance, and improve core strength and stability.\nIn the last few years, big steps have been taken in school sports to help ensure children and teens are as safe as possible. However, more can be done to prevent sports injuries in young athletes. Most importantly, keep up with visits to health care providers to help catch injuries early on (or before they occur!) and continue to be diligent with cross training and stretching.\nIf you would like to learn more about sports injury prevention and wellness for athletes, please contact firstname.lastname@example.org or call/text 616- 516-6230."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:85785016-bfef-4557-a453-501ded74570b>","<urn:uuid:a96cc471-9d87-474f-adb3-91dd3136bb29>"],"error":null}
{"question":"How to manage Takayasu arteritis with medications?","answer":"Takayasu arteritis is primarily managed with corticosteroid therapy, which initially shows good response. However, since disease activity often relapses during corticosteroid tapering or withdrawal, disease-modifying antirheumatic drugs (DMARDs) are typically added upfront to maintain remission. Various treatment options include conventional DMARDs like methotrexate, leflunomide, cyclophosphamide, azathioprine, and mycophenolate mofetil, as well as biological DMARDs such as tocilizumab and anti-tumor necrosis factor-alpha agents. While pooled data shows clinical remission or angiographic stabilization in over 60% of patients treated with various DMARDs, no single DMARD has shown definitive efficacy or effectiveness in controlled trials.","context":["|Year : 2021 | Volume\n| Issue : 4 | Page : 373-374\nManagement of Takayasu arteritis: The elusive search for the holy grail!\nUpendra Rathore, Durga Prasanna Misra\nDepartment of Clinical Immunology and Rheumatology, Sanjay Gandhi Postgraduate Institute of Medical Sciences, Lucknow, Uttar Pradesh, India\n|Date of Submission||29-Nov-2021|\n|Date of Acceptance||02-Dec-2021|\n|Date of Web Publication||22-Dec-2021|\nDr. Durga Prasanna Misra\nDepartment of Clinical Immunology and Rheumatology, Sanjay Gandhi Postgraduate Institute of Medical Sciences, Lucknow - 226 014, Uttar Pradesh\nSource of Support: None, Conflict of Interest: None\n|How to cite this article:|\nRathore U, Misra DP. Management of Takayasu arteritis: The elusive search for the holy grail!. Indian J Rheumatol 2021;16:373-4\nTakayasu arteritis (TAK) is an enigmatic large vessel vasculitis more commonly encountered in Asia, including in India. Aberrant activation of the immune system is understood to be the mechanism driving the pathogenesis of TAK. However, the medical therapy of TAK yet remains unclear., Assessment of disease activity in TAK also remains challenging. The site of pathology, namely the aorta and its branches remains inaccessible for direct examination, unlike the other form of large vessel vasculitis, giant cell arteritis, where temporal arteries are easily accessible for biopsy or imaging through ultrasound. Therefore, outcome assessment in TAK relies predominantly on clinical remission, whose assessment per se is heterogenous and often discordant with the actual vascular pathology, and stabilization or improvement of the extent of disease on serial angiography., TAK responds well to corticosteroid therapy, however, the disease activity often relapses as corticosteroid therapy is tapered or withdrawn. For this reason, disease-modifying antirheumatic drugs (DMARDs) are often added upfront to maintain remission of disease activity.\nUnfortunately, no DMARD has yet shown definitive efficacy or effectiveness in TAK. Few quality randomized controlled trials are available in TAK. Subcutaneous weekly administration of tocilizumab failed to demonstrate superiority against placebo for reduction of time to relapse using an intention-to-treat analysis, however, demonstrated a benefit with tocilizumab in per-protocol analysis., Intravenous abatacept failed to demonstrate superiority versus placebo for time to relapse in another clinical trial. Few observational studies have had suitable control groups for comparison of outcomes in TAK. Limited data in this regard suggest the potential for better clinical response with leflunomide than with cyclophosphamide, comparable clinical responses with leflunomide and methotrexate, similar responses with either antitumor necrosis factor-alpha agents or tocilizumab and better clinical responses (with similar angiographic progression) for tofacitinib versus methotrexate.,, Pooled comparisons from studies comparing biological DMARDs with conventional DMARDs suggest a potential for better clinical and angiographic response with biological DMARDs, although the results failed to attain statistical significance. Pooled data from uncontrolled observational studies have demonstrated clinical remission or angiographic stabilization in >60% patients treated with tocilizumab, antitumor necrosis factor-alpha agents, azathioprine, and leflunomide with a similar degree of clinical response with mycophenolate mofetil. The lack of an appropriate control group limits the understanding of a majority of observational studies on the management of TAK.,\nIn this context, Shumy et al. reported outcomes in a cohort of 11 patients with active TAK treated with corticosteroids with further addition of methotrexate if there was inadequate control of disease activity, followed up for 6 months and outcomes were assessed at 1 month, 3 months, and 6 months. Corticosteroid monotherapy was successful in maintaining clinical remission in only one patient, whereas eight out of the ten remaining patients continued to be in remission following the addition of methotrexate. The interpretation of the findings of the study was limited by the small number of patients (although this needs to be understood in the context of TAK being a rare disease), the limited duration of follow-up, the lack of assessment of angiographic evolution of disease following therapy, the lack of evaluation of patient reported outcomes such as quality of life and fatigue, and the lack of a suitable comparator group.,,\nNevertheless, the present study adds important information from Bangladesh regarding TAK, and the findings are of relevance to the Asian and the South East Asian regions. Clinical trials are difficult in TAK, therefore, good quality observational studies with appropriately matched control groups (matched for key prognostic factors) are essential to better understand the disease. Since clinical response and inflammatory markers have poor concordance with vascular pathology (which itself is difficult to access for evaluation), often a diagnosis of active TAK is only evident retrospectively by the progression of angiographic extent of disease on serial angiography., Emerging modalities like 18-fluorodeoxyglucose positron emission tomography computerized tomography (PET) or PET magnetic resonance imaging hold promise to provide both anatomical and functional information regarding vascular wall metabolic activity. However, PET is not a reliable tool for patients on immunosuppressive therapy. Recent literature has emerged regarding the use of composite scores involving imaging along with serological markers to assess disease activity in TAK. However, such tools require validation across different populations before they can be widely used., Future observational studies should provide due attention to methodological aspects to enhance their quality and contribute valuable scientific information toward the management of TAK.\n| References|| |\nMisra DP, Wakhlu A, Agarwal V, Danda D. Recent advances in the management of takayasu arteritis. Int J Rheum Dis 2019;22 Suppl 1:60-8.\nArnaud L, Haroche J, Mathian A, Gorochov G, Amoura Z. Pathogenesis of takayasu's arteritis: A 2011 update. Autoimmun Rev 2011;11:61-7.\nMisra DP, Sharma A, Kadhiravan T, Negi VS. A scoping review of the use of non-biologic disease modifying anti-rheumatic drugs in the management of large vessel vasculitis. Autoimmun Rev 2017;16:179-91.\nFerfar Y, Mirault T, Desbois AC, Comarmond C, Messas E, Savey L, et al.\nBiotherapies in large vessel vasculitis. Autoimmun Rev 2016;15:544-51.\nMisra DP, Misra R. Assessment of disease activity in takayasu's arteritis. Indian J Rheumatol 2015;10:S43-7.\nHoffman GS. Takayasu arteritis: Lessons from the American national institutes of health experience. Int J Cardiol 1996;54 Suppl:S99-102.\nMisra DP, Rathore U, Patro P, Agarwal V, Sharma A. Corticosteroid monotherapy for the management of Takayasu arteritis – A systematic review and meta-analysis. Rheumatol Int 2021;41:1729-42.\nNakaoka Y, Isobe M, Takei S, Tanaka Y, Ishii T, Yokota S, et al.\nEfficacy and safety of tocilizumab in patients with refractory Takayasu arteritis: Results from a randomised, double-blind, placebo-controlled, phase 3 trial in Japan (the TAKT study). Ann Rheum Dis 2018;77:348-54.\nNakaoka Y, Isobe M, Tanaka Y, Ishii T, Ooka S, Niiro H, et al.\nLong-term efficacy and safety of tocilizumab in refractory Takayasu arteritis: Final results of the randomized controlled phase 3 TAKT study. Rheumatology (Oxford) 2020;59:2427-34.\nLangford CA, Cuthbertson D, Ytterberg SR, Khalidi N, Monach PA, Carette S, et al.\nA randomized, double-blind trial of abatacept (CTLA-4Ig) for the treatment of Takayasu arteritis. Arthritis Rheumatol 2017;69:846-53.\nRathore U, Thakare DR, Patro P, Agarwal V, Sharma A, Misra DP. A systematic review of clinical and preclinical evidences for Janus kinase inhibitors in large vessel vasculitis. Clin Rheumatol 2021. Online ahead of print [doi: 10.1007/s10067-021-05973-4].\nRathore U, Patro P, Agarwal V, Sharma A, Misra D. Disease-modifying antirheumatic drugs for the management of takayasu arteritis – Protocol for a systematic review. Indian J Rheumatol 2021;16:79-82. [Full text]\nMisra DP, Rathore U, Patro P, Agarwal V, Sharma A. Disease-modifying anti-rheumatic drugs for the management of Takayasu arteritis – A systematic review and meta-analysis. Clin Rheumatol 2021;40:4391-416.\nShumy F, Anam AM, Choudhury MR, Shahin A, Haq SA, Rasker JJ, et al.\nRate and predictors of response to glucocorticoid therapy in patients of Takayasu arteritis at a tertiary level hospital of Bangladesh: A longitudinal study. Indian J Rheumatol 2021;16:375-80. [Full text]\nMisra DP, Rathore U, Patro P, Agarwal V, Sharma A. Patient-reported outcome measures in Takayasu arteritis: A systematic review and meta-analysis. Rheumatol Ther 2021;8:1073-93.\nWong SP, Mok CC, Lau CS, Yip ML, Tam LS, Ying KY, et al.\nClinical presentation, treatment and outcome of Takayasu's arteritis in southern Chinese: A multicenter retrospective study. Rheumatol Int 2018;38:2263-70.\nJanes AL, Castro MF, Arraes AE, Savioli B, Sato EI, de Souza AW. A retrospective cohort study to assess PET-CT findings and clinical outcomes in Takayasu arteritis: Does 18F-fluorodeoxyglucose uptake in arteries predict relapses? Rheumatol Int 2020;40:1123-31.\nMason JC. Takayasu arteritis – Advances in diagnosis and management. Nat Rev Rheumatol 2010;6:406-15.\nCampochiaro C, Misra DP. PET in Takayasu arteritis: Onwards and upwards towards a future of robust multimodality disease activity assessment? Rheumatology (Oxford) 2021. Online ahead of print [doi: 10.1093/rheumatology/keab644].\nMa LY, Wu B, Jin XJ, Sun Y, Kong XF, Ji ZF, et al\n. A novel model to assess disease activity in Takayasu arteritis based on 18F-FDG-PET/CT: A Chinese cohort study. Rheumatology (Oxford) 2021. Online ahead of print [doi: 10.1093/rheumatology/keab487]."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:43aba3bd-152d-4ef5-b2c2-f893f1fcb396>"],"error":null}
{"question":"I'm researching income inequality - what are the key differences between common law and civil law countries regarding executive compensation?","answer":"In common law countries like the United States, income inequality has increased rapidly with top 1% earners seeing significant gains while lower incomes have stagnated. In contrast, civil law countries like Japan and continental Europe have experienced much slower growth in income disparity. This difference is partly attributed to corporate governance rules and social norms, where civil law countries may have stronger cultural norms against excessive executive compensation and different corporate governance structures compared to the Anglo-American world.","context":["October 6 Class 1\n(by Prof. Sanae ITO and Designated Assistant Prof. Yuki SHIMAZU, GSID)\nIntroduction to Campus ASEAN and its joint education course\n1) Introduction to Campus ASEAN program\n2) Introduction to this course\n- Course description\n- Learning objectives\n- Group presentations\nOctober 13 Class 2\n(by Prof. Kiyoshi FUJIKAWA, GSID)\nFactors of economic development: Based on the neoclassical growth theory\n1) Recent trend of Japanese official development assistance (ODA)\n2) Activities of Japan International Cooperation Agency (JICA)\n3) To work as an international servant.\nOctober 20 Class 3\n(by Prof. Sanae ITO, GSID)\nRecent trends in international development cooperation\nThis lecture reviews the evolution of development theories after the Second World War and examines how the notion of development is being reframed as the influence of rising powers challenges the conventional theory and practice of international development. Special attention will be given to Asia where post-war relations of aid are being radically transformed and new norms of development cooperation are taking shape.\nOctober 27 Class 4\n(by Associate Prof. Kasumi ITO, ICCAE )\nAgricultural Technical Cooperation for Livelihood Improvement\nThis lecture provides several agricultural and environmental issues and its negative influence to livelihood of rural people in ASEAN countries by using pictures and statistical data. Students will form small groups to discuss about the expected technical cooperation to solve the selected issue, and present the result to the other students. After the presentation, several examples of real technical cooperation project will be introduced and students will discuss about important key factors for successful technical cooperation to solve the agricultural and environmental issues.\nNovember 10 Class 5\n(by Prof. Yuzuru SHIMADA, GSID)\nInternational assistance for law and governance\nSince 1990s, the \"law and governance reform\" is a popular agenda in international development. There has been a series of activities to make and implement laws in a society to promote economic and social development. If necessary, a foreign government or international organization gives assistance for it. Within an academic context, researches have been done to understand the causal relation between law and socio-economic development and what law has made bigger impacts on development. So, legal reform is a very important part of international cooperation. This lecture will introduce experiences of international cooperation for legal reform in Asia as an example of new trends in international cooperation.\nNovember 17 Class 6\n(by Designated Lecturer. David GREEN, Graduate School of Law)\nDiscussion Seminar on Japan’s Role in Asia\nAlthough its economic ranking has been surpassed by China in recent years, Japan remains a major economic, political and even military power in Asia. With the quickly changing Asian context in mind, this course will take a discussion-based approach to deliberate on Japan’s role in the region. What courses of action can Japan take to maximize benefits to itself and its allies? How can Japan counterbalance against regional and international threats? As the Abe administration seeks to bolster Japan’s military status, is this in fact a good idea from the Japanese and regional perspectives? Students should expect to be actively involved and willing to contribute their own thoughts and ideas to this discussion.\nNovember 24 Class 7\n(by Designated Associate Prof. Sean MCGINTY, Graduate School of Law)\nExecutive Compensation and Corporate Law in Comparative Context\nIn recent years the issue of income inequality has become a hotly debated topic in the United States and other developed countries in the common law world where the proportion of income earned by the top 1% of earners has rapidly increased while those at the bottom have stagnated or decreased. In civil law countries such as those in continental Europe and Japan, in contrast, income disparity has grown at a much lower pace than in the common law countries.\nThe debate over what has caused the increase in income inequality and why the di vergence between civil and common law countries exists in part relates to the question of how corporations are governed. The corporation is the organizational form for most large scale economic activity the world over and the explosion of income inequality in the Anglo-American world is closely associated with an explosion in the compensation of top executives at large corporations relative to those of rank and file workers.\nThis lecture will examine a key question which these observations raise: to what extent are differences in the rules governing corporations in the common and civil law worlds to blame for this divergence? Such rules have two potential sources which we will examine. On the one hand corporate law in most jurisdictions set out rules which govern the way executives are compensated. Do differences in such rules make it easier or more difficult for executives to receive higher compensation in some countries than others? On the other we have non-legal sources of rules such as social norms. Do cultural norms against greed or in favor of fairness have a greater disciplinary effect on executive compensation in civil law countries than they do in the common law world?\nIn examining these questions we will look at the examples provided by American corporate law and governance on the one hand and Japanese and European corporate law and governance on the other.\nDecember 1 Class 8\n(by Designated Associate Prof. Hiroko ITO, Graduate School of Law)\nAsian Family Law (Advanced)\nThe purpose of this session is to understand the reality surrounding the application of religious laws in a common law country. This session covers South Asia where religious laws and state laws regarding on family matters co-exist, and those laws vary in substances. We review the relevant statutes on child marriage, custody, bigamy and etc., to understand the aim to protect the rights of the weak, and also the opposition movement based upon the religious belief. Students are required to take the basic session on Asian Family Law provided for undergraduate students.\nDecember 8 Class 9\n(by Associate Prof. Teilee KUONG, CALE)\nLaw and Politics in ASEAN Integration – The ASEAN Charter and Beyond\nThis 90-minute session focuses on some particular features of the ASEAN Charter and other post-Charter documents related to the ASEAN regional integration in the 21st century. The particular features of these documents reflect the underlying tensions of the diverse national systems in the region and some pragmatic political compromises among the Members States in response to internal needs and external pressures. They also partly display the possible legal directions for this regional integration to go ahead in the coming years.\nIn addition to the talks by the lecturer, participants are expected to take part in short discussions on some critical issues related to the legal and political dimensions of regional integration in general and the latest situation of legal and political development in the ASEAN region.\nDecember 15 Class 10\n(by Prof. Yoshio SANO, Graduate School of Economics)\nHuman Resources Management from Cross-Cultural Aspects\nHuman Resources Management is vitally important for any corporation doing business in the global fields.\nIn the lectures we will look at how global corporations manage the human resources especially in cross-cultural circumstances. We will look at corporations in Japan and Asia. Case studies will be used. Positive participation of the students are required.\nDecember 22 Class 11\n(by Lecturer. Chie YOROZU, Graduate School of Economics)\nJapanese Firms and Management in Comparative Perspective\nThis lecture introduces students to some of the main features of Japanese national business systems. The aim is to understand the range of major ‘external’ influences and national histories (national institutions and contexts) that affect the way Japanese firms behave. On the basis of case study of Japanese firms, students will analyze how difficult it is to see radical attempted change in Japan. By the end of the lecture, students should be able to apply the conceptual frameworks learnt in this lecture to compare very different socio-economic models in the Japanese and ASEAN economies.\nJanuary 10 Class 12\n(by Associate Prof. Yasuhiro DOI, Graduate School of Economics)\nASEAN's Economic Integration -AEC-\nPurpose of this lecture is to show a guideline of ASEAN Economic Community. In order to grasp academic backgrounds of free trade, we employ the process of economic integration by Balassa (1961). Also economic levels of ASEAN countries will be referred as an important point of free trade. Productivity and industrial structure of each country are analyzed empirically to seek effectivities of free trade among ASEAN countries.\n2. Outlines of Free Trade\n3. ASEAN Economy\n4. Convergence of Industry\n5. Productivity Convergence\nJanuary 12 Class 13\n(by Prof. Jiro NEMOTO, Graduate School of Economics)\nMacro Perspectives of Economic Development and Growth\nThis lecture aims to learn economic growth and development by examining macroeconomic time series data in the long-run. A simple theoretical framework of macroeconomics will be introduced to facilitate understanding of implications drawn from data visualization. We will see experiences of the Japanese economy since 60s and compare them to those of the East Asian and ASEAN countries. Based on empirical evidence, the geese-flying pattern of economic development is briefly discussed.\nJanuary 19 Class 14\nJanuary 26 Class 15\n GSID: Graduate School of International Development\n ICCAE: International Cooperation Center for Agricultural Education\n CALE: Center for Asian Legal Exchange"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:b1d44c3c-232f-4c7b-b526-66cecc1667f4>"],"error":null}
{"question":"How do multinational companies exploit supply chains for profit, and what sustainability strategies are retailers adopting to reform this?","answer":"Multinational companies exploit supply chains by designing and selling products while capturing all the value, while outsourcing actual production to underpaid workers. Companies organize production in places with weak worker protection laws to maximize profits. To reform this, retailers are implementing several sustainability strategies, including partnering with Fair Trade Certified factories, improving procurement policies through supplier audits, partnering with local vendors to reduce emissions and support local economies, and exploring innovative fulfillment options. Some retailers like Pact and Outerknown are ensuring transparency by providing detailed information about their value chains and only working with certified factories that guarantee safe working conditions.","context":["A 14-minute master class on all that's wrong with global supply chains.\nBTS: Georgios, thanks for joining us. Can we start by asking you to explain why ILC 2016 was so important?\nGA: It was dealing with an important issue – global supply chains – which involve a number of major governance gaps. The economy has globalised over recent decades but the institutions and means to govern the economy haven’t caught up. This year’s ILC and the wider push towards a global supply chain convention was therefore crucial because it was about building towards global governance. Without that, we have problems. Currently, the way supply chains are structured ensures a race to the bottom when it comes to labour standards and wages. The lower these are, the more value big companies can capture – which is why they like things the way they are.\nBTS: So in your ideal scenario, we will have a global convention on supply chains?\nGA: That would be a key first step towards proper global economic governance. It would oblige governments to oblige their multinational companies to apply rules throughout their supply chains. It would force them to conduct meaningful due diligence.\nBTS: What about the issue of ‘accountability?’\nGA: Accountability is critical, but that is missing at the moment. Major companies build the lack of accountability into their business plans. They organise production in places with weak or no rule of law, at least with regard to worker protection. This needs to change and we need to hold these companies accountable.\nBTS: Do you think major companies intentionally build an economic system that fosters exploitation?\nGA: Definitely. That is how the system works. You have big multinational enterprises designing their products, selling them, and then capturing all the value from the process. While actual production is outsourced and underpaid.\nBTS: I know that the International Trade Union Confederation has recently released some research about value capture along the value chain…\nGA: Yes, this was the Scandal Report. We showed that companies are making vast profits while workers work in poverty and exploitation. Amazingly, we also found that 94% of the work force in global supply chains is ‘hidden’, working in the informal economy.\nBTS: This means that there really is a gigantic governance gap.\nBTS: Moving on, can I ask you to talk to us a bit about ‘due diligence’?\nGA: Well this is a complicated issue that has been made somewhat clearer by the Ruggie Principles on Business and Human Rights. These outline the responsibility that companies have to respect human rights and labour rights, and they outline the responsibility they have to put in place processes that identify, prevent, mitigate and in the end account for the different human rights abuses that may happen in their value chains.\nIn simple terms, when a company directly causes a rights abuse, they have to fix it and compensate for it. Likewise, when that abuse is linked to the company’s operations but not directly caused by it, they have a responsibility to use their influence to address that abuse. Or they have to stop working with, for example, the supplier that abuses.\nIn the end, these principles and this due diligence are important and even if they cannot replace national and international governance, they have the potential to be very powerful. Because if due diligence becomes mandatory, then the entire business model of global supply chains will have to change. Enterprises at the top will have to factor in costs that are now being externalised onto workers and the environment.\nBTS: Presumably, this will also imply a certain degree of transparency on the part of the multinationals regarding their supply chains?\nGA: Absolutely. Transparency is a necessary requirement without which we won’t get anywhere. In order to be able to map out supply chains, to know where the responsibility lies and from whom we should be expecting responsibility, we need full transparency.","Corporate supply chains have become more complex in recent years, and stakeholders at all levels — including consumers, investors, regulators and employees — are increasingly expecting businesses to account for the ESG performance of their suppliers. In addition, companies are finding it important to identify and address risks related to supplier performance. This can include issues like greenhouse gas emissions, deforestation, materials sourcing, human and labor rights and corruption. As retailers build their ESG strategies, many are including an assessment of supply chain impacts and efforts to engage suppliers.\nAs unsustainable supply chain practices become increasingly expensive and socially unacceptable, retailers must prioritize the resilience of their operations at all levels.\nGreenhouse gas emissions from supply chains, part of Scope 3 emissions, are becoming an important consideration. Scope 3 emissions are emitted from sources a company does not own or control but that are related to its operations. Companies are facing pressure to measure and report on their Scope 3 emissions; some are setting Scope 3 emissions reduction targets and engaging with suppliers to ensure these targets are achieved.\nRetailer supply chains extend across the globe. The power of social media to highlight risks can erode consumer trust or lead to consumer boycotts. Emerging consumer, investor and regulatory expectations are leading retailers to understand and mitigate the ESG risks throughout their supply chains.\nCompanies in all industries are facing growing scrutiny and demands to measure and account for the operations of their supply chains, and there are material and reputational consequences for companies that do business with partners that have, for example, significant (and increasing) carbon footprints, accusations of human rights violations (especially in developing regions), and other practices considered to be unethical or unsustainable.\nRetail supply chains also face increasing disruptions due to extreme weather events, labor and product shortages resulting from the COVID-19 pandemic or labor unrest, and wild fluctuations in consumer demand. Costs of labor and materials are increasing as developing regions build their economies, and global decarbonization efforts mean higher costs of fuel and premiums on “green” shipping options. As unsustainable supply chain practices become increasingly expensive and socially unacceptable, retailers must prioritize the resilience of their operations at all levels.\nThere are a few strategies retailers can use to improve the sustainability of their supply chains and, as a result, bolster the overall success of their business:\nEmbrace technological enhancements\nNew cloud-based and artificial intelligence technologies offer a range of solutions that can help optimize supply chains. These solutions include inventory management, real-time crisis response, supplier auditing and verification, and more.\nImprove procurement policies and practices\nAs regulatory, investor and public scrutiny grows around supply chain operations, retailers can mitigate their risk exposure by proactively evaluating and engaging with existing and potential suppliers. Sustainable sourcing policies demonstrate a commitment to best practices, and these must be supported by supplier audits, assessments and subsequent engagements or corrective actions where issues are identified. Supplier audits (whether conducted in-house or through a third-party firm) are key to this process; they provide transparency into suppliers’ potential vulnerabilities. When corporations use the audit results to engage in meaningful dialogue with their suppliers, they can effect change, strengthen supplier relationships and ensure long-term business value.\nPartner locally and sustainably\nWhile major suppliers can offer volume discounts, some retailers avoid concentrating too much of their business with single suppliers. Fragmenting partnerships and doing business with smaller, local vendors offers several sustainability benefits, such as reducing risks of major disruptions, reducing emissions from overseas shipping, supporting local economies and increasing the range of product offerings to consumers.\nExplore innovative fulfillment options\nRetailers are exploring new fulfillment options that decrease freight and shipping needs and allow consumers to receive their goods as quickly as possible. For example, Target acquired the delivery service Shipt to offer at-home delivery options and Amazon has been expanding its network of lockers and fulfillment hubs that allow consumers to buy online and pick up in person. Some retailers are even transforming existing stores into local online order fulfillment hubs.\nWhat retailers are doing\nRetailers are taking strides to ensure the transparency and sustainability of their supply chains. Clothing retailer Pact partners only with Fair Trade Certified factories that provide safe working conditions, uplift local communities and protect the environment. It even offers options for customers to offset the carbon footprint of shipping their orders. Similarly, Outerknown partners with Fair Trade USA and provides detailed and accessible information about its entire value chain and supplier list, from where it sources its cotton to the companies and regions that manufacture its clothing products. The company also enlists its customers as supply chain contributors and allows them to re-sell pre-worn clothing on the Outerknown website.\n- Forbes: How Disrupted Supply Chains Impact Retail Sustainability Efforts: Five Key Strategies For The Post-Pandemic World\n- Washington Business Journal: Integrating supply chain with corporate ESG strategy – Why it’s important\n- ESG Today: Guest Post: Sustainalytics on Why a Sustainable Supply Chain Matters for Companies\n- Retalon: Sustainable Supply Chains in 2022 (and Beyond)\n- McKinsey: Ten steps retailers can take to shock-proof their supply chains\nMore on sustainability in retail\nLast Updated: 4/15/2022"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:d547cc37-c55a-4c56-8993-da1418127bdb>","<urn:uuid:cb36f6ee-7a6f-4e34-ba83-f5f5b7c9e14b>"],"error":null}
{"question":"How do defamation laws handle online content and comments sections, and what protections exist for digital publishers across jurisdictions?","answer":"In the U.S., the Communications Decency Act Section 230 provides strong protection for Internet intermediaries, stating that no provider of an interactive computer service shall be treated as the publisher of information provided by others. This means bloggers are generally not liable for defamatory comments made by others on their platforms. However, foreign jurisdictions often don't provide such protections for computer services hosting third-party content. The SPEECH Act addresses this disparity by prohibiting U.S. courts from enforcing foreign defamation judgments against interactive computer service providers when Section 230 would have provided immunity under U.S. law. This creates a significant shield for American digital publishers against foreign libel judgments based on user-generated content.","context":["A Legal Primer for Bloggers, Part 3 – Defamation\nThis post continues a series dealing specifically with the legal issues that bloggers should be thinking about. Part 3, Defamation, will explore your options when somebody has posted something false and damaging about you, including some common defenses.\nConsider the following scenarios: You’re out surfing the internet one day and come across a false and damaging statement that someone has written about you on their blog or website. Maybe you’re the one writing a scathing review about a new hit movie, including unsavory stories about its lead actress. Or maybe you wrote a glowing review but someone else leaves a libelous comment to your post. In all of these situations, you’ll want to be aware of your rights and obligations under defamation law. Don’t think so? Check out this recent case where a blogger was sued for defamation by a Chinese game developer for his critical review of their product.\nWhat is defamation?\nGenerally speaking, defamation is the issuance of a false statement about another person, which causes that person to suffer harm. Slander involves spoken defamatory statements. Libel involves the making of defamatory statements in a printed or fixed medium, such as a newspaper, book or blog.\nDefamation laws vary from state to state. Indiana has the following laws:\nAllegation; burden of proof\nSec. 1. In an action for libel or slander, it is sufficient to state generally that the defamatory matter published or spoken was about the plaintiff. If the defendant denies the allegation, the plaintiff must prove at trial the facts showing that the defamatory matter was published or spoken about the plaintiff.\nTruth; mitigating circumstances; evidence\nSec. 2. In an action for libel or slander, the defendant may allege:\n(1) the truth of the matter charged as defamatory; and\n(2) mitigating circumstances to reduce the damages;\nand give either or both in evidence.\nIndiana does have a retraction statute that provides protection from defamation lawsuits if the publisher retracts the allegedly defamatory statement according to prescribed guidelines. The retraction must be published within three days and in as conspicuous a place and type as the original item was transmitted. It’s important to note that retraction affects the calculation of damages, not liability. Few courts have addressed retraction statutes with regard to online publications like blogs, but a Georgia court denied punitive damages based on the plaintiff’s failure to request a retraction for something posted on an Internet bulletin board.\nRetraction mitigates damages\nSec. 3. The plaintiff … may recover only actual damages if:\n(1) it appears at the trial of the action that:\n(A) the article was published or transmitted in good faith; and\n(B) the falsity of the article was due to mistake or misapprehension of the facts;\n(2) a full and fair retraction of a factual statement alleged to be false and defamatory was … transmitted to its members or subscribers by the news service.\nWhat about defamatory statements that someone else makes in my comments?\nThe ability to comment on a blog is one of the key features of the blogosphere. Usually it promotes interactivity and civil discourse. Of course, sometimes a comment will include defamatory statements. Generally, anyone who repeats someone else’s statements is just as responsible for the defamatory content as the original speaker if they knew, or had reason to know, of the defamation. That seemingly would put a very large burden on bloggers to carefully monitor and censor comments. Fortunately, the Communications Decency Act, Section 230 provides a strong protection against liability for Internet “intermediaries” who provide or republish speech by others.\n(c) Protection for “Good Samaritan” blocking and screening of offensive material\n(1) Treatment of publisher or speaker\nNo provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider.\n(2) Civil liability\nNo provider or user of an interactive computer service shall be held liable on account of—\n(A) any action voluntarily taken in good faith to restrict access to or availability of material that the provider or user considers to be obscene, lewd, lascivious, filthy, excessively violent, harassing, or otherwise objectionable, whether or not such material is constitutionally protected; or\n(B) any action taken to enable or make available to information content providers or others the technical means to restrict access to material described in paragraph (1)\nAre there any defenses to defamation?\nTruth is an absolute defense to a defamation claim. Defamation law does not prevent someone from publishing true information about you, no matter how damaging (although you might have a different cause of action).\nOpinions are not considered defamatory. But make sure you’re actually stating an opinion and not asserting a statement of fact. To determine whether a statement is an opinion, courts look at whether a reasonable reader or listener could understand the statement as asserting a statement of verifiable fact. (A verifiable fact is one capable of being proven true or false.) This is determined in light of the context of the statement. A few courts have said that statements made in the context of an Internet bulletin board or chat room are more likely to be opinions or hyperbole. For a blog, a court would likely start with the general tenor, setting, and format of the blog, as well as the context of the links through which the user accessed the particular entry. Next the court would look at the specific context and content of the blog entry, analyzing the extent of figurative or hyperbolic language used and the reasonable expectations of the blog’s audience.\nPublic vs. Private\nA private figure claiming defamation – your neighbor, your mom, the cute girl who works at the bar down the street – only has to prove you acted negligently, which is to say that a “reasonable person” would not have published the defamatory statement. On the other hand, a public figure must show “actual malice” – that you published with either knowledge of falsity or in reckless disregard for the truth. This is a much more difficult standard for a plaintiff to meet. A public figure is someone who has actively sought, in a given matter of public interest, to influence the resolution of the matter. So a statement that is defamatory when made about your neighbor might not be defamatory if made about the lead actress in a new box office hit.\nOnce you’ve concluded that someone has made a defamatory statement about you, what next? Consider consulting an attorney to discuss your options. But know that there are some very good reasons why actions for defamation may not be a good idea. First, a defamation lawsuit can create a greater audience for the false statements than they previously enjoyed. The media may cover the initial filing of a lawsuit and all the gory, illicity details of the complaint, but not follow through to the case’s ultimate resolution. The net effect could be that large numbers of people hear the false allegations but never learn how the litigation was resolved.\nSecond, damage awards in defamation lawsuits tend to be small. The fees expended in litigating even a successful defamation action can exceed the total recovery. There’s often a substantial price to pay to clear your name in the court of law.\nIf you’re interested in learning more about this topic, check the Electronic Frontier Foundation’s FAQ on Online Defamation Law.\nNext up in the series will be A Legal Primer for Bloggers – Anonymity. It will discuss what you should know about blogging anonymously and keeping your identity secret, including the duty of your internet service provider to protect your identifying information.\nA Legal Primer for Bloggers\nPart 1: Introduction\nPart 2: Intellectual Property\nPart 3: DEFAMATION\nPart 4: Anonymity\nPart 5: Privacy","On July 27, 2010, the U.S. House of Representatives passed by voice vote the Securing the Protection of our Enduring and Established Constitutional Heritage Act (“SPEECH Act”). Sponsored by the chairman of the Senate judiciary committee (Sen. Patrick Leahy) and the ranking member (Sen. Jeff Sessions) in an unusual show of bipartisan support, the SPEECH Act was passed unanimously by the Senate on July 19, 2010. When signed into law by President Obama, it will prohibit the enforcement of foreign libel judgments that are inconsistent with the protections accorded free speech by the First Amendment to the U.S. Constitution.\nThe SPEECH Act provides American authors, journalists, publishers, and media organizations with an important tool to fight back against “libel tourists”—plaintiffs who choose to file libel lawsuits in foreign jurisdictions over speech published primarily in the United States in order to get a more favorable result. These lawsuits typically involve celebrities or foreigners suing American publishers or authors over content that has little or no nexus to the foreign forum—with London having become a favored destination of visiting libel plaintiffs.\nAlthough a handful of states—New York, Illinois, Maryland, California, Florida, and Utah—have statutes that permit courts in those states to decline enforcement of a foreign defamation judgment if the plaintiff seeks enforcement in the United States, the SPEECH Act is the first nationwide federal legislation to tackle attempts to undermine the First Amendment rights of American authors and publishers.\nAs set forth in its key provisions, the SPEECH Act:\nApplies to all courts—state and federal—throughout the United States. Every “domestic court” is covered by the SPEECH Act. Under the Act, “domestic court” is defined to include both federal and state courts.\nMakes nonrecognition mandatory when the foreign libel law is not as protective as American law. The SPEECH Act prohibits any domestic court from recognizing or enforcing a foreign defamation judgment if the foreign jurisdiction’s libel laws do not provide as much protection to speech as does the First Amendment and/or the libel law of the state in which the domestic court sits. There is one exception to this provision: even if the foreign jurisdiction’s libel law is less protective, enforcement is allowed if the party seeking enforcement shows that there would have been defamation liability under the First Amendment and the law of the state where the domestic court sits.\nProhibits enforcement of a foreign defamation judgment if personal jurisdiction does not comport with U.S. principles of due process. The SPEECH Act also prohibits domestic courts from recognizing or enforcing a foreign defamation judgment if personal jurisdiction in the foreign forum did not comport with U.S. due process principles. For example, foreign courts have established personal jurisdiction over American publishers, journalists, and authors based on minimal downloads of content published on American websites. When faced with the same question, American courts have prohibited a plaintiff from establishing personal jurisdiction over a defendant based on content published on a website unless that content is targeted specifically towards the forum state. Under the SPEECH Act, the party seeking recognition of the foreign judgment will bear the burden of establishing that the foreign court’s exercise of personal jurisdiction was consistent with the due process requirements imposed on domestic courts by the Constitution of the United States.\nProhibits enforcement of foreign defamation judgments against providers of interactive computer services who would be immune under U.S. law. As an additional ground for nonenforcement, the SPEECH Act also prohibits a domestic court from recognizing or enforcing a foreign defamation judgment that was rendered against the provider of an interactive computer service, as defined by 47 U.S.C. § 230, unless the judgment would be consistent with Section 230. Under Section 230, providers of “interactive computer services” (a term that broadly encompasses ISPs, websites, chat rooms, and other online forums) receive statutory immunity from defamation suits arising from user-generated content. By contrast, many foreign jurisdictions do not provide any legal protection to computer services that merely host defamatory third-party speech. Now, when a foreign defamation judgment is issued against an interactive computer service provider for third-party content, under circumstances where Section 230 would have prohibited liability in the United States, enforcement of that foreign judgment by U.S. courts is barred by the SPEECH Act.\nCreates broad grounds for removing actions to enforce foreign defamation judgments from state court to federal court. The SPEECH Act relaxes the usual statutory requirements for removal from state to federal court. Without regard to the amount in controversy, any action seeking enforcement of a foreign defamation judgment may be removed by the defendant (or the defendants) from state court to the federal district court for the district where the action is pending so long as (1) any plaintiff is a citizen of a state different from any defendant; or (2) any plaintiff is a foreign state or citizen and any defendant is a U.S. citizen; or (3) any plaintiff is a U.S. citizen and any defendant is a foreign state or citizen. In other words, the SPEECH Act requires only minimal diversity between the parties for removal (in contrast to the usual statutory requirement of complete diversity). The Act also eliminates the usual statutory prohibition on removal when the action is brought in the defendant’s home jurisdiction.\nCreates a name-clearing remedy. The SPEECH Act also allows any “United States person” against whom a foreign defamation judgment is entered to bring an independent action in federal district court for a declaration that the foreign judgment is repugnant to the United States Constitution or the laws of the United States. Under the Act, service of process may be made on the defendant in the judicial district where the case is brought or in any other district where the defendant may be found, resides, has an agent, or transacts business. The effect of the statutory language is to authorize nationwide service of process in name-clearing actions and to allow personal jurisdiction to be asserted over the foreign judgment holder to the fullest extent permitted by due process principles.\nAllows for the award of attorneys’ fees. Where a party successfully opposes domestic recognition or enforcement of a foreign defamation judgment on one of the grounds set forth in the SPEECH Act, the Act requires that the court “shall, absent exceptional circumstances,” award reasonable attorneys’ fees to that party. The Act’s fee provision is a one way street—and does not permit a corresponding award of fees to a party who successfully enforces a foreign defamation judgment.\nThe SPEECH Act is a victory for American authors, journalists, and publishers who increasingly have seen their First Amendment rights being stifled by foreign libel judgments. It is also likely to have a ripple effect across the pond. “This law should present a clear message to the UK coalition Government. When Britain’s closest ally feels the need to create new laws to protect itself from the High Court in London, it’s clear that the status quo cannot continue,” said John Kampfner, chief executive of Index on Censorship.1\nMembers of Parliament agree with Kampfner’s assessment. “Our present libel laws are not fit for purpose and we have the chance to change this,” said Baroness Dianne Hayter in a recent speech to the House of Lords. “There has to be a better balance.”2 The House of Lords recently announced that it will bring forward a defamation bill aimed at reforming existing United Kingdom libel laws by the 2011-2012 parliamentary session.\n1 Dominic Ponsford, “USA Outlaws ‘Libel Tourism’ in the UK Courts,” Press Gazette, July 29, 2010 (http://www.pressgazette.co.uk/story.asp?sectioncode=1&storycode=45773&c=1)\n2 Rachel McAthy, “Government to Lead Libel Reform with New Defamation Bill,” Journalism.co.uk, July 9, 2010 (http://www.journalism.co.uk/2/articles/539552.php)"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:3bfe0f2a-659d-4273-a9ee-bac8115f074d>","<urn:uuid:24a9b447-0faf-4892-8126-51e892e00c93>"],"error":null}
{"question":"What are the key differences between mounting artwork on walls versus mounting a TV?","answer":"Mounting artwork and TVs have distinct requirements and methods. For artwork, there are several mounting techniques including wet-mounting with PVA glue, dry-mounting with heat-activated adhesive, and conservation mounting using acid-free materials and reversible methods. The choice depends on the artwork's value and preservation needs. For TVs, mounting requires finding wall studs, using appropriate VESA-compatible brackets, and ensuring the wall can support the TV's weight. While artwork mounting focuses on preserving the piece and maintaining its flatness, TV mounting primarily concerns security and structural support. TVs must always be mounted into wall studs and cannot rely on drywall anchors alone, whereas artwork has more flexible mounting options depending on its value and conservation needs.","context":["Below are advice and tips on picture framing artwork mouting. While we have endeavoured to be as accurate as possible no liability is assumed for any errors herein. It is the responsibility of users to ensure the correctness of all information. For help with orders, please visit our Store Help and FAQS page, or use our Contact page.\nMost photos, prints, posters and other paper art brought in by Customers to be framed tend to be inexpensive. commercial images of little commercial or personal value. This art does not need expensive conservation or museum-quality framing and can be industrially framed at more economical prices. Generally this art consists of thin, flexible, loose, square or rectangular sheets or pieces of paper. If these are simply inserted into a picture frame, this will not make the paper inside stay flat inside, even if taped on all or some of its sides. It will instead gradually expand and contract with time, temperature and humidity. Often paper will buckle, cockle or slightly 'bubble\" under the glass. The only way to make it and keep it permanently flat is for it to be adhered to a stiff, sturdy backing or \"mounting\" board. essentially, this is what mounting (in the context of picture framing) is. Picture framers have to mount most artwork before picture framing it, even small photos, of, say, 8\"x10\" size. If artwork isn't mounted it will move, cockle and buckle under the glass thus giving to the framed art that kind of cheap Sunday-market, flea-market, used, or second-hand frame look. Even thick papers and thin boards will move, if left unmounted. Mounting is therefore essential towards achieving a flat, straight, even and professional appearance.\nThe wet-mounting method consist of rolling PVA or woodworking glue, onto a clean, backing such as M.D.F. or plywood and working it to a thin, even film all over this surface. The paper art is then positioned on top of this wet, sticky, backing. This backing is then pressed inside a Vacuum Press for a few minutes, or until reasonably dry. This bonds the paper to its backing and produces a durable, smooth and flat finish. The art will not ripple or buckle under the glass. This quick and cheap mounting method is very economical but also permanent and irreversible. It suits inexpensive, replaceable and commercial items but it is not recommended for valuable, historical, irreplaceable artwork. The dry-mounting method instead uses heat to activate adhesive heat-tissue which, when heated, will bind the paper art to its backing, either M.D.F., foamboard, or similar sub-strata. Dry-mounting is more expensive than wet-mounting but cleaner, neater and faster. It too permanently and irreversibly bonds paper art and only really suits commercial, inexpensive and replaceable art. Like wet-mounting, dry-mounting will keep the poster flat and prevent it from buckling. However, if framing a work of fine art or an original, dry-mounting is not the recommended method. This is largely because if a work of art is permanently glued to its backing, whether by wet or dry-mounting, it will decrease significantly in value.\nThis method is largely reserved for fine art or artwork which, because of its personal, emotional, financial or historical value, needs conservation, protection or preservation form the ravages of time and materials. Unlike the previous methods described above, artwork in conservation must not in any way be permanently bonded to a backing or its substratum. Indeed, one of the key elements of conservation mounting and framing is reversibility. This mean that the artwork must be capable of being easily detached and removed, should the need arise. Conservation mounting thus involves lightly taping, or hinging, the top edge of the artwork onto a window mat. The mat is then laid on top of a clean acid-free backing board so that the art is sandwiched between the two boards for framing. Usually both boards and the tape are acid-free and of good quality, if not of conservations standard. This method is reversible, not permanent and is recommend for relatively inexpensive or unimportant artwork. conservation hinges for picture framing The conservation method: This is structurally similar to the above, hinging method. The main difference is that all materials used must be of far higher quality and of conservation standard. All boards and papers must to be of Museum quality, with the hinges from Japanese mulberry paper and hand-bonded with a rice starch paste. Gloves-on handling, a scrupulous cleanliness and the strict avoidance of polluting materials or contaminants are mandatory for this highly specialized matting and mounting method.","How do you mount a TV to the wall?\nHow to wall mount your TV Decide where you want to position the TV. Locate the wall studs using a stud finder. Mark and drill your pilot holes. Attach the mounting bracket to the wall. Attach the mounting plate to the TV. Mount your TV to the wall. Enjoy your newly mounted TV!.\nCan any TV be attached to wall mount?\nDo all TV wall mounts fit all TVs? Not all wall mounts can fit with all types of TVs. The TV brackets should fit the hole pattern on the back of the TV to work. Most of the TVs use a standard mounting pattern, called a VESA size.\nDo you have to put a hole in the wall to mount a TV?\nYou can’t mount a TV without putting holes in the wall. At the very least, you’ll have to use tiny nails that’ll leave a bunch of small holes. Some people suggest using adhesive tape, but that won’t hold the TV for very long.\nCan I mount a TV myself?\nMost flat TVs are designed for a wall mounted tv, but make absolutely sure yours is before you shop for a mount. Look for “VESA” (Video Electronics Standards Association) on the manual or the TV itself, followed by a number such as “VESA 75.” Any mount with the same VESA number will work with your TV.\nHow do you tell if your wall can support a TV?\nUse a stud finder to locate the studs in your wall to determine where you can hang the TV. Do not attempt to use drywall anchors to hang it. Eventually, the anchors will get pulled through the drywall and your TV will end up on the floor.\nHow do you know if your TV can be wall mounted?\nIf you don’t have your owner’s manual, look at the back of your LCD TV. If it has 4 or more threaded screw inserts where the mount can attach to the set, the television is capable of being mounted on a wall.\nCan I mount TV on drywall?\nWhile it may seem tricky to hang a TV on drywall, there are a few ways to make sure it stays secure without it falling down. Once you get a mount that works with your TV, check if there are studs behind your drywall. If there are, then you can screw the mount directly into the studs.\nHow do I mount a TV without holes?\nMounting your TV with strong adhesives on concrete or a brick wall is a great method without drilling. You can also use rails and as well as brick clip-on hangers.\nIs it better to wall mount a TV or put it on a stand?\nThe most obvious benefit of mounting your television versus having a stand is that it’s a huge space saver. This is especially beneficial to small space dwellers who never had room for a large entertainment center in the first place.\nAre TV wall mounts safe?\nAs we already know, mounting your flat screen TV set on the wall can drastically improve flexibility and viewing quality. But most people are hounded by the question – are TV wall mounts safe? The answer is definitely yes.\nHow much does it cost to have a TV wall mounted?\nInstalling a TV costs between $159 and $361 or an average of $260. Costs usually run anywhere from $100 to $600, though you could pay as low as $80 and as high as $1,150. Prices include labor, but may or may not include the mount, and vary depending on the size of the TV, type of mount and complexity of the job.\nHow much does it cost to install a wall mount TV?\nTypically, the price to have your TV mounted and installed by a professional falls within the $230-to-$500 range, according to HowMuch.net. The actual price varies depending on a few scenarios, such as materials, labor and how complicated the installation process is.\nHow much weight will a TV mount hold?\nA good rule of thumb is 80 pounds for a single stud, but a specific mount’s specifications should always be followed. Everything below 60 inches is 80 pounds.\nHow do you know if your TV is too heavy for a mount?\nGenerally speaking, TV size and weight go hand in hand. The larger the TV, the heavier it is. Mounts will have a maximum weight rating, as well as a range of VESA standards that are compatible. As long as your monitor falls within the designated guidelines, the mount should easily hold the weight of your TV.\nHow do I find the studs in my wall?\nHow to Find a Wall Stud Quickly and Easily Locate the nearest light switch or power outlet. Look for dimples in the wall. Use windows as a guide. Tap the wall. Drill a hole. Fish around with a wire hanger. Try a stud finder app. Or just use a stud finder!.\nAre TV wall mounts easy to install?\nIt’s a pretty simple process, but doing it right will be the difference between an attractively mounted TV and one that may not sit right, or even damages the TV. Once you’ve settled on the perfect spot on the wall, you’ll need to find the studs to mount the bracket properly.\nIs it safe to wall mount a 65 inch TV?\nIs it safe to mount your 65 inch, 75 inch or larger TV on the wall? The answer to this is yes, you can mount your XL TV on the wall. Safety is paramount, of course. That’s why it is always important to check whether the TV mount used is TÜV certified."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:0683a943-3bec-47ad-8ef4-32b44ff95deb>","<urn:uuid:b7713781-c43f-48f4-91cf-96b9026f55b5>"],"error":null}
{"question":"How do traditional and epoxy flooring compare in terms of their durability and installation delays, and what factors can affect their timelines?","answer":"Traditional flooring installation can face delays due to weather, illness, or other factors beyond control, requiring clear communication from contractors about timeline changes. With hardwood specifically, there's a mandatory waiting period of up to a week for the wood to acclimate to room conditions. For epoxy flooring, the installation process involves extensive preparation work and a crucial curing period that can take up to 30 days for full hardening. Regarding durability, epoxy floors are among the toughest commercial and industrial floors, competing only with pure concrete, and can last up to 30 years. However, daily traffic can eventually cause chipping or cracking, potentially requiring reapplication in heavily used areas after several years.","context":["Photo Credit: On Pexels, CC0 License.\nWhen you hire a contractor to install new flooring in your home there are a few things that you can expect. Some things will depend on what type of flooring you’re having installed as well as whether this is a new build or an older home being refurbished. Most contractors will perform the following when they feel it is needed.\nIf laying a floor over concrete it is important to perform a moisture test. This can take 24 hours. If your floor shows some buildup of moisture they’ll have to treat the floor in a different way before laying the floor to rid the floor of extra moisture.\nIf this is a remodel, or a refurbishing job, and your house was build or the floor was laid before 1980 then the contractor will need to perform an asbestos test. Asbestos is a material that is very dangerous and the dust up from normal floor installation can make people sick. If asbestos is found, professionals will have to come in and clean it up. This may change a lot about the work in terms of whether or not you can keep the old flooring and fix it, or whether you really need to completely replace it due to asbestos.\nWhen you hire a professional contractor you have a right to expect a certain amount of workmanship. No matter what type of floors that are being installed you want them to do a good job, clean up their messes, and seek to eliminate dust build up as much as possible. You want the finished work to look completely finished and wonderful.\nIf you are laying the floor yourself you may have overestimated your carpentry skills. Even the snap together laminate or wood flooring takes considerable skill. It’s made for do it yourselfers but you still need to know how to use a jigsaw and other equipment in order to do a good job. Expect to overestimate your ability and suffer some days of frustration due to that.\nSome people don’t realize this but if you are having hardwood floors laid, due to issues with different moisture levels the wood has to be stored for up to a week in the house, and in the very room that the flooring will be laid to let it get used to the new environment in terms of contracting and expanding. This might be an issue that you had not considered when you decided on hardwood flooring.\nIn most contract jobs it’s smart to expect a certain amount of delays due to issues behind your control. It might be due to weather, illness, or other factors. Ensure that your contractor always contacts you up front about any delays and gives you a reason. Make sure the contractor knows that without a phone call with explanation you expect contractors to arrive on the job site when stated.\nFinally, expect to be ecstatic about the look of your new flooring and the boost it can bring to your entire home.","If you’re considering installing an epoxy floor in your kitchen or bathroom, consider some of the pros and cons of this type of flooring. Here’s a look at stain resistance, durability, color options, and cost. It’s best to speak with a professional before making the final decision. Once you’ve made the decision, you can start planning the installation process. Listed below are the main benefits of installing this type of floor.\nFor a great stain-resistance flooring solution, you should have the floor thoroughly prepared before the epoxy coating application begins. This preparation process involves the use of media blasting, diamond grinding, jackhammers, chipping guns, and other materials. In order to ensure good adhesion, de-greasing may be required before the epoxy can be applied properly. Installation procedures vary according to the type of system you choose, but they commonly include screeding, troweling, broadcasting, and grinding. All of these procedures are discussed before the installation process begins.\nEpoxy floor installation is a cost-effective alternative to traditional materials like carpets. Because of the seamless nature of the epoxy surface, it requires less ventilation than other types of flooring. Traditional materials release particulates into the air. Moreover, a quality epoxy provides a stain-resistant surface that’s both smooth and glossy. These qualities make it an excellent choice for high-traffic industrial areas. In addition to enhancing aesthetics, stain-resistant epoxy floors are perfect for areas where people are prone to spills and liquids.\nMoreover, epoxy floors are highly durable and scratch-resistant. These floors can hold heavy items without losing their luster. Aside from that, epoxy flooring is also chemical and shock-resistant. It won’t absorb chemicals like antifreeze and acid, and it won’t spread electricity. Despite the many benefits of epoxy floors, it is important to note that regular maintenance and cleaning are still necessary to keep them looking new.\nCompared to other types of flooring, epoxy floors are easy to maintain. They can withstand heavy items being dropped on them. However, it’s important to keep epoxy floors free of dust and debris, and it’s best to keep them spotless for a few weeks. You can deep clean if the floor is heavily stained or soiled. This is particularly important in areas where heavy objects are dropped. This ensures that your floors will be clean for years to come.\nWhen you install an epoxy coating, you can easily connect your walls and floors. It will create a seamless transition between the two. You’ll also get a more hygienic environment in these areas. And if you have a cafeteria or a gym, you can install a seamless wall system around the facility. If you have a gym or a spa, you can choose epoxy coatings for the walls.\nAn epoxy floor installation is among the toughest commercial and industrial floors. Only pure concrete can compete with epoxy. Untreated concrete is porous and invites microbial infestation. An epoxy floor coating is also highly durable and long-lasting, lasting as much as 30 years. Over time, this means that an epoxy coating is a more cost-effective solution. And while epoxy may initially seem to be expensive, the long-term savings are worth it.\nThe durability of an epoxy floor installation depends on how much traffic and to use it receives. In general, a daily sweep is sufficient, but a deeper cleaning should be performed at least once a week. A floor deteriorates if it develops cracks or localized breakdown of the coating. Eventually, the floor will need a new coat of epoxy to prevent damage from occurring. For this reason, it is advisable to wear stable shoes when walking on a concrete floor.\nAfter epoxy flooring is installed, it takes several days for the surface to fully harden. The curing process should be undertaken in conditions that will not cause excessive moisture, as this will result in a stronger finish. The curing process will take up to 30 days. However, it is important to note that the drying time is critical as the epoxy will wear down and scratch easily if it is exposed to high humidity levels. If a floor is not dry enough for 24 hours, the floor can be damaged by moisture trapped beneath the floor finish.\nThe preparation work associated with epoxy floor installation is extensive. The concrete slab must be thoroughly cleaned, with oil, grease, and solvents removed from it. Properly applied epoxy will allow for the desired bond between the concrete slab and the sealant. It may take several attempts to clean the floor, but the process can be done relatively easily with hand tools. If any imperfections are present, the contractor can repair them. So, hiring a professional to install an epoxy floor is important; check out the Precision Epoxy Fort Myers listing.\nAlthough the longevity of an epoxy floor installation is generally uncompromising, daily traffic can cause it to chip or crack over time. A floor that receives daily traffic is likely to require reapplication in a few years if it is heavily used. If it does crack and requires reapplication, it may be time to look for another solution. Fortunately, Colorado has some of the best quality epoxy coatings available. We specialize in basement, garage, and commercial floor coatings.\nIf you want to create the ideal environment, choosing the right epoxy floor color is critical. Choose a color that blends in with the environment. If you are a woodworker, select a color that resembles sawdust to hide any dust that may accumulate on the floor. This way, your garage will appear cleaner and less cluttered. Light-colored soil should be white, or a light color that matches it.\nMetallic-colored concrete sealers reflect light, giving off blinding rays. Light colors make the space more prominent and reduce the need for additional lighting. Depending on the type of color, you can select a variety of different colors for your epoxy floor. However, you should know that darker colors can show dirt and require more frequent cleaning. However, light colors are easier to maintain. Metallic pearl effect epoxy is an excellent choice for creating dynamic colors.\nIn addition to industrial applications, epoxy paint is a great choice for garages and basement floors. Basements can get quite humid, so epoxy paint is a sensible choice instead of carpet. In addition to a beautiful floor, a washable area rug will also provide warmth, softness, and sound dampening. If you’re considering remodeling your basement, choosing a color-rich epoxy floor is an excellent way to begin. You can even choose to make the space radon-proof!\nDecorative color flakes are another option for enhancing your space. These are available in an endless number of sizes and textures, and you can customize the design and color scheme to enhance the environment. Flake color flakes are usually installed in conjunction with resinous flooring systems, so you can achieve the optimal appearance. Furthermore, they will blend in with the surrounding decor. With so many colors available, you’ll have no trouble finding the right match for your space.\nPolycuramine is another option. This is a material that is twenty times stronger than epoxy and dries much faster. It can be driven on within 24 hours. Another option is to paint over the old epoxy. A polyamine coating can be used as a top coat over a different color. If you don’t have time to hire an epoxy coating company, you can also opt for a DIY version.\nThe cost of epoxy floor installation can vary widely, depending on the area of the floor you want to be covered. For a 400-square-foot basement, for example, you may spend anywhere from $3,200 to $3,400. A discount of up to 10% will be given for projects of 600, 900, and 1,200 square feet. For large projects of over 2,500 square feet, you will receive a 25% discount. You can use the following tips to minimize the cost of epoxy flooring installation.\nBefore determining the cost, it’s essential to consider the four main variables. By doing this, you will be better prepared to answer the contractor’s questions and understand the range of prices for different Epoxy Flooring options. By preparing yourself, you’ll know exactly what you should expect from your new floor. It’s also important to understand the process of installation and the different materials used. When choosing a flooring system, you should consider the type of floor you’ll have in mind – basic, medium, and superior – and your budget.\nThe types of epoxy floor installation available vary in cost and quality. If you’re looking for a low-cost option, consider choosing a metallic epoxy floor system. It’s a more affordable option and can deliver outstanding performance for many years. It’s also important to check the Better Business Bureau for any complaints. DIY projects can also be a good idea, and you can often purchase do-it-yourself epoxy floor kits at paint stores.\nAmong the least expensive flooring options, an epoxy floor can cost as little as $2.50 per square foot, and the price can go as high as $8 per square foot for a smaller job. However, it’s worth considering that epoxy flooring is among the best all-around value for the money when it comes to resinous flooring. However, it is important to note that epoxy is durable and resistant to stains, but it’s not impervious to objects falling on it. If anything does happen to your epoxy floor, you can simply lay another layer of epoxy to fix the damage.\nThe cost of epoxy floor installation is directly proportional to the level of preparation work required by the concrete floor. The surface must be completely smooth and clean before the application of epoxy. In Portland, the prep work will take a day. If the concrete is in poor condition, the job will require more time and materials to ensure the best possible result. The installation process can last between eight and ten years, but proper care is essential to avoid costly repair costs."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:c8340016-b6c2-470d-9c66-cfdf5e3f0795>","<urn:uuid:57680291-20c4-43ab-ae13-9d0104fd7c53>"],"error":null}
{"question":"What's the difference in symptoms between West Nile Virus and Dengue fever? 发烧有什么不同？","answer":"Dengue fever causes acute febrile illness with headache, retro-orbital pain, myalgia, arthralgia, rash, hemorrhagic manifestations, and leukopenia. West Nile Virus symptoms include fever, headache, body aches, joint pain, vomiting, diarrhea, and rash in about 20% of infected people, while 70-80% of infected people don't develop any symptoms at all. Both diseases can progress to more severe forms, with Dengue potentially leading to shock syndrome, and WNV potentially causing serious neurologic illness.","context":["Dengue is a significant community ailment in subtropical and tropical locations worldwide. The DENV nonstructural proteins NS4B and subgenomic sfRNA hinder the RNAi pathway by inhibiting the RNAse Dicer. During heterotypic supplementary DENV infections subneutralizing antibodies can enable viral uptake through Fcγ receptors and down-regulate signaling cascades initiated via the design identification receptors TLR3 and MDA5/RIG-I hence reducing the antiviral condition DBU from the cell. The DENV NS2B/3 proteins cleaves individual STING/MITA interfering with induction of IFN-α/β. Finally DENV NS2A NS4A and NS4B complicated together to stop STAT1 phosphorylation while NS5 binds and promotes degradation of individual STAT2 thus stopping formation from the STAT1/STAT2 heterodimer and its own transcriptional induction of ISGs. Right here we discuss the web host innate immune system response DBU to DENV as well as the systems of immune DBU system evasion DENV is rolling out to manipulate mobile antiviral responses. Launch Four dengue trojan serotypes (DENV-1 -2 -3 -4 trigger dengue fever (DF) aswell as more serious disease manifestations typically known as dengue hemorrhagic fever (DHF) and dengue surprise symptoms (DSS)1. DF can be an severe febrile disease with headaches retro-orbital discomfort myalgia arthralgia allergy hemorrhagic manifestations and/or leukopenia. The hallmark top features of DHF contain thrombocytopenia hemorrhagic manifestations and signals of plasma leakage that may result in hypotensive surprise (DSS) and without suitable treatment death. The condition was lately reclassified into dengue with and unexpectedly signs and serious dengue2. Bhatt and mosquitoes which continue steadily to broaden geographically facilitated by elevated global trade and travel unplanned urbanization poor waste materials and water administration aswell as individual behavior and ecology5. No industrial vaccine or particular antiviral treatment is available for dengue though DBU they are areas of significant research and advancement efforts. Dengue is DBU certainly a individual disease without known pet reservoirs as well as the trojan has evolved DBU effectively to evade individual immune system responses specifically innate antiviral immunity. This review targets mechanisms from the innate intracellular antiviral DENV and response evasion within infected cells. The dengue trojan life routine DENV is certainly a positive-strand RNA enveloped flavivirus whose 10.7 kb genome includes a 5′ type I m7G cap structure and encodes a polyprotein that’s post-translationally cleaved by web host and viral proteases into three structural proteins (C capsid; pr/M membrane; E envelope) and seven nonstructural protein (NS1 NS2A Rabbit Polyclonal to BRS3. NS2B NS3 NS4A NS4B NS5). In human beings DENV mainly infects immune system cells from the myeloid lineage including monocytes macrophages and dendritic cells aswell as hepatocytes as proven in individual autopsy tissue by immunohistochemistry6 7 8 9 10 in peripheral bloodstream mononuclear cells (PBMC) through the severe phase of infections by stream cytometry11 and in epidermis explants12. Though many reports can be found of DENV infections of endothelial cells and in mosquito cells was discovered to work with DC-SIGN whereas trojan propagated in individual dendritic cells used L-SIGN to infect focus on cells36 40 Furthermore to DC-SIGN and L-SIGN the mannose receptor portrayed on individual macrophages was discovered to bind the carbohydrate moieties in the DENV envelope proteins41. DENV provides been proven to bind to a genuine variety of cell surface area substances. DENV can complex with high temperature surprise proteins (HSP) 90 and HSP70 on the top of mammalian cells42 43 and p74 on the top of mosquito cells44 amongst others. Pursuing heat surprise treatment web host cells were discovered to have elevated HSP appearance viral uptake and trojan result43 44 In cells missing selectin-type receptors latest studies show that DENV utilizes the transmembrane receptors TIM and TAM two receptors involved with phosphatidylserine-dependent removal of cells going through apoptosis45. TIM binds DENV directly whereas TAM interacts with DENV via two bridge protein Gas6 and Advantages45 indirectly. Finally during supplementary DENV infection using a heterotypic serotype the adaptive immune system response can action to improve viral infections via.","West Nile Virus\nMosquito Control and why it's Important to YOU\nWhat is West Nile Virus (WNV)?\nWNV is a mosquito-borne virus that can cause fever, encephalitis (inflammation of the brain), or meningitis (inflammation of the lining of the brain and spinal cord).\nHow do people get WNV?\nWNV is most commonly spread through the bite of an infected mosquito. WNV can be spread through blood transfusions, organ transplants, and from mother to baby during pregnancy, delivery, or breastfeeding but this is very rare. It is not transmitted from person to person, or from person to animal.\nWhat are the symptoms of WNV?\nMost people (70-80%) infected with WNV do not develop any symptoms.\nIf present, WNV symptoms usually appear 2-14 days after the mosquito bite. Approximately 1 in 5 people infected will develop a fever and possibly headache, body aches, joint pain, vomiting, diarrhea, or rash. Most people with these symptoms recover completely, but fatigue and weakness can last for weeks or months.\nLess than 1% of people infected will develop serious neurologic illness such as encephalitis or meningitis (inflammation of the brain or surrounding tissues). Recovery from severe illness may take weeks or months. Some of the neurologic effects may be permanent. Only about 10% of people who develop neurologic infection due to WNV will die.\nSerious illness can occur in people of any age. However, people over 60 years of age are at the greatest risk for serious illness. People with certain medical conditions, such as cancer, diabetes, hypertension, kidney disease, and people who have received organ transplants are also at greater risk for serious illness.\nSee your health care provider if you have symptoms of WNV.\nWho is at risk for WNV infection?\nAnyone living in an area where mosquitoes are infected with WNV is at risk. WNV has been detected in all states except Alaska and Hawaii. The risk of infection is highest for people who work outside or participate in outdoor activities because of greater exposure to mosquitoes.\nIs there a vaccine or treatment for WNV infection?\nThere is no vaccine or specific treatment for WNV infection.\nPeople with mild symptoms of WNV infection usually recover on their own. Over-the-counter pain relievers can be used to reduce fever and relieve some symptoms. People with severe illness usually need to be hospitalized to receive supportive treatment, such as intravenous fluids, pain medication, and nursing care.\nHow can I prevent WNV?Make you and your home a Bite-Free Zone to prevent WNV and other mosquito-borne diseases.\nWhat is the Chester County Health Department doing to prevent WNV?\n- Provides educational materials. Call 610-344-6490 to request materials.\n- Provides community education. Request a presentation or participation at a community event\n- Responds to complaints of standing water- Chester County Health Department enforces County regulations requiring property owners to dump and drain sources of standing water (ex. tires, pools, containers) which mosquitoes use for breeding. Citations may be issued for failure to comply.\n- Identifies bodies of water containing mosquito larvae.\n- Sets mosquito traps to collect and test adult mosquitoes for WNV – Traps are placed in highly populated areas, known mosquito breeding areas, and in areas where a resident has previously been identified as having a confirmed case of WNV infection. Traps are also placed in response to complaints from residents regarding high levels of mosquito activity.\n- Uses U.S. Environmental Protection Agency-approved products (Bti, Bs, or Methoprene) to kill mosquito larvae in bodies of standing water that cannot be drained.\n- Uses U.S. Environmental Protection Agency-approved products (Permanone or DeltaGard) to kill adult mosquitoes in areas that have high mosquito activity and multiple mosquito samples testing positive for WNV- Spraying is done as a last resort after exhausting all other mosquito control strategies.\n- The Chester County Health Department uses a truck-mounted sprayer to apply 1.5 ounces of the mosquito control product per acre of land. Sprays are conducted after sunset, when mosquitoes are most active and bees have returned to their hives. Sprayers are turned off near bodies of water and apiaries to protect aquatic life and bees. The Chester County Health Department also notifies beekeepers and residents who are listed as hypersensitive in a designated spray area prior to conducting a spray. People who are concerned about exposure to mosquito control products can reduce their potential for exposure by staying indoors with children and pets when their neighborhood is being sprayed. Because the mosquito control spray becomes inactive in just a few hours or with sunshine, it is not necessary to wash off outdoor furniture or playground equipment before use.\n- The Chester County Health Department is a member of the Environmental Protection Agency’s Pesticide Environmental Stewardship Program. This program requires participants to affirm that environmental stewardship is an integral part of their integrated pest management (IPM) practice, use current, comprehensive information regarding the life cycle of mosquitoes within their IPM program, educate the community on the benefits of IPM, and demonstrate a commitment to pesticide risk reduction activities.\n- Investigates reports of WNV illness in residents.\nHow can I find out when a mosquito control spray is being conducted in my neighborhood?\nThe Chester County Health Department notifies residents of sprays at least 48 hours ahead of time through the following channels:\n- News releases sent to the media, legislators, municipalities, etc.\n- Public Health Updates- E-mail updates that residents can sign up for.\n- Chester County Health Department website.\n- Chester County Health Department Facebook and Twitter.\n- Residents in a designated spray area who are listed as hypersensitive are contacted directly by the Chester County Health Department.\nPeople who are concerned about exposure to mosquito control products can reduce their potential for exposure by staying indoors when their neighborhood is being sprayed.\nFor more information, call 610-344-6752 or email firstname.lastname@example.org.\n- Prevent Mosquito-Borne Diseases\n- West Nile Virus Brochure- English, en Español\n- Zika Virus\n- Centers for Disease Control and Prevention- Avoid Mosquito Bites\n- Centers for Disease Control and Prevention- West Nile Virus\n- Penn State Extension- Pennsylvania Pesticide Hypersensitivity Registry\n- Penn State Extension- West Nile Virus\n- Pennsylvania's West Nile Virus Control Program"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:f4c3078e-3ccf-432b-8a77-71703c17a015>","<urn:uuid:6a411dea-76df-44fc-ae19-1e2dd7a03721>"],"error":null}
{"question":"How did real wages and labor productivity evolve in Britain and Germany historically, and what workplace safety regulations exist today to protect workers from hazardous substances?","answer":"Historical wage and productivity data shows comparisons between Britain and Germany from 1871-1938, with research examining modern economic growth patterns and labor market developments in both countries. Regarding workplace safety, current COSHH regulations require employers to implement control measures protecting workers from hazardous substances, maintain proper equipment, and conduct risk assessments. Employees must use provided control measures, wear appropriate PPE, and maintain good hygiene practices. Around 35,000 workers reported breathing problems in 2012/13, and approximately 13,000 deaths occur yearly from occupational lung disease and cancer, highlighting the importance of these protections.","context":["Real Wages and Labor Productivity in Britain and Germany, 1871–1938: A Unified Approach to the International Comparison of Living Standards\nDownload full text from publisher\nCitationsCitations are extracted by the CitEc Project, subscribe to its RSS feed for this item.\n- Christian Traxler & Carsten Burhop, 2010. \"Poverty and crime in 19th century Germany: A reassessment,\" Discussion Paper Series of the Max Planck Institute for Research on Collective Goods 2010_35, Max Planck Institute for Research on Collective Goods.\n- Uebele, Martin & Pfister, Ulrich & Riedel, Jana, 2012.\n\"Real wages and the origins of modern economic growth in Germany, 16th to 19th centuries,\"\nAnnual Conference 2012 (Goettingen): New Approaches and Challenges for the Labor Market of the 21st Century\n62076, Verein für Socialpolitik / German Economic Association.\n- Ulrich Pfister & Jana Riedel & Martin Uebele, 2012. \"Real Wages and the Origins of Modern Economic Growth in Germany, 16th to 19th Centuries,\" Working Papers 0017, European Historical Economics Society (EHES).\n- Kent Deng & Lucy Zheng, 2015. \"Economic restructuring and demographic growth: demystifying growth and development in Northern Song China, 960–1127,\" Economic History Review, Economic History Society, vol. 68(4), pages 1107-1131, November.\n- Juan Carmona & Markus Lampe & Joan Rosés, 2017.\n\"Housing affordability during the urban transition in Spain,\"\nEconomic History Review,\nEconomic History Society, vol. 70(2), pages 632-658, May.\n- Pidal, Juan Carmona & Lampe, Markus & Rosés, Joan R., 2014. \"Housing affordability during the urban transition in Spain,\" Economic History Working Papers 60556, London School of Economics and Political Science, Department of Economic History.\n- Carmona, Juan & Lampe, Markus & Rosés, Joan R., 2014. \"Housing affordability during the urban transition in Spain,\" IFCS - Working Papers in Economic History.WH wp14-05, Universidad Carlos III de Madrid. Instituto Figuerola.\n- Joost Veenstra & Herman Jong, 2016. \"A Tale of Two Tails: Establishment Size and Labour Productivity in United States and German Manufacturing at the Start of the Twentieth Century,\" Australian Economic History Review, Economic History Society of Australia and New Zealand, vol. 56(2), pages 198-220, July.\n- repec:kap:jecgro:v:22:y:2017:i:2:d:10.1007_s10887-017-9141-3 is not listed on IDEAS\n- Broadberry, Stephen & Fukao, Kyoji & Zammit, Nick, 2015.\n\"How Did Japan Catch-up On The West? A Sectoral Analysis Of Anglo-Japanese Productivity Differences, 1885-2000,\"\nCAGE Online Working Paper Series\n231, Competitive Advantage in the Global Economy (CAGE).\n- Broadberry, Stephen N & Fukao, Kyoji & Zammit, Nick, 2015. \"How Did Japan Catch-Up On The West? A Sectoral Analysis Of Anglo-Japanese Productivity Differences, 1885-2000,\" CEPR Discussion Papers 10570, C.E.P.R. Discussion Papers.\n- Broadberry, Stephen & Klein, Alexander, 2011. \"When and why did eastern European economies begin to fail? Lessons from a Czechoslovak/UK productivity comparison, 1921-1991,\" Explorations in Economic History, Elsevier, vol. 48(1), pages 37-52, January.\nMore about this item\nStatisticsAccess and download statistics\nAll material on this site has been provided by the respective publishers and authors. You can help correct errors and omissions. When requesting a correction, please mention this item's handle: RePEc:cup:jechis:v:70:y:2010:i:02:p:400-427_00. See general information about how to correct material in RePEc.\nFor technical questions regarding this item, or to correct its authors, title, abstract, bibliographic or download information, contact: (Keith Waters). General contact details of provider: http://journals.cambridge.org/jid_JEH .\nIf you have authored this item and are not yet registered with RePEc, we encourage you to do it here. This allows to link your profile to this item. It also allows you to accept potential citations to this item that we are uncertain about.\nWe have no references for this item. You can help adding them by using this form .\nIf you know of missing items citing this one, you can help us creating those links by adding the relevant references in the same way as above, for each refering item. If you are a registered author of this item, you may also want to check the \"citations\" tab in your RePEc Author Service profile, as there may be some citations waiting for confirmation.\nPlease note that corrections may take a couple of weeks to filter through the various RePEc services.","COSHH – A Guide to Employers’ and Employees’ Responsibilities\nEmployee Responsibilities under COSHH\nEmployee responsibilities within the COSHH (Control of Substances Hazardous to Health) Regulations of 2002 include:\n- Making use of control measures and facilities provided by the employer\n- Ensuring equipment is returned and stored properly\n- Reporting defects/insufficiencies in control measures\n- Wearing and storing personal protective equipment (PPE)\n- Removing PPE that could cause contamination before eating or drinking\n- Making proper use of washing, showering and bathing facilities when required\n- Maintaining a high level of personal hygiene\n- Complying with any information, instruction or training that is provided\nEmployer Responsibilities Under COSHH\nUnder COSHH regulations, employers’ responsibilities include:\n- Implementing control measures to protect workers from hazardous substances.\n- Preventing or adequately controlling exposure to hazardous substances.\n- Providing employees with suitable and sufficient information, instruction and training, and appropriate protective equipment where necessary.\n- Ensuring that control measures are maintained, kept in full working order, and in a clean condition where appropriate.\n- Drawing up plans and procedures to deal with accidents and emergencies involving hazardous substances.\n- Ensuring that any employees exposed to hazardous substances whilst at work are under suitable health surveillance.\n- Ensuring that substances do not exceed the Workplace Exposure Limit (WEL).\n- Carrying out a COSHH risk assessment.\nNaturally, workplaces with higher risks, such as catering or a hair salon, will require more action than, say, an office. But as an employer, you should be assessing what risks may be posed by hazardous substances, no matter where you work.\nThat way, you can identify if there are risks and if so take action to reduce them to a minimum.\nCOSHH Risk Assessment\nA COSHH risk assessment is essentially the same as a standard risk assessment in terms of the process, but your assessment of the workplace will focus solely on hazardous substances.\nIf you’re unfamiliar with risk assessments, here’s a breakdown of the main 5 steps:\n- Identify the hazards.\n- Decide who might be harmed and how.\n- Evaluate the risks and decide on precautions.\n- Record your findings and implement them.\n- Review your assessment and update if necessary.\nRisk assessments will also involve frequently monitoring the workplace’s processes and the level of exposure to substances.\nWorkplaces are active and constantly changing, so a one-off check won’t be sufficient in minimising the risks posed by hazardous substances. You have to remain constantly vigilant and alert to the dangers.\nRecap: What is COSHH?\nCOSHH stands for the Control of Substances Hazardous to Health Regulations (2002). It exists to ensure that both employers and employees do all they can in a workplace to minimise people’s exposure to hazardous substances and work in ways that are safe.\nThis means that all hazardous substances need to be identified and precautions need to be taken to ensure that workers know how to use and handle them safely.\nThe importance of controlling hazardous substances cannot be overstated. In 2012/13, around 35,000 workers reported that they had breathing or lung problems caused by work, and the most common type of reported skin disease was contact dermatitis.\nAnd it’s estimated that around 13,000 deaths occur each year due to occupational lung disease and cancer – fatal conditions that will have developed over a prolonged period of exposure to dusts and chemicals at work.\nAs an employee or employer, you can prevent statistics like this from increasing. If you fulfil your workplace duties, you can prevent dangerous levels of exposure and meet COSHH requirements.\nRecap: What is a Hazardous Substance?\nSimply put, a hazardous substance is any mixture or substance that is toxic, irritant, or corrosive – whether it’s a liquid, gas, vapour, fume, or dust.\nThey cause harm to the body via routes of entry:\n- By coming into contact with skin or eyes.\n- By being inhaled.\n- By being ingested through the mouth.\n- By entering the body through cuts or punctures in the skin.\nAlthough there are certain industries that will be at greater risk, hazardous substances could exist in any workplace. They are often used directly in work activities, produced by work activities, or already present in your workplace’s premises.\nExamples of hazardous substances include:\n- Chemicals, e.g. cleaning chemicals or bleach.\n- Fumes, e.g. from paint or vehicles that exhaust.\n- Gases, e.g. ammonia from refrigerators.\n- Dusts and powder, e.g. from flour.\nIt’s worth noting that even seemingly innocent substances can be harmful, and that includes natural materials like wood dust or flour.\nWhile many hazardous substances can cause immediate harm, such as a corrosive liquid being spilled onto someone’s skin, the main danger posed by hazardous substances is prolonged exposure. For example, if someone is in the presence of or uses a dangerous chemical for a long time, they could develop breathing difficulties or skin conditions.\nExamples of ill-health caused by hazardous substances includes:\n- Occupational asthma.\n- Occupational dermatitis.\n- Occupational cancers.\n- Skin irritation.\n- Infection from bacteria.\n- Injury or death as a result of exposure to toxic fumes.\nWhat to Read Next:\nSubscribe for the latest Hub updates! Tell us what you're interested in hearing about:"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:cfb32e64-b48d-482e-8d04-77af0740c772>","<urn:uuid:e2c99559-4fd5-48cf-884f-dca2baae7e40>"],"error":null}
{"question":"With my old toilet using 3 gallons per flush and my water heater set to 120°F, which upgrade would save more resources: installing a dual-flush toilet or lowering the water heater temperature to 115°F?","answer":"Installing a dual-flush toilet would save significantly more resources. While lowering the water heater from 120°F to 115°F provides some energy savings, upgrading from a 3-gallon toilet to a dual-flush toilet with 1.1 gallons for small flush and 1.6 gallons for large flush results in substantial water savings. Data shows that water-saving measures with toilets alone can save over 1,300 gallons per month through various conservation methods. The temperature reduction of the water heater, while beneficial, would have a much smaller impact on resource consumption.","context":["Frequently Asked Questions:\nThe temperature of my hot water seems to be higher than what I think it needs to be, what temperature should it be set on?\nThe standard temperature manufacturers’ use when pre-setting hot water heaters at the factory is typically 120°F. This is a sufficient temperature for most households; however you can adjust the temperature to meet your needs. Both thermostats should be set to the same temperature. Keep in mind that hot water also helps in minimizing the growth of bacteria. Consult Eastern Plumbing for the recommended temperatures for your particular needs.\nNOTE: You should turn off the electricity to the water heater before performing any maintenance. There may be exposed wires behind the panels which could result in shock.\nWhat could the rumbling sound I hear coming from the water heater be?\nRumbling sounds can be an indication that sediment has built up on the bottom of the water heater. Water may become trapped in the sediment and begin to boil. If this is happening, the water heater is not operating efficiently and the sediment isn’t allowing the heat to transfer to the water in the tank. You can try draining a few gallons of water off the bottom of the tank. Water heaters should be drained on an annual basis to remove sediment. Contact Eastern Plumbing if you require maintenance or have questions about your hot water heater.\nWARNING: Hot water is dangerous. Discharge the water into a floor drain, laundry tub or bathtub. Hot water will kill your grass if allowed to run on your lawn. Turn off power to water heater prior to draining.\nWhat happens when roots get inside drain lines?\nRoots from shrubs and trees can completely fill a pipe with multiple hair-like root masses at each point of entry. These root masses quickly become clogged with toilet tissue, grease and other debris flowing from your home to the main sewer, resulting in reduced flow, slow running drains and in most cases a complete blockage. Once roots have entered the pipe, they continue to grow and expand, exerting considerable pressure at the crack or joint. This increased pressure often breaks the pipe and may result in total collapse, which requires repair or replacement. Some pipe materials are more susceptible to root intrusion than others. Clay tile pipe is easily penetrated and damaged by tree roots. PVC pipe has fewer joints and when properly installed is almost 100% effective against root penetrations. Allow Eastern Plumbing to use state-of-the-art inline drain cameras to view and record your drain problems.\nWhat is the white substance around my shower head and faucet?\nThe unsightly buildup is mineral deposits. To remove these deposits from the shower head, take a plastic bag and pour a cup of vinegar in it. Place the bag over the shower head and use a twist tie to hold it in place overnight. In the morning, remove the bag and use an old toothbrush to gently scrub off the deposits. You might be able to remove the aerators from the faucets and allow them to soak in the vinegar overnight. A professional at Eastern Plumbing can explain water softening and conditioning options available to you.\nHow can I eliminate the odor coming from my garbage disposal?\nThis is a common plumbing troubleshooting question. Foul odors occur from a buildup of food debris within the disposal. To eliminate odors, place ice cubes and lemon peels or orange peels in the disposal, and run for 30 seconds. Next, squirt a little liquid dish detergent into the disposal while it is still running. Finally, run cold water for about 30 seconds to rinse all the debris away.\nWhat is the recommendation for replacing a toilet in my home?\nWhen considering any new fixture for your home, we recommend that you choose a fixture made by one of the major manufacturers. Poor mounting and deteriorating rings and seals may cause leaks which can cause costly damage to your home. Keep in mind that many of the new toilets conform to new government standards that require they use no more than 1.6 gallons per flush which can save you money on your water and sewer bills. If you need help with replacing a toilet in your home, contact Eastern Plumbing.\nWhat could be the cause of my recent high water bills?\nYou may want to check to see if a toilet is leaking. Check the water level in the tank to see if water is overflowing into the overflow pipe. This is the pipe in the middle of the tank which has a small tube connected to it. In the event water is running into the overflow pipe, adjust the fill valve to stop the flow approximately one inch below the top of the overflow tube or to the water level mark stamped on the side of the tank. Periodic maintenance by an Eastern Plumbing professional will ensure proper operation.\nI have a problem with the plumbing in my house making groaning and honking noises.\nHammering pipes can be cause by various things within your piping system. Loose fittings, toilet fill valves and the absence of an expansion tank on your water heater a just a few things which can cause pipes to hammer. If are hearing noises from your water pipes, contact Eastern Plumbing to get a professional diagnosis.\nI think my kitchen drains are partially clogged because the sink drains slowly. What do you recommend?\nFirst, you can try using a plunger. Second, you can remove the trap and remove any debris. Third, if the clog is beyond the trap, there are drain augers that extend from about 15 feet to about 50 feet. There are also special enzyme-based drain openers, which may help dissolve buildup in pipes in older homes. You can also call the professionals at Eastern Plumbing and we’d be happy to help.\nMy Toilet ‘Burps’! What’s Going On?\nThe common issue of drains that gurgle or burp is caused by inability of air to get into or out of the drainage system. All plumbing fixtures require a p-trap, to keep sewer gas from entering the home. The drainage system requires vents to allow air to move freely through the drainage system. If the vent line becomes obstructed, the air will compress within the system and then push through the p-trap which causes the gurgling or burping sounds. If you are having this problem, please call Eastern Pluming to determine proper solutions.","This page is intended to share methods we are experimenting with in order reduce our resource consumption and impact to the environment. We hope it stimulates a conversation amongst our followers in order to share ideas, provide constructive criticisms, and help people find practical methods of sustainability that work for their lifestyles. We will update this page with data we collect as soon as we have it available.\nWater Saving Techniques: Here’s a great water footprint calculator from National Geographic you can use to see how much water you use everyday.\nAccording to the EPA, “The average family of four can use 400 gallons of water every day, and, on average, approximately 70 percent of that water is used indoors.” That’s 146,000 gallons of water a year. According to Solomon in Water, The Epic Struggle for Wealth, Power, and Civilization, 2.5% of all Earth’s water is fresh; 2/3 of that freshwater is locked away in ice caps and glaciers; less than 3/10 of 1% of total freshwater is available in liquid form at the surface of the planet while the remainder is in permafrost, soil moisture, plants and animals, and water vapor while the most accessed source of water for humans is rivers and streams – these hold about 6/1000s of 1% of the total.\nIn The Bathroom\nOn Earth Day 2012, the city of Flagstaff was passing out low flow shower heads/faucets and shower timers. The great thing about these is they are adjustable from .5 to 1.5 gallons per minute (gpm). With the two minute shower timer, we are able to limit our water use from our showers and at that rate, each person uses 3 gallons of water per shower versus a standard shower head ( ~3.8 gpm) or 7.4 gallons per 2 minute shower per person, a savings for us of 4.4 gallons. That equates to 1606 gallons of water saved per year taking a 2 minute shower everyday. Imagine if the entire US population did this; that’s quite a savings!\nTo explore this even further, while lathering, shaving, or shampooing, we are able to turn the shower down to .5 gpm, which means we actually only run the shower at 1.5 gpm for half the time. That means we actually only use ~2 gallons per shower saving a total of 5.4 gallons/2 minute shower = 1971 gal/yr/person. Some people will even turn the water off while lathering, shampooing, and shaving which saves even more water! However, this is practical sustainability; some people like to keep the water flowing while showering, others don’t mind turning it off. What are your limits? Turning it off is best for conservation, but where is the balance for you? Can you reduce your time, the amount, or both?\nAgain, going further, we have buckets in each shower (below left). We collect the water while it is warming and as much as possible while showering. When the bucket is full, we use it to fill up the toilet tank instead of using fresh, clean water from the pipes. This helps to save more water just from flushing.\nWe also put 1 liter bottles in the toilet tanks (above right) to displace water with each flush and we also institute the “mellow yellow” philosophy, but capped it to 3 uses before the next flush. Based on the data we collected for one month of toilet use we saved the following:\n- Displacement with bottles: 109 gallons\n- Flushing with recycled shower water: 96 gallons\n- Not flushing every time: 1143 gallons\n- Total water savings in one month: 1348 gallons\nJust this week, we replaced the old toilets (3 gallons per flush) with dual flush, high efficiency toilets. The small flush is 1.1 gallons and the large flush is 1.6 gallons. Another savings in water and we will post more data as we collect it. Each toilet cost $100 and there will be $100 water credit to your water bill from Arizona in July of 2013 for installing high efficiency toilets, so save your receipts if you purchase one. Unfortunately, because we are on a well, we won’t be able to take advantage of that credit, but we believe having high efficiency toilets is the right thing to do so it is worth the $300 investment to reduce our impact on the environment.\nIn The Kitchen\nHere too, we installed a low flow, adjustable faucet. It makes it nice to turn it on all the way up when filling up reusable water bottles or pots for cooking, but we can turn it down during dishwashing to reduce our use. We also have three buckets to collect and reuse the water from the kitchen.\nYou’ll notice in the picture above, there is a compost bin on the window sill to reuse any food scraps or collect uneaten food. The major rinse bucket is the white bucket on the right, followed by the black wash bin in the middle, and finally the rinse bin on the left. We dump or rinse off the majority of any scraps into the white bucket, which preserves the quality of the water in the wash bin and prevents us from having to dump it before we are done washing all the dishes. We do have a dishwasher but do not use it in order to save water and electricity. We feel like it is an unnecessary luxury and also enjoy the time spent together in the kitchen washing dishes, talking, and sharing stories or jokes; again, practical sustainability and building relationships. After we wash all the dishes with biodegradable soap, we dump the water collected in the three bins onto our compost bins in a specific rotation so we do not “overwhelm” or inundate any area with too much water. This allows the environment to absorb that water in a timely fashion, and saves sending unnecessary amounts of water to the septic tank.\nEnergy Saving Techniques:\nHere’s some energy calculators:\nIn The Living Room\nWhen this house was built in 1974, sustainability did not seem to be on the forefront of the builder or designer’s minds. Although the view is beautiful, it is north facing, with large windows, and a very thin roof. We are losing lots of heat through the roof and windows, and get practically no direct sunlight to heat up the house. Next spring, we will explore more options of cutting down trees, installing solar, wind, or geothermal energy systems, but for right now, we are trying to work with what we have. We have a Lopi stove with a blower that has been helping, a propane furnace, but propane is extremely expensive. We keep the furnace set at 54 degrees, burn wood, and have a small electric heater. We have also applied plastic to the windows, put up insulation over our top windows, and have hung thermal drapes. All together, the house has been staying around a constant, balmy, 60 degrees. Understanding that it is winter, we add an extra layer of clothes and spend a lot of time around the fireplace working, talking, and eating which has really helped build a stronger community of people at the EcoRanch. Last, we put in weather stripping on all the doors in the house and put in insulation behind every outlet and light switch which surprisingly, can be quite drafty.\nFinally, we turned the water heater down to 115 degrees and insulated the hot water tank and all the hot water lines to reduce heat loss. We figured, what’s the point in heating water to a temperature that is too hot to touch so we need to waste more water by turning on the cold water to cool it off after we spent the money and energy to heat it up to an unusable temperature? Why not just turn down the temperature and save energy in the first place!\nAgain, we hope these ideas stimulate a discussion below or on our Facebook page and that you share your water and energy saving techniques with the rest of us. Remember, sustainability and conservation should not be an overwhelming process, but rather finding gradual, comfortable changes you can make to your lives. And, if all of us can make small changes, they will add up to very large, positive impacts to our shared commons – the environment we depend on everyday. Thanks and we look forward to your replies."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:5d37776b-6018-4daf-bbea-22aae9cae8be>","<urn:uuid:05468f39-0f3d-413e-b7e4-b22f1c2cc420>"],"error":null}
{"question":"With all the talk about protecting critical infrastructure from earthquakes lately, I'm curious - how do man-made earthquakes from fracking compare to the protection offered by earthquake cloaks? 🤔","answer":"Man-made earthquakes caused by oil and gas production through fracking have created swarms of seismic activity that put infrastructure like oil pipelines at risk. While earthquake cloaks could theoretically protect such infrastructure by deflecting seismic waves through arrays of precisely drilled holes, reducing a magnitude-7.0 quake's impact to magnitude-5.0 or lower, the fracking process itself continues to pose seismic risks. Studies show that fracking and its waste disposal wells can trigger minor earthquakes in nearby settlements, potentially leading to destruction of buildings and loss of lives. The protection method using earthquake cloaks requires significant space and has not yet been tested in real-world conditions against actual seismic waves.","context":["SAN FRANCISCO – Earthquake cloaks, or huge arrays of precisely drilled holes and trenches in the ground, could — at least in theory — protect important structures like nuclear power plants from powerful seismic waves, researchers say.\nThe array of holes, drilled at specific angles and depths, would extend sometimes hundreds of feet and scatter earthquake waves like pinballs, according to the scientists.\nThe idea is still highly speculative, requires a large amount of space that might be impractical, and has not been tested in the ground, but if it works, it could theoretically be used to protect expensive infrastructure that cannot be seismically retrofitted, such as oil pipelines, Vladimir Liberman, a physicist at the Massachusetts Institute of Technology Lincoln Laboratory, said here Thursday (Dec. 15) at the annual meeting of the American Geophysical Union. [Image Gallery: This Millennium's Destructive Earthquakes]\nProtecting vulnerable structures\nIn places like Oklahoma, oil and gas production has caused swarms of man-made earthquakes, meaning expensive infrastructure such as oil pipelines are now in vulnerable locations. In other areas, nuclear power plants are vulnerable to strong earthquakes. Sometimes, this infrastructure can't actually be physically modified to make it more resistant to earthquakes, Liberman said.\nBut what if seismic waves could be deflected before they reach critical infrastructure? To see if there was another way to protect these structures, Liberman and his colleagues created a 3D simulation where they modeled the ground in tiny, three-dimensional cubes, or chunks that varied in size. The model then incorporated drilled holes of varying sizes and orientations, forming a kind of underground zigzag shape. They modeled seismic waves coming from different orientations and found that in computer simulations at least, their setup could deflect a large amount of the energy coming from earthquake waves, Liberman said.\nNext, they created a tabletop mockup of the ground using a small block of plastic fitted with tiny accelerometers and drilled with lots and lots of holes in precise orientations, then subjected them to mock seismic waves. The plastic had the right set of physical parameters, such as shear wave velocity and viscosity, to mimic ground-based seismic waves. Similar to their model predictions, the mockup deflected the incoming waves. Based on these experiments, the team thinks its earthquake-cloaking method could reduce the impact from a magnitude-7.0 quake to a magnitude 5.0 or even lower, Liberman said.\nBased on these simulations, the scientists estimated that protecting infrastructure such as nuclear power plants, hospitals, air vehicle runways and pipelines would take anywhere from 2,000 to 8,000 boreholes drilled at precise angles, spanning hundreds of feet, and placed a distance up to a few miles away from the infrastructure, Liberman said.\nOf course, there are a number of caveats: The method hasn't been subject yet to peer review, and the researchers have yet to test it in real-world situations, against actual seismic waves. In addition, there's no telling yet whether deflecting these earthquake waves would lead to dangerous wave reflections to other areas, Liberman said. And given how much space is needed to create these earthquake cloaks, it is likely only practical for structures far away from urban areas, he said. Still, when talking about $2 billion in infrastructure, it can be relatively economical to drill a field of holes at a cost of about $100,000 to protect those structures, he added.\nAs the next step in their research, the team is testing out the earthquake-cloaking concept on a small scale in the ground using machines that generate vibrations.\nOne of the moderators of the session asked whether more visually appealing structures, such as trees, could replace boreholes while serving the same earthquake deflection process.\nUnfortunately, the trees would have to be extremely tall, Liberman said.\n\"You would need mini-Eiffel Towers to attenuate the low frequency waves\" that accompany earthquakes, Liberman said.\nOriginal article on Live Science.","geologic formations sometimes contains large pools of oil and/or gas but may\nhave a poor flow rate due to clogging or low permeability of the formation\nduring drilling and occurs in laces that have tight sands, shale’s or places\nthat have methane formations. To extract the mineral deposits in such places,\nhydraulic fracturing/cracking or fracking process is used since it has the\ncapability of stimulating wells drilled into the mineral formation locations\nthus enabling the extraction of oil or gas economically. Hydraulic fracturing\nis therefore a well stimulation technique that enables a rock to be fractured\nby hydraulically pressured liquid that comprises of water sand and other\nchemicals into a wellbore to create cracks that allow gas and other natural gases\nto flow freely and easily towards the collection point. The science behind the\nfracking process occurs after wells have been drilled and steel pipe inserted\nin the well bore. The steel case piping is perforates within the targeted\noil/gas zones such that when the fracturing fluid is injected into the well, it\nflows through the perforations into the targeted zones where pressure is\ncreated that causes the formation to crack/fracture, after which injection is\nceased allowing the fracturing fluid to flow back to the surface. The fractures\nmay also be created by injecting gases like propane or nitrogen causing\nacidizing and fracturing where acid is pumped into the formation to dissolve\nrock materials and to clean the pores to enable gas or oil to flow better into\nEconomic analysis of fracking\ncosts associated with fracking include the large amount of water required to\ncrack a single well and the toxic chemicals that have to be pumped into the\nrock formations to crack the surface. Fracking also produces greenhouse gases\nwhich affects the environment negatively. There has been reported tectonic\nimpact of the disposal wells that lead to minor earthquakes in the nearby\nsettlements. This is disastrous as it may lead to loss of lives and destruction\nof buildings. Water contamination cannot be avoided as a result of fracking.\nthe advent of fracking, gas prices have lowered comparatively because of the\ncompetitive nature of the natural gas. One of the benefits associated with\nnatural gas is that it produces less carbon dioxide and less sulfur dioxide\nwhich leads to multiple health problems. Green house emission have also been\nreported to have decreased as a result of the fracturing. Before the advent of\nthe shale gas, importation of the gas would have been inevitable, thus\nincreasing the cost of the product to the consumer. Natural gas can be burned to produce electricity\nthat is cheaper and cleaner than coal (Wicander & Monroe, 2015). Upon the extraction\nof the hydraulic fracturing, a lot of employment opportunities are availed to\nthe many unemployed Americans. This in effects uplifts the living standards of\nthe population and reduces the burden of government support to the unemployed.\nAt the same time, fracking has helped accelerate the growth of the energy\nsector thus increasing the annual GDP by over $300 billion annually (Gilbert, 2011).\nSteady production of oil can be deduced from the undertaking thus reducing the\nimport capacity costs.\nhydraulic fracturing is one of the key methods that are used to extract\nunconventional gases and other natural gas resources, it poses various risks,\nboth to the human being and the environment/habitats. Some of these issues that\nimpact the environment includes the water usage, chemical usage, pollution,\neffect on the air among other effects.\nto a 2010 survey that was carried out by the US Environmental Protection\nAgency, it was estimated that between 70 and 140 billion gallons of water were\nused to fracture 35000 wells every year. This is equivalent to the annual water\nconsumption of 40 – 80 cities whose population is 50,000. The extraction of\nsuch amount of water has ecological impact in that it affects the aquatic life\nas well as the aspect of dewatering the water aquifers. At the same time, the water transportation modes\n(trucks) affects the habitat by creating a localized air quality and road\nmaintenance issues (Spellman, 2013). It should be noted that these gas and oil\nwells use large quantities of sand and proppants that leads top excess water\nconsumption and air pollution. Health problems may also arise that relates to\nthe extraction of the unconventional minerals and shale gas, a lot of toxic\nchemicals are used that amount to approximately 0.5-2% of the volume of the\nfracturing fluids. The more the water used, the more the toxic gas implying\nthat the toxic fluid are a health hazard\nto human, animals and plants. Some of these chemicals cause incurable diseases\nincluding cancer (Spellman, 2013). These chemicals pollutes the water\nunderground, thus affecting the aquatic life as well as the air and drinking\nwater. Any human being that get exposed to the fracking chemicals are likely to\nhave health effects including skin, eye and sensory issues, respiratory and\ngastrointestinal problems, cardiovascular problems, kidney issues among many\nother health concerns (Howarth, Ingraffea & Engelder, 2011).\nalso exists the contamination of soil and surface water during waste disposal\nand chemical injection and preparation. The ground water which may have coal\nbends containing enough water for drinking may become contaminated as a result.\nOf concern is the chemical component that is left in the underground after fracturing is done. This\nmay lead to water contamination for many years to come. The air quality is also\ncompromised as a result of chemical toxicity near the wells due to flow backs and\nHurdles to regulating fracking\nstate regulations have enabled the extraction of the unconventional gas to\noperate safely and in an environmental friendly manner. Stiff measures\nincluding fines and other punitive measures have been put in place to prevent\ncompanies undertaking fracturing from destroying the environment. Ground water\nprotection agencies have been formed to address possible pollution to the\nwaters and each state has been mandated to disclose chemicals used in fracturing.\nWaste management commissions have also been formed to ensure safe disposal of\nthe waste products resulting from the fracking activities.\nEffect of the energy markets since the advent of\nadvent of fracking has increased the competition in the energy sector in the United\nStates. In particular, the prices of\nenergy/gas has decreased considerably and its increase has led US into being self-sufficient\nthus limiting their imports. The US market has now become an exporter of gas\nand coals that it no longer need. At the same time, as a result, the regulatory\nframework has changed to accommodate fracturing.\nThe future role of natural gas and shale oil in the\nstatistics depicts a positive trend in the production of shale gas. In the\nfuture, it is expected that the fractured gas will play a major role in the\nenergy sector in the United States. It is expected that about 42% of the total\nUS gas will emanate from the unconventional gas production. At the same time,\nthe demand for the natural gas will be expected to increase and many parties will\nvolunteer to work towards the exploration of the natural gas that will help\nsupply the nation for many years to come. Finally, I is expected that the low\nnatural gas and oil prices will help improve the energy sector by increasing\nthe firms fueled by the cheap natural gas. The continued production of the\nnatural oil will enable US to be self-sufficient in oil production and will\nhelp the country export surplus to other countries\nPolicy recommendation and course of action on\n300,000 barrels of natural gas are produced each day through the process of\nhydraulic fracking. This is a good economic undertaking, but it succeeds at the\nexpenses of environmental, safety as well as health hazard. This being the\ncase, it is important for all the concerned authorities to address the issue\nand come up with strategies that could exploit these minerals without\ndestroying the future. With the rising ozone degradation, the environment has to\nbe protected under whatever cost. The extracting companies ought to liaise with\nthe relevant bodies as they undertake their fracturing processes.\nStrategically, regulations should be put in place so that the companies\nundertaking the fracturing report and disclose promptly the type of chemical’s\nbeing used and the effect on the environment. The use of nontoxic chemicals\nought to be encouraged including nontoxic deliveries. At the same time, the\ngovernment and the federal bodies should ensure that the disposal of the waste\nwater that contains chemicals is done appropriately. In this, toxic waste\ntreatment facilities should be created that concentrate all waste products in a\ngiven place for efficient disposal. Strategies to recycle waste water to be\nused for re-drilling should also be put in place. All in all, the government should aim at\nensuring transparency in hydraulic fracturing and should put measures in place\nthat help identify the processes and effects of the hydraulic fracturing\nJ. R. (2011). Assessing the Risks and Benefits of Hydraulic Fracturing. Mo.\nEnvtl. L. & Pol’y Rev., 18, 170-208.\nR. W., Ingraffea, A., & Engelder, T. (2011). Natural gas: Should fracking\nstop?. Nature, 477(7364), 271-275.\nF. R. (2013). Environmental impacts of hydraulic fracturing. Boca Raton, FL: CRC\nR., & Monroe, J. (2015). Historical geology. Cengage Learning.\nThe post Research Paper Help on Hydraulic fracturing appeared first on Best Essay Services.\nOur writing company helps you enjoy campus life. We have committed and experienced tutors and academic writers who have a keen eye in writing papers related to Business, Management, Marketing, History, English, Media studies, Literature, nursing, Finance, Medicine, Archaeology, Accounting, Statistics, Technology, Arts, Religion, Economics, Law, Psychology, Biology, Philosophy, Sociology, Political science, Mathematics, Engineering, Ecology etc."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:c8046da5-ad48-481e-aac8-0fe3ed7a1e76>","<urn:uuid:1f83221c-8671-49c1-977d-4659c320df50>"],"error":null}
{"question":"What are the key innovations in coral restoration nurseries, and what's their success rate in the Caribbean?","answer":"Key innovations include Hawaii's ex situ shore-based nursery that can grow large-size adult coral colonies in just over a year, using professional coral husbandry techniques to grow small fragments and recombine them into large colonies. The nursery primarily uses corals from harbors, which are more resilient and don't impact natural reefs. As for success rates in the Caribbean, research has shown that current restoration methods are very effective, particularly for staghorn corals. Studies of coral restoration sites in Florida and Puerto Rico demonstrated that laboratory-raised coral fragments successfully adapt when transplanted, behaving just like wild colonies, while the collection process doesn't damage donor colonies.","context":["The state Department of Land and Natural Resources has found an effective way to safeguard Hawai‘i’s native, slow-growing coral reefs — a nursery away from the ocean.\nIn one corner of the Anuenue Fisheries Research Center on O‘ahu’s Sand Island, a modest collection of buildings has become home to the DLNR Division of Aquatic Resources Coral Restoration Nursery.\nPart neonatal intensive care unit and part bank for Hawai‘i’s native corals, the new nursery aims to use professional-level coral husbandry techniques to grow small fragments of a coral colony, recombine them into large colonies, and then transplant them into the field in a fraction of the time it would take these corals to grow naturally.\n“Most coral nurseries around the world are in situ, meaning they are in the field. These types of nurseries excel at raising naturally fast-growing species of corals, which are not components of major reefs in the Main Hawaiian Islands. At our Coral Restoration Nursery we’re focusing on ex situ or a shore-based nursery where we can grow large-size, adult colonies of coral for restoration purposes in a little more than one year.” DAR Coral Biologist David Gulko said.\nThe Hawai‘i nursery primarily uses corals for transplantation from harbors as they have lower ecological value compared to corals from natural areas; may be more resilient to disturbances and environmental changes; do not impact our natural reefs, and helps with upkeep and maintenance of manmade structures.\nThe Coral Restoration Nursery will also provide coral colonies for multiple restoration projects under the country’s first Aquatic Mitigation Bank, which primarily focuses on near-shore coral reef resources.\n“The mitigation bank, is akin to companies gaining carbon credits, in that costs recouped through the selling of coral restoration credits are based on lost ecological services from incidents like boat groundings and spills into the ocean,” DLNR Chair Suzanne Case said.\nNearly a quarter of coral species found in Hawai‘i are unique to the islands and are also among the slowest-growing corals on the planet, according to DAR Administrator Dr. Bruce Anderson.\n“This means it could take well over a decade for corals to get big enough to reproduce. The Coral Restoration Nursery is using techniques that will reduce the time it takes to grow transplantable corals to about one year,” Anderson said. “We are hopeful this will help recover reefs which have been seriously degraded by human impacts like coastal development, vessel groundings, pollution events, along with environmental factors such as climate change.”\nDAR’s Fast-Growth Protocol begins with the removal of a small coral from somewhere like a harbor piling. It is then quarantined in the nursery before being fragmented into a small living pieces. Each of these genetically-identical fragments are then exposed to optimal light, water and nutrient conditions before being re-aggregated together to create at least a 40 cm colony.\nPrior to being transplanted back into the ocean it is put in an acclimation tank, which duplicates the conditions it will experience once it’s transplanted onto the target restoration reef.\n“The technique makes use of non-coral reef source material (harbors, etc.), and provides protection from disease, water quality issues, aquatic invasive species, predation and competition to create re-combined coral colonies in a fraction of the time it would take to grow these corals naturally,” Gulko said.","Researchers provide science benchmarks for the restoration and recovery of threatened corals.\nMIAMI (July 25, 2017)—A new study found that Caribbean staghorn corals (Acropora cervicornis) are benefiting from “coral gardening,” the process of restoring coral populations by planting laboratory-raised coral fragments on reefs.\nThe research, led by scientists at the University of Miami (UM) Rosenstiel School of Marine and Atmospheric Science and partners, has important implications for the long-term survival of coral reefs worldwide, which have been in worldwide decline from multiple stressors such as climate change and ocean pollution.\n“Our study showed that current restoration methods are very effective,” said UM Rosenstiel school coral biologist Stephanie Schopmeyer, the lead author of the study. “Healthy coral reefs are essential to our everyday life and successful coral restoration has been proven as a recovery tool for lost coastal resources.”\nIn the study, the researchers set out to document restoration success during their initial two years at several coral restoration sites in Florida and Puerto Rico. Their findings showed that current restoration methods are not causing excess damage to donor colonies as a result of removing coral tissue to propagate new coral in the lab, and that once outplanted, corals behave just as wild colonies do.\nStaghorn coral populations have declined as much as 90% in the Caribbean since the 1980s. As a result, the species was listed as threatened under the U.S. Endangered Species Act in 2006 to help protect and conserve these species that form the foundation of the biologically rich coral reef habitats.\nThe findings, published in the of the journal Coral Reefs, offers a guide for successful restoration and recovery efforts of the threatened species worldwide.\nThousands of corals are raised in laboratories and planted onto degraded reefs each year. This study is the first to collect baseline coral restoration survival and productivity data at regional scales including data from 1,000s of individual A. cervicornis colonies, more than 120 distinct genotypes within six geographical regions to develop benchmarks to fully assess the progress and impacts of the region’s coral and reef restoration efforts.\nCoral reefs provide many goods and services including fisheries habitat, food for humans and other ocean species, and protection against natural hazards such as hurricanes. As a result, coral restoration is viewed as an effective and cost-efficient strategy to buffer coastlines from the effects of storm surge and sea-level rise.\n“Coral reefs are declining at an alarming rate and coral restoration programs are now considered an essential component to coral conservation and management plan,” said Diego Lirman, UM Rosenstiel School professor of marine biology and ecology and a coauthor of the study. “Our findings provide the necessary scientific benchmarks to evaluate restoration progress moving forward.”\nThe study was conducted in collaboration with U.S. Acropora Recovery Program partners: Nova Southeastern University, University of Miami, Florida Fish and Wildlife Conservation Commission, Mote Marine Laboratory, The Nature Conservancy, and the National Oceanic and Atmospheric Administration (NOAA).\nThe public can get involved in restoration through the UM Rescue-a-Reef program, where citizen scientists help plant nursery-grown corals onto depleted reefs alongside scientists.\nThe study, titled “Regional restoration benchmarks for Acropora cervicornis,” was authored by: Schopmeyer and Lirman from the UM Rosenstiel School; Erich Bartels, Cory Walter from Mote Marine Laboratory; David Gilliam and Elizabeth Goergen from Nova Southeastern University; Sean Griffin from I.M. Systems Group, NOAA Restoration Center; Meaghan Johnson and Caitlin Lustic from The Nature Conservancy; and Kerry Maxwell from the Florida Fish and Wildlife Conservation Commission.\nFunding for the study was provided by the American Recovery and Reinvestment Act (Award #NA09NFF4630332).\n— UM News"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:c0e5b4e2-d738-4a0c-88c5-a6e98d32775f>","<urn:uuid:392ac14b-ef1c-4114-b60b-2638e59a9303>"],"error":null}
{"question":"How do theories of cultural studies adapt when applied to non-Western contexts, and what specific challenges emerge when studying subaltern resistance in modern China?","answer":"Cultural studies theories require significant adaptation when applied to non-Western contexts, particularly regarding concepts of power, representation, and resistance. The application of these theories to China reveals that traditional Western analytical frameworks often fail to capture the complexity of subaltern resistance. While cultural studies emphasizes understanding power relations and representation, the Chinese context demonstrates specific challenges - particularly in how subaltern groups like rural farmers are rendered unconscious by dominant social and legal narratives, yet still find ways to resist through informal channels. This is evident in environmental protests like those against the Nu River dams, where local farmers' resistance doesn't fit neatly into Western theoretical paradigms. The challenge lies in avoiding epistemic violence - the inadvertent reinforcement of colonial attitudes when studying these groups - while still effectively analyzing their forms of resistance and consciousness.","context":["Cultural studies theories and the study of Asia, Africa and the Middle East\n- Module Code:\n- FHEQ Level:\n- Taught in:\n- Full Year\nThis module is available as an Open Option in MA degrees that allow them.\nObjectives and learning outcomes of the module\nThe aim of the module is to offer grounding in the theories on Cultural Studies and their use, application and adaptation in the cross-cultural contexts of Africa and Asia. It will provide an examination of the main historical concepts in Western culture such as ideology, power, class, identity, race, nation, subjectivity, representation, memory, etc. and how these are challenged by scholars working in non-Western cultures of Africa and Asia. The aim is to explore the different and plural cultural histories and memories of these contexts to which Cultural Studies must adapt.\nAt the end of the module, a student should be able to…\n- demonstrate understanding of key Cultural Studies theories applied to the study of Africa and Asia;show an awareness of the theoretical paradigms on which Cultural Studies is based and of key debates within and between these paradigms, particularly in the study of Africa and Asia\n- demonstrate a comprehensive knowledge of the economic and political forces that frame the cultural processes and the role of such processes in specific areas of contemporary political and cultural life\n- acquire a comprehensive understanding of the variety of methodologies that these approaches offer to the students of the cultures of Asia and Africa\n- evaluate and reflect on the use of Cultural Studies approaches and methodologies in the student’s areas of research\n- critically evaluate a variety of books, journal articles and other sources of information relevant to the topics studied in the module\n- acquire communication and presentation skills\nThis module will be taught over 20 week with 3 hours classroom contact per week consisting of a 2 hour lecture and 1 hour tutorial.\nScope and syllabus\nTheoretical paradigms covered will include: Modernism, Marxism, Structuralism, Post-Structuralism, Post-Marxism, Feminism, Phenomenology, Post-Modernism and Psychoanalysis. The course will investigate central questions of epistemology and methodology in relation to the application of Cultural Studies theories in non-Western contexts. It aims to equip students with sufficient knowledge to understand and evaluate the way in which Cultural Studies theories and methods are used in cross-cultural contexts and hence develop analytic skills for undertaking their own research projects.\n- Theorizing Culture\n- The use of Marxist theories in Cultural Studies\n- Ideology and hegemony\n- Post-modernist theories and their in/applicability in the context of Africa and Asia\n- Class, race, gender and sexuality, which cultural histories?\n- The Enlightenment’s ‘Discourse on In/equality’ and its Dialectic History in relation to non-Western contexts\n- The Politics of representation: Orientalism, Occidentalism\n- Subaltern studies\n- Rethinking Postcolonial theory and history\n- Nation/ Narration and Nationalism\n- Gendered discursivity and Feminisms\n- The Empire and its legacies\n- ‘Race’, Ethnicity and Multiculturalism\n- Diaspora Cultural Studies\n- The Religious vs. the Secular?\n- Cultural Studies theories and cross-cultural inquiry\n- Rethinking Cultural histories in the context of Africa and Asia\nMethod of assessment\nPortfolio of 4 reaction papers of 600-800 words each to be submitted on Monday, week 5 and 9, Terms 1 and 2. Students receive immediate detailed feedback and can edit before finally submitting on day 1, week 2, term 3 (30%); an essay of 2,000 words to be submitted on the day the course is taught, week 1, term 2 (30%); an essay of 3,000 words to be submitted on the day of teaching, week 1, term 3 (40%).\n- Abu-Lughod, Lila (ed.) (1998) Remaking Women: Feminism and Modernity in the Middle East, Princeton: Princeton University Press.\n- Adorno, T.W. (1991). The Cultural Industry: Selected Essays on Mass Culture (ed., with intro.), J.M. Bernstein. London: Routledge.\n- Baldwin, E. (2004). Introducing Cultural Studies. New York: Pearson/Prentice Hall.\n- Almquist, Kurt, (ed.), (2007) The Secular State and Islam in Europe. Stockholm, Sweden: Axel & Margaret Ax:son Johnson Foundation, pp. 81-96.\n- Balslev, A.N. (1996). Cross-cultural Conversation. Atlanta, Ga.: Scholars Press.\n- Barthes, R. (1973). Mythologies. London: Paladin.\n- Belsey, C. (2005). Culture and the Real: Theorizing Cultural Criticism. London; New York: Routledge.\n- Benjamin, W. (1968). Illuminations. New York: Schocken Books.\n- Bourdieu, P. (1993). The Field of Cultural Production. Cambridge: Polity Press.\n- Buruma, I. and Margalit, A. (2004) Occidentalism: The West in the Eyes of its Enemies. New York: Penguin.\n- Butler, J. (1993) Bodies that Matter: on the Discursive Limits of “Sex”. London: Routledge.\n- Byerly, C and Ross, K. (eds.) (2004) Women and Media: International Perspectives, Oxford: Blackwell.Chatterjee, Partha (1993). The Nation and Its Fragments. Colonial and Postcolonial Histories. Princeton University Press.\n- Chow, R. (1993). Writing Diaspora: Tactics of Intervention in Contemporary Cultural Studies. Bloomington: Indiana University Press.\n- Curran, J and Park, M. (eds.) (2000) De-Westernising Media Studies, London: Routledge.\n- Davies, I. (1995). Cultural Studies and Beyond: Fragments of Empire. London: Routledge.Fanon, F. (1986) Black Skin, White Masks. London: Pluto Press.\n- Foucault, M. (1972) The Archaeology of Knowledge. London: Routledge.\n- Forgacs, D. (ed.) (1988) A Gramsci reader: selected writings, 1916-1935. London : Lawrence and Wishart.Nigel Gilbert (ed.), (2001) Researching Social Life. London: Sage Publications.\n- Grossberg, L. et al. (eds.). (1992). Cultural Studies. London: Routledge.\n- Hall S. (1997). Representation: Cultural Representations and Signifying Practices. London: Sage.\n- Harvey D. (2006). Spaces of Global Capitalism: Towards a Theory of Uneven Geographical Development. London, New York: Verso.\n- Hills, M. (2005). How to Do Things with Cultural Theory. Oxford; New York: Oxford University Press.Jordan, G. & Weedon, C. (1994). Cultural Politics. Oxford: Blackwell.\n- Loomba, A. (2005). Colonialism/Postcolonialism. London; New York: Routledge.\n- Lull, J., (2000) Media, Communication, Culture: A Global Approach, Polity.\n- McCann, C. and Kim, S. (eds.) (2003) Feminist Theory Reader: Local and Global Perspectives, New York: Routledge.\n- McClintock, Anne (1995). Imperial Leather. Race, Gender and Sexuality in the Colonial Contest. Routledge, London.\n- Mohanty, C. T. (ed.) (1991) Third World Women and the Politics of Feminism, Bloomington: Indiana University Press.\n- Mouffe, C. (2005) On the Political: Thinking in Action, London: Routledge.\n- Said, E. (1978) Orientalism. London: Routledge 1978.\n- Said, E. (1994) Culture and Imperialism. London: Vintage.\n- Spivak, G.C. (1987). In Other Worlds: Essays in Cultural Politics. London and New York: Methuen.\n- Storey, J., (2001) Cultural Theory and Popular Culture, Prentice Hall.\n- Talal, A. (1993) Genealogies of Religion: Discipline and Reasons of Power in Christianity and Islam. The Johns Hopkins University Press.\n- Talal, A. (2003) Formations of the Secular: Christianity, Islam, Modernity. Stanford University Press.\n- Young, R. (1990) White Mythologies: Writing History and the West.\n- Williams, R. (1982). The Sociology of Culture. New York: Schocken Books.\n- Wolff, J. (2002) Why Read Marx Today? Oxford: Oxford University Press.","Virginia Review of Asian Studies\nCHINA’S ANGRY RIVER: ARE THE SUBALTERN SPEAKING?\nEMILY RUDLING UNIVERSITY OF TASMANIA\nWhat are the social implications for the proposed damming of China’s Nu River? Can the Chinese residents whose livelihoods depend upon the Nu River be classified as subaltern? If so, what are their forms of resistance and can we hear their protest? This paper argues that the damming of the Nu River marginalises and renders unconscious the ethnic minorities that inhabit the region. It explores tensions within subaltern studies to confirm that Nu locals are muted by dominant social and legal narratives. It applies this to the greater framework of power and resistance with examples of Chinese political protest in both subaltern contexts and normative narratives. Secondly, this paper applies these theories to the case study of the damming of the Nu River to explore nature of the affected subaltern groups.\nKeywords: China, Nujiang, Nu River, protest, resistance, consciousness, environment, damming, dams, subaltern.\nContemporary China is riddled with tensions between economic development, the preservation of natural resources and the transformation of a largely agrarian population into an urbanised, educated people. Metropolitan centres require agricultural goods, resources and hard labour in the endeavour for wealth and prestige. An obvious cost of this is environmental. The Chinese Communist Party (CCP) does not seem able, or even interested, in ensuring the prosperity of the country-side. While the CCP have heavily invested in the economic development of rural China, as exemplified by ‘The Great Development of the West’ campaign of the 1990s aimed at urbanising the rural population, problems in rural areas persist. As a consequence, many rural settings remain under-developed. Often, farmers resort to temporary migrant work in the urban centres to create income, thus leaving the vulnerable, elderly, youth and disabled in the villages to tend the land. These people, including the migrant workers, are China’s subaltern. They exist outside of the normative social organisations of education, permanent employment and healthcare services. They are unable to fully access these structures and are incapable of engaging with overarching political narratives. This leaves them the most exposed to legal and economic exploitation.\nThe lack of interest in human, food and environmental security problems pertaining to rural subjects exhibited by the CCP has given rise to protests against CCP policy: farmers are fighting for environmental protection to secure their livelihoods. This is exemplified by protests against damming along China’s Angry River; the Nujiang. The Nujiang is China’s largest undammed river and flows freely through several nations. In desperation to secure a hydro-electric supply to solve energy security fears, the CCP have lobbied to tame the river by way of thirteen dams. Local farmers, who were later joined by other actors, have created a movement which has managed to temporarily stop the CCP and protect the Nujiang.\nThis paper analyses the role of the farmers throughout this process. The premise of this paper is that the concept of subaltern is most productive for analysing the protest actions of the farmers. It begins with discussion of the origins of subaltern studies and evaluates the tensions within the ability of subaltern groups to have an awakened consciousness yet remain marginalised. Secondly, this paper explores three ways in which subaltern groups are understood to communicate and organise protest: rumour, communal solidarity and resistance. These themes are applied to the case study of the protest and resistance surrounding China’s Angry River.\nAnalyses of power and resistance often focuses upon ‘what happened’ as opposed to engaging with theoretical perspectives of ‘why’ and subsequently enriching the investigation. As a consequence, this paper focuses upon the theory that contextualises and attempts to explain subaltern groups. By doing so, it is hoped that this analysis will provide a sound understanding of subaltern groups and how they act.\nStudying subaltern groups is to engage with the unawakened consciousness of mass groups that are incoherent to normative structures of law, politics and the economy. It is a study conducted upon objects of suppression by the mediators of their domination. As Leela Ghandi suggests, subaltern studies are an attempt to allow the ‘people…to sound the muted voices…’ of the masses who have unconsciously shaped history yet remained outside of the major decision making processes. Karl Marx first ignites discussion surrounding subaltern groups. In The Eighteenth Brumaire of Louis Bonaparte, Marx encapsulates the meaning of ‘subaltern’ and the representation of such groups: ‘They cannot represent themselves; they must be represented’. Marx recognises the lack of class consciousness in their ‘mode of production’, absence of communication and subsequent separation from society. The concept is further developed by Antonio Gramsci who evaluates the workings of cultural hegemony, oppression and power. Gramsci argues that a society is controlled by the elite minority who elicit the cultural hegemony, thus dictating the appropriate norms, religion, ethnicity, sexuality and employment. Those who do not fit into the normative system are excluded from legal and political narratives and are socially marginalised. Importantly, these groups are also economically dispossessed. Therefore, due to the imposed cultural hegemony, subaltern groups do not have the ability to protest within the accepted languages of law and reason and are thus rendered unconscious.\nSubaltern studies were expanded when the Subaltern Studies Group (SSG) began to engage with theory and literature to try and hear these muted voices. The scope of their study is limited to post-colonial and post-imperial nations as these nations had suffered the imposition of a Western cultural hegemony and the subsequent marginalisation of their identities and voices. Although the SSG largely focuses upon Indian decolonisation and nationalism, the themes are applicable to China as a post-imperial nation who, in the contemporary context, is defined by an exclusive cultural hegemony. Subaltern groups were (found in) ‘the demographic difference between the total Indian population and all those whom we have described as the “elite,”’ therefore determining that subaltern studies seek to find the ‘culture that informs the condition’ and how that hegemony can be deconstructed argues Guha.A consequence of this is the difficulty of investigating subaltern groups and using their own narratives of power and resistance. Therefore, the investigator must engage with subaltern modes of communication such as rumour.\nWhen Spivak infamously questions whether the subaltern could speak, she reveals the difficulties of representation in subaltern studies. Errors in representations arise primarily from a West-East dichotomy. Traditionally, scholars have studied groups that have conformed to normative structures such as law and politics; narratives that can be reasoned with. Subaltern groups, however, do not exist within these frameworks and thus cannot be understood through the traditional lenses. The failure of the SSG was that subaltern groups could only be understood when they engaged with the prescribed narratives. Spivak exemplifies this with the Indian practise sati. Sati involves a widow burning herself upon her husbands’ funeral pyre. The motivation for immolation is subjective, however, it was not interpreted this way and the British Raj banned sati claiming it symbolised female oppression. Spivak describes this as ‘white men saving brown women from brown men’ to demonstrate how the “voice” of the female was constructed as an instrument of either indigenous male patriarchy or British rule. The Raj maintained what they were doing reflected the desires of the native population and that the legal protection of females symbolises the modernity of a nation. The banning of female immolation demonstrates the dangers in representation of subaltern groups. The Raj incorrectly identified sati and, as a consequence, further separated Indian widows from legal and political structures to further divide the Indian community under the British Raj.\nSpivak contends the hazard of subaltern studies exists in the unknowing and complicit reinforcement of colonial attitudes and understandings. The SSG are linked to post-colonial studies which, Spivak argues, irreversibly ties the area to colonisation and the economic, social and political domination that was originally conducted. Spivak questions whether post-colonial studies reaffirm the colonial classification of the East by observing practises from Western, privileged positions and consequently failing to properly dismantle preconceived interpretations of post-colonial nations. This implicit deconstruction of the subaltern that occurs in the study of their expression is known as epistemic violence. Edward Said’s work supports Spivak’s position, arguing that the investigator is strongly institutionalised to view subaltern groups as ‘other’ and therefore objects of examination. As a consequence subaltern groups must be studied in relation to socio-political realities.\nMisunderstandings of subaltern groups can be explained by the theory of essentialism. On a superficial level, essentialism is understood as the recognition of the essence of things and the core mechanism that defines it as an individual entity. Essentialism is defined in opposition to difference and can consequently be helpful in recognising the complex and unique interplays of culture, history and religion and therefore does not create a set of preconceived universal norms and values. The realisation of essentialism and difference, however, can be obstructive insofar as it can allow the denial of differences within essentialism. In a post-colonial context, essentialism enables the reduction of an essentialist idea to be summarised into what it means to be female, Chinese or Indian which Rushdie argues is similar to exoticism. The problem, argues Morris, is in what escapes the essentialist narrative. These interpretations further label and define subaltern groups to an essential notion of “Other” to prevent scholars from engaging with the consciousness of subaltern groups.\nSpivak prescribes a strategic approach to essentialism to allow the voices of the subaltern to be reviewed and unmuted. Spivak’s methodology entails deconstructing the ways in which subaltern groups are presented by analysing each facet of the motivation behind the actions of that group to uncover the ‘true voice’ of that subaltern: ‘[“Deconstruction”] is not the exposure of error. It is constantly and persistently looking into how truths are produced.’ Strategic essentialism is a method that uses group identity as the basis of a struggle but also recognises and debates issues related to that group identity and the individuals within the group. While this appears theoretically engaging, strategic essentialism has been regularly misinterpreted. Primarily, essentialist theory and deconstruction are often understood to be incompatible and there is difficulty in putting strategic essentialism into practise.As a consequence, the concept is subjective and inadequate to provide a benchmark for investigation. This problematises the ability of scholars to listen for subaltern groups.\nThe representation of subaltern groups is therefore a key tension within post-colonial studies. The question posed by Marx in the 19th Century has proven central to realising Eastern and Western differences and the understanding of the ‘Other’ in the shaping of and validity of subaltern and elitist identities. As Spivak demonstrates, there is significant difficulty in overcoming preconceived ideas of normative structures and narration to properly engage with the consciousness of subaltern groups. This logo-centric dependence on the West prevents subaltern groups from speaking independently and resultantly, the outcome of post-colonial studies becomes almost contradictory of its aims. While strategic essentialism may enable some groups to enter the fray, the subaltern remain subjects of investigation and consequently, are disempowered.\nA study conducted on the translation of the grievances of subaltern groups in China demonstrates how subaltern groups are disempowered. The study investigates an altercation in Taishi Village in 2005 regarding corrupt distribution of welfare benefits in the area. Village elders argued funds for collective welfare had been illegally taken by local cadres. The protests in Taishi Village quickly drew national attention and lawyers and legal representatives flocked into the village to aid the protesters and provide them with a conscious, recognisable voice that would resonate with the national political agenda. This removed the resistance from the control of the subaltern group and translated it into a legal narration: a language that the original protesters were incapable of reaching or understanding. The protest became part of the national agenda and synonymous with the fight for democracy and integral to the campaigning of the rights defence movement. External actors interpreted the protest as part of a larger, homogenous idea of empowering the exploited farmers. It was believed that by joining the issues of Taishi Village with other rural battles, it would create an empowering solidarity across China and influence CCP policy. The inhabitants of Taishi Village were not in want of this. The lawyers demonstrated a poor interpretation and translation of the grievances of the villagers thus rendering Taishi Village a tool in their construction of the framework of normative protest and resistance argues Woodman. Taishi Village exemplifies the pitfalls in representing subaltern groups.\nThe fiasco at Taishi Village questions whether subaltern groups can speak and simultaneously remain subaltern: do unmuted subaltern groups merge into the greater consciousness of class struggle? Utilising strategic essentialism, Spivak concludes subaltern groups cannot speak thus determining they remain unconscious. Subaltern resistance cannot be translated into another narrative without being changed which, as Woodman exemplifies, is not uncommon. Thus, for subaltern groups to consciously engage with other actors is to recognise the accepted modes of communication and to cease being subaltern. Guha disputes this and argues that the premise of subaltern studies is to engage with what consciousness is awakened in oppressed groups. Guha, therefore, questions what mechanisms subaltern groups use to protest and resist and whether these shaped or impacted on the political agendas of their time.\nThis is illustrated by the origins of what the British title the \"Indian Mutiny” or, for the Indians, the First War of Independence (1857). Indian soldiers were employed by British Raj as sepoys to help the crush Indian uprisings. The sepoys were deployed across India with modern weaponry, the Enfield Rifled Musket. This ensured greater accuracy and distance than its predecessors. To load the rifle, sepoys bit open the cartridge and poured gunpowder into the muzzle. The cartridge was waterproofed with grease and used as wadding. The mutiny began when rumour circulated that the cartridges were dipped in animal fat; namely lard from the pig and tallow of the cow. In reaction, Muslim sepoys refused to open cartridges for fear of breaking taboos regarding pork and the Hindu sepoys were admonished at the possibility of being lowered in caste for consuming the sacred cow. The rumours sparked the sepoys’ refusal to fight and thus caused the ‘Indian mutiny’.\nRumour is not a traditional narrative used to effect political change; however, in this case, rumour irreversibly affected the socio-political construction of British India. Rumour was the principal means of communication used by the soldiers of the War of Independence to mobilise insurgents and evoke comradeship. Spivak asserts the importance of oral traditions which conveys ideas, hopes and protest to unite subaltern groups. In the Indian Independence, these customs of song, story and myth gave rumour the greatest authority. It is evident the culture of the spoken word was utilised as a framework for protest to effect political change. This determined that the affected were in control of the conversation and their grievances were not forcefully translated into a separate narrative as had occurred in Taishi village. The “Indian Mutiny” is historically important because subaltern culture informed the protest. This is important insofar as culture has historically developed in juxtaposition with reason, contends Dirlik. Rationality, however, is premised on both culture and reason if it is to at all be tied to the living world. Accordingly, to avoid ideas regarding the influence of culture is to remain imprisoned in rational ways of seeing. Unconsciousness must be the departure point for critical analysis and radical activity. This is arguably what was achieved through rumour during the “Indian Mutiny”.\nThe Jasmine Revolutions that occurred in China early 2011 (19th February 2011 – 21st March 2011) illustrate the power of rumour in a modern context. The revolutions were sparked by the Arab Spring where protesters were fighting for democracy, human rights and transparent governance. Peculiarly, the Jasmine Revolution began outside China on social networking websites, Twitter and Boxun.com where anonymous users encouraged Chinese to meet on Sundays at various places around China to peacefully protest for change. On the arranged dates, thousands of Chinese gathered expectant of protest yet nothing actually happened and nothing was actually changed. The “revolutions”, however, demonstrate the impact and authority of rumour to unite groups through a common belief. While the men and women involved do not fit the traditional description of subaltern, their involvement and desire for change illustrates a feeling of frustration in their ability to shape the political agenda."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:ff73a79b-a542-4f32-828a-d38f18f5e189>","<urn:uuid:55b9e37b-437e-4259-8aeb-2a2b44e3c876>"],"error":null}
{"question":"How does a ratio detector handle noise differently from other FM detectors, and what is its main advantage?","answer":"A ratio detector suppresses amplitude noise without requiring limiter stages, which is its main advantage. It helps maintain constant circuit voltage to prevent noise fluctuations from interfering with the output.","context":["Module 12 - Modulation Principles\nPages i - ix,\n1-1 to 1-10,\n1-11 to 1-20,\n1-21 to 1-30,\n1-31 to 1-40,\n1-41 to 1-50,\n1-51 to 1-60,\n1-61 to 1-70,\n1-71 to 1-75,\n2-1 to 2-10,\n2-11 to 2-20,\n2-21 to 2-30,\n2-31 to 2-40,\n2-41 to 2-50,\n2-51 to 2-60,\n2-61 to 2-64,\n3-1 to 3-10,\n3-11 to 3-20,\n3-21 to 3-30,\n3-31 to 3-35, AI-1 to AI-6, Index-1\nto 2, Assignment 1, 2\nThe COMMON-BASE DETECTOR\nis an amplifying detector that is used in portable receivers.\nThe SLOPE DETECTOR is the simplest form of frequency detector. It is essentially a tank\ncircuit tuned slightly away from the desired fm carrier.\nThe FOSTER-SEELEY DISCRIMINATOR\nuses a double tuned RF transformer to convert frequency changes of the received fm signal into amplitude\nvariations of the RF wave.\nThe RATIO DETECTOR uses a double-tuned transformer connected so that the instantaneous\nfrequency variations of the fm input signal are converted into instantaneous amplitude variations.\nThe GATED-BEAM DETECTOR uses a specially-designed tube to limit, detect, and amplify the\nreceived fm signal.\nPHASE DEMODULATION may be accomplished using a frequency discriminator or a quadrature\nPEAK DETECTION uses the amplitude, or duration, of a pulse to charge a holding capacitor and\nrestore the modulating waveform.\nA LOW-PASS FILTER is used to demodulate DM by averaging the pulse amplitude over the\nentire period between pulses.\nPULSE CONVERSION is used to convert PPM, PDM, or PCM to PDM or\nPAM for demodulation.\nANSWERS TO QUESTIONS Q1. THROUGH Q40.\nA-1. Re-creating original modulating\nfrequencies (intelligence) from radio frequencies.\nA-2. Circuit in which intelligence restoration is\nA-3. A circuit that can detect the presence or absence of RF energy.\nA-4. An antenna,\ntank circuit for tuning, rectifier for detection, filter to give constant output, and an indicator device.\nA-6. By giving a different beat frequency for each signal.\nA-8. Oscillator, mixer, and detector.\nA-9. (1) Sensitive to the type of modulation applied, (2)\nnonlinear, and (3) provide filtering.\nA-10. The modulation envelope.\nA-11. Rectifies the RF pulses\nin the received signal.\nA-12. To filter the RF pulses and develop the modulating wave (intelligence) from the modulation\nA-13. The current-diode detector is in parallel with the input and load.\nA-14. When the input\nvoltage variations are too small to give a usable output from a series detector.\nA-17. By the collector current flow through R4.\nA-18. Emitter-base junction.\nA-19. A diode detector followed by a stage of audio amplification.\nA-20. C1 and R1.\nA-22. Converting frequency variations of received fm signals to amplitude variations.\ndouble-tuned tank circuit.\nA-24. Rectify the RF voltage from the discriminator.\nA-26. Suppresses amplitude noise without limiter stages.\nA-27. It helps to maintain a constant circuit\nvoltage to prevent noise fluctuations from interfering with the output.\nA-28. Limits, detects, and\nA-29. Both grids must be positively biased.\nA-30. Extreme simplicity, few components, and\nease of adjustment.\nA-31. In the amount and rate of phase shift of the carrier wave.\nof the incidental frequency shift that is caused while phase-shifting a carrier wave that is similar to fm\nA-33. The quadrature grid signal is excited by a reference from the transmitter.\nDetecting the presence of RF energy.\nA-35. Pulse amplitude or pulse duration.\nA-36. At least 10 times the interpulse period.\nBy making the time constant for charging the capacitor at least 10 times the maximum received pulse width.\nA-38. By averaging the value of the pulses over the period of the pulse-repetition rate.\nA-39. PPM, PFM, and PCM are converted to either PDM or PAM for demodulation.\nA-40. It will discharge to\none-half its value between pulses.\nNEETS Table of Contents\n- Introduction to Matter, Energy,\nand Direct Current\n- Introduction to Alternating Current and Transformers\n- Introduction to Circuit Protection,\nControl, and Measurement\n- Introduction to Electrical Conductors, Wiring\nTechniques, and Schematic Reading\n- Introduction to Generators and Motors\n- Introduction to Electronic Emission, Tubes,\nand Power Supplies\n- Introduction to Solid-State Devices and\n- Introduction to Amplifiers\n- Introduction to Wave-Generation and Wave-Shaping\n- Introduction to Wave Propagation, Transmission\nLines, and Antennas\n- Microwave Principles\n- Modulation Principles\n- Introduction to Number Systems and Logic Circuits\n- Introduction to Microelectronics\n- Principles of Synchros, Servos, and Gyros\n- Introduction to Test Equipment\n- Radio-Frequency Communications Principles\n- Radar Principles\n- The Technician's Handbook, Master Glossary\n- Test Methods and Practices\n- Introduction to Digital Computers\n- Magnetic Recording\n- Introduction to Fiber Optics"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:b8533169-5ad6-4072-8e84-f4d29fb9ff3c>"],"error":null}
{"question":"What are the key differences between how memory and cognitive problems manifest in Alzheimer's disease versus Huntington's disease?","answer":"Alzheimer's and Huntington's disease show distinct patterns in how they affect memory and cognition. In Alzheimer's, memory loss is the primary early symptom, with patients frequently forgetting recently learned information, dates, or events, and asking for repeated instructions. Cognitive decline in Alzheimer's manifests through difficulties with planning, problem-solving, following recipes, and handling finances. In contrast, Huntington's disease initially shows through irritability, poor coordination, and trouble learning new information or making decisions. While both conditions affect cognitive abilities, Huntington's disease is additionally characterized by uncontrolled movements (chorea), and typically progresses faster, with patients living 15-20 years after symptoms begin. Huntington's patients also experience more pronounced personality changes and emotional problems early in the disease course.","context":["There are no easy answers when it comes to memory loss disease known as Alzheimer’s. It can be a painful experience for everyone involved, not just the sufferer. A brain disease that causes the gradual loss of memory, reasoning, and thinking skills, it is sometimes even harder on the family member watching their loved one lose his/her mental faculties than it is on the Alzheimer’s patient him/herself.\nIt can be scary to admit that someone in your life is suffering from Alzheimer’s disease, but the faster it is diagnosed, the quicker the patient can start some brain exercises and other devices to slow the disease’s advance. Below are some warning symptoms of Alzheimer’s. If you notice them in yourself or someone close to you, it is probably time to consult a doctor.\nDaily life is disrupted by memory loss.\nMemory loss is the most common and well-known symptom of Alzheimer’s. While we all can be forgetful, those developing Alzheimer’s will frequently forget recently learned information and dates or events. Some people start asking for instructions or information over and over again, which can be frustrating for the people around them.\nConfusing time and/or place.\nWhile it is not atypical for aging people to get confused about the day of the week, he/she probably figures it out quickly. But people with Alzheimer’s will often lose track of not just dates, but also seasons and the passage of time. They may be confused as to where they physically are and how they arrived at that location.\nMaking a bad decision here and there is normal for anyone, regardless of age. But people with Alzheimer’s disease may begin to make more and more poor choices. They may make bad decisions when dealing with money, for example. Some will donate to charities they otherwise would not have, while others buy whatever the telemarketer on the end is selling. Some people suffering from the disease will also start paying less attention to personal hygiene and grooming.\nSometimes people who develop Alzheimer’s start to experience changes in their personalities. This can be very disconcerting for their loved ones. Patients will sometimes get sudden mood swings and become emotional, usually angry or upset, though there has been no particular trigger. Formerly outgoing, gregarious people will start to isolate themselves and stop participating in hobbies and activities. Sadly, many develop unfounded suspicions of the people surrounding them, including family members and caretakers.\nThe trouble with planning and problem-solving.\nEveryone makes occasional errors, whether in figuring out the tip on a meal or balancing a checkbook. But people suffering from Alzheimer’s disease will notice a pattern of increasing difficulty following plans or working with numbers. Once simple tasks like balancing a family checkbook, paying monthly utility bills, or following an old recipe become challenging. Many will develop trouble concentrating, and some will notice that what once was quick and easy is now long and hard.\nDifficulty comprehending spatial relationships and visual images.\nMany people develop cataracts as they age, or require stronger prescriptions for their glasses. This is normal. But for many people, vision trouble can be a warning sign of Alzheimer’s. This can come in the form of trouble reading, recognizing colors or contrast, and judging distances. These kinds of vision problems make driving dangerous, so if you are experiencing any of them, see a doctor promptly.\nChallenges with words, both spoken and written.\nOne of the most troubling symptoms for some Alzheimer’s patients is when they start to experience new problems with speaking and writing. They find they can’t follow or join the friendly conversation. They will sometimes stop speaking mid-sentence without any idea as to how to continue their thoughts. Many struggles particularly with vocabulary, finding it extra difficult to find the right word, even when it is a common one they would normally know.\nGenerally odd behavior.\nWhile everyone may misplace their belongings here and there, Alzheimer’s patients often place objects in odd and improper places. Putting a toothbrush in the fridge, a frying pan in the freezer or a jacket in the trashcan are all reported occurrences.","Feeling confused or overwhelmed about Huntington's disease? You are not alone.\nThe Huntington's Disease Foundation is here to help you in any way we can. We are expanding our reach and programs and will be adding new information to the web site.\nPlease remember that this information is a brief overview and is for educational purposes only. It is not intended to be a substitute for professional medical advice. Always consult your health care provider with any questions you may have regarding your specific medical condition.\nWhat is Huntington's Disease (HD)?\nHuntington disease is a progressive brain disorder that causes uncontrolled movements, emotional problems, and loss of thinking ability (cognition). Adult-onset Huntington disease, the most common form of this disorder, usually appears in a person's thirties or forties. Early signs and symptoms can include irritability, depression, small involuntary movements, poor coordination, and trouble learning new information or making decisions. Many people with Huntington disease develop involuntary jerking or twitching movements known as chorea. As the disease progresses, these movements become more pronounced. Affected individuals may have trouble walking, speaking, and swallowing. People with this disorder also experience changes in personality and a decline in thinking and reasoning abilities. Individuals with the adult-onset form of Huntington disease usually live about 15 to 20 years after signs and symptoms begin.\nA less common form of Huntington disease known as the juvenile form begins in childhood or adolescence. It also involves movement problems and mental and emotional changes. Additional signs of the juvenile form include slow movements, clumsiness, frequent falling, rigidity, slurred speech, and drooling. School performance declines as thinking and reasoning abilities become impaired. Seizures occur in 30 percent to 50 percent of children with this condition. Juvenile Huntington disease tends to progress more quickly than the adult-onset form; affected individuals usually live 10 to 15 years after signs and symptoms appear.\nThe Genetic Cause of HD\nHD is caused by mutation in a gene located on chromosome 4. This gene is found in every human being, and contains a CAG repeat sequence. We have not yet discovered the gene's normal function. In a case of HD, the gene contains an abnormally large number of CAG repeats. The larger the number of triplet repeats, generally speaking, the earlier in life one will develop HD. Furthermore, when the gene is passed from father to child (but not when passed from mother to child) the gene may lengthen even more, resulting in an earlier age of onset for the disease. This phenomenon is known as anticipation.\nGenes for diseases can be either dominant or recessive. The gene for HD is dominant. Each child of an affected parent has a 50/50 chance of getting the mutant gene, and therefore has a 50% chance of inheriting the disease. On the other hand, if people with a parent suffering from HD do not inherit the mutant gene, they cannot pass it on to anyone else.\nWhat genes are related to Huntington disease?\nMutations in the HTT gene cause Huntington disease. The HTT gene provides instructions for making a protein called huntingtin. Although the function of this protein is unknown, it appears to play an important role in nerve cells (neurons) in the brain.\nThe HTT mutation that causes Huntington disease involves a DNA segment known as a CAG trinucleotide repeat. This segment is made up of a series of three DNA building blocks (cytosine, adenine, and guanine) that appear multiple times in a row. Normally, the CAG segment is repeated 10 to 35 times within the gene. In people with Huntington disease, the CAG segment is repeated 36 to more than 120 times. People with 36 to 39 CAG repeats may or may not develop the signs and symptoms of Huntington disease, while people with 40 or more repeats almost always develop the disorder.\nAn increase in the size of the CAG segment leads to the production of an abnormally long version of the huntingtin protein. The elongated protein is cut into smaller, toxic fragments that bind together and accumulate in neurons, disrupting the normal functions of these cells. The dysfunction and eventual death of neurons in certain areas of the brain underlie the signs and symptoms of Huntington disease.\nHow common is Huntington disease?\nHuntington disease affects an estimated 3 to 7 per 100,000 people of European ancestry. The disorder appears to be less common in some other populations, including people of Japanese, Chinese, and African descent.\nHow do people inherit Huntington disease?\nThis condition is inherited in an autosomal dominant pattern, which means one copy of the altered gene in each cell is sufficient to cause the disorder. An affected person usually inherits the altered gene from one affected parent. In rare cases, an individual with Huntington disease does not have a parent with the disorder.\nAs the altered HTT gene is passed from one generation to the next, the size of the CAG trinucleotide repeat often increases in size. A larger number of repeats is usually associated with an earlier onset of signs and symptoms. This phenomenon is called anticipation. People with the adult-onset form of Huntington disease typically have 40 to 50 CAG repeats in the HTT gene, while people with the juvenile form of the disorder tend to have more than 60 CAG repeats.\nIndividuals who have 27 to 35 CAG repeats in the HTT gene do not develop Huntington disease, but they are at risk of having children who will develop the disorder. As the gene is passed from parent to child, the size of the CAG trinucleotide repeat may lengthen into the range associated with Huntington disease (36 repeats or more).\nImportant Information About HD Testing\nIt is important to understand that while people are born with the mutated gene for HD, in most cases they will not develop the symptoms until later in life. Therefore someone can be without symptoms or presymptomatic for a number of years. In the past, there was no way to test for the abnormal gene, but now a blood test can determine whether or not an individual carries the gene for HD. This test can be used in cases of suspected HD, to confirm the diagnosis, or it can be used as a predictive test in individuals who are at risk for HD. People who are at risk may want to undergo predictive testing in order to put their minds at ease, to plan for their medical needs, or prior to having children. The decision to have such a test is a momentous one and should not be taken lightly. Most centers that do predictive testing, require a period of counseling before and after the test.\nWhat Are the Characteristics of HD?\nOnset is usually in mid-life, but can occur any time from childhood to old age. The initial signs of this disorder may be subtle. HD is characterized by a movement disorder, dementia, and psychiatric disturbances. Additional characteristics of HD include personality changes, weight loss (probably from a combination of difficulty eating, and calories burned by the involuntary movements), difficulty swallowing, and hard-to-understand speech.\nThe Course of HD\nOnce an individual develops signs of HD the course of the disease can last anywhere from ten to thirty years. Typically, the course of HD can be roughly divided into three stages.\nEarly Stage:In this stage patients can still perform most of their usual activities. They may still be working and may still be able to drive. Involuntary movements are mild and infrequent, speech is still clear, and dementia, if present at all, is mild.\nMiddle Stage:At this stage patients are more disabled and may need assistance with some of their activities of daily living. Falls, weight loss, and swallowing difficulties may become a problem. Dementia is more obvious to the casual observer. Involuntary movements are more pronounced.\nLate Stage:Patients entering this stage of the disease require almost total care and may reside in hospitals or nursing homes, although some remain at home. They may no longer be able to walk or speak. They may be more rigid now and show fewer involuntary movements. Individuals in this stage may or may not be able to swallow food. At this stage most patients do not seem to suffer much as they are apparently unaware of their surroundings. When the patient passes away, the cause of death is usually related to malnutrition, pneumonia, or heart failure.\nWhat Treatments Are Available?\nAt this time, there is no cure for HD. Researchers are working on a number of treatments that may slow down the progression of the disease. There are a number of interventions available today that improve the quality of life for HD sufferers. In the early and middle stages of the disease, medications can be given in small doses to HD patients to help suppress the involuntary movements. Depression and other psychiatric conditions in people with HD can be quite effectively treated. Proper nutrition, exercise and precautions in the home can help minimize many of the potential consequences of HD such as weight loss, falls, and choking on food. Finally contact with other HD sufferers, family members, and care-providers can be a vital source of support for HD patients and their families.\nPeople with HD should discuss their concerns and wishes about treatments/interventions (e.g. feeding tubes, resuscitation requests) and autopsies with their families and doctors while they are still able to speak for themselves."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:4e244de3-f370-4cde-aabc-7b571a82fa71>","<urn:uuid:84b729b4-0f1c-47cd-b48f-439fcd5a7620>"],"error":null}
{"question":"How do the water conservation efforts at Boston College compare to New York City's water management system in terms of their approach to ensuring water quality and sustainability?","answer":"Both systems have comprehensive approaches but differ in their methods. Boston College focuses on infrastructure-level conservation through installing low-flow toilets, shower heads, and faucet aerators in dorms, along with efficient underground sprinkler systems and native plants for landscaping. Their dining services also prioritize water-efficient technologies. Meanwhile, NYC's system emphasizes large-scale treatment and distribution, utilizing UV disinfection, chlorine treatment, and fluoridation at facilities like the world's largest ultraviolet treatment plant. NYC's system is so effective it's one of only five major municipalities allowed to supply unfiltered water. Both systems prioritize water quality testing, with Boston's water being regularly filtered and tested through MWRA, while NYC conducts testing at nearly 1,000 sampling stations throughout the city.","context":["“the starting point for a better world is the belief that it is possible.” —norman cousins, journalist, professor, and world peace advocate\n|Boston College Conserves Water\nBoston's Water Supply\nAlthough 75 percent of the Earth’s surface is covered by water, only 3 percent of that supply is freshwater, and only 1 percent of that is accessible for drinking. Not only is the limited supply of drinking water an issue, water quality is an even more challenging problem for the world. Many developing nations have inadequate or contaminated water supplies, leading to disease and malnutrition.\nWater conservation is indeed a global effort, and Boston College is taking steps to reduce its consumption. Additionally, there are many simple steps you, as an individual, can take to preserve the world’s water supply.\nWater conservation is important to guarantee adequate supplies for future needs. In addition, water and sewer costs have risen over 500 percent in the last 10 years and are continuing to rise. Therefore, BC has taken a number of measures to reduce water consumption on campus.\nLow-flow toilets and shower heads, as well as faucet aerators, have been installed in a number of the dorms and will be used in new student living areas being created through renovation and expansion projects in many of the residence halls.\nBoston College uses underground sprinkler systems across campus for efficient irrigation. The school is now using native plants in new landscape and planting plans.\nBoston College Dining Services engages in ongoing efforts to ensure water quality and conservation. Dining Services continually researches energy- and water-efficient technologies when replacing food service equipment and purchases Energy Star– or equivalent-rated replacement equipment. Learn more about Boston College Dining Services's Sustainability efforts.\nLaundryView.com makes doing laundry almost as easy as when Mom used to do it for you (oh, those good old days). It’s an Internet application that lets you monitor the status of washers and dryers in connected laundry rooms via a Web browser. LaundryView's mission is to help you save time by keeping you informed about the current state of laundry room equipment wherever you have access to a browser or email.\nboston's water supply\nBoston is fortunate enough to have one of the freshest and best-tasting water supplies in the world. The Massachusetts Water & Reservoir Authority (MWRA) supplies and regulates the supply of water to Boston, including Boston College’s campus. MWRA's water comes from the Quabbin Reservoir, about 65 miles west of Boston, and the Wachusett Reservoir, about 35 miles west of Boston. The two reservoirs combined supply an average of 220 million gallons per day to consumers. The Quabbin alone can hold a four-year supply of water.\nWater taken from these reservoirs is filtered and tested over and over again to ensure quality in health, safety, and taste. This process is similar to the steps taken by some bottled water companies, yet costs much less and is better for the environment, healthier, and even more delicious! But you don’t have to take our word for how beneficial the Boston public water supply is. Follow the links below to see what the MWRA is doing to ensure water quality and view recent water quality reports:\nEver go for a walk or jog around “the reservoir” at BC? That little body of water used to be part of Boston’s water supply. Learn more about the Chestnut Hill Reservoir’s history.\nIn recent years, bottled-water consumption has increased rapidly, leading to vast amounts of waste and increased oil consumption. The plastic used to make bottles is derived from crude oil, and transporting the heavy cargo to the market demands large amounts of fuel. These bottles often end up in landfills, increasing global waste.\nIn light of this, Boston College students have promoted awareness of recycling and use of local water supplies. Tap water in the Boston area is clean, refreshing, and — at $0.02 a gallon — much less costly than its bottled-water counterpart at about $1.25 for half a liter. As it stands now, most bottled water comes from natural sources or the same public water supply that supplies water to your tap. Carry and use refillable bottles for water instead of buying water in plastic bottles.\nThere are many simple steps you can take to reduce your water consumption: Don’t take marathon showers, fill the sink to wash dishes instead of running water, and fix leaky faucets. For more simple conservation tips, visit the MWRA’s website.\nHave a leaky faucet? File a Work Order now to start conserving water.","Lifestyle How New York City gets its water, from reservoir to tap: NYCurious By Cristian Salazar with amNY.com staff Updated April 18, 2018 12:01 PM Print Share fbShare Tweet Email This is part of our series NYCurious, where we answer your burning questions about the city. Ask yours here. Most New Yorkers go about their days using water to bathe, make coffee, wash their hands or flush the toilet without much thought to where it originates. But behind each drop of water is a journey that can begin up to 125 miles away in upstate New York. Along the way, it gets disinfected by ultraviolet light, treated with chlorine, fluoridated and tested for purity. It travels through mountains and deep valleys and, once in the city, flows underground in tunnels and into distribution chambers. A billion gallons of water are delivered each day, with gravity alone being sufficient to push it into buildings at least six stories high. To learn more about how the city gets its drinking water, amNewYork turned to the folks at the Department of Environmental Protection, the agency that regulates the vast water supply. Watersheds, reservoirs and lakes Photo Credit: NYC DEP Before it goes anywhere, the city's drinking water starts out in three major watersheds -- the Delaware and Catskill systems west of the Hudson River and the Croton system just north of the city. In 2017, New York City got about 97 percent of its water from the Catskill/Delaware systems and about 3 percent from the Croton system, the DEP said. The watersheds feed more than a dozen reservoirs and controlled lakes. The largest reservoir, the Pepacton, has a capacity of 140 billion gallons. The Ashokan in Ulster County, pictured, has a capacity of 123 billion gallons. Officials take measurements throughout the reservoirs, looking at things like turbidity (water clarity) and contaminants, to select the highest quality water available at that moment to be released downstate. A well protected water source Photo Credit: NYC DEP The water supply is so critical to the city that a dedicated police force with more than 200 members works 24 hours a day to prevent illegal dumping and other misuses of the waterways. During Hurricane Irene, the DEP Police were even called on to conduct water rescues. Miles of aqueducts Photo Credit: NYC DEP Next, the water flows from the reservoirs and lakes through a system of aqueducts and tunnels. These include the 100-year-old Catskill Aqueduct, which extends 92 miles from the Ashokan Reservoir in the Catskill Mountains to the northern boundary of the city, and relies solely on gravity to carry the water. When it was completed in the early 1900s, the Catskill Aqueduct was considered by some as an engineering feat on the level of the Panama or Suez canals. The 85-mile Delaware Aqueduct to its southwest is much newer, having been completed in the mid-1940s. The Delaware is so large that a two-man submarine has been used to inspect it for leaks. There are other aqueducts and tunnels, too. They all give the system a cascading effect, letting the water flow downstate. Disinfecting the water Photo Credit: NYC DEP After traveling southeast through the Catskill and Delaware aqueducts, water arrives at the Kensico Reservoir about three miles north of White Plains in Westchester County. The reservoir is an important balancing reservoir for the daily demands of the city. Up until this point, the water has also been unfiltered and untreated. But now it gets treated with fluoride and disinfected at what is considered the world's largest ultraviolet treatment facility, as seen above. The UV treatment is especially useful for zapping Cryptosporidium and Giardia, which are not the names of punk bands but potentially harmful microorganisms. A stop in Yonkers Photo Credit: NYC DEP The water makes another stop on its southerly voyage to the city: Hillview Reservoir in Yonkers. The DEP says the reservoir serves three critical functions. First, it balances daily demand (water consumption peaks twice during the day, in the morning and at night when people are home); second, water undergoes additional disinfection. And third, the reservoir serves to elevate the water so that when it does continue on, gravity propels it with enough force to flow into homes. Into the city’s tunnels and mains Photo Credit: DEP From the aqueducts, water is distributed throughout the city via three tunnels -- No. 1 was put into service in 1917 and No. 2 has been in service since 1936. Tunnel No. 3, pictured, began serving the Bronx and upper Manhattan in 1998, and an extension into lower Manhattan was activated in 2013. Construction, which began in 1970 at a cost of about $5 billion, continues on the Brooklyn and Queens portions. Water then gets routed to distribution mains and then ... Drink up Photo Credit: iStock Finally, the water arrives in your home. If your building is less than six stories high, gravity does all the work. If not, then pumps in your building will help to move the water to the top floors. To maintain quality, testing is done at nearly 1,000 sampling stations around the city. How good is the water that comes out of your faucet? Here's one way to look at it: The city is only one of five big municipalities that is allowed by the federal government to supply unfiltered water. If that's not enough, the DEP releases a yearly Water Quality Report offering information on the water supply. You can read the full 2017 report at nyc.gov/html/dep/pdf. By Cristian Salazar with amNY.com staff Share on Facebook Share on Twitter More on this topic NYCurious: Answers to your burning questions about the cityYou have questions; we have answers. Comments We're revamping our Comments section. Learn more and share your input."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:78888c43-3a90-4edc-a753-190ff8157b60>","<urn:uuid:b643e559-7654-457e-a0f0-8a6a4c3f275c>"],"error":null}
{"question":"Could you detail the specific benefits of selenium and copper found in Chia seeds for human health?","answer":"Selenium in Chia seeds acts as a potent antioxidant that helps prevent inflammation and boosts immune system function. Copper helps the body utilize iron, maintains the health of bones, connective tissues, and skin, and supports normal thyroid gland function.","context":["What are vitamins and minerals?\nVitamins and minerals are considered essential nutrients because they perform hundreds of vital roles that keep our bodies healthy. They help shore up bones, heal wounds and bolster our immune system. They also convert food into energy, and repair cellular damage.\nVitamins and Minerals are often called Micronutrients because our bodies only need tiny amounts of them however failing to get even these small quantities virtually guarantees disease and illness.\nWhich vitamins and minerals are found in Chia seed?\nChia is full of vitamins and minerals, and includes high levels of all the following:\nImportant for bone and teeth structure, helps with blood clotting and assists with cellular processes.\nInvolved in red blood cell formation and the transportation and utilisation of oxygen.\nZinc aids in the metabolism of proteins, carbohydrates and fats. It helps to heal wounds, assists the immune system and is needed for building cells.\nSelenium is a potent antioxidant that helps prevent inflammation, as well as boosting the immune system function.\nCopper is a mineral that helps the body utilise iron. It maintains the health of bones, connective tissues and skin. It also helps the thyroid gland function normally.\nManganese assists your body to utilise many key nutrients, including biotin, thiamine and vitamin C. It maintains normal sugar levels, protect cells from free radical damage and supports bone health.\nVitamin A is essential for healthy vision, but is also necessary for keeping the immune system working efficiently, maintaining skin tissues and protecting fertility.\nVitamin B1 (Thiamine) forms a co-enzyme essential for the conversion of carbohydrates into energy.\nIt is required for the conversation of carbohydrates to energy, it also promotes healthy skin and eyes as well as normal nerve functions.\nAs with all B vitamins, Niacin helps the body to convert food (carbohydrates) into fuel (glucose), which is used to produce energy. These B vitamins, often referred to as B complex vitamins, also help the body use fats and protein. B complex vitamins are needed for healthy skin, hair, eyes, and liver. They also help the nervous and digestion system function properly.\nVitamins C helps with the growth and repair of our bodies cells, promotes healthy blood vessels, gums and teeth.\nVitamin E is another nutrient that is a potent antioxidant. It protects tissues against free radical damage and it helps in normal red blood cell formation.\nFolic Acid (Vitamin B9)\nIs essential in the formation of DNA and is necessary for red blood cell manufacture.\nInvolved in the metabolism of fats, proteins and carbohydrates. It helps in the manufacture of hormones and antibodies which help fight infection.\nChia is famous for its phytonutrients, plant chemicals that contain protective and disease preventing compounds. Phytonutrients founding Chia include quercetin, kaempferol, myricetin, chlorogenic acid and caffeic acid. Their role is to protect the plant from disease, injuries, insects, drought, excessive heat, ultraviolet rays and poisons or pollutants in the air or soil. They prevent disease and have been shown to ward off at least four of the leading causes of modern death in Western countries, including cancer, diabetes, cardiovascular disease and hypertension.Return to top of page"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:f225e378-ba77-49e9-8ffc-934ae9f834ca>"],"error":null}
{"question":"I'm planning to modernize our industrial control systems. What are the benefits of implementing IIoT for predictive maintenance, and what are the key security challenges that need to be addressed when integrating these new technologies?","answer":"IIoT implementation in predictive maintenance enables improved data aggregation, predictive analysis, and machine-to-machine communication, allowing for better monitoring and control of industrial systems like battery performance tracking. However, this modernization comes with significant security challenges. These include technology fragmentation complications due to different operating systems and varying patch schedules, difficulty in M2M and IoT application development requiring specialized skills, and challenges in integrating legacy systems with new protocols. Additionally, each IoT device must be properly secured to prevent network vulnerabilities that could lead to unauthorized system changes, compromised safety controls, or manipulation of operational data.","context":["Applied Data Science: Solving a Predictive Maintenance Business Problem\nThe use case involved is to predict the end life of large industrial batteries, which falls under the genre of use cases called preventive maintenance use cases.\nFormulating the Predictive Problem : Connecting the dots……\nTo help formulate the predictive problem, let us revisit the business problem we have at hand and then connect it with the data points which we have at hand. The predictive problem requires us to predict two things\n- Which battery will fail &\n- Which period of time in future will the battery fail.\nSince the prediction is at a battery level, our unit of reference for formulating the predictive problem is individual battery. This means that all the variables which are present across the multiple data sets have to be consolidated at the individual battery level.\nThe next question is, at what period of time do we have to consolidate the variables for each battery ? To answer this question, we will have to look at the frequency of data collection for each variable. In the case of our battery data set, the data points for each of the variables are capture at different intervals. In addition the volume of data collected for each of those variables at those instances of time also vary substantially.\n- Conductance : One reading of a battery captured once every 3 days.\n- Voltage & Temperature : 4-5 readings per battery captured every day.\n- Discharge : A set of reading captured every second at different intervals of a day once every 3 months (approximately 4500 – 5000 data points collected in a day).\nSince we have to predict the probability of failure at a period of time in future, we will have to have our model learn the behavior of these variables across time periods. However we have to select a time period, where we will have sufficient data points for each of the variables. The ideal time period we should choose in this scenario is every 3 months as discharge data is available only once every 3 months. This would mean that all the data points for each battery for each variable would have to be consolidated to a single record for every 3 months. So if each battery has around 3 years of data it would entail 12 records for a battery.\nAnother aspect we have to look at is how 3 months of data points for a battery can be consolidated to make one record corresponding to each variable. For this we have to resort to some suitable form of consolidation metric for each variable. What that consolidation metric should be can be finalized after exploratory analysis and feature engineering . We will deal with those aspects in detail when we talk about exploratory analysis and feature engineering phases.\nThe next important point which we have to deal with would be the labeling of the response variable. Since the business problem is to predict which battery would fail, the response variable would be classifying whether a record of a battery falls under a failure class or not. However there is a lacunae in this approach. What we want is to predict well ahead of time when a battery is likely to fail and therefore we will have to factor in the “when” part also into the classification task. This would entail, looking at samples of batteries which has actually failed and identifying the point of time when failure happened. We label that point as “failure point” and then look back in time from the failure point to classify periods leading to failure. Since the consolidation period for data points is three months, we can fix the “looking back” period also to be 3 months. This would mean, for those samples of batteries where we know the failure point, we look at the record which is one time period( 3 months) before failure and label the data as 1 period before failure, record of data which corresponds to 6 month before failure will be labelled as 2 periods before failure and so on. We can continue labeling the data according to periods before failure, till we reach a comfortable point in time ahead of failure ( say 1 year). If the comfortable period we have in mind is 1 year, we would have 4 failure classes i.e 1 period before failure, 2 periods before failure, 3 periods before failure and 4 periods before failure. All records before the 1 year period of time can be labelled as “Normal Periods”. This labeling strategy will mean that our predictive problem is a multinomial classification problem, with 5 classes ( 4 failure period classes and 1 normal period class).\nThe above discussed, labeling strategy is for samples of batteries within our data set which have actually failed and where we know when the failure has happened. However if we do not have information about the list of batteries which have failed and which have not failed, we have to resort to intense exploratory analysis to first determine samples of batteries which have failed and then label them according to the labeling strategy discussed above. We can discuss about how we can use exploratory analysis to identify batteries which have failed, in the next post. Needless to say, the records of all batteries which have not failed, will be labelled as “Normal Periods”.\nNow that we have seen the predictive problem formulation part, let us recap our discussions so far. The predictive problem formulation step involves the following\n- Understand the business problem and formulate the response variables.\n- Identify the unit of reference to which the business problem will apply ( each battery in our case)\n- Look at the key variables related to the unit of reference and the volume and velocity at which data for these variables are generated\n- Depending on the velocity of data, decide on a data consolidation period and identify the number of records which will be present for the unit of reference.\n- From the data set, identify those units which have failed and which have not failed. Such information will generally be available from past maintenance contracts for each units.\n- Adopt a labeling strategy for both the failed units and normal units. Identify the number of classes which will be applied to all records of the units. For the failed units, label the records as failed classes till a convenient period( 1 year in this case). All records before that period will be labelled the same as the units which have not failed ( “Normal Periods”)\nWrapping up till we meet again\nSo far we have discussed the initial two phase of a data science project . The first phase entails defining the business problem and carrying out the business discovery. In the next phase, which is the data discovery phase, we align the available data points to the business problem and then formulate the predictive problem. Once we have a clear understanding of how the predictive problem have to be formulated our next task will be to get into exploratory analysis and feature engineering phases. These phases and the subsequent phases would be dealt in detail in the next post of this series. Watch out this space for more.\nBio: Thomas Joseph is Senior Data Scientist at Aspire Systems, working on growing the Data Science footprint and enabling superior delivery.\nOriginal. Reposted with permission.","Industrial Control Systems (ICS) are found everywhere–from automated machines that manufacture goods to an office building’s cooling system.\nPreviously, it was standard that ICS were based on specific OS and specific communication protocols. However, in recent years, system development costs have been reduced and productivity has been improved by implementing network connection based on general purpose OS and standard communication protocols.\nTo compete in today’s market-driven economy, businesses and organizations opt for efficient control systems that can automatically manage processes. ICS can be found in manufacturing, processing facilities, and even power plants–which play a vital role in running a country. On the other hand, the increased efficiency that ICS introduce also presents new problems on security. In reality, threat actors have much to gain when they attack such companies. A successful attack on ICS has serious impact on any organization. Some of these effects include operational shutdowns, damaged equipment, financial loss, intellectual property theft, and substantial health and safety risks.\nMotivations for attacking ICS\nThreat actors have different motives when choosing an enterprise to target. When carrying out attacks, these threat actors are often motivated by financial gain, political cause, or even a military objective. Attacks may be state-sponsored or they could also come from competitors, insiders with a malicious goal, and even hacktivists.\nOne of the earliest examples of an ICS attack happened in 2005 when 13 DaimlerChrystler U.S. car manufacturing plants went offline for nearly an hour. The main cause was Zotob PnP worm infections that exploited a Windows Plug and Play service. The total downtime has resulted in a backlog in production costing the company thousands of dollars. While the attack was not linked to an individual or a cybercriminal group, cybercriminals may also be hired by competitors who have much to gain from the damage caused by an attack.\nHow are ICS attacked?\nThe first stage of an attack against ICS usually involves reconnaissance that allows the attacker to survey the environment. The next step would be to employ different tactics that will help attackers gain a foothold in the target network. The strategies and tactics at this point are highly similar to a targeted attack. To launch a malware, an attacker will make use of all the possible vulnerabilities and specific configurations of an ICS. Once these vulnerabilities have been identified and exploited, the effects of an attack can cause changes to certain operations and functions or adjustments to the existing controls and/or configurations.\nThe complexity of launching an attack on ICS depends on different factors, from the security of the system to the intended impact (e.g., a denial-of-service attack that disrupts the target ICS is easier to achieve than manipulating a service and concealing its immediate effects from the controllers). While there are already a lot of ways for attackers to damage an ICS, new tactics will continue to emerge as more and more devices are introduced to every ICS environment.\nWhat vulnerabilities are exploited in ICS?\nSince all ICS deal with both Information Technology (IT) and Operational Technology (OT), grouping vulnerabilities by categories assists in determining and implementing mitigation strategies. The National Institute for Standards and Technology’s (NIST) security guide for ICS divides these categories into issues related to policy and procedure, as well as vulnerabilities found in various platforms (e.g., hardware, operating systems, and ICS applications), and networks.\nPolicy and Procedure Vulnerabilities\n- Inadequate security architecture and design\n- Few or no security audits of the ICS environment\n- Inadequate security policies for the ICS\n- Lack of ICS specific configuration change management\n- No formal ICS security training and awareness program\n- Lack of administrative mechanisms for security enforcement\n- No ICS specific continuity of operations or disaster recovery plans\n- No specific or documented security procedures were developed from the security policies for the ICS environment\nPlatform Configuration Vulnerabilities\n- Data unprotected on portable devices\n- Default system configurations are used\n- Critical configurations are not stored or backed up\n- OS and application security patches are not maintained\n- OS and application security patches are implemented without exhaustive testing\n- Inadequate access control policies such as ICS users have too many or two few privileges\n- OS and vendor software patches may not be developed until after security vulnerabilities are discovered\n- Lack of adequate password policy, accidental password disclosures, no passwords used, default passwords used, or weak passwords used\nPlatform Hardware Vulnerabilities\n- Inadequate testing of security changes\n- Lack of redundancy for critical components\n- Unsecure remote access of ICS components\n- Lack of backup power from generators or Uninterruptible Power Supply (UPS)\n- Dual network interface cards to connect networks\n- Inadequate physical protection of critical systems\n- Undocumented assets connected to the ICS network\n- Unauthorized personnel have physical access to equipment\n- Loss of environmental control could lead to overheating of a hardware\n- Radio frequency and electromagnetic pulses (EMP) cause disruptions and damage to circuitry\nPlatform Software Vulnerabilities\n- Denial-of-Service (DoS) attack against ICS software\n- Intrusion detection/prevention software not installed\n- Installed security capabilities are not enabled by default\n- ICS software could be vulnerable to buffer overflow attacks\n- Mishandling of undefined, poorly defined, or “illegal” network packets\n- Unnecessary services are not disabled in the OS and could be exploited\n- No proper log management, which makes it difficult to trace security events\n- The OLE for Process Control (OPC) communications protocol is vulnerable to Remote Procedure Call (RPC) and Distributed Component Object Model (DCOM) vulnerabilities\n- Use of unsecure industry-wide ICS protocols such as DNP3, Modbus, and Profibus\n- Inadequate authentication and access control for configuration and programming software\n- Many ICS communications protocols transmit messages in clear text across the transmission media\n- ICS software and protocols’ technical documentation are easily available and can help adversaries plan successful attacks\n- Logs and endpoint sensors are not monitored real-time and security breaches are not identified quickly\nMalware Protection Vulnerabilities\n- Anti-virus software not installed\n- Anti-virus detection signatures not updated\n- Anti-virus software installed in the ICS environment without exhaustive testing\nNetwork Configuration Vulnerabilities\n- Weak network security architecture\n- Passwords are not encrypted in transit\n- Network device configurations are not properly stored or backed up\n- Passwords are not changed regularly on network devices\n- Data flow controls e.g. Access Control Lists (ACL), are not used\n- Poorly configured network security devices e.g. incorrectly configured rules for firewalls, routers, etc.\nNetwork Hardware Vulnerabilities\n- Lack of redundancy for critical networks\n- Inadequate physical protection of network equipment\n- Loss of environmental control could lead to hardware overheating\n- Noncritical personnel have access to equipment and network connections\n- Unsecured USB and PS/2 ports that can be used to connect unauthorized thumb drives, keyloggers, etc.\nNetwork Perimeter Vulnerabilities\n- No network security perimeter defined\n- Firewalls are nonexistent or are incorrectly configured\n- ICS control networks used for non-control traffic e.g. web browsing and email\n- Control network services are not within the ICS control network e.g. DNS, DHCP are used by the control networks but are often installed in the corporate network\n- Critical monitoring and control paths are not identified\n- Authentication of users, data, or devices is substandard or nonexistent\n- Many ICS communications protocols have no integrity checks built-in making it easy for adversaries to manipulate communications undetected\n- Standard, well-documented protocols are used in plain text e.g. sniffed Telnet, FTP traffic can be analyzed and decoded using protocol analyzers\nWireless Connection Vulnerabilities\n- Inadequate authentication between clients and access points\n- Inadequate data protection between clients and access points\nNetwork Monitoring and Logging Vulnerabilities\n- No security monitoring of the ICS network\n- Inadequate firewall and router logs make it difficult to trace security events\nPossible weaknesses in ICS network\nEvery ICS environment may contain weaknesses depending on their configuration and their purpose. The size of an ICS environment can also be a factor–the bigger the environment, the greater the chance for an error to occur. An ICS environment that replaced its legacy system with modern systems and introduced tools like Industrial Internet of Things (IIoT) devices may also have more weaknesses for threat actors to exploit.\nIndustrial IoT and How It Affects ICS\nAs ICS continue to modernize, an increasing number of Internet of Things (IoT) devices are introduced to improve productivity and enhance system control. With the use of related IoT devices; process controls, data monitoring, and communication with other systems are made simpler. However, there are risks involved when smart devices are used for such tasks.\nIIoT incorporates machine learning and big data analysis. It also harnesses sensor data, machine-to-machine (M2M) communication, and automation technologies that have previously existed in the industrial setting. IIoT can perform tasks such as data aggregation, predictive analysis, prescriptive analysis, data value addition, and even the creation of new business models.\nSimilar to how the introduction of smart phones was followed by the rise of vulnerabilities and malware related to the platform, integrating Human Internet of Things (HIoT) and IIoT devices may create similar problems. In fact, managing IoT devices in the ICS environment can create major challenges in security, as each device will have to be properly defended and secured. Not applying adequate security leaves the entire ICS ecosystem highly vulnerable to attacks.\nWith the use of IIoT there are also a few unique challenges to overcome:\n- Technology fragmentation complicates network processes. As devices of different and/or independent operating systems are used, the varying patching schedules may be difficult to address. An example of this is when an ICS uses a mix of legacy systems and new software. Not only will the two not communicate properly, the vulnerabilities found in unpatched legacy systems may also be used by threat actors to break into an ICS network.\n- Machine to Machine (M2M) and IoT application development is difficult. Unlike manufacturing HIoT, which are mass produced, the development of M2M and IoT applications for ICS requires special skill sets on hardware and software development, IT, and communications.\n- Legacy systems and legacy communication protocols are still widely used in industrial environments. An example of legacy systems is Windows 3.1, which still runs the program DECOR (used in Airplane takeoff and landing). Then there are also legacy communications protocols that include PROFIBUS, which is still widely used today. These systems have to be integrated via standards-based protocol gateways to send and receive data and commands easier.\nAlthough hacking IoT devices may be challenging, threat actors behind targeted attacks are both knowledgeable and persistent–which could lead to successful breaches in a target’s network. In addition to this, device loss is also a major cause of data breach. One misplaced device may give cybercriminals the necessary access to penetrate the target’s network.\nPotential Impact on ICS Components following Cyber Attacks\nThe impact of cyber attacks on industries using ICS depends on the target’s nature of operation or the motivation of cybercriminals pursuing the attack. Every effect listed below may be felt by a target’s internal, as well as external, clientele.\n- Changes in a system, an operation system, or in application configurations. When systems are tampered with, it may produce unwanted or unpredictable results. This may be done to mask malware behavior or any malicious activity. This may also affect the output of a threat actor’s target.\n- Change in Programmable Logic Controllers (PLC), Remote Terminal Units (RTU), and other controllers. Similar to a change in systems, a change in controller modules and other devices can lead to damaged equipment or facilities. This can also cause process malfunction and disabled controls over a process.\n- Misinformation reported to operations. This scenario may lead to the implementation of unwanted or unnecessary actions due to wrong information. Such an event can result in a change in the programmable logics. This can also help hide malicious activity, which includes the incident itself or the injected code.\n- Tampered safety controls. Preventing the proper operation of fail safes, and other safeguards puts the lives of employees, and possibly even external clients, at risk.\nLike it? Add this infographic to your site:\n1. Click on the box below. 2. Press Ctrl+A to select all. 3. Press Ctrl+C to copy. 4. Paste the code into your page (Ctrl+V).\nImage will appear the same size as you see above."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:536519df-dd7a-49e1-8c77-6834d9afe643>","<urn:uuid:a16ccbd6-041d-4489-8a93-f4173871c8d6>"],"error":null}
{"question":"How do modern group activities balance face-to-face communication needs with accessibility requirements, and what role does technology play in both aspects?","answer":"Face-to-face communication in group activities is crucial in the cyber age for building real community connections, with activities designed to help members appreciate similarities and differences while encouraging individual contributions. Technology plays a dual role - while it's essential for team-building activities, requiring proper preparation of equipment like cameras, microphones, and projectors, it also serves as a tool for accessibility. Communication must be facilitated through multiple technological means, including web sites with accessible design practices, captions for audio-visual presentations, and assistive listening devices. These technological solutions help bridge communication gaps for participants with disabilities while supporting the overall goal of effective group interaction and participation.","context":["In this cyber age, members of groups sometimes need opportunities to build a real sense of community and learn to communicate with one another face to face. The activities in this book can be a great place to start. They help groups grow by helping members get to know and appreciate each other’s similarities and differences, engaging participants in topics and issues relevant to the group, and encouraging individual contributions. First, though, let’s look at some tips for implementing effective team-building activities. The suggestions offered in this chapter, while specific to the activities provided in this book, can be adapted to any type of team-building activity.\nFive Things a Facilitator Should Know\nEven though a given activity is intended as a tool for building community, it can quickly turn into a disaster that leaves group members wanting to withdraw from the process. When the facilitator is not properly prepared, or does not believe in the process, participants will sense it. Thus, in order for growth activities to be successful, you as the facilitator should know your purpose, your audience, your environment, the needed equipment and supplies, and when to change plans to adapt to the participants.\nKnow Your Purpose\nWhile the overall purpose of all of these activities is to improve teamwork within your group, it is vital to select specific focuses to aid in the process. By clearly defining the purpose of an activity, you increase the likelihood that your group will begin to function more effectively and cohesively. Do you want the people in your group to learn each other’s names? Do you want them to learn how to think creatively? Do you want to introduce a specific topic for discussion? Choosing a specific purpose for an activity gives you and the participants more respect for the process and increases the likelihood that the group will become more cohesive because there is a clearly targeted purpose to the activity. Thus each activity presented in this book hinges on a clearly defined purpose to help you target specific areas that your group needs to address.\nKnow Your Audience\nWill the participants include a lot of new people, or do they generally know each other already? When a group includes new people, it is best to select activities that allow participants to get to know one another. Activities such as Ringtone Relay, A Picture Is Worth a Thousand Words, and What’s on Your Playlist? offer great ways to help new groups break the ice. On the other hand, groups where members know each other’s names and are familiar with each other’s tendencies in various situations might benefit more from activities such as Y3W, Self-Portraits, or Mirror, Mirror, on the Wall because these activities require a greater depth of knowledge about group members and increased self-disclosure.\nOne of the unique aspects of the team-building activities described in this book is that they were designed to be as inclusive as possible. Rather than ask group members to swing on ropes, lift objects, or climb to the top of objects, the activities mostly call for participants to think together and collectively solve problems or create solutions. If you have group members with physical disabilities, ask them how you can help them be involved; for most of these activities, a quick conversation on the topic is all you need in order to promote optimal participation. Remember, the point is to help people feel included—like they belong.\nKnow Your Environment\nSeveral important questions arise here. Will you have enough space for the activity? For example, if an activity requires a large open area, make sure that there is adequate space for people to move around (e.g., without bumping into chairs or people). Also, how long will the activity take? Make sure it will fit into the time period you have available. Does the activity work best for a large group or a small group? We do not list a maximum size for the activities discussed in this book; rather, we suggest that your group be split into smaller groups ranging from 2 to 5 members each. Understanding your group’s needs, as well as the suggested group sizes, will help you determine the best location for a given activity.\nKnow What Supplies You Need\nWe all have technology-related horror stories to share. Whether it was the big presentation that didn’t work because of the wrong version of Microsoft® Office® or the vital e-mail that went nowhere due to a faulty Internet connection, we have all had our struggles with technology. As a result, we cannot overemphasize the importance of making sure that you have the necessary equipment and that it is all working correctly. Make sure that you have everything before the activity begins. Are the camera batteries charged? Is the Internet connection working properly? Do you have all the cords for the LCD projector? For example, if you are going to do Ringtone Relay and are working with a large group, make sure that the microphone is working properly and can pick up a cell phone’s ringtone. Each activity in this book includes a list of supplies, but it falls to you as facilitator to make sure that all equipment is working properly before you need to use it.\nKnow When to Change Your Plans\nWatch your participants. If they are not having fun or don’t seem to be learning the intended lesson, then it is time to break up the activity and move on to something else. The fact that an activity didn’t work does not mean that you can’t try it again later. If an activity doesn’t seem to work well, ask the participants—at a later time—what made the activity difficult and what might have made it better. Addressing any concerns during an activity can take away from the flow, and any concerns regarding specifics about the activity or the manner in which it was facilitated would be best shared at a later time. The activities presented in this book are diverse, and some will work better than others with any given group. Your task as facilitator is to determine which ones are right for each group you work with. Just don’t give up! Keep talking with each group and keep trying new activities to help group members learn how to work together.\nThis is an excerpt from Team-Building Activities for the Digital Age.","Ensuring access to meetings, exhibits, performances, tours, festivals, and other types of events requires forethought and preparation. Such events are often held in locations, including outdoor venues, which present challenges related to facilities and terrain. Additionally, there are issues, such as communication or transportation, which may need to be addressed if people with disabilities are to participate in meaningful ways.\nDifferent types of events may also entail different approaches to accessibility. For example, some events are open to the public at large, with no pre-registration required. When planners have no idea who is going to show up, they must prepare for everyone. Other events are for specific, known audiences, and planners can respond to individual needs in a more focused way.\nCommunication and Interaction\nAny type of event involves communication, ranging from advertisements and promotions to presentations and speeches. Promotional information is often disseminated through a variety of media, including radio and television broadcasts, web site postings and e-mail messages, newspapers and periodicals, flyers, and posters. Throughout the course of an event, the multiplicity continues, with speech, audio-visual presentations (slides, movies, etc.), printed materials, signs, and maybe a few banners or flags thrown into the mix.\nEvent planners know that using multiple communication methods helps get the word out, facilitates activities and interaction, and reinforces messages and lessons for diverse audiences. Accessible features simply add more tools to the “multiplicity” toolbox. For example, captions can provide access to the “audio” in an audio-visual presentation for people who are deaf or hard of hearing; audio descriptions can provide access to the “visual” for those who are blind or have low vision.\nIt is important to remember that web sites are a form of communication, and web pages often include both visual and audible components, and sometimes interactivity as well (such as online registration forms). Using accessible web design practices will ensure that online features and opportunities are available to web-surfers with disabilities.\nIncluding information about accessibility features and options in announcements and promotional materials can be helpful for both event planners and participants. For example, if assistive listening devices (ALDs) are always on hand at the facility where an event will be held, then including that information in promotional materials will let potential attendees know that they don’t need to call ahead and request them to make sure they will be available.\nIt’s also a good idea to inform people about barriers that can not be overcome. For example, if a tour of an historic home will include an opportunity to climb down a narrow set of steps into an old root cellar, then that information may be of interest to people with disabilities who may not be able to do that. They may still choose to go on the tour to see and do all they can, but knowing what limitations to expect will help people make choices and plans, and avoid unpleasant surprises.\nWhere registration or advanced notice is required to participate in an event, promotional and registration materials should include contact information and a deadline for requesting individualized accommodations that might not otherwise be provided. Interpreters and materials in accessible formats, such as Braille or large print, are examples of things that could be provided on an as-needed basis; a reasonable deadline is needed to ensure there is enough time to order or produce materials, or make necessary arrangements for services.\nPlanners should remember to find out if participants who may not be required to register, such as presenters, performers, or exhibitors, have any disability-related needs.\nAlso, presenters, vendors, guides, or others who may interact with attendees should be informed about accessible elements or services (e.g., where elevators are located, or how to obtain receivers for the assistive listening system) so they can respond to questions or direct attendees appropriately.\nPresenters and other workers should also be given information, training, and support to ensure that they use accessible practices (e.g., describing visual presentation elements for the benefit of participants who are blind, or retrieving items that are out of reach for wheelchair users).\nSites, Facilities, and Vehicles\nWhile it may be difficult (or impossible) to find a “perfect” site for an event, accessibility should be high on the list of criteria to be considered. Whenever possible, site assessments should be conducted by professionals or people with extensive knowledge of accessibility standards and understanding of usability issues.\nIt is important to assess not only an actual facility (for example, a hotel or auditorium), but the surrounding area as well. Consideration should be given to how the site is situated in relation to various modes of transportation that people might need to use. Airports, rail stations, bus systems, taxi or shuttle services, or public parking may need to be checked for accessibility.\nAlso, if people are likely to walk to and from public transportation stops, or to walk to nearby restaurants, shops, or attractions during the course of an event, the neighborhood should be checked for “walkability.” Steep sidewalks (or no sidewalks at all), lack of curb cuts, uneven surfaces, and other barriers can adversely affect people who have a variety of mobility limitations. Low hanging tree branches and other protruding objects, reflecting pools and fountains without walls or edges, and poorly designed street crossings or circulation routes can make things difficult, if not downright dangerous, for people with vision impairments.\nWhen setting up areas where event activities will take place, arrangements should allow enough space so that people using wheelchairs or other mobility aids can maneuver around temporary elements like booths, signs, or tents. Displays and exhibits should be designed so that people can see and/or reach items from a seated position.\nWherever possible, seating arrangements for training sessions, performances, or dining should facilitate opportunities for integration by providing wheelchair seating spaces in more than one location. Dispersed wheelchair seating also makes it easier to ensure that wheelchair users are able to take advantage of the full range of available options, such as different lines-of-sight.\nWhen transportation is offered as part of an event (e.g., a shuttle from a remote parking lot to an event area), vehicles must be accessible, or other suitable options must be available (e.g., accessible parking located adjacent to the event area).\nFor events that last longer than a few hours, it may be a good idea to find a suitable area that can serve as a “relief” location for service animals. Signs can be posted, and directions and information can be disseminated and announced so that everyone who wants to find the area (or stay away from the area!) will know where it is.\nQuick Facility Fixes\nThere are a number of things that can be done fairly easily, some temporarily, that can enhance accessibility and participation for people with disabilities.\nParking: Where accessible parking is inadequate, or simply non-existent, spaces can be designated temporarily. Pavement tape, barricades, or the ever-popular orange traffic cones can serve to define space for parking and access aisles; temporary signs can be posted. Accessible parking should be located on surfaces that are as level and stable as possible, and connect to accessible routes that lead to entrances, transportation stops, or event areas.\nRamps: Portable ramps can be used to overcome curbs or steps; they must be securely placed or installed so that they do not shift when used. Ramps with drop-offs should always have curbs to keep people from going over the edge.\nDoors: Installing off-set (or swing-away) hinges can add a couple of inches of clear space at a narrow door. Add-on lever hardware can be attached to round doorknobs to make them easier to operate. Where doors are heavy, it may be possible to simply prop them open or even remove them for the duration of an event.\nRoutes/surfaces: There are a variety of products that can be used to create temporary accessible surfaces. These products, including modular or roll-out materials, work well in outdoor environments where natural surfaces consist of grass, sand, or other loose materials.\nDetectable warning devices: Detectable warning devices, such as planters or other heavy objects, can be placed on the floor beneath hazardous protruding objects (e.g., wall-mounted fixtures that project more than four inches) so that people who are blind or have low vision will avoid them.\nSigns: Good signage is often a critical communication component at an event, and can be even more important for people with disabilities, who may need to use alternate routes or find accessible elements. If a facility does not have good general signage in place, consider adding some temporary signs (e.g., “Elevators [with a directional arrow]”). “Event-specific” signs may be needed as well (e.g., “Festival Parking / ACCESSIBLE PARKING ONLY IN THIS LOT). Signs should be easy to see and read, with non-glare finishes, simple lettering, and good contrast between characters and background.\nWhen all is said and done, there may still be a need for assistance or accommodation on an individual level. But then, a little human interaction may be one of the reasons we planned the event in the first place.\nThis article first appeared in the Winter 2008 issue of ADA in Focus, a publication of the Mid-Atlantic ADA Center. The Center is administered by TransCen. Inc. and funded by the National Institute on Disability and Rehabilitation Research of the U.S. Dept. of Education (Grant # H133A060085). The opinions contained in this publication are those of the grantee and do not necessarily reflect those of the Department of Education."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:38a037b5-6da7-44d6-98ce-f43b1c3c6870>","<urn:uuid:24ce697d-36e2-43d2-a12c-a100cb6a2c80>"],"error":null}
{"question":"How do exothermic reactions affect entropy differently at high versus low temperatures? Please provide a detailed explanation.","answer":"Exothermic reactions (negative ΔH) always increase the entropy of the surroundings, but their impact varies with temperature. At lower temperatures, the energy transfer from exothermic reactions has a more significant effect on the surroundings' entropy. For the overall spontaneity, we must consider both ΔH and ΔS according to the Gibbs equation (ΔG = ΔH - TΔS). When ΔH is negative and ΔS is positive, the reaction is spontaneous at all temperatures. However, when ΔH and ΔS are both negative, the reaction is only spontaneous at low temperatures, where the enthalpy term dominates over the entropy term.","context":["18.3 Gibbs Free Energy and the Relationship between ΔG, ΔH, & ΔS\nGibbs Free Energy\nGibbs Free Energy is the thermodynamic quantity of a system that is the energy available to do work. It is used to determine whether or not a reaction is spontaneous. Simply put, spontaneous processes are those that occur 'naturally,' and nonspontaneous processes are those that do not. What I mean by 'naturally' is that a reaction will occur in a system without the net influx of free energy from the surroundings. For example, ice at 10oC and 1atm will melt spontaneously whereas ice at -10oC and 1atm will not.\nWhat we observe is that during a spontaneous process a system will 'use up' some of its free energy and therefore the change in Gibbs free energy is negative (ΔG<0) for a spontaneous process. Likewise the change in Gibbs free energy is positive (ΔG>0) for a nonspontaneous process and requires the input of free energy from the surroundings. Finally, the change in Gibbs free energy is zero (ΔG=0) for a reaction that has reached equilibrium. These are summarized in the table below.\n|MEANING OF ΔG VALUES|\nΔG = ΔH - TΔS\nThe change in Gibbs free energy (ΔG) for a system depends upon the change in enthalpy (ΔH) and the change in entropy (ΔS) according to the following equation:\nΔG = ΔH - TΔS\nΔGo = ΔHo - TΔSo\nThe relationship holds true under standard conditions or under non-standard conditions. We can take away a few generalizations regarding when a reaction will be spontaneous (i.e. when ΔG<0).\nA negative value for ΔH and a positive value for ΔS both contribute toward achieving a negative value for ΔG and a spontaneous reaction. And for a reaction to even have a chance of being spontaneous at least one of these (negative ΔH or positive ΔS) must be true.\nThe first term in the calculation of ΔG is ΔH, the enthalpy change, and for many reactions/conditions this is the dominant term in the equation. This is why we often anticipate that most exothermic reactions (negative ΔH) will be spontaneous and most endothermic reactions (positive ΔH) will not, but we cannot say this with absolute certainty.\nThe second term in the calculation of ΔG is -TΔS. ΔS is typically significantly smaller than ΔH explaining why ΔH is often the dominant term in the equation. But temperature is also a part of this term and this term, and ΔS specifically, have an increasing importance as the temperature is increased.\nWe can summarize the following regarding when a reaction is spontaneous.\nIf ΔH is Negative and ΔS is Positive\nIf ΔH is negative and ΔS is positive, ΔG will always be negative and the reaction is spontaneous at all temperatures.\nIf ΔH is Positive and ΔS is Negative\nIf ΔH is positive and ΔS is negative, ΔG will never be negative and a reaction will not be spontaneous at any temperature, or you could say that the reverse reaction is spontaneous at all temperatures.\nIf ΔH and ΔS are Both Negative\nIf ΔH and ΔS are both negative, ΔG will only be negative below a certain threshold temperature and we say that the reaction is only spontaneous at 'low temperatures.'\nIf ΔH and ΔS are Both Positive\nIf ΔH and ΔS are both positive, ΔG will only be negative above a certain threshold temperature and we say that the reaction is only spontaneous at 'high temperatures.'\nThese four possibilities are summarized in the following table:\n|-||+||-||Spontaneous at All Temperatures|\n|+||-||+||Nonspontaneous at All Temperatures|\n|-||-||+||Spontaneous at Low Temperatures|\n|+||+||-||Spontaneous at High Temperatures|\nFor a review of Enthalpy: 5.1 The First Law of Thermodynamics, Enthalpy, and Phase Changes\nFor a review of Entropy: 18.2 Entropy\nThe Relationship between ΔH and ΔS\nThere is a relationship between ΔH and ΔS for a system at one of its phase change temperatures, (i.e. melting/freezing or boiling point) students are often required to know. Take for example boiling water at 100oC. At the boiling temperature you actually have liquid and gaseous water in equilibrium with each other. As for any system at equilibrium ΔG=0 leading to the following derivation:\nΔG = ΔH - TΔS\n0 = ΔH - TΔS\nTΔS = ΔH\nIt is from this last expression that undergraduate students are presented with equations that relate the freezing temperature to the ΔH and ΔS of fusion and the boiling temperature to the ΔH and ΔS of vaporization:\nOne could also rearrange the equation to solve for temperature which could be used to solve for a freezing or boiling point. And for reactions in which ΔH and ΔS are either both negative or both positive this expression could also be used to solve for the threshold temperature below which or above which a reaction would be spontaneous.\nOne thing to keep in mind for calculations involving any of these equations is that ΔG and ΔH values are often reported in kJ/mol whereas ΔS values are typically reported in J/K.mol. Make sure to convert so that all units are the same (both kJ or both J...either way) before performing any calculations. Finally, all temperatures should be in Kelvin (the absolute scale) when performing calculations.\nDeriving the Equation for Gibbs Free Energy\nΔG = ΔH - TΔS\nWe've taken a long look at Gibbs Free Energy, its relationship to the change in enthalpy and the change in entropy of a process, and how it can be used to predict the spontaneity of a reaction, but how did Gibbs come up with this? While not something the typical undergraduate is required to know I include it here for the curious mind. Gibbs actually derived his equation for his newly coined \"Gibbs Free Energy\" specifically as a way to determine if/when a reaction is spontaneous. He actually derived it from the 2nd Law of Thermodynamics which states the following:\nFor a spontaneous process the entropy change of the universe is positive.\nWe could also express the 2nd Law as follows:\nFor a spontaneous process, ΔSuniverse > 0\nBut there are two parts to the universe, the system and the surroundings, and we could express the 2nd Law one final time as follows:\nFor a spontaneous process, ΔSsystem + ΔSsurroudings > 0\nThis is where Gibbs started. But measuring quantities for the surroundings is problematic as it includes all the rest of the universe outside of the system being investigated. So Gibbs set out to devise a way to determine the spontaneity of a process based only upon thermodynamic properties of the system alone. For this he needed to define ΔSsurroundings in terms of the system and substitute it back into the 2nd Law. The change in entropy is defined as ΔS = qrev/T.\nFrom this we can derive an expression for ΔSsurroundings:\nΔSsurroundings = ΔHsurroundings / T\nBut the enthalpy increase or decrease of the surroundings is due to the flow of enthalpy to or from the system, and therefore ΔHsurroundings and ΔHsystem are equal in magnitude but opposite in sign: ΔHsurroundings = -ΔHsystem. We can substitute this into our definition of ΔSsurroundings.\nΔSsurroundings = ΔHsurroundings / T = -ΔHsystem / T\nThis can now be substituted back into the 2nd Law of Thermodynamics.\nΔSsystem + ΔSsurroudings > 0\nΔSsystem - ΔHsystem / T > 0\nFinally multiplying all terms by -T yields Gibbs Free Energy equation (remember that multiplying or dividing an inequality by a negative number changes the sign).\n-TΔSsystem + ΔHsystem < 0 rearranged ΔHsystem - TΔSsystem < 0\nGibbs now had a condition for spontaneity that relied only on thermodynamic properties of the system and then coined it 'Gibbs Free Energy.'\nΔGsystem= ΔHsystem - TΔSsystem\nAnd therefore we have derived from the 2nd Law of Thermodynamics:\nFor a spontaneous process, ΔHsystem - TΔSsystem < 0\nFor a spontaneous process, ΔGsystem < 0\nAnd there you have it; Gibbs had devised a method of predicting if/when a process is spontaneous based upon thermodynamic properties of the system alone.","2 The First Law of Thermodynamics Energy can neither be created or destroyedThe energy of the universe is constant, but it can change forms.\n3 Energy book keeperFirst Law accounts for energy, but it does not tell us why a particular process occurs in a given direction\n4 Spontaneity DOES NOT MEAN FAST!!! Means that the process occurs without any outside intervention\n5 Energy released or absorbed during a chemical reaction (heat of reaction) is equal to the difference between the potential energy of the products and the potential energy of the reactants.In a chemical reaction; reactants --> productsΔPE = PE products - PE reactantsPE can be thought as heat energy (H)Therefore, ΔH (kJ) = H products - H reactants\n6 When ΔH is negative H products < H reactants and the reaction is exothermic.\n7 When ΔH is positive H products > H reactants and the reaction is endothermic.\n8 Energy released or absorbed by a chemical reaction can be represented by a potential energy diagram.\n9 Activation EnergyThe activation energy is the minimum energy required to start a chemical reaction by providing colliding molecules with enough energy for effective collisions to occur.The activated complex is the short-lived and unstable intermediate species located at the highest of the activation energy.\n10 CatalystsA catalyst provides an alternate reaction pathway, which has a lower activation energy than an uncatalyzed reaction.\n11 Look at Table A-6 Notice the following: Substances are in alphabetical orderΔHf (enthalpy of formation) is in kJ/moleFree elements have a ΔHf = 0(they are not compounds formed from elements)The enthalpy of reaction is equal to the sum of the enthalpies of formation for the products – the sum of the enthalpies of formation for the reactants Σ ΔHr = ΔHf products - Σ ΔHf reactants\n15 Which has more entropy? 1. Solid or gaseous phosphorus 2. CH4(g) or C3H8(g)3. NaCl(s) or NaCl(aq)\n16 Second Law of Thermodynamics In any spontaneous process there is always an increase in the entropy of the universeThe entropy of the universe is constantly increasing\n17 ENTROPY CALCULATIONSIf the reaction increases entropy, ∆S is positive and the reaction is said to be ENTROPY-FAVOREDCalculate the entropy change(∆S) for the following reactionCH4(g) O2(g) CO2(g) H2O(l)\n19 Suniv If it is +, the entropy of the universe is increasing Process is spontaneousIf it is negative, the process is not spontaneous\n20 Change of state H2O(l) H2O(g) What happens to the S of the water? Ssys= +\n21 What about surroundings? Heat is flowing from the surroundings to the systemRandom motion of particles decreasesSsurr = -\n22 Which S controls the situation? DEPENDS ON TEMP Is it spontaneous?Need to look at SunivWhich S controls the situation?DEPENDS ON TEMP\n23 Exothermic Process Always increases entropy of surroundings But, its significance depends on the temp at which the process occursEnergy transfer will be more significant at lower temps\n24 GIBBS FREE ENERGY CH4(g) + 2O2(g) CO2(g) + 2H2O(l) Gibbs free energy (∆G) is a measure of the chemical reaction potential of a systemIf ∆G is negative, the reaction is spontaneousIf ∆G is positive, the reaction is not spontaneousCalculate the change in free energy for the following reactionCH4(g) O2(g) CO2(g) H2O(l)\n25 Gibbs Free Energy ∆H ∆S ∆G Enthalpy and Entropy can be combined to predict reaction spontaneity∆G = ∆H - T∆S∆H∆S∆GComments on Reaction-+Always spontaneous+ or -Spontaneous at high temperaturesSpontaneous at low temperaturesNever spontaneous"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:77dfd088-bfcd-46ad-a6be-48e43e3fc7d5>","<urn:uuid:7f5c0afa-87d0-4ec7-9d8e-3adb2855b1a4>"],"error":null}
{"question":"What are the environmental benefits of modern washing machine design innovations, and what factors determine the optimal location for vertical farming facilities?","answer":"Modern washing machine design innovations, like replacing concrete weights with water-filled containers, could save approximately 44,625 tonnes of carbon dioxide emissions annually and reduce fuel consumption during transport by making machines up to a third lighter. However, this innovation faces practical challenges like space constraints and potential water leakage risks. As for vertical farming facilities, optimal location is determined by several factors: energy infrastructure capacity, proximity to food distribution centers, regional water scarcity, and local climate conditions. While city centers might seem ideal, locations near distribution centers on city outskirts are often more practical due to lower land costs and better logistics. Regions with water scarcity (like Sub-Saharan Africa and Middle East) or extreme climates (like Scandinavian countries) are particularly suitable for vertical farming, especially where conventional agriculture faces challenges.","context":["Washing machines are heavy. This is due to concrete blocks inside. If the drum wasn’t weighted down it would bang violently from side to side, and try to burst up through the lid during spin. Modern washing machines usually have 2 drum weights inside. One on top of the drum, and one either underneath or around the front of the drum.\nNew concept to replace the weights\nI’ve just seen an article on the BBC News website about a new idea to replace concrete weights with plastic containers that can be filled with water. The idea involves replacing the concrete weights with empty plastic containers. The weight would be returned to the washing machine by filling them up with water once delivered to the customer. This would make washing machines up to a third lighter during transport. They estimate it could save around 44,625 tonnes of carbon dioxide emissions a year as well as saving millions on fuel.\nIt sounds like a simple and clever idea. I like the concept. I also love the idea of people thinking of ways to improve things from outside an industry. However, I’m not sure how they will be able to make it work.\nCould plastic devices filled with water replace the concrete weights?\nAccording to the article, drum weights in a washing machine typically weigh around 25Kg (just under 4 stone). So getting rid of this weight is genius apart from one major problem – water isn’t as heavy as concrete. The replacement blocks would have to be a fair bit bigger, but washing machines have never been so short of space inside.\nA litre of water weighs 1 Kg. A typical washing machine would need up to 25 litres of water adding to equal the weight of previous concrete blocks. The picture shows my washing up bowl full of water. I measured out 10 Litres of water so it should weigh 10 Kg.\nTherefore a washing machine with 25 kg of weights inside would need weights capable of holding the equivalent of two and a half washing up bowls of water. Larger capacity drums have forced manufacturers to increase the size of the outer drum. It’s already probably too close to the cabinet and other parts. There needs to be adequate room between the outer tub and other parts as well as the sides of the casing and the lid. These drums can bounce and bang around violently on spin and cause damage. They can’t increase the size of the cabinet to accommodate larger weights. So there’s no spare room.\nWhere there’s a will there’s a way\nIf the savings in carbon dioxide emissions and fuel were overwhelmingly desirable then appliance manufacturers might find a way to make it work. I think major redesigns would be needed. The outer drum could be double skinned to take some of the water. I also think the hollow weights would need to be part of the outer drum’s mould. Attaching plastic boxes to it would be fraught with danger of them coming loose.\nIt’s only since manufacturers changed to a plastic outer drum that extra weights have been needed. Plastic drums are so much lighter than the old metal parts that they now need multiple weights. Ironically this idea would have been very workable back then because washing machines had plenty of space inside. But the weight savings would be too little to bother with because they only had one weight. (continued below..)\nBetter built washing machines didn’t need so many weights\nUp until roughly 25 years ago washing machines all had outer drums made of metal. They also had big aluminium back plates (see pic) holding the bearings. These parts weighed a decent amount on their own so they only needed a relatively small tub weight underneath.\nTransit packaging needs space\nSome space is also needed for the polystyrene packaging inside many washing machines. There may be no space left for transit packaging if the extra large plastic weights are fitted.\nWasher dryers have even less room\nBecause of all the extra drying components in a washer dryer there is even less space available. It would be even harder to fit larger drum weights in washer dryers. See the picture to get an idea how crammed a typical washer dryer is inside. If manufacturers were only able to fit the new weights in washing machines, and needed separate manufacturing processes for washer dryers, it would dramatically increase costs of washer dryers.\nIs it practical to fill the weights with water at point of delivery?\nEven if manufacturers managed to fit the larger blocks inside there is another potential downside. It will complicate installation at the customer’s home. Extra costs will be incurred by customers paying to have one installed. Extra complications and effort will be involved for diy installations.\nIt will be difficult adding water to plastic weights underneath the drum. It would just be too inaccessible. So the new blocks would have to be fitted around the front of the drum (as well as on the top). They could both then be accessible for adding water with the lid removed. I’d also be concerned about a customer or installer spilling water when filling them. What if water spilled inside onto electrical parts? If not fully filled – could water move around inside causing shifting weight issues?\nThe devices would need to be leak-proof too. If one leaked it could flood the machine with water causing potential fires, or catastrophic damage. Lots of centrifugal forces are involved during spin trying to shake off drum weights. The current concrete ones are always coming loose and breaking as a result. If one of the water filled weights came loose the plastic could soon wear through and water would leak everywhere – a disaster. The only sensible option would be for any fill-able weights to be part of the drum’s mould and not bolted on.\nIt’s a clever idea, but unless washing machine manufacturers radically redesign their machines to allow space for larger weights I can’t see them fitting inside. Also the practicalities of filling them up with water when delivered to the customer and potential disastrous water leakage into the machine if they leaked mean I struggle to see how it could be made to work.","Vertical Farming: Location a Key Factor to Success, Says IDTechEx\nVertical farming, the practice of growing crops indoors on vertically stacked layers, has received no small amount of interest over the last few years. Vertical farms commonly tout impressive numbers, such as using 95% less water and providing crop yields 20-30 times that of conventional agriculture. These claims, among many others, have seen many vertical farming start-ups being founded alongside large amounts of industry funding; funding for the industry reached a record high in 2021, with over US$1 billion being raised across the entire industry. The recent IDTechEx report, \"Vertical Farming 2022-2032\", details the economic and technological factors shaping this rapidly growing industry.\nWith crops being grown indoors under controlled environments, a selling point used by multiple vertical farms is that they can grow crops anywhere – even in the heart of a city. This has led to proponents of the industry envisioning \"smart cities\", where vertical farms in city skyscrapers help feed the urban population. While this is achievable in principle, the truth is that the choice of location for vertical farming is much more involved and intricate than it may appear from these claims alone. Choosing an ideal location can be one of the most important factors in determining the success of a vertical farm.\nSome vertical farms may choose to set up their facilities in pre-existing facilities, such as abandoned warehouses. In these cases, identifying the suitability of the venue is the first point of consideration: vertical farms are very energy intensive, and it is important to ensure the facilities chosen can support these energy loads. In addition, the ergonomics of the facility is also important; should the layout not be given proper consideration, this can impede workers and decrease worker efficiency. As labor costs are typically among the largest sources of expenditure for a vertical farm, improving labor efficiency to reduce these costs is of paramount importance.\nWhile growing crops in the center of a city may seem ideal, the reality is that this may be counterproductive. Obtaining and maintaining such a location is expensive and can contribute significantly to the operating expenditure of a vertical farm while presenting logistical challenges in distributing produce; the \"last mile\" of food distribution is often the hardest. Having a farm right next to the consumers themselves may also be less ideal than instead choosing a location near food distribution centers, as this allows for more efficient delivery of produce. As distribution centers are typically located on the outskirts of cities, the cost of land is also much cheaper. This is the approach chosen by UK-based Jones Food Company, which chose Scunthorpe as a location for its vertical farm – this is a relatively low-cost location located near food distribution centers and a network of motorways that could still reach many consumers in a day, even if it isn't right in the middle of the capital city. Vertical farms should carefully consider their place in the supply chain before establishing a base.\nOn a larger scale, vertical farms may prove more profitable in different geographical regions. Vertical farms can reduce water usage significantly over conventional agriculture, and the high degree of control over the growing environment allows them to grow crops in extreme climates – where such crops may not otherwise be able to grow. In return, vertical farms demand more energy to carry out growing operations. To maximize their potential, vertical farms would ideally be located in regions of water scarcity, such as Sub-Saharan Africa and the Middle East, or in areas with extreme climates, such as in Scandinavian countries, where the low amounts of sunlight and high costs of regulating greenhouse environments single out vertical farms as an optimal solution. The amount of agricultural land available is also an important factor – regions looking to increase food security and reduce reliance on imports while facing challenges in acquiring sufficient agricultural land would find vertical farms to be ideal. A particularly prominent example of such a country is Singapore, which has demonstrated much interest in vertical farming over the last few years.\nBeyond the considerations of water scarcity and temperature, the general availability of fresh produce and the distribution networks of given countries should also be considered. Vertical farms use the added freshness and higher quality of their crops as a primary selling point, but these are typically offset by higher prices. Should there already be a large supply of high-quality produce made available at lower costs, vertical farms will find it hard to distinguish their own produce and may struggle to establish a significant market share. The converse would also be true; should a country lack easy access to fresh produce, vertical farms are expected to see much demand for their produce. An example of such a region would be the Middle East: leafy greens typically travel several thousand miles to reach stores, resulting in consumers facing high prices and low-quality products. The high price of conventionally farmed leafy greens, alongside government subsidies, makes it easier for vertically farmed produce to approach price parity while providing much fresher, higher-quality products.\nWhile the choice of location is an important consideration, it is only one of many others that must be given proper thought. Only through proper optimization of growing operations to improve efficiency and reduce costs can vertical farms reach their true potential. In the IDTechEx report, \"Vertical Farming 2022-2032\", many further important factors for consideration are discussed in detail, and the future of vertical farming is evaluated through 10-year market forecasts.\nIDTechEx guides your strategic business decisions through its Research, Subscription and Consultancy products, helping you profit from emerging technologies. For more information, contact research@IDTechEx.com or visit www.IDTechEx.com.\nThis post does not have any comments. Be the first to leave a comment below.\nPost A Comment\nYou must be logged in before you can post a comment. Login now."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:b40939b9-5959-4b08-a6d9-588984ddf5d0>","<urn:uuid:98c0eed7-8d91-42cd-b0d1-cc7c105f9a4d>"],"error":null}