{"question":"What are the different types of structural traps in hydrocarbon reservoirs, and how do fault sealing properties affect their effectiveness?","answer":"Structural traps include anticlinal (fold) traps, salt dome traps, growth domes, and fault traps. Anticlinal traps form when sandstone beds overlain by low permeability shale are folded into anticlines with apical culmination. Salt dome traps occur where strata curve upward against sealing salt layers. Fault traps include normal faults, strike-slip faults, thrust faults, and growth faults. Their effectiveness depends on the fault's sealing properties - faults must have a sealing effect to function as fluid migration barriers. The sealing capacity of faults can be predicted using methods like Shale Gouge Ratio (SGR), which is transformed to hydrocarbon column height. For traps bounded by multiple intersecting faults, automated approaches are needed to evaluate leak points and column heights simultaneously across all fault surfaces.","context":["Hydrocarbon traps form where permeable reservoir rocks (carbonates, sandstones) are covered by rocks with low permeability (caprocks) that are capable of preventing the hydrocarbons from further upward migration. Typical caprocks are compacted shales, evaporites, and tightly cemented sandstones and carbonate rocks.\nThe caprock need not be 100% impermeable to water, oil or gas. If the upward loss of hydrocarbons is less than the supply of hydrocarbons from the source rocks to the trap, hydrocarbons may still accumulate…\nBasic Trap-Fluid Nomenclature\nTraps are usually classified according to the mechanism that produces the hydrocarbon accumulation. The two main groups of traps are those that are formed by structural deformation of rocks (structural traps), and those that are related to depositional or diagenetic features in the sedimentary sequence (stratigraphic traps).\nMany traps result from both of these factors (strati-structural or combination traps). A common example is stratigraphic pinch-out (e.g., a sandstone lens wedging into mudstone) that is combined with tectonic tilting (which allows hydrocarbons to pond in the updip part of the sandstone wedge). Other traps result mainly from fracturing (which creates the reservoir\nporosity) or hydrodynamic processes.\nThere are many classifications of hydrocarbon traps in use, but most have ~90% in common…\n1. Anticlinal (fold) and dome traps\ndirections). The simplest type of trap is formed when a sandstone bed that is overlain by\ntight (i.e. low permeability) shale is folded into an anticline. A simple anticline,\nhowever, may not necessarily be a trap. The crest of the anticline must have an apical\nculmination (i.e. a peak) somewhere along the fold axis so that hydrocarbons can be\ntrapped. Anticlinal traps are commonly detected by seismic reflection. In mature oilfields, most of these simple traps have probably been found, but many anticlinal traps remain to be discovered offshore and in new prospective areas.\nb) Salt domes: Strata around the salt dome curve upward creating traps against the sealing salt layers (see below for more details).\nc) Growth domes. Domes or anticlines that form during sedimentation when one area subsides more slowly than the surrounding areas. Their formation is concurrent with sedimentation (i.e. they form during deposition), and not due to later (tectonic) folding.\nGrowth anticlines may form due to differential compaction over salt domes or other upward-projecting features in the substrate (topographic highs on the buried landscape).\n2. Fault traps\nThe fault plane must have a sealing effect so that it functions as a fluid migration barrier for\nreservoir rocks. There are several common types of fault trap:\na) Normal faults — commonly associated with graben (rift) structures.\nb) Strike-slip faults — these may not be sealed due to incremental movements, but basement-controlled strike-slip faults commonly produce good anticlinal structures in overlying softer sediments.\nc) Thrust faults — commonly associated with compressional tectonics (e.g., the Front Ranges in Alberta).\nd) Growth faults — Growth faults typically form in sediments that are deposited rapidly, especially at deltas. Faulting occurs during sedimentation (i.e. syndepositionally), such that the equivalent strata on the downthrow side will be thicker than on the upthrow side.\nThe geometry and timing determine whether faults will be effective in forming fault traps:\n- Dead faults that predate basinal sediments only affect the underlying basement – they play no direct role in hydrocarbon trapping in the younger sedimentary pile.\n- Continuously developing faults (growth faults) — these are active during sedimentatioand are major petroleum traps (e.g., Niger Delta).\n- Young (late) faults —these form late during sedimentation; depending on their initiation and growth, they may or may not be effective as traps.\n- Late regenerated faults —these are new movements on old faults — they are more likely to destroy than form traps, but may be effective.\nMany petroleum fields are closely linked to faulting, but traps that result from faulting alone are less common. There are three common fault – petroleum pool associations:\n- The fault itself makes the trap without an ancillary trapping mechanism such as a fold —normal faults are the most common examples.\n- The fault creates another structure (e.g., a fold or horst) that in turn forms the main trap.\n- The fault may be a consequence of another structure that forms the main trap — e.g., the extensional crestal faults that form above some anticlines.\nImportant point: Faults are highly ambiguous features. They may leak, acting as permeable conduits for fluid flow (including oil and gas migration), but more commonly act as seals unless they are rejuvenated after petroleum has pooled.\nSALT DOME RESERVOIRS\nSalt domes form when salt is less dense than the overlying rock, and the salt moves slowly upwards due to its buoyancy. For this to happen, there must be a minimum overburden and the thickness of the salt deposits must be more than ~100 m. Upward movement of salt through the sedimentary strata, and associated deformation is termed halokinetics or salt tectonics. Movements may continue for several hundred million years.\nTraps may form (1) in the strata overlying the salt dome, (2) in the top of the salt domes (the cap rock - caused by brecciation and dissolution), (3) in the strata that curve upward against the salt intrusion (4) due to stratigraphic pinch-out of strata around the salt dome:\nSalt dome reservoirs produce major oilfields where basinal sediments contain thick salt deposits. Salt deposits are common in Permian-Jurassic sediments around the Atlantic Ocean. Examples include the Gulf of Mexico, where there is Permian and Jurassic salt, the Permian Zechstein salt in NW Europe and the North Sea.\nStratigraphic traps are created by any variation in the stratigraphy that is independent of structural deformation, although many stratigraphic traps involve a tectonic component such as tilting of strata.\nTwo main groups can be recognized —\nPrimary stratigraphic traps result from variations in facies that developed during sedimentation.\nThese include features such as lenses, pinch-outs, and appropriate facies changes.\n- Primary pinch out of strata, e.g., strata that pinch out updip in less permeable rocks such as shale;\n- Fluvial channels of sandstone that are isolated and surrounded by impermeable clay-rich sediments;\n- Submarine channels and sandstone turbidites in strata rich in shale;\n- Porous reefs that are surrounded by shale, etc.\nSecondary stratigraphic traps result from variations that developed after sedimentation, mainly because of diagenesis. These include variations due to porosity enhancement by dissolution or loss by cementation.\nPaleogeomorphic traps are controlled by buried landscape. Some are associated with\nprominences (hills); others with depressions (valleys). Many are also partly controlled by\nunconformities so are also termed unconformity traps.\nIf porewater flow in a sedimentary basin is strong enough, the oil-water contact may deviate from the horizontal because of the hydrodynamic shear stress that is set up. In some cases, oil may accumulate without closure. Flow of fresh (meteoric) water down through oil-bearing rocks commonly results in biodegradation of the oil and formation of asphalt, which may then form a cap rock for oil.","Bretan P.,Badley Geoscience Ltd\nPetroleum Geoscience | Year: 2017\nColumn height predictions are often displayed as attributes on fault-plane profiles. However, fault-plane profiles are difficult to interpret when derived from multiple faults that bound a trap. An automated approach, termed Trap Analysis, permits the rapid analysis of column height predictions using the deterministic fault-seal analysis method. For column height predictions to be meaningful, all faults that contribute to the sealing of hydrocarbons within a trap must be analysed as one coherent structural element. Hydrocarbon column height data at key reservoir juxtapositions on all faults that bound a trap are simultaneously interrogated to derive the unique location of the weakest point on the fault seal, termed Fault Leak Point (FLP). The FLP is trap-critical if it supports a column with a contact that is shallower than the trap’s structural spill point. The Trap Analysis approach enables sensitivity studies to be routinely undertaken. The predicted weakest point on a fault seal, and hence, the column height supported at that point, can depend on the calibration used to transform shale gouge ratio (SGR) to threshold capillary pressure, and on the density contrast between the buoyant and water phases. © 2017 The Author(s).\nMichie E.A.H.,University of Aberdeen |\nMichie E.A.H.,Badley Geoscience Ltd\nJournal of Structural Geology | Year: 2015\nRelatively few studies have examined fault rock microstructures in carbonates. Understanding fault core production helps predict the hydraulic behaviour of faults and the potential for reservoir compartmentalisation. Normal faults on Malta, ranging from <1m to 90m displacement, cut two carbonate lithofacies, micrite-dominated and grain-dominated carbonates, allowing the investigation of fault rock evolution with increasing displacement in differing lithofacies. Lithological heterogeneity leads to a variety of deformation mechanisms. Nine different fault rock types have been identified, with a range of deformation microstructures along an individual slip surface. The deformation style, and hence type of fault rock produced, is a function of host rock texture, specifically grain size and sorting, porosity and uniaxial compressive strength. Homogeneously fine-grained micrtie-dominated carbonates are characterised by dispersed deformation with large fracture networks that develop into breccias. Alternatively, this lithofacies is commonly recrystallised. In contrast, in the coarse-grained, heterogeneous grain-dominated carbonates the development of faulting is characterised by localised deformation, creating protocataclasite and cataclasite fault rocks. Cementation also occurs within some grain-dominated carbonates close to and on slip surfaces. Fault rock variation is a function of displacement as well as juxtaposed lithofacies. An increase in fault rock variability is observed at higher displacements, potentially creating a more transmissible fault, which opposes what may be expected in siliciclastic and crystalline faults. Significant heterogeneity in the fault rock types formed is likely to create variable permeability along fault-strike, potentially allowing across-fault fluid flow. However, areas with homogeneous fault rocks may generate barriers to fluid flow. © 2015 Elsevier Ltd.\nFreeman B.,Badley Geoscience Ltd. |\nBoult P.J.,GINKGO ENPGNG |\nYielding G.,Badley Geoscience Ltd. |\nJournal of Structural Geology | Year: 2010\nGood seismic interpretation of faults should include a workflow that checks the interpretation against known structural properties of fault systems. Estimates of wall-rock strains provide one objective means for discriminating between correct and incorrect structural interpretations of 2D and 3D seismic data - implied wall-rock strain should be below a geologically plausible maximum. We call this the strain minimisation approach. Drawing on the large body of published data for strike dimension and maximum displacement for faults we suggest a realistic upper limit of wall-rock shear strain of 0.05, and 0.1 for maximum longitudinal strain when measured in the displacement direction. Small-scale variation of fault wall-rock strain also adheres to this rule, except in specific areas of strain localisation such as relay zones. As a case study we review an existing structural interpretation of 2D seismic surveys. Mapping of shear and longitudinal strain on the fault planes show values commonly greater than 0.05 and 0.1 respectively. Thus the model is deemed inadmissible. We then reinterpreted the area in an iterative manner using the strain minimisation approach. By using regions of implied high wall-rock strain as an indicator of high uncertainty in the interpretation, we were able to break out two self-consistent fault sets, each of which had geologically plausible wall-rock strains, where previously there had only been one fault set with highly implausible wall-rock strains. © 2009 Elsevier Ltd.\nYielding G.,Badley Geoscience Ltd |\nLykakis N.,University of Edinburgh |\nLykakis N.,Midland Valley Exploration Ltd. |\nUnderhill J.R.,University of Edinburgh\nPetroleum Geoscience | Year: 2011\nExploration well 50/26b-6 in the UK Southern North Sea discovered a trap containing a gas-bearing Rotliegend Group (Leman Sandstone Formation) reservoir which was a major surprise at the time of drilling in that its gas composition was approximately 50% CO 2 (with 9% N2 and the remainder methane). Christened the 'Fizzy Discovery', the accumulation was appraised by well 50/26b-8. Subsequently, another CO 2-rich discovery (Oak) was made along-strike in nearby block 54/1b. Column heights at the well locations are of the order of a few tens of metres, but at the Fizzy Discovery the column height at the trap crest is estimated to be over 200 m. Interpretation of a high fidelity PSTM 3D seismic dataset has been constrained by 33 exploration wells allowing fault geometries and stratigraphic offsets to be determined with confidence. Despite late-stage (Late Cretaceous) structural inversion, the net boundary-fault offset is sufficient in both the Fizzy and Oak discoveries to almost breach the Zechstein Group evaporite super-seal, and the CO 2-bearing Rotliegend Group in the footwall is now juxtaposed against hanging wall sediments of the uppermost Zechstein Group. Hence, these Zechstein Group units evidently act as a robust long-term side-seal for the carbon dioxide column. The Fizzy and Oak accumulations are noteworthy in providing a natural demonstration of top seal and fault side-seal integrity for carbon dioxide in a subsurface reservoir, that has remained intact over a geological timescale in what is otherwise a prolific methane-rich reservoir play fairway. © 2011 EAGE/Geological Society of London.\nBretan P.G.,Badley Geoscience Ltd.\nFault and Top Seals: From Characterization to Modelling | Year: 2012\nEvaluating the structural integrity of fault-bounded traps for CO2 storage requires a thorough assessment of the likely sealing or non-sealing behavior of faults, in particular, i) will the increase in pressure generated by CO2 injection (or by a CO2 column) trigger fault instability and reactivation, thus leading to loss of CO2 from the trap, and ii) will the fault act as a capillary barrier, thus permitting CO2 to accumulate, and if so what might the likely height of the trapped column be before the fault leaks? The structural integrity of fault-bounded CO2 traps can be evaluated using workflows and predictive algorithms originally developed for the prediction of capillary seal of hydrocarbon, using appropriate CO2 fluid densities. Three-dimensional faulted-framework models are an essential first step in assessing the integrity of a fault-bounded CO2 trap. Fault-plane diagrams are used to investigate the juxtaposition geometry of CO2 bearing reservoir/non-reservoir intervals at the fault plane. Predictive algorithms for fault-sealing, such as Shale Gouge Ratio, and for stress-driven leakage enable a better understanding of the possible fault behavior to be derived.\nBretan P.G.,Badley Geoscience Ltd\n4th International Conference on Fault and Top Seals 2015: Art or Science? | Year: 2015\nThe deterministic method for predicting column heights in traps involves constructing a fault framework model and populating the model with attributes. Shale Gouge Ratio (SGR) is calculated at sand-on-sand juxtapositions and transformed to hydrocarbon column height. The application of the deterministic method is straightforward for traps defined by few faults. Fault-plane sections are inspected visually to identify the column height that could be supported at the fault. However, for traps bounded by multiple intersecting faults identifying column heights through the visual inspection of fault-plane sections is practically impossible. A new automated approach is described that enables leak points and column heights to be quickly derived and evaluated for traps bounded by multiple intersecting faults. Fault 'side walls' defined by branch lines are simultaneously interrogated to derive a unique location of the leak point. The leak point is that point on a fault side wall which, when trappable column heights are calculated, implies the shallowest hydrocarbon contact in the trap. The new approach has shown that the location of a leak point in a trap can depend upon the transformation used to convert SGR to capillary pressure and has important implications for migration studies in complex fault-bounded traps.\nYielding G.,Badley Geoscience Ltd\nPetroleum Geoscience | Year: 2012\nFault-seal analysis in hydrocarbon exploration often involves prediction of the sealing capacity of fault rock at reservoir-reservoir juxtapositions on subsurface faults. A proxy property, such as Shale Gouge Ratio (SGR), is mapped on to the fault surface, and then SGR is either (a) calibrated by observations of known sealing faults, to define its sealing capacity (empirical approach), or (b) assumed to be equal to the composition of the fault rock, for which a database of capillary threshold pressures is available from cores (deterministic approach). The deterministic approach implicitly assumes that capillary pressures measured on centimetre-scale samples are representative of seismically mappable faults, for example that faults of intermediate SGR are equivalent to phyllosilicate framework fault rocks.This contribution builds on earlier outcrop and modelling work to suggest an alternative explanation for the observed progressive increase in sealing capacity on faults of increasing SGR. Stochastic models of disrupted shale smears display the same pattern of increasing sealing capacity as SGR increases. These models have a bimodal 'fault rock' composed only of sealing shale smears and non-sealing matrix and, yet, at intermediate SGR the predicted column heights are similar to those normally ascribed to intermediate composition fault rocks. The resulting 'fault-seal envelope' in the models is a statistical estimate of the maximum trappable column height, dependent on the random occurrence of a gap in the smeared fault surface. © 2012 EAGE/Geological Society of London.\nRoberts A.M.,Badley Geoscience Ltd |\nKusznir N.J.,University of Liverpool |\nCorfield R.I.,BP Exploration Operating Co. |\nThompson M.,BP Exploration Operating Co. |\nWoodfine R.,BP Exploration Operating Co.\nPetroleum Geoscience | Year: 2013\nAn integrated workflow has been devised for the investigation of deep-water rifted continental margins. At a margin this allows us to predict the crustal structure, the distribution of continental-lithosphere thinning and the location of the ocean-continent transition with a new degree of confidence. The workflow combines the analytical techniques of 2D or 3D gravity inversion, 2D or 3D flexural backstripping with reverse thermal subsidence modelling, upper-crustal fault analysis and rifted margin forward modelling. No one technique on its own can provide all of the required answers, nor can it provide answers without some degree of uncertainty. The use of a combination of techniques, however, provides answers to several different problems and, crucially, more confidence in these answers. The workflow provides direct information on the present-day geometry of rifted margins and leads towards a better understanding of the geodynamic evolution of these margins. It also provides information which can inform the exploration process by making predictions about crustal structure at the ocean-continent transition, the location of the continent-ocean boundary, stretching-factor, heat-flow magnitude and history, palaeobathymetric history and subsurface palaeostructure. Application of the workflow is illustrated here with reference to the continental margins of West India, Brazil, West Australia, Norway and Newfoundland-Iberia. © 2013 EAGE/Geological Society of London.\nMorley C.K.,Chiang Mai University |\nAlvey A.,Badley Geoscience Ltd.\nJournal of Asian Earth Sciences | Year: 2015\nThe Central Andaman Basin (CAB) is generally accepted to be a site of continuous sea floor spreading since the Early Pliocene (~4.0. Ma). The adjacent Alcock and Sewell Rises, and part of the East Andaman basin have been interpreted as probable Miocene oceanic crust. Published seismic lines across the eastern half of the spreading centre show that 100's. m thickness of sediment are present right up to the central trough. The central trough margins are faulted, uplifted and tilted away from the central trough. The youngest sediment is ponded and onlaps the tilted central trough margin, while older faulted sediment lies within the trough. Such a configuration is incompatible with continuous spreading. Instead, either spreading in the central basin was episodic, probably comprising a Late Miocene-Early Pliocene phase of spreading, followed by extension accommodated in the Alcock and Sewell rise area (by faulting and dike intrusion), and then a recent (Quaternary) return to spreading in the central trough; or the central trough marks an incipient spreading centre in hyper-thinned continental (or possibly island arc) crust. To resolve these possibilities regional satellite gravity data was inverted to determine crustal type and thickness. The results indicate the CAB is oceanic crust, however the adjacent regions of the Alcock and Sewell Rises and the East Andaman Basin are extended continental crust. These regions were able to undergo extension before seafloor spreading, and when seafloor spreading ceased. Unpublished seismic reflection data across the East Andaman Basin supports the presence of continental crust under the basin that thins drastically westwards towards the spreading centre. Episodic seafloor spreading fits with GPS data onshore that indicate the differential motion of India with respect to SE Asia is accommodated on widely distributed structures that lie between the trench and the Sagaing Fault. © 2014 Elsevier Ltd.\nYielding G.,Badley Geoscience Ltd |\nBretan P.,Badley Geoscience Ltd |\nFreeman B.,Badley Geoscience Ltd\nGeological Society Special Publication | Year: 2010\nCalibration is a necessary step in the workflow for prediction of fault seal because there is no direct way to detect the hydraulic behaviour of a fault at the scale of a hydrocarbon trap. Over the last 20 years two general approaches have been developed: (i) Measurement of hydraulic properties of fault-zone samples (lab calibration), then mapping these results onto the appropriate parts of trap-bounding faults. (ii) Design of simple algorithms which attempt to capture a salient feature of the fault zone (e.g. CSP, SSF, SGR), then looking at known trap-bounding faults to find a relationship between the algorithm and the presence or capacity of a seal (sub-surface calibration). Seal capacity is typically y Hg-air threshold pressure in the lab or static prdescribed bessure differences in the subsurface (e.g. hydrocarbon buoyancy pressure). In addition to likely interpretation and geometry errors in approaches (i) and (ii), further uncertainty is introduced when converting the calibrated seal strength to potential hydrocarbon column height, because of the variability of subsurface hydrocarbon fluids (interfacial tension). Despite these potential problems, the different methodologies typically agree reasonably well in their predictions for fault-seal capacity. However, this agreement may be largely coincidental and is likely to be a response to the heterogeneity of fault-zone structure (especially at intermediate 'compositions' or SGR). © The Geological Society of London 2010."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:016f229b-0937-43a7-90e8-37ab9a042f76>","<urn:uuid:3b4b1b4b-d3f9-40f0-a006-978abd676edc>"],"error":null}
{"question":"What role does historical distance play in Bible translation and how does it affect the translation of covenant passages?","answer":"Historical distance involves differences between original and receptor languages in words, grammar, idioms, culture and history. When translating covenant passages, such as those in Hebrews discussing God's new covenant through Christ's sacrifice, translators must decide whether to bridge language gaps or let readers do so. The translation must accurately convey both the historical context of the old covenant's repeated sacrifices and the new covenant established through Christ's single sacrifice, while making these concepts understandable to modern readers through appropriate word choices and grammatical structures.","context":["Christ’s Sacrifice Once for All\n10 For since the law has but va shadow wof the good things to come instead of the true form of these realities, xit can never, by the same sacrifices that are continually offered every year, make perfect those who draw near. 2 Otherwise, would they not have ceased to be offered, since the worshipers, having once been cleansed, would no longer have any consciousness of sins? 3 But yin these sacrifices zthere is a reminder of sins every year. 4 For ait is impossible for the blood of bulls and goats to take away sins.\n5 Consequently, bwhen Christ1 came into the world, he said,\nc“Sacrifices and offerings you have not desired,\nbut a body have you prepared for me;\n6 in burnt offerings and sin offerings\nyou have taken no pleasure.\n7 Then I said, ‘Behold, I have come to do your will, O God,\nas it is written of me in the scroll of the book.’ ”\n8 When he said above, “You have neither desired nor taken pleasure in csacrifices and offerings and burnt offerings and sin offerings” (these are offered according to the law), 9 then he added, d“Behold, I have come to do your will.” He does away with the first in order to establish the second. 10 And by that will ewe have been sanctified through the offering of fthe body of Jesus Christ gonce for all.\n11 And every priest stands hdaily at his service, ioffering repeatedly the same sacrifices, jwhich can never take away sins. 12 But when Christ2 had offered for all time a single sacrifice for sins, he ksat down at the right hand of God, 13 waiting from that time luntil his enemies should be made a footstool for his feet. 14 For by a single offering mhe has perfected for all time those who are being sanctified.\n15 And the Holy Spirit also bears witness to us; for after saying,\n16 n“This is the covenant that I will make with them\nafter those days, declares the Lord:\nI will put my laws on their hearts,\nand write them on their minds,”\no“I will remember their sins and their lawless deeds no more.”\n18 Where there is forgiveness of these, there is no longer any offering for sin.\n19 pTherefore, brothers,3 since we have confidence to enter qthe holy places by the blood of Jesus, 20 by rthe new and living way that he opened for us through sthe curtain, that is, through his flesh, 21 and since we have ta great priest over the house of God, 22 let us draw near with a true heart in full assurance of faith, with our hearts usprinkled clean vfrom an evil conscience and our bodies wwashed with pure water. 23 xLet us hold fast the confession of our hope without wavering, for yhe who promised is faithful. 24 And zlet us consider how to stir up one another to love and good works, 25 anot neglecting to meet together, as is the habit of some, but encouraging one another, and ball the more as you see cthe Day drawing near.\n26 For dif we go on sinning deliberately eafter receiving the knowledge of the truth, fthere no longer remains a sacrifice for sins, 27 gbut a fearful expectation of judgment, and ha fury of fire that will consume the adversaries. 28 iAnyone who has set aside the law of Moses dies without mercy jon the evidence of two or three witnesses. 29 How much worse punishment, do you think, will be deserved by the one kwho has trampled underfoot the Son of God, and has profaned lthe blood of the covenant mby which he was sanctified, and has noutraged the Spirit of grace? 30 For we know him who said, o“Vengeance is mine; I will repay.” And again, p“The Lord will judge his people.” 31 qIt is a fearful thing to fall into the hands of the living God.\n32 But recall the former days when, after ryou were enlightened, you endured sa hard struggle with sufferings, 33 sometimes being tpublicly exposed to reproach and affliction, and sometimes being partners with those so treated. 34 For uyou had compassion on those in prison, and vyou joyfully accepted the plundering of your property, since you knew that you yourselves had wa better possession and an abiding one. 35 Therefore do not throw away your confidence, which has xa great reward. 36 For yyou have need of endurance, so that zwhen you have done the will of God you may areceive what is promised. 37 For,\nb“Yet a little while,\nand cthe coming one will come and will not delay;\n38 dbut my righteous one shall live by faith,\nand if he shrinks back,\nmy soul has no pleasure in him.”\n39 But we are not of those who shrink back and are destroyed, but of those who have faith and preserve their souls.\nAbout English Standard Version\nThe English Standard Version™ is founded on the conviction that the words of the Bible are the very words of God. And because the words themselves—not just the thoughts or ideas—are inspired by God, each word must be translated with the greatest precision and accuracy. As Jesus Himself stressed, “Man shall not live by bread alone, but by every word that proceeds from the mouth of God” (Matt. 4:4).\nThis passion for God’s Word is the driving force behind the translation of the ESV™ Bible. The English Standard Version™ does not try to “improve” on the original in light of today’s culture or by using trendy language. Instead, the utmost care has been taken to express God’s Word in English that most closely captures the meaning of the original, with understandability, beauty, and impact.\nThe Classic Reference Edition, English Standard Version® (ESV®)\nThe Holy Bible, English Standard Version\nESV Text Edition (2016)\nThe ESV text may be quoted (in written, visual, or electronic form) up to and inclusive of five hundred (500) verses without express written permission of the publisher, providing that the verses quoted do not amount to a complete book of the Bible nor do the verses quoted account for twenty-five (25%) percent or more of the total text of the work in which they are quoted.\nThe ESV text may be quoted for audio use (audio cassettes, CD’s, audio television) up to five hundred (500) verses without express written permission of the publisher providing that the verses quoted do not amount to a complete book of the Bible nor do the verses quoted account for twenty-five (25%) percent or more the total text of the work in which they are quoted.\nNotice of copyright must appear as follows on the title page or copyright page of printed works quoting from the ESV, or in a corresponding location when the ESV is quoted in other media:\n“Scripture quotations are from the ESV® Bible (The Holy Bible, English Standard Version®), copyright © 2001 by Crossway Bibles, a publishing ministry of Good News Publishers. Used by permission. All rights reserved.”\nWhen more than one translation is quoted in printed works or another media, the foregoing notice of copyright should begin as follows:\n“Unless Otherwise indicated, all Scriptures are from ... [etc.]”, or,\n“Scripture quotations marked ESV are from ... [etc.].”\nThe “ESV” and “English Standard Version” are registered trademarks of Good News Publishers. Use of either trademark beyond the use described in this Permission Notice requires the permission of Good News Publishers.\nWhen quotations from the ESV text are used in non-saleable media, such as church bulletins, orders of services, posters, transparencies, or similar media, a complete copyright notice is not required, but the initials (ESV) must appear at the end of a quotation.\nPublication of any commentary or other Biblical reference work produced for commercial sale that uses the English Standard Version must include written permission for the use of the ESV text.\nPermission requests that exceed the above guidelines must be directed to: Good News Publishers, Attn: Bible Rights, 1300 Crescent Street, Wheaton, Ill. 60187.\nPermission requests for use within the UK and EU that exceed the above guidelines must be directed to: HarperCollins Religious, 77-85 Fulham Palace Road, Hammersmith, London, W6 8JB, England.\nPublished by Good News Publishers\nGood News Publishers (including Crossway Bibles) is a not-for-profit organization that exists solely for the purpose of publishing the good news of the gospel and the truth of God's Word, the Bible.","“Linguistics” sounds like a cookbook of creative linguini dishes, right? Something like “The Logistics of Linguini.”\nLinguistics Teaching Moment\nLinguistics is the study of language and the way language works, in form, in meaning, and in context.\n“Linguistics” is similar in sound to linguini and logistics—sounds are an important part of the study of language.\n“Linguistics” and “logistics” also have similar sounds and are partly related in meaning.\n- Logistics is the complex detail of a plan.\n- Linguistics is the complex detail of language.\nMeaning, and its relation to other words either in part or in whole, is also part of the study of language.\nAnd of course, context—using logistics and linguini to describe linguistics would make no sense except in the context of this paragraph.\nAnd even that is questionable.\nMan Perceives The World Through Language\nEdward Sapir, considered one of the most important figures in linguistics, suggested that man perceives the world principally through language.\nThe worlds in which different societies live are distinct worlds, not merely the same world with different labels attached … We see and hear and otherwise experience very largely as we do because the language habits of our community predispose certain choices of interpretation.\nOk, read that again. It’s a lot to take in at once.\nSomething I read in Helmut Thielicke’s African Diary (Word Books, 1974) helps me to understand Sapir’s statement. During an extended trip to Africa, Dr. Thielicke spoke with a German anthropologist living in Africa. The anthropologist shared that the tribal peoples did not understand abstractions, squares, right angles, etc. And he added “Where in the jungle or the hills would they come across a right angle or straight line? On the other hand, they are very good at circles. It is not accidental that their huts are built round.” This doesn’t speak directly about language, but it is about perceiving one’s world differently. And this helps me understand Sapir. Distinct worlds. Same things. Different labels. Different meanings behind the labels.\nAnd a word is nothing but a label for something.\nLinguistics Is Essential To The Translation Of The Bible\nIn our distinct worlds where “…the language habits of our community predispose certain choices of interpretation,” it is understandable why linguistics is essential to the translation of the Bible.\nSapir also brings to light another important point: Translation of the Bible is not merely vocabulary, parsing verbs, grammar, idioms, etc., but linguistics also help us understand how the biblical writers saw and perceived their world.\n“Dashing babies against rocks” (Ps. 137:9) sounds hideously evil to modern ears. But the Hebrews who lived in a world governed by retribution, i.e. eye for an eye, watched their ruthless enemies dashing Hebrew babies against rocks. When the Hebrew people cry out for God to do the same to their enemies, it is essentially a plea for God’s quick justice. If the same prayer had been “bring us justice against these enemies,” some modern ears would be less appalled. But for the Hebrew community the prayer would not have had the same force and urgency. The language used helps us understand this important aspect of the Biblical text.\nBible Versions Series Recap\nBible Versions 101: Why Are There So Many Bible Versions discusses the difference between translation and interpretation.\nBible Versions 102: Textual Criticism discusses the original text.\nThis post, Bible Versions 103: Linguistics, discusses the language used in a Bible translation and the theories of translation.\nThe Science of Translation\nTranslation is a science which involves two kinds of choices—\nBible Versions 102 discusses the textual aspect of translation, in particular, the science used to make textual choices—Textual Criticism.\nBible Versions 103 discusses the language aspect.\nIn dealing with language, two choices present themselves:\nThis involves rewording words and ideas from one language to another, i.e. French la Maison-Blanche to English the white house.\nRecall from Bible Versions 101 the example of the Chinese missionary. He reworded a Chinese version into English. The older gentlemen heard/interpreted this as the missionary “messing up” or misquoting the English. To the missionary’s defense, he wasn’t concerned with only rewording word for word, but also rewording the ideas expressed using Chinese words in such a way as to convey the same ideas using English words that make sense to an English audience.\nTheories of Translation\nSeveral technical terms are used to discuss the theories of translation used in modern Bible translations.\nTerms used to discuss translating:\n- Original language–for the Bible it is Hebrew, Aramaic, and Greek; so the language that is being translated from\n- Receptor language–the language that the original language is being transferred into, i.e. English, Chinese, Russian, German (for this post we will assume English)\n- Historical distance–the differences between the original language and the receptor language, i.e. words, grammar, idioms; historical distance also considers culture and history\nTerms to describe translation theories:\n- Formal equivalence\n- Stays close to the form of the original, words and grammar, but still understandable in English\n- This theory of translation is often called “literal”\n- Historical distance is kept intact at all points\n- Functional equivalence\n- Keeps the meaning of the original but translates it into a “normal way of saying the same thing in English”\n- The more functional equivalence over formal equivalence is a theory of translation called “dynamic equivalence”\n- Historical distance is maintained on all historical and factual matters\n- Historical distance is “updated” for language, grammar, and style\n- Free translation\n- Translates the ideas from one language to another\n- Less concerned about using exact words from the original\n- Sometimes called a “paraphrase”\n- Eliminates as much historical distance as possible and still faithfully rewords the text\nExample using Hebrews 1:1-2:\n- Formal Equivalence – NASB\nGod, after He spoke long ago to the fathers in the prophets in many portions and in many ways, (2) in these last days has spoken to us in His Son, whom He appointed heir of all things, through whom also He made the world.\n- Dynamic Equivalence – ESV\nLong ago, at many times and in many ways, God spoke to our fathers by the prophets, 2 but in these last days he has spoken to us by his Son, whom he appointed the heir of all things, through whom also he created the world.\n- Free – The Message\n1-3 Going through a long line of prophets, God has been addressing our ancestors in different ways for centuries. Recently he spoke to us directly through his Son. By his Son, God created the world in the beginning, and it will all belong to the Son at the end.\nThe NASB, in an attempt to translate literally, has a somewhat awkward rendering, yet the ESV and NASB have pretty much the same words–both stay close to the form of the original.\nThe ESV has smoothed out some of the English without changing the meaning. It is more readable.\nAnd The Message gets the idea across, but the words used are not anything like the original.\nTheory of Translation\nOne of these theories—formal equivalence, functional equivalence, free—will control the translator’s basic approach to the task of creating a Bible translation/version.\nA Theory of Translation basically controls the following:\n- Is emphasis put on formal or functional equivalency?\n- To what extent does the translator go to reducing differences between the two languages, either in words and grammar, or in historical distance by using modern equivalents, i.e. 2 denarii or 2 pennies.\n- Should the translator bridge the language gap or let the reader?\n- Should translators reword something that may be culturally offensive?\n- Should a formal equivalent term meaningless in English be translated into what it actually means?\nHistorical Distance Challenges\nHistorical distance offers some translational and interpretational challenges to the translator. In general, these will also be directed by the theory of translation.\n- Translating weights, money, and measures\n- Euphemisms for matters of sex and toilet\n- Choosing a word that connotes the correct original language word, but that has not changed meanings over time in the receptor language. For example, the word “gay”; the U.S. use of this word has completely changed since the first half of the twentieth century\n- Wordplays; wordplays serve a major role in making a point (cf. Jer. 1:11-12), but are difficult to maintain in the receptor language\n- Grammar and Syntax – translated word for word from an original language may sound awkward in a receptor language, i.e. most Hebrew sentences start with an article, but the article is not always part of the spoken language\n- Gender – Hebrew and Greek both have masculine and feminine forms, and Greek also has neuter forms; A masculine plural form, depending on context, may mean “a group of people” or “the men.” “Man/men” is used as a default gender when referring to both genders. In the Luke 6:45 example below, NIV translates “man” literally from the Greek word used for man; ESV translates the same word “person” since Jesus clearly means either a man or a woman; in a language with masculine and feminine forms, the masculine is a default. The translator must decide, as in Luke 6:45, to use man (implied woman too), person, or man and woman/his and her, etc. (Note the pronouns in both.)\n(ESV) Luke 6:45 The good person out of the good treasure of his heart produces good, and the evil person out of his evil treasure produces evil, for out of the abundance of the heart his mouth speaks.\n(NIV) Luke 6:45 The good man brings good things out of the good stored up in his heart, and the evil man brings evil things out of the evil stored up in his heart. For out of the overflow of his heart his mouth speaks.\nTheory of Translation Categories\nNot all Bible translations fit nice and neatly under the theory of translation categories, but some blur the lines as seen in the chart below. Line 1 has the original translations. Line 2 has the revised translations.\n|1||KJV NASB RSV||NIV NAB GNB JB||NEB LB|\n|2||NKJV NASU NRSV ESV||TNIV NJB REB NLT||The Message|\nNotice that the revisions of the RSV, NRSV and ESV, have moved closer to dynamic equivalence from the formal side, while the NJB, REB, and NLT (revision of the LB) have also move closer to dynamic equivalence from the free side.\nWhat Is The Best Theory?\nThe best theory of translation is one that remains faithful to both the original and receptor languages. With the caveat that if something has to “give” it should be in favor of the receptor language without losing the meaning of the original language.\nAfter all, the purpose of any translation of the Bible is so you and I can hear God’s revelation to mankind.\nSummary of Bible Versions 101, 102, and 103\nAt this point you know:\n- The difference between translation and interpretation (Bible Versions 101)\n- Original Language involves Textual Criticism (Bible Versions 102)\n- “Translated Into” Language involves verbal and grammatical choices controlled by a theory of translation. (Bible Versions 103)\nWhich Bible Translation(s) Should Be Used?\nSo, which Bible translation(s) should you use? Be sure and read the final post in the Bible Versions series, Bible Versions 104: Choosing a Translation for things to consider when making this important decision.\nUntil next time –\nThe grace of the Lord Jesus Christ and the love of God and the fellowship of the Holy Spirit be with you all. 2 Corinthians 13:14 (ESV, dynamic equivalence; NASB, formal equivalence is the same, can you guess why?)\nThe amazing grace of the Master, Jesus Christ, the extravagant love of God, the intimate friendship of the Holy Spirit, be with all of you. 2 Corinthians 13:14 (The Message, free)\n Gordon D. Fee and Douglas Stuart, How to Read the Bible for All Its Worth (Grand Rapids:Zondervan, 2003), 42."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:f60f0cb5-2026-4617-9a51-e21c8f4b84de>","<urn:uuid:c8164350-39fc-42d2-aba7-4b2faee7b0b7>"],"error":null}
{"question":"How do reinforcement learning agents balance exploration versus exploitation, and what privacy concerns arise in deep learning applications?","answer":"In reinforcement learning, agents balance exploration and exploitation through strategies like ε-greedy, where they take random actions with probability ε (exploration) and select greedy actions with probability 1-ε (exploitation), or soft-max, where optimal actions are selected based on Q-values from neural networks. Regarding privacy concerns, as deep learning algorithms become more adept at processing and interpreting personal data, there is an increased risk of privacy breaches and misuse. Organizations must implement robust data protection measures and ensure transparency in their use of AI-driven technologies to maintain user trust and comply with regulations.","context":["Acrobot with Deep Q-Learning\nThis article was published as a part of the Data Science Blogathon\n- Introduction to a classic Reinforcement Learning problem, Acrobot\n- RL concepts covered – agent, environment, states, action, reward, Q-learning, Deep Q Learning\n- Learn theory through examples and illustrations\nAcrobot is a game, in which a robotic arm is composed of two joints and two links and the joint between the two links is actued. In the beginning, the links are hanging downwards. The goal of the task is to move the end of the lower link up to a given height .\nBelow, you can see the game before and after training. The agent has no prior knowledge of how its actions affect the environment and learns by itself playing the game many times. In the beginning, the agent doesn’t know how to behave and within the time it will be able to understand how to act optimally.\nIn this post, I will show the principal concepts of Reinforcement Learning describing this game. What is Reinforcement Learning? It’s a branch of machine learning inspired by human behavior, how we learn interacting with the world. This field is widely applied for playing computer games and robotics. So, this game I am showing fits perfectly to understand deeply the concepts of DL.\nThere are five important concepts when you want to grasp reinforcement learning’s mentality. Agent, Environment, State, Action, and Reward. They are all linked to each other. And at the end, I will explain Deep Q learning, a powerful method that merges Deep Learning Techniques with RL.\nThe state is the current condition of the robotic arm. The state can be constituted by the screen pixels of the game or by some informations about the agent, which can also be called environment observations. These lasts are:\n- sin and cos of the two rotational joint angles (4 in total)\n- the two angular velocities\nIn this post, I will focus on this external information, instead of the current frame.\nActions and Rewards\nWhen the robotic arm chooses and performs an action, it may receive a reward or not. In each time step, it receives -1 as punishment until the goal is reached. Then, the agent’s task is to understand which actions can maximize the cumulative reward. There are three possible actions:\n- Apply positive torque (+1)\n- Apply negative torque (-1)\n- Do nothing (0)\nQ-learning is an algorithm that quantifies the expected discounted future rewards that can be obtained by taking a certain action in a given state at any time step t. Then, it estimates the value of each state-action pair. Why Q? Q stands for Quality, which depends on how the action is useful to gain some reward in the future . The agent learns to associate to each state-action pair the Q-value, using the Bellman equation:\nEach step of the Q-learning algorithm is defined by the following equation:\nDon’t worry. I know, it scares you as soon as your eyes encounter this equation. We only need to understand the role of each parameter involved.\n- s = state\n- a = action\n- r = reward\n- t = time step\n- γ = discount rate\n- α = learning rate\nBoth the learning rate and discount rate are between 0 and 1. The last determines how much we care about the future reward. The more it’s near 1, the more we care.\nThe drawback of Q-learning is that it has issues with huge state and action spaces. Memorize every possible couple of actions and states needs big memory. For this reason, we need to combine Q-learning with Deep Learning techniques.\nDeep Q learning\nAs we saw, the Q-learning algorithm needs function approximators, such as artificial neural networks, to memorize the triplets (state, action, Q-value). The idea of Deep Q learning is to use neural networks to predict the Q-values for each action given the state. If we consider again the Acrobot game, we pass it to the artificial neural network as input the information is about the agent (sin and cos of joint angles, velocities). To obtain the predictions, we need to train the network before and define the loss function, which is usually the difference between the predicted Q-value and the target Q-value.\nDifferent from supervised learning, we don’t have any label, that identifies the correct Q-value for each state-action pair. In DQL, we initialize two identical artificial neural networks, called Target Network and Policy Network. The first will be used to calculate the target values, while the second to determine the prediction.\nFor example, the model for the Acrobat’s game is an artificial neural network that takes into input the environment observations, the sin and cos of the two rotational joint angles, and the two angular velocities. It returns three outputs, Q(s,+1), Q(s,-1), Q(s,0), where s is the state, passed as input to the network. Indeed, the goal of the neural network is to predict the expected return of taking each action given the current input.\nThe ANN is not enough alone. Experience is a technique where we store the past data discovered by the agent for (state, action, reward, next state) at each time step. Later, we sample randomly the memory for a mini-batch of experience and we use it to train the artificial neural network. By sampling randomly, we allow to provide uncorrelated data to the neural network model and improve the efficiency of the data.\nExploration vs Exploitation\nExploration and Exploitation are key concepts in the Deep RL algorithm. It refers to the way the agent selects the actions. What are Exploration and Exploitation? Let’s suppose that we want to go to a restaurant. Exploration is when you want to try a new restaurant, while exploitation is when you want to remain in your comfort zone, so you’ll go directly to your favorite restaurant. It’s the same for the agent. In the beginning, it wants to explore the environment. As long as it interacts with the environment, it will take choice more based on exploitation than exploration.\nThere are two possible strategies:\n- ε-greedy, where the agent takes a random action with probability ε, then it explores the environment and selects the greedy action with probability 1-ε, then we are in an exploitation situation.\n- soft-max, where the agent selects the optimal actions based on the Q-values returned by the artificial neural network.\nCongratulations! Now you grasp the RL and DRL concepts through the example of Acrobot that introduced you to this new world. Deep Q learning has gained a lot of attention after the applications in Atari games and Go. I hope that this guide didn’t scare you and will encourage you to go deeper into the topic. Thanks for reading. Have a nice day!\nReferences: https://gym.openai.com/envs/Acrobot-v1/  http://www.henrypan.com/blog/reinforcement-learning/2019/12/03/acrobot.html\nThe media shown in this article are not owned by Analytics Vidhya and are used at the Author’s discretion.","Deep learning is an advanced subset of machine learning, a current and ever-evolving field of technology that has the potential to revolutionize the way we interact with and understand the world around us. In recent years, deep learning has gained significant traction, becoming a widely discussed and utilized technology in a variety of industries and applications.\nAt its core, deep learning is a complex algorithmic approach to building and training artificial neural network architectures. These networks are inspired by the structure and function of the human brain, with interconnected nodes, or neurons, that work together to process and interpret data patterns. Through the use of these neural networks, deep learning algorithms can autonomously learn to identify and extract features from large datasets, enabling them to recognize and understand complex patterns and make accurate predictions or decisions.\nOne of the key strengths of deep learning lies in its ability to handle unstructured data, such as images, videos, and natural language. This makes it particularly well-suited for applications like image recognition, speech recognition, natural language processing, and even autonomous vehicles. For example, deep learning algorithms powering self-driving cars can process visual input from cameras and sensors to quickly and accurately identify objects, pedestrians, and potential hazards in real-time, enabling the vehicle to make split-second decisions to ensure safety.\nThe breadth of potential applications for deep learning is vast and diverse. In healthcare, deep learning algorithms can be used to analyze medical images, diagnose diseases, and predict patient outcomes. In finance, they can help detect fraudulent transactions and make investment recommendations. In marketing, they can analyze customer behavior and preferences to personalize product recommendations. In manufacturing, they can optimize production processes and predict equipment failures. The possibilities are virtually endless, and as the technology continues to mature, we can expect to see even more innovative and impactful applications emerge.\nOne of the most significant recent developments in the field of deep learning is the use of generative adversarial networks (GANs). GANs are a type of neural network architecture consisting of two networks – a generator and a discriminator – that work together to produce realistic synthetic data. This has huge implications for tasks like image and video synthesis, where GANs can be used to create lifelike images of non-existent people, places, or objects, or even produce deepfake videos that are nearly indistinguishable from real footage. While the ethical considerations of this technology are complex, it’s an exciting testament to the power and potential of deep learning.\nIn addition to its practical applications, deep learning also presents a number of challenges and considerations. One of the most significant challenges is the need for vast amounts of labeled training data to effectively train deep neural networks. As a result, sourcing and curating high-quality datasets is a critical step in the deep learning process. Additionally, deep learning models are often large and computationally intensive, requiring significant computational resources to train and deploy. This can be a barrier for smaller organizations or research groups with limited resources.\nPrivacy and security are also major concerns when it comes to the widespread adoption of deep learning. As deep learning algorithms become more adept at processing and interpreting personal data, there is an increased risk of privacy breaches and misuse. It’s essential for organizations to implement robust data protection measures and ensure transparency in their use of AI-driven technologies to maintain user trust and compliance with regulations.\nDespite these challenges, the continued growth and advancement of deep learning hold immense promise for the future of technology and society as a whole. With ongoing research and innovation, we can expect to see even more sophisticated deep learning models that push the boundaries of what is possible and drive new breakthroughs in fields like healthcare, finance, education, and beyond.\nIn conclusion, deep learning is a foundational technology with far-reaching implications. Its ability to process, analyze, and interpret complex data is driving significant advancements in a wide range of industries and applications. As the technology continues to evolve, it’s important for organizations and researchers to remain mindful of the ethical and practical considerations that come with harnessing the power of deep learning.\nRecent news in the field of deep learning includes the release of OpenAI’s GPT-3, the third generation of their groundbreaking language prediction model. GPT-3 represents a significant leap forward in natural language processing and understanding, with the ability to generate human-like text and perform a wide range of language-based tasks, such as writing essays, answering questions, and even writing code. While the technology has generated excitement and intrigue, it has also sparked discussions around responsible AI use and the potential consequences of highly advanced language models in the wrong hands.\nThis recent development serves as a testament to the rapid pace of advancement in deep learning and the potential for profound impacts on how we communicate and interact with technology. As deep learning continues to progress, it’s critical for researchers, developers, and policymakers to collaborate on establishing ethical guidelines and standards for the responsible development and deployment of AI technologies. By doing so, we can ensure that the potential of deep learning is harnessed for the collective benefit of society, while minimizing risks and vulnerabilities."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:8102c554-c121-4522-8090-e8f1efe987ab>","<urn:uuid:0d08b97a-a0bf-4297-bb0e-9d390a06a8b5>"],"error":null}
{"question":"As a consumer concerned about health effects of chemicals, I want to know: what are the issues with BPA substitutes in products labeled 'BPA-free', and what scientific resources are available to learn about chemical safety?","answer":"BPA substitutes like Bisphenol F (BPF) and Bisphenol S (BPS) in 'BPA-free' products actually have similar concerning effects as BPA. Studies show they have comparable negative impacts on reproduction and hormones in cellular and animal models, with similar biological effects in humans. These substitutes are widespread - BPS, BPF and BPA were detected in 89.4%, 66.5%, and 95.7% of tested urine samples respectively. For accurate information about chemical safety, several scientific resources are available: The CDC's National Biomonitoring Program assesses over 300 chemicals in human tissues and publishes exposure reports. The National Institute of Environmental Health Sciences (NIEHS) provides chemical fact sheets and current environmental health concerns. The Household Products Database by Health and Human Services contains ingredient information for common consumer products, while organizations like Paula's Choice maintain ingredient dictionaries aligned with current toxicology data.","context":["A Case of Misguided Activism\nJust in time for fall, Starbucks announced a recipe change to their beloved Pumpkin Spice Latte recipe: it is removing the caramel coloring and adding real pumpkin.\nWhy? It’s the result of a misguided campaign, to make a 400-calorie beverage appear “healthier”, led by consumer groups, like the Center for Science in the Public Interest and self-proclaimed food activists like the “Food Babe” Vani Hari.\nThese groups have demonized the caramel coloring, which contains the chemical 4-methylimidazole (4-MEI). It is a natural byproduct of roasting coffee beans and other processes that involve high temperatures, including the production of certain caramel colors (see: Maillard reaction). The concern does not seem to be based on science. Regulatory authorities in the U.S., Canada, Europe and Hong Kong have determined that that there is no immediate or short-term risk from 4-MEI levels typically encountered in food as a result of the addition of caramel coloring.\nThese groups claim that 4-MEI is a known carcinogen, ignoring the fact that the dose required to cause cancer in lab mice is over 80 milligrams per kilogram of body weight everyday for 106 weeks. This means the average adult male in the U.S., weighing about 195.5 pounds, would need to consume over 7 grams of 4-MEI every day for over two years. They also don’t seem particularly concerned about “natural” 4-MEI in their coffee, soy sauce, beer or bread, but people are very worried about the exact same chemical when it is added in artificial coloring. Because PSLs are, for most people, not a dietary staple and only available for a short time of year, the amount of 4-MEI exposure from pumpkin spice lattes is likely a tiny fraction of one’s total exposure to 4-MEI.\nIs this decision designed to treat us to a safer beverage or trick us through marketing to make us think we are consuming a safer treat? I’m gonna go with trick and brilliant marketing.\nBecause the uproar is only about the artificial 4-MEI, and no one is talking about all the naturally formed 4-MEI we are exposed to (even in the same drink), all I can conclude is that Starbucks made these changes, not based on scientific evidence regarding potentially dangerous exposure limits and the toxicity of 4-MEI, but rather on market research in response to rising consumer fears propagated by so-called “food activists”.\nAs someone involved in toxicology research, I am all in favor of reducing toxic exposures. This is a noble goal. Unfortunately, targeting the food villain of the month is a largely ineffective way to accomplish this. Consumers and journalists have an important role to play, but that all depends on having access to accurate, current information and working with scientists and regulators to work towards this goal.\nThese campaigns against single chemicals lead companies like Starbucks to change their recipes not based on science, but because activists like Vani Hari and Michael Pollan, who won’t buy their food anyway, can’t pronounce their ingredients. These campaigns usually do not reduce toxic exposures overall and they do not educate or empower consumers.\nThe tale of the pumpkin spice latte is a perfect example of how these campaigns are based on fear and a fallacious appeal to Nature, with little regard for the scientific data. Even when there are data to suggest that there might be some toxicity, these campaigns are rarely evidence-based. There is a crying wolf factor as well; the scientific illiteracy of many of these activists makes it easier to dismiss all concerns about toxic exposures, even the valid ones, as unfounded chemophobia.\nThese misguided campaigns are often counterproductive for reducing toxic exposures and effecting positive change.\nBisphenol A and regrettable substitutions\nThe campaigns against specific chemicals often overlook the big picture resulting in what has been dubbed “regrettable substitutions”. This refers to the removal of a chemical without considering the alternatives that might replace it. A now classic example of regrettable substitutions concerns Bisphenol A (BPA). Bisphenol A is thought to be an endocrine disrupting chemical that scientists have studied and continue to study extensively. Although there is still disagreement about the effects of BPA in humans, for sake of argument, let’s assume there is no question about whether BPA is toxic at real life exposure levels.\nWhen consumer groups bypassed scientists and regulators and convinced companies to remove BPA, it was replaced with Bisphenol F and Bisphenol S. Their main virtue was that they had been studied far less than BPA and were not in the crosshairs of activists and so they were easily substitutable. But in fact studies show they have similar activity and potency as BPA in cellular and animal models and similar biological effects in humans as BPA. Thus, while these campaigns reduced exposure to BPA specifically, they did not reduce exposure overall to phenols, which have similar effects. They may even have made it more difficult to make regulatory changes since there is less research on BPF and BPS.\nThere is real science behind how to choose safe alternatives when phasing out a chemical. These campaigns bypass that process completely and would likely be better able to reduce toxic exposures by pushing for adoption of adequate chemical alternatives assessment.\nAntibiotic resistance and false evidence\nLast week, Subway announced that they will only be serving meat from animals that have never been treated with any antibiotics, even to treat a sick animal.\nThe brand recently communicated a commitment to transition to only serving chicken raised without antibiotics important to human medicine. Today, the brand confirmed that it is beginning to transition to serving only protein from animals that have never received antibiotics across all of its 27,000+ U.S. restaurants in early 2016.\nThis announcement came as an effort to address concerns by activists about antibiotic resistance. They motivated people to join the campaign by scaring them about toxic antibiotic residues in meat products. Food activists all over the Internet are commending Subway for this decision. Vani Hari gushed on her blog:\nI had my bags packed and ready to go to deliver over 250,000 petition signatures with several consumer advocacy groups to Subway headquarters this week but all my plans came to an abrupt halt.\nSubway just announced that they have committed to eliminating the use of antibiotics in ALL of their meat in the U.S. – and they also provided a timeline. It’s never felt so good to cancel my plans!\nFarmers, on the other hand, are dismayed that this policy did not even allow for treating sick animals even if the antibiotics are not used in human medicine and completely ignored that there are very strict regulations and testing to ensure that there are no antibiotic residues in dairy, meat, poultry and egg products. In other words, the campaign did more to fuel mistrust of farmers than educate the consumer.\nTo be clear, antibiotic resistance is a looming problem. However, antibiotic residues in our meat are not a factor in this. The actual concerns about antibiotic resistance have nothing to do with drug residues in your meat; they are less about the treatment of sick animals and more about the use of antibiotics for growth promotion and prevention of disease (prophylaxis). Subway’s marketing decision may make food activists happy. However, actual policy only requires farmers to follow existing laws and the new voluntary FDA regulations that were announced in June of this year, before these groups launched their campaigns against Subway. In reality, this ‘victory’ will accomplish little in the very important battle against antibiotic resistance.\nAntibiotic resistance is a serious enough problem we should all worry about that there is no need to make up problems about exposure to antibiotic residues to justify taking action. Activists are motivating by misleading people and, as a result, it makes it easier for people to dismiss all concerns, even the valid ones, about antibiotic resistance.\nThese examples demonstrate how chemophobic hysteria detracts from the message when there are actual issues of concern, making it more difficult for valid concerns to be taken seriously. Organizations like the Environmental Working Group, The Campaign for Safe Cosmetics, and people like Vani Hari and Michael Pollan, seem to completely disregard the basic principles of toxicology and science to promote the idea that there is no acceptable level of any synthetic chemical, ever.\nMany scientists and skeptics remain doubtful about suspected endocrine disrupting chemicals and issues of antibiotic resistance, partly because the groups speaking out most loudly about these concerns have shown a lack of scientific credibility on other issues. For example, this past weekend, The Huffington Post ran an article about endocrine disrupting chemicals, but had to throw in some nonsense about glyphosate causing birth defects, even though it is neither teratogenic nor endocrine disrupting. Because they continue to misrepresent facts, to draw inflammatory conclusions, or to seemingly just make things up, these campaigns are, ironically, counterproductive in the long term for the goal of reducing toxic exposures.\nFor consumers who are concerned about chemicals, there is a lot of science-based information and it’s publicly available!\nNone of this is meant to say that toxic exposures aren’t an issue. But not all chemicals are toxic in the doses that we are typically exposed to. There is a lot of publicly available information about our exposures and the associated health effects. The Centers for Disease Control (CDC), the Department of Health and Human Services, and National Institute of Environmental Health Sciences (NIEHS) all maintain databases and websites meant for the public to find the most up-to-date scientific information.\n- The National Health and Nutrition Examination Survey (NHANES) at the CDC has collected enormous amount of demographic, socioeconomic, dietary, and health-related data about the U.S. population. Data from NHANES is used to generate the CDC growth charts for kids that many of us are familiar with. The data is also used to calculate the prevalence of diseases and risk factors for disease, in epidemiological studies and to identify areas of concern that need to be addressed by public health officials. Much of the data collected as a part of the survey and the analysis of this data is available on the CDC website. Data on chemical exposures is included in this survey and that data is compiled into tables that are published on the CDC website as well.\n- The National Biomonitoring Program, also run by the CDC, assesses over 300 environmental chemicals in human tissues and fluids and the nutritional measures in the US population. This data are used to figure out which chemicals get into our bodies and where they go within the body (blood, urine, saliva, breast milk), to monitor how many people are exposed above known toxicity levels and to track trends over time. The most recent assessment of exposures, the National Report on Human Exposure to Environmental Chemicals, in the U.S. was published earlier this year. This document contains all the data about how much of each chemical was detected and links to summary information about what these numbers mean and a chemical fact sheet on each chemical. NBP also publishes the National Report on Biochemical Indicators of Diet and Nutrition in the U.S.\n- NIEHS also funds exposure assessments, especially as it relates to children’s health. They recently launched an expanded program, the Children’s Health Exposure Analysis Resource, to help researchers add or expand the environmental exposures studied.\n- NIEHS also publishes chemical fact sheets and information about current areas of concern in environmental health sciences.\n- The Household Products Database is maintained by the U.S. Department of Health and Human Services. The database, which was started in 1995 and is updated twice a year, contains information about the most common non-food and non-pharmaceutical consumer products. It provides the ingredients for a huge number of products and links out to databases like ToxNet that contain the toxicology data on those ingredients. Information about food-related and pharmaceutical products are available on the FDA website.\n- Paula’s Choice maintains an ingredient dictionary that is much more in line with current toxicology data that EWG’s database. Their ratings take into account dose, mode of exposure and formulation; all things that EWG seems to ignore in their assessments.\nWhat are effective strategies for reducing toxic exposures at a public health level?\nFirst and foremost, be skeptical and apply reasoning and critical thinking when you read a claim. Educate yourself with accurate, science-based evidence. This means information from reputable, peer-reviewed scientific journals. If you are not familiar enough with a field to assess whether a journal is reputable, find science communicators with established reputations for reporting science accurately. Take advantage of the publicly available resources, including those listed above.\nRemember that no exposure occurs in isolation and that exposure to a chemical does not necessarily mean there is an ill effect. Even with these toxic exposures, toxicologists are often talking about small effects that can often be counteracted through positive exposures. Dr. Robin Whyatt, Deputy Director of the Columbia Center for Children’s Environmental Health said the following on an NIEHS podcast about phthalates that captures this idea (emphasis mine).\nPeople are exposed to a lot of different compounds but we know that eating a really good diet during pregnancy is absolutely critical and has enormous beneficial effects, that taking prenatal vitamins is very beneficial and probably the key thing in terms of a child’s development is stimulation of the child. Read to your child. Play with your child. Talk to your child. All those things are just incredibly important and probably have much more effect, positive effect than these chemicals are having negative effects. So it’s really important to keep this in perspective. This is one exposure. It’s worth trying to avoid, but you can do a whole lot to help your child by the way you eat and by how you play with your child.\nEncourage funding of research to fill the gaps in our knowledge. Toxicology and exposure science are making huge methodological and technical advances. Today, we can do so much more than screen just one compound at a time for mutagenicity and for whether it causes cancer. Regulators can only make decisions based on the evidence. Help them have more evidence by campaigning for increased funding for toxicology research. This funding must come from both public agencies and industry. Yes, I wrote industry. As those who stand to profit from this research, industry needs to bear some of the cost burden of this research, just as pharmaceutical companies contribute to clinical trials. Taxpayers should not bear this burden alone.\nLearn about the different regulatory mechanisms for different classes of chemicals. Chemicals are regulated based on how they are used. Pesticides are regulated differently than food additives, differently than cosmetics, differently than drugs, and differently than consumer products. Each class requires different levels of pre-market testing, different types of monitor and different procedures for handling violations. Multiple agencies play different roles in these regulatory processes. Without understanding how these processes work and how they are different, it is not possible to encourage effective reforms.\nAbove all, avoid inflammatory rhetoric and hysterical chemophobia; stick to the facts and the evidence.\nAlison Bernstein a neuroscientist studying the role of epigenetics in neurodegenerative diseases and toxic exposures. She lives in Atlanta with her husband, 2 kids, and 2 cats. You can follow her on Facebook and G+, where she writes as “Mommy PhD”, and on Twitter @mommyphd2.","Common Endocrine-Disrupting Chemicals and Women’s Health\nFemale reproductive health may be affected by a wide range of chemicals present both in the environment and within consumer products. Called endocrine-disrupting chemicals (EDCs), these substances have been linked to an increased incidence of early puberty, pregnancy length disorders, and other reproductive health abnormalities.1 In 2012 alone, the US produced 9.5 trillion pounds of EDCs, which are embedded in products such as pesticides, plastics, chemical drugs, and even personal hygiene products.1 Endocrine-Disrupting Chemical Exposure EDCs can be grouped according to their origin as follows: industrial (e.g., dioxins, polychlorinated biphenyls [PCBs], and alkylphenols), agricultural (pesticides, insecticides, herbicides, phytoestrogens, and fungicides), residential (phthalates, polybrominated biphenyls, and bisphenol A [BPA]), and pharmaceutical (parabens); even heavy metals such as cadmium, lead, mercury, and arsenic may be included in the list of EDCs.2 The most common exposure pathways are through inhalation, food intake, and direct contact.2 Personal care products, marketed uniquely to women, are a specific source of EDC exposure. The most widely found EDCs in personal care products include:\nResearch suggests that women ages 18 to 34 are more likely to be heavy buyers of personal care products, purchasing more than 10 types of products a year.4 What’s more, these women and their children may experience heightened vulnerability to these environmental chemicals if the products are used during sensitive periods of development such as preconception or pregnancy.5 In an analysis of National Health and Nutrition Examination Survey (NHANES) data, increased levels of phenolic 2,5-DCP from dichlorobenzene (DCB), a common fumigant, correlated with earlier menarche in girls aged 12-16.6 The researchers measured a single chemical, but there are hundreds of known endocrine disruptors in our everyday environment. In a different analysis of NHANES data, 15 known toxicants were identified as contributors to early menopause in women7 while other EDCs have been linked to earlier menarche.6 Polycystic ovarian syndrome (PCOS) has also been associated with EDC exposure, particularly bisphenols.1,2\nToxins have been known to be endocrine disruptors, and what that means is that these toxins are estrogen mimetics—they act like estrogen, but they are dysfunctional hormones. As a result, they get in and they start changing things like metabolism; they start binding to receptors and upregulating things that perhaps shouldn’t be upregulated. -IFM educator Deanna Minich, PhD, FACN, CNS.\nBisphenols & Female Health Exposure to bisphenol A (BPA) is ubiquitous, with more than 90% of Americans having traces of BPA in their bodies.8In fact, the first endocrine-disrupting chemical (EDC) identified in 1936 was BPA; later, in 1950, it was discovered that BPA could be polymerized for the manufacturing of plastics.9 The United States Environmental Protection Agency has established a safe level of 50µg/kg/day and the European Food Safety Authority has established a tolerable daily intake below 4µg/kg/day;1 however, data from the literature suggest that exposure to BPA, even at low doses, may result in adverse health effects, particularly among pregnant women.9 These may include:\nAdverse reproductive outcomes\nBecause bisphenol molecules have an effect similar to estrogens, they may influence hormonal regulation and the activity of estrogen receptors.11 Bisphenols may also negatively influence oocyte maturation, spermatogenesis, and the development of the reproductive system. A 2019 review of the research literature suggests that bisphenol S (BPS), which has now been used to replace BPA in many products, may have comparable negative effects on reproduction and may cause severe fertility disorders.11 BPS is an industrial alternative to the endocrine disruptor BPA and may be found in some products labeled “BPA-free.”11 Data on current human exposure levels of BPS and bisphenol F (BPF), which is also being used to replace BPA, is reflected in NHANES 2013-2014 data.12=3 BPA, BPS, and BPF were detected in 95.7, 89.4, and 66.5% of randomly selected urine samples, respectively, indicating that exposure of the general US population to BPA and its substitutes may be nearly ubiquitous. According to the European Chemical Agency, 1,000 to 10,000 million metric tons of BPS are manufactured or imported annually to the European Economic Area alone.13 In humans, Lee et al observed associations among high urinary BPA levels and increased serum levels of testosterone, estradiol, and pregnenolone in girls diagnosed with precocious puberty.10,14 In particular, a correlation was observed between estrogen metabolism and BPA levels irrespective of the type of precocious puberty; the correlation, however, does not imply causation.14 In another compelling study, serum BPA concentrations were higher in women diagnosed with PCOS compared to women in the healthy groups.9,14 In addition to PCOS, higher BPA levels have been associated with an increased risk of developing ovarian failure, infertility, and fibroids.3 BPA is known also to cause adverse reproductive outcomes in non-human animals.10 Specifically, it has been demonstrated that BPA disrupts the HPG axis in mice, rats, and zebrafish.10 An interesting 2018 study found that in aquatic larvae of C. riparius midges, the general transcriptional profile of several genes were affected after 24-hour exposure to BPS, especially those involved in endocrine and biotransformation pathways.11 The study suggests that BPS activated the transcription of genes encoding nuclear receptors, concomitant with an increase in expression levels of other genes involved in the hormonal pathway mediated by ecdysone, indicating that BPS may be acting as a hormone agonist.12 Clinical Applications: Education Is Key Educating women about EDCs, including guidance about potentially problematic ingredients in personal care products, may help reduce exposure. Research suggests that many people are unaware of the sources of endocrine disruptors; in 2017, Rouillon et al reported that in France, 54.0% of pregnant women or those in the postpartum period were unaware of endocrine disruptors and had limited knowledge about potential sources of exposure.16,17 A randomized intervention trial for female college students in the United States effectively reduced exposure to BPA by promoting improved hygiene habits and the use of BPA-free cosmetics and glass food and water containers.16,18 In addition to education, improving biotransformation and aiding in the elimination of toxicants may also assist in fertility and possibly overall health. Food and nutrients that support liver biotransformation may help alleviate toxic burden, allowing the body to operate more efficiently and improve resilience. IFM’s Detox Food Plan benefits patients by helping them eat more of those foods that support pathways in the liver for healthy elimination, as well as reduce additional exposures to toxic compounds. In functional medicine, practitioners often utilize the phytonutrient-dense Detox Food Plan to support intestinal and liver function during the metabolic detoxification process. Functional medicine clinicians guide patients on how to reduce their exposure to EDCs and develop and organize individual treatment protocols to help the body deal with these toxicants using a multi-pronged approach that includes diet, nutraceuticals, botanicals, and behavioral interventions."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:ebdff4f2-5eaf-4cf5-a5b5-3697ba68763e>","<urn:uuid:aaf89773-9fa0-461c-a959-68535e9b2d16>"],"error":null}
{"question":"Were both the MiG-21MF and F-4 Phantom II used in combat during the Vietnam War?","answer":"Yes, both aircraft saw combat in Vietnam. The US Air Force and Navy had their first encounters with the MiG-21MF in the skies over North Vietnam in the early 1970s, where its improved engine and afterburner surprised aircrews. The F-4 Phantom II also saw combat service in the Vietnam War, and later went on to serve in Operation Desert Storm.","context":["Trumpeter 1/32 MiG-21MF Fishbed J Kit First Look\n|Date of Review||April 2007||Manufacturer||Trumpeter|\n|Subject||MiG-21MF Fishbed J||Scale||1/32|\n|Kit Number||2218||Primary Media||Styrene, White Metal, Resin|\n|Pros||Best kit of the MiG-21 in any scale||Cons|\n|Skill Level||Intermediate||MSRP (USD)||$74.95|\nThe MiG-21 was the first generation of Mikoyan production aircraft designed to operate above Mach 2. Evolved from the MiG-19 series, the MiG-21 featured a delta wing and the R-11F-300 afterburning engine. While the MiG-21 retained the nose intake of its predecessors, a movable centerbody shock cone was used to manage the volume and velocity of the air reaching the engine.\nThe first generation of MiG-21 to enter production was the F-series (MiG-21F, MiG-21F-13) which were armed with the NR-30 30mm cannon internally as well as the ability to carry IR-guided missiles on two underwing pylons. This first MiG-21 series was a day-only interceptor as it did not have an intercept radar.\nThe next generation was the P-series (MiG-21PF, MiG-21PFM) which did have the intercept radar, but no internal gun and was still limited with two underwing pylons. It was powered by the slightly improved R-11F2S-300 afterburning engine.\nThe third generation was the M-series (though there are a few others in this family) with the MiG-21MF being the common version delivered to Warsaw Pact and exported quite extensively. This version of the MiG-21 family retained the intercept radar, regained an internal gun (the GSh-23 23mm), and now had four underwing pylons. It was powered by the improved R-13-300\nThe US Air Force and Navy had their first 'close encounters' with the MiG-21MF in the skies over North Vietnam in the early 1970s where it's improved engine and afterburner surprised aircrews when they were not able to outrun this new variant as they had the earlier MiG-21s in VNAF service. The MiG-21MF has been employed in combat in the Middle East, Persian Gulf and other parts of the world and, like other aircraft types, its successes were based upon the skills of the pilot. In capable hands, the MiG-21MF was fast, highly maneuverable, and enjoyed the mix of missiles and guns to kill its prey.\nThere are few 30+-year-old fighter aircraft still in service in the world, but the MiG-21MF not only continues to see front-line service, it has been the subject of numerous modernization programs by companies from around the world.\nWhen I first heard that Trumpeter was going to release the MiG-21 in 1/32 scale, I still wasn't convinced at the time that they could keep up the level of detail that was presented in their first 1/32 offerings. I've since learned that they were only warming up! I also thought it odd that Trumpeter would choose as their first installment the MiG-21MF as Revell's 1/32 kit was not bad at all! Since they did both the MiG-21MF Fishbed J and MiG-21PF Fishbed D, that left a wide range of subjects open. Well they did to the MiG-21MF and they did it beyond my expectations, and then they followed up with the MiG-21F-13 Fishbed E and MiG-21UM Mongol B which are two new subjects in this scale. These were of course followed by a few other MiG-21 variants produced by Chengdu in China, the J-7 and the export F-7.\nWhen you open the box, you are presented with twelve parts trees molded in light gray styrene, one tree molded in clear, a white metal intake centerbody radome (that doubles as ballast), white metal landing gear struts, rubber tires, and a sprue of resin parts for an optional gun-loading diorama.\nThe best part is that this kit design pre-dates Trumpeter's use of photo-etched flight control hinges, so installation and positioning of the flaps and flight control surfaces is simple.\nThe wings are correctly represented with the non-Fowler engine-blown flaps that equipped the MiG-21s from the MiG-21PFM Fishbed F and beyond.\nThe cockpit tub is quite detailed, though some modelers might find the molded-in details a little on the soft side. There is an excellent photo reference published for this aircraft (reviewed here) that will help you enhance the look and detail to your taste. The early production MiG-21MFs featured cockpits that were a mixture of black and dark gray, so one could use the kit cockpit as-is with no problems. Later MiG-21MFs were produced with Russian turquoise green cockpits and remanufactured aircraft were repainted the same way (check your references). There are also some excellent aftermarket cockpits produced for this kit from Cutting Edge and Black Box, as well as detail sets from Eduard, Part, and others.\nThe kit features a very detailed engine, which is a kit all unto itself. The only criticism that I have for this kit is with the engine, however, as it still has the strange spiral compressor face that is definitely not present on the R13F engine series. This 'feature' is also present in the MiG-21F-13 and MiG-21UM kits.\nThe MiG-21MF was able to employ a wide range of weapons in its air-to-air and air-to-surface missions. In the air-to-air arena, it could carry:\n- 2 - 4 K-5 (RS-1) AA-1 Alkali (radar aimed)\n- 2 - 4 K-13 (R-3S) AA-2 Atoll (copy of the IR-guided AIM-9B Sidewinder)\n- 2 - 4 K-13R (R-3R) AA-2 Atoll (radar guided)\n- 2 - 4 R-60 AA-8 Aphid\nThe Trumpeter kit provides 2 x AA-1, 6 x K-13, 2 x K-13R. You'll have to liberate R-60s out of your 1/32 Su-27 or MiG-29 kits, or perhaps you have one or more of the Trumpeter 1/32 Soviet/Russian aircraft weapons sets.\nIn the air-to-ground arena, the MiG-21 could carry a wide range of bombs, rockets, rocket pods, gun pods, and more. In the kit, Trumpeter provides a pair of UB-16-57 and UB-32-57 rocket pods, OFAB-250 bombs.\nDepending on the mission profile, the MiG-21MF usually carried a centerline fuel tank (two types provided in the kit) plus two 490 liter tanks on the outboards, leaving the inboard pylons free for missiles, bombs, rockets, whatever. If the duration was shorter, the outboard tanks were offloaded and weapons carried on all four pylons.\nAs with the other Trumpeter MiG-21s, there is a white-metal centerbody nose cone for ballast, and features white metal landing gear struts and rubber tires.\nAmong the features/options in this kit:\n- Detailed cockpit\n- Detailed engine\n- Positionable flaps\n- Positionable ailerons, rudder, and stabilators\n- Removable tail w/optional tail section dolly\n- Positionable canopy\n- Boarding ladder\n- Positionable speed brakes\n- Centerline external fuel tank (two types provided)\n- Nice selection of weapons (discussed above)\n- Pilot and ground crew figures\nWhich brings us to another interesting feature of the kit. One sprue contains four ground crew figures, three of which are loading the GSh-23 gun with 23mm ammunition from the resin-cast loader, one crew figure is posed reloading the brake parachute in the tail. Very nice touch!\nMarkings are provided for two examples:\n- MiG-21MF, 23+15, JG 1, Unified Luftwaffe\n- MiG-21MF, Iraqi Air Force\nAn extensive set of maintenance stencils are provided on this sheet.\nTrumpeter has provided a kit that easily outshines any other MiG-21 kit on the market. This is definitely the best MiG-21 kit produced to date. This kit is highly recommended!\n- MiG-21 Online Reference\n- MiG-21, Frantisek Koran, Wings & Wheels Publications, 2004, ISBN 80-86416-40-2\n- MiG-21 Fishbed, Yefim Gorgon & Bill Gunston, Aerofax, 1996, ISBN 1-85780-042-7\n- MiG-21, 4+ Publications, 1991, ISBN 80-900708-09\n- MiG-21 In Action, Don Linn & Don Sperling, Squadron/Signal Publications, 1993, ISBN 0-89747-290-X\n- Mikoyan MiG-21, Bill Gunston, Osprey, 1986, ISBN 0-85045-734-3","Price excl. VAT\nAvailable as instant download\n- Article number: AS13614\n- Publisher: Milviz\n- Language: English\n- Current version: A1.170721\nThe McDonnell two-place, twinjet, all-weather F-4 Phantom II, with top speeds more than twice that of sound, was one of the most versatile fighters ever built. The F-4 established 16 speed, altitude and time-to-climb records.\nIn 1959, its prototype set the world altitude record at 98,556 feet. In 1961, an F-4 set the world speed record at 1,604 mph on a 15-mile circuit. F-4s saw combat in both the Vietnam War and Operation Desert Storm and served with the air forces of 11 countries in addition to the United States. Both U.S. military flight demonstration teams, the Navy Blue Angels and the Air Force Thunderbirds, flew the Phantom II from 1969 to 1973.\nMax Speed: Mach 2.23 (1,472 mph, 2,370 km/h)\nService Ceiling: 60,000 ft (18,300 m)\nRate of Climb: 41,300 ft/min (210 m/s)\nPower Plant: Two 17,900-pound-thrust General Electric J79-GE-17A turbojets\nArmament: 15,983 pounds of weapons\nA Definitive Simulation\nUtilizing every resource available to us and spending countless hours in design, testing, revising, and more testing again, we're confident that our model represents an extremely true-to-life rendition of the real world aircraft. We've taken great care in presenting an authentic environment for the virtual pilot; closely reproducing the original in looks, systems, sounds and flight modelling.\nAttention To Detail\nThe cockpit of an F-4 represents a busy, complex workplace for the pilot. However, we've strived to perfect the feel of actually sitting in the pilot’s seat, being able to scan your vital instrumentation with a glance, all replicated with high resolution textures and smooth 3D animation. Being able to run through checklists, flipping all of the needed switches and toggles, monitoring systems as they spring to life. Being able to light the engines and feel the rumble of the massive turbojets behind you. Every bit of it, in your control and command!\nChoose Your Loadout\nWe've included a very large selection of authentic weapons and pods to outfit your F-4 with. Our configuration menu lets you setup and configure your payload any way you wish, allowing you to configure for almost any mission. And of course, adding or removing ordinance or fuel will have an appropriate effect on flight dynamics and handling characteristics.\nVariety And Possibility\nSeeing as the F-4E was the most numerous Phantom variant, with some 1,370 built, as well as the most widely exported Phantom, having seen service with 9 countries outside of the US, there is no shortage of interesting liveries to consider. Our package ships with numerous high resolution liveries, and we also have made available a detailed paint kit for users to create their own!\n- Realistic systems and avionics\n- Realistic startup and shutdowns\n- Fully functional ACM (loadout menu)\n- Large selection of weapons and pods\n- Flight dynamics created by Bernt Stolle\n- Realistic DX10/DX11 night lighting, landing lights and custom effects\n- Includes numerous highly detailed liveries\n- High quality sound set recorded from a real F-4\n- High quality external model using normal and specular maps\n- High quality internal model complete with custom 3D gauges\n- Includes external F-4J/S model (not carrier capable, no ILS)\n- High resolution paint kit available\n- Highly detailed product manuals included\n- Flap and Gear indicators\n- Slimelight on wing for J version\n- Radar scope reflection rotated 90* CCW\nSystem Requirements (Minimum):\nMicrosoft Flight Simulator X (Acceleration), FSX: Steam Edition or Lockheed Martin - Prepar3D V3/V4\nWindows Vista, Windows 7 (use in all other versions of Windows is unsupported)\nProcessor: 2.6 Ghz or higher\nMemory: 4 GB RAM\nGraphics: DirectX®9 compliant video card or greater, 1024 MB video RAM or higher\nHard Drive: 2 GB available space\n.pdf Manual (English): >> View here <<\nFree Livery Set : >> Click here <<"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:44595382-3b1d-44ab-b980-438c5661a13b>","<urn:uuid:9b5e173d-a48b-4a92-af91-45043dc0c8f9>"],"error":null}
{"question":"What characters are allowed in MySQL database identifiers?","answer":"Unquoted identifiers can contain any alphanumeric characters in the system default character set (utf8), plus the underscore ('_') and dollar ('$') characters. They can start with any legal character, including digits, but cannot consist entirely of digits. For database and table identifiers specifically, the period ('.') character and pathname separator characters ('/' or '\\') are not allowed, even in quoted identifiers. This is because databases are represented as directories and tables as files on disk.","context":["Almost every SQL statement refers in some way to a database or its constituent elements. This section describes the syntax and case sensitivity rules for identifiers that refer to databases, tables, columns, indexes, and aliases.\nReferring to Elements of Databases\nWhen you use identifiers to refer to elements of databases, you are constrained by the characters you can use and the length that identifiers can be. The format of identifiers also depends on the context in which you use them. Another factor that affects naming rules is that the server can be configured to use different SQL modes.\n- Legal characters in identifiers. Unquoted identifiers can consist of any alphanumeric characters in the system default character set (utf8), plus the characters ‘_‘ and ‘$‘. Identifiers can start with any character that is legal in an identifier, including a digit. However, an identifier cannot consist entirely of digits because that would make it indistinguishable from a number. MySQL’s support for identifiers that begin with a number is somewhat unusual among database systems. If you use such an identifier, be particularly careful if it contains an ‘E‘ or ‘e‘ because those characters can lead to ambiguous expressions. For example, the expression 23e + 14 (with spaces surrounding the ‘+‘ sign) means column 23e plus the number 14, but what about 23e+14? Does it mean the same thing, or is it a number in scientific notation? You should also be careful about using identifiers such as 0x1020 that begin with 0x because they might be interpreted as hexadecimal constants.\nIdentifiers can be quoted (delimited) within backtick characters (‘´‘), which allows use of any character except backtick or a byte with value 0 or 255:\nCREATE TABLE ´my table´ (´my column´ INT);\nQuoting is useful when an identifier is an SQL keyword or contains spaces or other special characters. Quoting an identifier also allows it to be entirely numeric, something that is not true of unquoted identifiers. To include an identifier quote within a quoted identifier, double it.\nFor database and table identifiers, there are two additional constraints, even for identifiers that are quoted. First, you cannot use the ‘.‘ character, because it is used as the separator character in qualified name notation of the forms db_name.tbl_name and db_name.tbl_name.col_name. Second, you cannot use the Unix or Windows pathname separator characters (‘/‘ or ‘\\‘). The pathname separator is disallowed in database and table identifiers because databases are represented on disk by directories, and tables are represented on disk by at least one file. Consequently, these types of identifiers must contain only characters that are legal in directory names and filenames. The Unix pathname separator is disallowed on Windows (and vice versa) to make it easier to transfer databases and tables between servers running on different platforms. (Suppose that you were allowed to use a slash in a table name on Windows. That would make it impossible to move the table to Unix, because filenames on that platform cannot contain slashes.)\nYour operating system might impose additional constraints on database and table identifiers. See “Operating System Constraints on Database and Table Naming,” in Chapter 10, “The MySQL Data Directory.”\nColumn and table aliases can be fairly arbitrary. You should quote an alias within identifier quoting characters if it is an SQL keyword, is entirely numeric, or contains spaces or other special characters. Column aliases also can be quoted with single quotes or double quotes.\nServer SQL mode. If the ANSI_QUOTES SQL mode is enabled, you can quote identifiers with double quotes (although backticks still are allowable).\nCREATE TABLE \"my table\" (\"my column\" INT);\nNote: Enabling ANSI_QUOTES has the additional effect that string literals must be written using single quotes. If you use double quotes, the server will interpret the value as an identifier, not as a string.\nFunction names normally are not reserved and can be used as identifiers without quotes. However, if the IGNORE_SPACES SQL mode is enabled, function names become reserved and must be quoted if used as identifiers.\nFor instructions on setting the SQL mode, see “The Server SQL Mode” later in this chapter.\nIdentifier length. Identifiers for databases, tables, columns, and indexes can be up to 64 characters long. Identifiers are stored using utf8 characters. (Before MySQL 4.1.5, the maximum identifier length is 64 bytes, not characters. Because utf8 characters take from one to three bytes each, the effective maximum identifier length is less than 64 characters if you use multi-byte characters.) Aliases can be up to 256 characters long.\nIdentifier qualifiers. Depending on context, an identifier might need to be qualified to make clear what it refers to. To refer to a database, just specify its name:\n- A fully qualified table name consists of a database identifier and a table identifier:\nSHOW COLUMNS FROM db_name.tbl_name;\nSELECT * FROM db_name.tbl_name;\nA table identifier by itself refers to a table in the default (current) database. If sampdb is the default database, the following statements are equivalent:\nSELECT * FROM member;\nSELECT * FROM sampdb.member;\n- A name written as db_name.tbl_name.col_name is fully qualified.\n- A partially qualified name written as tbl_name.col_name refers to a column in the named table in the default database.\n- An unqualified name written simply as col_name refers to whatever table is indicated by the surrounding context. The following two queries use the same column names, but the context supplied by the FROM clause of each statement indicates which table to select the columns from:\nSELECT last_name, first_name FROM president;\nSELECT last_name, first_name FROM members;\nSHOW TABLES FROM db_name;\nTo refer to a table, you have two choices:\nIf no database has been selected, you cannot refer to a table without specifying a database qualifier because the server cannot tell which database the table belongs to.\nTo refer to a column, there are three choices: fully qualified, partially qualified, and unqualified.\nIt’s usually unnecessary to supply fully qualified names, although it’s always legal to do so if you like. If you select a database with a USE statement, that database becomes the default database and is implicit in every unqualified table reference. If you’re using a SELECT statement that refers to only one table, that table is implicit for every column reference in the statement. It’s necessary to qualify identifiers only when a table or database cannot be determined from context. For example, if a statement refers to tables from multiple databases, any table not in the default database must be referenced using the db_name.tbl_name form to let MySQL know which database contains the table. Similarly, if a query uses multiple tables and refers to a column name that is used in more than one table, it’s necessary to qualify the column identifier with a table identifier to make it clear which column you mean.\nIf you use quotes when referring to a qualified name, quote individual parts of the name separately. For example:\nSELECT * FROM ´sampdb´.´member´ WHERE ´sampdb´.´member´.´member_id´ > 100;\nDo not quote the name as a whole. This statement is illegal:\nSELECT * FROM ´sampdb.member´ WHERE ´sampdb.member.member_id´ >"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:b783b7db-dd47-494d-8f8a-a81b3ceab0f9>"],"error":null}
{"question":"What are the key differences between undular bores and giant vortex phenomena in fluid dynamics?","answer":"Undular bores are shallow-water nonlinear wavetrains that connect two different basic flow states and have a structure of a slowly modulated periodic wave with a solitary wave at the leading edge. Giant vortex phenomena, on the other hand, occur in rotating Bose-Einstein condensates where vortices are strongly pinned in a central hole with negative potential, showing no vortices in the annular bulk until a critical rotational speed is reached. This critical speed grows logarithmically with the small parameter, at which point vortices begin to appear in the annular bulk.","context":["+44 (0)1509 263171\nPlease use this identifier to cite or link to this item:\n|Title: ||Propagation of solitary waves and undular bores over variable topography|\n|Authors: ||Tiong, Wei K.|\n|Keywords: ||Undular bore|\nKorteweg-de Vries equation\nAdiabatic and non-adiabatic deformations\n|Issue Date: ||2012|\n|Publisher: ||© Wei King Tiong|\n|Abstract: ||Description of the interaction of a shallow-water wave with variable topography is a classical and fundamental problem of fluid mechanics. The behaviour of linear waves and isolated solitary waves propagating over an uneven bottom is well understood. Much less is known about the propagation of nonlinear wavetrains over obstacles. For shallow-water waves, the nonlinear wavetrains are often generated in the form of undular bores, connecting two different basic flow states and having the structure of a slowly modulated periodic wave with a solitary wave at the leading edge.\nIn this thesis, we examine the propagation of shallow-water undular bores over a nonuniform environment, and also subject to the effect of weak dissipation (turbulent bottom friction or volume viscosity). The study is performed in the framework of the variable-coefficient Korteweg-de Vries (vKdV) and variable-coefficient perturbed Korteweg-de Vries (vpKdV) equations. The behaviour of undular bores is compared with that of isolated solitary waves subject to the same external effects. We show that the interaction of the undular bore with variable topography can result in a number of adiabatic and non-adiabatic effects observed in different combinations depending on the specific bottom profile. The effects include: (i) the generation of a sequence of isolated solitons -- an expanding large-amplitude modulated solitary wavetrain propagating ahead of the bore; (ii) the generation of an extended weakly nonlinear wavetrain behind the bore; (iii) the formation of a transient multi-phase region inside the bore; (iv) a nonlocal variation of the leading solitary wave amplitude; (v) the change of the characteristics wavelength in the bore; and (vi) occurrence of a ``modulation phase shift\" due to the interaction. The non-adiabatic effects (i) -- (iii) are new and to the best of our knowledge, have not been reported in previous studies. We use a combination of nonlinear modulation theory and numerical simulations to analyse these effects. In our work, we consider four prototypical variable topography profiles in our study: a slowly decreasing depth, a slowly increasing depth , a smooth bump and a smooth hole, which leads to qualitatively different undular bore deformation depending on the geometry of the slope. Also, we consider (numerically) a rapidly varying depth topography, a counterpart of the ``soliton fission\" configuration. We show that all the effects mentioned above can also be observed when the undular bore propagates over a rapidly changing bottom .\nWe then consider the modification of the variable topography effects on the undular bore by considering weak dissipation due to turbulent bottom friction or volume viscosity. The dissipation is modelled by appropriate right-hand side terms in the vKdV equation.\nThe developed methods and results of our work can be extended to other problems involving the propagation of undular bores (dispersive shock waves in general) in variable media.|\n|Description: ||A Doctoral Thesis. Submitted in partial fulfilment of the requirements for the award of Doctor of Philosophy of Loughborough University.|\n|Appears in Collections:||PhD Theses (Maths)|\nFiles associated with this item:\nItems in DSpace are protected by copyright, with all rights reserved, unless otherwise indicated.","SS6 - Équations aux dérivées partielles / SS6 - Partial Differential Equations\nOrg: M. Esteban (Paris) et/and C. Sulem (Toronto)\n- STAN ALAMA, McMaster University, Hamilton, Ontario, Canada\nOn the Ginzburg-Landau model of a superconducting sphere in a\nWe consider the three-dimensional Ginzburg-Landau model for a\nspherical superconductor in a uniform applied field, in the limit as\nthe Ginzburg-Landau parameter tends to infinity. We derive a reduced\nlimiting energy for vortex curves when the applied field is of the\norder of the logarithm of the Ginzburg-Landau parameter. We show that\nthe global minimizer of this limiting energy must be either the\ndiameter (along the field direction) or the vortexless (Meissner)\nconfiguration, depending on the strength of the applied field. For\nthe full energy we show that there exists locally minimizing solutions\nof the Ginzburg-Landau equations whose vortices converge (in a sense\nof rectifiable currents) to the diameter when the field is in the\nrange predicted by the analysis of the limiting problem.\nThis represents joint work with L. Bronsard and J. A. Montero.\n- CLAUDE BARDOS, Laboratoire Jacques-Louis Lions, Université Denis Diderot,\n175 avenue du Chevaleret, Paris 75013\nApplications of regularity results of Lebeau and Kamotsky to\nthe understanding of the Kelvin Helmoltz and Rayleigh Taylor\nAfter the approach of Duchon and Robert on the Kelvin Helmoltz who\nconsidered it as a \"Dirichlet\" problem, the results of Lebeau and\nKamotski on the analyticity of the curve which may carry singularities\nleads to new ideas for the weak solutions of Kelvin Helmholtz and the\nRaleigh Taylor problems. Appearance of singularities, breaking of the\ncurve which carries the density of vorticity, necessity of the surface\ntension, etc. ...\n- LIA BRONSARD, McMaster University, Hamilton, Ontario, Canada\nGiant vortex and the breakdown of strong pinning in a\nrotating Bose-Einstein condensate\nWe consider a two-dimensional model for a rotating Bose-Einstein\ncondensate (BEC) in an anharmonic trap. The special shape of the\ntrapping potential, negative in a central hole and positive in an\nannulus, favors an annular shape for the support of the wave function.\nWe study the minimizers of the energy in the Thomas-Fermi limit for\ntwo different regimes of the rotational speed.\nFor bounded rotations we observe that the energy minimizers acquire\nvorticity beyond a critical rotational value, but the vortices are\nstrongly pinned in the central hole where the potential is negative.\nIn this regime, minimizers exhibit no vortices in the annular bulk of\nthe condensate. There is a critical rotational speed, which grows as\nthe logarithm of the small parameter, for which this strong pinning\neffect breaks down and vortices begin to appear in the annular bulk.\nWe derive an asymptotic formula for the critical speed, and determine\nprecisely the location of nucleation of the vortices at the critical\nThis represents joint work with A. Aftalion and S. Alama.\n- PIERRE DEGOND, MIP, CNRS and Université Paul Sabatier\nQuantum hydrodynamics and diffusion models derived from the\nThis work addresses the question of deriving hydrodynamic and\ndiffusion models from a macroscopic limit of quantum kinetic\nmodels. This question is of key importance in a certain number of\nfields such as plasma or semiconductor mesoscopic modeling.\nThe major difficulty to solve when investigating hydrodynamic limits\nis that of the closure relation (i.e. finding the equation-of-state\nof the system). This problem is resolved in the classical framework by\nassuming that the microscopic state is at local thermodynamical\nequilibrium. Such a state realizes the minimum of the entropy\nfunctional subject to local constraints of mass, momentum and energy.\nWe propose an extension of this method to quantum systems. This leads\nto hydrodynamic models with non-local closure relations. These models\npreserve the monotony of the entropy functional. The same approach\nleads to a proposal for quantum extensions of the classical Boltzmann\nor BGK collision operators. Finally, it allows the investigation of\ndiffusion limits of quantum systems (which are distinguished from\nhydrodynamic limits by the nature of the scaling) and leads to quantum\nextension of the well-established drift-diffusion and energy-transport\n- NASSIF GHOUSSOUB, UBC\nThe optimal evolution of the free energy of interacting gases\nand its applications\nBy studying the evolution of the free-internal, potential and\ninteractive-energies of an interacting system of particles, along\nthe geodesics of mass transport, one can recover many of the basic\ningredients of modern analysis (functional inequalities) in a unifying\nframework that gives a good introduction to several natural evolution\nequations of Fokker-Planck type. Does it all mean that much of\nanalysis is yet to be discovered?\n- ROBERT JERRARD, University of Toronto, Toronto, ON M5S 3G3, Canada\nRefined Jacobian estimates for a Ginzburg-Landau functional\nThe Jacobian estimates mentioned in the title of this talk are\nestimates that control the Jacobian of a (typically complex-valued)\nfunction in certain negative Sobolev norms by its Ginzburg-Landau\nenergy. Some model such estimates will be surveyed, and some\napplications sketched. The remainder of the talk will present new\nrefined Jacobian estimates that are nearly sharp in certain situations\nof interest in PDE applications.\n- A. NACHMAN, University of Toronto, Toronto, Canada\nReconstructing Inhomogeneous Nonlinearities from Boundary Data\nThis talk will briefly review the solution of the inverse boundary\nvalue problem of Calderon, and describe analogous questions for\nquasilinear and semilinear operators.\nFor a general class of nonlinear, inhomogeneous Schroedinger equations\nin a bounded planar domain, we show that the nonlinear potential can\nbe analytically reconstructed from knowledge of the corresponding\nDirichlet-to-Neumann map on the boundary. This is joint work with\n- JEAN-MICHEL ROQUEJOFFRE, CNRS-MIP and IUF, Université Paul Sabatier, Toulouse\nExistence and stability of conical reaction-diffusion fronts\nThe premixed part of a Bunsen burner flame can be modelled-in a very\ncrude approximation-by a reaction-diffusion equation in the plane\nwith conical conditions at infinity. This means that the fresh gases\nare located in some given cone of the lower half plane. Travelling\nfronts to such an equation, whose velocity is given by the\n(100-year-old) Gouy formula, can be shown to exist.\nIt turns out that the same approach can be carried out successfully in\nbistable equations, extending an earlier result of P. Fife (concerning\nalmost planar fronts for scalar equations), and more recent results of\nHaragus-Scheel (almost planar fronts for systems). Our results are\nvalid in the 2D and 3D cylindrically symmetric cases.\nJoint work with F. Hamel and R. Monneau.\n- J. C. SAUT, Université Paris-Sud, 91405 Orsay\nThe global Cauchy problem for the Kadomtsev-Petviashvili I\nThe Kadomstsev-Petviahvili (KP) equations are universal models to\ndescribe the dynamics of long dispersive weakly nonlinear waves\npropagating in one direction with weak transverse effects. There are\ntwo versions, the (focusing) KP I equation, and the (defocusing) KP II\nIt has been discovered recently (Molinet, Saut, Tzvetkov) that the\nKP I equation has a \"quasilinear\" behavior. In particular, contrary\nto the KP II equation, it cannot be solved by Picard iteration in any\nnatural Sobolev class. This makes the Cauchy problem for KP I quite\nIn this talk we will survey recent results on the global Cauchy\nproblem for KP I, due to L. Molinet, N. Tzvetkov and the lecturer, and\nto C. Kenig. We will in particular solve the Cauchy problem in the\nbackground of a line soliton.\n- ERIC SERE, Paris-Dauphine\nA Hartree-Fock approximation of the polarized vacuum\nAccording to Dirac's ideas, the vacuum consists of infinitely many\nvirtual electrons which completely fill up the negative part of the\nspectrum of the free Dirac operator D0 (this model is called the\n\"Dirac sea\"). In the presence of an external field, these virtual\nparticles react and the vacuum becomes polarized.\nIn this work, we consider a nonlinear model of the vacuum derived from\nQED, called the Bogoliubov-Dirac-Fock model (BDF). In this model,\nthe vacuum is represented by a bounded self-adjoint operator G\non L2 (R3). An energy of this vacuum is defined. We show the\nexistence of a minimizer of the BDF energy in the presence of an\nexternal electrostatic field. Then we prove that this minimizer is a\nprojector, which solves a self-consistent equation of Hartree-Fock\ntype. This minimizer is interpreted as the polarized Dirac sea.\nThis is joint work with Christian Hainzl and Mathieu Lewin.\n- TAI-PENG TSAI, University of British Columbia, Vancouver, BC V6T 1R9, Canada\nScattering for Gross-Pitaevskii equation\nThe Gross-Pitaevskii equation, a nonlinear Schroedinger equation with\nnon-zero boundary conditions, models superfluids and Bose-Einstein\ncondensates. Recent mathematical work has focused on the short-time\ndynamics of vortex solutions, and existence of vortex-pair traveling\nwaves. However, little seems to be known about the long-time behaviour\n(eg. scattering theory, and the asymptotic stability of vortices). We\naddress the simplest such problem-scattering around the vacuum\nstate-which is already tricky due to the non-self-adjointness of\nthe linearized operator, and \"long-range\" nonlinearity. In\nparticular, our present methods are limited to higher-dimension. This\nis joint work in progress with S. Gustafson and K. Nakanishi."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:28bd9779-b635-4bb3-b688-359dfda1cfef>","<urn:uuid:27913685-244a-4b38-9293-87594ad5837a>"],"error":null}
{"question":"When was the arquebus used in warfare?","answer":"The arquebus was used in warfare during the 15th to 17th centuries.","context":["On this page:\nDefinition of the noun arquebus\nWhat does arquebus mean as a name of something?\nnoun - plural: arquebuses\n- an obsolete firearm with a long barrel\nThe arquebus, or \"hook tube\", is an early muzzle-loaded firearm used in the 15th to 17th centuries. It can be distinguished from its predecessor, the hand cannon, by the presence of a matchlock firing action. Like its successor the musket, it is a smoothbore firearm, but was initially lighter and easier to carry.\nPrinted dictionaries and other books with definitions for Arquebus\nClick on a title to look inside that book (if available):\nAlso a Descriptive Notice of Modern Weapons by Paul Lacombe\nThe true miniature arquebus is the pistol, which has been supposed to have derived its name from the circumstance that its calibre corresponded with the diameter of the coin — the pistole. Apparently it was common in Germany in about 1512 ...\nThe Southern Review (1831)\n“ ' An arquebus is an admirable ...\nMr. Eternity (2016)\nby Aaron Thier\nThe arquebus is a terrible weapon that will only become more terrible as it's perfected. We have clocks so small they fit in your pocket, and wateroperated latrines, and all kinds of cranks and wheels that can do in one hour the work a hundred ...\nThe Canadian Journal (1865)\n— Arquebus is the German haken- buchse, ...\nby Princeton Review, Grace Roegner Freedman\nB The arquebus is a type of firearm that preceded the musket and rifle. It was used extensively in Europe during the sixteenth and seventeenth centuries. Although it was introduced into Japan in the sixteenth century, its use was banned ...\nAge Past: The Incian Sphere (2013)\nMain Rulebook V1 by Jeff Mechlinski\nDUR: 1 cost: 250 gold An arquebus is a powerful two-handed black powder weapon. It takes 3 actions to reload the weapon. It requires a charge of black- powder to ...\n—Arquebus is the German haken-buchse , ...\nA Library of Universal Knowledge and an Unabridged Dictionary of the English Language ...\nARPENT—ARQUEBUS. produced. Bass chords thus treated form an Alberti Bass , so named from Domenico Alberti (1730), a popular singer and player, who often played the bass in this style. A. sometimes means a harp-accompaniment.\nby James C. Bradford\nWatson ARQUEBUS, also known as the harquebus or hackbut, was developed in the mid-fifteenth century. A smoothbore, muzzle-loading weapon with a barrel of about three feet, it employed a matchlock in which the operator, known as an ...\nby Ian McNeil\nThe matchlock handgun was called an arquebus, andit was the Spanish arqebusierswho firstproved its advantages during a series of campaigns inthe first quarter ofthe fifteenthcentury, culminating inthe Battle of Pavia against the French ...\nIllustrating the Words in Their Different Significations by Examples from Ancient and Modern Writers by John Jamieson\narquebus a croc; Gl. Compl. But the term is more nearly ...\nA Military Dictionary (1876)\nComprising Terms, Scientific and Otherwise, Connected with the Science of War by G. de Saint-Clair-Stevenson\nArquebus — An ancient hand-gun, which was cocked with a wheel. It was the first form of weapon which could fairly be compared with the modern musket. The design was taken from the old cross-bow, its name conveying the meaning of ...\nA Dictionary of Military Knowledge by Edward Samuel Farrow\nARQUEBUS.— The first form of hand-gun which could fairly be compared with the modern musket. Those of earlier date were ...\nAn Etymological Dictionary of the Scottish Language: Illustrating the Words in Their Different Significations, by Examples from Ancient and Modern Writers; Shewing Their Affinity to Those of Other Languages, and Especially the Northern; Explaining Many Terms, Which, Though Now Obsolete in England, Were Formerly Common to Both Countries; and Elucidating National Rites, Customs, and Institutions, in Their Analogy to Those of Other Nations: to which is Prefixed, a Dissertation on the Origin of the Scottish Language (1808)\nby John Jamieson\narquebus a croc; Gl. Compl. But the term is more nearly allied to O. Fland. haecb-buyse, O. F r. hacqubute, sclopus. This is said by Cotgr. to be somewhat bigger than a musket. Croc denotes the grapple or hook, ...\nA Cyclopaedia of Costume Or Dictionary of Dress, Including Notices of Contemporaneous Fashions on the Continent: A general history of costume in Europe (1879)\nby James Robinson Planché\nas the Flemings appear to have used them some time before other nations, had a marked effect on defensive armour, and towards the close of the fifteenth the arquebus had become a formidable rival to the bow. In 1485 Henry VII. instituted ...\nThe London encyclopaedia, or, Universal dictionary of science, art, literature, and practical mechanics, by the orig. ed. of the Encyclopaedia metropolitana [T. Curtis]. (1839)\nby Thomas Curtis (of Grove house sch, Islington)\nARQUEBUS a Croc is a sort of small fort buffaloes or men to the city of Arracan. Here pin, which carries a ball of about three half they are again embarked on deep narrow boats, ounces; now only ...\nThe Encyclopaedia Britannica (1911)\nA Dictionary of Arts, Sciences, Literature and General Information\nThe “musket '' proper, introduced into the Spanish army by the duke of Alva, was much heavier and more powerful than the arquebus. Its bullet retained sufficient striking energy to stop a horse at 5oo and 600 yards from the muzzle. A writer in ...\nIn Four Volumes. A-Kut by John Jamieson\nThey were since called the arquebus with a hook, on account of a little hook, cast with the piece ; they are placed on a kind of tripod, are of different lengths, and for caliber, between the smallest cannons and the musket; they are used in the ...\nby DK Publishing\nGERMAN ARQUEBUS (c.1500) The first matchlock muskets were fired by holding a slow-burning match above a pan of gunpowder primer to ignite it and propel the bullet out of the barrel. Later rifles contained a percussion cap that burst into ...\nOnline dictionaries and encyclopedias with entries for Arquebus\nClick on a label to prioritize search results according to that topic:\nPhotos about Arquebus\nClick on an item to view that photo:\n- Big Arquebus\nHard to tell from the photo, but the bore is probably over an inch in diameter.\nPhoto credit: ryochiji\n- Miniature silver arquebus.\nLength 110 mm. Materials : rhodium-plated 950-silver, blue sapphires.\nBy Mauro Cateb, Brazilian jeweler and silversmith.\nPhoto Del Carmen.\nPhoto credit: MAURO CATEB\n- Wheellock Arquebus (rifle)\nMusee de l'armee Paris\nPhoto credit: waitscm\n- Double arquebus\nPhoto credit: quinet\n- How an arquebus is made\nThe Japanese made some of the best matchlock arquebuses, partially because they took the time to refine the manufacturing process to a craft. In Europe, in contrast, arquebuses were quickly rendered obsolete in favor of flitlock muskets.\nPhoto credit: ryochiji\n- AIming the arquebus\nPhoto credit: Cavedragon\n- Loading the arquebus\nPhoto credit: Cavedragon\n- Sir John & the arquebus\nPhoto credit: Cavedragon\nVideo about Arquebus\nVideo shows what arquebus means. an obsolete matchlock firearm. Arquebus Meaning. How to pronounce, definition audio dictionary. How to say arquebus.\nScrabble value of A1R1Q10U1E1B3U1S1\nThe value of this 8-letter word is 19 points. It is included in the first and second editions of the Official Scrabble Players Dictionary.\nShare this page\nGo to the thesaurus of Arquebus to find many related words and phrases!"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:e4675510-b1d8-47ca-9962-16b8f3591505>"],"error":null}
{"question":"What role does moisture control play in both humidifying a room and preventing mold growth in air conditioning systems?","answer":"Moisture control is crucial for both purposes but requires careful balance. For humidification, moisture levels should be maintained between 35-50% for optimal indoor comfort and health. This can be achieved through various methods like using humidifiers, placing bowls of water near heat sources, or letting shower steam circulate. However, when it comes to air conditioning systems, moisture must be strictly controlled to prevent mold growth. AC units need proper drainage systems for condensation, and window units should be tilted slightly outside to drain properly. Moisture in AC systems can lead to mold growth, which can then spread spores throughout the house, potentially causing health issues like nasal stuffiness, throat irritation, and more severe reactions in people with mold allergies or compromised immune systems.","context":["As the winter approaches, you may begin to notice that your mouth, throat, nose and eyes feel drier. These symptoms could be due to low moisture levels in your home.\nInhaling dry indoor air can be detrimental to your health. It can cause skin irritation, asthma, colds, bronchitis, dry throat, or even nose bleeding. Dry air can also cause wood furniture to dry out and crack. Besides, moist air conducts temperature better, especially during winter and helps indoor plants to thrive.\nIn this article, we discuss the various ways you can humidify a room, including using a humidifier and 8 alternative methods.\nHow to Measure Humidity Levels in Your Home\nThe best way to measure humidity levels in your home is by using a hygrometer. It is an inexpensive humidity gauge that you can find in your local hardware store. It will indicate the exact moisture levels in a room.\nIdeally, the moisture levels should range between 35-50%. If lower, the indoor air is dry, while if it is above 60%, the room is over-humidified.\nHow to Use a Humidifier to Humidify a Room\nHumidifiers are appliances that produce water vapor to add moisture to the air. They are available in different sizes and designs.\nTypes of Humidifiers\nThere are 5 main types of home humidifies as follows:\n- Evaporative humidifiers. Their design constitutes of 3 main parts – a water reservoir, wick, and a fan. The wick absorbs water from the reservoir, and the fan distributes it to the room as cool moisture. These types of humidifiers are quite affordable but are prone to mold growth in the wick pad and reservoir.\n- Vapor humidifiers. They are also known as warm mist humidifiers. They operate by boiling water to create steam. They have a fan that distributes the steam. Their main advantage is that heating the water gets rid of pathogens and inhibits mild growth.\nOn the downside, they use up more energy to heat the water. Also, if knocked over, the hot water can cause scalding.\n- Ultrasonic humidifiers. Although a few can boil water or use UV light to sterilize the water, they are cool air appliances. They have vibrating ceramic discs that pulverize water into tiny droplets that are released into the air. They are quite safe but may release water minerals to the immediate environment.\n- Impeller humidifiers. These are cool air humidifiers. They have rotating discs that rotate at high speed, releasing water droplets in the air. The mist is visible. They can over-humidify a room if not correctly set.\n- Central humidifiers. The above types of humidifiers are portable and designed for single room use. On the other hand, central humidifies as fitted permanently as part of the HVAC system to humidify the entire house. Some have a rotating drum that pulverizes water into mist, while others steam the water.\nThese units are expensive to install but effective at humidifying the entire house. Since central humidifiers are more complex to install, it is best to consult an HVAC professional before buying one.\nTips for Using a Humidifier\n- Do not place the humidifier on a carpet, metallic, or wooden surface. The moisture may damage these types of surfaces. If placing it on the floor, ensure it is two feet above the ground.\n- Use the humidifier as need be. For example, run the humidifier for a few minutes in your bedroom before going to bed. Or for a few minutes near tropical house plants. Run the humidifier constantly if you live in low humidity areas or during low humidity season\n- Refill the humidifier regularly. For instance, a one-liter humidifier will need to be refilled with water after running for 8 hours. In comparison, a 3-gallon unit needs refilling after 12-15 hours. It is best to change the water with every refill to prevent bacteria manifestation.\n- Use purified, distilled water instead of tap water in the humidifier. Tap water has high levels of minerals that build up as plaque in the humidifier and wear out the filters. These minerals could also deposit on the surrounding surfaces.\n- Clean and sterilize your humidifier regularly. At least 1-3 times per week. The EPA recommends using 3% hydrogen peroxide to clean the humidifier.\n- If you are running the humidifier for extended periods, go for one that has a built-in humidistat. It senses when humidity levels are excessively high and controls the output.\n- Consider a built-in bacterial control feature. It reduces the risk of bacteria manifestation in the water tank.\nDisadvantages of Using a Humidifier to Humidify a Room\nWhile humidifiers are generally safe to use, they are associated with certain disadvantages. For instance, they can over humidify a room. Excess moisture can lead to mold growth, which leads to adverse health effects. It can also damage wallpaper, plaster and paint.\nThey are also high maintenance as they require regular cleaning and water change. If you do not clean it regularly and properly, it can encourage bacteria incubation.\nTherefore, some people are keen to use natural, easily accessible, low-cost methods to humidify a room. Below is a look at 9 natural methods of humidifying a room.\n8 Alternative Methods of Humidify a Room\n1. Incorporate some house plants in your interior décor\nPlants absorb water from the soil through the roots for mineral transportation. They then release excess water through the leaves in the process of transpiration. They also improve aeration in the room as they take up carbon dioxide and release oxygen.\n2. Open the bathroom door when showering\nIf you can, leave the door open when showering. The steam from the showerhead or bathtub will escape to the immediate rooms increasing moisture levels.\n3. Leave water in the bathtub\nOnce you are done showering, do not drain the water in the bathtub immediately. Allow it to sit for some time. As the water cools down, some moisture will slowly evaporate into the adjacent rooms. Do not leave the bathtub with water if you have small children, as it poses the risk of drowning.\n4. Hang clothes to air-dry indoors\nSet up a drying rack in the room you want to humidify. Instead of drying your clothes in the dryer, wring out the excess water and spread them out on the drying rack. As they dry, moisture slowly evaporates to the air, humidifying it. This method is not only affordable, but it also saves you energy bills involved with using a drier. It works best for small clothes and intimates.\n5. Put clean water in a bowl and place it near a source of heat\nPut water in a metallic or ceramic bowl. Place the water near heat sources, e.g. on top of HVAC registers or near a window under direct sunlight. The heat will cause the water to warm up and evaporate into the air.\nIf the room is big or the air is too dry, place several bowls of water near heat sources in the room. Check on the bowl every few days to determine whether you need to refill it with water.\nThis method also works for glasses or vases of water. However, the water evaporates much slower than in a bowl as they have a smaller surface area. You could also place shallow trays of water in direct sunlight.\n6. Boil water on the stovetop\nBoiling water on a stovetop is one of the fastest ways to increase moisture levels in the air. Ensure to keep the cooking pot open when boiling the water to allow the moisture to evaporate. You could also boil water in a kettle and leave it on for a few more minutes to produce adequate steam to raise moisture levels in the room.\n7. Mist the room with a water spray bottle\nFill up a spray bottle and spray around the room to add moisture to the air. Although this method is effective, you can easily over mist the room. Do not mist so much that you leave wet surfaces behind. You could also mist the curtains sparingly.\n8. Use an essential oil diffuser\nEssential oil diffusers work well for humidifying smaller rooms. Since water serves as a carrier for the oil droplets, a diffuser has a humidifying effect. Unlike a humidifier, it outputs less moisture. Therefore, it may not be the best idea if the air is too dry. Keep in mind that you should only run a diffuser for 30 minutes at a time.\nThe right humidity levels in your home are essential for comfortable and healthy living. Watch out for signs of dry air and use a hygrometer to confirm the moisture levels in different rooms. Then choose one or more methods of humidifying your home from the above discussed. Be careful not to over humidify as it can have adverse side effects such as mold growth.","Mold and mold spores can reduce the air quality in your home, especially if someone in your household has a mold allergy. Mold growing in the bathroom or basement is bad enough, but what if mold grows in your air conditioner or inside the ducts of your HVAC system? We will explain how mold might form in a window-unit air conditioner or in ductwork, how to prevent it, and what to do if you do find mold in your air conditioner.\nThe dangers of mold in your air conditioner\nIf mold is growing in your house, it can release spores that can be easily inhaled. According to the CDC, “molds can cause nasal stuffiness, throat irritation, coughing or wheezing, eye irritation, or, in some cases, skin irritation. People with mold allergies may have more severe reactions. Immune-compromised people and people with chronic lung illnesses, such as obstructive lung disease, may get serious infections in their lungs when they are exposed to mold.”\nMold growing in an AC unit is not necessarily more dangerous than mold growing elsewhere in your house. However, the function of an air conditioner is to spread cool air throughout a room, and the purpose of the HVAC ducts is to distribute air throughout the house. If they become contaminated with mold, they will efficiently distribute mold spores across an entire room or the entire house. If the concentration of mold spores is high enough, you will have a mold problem everywhere, rather than in just one location, and you will be inhaling mold spores in every room, even while you sleep.\nHow mold grows in air conditioners\nMold spores are everywhere. Unfortunately, it is impossible to get rid of all the mold spores in your house, and even if you did, more would come in every time you opened a door or window. When spores grow into mold, more spores are released, and these higher concentrations of spores are what cause the health problems associated with mold. Thus, the key is to prevent the mold from growing in the first place.\nMold needs two things in order to grow: moisture and an organic food source. Moisture can come from high humidity, or a leak or spill that is not cleaned up properly. Condenser and evaporator coils are the main contributors to condensation, and therefore have potential for water leakage if not properly drained. The food source can be the surface the mold is growing on, like wood or carpet, or organic particles found in dust, if there is enough of it.\nUnder most circumstances, air conditioners and HVAC ducts are not hospitable places for mold to grow. Sheet metal ducts and styrofoam channels inside window units do not offer mold a food source. However, dust often collects in these places, which can allow mold to grow.\nHow do I get rid of mold in my air conditioner?\nCleaning up mold can be difficult and messy. The area where you perform the clean-up should be well-ventilated, and you should wear non-porous gloves and a face mask with goggles, especially if you are sensitive to mold. Mold can be wiped up with a household cleaner and a cloth or sponge. Bleach is not needed to remove mold. If mold has grown on a porous surface such as wood, plaster, carpet or upholstery, you will probably not be able to get rid of all the mold. The moldy item or section will need to removed, thrown away and replaced.\nWindow unit: By the time you see small mold spots forming on the air direction vanes or grate of your window air conditioner, it is probably too late. The mold you see is just the tip of the iceberg. You can disassemble the unit and try to clean mold from the internal air ducts, coils, evaporators and other parts, but there is always a chance you will miss some and the mold will simply grow back. A moldy window unit likely needs to be replaced.\nCentral AC: Mold growing in the ductwork of your central AC system will almost certainly require professional remediation. The EPA suggests you shut off the system as soon as you notice mold to prevent it from spreading. The ducts will need to be vacuumed and cleaned, which could become very expensive and difficult if it has spread throughout the entire system. Sheet metal ducts are much easier to clean than fiberglass, plastic or lined ducts. The EPA does not recommend applying biocides or surface treatments to kill or prevent mold in ductwork.\nCar AC: Under normal operating conditions, the AC in your car should drain moisture properly and not get moldy. If your car gets wet because of a flood or leaving the windows open in the rain, clean and dry it out promptly. If mold grows in the AC system, your options are limited. You can disassemble the dashboard and access most of the ductwork, cleaning it with household cleaners and a cloth. Really moldy ducts can often be replaced, but the cost and effort involved varies from car to car. There are chemical products you can spray into the AC system to clean and kill mold, but their effectiveness is questionable, and any chemicals you put into the system will be blown back out again for you to inhale.\nHow do I prevent mold from growing in my air conditioner?\nControlling moisture is the key to preventing mold in air conditioners. Unfortunately, air conditioners can also be a source of moisture. Here are some steps you can take to control moisture when using an air conditioner.\n- Window units should fit the window tightly to prevent rain and humid outdoor air from entering the room.\n- When humid air is cooled in an air conditioner, the water vapor in the air condenses out of the air (cool air can hold less water than warm air, so the air is “wrung out” like a sponge). Window units should be tilted slightly toward the outside to allow this condensation to drain properly.\n- Grates and filters in window units should be cleaned regularly to prevent dust build-up, which can provide a food source for mold and impede air flow.\n- Whole house AC units should have drainage systems, ideally leading to a drain tile, through a basement slab, or to a utility sink. Make sure yours is working properly so moisture does not collect around the unit or get introduced into the ducts. Drains can become clogged by debris or build-up and result in significant flooding in your house.\n- Portable AC units need to emptied periodically. They typically have an auto shut-off and a light to let you know when the reservoir is full. Make sure portable units are empty and dry before storing for winter.\n- HVAC ducts tend to self-regulate moisture, because the air flow dries them out. Keep all grates and air returns unblocked and clean to allow air to flow properly to all parts of the system.\n- Replace air filters regularly. Clogged filters not only provide a food source for mold, but they can impede air flow.\n- Never introduce moisture to your HVAC system. Duct cleaning should use dry vacuuming or dry wiping, never water.\nMold growing in an AC unit or in your home’s HVAC system is a serious problem, because it allows mold spores to be spread throughout the house. Cleaning up an HVAC mold problem is a difficult and possibly expensive task. The best way to deal with mold in an air conditioner is to control moisture and prevent it from happening at all."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:82529341-b0de-4336-a0a6-d1d851bd928b>","<urn:uuid:0f5dfea6-8136-4ccd-960a-d7888b96b7ff>"],"error":null}
{"question":"What types of respirators exist and what maintenance requirements apply?","answer":"There are three main types of respirators: standard respirators that use filters to remove contaminants, Powered Air Supply (PAPRs) that use powered fans to force air through filters, and Supplied Air Respirators that provide clean air from sources like cylinders or compressors. For maintenance, workers must visually check their respirator for damage before each use, report any defects immediately, keep the equipment clean, and store it correctly. Equipment must be maintained with records kept, and workers should be trained on how to use, check, store, and clean their own RPE.","context":["RPE, respiratory protective equipment, is a type of PPE, which helps to protect people\nfrom breathing in substances that are hazardous to health. Some people find RPE a\nconfusing topic as there are a lot of options. Consider these factors when selecting to\nuse RPE as your control against hazardous substances.\nAirborne substances hazardous to health can be found in dust, mist, vapour or gases. You may or may not be able to see it in the air. If these hazardous substances are inhaled, workers or other people (visitors) could become unwell.\nDepending on the substance, the effects can be immediate or long term. Common immediate effects can include headaches, feeling dizzy and sick, and eye and skin irritation. Long term effects include cancer, organ damage and death.\nManaging Risk Using RPE\nTo manage risks arising from respiratory hazards, all appropriate and effective control\nmeasures which are reasonably practical need to be considered. With a preference of\ncontrol measures that protect multiple people at once. PPE, such as RPE, should not\nbe the first or only control measure considered.\nRPE is not a quick and easy solution. RPE can be costly to maintain and replace.\nEngineering controls, such as exhaust ventilation may be more cost effective long term.\nIf RPE is the selected control measure, there are some factors to consider when\nselecting the most appropriate RPE for your circumstance.\n• Is the RPE appropriate for the hazardous substance? (check SDS)\n• Is the RPE suitable for the work involved?\n• Will the RPE create another risk?\n• Does the RPE work with other PPE the worker uses?\nThere are a few types of respirator protection equipment to select from. It is important\nresearch options and identify the best respiratory system for your work.\nRespirators: Use filters to remove contaminants from the air the wearer breathes.\nPowered Air Supply: (PAPRs) Contaminated air is forced by a powered fan through filters\nto provide purified air for the wearer.\nSupplied Air Respirators: Provide a supply of clean air from a source, such as a cylinder\nor air compressor.\nWorkers need to visually check their respirator for signs of damage before each use.\nWorkers must inform management immediately, if there is any damage or defect that\nthey become aware of.\nRPE needs to be kept clean and stored correctly. As respiratory equipment should not\nbe shared having each team member trained of how to use, check, store and clean their\nown RPE is recommended.\nFitting of RPE:\nWith everyone’s faces being different shapes and sizes it is important to have\nemployee’s fit-tested before purchasing the equipment. It is unlikely that one\nmodel will fit every employee’s face characteristics.\nFit testing can be either qualitative (smell or taste tests) or quantitively (involving\nspecialist equipment). Negative pressure RPE must have a tight seal around the\nface to be effective.\nFit-testing can be a useful training exercise to teach workers how to use and\nwear their RPE properly. It is suggested fit-testing is performed once a year,\nespecially if the worker has changed weight or has sustainable dental work\ncompleted. The worker needs to be tested for each piece of RPE they use.\nFacial hair and stubble can make it almost impossible to get a tight seal. If a\nnegative pressure RPE is used please discuss the importance of clean shaven\nskin to workers. Jewelry, glasses, long hair and makeup can also compromise\nA ‘RPE check’ before entering the hazardous zone should be conducted to\nensure tight and correct fit of the RPE. (see attached poster)\nIf a workers glasses fog up when wearing a half-face respirator, this indicates\nthere is a leak at the top of the mask.\nWe recommend that a written record of the respiratory protection programmed ,\nincluding training, selection and use of RPE and any health monitoring are kept\non record. Keeping a record of regular reviews to RPE and any changes that\nresult is also recommended.\nSee in PDF, the below free poster for your workplace.","Respiratory Protection Information\nRespirators are used to protect the wearer from inhaling harmful dusts, fumes, vapours or gases. It is the responsibility of the employer to provide respirators which are applicable and suitable for the purpose intended.\nProtec Direct has a comprehensive range of respiratory products from fold-flat and moulded disposable masks to powered and supplied air respirators.\nTo select the correct equipment follow the four steps....\nIdentification of the hazard\n|Dust*||Sanding, cutting, grinding and brushing|\n|Mists*||Spraying, cutting, cleaning and grinding|\n|Fumes*||Welding, smelting and pouring metals|\n|Vapours*||Methylated spirits, petrol and degreasers|\n|Gases*||Air like at room temperatures and have the ability to travel a long way very quickly|\n|Oxygen Deficient*||A Normal respiratory equipment will not protect against this hazard.|\n* Note Dusts, Mists and Fumes are all classified as particulate\nAccess and understand the hazard\nEnsure that you fully understand the hazard and the correct respiratory equipment is selected also the correct eyewear and skin protection may need to be selected.\nSelect the correct type of respiratory equipment\nTraining for user and care of the respirator\n- Employer must supply suitable equipment for the employee\n- Employer must supply training including face fit testing COSHH regulations (2002)\n- Qualitative fit test for disposable masks and half masks\n- Quatitative fit test for full face masks\n- Equipment must be maintained and records kept.\nQualitative Fit Test Kits….\nCOSHH regulations require employers to conduct fit tests for all wearers of tight fitting face pieces, such as full or half face masks and disposable masks. If the fit is inadequate it will significantly reduce the protection provided to the wearer\nUK Standard Assigned Protection Factor (APF)….\nReflects the level of protection that a properly functioning respirator would be expected to provide to a population of properly fitted and trained users.\nThe Nominal Protection Factor (NPF)….\nThe reciprocal value of inward leakage.\n|EN149||:1991 - Filtering face piece|\n|EN149||:2001 - Filtering face piece|\n|EN405||- Maintenance free half masks|\n|EN136||- Full face mask|\n|EN137||- Filtering face piece|\n|EN140||- Half mask|\n|EN141||- Gas and vapour filters|\n|EN143||- Particulate filters|\n|EN146||- Filtering face piece|\n|EN149||- Filtering face piece for particulates|\n|EN149||- Gas and combined filters|\n|EN12941||- Power hoods and helmets|\n|EN12942||- Powered full face masks|\n- A Brown* - for use with Organic vapours with a boiling point greater than 65oc\n- B Grey* - to be used with Inorganic gases & Vapour eg Chlorine (NOT Carbon Monoxide)\n- E Yellow* - to be used with Acid gases & Vapour eg. Sulphur Dioxide and other acidic gases\n- K Green* - for use with Ammonia and organic ammonia derivatives\n- P White* - for protection against Particuate\n- P1 White* - for protection against coarse, solid particles (low toxicity)\n- P2 White* - for protection against solid and/or liquid aerosols (low to average toxicity)\n- P3 White* - for protection against solid and/or liquid aerosols (high toxicity)\nFor use against Gas & Vapour (EN371)\n- AX Brown* - Certain organic compounds with boiling points less than 65c\n*Filter Type & Colour Code"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:b5458e78-be81-4b21-9b63-06694391613a>","<urn:uuid:91ff3c3b-7cfa-4e44-b25f-dd818e0e8c2a>"],"error":null}
{"question":"What are the differences between real-time data management in mobile apps versus business process integration in construction software?","answer":"Mobile estimating apps focus on immediate access to current data, enabling quick decision-making and enhanced on-site work efficiency through real-time updates and cloud technology integration. In comparison, construction management software emphasizes the integration of business processes, which streamlines operations by combining financial and non-financial information, enabling better resource utilization and enhanced collaboration between team members through integrated systems.","context":["In the dynamic construction world, the advent of mobile estimating apps has marked a significant turning point. These tools, designed to bring unparalleled efficiency and flexibility to on-site operations, have evolved rapidly, integrating cutting-edge mobile technology with the specific needs of the construction industry. This article delves into how these apps transform the field, offer real-time data management, improve construction communication, and leverage mobile technology for on-site work efficiency.\nThe Role of Mobile Technology in Construction\nMobile technology has revolutionized numerous industries, and construction is no exception. Introducing smartphones and tablets with powerful processors and versatile capabilities has opened new avenues for managing construction projects. These advancements have paved the way for mobile estimating apps, which are now instrumental in streamlining processes and enhancing operational efficiency.\nBenefits of Mobile Estimating Apps for On-Site Work\nThe primary allure of mobile estimating apps lies in their ability to enhance on-site work efficiency. These apps facilitate the rapid gathering and processing of data, allowing for accurate and timely estimations. The real-time data capabilities ensure that project managers and workers have the most current information at their fingertips, leading to informed decision-making and efficient project management.\nHow Mobile Estimating Apps Revolutionize On-Site Work Efficiency\nMobile estimating apps have redefined the norms of on-site work efficiency. By comparing traditional methods with these modern solutions, we see a stark contrast in productivity and accuracy. Case studies from various construction projects illustrate the transformative impact of these apps, highlighting their ability to streamline operations and reduce errors.\nFeatures of Top Mobile Estimating Apps\nThe best mobile estimating apps come equipped with a range of features designed to cater to the diverse needs of the construction industry. These include user-friendly interfaces, comprehensive data analysis tools, and seamless accessibility. Such features make the apps more effective and ensure they are easy to adopt across different levels of technological proficiency.\nReal-Time Data Management\nOne of the critical advantages of mobile estimating apps is their capability to manage real-time data. This feature ensures that the information used for estimations and project planning is current and accurate. Coupled with cloud technology integration, these apps provide a reliable and efficient means of data handling and storage.\nOvercoming Challenges in Construction Communication\nEffective communication is crucial in construction, and mobile estimating apps enhance this aspect. By offering integrated communication tools, these apps facilitate smoother collaboration among team members, ensuring everyone is on the same page and reducing the likelihood of misunderstandings or information delays.\nUser Experience: Ease of Use and Training\nAdopting new technology can often be challenging, but the user experience with mobile estimating apps is typically designed to be intuitive. Training staff to use these apps is generally straightforward, thanks to their user-friendly interfaces. User feedback is also vital, helping developers continually refine and improve the app experience.\nIn terms of financial impact, mobile estimating apps are a cost-effective solution for construction projects. An analysis of their return on investment (ROI) shows that the initial cost is quickly offset by the savings in time and resources. When compared to traditional estimating methods, these apps demonstrate significant cost benefits.\nTo understand more about the financial implications and the return on investment in sustainable construction practices, read this detailed analysis on sustainable construction costs and ROI.\nSecurity and Data Protection in Mobile Apps\nIn an era where data security is paramount, estimating apps are designed with robust security features to protect sensitive information. Adherence to data protection regulations and strong privacy measures ensure that user data remains secure and confidential.\nCustomization and Scalability of Estimating Apps\nCustomizing and scaling mobile estimating apps according to specific project requirements is a significant advantage. Whether it’s a small renovation or a large-scale construction project, these apps can be tailored to meet the unique needs of each task, making them versatile tools in the industry.\nIntegrating Mobile Estimating Apps with Existing Systems\nMobile estimating apps must integrate effectively with existing project management systems and tools for seamless operation. This integration capability ensures that data flows smoothly between different platforms, enhancing the overall efficiency of project management processes.\nFuture Trends in Mobile Estimating Technology\nThe future of mobile estimating technology is bright, with continuous innovations expected to enhance its capabilities further. Upcoming trends and technological advancements promise to make these tools even more integral to the construction industry, shaping how projects are managed and executed.\nSustainable Construction Practices\nIn addition to efficiency and convenience, mobile estimating apps contribute to sustainable construction practices. These apps support environmental sustainability and green building initiatives by facilitating accurate resource estimation and minimizing waste.\nChoosing the Right Mobile Estimating App for Your Business\nSelecting the right mobile estimating app for your business involves considering various factors such as features, user interface, and compatibility with existing systems. Here, we provide a comparative analysis of four leading apps, examining their unique features and benefits to the construction industry. It provides insights into how these apps stand out in the market and their specific advantages for different construction projects. It will help you make an informed decision that best suits your business needs.\nBuildertrend is recognized for bringing order and efficiency to the construction process. It is designed to empower contractors with enhanced project management capabilities.\n- Comprehensive project management tools.\n- Integrated customer relationship management (CRM).\n- Financial tools, including budgeting and proposals.\n- Streamlines communication between contractors and clients.\n- Improves project scheduling and resource management.\n- Provides a centralized platform for managing multiple aspects of construction projects.\nAutodesk Construction Cloud\nThis app combines advanced technology, a vast builders network, and predictive insights to offer a robust construction management solution.\n- An extensive network of industry professionals.\n- Advanced predictive analytics for project planning.\n- Integration with other Autodesk products for a comprehensive workflow.\n- Facilitates collaboration across large teams.\n- Offers data-driven insights for informed decision-making.\n- Enhances overall project efficiency with integrated solutions.\nProcore Estimating is tailored for specialty and general contractors, offering cloud-based takeoff and estimating tools.\n- Specialized takeoff tools for accurate estimations.\n- Real-time collaboration tools for team communication.\n- Integration with the Procore platform for streamlined project management.\n- Increases accuracy in cost estimations.\n- Enhances team coordination and data sharing.\n- Provides a seamless transition from estimating to project execution.\nClockShark is geared towards local construction, field service, and franchises, focusing on time tracking and scheduling.\n- Robust time tracking and employee scheduling tools.\n- GPS tracking features for on-site employees.\n- Customizable job costing and reporting tools.\n- Improves workforce management and scheduling efficiency.\n- Provides precise tracking for labor costs.\n- Facilitates compliance with labor laws and regulations.\nEach of these apps offers a unique blend of features aimed at enhancing various aspects of construction management, from project planning and execution to workforce management. The choice of app depends largely on the specific needs of the construction project and the firm, whether it’s comprehensive project management, precise cost estimation, collaborative workflows, or efficient time and resource tracking.\nWhat are the main benefits of using mobile estimating apps in construction?\nMobile estimating apps offer numerous benefits, including improved accuracy in project estimations, enhanced on-site efficiency, real-time data access, and better communication among team members. They streamline the process of gathering and analyzing data, leading to more precise budgeting and resource allocation.\nHow do mobile estimating apps improve real-time data management?\nThese apps provide immediate access to the latest data, enabling teams to make informed decisions quickly. They allow for the instant update and sharing of information, reducing delays in communication and enhancing overall project management efficiency.\nCan mobile estimating apps integrate with other construction management tools?\nYes, many mobile estimating apps are designed to be compatible with other construction management tools. This integration facilitates seamless data transfer and communication across different platforms, ensuring a more cohesive and efficient project management process.\nAre mobile estimating apps suitable for small-scale construction projects?\nAbsolutely. Mobile estimating apps are versatile and can be tailored to suit projects of any size, including small-scale construction. They help optimize resource allocation, budgeting, and scheduling, regardless of the project’s scope.\nHow do mobile estimating apps contribute to sustainable construction practices?\nThese apps promote sustainability by enhancing accuracy in material estimation, thereby reducing waste. They also help in efficient project planning and execution, leading to less energy consumption and a smaller carbon footprint during construction.\nWhat should I consider when choosing a mobile estimating app for my business?\nWhen choosing an app, consider factors like compatibility with your current systems, ease of use, specific features that meet your business needs, cost, scalability, and the level of customer support the provider offers.\nMobile estimating apps are more than just a technological advancement; they represent a paradigm shift in the construction industry. By enhancing efficiency, accuracy, and communication, these tools are setting new standards for project management. As the industry continues to evolve, the role of mobile estimating apps will undoubtedly become more prominent, shaping the future of construction in an increasingly digital world.","SEATTLE, Feb. 9, 2022 /PRNewswire/ — According to Coherent Market Insights, The global construction management software market was valued at US$ 1.4 Bn in 2020 and is expected to reach US$ 2.6 Bn by 2028 at a CAGR of 8.2% between 2021 and 2028.\nConstruction managers can benefit from the use of construction management software. This software offers the ability to generate accurate construction schedule estimates for both big and small projects. The software has the capability to assist in planning, organize, allocate, and track various resource resources and then generate resource estimates in a timely manner. Through the use of this software, project managers will be able to ensure that construction schedule accuracy is achieved, project deadlines are met, costs are minimized, and that the resources utilized are of optimum use for the estimated budget. Through the accurate management of the construction schedule, project managers will be able to meet their delivery schedules and budgets.\nIn addition to the construction management software, it is also advisable to make use of business processes software that has been integrated with the construction management software. Together, these two programs enhance each other in terms of efficiency, productivity, effectiveness, and the level of collaboration expected between team members. These business processes software also enables project managers to make better use of all the project’s resources by making better use of time, energy, and cost by streamlining processes. Likewise, these systems also enable business processes managers to create reports that include both financial as well as non-financial information regarding the project.\nRequest for Sample Copy @ https://www.coherentmarketinsights.com/insight/request-sample/4566\nLaunch of new products is expected to propel growth of the global construction management software market over the forecast period. For instance, in March 2020, Sage launched Sage Intacct Construction, a new cloud financial management solution.\nMoreover, increasing adoption of construction management software is also expected to aid in growth of the market. For instance, in November 2021, BESIX Watpac, a multi-disciplinary construction company, choose Pegasus, an Avetta company, to manage workplace safety standards and workforce compliance on the Sydney Metro Barangaroo Station project.\nIncreasing funding is expected to offer lucrative growth opportunities for players in the global construction management software market. For instance, in November 2021, Mosaic Building Group, a U.S.-based construction tech startup, raised US$ 44 million in a Series B funding round led by Peak State Ventures, to automate the construction planning process.\nSteps to improve construction workforce management is also expected to offer lucrative growth opportunities for players in the global construction management software market. For instance, in October 2021, Procore Technologies, Inc. acquired LaborChart, a provider of workforce management software for specialty contractors and self-performing general contractors.\nMajor players operating in the global construction management software market are focused on adopting merger and acquisition strategies to expand their product portfolio. For instance, in October 2020, CoConstruct, the U.S.-based SaaS provider of project, financial, and client management software for the construction sector, acquired CBUSA, a US-based homebuilder group purchasing network, in order to complement its existing construction software.\nSimilarly, in March 2019, TriBuild Inc., a provider of SaaS for the construction industry, acquired Radar Construction Software Inc., a cloud-based construction management software firm.\nRequest for PDF Copy @ https://www.coherentmarketinsights.com/insight/request-pdf/4566\nMajor players operating in the global construction management software market include, Autodesk Inc., Buildertrend, Bentley Systems, Inc., BuildStar Technologies, Inc., Buildtools Inc., CATCloud., CMiC., ConstructConnect, e-Builder Inc., eSUB Inc., Jonas Construction Software Inc., Kahua, Inc., Oracle, PlanGrid, Inc., Odoo S.A., Procore Technologies, Inc., Sage Group plc, Systemates, Inc.,Trimble Navigation Limited, and Viewpoint Inc.\nMajor players operating in the global construction management software market are focused on adopting partnership strategies to enhance their market share. For instance, in November 2021, Kahua partnered with VariQ Corporation, a provider of cybersecurity, DevSecOps, and cloud services to federal, state, and local governments. VariQ joined the Kahua ecosystem as a certified solution provider to deliver solutions on the Kahua Platform.\nOn the basis of deployment, the global construction management software market is segmented into:\nOn the basis of end user, the global construction management software market is segmented into:\n- Builders & Contractors\n- Construction Managers\n- Engineers & Architects\nOn the basis of region, the global construction management software market is segmented into:\n- North America\n- Latin America\n- Asia Pacific\n- Middle East & Africa\nBuy this Complete Report Now @ https://www.coherentmarketinsights.com/insight/buy-now/4566\nFind more related trending reports below:\nGreen Construction Market, By Product Type (Exterior Product (Roofing, Windows, Siding, and Doors), Interior Product (Insulation and Flooring), Solar Products, Building Systems, and Others) By Application (Residential Buildings, Non-Residential (Commercial & Office, Institutional, Industrial, Hospitality & Leisure), and Others), By Region (North America, Europe, Asia Pacific, Latin America, and Middle East and Africa) – Size, Share, Outlook, and Opportunity Analysis, 2021 – 2028\nData Center Construction Market, by Construction Type (Electrical Construction, Mechanical Construction, and General Construction), by Enterprise Size (Small & Medium Enterprises and Large Enterprises), by Tier Standards (Tier 1 & Tier 2, Tier 3, and Tier 4), by End Use Industry (BFSI, IT & Telecom, Defense & Government, Education, Healthcare, Utilities, Power & Energy, Media & Entertainment, and Others), and by Region (North America, Europe, Asia Pacific, Latin America, and Middle East and Africa) – Size, Share, Outlook, and Opportunity Analysis, 2021 – 2028\nCoherent Market Insights is a global market intelligence and consulting organization focused on assisting our plethora of clients achieve transformational growth by helping them make critical business decisions. We are headquartered in India, having sales office at global financial capital in the U.S. and sales consultants in United Kingdom and Japan. Our client base includes players from across various business verticals in over 57 countries worldwide. We create value for clients through our highly reliable and accurate reports. We are also committed in playing a leading role in offering insights in various sectors post-COVID-19 and continue to deliver measurable, sustainable results for our clients.\nSenior Client Partner – Business Development\nCoherent Market Insights\nEmail: [email protected]\nFollow Us: LinkedIn | Twitter\nSOURCE Coherent Market Insights"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:028ac5e1-d8c1-439f-aecb-d3bba35d2347>","<urn:uuid:7a7b87b9-a104-4ce1-85c7-d5cb5fcf5f71>"],"error":null}
{"question":"How did Kenya's independence in 1963 differ from South Africa's independence from Britain?","answer":"Kenya gained independence from Britain in December 1963 under the leadership of Jomo Kenyatta, despite opposition from white settlers, though Kenyatta assured there would be no discrimination against whites. In contrast, South Africa's path to independence was more gradual - it became a sovereign nation within the British Empire in 1934 through the Status of the Union Act, and later became a republic in 1961 following a referendum.","context":["The British wanted to control South Africa because it was one of the trade routes to India. However, when gold and diamonds were discovered in the 1860s-1880s their interest in the region increased. This brought them into conflict with the Boers.\nWhen did South Africa gain independence from Britain?\nThe country became a fully sovereign nation state within the British Empire, in 1934 following enactment of the Status of the Union Act. The monarchy came to an end on 31 May 1961, replaced by a republic as the consequence of a 1960 referendum, which legitimised the country becoming the Republic of South Africa.\nWhy did Africa leave the British Empire?\nAs a result of colonialism and imperialism, a majority of Africa lost sovereignty and control of natural resources such as gold and rubber. The introduction of imperial policies surfacing around local economies led to the failing of local economies due to an exploitation of resources and cheap labor.\nWhy did Africans want to be independent?\nAfter the Second World War people in Africa wanted change. Only Egypt, Liberia and Ethiopia were independent at that point. But it was Indian self-rule which triggered the momentum leading to independence. Everywhere the mood was hopeful as people were inspired by the vision of a new society free of European control.\nWhen did South Africa gain its independence?\nHow old is South Africa as a country?\nIndependence: 31 May 1910 (from UK); South Africa became a republic in 1961. Geography: Location: Southern Africa, at the southern tip of the African continent. Area: 1.2 million km² (470,462 sq.\nWhat was South Africa called before?\nName. The name “South Africa” is derived from the country’s geographic location at the southern tip of Africa. Upon formation, the country was named the Union of South Africa in English and Unie van Zuid-Afrika in Dutch, reflecting its origin from the unification of four formerly separate British colonies.\nIs South Africa safer than Kenya?\nFor major cities in those countries you get more relevant data by specifying cities.\nCrime Comparison Between Kenya and South Africa.\nWhy did Britain want Africa?\nThe British wanted to control South Africa because it was one of the trade routes to India. However, when gold and diamonds were discovered in the 1860s-1880s their interest in the region increased. … The Boers disliked British rule. They wanted a simple farming life.\nHow did Britain rule the world?\nIn the 16th Century, Britain began to build its empire – spreading the country’s rule and power beyond its borders through a process called ‘imperialism’. This brought huge changes to societies, industries, cultures and the lives of people all around the world.\nWhy was Africa colonized so late?\nLarge parts of the continent were essentially uninhabitable for Europeans because of the high mortality rates from diseases such as malaria. They preferred to maintain coastal trading posts. After it was discovered that quinine could also be used preventatively for malaria, internal exploration became easier.\nWhat was the last country in Africa to gain its independence?\n24, 1973, now considered as Independence Day. However, independence was only recognized by Portugal on 10 September 1974 as a result of the Algiers Accord of Aug. 26, 1974.\nChronological List of African Independence.\n|Country||Independence Date||Prior ruling country|\n|Eritrea, State of||May 24, 1993||Ethiopia|\n|South Sudan, Republic of||July 9, 2011||Republic of the Sudan|\nWhich African country is still Colonised?\nWestern Sahara is still colonized because it is rich in natural resources that became a sort of curse to the Saharawi people, and free stolen goods to those countries and governments exploiting it in complicity with Morocco. And the list of the guilty plunderers of this African country is huge.\nHow did Britain get South Africa?\nThe British occupied the Cape in 1795, ending the Dutch East India Company’s role in the region. Although the British relinquished the colony to the Dutch in the Treaty of Amiens (1802), they reannexed it in 1806 after the start of the Napoleonic Wars.\nWho was in South Africa first?\nThe Khoisan were the first inhabitants of southern Africa and one of the earliest distinct groups of Homo sapiens, enduring centuries of gradual dispossession at the hands of every new wave of settlers, including the Bantu, whose descendants make up most of South Africa’s black population today.\nWho ruled South Africa in 1910?\nUnion of South Africa\n|Union of South Africa Unie van Zuid-Afrika (Dutch) Unie van Suid-Afrika (Afrikaans)|\n|Government||Unitary parliamentary constitutional monarchy|\n|• 1910–1936 (first)||George V|\n|• 1936||Edward VIII|","Sub-Saharan Africa 1963: Kenyan Independence\nDue to political resistance from the white settler population, Kenya did not gain independence from the UK until December 1963. Rejecting Kenyan rule, the Somali tribes of the country’s northeast preemptively launched the four-year Shifta War in the hope of joining neighboring Somalia.\nThe Two Republic of Congos 1960-64\nDuring this period, Congo (Brazzaville) was called the ‘Republic of Congo’ and Congo (Leopoldville/Kinshasa) was called the ‘Republic of the Congo’. For both the sake of simplicity and to avoid confusion, we always refer to Congo (Brazzaville) as the ‘Republic of Congo’ and Congo (Kinshasa) - the center of attention in Africa during this period - as simply ‘the Congo’.\n28 Dec 1962-17 Jan 1963 Operation Grandslam▲\nIn the wake of Katangan attacks on UN peacekeepers, United Nations Secretary-General U Thant authorized Operation Grandslam - an all-out offensive to eliminate the secessionist state of Katanga in the Congo. Reinforced by Swedish aircraft, the United Nations Operation in the Congo (ONUC) secured the Katangese capital of Élisabethville and vanquished the Katangese Air Force. On 14 January 1963 the Katangan President Moise Tshombe sued for peace, accepting the reintegration of his breakaway state into the Congo three days later.\n23 Jan 1963 Guinea-Bissau Independence War begins▲\nMembers of the Marxist African Party for the Independence of Guinea and Cape Verde (PAIGC) attacked the Portuguese garrison in Tite, Portuguese Guinea, as the first act of open warfare in the Portuguese colony. More guerrilla attacks followed elsewhere in the south of the country, with the PAIGC opening additional fronts in the north and east in 1964 and 1965, respectively. Portugal would never successfully come to grips with the rebels, who could melt into the jungle and rely on support from safe havens in neighboring Senegal and Guinea.\n14 May 1963-15 Aug 1964 Alfellaga▲\nFollowing Mali’s independence, Tuareg nationalists began their own movement for self-determination. In May 1963 militants under Zeyd ag Attaher launched a rebellion - the “Alfellaga” - against the Malian government in the northeastern region of Wadi Ouzzein. After several clashes, Mali brought the conflict to an end with support from Algeria and Morocco.\n25 May 1963 Organisation of African Unity▲\nAt a meeting in Addis Ababa, Ethiopia, representatives of all the independent African states, with the sole exception of apartheid South Africa, proclaimed the formation of the Organisation of African Unity (OAU). The OAU replaced the rival Casablanca and Monrovia Groups, supporting the continued push for the end of colonialism in Africa but rejecting the notion of a political federation. Ultimately, however, it had little power and its influence over the conduct of its members was minimal.\n22 Nov 1963-28 Oct 1967 Shifta War▲\nFrom 1960 on, the Somali population of the Northern Frontier District of the British colony of Kenya pushed for reform and autonomy, if not the integration of their region into neighboring Somalia. With their demands unmet and Kenyan independence looming, they revolted under the banner of the Northern Frontier District Liberation Movement in November 1963. Unable to match the Kenyan government militarily, the Shifta (rebels) resorted to mine warfare - laying land mines in the expected path of the Kenyan army - in 1965, which the Kenyans responded to by systematically rounding the Somali population up into “protected villages”. Eventually both sides agreed to a Somalia-sponsored ceasefire and political settlement in October 1967.\n10 Dec 1963 Zanzibar Act▲\nThe Zanzibar Act came into effect, ending the United Kingdom’s Protectorate over Zanzibar. Zanzibar became a constitutional monarchy under the newly-crowned 34-year-old Sultan Jamshid bin Abdullah and with Sheikh Muhammad Shamte Hamadi as Prime Minister.\n10 Dec 1963 Aden Emergency begins▲\nThe Egyptian-supported National Liberation Front (NLF) began a campaign of grenade attacks against British forces and civilians in Aden, capital of the British protectorate of the Federation of South Arabia. They were almost immediately joined in the fight by the rival Front for the Liberation of Occupied South Yemen (FLOSY), which proceeded to attack both the British and the NLF. The British authorities responded by declaring a state of emergency, but the conflict would only escalate until their final abandonment of the protectorate in 1967.\n12 Dec 1963 Kenyan Independence▲\nIn 1960 the British government began paving the way for the independence of its Kenya colony, granting increasing representation to the African population despite opposition from many of the 60,000 white settlers. In 1962 the Lancaster House conference set the date for independence, prompting the exodus of over half the white community - a loss of skilled workers which was only alleviated when Kenyan African National Union leader Jomo Kenyatta insisted that there would be no discrimination against whites if he gained power. Kenyatta was elected Prime Minister soon after and on 12 December 1963 Kenya became an independent state under his leadership."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:489d3105-8df6-439c-b0e4-bdf479720df1>","<urn:uuid:567d3149-83fe-4e51-8f6d-b8ff1fbb4e05>"],"error":null}
{"question":"How are visibility conditions reported in TAF forecasts?","answer":"In TAF forecasts, visibility is reported either in statute miles or in meters. For statute miles, visibility is given in whole and quarter mile amounts up to 6 miles, followed by 'SM'. Visibilities exceeding 6 statute miles are preceded by the letter 'P'. For metric reporting, visibility is shown as a 4-digit number (in meters), with 9999 indicating visibility greater than 9000 meters. The term CAVOK is used internationally to indicate that ceiling and visibility are good, exceeding maximum reportable values.","context":["Airport forecasting reports are important weather tools for pilots.\nBy Karsten Shein\nComm-Inst Climate Scientist\nBased on the terminal aerodrome forecast (TAF) from EUG (Eugene OR), the pilots figured that they’d have no problem getting in. The forecast for their arrival in a couple of hours had 3 miles of visibility with a broken scud at 400 ft, deteriorating over the following 12 hours as a fog developed over the region – not ideal, but not a problem for the experienced crew.\nFortunately, the pilots noted the issue time was already nearly 3 hours old, and the latest metar said the airport was already down to a 0.5-mile visibility in freezing fog and 100 ft broken ceiling.\nWaiting just a few minutes, they refreshed their TAF list and got the latest forecast, now just a few seconds old. Sure enough, the fog was now expected to build faster than previously forecast. The 2 pilots, based at EUG, knew they needed to plan for several alternates.\nBringing up the TAFs for PDX (Intl, Portland OR) and AST (Astoria OR), they felt confident that conditions at PDX would remain above minimums for the next few hours. As it turned out, they were able to shoot the ILS at EUG and land safely just a few minutes before the airport went zero-zero in a thick fog. TAFs play an important role in flight planning and anticipating conditions over the next several hours at departure, arrival, and alternate airports.\nBut, like any meteorological information, it is important for pilots to know and understand their strengths and limitations. TAFs are rudimentary forecasts made specifically for many, but not all, military and civilian airports and their immediate vicinity. In the US, they are valid for a 5-statute-mile radius around the airport, while elsewhere it is 5 nm (~9 km).\nMost TAFs are issued every 6 hours on a routine schedule at 0000, 0600, 1200, and 1800Z in most places. However, at core airports, and where forecasters can do so, TAFs may be issued on a 3-hr schedule instead. While there are international standards for TAFs, each national aviation or weather authority has some discretion in how they are produced.\nAt military airfields and at many international airports, TAFs are prepared and issued by forecasters located on site. In the US, TAFs are issued by meteorologists at the airport’s relevant National Weather Service (NWS) Weather Forecast Offices. Some offices, such as those serving major metropolitan areas, may have the responsibility for issuing regular TAFs at more than a dozen airports.\nBecause the purpose of a TAF is to provide the most relevant forecast weather conditions significant to aviation, and to do so quickly and efficiently, they are intentionally limited to just a few basic parameters and formatting. For example, the US NWS instructs its meteorologists to limit TAFs to no more than 6 lines, not including any TEMPO (temporary weather) statements, and each line is limited to no more than 69 characters.\nMilitary forecasters often include much more forecast information. For example, forecast temperature and altimeter settings are rarely included in civilian TAFs, but are common in military-issued TAFs.\nNearly all TAFs contain the same basic structure of information. They begin on the 1st line with the airport identifier – leading with the regional code, such as K for CONUS US stations, P for Pacific (including Hawaii and Alaska), E for Europe, C for Canada, T for the eastern Caribbean and Atlantic, and M for Mexico.\nThe US NWS also makes it a point to drop the last letter of an airport designator in its Pacific region, adding in the second position an H for Hawaiian airports, an A for Alaskan airports, and a G for Pacific Island territory airports, except where the airport designator begins with that subregional letter.\nWhile it works out for airports such as ANC (Anchorage AK), which becomes PANC, an airport such as OGG (Maui HI) becomes PHOG. This can be confusing for pilots who do not frequent these airports. Every now and then, the code AMD will follow an airport identifier.\nThis simply means that the TAF has been amended by the forecaster because the original TAF forecast conditions are no longer representative of the expected weather. Similarly, COR indicates a corrected TAF, suggesting some error in the original forecast.\nCorrections are normally issued within an hour of the original issuance, while amendments occur if an update is made more than an hour after issuing the original TAF. AMD and/or COR will be repeated at the end of the TAF, followed by the 4-digit UTC (Z) time at which the amendment or correction was made.\nAmended or corrected TAFs always supersede the original TAF. The airport identifier (or AMD or COR) is followed by the origination day and time (eg, 011153Z – 1st day of the month at 1153 UTC time). Pilots should note that the origination time is the time the forecast was actually made, not the time it was issued, amended, or corrected.\nTAFs can be issued as much as 30 minutes after origin because the issuing office often bundles the TAFs for a single transmission at the prescribed issuance time. Following the origin time are the valid times, meaning the times covered by the forecast. Routine TAFs are always valid for 24 hrs, and the valid times may be displayed as a single-day identifier followed by a start and stop hour or by 2 days and Z-times.\nYou might see a valid time displayed as 211818 or 2118/2218. Both mean the TAF is valid from 1800Z on the 21st day of the month until 1800Z on the 22nd. Subsequent TAF lines will normally begin with FM (meaning “from”), a 2-digit day, and a 4-digit Z-time (eg, FM281700).\nImportantly, at the few TAF-listed airports where weather observations are not available 24 hrs a day, TAFs are only valid to the end of the observing period, and the TAF at those airports, may end with AMD NOT SKED followed by the period of service interruption.\nWhere a short-term weather condition – usually less than an hour or 2 – may be significant to aviation at some time during the valid period, the forecaster will include the phrase TEMPO (or begin a line with TEMPO), for temporary. The duration of the temporary condition will follow in the same format as a valid period.\nSo, TEMPO 0115/0117 is a forecast of certain following conditions occurring between 1500 and 1700Z on the 1st of the month. Similarly, the forecaster may also include the phrase BECMG and a 4-digit time to indicate the start and end hour over which the conditions will gradually become those forecast following the BECMG entry.\nFor example, BECMG 2023 OVC020 suggests that between 2000 and 2300Z, an overcast ceiling at 2000 ft will form. Finally, a TAF might use the term PROB40 (or in some cases PROB30). This just means that there is a moderate likelihood (around a 40% probability) that the following forecast conditions will occur.\nIf the probability of forecast conditions exceeds the 30–50% range, it is simply reported as the forecast. If it is less than 30%, it is not reported in the TAF.\nAfter the timing qualifiers, the remainder of the forecast line is a forecast of wind, visibility, weather, sky condition, and, optionally, any important conditions such as wind shear, icing, or probability of convection.\nTAF weather coding is mostly identical to METAR coding. Wind is forecast in direction (first 3 digits) and speed (last 2 digits). Gusts are forecast with a G and the 2-digit gust speed. KT follows the wind forecast to indicate that the speed is in kts (some countries may report in meters/second). Calm wind is forecast as 00000KT.\nIf winds are forecast to shift by more than 30º, the direction digits are replaced by VRB (although meteorologists normally avoid using VRB in TAFs). Visibility will be reported either in statute miles or in meters. In the latter, visibility will be a 4-digit number with the units implied.\nStatute mile visibilities will be given in whole and quarter mile amounts (up to 6 miles) followed by SM. If visibility is forecast to exceed 6SM, the letter P will precede the visibility. In meters, 9999 indicates any visibility forecast greater than 9000 m (~7SM). The phrase CAVOK is still in wide use internationally, and simply indicates that ceiling and visibility are good, with values exceeding the maximum reportable.\nFamiliar METAR codes are used in TAFs to forecast the likely weather conditions for the forecast period. Common codes include FG (fog), RA (rain), TS (thunderstorm), and NSW (no significant weather). Precipitation qualifiers may be added to indicate showers (SH), freezing (FZ), or intensity (+/-).\nSky condition is the forecast state of clouds, reported in coverage and height in hundreds of feet (eliminating the 2 trailing zeros). There may be multiple cloud levels and the qualifier of CB to indicate vertically developing clouds. A TAF sky report might state BKN001 OVC030, forecasting a broken ceiling at 100 ft AGL and an overcast deck at 3000 ft. In lieu of cloud decks, some TAFs will show vertical visibility (VV) in hundreds of feet, often when fog is also forecast.\nSKC means a forecast of clear skies. TAFs may also forecast icing or turbulence by following the sky group with a 6-digit number beginning with 6 (icing) or 5 (turbulence). The 2nd digit indicates the type of icing/turbulence. The next 3 digits are the base of the forecast layer in hundreds of feet, and the last digit is the layer depth in thousands of feet.\nBecause TAFs are generally limited to immediate airport operation considerations, these groups are rarely included. Military TAF forecasters will also frequently include temperature and altimeter settings, but civilian forecasters do not. Where present, forecast altimeter settings will begin with QNH (or just Q where space is limited) and a 4-digit altimeter setting followed by INS (inches).\nTemperature forecasts start with T followed by the maximum temperature (°C)/hour (Z) and minimum temperature/hour for the forecast period. Despite their basic nature, TAFs are often more accurate than the area forecasts issued for the region surrounding the airport.\nThis is because they take into account observations made at the airport, as well as localized nuances in geography and weather patterns that the forecasters know affect the airport’s weather.\nTrend type forecasts\nA cousin to the TAF is the trend type forecast (TTF), normally only produced by a professional forecaster located at the airport itself, and issued as part of a METAR to alert pilots to a likely significant change in weather conditions over the next 2 hours.\nTTFs are most commonly issued in the UK and Europe, but may be issued anywhere. The TTF forecast appears in the METAR following the code TEMPO. When a TTF appears in a METAR, pilots should consider the TTF to be better information than what is contained in the current valid TAF for the airport.\nA TTF might look something like TEMPO 0500 +TSRA VV002 RED. This TTF suggests that a developing strong thunderstorm is expected to drop visibility to 500 m and ceiling to 200 ft. The term RED is a so-called “color state.” These are included in TAFs and TTFs in some places, and were added to improve the speed at which a pilot could interpret ceiling and visibility conditions.\nThere are 8 colors to this index, and they represent the worst conditions forecast for the valid period, ranging from blue (BLU – best, with minimum 2500 ft ceiling and 8 km visibility) to red (RED – worst, with min ceiling less than 200 ft and visibility less than 800 m).\nIf there is another reason that an airfield is unusable, the word BLACK will precede the applicable color code.\nTAFs are a good information source for pilots, both during flight planning and enroute. Ahead of the flight, they are a way to quickly sort out the meteorological viability of alternate airports. Many pilots don’t consider the individual weather forecasts of airports they are considering as alternates, preferring to simply choose a nearby airport that can handle their aircraft and may have the right facilities to get the boss home and turn the flight as soon as the weather at the destination improves.\nHowever, ignoring the TAFs at potential alternate airports may mean that, when you divert, you find your designated alternate is in even worse shape than your original destination. A quick look at the TAF for the alternate can have you deciding instead on a different alternate a little further out where the forecast is not quite as dire.\nEnroute, looking at TAF updates along with the current METAR of your destination can help you validate the accuracy and timing of the forecast. For example, you may notice that the old forecast had arrival time winds of 10 kts down the runway, ramping up to a strong crosswind later that day.\nBut halfway through the flight, the new TAF advances the frontal wind shift to your arrival time, meaning you’ll face a stiff 25-kt crosswind gusting to 32. Similarly, you might have seen a TAF call for a ceiling dropping from 5000 ft broken to a 100 ft overcast after your arrival time, but the METARs are showing a more rapid deterioration, giving you time to prep for an instrument landing to the minimums.\nKarsten Shein is cofounder and science director at ExplorEiS. He was formerly an assistant professor at Shippensburg University and a climatologist with NOAA. Shein holds a commercial license with instrument rating."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:fd8f9875-5ff4-4fc2-b86f-cbcf058a0735>"],"error":null}
{"question":"I need help understanding tank maintenance. How do floating point calculations compare to fixed point in tank monitoring systems, and what cleaning procedures are needed for different types of tanks?","answer":"Floating-point processing provides much greater precision than fixed-point processing, making it ideal when computational accuracy is critical. Fixed-point numbers are simpler but have limitations in range and precision. For tank maintenance, different types require specific cleaning procedures: Fuel tanks need regular cleaning to prevent microbial growth and contaminants that can clog filters. Potable water tanks should be cleaned and disinfected every 6-12 months to prevent microbial growth. Black and grey water tanks are most challenging due to highly corrosive atmospheres from hydrogen sulfide, requiring regular cleaning and inspections to prevent excessive corrosion. All tank cleaning must be performed by certified professionals using specialized equipment and safety measures.","context":["Fixed or semi-fixed fire protection systems for storage tanks in the early years of the oil industry, fire in a storage tank was a common occurrence. Fixed peg arrangements are recognized by the imf as a fairly inflexible exchange rate regime countries in this category peg their currency, either formally or on a se facto basis, to another currency or a basket of currencies at a fixed rate. Critical comparison of fixed and floating exchange rate mechanisms essay examine independently floating exchange rate arrangements and other conventional fixed peg arrangements in separate sections. As such, floating-point processing yields much greater precision than fixed-point processing, distinguishing floating-point processors as the ideal dsp when computational accuracy is a critical requirement. Gpu vs fpga performance comparison selection for each application is a critical decision for and fixed- and floating-point processing capacity for this analysis.\nThe floating exchange rate, in my opinion, is the much better alternative you're allowing demand and supply, the most powerful forces of the market, to balance out each other without interference, so that they make the economy awesome, like they usually end up doing. Floating exchange rates unlike the fixed rate, a floating exchange rate is determined by the private market through supply and demand a floating rate is often termed self-correcting, as any differences in supply and demand will automatically be corrected in the market. Fixed point numbers are a simple and easy way to express fractional numbers, using a fixed number of bits systems without floating-point hardware support frequently use fixed-point numbers to represent fractional numbers (systems without floating-point hardware support includes a wide range of. Here's a comparison, looking at the advantages and disadvantages of each, and some guidelines on how to make the best of them for starters, let's define terms: a fixed-rate mortgage is a home loan with a set interest rate that's applicable for the entire duration of the loan (typically 30 years.\nFixed vs floating vs regulated rates: a brief summary of your alberta electricity options regulated (default) rate the default rate for natural gas in alberta is offered by two regulated rate providers: direct energy regulated services in the atco gas service territory, and altagas utilities in its own service area. The first article presents a comparison of covered tanks vs uncovered tanks (tanks with a floating roof but no fixed-roof) as well as a comparison of aluminum-dome roofs (adrs) vs steel-cone. What are the main factors to choose floating roof tanks over fixed roof tanks we have requirement for storage of high speed diesel for which we have selected 33 m dia x 175 m of 3nos for one of our projects in india. Unlike a plain-vanilla bond, which pays a fixed rate of interest, a floating rate bond has a variable rate that resets periodically typically, the rates are based on either the federal funds rate or libor plus an added spread libor stands for london interbank offered rate, and like the. The difference is that the coupon rates are fixed in fixed rate bonds and variable in floating rate say if govt of india issues bond paying 9% coupon (interest ) during the entire tenure of bond, it is fixed rate bond.\nA floating-rate security, also known as a floater, is an investment with interest payments that float or adjust periodically based upon a predetermined benchmark while floaters may be linked to almost any benchmark and pay interest based on a variety of formulas, the most basic type pays a. Exchange rate are higher rather compare to fixed or intermediate rates moreover, sjaastad (2008) claims that floating exchange rate after the collapse of bretton-woods has been the. This paper examines the recent evolution of exchange rate policies in the developing world it looks at why so many countries have made the transition from fixed or pegged exchange rates to managed floating or independently floating currencies. The aim of the thesis is toanalyze and compare the english fixed and floating charge to the czech encumbering charge over business with regard to the level of protection of creditors granted by the two distinct legal systems through legislation and case law.\nCaipa also pays a qualified fixed dividend at a rate of 850% before 04/15/2023 and then switches to paying a floating rate dividend at a rate of the three-month libor plus a spread of 582. Abstract this study was conducted to longitudinally compare a new floating platform mobile-bearing (mb) prosthesis with an established fixed-bearing (fb) system with respect to early clinical outcomes in patients with bilateral tkas using the mb prosthesis in one knee and the fb prosthesis in the other. Floating platforms to access oil and gas reserves in deep water locations at a lower cost than fixed- bottom alternatives as such, there is a great deal of overlap regarding the design, fabrication, and. Floating-rate funds—including both open-end funds and exchange-traded funds (etfs)—rose by more than 70%, from about $696 billion to about $1203 billion, primarily fueled by inflows of more than $45 billion. By comparison, floating point is more resilient to these problems, because the large dynamic range gives you more headroom, and overflows will not lead to catastrophic failures most audio signal processing code running on desktop computers is using the -10 10 range, single or double precision so this gives more than hundreds of db of.\nPeer comparison - how will your company, its debt levels, and place on the fixed-floating continuum, be viewed by equity investors when compared to competitors while our ceo, cfo, and treasurer clients may feel confident in their choice of fixed-floating interest rates, it's critical they learn as much as they can about what their. The disadvantage of fixed point number, is than of course the loss of range and precision when compare with floating point number representations for example, in a fixed representation, our fractional part is only precise to a quantum of 05. For example, a fixed-point representation with a uniform decimal point placement convention can represent the numbers 12345, 123456, 1234567, etc, whereas a floating-point representation could in addition represent 1234567, 1234567, 000001234567, 1234567000000000, etc.\nCost versus ease of use the much greater computational power offered by floating-point dsps is normally the critical element in the fixed- or floating-point design decision. Comparisons between internal floating roof storage tank and external floating storage tank as a kind of important oil storage tanks, floating roof tank is different with fixed roof tank, because that floating roof tank is equipped with a floating roof, which floats up and down with the liquid level, while fixed roof tank isn't.\nFiat currency doesn't imply a fixed exchange rate in fact, fiat currencies are compatible with a floating exchange rate regime, in which the value of a currency is determined in foreign exchange markets floating exchange rates have these main advantages: no need for international management of. Chapter 24 fixed versus floating exchange rates one of the big issues in international finance is the appropriate choice of a monetary system countries can choose between a floating exchange rate system and a variety of fixed exchange rate systems.","Fuel Tank Cleaning is critical to keep the vessel’s engines and generators functioning efficiently. Yacht fuel tank cleaning and inspection should be part of your vessel’s scheduled maintenance plan. For those vessels traveling outside of the United States and taking on fuel from other countries there is an increased concern. The U.S. has stricter quality control standards in the way the fuel is refined, stored and delivered. Contaminant build up resulting from excessive microbial growth in the fuel can cause filters to become clogged. Algae, water, and micro-organisms cause fuel degradation and the formation of waste products. Blocked filters will cause loss of RPM’s, poor engine performance, lower fuel economy and the worst possible scenario an engine shutdown at sea. Routine diesel fuel tank cleaning will ensure no unscheduled downtime.\nPOTABLE WATER TANK CLEANING & DISINFECTION is also important to have completed every 6- 12 months. We have seen some severe microbial growth in fresh water tanks that have not been opened, inspected and sanitized for 12+ months. All cleaning and sterilizing is performed to USCG standards. We also find that the original Tank Linings installed by the yacht manufacturer only last approximately 2 years. This can be attributed to a number of factors such as inadequate surface cleanliness, surface profile and/or improper lining application. It is important to catch these tank lining failures early before excessive corrosion and metal loss occurs. Metal removal and replacement repairs are extremely costly and lead to significant haul out costs and downtime. We have the capability to complete the job properly and neatly even while the vessel is in the water. It is much more cost effective and faster to properly clean, blast and line the tanks with an epoxy tank lining before severe corrosion sets in.\nBlack & Grey Water Tanks have the most highly corrosive atmospheres of all tanks created by the release of Hydrogen Sulfide from accumulated waste. The upper portion of the tank lining exposed to the tank’s atmosphere experiences an accelerated rate of declining lifespan. Once the epoxy tank lining begins to fail the underlying steel or aluminum surface will corrode at a rapid rate. It is important to catch this early on through regular cleaning and inspections before the tank excessively corrodes requiring mandatory replacement by Lloyds & ABS.\nWe also have developed a circulatory systematic method for de-scaling black water piping systems to remove built up calcium and mineral deposits. We also have the specialty tooling required to perform ultra high pressure pipe jetting to remove clogs and calcium build up which is much faster but dependent on the design and construction of your piping system. It is crucial to keep your black water piping system clean to ensure all toilets function properly and solid objects do not become trapped in constricted plumbing that is not flowing as it was designed. Regular pipe cleaning will also eliminate the chance for unpleasant odors coming from heads.\nConfined Space Tank Cleaning requires specialized training and equipment; and should be left to trained and experienced professionals. All of our tank cleaning technicians are Hazardous Confined Space Certified and foremen are OSHA 30-hour trained. We own and operate a fleet of Vacuum Trucks for tank pump outs which are equipped with high pressure steam cleaners and air compressors for supplied filtered breathing air to get the job completed safely and to OSHA Standards. We also utilize Carbon Monoxide and Carbon Dioxide Monitors to keep our workers alerted and safe from any and all hazards. We take no chances!\nWhatever type of mega yacht tank cleaning you require, we can clean it safely and effectively."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:a32d5153-f4f8-41f3-9dca-a0d5300ea015>","<urn:uuid:9539ad19-e9b2-4885-97ed-8d657933e2a2>"],"error":null}
{"question":"What are the key differences between Game Theory and Agency Theory in terms of their focus on strategic interactions?","answer":"Game Theory focuses on strategic interactions between multiple participants where outcomes depend on everyone's decisions, as seen in games like chess. Agency Theory, in contrast, specifically deals with the relationship between principals and agents under conditions of incomplete and asymmetric information, such as when stockholders hire executives. While Game Theory analyzes optimal strategies in competitive situations, Agency Theory examines how to align interests when there are conflicts between principals and agents.","context":["What Is Game Theory? A Basic Introduction and Example\nGame Theory is one of the most fascinating branches of mathematics with tons of applications to fields ranging from the social sciences to the biological sciences. Game Theory has even found its way into mainstream media through movies such as A Beautiful Mind, with Russell Crowe.\nThis article will explain some of the fundamentals of game theory and work through a simple example.\nDefinition of a \"Game\"\nGame Theory is the study of \"games.\" Games, in the mathematical sense, are defined as strategic situations in which there are multiple participants. Furthermore, the outcome of the decision any individual makes is dependent on the decision that individual's decision and the decisions made by all of the other participants.\nIs Sudoku a \"game?\"\nNo, not the way we defined \"game.\" Sudoku is not a \"game\" because what you do when solving the game is independent of what anyone else does.\nIs Chess a \"game?\"\nYes! Imagine that you are playing a game of chess with a friend. Whether you win or not will be dependent on the moves you make and the moves your friend makes. At the same time, whether or not they win will be dependent on the moves they make and the moves you make.\nNOTE: The most important thing to realize in the chess example is that at least 2 \"participant's\" decisions were affected by the decisions of other participants. Solving a Sudoku puzzle is not a game since how you solve the puzzle is not affected by anyone else's decisions.\nOk, I get what a \"game\" is, but what is Game Theory?\nGame Theory is the study of \"games.\" Game theorists try to model \"games\" in a way that makes them easy to understand and analyze. A lot of \"games\" end up having similar properties or reoccurring patterns, but sometimes it is hard to understand a complicated game.\nLet's work through an example of a game and how a game theorist might model it.\nExample: The Game of Chicken\nConsider the \"game\" of chicken. In the game of chicken we have 2 people, Bluebert and Redbert, who drive their cars at full speed towards each other. They each have to make the decision just before crashing to either drive straight ahead or to swerve at the last minute. The possible results are as follows:\nBluebert is happy he wins, Redbert is sad he loses\nBluebert is sad he loses, Redbert is happy he wins\nThey stare at each other shocked at what they've done\nNow that we know the general results, this isn't the easiest way of understanding the game. Let's reorganize the possible results into a matrix.\nThis is called a payoff matrix. The rows represent the possible actions of Bluebert. The columns represent the possible actions of Redbert. Each box represents the result from each combination of decisions. By using this matrix, it is easy to see what the result of different combinations of actions is.\nA quick example: If Bluebert swerves, then we know the result will be one of the top 2 boxes, depending on what Redbert decides to do. On the other hand, if Blubert goes straight, then we know the result will be one of the bottom two boxes, depending on what Redbert decides to do.\nLet's replace the illustrations of the results with some numbers to make things easier to analyze.\n- Both swerving and staring at each other = 0 for both\n- Both going straight and crashing = -5 for both\n- One swerving and one going straight = 1 for the winner (straight) and -1 for the loser (swerve)\nSome Simple Analysis:\nNow that we have organized this game theoretic \"game\" into an easily readable payoff matrix, let's see what we can learn about how the game will be played out.\nThe first thing we will look at is something called a best response. Essentially, lets imagine that we are Bluebert and we KNOW what Redbert will do. How do we react?\nIf we KNOW Redbert will swerve, we need only look at the left column. We see that if we swerve we get 0 and if we go straight, we get 1. So the best response is to go straight.\nOn the other hand, if we KNOW Redbert will go straight, we need only look at the right column. We see that if we swerve we get -1 and if we go straight, we get -5. So the best response is to go straight.\nIn this game, Redbert has similar best responses.\nIf you have seen the Ron Howard movie, A Beautiful Mind, with Russell Crowe, you may remember that it was about the Mathematician John Nash. Nash Equilibriums are named after this very Nash!\nA Nash Equilibrium is when all players play a best response. In the game of chicken above, both players going straight is not a Nash Equilibrium because at least one player would have preferred to swerve. In the game of chicken, both players swerving is not a Nash Equilibrium because at least one player would have preferred to go straight.\nHowever, when one player swerves, and one player goes straight, this is a Nash Equilibrium because neither player can improve their outcome by changing their action. Another way of saying this is that both players are playing a best response.\nIf you've made it this far congrats! You've learned the basics of game theory. It wasn't the most fun we can have with game theory, but it did lay a solid foundation to understand this amazing branch of mathematics, and you can see how applicable it is to many different disciplines.\nIf you have questions, comments, or suggestions, please let me know. In particular, if something was unclear above, let me know so I can try to explain it better. Thanks!","Presentation on theme: \"DECISION THEORIES 1 Problem solving –Collaboration, GAME THEORY –Asymmetric information, AGENCY THEORY –Optimization, OPERATIONAL RESEARCH 2 Problem finding.\"— Presentation transcript:\nDECISION THEORIES 1 Problem solving –Collaboration, GAME THEORY –Asymmetric information, AGENCY THEORY –Optimization, OPERATIONAL RESEARCH 2 Problem finding –Intelligence, Design, Choice –Cognitive dissonance theory –Cognitive Fit theory 3 Collective problem - Mimetism\nCONTRACTCALCULATION UNDERSTANDING RATIONALITY - Autonomy - Calculation rationality - Preferences maximization - Pure market Positivism - Strategical, political - Bounded rationality - Satisfacing - Access cost to the market Behaviorism - Convention, Understanding, Trust - Rationality of Mimetism - Information screen Constructivism\n1. Problem solving\n. Game theory A branch of applied mathematics that uses models to study interactions with formalized incentive structures (\"games\"). Game theory studies choice of optimal behavior when costs and benefits of each option are not fixed, but depend upon the choices of other individuals : various players interact strategically Game theory has applications in a variety of fields, including economics, international relations, evolutionary biology, political science, and military strategy. Game theorists study the predicted and actual behaviour of individuals in games, as well as optimal strategies.\nAgency Theory - The « principal-agent » problem treats the difficulties that arise under conditions of incomplete and asymmetric information when a principal hires an agent For example when stockholders hire top executives of corporations: - The desires or goals of the principal and agent conflict - It is difficult or expensive for the principle to verify what the agent is actually doing - The principle and the agent may prefer different actions because of the different risk preferences Various mechanisms may be used to try to align the interests of the agent with those of the principal : piece rates/commissions, profit sharing, efficiency wages, the agent posting a bond, or fear of firing.\n2. PROBLEM FINDING\n. H. Simon : the bounded rationality Intelligence Design Choice The \"administrative man\" pursues his self-interests but often doesn't know what they are, is aware of only some of the possible decision alternatives, and is willing to settle for an adequate solution than continue looking for an optimal one Satisficing is a behaviour which attempts to achieve at least some minimum level of a particular variable, but which does not strive to achieve its maximum possible value.\n. Cognitive Dissonance Theory Leon Festinger (1957): there is a tendency for individuals to seek consistency among their cognitions (i.e., beliefs, opinions). When there is an inconsistency between attitudes or behaviors (dissonance), something must change to eliminate the dissonance. It is most likely that the attitude will change to accommodate the behavior. In this respect, dissonance theory is contradictory to most behavioral theories which would predict greater attitude change with increased incentive (i.e., reinforcement) BehaviorsAttitudes Intelligence Design Choice Dissonance\n. Cognitive Fit theory Vessey (1991) : The theory proposes that the correspondence between task and information presentation format leads to superior task performance for individual users In several studies, cognitive fit theory has provided an explanation for performance differences among users across different presentation formats (tables, graphs, schematic faces, geographic information systems…\nArtificial intelligence Implanting into IT systems so much intelligence that they are able to cooperate with humans at the same level as do humans among themselves: Chess World Champion Kasparov defeat against the system Deep Blue Windows XP’ troubleshooters and Vista’s Solutions to Problems features Search engines understanding the content of the web pages Data mining and information discovery Open mind common sense database Natural language understanding Intelligent robots\nHuman-Computer Interaction (HCI) Establishing more user-friendly systems: new interfaces –multisensoriality, –multi-modality, –multi-lingualism, –input/output by way of direct brain/machine or brain/brain interfaces new displays technologies: –wearable devices –head-mounted displays –micro-displays –3D displays\n3. Decision, a collective problem\nRules, regulations, codes « Screen » Human Agents Conviction, Mimetism A D B C Confirmation Interpretation Flux Uncertaincy? Transparency? Interpretation? Agreement, Convention, Understanding"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:0ee4b372-6cb2-4ebb-9aaa-5a4caebdb1d8>","<urn:uuid:6fbde78d-07a5-4043-a68e-7b3acf48b898>"],"error":null}
{"question":"How do physical symptoms compare between panic attacks and fear-related chronic pain?","answer":"During panic attacks, individuals experience at least four symptoms including palpitations, accelerated heart rate, trembling, shortness of breath, chest pain, nausea, dizziness, and numbness. In fear-related chronic pain, patients experience hypervigilance, muscular reactivity, and physical symptoms from disuse syndrome including cardiovascular vulnerability, obesity, musculoskeletal fragility, and premature aging.","context":["Acute pain is a warning system for your body and mind, letting you know something is wrong. So when you experience pain it’s natural to worry about it and protect the area that hurts. During acute pain when your body is injured, pain serves its protective purpose, helping the body to heal.\nHowever, when pain becomes chronic, it means that this warning system is broken; you continue to experience pain without an injury or danger being present. So, while it’s natural that your reaction to chronic pain would be to focus on it, to worry about it and to want to rest to promote healing, this fear and avoidance behaviour can keep you locked in a fear and pain cycle, sustaining the pain experience indefinitely.\nMany patients start to fear things that might make their pain worse, perhaps avoiding a situation which caused their original injury; maybe because a certain situation or action has made their chronic pain symptoms flare in the past; or sometimes even worrying about situations which aren’t based on any previous experience, anticipating pain before it happens.\nWhat is the fear avoidance model?\nThe concept of patients avoiding situations that they feel may cause or worsen chronic pain was developed in the 1980s; this is now known as the fear avoidance model.\nPatients develop and compound negative beliefs about their chronic pain and start to fear movement (also known as kinesiophobia). They fear that exercising and even normal day to day functioning that requires them to move their body, is going to worsen their pain or damage their body. This fear leads them to avoid those situations, acting in a way that they mistakenly feel is protecting themselves.\nThis fear and avoidance causes patients to become hypervigilant about their pain, meaning that they are constantly aware of it and considering it in every part of their life. They catastrophize about their pain, meaning that they are worrying about it in an extreme way. This study explains that, “Pain-related fear of movement (kinesiophobia) leads to hypervigilance, muscular reactivity, and avoidance.”\nFear activates our ‘fight or flight’ response and keeps us stuck in that chronic pain and stress cycle, one feeding into the other. There have been many studies that prove that patient’s who anticipate pain during an activity, will actually experience more pain and be able to function less, as shown in this study.\nFear of movement worsening their symptoms leads to patient’s avoiding exercise, avoiding socializing, going out, daily functioning and so much more; this increases isolation, depression and disability. Not moving their bodies then leads to muscles weakening, causing more stress on the body and more pain in turn; this is sometimes described as disuse syndrome. This article explains that disuse syndrome can cause,\ncardiovascular vulnerability, obesity, musculoskeletal fragility, depression and premature aging.\nHow is fear avoidance measured?\nOne of the first steps to looking at moving forward from this fear avoidance, is to work out how much it is affecting an individual’s life. This is typically done with a questionnaire by medical professionals. There are a few types of questionnaire which might be used: Pain Anxiety Symptom Scale (PASS), Fear-Avoidance Components Scale (FACS), Fear-Avoidance Beliefs Questionnaire (FABQ), Tampa Scale of Kinesiophobia (TSK), Photograph Series of Daily Activities (PHODA).\nThese scales sound complicated but essentially are all based around the same concept; they include questions that pose difference scenarios and situations, asking you to rate in severity how you experience your pain and how you react during certain situations in your day to day life. These sort of tools, alongside your clinical history and other tests, can help a medical professional to understand how your chronic pain is affecting your day to day life, how active you are and to what extent the fear avoidance model is influencing your life. From there they can help you to get the help that you need.\nTherapies which address fear and chronic pain\nFear is a natural and understandable reaction to pain, it’s not usually a conscious or chosen reaction; it doesn’t mean that it’s your fault that you are in pain. I can completely understand as a chronic pain patient that this can sound daunting and perhaps can be interpreted as someone invalidating your pain. However, as you start to learn the science behind what is compounding your pain, you can become more consciously aware of how you are processing that pain, in order to improve your life.\nThe fear avoidance model can make things sound a bit dire but don’t worry, there are plenty of ways that you can break the cycle and overcome this fear. Let’s look at how fear can be treated and beaten.\n- Therapeutic Neuroscience Education\nEducating patients about the cause of their pain and helping them to understand how it works can relieve anxiety and fear around pain; this can in turn calm an overactive pain system and reduce pain levels.\n- Cognitive Behavioural Therapy (CBT)\nCognitive Behavioural Therapy (CBT) is a talking therapy that helps patients to understand how their thoughts can impact their behaviours; it helps you to replace negative thoughts like fear and behaviours like avoidance, with positive, helpful thoughts and behaviours which increase daily functioning, exercise and fundamentally, help you get your quality of life back.\nCBT teaches patients to understand the cause of their pain; once you understand the science behind it, it helps to reduce that fear. It aids you in taking your focus away from catastrophizing about your pain and teaches you how to redirect that energy in a helpful way, so that you are taking control over your chronic pain.\n- Acceptance and Commitment Therapy (ACT)\nRather than changing the thoughts you are having about your pain, Acceptance and Commitment Therapy (ACT) focuses on accepting those thoughts and feelings, understand that what you are going through physically and emotionally is valid and that it isn’t going to ‘hurt’ you.\nACT teaches you that a negative thought or a feeling of pain is just a feeling you are having in the present; you don’t have to run from it, you don’t have to try and ignore it or avoid it. This reduces fear and avoidance and instead empowers patients to face their condition head on and not limit their life. Depending on the individual, ACT or CBT may be more effective; both have proven results.\n- Graded Exposure Therapy\nGraded Exposure Therapy can be used to address all kinds of fears and phobias; it has proven results on fear avoidance with chronic pain. It works by gradually exposing patients to situations that they are afraid of, working up from situations that evoke only minimal concern and building confidence along the way.\nAs patient’s face situations that they thought they could not cope with or were afraid of, they actively see that they can face these situations and that their body wasn’t damaged by taking that action. Confidence in their own abilities grows while fear and helplessness is reduced.\nYou may hear reference to Graded Exercise Therapy, which is part of the same concept and focuses on actively increasing the amount and intensity of exercise a patient is doing.\nThis study found that Graded Exposure Therapy, “appears to be the most effective treatment for chronic pain in individuals with increased fear and avoidance”\n- Graded Motor Imagery\nGraded Motor Imagery deals with the concept of central sensitization, which is basically an over sensitive nervous system causing chronic pain; it uses imagery techniques to help patients retrain their brains away from chronic pain.\nGraded Motor Imagery has proven to be very effective in breaking the chronic pain cycle. This therapy essentially ‘rewires’ the brain, using imagery to guide the brain through the processes of a specific movement without activating the pain sensors; therefore, the brain learns that this movement doesn’t cause pain. It works on a step by step scale, working up to the patient being able to function and perform those movements without experiencing pain.\n- Physical Therapy\nA physical therapist can help you with exercises to strengthen your body. They can help you re-learn how to move your body and build your confidence in daily functioning.\n- Mindfulness techniques\nMindfulness techniques can be varied and include activities like meditation, guided visualizations, yoga and more. Mindfulness is about being grounded in the moment, accepting the emotions you are feeling, the pain you may be experiencing and what is happening around you, rather than worrying about what is ahead. These sorts of techniques can help you to relax, which in turn reduces stress and helps you to get out of the pain and stress cycle.\nWhat can you do to help yourself?\nYou might be wondering what you can to actively help yourself overcome this fear and avoidance.\n- Seek out therapy: the therapies we have mentioned can be accessed through your doctor, sought out privately, or accessed online through an app like Pathways Pain Relief. Advocate for yourself with medical professionals and seek out the help in the way that you feel is most appropriate for your situation.\n- Educate yourself: learning about what is causing your pain can allow you to see that your chronic pain condition is not going to damage your body; this can give you confidence in being more active and take that fear away.\n- Exercise regularly: trying to do regular gentle exercise is beneficial. Exercise can help you to build confidence and tackle avoidance behaviours, to build muscle strength and to be healthier overall.\n- Set goals: setting a list of goals for each day or for your future, can help to keep yourself motivated and give you purpose in being active and continuing to function even when your pain is at its worst.\n- Practice self-care: self-care is any action that is actively improving your life and helping yourself, whether this is doing something fun, eating healthy foods, doing your housework, taking medication or anything else. You deserve the best and that includes from yourself!\n- Don’t be too hard on yourself: this fear reaction is inherent within us, it’s completely natural and it doesn’t mean that you have done anything wrong. Don’t be too harsh with yourself, instead try to focus on what you can change.\nEliminating the fear of chronic pain and breaking the cycle is a long road, but it can be done. You can take control back and live a high functioning, joy-filled life without fear of your chronic pain!\nPlease note: This article is made available for educational purposes only, not to provide personal medical advice.\n- Pain Medicine, Volume 2, Issue 4, Pages 259-266, Michael Pfingsten, PD, PhD, Eric Leibing, DSc, Wulf Harter, PhD, Birgit Kröner-Herwig, Doreen Hempel, Uta Kronshage, Jan Hildebrandt, (2001), “Fear-Avoidance Behavior and Anticipation of Pain in Patients With Chronic Low Back Pain: A Randomized Controlled Study”\n- The Western Journal of Medicine, Bortz WM, (1984), “The disuse syndrome.”\n- The Anterior Cruciate Ligament, Second Edition, Pages 498-500. Mark F.Sommerfeldt MD. FRCSC., LouiseThoma DPT., Laura C.Schmitt PT, PhD., Joshua S.Everhart MD., David C.Flanigan MD, (2018), “Psychological Predictors of Anterior Cruciate Ligament Recovery Outcomes”\n- Practical Pain Management, Volume 19, Issue 5, David Cosio, PhD, ABPP, (2019), “Fear-Avoidance and Chronic Pain: Helping Patients Stuck in the Mouse Trap”\nEmily L. Zale, Joseph W. Ditre, (2015), “Pain-Related Fear, Disability, and the Fear-Avoidance Model of Chronic Pain”\n- Steven Z. George, PT, PhD.,Virgil T. Wittmer, PhD., Roger B. Fillingim, PhD., Michael E. Robinson, PhD, (2010), “Comparison of Graded Exercise and Graded Exposure Clinical Outcomes for Patients With Chronic Low Back Pain”\n- Journal of Clinical Psychology in Medical Settings, Volume 14, Issue 2, pp 113–122, Jessica A. Lohnberg, (2007), “A Review of Outcome Studies on Cognitive-Behavioral Therapy for Reducing Fear-Avoidance Beliefs Among Individuals With Chronic Pain”\n- Translational Behavioural Medicine, Thomas P Guck, PhD, Raymond V Burke, PhD, Christopher Rainville, MD, Dreylana Hill-Taylor, MD, Dustin P Wallace, PhD, (2014), “A brief primary care intervention to reduce fear of movement in chronic low back pain patients”","It is normal to experience occasional anxiety, especially in stressful situations. However, continuing to experience extreme and persistent anxiety, can be a sign of an anxiety disorder presence. This is referring to those who feel their feelings becoming difficult to control and begin to cause psychological distress and interfere with daily functioning. There are several different types of anxiety disorders, including:\nSocial Anxiety Disorder\nSeparation Anxiety Disorder\nWhile it is difficult to determine the exact causes of anxiety disorders, there are several risk factors 3 for developing one, including:\nBrain Structure and Chemistry\nStressful or Traumatic Characteristics\nFamilty History of Depression\nCertain Medical Conditions\nSubstance abuse problems\nPeople with generalized anxiety disorder (GAD) experience overwhelmingly high amounts of anxiety and worry about numerous situations, activities, and events. They typically worry about daily life circumstances, including matters related to their family, relationships, finances, or health. They often also worry about minor issues.\nThe amount of anxiety they feel is disproportionate to the object or situation itself, or they may not even have a specific reason for their worries.\nPeople with GAD may also experience the following:\n• Feelings of restlessness or being “on edge” and difficulty relaxing\n• Being easily fatigued\n• Difficulty concentrating / mind going blank\n• Irritability Muscle tension\n• Trouble falling or staying asleep\n• Trembling, twitching, or feeling shaky\n• Physical symptoms such as increased heart rate, sweating, headaches, nausea, or diarrhea\nWhile the median age of onset for GAD is 30 years, it can also occur during childhood or adolescence. Individuals with GAD often describe that they have felt anxious for their entire lives.\nPeople with social anxiety disorder experience extreme fear or anxiety in social situations. Situations that may include interacting with others, performing in front of others, or being observed by others. The anxiety experienced in social cases is developed from a fear of being judged, rejected, or embarrassed by others. Some people may also fear that they will offend others by accident.\nTo be diagnosed with social anxiety disorder, the social situation fears must almost always trigger anxiety in the individual. This triggered anxiety must be deemed excessive.\nPeople with social anxiety disorder may also:\n• Spend many days worrying about an upcoming social event\n• Excessively prepare for anticipated social interactions\n• Show overly rigid body posture\n• Have inadequate eye contact\n• Speak in an overly quiet voice\n• Seek jobs where social connection is not required\n• Experience physical symptoms of anxiety in social situations, such as trembling, sweating, rapid heartbeat, or blushing\nThe typical age at onset for social anxiety disorder is between 8 and 15 years. It may develop slowly, or it may onset after experiencing a particularly humiliating or stressful event.\nAny friends or family members that you know struggling with panic disorders are known to repeatedly have unexpected panic attacks. According to professionals, panic attacks are sudden episodes of intense fear or discomfort that reach a peak within minutes.\nDuring a panic attack, at least four of the following symptoms occur:\n• Palpitations, pounding heart\n• Accelerated heart rate\n• Trembling or shaking\n• Sensations of shortness of breath\n• Feelings of choking\n• Chest pain or discomfort\n• Nausea or abdominal distress\n• Feeling dizzy, unsteady, light-headed, faint\n• Chills or heat sensations\n• Numbness or tingling sensations\n• Feelings of unreality (derealization)\n• Feeling detached from oneself\n• Fear of losing control or “going crazy.”\n• Fear of dying\nTo be diagnosed with panic disorder or other mental illnesses, panic attacks must be unexpected. This means that they are not triggered by anything. Instead, the panic attacks seemingly occur from out of the blue. Individuals with panic disorder continuously worry about having additional panic attacks.\nThe age at onset for panic disorder typically begins in early adulthood, between the ages of 20-24. Although it is less common, panic disorder can also occur in childhood or adolescence.\nClinical trials have shown anxiety disorders can be treated with psychotherapy, medication, or a combination of both 5. Research has shown that psychotherapy and medication are both effective treatments for anxiety disorders. Talking with your doctor to find a suitable treatment option would be extremely beneficial.\nPsychotherapy, or “talk therapy,” involves working with a licensed mental health professional to identify, understand, and treat the psychological symptoms and difficulties you are having.\nResearch shows that individuals who receive psychotherapy, experience an improvement in their functioning. About 75% 6 of people receiving psychotherapy experience some benefit from it.\nStudies show that cognitive-behavioral therapy (CBT) is the most effective 7 types of therapy for treating anxiety disorders. CBT helps people understand the relationship between their thoughts, feelings, and behaviors. Also, to focus on teaching people practical coping skills and problem-solving skills. Therapists often give their patients “homework” assignments so that they can practice the new skills they learn in their daily lives.\nTwo methods of CBT 8 are commonly used to treat anxiety disorders: cognitive therapy and exposure therapy. When using cognitive therapy techniques, your therapist will help you learn how your thoughts and beliefs are contributing to your anxiety symptoms.\nAlso, exposure therapy is especially beneficial for people who tend to avoid the things they fear, as it allows them to learn to confront their fears. In exposure therapy, your therapist will slowly “expose” you to the situation or object that provokes anxiety in a safe environment.\nOver time, you will become less and less sensitive to the feared situation or object, until, eventually, it no longer evokes fear. When treating panic disorder 9, interoceptive exposure may be used.\nThree standard classes of medications 10 used to treat anxiety disorders include antidepressants, benzodiazepines, and beta-blockers.\nSome medications help with anxiety symptoms immediately, while others may take several weeks until improvement is felt. Certain medications may work better for specific anxiety disorders, and, sometimes, medications may be combined to best treat symptoms.\nIt may take some trial and error to find the right drug and dosage for you, but your doctor will work with you until you find the right one.\nAntidepressants are frequently used to treat most anxiety disorders. Two newer types of antidepressants 11 are selective serotonin reuptake inhibitors (SSRIs) and serotonin-norepinephrine reuptake inhibitors (SNRIs). Both are considered first-line drug treatments for anxiety disorders.\nTricyclic antidepressants (TCAs) may also be used to treat anxiety disorders, but is used less often because it is capable of producing more side-effects than others. As antidepressants have a low risk of dependency, it can take 2 to 6 weeks before symptoms may begin to improve.\nBenzodiazepines are effective in rapidly relieving anxiety symptoms soon after they are taken. However, taking benzodiazepines for extended periods can lead to problems related to dependence and tolerance. Instead, benzodiazepines are commonly used 15 for short-term symptom relief.\nWhen someone suddenly stops taking their benzo medication, withdrawal symptoms are likely to develop. Because of this, your doctor can help you gradually reduce your usage to help make these effects minimal.\nAlthough beta-blockers are typically used to treat high blood pressure or heart conditions, they may also be used to treat certain anxiety disorders.\nWhile they do not relieve feelings of anxiety, they can help reduce the various physical symptoms of anxiety, such as rapid heart rate, trembling, and sweating.\nOther ways to manage anxiety symptoms are listed below.\nIt is recommended that you use these methods along with psychotherapy, medication, or both.\n• Deep breathing exercises 18\n• Progressive muscle relaxation 19\n• Binaural beats 20\n• Regular exercise, especially 30 min/cardio\n• Limiting alcohol, nicotine & caffeine intake"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:d447e174-ce06-4768-a395-657f05556374>","<urn:uuid:d914bc99-182b-4191-a39c-78cda47ec500>"],"error":null}
{"question":"As someone developing a large Python project, what benefits would I get from using Redex's testing capabilities versus mypy's static typing?","answer":"Redex allows you to evaluate programs in every possible order and compare results with expected outcomes, making it useful for testing language features and finding issues like non-determinism. Meanwhile, mypy's static typing offers different advantages: it helps make large projects easier to understand and maintain, enables finding bugs earlier in development with less testing, improves reliability, and supports development tools like IDEs with precise code completion. While Redex focuses on testing language semantics, mypy provides compile-time checks and documentation benefits that are particularly valuable for large, complex projects maintained by multiple developers.","context":["Over the last year or two, I’ve been using PLT Redex more and more often as a tool for my research. Redex is a domain-specific programming language and suite of tools for expressing and experimenting with semantic models of programming languages.\nTaking your semantics for a shakedown cruise\nWhat do I mean by “expressing and experimenting with semantic models of programming languages”? One way to think of Redex is as a programming language for writing programming languages. When you write up a model of a language L in Redex, you end up with something that is in fact an implementation of L, although one that probably runs too slowly to be practical. So it might be more accurate to think of Redex as a language for writing reference implementations of programming languages, together with a suite of tools for doing lots of things that you might want to do with such a reference implementation, like randomized testing, typesetting, and visualization.1\nBut, ugh! That phrase “reference implementation” raises the specter of mind-numbing technical standards documents and the like. It doesn’t convey the fun of Redex at all. Instead, I like to think of Redex as a quick way of giving potential new language features a try.\nFor instance, I want LVars to be a mechanism for deterministic parallelism: programs that use LVars to communicate between parallel tasks should always evaluate to the same value, regardless of the order in which LVar operations occur. To that end, it’s useful to model a tiny language in which LVars are the only interesting feature. If I know that no other feature of my tiny language introduces nondeterminism, then if any nondeterminism does arise in programs I’ve written using the model, I’ll know that something is wrong with my design for LVars.\nRedex isn’t a theorem-proving tool, so I can’t use it to prove that a language is deterministic.2 I can, however, use Redex to attempt to falsify properties of a language. For instance, Redex can evaluate a program in every possible order and compare the results with an expected result. If I ever get something different, then I’ll know that my language is not deterministic. In this sense, Redex is a way to take a language semantics for a shakedown cruise before you try to prove anything about it, because getting halfway through a long proof only to find that the property you’re attempting to prove is false is about as much fun as finding out that your boat’s not seaworthy when you’re halfway across the ocean.\nParameterizing a language definition by a lattice\nMy tiny LVar language, lambdaLVar, is more or less a garden-variety untyped lambda calculus, extended with a memory store and with\nget operations that respectively write to and read from store locations. lambdaLVar expressions can reduce in parallel, and having a store of shared mutable memory would ordinarily let nondeterminism in. Instead of ordinary mutable memory cells, though, the store contains LVars, which is short for “lattice variables”. An LVar’s value can only increase over time, where the meaning of “increase” is given by a partially ordered set, or lattice, that the user of the language specifies. Therefore lambdaLVar is really a family of languages: instantiate it with one lattice and you get one deterministic parallel language; with a different lattice, and you get another.\nOn paper, the definition of lambdaLVar is parameterized by that user-specified lattice. For a long time, I wanted the Redex definition of lambdaLVar to be parameterized in the same way, but I couldn’t figure out how to accomplish it in Redex. Finally, after checking with the Racket users mailing list, I learned that what I want to do isn’t possible in Redex as it stands today, although it should be possible in a future version.\nBut wait! Redex is embedded in Racket, a language with a powerful macro system that allows you to write programs that generate programs.3 So, even though I couldn’t parameterize the definition of lambdaLVar by a lattice using Redex alone, I could write a Racket macro taking a lattice as an argument, then use it to generate instantiations of lambdaLVar at macro expansion time.\nI defined a Racket macro,\ndefine-lambdaLVar-language, that takes a language name, a least upper bound operation, and a set of lattice values, and generates a Redex language definition. For instance, to generate a Redex language model called\nlambdaLVar-nat where the user-specified lattice is the natural numbers with\nmax as the least upper bound, I can call\ndefine-lambdaLVar-language like this:\nmax is an operation that’s built in to Racket.\nnatural doesn’t mean anything in Racket, but to Redex it means “the set of natural numbers”. The above program is a Racket program, not a Redex program, but because\ndefine-lambdaLVar-language is a macro, it’s perfectly okay to pass in arguments like\nnatural; they won’t be interpreted until after the macro has expanded.\nI’m no macrologist, but writing the\ndefine-lambdaLVar-language macro itself was easy.4 I already had a Redex model of lambdaLVar, but specialized to use\nnatural as the set of lattice elements, and calling out to a user-specified least upper bound operation called\nlub-op. So the macro just ended up being a very thin wrapper around the code I already had, with some trivial changes.\n1 2 3 4 5\nYou can see what it ended up looking like on GitHub.\nlambdaLVar.rkt defines the\ndefine-lambdaLVar-language macro. The\nnat directory has a test suite of programs for\nnatpair-ivars are two more example instantiations. As you might expect, for some lattices, the least upper bound operation is dead simple; for others, it’s a little more sophisticated. Try writing one yourself, and instantiate your own deterministic parallel language today!\nThanks to the folks on the Racket users list for their help, and to Matt Might, who originally suggested that I would need to write Redex-generating macros in a conversation at ICFP last September. I wanted so badly for there to be some way to do everything within Redex that I ignored his advice for another six months!\nI ended up doing that by hand, more’s the pity. ↩\nIn fact, Redex itself is implemented using Racket macros, although you don’t need to know how that works to use Redex. ↩","Frequently Asked Questions¶\nWhy have both dynamic and static typing?¶\nDynamic typing can be flexible, powerful, convenient and easy. But it’s not always the best approach; there are good reasons why many developers choose to use statically typed languages or static typing for Python.\nHere are some potential benefits of mypy-style static typing:\n- Static typing can make programs easier to understand and maintain. Type declarations can serve as machine-checked documentation. This is important as code is typically read much more often than modified, and this is especially important for large and complex programs.\n- Static typing can help you find bugs earlier and with less testing and debugging. Especially in large and complex projects this can be a major time-saver.\n- Static typing can help you find difficult-to-find bugs before your code goes into production. This can improve reliability and reduce the number of security issues.\n- Static typing makes it practical to build very useful development tools that can improve programming productivity or software quality, including IDEs with precise and reliable code completion, static analysis tools, etc.\n- You can get the benefits of both dynamic and static typing in a single language. Dynamic typing can be perfect for a small project or for writing the UI of your program, for example. As your program grows, you can adapt tricky application logic to static typing to help maintenance.\nSee also the front page of the mypy web site.\nWould my project benefit from static typing?¶\nFor many projects dynamic typing is perfectly fine (we think that Python is a great language). But sometimes your projects demand bigger guns, and that’s when mypy may come in handy.\nIf some of these ring true for your projects, mypy (and static typing) may be useful:\n- Your project is large or complex.\n- Your codebase must be maintained for a long time.\n- Multiple developers are working on the same code.\n- Running tests takes a lot of time or work (type checking helps you find errors quickly early in development, reducing the number of testing iterations).\n- Some project members (devs or management) don’t like dynamic typing, but others prefer dynamic typing and Python syntax. Mypy could be a solution that everybody finds easy to accept.\n- You want to future-proof your project even if currently none of the above really apply. The earlier you start, the easier it will be to adopt static typing.\nCan I use mypy to type check my existing Python code?¶\nMypy supports most Python features and idioms, and many large Python projects are using mypy successfully. Code that uses complex introspection or metaprogramming may be impractical to type check, but it should still be possible to use static typing in other parts of a codebase that are less dynamic.\nWill static typing make my programs run faster?¶\nMypy only does static type checking and it does not improve performance. It has a minimal performance impact. In the future, there could be other tools that can compile statically typed mypy code to C modules or to efficient JVM bytecode, for example, but this is outside the scope of the mypy project.\nHow do I type check my Python 2 code?¶\nYou can use a comment-based function annotation syntax\nand use the\n--py2 command-line option to type check your Python 2 code.\nYou’ll also need to install\ntyping for Python 2 via\npip install typing.\nIs mypy free?¶\nYes. Mypy is free software, and it can also be used for commercial and proprietary projects. Mypy is available under the MIT license.\nCan I use duck typing with mypy?¶\nMypy provides support for both nominal subtyping and\nStructural subtyping can be thought of as “static duck typing”.\nSome argue that structural subtyping is better suited for languages with duck\ntyping such as Python. Mypy however primarily uses nominal subtyping,\nleaving structural subtyping mostly opt-in (except for built-in protocols\nIterable that always support structural subtyping). Here are some\n- It is easy to generate short and informative error messages when using a nominal type system. This is especially important when using type inference.\n- Python provides built-in support for nominal\nisinstance()tests and they are widely used in programs. Only limited support for structural\nisinstance()is available, and it’s less type safe than nominal type tests.\n- Many programmers are already familiar with static, nominal subtyping and it has been successfully used in languages such as Java, C++ and C#. Fewer languages use structural subtyping.\nHowever, structural subtyping can also be useful. For example, a “public API” may be more flexible if it is typed with protocols. Also, using protocol types removes the necessity to explicitly declare implementations of ABCs. As a rule of thumb, we recommend using nominal classes where possible, and protocols where necessary. For more details about protocol types and structural subtyping see Protocols and structural subtyping and PEP 544.\nI like Python and I have no need for static typing¶\nThe aim of mypy is not to convince everybody to write statically typed Python – static typing is entirely optional, now and in the future. The goal is to give more options for Python programmers, to make Python a more competitive alternative to other statically typed languages in large projects, to improve programmer productivity, and to improve software quality.\nHow are mypy programs different from normal Python?¶\nSince you use a vanilla Python implementation to run mypy programs, mypy programs are also Python programs. The type checker may give warnings for some valid Python code, but the code is still always runnable. Also, some Python features and syntax are still not supported by mypy, but this is gradually improving.\nThe obvious difference is the availability of static type checking. The section Common issues and solutions mentions some modifications to Python code that may be required to make code type check without errors. Also, your code must make attributes explicit.\nMypy supports modular, efficient type checking, and this seems to rule out type checking some language features, such as arbitrary monkey patching of methods.\nHow is mypy different from Cython?¶\nCython is a variant of Python that supports compilation to CPython C modules. It can give major speedups to certain classes of programs compared to CPython, and it provides static typing (though this is different from mypy). Mypy differs in the following aspects, among others:\n- Cython is much more focused on performance than mypy. Mypy is only about static type checking, and increasing performance is not a direct goal.\n- The mypy syntax is arguably simpler and more “Pythonic” (no cdef/cpdef, etc.) for statically typed code.\n- The mypy syntax is compatible with Python. Mypy programs are normal Python programs that can be run using any Python implementation. Cython has many incompatible extensions to Python syntax, and Cython programs generally cannot be run without first compiling them to CPython extension modules via C. Cython also has a pure Python mode, but it seems to support only a subset of Cython functionality, and the syntax is quite verbose.\n- Mypy has a different set of type system features. For example, mypy has genericity (parametric polymorphism), function types and bidirectional type inference, which are not supported by Cython. (Cython has fused types that are different but related to mypy generics. Mypy also has a similar feature as an extension of generics.)\n- The mypy type checker knows about the static types of many Python stdlib modules and can effectively type check code that uses them.\n- Cython supports accessing C functions directly and many features are defined in terms of translating them to C or C++. Mypy just uses Python semantics, and mypy does not deal with accessing C library functionality.\nMypy is a cool project. Can I help?¶\nAny help is much appreciated! Contact the developers if you would like to contribute. Any help related to development, design, publicity, documentation, testing, web site maintenance, financing, etc. can be helpful. You can learn a lot by contributing, and anybody can help, even beginners! However, some knowledge of compilers and/or type systems is essential if you want to work on mypy internals."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:0e25f7ec-29d2-41ef-b806-ccce1ac2c654>","<urn:uuid:26216efc-796a-49a5-9855-b9e9f4713a15>"],"error":null}
{"question":"What role do awards and recognition play in promoting both literary excellence and environmental conservation in South Africa and the Amazon?","answer":"In South Africa, awards have played a significant role in recognizing literary excellence, as demonstrated by Antjie Krog's numerous accolades including the Hiroshima Foundation for Peace and Culture award, the Eugene Marais prize, and the Hertzog prize. In contrast, in the Amazon region, recognition has focused on environmental conservation, with research showing that Indigenous Territories have been highly effective at forest preservation, maintaining deforestation rates 49% to 88% below those of unprotected areas, though indigenous communities are disappointed that initiatives like REDD+ have not provided adequate rewards for their conservation efforts.","context":["Antjie Krog Bio\nAntjie Krog was born on 23 October 1952 on a farm in the Freestate. She completed her BA degree with Afrikaans (cum laude), Philosophy (cum laude) and English at the University of the Orange Freestate, a Masters degree in Afrikaans at the University of Pretoria and a Teachers diploma (cum laude) at the University of South Africa.\nKrog published nine volumes of poetry, two volumes of verse for children, a short novel published by Heinemann and a book , Country of my Skull, on the South African Truth and Reconciliation Commission published by Random House. Her first play has been performed in South Africa recently dealing with a black woman and a white woman trying to come to terms with their past and future.\nKrog was awarded the following awards:\n*Eugene Marais prize for the most promising young writer (1973)\n*Dutch/Flemish prize Reina Prinsen-Geerligs prize for most promising young writer (1976)\n*Rapport prize for best literary work in a particular year (1987)\n*Hertzog prize for the best poetry volume over three years(1990)\n*Pringle Award for excellence in journalism for reporting on the Truth Commission (1996)\n*Foreign Correspondent award for outstanding journalism (1996)\n*Allan Paton award for best South African non-fiction work (1999)\n*Booksellers Award for the book they liked to sell most (1999)\n* Honorary Mention for the Noma Award for books from Africa (1999)\n* Award from the Hiroshima Foundation for Peace and Culture for the year 2000\n* Olive Schreiner 2000 award for prose\n* FNB Award for best poetry volume for the year 2000\nKrog delivered the keynote speech at the Zimbabwe Book Fair in 1998 and the Conference on Women and Violence organised by the World Bank in Washington 1998. She gave lectures on aspects of the Truth and Reconciliation Commission at the University of London, the University of Glasgow, the Universities in Essen and Dortmund in Germany, the University of Utrecht and at NIZA (Netherlandsch Instituut voor Zuider Afrika) in Holland, as well as during a South African week in Antwerp, Belgium. She gave a series of lectures on the concept of Justice within the Truth Commission ambit at the Universities of Bishops, Concordia, McGill, Carleton and Toronto in Canada, as well as the New York University and Bard College in the UN. She appears as frequent guest on current affairs programmes of the BBC, of Hilversum in the Netherlands, Belgium, Australia, Nieu Zealand and America. She has been invited three times as poet to participate in Poetry International at Rotterdam, Nacht der Poezie in The Hague and the Berlin Literatur festival. Was resident at the Foundation Royaumont for Poesie and Traduction where several of her poems had been translated into French. Krog formed part of the South African writers invited to Aix-en-Provence for the Cite de Livre in 1997 and was part of the La Caravane de la Poesie in 1999 - seven poets from Africa who travelled the ancient slave route from Goree back to Tombouctou. She also lead the English session at a Conference on Writing as a duty of Memory held in Rwanda. She is a Director of the Institute of Justice and Reconciliation.\nKrog's works have been translated into English, Dutch, Italian, French, Spanish, Swedish and Serbian. Her book Country of my Skull is being widely prescribed at Universities in America and Europe as part of the curriculum dealing with writing about the past. She was recently asked to translated the autobiography of Nelson Mandela, Long Walk to Freedom into Afrikaans.\nShe is married to architect John Samuel and has four children.\nHuman and Rousseau Publishers:\nDogter van Jefta (1970)\nJanuarie Suite (1972)\nBeminde Antarktika (1974)\nOtter in Bronslaai (1981)\nLady Anne (Taurus:1989)\nGedigte 1989-1995 (Hond: 1995)\nRelaas van 'n Moord (1995) Human and Rousseau\nKleur kom nooit alleen nie (Kwela 2000)\nMet woorde soos met kerse (Kwela 2002)\nCountry of my Skull (1998) Random House\nDown to my Last Skin (2000)\nPoetry for Young Children:\nMankepank en ander Monsters (1989) Human and Rousseau\nVoëls van anderster vere (1992) Buchu Books\nAccount of a Murder, translated by Karen Press (1997)\nLang Pad na Vryheid (translation of Long walk to Freedom by Nelson Mandela\nDomein van Glas (translation of Mondvol Glas by Henk van Woerden from\nDutch into Afrikaans)\nroad trips reviews politics renaissances credits/bios submissions links archives e-mail","do you know our newsletter? It’ll keep you briefed on what we publish. Please register, and you will get it every month.\nThanks and best wishes,\nthe editorial team\nIndigenous peoples are key stakeholders\n– by Carmen Josse\nPink dolphins live in the Amazon.\nFor millennia, the indigenous peoples of the Amazon have de facto been the guardians of large tropical forest areas. Defined according to biogeographic criteria, the Amazon region has a size of almost 7 million square kilometres. This is the greatest forest area remaining on earth. More than a third (37 %) of it belongs to more than 3,344 formally acknowledged Indigenous Territories. They are home to 375 different ethnic groups.\nRAISG is a network of civil-society organisations from several Latin American countries. The abbreviation stands for “Amazonian Socio-environmental Georeferenced Information Network” (Red Amazónica de Información Socioambiental Georreferenciada). It uses every available method, including high-tech options, to document the socio-environmental state of the Amazon basin.\nRAISG research shows that, until 2015, only eight percent of Amazonian deforestation occurred in the forests inhabited by indigenous peoples. By contrast, 88 % of all deforestation happened in the less than 50 % of the Amazon area that is neither indigenous territory nor protected area. This pattern was consistent across all countries of the region.\nIn recent years, other studies have provided similar evidence. Conversion rates tend to be much lower where forests are managed by indigenous peoples and local communities (IPLCs). IPLCs therefore help to stem carbon emissions that are related to land-use, land-use change and forestry (LULUCF). Globally, emissions from the LULUCF sector amount to about eight percent of the total. In Amazonian countries, however, the share is much higher, with LULUCF accounting for 24 % to 50 % of national carbon emissions.\nResearchers have found out that indigenous territories indeed serve as deforestation barriers. Moreover, governance regimes make a difference. In Brazil, a study assessed different forest parcels that were under comparable threat of deforestation. The result was that those in Indigenous Territories and other protected areas were less likely to be destroyed. The deforestation pressures actually tended to be strongest in indigenous lands, but the actual deforestation rates were lowest there.\nIt is sometimes argued that many IPLC managed forests are in remote areas where deforestation is less likely. This perception is not accurate. At least it does not reflect the Brazilian experience in the years 2001 to 2013. A recent study showed that deforestation rates in IPLC forests stayed 49 % to 88 % below those of unprotected forest land that is comparable in terms of remoteness and other conditions. Similar patterns were evident in Bolivia and Colombia, but could not be discerned in Ecuador.\nLower rates of deforestation and degradation mean that carbon emissions are kept lower too. Vast amounts of carbon are stored in forest biomass, and it is crucial to keep it there. The Amazon region’s Indigenous Territories make important contributions to reducing countries’ carbon emissions.\nThe Indigenous Territories only account for about one third of the total forest area, but they store nearly one third of the region’s aboveground carbon. That makes them relevant for the success of the Paris Agreement on climate change. In its context, the countries of the Amazon basin have committed to making nationally determined contributions (NDCs) to mitigation. They would be unable to fulfil them if the carbon sinks that IPLCs manage and protect were to experience similar deforestation rates as unprotected areas do. That would be a disaster in other regards as well. The regional climate would change with considerable impacts on the continent’s rainfall patterns. Desertification may get worse, and biodiversity would definitely suffer dramatically (see article by Stephan Opitz in the Focus section of D+C/E+Z 2019/01).\nHistorically, the livelihoods of indigenous Amazonian peoples have depended directly on the forest. Its resources served all vital purposes, including food, shelter, water, fibre, fuel and medicines. Accordingly, the cultures of the many different ethnic groups are inextricably linked to the local environments where they live. The territory defines their identity. Their cosmology is based on relationships their ancestors forged with the forces of nature. That understanding was passed down from generation to generation. In the process, the traditional knowledge evolved that sustained communities for millennia, both in material and spiritual terms.\nToday, however, this balance is at risk. Western culture is encroaching on the Amazon region. Its influence on IPLCs and their territories is growing. RAISG data shows that, in 2018, 16,900 kilometres of roads cut through them. Moreover, concessions for mining and oil drilling have either been granted already or are likely to be granted soon for 470,000 square kilometres of IPLC forest. Unfortunately, governments are prone to grant such concessions regardless of an area’s legal status, so other protected areas are affected too.\nIndigenous leaders are aware of the importance of the forests. They express their communities’ concerns, demanding appropriate national policies and safeguards. Moreover, they are disappointed in REDD+. The acronym stands for “reducing emissions from deforestation and forest degradation and enhancing carbon sinks in developing countries”. It is an initiative taken at the UN climate summit in 2005. The idea was that forest-rich countries would get rewards for forest protection, provided that the results were measurable. REDD+ proved less effective than hoped. Implementation is difficult for several reasons. One problem to be addressed is that the local communities need to be rewarded too.\nIn 2011, indigenous groups from the Amazon region joined forces and proposed an alternative to REDD+. It is called Amazon Indigenous REDD+ (RIA for the Spanish translation). RIA was conceived as a strategy to contribute to the mitigation of – and adaptation to – climate change, for instance by building resilience through the conservation and holistic management of their territories. RIA emphasises traditional knowledge because it appreciates the value of standing forests and the ecosystem services they deliver. At the same time, the approach is supposed to promote the welfare, self-determination and future welfare of IPLCs.\nRecognition of collective land rights is an essential part of the RIA proposal, and so is the demand for the enactment of national development policies that are consistent with countries’ commitments to climate protection. Tangible steps must be taken towards better control and decisive reduction of deforestation and forest degradation. The drivers of environmental harm include the agroindustry, grazing, timber, mining etcetera. Large-scale infrastructure for hydropower and transportation matter too. These issues must be tackled.\nThe sad truth is that national governments are not really responding to this urgent need. Jair Bolsonaro, Brazil’s new president, has expressed his hostility to the very idea of environmental protection (for more on Brazil’s crisis of democracy, read Carlos Albuquerque’s essay in the Tribune section of D+C/E+Z e-Paper 2019/02). His disrespect for the rights of minorities and, indeed, human rights are worrisome too. Latin America certainly does not need any further empowerment of the businesses that cause deforestation. Letting them do will only lead to disaster.\nOn the upside, the bearing of indigenous peoples from the Amazon and other world regions on international negotiations has been growing. For example, the Local Communities and Indigenous Peoples Platform will serve as bridge that links the UN Framework Convention on Climate Change (UNFCCC) to local communities and their traditional knowledge. The Platform will promote the exchange of experiences and sharing of best practices (see article by Fatima Arkin in the Focus section of D+C/E+Z e-Paper 2019/02).\nScientists point out that reaching the Paris Agreement’s temperature goals will only be possible if forest-based strategies are adopted. Such approaches are costeffective ways to prevent harm. Afforestation, eco-friendly agriculture and sustainable forest management are needed. Measures must be scaled up and funded adequately. Given the vital role of Amazonian IPLCs and their current poverty, they must be involved in decision-making and should benefit from relevant investments.\nCarmen Josse is a researcher who works for the Fundación EcoCiencia in Ecuador. This civil-society think tank is a member of the international non-governmental network RAISG (Red Amazónica de Información Socioambiental Georreferenciada – Amazonian Socio-environmental Georeferenced Information Network)."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:c243513f-e551-41f2-b32b-ef47c6627de9>","<urn:uuid:b83ab18a-5c4b-4913-b8c8-0cfd5c672ca9>"],"error":null}
{"question":"What was unique about the six-sided plates found at Fort Walton archaeological sites?","answer":"Six-sided plates were unique to the Fort Walton culture. More than 350 bowls have been found at five major Fort Walton Sites in the Florida panhandle, with over 50 being six-sided plates. They may have been used as salt drying pans, ceremonial passing plates, or as representations of the tribal community house.","context":["The Fort Walton Culture was named by archaeologist Gordon Willey, based on his work at the Fort Walton Mound site near the Indian Temple Museum in the 1930s. Archaeologists have now come to believe the Fort Walton site was actually built and used by people of the contemporaneous Pensacola Culture. The peoples of the Fort Walton Culture used mostly sand, grit, grog, or combinations of these materials as tempering agents in their pottery, whereas the Pensacola Culture peoples used the more typical Mississippian Culture shell tempering for their pottery.\nFrom 1,000 to 1,200 CE, Weeden Island Culture people adopted maize agriculture, the building of platform mounds for ceremonial, political and religious purposes, and the making a new variety of ceramics. These cultural changes may have been influenced by contact with the Mississippian Culture centers to the north and west. This was the beginning of the Fort Walton Culture (1200 - 1500 CE). Fort Walton sites are similar to other Mississippian sites, with the exception of those in the Tallahassee Hills area, which because of the local geography, are located around lakes and swamps instead of along rivers. Settlement types include single family homesteads, multi family hamlets, small single-mound centers, and large multi-mound centers. The hierarchical settlement patterns suggests the area may have had one or more paramount chiefdoms.\nBy the Late Fort Walton period, increased contact with peoples from central Georgia saw another change in styles of decoration and manufacture of ceramics. This new phase is known as the Leon-Jefferson Culture. This period sees the collapse of the chiefdoms as aboriginal populations declined following contact with European explorers and colonizers. The Fort Walton and later Leon-Jefferson peoples are the direct ancestors of the Apalachee peoples, a tribe still in existence today.\nListed in the Florida Master Site File as Fort Walton Mound (8OK6), and also called \"Indian Temple Mound\", this archaeological site is located in present-day Fort Walton Beach, Florida. The large platform mound was built between 800-1400 CE by the Pensacola Culture, a localized form of the better known, Mississippian Period Culture. Because of its significance, the mound was designated a National Historic Landmark in 1964. This is one of three surviving mound complexes in the panhandle, the others being Letchworth-Love Mounds and Lake Jackson Mounds, both are Florida State Parks.\nDespite the hundreds of years of erosion, the massive mound is still 12 feet high and 223 feet wide at the base. An estimated 200,000 basket loads of earth were used to create this earthen structure. 8OK6 is an example of a complex mound-building culture, engineered by a hierarchical society whose leaders planned and organized the labor of many workers for such construction. The mound likely served ceremonial, political and religious purposes. At the center of the village and its supporting agricultural lands, the mound also served as the platform for the temple and residence of the chief. Successive leaders were buried in the mound and additional layers were added over time. Archaeological evidence suggests that several buildings once stood on top of the mound, perhaps at different times throughout its use. These buildings were likely wooden plank, or wattle and daub construction, common among Southeastern Native American groups.\nAfter the Fort Walton Culture abandoned it in the mid to late 1500s, the mound lay dormant. During the Civil War, in 1861, Confederate soldiers of the Walton Guard encamped on and around the mound to guard the waterway known as “The Narrows”. The soldiers displayed \"curiosities\" taken from the mound in a small museum tent. Unfortunately, the tent was burned down by enemy troops, destroying the artifacts. In 1883 the mound was examined by the Smithsonian Institution and has since been excavated nine times. Today's museum houses thousands of artifacts of stone, bone, clay and shell, as well as one of the finest collections of prehistoric ceramics in the Southeastern United States. A reproduction structure sits atop the mound which is accessible via a paved walkway and wooden boardwalk.\nHeritage Park & Cultural Center includes the Indian Temple Mound Museum, Camp Walton Schoolhouse Museum, Garnier Post Office Museum, Fort Walton Temple Mound, and the Civil War Exhibit Building. It is an educational and cultural institution of long standing traditions, with a mission to preserve, interpret and present the prehistory and history of the Fort Walton Beach community and the Northwest Florida area from 14,000 B.C. through the 1950’s. Admission for all museums in the complex will be taken at the Indian Temple Mound Museum building. All other museums are located within a one minute walk around the base of the mound.\nIn 1962 the Indian Temple Mound Museum opened as the first municipally owned and operated museum in the State of Florida. The current museum building opened to the public in 1972 and is located on Highway 98 in the heart of historic downtown Fort Walton Beach, Florida. The museum houses interpretative exhibits depicting more than 12,000 years of Native American occupation. Thousands of artifacts of stone, bone, clay and shell are here, as well as one of the finest collections of prehistoric ceramics in the Southeastern United States. Exhibits also include artifacts from the European Explorers, local pirates, and early settlers.\nA Museum Store offers visitors unique objects for purchase including museum quality replicas of artifacts on display. Items are of good quality and reflect the craft, culture and history of Native Americans and the museum industry. Many of these items are purchased from North, South and Central America. Items for sale include: Pottery, Beadwork, Shell Carvings, Jewelry, Baskets, Gourd Work, T-Shirts, Finely Woven Textiles, Heartwood Creations Secret Boxes, DVDs and CDs, Books, Handcrafted Native American Art, Jewelry, Children’s Toys, and much more. Every purchase supports the museum and its educational programs.\nShell tempered pottery vessels of the Mississippian household were much more efficient containers for cooking, particularly the increasing amounts of maize being grown, and thus sustaining larger and healthier populations. Around 800 CE, shell tempered pottery spread widely and rapidly from the middle Mississippi River valley to become an integral part of the expanding Mississippian culture.\nCERAMICS AND POTTERY\nThe ceramic tradition of the Mississippian Culture, (800 to 1600 CE) is often characterized by the adoption and use of riverine (or more rarely marine) shell-tempering agents in the clay paste. Shell tempering is one of the hallmarks of Mississippian cultural practices. Designs probably had meanings related to events or beliefs. Burial vessels had depictions of skeletons, which over the years became stylized bones. Each culture had their own designs, which identify the tribe and the region they came from. Local differences in materials, techniques, forms, and designs are some of the major ways archaeologists understand lifeways, religious practices, trade, and interaction among Mississippian peoples like those of the Fort Walton Culture.\nMany Mississippian ceramics are decorated by incising or engraving. Implements such as sticks, reeds, or bone fragments, were dragged through wet clay to incise it, or they were scratched into the surface of the dried but as yet unfired pieces to engrave. Sharpened reeds or fingernails were also used to punch small marks. Ornate designs and motifs are common decorative elements, which archaeologists use to track the spread of influences from one culture onto another culture. Many of the designs have symbolic meanings, usually associated with aspects of the Southeastern Ceremonial Complex.\nIndian Temple Mound Museum features one of the largest collections of southeastern ancient ceramics in the United States.\nCLAY TETRAPOD VESSEL (tetra=four pod=feet)\nThis vessel is one of the oldest found in Northwest Florida. It has been dated to the Deptford Culture, approximately 1170 BCE. The rim decoration was impressed into the clay using a knotted cord of fabric. Some Mississippian Culture pottery was decorated with textile imprints on them. Vegetal cordage or netting was impressed either over the entire external surface of a vessel, or just around the top rim area. Some archaeologists theorize that the textiles used for the imprints were older fabrics that were past their use as garments. Corncobs were also used to create texture on pots.\nAlthough the vast majority of Mississippian pottery was produced for daily utilitarian uses, the finer varieties seem to have been made specifically for trade or for ritual use. Chronologies based on pottery have been essential for dating Mississippian cultures. Studies of southeastern pottery has provided one of the best insights into the culture. Because pottery is durable and often survives long after artifacts made from less durable materials have decayed past recognition, ceramics and stone tools are often the only objects that survive in great enough quantities to establish such insights. Combined with other evidence, the study of pottery artifacts is helpful in the development of theories on organisation, economic conditions and cultural development. This has allowed inferences to be drawn about the daily life, religion, social relationships, and trade with other groups.\nWARE HUMAN EFFIGY VESSEL\nIn 1971, the Ware family found pieces of a clay vessel at a small mound, possibly a domiciliary or a house mound, about four miles west of The Indian Temple Mound Museum. The pieces were made of light brown to tan colored clay, coiled into a rough shape with features molded on the outside. When the clay fragments were carefully placed together, an Effigy (made to look like) of a human male was formed. Although it is unknown, the figure was probably made to resemble a specific individual. Like a portrait, this figure shows details of clothing and decoration. The hair is worn pulled back and a decorative band resembling a crown surrounds the head. The eyes are closed, suggesting a man already dead. The ears contain a set of decorative earrings that dangle. The body is naked, but bracelets can be seen on the wrists and a lip ornament is worn in the pierced bottom lip.\nThis vessel may have been shattered atop a burial mound as part of a ritual conducted 1300 years ago. Similar vessels are known to have served as status symbols, family heirlooms, burial urns, or statements of political and religious control. The Ware Human Effigy Vessel dates back to the Weeden Island Culture (600-900 CE) known for beautifully crafted ceramic works; however items such as this vessel are very rare. Effigy pots were a mainstay of many Mississippian peoples, although they come in many different varieties. Some come in anthropomorphic shapes, some zoomorphic shapes and others in the shape of mythological creatures associated with the Southeastern Ceremonial Complex.\nTHE BUCK-LONG EFFIGY URN\nThis artifact was found in 1961 at the Fort Walton Mound and reconstructed from over 100 shattered fragments. In 1966, the face and topknot were located down the slope on the mound, indicating that it was purposefully shattered on the slope of the mound. This vessel resembles a human with four legs. The two forward legs are clearly human while the two following legs are stumps, presumably reflecting a stool. It is known that the burial practices of the Woodland Time Period sometimes took the form of cremations, especially for important persons. Evidence suggests that the ashes of an important leader may have been retained in this effigy urn.\nThe vessel is 15 inches tall, made of red paste clay decorated with incised designs. A red and white cloak covers the body and attaches at the human wrists with white bands. The ears are pierced and the face-blackened to resemble a mask, which may represent a masked and costumed figure from a ritual event. The use of this vessel is difficult to determine. Such exotic wares are thought to have been status symbols, family heirlooms, or statements of political and religious control. They might have been cult objects or guardian figures.\nTwo methods were used to create this vessel. The legs were shaped from slabs and are hollow. The coil method was used to make the face and body. The firing of the vessel was at low heat resulting in a brittle finish. It has been called the \"finest ceramic vessel in the Southeast\" and only a few vessels with similar paste and shape have been found. The styling of the hands and general appearance suggest cultural contact with Central America, but in actuality this artifact is most closely related to the Mississippian Cultures.\nSIX SIDED PLATES OR SALT PANS\nSix sided plates are unique to the Fort Walton culture. In the five major Fort Walton Sites in the Florida panhandle, more than 350 bowls have been found. Over 50 of these are six sided plates. They may have been used as salt drying pans evaporating pans for drying salt, or a passing plate for ceremonies or a representation of the tribal community house. Large salt pans were common in Mississippian regions, but are usually ovular or even rectangular. These could hold from 10 to 26 liters of liquid. A heavy slip made them more waterproof. They were most likely formed from a mold, possibly a basket. They were lined with grass or textiles to keep from sticking to each other or the mold before firing.\nGlobular containers, resembling gourds, with a rounded base and a smaller \"head\", may have been used to carry and store liquids. One side of the head was shaped like an animal or human face, while the other side was a black, hollow opening. They were slipped on their exterior surface to make them smoother and water-resistant. Another theory is that these were used to store seed grain, and unfired clay plugs sealed the opening. Owls and opossums are often featured on hooded vessels.\nMaize cob fragments were found in the middens near Fort Walton. By the fourteenth century the Fort Walton site housed a large agricultural village. The land was fertile and rich, as it lay in a floodplain, however, fishing and seafood utilization continued to play a major role in the economy.\nYAUPON HOLLY (Ilex vomitoria) Indians throughout prehistoric Florida made a drink by boiling the leaves of the Yaupon Holly. Among the purposes of consuming the \"black drink\", was to empty the contents of the stomach in preparation for the consumption of the green corn. The principal active ingredient of Ilex vomitoria is caffeine. Vomiting was not caused by the drink, but is connected to the ceremonial expelling, and was a learned behavior. Large drinking vessels made from shells, often with incising, have been found throughout the state. Special pottery cups, some in effigy forms, may also be associated with the \"black drink\" and \"green corn\" ceremonies.\nHICKORY (genus Carya) Hickory nuts were found in the Fort Walton Mound. They would have been gathered from the ground in the fall. The nut of the hickory tree has nutritious meat, and the flexible wood of the hickory tree was favored for the making of bows. There are nine varieties of hickory found in North America, with almost half available throughout Florida. Hickory nuts were a staple food for prehistoric Floridians.\nPLAN YOUR VISIT\n139 Miracle Strip Parkway SE\nFort Walton Beach, Florida 32548\nPHONE: (850) 833-9595\nHOURS: Indian Temple Mound Museum\nMonday-Friday: 12:00pm -4:30pm\npage information credit: City of Fort Walton Beach Heritage Park & Cultural Center, Indian Temple Mound Museum, Wikipedia, Dr. Rochelle A. Marrinan, Dr. Nancy Marie White, Gordon Willey, and previous Trail web content\nphotos from the sources listed above, as well as publicly posted online sites with thanks to the contributors"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:c48026ee-86fe-4b5d-8c9c-355f41b59479>"],"error":null}
{"question":"What are the key differences in how these two compression systems handle initial data and codebooks for decompression?","answer":"The first patent system makes the initial data for private compression algorithms available by encrypting it and encapsulating it in data frames, typically no later than the first frame using that algorithm. The initial data can either be distributed with the frames or be pre-available at the recipient. In contrast, the second patent's system maintains a dynamic codebook that updates based on current probability density function estimates, where only model parameters need to be transmitted for updates. Rather than sending complete codebooks, it efficiently updates the decoder's codebook using these parameters, with an option to send just differential parameters that have significantly changed since the last update.","context":["US 7492902 B2\nAn apparatus for compressing media content is disclosed. The apparatus divides the media content into at least three predetermined portions, compresses each of the at least three portions using one of at least three different compression algorithms and makes the at least three compressed predetermined portions publicly available. Making the portions publicly available includes, for example, transmitting the portions over a computer network such as the Internet.\n1. A system for compressing media content, the system comprising:\na module configured to divide the media content into at least three predetermined portions;\na module configured to compress each of the at least three portions using one of at least three different compression algorithms; and\na module configured to make the at least three compressed predetermined portions publicly available.\n2. The system of\na module configured to group each of the at least three compressed portions of the media content into at least three portions of a data frame.\n3. The system of\n4. The system of\n5. The system of\n6. The system of\n7. The system of\n8. The system of\na module configured to encrypt the associated initial data of the at least one private data-based compression algorithm; and\na module configured to make the encrypted associated initial data publicly available.\n9. The apparatus of\nThe present application is a continuation of U.S. patent application Ser. No. 09/863,286 filed May 24, 2001, now U.S. Pat. No. 6,760,443B2,which is a continuation of U.S. patent application Ser. No. 08/888,014, filed Jul. 3, 1997, now U.S. Patent No. 6,266,419B1. The present application is related to an application U.S. patent application Ser. No. 08/888,009, filed Jul. 3, 1997, now U.S. Pat. No. 6,111,844A, entitled “Quality Degradation Through Compression/Decompression” by Jack B. Lacy and James H. Snyder. Each of these referenced applications is incorporated herein by reference.\n1. Field of the Invention\nThe present invention relates to the field of computing. More particularly, the present invention relates to a method for protecting encoded media content for network distribution.\n2. Description of the Related Art\nRecent technological advances involving digital data compression, network bandwidth improvement and mass storage have made networked distribution of media content more feasible. That is, media content, such as digitized music, can be conveniently distributed over the Internet. To protect the intellectual property rights associated with a particular piece of media content, it is desirable to obscure the media content to prevent pirating of the content.\nConsequently, what is needed is a way for compressing media content for convenient network distribution, while also securing the compressed media content against unauthorized use.\nThe present invention provides a method for compressing media content for convenient public distribution, such as over a computer network, which also securing the media content for controlling distribution of the media content and for preventing unauthorized user of the media content. One of skill in the art will recognize the basic hardware components in a computer network such as a computer server having a CPU, data bus, memory, display, networking capability and input/output circuitry, that processes data for distribution over the network. The advantages of the present invention are provided by a system and method of compressing media content in which a first predetermined portion of a media content is compressed using a first data-based compression algorithm and inserted into a first portion of a data frame. A second predetermined portion of the media content is compressed using a second data-based compression algorithm and is inserted into a second portion of the data frame. The second predetermined portion of the media content is different from the first predetermined portion of the media content, and the second data-based compression algorithm is different from the first data-based compression algorithm. Preferably, at least one of the first and second data-based compression algorithms is a private data-based compression algorithm. The first and second portions of the data frame are separated by a predetermined header code, or can be separated by relative positions of the first and second predetermined portions of compressed media content within the data frame.\nThe present invention also provides a method for inserting a data stream not associated with the media content into a compressed media content bit stream. The inserted data stream is carried by at least one symbol in at least one initial data set associated with the DBCA. A preferential implementation uses designated symbols in one or more Huffman codebooks for embedding a watermark in the compressed bit stream. The value of the watermark bits recovered from the bit stream depend upon either the values associated with the symbols or alternatively the position of the symbol in the compressed bit stream.\nAccording to the invention, a plurality of data frames are generated and are made available for distribution, for example, by transmission over a computer network, such as the Internet. Alternatively, the data frames can be made publicly available for storage in a memory device, such as a CD ROM.\nA plurality of predetermined portions of the media content can be compressed using data-based compression algorithms and grouped into a respectively different portion of the data frame. Each respective predetermined portion of the media content is different from the first and the second predetermined portions of the media content. Similarly, the data-based compression algorithm used to compress a respective portion of the media content is different from the first and the second data-based compression algorithms. Preferably, at least one of the data-based compression algorithms is a private data-based compression algorithm.\nInitial data associated with each private data-based compression algorithm is encrypted and made publicly available when the data frames are made available. The encrypted initial data is grouped into a data envelope within a data frame that is preferably available no later than a first data frame containing media content compressed using the private data-based compression algorithm with which the encrypted initial data is associated, but can be made available during a later data frame. Examples of initial data associated with at least one private data-based compression algorithm include a Huffman code-book and/or a vector quantization code-book.\nAccording to the invention, the media content can include audio content, such as music and/or speech, images, video content, graphics and/or textual content.\nThe present invention is illustrated by way of example and not limitation in the accompanying figures in which like reference numerals indicate similar elements and in which:\nThe present invention provides a method for compressing media content for convenient distribution, such as over a computer network, while also securing the media content for controlling distribution of the media content and for preventing pirating of the media content. As is know in the art, a computer server or computing device is used to compress and make available the media content for distribution over the computer network. A compression algorithm, as used herein, is an algorithm that accepts an in put data stream and produces a corresponding output data stream having substantially fewer bits. A data-based compression algorithm (DBCA) is an algorithm that is a subset of compression algorithms in general. The action of a DBCA, together with associated data, depends on a number of initial data values that have been determined before the compression operation begins (that is, without any knowledge of the particular input data sequence to be compressed). The initial data values represent parametric values or may be used as lookup tables (i.e., as code-books) by the algorithm. Typical DBCAs are noiseless compression (e.g., Huffman) algorithms and vector quantization (VQ) algorithms. The initial data values may be static, i.e., the initial data values do not change, or dynamic, i.e., the initial data values adapt to the input data stream during the course of compression. Two DBCAs are different if the initial data values are different, whether the algorithms are different.\nAt step 13, a selected portion of the frequency-domain samples of the media content are compressed in a well-known manner using a publicly available DBCA, such as a DBCA having a public Huffman code-book as initial data. Each binary character code or token of the public DBCA represents at least one different quantized representation of the frequency-domain samples. When the media content is music, the selected portion of the frequency-domain samples that are compressed using the public DBCA corresponds to a selected frequency band of the audio content frequency spectrum, for example, 300 Hz to 3 kHz. In video transform coding, DC coefficients would be encoded with the standard table, while the AC coefficients would be encoded with the custom (private) table. The selected portion of the media content, according to the invention, may be null.\nAt step 14, the remaining frequency-domain samples corresponding to the remainder of the audio content frequency spectrum are similarly compressed in a well-known manner using a private DBCA, that is, a DBCA in which the initial data is not publicly available. Examples of initial data for private DBCA include private Huffman code-books and private VQ code-books. Alternatively, the compression performed in steps 13 and 14 can be done by any well-known greedy-type algorithm that converts data into tokens or character codes, such as a VQ algorithm, as long as at least one of the two compression steps is performed by a private greedy-type algorithm. Of course, the present invention provides that the data compression of each step 13 and 14 can be performed by a private DBCA.\nAt step 15, the tokens for the frequency-domain samples that were compressed using the public DBCA are inserted into a first predetermined portion 31 of a data frame 30, shown in\nAt step 16, the tokens for the frequency-domain samples that were compressed using the private DBCA are inserted into a second portion 32 of data frame 30. According to the invention, second portion 32 can be explicitly or implicitly encapsulated within data frame 30. When second portion 32 is explicitly encapsulated within data frame, a header 33 formed by a predetermined character code or predetermined sequence of character codes containing information relating to the private DBCA, such as escape characters and/or the number of characters contained in second portion 32.\nAt step 17, the data frames are made publicly available, such as available for distribution by transmission in a well-known manner over a computer network, such as the Internet, or by storage in a user-owned storage device, such as a CD-ROM, at a point-of-sale device. In one embodiment of the present invention, the initial information associated with each private DBCA that is used is encrypted in a well-known manner using a secure encryption algorithm and is encapsulated in the data frames preferably no later than the first data frame containing media content compressed using the private DBCA with which the encrypted initial data is associated, but can be encapsulated during a later data frame. In another embodiment, the initial data for the public DBCA is made available with the encrypted initial data of the private DBCA. In yet another alternative embodiment, both the initial data for the public and the private DBCAs are available at the recipient of publicly available data frames 30 and are not distributed when the data frames 30 are distributed. Of course, for this embodiment, the encrypted initial data of the private DBCA is secure and is not accessible to unauthorized individuals. At step 18, the data frames and any initial data are received by the intended recipient.\nAt step 19, the tokens corresponding to the public DBCA in the first portion 31 of each data frame are decompressed using the public DBCA. At step 20, the character codes corresponding to the private DBCA in the second portion 32 of each data frame are decompressed using the private DBCA. When the first portion 31 of each data frame has been compressed by a private DBCA, portion 31 of each data frame is decompressed accordingly. When encrypted initial information is encapsulated in the data frames, the initial information is decrypted prior to decompression using the private DBCA. At step 21, the frequency-domain samples resulting from the decompression steps 19 and 20 are reassembled to form frequency-domain samples of the frequency spectrum of the media signal represented by each data frame. At step 22, the frequency-domain samples are transformed to time-domain samples using well-known inverse Fourier transform techniques. At step 23, the time-domain samples are converted to the media content using well-known digital-to-analog techniques.\nWhen the initial data for the private DBCA is not known at step 20, steps 21-23 operate on only the portion of the media content that was contained in the first portion 31 of the data frames. In this way, a limited version of the media content is generated that may entice the recipient to purchase the entire media content because the fidelity of the media content is not satisfying.\nBlock 47 contains a data sequence as a string of bits that preferably represents watermark data, but can represent any information that is not associated with the media content. Block 48 contains control logic for selecting a watermark data site and sequencing watermark data bits into custom DBCA 44, which emits symbols to the bitstream formatter 45. According to the invention, private DBCA 44 can contain either a single data set (e.g., a single Huffman or VQ codebook) or a plurality of data sets (e.g., multiple Huffman or VQ codebooks).\nControl and timing 48 can be implemented in many ways. For example, if the bit rate coming out of bit stream formatter 45 is N bits/sec, and M watermark bits per second are desired to be inserted, and 1 bit per watermark site is inserted (without loss of generality), then timing and control 48 must insert a watermark bit on average every N/M bits coming out of bit stream formatter 45. (Hence, the path connecting the output of bitstream formatter 45 to control and timing 48.) In this case, timing and control 48 can be implemented as a reloadable downcounter that indicates an insertion when the downcounter reloads. In a more secure implementation, randomness can be incorporated into control and timing 48 using a pseudo-random number generator that causes an insertion on average every NIM bits.\nMore generally, private DBCA 44 may have a plurality of distinct Huffman codes devoted to watermarking, for example, k is equal to 2K characters. Then, up to K watermark bits can be inserted per special Huffman symbol. For purposes of security, more than one Huffman symbol devoted to the same bit sequence might be chosen. In the case of K watermark bits per insertion, control and timing 48 causes an insertion on average every (N/M)*K bits. Alternatively, custom DBCA 44 may use one or more otherwise unused codebook indices for watermark insertion. For example, when control and timing 48 indicates an insertion, bitstream formatter 45 may put a watermark index and some predetermined number of bits into the bitstream. In this case, the watermark index appears to indicate an unused codebook. Similarly, the position of the watermark index may be used to indicate the value of the watermark data, for example, if the index occurs in an odd-numbered section in the bitstream, a “1” bit would be indicated, whereas appearance of the index in an even-numbered section indicates a “0” bit.\nWhile the present invention has been described in connection with media having an audio content, such as music and/or speech, it will be appreciated and understood that the present invention is applicable to media having audio and/or image and/or video and/or graph and/or textual content, and that modifications may be made without departing from the true spirit and scope of the invention.","|Publication number||US7236640 B2|\n|Application number||US 10/344,586|\n|Publication date||Jun 26, 2007|\n|Filing date||Aug 17, 2001|\n|Priority date||Aug 18, 2000|\n|Also published as||US7391918, US20040049384, US20070225974, WO2002017538A2, WO2002017538A3|\n|Publication number||10344586, 344586, PCT/2001/25838, PCT/US/1/025838, PCT/US/1/25838, PCT/US/2001/025838, PCT/US/2001/25838, PCT/US1/025838, PCT/US1/25838, PCT/US1025838, PCT/US125838, PCT/US2001/025838, PCT/US2001/25838, PCT/US2001025838, PCT/US200125838, US 7236640 B2, US 7236640B2, US-B2-7236640, US7236640 B2, US7236640B2|\n|Inventors||Anand D. Subramaniam, Bhaskar D. Rao|\n|Original Assignee||The Regents Of The University Of California|\n|Export Citation||BiBTeX, EndNote, RefMan|\n|Patent Citations (5), Non-Patent Citations (18), Referenced by (5), Classifications (26), Legal Events (4)|\n|External Links: USPTO, USPTO Assignment, Espacenet|\nThis application claims convention priority under from prior U.S. provisional application Ser. No. 60/226,137, filed Aug. 18, 2000.\nThe field of the invention is data encoding, transmission, and decoding. The invention is applicable to data source encoding, i.e., compression.\nData source encoding reduces the amount of bandwidth and resources required for transmission of a particular data source. Significant reductions are achieved by compression, especially in data sets exhibiting patterns. Image data and speech data are two exemplary data types upon which data source encoding is especially useful. Both produce large quantities of data that exhibit patterns rendering possible an efficient compression.\nQuantization schemes used for data source encoding evaluate a data source for rendering an intelligent encoding of the data based upon the statistics of the data source. Conventional data source encoding schemes design a quantizer using a large database of the source known as the training data. The training data is typically selected to encompass all possible statistics of the data source, i.e., the transmission encoded data. The balance in designing a succesful quantizer is a balance between perfomance and complexity. However, when the quantizer is designed to perform reasonably well for all possible source statistics, it will not be optimal for a given realization of a source.\nOther problems are unaddressed by conventional quantization data source encoding schemes. The conventional schemes are not able to adapt with time-varying statistics of a data source. In addition, bandwidth efficient adaptation is generally unfeasable due the enormous memory costs associated because it would be typically necessary to store data from the beginning of transmission to adapt the quantizer to the current statustics of the source. Then, even if the quantizer can be modified to depict current statistics of the source, it would typically be necessary to transmit the entire data encoding codebook to the receiver. This is a prohibitive bandwidth expense. Such conventional schemes do not provide for the possibility of variable rate encoding that holds promise in wireless code division multiple access (CDMA) communication environments.\nMany quantization encoding schemes also have considerable computational and search complexity in the nonadaptive case. The memory and computation costs of vector quantizers grows exponentially with bit rate. Such costs have lead to the employment of sub-optimal quantizers even for sources with large databases to provide sufficient statistical information for optimal quantization.\nThe present invention addresses problems inherent in the conventional quantization encoding schemes. According to the invention, quantization encoding is conducted using the probability density function of the source, enabling fixed, variable and adaptive rate encoding. To achieve adaptive encoding, an update is conducted with a new observation of the data source, preferably with each new observation of the data source. The current probability density function of the source is then estimated to produce codepoints to vector quantize the observation of the data source.\nEncoding of the invention is particularly significant for use with any non-stationary (time-varying) data source. Fixed and variable bit rate encoders are possible with the invention. However, the invention also provides computational savings for encoding of stationary data sources. The invention, using the probability density function of an observation of a data source, efficiently produces codepoints for vector encoding the data source. The computational expense for the encoder does not require a search through the entire set of possible codepoints. The disclosure will focus upon the adaptive capabilities of the encoding of the invention, while artisans will appreciate is broader applicability.\nGenerally, as seen in\nFor the purposes of further detailed discussion of the encoding performed in the transmitter 10, a mathematical expression of the parametric density is convenient. Ωk is an observation of a p-dimensional non-stationary random data source at time instant k. Ωk may be modeled as an iid (independent and identically distributed) realization of a parametric density, i.e.,\nαi are non-negative constants and\nwill be referred to as cluster i and is an individual parameteric density parameterized by Φi. According to the invention, quantization encoding adapts to time-varying probability density function of the source. The current probability density function of the source is estimated using a parametric model. Parameters are obtained with each observation. Accordingly, only the model parameters are necessary to produce a new set of codepoints, which may be considered as an updated codebook.\nIn a specific preferred embodiment of the invention a codebook limited to the set of codepoints determined through an observation or previous observations of a data source is maintained for encoding data observations from a data source. Upon arrival of new data from the data source, a current estimate of probability density function model parameters of the data-source are determined by applying a re-estimation algorithm to a previous estimate of the model parameters and the new data. The codebook is then updated using the model parameters m is the number of clusters. Φ is the parameter set which defines the parametric model. Ωk may be assumed to have been generated by one of the m clusters and the probablity that a given obervation has been generated by cluster i is αi. A density estimation algorithm is used to estimate 14 the parametric model parameters from the current data of the data source.\nOnce density has been estimated, a separate codebook is designed 16 for each of the clusters. The number of bits allocated to a specific cluster i, bi depends upon whther the communciation system is a fixed rate or variable rate system. Efficient bit allocation techniques and transform coding techniques are used to allocate bits to clusters, using an appopriate number of bits to be allocated for a particular cluster according to the particular fixed rate or variable rate system requirements. A given observation Ωk is quantized by identifying an appropriate cluster among the m clusters and quantizing it using the codebook of that cluster. Let btot represent the total number of bits used to quantize the parametric model density. Di(bi) represent the mean square distortion of an optimal bi bit quantizer of cluster i.\nA fixed rate codebook design bit allocation scheme may employ the invention. A bit allocation in the fixed rate case may be decided by minimizing the total average distortion given that the total number of codepoints used for quantizing the parametric model density is fixed. The minimization is given by:\nThe solution to this constrained optimization problem is used as the bit allocation scheme for the fixed rate case. Under reasonable conditions, the solution to the above constrained problem may be easily obtained in closed form.\nData encoding in the fixed rate case-is simple; A given observation is quantized 18 using all the clusters to obtain m prospective candidates. The quantization of the given observation by a particular cluster can be accomplished in an efficient manner, i.e., the number of searches used to locate the nearest codepoint is considerably smaller than the number of searches required for a full search (i.e., searching over all codepoints in the codebook). Then, a codepoint that minimizes relevant distortion is chosen 20 from amongst the m probables. The transmitter 10 sends 22 that codepoint to the receiver.\nA variable rate codebook design is also possible with the invention to achieve variable bit rate allocation. A bit allocation for the variable rate codebook design may be decided by minimizing the total average distortion given that the average rate of the quantizer is fixed, i.e.,\nwhere bq=btot−bc is the total number of bits less the number of bits required to identify a particular cluster (bc). As is the case for the fixed rate scheme, the constrained optimization problem can be solved in closed form under reasonable assumptions. One possible choice for is bc is\nObservations belong to clusters with varying probabilities. Accordingly, Huffman coding, for example, may be used to identify the cluster which can produce bit rate savings. In this case\nEncoding is similar to the fixed rate case. The same general steps are applied with quantizing 18 to obtain m prospective candidates and choosing 20 a codepoint to minimize distortion. The number of bits is determined 24. If the codepoint chosen to minimize distortion belongs to cluster i, then bk=bc+bi bits are used to quantize the given observation. Bit rate savings may be accomplished by removing the temporal correlation of the source by using conventional decorrelation techniques such as linear prediction. Decorrelated output is then quantized as described above. For the purpose of curtailing error propagation, error control-may be performed by loading the quantization error of a particular deccorrelated vector on the next decorrelated vector and then quantizing it.\nIn either the fixed or variable rate case, the arrival of new data creates a density update 26 that results in only model parameters 28 being used to update the codebook. On arrival of new data from the source (current data), the current estimate of the model parameter is determined 30 from a re-estimation algorithm that uses the previous estimate of the model parameters and current data to obtain the current estimate of the model parameters. Since only data since the last update is used, memory costs can be minimal in practice.\nAn exemplary application of the invention is to the vector quantization of speech LPC (Linear Prediction coefficients) parameters. This is a nonlimiting, specific example use. As mentioned above, the invention is applicable in general to the source coding of any non-stationary source, as well as stationary data sources. Speech data is typically broken down into frames of sizes 20–24 millisecondes each. An optimal pth order linear predictor is calculated for each of these speech frames (typically p=10). Line Spectral Frequencies (LSF) are one-to-one transformations of the LPC parameters which result in a set of parameters that can be efficiently quantized (using, for example, a scalar quantizer) while maintaining stability. Speech LSF's are modeled in the example as iid realizations of a multi-variate normal misture density. This particular type of modeling is motivated by the fact that gaussian kernels have a well-recorded history of being effective basis functions for functional approximations. The mixture model parameters are efficently estimated using the Expectation Maximization (EM) algorithm. In experiments, a tenth order predictor was used. This leads to an LSF vector that is ten dimensional. The source probability density is estimated using a mixture density of 15 clusters.\nThe general bit allocation scheme of the invention as discussed with reference to\nVarious additional steps may be performed with the invention, which could be incorporated as part of the general method of\nNormal expectation maximization algorithms sometimes perform inefficiently due to overfitting. In conducting a density estimate to carry out the invention, this problem may be addressed by averaging techniquies to reduce the number of iterations and/or improve accuracy in producing a density estimate. Various suitable techniques may be employed, including averaging using so-called bagging techniques, maximum penalized likelihood and Bayesian estimation. In addition, the invention might use parametric densities that are tuned to a particular application for modelling purposes.\nVarious methods of performing quantization of individual cluster components. One possibility is a look-up table of optimal quantizers for the particular parametric density at different bit rates. Another possibility is to build a large tree structured quantizer on the particular parametric density and cut back rate using a BFOS algorithm. Yet another possibility is to use lattice quantizers.\nAn alternative also exists to further reduce bandwidth requirements for transmission of model parameters with each update. A differential approach could be carried out. Namely, instead of sending the complete set of model parameters for the receiver to update its codebook a differential set of model parameters could be sent. The differential set would only include those parameters which have changed significantly since the last update.\nReceiver/decoder design is straightforward and admits of many possible variations. Any suitable form of look-up or other manner of determining the data vector from a received codepoint index is appropriate and may he used with an encoder/transmitter of the invention.\nArtisans will accordingly appreciate several advantages of quantization encoding of a source in accordance with the invention. The invention is bandwidth efficient since only model parameters, or even a sufficient subset of model parameters (e.g., differential parameters), is sent with each update. The current estimate of the model parameters are representative of the current data, representing an improvement of conventional non-adaptive techniques. Both fixed rate and variable rate encoding are possible.\nWhile various features and embodiments of the invention have thus been described, the invention is not limited thereto. Instead the scope of the invention is to be understood from the appended claims and legal equivalents thereto.\nVarious features of the invention are set forth in the following claims.\n|Cited Patent||Filing date||Publication date||Applicant||Title|\n|US5091945 *||Sep 28, 1989||Feb 25, 1992||At&T Bell Laboratories||Source dependent channel coding with error protection|\n|US5671327 *||Jan 22, 1993||Sep 23, 1997||Kabushiki Kaisha Toshiba||Speech encoding apparatus utilizing stored code data|\n|US5680508 *||May 12, 1993||Oct 21, 1997||Itt Corporation||Enhancement of speech coding in background noise for low-rate speech coder|\n|US6438268 *||Oct 15, 1997||Aug 20, 2002||University Of Strathclyde||Vector quantization codebook generation method|\n|US6807527 *||Feb 17, 1998||Oct 19, 2004||Motorola, Inc.||Method and apparatus for determination of an optimum fixed codebook vector|\n|1||Antonio Ortega, \"Adaptive Scalar Quantization Without Side Information,\" IEEE Transactions on Image Processing, vol. 6, No. 5, May 1997, pp. 665-676.|\n|2||*||Chen et al. (\"Image Sequence Coding Using Adaptive Finite-State Vector Quantization,\" IEEE Trans. Circuits and Systems for Video Technology, vol. 2, No. 1, Mar. 1992, pp. 15-24).|\n|3||Christopher F. Barnes, Syed A. Rizvi, Nasser M. Nasrabadi, \"Advances in Residual Vector Quantization: A Review\", IEEE Transactions on Image Processing, vol. 5, No. 2, Feb. 1996, pp. 226-262.|\n|4||Dae Gwon Jeong, Jerry D. Gibson, \"Uniform and Piecewise Uniform Lattice Vector Quantization for Memoryless Gaussian and Laplacian Sources\", IEEE Transactions on Information Theory, vol. 39, No. 3, May 1993, pp. 786-804.|\n|5||Dirk Ormoneit, Volker Tresp, \"Averaging, Maximum Penalized Likelihood and Bayesian Estimation for Improving Gaussian Mixture Probability Density Estimates\", IEEE Transactions on Neural Networks, vol. 9, No. 4, Jul. 1998, pp. 639-650.|\n|6||*||Duda & Hart, Pattern Classification and Scene Analysis, Wiley, 1973, pp. 31-32 & 44-49.|\n|7||*||Feng et al., \"Dynamic Codebook adaptive Vector Quantization for Image Coding,\" IEEE Trans. Consumer Electronics, vol. 45, Iss. 2, May 1999, pp. 327-332.|\n|8||*||Fowler et al., \"Adaptive Vector Quantization of Image Sequences Using Generalized Threshold Replenishment,\" IEEE Int'l Conf on Acoustics, Speech and Signal Processing, Apr. 21-24, 1997, vol. 4, pp. 3085-3088.|\n|9||Jianping Pan, Thomas R. Fischer, \"Vector Quantization of Speech Line Spectrum Pair Parameters and Reflection Coefficients\", IEEE Transactions on Speech and Audio Processing, vol. 6, No. 2, Mar. 1998, pp. 106-115.|\n|10||Kuldip K. Paliwal, Bishnu S. Atal, \"Efficient Vector Quantization of LPC Parameters at 24 Bits/Frame\", IEEE Transactions on Speech and Audio Processing, vol. 1., No. Jan. 1993, pp. 3-14.|\n|11||Mikael Skoglund, Nam Phamdo, Fady Alajaji, \"Hybrid Digital--Analog Source--Channel Coding for Bandwidth Compression/Expansion\", IEEE Transactions on Information Theory, vol. 52, No. 8, Aug. 2006, pp. 3757-63.|\n|12||Peter W. Moo, David L. Neuhoff, \"Optimal Compressor Functions for Multidimensional Companding\", IEEE Int'l Symp. on Info. Theory, Jun. 29- Jul. 4, 1997, p. 515.|\n|13||Richard A. Redner, Homer F. Walker, \"Mixture Densities, Maximum Likellihood and the EM Algorithm\", SIAM Review, vol. 26, No. 2, Apr. 1984, pp. 195-239.|\n|14||Robert M. Gray, \"Quantization\", IEEE Transactions on Information Theory, vol. 44, No. 6, Oct. 1998, pp. 2325-83.|\n|15||W.P. LeBlanc, B. Bhattacharya, S.A. Mahmoud, V. Cuperman, \"Efficient Search and Design Procedures for Robust Multi-Stage VQ of LPC Parameters for 4 kb/s Speech Coding\", IEEE Transactions on Speech and Audio Processing, vol. 1, No. 4, Oct. 1993, pp. 373-385.|\n|16||Wai-Yip Chan, Allen Gersho, \"Enhanced Multistage Vector Quantization with Constrained Storage\", IEEE Trans. on Comm., Nov. 1992, pp.659-663.|\n|17||*||Wang, et al. \"Vector Quantization Using Adaptive Codebook,\" IEEE Int'l Conf. on Communications, V 3, Jun. 1998, pp. 1350-1354.|\n|18||William R. Gardner, Bhaskar D. Rao, \"Theoretical Analysis of the High-Rate Vector Quantization of LPC Parameters\", IEEE Transactions on Speech and Audio Processing, vol. 3, No. 5, Sep. 1995, pp. 367-381.|\n|Citing Patent||Filing date||Publication date||Applicant||Title|\n|US7444030 *||Nov 12, 2004||Oct 28, 2008||Micron Technology, Inc.||Image encoding with dynamic buffer-capacity-level-based compression adjustment|\n|US7672834 *||Mar 2, 2010||Mitsubishi Electric Research Laboratories, Inc.||Method and system for detecting and temporally relating components in non-stationary signals|\n|US8982702||Oct 30, 2012||Mar 17, 2015||Cisco Technology, Inc.||Control of rate adaptive endpoints|\n|US20050021333 *||Jul 23, 2003||Jan 27, 2005||Paris Smaragdis||Method and system for detecting and temporally relating components in non-stationary signals|\n|US20060104524 *||Nov 12, 2004||May 18, 2006||Reid Donald M||Image encoding with dynamic buffer-capacity-level-based compression adjustment|\n|U.S. Classification||382/253, 348/422.1, 382/251, 704/222, 704/E19.024, 704/E19.005|\n|International Classification||G10L19/02, G10L19/06, G06K9/46, G10L19/12, H04N11/04, G06K9/36, G10L21/00, H04N11/02, G06K9/38, H03M7/30, G10L19/00, H04N7/12|\n|Cooperative Classification||G10L19/038, H03M7/3082, G10L19/008, G10L19/06|\n|European Classification||G10L19/008, G10L19/038, H03M7/30V, G10L19/06|\n|Apr 28, 2003||AS||Assignment|\nOwner name: REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE, CALI\nFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:RAO, BHASKAR D.;REEL/FRAME:014012/0176\nEffective date: 20030311\nOwner name: REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE, CALI\nFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:SUBRAMANIAM, ANAND D.;REEL/FRAME:014012/0168\nEffective date: 20030316\n|Nov 20, 2007||CC||Certificate of correction|\n|Dec 27, 2010||FPAY||Fee payment|\nYear of fee payment: 4\n|Dec 26, 2014||FPAY||Fee payment|\nYear of fee payment: 8"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:9f6764bf-3e63-4fbf-9912-8ae812bb2569>","<urn:uuid:011053b9-3077-4b92-8a09-2eb2f1014cd2>"],"error":null}
{"question":"¿Cómo se resuelve el logaritmo log 121 (11)?","answer":"To solve log 121 (11), first convert it to exponential form: 121z = 11. Since 121 is 11 squared, we can write that √121 = 11, or 1211/2 = 11. Therefore, z = 1/2 is the solution to the logarithm.","context":["Logarithms are an integral part of the calculus. To solve a logarithm without a calculator, let us first understand what a logarithm is.\nDefining a logarithm or log\nA logarithm is defined as the power or exponent to which a number must be raised to derive a certain number. The number that needs to be raised is called the base.\nLet’s see how a logarithm is depicted: c\nHere “x” is the base.\nNow, let’s get to the main part:\nHow to Solve a Log Without Using a Calculator?\nWe first need to understand square, cubes, and roots of a number. This is key to solving a logarithm.\nThe solution of any logarithm is the power or exponent to which the base must be raised to reach the number mentioned in the parenthesis.\nlog x (y) = z\nIf xz = y, then ‘z’ is the answer to the log of y with base x, i.e., log x (y) = z\nIn other words, x needs to be raised to the power z to produce y. z is hence the answer to log x (y).\nHere log x (y) is known as the logarithmic form, and xz = y is known as the exponential form. Remembering and understanding this equivalency is the key to solving logarithmic problems.\nlog x (y) = log x (xz) = z\nLet us use an example to understand this further: log 5 (25)\nThe base in this logarithm is 3. Let us try to replace the number in the parenthesis with the base raised to an exponent.\nlog 5 (25) = log 5 (52)\nOne the base and the number in the parenthesis are identical, the exponent of the number is the solution to the logarithm.\nTherefore log 5 (25) = 2.\nSome more examples:\nlog 2 (32) = log 2 (25) = 5\nlog 6 (1) = log 6 (60) = 0\nlog 4 (16) = log 4 (42) = 2\nIt is to be noted that in some instances you might notice that the base is not mentioned. Example: log 1000. In such cases, it is understood that the base value by default is 10.\nSo log 1000 = log 10 (1000) = 3.\nSome logarithms are more complicated but can still be solved without a calculator.\nHere are some examples:\nlog 4 (1/64)\nlog 1/4 (64)\nlog 121 (11)\nlog 3/2 (27/8)\nLet us solve each one of these.\nLet us consider that log 4 (1/64) equals to z\nThis can be written in another form as: 4z = 1/64\nNow let us try to find z, by simplifying the equation\n4z = (1/43)\n4z = 4-3\nHence z = -3\nlog 1/4 (64) = z\nHere 64 needs to be converted to (1/4) raised to an exponent, which is the solution to the logarithm.\n(1/4)z = 64\n(1/4)z = 43\n4-z = 43\nHence z = -3\nlog 121 (11) = z\nTo find z, first let us convert this to exponential form: 121z = 11\nWe know that 121 is 11 squared, and hence the square root of 121 is 11.\n√121 = 11\n1211/2 = 11\nHence z = ½\nlog 3/2 (27/8) = z\nThis equation is not as difficult as it may seem.\nLet us convert it to exponential form (3/2)z = (27/8)\n(3/2)z = (3/2)3\nHence z = 3\nlog 2√32 = z\nThis can be rewritten as log 2 (32)1/2 = z\nIn the exponential form, this is equivalent to 2z = 321/2\nWe know that 25 = 32\n2z = (25)1/2\n2z = (25/2)\nHence z = 5/2\nSolving a logarithm without a calculation is easier than it might seem. The most crucial part is to be well versed with squares, cubes, and roots of numbers.\nThe other important part of solving a logarithm is understanding its exponential form. Once you can do this, with a little practice, you can easily solve logarithms without needing a calculator.\nDo you have any logarithms you are unable to solve? Or do you have any questions for us? Please mention in the comments section below, and we will be happy to assist you."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:6cb6b93e-7aff-45ea-908a-6fbef1c7a0d2>"],"error":null}
{"question":"What are the key differences between Tshaka Mayanja's earlier and later albums in terms of musical style?","answer":"Tshaka Mayanja's first two albums were heavily focused on reggae music, while his later two albums shifted toward jazz funk. This was a conscious decision to showcase his versatility as a musician and songwriter. Though reggae remains his foundation, his music is an amalgamation of multiple genres including soul, funk, disco, blues, bossa nova, Latin jazz, and country.","context":["'Jazz' and 'Uganda' are rarely used in the same sentence. This little country in East Africa does not have much of a jazz tradition to speak of, let alone write about. Aside from international artists, the likes of Miriam Makeba and Hugh Masekela, as well as specially arranged cultural exchanges by the American, German and Dutch embassies, there has been, until recently, little to speak of locally.\nAll that is starting to change, for a variety of reasons. Somewhere in the thick of things is Tshaka Mayanja, who has staked his musical reputation on finding and thrusting some fine local artists into the spotlight. Mayanja has led a varied career, starting off as a bona fide reggae artist in Uganda, at a time when local music was not getting much airplay and recording facilities were hard to come by. He later moved to the United Kingdom, where he spent several years before returning to Uganda in 2004 to find great changes in the local music industry.\nAll About Jazz: Tell us a little about yourself. How would you describe yourself as a musician? How would you describe your music?\nTshaka Mayanja: I just turned 36 this year. I am a music fanatic. Obsessed, in fact. I have been writing songs for 20 years now, predominantly reggae music. I started writing \"jazzy\" pieces while in the UK a few years ago. Since then, I am a jazz music buff. To that add, funk, soul and the blues. I have hours and hours of jazz, soul and funk musicians' bios [and] live concerts.\nMy music is an amalgamation of all the above genres that inspire me, with the foundation being Roots and Lovers Rock reggae music.\nAAJ: Your first two albums were steeped more heavily in reggae, and the latter two skewed toward jazz funk. Was this a conscious decision?\nTM: I am reggae through and through. But, as earlier stated, I am actually a child of soul, funk, disco, the blues, bossa nova, Latin jazz and country. I grew up on all these genres. My parents owned a huge collection of vinyl LPs. It was such an eclectic mix of genres. Reggae and jazz came into my life at a later stage.\nIt was a conscious decision for me to do these albums in the different genres that shape me. I only started playing the bass in 2002. Playing and experimenting with these genres is fun. I also wanted to showcase my versatility as a musician and songwriter.\nAAJ: What is BlackRoots UNLIMITED, the moniker under which you release your music? What does it symbolize?\nTM: My music is 'Rooted in Blackness.' All the music I release has its roots in Africa. It symbolizes that both the heights and depths at which this music can go are unlimited.\nAAJ: The songs titles themselves are quite interesting. Tell us about your creative process. How do the name ideas come up? Do you not worry that the song titles might not resonate locally with Ugandans? Do you think your music is relevant to the Ugandan audience?\nTM: The creative process is spiritual. I cannot sit purposely to start writing a song. I'll fail. Music just comes naturally to me. I am very good with words, I can write a song literally about anything, in a flash. I am also good with melody creation. The recent albums with Pragmo [Nsaiga, featured on BRU's latest two albums] were a joint process.\nAs for the names, I cannot explain how they come about. I am not really concerned, never have been, as to whether the titles resonate with the Ugandan audience. I don't think my music is relevant to the majority of the Ugandan audience. It doesn't bother me anymore. I do have a following and for now, that will do. This music will one day be in the mainstream again in these parts, and history will show that I started it all. I did the same for reggae music [in Uganda] 15 years ago. At that time, nobody would touch it at all.\nAAJ: You are obviously marketing yourself to a much wider audience than in Uganda; how does the response compare locally and internationally?\nTM: The response outside Uganda has been tremendous. Even in Uganda, there is a section of music lovers who have supported these projects very much.\nAAJ: Was it a conscious decision to base yourself back in Uganda? Does that help or hinder what you are trying to achieve?\nTM: It does hinder creativity a bit, since there aren't many musicians here, if at all, with whom we share this vision. It does become frustrating. However, I am on the internet daily, communicating with inspirational artists and people with like minds all over the world.\nFunnily enough, I do not think I would have been able to record and release these projects had I stayed in the UK. There's way too much stress [in the UK], and being given a chance is next to impossible. Here, I can take my time, and still be able to release the music worldwide without leaving home.\nAAJ: Tell us a little about the people you have show casedAngela Kalule and Pragmo N'Saigawhy them? The partnership with Pragmo has produced two albums in quick succession, is this long term partnership musically?\nTM: Angela Kalule, who I 'baptised' K'Angie Mtume, is a very talented vocalist. When I came [back] to Uganda in 2004, she was a very frustrated artist who felt there was no light at the end of the tunnel. She wanted to sing jazz, and to sing in English, yet her peers discouraged her. I wrote, produced and played an album called Dark Chocolate (Blackroots Muzik, 2005) for her, so as to showcase her singing. As I write, she is now the most sought after female singer and MC's at all Ugandan corporate events.\nis number one, as a matter of fact.\nIs this a permanent arrangement? Not really. I would like to find and groom another Angela, another Pragmo. That is the essence of BlackRoots UNLIMITED; helping out superior talent that has otherwise been ignored in Africa. But, you never know. Pragmo has a brother called Greenman who is such an impeccable reggae vocalist! I am thinking of writing an album for him."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:6b36f0f4-f23c-46e8-81e4-210f92ed8da9>"],"error":null}
{"question":"Do both machine guarding and fall protection systems require regular equipment inspection?","answer":"Yes, both systems require regular inspection. For machine guarding, employers should inspect equipment daily to ensure all guards are intact, especially after maintenance or repair. For fall protection equipment, workers need to properly inspect their equipment, with specific attention paid to components like full-body harnesses and self-retracting devices to ensure they're in good working order.","context":["SAFETY SOLUTIONS: Machine Guarding\nThe primary function of all machine guarding is to\nprevent an operator or bystander from being\ninjured by a potentially dangerous portion of a\nmachine. Often the hazard involves moving parts with the\npotential to cut, crush or draw-in body parts, although\nbarrier guards may also be necessary when electrical,\nthermal or chemical dangers are present.\nGuarding or protecting people from harm may be accomplished\nwith simple physical shielding of machine parts, or\nmore advanced techniques such as photo light curtains. It\nis also often necessary to employ interlocks to disable\npower to the machine when a guard has been removed.\nAccident risks can be reduced with adequate machine\nsafeguarding. Identifying obvious and hidden hazards\nshould be the first step in planning and reviewing the need\nfor machine tool safeguarding. Some hazards are subject\nto the ‘seven-foot rule, which dictates that these potentially\ndangerous operations be enclosed or guarded if they\nare located less than seven feet above the floor or platform\nlevel. Guards are required to have one-half-inch or\nsmaller openings. Blades and other overhead hazards—\nsuch as pulleys, belt rope and chain drives, overhead horizontal\nbelts, vertical and incline belts, gears, sprockets\nand chains—must comply with this rule.\nMost incidents leading to injury are the result of inadvertent\nor unwise contact with moving machine parts. Because\nof the great diversity of machine designs and functions,\nappropriate safeguarding to protect workers from such hazards\nmay also have numerous forms. Certain principles,\nhowever, are basic to any effective safeguarding design.\nEvaluation and Design\nA uniform process should be applied and used to evaluate\neach of the hazards on the machine to develop the required\nlevel of safeguarding. The evaluation can be performed by a\nknowledgeable and experienced person or, for more complicated\nmachine designs and safeguarding issues, the evaluation\ncan be conducted by a qualified third party.\nThe OSHA/ANSI hierarchy for controlling machine hazards\nis as follows:\nIf the results of the hazard evaluation show the equipment\nto be safe (that is, poses no hazard to the employee),\nchanges to the equipment may not be necessary. This\nmay be true for manually-powered equipment.\n- Eliminate the hazard by design\nControl the hazard by guarding or devices\n- Personal protective equipment\nAssessing the Risk: Many times the employer will want\nto know the answer to this question, “What do we fix\nfirst?” Once you have identified the danger areas (hazards),\nyou should assess the risk (how likely it is to cause\ninjury, and how severe the injury could be.)\nFor every hazard that you identify on a machine, you\nmust then assign a risk factor to it. On the Probability\nchart listed below, decide what is the most predicable\ninjury that could occur, then assign a risk number to it.\nIf you score a 1 or 2, do something NOW.\nIf you score a 3 or 4, plan to do something soon.\nIf you score a 5 or 6, plan to review the risk in the future.\n| CONSEQUENCE |\nHow severely could it hurt someone?\n| What is the likelihood of it happening?\nFirst aid only,\n|VERY LIKELY: |\n|VERY UNLIKELY: |\nIt could happen,\nWhen designing machine guards the safeguards must\nmeet these minimum general requirements:\nIn summary, employees working on or near machinery\nwith hazardous moving parts must be protected. OSHA\nrequires that such parts be guarded to ensure worker\nsafety. If unguarded, those parts could entangle a worker’s\nhands, hair or clothing and lead to injury or even death.\nEmployers therefore should inspect equipment daily to\nmake sure that all guards are intact—especially after\nmaintenance or repair.\n- A guard is a protective device that PREVENTS anyone\nfrom reaching over, under, around or through the guard\nor guarding device.\n- An awareness barrier or chip shield can be used to\nwarn a person that they are coming in close proximity\nto a danger area. Other protective measures such as\ntraining or color coding must also be used so the person\nis reminded that they could potentially be injured if\nproper procedures are not followed.\n- Prevent contact: The safeguard must prevent hands,\narms, and any other part of the operator’s body from\nmaking contact with dangerous moving parts. A good\nsafeguarding system eliminates the possibility of the\noperator or another worker placing parts of their bodies\nnear hazardous moving parts.\n- Secure: Operators should not be able to easily remove\nor tamper with the safeguard, because a safeguard\nthat can easily be made ineffective is more dangerous\nthan no safeguard at all.\n- Protect from falling objects: The safeguard should\nensure that no objects can fall into moving parts. A\nsmall tool which is dropped into a cycling machine\ncould easily become a projectile that could strike and\nseriously injure someone.\nCreate no new hazards: A safeguard defeats its own\npurpose if it creates a hazard of its own, such as a shear\npoint, a jagged edge, or an unfinished surface which\ncan cause a laceration. The edges of guards should be\nrolled or bolted in such a way that they eliminate sharp\nCreate no interference: Any safeguard which impedes\na worker from performing the job quickly and comfortably\nmight soon be overridden or disregarded. Proper\nsafeguarding can actually enhance efficiency as it can\nrelieve the worker’s apprehensions about injury.\n- Allow safe lubrication: If possible, one should be able\nto lubricate the machine without removing the safeguards.\nLocating oil reservoirs outside the guard, with\na line leading to the lubrication point, will reduce the\nneed for the operator or maintenance worker to enter\nthe hazardous area. Guards and safety devices should\nbe made of durable material that will withstand the\nconditions of normal use.\nOSHA 1910.212 requires guards to be attached to the\nmachine where possible or secured elsewhere if attachment\nis not possible. The guard or guarding device\ncan not create a hazard in itself.\nFor more information, click on the author biography at the top of this page.\nThis article was written by Jack and Alan Podojil.\n|Back To Top|","Fall Protection Toolbox\nWorking at height can be a hazardous job and remains a leading cause of injuries and OSHA citations Our resources can help you address these challenges by understanding how to properly design, implement and use fall protection systems to advance your safety programs, help you increase efficiency and stay OSHA compliant.\nBeginner – Creating a Fall Protection Plan\nTo be OSHA compliant you must take the necessary steps to protect workers performing tasks at 4 feet or more, depending on industry, above ground level.\nArticle: Safety News You Need: Fall Protection – Learn the latest tools you can use to reduce work-at-height risks.\nPodcast #23: The Fall Protection Code – Learn about the full line of ANSI/ASSP Z359 standards and how they fit in your fall protection plan.\nWebinar: Fall Protection Critical Aspects Learn the important components of fall protection systems\nWebinar: Fall Protection in Construction Hear a high-level review of fall protection definitions, responsibilities and topics\nLive Virtual Classroom: Effective Fall Protection Programs | 1.4 CEUs – Learn through hands-on exercises how to best make the critical decisions required to protect workers at height\nIntermediate – Implementing Industry Best Practices\nElevate your safety program to incorporate the latest industry best practices. Implementing consensus safety standards can help increase efficiency in your workplace and help you stay OSHA compliant.\nFree Download: The Fall Protection Code: - Your guide to helping protect workers at heigh, the ANSI/ASSP Z359.1-2020 The Fall Protection Code provides an overview of the full line of Z359 standards.\nArticle: Four Steps of Designing an Effective Fall Protection System - These steps can help you make sure your employees have the right equipment, know how to operate it and keep it in good working order\nPodcast #7: Protecting Workers at Height - Join Kevin Denis, member of the Z359 standards committee, to learn how industry consensus standards can help keep workers safe at height.\nStandards: ANSI/ASSP Z359.2 – Minimum Requirements for a Managed Fall Protection System\nOnline Course: Managed Fall Protection | 2.1 CEUs – Build the knowledge you need to implement a comprehensive managed fall protection program supported by the included standard: ANSI/ASSP Z359.2-2017\nAdvanced – Proper Equipment Use and Training\nInsufficient anchorage strength and inappropriate anchorage connection are two common mistakes made with fall protection equipment. Learn how to properly inspect, use and anchor your fall protection equipment for optimum results.\nArticle: Proper Anchorage - Familiarize yourself with the different anchorage connector types and select the appropriate anchor points.\nPodcast #31: Self-Retracting Devices: The Fall Protection Lifeline – Dan Henn of the Z359 committee explains the role and best practices for using of self-retracting devices.\nPodcast #32: Fall Protection Anchorage – Greg Small of the Z359 committee talks about the important role of fall protection anchorage in protecting workers operating at height.\nWebinar: Training Employees to Use a Full-Body Harness – Regina McMichael and Thom Kramer share their expertise on how to teach workers to correctly use a full body harness.\nOnline Self-Paced Course: Fall Protection Equipment Course | 3.0 CEUs – Develop your knowledge of the most common types of fall protection equipment. Includes four ANSI/ASSP Z359 standards.\nStandards: Save when you purchase the full package of ANSI/ASSP Fall Protection and Arrest Standards\nOur articles, podcasts and free webinars are updated regularly to keep you informed on the latest best safety practices to help keep workers safe when performing tasks at height.\nArticle: Four Steps of Designing an Effective Fall Protection System These steps can help you make sure your employees have the right equipment, know how to operate it and keep it in good working order.\nRead View all Articles\nPodcast #59: Full Body Harnesses: Staying Secure at Height – Listen to our latest episode to learn the safe use of full body harnesses and to hear about the latest update of the ANSI/ASSP Z359.11 standard.\nListen View all Fall Protection podcasts\nFall Protection Critical Aspects - Learn the important components of fall protection systems from Thom Kramer, Chair of the Z359 Committee\nWatch View all Fall Protection webinars\nStandards and Technical Publications\nReferencing fall protection standards and technical publications, safety professionals can implement the latest best practices to identify risks, prevent injuries and create a comprehensive program to keep workers safe.\nThe ANSI/ASSP Z359 series of fall protection and fall restraint standards address identifying and abating hazards through a variety of fall protection equipment, systems, and training programs.\nView ANSI/ASSP Z359 Standards\nANSI/ASSP A10 standards cover safety requirements for a wide range of activities related to construction and demolition operations from erecting scaffolding, to handling explosives, to pouring concrete.\nView ANSI/ASSP A10 Standards\nThe A1264 standards establish provisions for safe working and walking environments where potential for slips, trips and falls exist.\nView ANSI/ASSP A1264 Standards\nEnhance your on-the-job knowledge with guidance from industry experts.\nView Fall Protection publications\nTake a course taught by industry experts to gain the knowledge you need to advance your fall protection safety programs. Select your skill level, preference of course modality and earn CEUs.\nJoin our Community\nMembers can connect with peers in our Chapters, Common Interest Groups and Practice Specialties. Explore all the benefits of membership including the members’ only online community, member pricing and access to member exclusive events.\nCheck here for information on OHSA initiatives and additional resources related to fall prevention and construction safety.\nAll participants are welcome. Please let us know of any accommodations that would make your experience better when you register."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:33cb5a5d-857b-4891-94cb-a8cf981285d7>","<urn:uuid:0efcbb96-8bf1-4ff5-9f59-f03bdc06f778>"],"error":null}
{"question":"What were the legal consequences for those involved in the Loyle Lanes bowling alley arson?","answer":"The three suspects faced charges of aggravated arson, aggravated arson for hire, and conspiracy to commit arson. If convicted on all counts, they could each receive up to 50 years in state prison. Steven Smink and Felix Manzano were held in Philadelphia on $300,000 bail, while the unnamed teenage suspect was released to his mother.","context":["Hardcore bowlers don't just call their main alley their lanes - it's their house. A beloved house burned down last week after 50 years on the edge of Vineland, a city in a part of New Jersey far from the historical home of the mob and the teeming chaos of the shore, a place where the state nickname, the Garden State, seems apt. Sadness turned to anger Wednesday, when authorities announced that the manager of a rival bowling alley, the only other one in Cumberland County, had been charged with arson in the destruction of Loyle Lanes.\nSteven Smink, the lessee-manager of Pike Lanes Family Fun Center in Deerfield, hired another man, Felix Manzano, 21, and a teenager to torch Loyle Lanes, police said.\nSmink, a 47-year-old former Pennsylvania warrant officer, essentially an independent contractor who does many of the warrant-serving functions that sheriffs officers in other states do, brought big ambitions when he took over Pike Lanes in 2007.\nThe Loyles, the family behind Loyle Lanes, said they'd never met Smink but had heard he boasted he'd put them out of business in two years - even though the alleys had coexisted peacefully for decades in the sandy-soiled part of deep southern Jersey, where the towns are small, the main streets are wide and agriculture has always been one of the main industries.\nCharles Loyle, who owns the alley with his brother but has handed operations over to his two sons, said he was stunned by the announcement of the charges.\n\"We just can't comprehend a youngster of 21 years old and a juvenile of 17 being talked into committing an act like this against us,\" he said.\nThe fire, discovered after 2 a.m. on Jan. 11, moved so fast that Loyle suspected arson right away as he watched from a police car.\nAlmost immediately, the building's roof and a section of the back wall were gone. The sign on the front was blown out. Bowling pins and balls melted, as did almost everything else inside.\nThe bowling alley's office, with legal documents and financial records, was the only part not ruined.\nLoyle's family brought out charred remains of lockers and their contents for some of their regular bowlers; they were parked along the fence put up around the fire site.\nPolice said the blaze began on the roof but gave no other details about how they identified the suspects or how the fire was set - or why.\nThe three suspects, all from Philadelphia, face charges of aggravated arson, aggravated arson for hire and conspiracy to commit arson. If convicted on all counts, they each could be sentenced to up to 50 years in state prison.\nSmink and Manzano were being held in Philadelphia, where they were arrested, on $300,000 bail. The teen, whose name has not been made public, was released to his mother.\nCumberland County prosecutor Jennifer Webb-McRae wouldn't say whether lawyers for any of the defendants had come forward.\nAt Smink's home, a woman who answered the phone said, \"I know nothing about it,\" and hung up."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:00f892be-5247-4e5e-a514-9d5723c93e90>"],"error":null}
{"question":"As a recording engineer looking to understand microphone technology, how do ribbon microphones compare to other types in terms of sound characteristics, and what power requirements do they need?","answer":"Ribbon microphones provide a sound quality that sits between dynamic and condenser mics, capturing detailed audio in a flattering way. They do not require phantom power - in fact, phantom power can severely damage them. However, ribbon mics need to be matched with high-quality preamps that can provide 70 db or more of clean gain. For applications like the SF-2 ribbon microphone, the electronics provide a perfect impedance match to the ribbon element at all times, ensuring optimal performance regardless of the preamp used. The ribbon element cannot be damaged by phantom power, electrical glitches or miswired cables.","context":["Active Low-Mass Ribbon Microphone\n- Aktives Bändchen Mikrofon, Achter-Charakteristik\n- Röhren-Elektronik mit hohem Output\n- Optimale Impedanz zum Ribbon Element und Output\n- Extrem tiefes Eigenrauschen\n- Externe Stromversorgung\n- Keine hochfrequenten Peaks, Ringing oder Phasenshifts\n- Stabiles Ribbon Element gegen Hitze/Feuchtigkeit\n- Gleiche Empfindlichkeit von Vorder- und Rückseite\n- Leicht unterschiedlicher Klang von Vorder- zu Rückseite\n- Gleicher Frequenzgang mit zunehmender Distanz\n- Kommt in Alukoffer mit Shockmount und PSU\nThe SF-2 ribbon microphone is a phantom powered version of our original SF-1 ribbon microphone. Designed primarily for classical applications and acoustic instruments, the SF-2 combines high-quality audio performance with our exclusive active electronics for ribbon microphones. The SF-2’s output of -38 dB puts its sensitivity on par with that of phantom powered condenser microphones, allowing it to be used with a wide variety of mic pre’s regardless of gain characteristics. The unique electronics and custom designed FET’s used in the SF-2 deliver ultra-quiet operation, with self-noise of lower than 18 dB.\nThe SF-2’s magnet/pole piece transducer structure gives a wide, uniform frequency response with no substantial peaks or dips, and the 1.8-micron ribbon element delivers superb transient response. Frequency response is excellent regardless of the angle of sound striking the ribbon and off-axis coloration is negligible.\nOur Active Series ribbon mics are as sensitive as phantom powered condenser microphones, allowing you to use virtually any mic preamplifier or board pre. Conventional ribbon microphones are 15 to 30 dB less sensitive than condenser mics, necessitating the use of high-quality, high-gain microphone preamplifiers when recording quieter sound sources like acoustic instruments, vocals, room ambiance, etc. The SF-2 contains a fully balanced, discrete head amplifier system which utilizes a specially wound toroidal transformer and ultra-low noise FET’s to deliver a sensitivity of -38 dB. Even with extremely quiet sound sources, you’ll have enough level to drive any recording medium.\nThe SF-2’s electronics create no additional self-noise. All of the SF-2’s higher output comes from its large, specially wound toroidal transformer which provides an additional 14 dB of ‘free gain.’ The phantom powered system operates at less than unity, adding no noise of its own.\nThe electronics in the SF-2 provide a perfect load to the ribbon element at all times, allowing the microphone to deliver 100% of its full sonic potential regardless of the input characteristics of the following mic-pre. Due to its low-impedance output, SF-2’s can be used on extremely long cable runs with minimal signal loss.\nA proper impedance match is critical to the performance of ribbon microphones. Impedance mismatching loads a ribbon element improperly, resulting in loss of low end and body, lower sensitivity, and an overall diminished performance. With our Active Series ribbon mics, the ribbon element sees a perfect impedance at all times regardless of the preamp you choose, so its performance is never compromised by the effects of improper loading. In addition, the ribbon element cannot be damaged by phantom power, electrical glitches or miswired cables.\nThe SF-2 Story\nTwenty prototype SF-2’s circulated in major studios and scoring stages for years before the microphone’s release. They were extremely well received in classical circles, where they excel on choir, piano, woodwinds, strings and many other applications. They were also well received in studios focusing more on acoustic instruments, singer/songwriters, etc. We couldn’t get most of the prototypes back…\nThe SF-2 ships in an aluminum presentation case with an SFS-2 shock mount, mic sock, documentation and manual.\nChoir, Woodwinds, Flute and other reed instruments, Voilin, Cello and other stringed Instruments, Brass, String and Woodwind sections, Piano, Harp, Orchestra, Acoustic Guitar, Mandolin, Banjo, Percussion Instruments, Vocals, Drum Overheads, Ambiance","So, why would I want to use a Boost Pedal between my guitar and my amp? First off, I have a nice guitar I’m super happy with and I’ve used this same guitar for gigging, teaching and recording most of my career. It’s an old 68 Gibson. I’ve always found that although I like the sound, the output has always been low and a little thin.\nThe other thing is that like many jazz guitarists, I like to use a small amp. I especially like all the small tube amps with EL84 tubes. This of course is my own personal taste. Even though, for a long time I opted for a nice loud, lightweight “Acoustic Image.” It wasn’t my ultimate jazz guitar sound but volume was never an issue and it sounded pretty good.\nCurrently, I’m back to using a small tube amp and love the sound. It’s great for recording but a little shy for volume on some gigs and when I have my regular Monday night rehearsals with the big band, I’m really pushing it.\nI was curious about the pickups in my guitar and if their were any known issues with some of the older Gibson Pickups. Like most Gibson owners, we hope we have the most famous of pickups, the PAF’s. Those things are worth a fortune so we all hope we have a pair just for the sake of bragging rights if nothing else. A quick search on Google and a visit to a Gibson forum, Wikipedia, and a few other sites I soon discovered I have T-Tops. I also discovered that Gibsons from 68 with T-Tops can have low output and a thin sound.\nWhy do they sound this way? From what others have suggested, the pickups are just old and lose their magnetic charge. Apparently you can have a guitar tech take apart your pickups and re-magnetize them or you can replace the magnets with fully charged magnets of your choice. I don’t really think I want to do that. If they end up sounding vastly different, I’ll be a very unhappy jazzer.\nSo back to the pedal. I had tried something years ago that was a little homemade pedal with in/out jacks and a single knob. It was described as giving you more volume but it wasn’t like a distortion pedal. I remember that it really made my guitar speak and it also gave a nice little boost in volume.\nWell here I am again in that same place; love my tone but It’s not loud enough. Do I buy a bigger, louder, heavier amp? I remembered that pedal I had tried and started doing some research. Low and behold there are dozens of companies making Boost Pedals. There are all kinds of prices, brands, features and so on.\nOne thing I will add is that when I plug in my Fender Strat with Lace pickups, I have tons more volume than I get from my Gibson. Interesting! So I’m thinking the Boost Pedal should give me a little more oomph going into the amp. At this point I’m sold. Time to spend a few bucks and order one of these little boxes.\nI went on Amazon and found a Donner “Boost Killer.” No, not the best name for a “Boost” pedal, I know. The name kind of suggests it’s going to take something away. Why would anyone want to kill their boost? It wasn’t the cheapest and certainly not the most expensive. It seemed to get very good reviews and was described as being a steal for the price. Perfect!\nIt’s very small (good thing) but along with it’s small footprint is the obvious problem: no room inside for a battery. Be forewarned, you will also need a 9V power supply which you will also have to carry around.\nSo how does it sound? So far I’m pleased. I’m getting a hotter signal into the amp with no added distortion at all. This pedal will distort though so play around with the volume and gain controls until you find something you like. Is my amp way louder now? No, of course not. I do have a little more volume for sure and the fact that there is a hotter signal going into the amp has added a little more tone and sparkle to my sound.\nSo there you have it. I’ve joined the guitar pedal craze! I’m a jazz guitarist and I own a guitar pedal!\nApart from all the time we spend practicing and doing gigs, it’s becoming more and more common for us as jazz guitarists to be able to record ourselves. Today, more than ever, musicians from all musical styles own and use a certain amount of home recording gear. It has become an essential part of our careers for us to be able to do everything from making our own demos, composing and recording music as well as providing guitar tracks for a project that we can upload to another artist or producer who lives halfway around the world.\nSo much gear, so much to know and so many opinions about what is best. In this post, I’d like to look at some of the different microphone choices to record a jazz guitar amplifier. What are some of the better microphones we can use to capture a good representation of what a straight up, clean jazz guitar should sound like?\nOne of the things you will encounter in your quest to find which microphone to buy is that the majority of the reviews and recommendations come from musicians and recording engineers who work predominantly in the pop and rock genres. All those great microphone reviews are focussed on capturing a guitar player shredding through a Marshall stack. Although some of what they find may be true and will still translate to the kinds of sounds we play, for the most part, there is much more for us to know.\nOk, so recording jazz guitar, what do we need to know? Let’s start with microphone types. There are 3 types of microphones you can use to record jazz guitar: Dynamic, Condenser and Ribbon. If you want to know more about each type, click here.All are great microphones that can be placed in front of your guitar amp. Which is best? Which type should you buy? The good news, all 3 types of microphones can produce great results. In the end, it all comes down to your own tastes, goals and what you are willing to spend.\nWe’ll listen to 2 dynamic microphones: Shure SM57 and Beyerdynamic M201 N (C). Dynamic microphones are generally on the less expensive side. Dynamic microphones will most often have a narrower frequency response and don’t require phantom power. Now it’s important to note that a narrower frequency response is not necessarily a bad thing. What that means is it’s not going to pick up the really low or the really high frequencies. We don’t really want the boomy low notes or the super high overtones anyway. So, in essence, dynamic mics are sort of providing a nice EQ for us. Dynamics will help take out some of the stuff we don’t really want anyway.\nFor condensers, we’ll listen to a Shure Beta 181 with supercardiod capsule and a Neumann TLM 102. Condenser microphones have a much wider frequency response, usually from 20-20,000 Hz and do require phantom power. Although most audio interfaces today do provide phantom power, there are still some that don’t so it’s always good to check. Condenser microphones are much more acurate and will pick up much more detail, both in a good way and in a bad way. This of course means that if you are in a noisy environment, the microphone will capture all of that noise as well. Any amp hum, ringing tubes, finger noise, street noise, all of this will be more evident when using a condenser mic. At the same time, more of the colour, nuance and the dynamics will also come through giving you a much richer sound.\nRibbon mics are a favorite for guitar players. I would describe them as being both accurate and flattering. The sound of a ribbon microphone is probably somewhere between that of a dynamic and a condenser. They seem to capture a lot of detail but always in a good way. Ribbon microphones do not require phantom power and in fact phantom power can severely damage a ribbon microphone. Ribbon microphones also need to be matched with a very good preamp that can provide 70 db or more of good, clean gain. If you are planning on using a ribbon microphone with a soundcard which does not have enough gain, there are solutions like the “Cloudlifter” or “Fethead” which offer an additional 20 db or so of ultra clean gain. The Ribbon microphone we will listen to is the AEA R84. It is a beautiful modern day recreation of (or perhaps a microphone inspired by) the vintage RCA 77. The AEA R84 is an expensive microphone but there are many excellent low cost Ribbons for as low as $99 which provide amazing results on guitar amps. (Apex, Cascade Microphones, MXL…..)\nHere’s the what and how used for all of the recorded examples. Microphones, placed around an inch and a half from the speaker grill, went through a BAE 1073MP preamp into a Universal Audio Apollo Quad into Pro Tools 2018. For the AEA R84 Ribbon Microphone, I used a Grace Design M101 preamp. The Grace has a Ribbon mode which works very well with the R84 and provides very clean, high gain levels.\nI played my 1968 Gibson ES-175 using the neck pickup through a Traynor YCV20 with JJ tubes and a 12″ bass speaker. Why a bass speaker? I’ve always preferred the sound of my guitar through a bass amp. Using a bass speaker helps to cut a lot of the unwanted highs you get from most amps. At this point, I like tube amps. I keep going from jazz amp (Polytone) to tube amp, (Mesa Boogie) back to jazz amp, (Acoustic Image) and now once again a tube amp. (Traynor) It’s funny because I’m sure the listener never actually notices the difference anyway. In the end, we sound like we sound.\nBelow are the recorded examples for each microphone. Since some of the microphones have higher signals than others, I’ve matched volumes to help make comparisons easier. Also, there are 2 examples for each microphone: one with just guitar and one with piano bass and drums. In most cases the sound of the guitar alone doesn’t tell us enough. How it’s going to sound in the context of an entire mix is much more important.\nTape emulation, parallel compression and reverb have been added to all examples with piano, bass and drums. The solo guitar examples have no processing. No EQ has been added to any of the examples.\nShure SM57 Solo Guitar\nShure SM57 Guitar with Trio\nBeyerdynamic M201 N (C)\nBeyerdynamic M201 Solo Guitar\nBeyerdynamic M201 Guitar with Trio\nShure Beta 181 (Supercardiod Capsule)\nShure Beta 181 (Supercardiod Capsule) Solo Guitar\nShure Beta 181 (Supercardiod Capsule) Guitar with Trio\nNeumann TLM 102\nNeumann TLM 102 Solo Guitar\nNeumann TLM 102 Guitar with Trio\nAEA R84 Solo Guitar\nAEA R84 Guitar with Trio\nWhich sounds best? To me, they all sound like they get the job done very well. To be fair, these are all microphones I like to use on guitar amps and especially when recording jazz guitar. They do all sound a little different, and bring out different aspects of the amp sound. My intentions are not to say one is better than the other or give you a list of “the best” microphones to record jazz guitar. It’s more of a chance to have one more listen from a clean jazz guitar perspective.\nThis comparison has actually been pretty revealing to me. Hearing all these microphones side by side has made me reconsider some of my own choices.\nIt’s also important to note that I did play the example 5 times in a row. Because I wanted to place the microphone in the exact same spot each time I could really only use one microphone at a time. I know some people like to record the guitar once direct and then do the re-amp thing. I don’t have confidence in that approach. So even though I tried to play exactly the same each time, I’m sure I was influenced slightly by the sound of each microphone and may have reacted to each to a certain degree.\nAs always, I hope my Blog Posts are helpful and that this one in particular in some small way will help you to find the right microphone that works for your own style of playing and sound."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:5eaeb095-3d42-4381-887e-7bbfd5fd5b3d>","<urn:uuid:f9096be8-f04a-4e57-9db4-882bcdd04bc7>"],"error":null}
{"question":"Como profesional de la salud, me gustaría saber ¿cuáles son las tres categorías principales de esporas de moho y cómo se puede confirmar su presencia?","answer":"Mold spores fall into 3 main categories: allergenic, toxigenic, and infectious. The only way to positively confirm the presence of mold is through testing performed by a certified laboratory. Visual indicators like color, texture, or smell are not sufficient to confirm contamination.","context":["Air samples are collected using a special machine that sucks air through it, and over a slide treated with a special solution to collect particles from the air. The machine runs for approximately 5 minutes per sample, and then the slides are sent to the laboratory for analysis. The lab uses a specific mathematical equation to determine how many mold spores are in each cubic meter of air.\nSurface samples are collected using a biotope or a completely clear/transparent tape with a glossy finish. We can also collect a bulk piece of material, or items with suspect signs of mold on them.\nWas this helpful?350\nMold spores are microscopic, and fall into 3 main categories: allergenic, toxigenic, and infectious. The only way to positively confirm whether or not mold is present is to perform testing through a certified laboratory. Color, texture and/or smell are not enough to confirm a possible contamination.\nWas this helpful?102\nAll of our inspectors are in the field working on inspections, and are not available by phone. However, all of our consultants are fully certified, and happy to answer any questions you may have.\nWas this helpful?143\nOne of the main parts of the inspection process is the use of a digital moisture meter. With this, we can determine if there is a buildup of moisture inside of a wall cavity, or not. Mold growth can start as early as 24-48 hours after any water incident, and so it can generally be assumed that where there is moisture, there is probably mold. To verify this, we can accompany the digital moisture meter testing with an Inner Wall sample. Inner Wall samples are collected by inserting a small tube into the inner wall cavity, either through a switch/plug plate, or by drilling a small hole. Then air is collected, in much the same manner as a normal air sample, and the slide is sent to the lab for evaluation.\nWas this helpful?133\nYes you can. We offer Rush service for an additional $195, which guarantees your report will be emailed to you the business day following your inspection.\nWas this helpful?61\nYes, mold is a natural part of the ecosystem, and in nature mold is a natural decomposer, which means that there are always mold spores in the air. Mold spores can travel into your home/office through open windows, doors, and on your clothing. However, mold should not be growing inside of your home/office, and should not be at elevated levels in the air within your home/office. The only way to determine if you have elevated levels of mold spores in your air is through testing.\nWas this helpful?72\nThe only way to get a completely clean result in your home/office is to have the area hermetically sealed and cleaned. There will always be low levels of mold spores in the air. The majority of our clients call us because they already suspect that there is a problem, or because they can see what they suspect to be mold, growing in their home. In these cases our testing is simply confirming or denying their suspicions, and determining whether the mold is allergenic, toxigenic, or infections. In these cases, we can offer our clients remediation recommendations, using our 5 step protocols which will ensure that removal is done safely, and with a certified technician.\nWe frequently have results come back that show no signs of a mold contamination within a home/office. In these cases, there would be no remediation recommended, and our services would be completed. We can, however, offer our clients periodic check-ups for their home/office, at a discounted rate, to make sure that mold does not start to grow.\nWas this helpful?120\n\"Mold\" and \"mildew\" are terms that are used generally to describe growths of fungi on various surfaces. \"Mildew\" also is a scientific term that describes a type of plant disease. In common usage, the difference between mold and mildew usually is in their appearance and the surfaces on which they are growing. Mold is often thicker and black, green, red or blue in color, and mildew usually is lighter, powdery and gray or white. Both mold and mildew often grow in moist and warm locations, but mildew is more often found in showers, on paper and on fabrics, and mold is often found on foods and in walls and other permanent structures. (Per http://www.wisegeek.com/what-is-the-difference-between-mold-and-mildew.htm)\nMold can cause structural damage to homes over time and can also cause numerous health problems, including: respiratory problems, pneumonia, allergic reactions, rashes or hives, migraines, sinus infections, inflammation and pain in the joints, mental status changes (depression, forgetfulness), and extreme fatigue. Mildew can cause damage to plants and crops and can also cause health problems, including: difficulty breathing, coughing, sore throat and headaches.\nWas this helpful?162"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:ba582f45-1e37-4d5a-b6d9-24be8aa7a11b>"],"error":null}
{"question":"What are the benefits of digital documentation for facility records, and what role does it play in emergency preparedness?","answer":"Digital documentation offers several benefits for facility records: it enables automated alerts for maintenance issues, secure cloud storage of water chemistry data, easy tracking of staff training/certifications, and customizable forms for incident reporting. From an emergency preparedness perspective, digital documentation ensures important company records and data are protected through off-site storage and cloud backup systems, making them accessible even if physical facilities are damaged in disasters. This approach also helps maintain business continuity and supports regulatory compliance during emergency situations.","context":["How many managers know when was the last time he/she reviewed the facility’s day-to-day operational records? For some, it may be at the start of the season, while for others it could even be last year. In many cases, these records may not have been looked at since they were initially created. In fact, it is quite possible they are the same operational records that have been used for years. Documentation of maintenance issues, safety inspections, and water quality results is more important now than ever, but there are very few facilities that are as diligent as the law requires.\nWith more government agencies in Canada and the U.S. adopting the Model Aquatic Health Code (MAHC), there is a new industry standard to follow for pool operating procedures and best practices. The last thing a facility manager wants to worry about in the face of potential litigation or a public health crisis is if his/her aquatic team followed the proper procedures for documentation requirements. Many organizations are turning toward digital storage and processing of their records to ensure they are complete and safely stored. There are many options to consider, so facility managers need to make sure he/she not only gets what they want, but also what will keep the facility safe.\nEvery facility has some sort of checklist they follow on a regular basis. These could include daily opening and closing procedures, weekly cleaning duties, or monthly maintenance items. The challenge with the current paper method is there is typically no accountability for items that need correction. For instance, safety checks are the primary method of facility surveillance.\nFacility managers, lifeguards, or other staff such as those who handle facility operations and maintenance—or a combination of both—may perform these checks. If these checks are to be useful, they need to include procedures for reporting issues and following up. For instance, how often does a facility manager need to comment about the shower still leaking before maintenance comes to repair it? What if the checklists a facility manager completed every day would automatically send alerts and reminders? With a digital tool, this is not only possible, but automated.\nA safety check is a quick method of assessing the condition of the facility and includes an evaluation of specific elements and areas, including communication equipment, rescue, first aid and safety equipment, operational equipment such as lifeguard stands, lane lines, bulkheads, starting blocks, pool decks, waterpark attractions, locker rooms (e.g. dressing/shower areas, restrooms), chemical storage areas, fencing, and access points.\nOther items may include checklists for daily oxygen or automated external defibrillators (AEDs), diving boards or waterslides, or even concession areas. Another benefit of digital tools is the ability to customize and create new checklists as items arise that requires documentation.\nIn-services and trainings\nAnother area that is critically important to document is on-going training. Every lifeguard should meet an in-service requirement before taking the stand, but how does a facility manager ensure every single lifeguard has completed their in-service?\nThe in-service records should include the dates and time of the in-service, what topics were covered and who attended. With old paper records, it is hard to track attendance by person and confirm they have recently attended one. By using digital forms, a facility manager can create a dashboard that can highlight lifeguards who have met this requirement versus those who have not. With this information being readily available, staff schedules and shifts can be easily managed, while also making sure everyone on staff is complying with the training standards in place. Further, these records can be extremely handy when it comes time to conducting staff evaluations.\nPool chemicals records\nOne of the most regular items documented at an aquatic facility is water chemistry. These readings should be performed and recorded several times per day and even up to once or twice an hour.\nHistorically, these readings were written down in a notebook that was stored in the pump room. This notebook would get splashed on, have spills, may contain illegible handwriting, and even torn or missing pages. With digital documentation, the information is safely stored in the cloud for future access. Additionally, with a digital facility, managers have the added benefit of these records automatically informing him/her about any non-compliance concerns and even recommending actions for correction. These could include chemical dosage calculations or providing step-by-step instructions to remove chloramines. Digital documentation can take a facility’s chemical logs to the next level.\nWhether it is a contamination issue (i.e. a pool fouling) or weather-related, no facility manager likes to close his/her pool. However, when action needs to be taken, facility managers need to document why they closed the pool and what actions were taken to minimize potential risks.\nDepending on the reason for closure, different sets of information need to be documented. This makes it hard to create one piece of paper that can work for all situations. For example, why would a facility manager write down the last time he/she heard thunder or what time the pool was closed due to poor water quality? In these scenarios, specific forms have to be created for each reason for the closure, or blank sections need to be included on the forms.\nWith digital documentation, facility managers can use dynamic forms that only require information to be filled in that is relevant to the reason for closure. This information is complete and safely stored for future reference. Another benefit is the reports can be run to show the most common reason for closure, the frequency of closures by facility or timeline, and several other areas to help identify specific trends and gain insight.\nIllness or injurySimilar to pool closures, every illness or injury that occurs at an aquatic facility should be documented; however, not every incident requires the same information. This is where digital forms help make things easier.\nBy having a dynamic form that allows facility managers to select the type of incident, he/she now has a flexible form that is suitable for various situations. This also allows this information to be stored and securely backed up in case any of the reports need to be referenced at a later date.\nLifeguard evaluations and certifications\nAfter a lifeguard is initially trained, the facility is responsible for keeping up with the ongoing education and evaluations. Like in-service records, it becomes difficult to track who has been evaluated, what area they were tested on, how they scored during the last test, and so on.\nFor example, how does a facility manager know the lifeguard who only works on Tuesdays has had a skill review? Digital documentation helps to ensure the manager knows exactly which lifeguards have been tested and how they need to follow up with them based on his/her evaluation.\nWhether the evaluation was positive or negative, every lifeguard should be well-trained and always ready to perform throughout his/her time at the facility. By using digital documentation, this information is easily tracked and viewable.\nThe biggest benefit of using a digital tool is the ability to add supporting information and reference points. Whether it is listing out of range values for water chemistry, providing the MAHC’s procedures for handling fecal-related incidents, or just a PDF of the facility handbook, all of these items help empower the aquatic facility’s team to be the best they can be.\nEvery operator dreads the unannounced visit from the health department and the always unexpected ‘code brown,’ but in the moment of surprise it can be difficult to ensure every team leader knows exactly what to do, or where to find the binder that is buried under mounds of timesheets and shift request forms on the facility operators desk. A digital platform not only makes it easily accessible but also organized so the information is readily available and easy to find.\nAnother benefit is the ability to assign and track accountability for various items. For instance, think about how often a submitted work order can get lost in the shuffle or the number of assigned maintenance or internal auditing tasks to head lifeguards that were never completed. Whether it is work orders, internal audits, and/or chemical/facility checks, with digital documentation various users can have access to submit, receive, and review pending and completed items.Further, with tracking tools and reporting, facility managers can measure success and show improvement.\nA new generation of employees has emerged who do not want to use paper forms, but rather prefer a digital tool that is accessible, easy-to-use, customizable, and current. With digital certification tracking, certifications can be documented during the hiring process within seconds and be tracked for the duration of the employee’s tenure. It also gives potential hires the impression of a well-managed and professional aquatics department.\nFurther, in today’s world of litigation and risk, proper documentation is an integral component of any risk management system. With several options for aquatic specific digital tools, it should be easy for anyone to find a system that works for his/her facility.\nWhile there are many benefits of digital documentation, there are several hurdles any organization will need to deal with before fully adopting this type of platform. The biggest is accepting change. While the data is stored has not changed, the process and steps to complete the documentation will. Change is a good thing; however, people are naturally reluctant to do things differently, especially when it is not in his/her comfort zone. The reality is this change will come eventually, so facilities will need to plan how to best implement these documentation strategies with minimal impact to the existing staff and processes.\nAnother challenge is the concern about the safety and security of the data. While hacking and cybersecurity will always be an issue, the reality is data is much safer when it is stored digitally than on paper in a filing cabinet. Most digital companies have several levels of security and storage back up to ensure the data is as safe as possible. How many aquatic facilities have systems in place to protect its current data from fires or other natural disasters? Digital storage can be backed up in a different region or even country, and across several servers.\nAnother issue with going digital is the cost. Paying for an annual license to use a digital tool is not a current budget item for most aquatic facilities. In fact, many facility operators view his/her current documentation as free, but the reality is there is a cost in creating, storing, and using this information. For instance, who pays for the paper? What about the time spent reviewing information and creating reports for councils and boards? When all of these things are considered, digital tools, in most cases, will often end up saving aquatic facilities money.\nThe industry standard\nWith the current trends in technology improving the ability to access information and the changing landscape of aquatic operations, digital tools will eventually become a standard for all aquatic facilities. The benefits of using a web-based documentation tool can and will help improve the safety and sustainability of pools. The key for facility managers will be to find the right system that helps support his/her facility needs.\nThis article was written by Kevin Post and originally appeared on Pool & Spa Marketing [link].","Natural disasters or other emergency situations can strike at any time – often without any warning at all. Being prepared in advance for the likelihood of an emergency situation can help protect your business.\nSituations that could affect your business include fires, floods, hurricanes, tornadoes, other severe weather events, earthquakes, terrorist attacks, gas leaks and chemical spills – to name just a few.\nPreparing for different scenarios in advance and knowing what to do when an emergency unfolds can make a huge difference to your business’ survival going forward.\nWhen you carry out emergency management planning you are able to identify risks to your organization as well as what the critical areas are and what you can do to protect them.\nAn emergency management plan will also ensure you have business continuity and recovery planning processes so your organization can survive and recover from a range of emergency situations.\nTips for planning for emergencies include:\n1. Knowing what your objectives are\nIn addition to immediately responding to an emergency situation and ensuring business continuity, other objectives for your business may include hazard prevention and deterrence, regulatory compliance and risk mitigation.\nDepending on your business and the industry you work in, your objectives might be different to even the business located next door.\n2. Be thorough with your risk assessment\nExamine different hazard and threat scenarios by carrying out a comprehensive risk assessment to determine what your business is vulnerable to.\n3. Determine a range of response procedures\nWhat actions should people take in the event of certain scenarios? This should include evacuation and shelter responses as well as steps to protect life, property and assets depending on the particular emergency.\n4. Have the resources your staff need for an emergency situation\nWhat systems do you have in place to handle different potential emergency situations? This includes not just plans and processes, but investing in people, systems and equipment too.\nFor example, how would you alert all staff to an escalating emergency situation in a timely manner? Have you considered investing in a cost-effective mass notification system such as DeskAlerts to warn your employees quickly in the event of a crisis?\n5. Make sure your staff are well-trained\nYou can have the best plan in the world…on paper. But when it comes to actually carrying it out, if your staff don’t know what to do then that plan becomes useless.\nTrain your staff well to understand what they need to do in the event of an emergency. Practice it through drills and role-playing scenarios so they can jump to action when confronted with the real deal.\n6. Make sure your important data is protected\nImportant files such as contracts, company records and financial data shouldn’t live in a filing cabinet. You should have digitized versions of all of this important information – with offsite storage to boot. Remind employees that data stored on their hard drives and not on a company server or in the cloud can be lost forever in the event of a disaster."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:9b701f17-1ed9-4534-8644-82017fd2027c>","<urn:uuid:6175bd9c-f55c-48fa-933e-3b68ef55486e>"],"error":null}
{"question":"What employment and vocational support services are offered for individuals with disabilities, and what are the specific eligibility requirements for receiving provincial disability assistance?","answer":"Employment services include Employment Discovery and Customization, Job Development, Supported Employment, and transition programs for students aged 14-21. These services focus on matching individual interests and skills with employer needs, while providing ongoing support through retention specialists who offer job coaching and case management. For provincial disability assistance eligibility, individuals must qualify under the Employment and Assistance for Persons with Disabilities Act. A person with no dependent children can receive up to $975 monthly, based on income. The assessment considers the entire family unit, including the applicant and their dependents. Recipients also qualify for supplemental benefits like dental care, medical equipment, eyeglasses, and monthly bus passes.","context":["We offer a range of programs and services that enhance growth, independence, and quality of life for individuals with special needs, including children, adolescents, adults with Autism Spectrum Disorder and other developmental disabilities. Our person-centered approach emphasizes individualized care, community integration and customized employment, with the goal of empowering individuals to achieve both personal and economic independence.\nHumanim’s Day Services and Personal Support Services offer transitional and rehabilitation support to individuals so that they can take an increasingly active role in their community. Individuals create personal goals, learn skills, exercise independence, and participate in recreational activities within the community. Programming includes:\n- Community based activities\n- Volunteer opportunities\n- Social, vocational, and life skills instruction\n- Hobby and recreational supports\nOur organization was founded on the belief that every human being has potential and that work is transformative. Our employment services therefore focus on matching an individual’s unique interests and skills to the hiring needs of employers. Once employed, our retention specialists continue to work with individuals and employers to ensure job success, through case management, job coaching, advocacy, and other job supports. Services include:\n- Employment Discovery and Customization\n- Job Development\n- Supported Employment\n- Students to Employment Program (STEP), ages 18 – 21\n- Pre-Employment Transition Services, ages 14 – 21\nWe offer residential and in-home support services to individuals with developmental and neurological disabilities, and acquired brain injuries, who need support within the home environment. Our services are designed to build independence so that individuals can continue to live, learn, and work in the community.\nHumanim’s Personal Support Services works with over 125 consumers living independently in their homes by teaching a variety of daily living skills and opening the door to both community and peer integration. Our Direct Support Professionals work closely with families to ensure that the services we offer to our customers are tailored to the individual’s unique situation.\nBehavioral Support Services\nLike all of Humanim’s programs, our behavioral support services foster greater independence by equipping caregivers, individuals, and their families with tools and strategies to manage severely challenging or disruptive behaviors. These services are designed to promote community integration and personal growth, by allowing individuals to live in the least restrictive environment. Our team of licensed psychologists and professional staff are there to support individuals and caregivers through behavioral assessment, consultation, training and other supports.\nHumanim is proud to offer transportation services to individuals in its Human Services programs who do not have access to a safe mode of transportation. Humanim’s transportation vehicles are carefully regulated, and our transportation staff is highly trained in providing safe, inclusive, and comfortable transportation to all Humanim individuals. We are committed to ensuring that no person is excluded from participation in transportation services on the basis of race, color, national origin, or limited English proficiency, consistent with Title VI of the 1964 Civil Rights Act. You can read our Title VI statement policy here.\nDevelopmental Disabilities Referral Form – Download\nThese programs are funded by the Maryland Developmental Disabilities Administration.","By Ryan Lincoln\nHow to qualify for disability assistance, plus 2 strategies for keeping government benefits while receiving other financial support.\nPeople with disabilities living in B.C. can take advantage of a variety of assistance planning opportunities, from group and private insurance to federal and provincial benefits. Let’s look at disability assistance offered by the provincial government by answering these questions:\n- What government assistance is available to people with disabilities?\n- How will financial support from other individuals such as family members affect government benefits?\n- What strategies can you use to maintain government support while also receiving help from others?\nHow Provincial Disability Assistance Works\nProvincial disability assistance falls under the Employment and Assistance for Persons with Disabilities Act. It consists of two components: monthly disability assistance payments and additional government benefits.\nA person with disabilities with no dependent children can receive a maximum of about $975 per month in assistance payments. The amount is based on the individual’s income.\nIf a person qualifies for disability assistance—even if it isn’t full amount—they also qualify for supplemental benefits. Some examples: dental care, medical equipment and devices (including walkers, wheelchairs, and scooters), eyeglasses, and a monthly bus pass.\nWho Is Eligible For Support?\nTo qualify for disability assistance, the individual in question must:\nThe asset and income tests are judged on a family-unit basis. In both cases, a family unit means an applicant for or recipient of disability assistance along with their dependents. Dependents include children, a spouse, or someone who plays a parental role for the applicant’s children.\nWho is included in the family unit? It depends whether the person receiving support is also the applicant. For example, if an adult receives disability assistance from the government, it makes them both applicant and recipient. Thus, assuming they have no spouse or children, they would be the sole person included in their family unit even if they live with a parent.\nOn the other hand, if a parent receives disability assistance on behalf of an adult with disabilities, they are considered a recipient and thus part of the family unit. Because members of the unit can dramatically boost its total income, give careful thought to determining who should be the person applying for and receiving assistance.\nThe provincial asset test permits a person with disabilities and no dependent children to have $100,000 in non-exempt assets. If the individual and the rest of their family unit exceed that limit, they no longer qualify for provincial disability assistance.\nExempt assets include clothing, housing, and a motor vehicle for transportation. Using the asset exemption effectively is key to successful disability assistance planning.\nA single person can claim a monthly exemption of $800 in employment income that won’t affect their entitlement to provincial disability assistance. Any employment income above $800, and most other types of income, will reduce disability assistance dollar-for-dollar until it reaches zero. At that point, the individual is no longer eligible for disability assistance.\nBut remember: the actual calculation may differ slightly from the computation of net income for tax purposes.\nStrategies To Maintain Government Assistance\nThere are many tools available to provide financial help to an individual without reducing or eliminating their disability assistance from the government. Here, we’ll consider registered disability savings plans (RDSPs) and trusts.\nRegistered disability savings plans\nAn RDSP is a program for individuals who qualify for the disability tax credit under the federal Income Tax Act. Any income earned inside the RDSP is tax-exempt until withdrawn from the plan. Used correctly, this long-term tax deferral can be very advantageous. Besides tax deferral, opening an RDSP offers two more advantages. One, the government helps fund RDSPs through bonds and grants. Two, assets inside an RDSP or amounts withdrawn from it are exempt from the asset and income tests.\nThe beneficiary and holder of an RDSP\nAn RDSP consists of a beneficiary and a holder or holders. The holder—who sets up the RDSP and looks after it—and the beneficiary can often be the same person. Click here to read more.\nIf the beneficiary is under 19, the RDSP can only be established by a parent or guardian. Once the beneficiary turns 19, they can become a sole or joint holder of the plan. If the beneficiary of the RDSP is 19 or older and the RDSP has yet to be established, then in most situations, the beneficiary must also be the holder.\nIf you’re dealing with a child who may need help managing the RSDP, consider opening an RDSP while they are still under 19. This way the parents or guardian can be a joint holder and help ensure the funds are properly managed. In most cases, if the child turns 19, parents no longer have the option of becoming a holder.\nContributions can be made to an RDSP until the year the beneficiary turns 59. Although there’s a lifetime $200,000 contribution limit for an RDSP, there are no annual contribution limits. Once income is withdrawn, it’s included as taxable income for the beneficiary. Anyone can contribute to an RDSP with the holder’s written consent.\nThe federal government helps fund RDSPs with Canada Disability Savings Bonds and the Canada Disability Savings Grant. As long as the beneficiary is a resident of Canada and under age 50, their RDSP will qualify for government funding. Also, if you’re late in setting up an RDSP plan, a carry-forward provision allows the beneficiary to receive unused government contributions from the past 10 years.\nCanada Disability Savings Bonds\nThe federal government will contribute $1,000 per year (for a maximum of 20 years) if the income for the beneficiary’s family unit is under $26,360. If the income for the beneficiary’s family unit is higher, the $1,000 will be prorated until the annual bond is eliminated.\nCanada Disability Savings Grant\nThe federal government will also match contributions made to the RDSP. Although the amount it matches is subject to family income, there’s no income amount that eliminates the savings grant.\nIf the family unit’s annual income is less than $90,000, the government will grant $3 for every $1 contributed, up to a maximum of $500 that year. For the next $1,000, it will grant $2 for every $1 contributed, making the maximum annual grant $3,500.\nThere are two types of RDSP withdrawals: lifetime disability assistance payments and disability assistance payments. The government intended the RDSP to be a long-term savings tool, so upon a withdrawal, the holder must pay back any government funding received in the previous 10 years. The repayment is called the assistance holdback amount (AHA).\nLifetime disability assistance payments\nLifetime disability assistance payments must start when the beneficiary turns 60, but they can begin earlier. Once started, these payments must be made annually from the RDSP until all the funds are withdrawn. This method allows withdrawal of minimum—once the beneficiary is 60—and maximum amounts.\nDisability assistance payments\nDisability assistance payments (DAPs) are discretionary payments made out of an RDSP. The maximum amount is dependent on whether the RDSP is primarily funded privately or through government contributions, and whether there are enough funds in the account to cover assistance holdback amounts.\nYou can use trusts to protect the individual receiving disability benefits from the asset test. For the purposes of the test, amounts of less than $200,000 held in trust are considered exempt assets. However, if the person doesn’t have a beneficial interest in the trust, all assets held in it will be exempt.\nTrusts can be discretionary and non-discretionary. Non-discretionary trusts give the beneficiary some control over payments from the trust, or the trust agreement may require the trustee to make certain payments. Discretionary trusts give the trustee full authority to manage and spend assets for the beneficiary. Click here for more about types of disability trusts.\nTrusts set up to preserve disability benefits are often called Henson trusts (based on the case Ontario vs. Henson, 1987). Henson trusts are discretionary trusts where the beneficiary has no legal capacity to access income or capital and no power to collapse the trust. Because the beneficiary has no control over distribution of the trust assets, they are not considered to have a beneficial interest. Therefore, assets inside a Henson trust are exempt from the asset test.\nOften it makes sense to have other beneficiaries to the trust in addition to the person with disabilities. Besides making a stronger case that the person with a disability has no beneficial interest in the trust, this provides extra flexibility. For example, if the trust has to be terminated during the lifetime of the person with disabilities, the assets may be allocated to a different beneficiary, ensuring that the person with disabilities doesn’t go over the asset limit.\nQualified disability trusts\nQualified disability trusts (QDTs) are trusts that arise because of an individual’s death. One of the trust’s beneficiaries must qualify for the disability tax credit under the Income Tax Act. QDTs offer one big advantage over most other trusts: they’re taxed at graduated rates, which rise as income increases, rather than at the highest personal rate for any amount of income.\nPayments from a trust\nMost payments from a trust must be included in the income test. However, the following payments are exempt:\n- Distributions from the trust for disability-related costs.\n- Distributions from the trust for the acquisition of a family unit’s place of residence.\n- Distributions from the trust used for registered education savings plan (RESP) contributions.\n- Distributions from the trust used for RDSP contributions.\nDisability-related costs include medical devices, caregiver services, education, renovations or maintenance to a housing unit to accommodate needs resulting for a person’s disability, and any other item or service that promotes the person’s independence.\nThe bottom line? You can use trusts to pay the beneficiary’s medical expenses while preserving their disability assistance.\nAs with many planning processes, we recommend that you start early, gather all the facts, and consult with appropriate advisers.\nPosted in Strategic Insights\n- Client News\n- Estate Planning\n- Industry News\n- Seminars + Presentations\n- Strategic Insights\n- Success Stories\n- Tax Legislation\n- Tax Tips for 2016 Tax Year\n- Tax Tips for 2017 Tax Year\n- Tax Tips for 2018 Tax Year\n- Tax Tips for 2019 Tax Year\n- Walsh King\n- Walsh King Company Culture\n- Walsh King News\n- Getting the Most out of a Business Purchase or Sale\n- What I Learned During My First Three Months as an Articling Student\n- Why Due Diligence Matters When Buying a Business\n- A FEW FACTS ABOUT THE B.C. FILM INDUSTRY\n- What the Employer Health Tax Means for Your Business\n- 10 Study Tips for Surviving the Common Final Examination"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:3a15db9c-b73f-47aa-8b8f-555fc41540e3>","<urn:uuid:ab5ae26d-bf42-42b8-9366-01c068f8621d>"],"error":null}
{"question":"What activities increase survival risks in cold conditions for both deer and people?","answer":"For deer, leaving protective cover during daylight to feed in open areas increases their vulnerability, especially as they must venture out to replenish energy reserves in winter. They face additional risks when their metabolism slows and they need to bed down for extended periods. For humans, risky activities include outdoor recreation like hiking, camping, or skiing without proper preparation. People must avoid perspiring or becoming overtired during these activities, and should not use alcohol or mood-altering substances. Both deer and humans seek shelter from energy-draining wind chills - deer in dense cover like cedar bottoms or thickets, while humans need to minimize time outdoors and use appropriate wind-resistant clothing.","context":["Hunting VideosBowhunt or Die\nDeer Hunting Tips For Late Season Hunting In The Upper Midwest\nMany deer hunters hang it up for the year by late November. But as winter approaches, serious deer hunters know that snow, cold winds and dwindling food supplies often make whitetails more predictable by concentrating them in smaller areas for food and cover. That’s why early to mid-December can often produce the season’s best deer hunting.\nHere’s some tips to put you in contact with more deer during your late-season hunts.\nHope for a Quick, Bitter Chill\nA bitter cold snap that plunges temperatures into the low teens to below zero anytime from late November to mid-December can shock deer into binge-eating. The colder the air, the bigger the shock and the greater their motivation to hit food sources, causing them leave cover more readily during daylight. In contrast, if heat, rain or a gradual cooling trend eases deer into winter, you might never see an exaggerated feeding run.\nDefeat Deafening Sounds\nSounds can travel much farther – and clearer -- on cold days, so use only your most silent hunting clothes and hunting equipment for late-season hunts. Why does sound transmit so well then? It involves inversions, which result when cold, ground-level air gets trapped by warm air above. Even though sound travels faster in warm air because it’s less dense, sound waves bend while rising from cold air into warm air. Once contacting the warmer air, the sound waves rocket farther than normal. This phenomenon is especially common at dawn and dusk – peak hunting time.\nDisappear into Thin Air\nIf you can’t find a big pine, spruce, cedar or other conifer to conceal you and your tree stand, consider wearing lighter colors and more “open” camouflage patterns. Also place your tree stand between two or more tree trunks to further break up your outline. Once trees shed their foliage, darker camo patterns tend to define your outline rather than break it up.\nSurvival, Survival, Survival\nIn deciding when and where to deer hunt, realize that bucks will never be hungrier during hunting season than they are in the post-rut. Besides their increased energy demands to battle cold weather, bucks are trying to recover from rutting activity, when they shed as much as 25 to 30 percent of their weight. Still, no matter how much they eat during the post-rut, they won’t add fat. All they can do is regain energy, stamina and some muscle weight. Their bulk won’t increase again until spring green-up.\nCount on Food, Not the Second Rut\nFocus on food sources for scouting and deer hunting. The so-called second rut -- when female fawns enter doe estrus for the first time and random unbred adult does cycle a second time – can’t rival hunger pangs for sparking deer activity. True, if an estrous doe is feeding where you hunt, it might provide a breeding opportunity no buck can resist. But it was food that brought them to the same place.\nEven so... Play the Odds\nWhen female deer congregate in late-season feeding areas, a buck has a target-rich environment for locating that rare doe that’s ready to breed. If the buck finds itself so fortunate, it might follow and pester the coy female just enough to stumble within range of your tree stand.\nWork Your Way Outward\nIn choosing where to deer hunt, look to woodland cover first, and fields and food plots next as hunting pressure fades. Late-season deer usually experienced enough hunting pressure earlier in the fall to be skittish about showing themselves in daylight. If they can satisfy their energy and dietary needs within cover, there’s no reason to risk feeding in the open.\nThere’s the Buck Rub\nTake time to revisit any buck rub lines you pieced together in recent years. Once the rut concludes and bucks resume their routine travels between bedding and feeding grounds, some return to travel routes they trust. If you find signs that a buck is back on earlier patterns, give the rub line a try. Start by hunting woodland stands closer to feeding sites, and then gradually move your stands toward its daytime deer sanctuary if you’re not successful.\nScout for Acorn Caches\nAcorns are seldom widespread by late season, so focus on the few that remain. After all, the more scarce the preferred deer food, the more reliably deer key on the rare caches they find. Whitetails almost always choose naturally produced, high-energy acorns over crops grown in fields or food plots.\nBetter Late than Early\nRemember what we said about sudden cold snaps spurring feeding activity? OK, so what happens after that feeding binge ends? As the deer’s metabolism slows, they need less food. They bed early and remain bedded much of the day. Therefore, focus your efforts on late-day hunts. They’ll be as hungry then as they’ll be all day. When late-season deer venture out to replenish their energy reserves, they tend to stay in one place longer than normal to fill their rumen.\nWatch that Barometer\nNever take your eye off weather forecasts, national weather maps and your personal barometer for advance warnings of approaching storms or a dramatic change in weather patterns. Late-season deer activity usually increases just before winter storms arrive, especially if it’s the first big storm system of the season. When the barometric pressure plunges, it’s time to grab your hand-warmers, face-mask and heavy boots and be waiting when deer move out to feed. You can be sure they already know the forecast.\nCheck Every Patch, Dimple and Pimple\nWhen doing deer drives or still-hunts in agricultural regions, check out every pothole, CRP field, grassy island, brushy depression, unpicked cornfield, marsh-bound island or bull-dozed brush piles. If such sites cover a quarter-acre to five acres, and look more like cottontail cover than deer cover, check it often, preferably after posting a partner or two downwind of it.\nDeer Like it Dense\nWhether it’s a forest’s cedar bottoms or a suburb’s thicket brimming with prickly ash, grape vines and blackberry stalks, a woodland’s densest cover usually holds late-season deer. Deer retreat to these thick sanctuaries to avoid human activity and/or to escape energy-robbing wind chills. Deer hunt these retreats from downwind tree stands, or by sending in two or more drivers to push them to standers.\nCatch Them with Their Flanks Exposed\nWhen the woods or forest can’t provide adequate food and energy, food plots and agricultural fields usually offer the best feed for hungry deer. When deciding where to hunt, let the wind determine your setup. Deer prefer to enter fields with the wind behind them, using their eyes to scan the field ahead and their nose to monitor the woods behind. Whenever possible, sit with the wind quartering toward you from their expected approach.","Precautions for Cold Weather Health and SafetyContact: Beth Perrine (517) 241-2112Agency: Community Health, Department of\nJanuary 20, 2005\nWinter in Michigan is a celebrated season despite the extreme drops in temperature posing serious risks and hazards. To combat these potential dangers, there are specific guidelines citizens can follow to stay safe and healthy throughout the cold weather months.\nBe extremely careful if you use a wood stove, fireplace or space heater in your home. Always keep a multipurpose, dry chemical fire extinguisher near the area you are heating. Do not burn paper in your fireplace or wood stove and do not leak flue gas indoors. If you are using an indoor gas heater, be sure it is located in a well-ventilated space and only use the type of fuel recommended by the manufacturer.\nRegardless of the type of heating device you are using, be sure that it is up to date and meets all safety standards. Toxic fumes, such as carbon monoxide, from old or faulty heaters can cause unconsciousness or death from lack of oxygen.\nWhile inside, monitor the indoor temperature carefully. Because they lose body heat much faster than adults, infants should never sleep in a cold room. It is also necessary for older adults to take extra home heating precautions, as they tend to have slower metabolisms and therefore make and retain less heat than other adults. If you are caring for an infant or senior citizen, be sure to frequently check that their homes are adequately heated. If heating is not at a safe level, making alternative housing arrangements is recommended.\nWhen the weather is extremely cold, and especially if there are high winds, try to stay indoors. Making trips outside as brief as possible can help to reduce the potential dangers associated with cold weather. To remain healthy and safe this winter, please follow these cold-weather tips while outdoors:\n- Dress warmly and stay dry: Be sure to dress in layers in wind resistant clothing. Wool, silk or polypropylene inner layers will hold more body heat than cotton. If your clothing is wet, go inside as soon as possible. When inside, remove the wet clothing as soon as possible.\n- Avoid exertion: Cold weather can put extra strain on the heart. If you have heart disease or high blood pressure, follow your doctor’s advice about shoveling snow or other hard work in the cold. The body is already working hard to stay warm, so extra work can cause an overload.\n- Cover exposed skin: Always wear a warm hat that covers ears, gloves or mittens that cover the full wrist, and a scarf or ski mask to protect face and neck.\n- Be Safe During Recreation: Notify friends and family where you will be before you go hiking, camping, or skiing. Avoid perspiring or becoming overtired. Be prepared to take emergency shelter. Pack dry clothing, a two-wave radio, waterproof matches and paraffin fire starters with you. Do not use alcohol and other mood altering substances, and avoid caffeinated beverages. Carefully watch for signs of cold-weather health problems. It is important to be aware of any changes in exposed skin during cold weather periods.\nFrostbite and hypothermia are very serious conditions that can be lessoned by early recognition and treatment. Shivering can be a good indicator that it’s time to go in, as it is the first sign that the body is losing heat.\nFrostbitten skin is hard, pale, cold and has no feeling. When the frostbitten skin is in warm air, it will become red and painful. Very severe frostbite can cause blisters, gangrene (blackened dead tissue), and deep tissue damage in tendons, muscles, nerves and bones.\nHypothermia is a life-threatening condition that is caused by short exposure to extreme cold or long exposure to mild cold. Symptoms of hypothermia include trembling, stiffness of muscles, puffiness in the face, poor coordination, confusion, and low consciousness and reactivity.\nIf you suspect frostbite, hypothermia or other complications surrounding extreme weather, seek emergency medical care immediately."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:02491699-10b9-4fbd-82f8-e94e0e48ef38>","<urn:uuid:17dbe6de-62e6-4e03-9ee7-2fc52740350b>"],"error":null}
{"question":"Are both the caryatid statues at the Erechtheion in Athens and the shoes at the Danube memorial in Budapest original artifacts from their respective historical periods?","answer":"No, neither are original artifacts. The caryatid statues at the Erechtheion are replicas, with the originals being displayed at the Acropolis Museum. The Shoes on the Danube is a modern memorial created by film director Can Togay and sculptor Gyula Pauer to commemorate Jews killed during World War II, not actual shoes from that period.","context":["Commonly referred to as the Paris of the East, Budapest is the capital of Hungary and an increasingly popular European travel destination.\nBudapest is filled with attractions that will keep you busy for days. With its enchanting castles, unparalleled riverfront, ruin bars, and everything in between, Budapest won’t leave you looking for things to do.\nBut beyond its main attractions, Budapest is home to numerous hidden gems tucked away in its streets, waiting to be discovered.\nMaybe you love to go off the beaten path, or maybe this isn’t your first time in Budapest. Whatever the reason, be sure to check out these eight cool hidden gems when traveling to the Hungarian capital.\n1. Gül Baba Street\nYou’ll only find Gül Baba Street, a steep cobblestone road near Margaret Bridge, if you’re looking for it. Though this street is located far away from the hustle and bustle of the city, it is one of the most historically significant streets in the entire capital.\nFrom 1541 to 1686, the majority of Hungary, Budapest included, was occupied by the Turks. Gül Baba, the Turkish holy man and Ottoman Bektashi dervish poet who, according to legend, introduced Hungary to roses, died in Budapest in 1541. The street named for Baba ends at his tomb, which is now located in a museum and is a popular Muslim pilgrimage site.\nGül Baba is known for being one of the steepest streets in all of Budapest, so be sure to wear comfortable walking shoes!\n2. For Sale Pub\nFor Sale Pub, which allows pubgoers to leave their mark on its walls, floors, and even ceiling, is undeniably one of Budapest’s most unique bars.\nWalking into For Sale Pub is kind of like walking into the Twilight Zone. This Budapest bar is covered from floor to ceiling in small pieces of paper — drawings, notes, business cards, paintings, pictures, and other mementos. The floor is covered in straws, and visitors are encouraged to throw their complimentary peanut shells directly onto the ground.\nCome to For Sale Pub for some great Hungarian beer and leave your mark on its walls.\n3. Shoes On The Danube\nOne of Budapest’s most moving memorials, Shoes on the Danube honors the Jews who were killed by fascist militiamen in Budapest during World War II. During the war, Jews were forced to remove their shoes so that when they were shot and killed, their bodies would easily drift away along the river. The memorial was created by film director Can Togay and the sculptor Gyula Pauer.\nWhile it’s hard to visit Budapest without strolling along the Danube, many pass by this memorial without even noticing it — or simply wonder what a bunch of old shoes are doing sitting at the edge of the river.\nThis chilling memorial serves as a reminder of those innocent victims of war and of the dark days the city experienced during World War II.\n4. House Of Hungarian Art Nouveau\nA museum dedicated entirely to the Hungarian Art Nouveau style, the House of Hungarian Art Nouveau recalls the beginning of the 20th century, a time when Art Nouveau flourished throughout the country.\nArt Nouveau is a style of decorative art, architecture, and design that was prominent in Europe from the late 1800s until World War I. At the House of Hungarian Art Nouveau, everything from the building itself to the jewelry sold in the gift shop represents Art Nouveau.\nThe House of Hungarian Art Nouveau is open Monday through Saturday from 10 a.m. to 5 p.m. and is closed on Sunday. Admission to the museum costs 1,500 forints ($5.40).\n5. Vajdahunyad Castle\nWould you believe it if we told you that Budapest is home to a castle that was originally built entirely out of cardboard and wood? Well, you should.\nVajdahunyad Castle was constructed by Ignác Alpár in 1896 to commemorate the 1,000-year anniversary of the settlement of the medieval Magyars on the plains of Pannonia. The exhibition, intended to be temporary, was constructed out of wood and cardboard, but it was so popular that it was later converted to stone and made permanent.\nThe castle showcases four distinct styles of Hungarian architecture that represent the evolution of architecture in Hungary over the centuries.\nVajdahunyad Castle is open Tuesday to Sunday from 10 a.m. to 5 p.m. and is closed on Monday. Admission to the castle costs 1,600 forints ($5.75) for adults and 800 forints ($2.88) for students and senior citizens.\n6. The Buda Hills\nFor those yearning for some outdoor adventure and scenic beauty, head for the hills!\nThe Buda Hills, situated on the Buda side of Budapest, offer an abundance of hiking trails and breathtaking panoramic views of the city.\nJános-hegy is the highest point of Buda Hills and the most popular scenic area. To reach János-hegy, take the Zugliget Chairlift. Built in 1970, the chairlift is one of the most legendary of Budapest’s lesser-known attractions. Slowly ascending over lush green hills, the chairlift provides visitors the most spectacular views of the capital city.\n7. Terror Háza\nA museum dedicated to the terror regimes of Hungary, Terror Háza, also known as the House of Terror Museum, was purchased in 2000 by the Public Foundation for the Research of Central and East European History and Society. The organization strives to recreate for visitors the political brutality victims faced for decades in Hungary.\nArchitects worked together to restore the building to its original dreariness and create a multisensory experience for visitors.\nTerror Háza features permanent and temporary exhibitions, photographs, historical mementos, and videos that portray what it was like to live during those dark periods in Hungarian history.\nThe museum is open Tuesday to Sunday from 10 a.m. to 6 p.m. and is closed on Monday. Admission to the museum costs 3,000 forints (USD $10.79).\n8. Füvészkert Botanical Garden\nFounded in 1771, Füvészkert Botanical Garden is Hungary’s oldest botanical garden. It features more than 8,000 plant species spread over more than 8.6 acres of greenhouses and lush parks. It is best known for its lilies, bromeliads, cacti, and palms.\nThe botanical garden features more than 400 species of Hungarian flora, more than 200 endangered plants, and a palm house with tropical and subtropical plants. Each April, Füvészkert Botanical Garden hosts a beautiful cherry blossom festival.\nThe botanical garden is open daily from 9 a.m. to 4 p.m. Admission to the gardens costs 1,000 forints ($3.60).","I always find myself awed by grandiose edifices. Beholding the Parthenon up close, unfailingly grandiose despite its ruined state blended with a construction site, made the visit to Acropolis instantly worthwhile.\nBuilt in the 5th century BC to honor goddess Athena, the patron of the city, the temple survived rise and fall of empires and had reincarnations as a church and a mosque, until grave damage was done to it at the end of the 17th century AD during hostilities between the Ottoman Empire and the Venetian Republic. In the early 19th century, representatives of the British Empire removed almost all of the then-remaining marble statuary, leaving the grand temple as an empty shell, which nonetheless retains the status of a signature piece of Doric architecture.\nAcropolis, of course, is not just about the Parthenon. The monumental complex is an enduring symbol of the classical antique civilization that gave birth to many forms of art and schools of thought that we value today.\nOne of the other important monuments in Acropolis is the Erechtheion, which is just a few decades younger than the Parthenon.\nThe temple is associated with a number of sacred relics of the Athenians, including the olive tree that sprouted when Athena struck the rock with her spear in her successful rivalry with Poseidon for the city. The present-day tree, seen by the side of Erechtheion, is a nice link to the legend, even though it was only planted a hundred years ago.\n“The Porch of the Maidens”, with six caryatids supporting the roof, is easily among the most eye-catching features of the Acropolis. The figures are all replicas, though; the originals are on display at the Acropolis Museum.\nThere are several other monuments on the hilltop and the southern slope of Acropolis. These are the remains of the temple of Asclepios.\nOne of the two major theaters, Odeon of Herodes Atticus.\nA statue near the Theatre of Dionysus.\nBeing in the center of the ancient city, Acropolis offers elevated perspectives on all other points of interest in Athens, such as this familiar to us temple of Olympian Zeus.\nThe building in this perspective is the new Acropolis Museum, which is still less than 10 years old.\nIt requires a separate fee to enter and undoubtedly has a lot to offer, but we chose to leave it off our itinerary. The Acropolis treasures that currently reside in the British Museum in London – where we saw them several times during our time of living in the UK – are a gaping hole in the museum’s collection, and the Greek government have been waging an understated battle for over three decades now to have them returned to their rightful home. When they are returned to Greece, the museum will become an essential companion to the World Heritage site.\nA perspective towards Mount Lycabettus.\nAnd a dawn view towards both Acropolis and Lycabettus from another high hill, Philopappos.\nAcropolis is the focal point of Athens, unmissable if you spend any time in the city. Ticket lines can get pretty long in the middle of the day, so either come right before the opening or wait until 5pm or so; only right after the opening and right before the closing time will you have a chance of not sharing the site with hundreds of other tourists. Of the two main entrances, the southern one has shorter lines at all times of the day. Minimum of one hour is needed to see all there is to see; if you let the awe overtake you, it could be quite longer."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:af91fc34-0370-4565-a6c5-5f56133ae9ea>","<urn:uuid:c7deaa10-7162-4916-b45a-bb39da669ad8>"],"error":null}
{"question":"I'm fascinated by great rivers and their influence on human society. Could you compare how the Mississippi and Amazon rivers have shaped their respective regions in terms of historical significance, cultural impact, and physical characteristics?","answer":"Both the Mississippi and Amazon rivers have been monumentally influential, though in different ways. The Mississippi River has been crucial to U.S. development, dividing the country into east and west while serving as a portal to western expansion, symbolized by the Gateway Arch in St. Louis. It has deeply influenced American culture, featuring prominently in the works of Mark Twain and William Faulkner, and has been central to the nation's growth by providing transportation of goods and services through its extensive network of ports. Physically, it runs from Minnesota to the Gulf of Mexico, crossing ten states. The Amazon River, in comparison, has an even more massive physical presence, being the world's widest river - expanding from 6.8 miles in the dry season to 24.8 miles in the wet season. Its basin influences multiple South American countries including Brazil, Peru, Columbia, Ecuador, Bolivia, and Venezuela, with Brazil containing most of the basin. The Amazon's name itself reflects European exploration history, named by Francisco de Orellana after fierce female warriors he encountered. Both rivers have been vital for indigenous peoples, exploration, and continue to be essential waterways in their respective regions.","context":["Map Of The Mississippi River\nHere we will provide you with maps of the Mississippi River. The river is so large that we felt it necessary to provide multiple maps of this diverse region.\nAs you may well know the River is so large that it actually splits the Unites States in half. Here is a map of the Mississippi River that illustrates that fact:\nAnd since the River is so long, stretching from Minnesota to the Gulf of Mexico, here are two maps. One map will show the Upper Mississippi River and the other the Lower Mississippi River:\nThe Mississippi RIver is such an important waterway for transporting goods and services, here is a map of the ports that are located in Louisiana:\nThese maps should provide you with a great perspective on this wonderful River. “Old Man River,” “Big Muddy,” “Fathers of Waters,” and the mighty Mississippi, all refer to the longest river in North America. Historians believe the name is based on Native American descriptions of the great waterway. No matter what name people use for it, there are a number of reasons the Mississippi River is one of the United States’ defining geographic features. That is the reason we have provided so many maps here for you to enjoy.\nThe river neatly divides the country into east and west, and its place in history as the portal to the west, is exemplified by the dramatic Gateway Arch in St. Louis. More recently, critics and fans alike use terms like “East Coast” and “West Coast” to describe hip hop’s primary division. Further, individuals routinely think of the country as divided by the Mississippi, despite the fact that the waters have not been an impediment to travel for many years.\nNo less than ten states share at least one shore with the river and, more impressively, the Mississippi and its tributaries drain more than half of all U. S. states. It is the fourth longest river in the world. These dramatic features could not help but impact the country’s growth, and cement a place for it in the nation’s culture and mythology. The maps above show those tributaries and the vast length of the river.\nThe maps above show how the Mississippi follows begins in Minnesota, then continues almost directly south meeting the states of: Wisconsin, Iowa, Illinois, Kentucky, Missouri, Tennessee, Arkansas, Mississippi and finally slices through Louisiana, and emptying into the Gulf of Mexico. Six tributaries of the main river, the Missouri, Illinois, Arkansas, Ohio, Tennessee and Red Rivers further subdivide the country, and during its primary growth phase, the main river and tributaries provided means for the rapid movement of people and supplies.\nWhile the Mississippi bisects the country, the state of Louisiana is divided by both the mighty river and the Atchafalaya River, an important fact given the larger river’s tendency to deviate towards the smaller. A permanent change in the Mississippi’s course would have innumerable consequences for the Delta area generally, and Louisiana specifically.\nNative Americans, explorers, river boat captains, businessmen and writers all helped create the great river’s image. Two of the nation’s most storied authors, Mark Twain and William Faulkner, used the Mississippi in their works. In fact, for Twain, the it is all but a cornerstone for his writings. For authors, and the nation, the waterway was, and perhaps always shall be, a symbol of the country’s dynamic growth and accomplishment.\nWe hope you find these maps of the Mississippi River helpful.","The Amazon River is a heck of a big tributary. Besides being one of the LONGEST rivers in the world, it also happens to be the WIDEST. While its estimated length of 4,000 miles (6,400 kilometers) puts it under the Nile River, that statistic could be amended as some believe it’s even longer than that.\nNevertheless, its width puts it at a big river that carries more volume than the Nile. We have a few more facts about the Amazon below.\nAccording to Extreme Science, even during the dry season it is about 6.8 miles (11 kilometers) wide, which is still a respectable width. When things get rainy, however, that’s when stuff really begins to open up. It more than doubles its width to 24.8 miles (40 kilometers).\nIf that’s enough for you, consider the amount of land it covers. Dry season, Extreme Science says, sees it at 42,471 square miles (110,000 square kilometers), or roughly the land area of Cuba. That astonishing statistic triples during the wet season, when it reaches 135,135 square miles (350,000 square kilometers) — about approximate to Germany’s size.\nAll of this makes the South American river the largest drainage system in the world, according to Encyclopedia Britannica. Its recorded source is in the Andes Mountains and it flows down to its Atlantic Ocean mouth off the coast of Brazil. But as we’ve noted before, there’s controversy both to its source and to its actual length.\nThe Amazon basin (the areas that are affected by the river) cover a good portion of South America, the encyclopedia adds: Brazil, Peru, Columbia, Ecuador, Bolivia and Venezuela. But it’s Brazil that has most of the basin and two-thirds of the stream.\nAboriginals in the region have explored the river for centuries, but its name comes from European exploration of the river, the encyclopedia says. “Amazon” is a reference from Europe’s first reported explorer, Spanish soldier Francisco de Orellana, who said the fierce female warriors in battle in the area reminded him of Amazons in Greek mythology.\nMany of these statistics could change if the source of the Amazon River is also changed. National Geographic says there at least six possible origin points, based on methods ranging from satellite observation to GPS to “ground truth” examinations. You can see more details about the ongoing quest in this article.\nUniverse Today has articles on the longest river and Europe’s longest river. Astronomy Cast has an episode on Earth you should watch.\nPlanet Earth boasts some very long rivers, all of which have long and honored histories. The Amazon, Mississippi, Euphrates, Yangtze, and Nile have all played huge roles in the rise and evolution of human societies. Rivers like the Danube, Seine, Volga and Thames are intrinsic to the character of some of our most major cities.\nBut when it comes to the title of which river is longest, the Nile takes top billing. At 6,583 km (4,258 miles) long, and draining in an area of 3,349,000 square kilometers, it is the longest river in the world, and even the longest river in the Solar System. It crosses international boundaries, its water is shared by 11 African nations, and it is responsible for the one of the greatest and longest-lasting civilizations in the world.\nOfficially, the Nile begins at Lake Victoria – Africa’s largest Great Lake that occupies the border region between Tanzania, Uganda and Kenya – and ends in a large delta and empties into the Mediterranean Sea. However, the great river also has many tributaries, the greatest of which are the Blue Nile and White Nile rivers.\nThe White Nile is the source of the majority of the Nile’s water and fertile soil, and originates from Africa’s Great Lakes region of Central Africa (a group that includes Lake Victoria, Edward, Tanganyika, etc.). The Blue Nile starts at Lake Tana in Ethiopia, and flows north-west to where it meets the Nile near Khartoum, Sudan.\nThe northern section of the Nile flows entirely through the Sudanese Desert to Egypt. Historically speaking, most of the population and cities of these two countries were built along the river valley, a tradition which continues into the modern age. In addition to the capitol cities of Juba, Khartoum, and Cairo, nearly all the cultural and historical sites of Ancient Egypt are to be found along the riverbanks.\nThe Nile was a much longer river in ancient times. Prior to the Miocene era (ca. 23 to 5 million years ago), Lake Tangnayika drained northwards into the Albert Nile, making the Nile about 1,400 km. That portion of the river became blocked by the bulk of the formation of the Virunga Mountains through volcanic activity.\nBetween 8000 and 1000 B.C.E., there was also a third tributary called the Yellow Nile that connected the highlands of eastern Chad to the Nile River Valley. Its remains are known as the Wadi Howar, a riverbed that passes through the northern border of Chad and meets the Nile near the southern point of the Great Bend – the region that lies between Khartoum and Aswan in southern Egypt where the river protrudes east and west before traveling north again.\nThe Nile, as it exists today, is thought to be the fifth river that has flowed from the Ethiopian Highlands. Some form of the Nile is believed to have existed for 25 million years. Satellite images have been used to confirm this, identifying dry watercourses to the west of the Nile that are believed to have been the Eonile.\nThis “ancestral Nile” is believed to be what flowed in the region during the later Miocene, transporting sedimentary deposits to the Mediterranean Sea. During the late-Miocene Era, the Mediterranean Sea became a closed basin and evaporated to the point of being empty or nearly so. At this point, the Nile cut a new course down to a base level that was several hundred meters below sea level.\nThis created a very long and deep canyon which was filled with sediment, which at some point raised the riverbed sufficiently for the river to overflow westward into a depression to create Lake Moeris southwest of Cairo. A canyon, now filled by surface drift, represents an ancestral Nile called the Eonile that flowed during the Miocene.\nDue to their inability to penetrate the wetlands of South Sudan, the headwaters of the Nile remained unknown to Greek and Roman explorers. Hence, it was not until 1858 when John Speke sighted Lake Victoria that the source of the Nile became known to European historians. He reached its southern shore while traveling with Richard Burton on an expedition to explore central Africa and locate the African Great Lakes.\nBelieving he had found the source of the Nile, he named the lake after Queen Victoria, the then-monarch of the United Kingdom. Upon learning of this, Burton was outraged that Speke claimed to have found the true source of the Nile and a scientific dispute ensued.\nThis in turn triggered new waves of exploration that sent David Livingstone into the area. However, he failed by pushing too far to the west where he encountered the Congo River. It was not until the Welsh-American explorer Henry Morton Stanley circumvented Lake Victoria during an expedition that ran from 1874 to 1877 that Speke’s claim to have found the source of the Nile was confirmed.\nThe Nile became a major transportation route during the European colonial period. Many steamers used the waterway to travel through Egypt and south to the Sudan during the 19th century. With the completion of the Suez Canal and the British takeover of Egypt in the 1870s, steamer navigation of the river became a regular occurrence and continued well into the 1960s and the independence of both nations.\nToday, the Nile River remains a central feature to Egypt and the Sudan. Its waters are used by all nations that it passes through for irrigation and farming, and its important to the rise and endurance of civilization in the region cannot be underestimated. In fact, the sheer longevity of Egypt’s many ruling dynasties is often attributed by historians to the periodic flows of sediment and nutrients from Lake Victoria to the delta. Thanks to these flows, it is believed, communities along the Nile River never experienced collapse and disintegration as other cultures did.\n[/caption]The largest river in the world can be hard to calculate. Many factors come into play: the source, the identification of the mouth, and the measurement of the river length between source and mouth. As a result, the measurements of many rivers are only approximations. So, there has been disagreement whether the Amazon or the Nile is the world’s largest river based on the inclusion of estuaries.\nThe mouth of a river is hard to determine in cases where the river has a large estuary that gradually widens and opens into the ocean. The source of some rivers starting in farming areas can be difficult to determine, if the river is formed by the confluence of several farm field drainage ditches which only contain water after rain. Similarly, in rivers starting in a chalk area the length of the upper course which is dry varies with how high the water table is. How large a river is between source and mouth may be hard to determine due to issues of map scale. Small scale maps tend to generalize more than large scale maps. In general, length measurements should be based on maps that are large enough scale to show the width of the river, and the path measured is the path a small boat would take down the middle of the river.\nGiven, and despite, this ambiguity, the Nile has been determined to be the largest river in the world followed by the Amazon and the Yangtze. The Nile is a north-flowing river in North Africa. It is 6,650 km long. It has two major tributaries, the White Nile and the Blue Nile. The Blue Nile is the source of most of the water and fertile soil in the system. The White Nile is longer and rises in central Africa beginning in Rwanda. The two rivers meet near the Sudanese capital of Khartoum. The northern section of the Nile flows almost entirely through desert. Most of the ancient civilizations of the area were centered along the river’s banks. The Nile ends in a large delta that empties into the Mediterranean Sea.\nThe debate over which is the largest river in the world seems to be over for now. The Nile is 250 km larger than the Amazon. Both rivers have played important roles in the evolution of the civilizations that sprang up around them and will continue to do so for centuries to come."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:a290e9db-eb8c-4f79-8b0f-e9d198bd4409>","<urn:uuid:a944b86b-0f78-439b-96de-8ff034d9fead>"],"error":null}
{"question":"As a climate policy researcher, I need to understand how climate change affects water resources and vulnerable populations. What are the main water-related risks from climate change, and how do they specifically impact people in poverty?","answer":"Climate change creates several major water-related risks: coastal and river flooding, changes in water availability, drought risks, salinization of deltas, and increased urban flooding risks. These impacts disproportionately affect people in poverty - cyclones and frequent droughts often hit communities where poor people live, floods from rising sea levels force them to abandon their homes, soil salinization destroys their crops, and ocean acidification threatens their livelihoods. These populations are particularly vulnerable since they have fewer means to protect themselves, despite being least responsible for causing climate change.","context":["Addressing the consequences of climate change without ignoring or harming people living in poverty\nPeople who are most vulnerable to the adverse consequences of climate change are the least responsible for its causes and have fewer means to protect themselves from it. Cyclones and frequent droughts often hit the communities and countries where people in situations of poverty live. Floods due to rising sea levels force them to leave their homes and land. Soil salinization destroys their crops and ocean acidification threatens their livelihoods.\nSince COP 21 (the 21st United Nations Conference on Climate Change), ATD Fourth World has focused its advocacy on demanding that the mechanisms and provisions required by the Paris Agreement, adopted in 2015, take into account populations in situations of extreme poverty so that climate actions are also aimed at eradicating poverty. ATD has therefore partnered with other international NGOs to urge that the implementation rules of the Paris Agreement explicitly include human rights obligations to protect the most vulnerable populations. However, the final ‘Rulebook’ adopted at COP24 in Katowice, Poland, contains little rights-base language.\nAll the same, growing mobilization throughout the world has shown governments that their citizens are ready to take up the challenges of climate change, and will push them to step up their climate commitments.\nATD Fourth World will continue to work for climate justice. Advocacy will highlight how measures taken in response to climate change may negatively impact people living in poverty, especially if they are left out of the design and implementation process. It is imperative that “clean energy” programs prioritize the most vulnerable communities and ensure that they benefit from training and jobs that the “green economy” creates. ATD Fourth World argues that a “Just Transition” should not be limited to contractual relations between employees and employers, so that it would not leave out the significant number of people with precarious jobs in the informal sector around the world.\nIn the area of climate financing, ATD Fourth World has requested an accountability mechanism that allows affected people to obtain remedy for the damage caused by programs supported by the Green Climate Fund. ATD has also stressed that climate programs often ignore the ability of people and communities in poverty to provide solutions. Therefore, ATD recommends supporting projects of indigenous peoples and local communities that rely on traditional knowledge and patterns of subsistence.\nOne of ATD Fourth World’s priorities is to promote “a people-centered and earth-friendly economy”. It is important for others to be aware that people in extreme poverty are already working to overcome the effects of climate change, and they have ideas to address its problems. At their own level, these efforts contribute to an ecological transition.\nEffective climate initiatives to achieve the “Leave no one behind” overarching principle of the 2030 Agenda for Sustainable Development must:\n- Involve people living in poverty in designing strategies for prevention, mitigation or adaptation;\n- Ensure that people living in poverty have access to better energy and technology options as well as new scientific developments and products that can improve their standard of living;\n- Include policies that avoid or reduce the adverse impacts of climate projects on people living in extreme poverty and their communities.","Presentation on theme: \"Willem Ligtvoet, January 12 1 Climate change and Water Management Policy options for the future.\"— Presentation transcript:\nWillem Ligtvoet, January 12 1 Climate change and Water Management Policy options for the future\nWillem Ligtvoet, January 12 Climate Change and Water Management 2 Climate change – dealing with uncertainties Temperature rise Sea level rise Precipitation patterns River discharges – averages and peak discharges Storm surges and hurricanes\nWillem Ligtvoet, January 12 Climate Change and Water Management 3 Risks with respect to water management Changes in flood risks: coastal and river areas Changes in water availability and drought risks Salinization of deltas Increased risks of urban flooding According to IPCC effects of climate change may be prominent in second half of 2100 (IPCC, 2008)\nWillem Ligtvoet, January 12 Climate Change and Water Management 4 Trend in weather-related disasters 1980-2009 -Data do not allow conclusions about relationship climate change and disasters -Corrected for population growth and economic growth there is a stabilization Source: Visser et al., in prep 2010-2050 -Population growth by 1/3 up to 9 billion -Further economic growth Vulnerability increases Water demand increases\nWillem Ligtvoet, January 12 Climate Change and Water Management 5 World water resources Salt water1,05 billion km397,5% Freshwater 35 million km3 2,5% Available for use <1 % Source: UNEP; WWAP\nUncertainties availability demand: tipping points Resource variability time water demand 2030 2050 Options: -Increase resource *water harvesting *de-salinization - Increase resource efficiency *households *industries *agriculture Result: - Reduced vulnerability - Buying time water quantity\nFreshwater use world wide Households 8% Industry22% Agriculture70% 20% of agricultural area => 40% of food production 80% agricultural area rainfed Source: UNEP; WWAP Irrigation increases crop production factor 2-5\nRelevant drivers increasing pressure on water Population growth up to 9 billion people with 70% in cities Economic growth and increasing wealth Growth of food production (irrigation, nutrients, pesticides) Changes in diet: more meat increases water demands Globalisation and liberalisation => shift of food production from dry areas to wet areas Biomass production: water demand >> rice and wheat Climate change\nWater demand 2000-2050 increases Source: PBL in OECD\nPopulation lacking access to improved watersupply UrbanRural Source: PBL in OECD\nPopulation lacking access to improved sanitation UrbanRural Source: PBL in OECD UrbanRural\nShift of food production increases water stress Source: PBL in OECD; WUR Saoudi Arabia -> Ethiopia food Soedan China, Korea, Japan -> Africa food, biomass Brasil -> Mozambique biomass sugercane Europe food/biomass\nWater embedded in complex interactions Urban developments Rural & Nature developments Capital driven agriculture water land conversion labour emissions food migration capital land conversion capital food …. Export - food - biomass international networks Food import national & foreign investors Water and food- security not only a matter of water\nRole of water management Main drivers out of reach Water needs to be integrated in economic analyses - optimizing crop per drop (production/m3, $$ /m3) - $$/m3 agriculture $$/m3 competing activities - $$ ecosystemservices - … Contribution to fair sharing: between nations, between people, between sectors (nature, ecosystems) Basis: analysis on scale of river basins!\n+ complex thematic interactions Land use Water use\nWide variety of policy instruments - Information – behavioural changes - Standards waterquality * nutrients * other emissions - Water permits, water rights - Land use planning - Technology * improving resource eff. * de-salinisation - Cutting perverse subsidies - Introduce positive subsidies -…..\nWillem Ligtvoet, January 12 Climate Change and Water Management 20 Future challenges Strategic -Integration of water and climate in economical and political strategies -Powerfull economical analyses on river basin scale for informed decisions on water allocation and use (River Basin Committees National governments) -Water is cross-cutting issue: supra-sectoral approach required within context of water basins -Guiding principles: sustainable use and fair sharing Technology -Sharp improvement of resource efficiency especially in agriculture -De-salinization based on renewable and cheap energy -Water-harvesting techniques -…………\nWillem Ligtvoet, January 12 Climate Change and Water Management 21 Enormous geographical differences No silver bullets – area-specific analyses and approaches needed Physical system Economic system Political/societal system What?How?\nWillem Ligtvoet, January 12 Climate Change and Water Management 22"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:32bed2dd-dec2-41fa-a17c-4d2e5a67682a>","<urn:uuid:3a2bcc7c-89de-4771-8285-0827ae6afb92>"],"error":null}
{"question":"How do spatially embedded networks model connectivity patterns, and what role do weak ties play in the diffusion of information across these networks?","answer":"Spatially embedded networks model connectivity based on the distance between network nodes, applicable to real-world systems like the Internet and social networks. These networks help analyze how spatial embedding mediates network structure, with connectivity depending on the distance between nodes. As for the role of weak ties in diffusion, they significantly accelerate information spread. In networks with weak ties, information can jump across distant parts of the network rather than spreading only to nearby nodes. For example, while information takes 14 days to spread through a purely clustered spatial network, it only takes 5 days when some weak ties are present. When all ties are rewired to create weak connections, redundancy is minimized and each new person reached creates exponentially more new exposures.","context":["Spatially-embedded random networks: Mathematical framework\nMany real-world networks analysed in modern network theory have a natural spatial element; e.g. the Internet, social networks, neural networks, etc. Yet, aside from a comparatively small number of somewhat specialised and domain-specific studies, the spatial element is mostly ignored and, in particular, its relation to network structure disregarded. In work in collaboration with Lionel Barnett and Seth Bullock, we have introduced a model framework to analyse the mediation of network structure by spatial embedding; specifically, we have modelled connectivity as dependent on the distance between network nodes. Our Spatially Embedded Random Networks (SERN) construction is not primarily intended as an accurate model of any specific class of real-world networks, but rather to gain intuition for the effects of spatial embedding on network structure; nevertheless we are able to demonstrate, in a quite general setting, some constraints of spatial embedding on connectivity such as the effects of spatial symmetry, conditions for scale free degree distributions and the existence of small-world spatial networks.\nOne interesting result is the lack of transition to a giant component. Below: Fraction of network occupied by largest component plotted against mean connectivity with increasing network size, for several Generalised Random Geometric Graphs (GRGGs: spatial networks with truncation decay in spatial connectivity), estimated in sample. The small arrow marks the value estimated connectivity for the phase transition to the appearance of a giant component for a uniform GRGG of corresponding dimension. Sample sizes are large enough that standard error bars are insignificant.\nBarnett, L., Di Paolo, E. A., and Bullock, S. (2007) Spatially embedded random networks. Phys. Rev. E., 76, 056115.\nBullock, S., Barnett, L. and Di Paolo, E. A. (2010) Spatial embedding and the structure of complex networks, Complexity, 16(2): 20 – 28, doi:10.1002/cplx.20338.\nRipple-spreading algorithm for network design\nRipple-spreading modelling is a novel approach inspired by the natural ripple-spreading phenomenon on fluid surfaces invented by Xiaobing Hu. It has good potential as an encoding scheme for modeling random complex networks using stochastic optimization and improving the performance of such genetic algorithms for combinatorial optimization problems. Suppose a bunch of stakes are randomly distributed in a quiet water pool. Then a stone is thrown into the pool and an initial ripple is generated from the point where the stone enters the water. When the ripple reaches a stake, a new ripple is generated around the stake due to wave reflection. As the initial stimulating ripple is spreading, more and more responding ripples are stimulated around stakes. This can be used to create connections (e.g., network links) between the spatio-temporaly distributed nodes.\nAn energy decay model for the spreading ripples can be used to determine connectivity or probabilities of connectivity in stochastic or semi-stochastic versions of the model. The advantage of this idea (also used for optimization problems like multi-objective scheduling in ATC where complex solution encodings create a consistency problem for operators like crossover) is that only a very simple encoding is necessary (the coordinates of the epicentre of the ripple-spreading process). Different networks are created from a same spatial distribution of nodes depending of this initial parameter.\nHu, X-B. Wang, M., Leeson, M. S, Hines, E. L., and Di Paolo, E. A. (2011) A Deterministic Ripple-Spreading Model for Complex Networks, Physical Review E, 83, 046123, doi: 10.1103/PhysRevE.00.006100.\nHu, X-B., Di Paolo E. A. and Barnett, L. (2008). Ripple-spreading model and genetic algorithm for random complex networks: Preliminary study. In The World Congress on Computer Intelligence (WCCI2008), Hong Kong, China, 01-06 June 2008.","Chapter 2 – Understanding Diffusion\nThese “computational experiments” test the dynamics of word-of-mouth diffusion on three different networks—a clustered spatial network (shown in fig. 2.9), a partially rewired network with a few weak ties (shown in fig. 2.10), and a random network composed entirely of weak ties (shown in fig. 2.11)\nAt the beginning of each of the three experiments, all of the nodes (except the two initial seeds) are unactivated, as shown in gray. They have not yet adopted the behavior. The two seed nodes are shown in black. They are the social innovators who initiate the diffusion process. Diffusion follows a basic social transmission rule. As with any word-of-mouth process, the only way that persons can become activated is by coming into contact with an activated neighbor. When activated, nodes turn black and pass the word along to their neighbors. Diffusion continues until the social contagion has spread through the entire network. In each of these simulations everyone has four neighbors, that is, two neighbors on the left and two on the right.\nFigure 2.9: Diffusion in a Large World\nFigure 2.9 shows that when the diffusion process is initiated, information spreads from the seed nodes to the neighbors on both sides. From there, it spreads to the neighbors’ neighbors, and so on around the network. By the end of the diffusion process in figure 2.9, it takes fourteen days for word of mouth to spill over from one neighborhood to the next, until it ultimately reaches the entire population.\nThings get more interesting when we add some weak ties. Figure 2.10 repeats the diffusion experiment, except this time a few of the connections have been randomly rewired to create long-distance ties in the network. It is important to remember that the overall number of ties remains the same—everyone still has four neighbors. The only difference is that there is slightly less redundancy because a few of those neighbors are no longer connected to each other.\nFigure 2.10: Diffusion with Weak Ties\nAt the start, the diffusion process initially unfolds as before. Word of mouth spreads out spatially until it hits one of the long-distance links. It then jumps across the network and begins to fan out across the new area until it hits another long-distance link and jumps again. Each long tie allows information about the job to spread to an untouched region of the network. The result is that word of the job spreads much faster than it did before. Instead of taking fourteen days to reach everyone in the network, now it only takes five days.\nFigure 2.11: Diffusion in a Small World\nWhat happens if we add more weak ties? Figure 2.11 repeats the same experiment in a completely random network, in which all of the ties have been rewired. In this network, redundancy is minimized, giving each person maximum exposure to the network. As in all the previous experiments, every individual has four contacts, but now there is no clustering in the neighborhoods. Consequently, as the diffusion process gets going, each new person that is reached creates exponentially more new exposures than before."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:466b5c7e-9069-4104-b85d-cf3ab7c9a36a>","<urn:uuid:e089d38a-a5f1-4b2a-a5ff-88e880cb939a>"],"error":null}
{"question":"How do Qualifications Review Boards (QRBs) ensure leadership quality in federal government, and what legal duties must nonprofit board members fulfill for effective governance?","answer":"QRBs ensure leadership quality by evaluating SES candidates based on executive core qualifications, with three executives from different agencies (at least two career public servants) serving on each board to promote transferable leadership skills over technical expertise. They act as vital gatekeepers for succession planning in the highest federal government levels. As for nonprofit board members, they must fulfill three key fiduciary duties: acting in good faith with honesty and faithfulness, exercising ordinary care using good judgment, and serving the best interest of the nonprofit over personal interests. They must also provide legal, management, financial, and program oversight while ensuring compliance with the organization's mission and tax-exempt status requirements.","context":["What is a SES Qualifications Review Board (QRB)?\nA Qualifications Review Board (QRB) is a panel of Senior Executive Service (SES) members who decide whether a candidate for SES membership will be admitted.\nThe US Office of Personnel Management (OPM) administers SES processes which include assembling QRBs and overseeing the activities of each one. While the US Office of Personnel Management ensures boards adhere to process requirements, boards make independent decisions about SES candidates. OPM provides a staff member for each board that “serves as the QRB Administrator for each board, conducts a briefing about the hiring selection methods used by agencies, gives instructions about the certification process, answers questions from QRB members, and provides any other guidance and staff support as appropriate.”\nEach board is made up of three executives from different agencies. At least two of the three must be career public servants. One of the three must have served on a QRB before. This composition helps OPM de-emphasize technical skill and promote transferable leadership skills in the SES. “This independent and objective review is intended to ensure that the (US) government is hiring executives with the qualifications needed in today’s environment, especially the ability to lead in times of change and that technical expertise does not outweigh leadership skill in the selection of new senior executives,” OPM says.\nQRBs evaluate the credentials of those applying for admittance into the Senior Executive Service. Admittance allows career federal employees to assume some of the highest leadership positions in the federal government. Senior Executive Service members compete for jobs directly supervised by Presidential appointees. A candidate’s approval by a QRB is no guarantee of a job. It only means the candidate can legitimately apply.\nBoard members volunteer their time and effort. Their motivation for volunteering is to ensure the federal government has a quality stable of applicants ready to fill leadership positions. Volunteers have the opportunity to leave a mark on the SES beyond their own careers. Boards help the federal government maintain a baseline of excellence in top tier career service positions. Those interested in volunteering should work with their agencies’ human resource offices or contact OPM directly.\nQRB members evaluate each candidate based on the executive core qualifications, but members do not limit themselves to only those factors. “The QRB is responsible for the fair and objective assessment of all case documents in the candidate’s QRB case to determine if the candidate possesses the required executive core qualifications. Board members do not limit their assessment of executive qualifications to the candidate’s ECQ documentation statement; they consider all of the information included in the application package.\nThe candidate’s qualifications taken as a whole must demonstrate that the individual has the leadership qualities needed in today’s SES,” OPM says.\nSES candidates are not compared to each other in QRB deliberations. Rather, candidates are evaluated individually on their own merits. Anyone deemed worthy of approval is given approval without competing with other candidates.\nCommunication among board members about board business is privileged. OPM may release the names of individuals who have volunteered on QRBs. OPM does not release the makeup of particular boards.\nSuccession planning is important in all levels of government. While hiring processes should be open competitions, managers need to groom likely successors. When promotion opportunities arise, current employees need to be ready to step into roles with greater responsibilities. If an organization has a person who can promote into a new job, that person can likely be up to speed more quickly than someone entering the organization from the outside.\nQRBs play a vital gatekeeping role for succession planning in the highest levels of the federal government. By playing this role, QRBs set baseline expectations for the leadership skills possessed by SES members.\nSource/Citation: Balanced Careers","What Are the Duties of Nonprofit Directors?\nState law sets out which type of management and governing structure is acceptable for nonprofit corporations in that state. In some states, nonprofit organizations can be managed by a board of directors, by voting members, or by a combination of directors and members. The founding documents of the organization (often called the “Articles of Incorporation or “Certificate of Formation” in different states) will set out what type of management is in place. Very often, the board of directors is its legal, governing body.\nThis article discuss the board of directors as the top governing body of the nonprofit organization. It does not address different rules for trustees of charitable trusts. Each state has specific requirements for how boards of directors must operate. Check with your legal counsel for specifics.\nBoards of directors of nonprofit corporations may be designated by other names:\nBut regardless of the name, if management of the nonprofit corporation is placed with the board, the board has legal and ethical duties that cannot be delegated to others.\nThe board must follow the fiduciary duties of care, loyalty, and obedience to the nonprofit.\nWhat are Nonprofit Directors’ Legal Duties and Obligations?\nWhile state laws differ, generally directors are required to perform their duties in good faith, with ordinary care, and in the best interest of the nonprofit.*\n- In good faith. Good faith is shown by honesty and faithfulness to duties and obligations.\n- With ordinary care. Ordinary care is the use of good judgment and common sense. It means doing what an ordinarily prudent person in a similar position would do under similar circumstances. Ordinary care may differ from director to director based on their background and experience and the role they play in the organization.\n- In the best interest of the nonprofit. A director acts in the best interest of the nonprofit if the director reasonably believes that the action will benefit the nonprofit. Doing what is in the best interest of the nonprofit means being loyal to the nonprofit – it means the nonprofit’s interest prevails over the director’s personal or business interest.\n- Doing what is in the best interest of the nonprofit means that directors are obedient to the “laws” of that nonprofit, which include adhering to the Articles of Incorporation (or Certificate of Formation), bylaws, federal IRS tax-exempt rules, and faithfully following the organization’s mission and purpose.\n- It means that directors know and follow all laws applying to the nonprofit – federal, state, and local laws and regulations.\n- A director’s personal interests cannot prevail over the nonprofit organization’s interest. It is important to pay attention to perceived or actual conflicts of interest and deal with those.\nSome of these tasks may include:\n(1) Legal Oversight.\n- The board generally ensures that it is operating in accordance with its mission and the purpose for which it was granted tax-exempt status. Are board members checking that mission is tied to all of the organization’s activities?\n- As safeguards of the public trust, board members generally are responsible for protecting the organization’s assets.\n- The board should ensure legal and ethical integrity and maintain accountability.\n- Is the board following its founding documents and bylaws?\n- Is the board holding meetings and keeping minutes?\n- Is the organization filing its required state and IRS reports? Is the board reviewing those reports before they are submitted?\n(2) Management Oversight.\n- The board is responsible for ensuring that the nonprofit corporation is being run well.\n- The board selects the chief executive and decides his/her role. (The chief executive is often called the executive director.)\n- The board supports the chief executive and assesses his/her performance.\n- The board usually has the power to hire and remove the chief executive.\n(3) Financial Oversight.\n- The board provides proper financial oversight, including setting and approving an annual budget.\n- Are board members reviewing the financial data closely?\n- Are board members making sure there is no private inurement to insiders?\n- Is compensation to staff reasonable?\n- Is there an independent body conducting a salary survey and using that independent data in setting the executive compensation?\n- Is the organization keeping accurate financial records and able to provide those for public inspection?\n(4) Program Oversight.\n- The board ensures that programs are in place to further the mission and goals of the organization.\nHow should the nonprofit board and its executive director work together?\nStrong nonprofit organizations have boards and staff with respectful working relationships. It is often the job of the executive director to keep the board informed on various legal, financial, planning, and policy, personnel issues. And since it is the board’s job to provide oversight of the executive director to ensure that the nonprofit is being run well, it is helpful for the two to find a healthy balance of guidance and supervision.\nYou can learn more at Who’s in charge here? Role of the board of directors vs. executive director.\nWhat about advisory boards or committees?\nDepending on the articles of incorporation and bylaws, the board of directors may be able to create any number of advisory boards or committees.\nGenerally, a committee or advisory board works to give advice and support to the organization in some particular way.\nEven though the word “board” is included in an “advisory board” or “fundraising board” or “medical board,” these likely are committees of the governing board. These groups often are not the top, ultimate governing board, and they may not have the same legal duties as the board of directors. Check the governing documents!\nSome typical types of advisory boards include\n- Fundraising and special event planning\n- Program support, policy creation, expert guidance\n- Specific skill set: medical board, academic advisory board, marketing board.\nBecause the names and jobs on the “board of directors” and an advisory board can seem similar, sometimes there is confusion. It is often helpful to set out the duties and purpose of any committee or advisory board. Members of the committee should receive information on their expectations and responsibilities in their role.\nAre there any protections for nonprofit directors?\nIn some states, there are some protections for directors, including the following:\n- Reliance on certain information prepared by others. In some cases, a director may rely on information prepared by others. If the director is acting in good faith and with ordinary care, the director may rely on reports, financial statements, and information prepared by another director or by an employee, a board committee, legal counsel, accountants, or other professionals hired. However, the director is not protected from liability if she has knowledge that makes the information unreliable.\n- Delegation of Investment Authority. If the board acted in good faith and with ordinary care in selecting a financial advisor for the nonprofit, the board may have no liability from any action taken or omitted by an investment advisor who invested the funds of the nonprofit.\n- Indemnity. Occasionally a person is sued simply because he or she is or was a director of a nonprofit. In some situations the nonprofit may indemnify (pay the legal expenses for) the director; in other situations the nonprofit must must indemnify the director. Check the organization’s documents.\n- Insurance and other protections. A nonprofit may provide certain insurance for directors — Director’s and Officer’s liability insurance. Learn more about D & O Insurance.\nYou should check with your legal advisor in your state for specifics.\nWhat directors should know about the organization. What documents directors should have\nDecision makers of nonprofit corporations that engage in ongoing operations should understand that their duty of care goes beyond financial or business decisions to reach all decisions made in the course or scope of their duties as directors.\nDirectors should keep the following:\n- Formation Documents — the Articles of Incorporation/Certificate of Formation — from the Secretary of State\n- Conflict of interest policy\n- Minutes of the previous year\n- Most recent audit/review\n- Budget and most recent financials (Profit and Loss; Balance Sheet)\nBoard members should know details concerning the following matters:\n- Legal form of the organization (is it a corporation or an unincorporated association?)\n- Mission of the organization\n- Any policies affecting decision makers (Conflict of Interest Policy)\n- Financial Picture (budget and financials)\n- Most recent IRS Form 990\n- Existence/operations of related entities\n- Where the organization is conducting activities\n- Tax status and applicable legal requirements of the organization (is it a 501(c)(3)?)\n- Management structure and key employees\n- Committee structure\n- How directors and officers are selected\n*In Texas, the law to check is the Texas Business Organization’s Code, which sets out the conduct of corporate boards – for-profit or nonprofit boards of directors. Chapter 22 sets out requirements for notice of board meetings, duties of directors, and more.\nThe Cullinane Law Group works exclusively with the tax-exempt sector. We set up and maintain strong and legally compliant organizations that have solid bases for long-term success. We provide risk management and offer practical solutions for sound governance and help you understand the duties of nonprofit directors. We help nonprofits, foundations, and professional associations who seek to create positive change."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:b1ac375f-6dd3-40a5-8736-ab011ef342e2>","<urn:uuid:f91a527c-7ee2-4b38-a475-0779574742b6>"],"error":null}
{"question":"What is the Zuni belief about how animal fetishes were created?","answer":"According to Zuni mythology, when the world was covered in floodwaters, the Sun Father's twin sons dried the earth with lightning arrows, but this made it too easy for predators to catch people. To protect humans, the Twins struck these predator animals with lightning, turning them to stone while keeping their hearts alive. These animals were instructed to help humankind with the magic captured in their hearts. When Zuni people find stones naturally resembling animals, they believe these are those ancient stone beasts.","context":["In the distance silver helmets and breastplates reflected the brilliant July sun, as Spanish soldiers mounted on majestic Lipizzaner stallions marched toward me in a swirling cloud of dust. Franciscan monks carried crosses and the flag of Spain. Leading the desert procession is Francisco Vazquez de Coronado y Lujan, searching for the legendary Seven Cities of Cibola in 1540. They came upon the Zuni homeland of Shiwannagan spread out over six towns, where the A:shiwi have lived for about 4,000 years.\nI imagine this scene as we retrace the Spanish explorer’s route in our journey from Gallup, New Mexico on Highway 602 to the Zuni Pueblo. We note weather-worn pickup trucks parked off the highway. As we drive by we are unable to spot anyone, but since it is October, families must be out among the pinyon pines gathering pine nuts.\nCoronado did not find the Seven Cities of Gold, only the isolated pueblo villages of the Zuni. Today about 10,000 Zuni live in the largest of New Mexican pueblos. There are adobe ruins of former settlements. The homes that we could see were of simple cinder-block construction. Isolation from other pueblos of New Mexico made their language and culture distinct. The physical presentation of the place did not have the romantic aspect of the terraced old adobe buildings of Taos. But if you spend the night at the Inn at Halona or talk with some of the notable artisans, you will have a deeper sense of Zuni.\nRoger Thomas, owner of the Inn at Halona shares:\n“You have to want to come here. Our visitors tend to be better educated and more culturally aware. Their reward is often a very profound experience.” (“The Boundaries of the Sacred”).\nFor years I have collected stone-carved Zuni animal fetishes and used them in my college lectures on native American spirituality. I had a vague understanding of their sacred power, but I wanted to visit the source of the fetishes to understand their connection to the sacred.\nAnother spiritual explorer as myself visited the Zuni Reservation in 1879 with the J. W. Powell Expedition. The U. S. Government sent Frank Hamilton Cushing to investigate the mysterious power of the legendary fetishes. Could they be a threat to America?\nCushing immersed himself among the Zuni, gained their trust and learned the obscure language. He was initiated into the Bow Priesthood as a War Chief and given the name Medicine Flower. You can read about his experience and what he learned about fetishes in his book Zuni Fetishes.\nCushing encountered an enticing animistic world where “all inanimate objects as well as plant, animals and men, belong to one great system of all conscious and interrelated life. Any element in nature is endowed with a personality analogous to that of the animal whose operations most resemble it’s manifestations.” (Cushing, p. 9).\nFor Cushing, the Zuni stone fetishes were sacred living stones.\n“It is supposed that the hearts of the great animals of prey are infused with a spirit or medicine of magic influence over the hearts of the animals they prey upon, or the game animals; that their breaths, derived from their hearts, and breathed upon their prey, whether near or far, never fail to overcome them, piercing their hearts and causing their limbs to stiffen, and the animals themselves to lose their strength…..Moreover, these powers, as derived from his heart, are preserved in his fetich, since his heart still lives, even though his person be changed to stone.” (Cushing, p. 15).\nThus, the Zuni fetish is a vital spiritual aid to a successful hunt.\nHow did the Zuni translate the power of the great animals into the stone fetishes?\nKent McManis reveals an answer from Zuni mythology in his book Zuni Fetishes:\n“The Zuni believe that the world was once covered with floodwaters, which left it swampy. The Sun Father, revered by the Zuni as the giver of life and light, created twin sons. The Twins realized the world was too wet for humankind to survive and needed to be dried. The Sun Father had given his sons a magic shield, a bow (the rainbow) and arrows (lightening). The Twins placed their shield on the earth crossed the rainbow and lightning arrows on top of it, and shot an arrow into the point where they crossed. Lightning flew out in each direction creating a tremendous fire. Although this dried the earth, it made it too easy for predators to catch and eat people. So, to save humans, the Twins struck these animals with their lightning, burning and shriveling them into stone. But deep within, the animals’ hearts were kept alive, with instructions to help humankind with the magic captured in their hearts. When a Zuni finds a stone that naturally resembles an animal, he believes that it is one of these ancient stone beasts.”\n(McManis, p. 6).\nJanice, Erik and I stop at the Visitors Center on the north side Highway 53, half way through town.\nZuni tribal drummers beat a loud cadence behind me as dancers swirl and stomp, feathers flutter and bells tingle on their costumes. At this Fall Festival in front of the Zuni Cultural Center artisans have set up tables to display their work. I approach a woman seated at her table, head bent over in concentration as she works with a lump of native turquoise. I want to be respectful and not ask too many probing questions. I walk cautiously forward, close enough so that my shadow covers her work and she looks up. She greets me with a beautiful smile and twinkling eyes.\n“Hello. Please sit down.”\nI am meeting the Zuni fetish artist Verla Lasiloo Jim.\nI do not need to ask a lot of questions, because Verla may see my interest in her work and she shares her story.\n“My husband passed away several years ago. He carved the fetishes. I always watched him at his work and wondered how he decided what animal he would carve. He said he could see the spirit inside the stone and what he was doing was helping the form become what it was meant to be. When he died, it was a tough time and I didn’t know what to do. I began to work with his tools and some of the stones that he had. I began with turtles and frogs. Sometimes what came out was ugly. But I would save it to remind me. There is one over there.”\nI could see on the table some very small fetishes, which looked as if they could be placed in a medicine bag as a kind of sacred talisman.\nThe Spanish invaders and the Christian missionaries tried to stop the practice of fetish making as it seemed like idolatry.\nMs. Lasiloo-Jim had a friend who was a buyer and he began to sell her fetishes and slowly her popularity grew. She is a member of the Mahooty, Lasiloo and Laiwakete interrelated family clan, known for their use of a variety of materials such as stone, wood and shells.\nThe drumming is growing louder and I must draw closer to Ms. Lasiloo-Jim, as she has a soft voice.\nI asked, “Are all the fetishes sacred?”\n“If the medicine man blesses them, they should be used in the traditional manner. They need to be cared for by feeding them with blue corn meal. Some people keep them in turquoise encrusted pots”\n“Are they alive?”\n“I can tell you that if I am bothered by a problem or worry, I can pray over a fetish and the answer to my concern will be given to me.\nShe seems to be inviting me to stay as long as I wish, as she continues to work on the turquoise.\n“What will it become.”\n“I don’t know yet, but I think it is a bear.”\nI purchase a fetish.\nAs I decide to leave and join my family, she says:\n“Here is my card with my address. Let me know if you want me to make something for you. You can even send me a drawing or a photo. I see your black poodle over there. I can make a poodle for you. Please let me know.”\nA few days later we are at a gift shop at Grand Canyon National Park. Sheltered within a glass case are an array of Zuni fetish. I see a stone bear with a turquoise line running from its mouth to the heart.\n“An inlaid, carved, or painted “heartline” represents the breath path leading to the magical power in the fetish’s heart…A bundle consisting of various stones, shells, and/or arrowheads is sometimes tied onto a fetish. The bundle serves as an offering that empowers the fetish to better aid the user.”\nMcManis p. 10.\nHow do you choose a fetish?\nKent McManis suggests:\n“I have simple rule of fetish selection; if the fetish talks to me, I buy it no matter what the animal is or who carved it. I believe that fetishes usually pick you out.”\nMcManis, p. 139.\nI am at Richardson’s Trading Post on Route 66 in downtown Gallup, New Mexico. In my hand is a turquoise bear fetish, which somehow caught my attention. The red heartline runs from nose to heart. Was it calling to me? Am I holding a quaint relic from a “primitive” culture?\nTutored in the mindset of the Enlightenment, I feel dissonance. Philosopher Charles Taylor summarizes his helpful insights from A Secular Age (2207):\n“Almost everyone can agree that one of the big differences between us and our ancestors of five hundred years ago is that they lived in an “enchanted” world, and we do not; at the very least, we live in a much less “enchanted” world. We might think of this as our having “lost” a number of beliefs and the practices which they made possible. But more, the enchanted world was one in which these forces could cross a porous boundary and shape our lives, psychic and physical. One of the big differences between us and them is that we live with a much firmer sense of the boundary between self and other. We are “buffered” selves. We have changed.\nLike my European ancestors five hundred years ago, the Zuni world today is a porous world, aware of demons, witches and dark forces that can threaten, and at the same time open to ecstatic and mystical experiences with the Creator. We “modern” folk with our buffered self are closed off to both kinds of powers\nYet there continues to be a fascination, a longing, a restlessness that brings spiritual seekers like me to Zuni and Vera Lasaloo Jim.\nJohnathan Napier describes the divide between the spiritual and the secular in Charles Taylor’s work and how it is not relevant to Native American world views.\n“…..Taylor introduces his “immanent frame” which describes how people understand their relation to the supernatural. People either live in interaction with the supernatural or live separate from it. Taylor depicts this as a divide between the porous and the buffered self. The porous self has an enchanted worldview; it see itself as interacting with the spiritual world; it is vulnerable and open to forces beyond the physical realm.”\nNapier pp 83-84.\nSacred power is found in objects (e.g. Zuni fetish) and places. In the West, with the influence of the Enlightenment, Science and a focus on human reason, a process of disenchantment set in and the buffered self dismissed or compartmentalized spiritual experiences. Initiated by the philosophy of Rene Descartes, this new modern self turned radically inward, becoming personal and private.\nIndigenous cultures as the Zuni, in contrast, focus outward toward nature, the land and communal relationships. There is no separation between the material world and the spiritual realm: all is infused with the sacred. While the West compartmentalizes, the Zuni seek harmony and balance in a unified world.\nAs I hold the bear fetish in my hand, a soft-spoken, patient Navajo saleswoman speaks to me across the glass display case about the fetish. A porous soul speaks to a buffered soul about the sacred.\n“The bear is the best mediator with the Creator because it has the closest resemblance to humans. The bear has power, strength and intelligence to help you. The bear can help you make peace in times of conflict and guide you when you have spiritual challenges.”\nI purchase the bear fetish and she wraps it carefully in cotton and places it within a protective box. She smiles as she hands me a transparent plastic bag with the fetish and a tiny zip lock bag filled with what looks like blue cornmeal.\nI am at our home in Laguna Niguel, California. I hold the bear fetish, which I keep in a glass case above artifacts I have collected over the years of the Day of the Dead. The fetish feels warm in my hand. It is not one of the sacred fetishes blessed by the Zuni priest, who would have animated the figure with a real spirit presence.\nI trace with my thumb the red lifeline running from the bear’s mouth to its heart. The artist who created this believed in “The Spirit that lives in all things.” The bear fetish would be a messenger and protector from that Spirit.\nAs I hold the bear, the word that comes to me is “kinship.” The Zuni believe that all created things, animate and inanimate, are connected. There are similar words from St. Paul in my Christian tradition:\n“In Him all things in heaven and on earth were created, things visible and invisible, whether thrones or dominions or rulers or powers – all things have been created through him and for him. He is before all things, and in him all things hold together.” Colossians 1:16,17.\nAt the heart of the spirituality of St. Ignatius Loyola is the belief that we encounter God in all things. Our spirituality and awareness of the presence of God grows deeper as we draw closer to our kindship with all created things.\nI am remembering Thomas Merton’s words:\n“it is good and praiseworthy to look at some real created thing and feel and appreciate its reality. Just let the reality of what is real sink into you..for through real things we can reach Him who is infinitely real.”\nIn my study of world religions, most traditions create sacred images. Most of these have been animated by blessings from a priest or shaman. While they may be sacred and fed, like this bear fetish, a statue of Shiva in a Hindu temple, or a statue of Quan Yin in a Taoist Temple, they are tangible mediums to connect with the Divine.\nThe Zuni may pray to the bear fetish for courage as he meets a particular challenge. I may kneel in church and pray to Our Lady of Guadalupe. They are not the same but similar connections to the Sacred.\nOur Buffered Self fostered by science and Enlightenment philosophy has distanced us from our kinship with the natural world.\nJohn Swanson observes:\n“In modern society, animals have lost their central role in cultural organization. When animals are no longer viewed as guiding spirits nor connected to us by sacred rituals that guide our behavior, animals lose their significance retaining only their function as secular emblems. Vestiges of these connects between animals and societal groupings remain in the naming of our sports teams and lodges: the Miami Dolphins, Detroit Tigers, and Chicago Bulls; in the Lions Club and Elks Lodge, and in the stuffed animals we buy for our children. Revered spirit animals are reduced to team mascots.”\n- 107 Communing with Nature: a Guidebook for Enhancing your Relationship with the Living Earth, John L. Swanson, Ph.D.\nI am grateful for solitary sunset walks into desert spirit places, renewing my kinship with all created things.\nZuni Fetishes by Frank Cushing. 1990. Facsimile edition by KC Publications, Las Vegas, Nevada, from the Second Annual Report of the Bureau of Ethnology, submitted by J. W. Powell. Original Printing 1883.\nZuni Fetishes and Carvings by Kent McManis (Tucson: Rio Nuevo Publishes, 2004).\n“The Boundaries of the Sacred—a Visit to Zuni Pueblo”, April 27, 2015. http://www.aroundtheworldineightyyears.com/visit-zuni-pueblo/\nSpirit in the Stone: A Handbook of Southwest Indian Animal Carvings and Beliefs by Mark Bahti.\n“Interfaith Dialogue Theory and Native/Non-Native Relations”, Jonathan Napiter, University of Calgary (Illumine: Journal of the Centre for Studies in Religion and Society: Graduate Students Association), Vol. 10, No. 1, 2011, pp 77-90.\nI live in the south, which has no indigenous tribes following the Zuni religious tradition of fetish making. Yet, I am puzzled to find similar carved rocks that appear in the forms of animals. I have also found rock mosaics representing what look to be prehistoric animals.The problem is, no one I have tried to seek help from is even willing to look at them. Time and traffic on my land over them is quickly destroying them, along with heavy rains.I know very little on these subjects, but I would appreciate any recommendations you could give me. I can barely find much information on fetish rocks; these appear old and without much detail left, and some are better than others. Do you have any idea what they may be or who they were left by? Thank you for reading. M.M.A.\nHi Mary, someone who has written several books on Rock Art and teaches at UCLA\nDavid S Whitley\n24160 Woodbine Court\nTehachapi CA 93561\nHope this helps.\nFr Brad Karelius"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:991a7197-bf5d-4442-92ec-f825f439b0f8>"],"error":null}
{"question":"As a theology student, I'm curious: what are the key differences between investigating biblical texts using hermeneutics versus the historical-critical method?","answer":"Hermeneutics and historical-critical method differ in their primary focus and approach. Hermeneutics is defined as both a science and art of interpretation, following specific rules while requiring practiced skill development. It emphasizes principles like contextual analysis, Scripture comparison, and cultural understanding to determine meaning. In contrast, the historical-critical method focuses more specifically on studying biblical texts' origins through comparison with contemporary texts, examining questions of authorship, audience and authenticity, with the main goal of getting as close as possible to the 'original text' and its 'original meaning'. While both methods are scholarly approaches to biblical interpretation, hermeneutics provides a broader framework of interpretive rules and principles, while historical-criticism concentrates more narrowly on historical origins and textual criticism.","context":["Interpretation: What Does It Mean?\nDr. Daniel L. Akin President Southeastern Baptist Theological Seminary Wake Forest, North Carolina\nTHE PROCESS OF BIBLICAL INTERPRETATION Hermeneutics is the science and art of interpretation. It is a science because it follows certain rules. It is an art because it is a skill one develops with practice. Hermeneutics is the study of methodological principles of interpretation which allows us to take what we see and determine what it means. Three Truths to remember: 1. It takes time - to expose oneself to the brilliance of revealed truth. 2. There is more truth in the Bible than we can grasp in one or many readings. Infinite, eternal truth has this nature. 3. It takes practice and experience - skills to develop an understanding of the text with accuracy. A. • • • • • • •\nSOME BASIC PRINCIPLES OF INTERPRETATION – ANSWERING THE QUESTION: WHAT DOES IT MEAN? Content - What is actually before you in the text. It is discovered by the results of your observational study. How to read and what to look for is the key (there is a huge difference between seeing and reading). Clue - The more time spent in observation, the less time you will spend in interpretation and the more accurate will be the results of your interpretation. Context - What goes before and after? (There is both a near and a far context). Comparison - Compare Scripture with Scripture. *Remember the parts always take on meaning in the light of the whole. Culture - What was the social setting at that time? What was the historical situation? What was the chronos, language, customs, political environment? Consultation - Use resource tools (after you have done personal study). This includes dictionaries, atlases, concordance, commentaries, etc.; check your interpretation with other great women and men of God. If you are the only one to see the text a certain way, you are probably wrong. Construction - Build an exegetically and homiletically sound outline that arises clearly out of the text. Let the text determine the structure of your outline.\nRemember: First comes God’s Word, then secondary sources!\nTEN INTERPRETIVE RULES\nJust as there must be the proper use of the proper tools, there must also be the observance of some simple rules if accurate interpretation is to take place. Remember that hermeneutics is both an art and a science; a science because there are rules and principles. 1. Work from the assumption that the Bible is authoritative. 2. Interpret difficult passages in the light of clear passages. Let the Bible interpret itself. 3. Interpret personal experience in the light of Scripture and not Scripture in the light of personal experience. 4. Remember that Scripture has only ONE MEANING but many applications. • One Meaning (Sense) • Many Applications (Significance) 5. Interpret words and passages in harmony with their meaning in the time of the author. INTERPRETATION IS BRIDGING THE GAPS • • • • • •\nThe Language Gap The Historical Gap The Cultural Gap The Geographical Gap The Literary Gap The Theological Gap\n6. Interpret Scripture in light of its PROGRESSIVE REVELATION. 7. Remember you must understand the Bible grammatically before you can understand it theologically. 8. A doctrine cannot be considered biblical unless it includes all that the Scriptures say about it. DO not practice “selective citation” or “proof-texting.” 9. Distinguish between the PROVERBS and the PROMISES of God. 10. When two doctrines taught in the Bible appear to be contradictory, accept both as Scriptural in the confident belief that they resolve themselves in a higher unity.\nTHE PREACHER/TEACHER AND PREPARATION: INVESTIGATION\nExtrabiblical Contemporary usage\nOther biblical usages\nOther books by\nContext Biblical book The same author (if any)\nGUIDING PRINCIPLES FOR INTERPRETATION\n1. The context rules when interpreting the text.\n2. The text must be interpreted in light of all Scripture.\n3. Scripture will never contradict itself.\n4. Scripture should be interpreted literally.\n5. Do not develop doctrine from obscure or difficult passages.\n6. Discover the author’s original intended meaning.\n7. Check your conclusions using reliable resources.\nAnalyzing The Text\nVerse 1 (1/4 page to a full page)\nVerse 2 (1/4 page to a full page)\nVerse 3 (1/4 page to a full page)\n____________________________________________________________________ 1. 2. 3. 4. 5.\nPray. Track the verbs and parse them (if you can). Look for key words needing definition. Look for repetition of phrases and words. Look for seams in the text which will inform the number of points and the nature of the teaching outline. 6. Note the near and far context. 7. Search for helpful and supporting Scripture (cross reference). 8. Write out any and all observations and applications you see in the text. 9. Examine your study aids and write out any helpful insights (note the source for future reference and appropriate citation). 10. Look for exegetical truth and avenues the text logically supports. 11. Merge your exegesis into the outline structure of your teaching.\nSEVEN STEPS TO STUDYING AND PREACHING/TEACHING THE BIBLE (A Summation)\nWhat do I see?\nWhat does it mean?\nHow does it fit together?\nHow do I put this into practice?\nHow has this principle worked in other areas and in other people’s lives?\nHow do I communicate this truth to others?\nHow do I encourage others to love God by obeying God?","By David R. Law\nThe time period refers to more than a few methodologies which learn the origins of biblical texts, with regards to different contemporaneous texts, to shape serious techniques and to questions of authorship, viewers and authenticty. the purpose is to get as just about the ‘original textual content' and its ‘original which means' as attainable. for a few years old serious process has been the cornerstone upon which biblical scholarship is outfitted, at the same time smooth reviews study different theoretical methods to examining the textual content in heritage, culture, and from assorted viewers views the historic serious procedure nonetheless offers the the most important place to begin for college students and students.\nRead Online or Download The Historical-Critical Method: A Guide for the Perplexed PDF\nSimilar bible study books\nNot anyone can doubt that the Bible has exerted a major impact on Western civilization because the sunrise of Christianity. yet few folks have thought of the perfect nature of that impact particularly historic contexts. during this publication, David Kling strains the interesting tale of ways particular biblical texts have at diversified occasions emerged to be the foundation of activities that experience replaced the process background.\n~ How is the human spirit reborn? ~ what's religion? ~ How does worry have an effect on the actual physique? ~ what's the strength of religion? Kenneth Copeland explores those questions and extra during this enlightening, inspiring two-chapter research of religion. observe the adaptation among the actual legislation of this global and the precepts that govern our non secular lives.\nExtra info for The Historical-Critical Method: A Guide for the Perplexed\nIndd 25 1/27/2012 4:23:05 PM 26 THE HISTORICAL–CRITICAL METHOD Another group of scholars traces the origins of historical criticism still further back, namely to the Renaissance. 7 For Barton, ‘the intellectual pedigree’ of biblical criticism is also to be found in the Renaissance rather than the Enlightenment. ’8 It is thus mistaken to identify the origins of the historical–critical method exclusively with the Enlightenment period. Its roots lie much deeper and both the Reformation and above all the Renaissance laid the foundations which would make possible the development of the historical– critical method in the modern period.\nAlthough the dominance of the allegorical method retarded the development of historical criticism, there were some hints of historical approaches to biblical interpretation in the early Church. Firstly, despite the dominance of allegorical interpretation, there was also awareness of the danger of it not doing justice to the reality of the text. 17 Secondly, the need to decide on the status of disputed writings led some early Church Fathers to address issues that we would today associate with historical criticism.\nWhat is known to be possible in the present is made the criterion for what is likely to have happened in the past. If texts report events which are now considered to be improbable or even impossible, then they should not be regarded as historical accounts and the interpreter should look for other explanations such as, for example, that the text reflects a now outmoded world view or is a literary embellishment. The consequence of making the present the criterion for understanding the past is that natural explanations are preferred over supernatural explanations."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:03879f2e-e5f3-420a-b668-366854e83d7f>","<urn:uuid:f2ccc234-6e78-4129-8528-e6bcec6d3908>"],"error":null}
{"question":"What's the difference in hunting applications between elephant guns and the .416 Rigby cartridge for dangerous game?","answer":"Early elephant guns were primarily used for hunting elephants, rhinoceros, hippopotamus, and cape buffalo, but struggled with penetration, especially for head shots on elephants. The .416 Rigby, while also effective for dangerous game in Africa and India, proved more versatile. It was successful against not only elephants and buffalo but was also suitable for hunting big cats like lions and tigers (though considered overpowered for them), and could be used with lighter 19-23g bullets for these species. Both types shared the common goal of having enough stopping power to prevent harm to the hunter from charging game.","context":["An elephant gun is a large caliber gun, which could be (but does not have to be) a rifle. Elephant guns were first made to be used by big-game hunters who were hunting elephants and other large animals.\nEarly use[change | change source]\nAs people from Europe began exploring Africa in the early 1800s, guns were made to handle the very large animals that people saw. This was for people to protect themselves, to shoot animals for food, and later, and most commonly, sport. The first guns were the simple shotgun designs already used for birds. They were loaded with solid balls of lead that could shoot large animals. Because they did not kill large animals very easily (some writers said that it could take up to 35 shots to kill one elephant), elephant guns were soon made into larger caliber black powder smoothbores. The caliber was still measured in bore or gauge - or the guns were named by how much the projectiles (what was shot out of the guns) weighed in ounces. The projectiles were lead round balls or short slugs shaped like cones. Sometimes, antimony was put in them to make them harder.\nThese very large and heavy firearms were the first to be known as the elephant guns of the black powder era (1850–1890). They were not only used to kill elephants. They were also used to kill dangerous animals such as the rhinoceros, the hippopotamus and the cape buffalo. Because black powder and lead cannot go faster than about 1,500 feet per second (460 m/s) - the only way to make the projectiles go deeper into the animals' skins was to make a larger gun. Although they were very powerful, the short slugs (a type of projectile), which did not go very fast, still had problems going fully into their targets. This was especially hard for the toughest shot of all - going through the bone when an elephant's head was shot around the brain area.\nNitro Express rifles[change | change source]\nNitro Express elephant guns were first made around 1895. They used smokeless powder, which was new at the time. With smaller metal-cased bullets with sizes from .400 to .620 and speeds around 2,000 ft/s (610 m/s), they had a much better trajectory and penetration over the black powder guns. In a few years the big bore guns disappeared from the gamefields. Early 20th century rifles came out in single shot, bolt action, and double rifle ways and were used until ivory hunting died off in the mid 20th century. Then the guns switched roles to tools for game wardens and as backup firearms for professional hunters guiding international hunters.\nThe American gun market made several famous dangerous gun cartridges around this time, such as the .458 Winchester Magnum, .378 Weatherby Magnum and .460 Weatherby Magnum. Many of these were 'wildcatted' (to modify an existing case and rifle to fire a different caliber bullet). The rest of the old Nitro express calibers faded to obscurity until people starting safari hunting in the 1970s and 1980s. Then elephant guns like the .416 Weatherby Magnum and the .416 Remington Magnum were made again. The .700 Nitro Express (made in the 1980's and 1990's) and the new brass manufacturers made even more powerful elephant guns such as the .585 Nyati by Ross Seyfried, .577 Tyrannosaur by Colonel Art Alphin and .585 Gehringer by Karl Gehringer to be made by wildcatters. The .600 Overkill made by Rob Garnick shows the biggest power that could come from a standard hunting action. Other wildcats based on the heavy machine gun .50 BMG and similar anti-materiel rounds have been devised which are much more powerful, though they are not generally useful hunting arms because they are heavier than 25 lb (11 kg).\nFeatures[change | change source]\nAll elephant guns have one idea in common: to have enough stopping power to prevent harm to the hunter in the case of charging game. The necessities for the gun are not only very high power (any big gun could do that), but that it can be carried for long periods, shot from any position, and be well balanced enough to track on rapidly moving animals. It is really no more than a very big hunting rifle with the same use as any hunting rifle.\nUse in war[change | change source]\nDuring World War I, both the British and Germans used elephant guns[source?] taken from their African colonies when they tried to break the stalemate in the trenches. The British used elephant guns against the German tactic of having their snipers advance towards Allied lines under the cover of a large, 6-10 millimeter (0.24-0.4 inch) thick steel plate. Ordinary infantry rifles didn't do anything to the plate, but elephant guns were able to punch through it. Likewise, the Germans used a mass-produced anti-tank rifle, the Mauser 1918 TuF Gewehr, to knock out lightly armored British tanks.\nDuring the North African Campaign in 1941, the Italians in East Africa fought against the British. The Commander - The Duke of Aosta - gave his personal collection of elephant guns to his Italian soldiers to shoot armored cars because they didn't have enough anti-tank guns.\nThe Finnish 20 mm antitank gun Lahti L-39 had the nickname Norsupyssy (Elephant Gun) during the Winter War because of its stopping power. It is not a true elephant gun, though, since it was not made for elephant hunting but as a military weapon.","|This article needs additional citations for verification. (January 2013) (Learn how and when to remove this template message)|\n|Place of origin||England|\n|Designer||John Rigby & Company|\n|Case type||Rimless, bottleneck|\n|Bullet diameter||10.57 mm (0.416 in)|\n|Neck diameter||11.33 mm (0.446 in)|\n|Shoulder diameter||13.72 mm (0.540 in)|\n|Base diameter||14.96 mm (0.589 in)|\n|Rim diameter||14.99 mm (0.590 in)|\n|Rim thickness||1.65 mm (0.065 in)|\n|Case length||73.66 mm (2.900 in)|\n|Overall length||95.25 mm (3.750 in)|\n|Case capacity||8.28 cm3 (127.8 gr H2O)|\n|Rifling twist||420 mm (1-16.5 in)|\n|Primer type||Large rifle magnum|\n|Maximum pressure||325.00 MPa (47,137 psi)|\n|Test barrel length: 660 millimetres (26 in)\nSource(s): Reloaders Nest\nThe .416 Rigby or 10.6×74mm was designed in 1911 by John Rigby, of John Rigby & Company, as a dangerous game cartridge. It is the first to use a bullet with a diameter of 10.6 millimetres (0.416 in). The rifles, as built by John Rigby & Co., were initially made up on Mauser magnum-length actions, although in later years, some were made on standard length actions, a perfect example being the rifle used by legendary professional hunter Harry Selby. Other famous users of the cartridge were Commander David Enderby Blunt, John Taylor, and Jack O'Connor.\nOrigin & History\nTwo major developments at the turn of the 20th Century set the course for the development of the .416 Rigby as a successful rifle cartridge. The first was the development of cordite in the United Kingdom in 1889 and the development in Germany of the Gewehr 98 magazine rifle.\nPrior to the invention of cordite, rifles used gunpowder (black powder) as a propellant. Due to the burn characteristics of black powder it did not produce high pressures and therefore did not produce high velocities. Big bore cartridges of the era were the 4 bore, 6 bore and 8 bore rifles cartridges. Sub 12.7-millimetre (0.50 in) Caliber were considered small bore cartridges. Although the 4 bore, 6 bore and 8 bore cartridges were considered appropriate for dangerous game during that era, these cartridges lacked the penetration required to take heavy thick skinned game such as elephant, buffalo or rhinoceros humanely. The development of smokeless powder revolutionized the rifle. One version of this smokeless powder developed in the U.K. was cordite which allowed higher pressures to be developed and thereby increasing the velocity of bullets. The invention of smokeless powder rendered the big bore rifles of the era obsolete. With the emergence of cordite as a propellant what was considered a big bore cartridge changed to any cartridge having a caliber of over 11.6 millimetres (0.458 in). The switch during World War I to modern smokeless powders would cause what constituted a big bore to be further refined to mean any cartridge over 10.2 millimetres (0.400 in).\nNext improvement was the development of the Gewehr 98 rifle by Paul Mauser. Paul Mauser did not invent the bolt-action rifle but rather he refined the design allowing controlled round feeding, magazine feeding using a stripper clip, and a strong action with the ability to withstand high pressures generated by the new smokeless powders. The rifle design would go on to become the most common and successful rifle design in the history of firearms. During World War II most Axis and Allied nations with the exception of the British (Lee–Enfield), and the Russians (Mosin–Nagant) used rifles based on the Mauser 98 action. Today this is still the most popular rifle design and is used to this day by Mauser, Dumoulin-Herstal, CZ, Holland & Holland, Kimber, Rigby, Ruger and Winchester among others. The Mauser 98 action provided the consumers and gun makers an inexpensive alternative to the double and single shot rifles which until that time predominated the dangerous game hunting scene.\nAt the turn of the 20th Century, three major British rifle manufacturers, Jeffery, Westley-Richards and John Rigby & Co. designed cartridges which could operate in the Magnum Mauser action and could offer big bore nitro express ballistics and performance in a magazine rifle which was what the British called their bolt-action rifles. The result was the .404 Jeffery, .425 Westley-Richards and the .416 Rigby. While these cartridges were considered to be the new medium bore cartridges during their day, their performance on game matched the performance of the big bore Nitro Express cartridges. The performance of these cartridges was due to the sectional density (greater than 7.6 millimetres (0.300 in)) and higher velocity (~700 m/s (2,300 ft/s)).\nThe first .416 Rigby rifles used the Magnum Mauser Square Bridge No. 5 action. The large bolt face and the length of the Magnum Mauser No. 5 action was easily adopted for use with the .416 Rigby cartridge. As the Magnum Mauser action became scarcer after World War II, .416 Rigby rifles were built on Enfield P-17 and the BRNO actions instead of the Magnum Mauser action. Both the BRNO and the Enfield P-17 actions are in turn based on the Mauser 98 rifle.\nAfter World War II with the dwindling of areas to hunt dangerous game, interest in the .416 Rigby cartridge and most big bore cartridges began to wane. By the 1970s with the demise of the British ammunition supplier Kynoch as an entity, the supply of .416 Rigby ammunition was dwindling, and many hunters including Selby set aside their .416 Rigby rifles taking up the more popular .458 Winchester Magnum or the .375 H&H Magnum.\nBetween 1912 and the beginning of World War II John Rigby & Co. produced just 169 .416 Rigby rifles and 180 between 1939 and 1984. Between 1984 when Paul Roberts took the reins of John Rigby & Co. and 1997 when the company was purchase by Geoff Miller’s investment group 184 more rifles were produced. It was not until Bill Ruger of Sturm Ruger Co. began offering the Ruger Model 77 RSM Magnum Mk II in 1991 that the cartridge finally took off. Ruger produced approximately 1,000 rifles between 1991 and 2001, dramatically boosting the number of .416 Rigby rifles in circulation.\nWith renewed interest in dangerous game hunting in Africa, and the renewed demand for .416 Rigby ammunition, ammunition manufacturers Federal, Hornady and Norma began producing ammunition to meet the new demand. The Kynoch brand name was licensed by Eley to Kynamco, a British ammunition manufacturer, based in Suffolk England, which continues to manufacture .416 Rigby ammunition under the Kynoch brand name.\nDesign & Specifications\nThe .416 Rigby cartridge case is one of the most voluminous designed for a magazine rifle. The case was originally designed to utilize cordite strands invented in the United Kingdom as a propellant. The large case allowed the .416 Rigby to operate at what today would be considered moderate pressures, yet turn in a good performance with regard to velocity and energy. Like many of the big bore cartridges designed during the early 20th century, the .416 Rigby was intended for use in Africa and India. As cordite burnt hot and was susceptible to high chamber pressure variations dependent on ambient temperature, the relatively moderate pressure loading by today’s standards of the .416 Rigby provided a safety margin against dangerously high pressures when used in tropical regions.\nThe .416 Rigby’s dimensions and specifications are governed by the European Commission Internationale Permanente pour l'Epreuve des Armes à Feu Portatives (CIP) which mandates compliance by member nations to these published dimensions and specifications. The CIP mandates a 6 groove barrel with a bore diameter of 10.36 mm (0.408 in) and a groove diameter of 10.57 mm (0.416 in) with each groove being 3.60 mm (0.142 in) wide and a twist rate of 1 revolution in 420 mm (17 in). Commencement of rifling is to begin at 7.62 mm (0.300 in). CIP stipulates a maximum average pressure of 325 MPa (47,100 psi) for the cartridge. At present the North American Sporting Arms and Ammunition Manufacturers' Institute (SAAMI) has not provided recommendations for the .416 Rigby.\nThe original ammunition for the .416 Rigby used cordite as a propellant, firing a full metal jacket or soft-point round nose weighing 27 g (410 gr) at 700 m/s (2,300 ft/s) generating 6,375 J (4,702 ft·lbf) . The current standard using smokeless powder is a 26 g (400 gr) bullet at 730 m/s (2,400 ft/s), generating 6,935 J (5,115 ft·lbf). This is the standard to which Federal, Hornady and Winchester load their ammunition. In its original configuration, the .416 compares favorably with its close counterparts of the era: the .450/400 Nitro Express, .404 Jeffery and the .425 Westley-Richards. The .416 Rigby loaded with the 26 g (400 gr) bullet at 736 m/s (2,415 ft/s) as the Hornady’s DGS and DGX ammunition are, has an MPBR of 181 m (198 yd). The cartridge is capable of producing over 5,400 J (4,000 ft·lbf) of energy at a range of 100 m (110 yd). In comparison, the typical .458 Winchester Magnum firing a 32 g (500 gr) bullet at 620 m/s (2,050 ft/s) manages to stay above the 5,400 J (4,000 ft·lbf) just past the 46 m (50 yd) mark.\nSince the late 1980s, several .416 cartridges have come to the market. Among these, the .416 Remington Magnum, the .416 Ruger and the .416 Weatherby Magnum have garnered the most attention of the firearms press. Both the Ruger and Remington cartridges were designed to emulate the Rigby cartridge’s performance level of a 26 g (400 gr) bullet at 730 m/s (2,400 ft/s). When loaded to their respective maximum average pressure level, both the Remington and Rigby cartridges are capable of driving the 26 g (400 gr) bullet at over 760 m/s (2,500 ft/s). However, the Rigby cartridge is loaded to the relatively low maximum allowable pressure of 325 MPa (47,100 psi) while the Remington cartridge has a stipulated maximum average pressure of 430 MPa (62,000 psi). The case capacity of the Remington case is about 82% of that of the Rigby cartridge. The larger case of the Rigby allows the cartridge to generate the same velocity and energy as that of the .416 Remington but does so at far lower pressure levels. Unlike the Remington and Rigby cartridges, the .416 Ruger, due to its case having even less capacity than the Remington, operates at near its peak allowable pressure to emulate the performance of the Rigby and Remington cartridges’ factory ammunition. The .416 Weatherby Magnum, which uses a case of similar size as the Rigby, is capable of launching the same bullet at 820 m/s (2,700 ft/s).\nWhen designed the .416 Rigby was intended for use against dangerous game in Africa and India. The original 27 g (410 gr) bullet has a sectional density of .338 and at a velocity of 700 m/s (2,300 ft/s) generated 6,375 J (4,702 ft·lbf). The energy generated by the cartridge was on par with that of Rigby’s earlier .450 Nitro Express which, until the ban on the 11.6-millimetre (0.458 in) caliber in India and the Sudan in the early 1900s, had been the standard of measure for dangerous game rifles. The .416 Rigby would in its own right go on to become one of the most successful dangerous game cartridges designed for a magazine rifle.\nJack O’Connor, the noted advocate of small bore high velocity cartridges, took a .416 Rigby on his African safari and successfully took elephant and lion with it. Professional hunters such as John “Pondoro” Taylor, David Enderly Blunt and Harry Selby used the cartridge extensively for the hunting and the culling of elephant and Cape Buffalo. Today the .416 continues to be one of the favored rifle cartridge carried by professional hunters in Africa. J.A. Hunter provided a testimonial to John Rigby & Company stating “You will be pleased to know that the rifle which accounted for all the rogue lions on my last Government Expedition was the 416 Bore Magazine Rifle you supplied me with. I cannot speak too highly of it. Its stopping power was extraordinary, and the fact that all the lions, rhino, buffalo, etc., were shot at comparatively short range, and no other rifle to back me up, speaks volumes for the accuracy and efficiency of your rifle.”\nWhile considered overpowered for the big cats, the .416 is regularly used for the hunting of these felines. In African nations which have enforced a ban on the use of sub 10.2-millimetre (0.400 in) rifle cartridge for dangerous game, the .416 Rigby is one of the first cartridges which can be considered for the hunting of lion or leopard. Prior to India’s independence in 1947 the .416 had success against India’s dangerous game which included the Bengal tiger. However, even the largest of the wild felines weigh no more than 300 kg (660 lb) and are thin skinned species and for this reason cartridges in the 8.6-millimetre (0.338 in) caliber magnums are more appropriate for these species. When using the .416 Rigby to hunt these large felids lighter bullets weighing 19–23 g (300–350 gr) which open up rapidly or fragment are the most appropriate.\nUntil recently, the use of .416 cartridges was mostly confined to Africa, where they were used primarily on dangerous or \"thick-skinned\" large game such as rhino, elephant and Cape buffalo. The .416 Rigby would be considered overpowered for North American game species. However, the .416 Rigby does offer a greater insurance against polar bear, Alaskan brown bear, and useful for the hunting of American bison where allowed.\nAs a Parent Cartridge\nThe .416 Rigby cartridge case is of a unique design in that it had no prior cartridge case acting as a parent cartridge during its development. Due to the volume of the case, the .416 Rigby case has gone on to act as a parent cartridge to several modern cartridges and provide the inspiration to many others. The .378 Weatherby Magnum family of cartridges which include the .30-378, .338-378, .378, .416 and the .460 Weatherby Magnums use a case similar to the .416 Rigby albeit with a belt added to the case design.\nThe .416 Rigby is the parent cartridge for the following cartridges:\n.300 Lapua Magnum\nThe .300 Lapua Magnum cartridge was designed by Lapua of Finland using the .338 Lapua Magnum case which in turn was based on the .416 Rigby. Lapua does not manufacture ammunition for the cartridge and should be considered a wildcat cartridge.\n.338 Lapua Magnum\nThe .338 Lapua Magnum cartridge is a redesign by Lapua of a prior designed by Research Armament Industries (RAI) and Brass Extrusion Labs Ltd. (BELL) known as the .338/416. The Lapua uses a modified .416 case shortened and necked down to accept a 8.59 millimetres (0.338 in) bullet. The cartridge is capable of firing a 15.0 g (231 gr) bullet at 920 m/s (3,000 ft/s).\nThe .450 Dakota was designed by Don Allen of Dakota Arms. It is virtually identical to the .450 Rigby which it predates by a few years. The cartridge is based on the .416 Rigby necked up to 11.6 millimetres (0.458 in). The .450 Dakota fires a 32 grams (500 gr) bullet at 780 m/s (2,550 ft/s).\n.450 Rigby Magnum Rimless\nThe .450 Rigby was designed by Paul Roberts of John Rigby & Company. The cartridge was designed to fire a 31 grams (480 gr) bullet at 725 m/s (2,378 ft/s).\n- .416 Remington Magnum\n- .416 Ruger\n- .416 Weatherby Magnum\n- .450 Rigby\n- List of rifle cartridges\n- Table of handgun and rifle cartridges\n- 10 mm caliber\n- .416 Rigby data from Reloaders Nest\n- Helsley, Steve. \"Rigby Marks 275th Anniversary\", in Safari: The Journal of Big Game Hunters, Safari Club International, Nov-Dec 2009, p.27.\n- Coogan, Joe (October 2002). \"The .416 Rigby:Just Enough\", \"American Rifleman\", pg. 80\n- The .416 Rigby and .416 Remington Magnum by Chuck Hawks\n- John Rigby (Gunmaker's) Ltd. London, England\n- John Rigby & Co.\n- C.I.P. decisions, texts and tables (free current C.I.P. CD-ROM version download (ZIP and RAR format))"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:92d7a9c1-e046-4a72-ae16-c363c7a7d8aa>","<urn:uuid:62ac511a-205b-4cc5-88cc-de5131638caf>"],"error":null}
{"question":"What are the key requirements for corporate indemnification of directors, and how does it relate to social responsibility?","answer":"Corporate indemnification of directors requires three key conditions: the director must have been substantially successful in defending claims, must have acted honestly and in good faith with a view to the corporation's best interests, and must be fairly entitled to indemnity. This connects to social responsibility as corporations must ensure their actions benefit society as a whole and are ethically considered. While companies can protect their directors through indemnification, they cannot do so if the directors breach their fiduciary duties or act against social responsibility principles. Corporate indemnification provisions can be included in company bylaws or separate agreements, but they must align with both legal requirements and broader social responsibility obligations that require businesses to operate ethically and beneficially for society.","context":["A responsibility is a particular obligation for which an individual is to be held accountable, in order to remain upstanding member of a group or community. Good examples of responsibility, include the requirement for a student to complete all of the necessary coursework to graduate on time with the rest of his class, and the need for a parent to provide a good home for his or her children.. To explore this concept, consider the following responsibility definition.\nDefinition of Responsibility\n- The state of being accountable for something or someone that is under one’s control.\n- An instance of being responsible; a burden of obligation.\n- The person or thing for which another is responsible.\n1780-90 Latin respondere\nWhat is Responsibility\nResponsibility is the burden someone is obligated to fulfill in order to meet a particular need. Someone’s level of meeting his responsibilities shows how trustworthy he is, particularly if he consistently meets his responsibilities. The act of an athlete showing up on time for football practice is an example of responsibility. Responsibility can also be used to describe the person or thing for which someone is responsible. For instance, a child is his parent’s responsibility, or keeping track of a company’s finances is a bookkeeper’s responsibility.\nThe idea of social responsibility is a theory in which everyone in society must fulfill their civic duties. What this means is that the actions of each person in any given society should be motivated by a desire to benefit society as a whole. Social responsibility is founded on a system of ethics, in which any decisions made, or actions taken, should be ethically considered. Undertaking an action or decision that is harmful to society or the environment in any way, would be considered socially irresponsible.\nMorality helps people draw a line between what is right and what is wrong. Social fairness, then, is determined by the majority to be “right,” though what is considered to be “right” does not always equal “fair.” Ultimately, however a person chooses to act in the face of social responsibility, the overall outcome must be beneficial to society. The individual must accept the fact that the action he takes – or the decision he makes – may not be beneficial to him personally, but so long as it is beneficial to his peers, then that is the right thing to do.\nExamples of responsibility include a business giving away a portion of the company’s profits to charity, or taking on “greener” initiatives in an effort to benefit the environment.\nBusinesses find that having a strong sense of corporate responsibility actually attracts more business. Customers are drawn to companies that are passionate on similar issues. If a customer cares about the environment, and a company has just announced its intentions of pursuing “greener” methods of doing business, then that customer will probably be drawn to doing business with that company.\nThe environment, in particular, is a major focal point of corporate responsibility because it affects all of society. Businesses, no matter their size, tend to leave larger carbon footprints than any other group, so whatever measures they implement in order to reduce that affect are beneficial to the society surrounding that business, as well as the world as a whole.\nPersonal responsibility is self-explanatory, in that it is the act of taking responsibility for:\n- The things one says or does\n- The actions one undertakes\n- Taking care of one’s business and obligations\nThose who have a strong sense of personal responsibility do not blame others for things that go wrong, depend on others to do the things that they should be doing, or attempt to justify the things they’ve done wrong with an excuse. Responsible people own up to their mistakes, and accept full responsibility for their obligations.\nPersonal responsibility can also be described as a person’s “response-ability,” meaning their capability of responding to, or meeting and fulfilling, the challenges that are presented to him. Someone who is said to have a high level of personal responsibility is also considered to be a person of good character, with high moral and ethical standards. When someone has a low level of personal responsibility, he may play the victim, and blame others or circumstances for how he felt or acted in a situation.\nVictims tend to feel powerless, dependent on others, entitled, apathetic, fearful, and doubtful in difficult situations. People with a higher level of personal responsibility are more likely to stand up to and conquer trials of adversity. The victim is at the mercy of the events that happen around him, while another who approaches such situations proactively, in order to defeat them, are considered to have a greater sense of personal responsibility.\nFiduciary responsibility is the legal obligation that a person or organization has to act in the best interests of another person or organization. A fiduciary is any person or group that is legally responsible for controlling and managing another person or group’s assets or other interests. Those who have fiduciary responsibility include such people as investment managers, stockholders, partners in business, bankers, attorneys, trustees, and even parents who are responsible for their children’s finances.\nFor someone to accept fiduciary responsibility, he acknowledges that he is being given the highest possible level of trust, as he takes on the handling another person’s finances or assets. While fiduciaries are legally responsible for those assets, the assets do not belong to them. Instead, fiduciaries are provided with a legal document that allows them to manage the assets for a specified period of time, or for a very specific purpose.\nFiduciaries must act solely in the principle’s, or clients’, best interests, rather than their own. Fiduciaries must ensure that they are working to avoid any potential conflicts of interest, and that they do not receive any profits whatsoever from the relationship, no matter whether those profits would be direct or indirect. This is not to say that there cannot be some form of pay or reimbursement built into the contract, but the fiduciary cannot undertake any actions in his role as fiduciary for his own benefit. Fiduciaries must consistently act in harmony with the standards imposed on them by society, and the law.\nCivic responsibility is the responsibility imposed on societal members, simply by belonging to that society. It is directly tied to a person’s involvement with the community’s functioning, in its government, and even in its associations. People show civic responsibility when they take action on matters relating to politics, the environment, and the economy, for instance.\nThe strength of a society directly correlates to the effectiveness of the democracy and philanthropy that exists within that community. These things are related to the civic responsibility undertaken by its members. In the United States, it is because Americans participate in civic responsibility that everyone is able to uphold the democratic values written into the Constitution’s Bill of Rights.\nThese values include freedom, justice, equality, tolerance, and due process of law. The point of civic responsibility is to encourage citizens to participate in social issues, and to become willingly responsible for matters that affect the community and the government.\nFiscal responsibility is a difficult term to define because it means different things to different people, depending on the circumstances involved. However, the one thing that everyone can usually agree on is that fiscal responsibility almost always involves the developing of strategies for managing debt and minimizing spending, to create a balanced budget.\nSome believe that fiscal responsibility is knowing when and where to cut debt, while others feel that it’s about eliminating debt entirely while simultaneously making financial plans for the future. Still others believe that fiscal responsibility is the ability to control debt, and that the debt does not necessarily need to be reduced, only managed. While people can be fiscally responsible at an individual level, the term is more often applied to the bigger numbers involved in corporate spending and government finances.\nCorporate Responsibility Example in a Human Rights Violation\nIn the 1990s, Royal Dutch Petroleum Co., which had previously proclaimed its strong commitment to corporate responsibility on its website, came under fire by the people of Nigeria. The company, in league with several others, was accused of helping the Nigerian government to violate international customs law.\nEsther Kiobel was one of several peaceful protestors who had organized to object to Royal Dutch’s presence in the Ogoniland region of Nigeria. Kiobel and the other petitioners alleged that they or their relatives were killed, tortured, held prisoner, forced into exile, and deprived of their property by the Nigerian government because of their protest efforts.\nKiobel and the others accused Royal Dutch of being in agreement with the Nigerian government’s alleged violation of the protestors’ human rights, filing a civil lawsuit attempting to pin responsibility on Royal Dutch and the others. The companies’ response was that the law used to bring the company before a U.S. Court, the Alien Tort Statute, should not apply to this case, and that Kiobel’s attempt to tie the alleged events that occurred in Nigeria to the United States was weak at best.\nKiobel and the others lost in District Court, so they appealed. Royal Dutch fought the appeal, arguing that corporations should not be held responsible for civil liability. Kiobel argued the exact opposite, that corporate actors should be held just as liable for what had allegedly happened as private parties could have been. The Second Circuit Court, however, affirmed the dismissal of Kiobel’s lawsuit.\nThe case eventually made its way up to the Supreme Court. The Court issued a unanimous decision affirming the Second Circuit, reasoning that there was nothing within the “text, history, or purpose” of the Alien Tort Statute that indicated that it could be applied to matters that took place outside the U.S. This meant that Kiobel would only be permitted to sue in the U.S. if she and her fellow protestors could provide strong evidence as to why the United States should be directly tied to their claim.\nRelated Legal Terms and Issues\n- Philanthropy – The practice of offering charitable donations of money and time to help make others’ lives better.\n- Carbon Footprint – The total amount of greenhouse gases emitted due to use of fossil fuels by any one person, group, or company.","Protecting Directors from Civil Liability Through Indemnification\nA likely question an entrepreneur may ask themselves early in their venture is “how do I protect the directors of my company?” They may (or perhaps should) think about this because in all likelihood, they will be one of, if not the only director of their business during its early phases following incorporation. Please note: this post assumes that the company in question is incorporated under the Business Corporations Act of Alberta\nIndemnification refers to one party’s agreement to secure another against responsibility for their actions, or to give security for the reimbursement of a person in case of an anticipated loss. In this case, it refers to a corporation’s agreement to make a director whole, should they be subject to legal proceedings as a result of their actions in their capacity as a director of the corporation.\nGenerally speaking, the Business Corporations Act (the Act) allows corporations to indemnify their directors for both legal costs incurred, as well as any monetary damages that arise from a director’s conduct in relation to the business. In order to benefit from such indemnification, a director must have “acted honestly and in good faith with a view to the best interests of the corporation.”\nAn Alberta corporation is not permitted to indemnify its directors for their actions if they have not acted honestly and in good faith with a view to the best interests of the corporation – that is, if they have breached their fiduciary duty to the corporation. If a director has breached his or her fiduciary duties to the corporation, any indemnity the corporation has offered will be void.\nThe scope of conduct that may be indemnified under the Act is very broad. Section 124(1) of the Act states:\n“…a corporation may indemnify a director or officer of the corporation, a former director or officer of the corporation…against all costs, charges and expenses, including an amount paid to settle an action or satisfy a judgment, reasonably incurred by the director or officer in respect of any civil, criminal, or administrative action or proceeding to which the director or officer is made a party by reason of being or having been a director of that corporation or body corporate…”\nWhen Are Directors Entitled to Indemnification?\nIn Alberta, a director is only entitled to indemnification by the corporation for all costs, charges and expenses, including an amount paid to settle an action or satisfy a judgment in a civil context if they (i) were substantially successful in defending the claim; (ii) acted honestly and in good faith with a view to the best interest of the corporation; and (iii) is fairly and reasonably entitled to indemnity.\nA corporation that does not contain indemnity provisions in its by-laws will still be liable for any loss incurred so long as these criteria are met. If indemnification provisions found in either the corporation’s by-laws, or in an agreement between the corporation and a director impose mandatory indemnification, it will of course be liable to do so.\nHow to Indemnify Directors\nIndemnification provisions can be found within a corporation’s by-laws. If a corporation seeks to provide its directors with a wide range of protection, these provisions do not need to be particularly robust. Any attempt to predict the types of conduct or liabilities that the corporation anticipates indemnifying its directors against may simply limit its ability to protect its directors.\nIf the company’s bylaws do not provide indemnification provisions that are acceptable to a potential director, indemnification provisions may be included within a written agreement between the corporation and the director. This method provides the greatest flexibility as each agreement can be tailored to suit the needs of both the corporation and the individual director.\nSome things that indemnification provisions should contemplate include whether the corporation is required, or simply permitted to indemnify its directors (and in which circumstances), the timing of indemnity payments, and out of court settlement. Indemnification provisions that do not require the corporation to indemnify its directors should also consider a mechanism to oblige the corporation to do so such as arbitration.\nCorporations that provide the widest range of indemnity to their directors often simply state in its indemnification provisions that the corporation must indemnify the director to the greatest extent authorized under the relevant law. Where it is desirable to minimize the short-term financial impact of litigation on directors, indemnity provisions may require the corporation to advance defence costs as they are incurred. Such provisions should also contemplate whether the corporation is required to indemnify the director for out of court settlements, as opposed to simply court judgments.\nWhat Indemnification Provisions Do Not Cover\nIndemnification provisions do not cover directors’ actions when they are not made in good faith with a view to the best interests of the corporation.\nIn cases where a director is being sued by the corporation or its shareholders, including in derivative actions, a corporation may only indemnify a director for their legal expenses. This leaves directors exposed to liability for corporate or shareholder damages arising from their action (or inaction as the case may be). Why is this? Most derivative actions against directors include a claim for breach of fiduciary duty. If this claim is successful, and a breach has been found, a director will have been found not to have acted in good faith with a view to the best interests of the corporation, and indemnity would not be available in any event.\nHamish Gray is a member of the BLG Business Venture Clinic and is a third-year law student at the Faculty of Law, University of Calgary.\n Black’s Law Journal; 2nd ed; online, <a href=\"https://thelawdictionary.org/indemnify/\" title=\"INDEMNIFY\">INDEMNIFY</a>\n Business Corporations Act, RSA 2000 cB-9 s124 [the Act]\n Act supra note 2 s124(3)\nBlog posts are by students at the Business Venture Clinic. Student bios appear under each post."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:8aff89f5-33d2-4d96-a1e9-40262ec5b847>","<urn:uuid:f9f41655-9427-49e4-83bf-cc532fc552b3>"],"error":null}
{"question":"How do student loan discharges through undue hardship compare to regular bankruptcy discharges?","answer":"Regular bankruptcy discharges relieve debtors of most debts automatically upon completing bankruptcy requirements, while student loan discharges require proving undue hardship through an additional adversary proceeding. Student loans are normally non-dischargeable unless the debtor can demonstrate that repaying would cause extreme hardship, typically by passing tests like the Brunner test which requires showing poverty-level living conditions, long-term inability to pay, and good faith efforts to repay. About 40% of debtors who include student loans in bankruptcy get some or all discharged, but it's much more limited than regular bankruptcy discharge which covers most other debts automatically.","context":["One goal of filing Chapter 7 or Chapter 13 bankruptcy is getting a discharge of customer debts. Nonetheless, particular debts are non-dischargeable, and figuratively speaking in many cases are one of them. The only exclusion is whenever a debtor can show that repaying the pupils loans would cause a hardship that is undue. You can get your student loans discharged if you can prove undue hardship.\nIn many courts, you can either have the entirety of one’s education loan released, or perhaps you cannot have it released at all. Particular courts, but, can be happy to discharge a portion regarding the education loan that they employ if you pass the hardship test.\nGenerally speaking you will need to file a Complaint to Determine Dischargeability with the bankruptcy court if you want to discharge student loans. This initiates an adversary continuing separate from your own bankruptcy instance. You may then need certainly to show to your court that repaying loans would cause an undue difficulty. As well as affirmatively showing hardship that is undue you may have different defenses up to a creditor’s proof claim, such as for instance breach of agreement or unjust company methods. You will not need to repay the debt if you successfully prove one or more of these defenses.\nIt is hard to pass through the undue difficulty test, however impossible. A paper that is academic within the United states Bankruptcy Law Journal unearthed that at minimum 40percent of debtors whom consist of their student education loans inside their bankruptcy filing had the ability to find some or all their figuratively speaking released.\nUndue Hardship Test\nUndue difficulty is decided based on various tests, according to the court, but most courts grant a hardship that is undue just in a really slim selection of situations. Most frequently, you will get a student-based loan release just in the event that you encounter a critical impairment that prevents you against having the ability to work and now have dependents, or perhaps you are elderly. It might assist to consult a skilled bankruptcy lawyer that knows which undue difficulty test is used in your neighborhood bankruptcy court and exactly how it really is used. Should your lawyer knows exactly just what courts in your town did in the last, you will have an improved potential for persuading the court. Furthermore, a lawyer makes it possible to litigate a protection to a creditor’s proof claim.\nOne of several tests employed by courts could be the Brunner test. Underneath the Brunner test, it is possible to only discharge figuratively speaking if:\n- Repaying the student education loans would result you unable to maintain even a basic standard of living in you and your dependents living in poverty and make;\n- Your position will stay over a significant percentage of the education loan payment duration; and\n- You get an effort that is good-faith repay the loans.\nAnother test utilized may be the “totality of circumstances test. ” Under this test, courts have a look at all relevant facets to choose whether trying to repay your student education loans poses an undue difficulty.\nIf you fail to pass the undue difficulty test, along with filed for Chapter 7, you are going to still owe the student education loans after your Chapter 7 situation has ended. Nevertheless, in the event that you filed for Chapter 13, you are in a position to spend a lower amount through the length of your Chapter 13 plan, which takes 3-5 years. You shall nevertheless want to repay figuratively speaking, nonetheless, once the Chapter 13 instance is determined along with your customer debts are released.\nWant free appropriate assistance?\nThe http://www.speedyloan.net/reviews/loannow after concern had been submitted to John Roska, an attorney/writer whose regular newsprint line, “The Law Q&A, ” went into the Champaign Information Gazette.\nCan other people be accountable for my debts once I die? In specific, after I die if I make someone my power of power of attorney, to help pay my bills, will they have to repay my debts? We don’t want to burden a person with my debts.\nNo. Individuals don’t inherit financial obligation. Assisting you to spend your bills does make someone liable n’t for many bills.\nContract legislation makes some body responsible for a financial obligation. A fundamental agreement requires an understanding between two events. Most of the time, only those two events are obligated.\nAs an example, in a agreement for the loan, or even for credit, the creditor agrees to provide money, or expand credit, together with debtor agrees to settle. Outsiders into the agreement aren’t liable. Just some contract that is new cause them to liable.\nThere might be implied agreements, centered on conduct and inferences which can be reasonable that are just like appropriate and enforceable as express agreements. It’s a suggested agreement, for instance, which makes a restaurant customer liable for paying the bill. There’s no express contract to cover.\nWith uncommon exceptions, there can’t be a suggested agreement when there’s an express one. Then when you’re accountable for debts considering express contracts—loans, charge cards, utilities—someone else can’t be liable through conduct like spending a bill for you personally.\nThey are able to make their, split contract in order to become responsible for your bills. But that will require an express agreement, plainly aiming their contract to settle your creditor. The work of spending your bills, or elsewhere working out for you, is not sufficient.\nBeing your energy of attorney doesn’t alter that. You whilst the principal simply authorize your representative to expend your hard earned money for your needs. They’re maybe maybe not promising to spend of one’s own pocket.\nAnd, first and foremost, energy of lawyer terminates upon your death. Without having a principal, there’s no agent, because there’s no longer authority.\nServing as your energy of lawyer, then, won’t make some body accountable for the money you owe.\nThe one exclusion to being accountable for another’s debts has been partners. Then, just exactly exactly what solicitors call the grouped Family Expense Act makes one partner accountable for another’s debts each time a financial obligation is actually for a family group cost. Even though just one partner indications a agreement, the legislation presumes that both partners consent to buy a household cost.\nIt is never clear what’s a family group expense, but cases have actually stated that listed below are: medical bills, funeral bills, clothes, precious precious jewelry sometimes, lease when it comes to house, carpeting when it comes to house, and wages for a domestic servant.\nMoney loans, but, aren’t family expense. The debt has got to be for purchasing certain products or solutions.\nObligation beneath the Family Expense Act will be based upon being a partner. One spouse’s liability for the other’s debts might survive their spouse’s death, but started as they had been alive, since they had been hitched.\nFinally, making some body your executor does not cause them to become accountable for the money you owe. They just have actually to settle your financial situation utilizing the assets of the property. If those assets are not enough, the executor is not actually liable, plus the debts just get unpaid.","What is the Bankruptcy Discharge as Explained by a Tucson Bankruptcy Attorney\nAfter an individual goes through either a Chapter 7 bankruptcy or a Chapter 13 bankruptcy and completes the process successfully, that individual will receive a bankruptcy discharge. A bankruptcy discharge relieves a debtor of their personal responsibilities for the specific debt that was discharged by the bankruptcy court.[i] There are some debts that are not dischargeable, so it would be incorrect to think that a discharge order from the court is blanketed over all the debts. The discharge from the bankruptcy court will be provided in a court order and will prevent a creditor from collecting from the debtor personally for debts that the debtor owed prior to the bankruptcy. This means that a creditor cannot call or send any more demand letters to the debtor after the discharge has occurred. Keep in mind that a bankruptcy discharge is only going to be provided for individuals.[ii] Corporations, partnerships, and municipalities are not going to be eligible for a bankruptcy discharge.[iii]\nThe discharge order will be granted at the very end of the proceeding after all the requirements of the debtor have been satisfied.[iv] These requirements could include; completed all the requirements of your personal bankruptcy, attended all the meetings of creditors, provided the court with accurate records of your debts, assets, income, and financial dealings, participated in a session with a credit counselor, and taken a financial management course, and if the debtor has filed a Chapter 13 bankruptcy a�� they have made all the required payments under their personal repayment plan.[v]\nNow, as stated previously, not all debts will be dischargeable through the bankruptcy proceeding. The bankruptcy code provides a list of which debts are eligible and are not eligible for discharge.[vi] Some of the debts that are included on the non-dischargeable list include recent taxes, student loans (unless the hardship test can be established), alimony, and child support.[vii] So, even though every other possible debt a person has could be discharged a�� the above listed are here to stay through the good and the bad.\nAnother type of debt that a discharge will not be successful is liens on secured property.[viii] A lien on a persona��s property occurs when a creditor takes an interest in the debtora��s property in exchange for a loan.[ix] So if the debtor wants to take out a mortgage to purchase the house, a creditor may agree to lend the debtor money but only if the debtor allows the creditor to take an interest in the house itself. This will provide assurance for the creditor that if the debtor fails to pay the money lent to them a�� the creditor will be able to foreclose on the house and make back some of the money. Now, because this type of debt will not be discharged through the bankruptcy, the creditor can still go after the property that has the lien on it.[x] The creditor can repossess cars, or foreclose on homes, and recover as much money as possible. If after the creditor repossess a car or forecloses on a home there is still money owed to the creditor, that creditor CANNOT go after the debtor for the remaining amount. One way for debtors to avoid this from happening to their property is to reaffirm the debt with the lien.[xi] The debtor can do this by agreeing with the creditor that they will continue to pay the creditor, in exchange for the debtora��s ability to keep the property.\nRevocation, Denial, and Objections to the Discharge\nJust because a debtor has filed for bankruptcy and have gone through most of the requirements for the proceeding, the court may still deny the discharge that is typically available to debtors at the end of the proceeding.[xii] The court needs to have a reason for doing so, and some typical reasons include for example, the debtor did not cooperate with the court or the trustee on their case. The bankruptcy discharge may be denied if the debtor lied on their financial documents or even hid assets to avoid having them sold if the asset was not protected by an exemption. Those are just a few examples of when a court may deny to provide the discharge court order. The court could also revoke the court order of discharge if the debtor was found out to be lying do the court, or doing any of the listed above a�� and the court already provided the discharge order.\nThere may also be objections to the discharge order after a debtora��s bankruptcy proceeding. An objection will occur when a party to the case, one of the creditors, disputes whether or not the debt they are connected with should be discharged.[xiii]\nNow, there are two A�types of objections to a Chapter 7 bankruptcy: an objection to a particular debt and an objection against all of the debts.[xiv] The first type of objection will not affect any other debt in the proceeding a�� just the debt that has been objected to. If the court approves this objection, then the debt will be basically be reaffirmed and the debtor will remain liable to pay the creditor for this debt.[xv] Keep in mind that this can occur even if the court decides to discharge all of the debtora��s other debts.\nThe next type of grounds for objection, to all of the debtora��s assets, usually occurs when the creditor or trustee believes that the case has been based off fraud.[xvi] Some ways in which bankruptcy fraud can occur include; perjury by providing false information on your bankruptcy petition and schedules, transferring the title or property to another person to avoid having to claim in during the bankruptcy proceeding, or lying to the bankruptcy trustee or judge during the hearings.[xvii] Some people may think they can be sly during a bankruptcy proceeding, but this process is so invasive into the lives of the debtor a�� the truth is eventually bound to come out. If the truth comes out and shows that the debtor was fraudulent, the debtor may face more than a denial of discharge a�� the debtor will be liable to pay ALL of their debts and the debtor could potentially face jail time. A�Article written by Ariano and Associates.\nWho Can Object to the Discharge of the Bankruptcy?\nSo, is it just the creditor who can object to the discharge of bankruptcy? No. In fact, nany of the debtora��s creditors can object, the Chapter 7 bankruptcy trustee on the account can object, and the United State Trustee can object.[xviii] For the creditors, the typical reason that they might file an objection to the discharge would be if the debtor used false or misleading information on the loan application or financial statement between the debtor and creditor.[xix]\nThe Chapter 7 bankruptcy trustee on the account has the duty of ensuring that all of the debtora��s assets are collected and that all creditors have been treated equally throughout the proceeding. The trustee has the ability to object to a particular debts discharge, or to all of the debts discharge.[xx] Again, the trusteea��s objection will be anchored in bankruptcy fraud. Finally, the United States Trustee can also object to the discharge of debts, and can do so for all of the debtora��s debts.[xxi] This objection can occur if the United States Trustee believes that there was a violation of the United States Bankruptcy Code.[xxii] An example of a violation would be if the debtor did not wait the appropriate period for filing another Chapter 7 bankruptcy.[xxiii] An individual must wait eight years after a Chapter 7 bankruptcy to file for a subsequent Chapter 7 bankruptcy. If the debtor fails to do so, and the court does not catch this, the United States Trustee can step in and object to the discharge of those debts on those grounds.\nAn objection to a discharge MUST be filed with 60 days after the meeting with the creditors takes place for the debtor.[xxiv] The objection must be made in writing and set out specific reasons for why the filing party believes that the debt should not be discharged.[xxv] The objection to the discharge will be reviewed during a proceeding called the adversarial proceeding. An adversarial proceeding is a separate lawsuit that takes place and is heard within the bankruptcy proceeding.[xxvi] The adversarial proceeding will have its own case number, even though it takes place during the bankruptcy proceeding.[xxvii] The debtor may even have a separate attorney during this proceeding.[xxviii]\nOnce the person who the adversarial proceeding is against receives notice of the hearing, that person will have a limited number of days to respond to the complaint against them. The response time allotted will depend on the state and the court. In the case of an objection to the bankruptcy discharge, the debtor will be the person who receives notice of the adversarial proceeding. The adversarial proceeding will be heard and decided upon before the bankruptcy proceeding overall can be decided.[xxix] If the judge within the adversarial proceeding finds in favor of the debtor, then their eligible debts may be discharged.[xxx] If the judge, however, finds for the creditor or trustee, then the debt will NOT be discharged and the debtor will remain liable to pay for the debt after the other debts have been discharged through the bankruptcy proceeding. Just like any other proceeding, the adversarial proceeding can be settled before the proceeding concludes.[xxxi]\nConclusion to Bankruptcy Discharge\nWhile many people believe that filing for bankruptcy is a quick way to get out of their financial responsibilities, there are a lot of obstacles to overcome in the proceeding to ensure that everything goes according to plan. After the bankruptcy proceeding, for either Chapter 7 or Chapter 13, the court still has to provide a court order for a discharge of the debtora��s debts. The discharge may be prevented by a number of ways. The court could decide to deny the discharge if the court finds that the debtor was fraudulent, or the court could revoke the discharge order for the same reason if new evidence comes to light after the court has been granted. Creditors, Chapter 7 bankruptcy Trustees, and even the United State Trustee can also object to the discharged based on fraudulent grounds. Overall, just because the bankruptcy proceeding is completed or coming close to completion, there is no guarantee that the debtora��s debts will all be discharged. If any sign of fraud becomes known, the entire bankruptcy proceeding could be compromised. A�For more information contact an affordable bankruptcy lawyer in Tucson at Ariano & Associates.\n[i] See What is the Bankruptcy Discharge. NOLO Legal Encyclopedia. (Accessed April 22, 2016). http://www.nolo.com/legal-encyclopedia/what-is-the-bankruptcy-discharge.html\n[ix] See What is a Secured Debt. NOLO Legal Encyclopedia. (Accessed April 22, 2016). http://www.nolo.com/legal-encyclopedia/what-secured-debt.html\n[x]A� See What is the Bankruptcy Discharge. NOLO Legal Encyclopedia. (Accessed April 22, 2016). http://www.nolo.com/legal-encyclopedia/what-is-the-bankruptcy-discharge.html\n[xiii] See Objections to the Bankruptcy Discharge. NOLO Legal Encyclopedia. (Accessed April 22, 2016). http://www.nolo.com/legal-encyclopedia/objections-the-bankruptcy-discharge.html\n[xxvi] See Adversary Proceedings in Bankruptcy. NOLO Legal Encyclopedia. (Accessed April 22, 2016). http://www.nolo.com/legal-encyclopedia/adversary-proceedings-bankruptcy\n[xxvii] See Adversary Proceedings in Bankruptcy. NOLO Legal Encyclopedia. (Accessed April 22, 2016). http://www.nolo.com/legal-encyclopedia/adversary-proceedings-bankruptcy.html\n[xxx] See Objections to the Bankruptcy Discharge. NOLO Legal Encyclopedia. (Accessed April 22, 2016). http://www.nolo.com/legal-encyclopedia/objections-the-bankruptcy-discharge.html"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:331898e1-ba15-4ca7-9c14-4a1e68d30ca5>","<urn:uuid:f7c2782c-90ff-4190-b204-9f5f8aac040b>"],"error":null}
{"question":"What are the key differences between Impressed Current Cathodic Protection (ICCP) systems and hot dip galvanizing in terms of their protection mechanisms and maintenance requirements for corrosion prevention?","answer":"ICCP systems and hot dip galvanizing differ significantly in their protection mechanisms and maintenance needs. ICCP systems use an external power supply (DC) to directly apply current to the surfaces prone to corrosion, controlling the metal's potential at a fixed value to prevent anodic dissolution. These systems require ongoing power supply and monitoring, using corrosion-resistant anodes like platinized niobium. In contrast, hot dip galvanizing is a sacrificial coating method where the metal is immersed in molten zinc, forming an alloy that bonds to the substrate. The zinc coating acts as a sacrificial anode to protect the underlying metal through galvanic action. While ICCP systems need constant power and monitoring, hot dip galvanizing requires no power source but does need periodic reapplication as the zinc coating is consumed over time. Hot dip galvanizing is particularly suitable for corrosion categories C3 to C5 when used as part of a duplex system, while ICCP systems are primarily used as backup to coating systems in marine applications.","context":["Anti corrosion coating prevents rust on steel and other ferrous metals\nAnti corrosion coating acts as a barrier between a metal (usually steel) and its environment, and increases its durability and lifespan. The roughly estimated global cost of metal corrosion damage is trillions of rials. The good news is, a lot of this loss can be prevented by being proactive, and making the right choice of anti corrosion coating from the start.\nTo determine the best rust proof metal coating for your project, it is important to factor in the environment and type of metal. Whether corrosion is due to moisture, chemicals, salt spray, prolonged exposure to sunlight or oxidation, corrosion resistant coating for steel and metal can help protect the substrate from the elements.\nRust proof metal coating is not just one type of paint\nAnti rust coating is essentially a collective name for various types of coatings that protect a metal substrate from corrosion. An anti corrosion coating can do more than just protect from corrosion, and its multi-functional nature means that it is possible to find the exact coating your project requires. Corrosion is caused by a chemical reaction between a metal and its environment, typically producing an oxide or a salt of the original metal. The long and the short of it is the metal is weakened, as is the structure it creates. An anti corrosion paint prevents direct contact between water, fluids or another hazard (UV radiation) and the steel substrate and therefore prevents or slows down the corrosion process.\nIn general anti corrosion coating is suitable for almost any type of steel and metal, and has the following 5 benefits:\n- Fends off fungi, algae, and moss\n- Weather protection against acid rain, salt water, ice and so on\n- Chemical resistance\n- Repels water & other fluids (in case of barrier coatings)\n- Depending on the type of anti-corrosion coating you opt for: anti fouling, non slip or self cleaning properties\nIdentify the corrosion category to pick the best anti corrosion coating\nTo determine the most suitable anti corrosive coating for your project, you need to understand the environment and use of the substrate; especially its exposure to water, moisture, and other aggressive substances that might be present in the environment. The corrosivity of certain atmospheres has been classified and standardised by the International Organization for Standardization (ISO). The standard divides the degree of corrosivity into 5 categories , C1 to C5, in order of increasing corrosivity. To find the right anti-corrosion coating, you need to know how corrosive the environment will be. For example, a coating at C5M level is intended for offshore constructions an pipelines which are constantly exposed to moisture, but also for small pipes that are equally exposed. An example of such applications is the Al Ain – Fujairah pipeline, as part of the Dolphin Gas Project where Ras Laffan is in a key position, that exports natural gas from Qatar to Oman; the pipe is 182 kilometers long and is protected with rust proof coating all the way.\n- C1 – very low corrosion risk: Heated buildings with clean air, interiors only.\nSuitable for: offices, schools, hotels, shops and other heated premises.\n- C2 – low corrosion risk: Unheated buildings, rural areas.\nSuitable for: storage facilities, sports halls, garages, barns and other unheated buildings.\n- C3 – moderate corrosion risk: Buildings with high humidity, urban and industrial areas.\nSuitable for: laundries, breweries, kitchens, food processing sites and other buildings with moderate humidity.\n- C4 – high corrosion risk: Chemical manufacturers and swimming baths, industrial and coastal areas.\nSuitable for: industrial buildings, chemical plants, swimming pools, ports, and ship- and boatyards.\n- C5 – very high corrosion risk: Buildings with almost permanent condensation, offshore and industrial areas.\nSuitable for: Water pipes and other industrial applications (C5I – industrial). Offshore and maritime constructions (C5M – marine).\nOnce you have determined the corrosivity of your environment, you can determine the right coating systems for your project and the right anti corrosive coating specification to protect it for years to come. Following these guidelines will allow you to pick appropriate anti rust coatings, allowing you to avoid overspending on unnecessary degrees of protection or simply making the wrong choice.\nThe 3 options for industrial anti rust coatings\nAnti corrosion coatings can be divided into three categories:\n- Barrier coatings (C1 – C3) – non-porous coatings (anti corrosion paint) designed to prevent corrosive factors coming into contact with the substrate.\nFor example: powder coating, polyurethane paint, chloro rubber paints, Teflon coatings, nano coatings.\n- Inhibitor coatings (C1 – C4) – release a chemical which interferes with the electrolyte and stops the corrosion process.\nFor example: all oil based coatings with corrosion inhibitor additives such as zinc, aluminum, zinc oxide and so on.\n- Cathodic protection with galvanic coatings (C3 – C5) – metal-rich coatings which provide a sacrificial layer. Prevents corrosion by providing a more easily corroded metal (such as zinc) to be the anode to the protected metal’s cathode. Also called the sacrificial anode, this metal will corrode instead of the protected metal.\nFor example: hot dip galvanizing which provides steel (cathode) with a layer of zinc (anode).\nKeep in mind that for categories C4 and C5 it is not recommended to apply the coating yourself. Please search out a specialist in that case.\nApply anti rust coating by spraying or dipping\nThe two most common methods for applying an industrial grade anti corrosion coating for steel are hot dip galvanising and thermal (metal) spraying. Barrier coatings and corrosion inhibitor coatings can also be applied by spraying or dipping.\nHot Dipping is the process of immersing a metal in a bath of metal, often molten zinc,(or a polymer) in order to form a coating. The liquid metal bonds to the substrate and forms an alloy, which is then coated in zinc as it is removed from the bath. Hot dip galvanising uses the principle of cathodic protection, as the zinc coating acts as an anode to its substrate.\nThermal spraying applies zinc or aluminium to a substrate by taking the metal in the form of a powder or wire and feeding it into a special spray gun. The metal melts within the gun and can then be sprayed onto the substrate. It does not alloy, but instead works by coating the surface in overlapping metal platelets.\nDuplex System creates the best anti corrosion coating\nWhen hot dip galvanising is used together with a top coat of anti corrosion paint or powder it is known as a Duplex System.\nA duplex system provides multiple types of protection and the longest-lasting results. Each layer with anti corrosive properties needs to be compatible in order to allow the system to work optimally. It is particularly suitable for corrosion categories C3 to C5 and looks like this:\n- Surface preparation: derusting, blasting, removing grease, oil, dirt for optimum adherence.\n- Primer: hot dip galvanisation OR applying an inhibitor coating primer depending on the coating system of your choice.\n- Sealer: To seal the anti corrosion coating. Often epoxy based.\n- Intermediate coat: there may be several layers necessary for optimum protection, depending on the corrosion category.\n- Finishing coat: provides appearance and surface resistance, often first line of defence.\nAnti rust coating spray and paint for small projects\nFor smaller substrates or do-it-yourself application up to category C2, painting at home is also an option to consider. There are also small anti corrosion coating spray cans available for this purpose. An anti corrosion spray can be described as an ultra thin fluid film compound which you can spray on any steel or other metal surface. In spray form it can protect for up to a year. Keep in mind that more exposed areas which are getting constant abuse from rain and salt will need spraying regularly. In paint form, longer lasting results can be accomplished depending on the coating system you choose. For the best result always opt for a two component coating with corrosion inhibitor additives, for example a zinc rich epoxy paint or primer.\nFind an anti corrosion coating expert in Qatar\nIf you are looking for a professional company to apply anti corrosion coating for you, it’s important to understand how prices are established before you request a quote. Different coating processes use different methods to calculate the cost of professional application. Hot dip galvanising prices are usually calculated by weight. The galvaniser will quote a price per tonne, and then use the weight of your steelwork after galvanising to calculate the final cost. Unlike galvanising, powder coating prices tend to be calculated by size or surface area.\nRegional differences in materials, labour, and equipment can all have an impact on overall costs when contracting a coating expert. If you want to receive a custom made quote, please contact us.\nHere are a few examples of local anti-corrosion specialists in Qatar:\n|Anti corrosion coating company||Address||Specialization|\n|Hitech Projects||56 Salwa Rd, Doha 201646, Qatar||Application of industrial anti rust paints|\n|Hertel||Office 202, 2nd Flr, Bldg 141, Thani Bin Jassim St, Gharafa||Application of industrial anti rust paints|\n|Hempel Paints Qatar WLL||St 16, Gate 96, Salwa Ind Area||Distribution of industrial anti corrosion coatings|\n|Henkel Polybit||Sh Eid Bin Mohd Bldg, Frij Bin Mahmoud, Al sadd, Doha||Manufacture of industrial and offshore corrosion resistant coatings|\n|Petrogulf WLL||11th-Flr. Almana Business Tower, C-Ring Road, Doha, Qatar||Application of industrial and offshore anti corrosion paints|","Cathodic protection is a widely used and accepted form of corrosion prevention. The goal of cathodic protection is to reduce the deterioration of a metal exposed to an aqueous electrolyte by lessening the thermodynamic driving force for corrosion. A properly maintained cathodic protection system can effectively eliminate metal dissolution and provide a long-term solution to many corrosion problems. The two cathodic protection systems that are most important to the marine industry are (1) sacrificial anode and (2) Impressed Current Cathodic Protection (ICCP). Figure 1 is an excerpt from Naval Ships Technical Manual Chapter 633 and lists many of the advantages and disadvantages of these two methods for naval ships.\nFigure 1: Adapted from Naval Ships Technical Manual: S9086-VF-STM-010/CH-633 p 13.\nIt is important to note that sacrificial anode and ICCP systems present an effective means of corrosion protection only when they are submerged in a conductive fluid medium. Anodes do not work in air due to its limited charge-carrying ability.\nThis type of cathodic protection involves the coupling of an active metal to a structure for which corrosion protection is desired. In this system, the active metal corrodes preferentially and provides protection for the structure. In other words, one metal is sacrificed to protect the other.\nTwo dissimilar metals or alloys joined together in an electrolyte form what is called a galvanic couple or galvanic cell. Any metal or alloy, when submerged in a conductive electrolyte, has its own unique corrosion potential (open circuit potential). Figure 2 provides a listing of various alloys and their potentials in seawater. This chart, known as a galvanic series, provides meaning to the terms active and noble in reference to metals. The further down and to the left a metal appears in the series, the more active or prone to corrosion it is. The most noble, or corrosion resistant, metals appear at the top of the series.\nFigure 2: Galvanic series of metals and alloys in seawater. Potential values are shown as ranges. Adapted from Naval Ships Technical Manual: S9086-VF-STM-010/CH-633 p 6 and D. Jones Principles and Prevention of Corrosion 2nd Ed. page 170.\nWhen an electrical connection is established between two dissimilar metals in a conductive environment, electrons will flow from the more negative (active) surface to the more positive (noble) surface. The electrons that flow to the noble metal drive it to more negative potentials (cathodic polarization). This current flow and polarization correspond to an electron surplus that reduces the rate at which the noble metal corrodes. As an example, a zinc block welded to a steel hull forms a galvanic couple in seawater. As shown in Figure 2, zinc is more active than steel. The anodic reactions for steel and zinc in seawater are:\nFe ® Fe2+ + 2e– (1)\nZn ® Zn2+ + 2e– (2)\nIf an excess of electrons is provided to the steel surface where reaction (1) is taking place, a driving force for the reverse reaction will be present. As a result, the oxidation of metal will be slowed. The source of these electrons, in this case, is the corrosion of the zinc block, reaction (2), attached to the steel surface.\nIn summary, when a galvanic couple is immersed in an electrolyte, corrosion will take place on the surface of the more active metal. The more noble metal in the couple, acting as a cathode, will be protected from corrosion. In the presented case of zinc coupled with steel in seawater, zinc will corrode preferentially and provide protection to the steel.\nSacrificial anodes need be nothing more than a block of metal electrically connected to the surface to be protected. There are, however, a few electrochemical properties to consider when creating a successful sacrificial anode system. The corrosion potential of the anode must be active (negative) enough to drive current through the electrolyte. The resistance of the electrolyte and the separation between anode and protected structure play a role in the effectiveness of the system. The higher the resistance and separation between anode and structure, the more active the anode must be. Periodic replacement of sacrificial anodes is necessary due to continuous consumption by corrosion. The cost of replacing anodes, however, pales in comparison to the potential costs of corrosion damage.\nZinc anodes are often used in marine applications and are effective at reducing corrosion of steel structures in seawater. Zinc anodes, while effective, tend to be consumed rapidly. Aluminum anodes have been developed for longer service life than zinc in seawater. The corrosion rate of the aluminum-protected steel may be higher than the cases where zinc is used but for many applications is still acceptable.\nOn the majority of U.S. Navy ships, the primary source of underwater hull corrosion protection is anti-corrosive coating systems. Impressed current cathodic protection systems serve as the primary back-up to the coating system. Sacrificial anodes are also installed on the underwater hull and in sea chests as a supplement to coating systems and ICCP systems.\nThe Navy also uses zinc sacrificial anodes or “zincs” in several other applications. Zincs are used inside ballast tanks, bilges, heat exchangers, collection, holding and transfer (CHT) tanks, and in various machinery.\nFigure 3: Inside of ballast tank protected by zinc sacrificial anode.\nZinc anodes must conform to MIL-A-18001 and MIL-A-18001 Amendment 1. Aluminum anodes must conform to MIL-A-24779/QPL-24779.\nImpressed Current Cathodic Protection Method\nAnother effective method of cathodic protection involves the direct application of current from an external power source to surfaces prone to corrosion rather than by using sacrificial anodes previously discussed.\nThe basic principle of the two methods is the same. In both cases, the vulnerable metal is supplied with a surplus of electrons. The excess electrons reduce the potential of the metal (cathodic polarization) and tend to drive the anodic corrosion reaction in reverse. This results in a reduced corrosion rate. The general form of the anodic reactions discussed above is:\nM ® Mn+ + ne–\nIn the above equation, M represents the atomic symbol of some metal and n is the number of electrons involved in the reaction. Excess electrons supplied to the surface slow this reaction. Both sacrificial anode and impressed current cathodic protection techniques operate on the same basic principal; the source of current, however, differs. Impressed current systems use an external power supply (DC) such as a battery or rectifier to supply the current necessary to provide cathodic protection.\nMost ICCP systems are designed to control the potential of the metal at a fixed value where anodic dissolution of the metal effectively does not occur. This is known as controlled-potential cathodic protection and is the method used most extensively for ship hulls and seawater applications. A controlled-potential system consists of the following basic components: a power supply, a transformer-rectifier (to convert the AC signal to DC), anodes, reference electrodes, and a dielectric shield. The dielectric shield prevents shorting of the anode current to the hull adjacent to the anode, allowing wider current distribution.\nFigure 4: Diagram of basic ICCP system. Taken from Naval Ships Technical Manual: S9086-VF-STM-010/CH-633 p 18.\nUnlike sacrificial anodes, impressed current anodes are designed to be resistant to corrosion. Desirable properties include low resistance to current flow, physical toughness, low rate of consumption, and low cost of production. Platinum is an ideal candidate for impressed current anodes because consumption is almost non-existent; however, it is cost-prohibitive. Using platinum-coated titanium rather than solid platinum for the anodes can reduce cost. The Navy specifies exclusive use of platinized niobium impressed current anodes for its ships.\nThe US Navy designs ICCP systems at the Naval Research Laboratory in Key West, FL. The methods used by the Navy ensure optimum anode to reference cell configuration and location to provide the best protection to the ship.\nDielectric Shield Coating Requirements\nICCP system anodes are surrounded by thick shielding material (often referred to as “capastic coating” or “capastic epoxy”) consisting of a high-solids epoxy with high dielectric strength. As noted above, this shielding prevents shorting of the anode current to the hull near the anode and aids in wider current distribution to the hull. The dielectric shield includes an inner and outer shield and covers an area about 13 x 16 feet around a 4-foot anode or 13 x 20 feet around an 8-foot anode. The shield is topcoated with anti-corrosive and anti-fouling coatings. The shielding deteriorates over time and eventually requires replacement. Dielectric shield material is not covered by a military specification.\nThe Standard Specification for Ship Repair and Alteration Committee (SSRAC) is responsible for providing technically and contractually sound standards for the Navy’s ship repair and alteration community. The NAVSEA Standard Item applicable to surface ship preservation is Standard Item 009-32, “Cleaning and Painting Requirements.” It contains cleanliness, surface preparation, and coating application requirements, along with complete system application instructions for each product (number of coats, coating thickness per coat, etc.) approved for cathodic protection system preservation. All current NAVSEA Standard Items may be found here.\nNew Construction Ships\nNew construction ships are painted in accordance with the specific Ship Specification for that class of ship.\nNAVSEA Point of Contact\nNaval Sea Systems Command, SEA 05P23\n1333 Isaac Hull Ave., SE\nWashington Navy Yard\nWashington, DC 20376\nPhone: (202) 781-3670\n- D. Jones, Principles and Prevention of Corrosion, Prentice Hall, New Jersey (1996)\n- V. G. DeGiorgi, E. Hogan, and S. A. Wimmer, “New Horizons in Cathodic Protection Design,” U.S. Naval Research Laboratory. Online. http://www.nrl.navy.mil/content.php?P=04REVIEW51. (2003)\n- A.R. Parks, E.D. Thomas, and K.E. Lucas, “Verification of Physical Scale Modeling with Shipboard Trials,” Corrosion 90, Paper 370, National Association of Corrosion Engineers (1990).\n- K.E. Lucas, E.D. Thomas, A.I. Kaznoff, and E.A. Hogan, “Design of Impressed Current Cathodic Protection Systems for the U.S. Navy,” Designing Cathodic Protection Systems for Marine Structures and Vehicles, American Society for Testing and Materials, Special Technical Publication (STP) 1370, H.P. Hack (ed.), 17-33 (1999).\n- R.A. Adey and S.M. Niku, “Computer Modeling of Corrosion Using the Boundary Element Method,” Computer Modeling in Corrosion, American Society for Testing and Materials, Special Technical Publication (STP) 1154, R.S. Munn (ed.), 248-264 (1992).\n- V. G. DeGiorgi, E. Hogan, K.E. Lucas, and S. A. Wimmer, “Computational Modeling of Shipboard ICCP Systems,” J. Corrosion Sci. and Eng. (http: www2.umist.ac.uk/corrosion/JCSE/), 4, Paper 3 (2003).\n- V.G. DeGiorgi, A. Kee, K.E. Lucas, and E.D. Thomas, “Examination of Modeling Assumptions for Impressed Current Cathodic Protection Systems,” in Proceedings of the Corrosion ’99 Research Topical Symposium, Cathodic Protection: Modeling and Experiment, National Association of Corrosion Engineers, 1-16 (1999).\n- V.G. DeGiorgi, E.D. Thomas, and K.E. Lucas, “Scale Effects and Verification of Modeling of Ship Cathodic Protection Systems,” Eng. Anal. Bound. Elements 22, 41-49 (1998).\n- NSTM Chapter 633: Cathodic Protection\n- U.S. Navy Underwater Safety Handbook, Chapter 19 (Cathodic Protection Systems)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:a624905d-7651-44c8-93b5-47208e9d4c10>","<urn:uuid:6d0b12e4-0280-4097-a150-b1e8b866b915>"],"error":null}
{"question":"With increasing water infrastructure problems causing concern, could you explain: What are the current challenges with water infrastructure in the US, and how does power generation affect water availability?","answer":"In the US, 2.1 trillion gallons of clean water are lost annually due to poor infrastructure, including old, leaky pipes and broken water mains. Fixing America's water infrastructure will cost an estimated trillion dollars, according to the American Water Works Association CEO. Regarding power generation's impact on water availability, power plants account for 45% of total water withdrawals in the US. Traditional energy sources like coal are particularly water-intensive, requiring 20,000 to 50,000 gallons per megawatt-hour, while renewable sources like wind power require almost no water at all.","context":["Explanation: How much of planet Earth is made of water? Very little, actually. Although oceans of water cover about 70 percent of Earth’s surface, these oceans are shallow compared to the Earth’s radius. The above illustration shows what would happen is all of the water on or near the surface of the Earth were bunched up into a ball. The radius of this ball would be only about 700 kilometers, less than half the radius of the Earth’s Moon but slightly larger than Saturn's moon Rhea which, like many moons in our outer Solar System, is mostly water ice. How even this much water came to be on the Earth and whether any significant amount is trapped far beneath Earth's surface remain topics of research.\nIllustration Credit & Copyright: Jack Cook, Woods Hole Oceanographic Institution, Howard Perlman, USGS\nAs climate change heats lakes, streams and the ocean, toxic cyanobacteria contamination rises.\nIn 2015, drought and low snow pack throughout the West has led to large and toxic algal blooms earlier than in previous years.\nIn a related marine concern, all along the West Coast many shellfish harvests are closed due to an ongoing event of domoic acid shellfish poisoning, producing what is thought to be the largest algal bloom in recorded history.\nNo testing for cyanobacteria is mandated by state or federal drinking water regulators, according to scientists from Oregon State University, nor is reporting required of disease outbreaks associated with algal blooms. But changes in climate and land use, and even increasing toxicity of the bacteria themselves, may force greater attention to this issue in the future, the researchers said.\nScientists said a concern is that nutrient over-enrichment may select for the more toxic populations of these bacteria, creating a positive feedback loop that makes the problem even worse.\nCyanobacteria are ubiquitous around the world, and a 2007 national survey by the EPA found microcystin, a recognized liver toxin and potential liver carcinogen, in one out of every three lakes that were tested. Some of the toxic strains of cyanobacteria can also produce neurotoxins, while most can cause gastrointestinal illness and acute skin rashes. [emphasis mine]\nGreen energy would mean more water for us to use.\n... power plants are significant water users across the U.S., accounting for 45 percent of total water withdrawals.\nThe Union of Concerned Scientists reports that, on average, producing the electricity you use in your home results in more freshwater withdrawals than all of your daily water-related tasks, like sprinkling lawns and washing dishes. Where that electricity comes from makes a big difference in how much water is involved, though. Thirsty energy sources like coal can take 20,000 gallons per megawatt-hour to 50,000 gallons per megawatt-hour, while wind power requires almost no water at all.\nBy 2025, two-thirds of world’s population may face water scarcity.\nWelcome to the Anthropocene Era, where lakes can get so polluted they foam and catch fire.\nBengarulu lake in India.\nOld landfills become toxic timebombs as climate change accelerates the water cycle and sea level rises, threatening groundwater with leached chemicals.\nThousands of landfill dumps around the UK are at risk of being compromised by flooding and coastal erosion, sparking fears that dangerous substances could spill into rivers, streets and beaches, academics warn.\nThe UK faces a “toxic timebomb” after an analysis of its ageing dumps revealed that 2,946 are located in flood plains, experts say.\nFurthermore, 1,655 of these “historical” landfill sites contain dangerous materials such as hazardous chemicals and asbestos,...\nToxic algae poison more than a third of small streams in Alabama, Virginia, and the Carolinas.\nScientists with the U.S. Geological Survey have found toxins produced by algae, known as microcystins, in 39 percent of the small streams assessed in the southeastern United States.\nTheir study looked at 75 streams in parts of Alabama, Georgia, North Carolina, South Carolina and Virginia.","Water Scarcity Woes: A Global Problem That’s Getting WorseSep 30, 2021 06:30AM ● By Jeremiah Castelo\nWater scarcity is a legitimate concern.\nIt is true that the hydrologic cycle, the process in which the Earth circulates water throughout its ecosystems, is a closed-loop cycle that neither adds nor takes away water. In theory, the amount of water on Earth will always remain the same. But problems occur when the hydrologic cycle is disrupted, causing some regions to grow arid while others get constant floods. The human activities that disrupt that process include the building of dams, the industrial pollution of waterways, the paving of roads, excessive drilling and bottled water privatization.\nHere are 10 of the most alarming water scarcity facts that the world is currently facing.\n1. By 2025, half of the world’s population will be living in areas of water stress as people will be unable to access the water they need. Climate change, population growth, agricultural demands and mismanagement of water resources all contribute to the growing water crisis.\n2. The world’s population will rise to 9.7 billion by 2050, leaving even more people in water-stressed conditions. An estimated 60 percent of all surface water on Earth comes from river basins shared by separate nations and almost 600 aquifers cross national boundaries. In places where water is already scarce, this can lead to geopolitical conflict.\n3. Three in 10 people on Earth currently do not have access to safe and clean water. According to the World Health Organization, 2.1 billion people do not have access to a safely managed water source. An estimated 263 million people must travel over 30 minutes to access water that isn’t clean, and 159 million still drink from untreated surface water sources.\n4. One in three people worldwide does not have access to a toilet. Around 2.3 billion people lack access to even basic sanitation services, forcing them to either practice open defecation or use pit latrines and buckets. Fecal contamination in the water supply is a major cause of deadly waterborne diseases such as hepatitis A, norovirus and E. coli.\n5. Annually, 1.6 million people die from waterborne diseases. Of the 5 million people that become ill from bad water, most are children.\n6. Water privatization causes harm. When corporations site water bottling operations in developing countries like India and Bolivia, they significantly deplete supplies needed by local farmers. In the U.S., when a struggling public water or electricity utility sells their rights to a private corporation, household water and sewer services typically become, respectively, 59 percent and 63 percent more costly.\n7. In the U.S., 2.1 trillion gallons of clean water is lost each year due to poor infrastructure, including old, leaky pipes and broken water mains. David Le France, CEO of the American Water Works Association, estimates that repairing America’s water infrastructure will be a trillion-dollar program. Due to divided efforts in governmental decision making, adequate policies and budgeting are often difficult to come by.\n8. Often, water burdens fall upon women, some of whom walk four miles a day just to fetch water that is likely contaminated. In sub-Saharan Africa, for example, it takes about six hours to carry a 44-pound container of water from a source that often has the potential to make them sick, according to the Global Water Institute.\n9. One-third of the world’s largest aquifers are water-stressed. Underground aquifers are naturally replenished through rainfall and surface water, but a deficit occurs when more water is pumped out than replenished. Eight of the biggest aquifers, including those in Saudi Arabia, northwestern India and Pakistan, are not being replenished at all.\n10. Meeting the United Nations’ sustainable development goals for the water crisis will cost $114 billion per year. Attaining these critical goals will be time-consuming, expensive and may face political division. Yet the cost of not doing so is also high. Addressing healthcare needs due to water-related diseases and poor sanitation costs $260 billion globally each year.\nWater scarcity is real. To ignore it or to assume that it is only a problem of the developing world is to be blind to the reality that the rest of the world is experiencing. Excessive water consumption and poor water management are factors that can be controlled. Supporting clean water initiatives will certainly help the movement against the global water crisis. Finally, educating ourselves and raising awareness is a task we should all take on."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:b204a991-43e3-47e8-b944-7a5ead642f91>","<urn:uuid:1093fcb7-2fa7-4b76-9d96-896f7106092a>"],"error":null}
{"question":"Both Philinda Humiston and Chaplain Wainwright supported soldiers' families - how did their roles differ?","answer":"Philinda Humiston and Chaplain Wainwright supported military families in distinct ways. Philinda Humiston took on a supervisory role at the National Soldier's Orphan Home in Gettysburg, which cared for children of fallen Union soldiers, providing direct support to military families who had lost their fathers. Chaplain Wainwright, on the other hand, provided spiritual support to active-duty soldiers and their families at Fort Hood, emphasizing that 'God loves all Soldiers' and helping them maintain their spiritual core. He focused on showing soldiers that their military service was compatible with faith, stating that wearing combat gear doesn't make one 'unclean or less loved' by God.","context":["News: Greywolf leader baptized at range\nStory by Pfc. Benjamin Fox\nBy Spc. Ben Fox\n3rd Brigade Combat Team, 1st Cavalry Division Public Affairs\nFORT HOOD, Texas – At a range, the Soldier began his day by running and firing at targets, carrying heavy loads and evaluating mock casualties.\nAfter completing a test that visually showed his physical and mental capabilities on the battlefield, he would visually show his faith.\n1st Lt. Benjamin Harrow, a platoon leader with Headquarter and Headquarters Troop, 3rd Battalion, 8th Cavalry Regiment, 3rd Brigade Combat Team, 1st Cavalry Division, was baptized at House Creek Assault Course on Fort Hood, Texas, May 21.\n\"I wanted to get baptized before I went over to Iraq, but it just seemed like the timing was never right and things just weren't coming together for it,\" said Harrow.\n\"Finally when we got back, I talked to the chaplain ... about it,\" said the Wilmington, N.C. native.\nAlbuquerque, N.M., native Capt. Kevin Wainwright, the 3-8 Cav. chaplain, baptized Harrow.\n\"This is a combat unit, he is an infantry officer and this is bringing God to Soldiers and Soldiers to God,\" said Wainwright.\n\"He said he would try to put something together that was pretty special, and this is pretty special, coming out to the field with all the guys here during training and getting baptized out here,\" said Harrow. \"It was a little different and I think different, sometimes, is good. Out here with all of the guys and the shooting going on and the tone of religion, it lets you take a step back and realize the bigger picture.\"\n\"This was a Christian sacrament, and I don't want to take anything away from that, but what I also want to get out is that God loves Soldiers. He loves all Soldiers,\" said Wainwright. \"I think this is a visible reminder of God's love for Soldiers, and also a visible reminder of how important our spiritual core is.\"\n\"It's something that we don't focus on a lot... but when we face that moment of crisis, if you don't have something to reach back to, it can be a pretty lonely and hard place to be,\" he said. Wainwright said this event was also important to help Soldiers break the stigma that what they do is evil or wrong.\n\"When I look at scripture and faith and God ... God has a place in his heart for the warrior person of faith,\" said Wainwright.\n\"I think it was a good visual reminder that wearing this stuff (combat gear) doesn't make you unclean or less loved or somehow God wouldn't want his presence to be here,\" he said. \"God wants to be here; God wants to be in the heart of our Soldiers.\"\n\"I think a little spiritual health is good for all Soldiers, especially when you deploy and you go through some tough times, you can realize that God is there to help you get through those tough times,\" said Harrow.\nWainwright also said it was important for the Soldiers to see another Soldier making the commitment instead of hearing about it.\n\"Soldiers are big on rituals and visuals,\" said Wainwright. \"We can talk about a lot of things, but when you actually see it, it makes a whole lot of difference.\"","|Answer to Quiz #36 - November 18, 2005\nWhat was Sergeant Humiston's wife's name?\nWhere did his family live?\n|Submitted by Dale Neisen.\nClick on thumbnails to see larger images.\nSergeant Amos Humiston's wife's name was Philinda.\nHis family lived in Portville, NY.\n|Gettysburg: Profiles in Courage / Amos Humiston\nUnion sergeant died as the battle began, holding a picture of his children\nSunday, July 06, 2003\nAmos Humiston is the only enlisted man at Gettysburg who has his own monument on\nthe battlefield. It wasn't because of his heroism in the battle. A Union sergeant in New\nYork's 154th \"Hardtack\" regiment, Humiston was killed on the first day of fighting in\nGettysburg, after Confederate troops overwhelmed his company at a spot known as\nWhat earned him a permanent marker was his love for Frank, Freddie and Alice.\nHumiston was just one of more than 3,000 Union soldiers who died in the monumental\nthree-day conflict. But when his body was found later that week, lying in a secluded\nspot at York and Stratton streets in Gettysburg, he was holding an ambrotype -- an\nearly kind of photograph -- and on it were the serious, round faces of his three adored\nchildren: 8-year-old Frank, 6-year-old Alice and 4-year-old Freddie. Somehow,\nhistorians believe, Amos Humiston had managed to drag himself to this patch of ground\nafter he had been wounded, and was probably looking at his children's faces when he\nEven then, Humiston might have faded into obscurity, because there was nothing on his\nbody to identify him and the few soldiers from his unit survived the battle had moved\non before he was found. Somehow, though, the image of his children ended up in the\npossession of Dr. John Francis Bourns, a 49-year-old Philadelphia physician who\nhelped care for the wounded at Gettysburg. Months after wrapping up his volunteer\nwork there, he decided to try to find out the identity of the children's father.\nHis efforts produced a wave of publicity\nthat swept the North and became the\nPeople magazine cover story of its day. It\nbegan quietly enough, on Oct. 19, 1863,\nwhen the Philadelphia Inquirer published\na story under the provocative headline:\n\"Whose Father Was He?\"\nAfter the battle of Gettysburg,\" the article read, \"a Union soldier was found in a\nsecluded spot on the battlefield, where, wounded, he had laid himself down to die. In\nhis hands, tightly clasped, was an ambrotype containing the portraits of three small\nchildren ... and as he silently gazed upon them his soul passed away. How touching!\nHow solemn! ...\"\n\"It is earnestly desired that all papers in the country will draw attention to the discovery\nof this picture and its attendant circumstances, so that, if possible, the family of the\ndead hero may come into possession of it. Of what inestimable value will it be to these\nchildren, proving, as it does, that the last thought of their dying father was for them,\nand them only.\"\nWhen the article appeared 140 years ago, newspapers were not able to publish\nphotographs, and so the story, subsequently reprinted in dozens of newspapers and\nmagazines throughout the North, had to rely on a detailed description of the children.\nThe eldest boy, it said, was wearing a shirt made of the same fabric as his sister's\ndress. The younger boy in the middle was sitting on a chair, wearing a dark suit. It\nestimated their ages at 9, 7, and 5, only a year off the mark.\nOne of the reprints appeared in the\nAmerican Presbyterian, a church\nmagazine. That is where Philinda\nHumiston, living in Portville, N.Y., first\nsaw word of the ambrotype and the dead\nsoldier. She hadn't heard from Amos\nsince weeks before Gettysburg, and\nwhen she saw the description of the\nchildren, she feared the worst. But she\ncouldn't be sure. So she contacted\nBourns through a letter written by the\nBourns had printed copy upon copy of\nthe children's picture to respond to\n|Amos Humiston's Grave at the\nGettysburg National Cemetery\ninquiries, but so far, none of the people who had contacted him had turned out to be the\nright family. He replied to Philinda's inquiry as he had to the others.\nAnd so it was that one mid-November day, four months after the battle, she opened the\nenvelope from Philadelphia and knew for sure that she had been widowed for a second\ntime, and that her children were fatherless.\nThe story might have ended there if it weren't for another idea Bourns had. He believed\nhe could capitalize on the outpouring of sympathy toward the Humistons to raise funds\nfor an orphanage in Gettysburg, to house the children of fallen Union soldiers. And so a\nsecond publicity campaign began, appealing for donations.\nGifts came from the wealthy and the\nhumble. Among the contributors was\nfinancier Jay Gould, one of the richest men\nin America. But Sunday school classes also\npitched in to raise money, and, if they\ndonated a sufficient amount, they could\nreceive copies of a popular song called\n\"Children of the Battlefield\" by balladeer\nJames Gowdy Clark, whose first stanza\nconcluded with the lines, \"and blame him\nnot, if in the strife, he breathed a soldier's\nprayer: Father, shield the soldier's wife, and\nfor his children care.\"\nThe orphanage became a reality in October\n1866 and began with 22 soldiers' children\nranging in age from 5 to 12. At its peak, the\nHomestead, as it was known, had just\nunder 100 children. Bourns even asked\nPhilinda Humiston to move there with her\nchildren and help supervise the home,\nwhich gave her a means of support.\nNational Soldier's Orphan Home\nFrank Humiston is on line 15 and\nFred is on line 23.\nClick on thumbnail to view larger image.\nShe agreed to the arrangement but loathed living in Gettysburg, according to Humiston\nbiographer Mark H. Dunkelman. Possibly in order to escape, she accepted a marriage\nproposal from a retired preacher she had met only briefly as he passed through the\ntown. She wed Asa Barnes in 1869 and moved to Massachusetts. Her children finished\ntheir schooling in Gettysburg and then joined her.\nThe orphanage itself would have a short, unhappy history. It closed just 12 years after\nit opened, crippled by two scandals. The matron of Homestead, Rosa Carmichael, was\naccused of abusing the children and even shackling some of them in a dungeon she had\ncreated in the basement. And Bourns, the man who had made the Humistons famous\nand founded the orphanage, was accused of embezzling large sums of money from\nOf the Humiston children, Frank was the only one to receive a higher education,\nattending Dartmouth College and the University of Pennsylvania medical school. He\nbecame the honored town doctor of Jaffrey, N.H., had six children, and died at the age\nof 57 from complications of gallstone surgery.\nPhilinda, brokenhearted, died a few months\nFred Humiston became a traveling salesman\nand was the most carefree and peripatetic\nof the children. His home was in the Boston\narea, where he married and had two\ndaughters, but his sales work took him\nfrom Canada to Florida. In his 50s, he\nbegan to suffer from heart disease, and he\ndied in 1918, at age 59.\nAlice lived with her mother for several\nyears, ran a chicken farm for a short while,\nthen began to move almost constantly.\nFinally she settled in Southern California,\nliving near a namesake niece. In 1933, at\nthe age of 76, Alice was sweeping her\nrooms in a Glendale home and talking with\na neighbor when her skirt caught fire from\nan open heater. She was badly burned from\nankles to waist and died two days later.\nFor whatever reason, the Humiston children\nalmost never mentioned their childhood\nAlice E. Humiston is listed in the 1910 US census\nof Leominster, MA. She was then 53 years old.\nShe lived with her mother age 79 who evidently\nremarried but in 1910 was again a widow. All\nthree of the Humiston children were still alive in\n1910 since the census information shows the\nformer Mrs. Humiston had borne three children\nand all were living. Her name [on the first line] in\nthe 1910 census is spelled as Filinday Barnes.\n|Click on thumbnail to view larger image.\nMany thanks to Stan Read for supplying these census\nimages from www.heritagequest.com\ncelebrity, and most of those who knew them had no idea they were once the \"Children\nof the Battlefield.\" Dunkelman thinks their moment in history may have been too tragic\nfor them to want to relive it with anyone. \"They put this celebrity under a blanket\nwhen they reached their adult years,\" he said.\nYet their story continues to be told because of a father's love that has survived the\ncenturies. In his last letter to Philinda, two months before his death, Amos expressed\nthose feelings with his own sense of spelling and punctuation. \"... I got the likeness of\nthe children and it pleased me more than eney thing that you could have sent me how I\nwant to se them and their mother is more than I can tell I hope that we may all live to\nsee each other again if this war dose not last to long.\"\nThis story was based on research by historian Mark H. Dunkelman, author of\n\"Gettysburg's Unknown Soldier: the Life, Death and Celebrity of Amos Humiston.\"\nInformation specialist Steve Karlinchak also contributed.\n(by Mark Roth, Post-Gazette Assistant Managing Editor)\nGettysburg's Unknown Soldier: The Life, Death, and\nCelebrity of Amos Humiston (Westport, Conn.:\nPraeger, 1999). Gettysburg's Unknown Soldier tells the\ntale of nineteenth-century war, sentiment, and popular\nculture in greater detail than ever before. \"Mark\nDunkelman has told [Amos] Humiston's story with a\nverve and sensitivity that will leave no reader\nunmoved.\" James M. McPherson. \"A compelling\nnarrative that should fascinate all who are interested in\nthe broader, human implications of the tragic events\nthat occurred at Gettysburg in 1863.\" William A.\nFrassanito. \"The definitive account of one of\nGettysburg's best human interest stories.\" Harry W.\nPfanz. For more information or to order a copy of the\nbook, visit the Greenwood Publishing Group Web site.\nMr. Dunkelman has written several books, pamphlets, and many articles on the 154th\nNY volunteer infantry.\nI was very interested because my Gg Grandfather (remember my web site?) was in the\n157th NY Volunteer Infantry, but was wounded at Chancellorsville and was carried\nfrom the field by Roswell Bourne! I have no idea whether he was related to the Dr.\nBourne in the article and on the rear of the photo.\nBourne, R. Walworth [Lawyer]; Co C 157th NY V Inf; Lieut. Served three yrs. Was\ntaken prisoner at Gettysburg. Was in all the battles the Regiment was engaged in. At the\nBattle of Chancellorsville May 3rd 1865, under a heavy shower of shot and shell he\nhelped remove his comrade and former schoolmate, W. W. Chapel, who was severely\nwounded. Was promoted to 1st Lieutenant in Co. C. Discharged at Charleston S.C. July\nNote: We found out later that there was no relation. The man who founded the\norphanage was Dr. Bourns, and Bill is related to Roswell Bourne. Also, Bill's gg\ngrandfather servied in the 157th, not the 154th volunteer infantry.\nTo read about\n- How the photo came into the hands of Dr. Bourns through a lucky turn of events\n- Amos' Humiston's early life as a crew members on a whaling ship in the N. Pacific\n- Amos' and Philinda's courtship and marriage\n- The details of Amos' military service with the 154th \"Hardtack Regiment\"\nsee the following article. Click on link to see full text. Very interesting!!\n|Key to a Mystery: The Death of Amos Humiston\nArticle from America's Civil War\nMortally wounded at the Battle of Gettysburg, Union soldier Amos Humiston died\nclutching the only clue to his identity: an ambrotype of his three small children.\nBy Mark H. Dunkelman\nOf all the fallen heroes of the epic, three-day Civil War Battle of Gettysburg in July\n1863, this Union soldier was unique. He had not led a charge, nor captured an enemy\nflag, nor rescued a comrade under fire. Instead, his fame rested on his dying act of\ndevotion and love; his death pose made his story special.\n(Continued at http://historynet.com/acw/blmysterydeathhumiston/index.html\nThe town of Portville was formed from\nOlean, April 27, 1837. It lies on the\nsoutheast corner of the county. The\nsurface is a hilly upland, with the summits\nbeing 500-600 feet above the valleys. The\nVillage of Portville is approximately 1,566\nft in elevation. The Allegany River enters\nthe town upon the southern border, flows\nnorth to near the center, and then\nnorthwest to the west border. It receives\nas tributaries the Oswayo, Dodges and\nHaskel Creeks. Lumbering is the chief\nPortville is on the Allegany. In 1863, it\ncontained 2 churches, 2 sawmills, and a\ngristmill. It had a population of 287. Mill\nGrove, south of Portville, is also on the\nAllegany. In 1863, it contained 2 sawmills,\nand a gristmill and 18 dwellings. The first\nsettlement was made in 1805, by James\nGreen, on Haskell Creek in the north part\nof town. The first child born was Hannah\nGreen, daughter of James Green on April\n28, 1807. The first marriage was between Jonathon Dodge and Eunice Atherton, in\n1809. David Heusten was the first person to die, killed by the spring of a tree while\ngetting out spars, in early 1807. The first school was taught by Anna Carpenter, near\nPortville Village. Lyman Rice kept the first inn, in 1822 and Allen Rice the first store in\n1823. The first gristmill was located on Dodges Creek, started by Samuel King. The\nfirst sawmill, on Haskell Creek, was erected by James Green and Alpheus Dodge in\n1807. The first church was formed in 1824.\nThe Village of Portville is 0.81 square miles in area and had 1,136 residents in 1980,\n1,040 residents in 1990, and 1,024 residents in 2000. The Town of Portville is 36.05\nsquare miles in area and had 3,952 residents in 2000.\n|Congratulations to our winners!\nMary Fraser Bill Burrows\nAlice Hix Judy Cook\nGus Janssen Stan Read\nDon Schulteis Melissa Brown\nMaureen O'Connor Jon Fox\nE-Pop Nienhaus Jim Turner\nAlice Fairhurst Sue Edminster\nRick McKinney Kelly Fetherlin\nCarol Haueter Marilyn Hamill-Stewart\nEdee Scott Mary Parks\nIf your name has been omitted from our winner's list, please let me know, it was unintentional.\n|If you enjoy our quizzes, don't forget to order our book!\nIf you have a picture you'd like us to feature a picture in a future quiz, please\nemail it to us at CFitzp@aol.com. If we use it, you will receive a free analysis of\nyour picture. You will also receive a free Forensic Genealogy CD or a 10%\ndiscount towards the purchase of the Forensic Genealogy book."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:9066e342-f27a-463e-a53b-3004cca25e04>","<urn:uuid:5e007987-7208-4324-bde8-e036f950e861>"],"error":null}
{"question":"Compare how IBDV and influenza B viruses affect their respective host organisms in terms of disease severity and mutation patterns.","answer":"IBDV is an acute, highly contagious, and immunosuppressive disease in young chickens that causes severe economic losses globally. It induces apoptosis in multiple organs including the bursal fabricius, spleen, and thymus of susceptible chickens, and employs complex mechanisms including epigenetic regulation of gga-miR-16-5p expression to enhance virus-induced apoptosis. In contrast, influenza B viruses typically cause less severe epidemics than influenza A viruses and are found only in humans. While influenza B can cause morbidity and mortality, it undergoes genetic changes less rapidly than influenza A viruses and has never caused a pandemic. The virus is divided into two genetic lineages (B/Yamagata and B/Victoria) but is not classified by subtypes like influenza A viruses.","context":["J Gen Virol 75:1803C1806. of DF-1 cells with IBDV reduced Bcl-2 expression, and this reduction could be abolished by inhibition of gga-miR-16-5p expression. Moreover, transfection of DF-1 cells with gga-miR-16-5p mimics enhanced XL-228 IBDV-induced apoptosis associated with increased cytochrome release and caspase-9 and -3 activation, and inhibition of caspase-3 decreased IBDV growth in DF-1 cells. Thus, epigenetic upregulation of gga-miR-16-5p expression by IBDV contamination enhances IBDV-induced apoptosis by targeting the cellular antiapoptotic protein Bcl-2, facilitating IBDV replication in host cells. IMPORTANCE Infectious bursal disease (IBD) is an acute, highly contagious, and immunosuppressive disease in young chickens, causing severe economic losses to stakeholders across the globe. Although IBD virus (IBDV)-induced apoptosis in the host has been established, the underlying mechanism is not very clear. Here, we show that contamination of DF-1 cells by IBDV upregulated gga-miR-16-5p expression via demethylation of the pre-miR-16-2 promoter. Overexpression of gga-miR-16-5p enhanced IBDV-induced apoptosis associated with increased cytochrome release and caspase-9 and -3 activation. Importantly, we found that IBDV XL-228 contamination induced expression of gga-miR-16-5p that brought on apoptosis by targeting Bcl-2, favoring IBDV replication, while inhibition of gga-miR-16-5p in IBDV-infected cells restored Bcl-2 expression, slowing down viral growth, indicating that IBDV induces apoptosis by epigenetic upregulation of gga-miR-16-5p expression. These findings uncover a novel mechanism employed by IBDV for its own benefit, which may be used as a potential target for intervening IBDV contamination. belonging to the family, which is composed of nonenveloped viruses containing two segments of double-stranded RNA (segments A and B) (5). Segment B (2.8?kb) encodes VP1, an RNA-dependent RNA polymerase (RdRp) linked to the virus genomic segments (6, 7), whereas segment A (3.17?kb), encoding the major components of the virus, contains two partially overlapping open reading frames THBS5 (ORFs) (8). The first ORF encodes a nonstructural protein, VP5 (17?kDa), and the second one encodes the pVP2-VP4-VP3 polyprotein (110?kDa) that can be cleaved by the viral protease VP4 to release pVP2 (54.4?kDa), VP4 (28?kDa), and VP3 (32?kDa) (9, 10). IBDV contamination causes apoptosis in the BF, spleen, and thymus of susceptible chickens, and it was reported that this VP2 and VP5 were the major viral proteins involved in IBDV-induced apoptosis (11,C15); however, other factors might also be involved in IBDV-induced apoptosis because inhibition of VP2- and/or VP5-induced apoptosis by inhibitors or knocking down the target proteins of VP2 and/or VP5 during IBDV contamination could only partially block IBDV-induced apoptosis in host cells (16,C18). Thus, it is very likely that IBDV-induced apoptosis involves multiple factors. MicroRNAs (miRNAs) are small noncoding RNAs of 20 to 24 nucleotides?(nt) in length that are widespread in eukaryotes (19, 20). Cellular endogenous miRNAs can serve as a type of guiding molecule through base pairing with their target mRNAs, thereby leading to posttranscriptional splicing or translation inhibition by targeting the 3 untranslated region (UTR) of mRNA in target genes. It has been reported that miRNA plays critical roles in a wide variety of biological processes (21), such XL-228 as cell growth, differentiation (22), proliferation (23), apoptosis (24), immune response, cancer, etc. (25, 26). Increasing evidence suggests that cellular miRNAs contribute to the repertoire of host-pathogen interactions during viral contamination (27, 28). Alterations in cellular miRNA expression, as a consequence of host-virus interactions, play a key role in the regulation of viral replication during virus contamination (29, 30). In our previous study, we screened IBDV-infected DF-1 XL-228 cells for the potential host miRNA response to IBDV contamination by deep sequencing (31, 32). Among the miRNA candidates, gga-miR-16-5p was found to be upregulated with IBDV contamination. In the present study, we found that contamination of DF-1 cells by IBDV upregulated gga-miR-16-5p expression via demethylation of the pre-miR-16-2 promoter and that gga-miR-16-5p induced apoptosis by directly targeting the cellular antiapoptotic protein B-cell lymphoma 2 (Bcl-2), favoring IBDV growth in DF-1 cells, while inhibition of gga-miR-16-5p in IBDV-infected cells XL-228 restored Bcl-2 expression, slowing down viral growth. These data suggest that the epigenetic upregulation of gga-miR-16-5p expression by IBDV contamination favors viral replication in host cells via enhancing IBDV-induced apoptosis. RESULTS Contamination of DF-1 cells with IBDV strain enhances gga-miR-16-5p expression..","There are three kinds of influenza: A, B, and C. Influenza B and C aren’t much to worry about, at most causing minor illness. The influenza A viruses, by contrast, are highly variable and so have the potential to outwit the human immune system and cause a pandemic.\nPandemic Influenza: The Inside Story\nIt is helpful to understand a little bit about the influenza virus—the different types, how they are named, and how they mutate. The more you know, the better you will be able to protect your patients, friends, and family members from catching the flu.\nInfluenza viruses are categorized and named by type. There are three types of influenza viruses—A, B, and C. Type is determined by the material within the nucleus of the virus.\nLeft: The influenza virus. Copyright Zygote Media Group. Used with Permission. Right: Structure of the influenza virion. The hemagglutinin (HA) and neuraminidase (NA) proteins are shown on the surface of the particle. The viral RNAs that make up the genome are shown as red coils inside the particle and bound to ribonuclear proteins (RNPs). Source: NIH, public domain.\nThe nomenclature used to describe a specific influenza virus was established by the World Health Organization in 1980 and is expressed in this order:\n- Virus type,\n- Geographic site where the virus was first isolated,\n- Strain or lineage number,\n- Year of isolation, and\n- Virus protein antigen subtype described by letter and number, H1 to H16 and N1 to N9 (CDC, 2015PB)\nFor example, the 2009 H1N1 pandemic influenza virus was named as follows:\nThis is translated as: Influenza type A, isolated first in California, lineage (strain) number 04, year 2009, and type H1N1.\nIn the image below, a Fujian influenza virus that circulated in 2002 was named as follows:\nThis is translated as: Influenza type A, first isolated in Fujian (a province on the Southeast coast of mainland China), lineage number 411, year 2002, type H3N2.\nInfluenza virus nomenclature (for a Fujian flu virus). Source: Wikipedia.org\nThe Fujian H3N2 influenza of 2002 caused an unusually severe 2003–2004 flu season, partly because it spread rapidly and partly because the vaccine for that season had already been formulated when the Fujian H3N2 virus was identified.\nType A Influenza and Its Subtypes\nType A influenza viruses are divided into subtypes, based on the presence of two glycoproteins on the surface of the virus. These glycoproteins are called hemagglutinin (HA) and neuraminidase (NA). About 18 hemagglutinins have been identified, although generally, only H1, H2, and H3 are found in human influenza viruses. There are more than 100 types of neuraminidase, but only N1 and N2 have been positively linked to influenza epidemics in humans.\nThe above image shows the features of an influenza virus, including the surface proteins hemagglutinin (HA) and neuraminidase (NA). Following influenza infection or receipt of the influenza vaccine, the body’s immune system develops antibodies that recognize and bind to “antigenic sites,” which are regions found on an influenza virus’s surface proteins. By binding to these antigenic sites, antibodies neutralize flu viruses and prevent them from causing further infection. Source: CDC.\nHemagglutinin and neuraminidase are also called antigens, substances that, when introduced into the body, stimulate the production of an antibody. Currently, there are two subtypes of influenza A viruses found circulating among human populations: influenza A (H1N1) and influenza A (H3N2).\nWild Birds Provide the Usual Reservoirs\nA reservoir is the place where a pathogen lives and survives. For all subtypes of influenza A viruses, wild birds are the primary natural reservoir and are thought to be the source of influenza A viruses in all other animals. Influenza A viruses are found in many different animals, including ducks, chickens, pigs, whales, horses, and seals.\nMost influenza viruses cause asymptomatic or mild infection in birds; however, clinical signs in birds vary greatly depending on the virus. Infection with certain avian influenza A viruses (for example, some H5 and H7 viruses) can cause widespread, severe disease and death among some species of birds (CDC, 2018a).\nZhejiang province, China (in red). Shanghai, a city with a population of 24 million, is located on the northern tip of Zhejiang province. Source: Uwe Dedering, Wikipedia Commons.\nIn 2013 the ability to quickly identify the reservoir of a novel avian influenza A (H7N9) virus helped Chinese officials contain what started as an outbreak of “pneumonia of unknown cause” in the eastern coastal province of Zhejiang, China. During the outbreak, there were 135 confirmed human infections with H7N9, the vast majority during the month of April. Many of the people infected with H7N9 reported contact with poultry. By August 2013, 45 people had died (Chen et al., 2013). The H7N9 virus had previously been detected in birds but had never been seen in humans or any other animals prior to this outbreak.\nAnnual epidemics of sporadic human infections with Asian-lineage avian influenza A (H7N9) virus (“Asian H7N9”) in China have been reported since March 2013. In late 2016, China experienced its fifth epidemic of Asian H7N9 human infections. This was the largest annual epidemic to date. As of September 13, 2017, the World Health Organization reported 764 human infections with Asian H7N9 virus during the fifth epidemic. During epidemics one through four, about 40% of people confirmed with Asian H7N9 virus infection died (CDC, 2018a).\nThe eight genes of the H7N9 virus are closely related to avian influenza viruses found in domestic ducks, wild birds, and domestic poultry in Asia. The virus likely emerged from “reassortment,” a process in which two or more influenza viruses co-infect a single host and exchange genes. This can result in the creation of a new influenza virus. Source: CDC, 2014.\nType A Influenza Viruses Circulate in Pigs\nPigs are susceptible to avian, human, and swine flu viruses and can potentially be infected with influenza viruses from different species at the same time. If this happens, it is possible for the genes of these viruses to mix (reassort) and create a new virus.\nInfluenza viruses that normally circulate in pigs are called “variant” viruses when they are found in people and denoted with a letter “v.” H3N2v viruses from the 2009 H1N1 pandemic virus were first detected in people in 2011 and were responsible for a multi-state outbreak in the summer of 2012 that resulted in 306 cases, including 16 hospitalizations and 1 fatality (CDC, 2019j).\nMost cases of H3N2v identified during 2012 were associated with exposure to pigs at agricultural fairs. Many fairs have swine barns where pigs from different places come in close contact with each other and with people. These venues may allow the spread of influenza viruses both among pigs and between pigs and people. Infected pigs can spread influenza viruses even if they are not symptomatic. Although instances of limited person-to-person spread of this virus have been identified in the past, sustained or community-wide transmission of H3N2v has not occurred (CDC, 2019j).\nType B Influenza\nInfluenza type B viruses are separated into two genetic lineages (B/Yamagata and B/Victoria). They are not classified by subtype like influenza A viruses. Influenza B viruses from both the Yamagata and Victoria lineages have co-circulated in most recent influenza seasons. The trivalent influenza vaccines available in recent seasons have contained one influenza B virus, representing only the Yamagata lineage (CDC, 2019f).\nInfluenza type B viruses are usually found only in humans, and can cause morbidity and mortality among humans, but in general are associated with less severe epidemics than influenza A viruses. Although influenza type B viruses can cause human epidemics, they have not caused pandemics. Influenza B viruses undergo genetic changes less rapidly than influenza A viruses.\nType C Influenza\nInfluenza type C is less common and less studied than influenza A and B. It can cause illness in humans and pigs, and it is thought that most people are exposed to influenza C during childhood. The influenza C virus lacks the multiple subtypes (hemagglutinin and neuraminidase) found in influenza A, which limits its ability to mutate. Influenza C is thought to be unlikely to cause a pandemic, although localized epidemics have occurred. As with type B influenza viruses, type C influenza viruses are not classified according to subtype.\nTypes of Influenza Virus"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:8d1f1be4-6bfb-4f36-86f9-193b3b3f3bd4>","<urn:uuid:2b684524-9c26-48e7-9a1d-bd88db5d559c>"],"error":null}
{"question":"How do fish use their sense of smell underwater, and what types of insect repellents could interfere with their detection abilities?","answer":"Fish have a highly developed sense of smell underwater, with two nostrils on each side of their head containing olfactory organs. They can detect extremely low levels of dissolved chemicals - as little as 1 part per 10 million under laboratory conditions. Salmon can even detect when a person puts their hand in water 100 feet upstream. Fish's olfactory ability is several times better than that of a bird dog. Regarding insect repellents, they are among the most offensive odors to fish. Products containing DEET or other chemical repellents that come in contact with fishing flies can severely impact fishing success. Various forms of repellents like sprays, creams, lotions and even clothing treated with permethrin can transfer these offensive odors. To avoid this interference, anglers should avoid touching flies after applying insect repellent and should wash hands thoroughly before handling fishing equipment.","context":["January 15th, 2001\nThe Premiere OnLine Magazine for the Fly Fishing Enthusiast.\nArchive of Readers Casts\nThis is where our readers tell their stories . . .\nFish Can Really Smell\nI have often wondered why a fish would follow my fly for\nseveral feet, and come within an inch of eating it, but quickly\nrefuse it and turn away. Then one winter day when I was surfing\nthe Internet, I came across an article published by a marine\nbiologist at Louisiana State University. It was a study of the\nolfactory [smell] and gustatory [taste] ability of catfish and\nrainbow trout. Although there were some six-dollar words used\nin the discussion of his experiments that were hard to\nunderstand, I came to realize there might be an \"odor factor\" to\nmy flies that might explain the refusal mystery.\nSo I started searching for more and more information on the\nchemoreception [smell & taste] ability of fish. I was primarily\ninterested in what the fisheries biologists had to say about the\nsubject, and believe me, there is a tremendous amount of\ninformation on the Internet about these studies. If you are\ninterested, just go to your search engines and search for \"fish\nolfactory\" or \"fish gustatory\" and you will have considerable\nreferences to examine.\nThe primary purpose of this article is to make the fly fisherman\naware that fish, within their watery environment, are better at\nsmelling and tasting, than the bird dog is in the free air\nenvironment. And this fact could possibly explain the refusals,\nturn-around and spit-outs that all of us have observed over the\nyears. When you consider the variety of materials used to\nconstruct a fly, plus the contamination you impart to the fly with\nyour own body acids, you never know what it will smell like to a\nfish. The rest of this article is a summary of the research that has\nbeen done, what are the compounds that offend the fish and\nwhat can be done to eliminate the offensive odors.\nFish have two nostrils on each side of their head like this (::),\nwhere water enters and exits. The olfactory [smell] system is\nlocated between the entrance and exit nostrils on each side of its\nhead. There is no connection between the olfactory organs and\nthe throat, as there is in the human. Fish also have the ability to\ntaste, with taste buds on their lips, tongue, and throughout their\nmouth. This is called the \"gustatory\" system in scientific lingo.\nSome fish like catfish have barbels which are like whiskers that\nIt has also been determined that different species of fish\nrespond to different scents. This is because the scent\nreceptor sites are different in size, and they will only respond to\nscent molecules that are the same size or smaller than the scent\nreceptor. In short, there is no one flavor that will stimulate all\nfish species, also your fly may give off scent molecules that\nare larger than the scent receptors in the fish you are\ntrying to catch, which is a real advantage. However, it is\nreasonable to assume that larger fish have larger receptors and\nhave the ability to detect a wider variety of scent compounds.\nWHAT IS \"SCENT\"?\nWhat are these dissolved compounds that create \"scent\" that is\nfavorable to feeding behavior? Basically a scent is caused by\namino acids and things called pheromones, in molecular form.\nPheromones are chemicals that are used to communicate\nbetween members of the same species during courtship and\nmating or to signal danger when a predator is in the area. They\ndecompose rapidly, and are thought to have little to do with\nAmino acids are the critical chemicals that affect feeding\nbehavior. Dissolved amino acids indicate the presence of living\nor injured organisms to the fish, which may represent either food\nor something foreign that should be avoided. Amino acids are\nthe molecular building blocks of proteins, which provide the\nstructure for all living things. Proteins are a necessary part of a\nliving cell, and next to water; protein makes up the greatest part\nof body weight. There is some debate over the actual number of\namino acids because of the possibility of several combining to\nmake up others. Generally, there are 29 amino acids that have\nbeen identified as performing different functions in the body.\nSome are essential to life and some are not.\nAll living things, including man, continuously give off amino acids\nin molecular form. The amount and type of chemicals given\noff by a living organism depends upon its physical activity\nas well as its emotional state. Catfish are sensitive to\nexcretions given off by other fish, such as urine and excrement\nand other substances. A fish that is stressed will give off more\nexcrement than a \"happy\" fish. And a stressed fish may indicate\na \"happy meal\" to the catfish. Imagine the different chemicals\nthat a worm would excrete when impaled several times on your\nfishhook. Now perhaps we can understand that there are\namino acids given off by emerging insects that fish can\nreadily detect. If the hatch is large enough, they may actually\nflavor the water, which would cause a feeding frenzy.\nHOW FAR ARE SCENTS DETECTABLE?\nThe distance from which fish can detect specific dissolved\nchemicals can vary widely, depending on currents, water content\nand the type of fish. Biologists have used very low levels of\namino acid stimuli, down to 1 part per 10 million in water, to\nobtain a reliable electrical response from the olfactory nerves of\nthe fish under study. However these tests were conducted\nunder laboratory conditions. Bass are supposed to detect 1-\n200th of a drop of attractant in 100 gallons of water. It has been\nreported that Salmon, Sharks and Eels can detect certain\ndissolved chemicals from as far as 500 miles. It has also been\ndetermined that the memory of the home stream for a salmon is\nnot inherited, but is imprinted by the unique odors of the home\nstream during the smoltification process when the young salmon\nbegin their downstream migration. This suggests that food odor\nand other dissolved chemicals are learned and\nremembered by the fish.\nJust how acute the smell and taste ability is in a fish, is hard to\nmeasure precisely. It has been demonstrated that a salmon\nwith its supernatural sense of smell can detect when a man\nsticks his hand in the water 100 feet upstream! It has also\nbeen said that the olfactory [smell] system in fish is several times\nbetter than that of a good bird dog. The human nose has about\n5 million olfactory cells and some dogs have over 200 million,\nand a volume of four times that of our nose. That puts the fish\npretty high up on the smell-ability scale.\nOkay, if the fish have such a terrific sense of smell, why are so\nmany caught on artificial flies, plugs, spoons, spinners and other\nstuff. This can be explained primarily by the fact that the fish's\nsenses have been developed for the watery environment\nin which it lives. Remember that the fish will respond if the\nscent molecules are the same size or smaller than the scent\nreceptors. These receptors were developed to detect and taste\nits basic food supply, such as insects, crustaceans, leeches, and\nsmaller fish of its own kind. The receptors were not developed\nto sense fur, feathers, or other materials foreign to its watery\nThe second most significant factor is that vegetation, algae\nand bacterial systems present in all fishing waters can\nefficiently reduce the background levels of free amino\nacids to exceptionally low levels. Therefore, the\ndetectable chemicals given off by an injured prey should\nbe fairly localized around its body. Perhaps this is the reason\nwhy most fish species rely heavily on sight feeding. It also\nexplains why a fish may nose your fly and then refuse it,\nexpecting it to smell like something to eat, but when it doesn't, he\nbacks off. The only way to catch this fish with an artificial fly, is\nto create a \"knee jerk\" reaction with your presentation, where\nthe fish has it in his mouth before he can taste it.\nMany of the bait scents and so called fish attractants sold on the\nmarket today do not really attract, but cover up the negative\nscent combinations. In fact, many oil-based attractants would\nbe undetectable because their molecules are too large for the\nreceptor sites. Products such as Cossacks Bait Products\nShrimp, Herring, and Salmon Egg Oils; Riverside Lures Real\nCraw; Smelly Jelly; Edge Products Hot Sauce; Fish Formula;\nand Mikes Shrimp Oil are thought to be primarily oil based. I'm\nsure there are many others.\nProducts that claim to be based on amino acids would be\nBerkley's attractants along with Pharmacal's Baitmate Live and\nDr. Juices Elixirs.\nPlant extracts are very effective in covering human odors.\nScents such as banana oil, garlic and anise are extracts from\nplants. Some plant scents are Cossack Bait Products Anise and\nGarlic Gel; Fish Formula Sparkle Scales; Mister Twister Banana\nOil; Mike's Glow Scent Jel and Anise Oil. Plant extracts do not\nreally attract, but provide an odor that the fish is not really\naccustomed to smelling, yet is not offensive if used properly.\nFish \"attractants\" were developed primarily for the warm water\nspecies like Bass. If you were fly fishing for catfish or carp, the\napplication of scents might be considered because they are\nspecies that rely most heavily on smell and taste. But for the fish\nspecies that rely primarily on sighting their source of food, my\nrecommendation is to forget formulated \"fish attractants\". There\nare two reasons: the first is that the application of a formulated\nscent cannot be accurately controlled. Too much scent is\nworse than no scent at all, or even having a slightly negative\nscent. The second reason is that if a scent gets too old, or too\nhot, it may change into a toxic substance that does just the\nopposite of what it was designed to do. Enough said for\nPublishers Note: It is not legal in all states (or countries)\nto use such scents. Always check local regulations.\nPREVENTING OFFENSIVE ODORS ON THE FLY\nThe first thing an angler should do is to try and eliminate the\noffensive odors that could be transferred to the fly. At the top of\nthe list should be insect repellents. If you use an insect\nrepellent on your hands, don't touch the fly. If you want to\nsabotage your fishing buddy, just spray insect repellent in his fly\nNext comes tobacco and nicotine. If you smoke or chew\ntobacco when you are fishing or tying flies, take precautions so\nthat the smoke or tobacco does not come in contact with the fly.\nDon't store flies or fly tying materials in empty tobacco tins or\nGasoline is pretty high on the list of transferable odors. Gas up\nthe night before your fishing trip or wash your hands thoroughly\nbefore you handle your fly. Fly anglers who fish from boats with\noutboard motors are likely to transfer this odor to the fly.\nHumans give off a very offensive amino acid called L-Serene.\nOf course this scent is transferred to the fly you tie or handle.\n(And whatever you do, don't spit on the fly for good luck.)\nNever wet your fingers with saliva to apply dubbing. Although\nyou can't eliminate it totally, washing your hands with Lava or\nIvory bar soap before tying flies or handling them will help\nimmensely. Wetting your hands in the stream or lake before\ntying on a fly will help.\nAnother major offensive odor to fish is sun tan lotion, and just\nabout any other hand lotion or soap that is designed to be\nfragrant and lubricating. Dishwashing detergents are known\nto be offensive to fish. So don't wash your hands with liquid\nsoaps before tying flies.\nThe actual fly itself can contain a host of scent combinations.\nAlthough there has never been a study to my knowledge of the\nresident chemicals and scents built into a fly, you only have to\nimagine the possibilities. Since there is no practical way to inject\nan attractive flavor (an amino acid that duplicates the living\norganism) into the fly, I prefer a \"no-odor\" fly, and hope my\npresentation is good enough to get it into the fish's mouth before\nhe tastes it.\nOne of the best odor cleansing operations you can give your fly\nis to use the vegetation, moss, mud and weeds that are present\non the waters you are fishing. Don't cuss the next time you\nretrieve a load of moss or weeds on your fly, you have just\nmade your fly more acceptable to the fish. ~ Phil Garberich\n[ HOME ]\n[ Search ]\n[ Contact FAOL ]\n[ Media Kit ]\nFlyAnglersOnline.com © Notice","What are the different types of insect repellent?\nYou can choose from these forms, depending on your preference:\nSpray in the form of oil or liquid - a very common form of insect repellent, this can be sprayed on clothing or directly onto skin. Most spray repellent preparations contain concentrated amount of DEET. Insect repellents with DEET are considered to be effective even after several hours of walking through places that are heavily infested with mosquitoes.\n- Cream or lotion - are most effective when applied directly to the skin and are rubbed to create a repellent barrier. You can use this in combination with mosquito repellent clothing and are usually made with natural ingredients. These usually have a very minimal scent or sometimes an undetectable scent.\n- Insect or mosquito repellent clothing - specially designed clothing materials with tight fibre weave infused with long lasting insect repellent. It is a great alternative to other insect repellent forms because it can protect you from mosquito or insect bites everyday.\n- Mosquito patch - is the newest kind of insect repellent. It is made of 100% natural and safe vitamin B1. It is small, transdermal skin patch that is very easy to use. Simply slap it onto your skin and it does its work naturally.\n- Mosquito repelling bracelets - are specially designed clip on bracelets or simply clip on devices that are made with either chemical or natural insect repellent pellets inside. These are ideal for babies or those who prefer not to apply anything on their skin. These can be used either as a bracelet or clipped on bags, chairs, prams etc.\n- Mosquito repellent devices - are various types of devices that emit a repellent fragrance usually through the process of burning. These may come in the form of candles, coils or Thermacell products.\n- Electronic repellents - emit ultrasonic sound as a deterrent to bugs and insects.\n- Vitamin B - Thiamin - This product is rumored to put the mosquitos off the smell of your blood.\nWhat are the active ingredients used in insect repellents? DEET\n- (N,N-diethyl-3-methylbenzamide) is a chemical that has been approved for use since 1957. It is considered as reliable and highly effective in repelling insects of many kinds. It is present in most forms of insect repellents. Some products contain a higher percentage of DEET than others. Its concentration content signifies the length of protection time it offers. The higher the concentration, the longer protection time it provides. Picardin\n- also known as KBR 3023 is another active ingredient used in insect repellents and is also an effective alternative to DEET. It offers long lasting protection against mosquito bites. It has been widely used since 1998. It differs from DEET on several accounts: less odour, does not cause skin irritation and no adverse effect on plastics.\nIt also offer long lasting protection. Permethrin\n- is known as an effective pesticide and is also used in insect repellent. Compared to the first two active ingredients, permethrin is not used on the skin but rather used to treat clothes that repel insects of many kinds. It can retain its potency for at least two weeks even through several washings. It can also be used or applied on tent walls and mosquito nets. Clothing treated with permethrin used in combination with products containing DEET applied on skin offers excellent protection even in demanding conditions. Best when camping in forests or mountains. Lemon Eucalyptus Oil\n- is also considered as a natural insect repellent. This has been tested against mosquitoes and found in the US to provide similar protection to repellents containing low concentrations of DEET. PMD is the synthetic form of the chemical derived from oil of lemon eucalyptus. However the use of this product is not advised for those ages 3 years old and below. IR-3535\n- is another active ingredient used in insect repellents and it offers broad spectrum protection from several insects including mosquitoes, deer ticks, and biting flies. It offers reasonably long protection comparable to DEET thus offering a great alternative for those seeking non-DEET products. Plant Based Repellents\n- examples of these are citronella, geranium, basil, garlic and peppermint. Insect repellent plants generally provide quite limited protection against mosquitoes. Usually offering protection for only 2 hours and therefore needing constant reapplying.\nTips for choosing the best repellent\nTo help you choose the insect repellent product that is best suited for you, you can start by identifying the following:\n- Type of insect you want protection from\n- How long do you need protection?\n- What active ingredient do you prefer?\n- Other product specific information that may be useful for you (e.g. allergies to consider with certain ingredients)\n- Consider the kind of activity you will be engaging in and the length of exposure you will have to insects.\nUsing insect repellents with children*\n- Read and follow the directions and precautions on the label\n- Only apply insect repellents on the outside of children's clothing and on exposed skin. NB: Permethrin-containing products should not be applied to the skin.\n- Spray repellents in open, well ventilated areas to avoid breathing them in.\n- Only use enough repellent to cover your child's clothing and exposed skin - using more does not make the repellent more effective. Avoid reapplying unless definitely needed.\n- Help young children to apply their insect repellent and supervise older children when using these products.\n- Wash your children's skin with soap and water to remove any repellent when they return indoors. Wash their clothing before they wear it again.\n- Do not apply insect repellent on children younger than 2 months.\n- Never spray insect repellent directly onto your child's face. Instead, spray a little on your hands first and then rub it on your child's face, avoiding the eyes and mouth.\n- Never spray insect repellent on cuts, wounds, or irritated skin.\n- Avoid using products that combine DEET with sunscreen. The DEET can make the sun protection factor (SPF) less effective, meaning these products can overexpose your child to DEET because the sunscreen needs to be reapplied often.\n*Source: https://www.healthychildren.org/English/safety-prevention/at-play/Pages/Insect-Repellents.aspx Page updated 06/04/18 12:47:36 p.m."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:9cbd1126-8096-4203-9740-6ca8c3011718>","<urn:uuid:618e86c3-dd34-40fb-93bf-cf94ec8fd633>"],"error":null}
{"question":"What are the key differences between managing typical sibling rivalry and addressing anti-social behavior in children?","answer":"Sibling rivalry is considered normal and common, with different intervention levels based on severity. For normal bickering (green light), parents should stay out while monitoring escalation. More serious conflicts require graduated responses, from acknowledging feelings (yellow light) to separating children (red light). In contrast, anti-social behavior is a more serious concern requiring professional intervention, especially if it involves ongoing bullying, physical aggression, or manipulation of others. While sibling conflicts can be used as opportunities to teach communication and negotiation skills, persistent anti-social behaviors may need family therapy and early intervention services to prevent the development of anti-social personality disorder later in life.","context":["Tips on managing children’s challenging behaviour\nIn the current context of the COVID-19 pandemic, we at the Guelph Family Health Study understand that it can be a challenging time for many families. Whether it is from disruptive or unprecedented lifestyle changes, increased stress, or simply spending so much time staying home, we have heard from many families that it is a little more difficult to manage their children’s behaviour. Below are some resources that may be helpful.\nEncouraging Good Behaviour\nModelling Good Behaviour\nChildren notice more things than we realize. They learn by watching those around them. Practice what you preach when it comes to good behaviour.\n- Point out good behaviours between adults, e.g. sharing, communicating, using good manners, taking turns\n- Model how to calm down, e.g. taking deep breaths together, drinking a glass of water together (both when the child is frustrated or when you are)\n- Express your actual feelings instead of using critical statements that might attack the other person, e.g. “I am feeling sad/frustrated/angry” rather than “You are driving me crazy”\nReinforcing Your Child’s Good Behaviour\n- Catch your child doing the right thing! Instead of only giving attention to bad behaviour (“If I misbehave, I’ll get attention”), make sure to do the same to and acknowledge your child’s good behaviour\n- Give praise or acknowledge even small things, like saying please/thank you, actively listening, speaking at a lower volume (inside voices), sharing\n- “Good job doing _____!” or “Thank you for _____”\nManaging Problem Behaviour\nTips to Prevent Problem Behaviours\n- As a family, be clear about the behaviours you want to encourage or discourage. Your children may not understand on the first try — repeat as necessary to make your expectations clear.\n- Have a focused and face-to-face conversation about goals or expectations, rather than a distracted one.\n- Use warnings to help with transitions to new activities, e.g. 10 minutes to dinnertime, screen time is ending in 3 minutes.\n- Ask questions or give instructions one at a time rather than all at once.\nSet SMART goals:\n- Specific: What is the expected behaviour? (e.g. “in bed by 9PM” vs. “sleeping early”)\n- Measurable/Observable: How can we agree the behaviour happened? What counts?\n- Achievable: Is this goal behaviour appropriate for the child’s current age/cognitive maturity? Will it work with our schedule?\n- Relevant: Is this goal behaviour something we want to achieve? As a parent, there are only so many rules you can enforce – which ones are the most important to you/your family?\n- Timely: When will we administer rewards/consequences for this behaviour?\n- Identify what the consequence will be for unwanted behaviour, e.g., time out, and positive behaviour, e.g., praise.\n- Be consistent. Consequences work when children know what to expect every time.\n- Give immediate consequences. The consequence needs to implemented very soon after the behaviour for children for children to link the consequence with the behaviour.\n- Remember to reinforce good behaviour, not just look for unwanted behaviour.\n- Avoid positive ‘punishment’, i.e. cleaning up for your child when they dawdle.\nSibling Conflict and Rivalry\nAlthough it can drive us crazy as parents, sibling rivalry is normal and common.\nHow do I know when to intervene?\nThe ‘Traffic Light’ Guideline can help you identify when and how to intervene:\n- Green light\n- Normal bickering, minor teasing\n- Stay out of it, but be aware of escalation\n- Yellow light\n- Increased volume, harsher teasing or name calling, threats, possible physical contact\n- Acknowledge the conflict and each child’s anger and point of view\n- Orange light\n- Potential to be a dangerous situation, more serious, half play/half real fighting\n- Be firm, stop the situation, review rules that both should follow, guide conflict resolution as a mediator\n- Red light\n- Situation has escalated to a dangerous level, significant harm may occur\n- Stop and separate the children, speak with them separately first and then together, review rules, impose a plan of conflict resolution that involves both parties\nWhen managing conflict, try to use it as an opportunity for your children to:\n- Practice communication and conflict resolution skills\n- Practice patience and honesty\n- Negotiate and compromise\n- Learn to stand up for themselves\nEffective strategies for managing conflict:\n- Be sure to listen to both sides of the story fairly, regardless of age\n- Be receptive to what your children may need, based on age, level of conflict, nature of conflict\n- Remain calm and speak slowly at a low-normal volume. This can help bring down the level of conflict and is a good chance to model patience.\n- Emphasize cooperation, e.g. working together to come up with a solution, giving each other permission to speak/get up\n- How to Make Time Outs Work: https://childmind.org/article/how-to-make-time-outs-work/\n- Managing Children’s Challenging Behaviours in the Midst of COVID-19: https://behaviortherapyassociates.com/blog/social-emotional-learning/managing-childrens-behavior-during-coronavirus/\n- Using Rules for Discipline that Works: https://centerforparentingeducation.org/library-of-articles/discipline-topics/using-rules-discipline-works/\n- How to End Sibling Rivalry in 6 Simple Steps: https://www.positiveparentingsolutions.com/sibling-rivalry\n- Sibling Rivalry: https://kidshealth.org/en/parents/sibling-rivalry.html\n- Coping with Sibling Rivalry: https://centerforparentingeducation.org/library-of-articles/sibling-rivalry/coping-sibling-rivalry/\n- How to Shape & Manage Your Young Child’s Behaviour: https://www.healthychildren.org/English/family-life/family-dynamics/communication-discipline/Pages/How-to-Shape-Manage-Young-Child-Behavior.aspx\n- Managing Problem Behaviour at Home: https://childmind.org/article/managing-problem-behavior-at-home/","Anti-social behaviors in children can stem from a number of issues, including abusive parenting, an inability to fit in with peers, emotional problems or low self-esteem. While many children might occasionally experience anti-social tendencies, ongoing troubling behaviors or significant behavioral changes should be addressed as soon as possible. Children who exhibit such behaviors might be at risk for developing anti-social personality disorder later in life, according to the Mayo Clinic website.\nAnti-social children might bully others physically or emotionally to create an imbalance of power, according to StopBullying.gov. They might force others do embarrassing things or cause physical pain. Peer cliques might demonstrate collective anti-social behaviors if they exclude other children, tease or make unwanted sexual comments or spread other hurtful rumors in person or online.\nWhile it is not uncommon for very young children to lash out when frustrated, parents might have cause for concern when aggressive behaviors continue past the toddler years. Anti-social behaviors in children include kicking, punching, hitting or fighting with peers, siblings, parents or other authority figures. While most children begin to develop empathy for others and find alternate solutions to physical altercations, those exhibiting anti-social tendencies might not, reports the American Academy of Pediatrics' HealthyChildren.org.\nChildren with an inability to manage stress might withdraw socially and isolate themselves from peers and family members, a publication by the Virginia Cooperative Extension reports. Socially isolated children might be more easily aggravated by minor irritants and appear lazy or lethargic. Some children might be isolated from peers because of an inability to regulate their behaviors to match those around them. Children who have not had regular social interactions due to physical illness or disabilities might not have learned proper social competencies, the website LD Online states.\nIt is normal for young children to tell minor lies or exaggerate the truth from time to time, but lying can become an anti-social problem when it is ongoing and represents deeper emotional problems, according to the American Academy of Child and Adolescent Psychiatry website. If children are not bothered by lying or regularly lie to take advantage or manipulate others, they are exhibiting anti-social and potentially detrimental behaviors.\n5. Cause for Concern\nParents should contact their family's pediatrician if they become worried that their child is exhibiting anti-social behaviors, which can also include manipulativeness, impulsiveness and unnecessary risk-taking. The Mayo Clinic site recommends early intervention services, including family and individual therapy, to lessen the risk of being diagnosed with anti-social personality disorder later in life. Even if a child is later diagnosed with the disorder, therapeutic interventions will help him develop tools to manage it. If potentially anti-social behaviors are actually symptoms of a different disorder, therapists, counselors and pediatricians can help families find proper treatment.\n- HealthyChildren.org: Aggressive Behavior\n- StopBullying.gov: Bullying Definition\n- Virginia Cooperative Extension: Children and Stress: Caring Strategies to Guide Children\n- LD Online: Helping the Socially Isolated Child Make Friends\n- American Academy of Child and Adolescent Psychiatry: Children and Lying\n- Mayo Clinic: Antisocial Personality Disorder\n- Pixland/Pixland/Getty Images"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:16128974-4db9-43a1-9733-6f674e72f0af>","<urn:uuid:1df598c8-f8f8-46f4-9d43-ae85d84d357b>"],"error":null}
{"question":"I'm starting a business and need to protect my brand. How do registered and unregistered trademarks differ in terms of legal protection?","answer":"Registered and unregistered trademarks offer different levels of legal protection. Unregistered trademarks (using the ™ symbol) only provide protection in the state where your business is registered and are only protected by common law. In contrast, registered trademarks (using the Ⓡ symbol) have federal protections through the USPTO and are protected in all 50 states. Registration enhances your rights by providing evidence and public notice of ownership, and allows you to sue others for infringement in federal court. The registration process costs approximately $375/class for paper filings and $325/class for online filing with the USPTO.","context":["What is a Trademark in the Marketing Industry?\nTrademarks are a type of intellectual property consisting of a word, name, symbol, or device that distinguishes products or services from a specific source from the products and services of others. Trademarks (™) are typically used to identify products, while service marks (℠) are used to identify services.\nTrademarks and service marks are essential in the world of marketing because they help customers identify those trademarked slogans and designs with a specific brand. Not only does this help the brand build recognition with their target audience but it also helps customers ensure they’re using a brand they trust. Trademarks and service marks protect the rights of owners and the safety of consumers.\nThat said, how do you go about creating a trademark or service mark for your brand? How do you register for one? Let’s take a closer look at the different trademark symbols and how you use them.\nEstablish and Register Your Trademark\nYou can establish a trademark without registering for one, although it is not recommended. Legally registering your trademark helps to protect your business. To register, you’ll need to file with the United States Patent and Trademark Office (USPTO). It’s best to hire an attorney well-versed in trademark law and protection for this process because of the strict guidelines, deadlines, and fees associated with it.\nA business with an unregistered trademark will use the ™ symbol over their brand name. A business with a registered trademark will use the Ⓡ symbol over their brand name. The difference between an unregistered and registered brand name is the legal protection behind each trademark.\nUnregistered trademarks only give you protection in the state where your business is registered and it’s only protected by common law. Registered trademarks have federal protections that the USPTO provides and your trademark is protected in all 50 states.\nWhat’s the Process for Registering a Trademark?\nBefore you register your trademark with the USPTO, the organization recommends that you ask two questions first: How difficult will it be to protect your trademark based on its strength and is your trademark capable of being registered?\nReferring to the first question, your trademark needs to be distinctive enough from other marks or products. You can use the public search database the USPTO maintains to search for similar logos, names, designs, phrases, and more to ensure your trademark is truly unique.\nThe second question refers to whether you’re applying to register for your brand or if you’re filing a patent for some other form of intellectual property. Trademarks protect words, symbols, designs, logos, or other parts of your brand. If you’re not registering a good, but a service, you’ll need to use a service mark.\nA patent is different from a trademark or service mark. Patents are limited duration property rights that relate to an invention.\nA copyright is also different from trademarks, service marks, and patents. Copyright is used for creative works and protects the authorship of those works. Copyrights aren’t handled by the USPTO, but by the U.S. Copyright Office.\nHow Do Trademarks Protect Your Brand?\nTrademarks have no expiration date, only maintenance fees. You pay these maintenance fees between the fifth and sixth year after you’ve filed for your trademark registration and then at the 10-year mark. After that mark, you only have to pay a fee every 10 years.\nWhen your trademark is officially registered, your brand is protected against trademark infringement. Trademark infringement is the unauthorized use of your trademark in a manner that causes deception or confusion about the source of specific goods or services. For instance, a ride-sharing service named Guber would be infringing on the Uber trademark.\nIf your trademark has been infringed upon, you’ll need to file a civil suit in federal court. The court considers the evidence including whether the defendant’s goods or services are sufficiently related to your trademark.\nThe penalties for the offending parties if you win your case include an injunction to stop using the mark and monetary relief. While marketers may be intimidated by the legal process of registering for a trademark, the legal benefits far outweigh the fees.","Trademarks and Patents: Everything You Need to Know\nWhile trademarks and patents are different from one another, they both fall under the intellectual property realm.4 min read\nTrademarks and Patents\nWhile trademarks and patents are different from one another, they both fall under the intellectual property realm. Intellectual property refers to ideas, concept, and inventions that are both unique and valuable. If a person or business owns the rights to that invention, then that means that the person or business can manufacture or license the invention.\nInventions with such rights can patent, copyright, or trademark the invention. But, keep in mind that not all inventions or ideas can be patented or trademarked.\n- The design of a car can be patented, but not the idea itself.\n- A story or manuscript is copyrighted, but not the idea itself.\n- A single feature of an invention can be patented, as can the entire invention itself.\nLaws regarding intellectual property rights vary in every country, but the principle remains the same. Once you have a patent, copyright, or trademark, you have the legal rights to that invention. No one else can infringe upon those benefits. Furthermore, if you have protection in one country, that protection is recognized internationally, under the World Intellectual Property Organization treaty.\nBenefits of a Trademark\n- It enhances your right by providing evidence and public notice of ownership to all others. If someone else uses your trademark, then they have infringed upon your legal rights as the owner of the trademark.\n- The trademark itself provides national exclusive rights to the mark, allowing you as the trademark owner to sue someone else.\n- A registered trademark can use the ® symbol.\n- Trademarks provide lifetime protection, but you’ll need to renew the trademark every 10 years.\n- The trademark can be renewed so long as the mark is continuing to be used.\nHow to Register a Trademark\nOnce you begin using your name or logo for your business, you have common law protection and should use the ™ symbol. Be mindful that common law protection is limited. In order to have additional protection, you’ll want to register the trademark, which can be done with the United States Patent and Trademark Office (USPTO). It will cost approximately $375/class for paper filings and $325/class for filing online. Once the registration is approved, you can begin using the ® symbol.\nTypes of Patents\n- Utility patents. Such patents are granted for processes, machinery, composition of matter, and other inventions that improve a previous invention. The invention itself must be ‘new, non-obvious, and useful.’\n- Design patents. These types of patents are granted for new ‘ornamental’ designs of a manufactured product. The appearance, or design, of the product receives patent protection.\n- Plant patents. Such patents protect asexually reproducible plants that are ‘distinct and new.’\n>Patent Protection Timeframe\nHaving a patent provides you with exclusive protection over your invention, but remember that that right lasts for a certain period of time.\n- A non-provisional utility patent protects you for 20 years, but it cannot be renewed after that.\n- A provisional patent lasts for one year, at which point you must determine if you will file a non-provisional patent to obtain full protection. More specifically, the provisional patent application simply buys you a year’s worth of time to expand upon and improve your invention. During this one year time period, you can indicate to the public that your invention is ‘patent pending’ and can receive full protection once you’ve filed a non-provisional patent application.\n- A design patent lasts for a period of 14 years.\n- Some inventions can fall into more than one patent category. For example, certain software inventions can be protected by a design and utility patent.\nHow to Register a Patent\nIf you have an invention that you want to patent, you’ll need to visit the USPTO website, which can be filed online or via paper filing. The costs associated with the patent application vary depending on the type of protection being sought.\nPatent vs. Trademark vs. Copyright\n- Patents prevent other people and businesses from manufacturing, using, and/or selling your invention.\n- Trademarks protect your words, symbols, phrases, and logos that you use to identify your goods or services, i.e., packaging on products, name of products, business logos, etc.\n- The overlap of patents, trademarks, and copyrights generally doesn’t occur. However, if a design patent protects the design of a product, then that product may also have a trademark or copyright on its name.\n- In certain cases, you may be able to obtain a copyright and patent.\n- Copyright owners also have an exclusive right to the work, including a right to duplicate their own work, display the work in public, and perform the work publicly.\nIf you need help with registering your trademark or patent, you can post your legal need on UpCounsel’s marketplace. UpCounsel accepts only the top 5 percent of lawyers to its site. Lawyers on UpCounsel come from law schools such as Harvard Law and Yale Law and average 14 years of legal experience, including work with or on behalf of companies like Google, Stripe, and Twilio."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:ee30f7eb-fe2e-40e4-91f2-ca7a95196ac9>","<urn:uuid:b86951dd-a78f-4014-b7e1-4ddf9f8bbf7f>"],"error":null}
{"question":"Is there vitamin C in rosehip oil?","answer":"No, rosehip oil does not contain vitamin C, despite a common misconception. This is because vitamin C is water-soluble and therefore not present in the oil. The antioxidant and regenerative properties of rosehip oil come from oil-soluble tocopherols (vitamin E) and carotenoids (pro-vitamin A).","context":["Cocoa Butter Formula Skin Therapy Oil\n|Ingredient name||what-it-does||irr., com.||ID-Rating|\n|Isopropyl Myristate||emollient, perfuming||3, 3-5|\n|Sesamum Indicum (Sesame) Seed Oil||emollient||0, 1-3||goodie|\n|Theobroma Cacao (Cocoa) Seed Butter||emollient||0, 4||goodie|\n|Argania Spinosa Kernel Oil||antioxidant, emollient||goodie|\n|Helianthus Annuus (Sunflower) Seed Oil||emollient||0, 0||goodie|\n|Rosa Canina Fruit Oil||emollient|\nPalmer's Cocoa Butter Formula Skin Therapy OilIngredients explained\nA clear, colorless oil-like liquid that makes the skin feel smooth and nice (aka emollient) and it does so without it being greasy.\nWhat's more, it can even reduce the heavy, greasy feel in products with high oil content. It's also fast-spreading meaning that it gives the formula a good, nice slip. It absorbs quickly into the skin and helps other ingredients to penetrate quicker and deeper.\nThanks to all this, it's one of the most commonly used emollients out there. There is just one little drawback: it has a high comedogenic index (5 out of 5...), so it might clog pores if you're prone to it.\nA synthetic emollient oil that leaves a soft non-greasy, non-sticky feel on the skin, absorbs fast and can be emulsified (mixed with water) very easily.\nA goldish to dark yellow emollient plant oil coming from Sesame seeds. Similar to many other plant oils, it contains high amounts of nourishing and moisturizing fatty acids (about 38% of oleic and 48% of linoleic acid) and is a nice oil to repair and regenerate dry skin. It is rapidly absorbed and gives the skin a soft and gentle feel.\nTheobroma means \"food of the gods\" in Greek though probably \"treat of the people\" would be more spot on. The cacao fruits and especially the seeds in it need no introduction as everyone knows them as the magical raw material of the magical sweet treat, chocolate (the flavour is composed of more than 1200(!) substances, and the exact chemical nature of it is not really understood, so it's indeed magic. :)).\nAs for skincare, cocoa butter counts as a rich emollient that can moisturize and nourish even the driest skin (think chapped hands or lips). It's solid at room temperature and melts nicely when you smear it on. It's loaded with good-for-the-skin things: it contains fatty acids, mainly oleic (35%), stearic (34%), and palmitic (25%) and it also has antioxidant vitamin E and polyphenols.\nAn ex-vivo (made on human skin but not on real people) study examined the cocoa polyphenols and found that 0.5-0.75% of them improved skin tone and elasticity and had a similarly positive impact on GAGs (important natural moisturizing factors in the skin) and collagen synthesis than a commercial high-end moisturizer (it was an Estee Lauder one).\nAll in all, cocoa butter is a goodie, especially for very dry skin.\nWhen it comes to cosmetic oils and hype, argan oil is for sure leading the way. Dubbed as the \"liquid gold of Morocco\", we have to admit we have some trouble determining why this oil enjoys such a special miracle status. Not that it's not good, it is good, even great but reading the research about argan and a bunch of other plant oils we just do not see the big, unique differentiating factor (though that might be our fault not reading enough, obvs.)\nSo, argan oil comes from the kernel of the argan fruit that comes from the argan tree that grows only in Morocco. The tree is slow growing and getting the oil is a hard job. The traditional process is that the ripe argan fruits fall from the tree, then goats eat them up and poop out the seeds. The seeds are collected and smashed with a stone to get the kernels inside. This part is the hard one as the seeds have extremely hard shells. Once the kernels are obtained, the oil is pressed out from them (the kernels contain about 50% oil).\nAs for skincare, argan oil is loaded with lots of skin goodies (but so are many other plant oils): it contains 80% nourishing and moisturizing unsaturated fatty acids, mainly oleic (38-50%), linoleic (28-38%) and palmitic (10-18%). It also contains a relatively large amount of antioxidant vitamin E (600-900 mg/kg, about twice as much as olive), small amounts of antioxidant phenols (including caffeic acid, ferulic acid, and epicatechin), as well as some rare sterols with soothing and anti-inflammatory properties.\nThanks to all the above goodness in argan oil, it can greatly nourish and moisturize the skin and hair. It's also claimed to be able to neutralize collagen-damaging free radicals, help reduce scars, and revitalize and improve skin elasticity. You can even read that argan might help acne-prone skin, but being a high oleic oil, we would be careful with that.\nAll in all, argan oil is a real goodie but we do not fully understand the special miracle status it enjoys.\n- Primary fat-soluble antioxidant in our skin\n- Significant photoprotection against UVB rays\n- Vit C + Vit E work in synergy and provide great photoprotection\n- Has emollient properties\n- Easy to formulate, stable and relatively inexpensive\nSunflower does not need a big intro as you probably use it in the kitchen as cooking oil, or you munch on the seeds as a healthy snack or you adore its big, beautiful yellow flower during the summer - or you do all of these and probably even more. And by even more we mean putting it all over your face as sunflower oil is one of the most commonly used plant oils in skincare.\nIt’s a real oldie: expressed directly from the seeds, the oil is used not for hundreds but thousands of years. According to The National Sunflower Association, there is evidence that both the plant and its oil were used by American Indians in the area of Arizona and New Mexico about 3000 BC. Do the math: it's more than 5000 years – definitely an oldie.\nOur intro did get pretty big after all (sorry for that), so let's get to the point finally: sunflower oil - similar to other plant oils - is a great emollient that makes the skin smooth and nice and helps to keep it hydrated. It also protects the surface of the skin and enhances the damaged or irritated skin barrier. Leslie Bauman notes in Cosmetic Dermatology that one application of sunflower oil significantly speeds up the recovery of the skin barrier within an hour and sustains the results 5 hours after using it.\nIt's also loaded with fatty acids (mostly linoleic (50-74%) and oleic (14-35%)). The unrefined version (be sure to use that on your skin!) is especially high in linoleic acid that is great even for acne-prone skin. Its comedogen index is 0, meaning that it's pretty much an all skin-type oil.\nTruth be told, there are many great plant oils and sunflower oil is definitely one of them.\nProbably the most common silicone of all. It is a polymer (created from repeating subunits) molecule and has different molecular weight and thus different viscosity versions from water-light to thick liquid.\nAs for skincare, it makes the skin silky smooth, creates a subtle gloss and forms a protective barrier (aka occlusive). Also, works well to fill in fine lines and wrinkles and give skin a plump look (of course that is only temporary, but still, it's nice). There are also scar treatment gels out there using dimethicone as their base ingredient. It helps to soften scars and increase their elasticity.\nAs for hair care, it is a non-volatile silicone meaning that it stays on the hair rather than evaporates from it and smoothes the hair like no other thing. Depending on your hair type, it can be a bit difficult to wash out and might cause some build-up (btw, this is not true to all silicones, only the non-volatile types).\nThough it says fruit oil in its name, the rosehip fruit contains the seeds that contain the oil. So this one is the same as Rosa Canina Seed Oil, or Rosehip Oil, known for its high omega fatty acid content (linoleic acid - 51%, linolenic acid - 19% and oleic acid - 20%) and skin-regenerative properties.\nThere is a common misconception that rosehip oil contains vitamin C as the fruit itself does, but vitamin C is a water-soluble vitamin hence it is not contained in the oil. The antioxidant and regenerative properties of the oil probably come from the oil-soluble tocopherols (vitamin E) and carotenoids (pro-vitamin A). Read more here.\nExactly what it sounds: nice smelling stuff put into cosmetic products so that the end product also smells nice. Fragrance in the US and parfum in the EU is a generic term on the ingredient list that is made up of 30 to 50 chemicals on average (but it can have as much as 200 components!).\nIf you are someone who likes to know what you put on your face then fragrance is not your best friend - there's no way to know what’s really in it.\nAlso, if your skin is sensitive, fragrance is again not your best friend. It’s the number one cause of contact allergy to cosmetics. It’s definitely a smart thing to avoid with sensitive skin (and fragrance of any type - natural is just as allergic as synthetic, if not worse!).\n|what‑it‑does||emollient | perfuming|\n|irritancy, com.||3, 3-5|\n|irritancy, com.||0, 1-3|\n|irritancy, com.||0, 4|\n|what‑it‑does||antioxidant | emollient|\n|irritancy, com.||0-3, 0-3|\n|irritancy, com.||0, 0|\n|irritancy, com.||0, 1|"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:1cebf72e-d45b-41f2-81c0-9b50489320d4>"],"error":null}
{"question":"What is maximum size of Galeus melastomus and what does it eat?","answer":"The maximum length of Galeus melastomus (Blackmouth Catshark) is debated - while there is a record of 90cm, other researchers list smaller maximum sizes of 62-67cm. Regarding diet, they hunt for bottom dwelling invertebrates like shrimps and cephalopods, as well as small bony fishes including lanternfishes.","context":["Slender body. Snout pointed. First dorsal origin approximately level with pelvic fin insertion. First and second dorsal fins of equal size, with a pointed apexes. Pectoral fins large. Anal fin very long; extending from level of first dorsal insertion to origin of caudal fin. Caudal fin has a distinct row of enlarged dermal denticles along upper margin. Dorsal coloration predominantly brown with a vivid pattern of large and small brown circles, edged in white. Circles form rows extending from head to tip of tail. Larger animals have more intricate patterns with a greater amount of circles within each row. Fins dark blueish-grey with vague pale circles and pale margins.\nGaleus melastomus is one of the largest sawtail catsharks. Maximum length 90cm (Compagno et al. 2005). This record is questionable since other researchers list vastly smaller maximum sizes of 62-67cm (Rey et al. 2002, Costa et al. 2005). Size at birth unknown.\nRocky, sandy or muddy substrates on outer continental shelf. Usually remains on bottom or close to it. Mostly found between 200-500m. Listed as occurring between 55-1000m, but regularly encountered in certain Norwegian fiords between 25-40m even when no chum is used.\nThe blackmouth Catsharks is present in the Northeast Atlantic Ocean and Mediterranean Sea. From the Faroe Islands and Southern Norway southward to the Azores and Senegal.\nThis species is taken as bycatch by demersal trawls and longlines throughout large areas of its geographic range. It is generally discarded, but is retained and utilised in some areas.\nAlthough a large portion of the population of G. melastomus avoided most of the commercial fishing pressure associated with the 1970s deepwater trawl fishery for Blue Ling (Molva dypterygia) in the northeast Atlantic at >600 m, it is concerning to note that mature individuals of this species are found at similar depths to the shallowest depth range of this fishery, and that commercial deepwater trawl vessels are now targeting these sharks. The targeting of mature individuals of this species may lead to similar detrimental impacts experienced by other deepwater species in this area (Crozier 2003).\nOff the south coast of Portugal (Algarve), this species is captured in high quantities as bycatch of the bottom trawl fishery that targets the Norway Lobster (Nephrops norvegicus), Red Shrimp (Aristeus antennatus) and Deepwater Pink Shrimp (Parapenaeus longirostris), and by the near bottom longline fishery that targets European Hake (Merluccius merluccius), Conger Eels (Conger conger) and Wreck Fish (Polyprion americanus). In both fisheries, most captured specimens are discarded (Coelho et al. 2005). Most specimens are captured and returned to the sea alive, but usually with severe injuries (due to the long trawling periods or hooks) that are likely to impair their survival. However, declines in traditional target species during the last few years mean it is likely that fisherman are now landing larger quantities of “alternative” species, such as this catshark, so it may be increasingly retained and sold.\nThe species is caught as bycatch by trawl nets and bottom longlines on slope bottoms. The species appears to suffer greater fishing mortality in the Ionian, south Adriatic and Aegean Seas, compared to along the coasts of Morocco, Spain, France and around Crete. Length Frequency Distributions (LFD) show that along the coasts of Morocco, Spain, France and around Crete specimens were mostly larger than 30 cm (78% of the total), while only 23% of the specimens around the coasts of Corsica, Sicily and in the Ionian, South Adriatic and Aegean Seas were over 30 cm (Serena et al. 2005).\nIt seems that this species suffers relatively moderate effects from fishing pressure in the south Ligurian and northern Tyrrhenian sea, although it is an important bycatch of the Norway lobster Nephrops norvegicus fishery.\nG. melastomus constitutes a significant portion of the bycatch of the Viareggio fleet’s fishing efforts, but most of the individuals are discarded due to the limited market demand and low commercial value. Only a fraction of the larger individuals (TL>40 cm) are landed at Viareggio (about 700 kg in 2002) (Abella and Serena 2005). Considering the depths at which G. melastomus is caught (250–800 m) and the observed poor condition of the individuals immediately after their capture, it is likely that only a small fraction of the discarded individuals survive. However, it should be noted that the fishing grounds for the Viareggio fleet coincide only partially with the areas where G. melastomus is known to be abundant, and that higher densities of this species are found in deep waters off northern Corsica, where the fishing pressure is moderate. These areas could therefore act as a refuge for this species (Abella and Serena 2005).\nIn the Alboran Sea, where this species is very abundant, G. melastomus is the most important bycatch species in the recently developed bottom trawl fishery targeting the Deepwater Shrimp (Aristeus antennatus) (Torres et al. 2001).\nThe recently developed ban on bottom trawling below depths of 1,000 m in the Mediterranean Sea probably offers this species some refuge from fishing pressure.\nCitations and References\nSerena, F., Mancusi, C., Ungaro, N., Hareide, N.R., Guallart, J.,Coelho, R. & Crozier, P. 2009. Galeus melastomus. The IUCN Red List of Threatened Species 2009: e.T161398A5414850. https://dx.doi.org/10.2305/IUCN.UK.2009-2.RLTS.T161398A5414850.en. Downloaded on 13 October 2020.\nAn oviparous species, laying up to 13 egg cases. Egg production occurs year round. Hatching occurs mainly in spring and summer.\nHunts for bottom dwelling invertebrates (shrimps, cephalopods, etc) and small bony fishes including lanternfishes.\nLittle is known about blackmouth catshark behavior. Forages over substrate in search of food, sometimes seen resting in areas where an abundance of food is available i.e. near fish and scallop farms.\nReaction to divers\nFairly easy to approach when resting on the sea floor. Will bolt if approached to quickly or aggressively.\nRarely encountered south of Norway. Although normally found in water too deep for recreational diving, in certain Norwegian fiords e.g. Namsen Fiord and Trondheim Fiord, run-off at the surface creates a layer of silty water that significantly lowers the light level in the water below it.\nIn these areas, blackmouth catsharks and other deepwater species (such as velvetbelly lantern sharks), are found much closer to the surface than elsewhere.\nBlackmouth Catsharks can often be seen when exploring certain reefs within these fiords but they are even easier to see and approach when bait is introduced.\nAtlantic Sawtail Catshark Distinguished by less intricate markings including large blotches and saddles. Limited range from Spain to Northwest Africa, at depths between 330-790m.\nAfrican Sawtail Catshark Distinguished by blotchier flank markings and saddles. Range overlap from Morocco to Senegal. Found at depths between 159-720m.\nThe Shark Forum\nLet’s talk about sharks"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:f5ca3907-e243-4942-ad49-f6f88728ee0a>"],"error":null}
{"question":"Flying range comparison needed: What is difference between Czech-Israel military flights in 1948 versus modern C-5M Super Galaxy maximum range? Distance Zatec-Israel was how many miles?","answer":"The flight distance from Zatec, Czechoslovakia to Israel in 1948 was 1,800 miles, which was considered a very tough route that required careful planning and refueling stops. In comparison, the modern C-5M Super Galaxy has an unrefueled range of 5,250 nautical miles (9,723 km) while carrying 120,000 lbs of cargo. This shows a dramatic improvement in aircraft range capabilities, as the modern C-5M can fly more than twice the distance of the 1948 route without requiring any refueling stops, while carrying significant cargo loads.","context":["Aliyah Bet & Machal Virtual Museum\nNorth American Volunteers In Israel's War of Independence\nPictorial History: Air Force Volunteers\nOnly a handful of Palestinian\nJews had military pilot training. Veterans from World War II – primarily\nfrom the U.S., Canada, England and South Africa – manned the\nhodgepodge of German, American and British aircraft to stop the Arab\nair and ground attacks.\nSince England would not admit Palestinian Jews into the Royal Air Force for aircrew training until 1943, pilots, navigators and other flying personnel with military experience were in short supply. Israel turned to the Diaspora – primarily to the U.S., Canada, England, and South Africa – for veteran flying crews who could help stop the Arab invasion on the ground and in the air. More than half of all American and Canadian volunteers served in the air force.\nEddy Kaplansky, an authority on the IAF during the 1948-49 war, concluded: “It is generally accepted that without Machal the nascent IAF would not have been able to fly its heavy bombers and transport planes, nor could it have wrested control of the skies from enemy air forces. It may well be, therefore, that the participation of Machal in the IAF is what tipped the scales in Israel’s favor in the War of Independence, whose outcome hung precariously in the balance.”\nGroup of men in front of B-17\nA Heavy Bomber for Israel\nThis group of men, almost all Machal, are shown in front of their B-17 shortly before it took off for Israel from Zatec airport in Czechoslovakia in July 1948. It was one of three B-17s that had come from Miami. They remained the only heavy bombers in the Israeli Air Force for the duration of the war.\nTop Canadian Ace\nGeorge F. “Buzz” Beurling, shown painting a “win” on his Royal Canadian Air Force spitfire, was the top Canadian air ace in World War II, with 31 Nazi planes to his credit. He was one of 34 Christian pilots from the U.S. and Canada to volunteer for the IAF. Beurling, 26, and his Jewish co-pilot, Leonard Cohen of England, were killed while attempting to ferry a plane from Italy to Israel on May 20, 1948.\nGerman Fighter Plane for Jewish Air Force\nIronically, Israel’s first fighter plane was the famed German fighter Messerschmitt ME-109. The Czech’s sold 25 of its own version of the fighter to Israel. It had a bomber motor, making it very unwieldy to fly and land. Many of the planes crashed shortly before or after arriving in Israel. The Czechs then sold Israel Spitfires they had obtained from England. This was a much better fighter.\nRudy Augarten, 26, a Harvard student when he volunteered for the IAF, stands in front of a crashed Egyptian spitfire. Augarten had downed two German ME-109s while flying a P-47 during World War II. He shot down four Egyptian aircraft while flying a Czech ME-109, a British Spitfire and an American P-51. He was one of only six Americans awarded “ace” status by combining victories in two wars. Augarten returned to Israel in 1950-52 to become commanding officer of Ramat David Air Force Base and IDF Flying Courses.\nThis page of a flight log kept by flight engineer Bill Lichtman, 30, of New York City shows that the B-17 took off from Miami on June 19, 1948. After refueling stops in Puerto Rico and the Azores, it landed in Zatec, Czechoslovakia, on June 20 to be refitted with guns and bomb racks. It took off from Zatec on July 15 with a full bomb load, and on its way to Israel detoured for a bombing mission over Cairo. This was the first and time an Israeli plane bombed Cairo in 1948. This raid essentially put a stop to the daily bombing of Tel Aviv by the Egyptians. Pilot of the B-17 was Ray Kurtz, a former New York City fireman. Both Kurtz and Bill Lichtman were World War II veterans.\nRow of Norseman aircraft\nIsraeli Parcel Service\nSome 16 of these Canadian-designed Noorduyn Norsemans were purchased as war surplus in Germany, and refitted with long-range tanks by KLM airlines in the Netherlands. Machal pilots flew 10 of them non-stop from Rome to Israel in the first weeks of the war. It was a grueling 11½-hour journey. The large, single-engine planes supplied Dead Sea and Negev outposts, and even flew as improvised bombers.\nThree Americans Who Flew A German ME-109\nIsrael’s only fighter planes in the first few months of the war were 10 S-199 Aviahs (the Czech version of the famed German Messerschmitt ME-109). Shown with this Avia are, left to right, Gideon Lichtman, 24, Newark, New Jersey, Bill Pomerance, 26, also of Newark, and Leon Frankel, 24, St. Paul, Minnesota. Gideon Lichtman was the first Israeli Air Force pilot to shoot down an Arab fighter plane. Pomerance was one of the few U.S. pilots in World War II to down four enemy planes in one day. Frankel won the Navy Cross, the U.S. Navy’s second-highest medal, for sinking a Japanese cruiser while flying a torpedo bomber.\nPiper Cubs go to War\nPiper Cubs provided a host of different services. They served as observation planes in battle, ferried medical supplies to isolated kibbutzim, and dropped mail and newspapers to front-line troops. Machal instructors also used them as trainers for Israeli student pilots. A line of Piper Cubs is shown at the St. Jean student pilot airfield near Acco. (Note the bomb racks on the belly of the Piper.)\nNew Generation of Pilots\nOne of the first Israeli graduates of the flying course, Shaikey Gazit, receives his wings from Lt. Gen. Yaacov Dori, first chief of staff of Israel’s armed forces.\nMachal Ground Forces\nVolunteers brought important specialized skills to the fledgling Israeli Air Force – among them aerial photography, radar operations, and aircraft maintenance. Shown here are Machal volunteers exercising control room skills learned during World War II service.\nFreight to Win the War\nCurtis-Wright C-46 Commando\nThe Curtiss-Wright C-46 Commando could be called the plane that saved Israel. Ten of the huge planes were bought as war surplus in California. They were sent to Panama as part of the dummy “Lineas Aereas de Panama” (Panamanian Airlines) fleet, and then flown to Czechoslovakia. With Machal pilots serving in Israel’s Air Transport Command, they became the freight trains that shipped Czech arms, ammunition, and even disassembled aircraft to beleaguered Israel.\nHal Auerbach, 33, a Navy pilot in World War II, flew heavy transports in 1948 on their various journeys to Panama, Czechoslovakia, and Israel. A native of Escanaba, Michigan, he is shown with a DC-5. The crew drew a Star of David with wings on the nose and named the plane “Yankee Pasha, Bagel Lancer.”\n1,800 very, very tough miles, Zatec, Czechoslovakia, to Israel.\nThe Czech Connection\nA little-known story of the Arab-Israeli war of 1948 involved American planes, mostly-American pilots and the decision of one small country to help another.\nAfter approval of the Partition Plan in November 1947, England continued to supply weapons and ammunition to its client-states Egypt and Trans-Jordan. But virtually the entire world imposed an embargo on sale and shipment of military equipment to Israel—except Czechoslovakia, which agreed to sell a substantial amount of German-designed rifles, machineguns, ammunition, and even fighter planes to the Jewish state\nBut Czechoslovakia was land-locked, surrounded by countries that would not allow transshipment of arms in violation of the embargo, and more than 1,800 miles from Israel. With a chartered C-54 and seven of the C-46s originally purchased as war surplus in California, Machal pilots and crews in the Israeli Air Force Air Transport Command began an airlift that would become one of the miracles of the War of Independence.\nFor more than three months—May 1948 to August 1948—Czechoslovakia loaned Israel its Zatec air field. It become virtually an Israeli installation and was used for refitting\nplanes, training pilots, and shipping point for guns and ammunition. Pilots and crews of planes utilizing the airfield stayed at the Stalingrad Hotel in Zatec. (Shown at left of\nphoto is Bill Lichtman, a crew member of a B-17 being refitted at Zatec).\nC-46 over Haifa Bay\nCzech-made ME-109 fighters were taken apart, loaded into C-46s (it took two C-46s to carry the pieces of one ME-109) and flown to Israel, with one refueling stop in Corsica. The first ME-109 arrived in Israel on May 20, 1948. It was immediately re-assembled, and within one day attacked Egyptian troops nearing Tel Aviv. By the time the Czechs closed Zatec to the Israeli armed forces, Machal volunteers in the Air Transport Command had completed 95 flights, carrying 25 Me-109s to Israel and an incredible 35 tons of arms and ammunition, including more than 15,000 rifles, 4,000 machineguns and 3 million rounds of ammunition.\nEddy Kaplansky. A native of Montreal and a veteran of the Royal Canadian Air Force in World War II, Eddy was both an Aliyah Bet crewman (Northland\\Jewish State) and a Machal pilot in the Israeli Air Force during the War of Independence. A resident of Haifa, Eddy provided research and advice on most of the panels in this display. He wrote the entire article in this section on the history of the Air Force volunteers, and compiled the photos and text for the section on the 40 men who died in the service of Israel. Eddy wrote the definitive book on the early days of the Israel Air Force, “The First Fliers” (Israel Air Force Historical Branch, 1993), and meticulously named every Canadian who served in Machal. Eddy died in Haifa on March 6, 2005, while corresponding daily with the Gainesville production crew of the Museum of American and Canadian Volunteers in Israel’s War of Independence, located in the main hallway of the University of Florida’s Hillel building.","Lockheed Martin delivered the 52nd C-5M Super Galaxy strategic transport modernized under the U.S. Air Force’s Reliability Enhancement and Re-engining Program (RERP) on August 2 at the company’s Marietta, Georgia, facility.\nThe delivery completes the RERP upgrade, which extends the service life of the C-5 fleet out until the 2040s.\n«With the capability inherent in the C-5M, the Super Galaxy is more efficient and more reliable, and better able to do its job of truly global strategic airlift», said Patricia Pagan, Lockheed Martin Air Mobility and Maritime Missions Strategic Airlift director, «I am very proud of the contractor-government team than carried out the C-5 fleet modernization effort. We’ve worked very hard to ensure the C-5Ms are the absolute best strategic airlifters possible for our armed forces».\nAn Air Force Reserve Command aircrew from the 439th Airlift Wing at Westover Air Reserve Base, Massachusetts, ferried the final C-5M Super Galaxy to Stewart Air Force Base, New York, where the aircraft will undergo interior paint restoration. Once that work is complete, the aircraft will be flown to Westover where it will be the eighth C-5M Super Galaxy assigned to the base.\nLockheed Martin began RERP development work in 2001. RERP incorporates more than 70 improvements that improve reliability, efficiency, maintainability and availability. RERP included changes or modifications to the airframe structure; environmental and pneumatic systems; hydraulic systems, electrical system; fuel system; landing gear; and flight controls.\nThe heart of the system is the GE F138 turbofan engine (known as a CF6-80C2L1F in the commercial world) de-rated to 50,000 pounds/22,680 kg of thrust on the C-5M Super Galaxy. This engine provides 22 percent more thrust than the out-of-production TF39 turbofans on the earlier C-5A/B/C aircraft. The engines also allow the C-5M Super Galaxy to meet the FAA’s (Federal Aviation Administration) Stage 4 noise reduction requirements.\nThese changes, taken together, result in a 22 percent increase in thrust, a shorter takeoff roll; a 58 percent improvement in climb rate; allows the C-5M Super Galaxy to cruise – at maximum gross weight – in the Communication/Navigation/Surveillance/Air Traffic Management (CNS/ATM) flight environment; and greatly enhanced fuel efficiency and less tanker support demand.\nFirst flight of a modified aircraft to the C-5M Super Galaxy standard came in Marietta, Georgia, on June 19, 2006. The first operational C-5M Super Galaxy was delivered to Dover Air Force Base, Delaware, on February 9, 2009. A total of 49 C 5Bs, two C-5C aircraft, and one original C-5A was modified under RERP.\nThe C-5M Super Galaxy holds 89 FAI-certified (Fédération Aéronautique Internationale) world aviation records, the most by any aircraft type. These records include time-to-climb with payload, altitude with payload, and greatest payload carried.\nThe C-5 Galaxy has been operated solely by the U.S. Air Force since 1970 and is the largest strategic airlifter in the U.S. Air Force’s fleet. The C-5 Galaxy is capable of carrying two 78-ton M1A1 main battle tanks or helicopters and other large equipment intercontinental distances. Fully loaded, a C-5 Galaxy has a gross weight of more than 800,000 pounds/362,874 kg. All of the C-5s were built at Lockheed Martin’s Marietta site.\nIn addition to Westover, C-5Ms are assigned to active duty and Air Force Reserve Command units at Dover Air Force Base, Delaware (436th and 512th Airlift Wings) and Travis Air Force Base, California (60th and 349th Air Mobility Wings). The C-5 aircrew training squadron is part of the 433rd Airlift Wing, the Reserve wing at Joint Base San Antonio-Lackland, Texas.\nC-5M Super Galaxy\nThe C-5M Super Galaxy aircraft is a game changer to the warfighter and America’s premier global direct delivery weapons system. It is also the Air Force’s only true strategic airlifter. While setting 86 world records in airlift, the C-5M Super Galaxy established new benchmarks in carrying more cargo faster and farther than any other airlifter.\nA venerable workhorse, the recognized improvements in performance, efficiency and safety it provides validate the tremendous value to the taxpayer in modernizing proven and viable aircraft. As the only strategic airlifter with the capability of carrying 100 percent of certified air-transportable cargo, the C-5M Super Galaxy can carry twice the cargo of other strategic airlift systems. The C-5M Super Galaxy also has a dedicated passenger compartment, carrying troops and their supplies straight to the theater. It can be loaded from the front and back simultaneously, and vehicles can also be driven directly on or off the Galaxy. This means the C-5M Super Galaxy can be loaded quickly and efficiently.\nThe C-5M Super Galaxy has been a vital element of strategic airlift in every major contingency and humanitarian relief effort since it entered service. The C-5M Super Galaxy is the only strategic airlifter capable of linking America directly to the warfighter in all theatres of combat with mission capable rates excess of 80 percent. With more than half of its useful structural life remaining, the C-5M Super Galaxy will be a force multiplier through 2040 and beyond.\n|Primary Function||Outsize cargo transport|\n|Prime Contractor||Lockheed-Georgia Co.|\n|Crew||Seven: pilot, co-pilot, 2 flight engineers and 3 loadmasters|\n|Length||247.8 feet/75.53 m|\n|Height||65.1 feet/19.84 m|\n|Wingspan||222.8 feet/67.91 m|\n|Power Plant||4 × General Electric CF6-80C2 turbofans|\n|Thrust||50,580 lbs/22,942.7 kgf/225 kN|\n|Normal cruise speed||Mach 0.77/518 mph/834 km/h|\n|Unrefueled Range with 120,000 lbs/54,431 kg||5,250 NM/9,723 km|\n|Max takeoff weight (2.2 g)||840,000 lbs/381,018 kg|\n|Operating weight||400,000 lbs/181,437 kg|\n|Fuel capacity||332,500 lbs/150,819 kg|\n|Max payload (2.0 g)||285,000 lbs/129,274 kg|\n|Length||143.7 feet/43.8 m|\n|Width||19 feet/5.79 m|\n|Height||13.48 feet/4.11 m|\n|Unit Cost||$90 million (fiscal 2009 constant dollars)|\n|16 C-5Ms have been delivered through December 2013|\n|52 C-5Ms are scheduled to be in the inventory by fiscal 2017|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:5e8c4767-f0b3-4eea-ae21-8a1078655576>","<urn:uuid:5debac80-67c2-4668-8a62-4b4c09511056>"],"error":null}
{"question":"how true wind vs apparent wind affect sail performance?","answer":"True wind and apparent wind affect sailing performance differently. True wind is what you feel when tied up at the dock and is measured relative to the fixed earth, while apparent wind is what you experience while moving with the boat - it's a combination of true wind and boat speed wind. While apparent wind is important for setting sails and judging performance, true wind is crucial for understanding weather patterns and detecting wind shifts. In practice, when sailing into wind gusts, the apparent wind increases and changes direction, making leeward telltales spin and causing the boat to heel over. Conversely, in wind lulls, the apparent wind changes direction making windward telltales spin. For fast planing boats, sailing dead downwind is rarely optimal as they generate more apparent wind and achieve better speed by sailing at more of a reaching angle.","context":["How to calculate the true wind and why it matters to sailors (published September 2013)\nThere are several ways to define the wind. For weather work at sea we care only about the true wind. This true wind is the speed and the direction of the wind relative to the fixed earth under the ocean. Tied up at the dock, we feel the true wind. Once we get underway, however, our own motion changes the wind we feel, and then it is called the apparent wind.\nMany sailors claim that the apparent wind is all they care about, and that can be well argued when it comes to setting sails and judging performance. But to know about the weather patterns that are causing the wind and how the wind is changing, we need to know the direction of the true wind as accurately as possible. Shifts in the true wind are usually the first sign of changing patterns (for more on wind shifts see the June 2013 issue of BWS). If we do not figure this properly, we can miss an important shift. This is not a simple observation though, which is the point at hand. Slight changes in true wind speed affect boat speed, and in turn, the apparent wind speed and direction, which can easily mask a small but important shift in the true wind direction.\nTo help practically illustrate these points, let’s bring in some shorthand:\nAWS = Apparent Wind Speed (relative to the boat)\nAWA = Apparent Wind Angle (relative to the bow, 0 to 180, starboard plus, port minus)\nAWD = Apparent Wind Direction (relative to true north)\nS = Knotmeter speed (relative to the water)\nH = Heading (relative to true north)\nDFT = Current Drift (speed, relative to fixed earth)\nSET = Current Set (direction it flows toward, relative to fixed earth)\nSOG = Speed Over Ground (relative to the fixed earth)\nCOG = Course Over Ground (relative to the fixed earth)\nTWS = True Wind Speed (relative to the fixed earth)\nTWD = True Wind Direction (relative to true north)\nSince wind directions are almost always discussed in terms of true directions, not magnetic, we’ll forget the compass for now and consider all directions as being true. Our actual use of compass directions in navigation does indeed complicate things a bit, but that can be sorted out later as it is not really related to the subject at hand.\nTo review the issues involved, we’ll start with a basic example. It can be dead calm at the dock, and I take off under power headed due north with my knotmeter reading 5.0 knots, and sure enough, I will have 5.0 knots of apparent wind right on the bow. S = 5.0, H = 000, AWS = 5.0; AWA = 0, implying AWD = 000.\nIf I then turn to H = 090, I will still have AWS = 5.0 and AWA = 0, but now the AWD = 090. So, if there is no wind at all, I am creating it all myself.\nA bit closer to the point at hand, I could do this same thing, still with S = 5 knots and then I notice that I have AWS = 7.0 knots, still with AWA = 0. Something changed. I check the GPS and see that my SOG = 7.0 knots, and that accounts for the extra wind. I am in a current that is moving the boat at 2.0 knots. Now I need to look at the COG. If the COG is exactly equal to my Heading, then this current is directly on my stern, pushing me forward at DFT = 2.0, SET = 090.\nNow, if I shut off the engine and slow to S = 0, with H = 090, I should see AWS = 2.0, still with AWA = 0, providing the COG = 090, and SOG = 2.0 (still H = 090), and I can conclude that I have measured two things: The true wind is calm, and the current is setting toward 090 at 2.0 knots. If this were not the case, one of these numbers had to be different.\nWhen TWS is not zero, this analysis gets more complex and a vector triangle must be solved, but the key point is always the difference between COG and H. If COG = H, meaning you are moving the direction you are headed, then all of the standard vector triangle solutions for finding true wind will work fine. You just substitute SOG for the S that is in the equations or plotting routines.\nGenerally, these formulas and plotting routines solve for true wind angle (TWA) based on AWA, AWS and S. Then you apply the TWA to H to get the TWD. That all works fine in those cases, and there are numerous resources online, such as the one included in what we call the NIMA Nav Calculators, which is a free download at www.starpath.com/navpubs.\nOnce you are being set off course and COG does not equal H, then the standard formulas for computing true wind from apparent will not work properly, because we measure the wind direction relative to H, but our actual motion is in direction of COG. Thus, you can no longer simply work with apparent wind angle (AWA); you have to switch to using apparent wind direction (AWD) and solve the vectors relative to COG, as shown in the sketch opposite.\nAlso, it seems to me that the typical equations we see in books (including my own) that use some form of the Law of Cosines might not be able to handle all the various combinations of directions in this case. It seems safer to get the answer from x-y coordinates, and so we present these formulas, written in a way that can go directly into a spreadsheet or calculator.\nAWA = + for Starboard, – for Port\nAWD = H + AWA ( 0 < AWD < 360 )\nu = SOG * Sin (COG) – AWS * Sin (AWD)\nv = SOG * Cos (COG) – AWS * Cos (AWD)\nTWS = SQRT ( u*u + v*v )\nTWD = ATAN ( u / v )\nRemember, in a spreadsheet all the angles have to go in as radians, i.e. COG = COG(º)*(Pi/180). In a spreadsheet you can write AWD = MOD(H+AWA;360).\nNote: the above picture is more complicated than we need in practice. Once you have figured AWD, you can use your standard plotting method to get the true wind. In other words, usually you do not have to compute SOG and COG; they can be measured from the GPS.\nHowever, it is likely simpler to plot it with actual bearings, rather than as a relative plot using COG as 000. Below is a sample. It is the green triangle that you plot, i.e. plot SOG/COG and plot AWS/AWD and connect the end points to get TWS/TWD.\nThe spreadsheet format that computes everything will make it easier to experiment with various interactions of sailing and current to see how this affects the final outcome. You can download a copy of this spreadsheet with the equations in it at the tech support page for Modern Marine Weather (www.starpath.com/weatherbook).\nKeep in mind that these measurements assume the instruments are calibrated and the wind sensors are located away from disturbing wind from the sails or other rigging on a power driven vessel. We have seen cases where the masthead instruments are affected by updrafts from the sails, which is why some race boats use a rather large arm holding the instruments a good distance off of the masthead.\nOne easy test is to measure true wind on one tack compared to the other tack as you tack back and forth in smooth water. This exercise might expose other important issues too, namely that your speed varies noticeably on each tack, implying that the speed sensing is not purely symmetric––assuming the sails are. In big waves, you often expect the speed to be different on opposite tacks, but if the speed sensors and sail trim are working properly, the true wind should be the same on each tack or gybe.\nBen Ellison has pointed out (www.panbo.com) that many performance sailors prefer to know the wind vector relative to the water as opposed to the fixed ground below it, which is what we would get by simply using S for SOG and H for COG. This is the way many instruments compute this data, though many models now offer options. He proposes to call this wind the Water Wind, as opposed to True Wind (which as shown above is not correct), and then do away with the term True Wind and call that Ground Wind. There is clearly logic in this terminology, and it drives home the point that we should think on these differences. We will have to see how the sport and industry responds.\nI am old fashioned in these matters, and will likely stick with true wind, and just check that it is computed properly when it matters. But then, I still use GMT when I should say UTC1.\nDavid Burch is the director of Starpath School of Navigation, which offers online courses in marine navigation and weather at www.starpath.com. He has written eight books on navigation and received the Institute of Navigation’s Superior Achievement Award for outstanding performance as a practicing navigator.","Understanding how Apparent Wind works and its impact on how you should efficiently sail the boat is crucial, and even though it may seem theoretical at first it’s well worth mastering this subject. You may get some “aha moments” while reading the theory as you would have seen the effects on the water already.\nWhat is Apparent Wind?\nThe wind you experience while moving with the boat is called Apparent Wind. It’s the combination of the True Wind and the Boat speed Wind.\nApparent wind changes in wind gusts\nSo, what happens when your boat sailing close hauled suddenly is hit by a stronger breeze – a wind gust?\nThe first thing that happens is that the True Wind component increases, and hence the Apparent Wind also increases and changes direction. This means that your leeward telltales will suddenly start spinning, the boat will be heeling over from the stronger wind and it feels like you are getting a lift, although the True Wind still comes from the same direction as before.\nWhen the boat is hit be the more powerful breeze it will either accelerate and eventually the True Wind direction will become more or less the same as it was before the gust, or if the boat has already reached its maximum speed it won’t accelerate further. Hence the way to respond to these gusts will vary if you’re in e.g. a small planing skiff or in a large keel boat.\nand in lulls…\nThe opposite obviously applies when sailing into a lull (less wind). Suddenly the Apparent Wind changes direction and your windward telltales will start spinning around. It’s tempting to bear away, although if it’s a very short lull it may be better to keep your course waiting for the wind to fill in again. There may also be a temptation to tack as it feels like you’ve been headed. The decision whether to tack or not should then be based on where the best wind strength is and other tactical aspects such as what other boats are doing. Just be aware it’s not a real header you sailed into.\nThe boat will also slow down in the lighter breeze and eventually the Apparent Wind direction will be similar to before. Again, changes in boat types will react differently, where a large heavy boat will keep its boat speed much longer than a dinghy would.\nWhy fast boats don’t sail dead downwind\nLet’s now look what happens when we sail downwind. See how the Boat Speed Wind and the True Wind are opposite resulting in a small force of Apparent Wind speed. At times at the end of a gust, or surfing down a wave, you may even sail faster than the wind and suddenly all power goes out of the sails.\nFor fast planing boats going dead downwind is rarely a good option as they will be so much faster reaching that the extra distance they will need to cover is more than well compensated for in better boat speed. By sailing at more of a reaching angle these boats will generate more apparent wind which in turn allows them to sail much faster.\nApparent Wind and current / tide\nIf you’re sailing in a current your boat speed component will also be affected by the moving water. We’ll look further into this in another article.\nI’m sure there’s a lot more to be said about apparent wind, but this hopefully should serve as an introduction. As always we welcome questions and comments to the article."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:1b8265d6-49d4-4471-a596-1563f17d4fb0>","<urn:uuid:15abd82a-a7f0-454f-bbd4-3ebed7896840>"],"error":null}