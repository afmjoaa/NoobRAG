{"question":"Which natural pest control method provides better coverage: biological controls through predatory organisms or companion planting through diverse vegetation?","answer":"Based on the documents, companion planting through diverse vegetation provides more comprehensive pest control coverage than relying solely on biological controls through predatory organisms. While biological controls like predators (ladybird beetles, ground beetles), parasites (trichogramma wasps), and pathogens can help control specific pests, companion planting offers multiple pest control mechanisms simultaneously. It attracts and sustains these same natural enemies while also disrupting pests' ability to locate host plants, provides alternate prey sources for beneficial insects, creates ground-level complexity for predator habitat, and can even produce soil-benefiting effects like nitrogen fixation. For example, combining herbs, flowers like sweet alyssum, and native perennials creates a multi-layered approach to pest management that supports various beneficial organisms while providing multiple barriers to pest establishment.","context":["FEWER BUGS AND WEEDS\nPesticides are chemicals used to kill or repel pests. Pesticides include herbicides (Which kill plants), insecticides (which kill insects) and fungicides (which kill fungi).\nThe pesticides used in a yard are poisons and may pose a health threat to the person applying them if not handled carefully. They also pose a threat to animals, plants, and insects beyond the intended pests. Honeybees are an example of non-target organisms. They are very susceptible to many household pesticides such as carbaryl (sevin) and chlorpyrifos. Other non-targets include ladybird beetles, which are natural biological pest controls, and fish, which can suffer direct poisoning from the household insecticides, permethrin, resmethrin, pyrethrin, and rotenone washed into a stream or lake. Studies have detected pesticides in 97% of urban stream water samples. Pesticides have been linked to hormonal imbalances in fish.\nUntil recently, groundwater was thought to be immune from the many chemicals used on lawns and gardens. However, contamination may occur when polluted surface water moves through the soil to the water table.\nIntegrated Pest Management\nWhen we see weeds or insects invading our favorite plants, our first response is often to apply a pesticide. Some people even apply a pesticide to prevent invasions by pests. Both of these automatic responses lead to unnecessary pesticide use. A better approach is Integrated Pest Management (IPM).\nCultural pest control methods attempt to create optimal growing conditions for plans and unfavorable conditions for pests. Methods include:\n- Select disease-resistant varieties of plants.\n- Plant varieties adapted to the geographic and soil conditions.\n- Maintain a rich, fertile soil, with the proper pH for the plants being grown.\n- Rotate plants to disrupt the life cycle of pests (this is called crop rotation).\n- Plant and harvest early to promote healthier, stronger plants and avoid peak insect populations.\n- Remove pest-infected plant residue in the fall.\n- Plant a wide variety of crops to reduce potential pest problems.\n- Evaluate the availability of sunlight and water. Most garden plants need plenty of each to help control pest problems.\nProper mowing heights are important. Set the mower to cut at 3 inches or higher. Mow often, each time the grass reaches 4 inches. (It’s important not to cut more than one-third of the height.) On troublesome spots, remember that improper light, moisture or soil conditions discourage good turf. Use of shade-tolerant grasses, bringing in topsoil, or switching to alternative ground covers may be the answer.\nNumerous organisms feed upon or infect insect pests. These biological controls frequently prevent the insect pollution from reaching damaging levels. Three types of natural enemies are:\n- Predators – Such as ladybird beetles, ground beetles and birds that consume many pests in their lifetime.\n- Parasites – such as the trichogamma wasp, which will generally consume one individual insect pest during its own lifetime.\n- Pathogens – such as fungi, bacteria, and viruses which infect many insect pests simultaneously.\n- Minimizing the use of pesticides on lawns and gardens allows these natural enemies to thrive, helping to keep pest populations in control.\nSource: Yard Care And The Environment by the West Valley City Storm Water Utility\nResources: What are pesticides?, Pesticides, Household Hazardous Waste, Stormwater Runoff & Pesticides, Pesticides, Herbicides, & Stormwater, Stormwater Management: Pesticide Use in the Lawn and Garden","Fact Sheets And Publications\nThe \"New\" Companion Planting: Adding Diversity to the Garden\nDo tomatoes love basil but hate brussels sprouts? Traditional companion planting, which involves planting different types of plants together or in close proximity, makes many such statements, often based on little more than folklore. In recent decades, however, scientists have found that in fact there are definite benefits to adding diversity to your garden, primarily because certain plants attract and support beneficial insects that either help control pests or help pollinate your crops.\nWhy add diversity?\n- Resources from flowers, i.e. nectar and pollen:\n- Attract and support predators and parasitoids (natural enemies) for pest control. Some tiny parasitoids require nectar or another source of sugar, and abundant nectar improves their survival and increases reproduction. Syrphid or hover flies feed on nectar and pollen, and lay hundreds of eggs near soft bodied insects such as aphids. The eggs hatch into larvae that are voracious feeders on those small pests. Lacewings and ladybird beetles are also attracted to flowers and can effectively control aphids.\n- Attract and support pollinators, providing nectar and pollen that bees and butterflies need.\n- Some flowers support alternate prey for natural enemies. For example, marigolds often support numerous tiny pest insects called thrips, which in turn are fed on by tiny voracious predatory bugs, Orius species, also known as minute pirate bugs. The Orius may also patrol nearby crop plants, reducing populations of soft-bodied pests. Marigolds are also well-known for their ability to control nematodes due to the toxic chemicals exuded by their roots; however, this works better when marigolds are planted as a cover crop, with their residues tilled into the soil before the crop is planted.\n- The presence of different plant species grown together can disrupt the ability of pests to find their host plants. Plant-feeding insects, especially those that only feed on one or a few types of plants, find their host plants by sight and smell, and these cues can be disrupted by surrounding plants, especially aromatic or bushy plants.\n- Adding ground-level complexity, for example strips of grass, weeds, or cover crops, can increase populations of ground-dwelling generalist predators, such as ground beetles and spiders, which can feed on plant-feeding insects, especially those that spend a part of their lives in the soil. Grassy “beetle banks” also provide sheltered overwintering habitat for insect predators.\n- Caution: although there are many studies showing that diverse plantings increase populations of natural enemies, this does not always translate into fewer pests on the desired crop plant, since the predators and parasitoids may not disperse to where they are needed. You will still need to check your plants frequently for unwanted pests, and control them in some other way if the good bugs are not effective enough!\n- In addition, the added plants will compete with the crop for light, water, and nutrients, and therefore crop yield may be reduced compared to a monoculture of the crop. Select companion plants that are not overly competitive with the main crop.\n- Other examples where diverse plantings make sense. Plants with different characteristics can be used to support soil nutrition and better yield in a small space. For example, legumes, such as alfalfa, clover, peas, and beans, fix nitrogen and can be planted in rotation with non-legumes; deep-rooted plants can be grown with shallow-rooted plants; and sun-loving plants can provide shade for shade-loving plants and also help to reduce weeds. A classic example of this type of companion planting is the so-called “three sisters” planted together by Native Americans. Corn, pole beans, and squash were planted together, with corn providing support for the beans and the large squash leaves suppressing weeds.\nHow to add diversity?\nCombine crop plants with other annual or perennial plants in the vegetable bed.\n- Herbs are desirable crops themselves, and often produce small flowers with exposed nectaries that attract and support predators and parasitoids. They also tend to be aromatic. Herbs that have been shown to attract natural enemies or repel herbivores in at least some studies include basil, coriander, rosemary, lavender, parsley, borage, dill and chives.\n- Annual flowers can be planted in the beds around vegetables. In the Master Gardener Vegetable and Fruit Demonstration Garden (VFDG) at the New Castle County Cooperative Extension Office, sweet alyssum has been planted within vegetable beds for several years to attract and support beneficial insects. Alyssum is inexpensive, easy to grow, low growing and compact (so it doesn’t compete with the vegetables), has a long growing season, and doesn’t leave significant biomass at the end of the season. It can be grown from seed, but at the VFDG plants are typically purchased, for convenience and quick establishment. Numerous syrphid flies (mentioned above) can be seen swarming about the flowers in the spring. Other popular choices are marigolds and nasturtiums. Some popular annual plants such as pansies, however, have been selected primarily for large colorful flowers and may not produce the nectar and pollen needed by beneficial insects.\n- Plant flowering native perennials in a bed near the garden. The VFDG also has a native perennial bed, consisting of various species that bloom at different times and are known to attract and support beneficial insects (see RESOURCES for plants to consider).\n- Plant flowering shrubs and trees in a nearby hedgerow. If you have room for trees and shrubs, this is a great way to add additional flower resources, in addition to berries and habitat for birds. Trees are often the first source of flowers in the spring (see RESOURCES).\n- Michigan State has research-based lists of native perennial herbaceous plants of Michigan that are attractive to both pollinators and natural enemies. Most of these are also native to our region: http://www.canr.msu.edu/nativeplants/plant_facts/\n- Michigan State also produced a multistate bulletin on protecting and enhancing pollinators in urban landscapes: https://www.canr.msu.edu/publications/how_to_protect_and_increase_pollinators_in_your_landscape\n- The University of Kentucky has developed a research-based list of flowering woody landscape plants (trees and shrubs) that are attractive to bees: https://entomology.ca.uky.edu/files/bee_friendly_shrubs_and_trees_handout.pdf\n- The North American Pollinator Protection Campaign (NAPPC), and its parent organization, the Pollinator Partnership, offers eco-regional planting guides for pollinator-friendly landscapes. These include trees, shrubs, and perennials that attract and support pollinators as well as host plants for butterflies: http://pollinator.org/guides\n- The Delaware Department of Agriculture has published a guide to planting for native bees in Delaware (both coastal plain and piedmont), including a list of 39 herbaceous and woody species with bloom time and types of bees that are attracted (Sarver, M.J. 2009. Delaware Native Plants for Native Bees). A guide to creating relatively large-scale meadows friendly to pollinators is also available: http://matthewsarver.com/downloads/Meadows_and_Buffers_for_Bees.pdf\n- The Delaware Nature Society has a list of resources relevant to planting for a certified wildlife habitat and related subjects: https://www.delawarenaturesociety.org/what-we-do/protecting-habitats-wildlife/garden-for-wildlife/?CWH=6\n- The Xerces Society for Invertebrate Conservation includes both herbaceous and woody plants in this list of pollinator-friendly plants for the Mid-Atlantic Region: https://xerces.org/pollinator-conservation/plant-lists/pollinator-plants-mid-atlantic-region/\n- The National Wildlife Federation has a section on native plants of value to wildlife, including a Native Plant Finder to assist in finding plants that support caterpillars: https://www.nwf.org/Garden-For-Wildlife/About/Native-Plants.aspx\n- The Lady Bird Johnson Wildflower Center Native Plant Database is searchable for a variety of characteristics, including value to native insects: wildflower.org/plants/\n- As part of his website “Illinois Wildflowers,” Dr. John Hilty lists flowers that have been observed to be attractive to insects and birds, based on a variety of scientific publications: http://www.illinoiswildflowers.info/flower_insects/index.htm\nUD Cooperative Extension\nThis institution is an equal opportunity provider.\nIn accordance with Federal law and U.S. Department of Agriculture policy, Cooperative Extension is prohibited from discriminating on the basis of race, color, national origin, sex, age, or disability."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:b8bbbff1-4826-4cb0-bd18-a9fd80f02afc>","<urn:uuid:b63630bb-d295-4e3d-be42-06f86673f022>"],"error":null}
{"question":"How do specimen collection practices differ between NHANES biospecimen gathering and chemotherapy treatment monitoring?","answer":"NHANES biospecimen collection involves standardized protocols for blood and urine specimens, with specific age-based eligibility criteria and controlled collection environments in mobile examination centers. Blood is collected from participants aged 1 year and older, while urine is collected from those 3 years and older. In contrast, chemotherapy monitoring requires ongoing assessment of multiple biological markers to track treatment effectiveness and side effects, including white blood cell counts, red blood cell counts, platelets, and liver/kidney function, as chemotherapy drugs affect rapidly dividing cells throughout the body.","context":["MEC Operation and Schedule\nNHANES collected biological specimens (biospecimens) for laboratory analysis to provide detailed information about participants' health and nutritional status. Eligibility for specific laboratory tests was based on the survey participants' gender and age at the time of screening. The biospecimen collection took place in the mobile examination center (MEC). This included collecting, processing, storing, and shipping blood, urine, and other types of specimens. The controlled environment of the MEC allowed laboratory test to be performed under standardized conditions at each survey location.\nThe MEC was open 5 days per week; the non-operational days changed on a rotating basis so that appointments could be scheduled on any day of the week. Two examination sessions were conducted daily. Participants are randomly assigned to exams in the morning, or in the afternoon/evening session. Participants aged 12 years and older assigned to a morning session were asked to fast for 9 hours. Participant's fasting status was assessed by the MEC phlebotomist prior to the blood draw.\nBiological Specimens Collection\nBlood was collected from participants aged 1 year and older by a phlebotomist. The amount of blood drawn varied by age. Blood was processed and aliquoted into vials. The vials were then refrigerated or frozen before transport to laboratories across the United States. Except for complete blood count (CBC) and pregnancy tests, which were performed in the MEC, most assays were completed in 35 laboratories across the United States. If consent was granted, some specimens were stored for future studies.\nIn 1999-2014, NHANES collected urine specimens for all participants aged 6 years and older. Starting 2015, the target age for urine collection was extended to participants aged 3 years and older.\nParticipants aged 6 and older were asked to provide a full void urine specimen. The parents/guardians of participants aged 3-5 years were asked to help their children collect a full void urine specimen. The date and time of the prior urine void, along with the date, time, and volume of the urine specimen collected in the MEC were used to calculate urine flow rate. The urine specimen was also used: 1) to perform a urine pregnancy test on all female participants aged 12-59 years and menstruating females aged 8-11 years; 2) to aliquot, store, and transport to multiple laboratories for analysis; and 3) to aliquot and bank for future studies.\nFemale and male participants aged 14-59 were asked to self-collect a vaginal or penile specimen using a sterile swab. The vaginal and penile swabs were tested for the presence of multiple types of human papillomavirus (HPV).\nCollection procedures varied based on the specimen types. Please refer to the 2017-2018 Laboratory Procedures Manual for more details.\nNHANES Laboratory Setting\nEach MEC had a laboratory containing a laminar flow hood, complete blood count (CBC) with 5-part differential analyzer, two centrifuges, a portable balance (scale), refrigerators, and freezers. Each MEC laboratory team included three medical technologists and a phlebotomist. Staff were certified in accordance with guidelines set forth by the American Society for Clinical Pathology. The qualifications for these laboratory staff are described in the component training manuals. All laboratory staff were thoroughly trained to ensure the safety of the laboratory environment. This includes annual training in the following laboratory safety and infection control policies and procedures:\n- Occupational Safety and Health Administration (OSHA) Blood borne Pathogen Regulation;\n- NHANES exposure control plan;\n- Working safely with hazardous chemicals;\n- Universal precautions and a set of guidelines for preventing the transmission of blood borne pathogens such as human immunodeficiency virus (HIV) and hepatitis viruses in health care settings; and\n- International Air Transport Association (IATA) training for proper shipping dangerous goods.\nAll staff also completed privacy protection and confidentiality training, and cardiopulmonary resuscitation training. In addition, all laboratory staff completed component-specific training to learn the standardized NHANES laboratory protocols.\nAutomated Data Collection\nIn the MECs and analytical laboratories, data for the laboratory component were recorded directly into a computerized database. Related questionnaire forms (e.g., fasting status) were also automated. The laboratory data collection and reporting systems were integrated with the main NHANES survey database.\nQuality Control Monitoring\nThe NHANES MEC laboratory has been a Clinical Laboratory Improvement Act (CLIA)-certified laboratory of moderate complexity. Quality assurance and quality control (QA/QC) involved both internal and external surveillance. QA/QC procedures were performed in the MEC as well as in contract and CDC laboratories. As part of the overall QA process, all collection materials, vacuum sample vials, and storage containers used were initially prescreened for background contamination (e.g., lead, mercury, etc.). EDTA (ethylenediaminetetraacetic acid) tubes were used after prescreening for contamination. The lot number and expiration dates for all vacuum sample vials, needles, and reagents were recorded.\nSpecific QC procedures were followed in the laboratory. For example, the freezers, refrigerators, and centrifuges were cleaned before the MEC opened, and a temperature reading on these items was conducted daily. On-site calibrations were performed twice each year. The NCHS biomedical engineer certified the revolutions per minute (rpm) of the centrifuges periodically and replaced the high-efficiency particulate air filters as necessary. All instrument maintenance was recorded. NHANES laboratories participated in the College of American Pathologists (CAP) proficiency-testing program. CAP samples were sent three times a year for the CBC and qualitative serum human chorionic gonadotropin. In addition, blind split samples were used for QC determinations.\nContract laboratories followed QA/QC guidelines when working with NHANES specimens and were required to be CLIA-certified. In addition, to ensure the data quality, NHANES staff conducted annual laboratory inspections and reviewed the QC data from each laboratory.\nRoutine data preparation procedures included a review of frequency data, outliers, and technician notes. Analysts should review the data reported for each component or laboratory assay prior to beginning data analyses.\nLow Detection Limits\nFor laboratory tests with a lower detection limit, results below the lower detection limit were replaced with a value equal to the detection limit, divided by the square root of two. This value was created to help users distinguish a nondetectable laboratory test result from a measured laboratory test result.\nSome NHANES components were collected or processed for a subsample of participants. Subsampling was done to reduce participant burden and facilitate the scheduling and completion of examinations. Each subsample was selected to be nationally representative. For example, some participants were selected to give a fasting blood sample on the morning of their examination. The subsamples selected for these components were chosen at random with a specified sampling fraction (e.g., one-half of the total examined group). Each component subsample has its own designated analytic weight, which accounts for the additional probability of selection into the subsample component as well as nonresponse to the component. See the respective survey protocol and documentation for more specific information on each subsample.\nPlease note that when merging full sample data to the subsample data files, the analytic sample is the subsample and the subsample analytic weights must be used. Users are strongly urged to read the data file documentation to ensure proper analysis and interpretation of the data.\nPlease refer to the NHANES Analytic Guidelines and the Continuous NHANES Web Tutorials for further details on NHANES subsamples, the use of sample weights, and other related analytic issues.\nSpecial Analytic Notes for the Laboratory Data\nThe analysis of NHANES 2017-2018 laboratory data must be conducted using the appropriate survey design and demographic variables. The NHANES 2017-2018 Demographics File contains data on demographic characteristics, health indicators, and other related information collected during household interviews as well as the sample weights. The Fasting Questionnaire File includes auxiliary information, such as fasting status, the time of venipuncture, and the conditions precluding venipuncture. The demographics and fasting questionnaire files may be linked to the laboratory data file using the unique survey participant identifier (i.e., SEQN).\nThere are over 800 laboratory tests performed. However, not all participants provided biospecimens or enough volume for all the tests to be performed. The specimen availability can also vary by age or other population characteristics. For example, in 2017-2018, approximately 80% of children aged 1-17 years who were examined in the MEC provided a blood specimen through phlebotomy, while 95% of examined adults age 18 and older provided a blood specimen. Analysts should evaluate the extent of missing data in the dataset related to the outcome of interest as well as any predictor variables used in the analyses to determine whether additional re-weighting for item non-response is necessary.\nWe strongly encourage data users to read all relevant documentation on the survey overall and for the specific data files to be used in their analysis. Specific data file documentation can be found via the link next to the respective data file on the NHANES website. Data users should also review the NHANES Analytic Guidelines prior to beginning any analyses.","- NHL Treatment\n- Hodgkin's Treatment\n- Clinical Trials\n- Monoclonal Antibodies\n- Types of NHL\nLymphoma and Pets\nHodgkin's Lymphoma: Chemotherapy\nNote: \"Hodgkin's lymphoma, \"Hodgkin's disease\" and \"Hodgkin lymphoma\" are used interchangeably on this site.\nChemotherapy is the use of drugs to kill cancer cells and shrink tumors. Chemotherapy is a well-established and widely used treatment for all cancers and most of us probably know someone who has undergone \"chemo\". It follows, then, that most of us also know that chemotherapy has serious side effects.\nThe side effects are laregly due to the fact that, because chemotherapy is applied to the whole body (a \"systemic\" treatment), it not only destroys cancer cells in a specific location but harms many normal, noncancerous cells as well. Chemotherapy drugs are engineered to attack cells that divide rapidly. They do a good job of attacking mestastasizing cancer cells but also damage rapidly dividing cells such as red and white blood cells, platelets, cells in the digestive lining and, as you might guess, hair follicles.\nMany advances have been made (and are still underway) in chemotherapy over the years, and more and more drugs are becoming available to target specific kinds of cancer cells and to minimize side effects.\nUndergoing \"chemo,\" however, is still a difficult process for the patient. But for lymphoma patients--especially non-Hodgkin lymphoma patients--chemotherapy is often an essential treatment because the disease often spreads throughout the body.\nChemotherapy treatments for lymphomas vary widely depending on the patient and the stage of the disease. Drugs may be taken by pill, or administered via injection. A lymphoma patient may take only a single drug or undergo a regimen involving a combination of drugs. Two types of drug agents are routinly used for chemotherapy: alkylating agents and nucleosides.\n- Alkylating agent\n- A cytotoxic (toxic to cells) agent that inhibits cell division by reacting with DNA.\n- These inhibit DNA and RNA replication and therby prevent cancer cells from growing.\nThese are no longer the only options as researchers continue to develop new drugs. In fact, there are countless possible treatment regimens because drugs are frequently used in combination. With so many variables it is very important to get second or even third opinions regarding the type and stage of your lymphoma and the recommended treatment.\nHere we list some of the more prevalent treatments. The type of treatment depends on the patient and on the type and stage of lymphoma. Multiple treatments might also be necessary for some patients. This is by no means comprehensive and is only intended to present a broad outline.\nThe mainstream chemotherapy regimen is:\nABVD composed of 4 drugs:\nOther treatments that may be used, especially for disease that is resistant to other treatments:\n- MOPP alternating with ABV\n- MOPP alternating with ABVD\n- COPP / ABVD\n- ChlVPP - Chlorambucil, Vinblastine, Procarbazine, Prednisone\n- Stanford V\n- Used by Stanford in California\n- Radiation Therapy/\n- A 1997 study in the Annals of Oncology suggest that people who have stage III or stage IV Hodgkin's and only achieve partial remission with chemotherapy can have a high remission success rate with follow-up radiation therapy.\n- Bone marrow transplantation (BMT)\n- BMT and peripheral blood stem cell transplantation (PBSCT) are the use of high doses of chemotherapy with a rescue of the immune system afterwards.\n- Clinical trials\n- Often used for people who are not responsive to conventional treatment or who wish to help researchers test new therapies. New research is underway to engineer chemotherapeutic agents that attack proteins inside cells rather than DNA.\nSide Effects of Chemotherapy\nChemotherapy is tough on the body. The drugs attack the entire body and this can produce a variety of complications. Common side effects include nausea and vomiting, diarrhea, hair loss, weight loss, Depression, mouth sores, leukopenia (decreased white blood cell count; may lower resistance to infection)\nMost of the above side effects are temporary and usually (though not always) not too serious. Potentially serious side effects may include neutropenia (a severe drop in white blood cells), anemia (decreased red blood cell count), peripheral neuropathy (nerve damage), liver and kidney damage, thrombocytopenia (abnormal blood clotting), allergic reaction, and tumor lysis syndrome (specific to bulky lymphomas–cells split apart and release fragments into the bloodstream).\n- Chemotherapy and You from Cancer.Gov\n- Research Protocols used by Stanford University\n- Bone Marrow / Peripheral Blood Stem Cell Transplant Information Page"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:9f628a82-c83c-4769-a44e-8f7c242816bc>","<urn:uuid:5e2dcb01-fb2f-4487-9e8a-9f763d2cd468>"],"error":null}
{"question":"What's the educational pathway for Clinical Neuropsychologists versus West Virginia Licensed Professional Counselors?","answer":"Clinical Neuropsychologists must have a foundation in clinical neurosciences, including neurology, neuroanatomy, and neurophysiology, along with basic and applied generic core psychology courses. For Licensed Professional Counselors in West Virginia, a master's degree or higher from a CACREP or CORE accredited program is required, including 60 graduate semester hours (or 90 quarter hours) with a practicum and internship. The degree must specialize in areas like community agency counseling, mental health counseling, pastoral counseling, rehabilitation counseling, school counseling, or substance abuse counseling.","context":["The American Board of Clinical Neuropsychology (ABCN) is a member board of the American Board of Professional Psychology (ABPP). The ABPP oversees and authorizes the credentialing activities of thirteen specialty boards. The ABCN is responsible for establishing criteria related to the definition and requirements for education, training, competencies, and the examination, which leads to Board Certification in Clinical Neuropsychology. The ABCN is governed by a Board of Directors who are certified in Clinical Neuropsychology and are representative of the specialty on a national basis.\nThe Board, in association with the American Board of Professional Psychology (ABPP), is responsible for conducting Board examinations in the specialty of Clinical Neuropsychology, mentoring and training examiners, and awarding the Diploma in Clinical Neuropsychology. Board Certification by ABCN, is intended to certify that the successful candidate has completed the educational, training and experience requirements of the specialty, including an examination designed to assess the competencies required to provide quality services in the specialty of Clinical Neuropsychology. The primary objective of the ABCN Board Certification process is to recognize, certify, and promote competence in the specialty.\nDEFINITION OF A CLINICAL NEUROPSYCHOLOGIST\nClinical Neuropsychologists have specialized knowledge and training in the applied science of brain-behavior relationships. Clinical Neuropsychologists use this knowledge in the assessment, diagnosis, treatment, and rehabilitation of patients across the lifespan who have neurological, medical, developmental, or psychiatric conditions.\nThe Clinical Neuropsychologist employs psychological, neurological, or physiological methods to evaluate patients’ cognitive and emotional strengths and weaknesses and relates these findings to normal and abnormal central nervous system functioning.\nClinical Neuropsychologists use this information, in conjunction with information provided by other medical/healthcare providers, to identify and diagnose neurobehavioral disorders, conduct research, counsel patients and their families, or plan and implement intervention strategies.\nA definition of clinical neuropsychology, a description of the work settings in which clinical neuropsychologists are employed, and other associated information can be found in the Practice Guidelines published by the American Academy of Clinical Neuropsychology (AACN). This document can be downloaded from a link on the AACN website (http://www.theaacn.org)\nThe services provided by Clinical Neuropsychologists typically include:\nAssessment (evaluation, diagnosis, formal psychological testing)\nConsultation with others professionals in diverse settings\nIntervention (treatment, prevention)\nConduct of clinically-relevant research\nSupervision, teaching, and management activities (e.g., program development, administration)\nIt is expected that Clinical Neuropsychologists will demonstrate sensitivity to and skills in dealing with multicultural/diverse populations. In this manual, we will use the terms ‘multicultural’ and ‘individual and cultural diversity’ interchangeably. Individual and cultural diversity recognizes the broad scope of such factors as race, ethnicity, language, sexual orientation, gender, age, disability, class status, education, religion/spiritual orientation, and other cultural dimensions.1\nPreparation for the practice of clinical neuropsychology at the specialty level of competency characteristically entails some combination of pre-doctoral internship, and post-doctoral education and training experience. Specialized competency presumes the establishment of both a basic and applied generic core knowledge base in psychology and in the clinical neurosciences.\nThe candidate is expected to demonstrate more than a narrow or circumscribed adjunctive skill in order to meet competency criteria, though he or she may declare an adult or child emphasis for examination purposes. In addition to the basic and applied generic core courses that all applied psychologist must have, competency in clinical neuropsychology requires a foundation in the clinical neurosciences, including neurology, neuroanatomy, and neurophysiology. Two years of supervised training in clinical neuropsychology and at least two to three years of overall experience in the specialty area, depending on the year a candidate received their doctoral degree, are required to become eligible for the examination in clinical neuropsychology.\nFor more information about the American Board of Clinical Neuropsychology, or to apply for board certification, click here\n1 American Psychological Association (2002). Guidelines on multicultural education, training,\nresearch, practice, and organizational change for psychologists. American Psychologist,\n58 (5) 377-402. http://www.apa.org/pi/multiculturalguidelines.pdf","Counselor Licensing Requirements in West VirginiaCounselor Licensing Requirements in West Virginia are covered on this page. We want to ensure that you have accurate information about Counselor Licensing Requirements in West Virginia so that you can make informed decisions regarding your counselor career.\nFind schools and get information on the program that’s right for you. (It’s fast and free!)\nWest Virginia Counselor Credential TitlesLicensed Professional Counselor (LPC) Provisional Licensed Professional Counselor An applicant who has met the education and exam requirements, but not the 2 years supervised experience requirement\nWest Virginia Counselor Education RequirementsMaster’s degree or higher from a program accredited by CACREP or CORE, or a comparable accrediting body, that includes 60 graduate semester hours (or 90 quarter hours) and a practicum and internship. Acceptable graduate degrees include a specialization in community agency counseling, mental health counseling, pastoral counseling, rehabilitation counseling, school counseling, and substance abuse or addictions counseling. Similar degrees that include the word “counseling” and include specific coursework, and are determined by the board to be a closely related field, are also acceptable.\nWest Virginia Counselor Experiential Requirements\nMust already possess provisional license 2 years/3,000 hours of postmaster’s supervised professional counseling experience. If obtained a doctoral degree: 1 year/1,500 hours of postdegree supervised professional counseling experience. At least 50% of the supervised counseling experience must be in the direct provision of counseling services to clients. A minimum of 1 hour of direct individual supervision is required for every 20 hours of practice. Supervision must be under a board approved professional.\nWest Virginia Counselor Exam RequiredNCE, CRCE, or NCMHCE\nWest Virginia Requirements for Clinical SupervisorsWest Virginia LPC Licensed as a professional counselor, or other qualified supervisor as determined by the Board. At a minimum the professional should be licensed for 2 years with 5 years of counseling experience, completion of training in clinical counseling supervision, is currently licensed, and board approval. Supervisor must be pre-approved before hours can begin to accrue. The professional supervisor provide a statement detailing counseling philosophy, supervision experience, and counseling experience as well as being able to demonstrate skills necessary to address core areas of practice.\nWest Virginia Requirements for Out of State ApplicantsAn individual may apply for reciprocity review if the individual is currently licensed in another state whose licensing requirements are greater than or equal to the requirements in this rule as determined by the board. It is the applicant’s responsibility to provide the documentation necessary for the board to make an appropriate decision on reciprocity. The following documentation is required for the board to review for reciprocity: a completed WV application form and the required fee; copies of graduate transcripts from the issuing institutions; a certified copy, including exam results, of the applicant’s file from the jurisdiction where currently licensed; and two completed professional recommendation forms from individuals permanently licensed as professional counselors, psychologists, social workers, or psychiatrists on forms provided by the board. Persons with a temporary license cannot complete the recommendation form.\nWest Virginia Scope of Practice“PROFESSIONAL COUNSELING” means the assessment, diagnosis, treatment and prevention of mental, emotional or addiction disorders through the application of clinical counseling procedures. Professional counseling includes the use of psychotherapy, assessment instruments, counseling, consultation, treatment planning, and supervision in the delivery of services to individuals, couples, families and groups. “CLINICAL COUNSELING PROCEDURES” means an approach to counseling that emphasizes the counselor’s role in systematically assisting clients through all of the following including, but are not limited to, observing, assessing and analyzing background and current information; utilizing assessment techniques useful in appraising aptitudes, abilities, achievements, interests or attitudes; diagnosing; and developing a treatment plan. The goal of these procedures is the prevention and elimination of symptomatic, maladaptive, or undesired behavior, cognitions, or emotions in order to integrate a wellness, preventative, pathology and multicultural model of human behavior to assist an individual, couple, family, group of individuals, organization, institution or community to achieve mental, emotional, physical, social, moral, educational, spiritual, vocational or career development and adjustment through the life span of the individual, couple, family, group of individuals, organization, institution or community. The licensee’s areas of competence in counseling and the services provided, based on training and experience, from the following list, as is appropriate: career counseling, consultation, diagnosis and treatment of mental and emotional disorders, employee assistance counseling, family counseling, human resources counseling, marriage counseling, mental health counseling, rehabilitation counseling, school counseling, substance abuse and addictions counseling, supervision, and vocational counseling.\nSalary Information for West Virginia CounselorsIn the state of West Virginia, being a counselor can be both mentally and fiscally satisfying. According to The Bureau of Labor Statistics, a counselor in the state of West Virginia will earn between $27,780 and $43,040 per year, in addition to changing the lives of individuals in their communities. Now that you are familiar with the counselor licensing requirements in West Virginia, visit our How to Become a Counselor in West Virginia page for a more detailed look into the steps you will need to take to make your dream of becoming a counselor a reality.\nState InformationWV Board of Examiners in Counseling 812 Quarrier Street, Suite 212 Charleston, WV 25301 304/558-5494 304/558-5496 (fax) Executive Director Jean Ann Johnson CONTACT: Roxanne Clay [email protected] WEBSITE: www.wvbec.org Application fee: $200 Initial License fee: depends ondate applicant is licensed"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:21626344-dc33-4062-b4db-e20c3b936ca2>","<urn:uuid:770d9f63-6666-414b-82a4-3ff025c21edb>"],"error":null}
{"question":"How to properly preserve computer evidence during a forensic investigation? I need steps for a case.","answer":"Proper preservation of computer evidence involves several critical steps: 1) Ensure no possible evidence is deleted, altered, or compromised during examination procedures. 2) Prevent introduction of computer viruses to the subject system during investigation. 3) Protect extracted evidence from mechanical or electromagnetic damage. 4) Establish and maintain a continuous chain of custody. 5) Document company procedures for each case. 6) Maintain ethical and legal handling of any inadvertently discovered client-attorney information.","context":["Computer Forensics and Data Recovery\nComputer forensics and Data Recovery is the science of analyzing a computer system hard disk using forensically sound methods and tools that have been tested and have had publications released such as the Department of Justice, NIST, Homeland Security and other approved forensic associations. The computer examination and analysis strategies might vary from case to case depending upon the evidence that is being attempted to be discovered to establish legal proof of the examination for legal cases. Computer Forensics and Data recovery can be utilized in a wide range of computer system criminal activity or abuse, consisting of but not limited to theft of data, theft of or violation of copyrights, and fraudulence. Computer experts could draw on a collection of approaches for uncovering data that resides in a computer system, and recovering deleted, secured, or damaged file details.\nBENEFITS OF PROFESSIONAL Computer system Forensics and Data Recovery\nThe unbiased computer Forensics professional that helps during a legal case will have experience on a large range of computer and software applications. This is constantly beneficial when your case has hardware and software applications with which this specialist is directly knowledgeable. Key computer components and software application execution is commonly comparable from one technology to an another, in which experience in one application or operating system area is frequently quickly transferable to a brand-new technology in a computer operating system.\nUnlike paper proof, computer system evidence can typically exist in numerous types, with earlier variations still easily accessible on a computer system disk. Understanding the possibility of their existence, also alternative formats of the same information can be uncovered. The discovery procedure could be offered well by a knowledgeable specialist recognizing additional opportunities that could be requested as perhaps relevant proof. Moreover, throughout on-site premises assessments, for situations where computer disks are not actually taken or forensically copied (see listed below), the forensics specialist could more quickly identify areas to look, indications to look for, and added information resources for relevant evidence. These could take the form of earlier versions of data documents (eg. memos, spreadsheets) that still exist on the computer’s disk or on backup media, or differently formatted versions of data, either developed or addressed by various other application software programs (eg. data processing, spreadsheet, email, timeline, organizing, or graphic).\nPreservation of data from changing is critical in computer forensic examinations. An experienced computer forensics professional will ensure that a subject computer system is carefully handled, documented to ensure that:\n- No feasible evidence is deleted, changed, or otherwise endangered by the procedures used to examine the computer system.\n- No feasible computer virus is presented to a subject computer system throughout the examination process.\n- Extracted and potentially relevant evidence is properly handled and safeguarded from later mechanical or electromagnetic damage.\n- A proceeding chain of custody is developed and kept.\n- Company procedures are documented for each case.\n- Any client-attorney details that is inadvertently discovered during a forensic examination is ethically and legitimately not disclosed.\nACTIONS TAKEN BY COMPUTER SYSTEM FORENSICS SPECIALISTS\nThe computer forensics professional will certainly take a number of mindful steps to determine and attempt to recover feasible evidence that could existing on a subject computer system:.\n- Secures the subject computer system during the forensic examination from any type of possible modification, damage, data corruption, or infection intro.\n- Discovers all files on the subject system. This includes existing typical documents, removed yet continuing to be archived documents, concealed data, password-protected documents,.and encrypted files.\n- Recovers all (or as much as possible) of discovered deleted files.\n- Reveals (to the extent possible) the contents of hidden files as well as temporary or swap files used by both the application programs and the operating system.\n- Accesses (if possible and if legally appropriate) the contents of protected or encrypted files.\n- Analyzes all possibly relevant data found in special (and typically inaccessible) areas of a disk. This includes but is not limited to what is called ‘unallocated’ space on a disk (currently unused, but possibly the repository of previous data that is relevant evidence), as well as ‘slack’ space in a file (the remnant area at the end of a file, in the last assigned disk cluster, that is unused by current file data, but once again may be a possible site for previously created and relevant evidence).\n- Prints out an overall analysis of the subject computer system, as well as a listing of all possibly relevant files and discovered file data. Further, provides an opinion of the system layout, the file structures discovered, any discovered data and authorship information, any attempts to hide, delete, protect, encrypt information, and anything else that has been discovered and appears to be relevant to the overall computer system examination.\n- Provides expert consultation and/or testimony, as required.\nWHO CAN USE COMPUTER FORENSIC EVIDENCE?\nMany types of criminal and civil proceedings can and do make use of evidence revealed by computer forensics specialists:\n- Criminal Prosecutors use computer evidence in a variety of crimes where incriminating documents can be found: homicides, financial fraud, drug and embezzlement record-keeping, and child pornography.\n- Civil litigations can readily make use of personal and business records found on computer systems that bear on: fraud, divorce, discrimination, and harassment cases.\n- Insurance Companies may be able to mitigate costs by using discovered computer evidence of possible fraud in accident, arson, and workman’s compensation cases.\n- Corporations often hire computer forensics specialists to ascertain evidence relating to: sexual harassment, embezzlement, theft or misappropriation of trade secrets and other internal/confidential information.\n- Law Enforcement Officials frequently require assistance in pre-search warrant preparations and post-seizure handling of the computer equipment.\n- Individuals sometimes hire computer forensics specialists in support of possible claims of: wrongful termination, sexual harassment, or age discrimination."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:c82ba33d-be8b-44ed-b168-265775e028b1>"],"error":null}
{"question":"How to treat congestive heart failure?","answer":"Congestive heart failure is treated through multiple approaches. Medications include diuretics to remove excess fluid, ACE inhibitors to open blood vessels and reduce blood pressure, and beta-blockers to slow heart rate. Lifestyle changes are crucial, including regular gentle physical activity, stopping smoking, following a low-salt and low-fat diet, and restricting alcohol. In advanced cases where medicines and lifestyle changes aren't sufficient, medical procedures may be needed such as heart valve repair/replacement, angioplasty to open blocked arteries, coronary bypass surgery to reroute blood flow, or in severe cases, heart transplant.","context":["Congestive heart failure is a highly common condition that affects nearly 10 million Indian every year. It is one of the leading causes of hospitalization, especially in older people. However, most people take congestive heart failure literally, when it’s not.\nWhat is Congestive Heart Failure?\nCongestive heart failure is a chronic and progressive condition that affects the pumping power of the heart muscles.\nIt represents a stage of heart failure in which fluids build around the heart muscles, making it difficult to pump blood.\nLet’s see what exactly happens in congestive heart failure.\nThe heart is made of four chambers, the upper half has two atria, and lower half has two ventricles. The function of ventricles is to pump blood to the body (organs and tissues), and atria receive the blood from the body and circulate it back from the rest of the body. Congestive heart failure develops when the heart is unable to pump sufficient blood to your body resulting in blood and other fluids backing up inside the body. It can be a life-threatening condition, and failure to provide medical assistance can even cause death.\nCongestive heart failure may or may not show symptoms, depending on the stage of the condition. Symptoms can also be temporary or permanent and can come and go. The most common ones are:\nCongestion in the Lungs\nFluid can back up into the lungs which can cause difficulty in breathing and can induce a hazing or a dry cough.\nWeakness, Dizziness and Fatigue\nAs soon as the pumping action of the heart is reduced, there is less blood sent to the organs which can make the patient feel weak and tired. Less blood to the brain can cause extreme dizziness and can further complicate the condition.\nWater and Fluid Retention\nIf the pumping action of the heart is affected, it circulates less blood to the kidneys, resulting in swollen legs and abdomen (oedema).\nIrregularity in the Heartbeat\nCongestive heart failure puts pressure on the heart to pump more blood because of decreased function. The heart will beat faster causing irregular heartbeats.\nWhat are the causes?\nCongestive heart disease can occur because of conditions that can directly affect your cardiovascular system. It is important to get complete heart checkups regularly, especially if you are above 30 years of age. Complete heart check-up will highlight any withstanding problems and doctors will be in a better position to treat the condition.\nIf it is higher than normal blood pressure, it can cause congestive heart failure. Hypertension occurs when blood vessels become still, thereby making it harder to pass blood through them.\nCoronary Artery Disease\nCoronary arteries supply blood to the heart. Excess of cholesterol and other fatty substances can block these arteries. Narrow coronary arteries are prone to damage as they can restrict the blood flow to the heart and sudden blockage of coronary arteries is one of the reasons for heart attack.\nIt is a progressive heart disease in which the heart is abnormally enlarged because of reasons other than artery or blood flow. Infections, drugs or alcohol are the leading factors that cause cardiomyopathy.\nCertain conditions can lead to coronary artery disease including diabetes, obesity and even thyroid.\nIs there any treatment available?\nToday, with the advent of medical sciences, there are several treatments available for congestive heart failure. The goal of treating a congestive heart failure is to make the heart beat more efficiently. A combination of medications is usually used to treat a congestive heart failure treatment.\nCongestive Heart Failure is treated with medications such as diuretics to remove the excess fluid. ACE inhibitors are used to open blood vessels and reduce blood pressure. Medications are also used to reduce sodium and water retention in the heart which helps the organ pump blood more effectively. Some beta-blockers are used to slow down the heart rate and reduce the workload.\nChanges in the Lifestyle\nOne of the primary changes is done to the lifestyle to control congestive heart failure from going to the next stage. Gentle but regular physical activity is advised. Patient must stop smoking and adhere to a low-salt and low-fat diet. Restriction on alcohol is also implemented.\nIn some cases, with advanced congestive heart failure, medicines and lifestyle changes are not enough. Medical procedures are often recommended in such cases:\nIn advanced cases of congestive heart failure, narrowed or leaking heart valves are repaired or replaced with a mechanical valve.\nIt is used to open a blocked artery where the doctor places a stent to help the blood vessel remain open.\nCoronary Bypass Surgery\nThis surgery is used to reroute blood vessels so the blood can travel throughout the body, avoiding blocked blood vessels.\nA heart transplant is the only choice for people with severe congestive heart failure.\nCongestive heart failure is treatable. If you or a loved one is suffering from a cardiovascular disease, it is imperative to get an expert advice. Remember, lifestyle changes go a long way in improving your wellness and are highly recommended for someone who has a heart condition."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:83d164e1-53af-4d08-8a32-2bebda1fbfd2>"],"error":null}
{"question":"What are the key differences between barbecue rubs for beef and pork?","answer":"The main differences between beef and pork barbecue rubs are in the salt-sugar ratio and specific spices used. Beef requires a higher ratio of salt, while pork works better with a higher ratio of sugar. Both meats can use similar spices including chili powder, whole cumin, paprika, coriander, garlic, onion, mustard, and thyme. However, ginger works well with pork but is not recommended for beef. Additionally, oregano is specifically recommended for beef rubs.","context":["A good barbecue starts with a good barbecue rub. The ingredients of your spice rub are the ones liable for the flavor surprises of your barbecue, and there are enough ingredients you can choose from and experiment with.\nFor your barbecue spice rub, there are three sets of ingredients to note.\n1. Salt and Sugar\nThis is where to start with – a good salt and sugar base. The combination of correct amounts of salt and sugar will give the taste balance and caramelization to the food. The ratio between the amounts of salt and sugar depends on the type of food you are cooking. A higher ratio of sugar works best for pork while a higher ratio of salt suits great with beef and fish. The type of salt and sugar to use now depends on your preference. For salt, you can choose from a fine-grained refined salt, an additive-free coarse-grained kosher salt, a very fine- grained sea salt that came from evaporated seawater, or a seasoned salt – a regular salt mixed with flavoring ingredients such as garlic, onion, or celery. For sugar, the two choices are the white sugar, which is highly refined cane sugar that will scorch in high temperature, and the brown sugar, which is a white sugar mixed with molasses that add color to the food.\n2. Pepper and Herbs\nOf course, pepper adds the heat and completes the blend of taste and warmth to the barbecue. Remember to go slow when adding pepper to the mixture of salt and sugar until your desired blend of flavor and heat is achieved. Various types of pepper can be used for your barbecue rub. First on the list is the cayenne pepper or the ground red pepper that gives a good deal of heat and a bit of color to the food. White pepper gives lighter color, milder flavor, and gentle heat while cracked black pepper provides a stronger flavor compared to cayenne and white pepper. Smoked Chile powders such as the ground chipotle pepper also add deep flavor and heat to the spice rub.\n3. Added Spices and Flavors\nThese are the herbs and other spices that match the type of food you are cooking. Here is a list of the best herbs and spices you can use for some meat cooked in grills.\n- For pork, you can add chili powder for an extra pungent flavor, whole cumin for an added aroma and peppery flavor, and either the deeper flavor of Hungarian paprika or the milder flavor of Spanish paprika. To achieve signature flavors for pork barbecue, you can also use coriander, garlic, ginger, onion, mustard, and thyme.\n- For beef, you can use almost everything used in pork except for ginger. You can also add oregano.\n- For poultry, you can also use whole cumin, paprika, coriander, garlic, ginger, onion, mustard, and thyme just as with pork, but other options include rosemary and dill.\n- For fish and seafood, you can mix your spice rub with whole cumin, paprika, dill, garlic, ginger, onion, rosemary, thyme, and oregano.\n- Hungarian paprika gives deeper flavor while Spanish paprika is milder, but both provide sweet and hot flavors to the food.\n- Whole Cumin offers aroma to the food plus a nutty taste.\n- Bay Leaf is also widely used as an aromatic element to the food. It also adds a strong taste to the spice rub. You can read more about how bay leaf are supposed to be used here.\n- Dried mustard powder excellently combines with many spices."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:59ba15a8-52c1-4868-9a29-664921d9ea30>"],"error":null}
{"question":"How do carbon markets work today and what challenges do companies face in implementing net-zero strategies?","answer":"Carbon markets operate through two main components: the compliance market, which mandates emission reductions through instruments like carbon taxes and emission trading systems (ETS), and the voluntary market, which enables companies to offset emissions. There are currently 73 carbon pricing instruments globally, mostly in Europe and North America. Companies implementing net-zero strategies face several challenges, including measuring emissions across their supply chain (which are typically 11.4 times greater than operational emissions), setting credible targets, building internal capabilities, and selecting appropriate carbon offsets. The legitimacy of carbon offsets is particularly challenging, with concerns about additionality, permanence, double-counting, and leakage.","context":["Disclaimer: The views expressed in this blog are those of the authors and do not necessarily reflect the views of the Asian Development Bank, its management, its Board of Directors, or its members.\nFacing twin crises—climate change and biodiversity loss, corporate actions on climate change are a new norm for business. Multilateral financial institutions function through international treaties and have been quick to respond with their commitment to the Paris alignment.\nThis blog shares thoughts about valuing carbon as a commodity and developing the currently immature carbon market. It provides insights into how developing countries can recognize opportunities from the carbon market and leverage the support from MFIs in their decarbonization pathways.\nCarbon pricing is the act of putting a price on carbon emissions to mitigate climate change. It comprises of carbon taxes, carbon border adjustments, emission trading system (ETS), and carbon crediting. There are currently 73 instruments, most of which are carbon taxes and ETSs in Europe and North America. The People’s Republic of China (PRC) started running its national ETS in 2021.\nCarbon prices have hit record highs recently in many markets. The price of an EU ETS credit topped at more than 99 euros in August 2022, while the carbon tax in Singapore stayed at about 17 euros. To prevent carbon leakage, the EU is introducing the carbon border adjustment mechanism (CBAM) to require importers in selected industrial sectors to purchase certificates equivalent to the weekly EU carbon price. Higher carbon prices are necessary to keep global heating to below 2°C—the upper end of the limit agreed in the Paris Agreement. The Report of the High-Level Commission on Carbon Prices identified a USD 50-100/ton range as the price needed by 2030 to keep global heating to below 2°C—the upper end of the limit agreed in the Paris Agreement—as part of a comprehensive climate policy package. Further, more recent estimates indicate even higher prices may be needed to reduce emissions to net-zero by 2050.\nUnder the new rules of Paris Agreement Article 6, governments can decide on the type of projects in their countries and whether to authorize carbon emission reductions from those projects. These rules can lead to further divergence in approaches, credit types, and prices for carbon.\nSource: Asian Development Bank. 2023 price is not included because it is subject to change.\nActions that developing countries can take to leverage carbon market opportunities for government revenue enhancement and decarbonization pathways:\n- Enhancing the measurement and verification of carbon credits for market opportunities:\nADB is applying carbon price in economic analysis, set at US$49.8/ton in 2022, to quantify the difference in emissions between a with-project scenario and a without-project scenario.\nWith its huge volume and rising price, carbon has the potential to become the most valuable commodity. The World Bank has begun implementing result-based climate finance programs through the purchase of carbon credits or providing revenue to private sector clients via the carbon markets. For carbon credits to be traded, they must be issued to eligible projects that recognize quantified emission reductions that are real, additional, permanent, and below a baseline scenario.\nDeveloping countries can engage MFIs’ independent role in the measurement and verification of carbon credits issued to domestic and regional projects. Then, governments can ensure that their verified carbon credits are good for trading activities in the market.\n- Developing the carbon markets through supporting the convergence of the compliance and voluntary markets\nThe carbon market is an evolving space and immature market. The Paris Agreement Article 6 enables governments to independently choose projects and whether to authorize emissions reductions in their countries. It is unclear how Article 6 will shape the carbon market, but global climate change ambition can only materialize if governments and MFIs act proactively together.\nThe components of the carbon market are the voluntary market and the compliance market. The smaller voluntary carbon market, valued at only $2 billion in 2021, enables corporates to offset hard-to-abate emissions to achieve net-zero and carbon-neutral ambitions. The much larger compliance market, valued at $751 billion in 2021 and dominated by EU ETS, is essentially a policy instrument mandating the reduction of greenhouse gas emissions. Currently, compliance and voluntary carbon markets operate largely independently of one another, but the blurring of lines has occurred. There is already a convergence between voluntary and compliance markets. Various compliance schemes, such as the PRC and Republic of Korea ETS, allow for a limited use (i.e., 5%) of carbon offsets. Voluntary programs can also participate in international compliance mechanisms such as Article 6.\nBy leveraging MFIs’ capacity building resources, developing countries can make the convergence of the voluntary and compliance markets happen sooner through proper institutional framework designs.\nDecarbonization and carbon market development are challenging processes that take place together. They are constantly updated processes as new rules come out. Developing countries can work with MFIs to keep track of the rules and use their own individual climate neutrality targets to effectively cope with the carbon market.\n 2023. State and Trends of Carbon Pricing, World Bank. https://openknowledge.worldbank.org/handle/10986/39796\nThis article was first published as an ADB blog.","Net-zero emissions companies is one of the fastest-growing business trends. According to scientists achieving net-zero before 2050 is critical to keeping us safe from the catastrophic consequences of climate change.\nThe number of net-zero emissions commitments has doubled this year, as many prioritize climate action in their recovery from Covid-19 ( Data-Driven EnviroLab report).\nStill, many organizations struggle to make their first steps to become Net-Zero companies.\nIn this article, you will learn what net-zero companies are, why embark in such endeavour and how to make your net-zero targets credible.\n- 1 What is a Net-Zero company?\n- 2 Why should a company be net-zero?\n- 3 How to start a net-zero roadmap?\n- 4 Using Offsets in net-zero targets\n- 5 Conclusions\nWhat is a Net-Zero company?\nNet-zero company refers to an organization who reaches a balance between emissions produced due to its activities and those emissions it removes from the atmosphere.\nAchieving a net-zero emissions state is similar to maintaining the water level of a bathtub with the tap fully on and its drain open.\nTo achieve the water balance, we could turn down the faucet (reduce the emissions released) until there’s no more water coming out. Besides, we could also drain an equal amount down the plughole (removing emissions from the atmosphere).\nTherefore, a company achieves a net-zero state by first reducing to the minimum its carbon sources. Then, the organization can balance out the remaining emissions by investing in projects that remove emissions (carbon sinks).\nWhy should a company be net-zero?\nReason 1 – Is the right thing to do to save the planet\nAfter the signature of the Paris Agreement in 2015, science has become widely accepted. The cause for climate change is due to human activities (read my article about Milankovitch Earth’s Cycles). Therefore, companies have increasingly focused on reducing carbon emissions.\nNevertheless, emissions kept growing. As a consequence, we have reached a global warming of 1 degree Celsius above pre-industrial levels (UN IPCC SR15).\nTo limit global warming to the safe threshold that science has set at 1.5°C, reducing carbon emissions alone is not sufficient. We need to go further and reach a Net-Zero future where we stop emissions growth.\nCOVID-19 has reminded us that human and, planetary health are interlinked and, this is one of the reasons that Net-Zero emissions companies has become one of the fastest-growing business trends.\nDecreasing GHG emissions also reduce air pollution and, prevent millions of premature deaths. Also, shifting to energy efficiency and renewable energy aligns with efforts to improve energy security and reduce poverty (IPCC, 2018).\nReason 2 – It makes business sense\nBesides, companies have understood that achieving net-zero emissions is not only the right thing to do to save the planet. Net-zero also reduces climate risks (read my TCFD article), reduce costs and attracts ESG investors and talent.\nDespite these two reasons, some companies don’t understand the benefits of the low carbon economy yet. Ignoring those benefits means ignoring the risk that new regulation, customers or investors could put your business out of the market.\nHow to start a net-zero roadmap?\nAccording to Race to Zero, a campaign led by the UNFCCC Champions for Climate Action, 25% of global CO2 emissions are covered by net-zero commitments. Moreover, a recent report by the Energy and Climate Intelligence Unit (ECIU) and Oxford Net Zero affirms that 21% of the world’s 2,000 largest public companies, representing sales of nearly $14 trillion, now have net-zero commitments.\nHowever, there is a great degree of inconsistency in the scope, timeline and actions necessary to reach net-zero. This inconsistency creates confusion and puts off many companies who want to start their net-zero journey.\nIn a Linkedin poll I recently launched, +50% of the answers were to understand how to start the net-zero journey.\nSo how should you create a roadmap to make your company net-zero?\nIt requires you to follow a 4-step process:\n1- Understand your carbon footprint\nYou cannot improve what you don’t measure. Therefore, developing a basic map of your emissions in both your operations and in your supply chain should be the first step.\nHere, the GHG protocol is the most widely used international accounting tool for greenhouse gas emissions accounting.\nCalculating the emissions from the companies operations such as factories, offices or, fleet is quite a straight forward process. It requires collecting fuel and electricity consumption and applying some international emissions coefficients.\nBeyond the company’s operations, there are other emissions produced in the supply chain. Moreover, according to CDP, supply chain emissions are on average 11.4 times greater than those generated from companies operations. Therefore, the potential for reductions is vast in the supply chain.\nBusinesses must close the ‘Say : Do’ gap; the greenwashing space between their environmental pledges and (lack of) actions to meet themPaul Polman, former Unilever CEO\nYour company should build a first simple supply chain emissions model focusing on company spending. Above all, the purchasing of products and services is the category that usually drives most of the emissions. Then using some tables called EEIO, the company can translate spending into carbon emissions.\nOver time, you can improve the model by incorporating data from suppliers and the company’s products life cycle assessments (LCA).\nStill, if the company doesn’t have the carbon footprint expertise, it may be wise to use external help to develop the first model. Here my article about supply chain carbon footprinting and here a list of experts in carbon footprinting or LCAs.\n2 – Set credible and ambitious net-zero targets\nCredibility and ambition are vital aspects when setting a net-zero target.\nThe level of ambition of a target depends on its scope, timeline aligned with science and the strategy behind:\n- Scope: your company should consider including 100% of the emissions produced in your factories, offices, warehouses, fleet and other assets that you own or operate. Besides, since most companies have the majority of their emissions from their supply chain, your targets should also cover those emissions. 52% of the 160 largest GHG emitters committed to net-zero before 2050 and half of them cover the full scope of emissions according to a benchmark from The Climate 100+, a 575 investor initiative with $54 trillion assets under management.\n- Timeline: net-zero targets should be no later than 2050. Your stakeholders also will appreciate that you set interim targets 2025, 2030 to review your progress. Of course, companies that can afford to go faster should do, although without compromising the level of abatement in their targets.\n- Strategy: validating your target against the Science-Based Target Initiative (SBTi) criteria will provide confidence to your stakeholders that your targets are aligned with the latest climate science. The other option is to disclose transparently the methodology your company has used to calculate its targets.\nAccording to Dexter Galvin, Global Director of CDP Supply Chain, there are six benefits of setting a science-based target. Brand reputation, investor confidence, Resilience against regulation, Increased innovation, Bottom line savings and Competitive edge,\n3 – Create programs and internal capabilities\nAchieving a net-zero target will require building a carbon emissions program and the capabilities to implement them.\nCarbon Emission Programs\nAs explained in the bathtub analogy, your company will need to reduce emissions and increase carbon removals.\nTo avoid or reduce emissions, the company can invest in energy efficiency or power the business with renewable energy. Besides, companies can contribute to fighting climate change by developing low-carbon products, services and low-carbon technologies that reduce their customers’ carbon emissions.\nThe company can also decide to invest in low-carbon projects inside of its value chain, also called insetting or outside of its value chain by using offsets.\nTo increase carbon removals, the company must promote carbon removals projects, also called carbon sinks, within its operations or in its value chain. Besides, companies can finance carbon sequestration projects outside its value chain. Typical projects are those related to nature-based solutions such as protecting or restoring forests, or soil carbon sequestration.\nBesides, projects such as Carbon Capture Sequestration and Utilization (CCSU), Direct Air Carbon Capture and Storage (DACCS) or Bioenergy with Carbon Capture and Storage (BECCS) technology allow to capture and store carbon.\n|Avoid or Reduce Emissions||Increase Carbon Removals|\n|Energy Efficiency, Renewables in company’s operations||Nature-Based Solutions, CCSU, DACCS in company’s operations|\n|Low-carbon Services or Products|\n|Finance Low-carbon projects (insetting-offsetting)||Finance carbon absorption projects|\nCarbon Emission Capabilities\nFor both reducing carbon emissions and increase carbon removals, you will need to build internal capabilities.\nYour company should create a robust central sustainability team to set the foundations and coordinate the full carbon emission program.\nOver time, this central team will train experts embedded in other functions of the company. With this knowledge transfer, functions such as procurement, product design, communications, or investor relations will develop their function sustainability programs aligned with the overarching strategy.\nAs important as having the right capabilities in the organization is having robust incentives. Incentives for senior leaders who will cascade down emission targets into their organizations.\nAlso, your company can use instruments such as an internal carbon price to influence investment decisions and internalize externalities. 23% of companies use an internal carbon charge of $27 per metric ton in the EU, while in Asia, it’s $18, according to research done by McKinsey & Company. These prices are still below the $50 to $100 per ton needed by 2030 to achieve the Paris Agreement’s reductions.\n4 – Report progress\nThe last step is Voluntary sharing progress against net-zero targets.\nYour company should use existing formal reporting by using an integrated report. The report should be aligned with broader climate-related reporting such as the Taskforce on Climate-Related Financial Disclosures (read TCFD article).\nBesides, it could use sustainability reporting platforms such as CDP. These platforms allow your company to gain a competitive advantage by getting ahead of regulatory changes and identifying growing risks. Moreover, it will enable your company to find new opportunities for action that your investors, employees and customers are demanding.\nThis is the decade of climate action. We have got to get it done. And when we are busy in the office, I remind my colleagues that this is the market that we hoped forBill Goldie, director of offsetting at Redshaw Advisors\nThese four steps are required to be revised continuously and, perfect is the enemy of the good. Start with simple objectives, simplify as much as possible and aim at solving the most material issues first. Aim at improving year after year using feedback from the company’s stakeholders.\nUsing Offsets in net-zero targets\nMandatory vs Voluntary Carbon Offsets\nCompanies should reduce their emissions according to the latest science.\nThe organization should balance out residual emissions that cannot be eliminated with activities that reduce or remove GHG from the atmosphere by using carbon offsets.\nThere are two types of carbon offsets: compliance offsets and voluntary offsets.\nCompliance offsets are those offsets that companies purchase to meet legal obligations such as cap-and-trade schemes (e.g. ETS in Europe)\nVoluntary offsets are those offsets that companies purchase at their discretion. They have become a widespread and controversial instrument to fight climate change.\nThe main concerns are the project’s Additionality, Permanence Double-counting, Leakage and global availability of offsets.\nThe solution is first to choose offsets that are validated and verified under well-known standards such as Gold Standard or Voluntary Carbon Standard (VCS).\nSecond, the company should transparent and publicly communicate the use of offsets.\nFinally, choose offsets that invest in programs that empower local communities, improve health and tackle poverty while reducing carbon emissions.\nThe Voluntary Carbon Offset Market needs to grow by 15 times by 2030 and 100x by 2050 according to Taskforce on Scaling Voluntary Carbon Markets’ (TSVCM) latest report. Besides, prices in 2030 could go from current y $2-10 per ton to $15-90 depending on the scenario. This could create a market of $30-50 billion in 2030.\nSBTi and Carbon Offsets\nNote that the SBTi currently doesn’t accept the use of offsets as reductions toward the progress of companies’ science-based targets.\nStill, they consider offsets as an option for companies wanting to contribute to financing additional emission reductions beyond their science-based target.\nThe paper Foundations for net-zero target setting in the corporate sector published in September 2020 by SBti, provided the initial conceptual foundations for future guidance clarifying net-zero targets and in particular the role of offsets.\nCurrently, the SBTi is working on detailed criteria and guidance using a public consultation in early 2021. A final net-zero framework, including target-setting guidance and target validation criteria, will be released in 2021 before COP26 in November 2021.\n- Net-Zero emissions companies is one of the fastest-growing business trends.\n- The lack of standard approaches puts off organizations who struggle to make their first steps.\n- Following a 4-step process, your company can start early the net-zero journey to improve over time.\n- Offsetting will play a role in decarbonizing unavoidable emissions.\n- The SBTi framework to be published before COP26 will enable companies to set credible net-zero targets and offsets.\nWe are all responsible for doing what is in our hand to address this climate crisis. I hope this article will bring you some clarity into net-zero companies.\nThe lack of standards should not stop companies from going from bold ambition to action.\nWhether as an individual or as a company, starting a net-zero emissions journey is the best way to help make this world a better place."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:9c2c65f2-e3e1-4572-a35b-2cdbef1ba8ea>","<urn:uuid:2c7dbf75-d14f-4e6c-9f9d-18de0b5975c8>"],"error":null}
{"question":"Hey! I work in both automotive and electrical engineering. I'm curious - how do power factor tests for transformer oils compare to friction tests for automotive lubricants in terms of measuring energy losses?","answer":"Both tests measure energy losses but in different ways. For automotive lubricants, friction tests use a high frequency reciprocating rig where a steel ball is loaded against a plate to measure energy lost through friction - for instance, tests showed Nanodrive lubricants reduced friction by up to 25% compared to conventional lubricants. For transformer oils, the power factor test (ASTM D-924) measures energy lost as heat when AC potential is applied to the oil, using a test cell of known gap and a calibrated bridge to measure reactive and resistance portions of current. Pure oil has very low energy loss, while contaminants increase energy absorbed as heat. The power factor is measured as the angular displacement between applied AC potential and resulting current.","context":["Nano Technology Lubricants from Millers Oils\nA low friction oil developed for motorsport applications could provide a cost-effective reduction in the CO2 emissions of road cars.\nDeveloped entirely in house by UK specialist oil developer and producer, Millers Oils, Nanodrive is a family of fully synthetic lubricants containing nanoparticles. Independent back-to- back tests on a Porsche 911 race engine showed an immediate power gain of over five percent by replacing a top conventional synthetic lubricant with Nanodrive oil of the same viscosity.\n“In motorsport, lower friction means quicker lap times and reduced wear means fewer costly engine rebuilds,” said Martyn Mann, Millers Oils technical director. “In the road car industry, there is mounting pressure to reduce vehicle fuel consumption and CO2 emissions, so engineers are continually trying to improve engine efficiency through developments such as smaller bearings and low friction rings and cylinder liners. Nanodrive contributes to each of these requirements without needing any design modifications or changes to manufacturing. It can be implemented immediately and compared with engine modifications giving the same benefit, it is very low cost.”\nEngine friction arises from two primary sources: viscous losses and boundary friction. “Viscous losses occur wherever a lubricant flows, due to shearing between adjacent layers of the oil,” explained Mann. “To reduce the effect, engine manufacturers specify ever thinner grades of lubricant. Replacing a 5w30 multigrade oil with a 0w20 grade has been estimated to give a direct improvement of two percent in fuel consumption.”\nBut, reducing viscous losses by using thinner oils risks increasing boundary friction and reducing engine life through increased wear, said Mann: “Boundary friction occurs where the oil films are so thin that opposing metal surfaces begin to interact with each other,” he continued. “These conditions exist between piston rings and cylinder bores, and in the crankshaft bearings as they begin to rotate during engine start-up. As more vehicle manufacturers introduce stop-start technology to eliminate wasteful idling and improve urban fuel economy, start-up conditions will occur much more frequently, from an average of around 40,000 times in a lifetime to one million.”\nMillers Oils used nanotechnology to create a combination of low viscous friction and reduced boundary friction. Proven in their range of transmission lubricants that won the World Motorsport Symposium’s Product Innovation award, the technology has now been further developed to provide a family of race engine lubricants.\nMillers joint managing director, Nevil Hall, said that a Nanodrive variant for high performance road cars is already in development.\nThe precise chemistry involved is being kept confidential but Millers Oils attributes the breakthrough to the exceptional reactivity of the nanoparticles used in the formulation. “The particles we use have some very special properties that make them uniquely useful as lubricants for extreme conditions,” said Mann. “As the contact load between opposing engine parts increases, reactions between the particles and the metallic surfaces actually lead to a reduction in friction. Another useful property is the way the nanoparticles nest around each other, like the layers of an onion, able to peel off under pressure, shedding a slippery, protective film over the metal surfaces to reduce friction and wear.”\nIn comparison tests with conventional boundary lubricants such as molybdenum disulphide, conducted at Millers new R&D centre in Yorkshire (UK), Nanodrive lubricants reduced friction by up to 25 percent while increasing load capacity by up to80 percent.\nA typical test to compare the sliding friction performance of different lubricants involves a high frequency reciprocating rig in which a steel ball is loaded against a reciprocating plate. In a test for a Formula One transmission application the ball was loaded at 4 Gigapascals (approximately twice the service condition) while the temperature was increased from 40oC to 160oC at 3oC per minute.\nMann outlined the test results: “The friction coefficient of a standard road car oil was 0.17 and the average film strength (measured by electrical resistivity) 84 percent. A race oil from another manufacturer showed friction of 0.11 and film strength around 75 percent. A competition oil from another brand showed friction below 0.1 but highly variable film strength, averaging 34 percent. Another race oil showed a drop in friction above 140degC meaning any benefits are restricted to extreme temperature conditions.\nMillers current triple ester synthetic oil showed a good friction figure with a film strength of 98% but the new Nanorange recorded a friction value that began to drop away from around 75oC, falling to 0.06 while retaining a film strength of 98% – halving the friction without losing any film strength.\nThe power gained by cutting frictional losses was independently demonstrated in rolling road tests on a Porsche 911 RSR. With a conventional 10w60 grade race lubricant, the car produced 268bhp, measured to DIN70020. On replacing the engine oil with Millers 10w60NT Nanodrive the result was 283bhp, an increase of 5.6 percent.\n“With prices of Nanodrive oils only around a third higher than conventional synthetic lubricants, the power gains look extremely good value for money,” concluded Hall. “Couple that with a corresponding CO2 reduction and we believe that there is a key role for these lubricants beyond motorsport, particularly in vehicles with downsized bearings, in stop-start applications, where an immediate drop in CO2 is required and in specialist high performance vehicles.”","ASTM (American Society for Testing and Materials) has developed the standards for oil testing. The following tests we recommended for a complete analysis of a transformer’s oil:\nDielectric breakdown (ASTM D-877 & D-1816)\nThe dielectric breakdown is an indication of the oil’s ability to withstand electrical stress. The most commonly performed test is ASTM D-877, and because of this, it is more readily used as a benchmark value when comparing different results. The oil sample is placed in a test cup and an AC voltage is impressed on it. The electrodes are two discs, exactly 1 in. in diameter and placed 0.10 in. apart.\nThe voltage is raised at a constant rate, until an arc jumps through the oil between the two electrodes. The voltage at which the arc occurs is considered the dielectric strength of the oil.\nFor systems over 230 kV, this test is performed using spherical electrodes spaced 0.04 or 0.08 in. apart (ASTM D-1816). Portable equipment is available for performing both levels of this test in the field.\nNeutralization number (ASTM D-974)\nAcids are formed as by-products of oxidation or sludging, and are usually present any time an oil is contaminated.\nThe concentration of acid in an oil can be determined by the amount of potassium hydroxide (KOH) needed to neutralize the acid in 1 g of oil. Although it is not a measure of the oil’s electrical strength, it is an excellent indicator of the pressure of contaminants. It is especially useful when its value is monitored over a number of sampling periods and trending data is developed.\nInterfacial tension (ASTM D-971 & D-2285)\nThe interfacial tension of an oil is the force in dynes per centimeter required to rupture the oil film existing at an oil-water interface. when certain contaminants, such as soaps, paints, varnishes, and oxidation products are present in the oil, the film strength of the oil is weakened, thus requiring less force to rupture. For in-service oils, a decreasing value indicates the accumulation of contaminants, oxidation products, or both.\nASTM D-971 uses a platinum ring to physically break the interface and measure the force required. ASTM D-2285 measures the volume of a drop of water that can be supported by the oil without breaking the interface.\nPower factor (ASTM D-924)\nThe power factor is an indication of the amount of energy that ls lost as heat to the oil. When pure oil acts as a dielectric, very little energy is lost to the capacitance charging. Contaminants will increase the energy absorbed by the oil and wasted as heat. The power factor ls a function of the phasor angle (the angular displacement) between an AC potential applied to the oil and the resulting current.\nThe test is performed by passing a current through a test cell of known gap, and “sing a calibrated capacitance or resistance bridge to separate and compare the reactive and resistance portions of the current passing through the oil.\nColor (ASTM D-1500)\nThe color of a new oil is generally accepted as au Index of refmement. For in-service oils, a darkening of the oil (higher color number), observed over a number of test intervals, is an indication of contamination or deterioration.\nThe color of an oil is obtained by comparison to numbered standards. Although there are charts available, the most accurate way to determine the oil’s color is by the use of a color wheel and a comparator. An oil sample is placed in the comparator, and the color wheel is rotated until a match is obtained. This test is most effective when results are compiled over a series of test intervals, and trending data is developed.\nTable 1 – Insulating fluids suggested test values\n|Laboratory Test Values|\n|ASTM Test||Oil||High Molecular|\n|30kV minimum||30kV minimum||30kV minimum||30kV minimum|\n|Neutralization number D-974||0.04 MG-KOH/GM maximum||0.03 MG-KOH/GM maximum||0.01 MG-KOH/GM maximum||0.25 MG-KOH/GM maximum|\n|Interfacial Tension D-971|\n|35 Dynes/cm minimim||33 Dynes/cm minimim||-||-|\n|Color D-1500||1. Maximum||N/A Maximum||0.05 D-2129||-|\n|Visual Condition D-1524||Clear bright pale straw||N/A||Crystal clear D-2129||Clear, Slightpink Iridscent|\n|Power Factor D-924 & 25|\n|0.1% maximum||0.1% maximum||0.1% maximum||2% maximum|\n|Water Content D-1533|\n15kV and below\n|35 PPM*maximum||35 PPM*maximum||80 PPM*maximum||25 PPM*maximum|\n|115kV – 230kV||20 PPM*maximum||-||-||-|\n|Above 230kV||15 PPM*maximum||-||-||-|\n* Or in accordance with manufacturer’s requirements. Some manufacturers recommend 15 PPM maximum for all transformers.\nMoisture content (ASTM D-1533)\nMoisture content is very important in determining the seniceability of an oil; the presence of moisture (as little as 25 parts per million) will usually result in a lower dielectric strength value. Water content is especially important in transformers with fluctuating loads. As the temperature increases and decreases with the changing load, the transformer’s oil can hold varying amounts of water in solution.\nLarge amounts of water can be held in solution at higher temperatures, and in this state (dissolved) the water has a dramatic effect on the oil’s performance.\nWater contamination should be avoided.\n(1) Water content is expressed in parts per million, and although water will settle to the bottom of the tank and be visible in the sample, the presence of free water is not an indication of high water content, and it is usually harmless in this state.\nThe dissolved water content is the dangerous factor; it is usually measured by physical or chemical means. A Karl Fischer titrating apparatus is one of the more common methods of measuring the dissolved water content.\n(2) There are other tests available, such as Flashpoint, Viscosity, and Specific Gravity. They are of limited value for interpretation of the oil’s quality, but can be used for further investigation if unsatisfactory results are obtained for the tests listed above.\n(3) Table 1 lists the acceptable values for the laboratory test results for various insulating fltids."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:8cd6e486-d4b1-40e1-8025-f5d0bc20a695>","<urn:uuid:73946803-0fc4-4055-9165-f8f6113c0a89>"],"error":null}
{"question":"Are calcium and tungsten both used in lighting applications?","answer":"Yes, both calcium and tungsten have been used in lighting applications, though in different ways. Calcium was historically used as lime to produce intense white light in theaters, leading to the phrase 'in the limelight.' Tungsten is still used today in incandescent light bulbs, where it forms the thin metal wire filament that heats up to produce light.","context":["Calcium is an alkaline earth metal. The alkaline earth metals make up Group 2 (IIA) of the periodic table, a chart that shows how the elements are related. They include beryllium, magnesium, strontium, barium, and radium. The alkaline earth metals are more chemically active than most metals. Only the alkali metals in Group I (IA) are more reactive.\nCalcium compounds are common and abundant in the Earth's crust. Humans have used calcium compounds for hundreds of years in construction, sculpture, and roads.\nCalcium metal was not prepared in a pure form until 1808 when English chemist Humphry Davy (1778-1829) passed an electric current through molten (melted) calcium chloride.\nMetallic calcium has relatively few uses. However, calcium compounds are well known and widely used. They include chalk, gypsum, limestone, marble, and plaster of paris.\nGroup 2 (IIA)\nAlkaline earth metal\nDiscovery and naming\nIt is impossible to say when humans first knew about or used compounds of calcium. Whenever they used limestone to build a structure, they were using a compound of calcium. Limestone is the common name for calcium carbonate (CaCO 3 ). Whenever humans built a statue or monument out of marble, they were using calcium carbonate in another form. Ancient Egyptians and early Greeks used mortar, a cement-like material that holds stones and bricks together. Early mortar was made by roasting or heating limestone for long periods of time. Water was then mixed with the powder, which would then dry to form a strong bond.\nHumphry Davy | English chemist\nH umphry Davy (1788-1829) was a major contributor to the field of electrochemistry. This is the science involving the relation of electricity to chemical changes. He is best known for discovering calcium, sodium, potassium, magnesium, strontium, and barium. He also discovered nitrous oxide and two types of lamps.\nDavy grew up in Cornwall, England, in a poor family. His father, who died when Davy was a boy, had lost money in unwise investments, so Davy helped his mother pay off the debts. He disliked being a student, though he liked reading about science. In later life, he said he was happy he did not study too hard because he had more time to think on his own.\nWith no money for further education, the 17-year-old Davy began to work for a surgeon-pharmacist. He also started learning on his own about other subjects that interested him, such as geography, languages, and philosophy. He even wrote poems that later earned him the respect and friendship of William Wordsworth, Samuel Coleridge, and other leading English poets of his time!\nAt 19, Davy read a chemistry book by the famous French scientist Antoine-Laurent Lavoisier (1743-94). That book convinced him to concentrate on chemistry. For the rest of his life, Davy's career was marked by brilliant scientific explorations in chemistry and electrochemistry.\nDavy discovered nitrous oxide after testing the effects of hydrogen and carbon dioxide on himself. (He liked to use himself as a human guinea pig!) Nitrous oxide is a gas consisting of nitrogen and oxygen. While studying nitrous oxide gas, he discovered that its effects often made him feel very happy or very sad. The feeling of happiness eventually gave nitrous oxide another name: laughing gas. Most importantly, though, Davy recognized that it could be used as an anesthetic. An anesthetic is a chemical used to dull pain during minor surgery.\nIn 1808, Davy invented the carbon arc lamp. He had proposed using carbon as the electrode material instead of metal. (Electrodes are conductors used to establish electrical contact with a nonmetallic part of a circuit.) With carbon electrodes, he made a strong electric current leap from one electrode to the other. This created an intense white light. Davy's invention marked the beginning of the era of electric light. Arc lamps are still used today.\nUsing his knowledge of electricity, Davy built a large battery which he used to break down substances most scientists thought were pure elements. In 1807, he discovered the element potassium. He created this by using electrolysis. Electrolysis produces chemical changes by passage of an electric current through an electrolyte. An electrolyte is a nonmetallic electric conductor. Within a week he isolated sodium in a similar way. Then in 1808, he used a slightly modified method to isolate calcium, magnesium, barium, and strontium. Davy was only 29 by the time he had discovered all of these elements!\nDavy later invented the miner's lamp (now known as the Davy lamp). He learned that methane was the mine gas that caused explosions. But he realized it ignited only at high temperatures. So he designed a lamp in which the flame was surrounded by wire gauze. This reduced the heat and prevented flammable gases from igniting. This made coal-mining safer by reducing the number of explosions in mines.\nDavy was rewarded by many honors and medals for his discoveries and inventions. He died of a stroke in 1829 at the age of 49.\nAnother calcium compound used by early civilizations was plaster of paris. Plaster of paris is made by heating gypsum, or calcium sulfate (CaSO 4 ), to remove the water that makes it crystallize. Water was added and it hardened into a brittle, cement-like substance. Until recently, it was most often used to make casts to protect broken bones. However, it has largely been replaced by fiberglass, which is lighter, yet stronger. The first mention of plaster of paris to protect broken bones can be found in a book written by Persian pharmacist Abu Mansur Muwaffaw in about 975 A.D.\nBy the 1700s, chemists had learned a great deal about calcium compounds. They knew that limestone, gypsum, marble, and many other commonly occurring compounds all contain a common element. They called the element calx. That word comes from the Latin term for lime. In 1807, Davy isolated the new element.\nDavy invented a system for melting compounds of elements that were difficult to separate by usual methods. He passed an electric current through the compound, causing the compounds to break into parts. One of those parts was calx. He created the name calcium by adding the suffix -ium to calx; -ium is the ending used for almost all metallic elements. Davy was also able to produce free sodium, potassium, strontium, magnesium, and barium.\nCalcium is a fairly soft metal with a shiny silver surface when first cut. The surface quickly becomes dull as calcium reacts with oxygen to form a coating of white or gray calcium oxide.\nCalcium's melting point is 850°C (1,560°F) and its boiling point is 1,440°C (2,620°F). It has a density of 1.54 grams per cubic centimeter.\nCalcium is a moderately active element. It reacts readily with oxygen to\nform calcium oxide (CaO):\nCalcium reacts with the halogens—\nfluorine, chlorine, bromine, iodine,\nThe halogens are the elements that make up Group 17 (VIIA) of the\nperiodic table. Calcium also reacts readily with cold water, most acids,\nand most nonmetals, such as\nFor example, calcium reacts with sulfur:\nOccurrence in nature\nCalcium is the fifth most common element in the Earth's crust. Its abundance is estimated to be about 3.64 percent. It is also the fifth most abundant element in the human body.\nCalcium does not occur as a free element in nature. It is much too active and always exists as a compound. The most common calcium compound is calcium carbonate (CaCO 3 ). It occurs as aragonite, calcite, chalk, limestone, marble, and travertine, and in oyster shells and coral.\nShellfish build their shells from calcium dissolved in the water. When the animals die or are eaten, the shells sink. Over many\nSix naturally occurring isotopes of calcium exist: calcium-40, calcium-42, calcium-43, calcium-44, calcium-46, and calcium-48. Isotopes are two or more forms of an element. Isotopes differ from each other according to their mass number. The number written to the right of the element's name is the mass number. The mass number represents the number of protons plus neutrons in the nucleus of an atom of the element. The number of protons determines the element, but the number of neutrons in the atom of any one element can vary. Each variation is an isotope.\nRadioactive isotopes of calcium have also been made. A radioactive isotope is one that breaks apart and gives off some form of radiation. Radioactive isotopes are produced when very small particles are fired at atoms. These particles stick in the atoms and make them radioactive.\nTwo radioactive isotopes of calcium are used in research and medicine. Calcium-45 is used to study how calcium behaves in many natural processes. For example, it can be used to see how various types of soil behave with different kinds of fertilizers. The calcium-45 is used as a tracer in such studies. A tracer is a radioactive isotope whose presence in a system can easily be detected. The isotope is injected into the system at some point. Inside the system, the isotope gives off radiation. That radiation can be followed by detectors placed around the system. Calcium-45 can also be used as a tracer in the study of glassy materials, detergents, and water purification systems.\nBoth calcium-45 and calcium-47 can be used to study how calcium is used in the body. A doctor may think that a person's body is not using calcium properly in making bones or regulating nerve messages. The doctor can use calcium-45 or calcium-47 to find out more about this problem. The radioactive isotope is injected into the person's bloodstream. Then its path can be followed by the radiation it gives off. The doctor can then tell if the calcium is being used normally in the body.\nPure calcium metal can be made by the same method used by Davy. An\nelectric current is passed through molten calcium chloride:\nThere is not much demand for pure calcium. Most calcium is used in the form of limestone, gypsum, or other minerals that can be mined directly from the earth.\nShellfish build their shells from calcium dissolved in the water.\nCalcium metal has relatively few uses. It is sometimes used as a \"getter.\" A getter is a substance that removes unwanted chemicals from a system. Calcium is used as a getter in the manufacture of evacuated glass bulbs. Calcium is added to the\nCalcium is also used to make alloys. An alloy is made by melting and mixing two or more metals. The mixture has properties different from those of the individual metals. An alloy of calcium and cerium is used in flints found in lighters (the elements that create sparks).\nThe starting point for the manufacture of most calcium compounds is limestone. Limestone occurs naturally in large amounts in many parts of the world. It is usually mined from open-pit quarries. A quarry is a large hole in the ground from which useful minerals are taken.\nLimestone is first heated to obtain lime, or calcium oxide (CaO):\nLime is one of the most important chemicals in the world. It usually ranks in the top five chemicals produced in the United States. In 1996, about 19 billion kilograms (42 billion pounds or 21 million tons) of lime was produced in the United States.\nLime is used in the production of metals. It is used during the\nmanufacture of steel to remove unwanted sand, or silicon dioxide (SiO\n), present in iron ore:\nThe product formed in this reaction, calcium silicate (CaSiO 3 ), is called slag.\nAnother important use of lime is in pollution control. Many factories\nrelease harmful gases into the atmosphere through smokestacks. Lining a\nsmokestack with lime allows some of these gases to be captured. The lime\nis known as a scrubber. Lime captures one harmful gas, sulfur dioxide (SO\n), which is a contributor to acid rain (a form of precipitation that is\nsignificantly more acidic than neutral water, often produced as the result\nof industrial processes):\nCalcium sulfite (CaSO 3 ) is a solid that can be removed from the inside of the smokestack.\n\"In the limelight\"\nAt one time, lime was used as a source of light in theaters. When lime is heated to a high temperature, it gives off an intense white light. Pots of hot lime were often used to line the front of the stage. The light the pots gave off helped the audience see the performers. As a result, the performers were said to be \"in the limelight.\" That phrase is still in use today, but lime is no longer used as a source of light in theaters.\nLime is also used in water purification and waste treatment plants. When\nwater combines with water, it forms slaked lime, or calcium hydroxide\nSlaked lime traps impurities present in the water as it forms. It carries the impurities with it as it sinks to the bottom of the tank.\nLime is used to make more than 150 different industrial chemicals. Some examples of these chemicals with their uses are:\nMilk is a good source of calcium.\ncalcium alginate: thickening agent in food products such as ice cream and cheese products; synthetic fibers\ncalcium arsenate (Ca 3 (AsO 4 ) 2 ): insecticide\ncalcium carbide (CaC 2 ): used to make acetylene gas (for use in acetylene torches for welding); manufacture of plastics\ncalcium chloride (CaCl 2 ): ice removal and dust control of dust on dirt roads; conditioner for concrete; additive for canned tomatoes; provides body for automobile and truck tires\ncalcium cyclamate (Ca(C 6 H 11 NHSO 4 ) 2 ): sweetening agent (cyclamate), no longer permitted for use because of suspected cancer-causing properties\ncalcium gluconate (Ca(C 6 H 11 O 7 ) 2 ): food additive; vitamin pills\ncalcium hypochlorite (Ca(OCl) 2 ): swimming pool disinfectant; bleaching agent; deodorant; algicide and fungicide (kills algae and fungi)\ncalcium permanganate (Ca(MnO 4 ) 2 ): liquid rocket propellant; textile production; water sterilizing agent; dental procedures\ncalcium phosphate (Ca 3 (PO 4 ) 2 ): supplement for animal feed; fertilizer; commercial production of dough and yeast products; manufacture of glass; dental products\ncalcium phosphide (Ca 3 P 2 ): fireworks; rodenticide (kills rats); torpedoes; flares\ncalcium stearate (Ca(C 18 H 35 O 2 ) 2 ): manufacture of wax crayons, cements, certain kinds of plastics, and cosmetics; food additive; production of water resistant materials; production of paints\ncalcium tungstate (CaWO 4 ): luminous paints; fluorescent lights; X-ray studies in medicine\nCalcium is essential to both plant and animal life. In humans, it makes up about two percent of body weight. About 99 percent of the calcium in a person's body is found in bones and teeth. Milk is a good source of calcium. The body uses calcium in a compound known as hydroxyapatite (Ca 10 (PO 4 ) 6 (OH) 2 ) to make bones and teeth hard and resistant to wear.\nCalcium has many other important functions in the human body. For example, it helps control the way the heart beats. An excess (too much) or deficiency (not enough) of calcium can change the rhythm of the heart and cause serious problems. Calcium also controls the function of other muscles and nerves.","Tungsten is a transition metal. The transition metals are a group of elements found in the middle of the periodic table. They occupy the boxes in Rows 4 through 7 between Groups 2 and 13. The periodic table is a chart that shows how chemical elements are related to one another.\nThese metals have very similar physical and chemical properties. One of tungsten's unusual properties is its very high melting point of 3,410°C (6,170°F). This is the highest melting point of any metal. Another of its important properties is its ability to retain its strength at very high temperatures. These properties account for tungsten's primary application, the manufacture of alloys. An alloy is made by melting and mixing two or more metals. The mixture has properties different from those of the individual metals.\nGroup 6 (VIB)\nCredit for the discovery of tungsten is often divided among three men—Spanish scientists Don Fausto D'Elhuyard (1755-1833) and his brother Don Juan Jose D'Elhuyard (1754-96), and Swedish chemist Carl Wilhelm Scheele (1742-86). Tungsten's chemical symbol, W, is taken from an alternative name for the element, wolfram.\nDiscovery and naming\nThe first mention of tungsten and its compounds can be traced to about 1761. German chemist Johann Gottlob Lehmann (1719-67) was studying a mineral known as wolframite. He found two new substances in the mineral but did not recognize that they were new elements.\nAbout twenty years later, Scheele also studied this mineral. He produced from it a white acidic powder. Scheele knew the powder was a new substance. But he could not isolate a pure element from it. Scheele's discovery was actually tungstic acid (H 2 WO 4 ). (See sidebar on Scheele in the chlorine entry in Volume 1.)\nTungsten metal was prepared for the first time in 1783 by the D'Elhuyard brothers. In 1777, they were sent to Sweden to study mineralogy. After their return to Spain, the brothers worked together on a number of projects. One project involved an analysis of wolframite. They produced tungstic acid like Scheele but went one step further. They found a way to obtain pure tungsten metal from the acid. For this work, they are generally given credit as the discoverers of tungsten.\nThe name tungsten is taken from the Swedish phrase that means \"heavy stone.\" In some parts of the world, the element is still called by another name, wolfram. This name comes from the German expression Wolf rahm, or \"wolf froth (foam).\" The element's chemical symbol is taken from the German name rather than the Swedish name.\nTungsten is a hard brittle solid whose color ranges from steel-gray to nearly white. Its melting point is the highest of any metal, 3,410°C (6,170°F) and its boiling point is about 5,900°C (10,600°F). Its density is about 19.3 grams per cubic centimeter. Tungsten conducts electrical current very well.\nTungsten is a relatively inactive metal. It does not combine with oxygen at room temperatures. It does corrode (rust) at temperatures above 400°C (700°F. It does not react very readily with acids, although it does dissolve in nitric acid or aqua regia. Aqua regia is a mixture of hydrochloric and nitric\nOccurrence in nature\nTungsten never occurs as a free element in nature. Its most common ores are the minerals scheelite, or calcium tungstate (CaWO 4 ) and wolframite, or iron manganese tungstate (Fe,MnWO 4 ). The abundance of tungsten in the Earth's crust is thought to be about 1.5 parts per million. It is one of the more rare elements.\nThe largest producers of tungsten in the world are China, Russia, and Portugal. No tungsten was mined in the United States in 1996. Detailed information about the production and use of tungsten in the United States is not available. This information is withheld from the public to protect the companies that produce and use tungsten.\nIn some parts or the world, tungsten is still called by another name, wolfram. This name comes from the German expression Wolf rahm, or \"wolf froth (foam).\"\nFive naturally occurring isotopes of tungsten exist. They are tungsten-180, tungsten-182, tungsten-183, ungsten-184, and tungsten-186. Isotopes are two or more forms of an element. Isotopes differ from each other according to their mass number. The number written to the right of the element's name is the mass number. The mass number represents the number of protons plus neutrons in the nucleus of an atom of the element. The number of protons determines the element, but the number of neutrons in the atom of any one element can vary. Each variation is an isotope.\nAbout a dozen radioactive isotopes of tungsten are known also. A radioactive isotope is one that breaks apart and gives off some form of radiation. Radioactive isotopes are produced when very small particles are fired at atoms. These particles stick in the atoms and make them radioactive.\nNone of the radioactive isotopes of tungsten has any important commercial use.\nTungsten metal can be obtained by heating tungsten oxide (WO\nIt also results from passing\ngas over hot tungstic acid (H\nBy far the most important use of tungsten is in making alloys. Tungsten is used to increase the hardness, strength, elasticity (flexibility), and tensile strength (ability to stretch) of steels. The metal is usually prepared in one of two forms. Ferrotungsten is an alloy of iron and tungsten. It usually contains about 70 to 80 percent tungsten. Ferrotungsten is mixed with other metals and alloys (usually steel) to make specialized alloys. Tungsten is also produced in powdered form. It can then be added to other metals to make alloys.\nAbout 90 percent of all tungsten alloys are used in mining, construction, and electrical and metalworking machinery.\nAbout 90 percent of all tungsten alloys are used in mining, construction, and electrical and metal-working machinery. These alloys are used to make high-speed tools; heating elements in furnaces; parts for aircraft and spacecraft; equipment used in radio, television, and radar; rock drills; metal-cutting tools; and similar equipment.\nA small, but very important, amount of tungsten is used to make incandescent lights. The very thin metal wire that makes up the filament in these lights is made of tungsten. An electric current passes through the wire, causing it to get hot and give off light. It does not melt because of the high melting point of tungsten.\nProbably the most important compound of tungsten is tungsten carbide (WC). Tungsten carbide has a very high melting point of 2,780°C (5,000°F). It is the strongest structural material. It is used to make parts for electrical circuits, cutting tools, cermets, and cemented carbide. A cermet is a material made of a ceramic and a metal. A ceramic is a clay-like material. Cermets are used where very high temperatures occur for long periods of time. For example, the parts of a rocket motor or a jet engine may be made from a cermet.\nA cemented carbide is made by bonding tungsten carbide to another metal. The product is very strong and remains strong at high temperatures. Cemented carbides are used for rock and metal cutting. They can operate at 100 times the speed of similar tools made of steel.\nTungsten has no essential role in the health of plants, humans, or animals. In moderate amounts, it also presents virtually no health danger."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:098c8368-e0d8-44a3-83e3-98dfb87ed79a>","<urn:uuid:3752bd29-fd88-4c4a-a2cb-e9b963d4373e>"],"error":null}
{"question":"As a Kubernetes developer, I'm comparing failure handling mechanisms: what's the key difference between how liveness probes handle HTTP status code 404 versus 500?","answer":"The difference lies in how these HTTP status codes affect liveness probe behavior. For liveness probes using HTTP checks, a 404 status code would fail the probe since it falls outside the acceptable range of 200-399, leading to a container restart. Similarly, a 500 status code would also fail the probe as it indicates an internal server error and falls outside the successful range. However, the key distinction is in what they indicate: a 404 means the requested resource was not found at the given URL, while a 500 indicates the server encountered something unexpected and was unable to complete the request.","context":["Kubernetes liveness probes determine whether your pods are running normally. Setting up these probes helps you check whether your workloads are healthy. They can identify application instances that have entered a failed state, even when the pod that contains the instance appears to be operational.\nKubernetes automatically monitors your pods and restarts them when failures are detected. This handles issues where your application crashes, terminating its process and emitting a non-zero exit code. Not all issues exhibit this behavior, though. Your application could have lost its database connection, or be experiencing timeouts while communicating with a third-party service. In these situations, the pod will look from the outside like it’s running, but users won’t be able to access the application within.\nLiveness probes are a mechanism for indicating your application’s internal health to the Kubernetes control plane. Kubernetes uses liveness probes to detect issues within your pods. When a liveness check fails, Kubernetes restarts the container in an attempt to restore your service to an operational state.\nIn this article, you’ll explore when liveness probes should be used, how you can create them, and some best practices to be aware of as you add probes to your cluster.\nWhy Do Liveness Probes Matter?\nLiveness probes enhance Kubernetes’ ability to manage workloads on your behalf. Without probes, you need to manually monitor your pods to distinguish which application instances are healthy and which are not. This becomes time-consuming and error-prone when you’re working with hundreds or thousands of pods.\nAllowing unhealthy pods to continue without detection degrades your service’s stability over time. Pods that are silently failing as they age, perhaps due to race conditions, deadlocks, or corrupted caches, will gradually reduce your service’s capacity to handle new requests. Eventually, your entire pod fleet could be affected, even though all the containers report as running.\nDebugging this kind of issue is often confusing and inefficient. Since all your dashboards show your pods as operational, it’s easy to turn down the wrong diagnostic path. Using liveness probes to communicate information about pods’ internal states to Kubernetes lets your cluster handle problems for you, reducing the maintenance burden and ensuring you always have serviceable pods available.\nTypes of Liveness Probes\nThere are four basic types of liveness probes:\n- Exec: The probe runs a command inside the container. The probe is considered successful if the command terminates with <terminal inline>0<terminal inline> as its exit code.\n- HTTP: The probe makes an HTTP <terminal inline>GET<terminal inline> request against a URL in the container. The probe is successful when the container’s response has an HTTP status code in the 200-399 range.\n- TCP: The probe tries to connect to a specific TCP port inside the container; if the port is open, the probe is deemed successful.\n- gRPC: gRPC health-checking probes are supported for applications that use gRPC. This type of probe is available in alpha as of Kubernetes v1.23.\nThe probe types share five basic parameters for configuring the frequency and success criteria of the checks:\n- <terminal inline bold>initialDelaySeconds<terminal inline bold>: Set a delay between the time the container starts and the first time the probe is executed. Defaults to zero seconds.\n- <terminal inline bold>periodSeconds<terminal inline bold>: Defines how frequently the probe will be executed after the initial delay. Defaults to ten seconds.\n- <terminal inline bold>timeoutSeconds<terminal inline bold>: Each probe will time out and be marked as failed after this many seconds. Defaults to one second.\n- <terminal inline bold>failureThreshold<terminal inline bold>: Instructs Kubernetes to retry the probe this many times after a failure is first recorded. The container will only be restarted if the retries also fail. Defaults to three.\n- <terminal inline bold>successThreshold<terminal inline bold>: This sets the criteria for reverting an unhealthy container to a healthy state. It means the container must successfully pass this number of consecutive liveness checks before it’s deemed healthy again. Defaults to one.\nSuccessful liveness probes have no impact on your cluster. The targeted container will keep running, and a new probe will be scheduled to run after the configured <terminal inline>periodSeconds<terminal inline> delay. A failed probe will trigger a restart of the container, as it’s expected that the fresh instance will be healthy.\nCreating Liveness Probes\nLiveness probes are defined by a pod’s <terminal inline>spec.containers.livenessProbe<terminal inline> field. Here’s a simple example of an <terminal inline>exec<terminal inline> (command) type liveness probe:\nThis pod’s containers have a liveness probe that has an initial delay of five seconds, then reads the content of the <terminal inline>/healthcheck<terminal inline> file every fifteen seconds. The container is configured to create the <terminal inline>/healthcheck<terminal inline> file when it starts up; it then removes the file after thirty seconds have elapsed. The liveness probe’s <terminal inline>cat<terminal inline> command will begin to issue non-zero status codes at this point, causing subsequent probes to be marked as failed.\nApply the YAML manifest to your cluster:\nNow inspect the events of the pod you’ve created:\nEverything looks good! The container was created and started successfully. There’s no sign of any failed liveness probes.\nNow wait for thirty seconds before retrieving the events again:\nThe event log now shows that the liveness probe began to fail after the container deleted its <terminal inline>/healthcheck<terminal inline> file. The event reveals the output from the liveness probe’s command. If you used a different probe type, such as HTTP or TCP, you’d see relevant information such as the HTTP status code instead.\nHTTP probes are created in a similar manner to exec commands. Nest an <terminal inline>httpGet<terminal inline> field instead of <terminal inline>exec<terminal inline> in your <terminal inline>livenessProbe<terminal inline> definition:\nThis probe sends an HTTP <terminal inline>GET<terminal inline> request to <terminal inline>/healthz<terminal inline> on the container’s port <terminal inline>8080<terminal inline> every fifteen seconds. The image used is a minimal HTTP server provided by Kubernetes as an example liveness check provider. The server issues a successful response with a <terminal inline>200<terminal inline> status code for the first ten seconds of its life. After that point, it will return a <terminal inline>500<terminal inline>, failing the liveness probe and causing the container to restart.\nThe <terminal inline>livenessProbe.httpGet<terminal inline> field supports optional <terminal inline>host<terminal inline>, <terminal inline>scheme<terminal inline>, <terminal inline>path<terminal inline>, and <terminal inline>httpHeaders<terminal inline> fields to customize the request that’s made. The <terminal inline>host<terminal inline> defaults to the pod’s internal IP address; the scheme is <terminal inline>http<terminal inline>. The following snippet sets up a probe to make an HTTP request with a custom header:\nTCP probes try to open a socket to your container on a specified port. Add a <terminal inline>tcpSocket.port<terminal inline> field to your <terminal inline>livenessProbe<terminal inline> configuration to use this probe type:\nThe probe will be considered failed if the socket can’t be opened.\ngRPC probes are the newest type of probe. The implementation is similar to the grpc-health-probe utility, which was commonly used before Kubernetes integrated the functionality.\nTo use a gRPC probe, ensure you’re on Kubernetes v1.23 and have the <terminal inline>GRPCContainerProbe<terminal inline> feature gate enabled. Add a <terminal inline>grpc.port<terminal inline> field to your pod’s <terminal inline>livenessProbe<terminal inline> to define where health checks should be directed to:\nThe <terminal inline>etcd<terminal inline> container image is used here as an example of a gRPC-compatible service. Kubernetes will send gRPC health check requests to port 2379 in the container. The liveness probe will be marked as failed when the container issues an unhealthy response. The probe is also considered failed if the service doesn’t implement the gRPC health checking protocol.\nBest Practices for Effective Probes\nLiveness probes have some pitfalls that you need to watch out for. Foremost among these are the impact misconfigured probes can have on your application. A probe that’s run too frequently wastes resources and impedes performance; conversely, probing infrequency can let containers sit in an unhealthy state for too long.\nThe <terminal inline>periodSeconds<terminal inline>, <terminal inline>timeoutSeconds<terminal inline>, and success and failure threshold parameters should be used to tune your probes to your application. Pay attention to how long your probe’s command, API request, or gRPC call takes to complete. Use this value with a small buffer period as your <terminal inline>timeoutSeconds<terminal inline>. The <terminal inline>periodSeconds<terminal inline> needs to be bespoke to your environment; a good rule of thumb is to use the smallest value possible for simple, short-running probes. More intensive commands may need to wait longer between repetitions.\nProbes themselves should be as lightweight as possible. To ensure that your checks can execute quickly and efficiently, avoid using expensive operations within your probes. The target of your probe’s command or HTTP request should be independent of your main application, so it can run to completion even during failure conditions. A probe that’s served by your standard application entry point could lead to inaccurate results if its framework fails to start or a required external dependency is unavailable.\nHere are a few other best practices to keep in mind:\n- Probes are affected by restart policies. Container restart policies are applied after probes. This means your containers need <terminal inline>restartPolicy: Always<terminal inline> (the default) or <terminal inline>restartPolicy: OnFailure<terminal inline> so Kubernetes can restart them after a failed probe. Using the Never policy will keep the container in the failed state.\n- Probes should be consistent in their execution. You should be able to approximate the execution time of your probes, so you can configure their period, delay, and timeout correctly. Observe your real-world workloads instead of using the defaults that Kubernetes provides.\n- Not every container needs a probe. Simple containers that always terminate on failure don’t need a probe. You may also omit probes from low-priority services, where the command would need to be relatively expensive to accurately determine healthiness.\n- Revisit your probes regularly. New features, optimizations, and regressions in your app can all impact probe performance and what constitutes a “healthy” state. Set a reminder to regularly check your probes and make necessary adjustments.\nOther Types of Probes\nLiveness probes aren’t your only option for disclosing a pod’s internal status to Kubernetes. Liveness probes exclusively focus on the ongoing health of your application; two other probes are better suited for detecting problems early in a pod’s lifecycle.\nReadiness probes determine when new containers are able to receive traffic. Pods with one of these probes won’t become part of services until the probe indicates its assent. You can use this mechanism to prevent a new container from handling user requests while its bootstrap scripts are running.\nStartup probes are the final type of probe. They indicate if a container’s application has finished launching. When a container has this type of probe, its liveness and readiness probes won’t be executed until the startup probe has succeeded. It’s a way to avoid continual container restarts due to probes that fail because the application’s not ready to handle them.\nLiveness probes are a Kubernetes mechanism for exposing whether the applications inside your containers are healthy. It’s a way to address the disconnect between Kubernetes’ perception of your pods and the reality of if users can actually access your service.\nIn this article, you’ve learned why you should use liveness probes, the types of probes that are available, and how you can start attaching them to your pods. We’ve also discussed some of the config tweaks necessary to prevent probes becoming problems themselves.\nYou can keep tabs on your Kubernetes installation and watch for unhealthy pods using ContainIQ. The platform provides an integrated view of your cluster and its activities, including liveness probes and container restart events, and is a great way to check whether your probes are having the effect you intended.","Blog » HTTP Status Codes for Beginners\nHTTP, Hypertext Transfer Protocol, is the method by which clients (i.e. you) and servers communicate. When someone clicks a link, types in a URL or submits out a form, their browser sends a request to a server for information. It might be asking for a page, or sending data, but either way, that is called an HTTP Request. When a server receives that request, it sends back an HTTP Response, with information for the client. Usually, this is invisible, though I'm sure you've seen one of the very common Response codes - 404, indicating a page was not found. There are a fair few more status codes sent by servers, and the following is a list of the current ones in HTTP 1.1, along with an explanation of their meanings.\nA more technical breakdown of HTTP 1.1 status codes and their meanings is available at http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html. There are several versions of HTTP, but currently HTTP 1.1 is the most widely used.\n- 100 - Continue\nA status code of 100 indicates that (usually the first) part of a request has been received without any problems, and that the rest of the request should now be sent.\n- 101 - Switching Protocols\nHTTP 1.1 is just one type of protocol for transferring data on the web, and a status code of 101 indicates that the server is changing to the protocol it defines in the \"Upgrade\" header it returns to the client. For example, when requesting a page, a browser might receive a statis code of 101, followed by an \"Upgrade\" header showing that the server is changing to a different version of HTTP.\n- 200 - OK\nThe 200 status code is by far the most common returned. It means, simply, that the request was received and understood and is being processed.\n- 201 - Created\nA 201 status code indicates that a request was successful and as a result, a resource has been created (for example a new page).\n- 202 - Accepted\nThe status code 202 indicates that server has received and understood the request, and that it has been accepted for processing, although it may not be processed immediately.\n- 203 - Non-Authoritative Information\nA 203 status code means that the request was received and understood, and that information sent back about the response is from a third party, rather than the original server. This is virtually identical in meaning to a 200 status code.\n- 204 - No Content\nThe 204 status code means that the request was received and understood, but that there is no need to send any data back.\n- 205 - Reset Content\nThe 205 status code is a request from the server to the client to reset the document from which the original request was sent. For example, if a user fills out a form, and submits it, a status code of 205 means the server is asking the browser to clear the form.\n- 206 - Partial Content\nA status code of 206 is a response to a request for part of a document. This is used by advanced caching tools, when a user agent requests only a small part of a page, and just that section is returned.\n- 300 - Multiple Choices\nThe 300 status code indicates that a resource has moved. The response will also include a list of locations from which the user agent can select the most appropriate.\n- 301 - Moved Permanently\nA status code of 301 tells a client that the resource they asked for has permanently moved to a new location. The response should also include this location. It tells the client to use the new URL the next time it wants to fetch the same resource.\n- 302 - Found\nA status code of 302 tells a client that the resource they asked for has temporarily moved to a new location. The response should also include this location. It tells the client that it should carry on using the same URL to access this resource.\n- 303 - See Other\nA 303 status code indicates that the response to the request can be found at the specified URL, and should be retrieved from there. It does not mean that something has moved - it is simply specifying the address at which the response to the request can be found.\n- 304 - Not Modified\nThe 304 status code is sent in response to a request (for a document) that asked for the document only if it was newer than the one the client already had. Normally, when a document is cached, the date it was cached is stored. The next time the document is viewed, the client asks the server if the document has changed. If not, the client just reloads the document from the cache.\n- 305 - Use Proxy\nA 305 status code tells the client that the requested resource has to be reached through a proxy, which will be specified in the response.\n- 307 - Temporary Redirect\n307 is the status code that is sent when a document is temporarily available at a different URL, which is also returned. There is very little difference between a 302 status code and a 307 status code. 307 was created as another, less ambiguous, version of the 302 status code.\n- 400 - Bad Request\nA status code of 400 indicates that the server did not understand the request due to bad syntax.\n- 401 - Unauthorized\nA 401 status code indicates that before a resource can be accessed, the client must be authorised by the server.\n- 402 - Payment Required\nThe 402 status code is not currently in use, being listed as \"reserved for future use\".\n- 403 - Forbidden\nA 403 status code indicates that the client cannot access the requested resource. That might mean that the wrong username and password were sent in the request, or that the permissions on the server do not allow what was being asked.\n- 404 - Not Found\nThe best known of them all, the 404 status code indicates that the requested resource was not found at the URL given, and the server has no idea how long for.\n- 405 - Method Not Allowed\nA 405 status code is returned when the client has tried to use a request method that the server does not allow. Request methods that are allowed should be sent with the response (common request methods are POST and GET).\n- 406 - Not Acceptable\nThe 406 status code means that, although the server understood and processed the request, the response is of a form the client cannot understand. A client sends, as part of a request, headers indicating what types of data it can use, and a 406 error is returned when the response is of a type not i that list.\n- 407 - Proxy Authentication Required\nThe 407 status code is very similar to the 401 status code, and means that the client must be authorised by the proxy before the request can proceed.\n- 408 - Request Timeout\nA 408 status code means that the client did not produce a request quickly enough. A server is set to only wait a certain amount of time for responses from clients, and a 408 status code indicates that time has passed.\n- 409 - Conflict\nA 409 status code indicates that the server was unable to complete the request, often because a file would need to be editted, created or deleted, and that file cannot be editted, created or deleted.\n- 410 - Gone\nA 410 status code is the 404's lesser known cousin. It indicates that a resource has permanently gone (a 404 status code gives no indication if a resource has gine permanently or temporarily), and no new address is known for it.\n- 411 - Length Required\nThe 411 status code occurs when a server refuses to process a request because a content length was not specified.\n- 412 - Precondition Failed\nA 412 status code indicates that one of the conditions the request was made under has failed.\n- 413 - Request Entity Too Large\nThe 413 status code indicates that the request was larger than the server is able to handle, either due to physical constraints or to settings. Usually, this occurs when a file is sent using the POST method from a form, and the file is larger than the maximum size allowed in the server settings.\n- 414 - Request-URI Too Long\nThe 414 status code indicates the the URL requested by the client was longer than it can process.\n- 415 - Unsupported Media Type\nA 415 status code is returned by a server to indicate that part of the request was in an unsupported format.\n- 416 - Requested Range Not Satisfiable\nA 416 status code indicates that the server was unable to fulfill the request. This may be, for example, because the client asked for the 800th-900th bytes of a document, but the document was only 200 bytes long.\n- 417 - Expectation Failed\nThe 417 status code means that the server was unable to properly complete the request. One of the headers sent to the server, the \"Expect\" header, indicated an expectation the server could not meet.\n- 500 - Internal Server Error\nA 500 status code (all too often seen by Perl programmers) indicates that the server encountered something it didn't expect and was unable to complete the request.\n- 501 - Not Implemented\nThe 501 status code indicates that the server does not support all that is needed for the request to be completed.\n- 502 - Bad Gateway\nA 502 status code indicates that a server, while acting as a proxy, received a response from a server further upstream that it judged invalid.\n- 503 - Service Unavailable\nA 503 status code is most often seen on extremely busy servers, and it indicates that the server was unable to complete the request due to a server overload.\n- 504 - Gateway Timeout\nA 504 status code is returned when a server acting as a proxy has waited too long for a response from a server further upstream.\n- 505 - HTTP Version Not Supported\nA 505 status code is returned when the HTTP version indicated in the request is no supported. The response should indicate which HTTP versions are supported."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:ff88fe95-368c-482b-843e-fd73eba34ce0>","<urn:uuid:04a37397-d5bc-429d-bfde-8cf868d179fe>"],"error":null}
{"question":"What are the key differences between traditional hip replacement and anterior hip replacement in terms of surgical incision and muscle impact?","answer":"Traditional hip replacement requires an eight to 12 inch incision in the side or back of the leg and involves cutting muscles, tendons, and ligaments to access the hip joint. In contrast, anterior hip replacement uses a smaller three to six inch incision on the front of the hip and is a muscle-sparing surgery where no muscles are cut to access the joint. Instead, muscles are moved aside along their natural tissue planes. The anterior approach also preserves the tissue that keeps the joint tight, which may help reduce the risk of dislocation after surgery.","context":["If other treatment methods have been unsuccessful, depending on your diagnosis, surgery may be an option to address your hip pain and mobility. There are various surgical options available, all intended to help restore your ability to move, alleviate your pain, and improve your quality of life. Talk to your surgeon about what may be right for you.\nDuring total hip replacement surgery, the bone surfaces and cartilage that have been damaged are removed and replaced with implants. A standard total hip replacement has four parts: a cup, liner, ball, and stem. The cup is made of metal and fits into the natural hip socket. A liner, made of a medical grade plastic called polyethylene, fits inside the cup. The top of the thighbone is replaced with a metal, or ceramic, ball that is then attached to a metal stem that fits down into the thighbone.\nThese implants are designed to mimic the action of your natural hip joint, helping to restore movement and reduce painful bone-on-bone contact.\nTo learn more about hip pain treatment options, click here.\nAnterior hip surgery uses the same implants as total hip replacement surgery, but requires less cutting of the tissues around the hip. During traditional hip replacement surgery, an eight to 12 inch incision is made in the side or back of your leg. With anterior hip surgery, your doctor will make a three to six inch incision. This procedure also allows your surgeon to preserve the tissue that keeps your joint tight, which might help minimize the risk of dislocation after surgery.\nAnother type of hip replacement procedure is called hip resurfacing. In traditional total hip replacement, the top of the thighbone and the damaged socket are both removed. They are then replaced with metal, plastic, and/or ceramic components. With hip resurfacing, the top of the thighbone isn’t removed. It’s trimmed and capped with a smooth metal covering. The damaged bone and cartilage in the socket are removed and replaced with a metal shell, typically lined with a plastic-like insert.\nThe prospect of having any of the treatments listed above can be a lot to handle. Be open with your doctor and your family about how you are feeling. As with many procedures, there are risks associated with joint replacement as you can see below. Together, you and your surgeon can discuss these risks and figure out a treatment path that feels right for you.\nSome of the risks associated with joint replacement include infection, wear, implant or bone fracture, loosening, nerve damage and implant migration (movement); some patients continue to experience some pain after joint replacement. Individual results of joint surgery will vary. Your results will depend on your personal circumstances. How long a hip replacement will last varies from patient to patient. It depends on many factors, such as the patient's physical condition, activity level, and body weight and how well you follow doctor’s orders. Replacement joints are not as strong or durable as natural, healthy joints, and there is no guarantee that a prosthetic joint will last the rest of a patient's life. All hip replacements may need to be replaced at some point. Talk to your surgeon about these and other risks associated with joint replacement.\nTo learn more about the risks of hip replacement surgery, click here.","The surgical procedure involves a small incision in front of the hip, anterior, as opposed to an incision on the side or back of the hip. It is referred to as a muscle sparing surgery because no muscles are cut to access the hip joint enabling a quicker return to normal activity.\nWhat muscles do they cut for anterior hip replacement?\nBesides cutting through the gluteal muscle (buttock muscle), most of the tendons that attach to the back of the hip have to be cut to gain access to the hip joint during the posterior approach to hip replacement. The majority of the posterior tendon of the hip are preserved during the direct anterior approach.\nDo muscles get cut during a hip replacement?\nIn traditional hip replacement surgery, the surgeon makes a long incision and cuts muscles, tendons and ligaments to get to the hip joint. When more tissues, muscles and tendons are cut during surgery, the recovery is more painful and the healing process takes longer.\nWhere is the incision for an anterior hip replacement?\nDirect anterior hip replacement is a minimally invasive surgical technique. This approach involves a 3 to 4 inch incision on the front of the hip that allows the joint to be replaced by moving muscles aside along their natural tissue planes, without detaching any tendons.\nHow long does muscle pain last after anterior hip replacement?\nIf you feel like you are consistently at a 6 or more on a 1–10 pain scale, mention it to your doctor, because it could be a sign of infection or another complication. As you continue physical therapy, your pain levels should slowly decrease to about 1 or 2 in 12 weeks after the hip replacement.\nHow much does it hurt after an anterior hip replacement?\n3 Days After\nPatients may require pain medication this day/evening to rest comfortably. Use as prescribed. Swelling, redness, warmth, and tingling/numbness may still be felt around the incision site. Thigh stiffness and mild knee pain may be present.\nWhat can you never do after hip replacement?\n- Don’t cross your legs at the knees for at least 6 to 8 weeks.\n- Don’t bring your knee up higher than your hip.\n- Don’t lean forward while sitting or as you sit down.\n- Don’t try to pick up something on the floor while you are sitting.\n- Don’t turn your feet excessively inward or outward when you bend down.\nHow do you poop after hip surgery?\nMake sure you’re drinking plenty of fluids — lots of water — and eating foods with fiber, like vegetables and beans. Feel free to use a stool softener, too. Any over-the-counter product will do. Also, remember that there’s no set rule for how many bowel movements you should be having.\nHow long does it take for bone to grow into hip replacement?\nIf the prosthesis is not cemented into place, it is necessary to allow four to six weeks (for the femur bone to “grow into” the implant) before the hip joint is able to bear full weight and walking without crutches is possible.\nWhat is the best hip replacement to have?\nPeople who are sensitive to the nickel used in metal implants might be a good fit for the ceramic type. We use ceramic on polyethylene in the majority of total hip replacements. Ceramic on Ceramic – This type of implant was very popular 10 years ago. It had very low wear.\nHow long does it take for an anterior hip replacement to heal?\nSince the muscles around the hip joint are not cut with the anterior approach, recovery only takes two to eight weeks.\nCan you sleep on your side after anterior hip replacement?\nIt’s best to avoid sleeping on your affected side for at least six weeks. After your doctor gives you the go-ahead, listen to your body, and only lie on your operative side when you feel comfortable.\nWhy does my whole leg hurt after hip replacement?\nYou can expect to experience some discomfort in the hip region itself, as well as groin pain and thigh pain. This is normal as your body adjusts to changes made to joints in that area. There can also be pain in the thigh and knee that is typically associated with a change in the length of your leg.\nHow long does thigh pain last after anterior hip replacement?\nIt is common to experience thigh soreness, swelling, and/or bruising. The bruising often does not peak until you are 1 week or more post-op, and may appear all the way down to or below your knee. It may take a month or two for the swelling and bruising to resolve.\nWhy does my thigh hurt after hip replacement?\nTendonitis around the hip muscles or subtle tears. Sometimes, inflammation around these tendons irritates the local nerves around the hip and can cause radiation or pain in the groin, thigh, and buttock. These can also usually be addressed with physical therapy, cortisone injections and anti-inflammatories."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:0035500e-9c33-4629-adc8-6c3501475ddd>","<urn:uuid:468edea1-956c-4007-bdef-94be6618f11b>"],"error":null}
{"question":"How do the treatment approaches differ between carpal tunnel syndrome and traumatic brain injury in workplace injuries?","answer":"The treatment approaches for these conditions differ significantly. For traumatic brain injury, the emphasis is on seeing medical providers specifically experienced in treating brain injuries, as treatment and recovery can vary widely in cost and scope. Meanwhile, carpal tunnel syndrome (a form of distal median nerve dysfunction) has more standardized treatments including wrist splints to reduce further nerve injury, particularly when worn at night to decrease inflammation. While TBI treatment requires specialized expertise, carpal tunnel may be treated with various approaches including over-the-counter medications, physical therapy, orthopedic assistance with braces or splints, and in some cases surgery through carpal tunnel release. Both conditions benefit from early intervention and proper medical provider selection.","context":["Like carpel tunnel a decade ago, traumatic brain injury (TBI) is an emerging work comp trend causing concern for many employers. At a Traumatic Brain Injury seminar we hosted on April 3, work comp and brain injury specialists made it clear that these injuries can be subjective and depending on the doctor, treatment and recovery can vary widely in cost and scope. From concussions to severe trauma, when an employee suffers a traumatic brain injury at work, make sure they see a medical provider experienced in treating these types of injuries.\nBest Practices to Get Employees Back to Work\nWithout a return to work process in place, employees seek treatment at the ER or with a family doctor which can draw out the recovery process and drive up the cost of the claim. The best way to get injured employees back to productive work and reduce the cost of claims is to partner with a medical provider who understands work comp.\nChoosing the Right Provider to Treat Workplace Injuries\nIn Minnesota, you cannot force your employees to see a specific medical provider for workplace injuries, but you can recommend a designated provider who knows your company and understands work comp. Developing a relationship with the right medical provider may take some time, but the continued benefit to your work comp program will make your effort worthwhile.\n- Look for an occupational medicine or other provider that offers the following:\n- Occupational health and employee injury management as part of their core practice areas\n- Mission and vision that support your goals of keeping employees safe, healthy, and productive\n- Evidence-based protocols, such as those established by the American College of Occupational and Environmental Medicine (ACOEM) or the American Medical Association’s Guides to the Evaluation of Work Ability and Return to Work\nThe right medical provider will help you control your work comp costs in several specific ways: keep claims medical-only when possible, reducing the cost of the claim by 70% on your experience mod; reducing overall medical costs; and, if lost-time wages are paid, keeping time off to a minimal amount. The right provider can also help prevent malingering claims and decrease the likelihood of lawyer involvement.\nHow to Evaluate Medical Providers\nCreate a list of medical providers then give them a call. Ask for the names of the medical director, clinic director, business manager or clinic marketing staff. Most clinics are eager for new business and will be open to discussing options.\nQualify the providers on your list by scheduling a visit. During the visit, share more information about your company and operations, and your return to work program, and find out if the provider is able to meet your goals. The focus of your visit is not to negotiate a discounted fee schedule, but to provide the clinic with regular business in exchange for their commitment to certain requirements. If the clinic is unable to commit, cross them off and move onto the next provider on your list.\nTrain your employees on your return to work process. Let them know you are fully committed to helping them get the best possible care if they get injured at work, and that you have a return to work process in place.\nIf the employee chooses to see a provider not on your list, do not be afraid to reach out to the clinic to inform them of your return to work process, provide the employee’s job description and a list of available light duty work, and ask for documentation.\nYou should also partner with a 24/7 nurse care line specializing in workplace injuries. Available any time, a nurse care line program often cuts out a trip to the ER by immediately assessing the seriousness of an injury, recommending treatment options, and assisting the employee with seeking medical care as needed. The care line nurse can also assist with obtaining documents and sharing other important information with the medical provider, regardless of who the employee chooses to visit. Contact your insurance company or broker to see if a nurse care line is available to you.\nTake Steps to Prevent Brain Injuries at Work\nIn addition to a return to work program, take steps to prevent traumatic brain injuries in your workplace:\n- Remove tripping hazards from walkways and workspaces like clutter, cords, rugs, spills, or anything else that could cause a slip, trip, or fall\n- Clean up spills immediately and use “wet floor” signs to alert employees of slippery surfaces\n- Use handrails when taking the stairs\n- Only use objects designed specifically for climbing; never use chairs, tables, or other objects to reach overhead items\n- Use caution working from heights; never stand on the top two steps of a ladder\n- For jobs that require a helmet, make sure it’s properly fitted and in good condition\n- During the winter, provide employees with portable salt-and-sand shakers and encourage them to use the shakers on slippery spots on their way into or out of the workplace","Distal median nerve dysfunction\nDistal median nerve dysfunction is a form of peripheral neuropathy that affects the movement of or sensation in the hands.\nA common type of distal median nerve dysfunction is carpal tunnel syndrome.\nNeuropathy - distal median nerve\nDysfunction of one nerve group, such as the distal median nerve, is called a mononeuropathy. Mononeuropathy means there is a local cause of the nerve damage, although occasionally body-wide (systemic) disorders may cause isolated nerve damage.\nDistal median nerve dysfunction occurs when the nerve is inflamed, trapped, or injured by trauma. The most common reason is trapping (entrapment), which puts pressure on the nerve where it passes through a narrow area. Wrist fractures may injure the median nerve directly or may increase the risk for trapping a nerve later on.\nInflammation of the tendons (tendonitis) or joints (arthritis) can also cause nerve compression. Some repetitive movements increase the chance of developing carpal tunnel entrapment.\nConditions that affect connective tissue or cause deposits to form in tissue can block blood flow and lead to nerve compression. Such conditions include:\nIn some cases, no cause can be identified. Diabetes can make this condition worse.\n- Pain in the wrist or hand that may be severe and wake you up at night, and that may be felt in other areas, such as the upper arm (this is called referred pain)\n- Sensation changes in the thumb and pointer (index), middle, and part of the ring fingers, such as a burning feeling, decreased sensation, numbness, and tingling\n- Weakness of the hand that causes you to drop things or have difficulty grasping objects or buttoning a shirt\nExams and Tests\nYour doctor will examine your wrist and ask questions about your medical history. The examination may show decreased sensation in the thumb side of the hand. This is called the \"radial\" side. There may be weakness of the thumb and difficulty using it to pinch.\nTests that reveal distal median nerve dysfunction may include:\nTests are guided by the suspected cause of the nerve dysfunction, which is based on your history, symptoms, and the way symptoms developed. They may include various blood tests, x-rays, imaging scans, or other tests and procedures.\nTreatment is aimed at correcting the underlying cause.\nIf the median nerve is affected by carpal tunnel syndrome, a wrist splint can reduce further injury to the nerve and help relieve symptoms. Wearing the splint at night will give the area a rest and allow inflammation to decrease. An injection into the wrist may help with symptoms, but it won't fix the underlying problem.\nIn some cases, no treatment is required and recovery happens on its own. Over-the-counter or prescription medication may be needed to control nerve pain (neuralgia).\nIf other nerves are also affected, it is necessary to look for an underlying medical problem that can affect nerves. Medical conditions such as diabetes and kidney disease can damage nerves. In these cases, treatment is directed at the medical condition.\nPhysical therapy exercises may help some peoplemaintain muscle strength. Orthopedic assistance may maximize the ability to use the hand. Such therapy may involve braces, splints, or other appliances. Vocational counseling, occupational therapy, occupational changes, job retraining, or other measures may be recommended.\nSome patients with carpal tunnel syndrome may need surgery. See: Carpal tunnel release\nIf the cause of the nerve dysfunction can be identified and successfully treated, there is a good chance of full recovery. In some cases, there may be partial or complete loss of movement or sensation. Nerve pain may be severe and persist for a prolonged period of time.\n- Deformity of the hand (rare)\n- Partial or complete loss of hand movement\n- Partial or complete loss of sensation in the fingers\n- Recurrent or unnoticed injury to the hand\nWhen to Contact a Medical Professional\nCall your health care provider if you have symptoms of distal median nerve dysfunction. Early diagnosis and treatment increase the chance of curing or controlling symptoms.\nPrevention varies depending on the cause. In patients with underlying diabetes, controlling blood sugar may reduce the risk of developing nerve disorders.\nIn occupations that require repetitive wrist movements, a change in the way the job is performed may be necessary. Frequent breaks in activity, \"wrist rests\" on keyboards, and other measures may reduce the risk of distal median nerve dysfunction. When possible, avoid prolonged repetitive movement of the wrist.\nJarvik JG, Comstock BA, Kliot M, et al. Surgery versus non-surgical therapy for carpal tunnel syndrome: a randomized parallel-group trial. Lancet. 2009 Sep 26;374(9695):1074-81. PMID: 19782873 www.ncbi.nlm.nih.gov/pubmed/19782873.\nKatirji B, Koontz D. Disorders of peripheral nerves. In: Daroff RB, Fenichel GM, Jankovic J, Mazziotta JC, eds. Bradley's Neurology in Clinical Practice. 6th ed. Philadelphia, PA: Elsevier Saunders; 2012:chap 76.\nReviewed By:Joseph V. Campellone, MD, Department of Neurology, Cooper University Hospital, Camden, NJ. Review provided by VeriMed Healthcare Network. Also reviewed by David Zieve, MD, MHA, Isla Ogilvie, PhD, and the A.D.A.M. Editorial team.\nThe information provided herein should not be used during any medical emergency\nor for the diagnosis or treatment of any medical condition. A licensed medical professional\nshould be consulted for diagnosis and treatment of any and all medical conditions. Call 911\nfor all medical emergencies. Links to other sites are provided for information only -- they\ndo not constitute endorsements of those other sites. © 1997-A.D.A.M., Inc. Any duplication or distribution of the information contained herein is strictly prohibited.\nThe Agency for Health Care Administration (Agency) and this website do not claim the information on, or referred to by, this site is error free. This site may include links to websites of other government agencies or private groups. Our Agency and this website do not control such sites and are not responsible for their content. Reference to or links to any other group, product, service, or information does not mean our Agency or this website approves of that group, product, service, or information.\nAdditionally, while health information provided through this website may be a valuable resource for the public, it is not designed to offer medical advice. Talk with your doctor about medical care questions you may have."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:64cffd16-53df-4775-ae20-f3d104765f0d>","<urn:uuid:efe4a21f-c4f2-4428-9833-127fd1b56d0f>"],"error":null}
{"question":"How do the refueling times compare between the Renault Kangoo hydrogen van and regular electric vehicles?","answer":"The Renault Kangoo hydrogen van can be refueled in just a few minutes at hydrogen fuel stations, which is considerably faster than electric vehicles. While electric vehicles can take hours to charge, and even the fastest chargers take around 30 minutes to fully charge a current EV, hydrogen refueling is similar to filling up a conventional petrol or diesel car in terms of time.","context":["FIFE-based Living Solutions (LS) are going all out this week to increase their ‘green energy footprint’, as they take delivery of their new hybrid Renault Kangoo van*, supplied by local company – Bright Green Hydrogen (BGH).\nThe Levenmouth Community Energy Project - led by BGH in Methil, Fife – is a collaborative initiative supported by Fife Council and Toshiba.\nBegins a spokesperson: “This new industry development involves the facility being created into the world’s foremost demonstrator of hydrogen derived from renewable turbine and solar resources.\n“It is the first project of its kind in Scotland to use green hydrogen to fuel a fleet of hybrid/electric vans to the road.”\nThis new vehicle will add to Living Solutions’ green credentials, as they are already working to create an eco-friendly zero emissions tree-surgery service – as they ramp up their contracting business.\nWorking in collaboration with the Methyl-based company – who run what is believed to be the first green hydrogen project of its kind in Scotland, to provide climate-friendly hybrid/electric vans – BGH aim to deliver an effective green travel scheme in the area to benefit local groups and businesses.\nLiving Solutions leader, Paul Cruise, said: “We are delighted to be involved in this cutting-edge hydrogen vehicle project and see it as a highly innovative way to tackle climate change and carbon emissions, head on.\n“It really will transform business travel in the future as well as our environment. It is great timing for us as we aim to offer a fully green eco-arborist service and this is huge step forward for us.”\nThe Living Solutions van is one of ten electric-powered Renault Kangoo vans with H2 fuel cell range extender which will be 100 per cent zero omissions when it is charged using the green electric vehicle charging stations.\nThe hydrogen gas, stored in the cabin tank, is fed into the fuel cell and when it combines with oxygen, the fuel cell produces electricity to power the electric motor of the vehicle.\nBy converting the original electric model to a hydrogen-electric hybrid van, the range of the vehicle is doubled to a radius of 200 miles.\nThe refuelling process can take place from hydrogen fuel stations, as opposed to electrical charging.\nThis speeds up the process considerably as it is possible to fill the car with the hydrogen gas rather than spending hours on charge.\nBright Green Hydrogen, chief executive, George Archibald, said: “We are delighted to have a local social enterprise on board with our Kangoo leasing scheme.\n“As a community-focused project, this is precisely the sort of customer that we are aspiring to benefit and provide for.\n“This agreement is a great opportunity for Living Solutions to move forward with their own project development and allows them to adapt green travel into their routine.”\nIn due course, two hydrogen refuelling stations will come on stream – one at Bankhead and one in Methil.\nFor contract information:\nPaul Cruise, development manager, firstname.lastname@example.org\nTel: 0845 222 0418\nThistle Industrial Estate\nFife KY4 8LP\nFor information check out the website: www.living-solutions.org and Facebook\nFor further press information contact:\nFiona Stewart, Interwoven PR\nPhotography credit Lesley Martinemail@example.com\nImage: Leader, Paul Cruise, with lead arborist Reece Paterson and apprentice Graham Dodds.\nNotes to editors:\n* The van is a Renault Kangoo Ze Business model, which is an electric vehicle. This model has been converted by hydrogen and fuel cell specialists Symbio, a French company. This conversion includes the addition of a 5kW hydrogen range extender and the installation of a 1.7g hydrogen tank.\nIncreased contracting potential with new Valmet Botex Forestry Tractor and 8-ton forwarding trailer with roof mounted crane and 5-ton winch.\nWe help demonstrate the role the energy efficiency, renewables and hydrogen play in reducing the impact of climate change and securing the world’s future energy supply.\nLiving Solutions Ltd\nA long-established social enterprise based in Fife – focussing on the long-term unemployed – runs an extensive programme of apprenticeship training and takes on 16 people a year through its Rural Skills Academy on Rural Skills apprenticeships.\nA 12-week programme brings apprentices to work ready level and includes training in power pole pruner, wood chipping, chain saw maintenance and cross cutter skills to recognised NPTC and LANTRA national standards of proficiency and has now added arborist training and skills to its training programme.\nMEDIA RELEASE issued by Interwoven PR. You too can share your stories (aka press or media releases), on allmediascotland.com. Email here for more information.\nCheck out twitter.com/newsdipper for your very own media releases feed…\nCheck out too twitter.com/allMotorsPR.\nStay connected with our various twitter feeds: Charities, Drink, Education, Energy, Fashion, Film, Food, Gardens, Legal, Motors, Music, Outdoors, Property, Science and Sports. And not forgetting Finance, Theatre, Travel, Festivals, Visual Arts, Aberdeen, Dundee, Edinburgh, Glasgow, Inverness, Perth and Stirling.\nTo catch up on all the media releases recently posted on to allmediascotland.com, you need only click the link icon that you see towards the bottom right of our two media release ‘gateway boxes’.\nInterwoven PR contact details…","Hydrogen cars: How the fuel cell works, where the UK's filling stations are and how expensive they are to run\nThe Government has announced that it is accelerating the ban on new petrol and diesel cars.\nIt now wants to outlaw the sale of fossil fuel cars by 2035 and has extended its plans to cover hybrid vehicles as well.\nAs a result, a lot of attention has turned to battery electric vehicles (BEVs), which the Government is expecting to fill the gap left by internal combustion cars.\nHowever, alongside BEVs there is another class of zero-emissions car that could help replace conventionally fueled ones - hydrogen fuel cell vehicle (FCEVs).\nWhat is hydrogen fuel cell car?\nSimply put, an FCEV is an electric car where the motor or motors is powered by electricity created by the splitting of hydrogen atoms rather than from a traditional battery stack.\nA fuel cell contains an anode, a cathode, and an electrolyte membrane. Hydrogen passes through the anode, where its molecules are split into protons and electrons. The electrons are forced through a circuit, generating an electric current to power the motor, while the protons pass through the membrane. At the cathode, the electrons are reunited with the protons and oxygen to produce water - a FCEV’s only tailpipe emission.\nHow do you fuel them, where are the filling stations and is it safe?\nAn FCEV has a regular fuel tank and is refuelled in a similar way as a petrol or diesel car is now, from a pressurised storage tank via a fuel filler.\nThe process takes a similar time to refuelling a petrol or diesel car, meaning an FCEV can be refuelled and on its way in a few minutes.\nThose behind FCEVs say it’s just as safe as filling up with a “regular” fuel and car makers put their cars’ hydrogen fuel tanks through even more rigorous testing than standard petrol or diesel. Toyota says its Mirai’s hydrogen fuel tank can absorb five times as much crash energy as a regular petrol tank.\nHowever, there are very few filling stations in the UK. Most are close to the M25 in England’s south-east, with two in Wales, two in Aberdeen, and one each in Coventry, Sheffield, Swindon and on Orkney.\nHow much do hydrogen fuel cell cars cost to run?\nHydrogen cars are expensive to buy. The Hyundai Nexo is around £65,000 and the previous generation Toyota Mirai was a similar price.\nOnce you’ve bought the car, the running costs are also more than for a conventional or BEV car.\nIn the UK, hydrogen fuel costs between £10 and £15 per kg (it’s measured in kilogrammes rather than litres). That means filling a Hyundai Nexo’s 6.33kg tank, which offers around 414 miles of range will cost anywhere between £63 and £95 pounds.\nWith consumption of 0.95kg per 100km (62miles) that means it will cost around £11.40 to cover 100km in a Nexo (at a cost of £12 per kg). An equivalent diesel with economy of 55mpg (5.1l/100km) will cost around £6.72 to cover the same distance.\nCharging a BEV such as the Hyundai Kona, which requires 19.4kWh per 100km, will cost around £3 at 15.5p per kWh.\nWhat are the positives of hydrogen cars?\nHydrogen is the universe’s most abundant substance and can be obtained in a number of ways, making it a readily available fuel source.\nThe advantages of an FCEV over a BEV currently lie in refuelling and range. Filling up a car with hydrogen takes around five minutes while even the fastest chargers will take around 30 minutes to fully charge a current EV.\nFCEV models such as the Hyundai Nexo and Toyota Mirai have a WLTP range of more than 400 miles. Even the longest-range battery EVs can only manage around 300 miles. Linked to the quick refuelling, this gives them an advantage as long-distance vehicles.\nThose backing hydrogen power also argue that fuel cells are better suited to heavier purposes including industrial vehicles such as trains, ships and potentially even planes, where batteries cannot produce the required power or longevity.\nAnd the only tailpipe emission is water, meeting demand for cars that produce no CO2 emissions.\nWhat are the negatives?\nOne of the challenges facing FCEVs at the minute is that there aren’t many hydrogen fuelling stations. Major fuel brands including Shell are moving to install facilities but at the moment there are only 16 in the whole of the UK and fewer than 200 across Europe.\nThere are also questions over the environmental impact of harvesting the hydrogen in the first place. The most common ways to obtain it are by breaking down water through electrolysis or natural gas.\nElectrolysis of water requires electricity, so unless this is 100 per cent renewable there are still CO2 emissions associated with the hydrogen production. Breaking down natural gas also produces carbon dioxide as well as hydrogen. However, those backing FCEVs argue that the CO2 emitted is still far less overall - up to 30 per cent - than in running a conventionally fuelled car.\nPricing is also a major hurdle. The only FCEV currently on sale in the UK costs nearly £70,000 while a BEV with a 280-mile range such as a Hyundai Kona Electric or Kia e-Niro costs almost half that. And there are the relatively high fuelling costs to consider.\nWhat FCEVs are available in Britain?\nThere is currently only one FCEV model on sale in the UK - the Hyundai Nexo - and it costs £65,995.\nToyota’s Mirai was a pioneer in FCEV and a new version of that is due in 2020 but it will cost a similar price.\nThe second generation of Toyota Mirai is due to be launched later in 2020 (Photo: Toyota)\nOther brands are investigating FCEVs but there are no confirmed new models for the UK yet. Mercedes has built the GLC F-Cell SUV but it’s not currently available in the UK and Audi and BMW are planning their own FCEVs but these will not arrive for at least another two years.\nThere is also a homegrown FCEV firm looking to introduce its own car to the market. Riversimple’s Rasa is a compact two-seat car with a range of around 300 miles. The company has produced several prototypes and plans to offer the car on a lease-only arrangement but it is not currently available to the public.\nDo hydrogen cars have a future?\nTesla’s Elon Musk has dismissed FCEVs as “incredibly dumb” but, as a man who owns a battery electric car company, that’s hardly surprising.\nHe argues producing hydrogen fuel is less efficient that producing electricity for battery EVs. The counter argument is that hydrogen can be produced in a zero-emissions manner and offers the convenience of quicker fuelling and longer range than lithium-ion powered EVs.\nThe big question for FCEV is are they too late to the party? Battery EVs like the Nissan Leaf, Tesla Model 3 and Jaguar I-Pace are increasingly commonplace on our roads and the UK Government has clearly thrown its weight behind plug-in vehicles with the promise of £400m to expand charging infrastructure. What’s more, EV range and charging abilities are improving all the time. The new Leaf can hit 80 per cent charge in as little as an hour and VW says its ID3 all-electric hatchback will do up to 341 miles on a charge.\nHyundai, Kia and Toyota say their latest FCEVs are fully commercial viable vehicles with realistic lifespans, unlike the early examples, but they’re already playing catch-up. In their favour, the longer range and rapid refuelling ease many of the worries motorists have around EVs but that’s only relevant if there are enough fuelling stations.\nThere’s also the expense. You can get a Leaf or Zoe for less than £30k but the Nexo costs more than £65,000 and the new Mirai likely to be a similar price. Hyundai/Kia’s head of FCEV research Dr Sae-Hoon Kim argues that the more people who buy FCEVs, the cheaper they’ll get but, as with the fuelling stations there’s a chicken and egg scenario where people will only start to buy them when they reach mainstream prices."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:f1a014f4-a054-4aa3-add2-3ccdec3fd4bb>","<urn:uuid:a7b2e7f4-367a-41f7-9c39-b6a8938235e4>"],"error":null}
{"question":"How does Venus' atmosphere affect the detection of volcanic activity through sulphur dioxide measurements?","answer":"Venus' 'super-rotating' atmosphere, which circles the planet every four Earth-days (much faster than Venus' 243-day rotation), spreads sulphur dioxide around the planet. This makes it difficult to isolate individual sources of the gas. Additionally, most sulphur dioxide remains hidden below Venus' dense upper cloud deck because the gas is quickly destroyed by sunlight in the upper atmosphere. When sulphur dioxide is detected in the upper atmosphere, it must have been recently transported there, as individual molecules are destroyed within a couple of days.","context":["The thick atmosphere of Venus contains over a million times as much sulphur dioxide as Earth’s, where almost all of the pungent, toxic gas is generated by volcanic activity. Most of the sulphur dioxide on Venus is hidden below the planet’s dense upper cloud deck, because the gas is readily destroyed by sunlight. Six years of observations by ESA’s Venus Express have led NASA astronomers to the intriguing possiblity of live active volcanic eruptions that created the sulphur dioxide detected in Venus’ upper atmosphere above the cloud deck.\nNow, an analysis of sulphur dioxide concentration in the upper atmosphere over six years provides another clue. Immediately after arriving at Venus in 2006, the spacecraft recorded a significant increase in the average density of sulphur dioxide in the upper atmosphere, followed by a sharp decrease to values roughly ten times lower by today. A similar fall was also seen during NASA’s Pioneer Venus mission, which orbited the planet from 1978 to 1992. At that time, the preferred explanation was an earlier injection of sulphur dioxide from one or more volcanoes, with Pioneer Venus arriving in time for the decline.\n“If you see a sulphur dioxide increase in the upper atmosphere, you know that something has brought it up recently, because individual molecules are destroyed there by sunlight after just a couple of days,” says Dr Emmanuel Marcq of Laboratoire Atmosphères, Milieux, Observations Spatiales, France, and lead author of the paper published in Nature Geoscience.\n“A volcanic eruption could act like a piston to blast sulphur dioxide up to these levels, but peculiarities in the circulation of the planet that we don’t yet fully understand could also mix the gas to reproduce the same result,” adds co-author Dr Jean-Loup Bertaux, Principal Investigator for the instrument on Venus Express that made the detections.\nVenus has a ‘super-rotating’ atmosphere that whips around the planet in just four Earth-days, much faster than the 243 days the planet takes to complete one rotation about its axis, which spreads the sulphur dioxide around, making it difficult to isolate any individual points of origin for the gas.\nMarcq’s team speculate that if volcanism was responsible for the initial increase, then it could come from a relatively gentle increased output of several active volcanoes rather than one dramatic eruption.*“Alternatively, and taking into account the similar trend observed by Pioneer Venus, it’s possible that we are seeing decadal-scale variability in the circulation of the atmosphere, which is turning out to be even more complex than we could ever have imagined,” he notes.\n“By following clues left by trace gases in the atmosphere, we are uncovering the way Venus works, which could point us to the smoking gun of active volcanism,” adds Håkan Svedhem, ESA’s Project Scientist for Venus Express.\nThe image at the top of the page is 3-d construction of a portion of Western Eistla Regio of Venus. Lava flows extend for hundreds of kilometers across the fractured plains shown in the foreground, to the base of Gula Mons, a 3 kilometer (1.86 mile) high volcano and Sif Mons, a volcano with a diameter of 300 kilometers (180 miles) and a height of 2 kilometers (1.2 miles). The distance between Sif Mons and Gula Mons is approximately 730 kilometers (453 miles). Simulated color and a digital elevation map developed by Randy Kirk of the U.S. Geological Survey, were used to enhance small scale structure. The simulated hues are based on color images recorded by the Soviet Venera 13 and 14 spacecraft. The image was produced at the JPL Multimission Image Processing Laboratory by Eric De Jong, Jeff Hall, and Myche McAuley.\nThe Daily Galaxy via Venus Express Mission"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:21bb21ef-abdf-4f1c-8075-a5e3b8b9caa3>"],"error":null}
{"question":"As an art history student, I'm wondering how Abstract Expressionism and Minimalism differ in their artistic philosophies?","answer":"Abstract Expressionism and Minimalism represent contrasting artistic philosophies. Abstract Expressionism, emerging in the mid-20th century, emphasized spontaneous improvisation, emotional expression, and individuality. Abstract Expressionist artists created loosely structured works focusing on sensual and psychological subjects, often working with spontaneous techniques like Pollock's 'drip and splash' style. In contrast, Minimalism, which emerged in the early 1960s, focused on stark reduction and geometric simplicity. Minimalist artists emphasized the viewer's direct experience with the work over self-expression, using simple geometric forms and industrial processes. They rejected expressive content in favor of modular units and precise execution.","context":["Werner Hammerstingl ©1998\nExpressionism, in general, describes the artist's philosophical perspective concerning the purpose of their art more than specifically defining their method.\nWebster's dictionary on WWW, Main Entry: abstract expressionism Function: noun Date: 1951 : an artistic movement of the mid-20th century comprising diverse styles and techniques and emphasizing especially an artist's liberty to convey attitudes and emotions through nontraditional and usually nonrepresentational means - abstract expressionist noun or adjective\nThe movement of abstract expressionism originating in the middle of the twentieth century was an approach to modernism/ post-modernism accentuating the uninhibited expression of emotions. The products of this genre are characteristically free and loosely structured, stylistically. They tend to focus on the sensual and psychological subjects, but as abstractions, essentially avoid any clear representational imitation of reality.\nHowever great a disaster World War II was, it did at least mean that artists such as Paul Klee, Marcel Duchamp, Piet Mondrian and Max Ernst, in leaving Europe for the safety of the USA, greatly extended their artistic influence. It is impossible to estimate how much they affected American art, but the fact remains that in the 1940s and '50s, for the first time, American artists became internationally important with their new vision and new artistic vocabulary, known as Abstract Expressionism.\nThe first public exhibitions of work by the ``New York School'' of artists-- who were to become known as Abstract Expressionists-- were held in the mid '40s. Like many other modern movements, Abstract Expressionism does not describe any one particular style, but rather a general attitude; not all the work was abstract, nor was it all expressive. What these artists did have in common were morally loaded themes, often heavyweight and tragic, on a grand scale. In contrast to the themes of social realism and regional life that characterized American art of previous decades, these artists valued, above all, individuality and spontaneous improvisation. They felt ill at ease with conventional subjects and styles, neither of which could adequately convey their new vision. In fact, style as such almost ceased to exist with the Abstract Expressionists, and they drew their inspiration from all directions.\nThe painters who came to be called ``Abstract Expressionists'' shared a similarity of outlook rather than of style-- an outlook characterized by a spirit of revolt and a belief in freedom of expression. The main exponents of the genre were\nbut other artists included\nThe term Abstract Expressionism was first used by Robert Coates in the March issue of the New Yorker in 1936. The movement was hugely successful, partly due to the efforts of the critics Harold Rosenberg and Clement Greenberg who also originated the terms Action Painting and American Style.\nStella's works have been called critical rebellion against abstract expressionism as well as heralded as examples of it. The works of Frank Stella have evolved to exhibit the extravagant designs, wild flourishes, and vivid, variety of the chromatic spectrum that makes him an expressionist. But on the surface, his first works seem hardly effusive or passionate. Still, even the minimal, geometric patterns of his early work must not be dismissed as simple and cold. They hint at the deep mystery and illusion as he breaks the structure of framing and two-dimensional ground and maintains personality of line even in the deceptively hard-edge Black and Metallic exhibit. His more recent pieces, high relief collages and metallic sculpture, are more clearly bold, progressive works influenced by abstract expressionism.\nPollock, Jackson (1912-56). American painter, the commanding figure of the Abstract Expressionist movement.(also known as Jack the dripper)\n``On the floor I am more at ease, I feel nearer, more a part of the painting, since this way I can walk around in it, work from the four sides and be literally `in' the painting.'' -- Jackson Pollock, 1947.\nHe began to study painting in 1929 at the Art Students' League, New York, under the Regionalist painter Thomas Hart Benton. During the 1930s he worked in the manner of the Regionalists, being influenced also by the Mexican muralist painters (Orozco, Rivera, Siqueiros) and by certain aspects of Surrealism. From 1938 to 1942 he worked for the Federal Art Project. By the mid 1940s he was painting in a completely abstract manner, and the `drip and splash' style for which he is best known emerged with some abruptness in 1947. Instead of using the traditional easel he affixed his canvas to the floor or the wall and poured and dripped his paint from a can; instead of using brushes he manipulated it with `sticks, trowels or knives' (to use his own words), sometimes obtaining a heavy impasto by an admixture of `sand, broken glass or other foreign matter'. This manner of Action painting had in common with Surrealist theories of automatism that it was supposed by artists and critics alike to result in a direct expression or revelation of the unconscious moods of the artist.\nPollock's name is also associated with the introduction of the All-over style of painting which avoids any points of emphasis or identifiable parts within the whole canvas and therefore abandons the traditional idea of composition in terms of relations among parts. The design of his painting had no relation to the shape or size of the canvas -- indeed in the finished work the canvas was sometimes docked or trimmed to suit the image. All these characteristics were important for the new American painting which matured in the late 1940s and early 1950s. Action painting: Pollock was the first ``all-over'' painter, pouring paint rather than using brushes and a palette, and abandoning all conventions of a central motif. He danced in semi-ecstasy over canvases spread across the floor, lost in his patternings, dripping and dribbling with total control. He said: ``The painting has a life of its own. I try to let it come through.'' He painted no image, just ``action'', though ``action painting'' seems an inadequate term for the finished result of his creative process. Lavender Mist is 3 m long (nearly 10 ft), a vast expanse on a heroic scale. It is alive with colored scribble, spattered lines moving this way and that, now thickening, now trailing off to a slender skein. The eye is kept continually eager, not allowed to rest on any particular area. Pollock has put his hands into paint and placed them at the top right-- an instinctive gesture eerily reminiscent of cave painters who did the same. The overall tone is a pale lavender, maide airy and active. At the time Pollock was heiled as the greatest American painter, but there are already those who feel his work is not holding up in every respect.\nLee Krasner (1908-84), who married Pollock in 1944, was not celebrated at all during her lifetime (cut short in 1956 by a fatal car crash), but it was actually she who first started covering the canvas with a passionate flurry of marks. The originality of her vision, its stiff integrity and its great sense of internal cohesion, is now beginning to be recognized. Cobalt Night (1962; 237 x 401 cm (7 ft 9 1/3 x 13 ft 2 in)) at 4 m (over 13 ft) is even larger than Lavender Mist and has the same kind of heroic ambition.\n1950 Change was in the air and on the walls. Europe's boldest artistic experiments had become almost mainstream. Startling innovations were being experimented in America by artists like Jackson Pollock, and Willem de Kooning to term the radical art movement Abstract expressionism. Abstract expressionism would take America by surprise. A leading New York School painter, Jackson Pollock (also known as Jack the dripper) delved into Karl Jung's theory of the collective unconsciouness. During this time modern paintings were to say the least abstract, and often dealt with the artists psyche and state of mind when the painting was created.\nLike movements in time, abstract expressionism would develop a new and improved look (so to speak). If abstract expressionism was to be thought of as abstract, hard edge painters took out the \"abstract\" in painting. Hard edge paintings exhibited calculated, impersonal expressionism; instead of spontaneous, subjective abstract expressionism. Hard edge painters preferred sharply contoured, simple forms. The paintings are termed as \"precise and cool\", as if made by machines. Frank Stella perfectly describes Hard edge painting as: \"What you see is what you see\".......","This installation examines the legacies of Minimal art through the Nashers' support in the 1970s of artists including Siah Armajani, Martin Puryear, and Christopher Wilmarth, as well as the recent acquisition of a sculpture by Judy Chicago.\nAbout Track 3: The Ends of Minimalism\nIn the early 1960s, a number of artists in different places began making sculptures that appeared starkly reductive. Created from simple, geometric, modular units and often fabricated using industrial processes and materials, such objects led observers to describe them in a variety of ways, but Minimalism soon emerged as the leading designation for what became one of the most influential developments in twentieth-century art. Artists associated with Minimalism, such as Donald Judd, Robert Morris, and Carl Andre emphasized the viewer’s visceral, direct experience with their work over its potential for self-expressive content, and they rejected modern art of the past as largely irrelevant to their concerns. While many of them had strong political beliefs, these were set aside in the creation of their art.\nWhen Raymond and Patsy Nasher began collecting sculpture in the late 1960s, reactions to Minimalism were just beginning to coalesce among a new generation of artists—sometimes called Post-Minimalists—who bridled against its restrictions even as they drew inspiration from its example. As Patsy in particular became more interested in contemporary art in the 1970s, among the younger artists whose work attracted the couple’s attention were individuals wrestling with various facets of Minimalism’s legacy.\nIn the tensions between Minimalism and the ends to which artists have put it, the Nasher’s recently acquired sculpture by Judy Chicago plays a special role. With its geometric forms fabricated in aluminum and coated with vibrantly hued automotive paint, Rearrangeable Rainbow Blocks exemplifies essential qualities of Minimal art but proposes a subversive twist. Taking its modular logic to a singularly playful conclusion, Chicago pushed past Minimalism’s constraints by stating her sculpture’s perpetual susceptibility to reconfiguration, as if it were an enormous set of children’s blocks.\nHear different perspectives on works in Track 3: The Ends of Minimalism.\nOverview of The Ends of Minimalism\nMaren Hassinger on Repetition in Minimalism\nJoel Shapiro on Scale and Architecture\nDiscover more about sculpture. Find bonus content like video tours, inspiration playlists, and insights from curators, educators, and living artists.\nBest of The Ends of Minimalism\nBringing together the greatest hits of Track 3: The Ends of Minimalism artists and themes.\nVideo: Judy Chicago Lecture Highlights\nTop recommendations to dig deeper into your favorite artworks and art trends.\nVideo: Artists Within Institution: Scholar Lewis Kachur speaks about Scott Burton\nVideo: Judy Chicago in conversation with Sarah Thornton: 3D Liberation\nVideo: Sheila Hicks and Giving Material Form to Color\nSuggested resources for families, educators, and the young at heart.\nTeacher Resource: Joel Shapiro\nVideo: Night and Day Embroidery Art Activity with Artist Mylan Nguyen\nListen to a music playlist inspired by artworks in Track 3: The Ends of Minimalism.\nListen on Spotify.\nExplore the Collection\n- Siah Armajani, Dictionary for Building: Door in Window #2, 1982-83\n- Scott Burton, Untitled: Two Chairs, 1979\n- Judy Chicago, Rearrangeable Rainbow Blocks, 1965\n- Martin Puryear, Night and Day, 1984\n- Joel Shapiro, Untitled, 1975\n- William Tucker, Building a Wall in the Air, 1978\n- Sheila Hicks, Menhir, 2018 (long-term loan)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:7ba8feea-6682-4256-9d25-8a9c6652dca9>","<urn:uuid:4e11f1b0-a73d-4c1e-bc15-c6d1238da985>"],"error":null}
{"question":"As someone who works with housing facilities, I'm wondering - what are the security measures like at the Seattle Ronald McDonald House compared to typical business establishments with service animals? 🏠","answer":"The Ronald McDonald House has more stringent security measures since it houses vulnerable children - they require ID for all registered adults, wristband wearing, screening for safety/security issues and infectious diseases, and mandatory adult supervision for anyone under 18. In contrast, typical business establishments mainly focus on service animal regulations - they can only inquire if an animal is a service animal and what task it performs, cannot ask about disabilities or demand certifications, and must allow properly behaving service animals in all customer areas. The key difference is that RMH's security goes beyond just service animal policies to protect their medically fragile residents.","context":["KNOW THE LAW REGARDING SERVICE ANIMALS IN A BUSINESS ESTABLISHMENT\nJuly 14, 2016\nDuring the middle of a business rush, someone walks in with their dog. A small child is in the building and becomes frightened of the animal. Their parent comes to the rescue of their child and requests the removal of the canine due to the safety concerns. The animal is wearing a vest, is behaving calmly, and the patron additionally produces a service handler identification. Having knowledge of business operations regarding service animals can prevent any potential future backlash.\nWHAT IS A SERVICE ANIMAL?\nThe Americans with Disabilities Act governs many service animal concerns and defines a service animal as any animal that performs a function or a task that the handler is unable to perform due to a disability. The mental image that most commonly comes to mind is a guide dog for someone who is blind, yet dogs and other service animals can provide a multitude of other services due to their high levels of intelligence. Examples of service animal assistance include:\nAlerting a handler with hearing impairments to sounds;\nPulling a wheelchair;\nCarrying or picking up items for someone with mobility disabilities; and\nAssisting with emotional stability for someone with a mental ailment.\nTHE LEGAL ANSWER\nAccording to the ADA, businesses and organizations that serve the public must allow people with disabilities to bring their service animals into all areas of the facility where customers are normally allowed to go. The federal statute applies to all businesses open to the public, including restaurants, hotels, taxis and shuttles, grocery and department stores, hospitals and medical offices, theaters, health clubs, parks, and zoos. Such animals are not “pets”, they are trained working animals. Therefore, any posted pet restrictions for the establishment do not apply and should be altered to compensate for service animals.\nCAN SERVICE ANIMALS BE PROHIBITED OR REMOVED?\nIn the hypothetical situation of the service animal and the child being scared, the answer is no; the animal can not be asked to leave. Additionally, they may not be called upon to leave or denied service even if someone has an allergy. If this is the case and the two must spend an extended amount of time together, reasonable accommodations must be made to both patrons. Other guidelines include:\nMany service animals have a vest or collar identification, but it is not required, nor is it required that the animal is tethered or otherwise harnessed. The only requirement to this is that the animal is under control, even if that control is verbal or visual;\nA formal request for the removal of the animal is legal if the animal is not able to be controlled or is not housebroken, in which case service must still be offered in such a way that the animal is not required; and\nThe only questions that may be asked are if the animal is a service animal for a disability and what the life task is that the animal performs. It is not legal to ask about the disability or for a display of certifications.\nThe laws surrounding service animals are in-depth and extensive. With the broad array of qualifications for each category of services animals can perform, it is beneficial to discuss this topic with an experienced business lawyer. Doing this before an issue arises may prevent future legal headaches. If you are interested in speaking with a proven San Jose, CA business attorney, contact The Law Offices of Steven E. Springer today at 408-779-4700 to schedule a 20 minute free initial consultation. To better serve our clients, we also have offices in Morgan Hill and Fremont.","Frequently Asked Questions\nRonald McDonald House Charities (RMHC) of Western Washington & Alaska is a nonprofit 501 (c)(3) organization and a chapter of the global RMHC. Our cornerstone is the Seattle Ronald McDonald House which provides a caring \"home-away-from-home\" for families of seriously ill children being treated at Seattle Children’s. RMHC extends its reach by also providing van transportation to families staying in Anchorage while their children receive treatment. Back to top\nThe House is owned and operated by Ronald McDonald House Charities of Western Washington & Alaska and is governed by a local Board of Directors. Back to top\nRonald McDonald House Charities of Western Washington & Alaska has a paid staff that runs the day-to-day operations. They are supported by volunteers. Back to top\nCurrently, there are more than 300 Ronald McDonald Houses throughout the United States and world. All operate under licensing guidelines from the global Ronald McDonald House Charities. However, each Ronald McDonald House is independently operated. Back to top\nThe Seattle House can accommodate 80 families each night in three buildings. House A houses 48 families; House C houses 22 families, and our Bone Marrow Transplant Apartments are self-contained units for 10 families. These facilities are within walking distance of Children's Hospital. Back to top\nBy generous supporters like you! Over 75 percent of our operating funds come from individuals, organizations and businesses in the Pacific Northwest and Alaska. It costs about $4 million annually to operate RMHC. The majority of that amount is raised through individual and corporate donations. These include events, grants, will bequests, property and goods donations. Back to top\nLocal McDonald’s restaurant owner/operators and the McDonald's Corporation fund 24 percent of our annual operating costs. This funding includes in-store canister donations and newspaper sales, promotions and annual gifts from McDonald's restaurant owner/operators. Back to top\nBy donating and volunteering! We could not operate the House without donations from individuals and groups. Our volunteers are the heart and soul of our House - and the reason we can accomplish so much with such a small staff. Back to top\nFamilies of seriously ill children undergoing medical treatment at Children's Hospital who live more than 45 miles from Seattle may stay at the House. Most of our families come from Washington, Alaska, Montana and Idaho. However, we serve families from throughout the U.S. and world. See our housing eligibility guidelines. Back to top\nWe ask families to contribute $30 per night to stay at the House, but no is ever turned away for financial reasons. In contrast, it costs $135 per night to house a family. Thanks to your support, we never turn a family away because of their inability to contribute financially. Back to top\nIt varies greatly, depending on the child's illness and treatment. Stays may last several weeks to several months and even extend to a year or more. Back to top\nVolunteers are vital to our operation as they work the front desk and greet visitors, help in family services and help with cleaning and day-to-day operations. They also organize fundraisers, cook dinners and sponsor activities for the families. Back to top\nRMHC of Western Washington & Alaska has a $3.4 million operating budget. This is used for maintaining and operating the Ronald McDonald House every day of the year. Back to top\nTo qualify, your child, aged 21 and under, must be admitted to or have an appointment at Seattle Children's Hospital. You must live at least 45 miles away from Seattle Ronald McDonald House, and have a stay of 4 nights or more. Back to top\nParents, legal guardians, and other immediate family members are welcome to stay. Back to top\nFamily income is not a consideration for admittance. All families are requested to pay $30 a night towards the cost of their stay; however, no one is ever turned away due to financial reasons. Back to top\nOnly one room will be provided to each family, and the maximum occupancy per room is 6 people. Back to top\nRooms in House A and House C each have two twin or queen size beds, a private bathroom, closet space and dresser, television/DVD, telephone with direct phone number and high-speed DSL internet access.\nHouse B has 10 self-sufficient apartments reserved for families with children who have received a stem cell or bone marrow transplant. Back to top\nThe safety of our families is very important.\n- Identification will be required for all registered adults and all adult guests are asked to wear green wristbands while in the House.\n- Every family will be screened for current or past safety or security issues.\n- All families are screened to prevent infectious diseases being brought into the House.\n- Anyone under the age of 18 must be accompanied by an adult relative or legal guardian. Back to top\nUp to two weeks before your arrival, you can contact our Housing Office at (206) 838-0610 to get your information into our system. Emergent and unplanned requests are also accepted on a daily basis. Staff will then contact you 24 hours before your arrival to let you know if a room is available. We do not take advance reservations because we never know how long a child may need to be in the hospital. As our House is normally full, we encourage families to call Seattle Guest Services Department at (206) 987-9330 or toll free at 1-866-987-9330 to inquire about other housing options. Back to top\nCheck-in time is between 9 a.m. and 8 p.m. seven days a week. Back to top\nWithin 24 hours of your arrival or when a room becomes available for your family, a Housing Coordinator will contact your family to schedule a time for your family to check into the House. Check in hours are between 9 a.m. and 8 p.m. daily. When you arrive, staff will request a photo ID for all adult guests staying in your room. The House Manager will then review the House Rules, ask you to agree to the rules by signing the appropriate paperwork and then will provide a tour of the House. Back to top\nAs long as a child is being treated at Children's Hospital, families are welcome to stay at the Ronald McDonald House. Eligibility is based on appointment schedules and medical status, and is reviewed at least every 30 days. Back to top\nHouse A and House C each have a communal kitchen and pantry of non-perishable foods that are offered for free to all families. Each family has refrigerator and cupboard space where personal food can be stored. Outside volunteer groups regularly visit the House to make dinners for the families. Free coffee and Coke products are available in vending machines. There is no eating allowed in the rooms or anywhere in the House outside of the kitchen and dining room. Back to top\nThere is an RMHC van and volunteer drivers who occasionally take families on outings and shopping trips. Children's Hospital provides a complimentary shuttle between the House and the hospital by request; however, the hospital is within walking distance. Back to top\nYes. Groups regularly visit the House to make dinner for the families. There are outings to events and shopping. Movie nights, arts and crafts, visits by Pet Therapy dogs and other activities occur on a regular basis. Back to top\nVisiting hours are between 9 a.m. and 8 p.m. Visitors are welcome, but must sign in and out at the front desk. The children living at Ronald McDonald House are medically fragile and highly susceptible to infections. Please do not plan on coming to the House if, within the last month, you or any family members have been exposed to: chicken pox, shingles, measles, tuberculosis, influenza or flu, hepatitis A or any other infectious disease such as e. coli, or if you have any of the following symptoms: sore throat, runny nose, watery eyes, cough, fever, chills, unexplained rash, general aches, nausea, vomiteing, diarrhea. If you received the flu mist, the anti-flu nose spray vaccine within the last seven days, you may not enter the House. Back to top\nYes. All mail and packages should be addressed to your room as follows: Your child's name (patient) and Building/Room Number, Ronald McDonald House, 5130 40th Avenue NE, Seattle, WA 98105. Mail is delivered Monday - Friday.\nThere is no smoking anywhere in the House. A Washington State law prohibits indoor smoking and smoking within 25 feet of any entrance. After dark, families are allowed to smoke in the designated smoking area. Back to top\nNo. Towels, blankets, and other linens are provided; however, families are responsible for laundering them. Back to top\nNo. Families actively participate in keeping the House clean and tidy. Families are responsible for keeping their room in good condition, cleaning up after their family members in all areas of the House, washing their linens as needed, and cleaning their room before leaving so it is ready for the next family. Back to top\nNo. Parents are required to be responsible for their own children and provide supervision at all times. Back to top\nThe House is open 24 hours a day for families staying here to come and go. Visiting hours are between 9 a.m. and 8 p.m. Back to top\nOnly service animals are allowed in the House and require advance approval. Back to top"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:8d6cdf36-cb49-417a-ace8-4c946504cc6f>","<urn:uuid:c820ec7c-7460-4c46-8a74-f05d86a4ca35>"],"error":null}
{"question":"What are food webs in nature, and how do they contribute to the emergence of new diseases in humans?","answer":"A food web is a description of which species eat which other species, illustrated like a roadmap with arrows showing energy flow between species. In the context of disease emergence, food webs are particularly important because humans can become part of these networks through our consumption of animals, which puts us at risk of being 'eaten' by infectious agents that affect those animals. For example, when humans consume animals like ducks, pigs, or cattle, we can become infected by viruses, bacteria, and other parasites that normally affect these animals. The emergence of new diseases is often linked to changes in how humans interact with these food webs, particularly through agricultural practices, population growth, and urbanization. Nearly 60% of human infectious diseases originated in animals, and scientists estimate there are around 300,000 unknown pathogens that could potentially spread from animals to humans.","context":["Question: What is a “food web?”\nJoel Cohen: A food web is a description of which species living in a place eat which other species. You can think of it like a roadmap with one-way streets. It shows you, if there's an arrow from A to B, it means the energy flows from A to B, or in other words, B eats A, okay? So it's usually drawn with a bunch of circles, you put the name of a species in the circle and then you draw an arrow showing which way the food is flowing. Okay? That's what a food web is.\nNow, we have just been talking about a food web. We've been talking about the food web in which people eat ducks, geese, swine, cattle, okay? And, what most people don't realize is, the things that eat us are the infectious diseases, like the viruses and the bacteria and the worms and the other parasites, much more important than the lions and the tigers.\nAnd what I've been studying is how the animals we eat put us at risk of being eaten by the infectious agents that eat those animals. So when we eat the duck, it puts us at risk of being eaten by the virus that eats the duck, the H5N1. But let me give you some other examples, okay? The monkeys that live in the forests of west Africa, have long been infected by a virus called the simian influenza—sorry, simian immunodeficiency virus. Okay? SIV. We now believe that people went hunting for those monkeys and either got the blood in their hands or ate them without cooking them fully, and the simian immunodeficiency virus infected the people who were dealing with the blood from those animals and evolved very slightly, because we can compare the genes, and gave us the human immunodeficiency virus, HIV. So by going into a new habitat, eating the monkeys and getting their blood, the things that were eating the monkeys turned to eating us. That's the current understanding of the origin of HIV. It was going after food in the forest.\nAnother, okay, do you follow that? We've talked about avian influenza, that's from the expansion into new habitats. Another example is swine flu and trichinosis. We eat the pigs, the worms of trichinosis, if they're not cooked to death and we eat uncooked ham or pork, they start infecting the people. The influenza that swine have infects the people who live with the swine. A last example, mad cow disease. Mad cow disease is a prion that causes bovine spongiform encephalitis, BES. If you eat the flesh of a cow that has been eaten by one of those prions, it will eat you, and then you get Jackob Creutzfeldt disease.\nAnd, so there's a World Health Organization for animals, did you know that? Probably not. It's World Organization for Animal Health, it's called, and they have a long list of what are called zoonotic diseases. And a zoonotic disease is a disease that regularly infects vertebrates and will also infect people if they are exposed to it. And many, many, many of those zoonotic diseases are diseases that arise because we raise domestic animals for meat. So there's a connection with the meat and our health that's very close.","This article was originally published on The Conversation. It is also the third and final article in our disease evolution package. Click here to read the first: Disease evolution: our long history of fighting viruses and second instalments: Disease evolution: the origins of anorexia and how it’s shaped by culture and time.\nHumans have been “acquiring” infectious diseases from animals (zoonotic diseases) since we first started hunting wild game on the African savannahs. Indeed, nearly 60% of bugs that infect humans originated in animals.\nThese days, we seem to see more “new” diseases, such as Zika, Ebola and SARS. But there are plenty more lurking. A recent study suggests there are around 300,000 pathogens we don’t even know about and some have the potential to spread from animals to humans.\nThe world’s scientific community is focused on how to improve detection and responses to emerging diseases such as Zika virus and Ebola. So what can we learn from the most recent large-scale outbreaks?\nThe three most common factors associated with the emergence of diseases are:\nchanges in land use for agricultural practices\nchanges in human demography, such as population growth and urbanization\npoor population health and health services.\nThese factors are often interlinked and can turn a small “spillover” outbreak from animals into a major epidemic, as seen in the most recent Ebola epidemic.\nEssentially, humans put themselves in harm’s way just by going about their daily business of growing or harvesting food and seeking shelter.\nEbola is caused by a virus thought to be carried in fruit bats that spills over into other mammals such as primates and antelope.\nHumans are infected when they hunt or butcher animals for food or consume uncooked fresh or dried bushmeat.\nHuman-to-human transmission involves close contact with bodily fluids. This often happens in health-care settings and when people care for sick relatives or perform traditional burial practices that involve direct contact with bodies.\nThe 2014 outbreak in West Africa, which caused more than 28,000 infections and 11,000 deaths, was a sudden departure from the usual picture of small, localized outbreaks in remote areas because of a “perfect storm” of factors.\nThe war-torn countries involved experienced a dramatic increase in population growth, high levels of urbanization, increases in agricultural production (especially livestock) and associated changes in land use and land clearing.\nOn top of that, they had very few health services (reportedly just 50 doctors in the whole of Liberia), especially in rural areas. This combined with the widespread consumption of bushmeat, traditional burial practices and rapid transport networks to drive the outbreak.\nIt’s not hard to see why the spread from rural areas to cities occurred so rapidly; where else would people go for help?\nSevere acute respiratory syndrome (SARS) was the defining emerging disease of the 21st century. Caused by a highly infectious coronavirus, it was a global shock which demonstrated how quickly diseases can spread around the world.\nThe spread of SARS was greatly accelerated by geography. It was first detected in Guangdong Province in China but it spread from nearby Hong Kong via a vast network of international air travel.\nThe natural host of SARS is thought to be bats. But the jump to humans occurred via the palm civet, a small omnivorous mammal.\nCivets are a delicacy and eating them is a sign of wealth in Cantonese culture. At the time, civets were slaughtered for local consumption at restaurants specializing in wild game. One of the first cases was a cook in Shenzen.\nThe live animal markets bring together a bewildering array of animal species and are critical junctures between rural and urban communities. This is where one-third of cases originated.\nZika virus is the latest emerging disease to hit the news. It was first isolated from a rhesus monkey in the Zika forest of Uganda in 1947 by scientists studying the closely related yellow fever virus.\nLike its relative the dengue virus, Zika’s usual cycle of mosquito-monkey-mosquito expanded to include humans when we entered their ecological niche to collect food or for shelter.\nThe human disease caused by Zika had remained largely invisible since its first identification in 1954. Its recent “emergence” may just be a response to its higher profile after the discovery that infection during pregnancy is associated with the birth defect microcephaly, which causes babies to be born with unusually small heads.\nZika virus will continue to quietly spread around the world via air travel and establish in more countries because its mosquito carrier, Aedes aegypti, is present in more than 128 countries including parts of Europe, the United States and Australia.\nWhy did these diseases jump species?\nThe common theme in the spillover of each of these viruses is food; they are a consequence of the human need for protein.\nOnce the viruses make the species jump, their severity is a major factor in what happens next. It is easier for a mild disease such as Zika to spread unnoticed in a population because it is unlikely to lead a person to seek medical attention.\nWhen disease is severe (think rapid hospitalization and death), such as Ebola or SARS, it tends to make itself known more rapidly, triggering an aggressive public health response that can lead to suppression of the outbreak.\nThe rapid spread of SARS by international air travel to wealthy countries with effective public health systems was a major factor in its limited duration compared with Ebola, which largely remained in a limited geographic range. Ebola may well have become a global pandemic if it had occurred in a major international transport hub.\nPreventing disease outbreaks\nThe world will not prevent the next global pandemic using “business as usual” thinking. We need to acknowledge we live in a rapidly converging world where solutions cross all sectors of society.\nMajor cross-sectoral initiatives, such as the US government’s Emerging Pandemic Threats program, are making some progress. This program attempts to create national, regional and global “One Health” networks to reduce the risk of disease emergence and improve our ability to detect and respond to these unpredictable beasts.\nBut this is not enough because the emergence of diseases is largely driven by changes in human societies. The only thing that will change the drivers of disease is a fundamental rethink about how we co-exist with our environment.\nUnfortunately, there are no easy answers to how we build and feed a global community of 9 billion and not cause an emerging disease disaster along the way.\nWe picked linked items based on the quality of products, and list the pros and cons of each to help you determine which will work best for you. We partner with some of the companies that sell these products, which means we and our partners may receive a portion of revenues if you make a purchase using a link(s) above."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:e6f1731f-5f3c-4aa8-96bf-8732ffa1946e>","<urn:uuid:61b4fcb2-a5b2-4cee-b3a3-83a732ddd797>"],"error":null}
{"question":"What are the main problems affecting food systems globally, and how is Indonesia's food estate program impacting local farmers' food security?","answer":"Global food systems face three main problems: the 'last mile' problem where isolated populations struggle to access affordable nutritious food; the 'bad year' problem when crop failures force families to adopt harmful coping strategies; and the 'good year' problem where inadequate storage and transport infrastructure causes food waste and price drops. In Indonesia's case, the food estate program, despite aiming to improve domestic food availability, has actually worsened food security for local farmers. In North Sumatra, farmers who were asked to grow alternative crops like potatoes and garlic saw their rice harvests decline by up to 70%. This decline wasn't offset by the new crops due to lower prices, leading to 30% of households lacking sufficient rice for the year.","context":["© WFP/Diego Fernandez\nThe fact that almost 800 million people are chronically hungry across the world suggests that food systems – the networks that are needed to produce and transform food, and ensure it reaches consumers – are not meeting the needs of large sections of society. Improving the performance of food systems and their ability to cater even for the poorest will therefore be key to achieving Zero Hunger.\nFlawed or broken food systems can affect food security in a number of ways. They can drive prices up, making it difficult for the poorest to afford nutritious food, or prevent smallholder farmers from making good profits from their crops.\nFood system disruptions can be linked to shocks related to climate change and globalization, as well as conflict and strife. Even in stable contexts, poor communication, transportation and storage facilities, dysfunctional commercial markets and inequalities can limit people’s ability to access the food they need.\nFor the World Food Programme (WFP), food systems are not abstract concepts. Our experience buying and distributing food in 80 countries across the world has given us an understanding of the main problems facing food systems. These are:\n- The “last mile” problem – The vast majority of the hungry poor are isolated – geographically, economically, socially and politically – and hard to reach. Even when nutritious food is available, it is often too expensive.\n- The “bad year” or “lean season” problem – When crops fail, or during the lean months between harvests, poor families in both urban and rural areas lack the resources to meet their food needs and are forced to adopt detrimental strategies to cope, including eating less, and less nutritious, food.\n- The “good year” problem – Even a plentiful harvest can have its downsides. Inadequate capacity to store, market and transport food surpluses causes food prices and quality to drop. Farmers are unable to put their produce for sale at a premium when demand is highest, food is wasted and spoiled, and market volatility is sharpened.\nThese three problems tend to affect women more, partly because they have more limited access to assets and services, and may be excluded from decision-making processes.\nBecause of the nature of WFP’s work, our partnerships, programmes and capacities stretch across food systems, and are especially strong within the “midstream” – where food is transported, stored, handled, processed, wholesaled and retailed.\nThe size and reach of our operations mean we have a great potential to address the systemic problems that disrupt food systems. For example, in Kenya’s Kakuma and Dadaab refugee camps, WFP is leveraging its purchasing power and the creation of consumers’ demand through its cash-based transfers to address inefficiencies along the supply chain and achieve the best value for refugees and host communities.\nOther examples of WFP interventions that can have a positive influence on food systems include Home Grown School Meals, which connect local smallholder farmers to the supply chain of school meals programmes; fortification initiatives that help communities access locally produced nutritious food; the creation and rehabilitation of infrastructure in exchange for food or cash-based assistance; strengthening public food reserves; and supporting smallholder farmers through the facilitation of credit, capacity development and access to markets.","- Indonesia’s food estate program, billed as improving domestic food availability, has had the opposite effect on farmers recruited into the scheme, a new study shows.\n- The research by NGOs shows that farmers in North Sumatra province saw their rice harvests decline by up to 80% as they were told to farm other crops for the program.\n- And the harvests from those other crops, including potatoes and garlic, were not enough to make up for the loss of their rice harvests, due to the lower prices they fetched.\n- The researchers warn that the food estate program also puts participating farmers at risk of losing their land rights and being coopted by agribusiness interests serving the food export market.\nJAKARTA — The establishment of large-scale agriculture under the Indonesian government’s “food estate” program is harming local farmers in Sumatra, a study has found.\nThe program was announced in 2020 by President Joko Widodo to boost domestic food production and reduce reliance on crop imports. But in North Sumatra province, one of the regions where the program’s massive farms are being established, food security for at least one village has gotten worse, researchers say.\nFarmers in the village of Ria-Ria, were asked by the government to grow crops such as potatoes, garlic and shallots as part of the program. As a consequence, their harvests of rice, their staple food crop, decreased by up to 70%, according to the joint study by NGOs including Food First Information and Action Network (FIAN) Indonesia and the People’s Initiative Development and Study Group (KSPPM).\n“The [rice] harvest is usually enough for one year, but since last year [when we were asked to] focus on the food estate program, the harvest greatly declined,” said one farmer, identified only by her initials of I.S.\nThe farmers attributed this decline to the timing of the start of the food estate program, in August 2021, which coincided with their rice-growing season. That meant they had to split their time and labor between tending to their rice crops and the food estate crops.\n“The time to work on the paddy field, especially during the maintenance period such as weeding and clearing bushes, is reduced,” said another farmer, O.P. “As a result, [weeds] in the rice paddies grow thick and the amount of rats is uncontrollable. The harvest declined drastically, up to 70%.”\nAnd the harvest of the food estate crops failed to compensate for the decline in the rice harvest, due to the lower prices that they fetch at the local cooperatives where farmers sell their crops, according to Fuad Abdulgani, a FIAN Indonesia researcher.\n“The ones who already sold their harvest to the cooperatives had to face fund management that’s not accountable, where the fund was only disbursed two months later,” he said during a recent online discussion. “All these resulted in lack of food for farmers’ households.”\nThis decline in productivity is especially concerning because up to 30% of households in the village now lack enough rice to feed them for a whole year.\nFuad said the government has ignored this fact by pushing ahead with the food estate program at the expense of addressing the villagers’ basic need for food.\nGusti Nur Asla Shabia, another FIAN Indonesia researcher, said the government had violated the villagers’ right to sufficient food.\n“Food availability should be the responsibility of the state,” she said. “The food estate program is positioned as a policy [to boost] production. But [we] forget that the ones involved [in the program] are farmers.”\nBesides harming the farmers’ food availability, the food estate program also puts them at risk of losing their land rights, the researchers said.\nFuad said some of the Ria-Ria villagers had asked for legal titles to their land rights before the government commenced with the food estate program.\n“But this wasn’t accommodated through a land certification process before the food estate program began,” he said.\nThis lack of formal recognition of their land rights compounds the farmers’ already weak position in the contracts they signed with the companies that would buy their food estate harvests, Fuad said.\n“We didn’t find any contracts that placed both [the farmers and the companies] in an equal position,” he said. “What we found were statement letters whose clauses were determined by the companies without explaining the distribution of costs and benefits, and there’s no clear scheme for how to mitigate risk before the contracts were signed.”\nThis means the companies essentially wield control over the farmers’ lands, even in the few instances where a farmer holds legal title to their land, according to Fuad.\n“Small farmers only become a supplier to agribusiness” under the food estate program, he said.\nKartini Samon from GRAIN, a nonprofit that supports small farmers and social movements, said it’s clear the food estate program isn’t aimed at bolstering food security in the country, but rather at privatizing the nation’s food industry and growing crops for export.\n“We see that the original intention [of the food estate program] is to solve hunger and food insecurity due to the pandemic, but the target itself in the end is to penetrate the international market,” she said during the online discussion. “Once again, we see [our] farmers being given the responsibility to feed the world, but [we] forget that the ones who live in the food estate areas lose their food sources and livelihoods.”\nPosman Sibuea, an agricultural lecturer at the Catholic University of St. Thomas in North Sumatra, said the food estate program was designed with a top-down approach, meaning that local communities didn’t have a say in the design and implementation of the program.\nAs a result, the crops chosen for the program are those that suit agribusiness purposes, rather than those most suitable for feeding Indonesians, he said.\n“It didn’t accommodate the aspirations of local farmers and local governments,” Posman said.\nMiftah Firdaus, from the office of the Indonesian Ombudsman, welcomed reports submitted to the office showing that the food estate program was found to be harming the rights of local communities.\n“If the government proceeds with the food estate program, there are things that have to be paid attention to,” he said during the discussion. “Don’t let the program cause material and immaterial damage to the people. [We] have to make sure that no one is harmed.”\nBanner image: The food estate program in Humbang Hasundutan district, North Sumatra province, Indonesia. Image by Barita News Lumbanbatu/ Mongabay Indonesia.\nFEEDBACK: Use this form to send a message to the author of this post. If you want to post a public comment, you can do that at the bottom of the page."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:942cf85e-a551-47f3-9615-4a156e1c80a4>","<urn:uuid:b9316f79-e821-430f-b9c4-a3b64d7c7f17>"],"error":null}
{"question":"How do the initiatives to protect American chestnuts in Canada compare with the efforts to preserve elm trees at the University of Toronto?","answer":"Both species have faced significant challenges and received dedicated preservation efforts. The Canadian Chestnut Council (CCC) has worked since 1988 to preserve American chestnuts through surveying existing sites, collecting seeds, and establishing new plantings across multiple Canadian provinces. They've also explored biological control through hypovirulence. For elm trees at U of T, preservation efforts have focused on protecting specific specimens, particularly the historic UTSU elm, through fungicide injections and structural support systems like steel wires. The elm preservation became necessary after Dutch Elm disease devastated Toronto's elm population, reducing it from 100,000 trees in the 1960s to just 158 elms compared to 1368 maples today. Both species are protected through different approaches - the American chestnut through broad geographical conservation and breeding programs, while the elm trees through intensive individual care and disease management.","context":["A Decade Of Progress\n\"Alone each of us can do a little – Together we can do much more!\"\n- The Canadian Chestnut Council (CCC) is a charitable organization that has been actively involved since 1988 in the development and implementation of numerous objectives in support of American chestnut. Through the volunteer efforts of members of the Board and the CCC, the following activities and results have been initiated and/or completed.\n- The CCC acts as an information network for coordinating the support efforts by various Chestnut enthusiasts and research scientists across Ontario and Canada, and to communicate with similar groups in the United States and elsewhere.\n- Annual meetings of the CCC are held each fall to allow members a chance to meet and discuss new developments and interests regarding chestnut. Guest speakers and members regularly highlight new developments in chestnut research, and members often use the annual meeting as an opportunity exchange chestnut seed and discuss common interests.\n- Existing sites of American chestnut in southern Ontario have been surveyed and mapped to identify as many surviving individuals as possible. Several hundred sites have been identified through the efforts of numerous volunteers working with the CCC in eastern Canada.\n- Identification of interpollinating sites of American chestnut, and collection and distribution of nuts and seedlings of American chestnut to individuals with suitable sites and interest in propagation of this species. As a result of these efforts, several hundred new plantings of American chestnut have been initiated in southern Ontario by volunteers working with the CCC.\n- To ensure as much genetic diversity of American chestnut as possible is preserved, members of the CCC have surveyed regions suitable for the survival of American chestnut outside of southern Ontario. Where feasible, collaborators have been identified and disease-free seeds have been provided for the initiation of new sites of American chestnut in these areas outside of the range of the Chestnut blight pathogen. To date, sites of American chestnut have been identified and/or initiated in eastern Ontario, Quebec, Nova Scotia, Prince Edward Island, and British Columbia.\n- In 1986, the status of American chestnut in Ontario was assessed for the World Wildlife Fund and determined to be that of a Threatened Species. Many of these original sites were revisited from 1995-98 to review possible changes in the status of these trees. Currently “The American Chestnut is listed as an endangered species under Ontario’s Endangered Species Act, 2007. This Act protects the tree from being collected, killed or harmed. The Natural Heritage component of the Provincial Policy Statement under Ontario’s Planning Act provides for the protection of significant habitat of threatened species.” See: http://www.rom.on.ca/ontario/risk.php?doc type=fact&id=27\n- Hypovirulence is a naturally-occurring biological control phenomenon that contributed to the regeneration of European chestnut (Castanea sativa) throughout much of Europe after Chestnut blight also destroyed these populations. Naturally occurring hypovirulence also has been found in populations of chestnut blight in southern Ontario and experiments to assess the potential for biological control of chestnut blight in Canada have been initiated.\nFor further information on the Canadian Chestnut Council, please contact us\nThere are no active events\nVarious reports on the status of restoration efforts, tree population surveys, DNA analysis, breeding and propagation programs, etc.\nThe American Chestnut\nMission & History\nUpdates from the..\nQuestions & Resources","Looking for the oldest tree at U of T\nVelut arbor aevo. This Latin phrase is U of T’s motto, and means “as a tree through the ages,” expressing the hope that U of T will grow large and impressive like a mature tree. So to locate the oldest tree on campus is thus to find the tree that best embodies the motto of the school, and to find U of T’s very own living, breathing, and unacknowledged arboreal mascot.\nThis quest initially seemed like it would be over in a few minutes. Within two minutes of my 11:47pm email, Stan Szwagiel, head of grounds at U of T St. George, emailed me back with an enjoyably definitive answer: the oldest tree on campus is the elm tree behind the UTSU building. An impromptu hike to this location revealed an appropriately large and beautiful tree, which I was surprised I hadn’t noticed before. This tree has street cred: a few minutes after I heard from Mr. Szwagiel, Terry Carleton, a professor at the faculty of forestry, independently told me that this tree was his bet for the oldest on campus. Mr. Szwagiel thought that the size of the tree indicated that it could even be as old as 165 years, which would make it one year older than U of T (which came into existence in 1850), and that it could well be even older.\nThrough Paul Aird, an emeritus professor of forestry who has written a book about ecological fables and nature tales, I learned that the U of T Archives has a 1910 topographical map that lists all the trees that were then on campus. I consulted this map – which is over 6 feet tall and requires two people to open – but, intriguingly, the elm is not on it. The map does have some irregularities; could the cartographers just have missed the tree? For the UTSU elm is visible in an aerial photograph of the campus taken in 1933, and partially visible in a 1924 image. So it is at least 90 years old, and the size of the tree in those photographs makes it seem like it must have been more than a teenager then. And Mr. Szwagiel told me about another large elm tree on campus that recently had to be cut down after disease killed it. That tree had a trunk that was much smaller than the UTSU elm. When it was cut an arborist counted its rings and it was well over 150 years old. It’s enormous stump is still visible beside the path between Whitney Hall and the back campus field.\nIn order to learn more about trees in general I contacted Jennifer Gagné, a former forestry student who now works for the ministry of the environment. She used to lead tree tours on campus and took me on one. Our first stop was the two little copses planted at the centre of the forestry department building. According to Gagné, the one on the north-side is meant to replicate a Carolinian forest (sample species: a tulip tree, a Kentucky coffee tree), and the other a boreal forest (spruce, tamarack). According to Gagné, being enclosed within these buildings is not protecting or helping the trees; the boreal trees especially are not shade tolerant, and random shrubs have taken over the undergrowth. I later learned from Tony Ung, a forestry researcher, that the copses had gotten out of control and that they had to urgently cut out some of the brush. “We feared for the safety of students. People were sleeping in there. We found needles,” he told me. But today it seemed benign, soggy, lonely to me. Though for Gagné, the important personalities, the trees, are still here. To know the names and life stories of trees is to be surrounded by their presences. Human beings depend on trees quite as much as on rivers and the seas; the ability to know them is meaningful. And every tree has a different method to identify it, some more heuristic than scientific, like when Gagné began plunging her palm repeatedly into a conifer’s needles. If it hurts, it’s a Red Pine. And it did hurt. Leaving the copses, Gagné showed me a recent building at New College that had a hole in the third-story concrete balcony to allow the tree to grow through the building. A high-minded design, or maybe because the building was right beside the forestry department, where it’s probably harder to get rid of a perfectly healthy tree.\nThere is an oak tree on U of T’s coat of arms (rounded leaves, hence, a white oak), but an elm tree was probably the most significant tree in U of T’s history, being the deciding factor in the location of U of T’s most iconic building. In 1856, before UC College was built, the governor general and the architect were surveying the grounds. The governor general wanted the building to face west, though to the architect–and to us today–it seemed obvious that it should face south. The decision was made by the fact of a tall elm tree which the governor general, calling it, “the handsomest tree about Toronto,” did not want cut. He is reported to have told the architect: “I am sure that you can never put anything up half so pretty.\" So to save that tree, the building faced south. The tree was toppled in a storm the following year.\nU of T exists atop the ghosts of cut forests and lost trees. If you stood in front of the UTSU elm as time was rolled back a hundred and fifty years, you would see the UTSU building taken down, Soldier’s Tower unspooled, and Hart House deconstructed. You would arrive to see the elm growing beside a thicket of other trees, all nestled together around the banks of a small pond. The pond is McCaul’s Pond (the tree is still on a bit of hill: the rise that used to be the pond’s edge), which was drained in the summer of 1879. Back then, there were only about 200 students at U of T, and the college was a semi-rural retreat, somewhat removed from the city, and nature and trees were among the chief pleasures of the school. Students and professors spent the afternoons taking walks. “No professor,” a student at the time said, “if he could avoid it, lectured in the afternoon, which was reserved for recreation and walking.”\nPeople enjoy trees, but they also cut them down for heat and timber, and to make room for development. But perhaps the most destructive damage that people inflict on trees is accidental, though the spreading of disease. The UTSU elm is diseased with the scourge of elm trees, Dutch Elm disease, which spread to Ontario in 1951. Originating in the Himalayas, and named for the Dutch scientists who identified it, the disease is a fungal parasite. The effects of Dutch Elm are ruinous; Ms. Gagné explains that “elms almost kill themselves, because it triggers them to cut off the water system in their xylem, in order to get the fungus out.” In North America, elms have died by the millions. Many thought Dutch Elm would bring about the extinction of the American elm.\nElms used to be the dominant species at U of T, and now are among the more rare of native trees. There were more than 100,000 elms in metropolitan Toronto in the 1960s, 10 percent of all street trees, and 90 percent of the trees in the groves on the University of Toronto campus were American elm. There are currently 1368 maples to 158 elms. The main road into Kings College Circle used to be marked by a row of tall elms; now it has short young oaks. The introduction of Dutch elm disease in North America is the most significant event in the history of urban forestry. The disease altered urban forestry policy and law, and changed the public’s awareness of street tree management. Arborists trying to combat the devastation of this disease pioneered the profession of “tree health care,” opening up an entirely new industry for managing the care of urban trees. In fact, the term “urban forestry” was coined by a U of T professor, Erik Jorgensen, who was working on dealing with Dutch Elm disease. Even the current emerald ash borer pandemic is directly linked to Dutch Elm disease because most of the ash population are replacement trees for lost elms. In Toronto, 80% of the elm trees have been lost to Dutch Elm disease.\nMr. Szwagiel met me at the UTSU tree, and pointed out the tiny tell-tale holes at the base of the tree where it is has been injected with fungicide to stop the Dutch Elm. The tree gets hooked up to bottles of fungicide like a patient on an IV drip. If enough fungicide can be injected into the tree’s vascular system, then a spore introduced by a beetle won’t be able to germinate. Without this treatment, which is expensive, the tree could die within a year. Mr. Szwagiel also pointed out the extensive series of steel wires strung between the tree’s branches, which that add strength to it’s canopy and keep it from collapsing in storms. Without question this tree would be dead by now if it weren’t for the labour of the forestry professors, grounds crew, and arborists who contribute to it’s well-being. The university makes these efforts because these trees give campus much of its well-to-do, pastoral, collegiate identity. So perhaps trees should take as their motto “as a university through the ages.” The motto’s declaration to make the school like a tree—a line adapted from the roman poet Horace (Odes I.12, lines 45–46) “crescit occulto velut arbor aevo fama Marcelli”: Marcellus’ fame, its up-growth hid / springs like a tree—makes a fine picturesque image, but it does not reflect the fragility of our tree canopies in an age of globalized tree disease. The trees persist, but not without struggle and constant maintenance; which is also true enough for a university.\nU of T St. George currently has over 3,000 trees (more now than in 1910), and, though the UTSU elm is a strong suspect, the jury is out on which one of them is empirically the oldest. Tony Ung says that the only way to know for sure is to take a core sample of the tree. He showed me the apparatus, a sort of tree corkscrew—“from the 1940s, I think”—that he would use to get a sample; a process that, most likely, would not harm the tree. But it is still a risk and Mr. Szwagiel does not want to immediately pursue that option. The age of this tree will thus remain a mystery. But thanks to the care it receives, this elm could live another 300 years. We will send someone then to report on how the university is doing compared to the tree. In the meantime, we can enjoy it."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:ff94e595-2d2b-4eda-bc41-eb849eedea29>","<urn:uuid:75273a8f-bf42-495d-bd61-3a5709b9e05c>"],"error":null}
{"question":"¿Cuántas emociones básicas pueden mostrar realmente los humanos en sus expresiones faciales?","answer":"According to research from the University of Glasgow, humans only display four basic emotions rather than six. Their study of facial expressions' temporal dynamics showed that 'fear' and 'surprise' share typical facial signals, as do 'anger' and 'disgust'.","context":["Where’s the fastest glacier in the world?\nWhat’s red hot and found in the Pacific ocean?\nA new technique for studying particles from out of this world.\nAnd the four faces of human expression. Coming today…On Science!\nHello and welcome to On Science. I’m Emerald Robinson.\nA glacier in Greenland is breaking the speed limit. Researchers from the University of Washington and the German Space Agency say that a Greenland glacier is moving at unprecedented speeds. Comparing satellite data, they say the current speeds are four times faster than those observed on a glacier in the 1990s. Just how fast is fast for glacier? This one clocked in at 10 miles per year – setting the record for fastest glacier or ice stream in Greenland or Antarctica. And thanks to its fast melting, it has contributed an .03-inch rise in sea level in the past ten years and is expected to contribute a bit more over the next decade. Pull over! That ice is too fast.\nWhile that sea may be icy, there’s a fire beneath the Peruvian Pacific. Scuba divers recently collected a new fiery-red coral species in Peru’s Paracas National Reserve. Researchers at the Smithsonian Tropical Research Institute say this coral may be a one of a kind and not to be found anywhere else in the world. Researchers identified the new species of soft coral using light and scanning-electron microscopy. Researchers say they’re beginning to discover the amazing biodiversity of corals and marine invertebrates in the Peruvian Pacific. Here’s a little bonus for researchers. Obviously, you find it you name it. The new species is named Psammogorgia hookeri for biologist Yuri Hooker.\nAnd scientists have a new technique for studying life ingredients that are out of this world. Earth is constantly blasted with dust from comets and asteroids. Researchers at NASA say that, despite their small size, these dust particles “may have provided higher quantities and steadier supply of extraterrestrial organic material to early Earth” than meteorite impacts. But their extremely small size has kept them from being studied heavily. Scientists at NASA’s Goddard Astrobiology Analytical Laboratory used a nanoflow liquid chromatography instrument to sort the molecules, then applied nanoelectrospray ionization to identify the molecules based on their mass. They said they “are pioneering the application of these techniques for the study of meteorite organics.” They also said that these techniques and any others they develop will be beneficial to future sample return missions, such as ones to Mars, where sample size will be limited.\nLet’s play “guess the expression.” What am I feeling? What am I feeling now? If you guessed “surprise” and then “fear” you were correct. But you’re probably saying, they both looked the same. New research from the University of Glasgow says that humans only display four rather than six basic emotions. Using new technology to look at the “temporal dynamics” of facial expression, they found that “fear” and “surprise” share typical facial signals as do “anger” and “disgust.” These finds help researchers better understand the basics of human emotion communication.\nToday is World Cancer Day – a day in which to celebrate survivors and spread awareness for those who’ve been lost. Cancer cases are predicted to surge 57% worldwide in the next 20 years due to a growing and aging population. Researchers say that treatment will not be enough. Our focus needs to be on preventive public health policies involving prevention and early detection. But on a positive note, half of all cancers are preventable and can be avoided if current medical knowledge is acted upon. So to honor World Cancer Day, start living a healthier lifestyle and addressing bad habits like smoking and alcohol consumption. And remember, the key is early detection.\nAnd that’s the latest in science news! See you tomorrow, On Scientists!"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:090977ba-462c-4049-a365-6c61462ce424>"],"error":null}
{"question":"How to 怎样 save energy 在 home heating and cooling 方面?","answer":"To save energy on heating and cooling: 1) Seal cracks and openings that allow air drafts in and out of the house, as these can be as wasteful as leaving a window open all winter. 2) Seal heat ducts to reduce your energy bill by 20%. 3) Keep thermostats at moderate temperatures in unused rooms. 4) In summer, try using ceiling fans, window fans, or open windows before turning on air conditioning.","context":["What Can You Do to Reduce Pollution and Conserve Energy?\nEnergy conservation and pollution reduction go hand-in-hand, as the power plants that generate your electricity often release arsenic, mercury, other metals and acid gases that threaten human health and the environment (see References 1, page 3). Putting into practice a few simple, convenient ways to conserve energy will also help you to trim your utility bills.\nChoose Eco-Friendly Appliances\nThe U.S. Environmental Protection Agency and Department of Energy established the Energy Star program to label products, such as appliances and electronics, that utilize significantly less energy, while offering comparable quality to similar products. If the product costs more than non-Energy Star products, savings on your energy bill typically make up for the price difference. Purchasing appliances with the Energy Star label will help you to cut your energy costs and the pollution that accompanies high energy use. (See References 2)\nCut Heating and Cooling Expenditures\nSave on your home's energy usage for heating and cooling. Begin by sealing cracks and openings that allow air in and out of the house. These drafts can exert the same drain on your home's energy efficiency as leaving a window open all winter. Sealing heat ducts can shave an additional 20 percent off your energy bill. Keep the thermostat set at moderate temperatures in unused rooms, focusing your heating and cooling expenditures on the rooms you use the most. In the summer, before you switch on the air conditioning, use ceiling fans, window fans or open windows to keep you cool while using less energy. (See References 4)\nSwitch to Renewal Energy Sources\nIncreasingly, homeowners have the opportunity to purchase all or part of their electricity from a supplier that uses green or renewal energy sources, such as solar or wind. Your local utility company and the EPA's Green Power Locator can provide more information about opportunities in your area. (See References 5)\nReduce, Reuse, Recycle\nWhat you do with your household wastes also determines the amount of pollution and energy use your household creates. When you purchase a product with minimal disposable packaging or reuse an item instead of buying new, you save the energy it would have taken to make that packaging or that new item. Recycling also saves energy and reduces pollution. The EPA reports that, in 2009, the 178 million metric tons of carbon emissions avoided by recycling was equivalent to removing almost 33 million cars from the road that year (see References 3, page 17). Recycling also diminishes the need for harvesting or mining virgin materials, activities that can damage the environment and cause pollution. (See References 6)\n- U.S. Environmental Protection Agency; Reducing Toxic Pollution from Power Plants: EPA's Proposed Mercury and Air Toxics Standards; March 2011\n- Energy Star: How a Product Earns the Energy Star Label\n- U.S. Environmental Protection Agency; Municipal Solid Waste in the United States: 2009 Facts and Figures; December 2010\n- U.S. Environmental Protection Agency: Reducing Energy Use\n- U.S. Environmental Protection Agency: Buying Green Power\n- U.S. Environmental Protection Agency: Communicating the Benefits of Recycling"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:c80be826-de01-440e-bb02-f77110ff0c6a>"],"error":null}
{"question":"When conducting microbiological growth measurements, what direct counting method requires no incubation time, and what specific mathematical calculation is used to determine the cell count?","answer":"The direct microscopic count is a counting method that requires no incubation time. To determine the cell count, the following mathematical formula is used: Number of cells per mm = number of cells counted × dilution × 50,000. This calculation factor of 50,000 is used to determine the cell count for 1 ml, as 1 ml equals 1000 mm³, which is 50 times the chamber depth of 0.02 mm multiplied by 1000.","context":["Immunologist - studies ecology of Legionella pneumophila\nWhich of the following statements about fungi is true?\nAll are plants.\nWhich of the following pairs is mismatched? N\nNormal microbiota - harmful\nWho proved that microorganisms cause disease?\nWhich of the following pairs is mismatched? V\nvan Leeuwenhoek - germ theory\nWhich of the following requirements was NOT necessary for Pasteur to disprove spontaneous generation?\nRegarding Pasteur's experiments with the S-neck flask, which of the following statements is true?\nAny possibility of contamination was removed. There was air involved. There was a food source involved. All microorganisms were killed before beginning.\nWhich of the following statements about the atom 12/6 C is false?\nIt has 12 neutrons in its nucleus\nWhich of the following statements is false?\nWater molecules are formed by hydrolysis.\nWhich of the following is the type of bond holding K+ and I- ions in KI?\nWhich of the following is the type of bond between molecules of water in a beaker of water?\nWhat is the type of bond holding hydrogen and oxygen atoms in the H2O molecule?\nIdentify the following reaction: Glucose + Fructose → Sucrose + Water\nDehydration synthesis reaction\nIdentify the following reaction: Lactose + H2O → Glucose + Galactose\nWhich type of molecule contains the alcohol glycerol?\nIdentify the following reaction: H20+CO2 ⇌ H2CO3\nWhich molecule is composed of a chain of amino acids?\nWhich type of molecule contains -NH2 groups?\nWhat structure does light pass through after leaving the condenser in a compound light microscope?\nWhich of the following pairs is mismatched? G\nGram-negative bacteria - negative stain\nWhich of the following pairs is mismatched? S\nSafranin - acid dye\nWhich type of molecule is composed of (CH2O) units?\nWhat do genes consist of?\nWhich are the primary molecules making up plasma membranes in cells?\nIdentify the following reaction: NH4OH ⇌ NH3 + H2O\nThe counterstain in the acid-fast stain is\nA basic dye.\nThe purpose of a mordant in the Gram stain is\nTo prevent the crystal violet from leaving the cells.\nPlace the following steps in the correct sequence: 1-Staining; 2-Making a smear; 3-Fixing.\nIn this microscope, the observer does NOT look at an image through a lens.\nPlace the steps of the Gram stain in the correct order: 1-Alcohol-acetone; 2-Crystal violet; 3-Safranin; 4-Iodine.\nIn Figure 3.1, line \"a.\" points to the microscope's\nIn Figure 3.1, line \"b.\" points to the microscope's\nThe appearance of gram-negative bacteria after addition of the decolorizing agent in the Gram stain.\nThe appearance of gram-negative bacteria after completing the Gram stain.\nWhich of the following is NOT a distinguishing characteristic of prokaryotic cells?\nThey lack a plasma membrane.\nThe best definition of osmotic pressure is\nThe force with which a solvent moves across a semipermeable membrane from a higher to a lower concentration.\nBy which of the following mechanisms can a cell transport a substance from a lower to a higher concentration?\nWhich of the following statements about viruses is false?\nThey have both DNA and RNA.\nWhich drawing in Figure 4.1 is a tetrad?\nWhich drawing in Figure 4.1 possesses an axial filament?\nWhich drawing in Figure 4.1 is streptococci?\nWhich drawing in Figure 4.1 is a bacillius?\nWhich of the following structures is NOT found in prokaryotic cells?\nIn Figure 4.3, which diagram of a cell wall is a gram-negative cell wall?\nWhich microscope achieves the highest magnification and greatest resolution?\nWhich of the following is NOT a chemical component of a bacterial cell wall?\nIn Figure 4.3, which diagram of a cell wall is a toxic cell wall?\nWhich of the following terms best describes the cell in Figure 4.2?\nSimple staining is often necessary to improve contrast in this microscope.\nCompound light microscope\nIn Figure 4.3, which diagram of a cell wall has a wall that protects against osmotic lysis?\nBoth a and b\nAssume you stain Bacillus by applying malachite green with heat and then counterstaining with safranin. Through the microscope, the green structures are then counter-stained with safranin. Through the microscope, the green structures are :\nWhich of the following pairs is mismatched?\nCentrosome - food storage\nWhat Gram reaction do you expect from acid-fast bacteria?\nIn Figure 4.3, which diagram of a cell wall is decolorized by acetone-alcohol?\nThe purpose of the ocular lens is to\nMagnify the image from the objective lens.\nThe resolution of a microscope can be improved by changing the\nWavelength of light.\nWhich microscope is most useful for visualizing a biofilm?\nScanning acoustic microscope\nIn Figure 4.3, which diagram of a cell wall is resistant to many antibiotics (e.g., penicillin)?\nWhich of the following organelles most closely resembles a prokaryotic cell?\nIn Figure 4.3, which diagram of a cell wall contains teichoic acids?\nYou have isolated a motile, gram-positive cell with no visible nucleus. You can safely assume that the cell\nHas a cell wall.\nIn Figure 4.3, which diagram of a cell wall contains porins?\nIn Figure 6.2, which section shows a growth phase where the number of cells dying equals the number of cells dividing?\nIn Figure 6.2, which sections of the graph illustrate a logarithmic change in cell numbers?\nB & D\nMost bacteria grow best at pH\nDuring which growth phase will gram-positive bacteria be most susceptible to penicillin?\nWhich of the following is an advantage of the direct microscopic count?\nRequires no incubation time\nWhich of the following is NOT a direct method to measure microbial growth?\nWhich of the following statements is false?\nDNA replication proceeds in one direction around the bacterial chromosome.\nWhich of the following pairs is mismatched? T\nThermophile - growth at 37°C\nIn Figure 6.4, in which tube are microaerophiles growing?\nIn Figure 6.4, in which tube are facultative anaerobes growing?\nWhich enzyme catalyzes the reaction: O2- + O2- + 2H+ → H2O2 + O2?\nA culture medium on which only gram-positive organisms grow and a yellow halo surrounds Staphylococcus aureus colonies is called a(n)\nSelective medium & Differential medium\nThe initial effect of ionizing radiation on a cell is that it causes\nThe formation of highly reactive ions.\nA culture medium consisting of agar, human blood, and beef heart is a\nWhich of the following is the best definition of generation time?\nThe length of time needed for a cell to divide\nWhich group of microorganisms is most likely to spoil a freshwater trout preserved with salt?\nWhich of the following is the best method to sterilize heat-labile solutions?\nWhich of the following does NOT achieve sterilization?\nWhich of the following is NOT used to disinfect water?\nWhich of the following substances is NOT effective against nonenveloped viruses?\nIf you were preparing nutrient agar at home and didn't have an autoclave, what could you use to sterilize the nutrient agar\nPressure cooker at 121°C for 15 minutes\nWhich of the following pairs is mismatched? R\nRNA polymerase - makes a molecule of RNA from an RNA template\nDNA is constructed of\nTwo strands of nucleotides running antiparallel.\nWhich of the following is NOT a product of transcription?\nA new strand of DNA\nGenetic change in bacteria can be brought about by","Last Updated on February 4, 2021 by Sagar Aryal\n- Studies involving the analysis of materials including food, water, milk, and, in some cases, air require quantitative enumeration of microorganisms in the substances.\n- Many methods have been devised to accomplish this, including direct microscopic counts, use of an electronic cell counter such as the Coulter Counter, chemical methods for estimating cell mass or cellular constituents, turbidometric measurements for increases in cell mass, and the serial dilution–agar plate method.\n- Direct microscopic counts require the use of a specialized slide called the Petroff-Hausser counting chamber, in which an aliquot of a eukaryotic cell suspension is counted and the total number of cells is determined mathematically.\n- The Petroff-Hausser counting chamber is a thick glass microscope slide with a chamber 0.02 mm (1/50 mm) deep in the center.\n- The chamber contains an etched grid and has improved Neubauer rulings (1/400 square mm).\n- The rulings cover 9 mm2. The boundary lines (Neubauer rulings) are the center lines of the groups of three.\n- The center square millimeter is ruled into groups of 16 small squares, and each group is separated by triple lines, the middle one of which is the boundary.\n- The ruled surface is 0.02 mm below the cover glass, which makes the volume over a square millimeter 0.02 mm3 (cubic mm). All cells are counted in this square millimeter.\n- The number of cells counted is calculated as follows:\nNumber of cells per mm = number of cells counted * dilution * 50,000\n[The factor of 50,000 is used in order to determine the cell count for 1 ml: 1 ml = 1000 mm3 = (50 times the chamber depth of 0.02 mm) * 1000.]\nA variation of the direct microscopic count has been used to observe and measure growth of bacteria in natural environments. In order to detect and prove that thermophilic bacteria were growing in boiling hot springs, T.D. Brock immersed microscope slides in the springs and withdrew them periodically for microscopic observation. The bacteria in the boiling water attached to the glass slides naturally and grew as microcolonies on the surface.\nAdvantages of Direct Microscopic Count\n- Rapid, Simple and easy method requiring minimum equipment.\n- Morphology of the bacteria can be observed as they counted.\n- Very dense suspensions can be counted if they are diluted appropriately.\nLimitations of Direct Microscopic Count\n- Although rapid, a direct count has the disadvantages that both living and dead cells are counted.\n- Only dense suspensions can be counted (>107 cells per ml), but samples can be concentrated by centrifugation or filtration to increase sensitivity.\n- It is not sensitive to populations of fewer than 1 million cells.\n- Small cells are difficult to see under the microscope, and some cells are probably missed.\n- Precision is difficult to achieve\n- A phase contrast microscope is required when the sample is not stained.\n- Cappuccino, J. and Welsh, C. (2014). Microbiology: A Laboratory Manual, Global Edition. 1st ed. Pearson Education\n- Sastry A.S. & Bhat S.K. (2016). Essentials of Medical Microbiology. New Delhi : Jaypee Brothers Medical Publishers."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:0e571338-2a95-4428-abd4-81159ec632fe>","<urn:uuid:3784feff-044f-4785-a970-88f42d68ad17>"],"error":null}
{"question":"What is model order selection in statistical signal processing, and how does missing data analysis affect its implementation?","answer":"Model order selection is a common problem in statistical signal processing where methods like MDL and AIC are used to offset overestimating tendencies by introducing penalty terms. While MDL is consistent and AIC tends to overestimate as sample size increases to infinity, both are surprisingly inconsistent for fixed sample sizes as noise variance approaches zero. Missing data analysis impacts this implementation as any statistical method makes assumptions about missing values that cannot be verified from available data. Typically, analyses rely on missing at random (MAR) assumptions, though there's always a possibility that missingness depends on unobserved values (MNAR), requiring sensitivity analysis to assess robustness of results.","context":["Statistical signal processing and its applications to detection, model order selection, and classification\nThis dissertation has focused on topics in statistical signal processing including detection and estimation theory, information fusion, model order selection, as well as their applications to standoff detection. ^ Model order selection is a very common problem in statistical signal processing. In composite multiple hypothesis testing, the maximum likelihood rule will always choose the hypothesis with the largest order if the parameters in each candidate hypothesis are hierarchically nested. Hence, many methods have been proposed to offset this overestimating tendency by introducing a penalty term. Two popular methods are the minimum description length (MDL) and the Akaike information criterion (AIC). It has been shown that the MDL is consistent and the AIC tends to overestimate the model as the sample size goes to infinity. In this dissertation, we show that for a fixed sample size, the MDL and the AIC are inconsistent as the noise variance goes to zero. The result is surprising since intuitively, a good model order selection criterion should choose the correct model when the noise is small enough. Moreover, it is proved that the embedded exponentially family (EEF) criterion is consistent as the noise variance goes to zero. ^ Standoff detection aims to detect hazardous substances in an effort to keep people away from potential damage and danger. The work in standoff detection has been on developing algorithms for detection and classification of surface chemical agents using Raman spectra. We use an autoregressive model to fit the Raman spectra, develop an unsupervised detection algorithm followed by a classification scheme, and manage to control the false alarm rate to a low level while maintaining a very good detection and classification performance. ^ In information fusion and sensor integration, multiple sensors of the same or different types are deployed in order to obtain more information to make a better decision than with a single sensor. A common and simple method is to assume that the measurements of the sensors are independent, so that the joint probability density function (PDF) is the product of the marginal PDFs. However, this assumption does not hold if the measurements are correlated. We have proposed a novel method of constructing the joint PDF using the exponential family. This method combines all the available information in a multi-sensor setting from a statistical standpoint. It is shown that this method is asymptotically optimal in minimizing Kullback-Leibler divergence, and it attains comparable detection/classification performance as existing methods. ^ The maximum likelihood estimator (MLE) is the most popular method in parameter estimation. It is asymptotically optimal in that it approximates the minimum variance unbiased (MVU) estimator for large data records. Under a misspecified model, it is well known that the MLE still converges to a well defined limit as the sample size goes to infinity. We have proved that under some regularity conditions, the MLE under a misspecified model also converges to a well defined limit at high signal-to-noise ratio (SNR). This result provides important performance analysis of the MLE under a misspecified model. ^\nEngineering, Electronics and Electrical\n\"Statistical signal processing and its applications to detection, model order selection, and classification\"\nDissertations and Master's Theses (Campus Access).","When analysing partially-observed data, any statistical method makes either explicit or implicit assumptions about the missing values which can never be verified from the data at hand. Typically, most analyses rely on a missing at random (MAR) assumption, that is they assume that the observed data are able to fully explain missingness. However, there is always the chance that this assumption is not correct and missingness may depend on some values which are not observed, leading to a missing not at random (MNAR) assumption. Thus, it is extremely important that the robustness of the results to a range of alternative missingness assumptions is assessed in sensitivity analysis, including MNAR.\nEach of the three types of missingness models in\nmissingHE, namely selection, pattern mixture, and hurdle models, can be fitted under MNAR for either or both the effectiveness and cost outcomes. In\nmissingHE, MNAR assumptions are codified in terms of some suitably-defined departures from MAR for the mean effectiveness and cost parameters, which are the main quantities of interest in the economic evaluation. This tutorial shows how MNAR assumptions can be specified for each type of model in\nmissingHE. Throughout, we will use the built-in dataset called\nMenSS as a toy example, which is directly available when installing and loading\nmissingHE in your\nR workspace. See the vignette called Introduction to missingHE for an introductory tutorial of each function in\nmissingHE and a general presentation of the data from the\nMenSS dataset. See also the vignette called Model customisation in missingHE for few examples on how to customise the functions in\nmissingHE to handle different types of issues in the analysis.\nIf you would like to have more information on the package, or would like to point out potential issues in the current version, feel free to contact the maintainer at firstname.lastname@example.org. Suggestions on how to improve the package are also very welcome.\nSelection models specify MNAR assumptions by directly modelling the missingness mechanisms, that is the models for the missing data indicators, as a function of some partially-observed variables. In\nmissingHE, MNAR is defined by including the outcome variables (\\(e\\) and \\(c\\)) inside the logistic regression models for the corresponding missing indicators (\nmodel.mc). Since some outcome values are not observed, the parameters capturing the dependence between missingness and the outcomes (called\ndelta.c) cannot be fully estimated from the observed data but are, at least partially, informed from some external sources of information, therefore defining a MNAR assumption. Two sources of external information are used to identify these parameters: informative prior distributions and distributional assumptions.\nInformative priors on\ndelta.c can be provided in the form of a list object containing the hyperprior values to be passed to the\nselection function using the optional argument\nprior. By default,\nmissingHE specifies standard normal distributions on these parameters, which are likely to have little impact compared to the results under MAR (i.e. when the parameters are set to zero). Different values for the priors on\ndelta.c can be passed to the function to overwrite the default values to assess the robustness of the results to different choices. The type of distributions for each outcome can be specified among a pre-defined set of choices using the arguments\nhelp(selection) to access the full list of available distributions for \\(e\\) and \\(c\\).\nFor example, we can fit a selection model under MNAR assumptions for the effectiveness variables (QALYs) in the\nMenSS dataset using the\nselection function. We must set the argument\ntype = \"MNAR\" and then add the terms\ne inside the model for the corresponding missingness indicator, namely\nmodel.me = me ~ e.\n> NN.sel1=selection(data = MenSS, model.eff = e ~ u.0, model.cost = c ~ 1, + model.me = me ~ e, model.mc = mc ~ 1, type = \"MNAR\", + n.iter = 1000, dist_e = \"norm\", dist_c = \"norm\")\nThe model assumes normal distributions for both outcomes and includes the baseline utilities as covariates in the model of \\(e\\). Since we did not provide any prior, default prior values are used for the MNAR parameter\nmissingHE allows a flexible specification in terms of the variables assumed to be MNAR (either \\(e\\), \\(c\\) or both). In addition, other fully-observed variables can be included into the models\nmodel.mc, either under MAR or MNAR, to improve the estimation of the missingness probabilities. We can retrieve the estimates for the mean effectiveness and cost outcomes from the model using the\n> print(NN.sel1) mean sd 2.5% 97.5% Rhat n.eff mu_c 209.956 52.249 111.556 312.403 1.012 580 mu_c 189.938 39.945 113.229 264.546 1.013 170 mu_e 0.872 0.016 0.839 0.904 1.009 210 mu_e 0.922 0.022 0.883 0.964 1.008 200\nWe now consider an alternative MNAR specification where we provide some informative prior distributions on\ndelta.e. In general, it is difficult to attach any specific interpretation to the values for this parameter because its effect may vary depending on the type of distributional assumptions made. We first define our prior values by creating a list object called\nmy.prior. Within this list, we create a vector of length two called\n\"delta.prior.e\" which contains the prior values to be passed to\n> my.prior <- list( + \"delta.prior.e\" = c(10, 1) + )\nAs a simple exercise, we increase the prior mean of\ndelta.e to \\(10\\) to assess the impact on posterior estimates of a more informative prior about this parameter (relatively high positive value on the logit scale). We then fit the second MNAR model using the new prior values by setting the argument\nprior = my.prior\n> NN.sel2=selection(data = MenSS, model.eff = e ~ u.0, model.cost = c ~ 1, + model.me = me ~ e, model.mc = mc ~ 1, type = \"MNAR\", + n.iter = 1000, dist_e = \"norm\", dist_c = \"norm\", prior = my.prior)\nWe can now check the results and compare them to those obtained under the first MNAR model.\n> print(NN.sel2) mean sd 2.5% 97.5% Rhat n.eff mu_c 208.152 52.202 108.603 307.084 1.001 1000 mu_c 190.555 38.189 115.044 267.196 1.000 1000 mu_e 0.974 0.036 0.913 1.055 1.000 1000 mu_e 0.979 0.034 0.930 1.053 1.012 1000\nWe see that, with respect to the results from\nNN.sel1, the mean effectiveness estimates are on average higher in both treatment groups. To have a better idea of the impact in terms of cost-effectiveness conclusions for the different MNAR assumptions, we can use the function\nceac.plot inside the package\nBCEA to display the cost-effectiveness acceptability curves based on the results from each model.\n> par(mfrow=c(1,2)) > BCEA::ceac.plot(NN.sel1$cea) > BCEA::ceac.plot(NN.sel2$cea)\nThe comparison between the two graphs shows that CEA conclusions are substantially affected by the specific assumptions made about the missing effects, therefore suggesting that the results of the model are not robust to the missingness assumptions considered. It is very important that the specific MNAR scenarios explored are informed based on some external information (e.g. expert opinion) so to provide a range of plausible assumptions to assess.\nPattern mixture models specify MNAR assumptions through the combinations of two elements: identifying restrictions and sensitivity parameters. Since these models are defined within each missingness pattern, parameters that cannot be idenfitied from the patterns are typically identified by imposing some modelling restrictions, that is they are set equal to the corresponding parameters from other patterns which can be identified from the observed data.\nFor example, the complete case restriction identifies all unidentified parameters in each pattern by setting them equal to those estimated from the complete cases. Under MAR, these restrictions are the only element used to achieve the identification of the model. However, when MNAR assumptions are specified, identifying restrictions are combined with sensitivity parameters, that is parameters that are entirely identified based on evidence external to the data, to achieve the identification of the model. Sensitivity parameters are identified based on informative prior distributions but, unlike the priors for the MNAR parameters in selection models, they have more natural interpretations in terms of the impact on the posterior results.\nmissingHE allows the specification of MNAR assumptions for either or both outcome variables using the function\npattern via the arguments\nDelta_c. The first is the type of identifying restrictions imposed: available choices are complete case (\n\"CC\") or available case (\n\"AC\") restrictions. The second and third are the prior values for the sensitivity parameters associated with the mean effectiveness and costs. Under MAR, these are set to \\(0\\) (default values). Under MNAR, prior values for these parameters must be provided by the user in the form of a \\(2\\times2\\) matrix. For example, assuming a MNAR mechanism for the effectiveness, a possible choice for the prior values on\n> Delta_e <- matrix(NA, 2, 2) > Delta_e[1, ] <- c(- 0.3, - 0.2) > Delta_e[2, ] <- c(-0.1, 0)\nThe rows represent the treatment group while the columns represent the lower and upper bounds for the uniform prior distributions that\nmissingHE assumes for these parameters under MNAR. The values specified aboved correspond to assuming that, on average, we expect the mean effectiveness in the control group is between \\(0.3\\) and \\(0.2\\) lower and that the mean effectiveness in the intervention group is between \\(0.1\\) and \\(0\\) lower than the corresponding values under MAR. We proceed to fit the MNAR pattern mixture model using\npattern by setting the argument\ntype = \"MNAR\" and by passing our prior values contained in the object\nDelta_e to the function.\n> NN.pat2=pattern(data = MenSS, model.eff = e ~ u.0, model.cost = c ~ 1, + type = \"MNAR\", restriction = \"CC\", n.iter = 1000, Delta_e = Delta_e, Delta_c = 0, + dist_e = \"norm\", dist_c = \"norm\")\nThe function includes the baseline utilities in the model for \\(e\\) and achieves identification under MNAR using complete case restrictions (\nrestriction = \"CC\") and informative priors on the sensitivity parameters for the mean \\(e\\) (\nDelta_e = Delta_e). Economic results in terms of posterior summaries about the mean parameters from the model can be seen using the\n> print(NN.pat2) mean sd 2.5% 97.5% Rhat n.eff mu_c 208.837 53.806 103.712 319.379 1.007 1000 mu_c 189.257 39.142 109.332 267.530 1.001 1000 mu_e 0.717 0.029 0.664 0.772 1.018 100 mu_e 0.878 0.031 0.819 0.940 1.000 1000\nFor comparison, we also fit the same model under MAR, by typing\n> NN.pat1=pattern(data = MenSS, model.eff = e ~ u.0, model.cost = c ~ 1, + type = \"MAR\", restriction = \"CC\", n.iter = 1000, Delta_e = 0, Delta_c = 0, + dist_e = \"norm\", dist_c = \"norm\")\nWe assess the impact on the cost-effectiveness results between the MNAR and MAR models by looking at the acceptability curves associated with each model using again the function\nceac.plot inside the package\n> par(mfrow=c(1,2)) > BCEA::ceac.plot(NN.pat1$cea) > BCEA::ceac.plot(NN.pat2$cea)\nResults under MNAR (\nNN.pat2) clearly suggest a higher chance for the new intervention to be cost-effective compared with those from the MAR model (\nNN.pat1). This is in accordance with our MNAR assumptions under which we expect, on average, lower QALYs in the control with respect to the intervention group compared with the results under MAR (when\nDelta_e = 0). The range of values for the sensitivity parameters under MNAR should be informed based on some external source of information (e.g. expert opinion) which can be used to guide the choice of the values and the number of scenarios to explore.\nEven though, technically speaking, hurdle models cannot be qualified as missingness models, they can still be specified so to assess the impact of some MNAR assumptions on the posterior results. This can be achieved by making arbitrary assumptions about the number of individuals with missing outcomes who are assigned a structural value in the model.\nConsider first a standard hurdle model specification under MAR. We specify the model using\nhurdle to handle both structural ones and zeros in \\(e\\) and \\(c\\) from our economic data in\nMenSS (setting the arguments\nse = 1 and\nsc = 0).\n> NN.hur1=hurdle(data = MenSS, model.eff = e ~ u.0, model.cost = c ~ 1, + model.se = se ~ 1, model.sc = sc ~ 1, type = \"SCAR\", se = 1, sc = 0, + n.iter = 1000, dist_e = \"norm\", dist_c = \"norm\")\nThe model assumes that the mechanisms of the structural values in both outomes do not depend on any observed covariate, i.e. it is structural completely at random (SCAR). The function automatically assignes all individuals with an observed one and zero to the structural components of the effectiveness and cost mixture distributions, while all the remaining individuals are modelled using normal distributions. In general, we do not know to which component of the mixture individuals with a missing outcome value should be assigned, as this information cannot be obtained from the data. However, based on some external information that we may have, we can impose this assignment, which effectively corresponds to a MNAR mechanism.\nWe can perform this type of analysis in\nmissingHE by first creating an indicator variable (called\nd_e), telling for each individual whether a structural value is observed (\nd_e = 1) not observed (\nd_e = 0) or missing (\nd_e = NA). For example, focussing on the effectiveness variables, we can obtain this indicator by typing\n> d_e <- ifelse(MenSS$e == 1, 1, 0) > > #number of ones > sum(d_e == 1, na.rm = T)  17\nNext, for all or some of the individuals with a missing effect value, we set the value of\nd_e = 1 to assign them to the structural component of the hurdle model. For example, we may believe that it is likely for all individuals aged \\(< 22\\) to be associated with a perfect health status (i.e.\ne = 1). We can obtain this by typing\n> myd_e <- ifelse(is.na(d_e) & MenSS$age < 22, 1, d_e) > > #number of ones > sum(myd_e == 1, na.rm = T)  41\nThe number of individuals associated with \\(e = 1\\) has considerbly increased with respect to that based on the observed data alone. We can now proceed to fit our model using this new indicator variable for the structural values of \\(e\\) by setting the optional argument\nd_e = myd_e.\n> NN.hur2=hurdle(data = MenSS, model.eff = e ~ u.0, model.cost = c ~ 1, + model.se = se ~ 1, model.sc = sc ~ 1, type = \"SCAR\", se = 1, sc = 0, + n.iter = 1000, dist_e = \"norm\", dist_c = \"norm\", d_e = myd_e)\nWe can inspect the posterior results by typing,\n> print(NN.hur2) mean sd 2.5% 97.5% Rhat n.eff mu_c 203.030 50.336 117.465 312.938 1.000 1000 mu_c 182.136 38.041 110.688 259.550 1.005 450 mu_e 0.930 0.017 0.896 0.960 1.001 1000 mu_e 0.950 0.018 0.911 0.980 1.008 240\nand we can look at how imputations in each treatment group are carried out based on our model using the generic\n> plot(NN.hur2, outcome = \"effects\")\nAs it is possible to see, for some individuals, imputed values are essentially equal to one with very small credible intervals. These imputations are due to the fact that the outcome values for these people are assumed to be one with almost no uncertainty. Finally, we compare the economic results from the two alternative hurdle models using the\nceac.plot function from the\n> par(mfrow=c(1,2)) > BCEA::ceac.plot(NN.hur1$cea) > BCEA::ceac.plot(NN.hur2$cea)\nThe probabiility of cost-effectiveness for the “standard” hurdle model (\nNN.hur1) remains stable around \\(0.6\\) for most willingness to pay values. However, for the MNAR model (\nNN.hur2), results indicate an higher chance of cost-effectiveness up to about \\(0.8\\) for most threshold values. This is due to the fact that, under our MNAR assumptions, the difference between the treatment groups in terms of the number of individuals assigned to a structural one is more in favour of the new intervention compared with that under MAR."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:3b79d5e5-42d1-4fa6-a3c2-da9b22437b47>","<urn:uuid:98bdb97a-1b24-4b7b-942c-8e9184e9eb56>"],"error":null}
{"question":"How do the approaches to nitrogen management in environmental policy compare with climate change mitigation strategies under the Paris Agreement?","answer":"Both domains involve comprehensive management strategies but differ in their approaches. For nitrogen management, the SAB recommends using the nitrogen cycle framework and suggests a 25% reduction of excess reactive nitrogen can be achieved with existing technology, though this alone won't solve the problems. The Paris Agreement, in contrast, takes a more structured global approach, requiring all countries to formulate national strategies to reduce emissions, participate in five-year Global Stocktake exercises, and develop long-term low carbon emission strategies. Both issues involve multiple stakeholders, but while nitrogen management focuses primarily on domestic controls, the Paris Agreement establishes different obligations for developed and developing countries, with developed nations providing resources and developing nations receiving assistance for implementation.","context":["This original SAB study analyzes sources and fate of reactive nitrogen in the environment, and provides advice to the EPA on integrated nitrogen research and control strategies.\nSources of Reactive Nitrogen\nNitrogen gas in the air is an abundant, inert form of nitrogen that is transformed by nitrogen-fixing microbes into reactive forms of nitrogen that are taken up by algae, plants and other producers at the base of the food web. Human activities (primarily production and use of nitrogen fertilizers, nitrogen-fixing legume crops, and burning of fossil fuels) introduce five times more reactive nitrogen into the U.S. environment than natural sources.\nThe overload of reactive nitrogen causes a range of effects as it cycles in the atmosphere, on land, and in water bodies. This sequence of effects is called the “nitrogen cascade.” Reactive nitrogen provides essential benefits as a fertilizer for food production. However, most of this nitrogen is not taken up by crops and is lost to the environment where it can contribute to the impacts noted above. Nitrogen oxides from burning of fossil fuels for transportation and power generation contribute to formation of smog, particulate matter and acid rain, and then can go on to contribute to over-fertilization of unmanaged forests and grasslands, coastal eutrophication, greenhouse effect and stratospheric ozone depletion.\nThe SAB recommends (1) the use of the nitrogen cycle as an essential framework to address the environmental loading of reactive nitrogen; (2) an integrated cross-media approach to more effectively manage reactive nitrogen; (3) and monitoring and research to support management of reactive nitrogen. The SAB suggests that a 25 percent reduction of excess reactive nitrogen can be achieved with existing technology in the near term. The SAB also emphasizes that this decrease alone will not solve the problems of excess reactive N in the environment.\n- Letter to the Administrator (PDF, 18 pp., 313 kb, About PDF Files)\n- Front Matter (PDF, 16 pp., 197 kb, About PDF Files)\n- Executive Summary (PDF, 12 pp., 337 kb, About PDF Files)\n- Chapter 1. Introduction (PDF, 8 pp., 235 kb, About PDF Files)\n- Chapter 2. Sources, Transfer and Transformation of Nr in Environmental Systems (PDF, 30 pp., 2228 kb, About PDF Files)\n- Chapter 3. Impacts of Nr on Aquatic, Atmospheric and Terrestrial Ecosystems (PDF, 2 pp., 181 kb, About PDF Files)\n- Chapter 4. Metrics and Current Risk Reduction Strategies for Nr (PDF, 16 pp., 2306 kb, About PDF Files)\n- Chapter 5. Integrated Risk Reduction Strategies for Nr (PDF, 14 pp., 964 kb, About PDF Files)\n- Chapter 6. SAB Recommendations for Nr Data Collection, Risk Management and Research (PDF, 16 pp., 308 kb, About PDF Files)\n- Appendices (PDF, 34 pp., 6025 kb, About PDF Files)\n- References (PDF, 20 pp., 283 kb, About PDF Files)\n- Full report (PDF, 172 pp., 14 MB, About PDF Files)\n- Additional Acknowledgments (PDF, 1 p., 15 kb, About PDF Files)\n- Briefing Slides: Reactive Nitrogen in the U.S.--An Analysis of Inputs, Flows, Consequences and Management Options(PDF, 17 pp., 812 kb, About PDF Files)","Understanding the Paris Agreement, where to from here, with S.P.R.E.P\nThe adoption of the Paris Agreement at the recent 21st Conference of the Parties (COP) to the United Nations Framework Convention on Climate Change (UNFCCC) marks a potentially revolutionary moment in the history of the battle against climate change.\nFor the first time we now have a global agreement that obliges all countries who are ‘Parties’ to the agreement to take meaningful action on climate change.\nThe main difference with the Kyoto Protocol, which had obligations for developed country Parties only – meaning that some larger developing countries, such as India, China, and Brazil, for example, had no obligation to reduce their emissions. Under this new Agreement, all countries are now required to reduce their greenhouse gas emissions and take some form of action to address climate change.\nWhat does the Paris Agreement mean for the Pacific? Agreement to limit global temperature change\nAs mentioned above, the Paris Agreement called for all parties to limit global temperature change to well below 2 degrees Celsius above pre-industrial temperature levels. To put this into perspective, scientists have noted that the global temperature has already increased by 0.7 degrees from pre-industrial levels. The Intended Nationally Determined Contributions (I.N.D.Cs) collected before COP 21 in Paris will put the world in a 2.7 degrees pathway.\nUnder the Paris Agreement, countries must take actions to ensure that the temperature increase does not exceed 2 degrees above pre industrial levels. Recognising that this level of warming would be too high for many vulnerable nations, the Paris Agreement also calls for countries to make further progress to limit warming to no more than 1.5 degrees Celsius above pre-industrial levels. This was a key ask from political leaders of the Pacific.\nEfforts aimed at the 1.5 degree target will be supported by the obligation of all countries to look at the long term picture through their low carbon emission development strategies.\nUnder the previous arrangements, the majority of climate change funds focussed on greenhouse gas emissions known as ‘mitigation’ actions, with less emphasis on adaptation funding which is an important source of funding for the Pacific, to help address the impacts of climate change. Under the new Agreement, equal weight will be placed on mitigation and adaptation funding, which will bring about more adaptation funding opportunities to the Pacific.\nSupport for Adaptation\nWhile the Kyoto Protocol focused almost purely on mitigation, the Paris Agreement adopted a global goal for adaptation – to enhance the capacity to adopt, strengthen resilience against impacts and reduce vulnerability to climate change. This has elevated the status of adaptation giving it equal importance as an issue. This is particularly beneficial to countries in the Pacific, who are amongst the most vulnerable to climate change.\nA mechanism to address Loss and Damage caused by Climate Change\nThe Paris Agreement also provides for a mechanism to address loss and damage, caused by the impacts of climate change. While previous COP’s had agreed to such a mechanism known as the Warsaw International Mechanism on Loss and Damage, the danger was that COP decisions could be over turned and may not be permanent. This new mechanism in the Paris Agreement spans issues such as insurance for climate change related events, and how to deal with the displacement of people due to climate change.\nWhat are the obligations of countries under this Agreement?\nUnder the Paris Agreement there are different sets of obligations - some for all countries, some for developed countries only, and some for developing countries such as those in the Pacific island region.\nAll countries will now have to formulate national strategies to reduce their emissions of climate changing gasses - mitigation against climate change. These will be in the form of ‘Nationally Determined Contributions’ where governments decide at the national level how they might best do this, for example, through their energy or transportation sectors, or in comes cases, through the protection of national forests which take carbon out of the atmosphere and store it.\nAll countries will be required to report against the actions that they take to both mitigate against climate change, and also what they are doing to adapt to climate change.\nThis information will be used in a Global Stocktake exercise held every five years. This ‘Global Stocktake’ will be used to measure progress against limiting the global temperature, and also to inform future discussions on whether or not more action is needed. Furthermore, all countries will have to formulate longer term strategies aimed at low carbon emission development.\nDeveloped countries will have much more stringent reporting requirements, and are requested to provide additional resources such as financial, technology and capacity building, to assist developing countries to meet their climate change obligations.\nDeveloping countries, like the Pacific islands will be provided with the assistance to carry out their obligations and to develop and implement strategies to cope with the impacts of climate change.\nThis demonstrates the willingness from the international community to tackle the global issue of climate change. The challenge now is for the region to be proactive and take the necessary steps for ratification and implementation of the Paris Agreement.\nThe Secretariat of the Pacific Regional Environment Programme (SPREP) will continue to work closely with its member countries, regional organisations and development partners to provide direct support to the implementation of this agreement as follows:\n• Assist Pacific Island Countries to sign on to ratify the Paris Agreement\n• Develop national strategies to reduce the emissions of greenhouse gases which are referred to as Nationally Determined Contributions\n• Provide assistance for countries to report against progress of meeting the goals of these strategies, every five years\n• Work with members to develop long term low carbon development strategies\n• Provide on-going support to adaptation and resilience building programmes\n• Work with countries to complete their Adaptation Communications which all countries are required to produce\n• Assist countries to access the financial opportunities provided by the Agreement, including mitigation and adaptation funding under the Global Environment Facility, Adaptation Fund and Green Climate Fund\nTo learn more about the Paris Agreement please access the below. You can also contact Dr Netatua Pelesikoti the Director of the Climate Change Division of SPREP at [email protected]\n• You can read the Paris Agreement here or visit http://unfccc.int/files/home/application/pdf/paris_agreement.pdf\n• To read the Decision adopting the Paris Agreement please click here or visit http://unfccc.int/files/home/application/pdf/decision1cp21.pdf\n• To learn more about The Next Steps for the Paris Agreement please click here or visit http://unfccc.int/files/meetings/paris_nov_2015/application/pdf/paris_agreement_next_steps_post_adoption.pdf\n• For a copy of All COP 21 Outcomes please click here or visit http://unfccc.int/meetings/paris_nov_2015/session/9057.php"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:572db499-5469-4fcf-a40d-b0554e4bd0ac>","<urn:uuid:2a00a85d-3d08-43e4-a00b-750bc8865644>"],"error":null}
{"question":"What steps are needed to improve the bonding between silk and resin in composites?","answer":"To improve the bonding between silk and resin in composites, sizing must be applied to the silk fabric first. Sizing is a plastic-based mixture that adds stiffness and finish to synthetic fibres. The right sizing compound can improve resin adherence and reduce void formation (tiny bubbles within the resin) during the manufacturing process. The mechanical properties of the composite can be modified by changing the chemical composition of the sizing and its application method.","context":["UHCL scientist suggests using silk fibres in composites\nPic: University of Houston-Clear Lake\nSilk fibres can make composites more resilient to impact and stress, according to a University of Houston-Clear Lake assistant professor. This implies creating load-bearing composites that could replace much of the steel used in cars and other manufactured goods is possible. Traditionally, composites consist of resins reinforced with carbon or glass fibres.\nThe demand for natural fibre-reinforced composite materials is expected to surge through 2023, market research firm Modor Intelligence reported, a demand driven by the automotive industry as it races to meet US government standards for more fuel-efficient vehicles by 2025. It will require composites that are more lightweight, recyclable, tougher and cost-effective to produce. University of Houston-Clear Lake Assistant Professor of Mechanical Engineering Youssef Hamidi’s ongoing research into this field shows promising results. Hamidi is seeking funding to continue his research.\nTraditionally, composites consist of resins reinforced with carbon or glass fibres. In recent years, manufacturers have worked with plant fibres — cotton, jute, hemp and others — in attempts to create composites from sustainable and biodegradable materials. Those attempts have come with trade-offs in either manufacturing costs or in the materials’ “mechanical properties” — hardness, impact resistance, the ability to withstand stress, strain, deformation and other factors.\nHamidi, who is experimenting with using silk to reinforce composites, explained the process and his progress in an article published recently in Materials, a renowned scientific journal on materials science.\nCarbon or glass fibres in traditional advanced composites give the material strength and are sometimes costly to produce, depending on usage, Hamidi explained. But the fibres are often shatterable, which contribute to the composites’ brittleness. In contrast, he said, silk fibres are ductile, which by their nature would make composites more resilient to impact and stress. It raises the possibility of creating load-bearing, silk-fibre composites that could replace much of the steel used not only in cars, but in other manufactured goods.\nHamidi, who joined UHCL’s mechanical engineering faculty in 2018, has been researching composite materials since 2000, mainly working out ways to reduce process-induced defects. He and his colleagues at the University of Oklahoma’s School of Aerospace and Mechanical Engineering in Norman, Okla, started working with silk about a year ago.\n“I was thinking about what would be a good fit,” he said. “In most (bio-based) applications, people are using short, plant-based fibres. But silk has higher properties. It’s readily available. There’s no shortage of it.”\nAmong silk’s notable properties, Hamidi says, are its tensile strength and the amount of elongation it allows before it breaks, which would make silk-fibre composites far less brittle than those made with glass, carbon or other natural fibres. “That’s a nice feature if you are using the composite in some application where impact is expected,” he said, using car bumpers or fenders as examples.\nIn composite materials, before resin is applied, untwisted bundles of continuous filaments, called “tows,” are woven or knit into “preforms” — three-dimensional fabric forms designed to conform to a specific shape. Hamidi first worked with silk filaments, straight from silkworm cocoons, but found it cumbersome. He soon discovered that silk fabric — straight off the shelves — worked best.\nHowever, he found that once the resin dried, it left tiny voids, or bubbles within the resin. Furthermore, the resin didn’t adhere fully to the fabric. He added that it’s a common problem in composites manufacturing, one that diminishes the finished molding’s integrity. Manufacturers solve the problem by using large, expensive autoclaves to apply intense compression to the composite during the molding process to remove the defects.\n“Autoclaves cost an arm and a leg,” Hamidi said. Since the idea is to create a low-cost alternative to high-cost manufacturing processes, Hamidi wants to find a solution that would deliver “a decent composite at a fraction of the price.”\nUnderstanding how these voids form and how to remove them was the theme of Hamidi’s doctoral dissertation. He is currently tackling the resin/fibre adherence problem. For that, he turned to a solution known to tailors, seamstresses and others who work with textiles: sizing.\nIn textiles, sizing is a plastic-based mixture that adds stiffness and finish to synthetic fibres, like starch does to natural fibres. The principle is similar for composite materials, although the chemistry is different. Hamidi expects that applying the right sizing first to the silk fabric will improve the resin adherence and reduce voids, which would result in silk composites with significantly improved performance.\nHe’s currently working with UHCL chemistry professors on coming up with a better sizing compound. “We need to find the right sizing, one that improves the bonding. Normally, the mechanical properties of the composite are defined by that bonding. We can change the bulk of mechanical properties of the composite by changing the chemical composition of the sizing and how it is applied.” (SV)\nFibre2Fashion News Desk – India"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:343b558d-dfe1-4820-a565-dbc5cc0203c1>"],"error":null}
{"question":"I'm fascinated by massive space impacts! How do the Tunguska event and the Cretaceous-Tertiary extinction impact compare in terms of their magnitude and effects on Earth?","answer":"The Cretaceous-Tertiary extinction impact was vastly more powerful than the Tunguska event. The C-T impact involved an asteroid 10-14 kilometers in diameter, created a 180-kilometer crater (Chicxulub), and caused a mass extinction that killed off the dinosaurs. It left worldwide evidence including an iridium layer, shocked quartz, and high levels of soot and ash. The Tunguska event in 1908, while significant, was much smaller - estimated to release energy equivalent to 10-15 megatons of TNT. It flattened trees over 2,000 km² and caused effects up to 400 km away, but left no crater as the object (likely an 80-meter ice-rich body) exploded about 8 km above the surface.","context":["Centuries ago, the Western vision of the past saw an Earth that had been created a few thousand years ago, and had been shaped since that time by a number of global cataclysms (see catastrophism). This view gradually gave way to the consensus that the Earth was several billion years old, and that its features reflected the slow processes of gradual change.\nSince 1970, this view has gradually expanded to accommodate the fact that the Earth has in fact gone through periods of abrupt and catastrophic change due to the impact of large asteroids and comets on the planet. A few of these impacts may have caused massive climate change and the extermination of large numbers of plants and animals.\nThe fact that this modified view of the Earth's history did not emerge until recently seems surprising. Based on crater formation rates determined from our closest celestial partner, Luna, astronomers have determined that during the last 600 million years the Earth has been struck by 60 objects larger than 5 kilometers or more across. The smallest size of these impactors would release the equivalent of 10 million megatons of TNT and leave a crater 95 kilometers across.\nIn the past 600 million years there have been 5 major mass extinctions that on average extinguished half of all species. The last such mass extinction led to the demise of the dinosaurs and has been found to have coincided with a large asteroid impact; this is the Cretaceous-Tertiary extinction event.\nEvidence is also mounting that other mass extinctions may also have been caused or at least assisted by large impacts. The largest mass extinction to have affected life on Earth was the Permo-Triasic one that ended the Permian Period 250 million years ago and killed-off 90% of all species.\nIn 1980 Luis Alvarez[?] and his son Walter[?] led a team from the University of California at Berkeley that discovered unusually high concentrations of iridium, an element that is rare in he Earth's crust but relatively abundant in many meteorites From the amount and distribution of iridium present in the 65 million year old \"iridium layer\" , the Alvarez team later estimated that an asteroid of 10-14 kilometers must have collided with the earth. This iridium layer at the C-T boundary has been found worldwide at 100 different sites. Multidirectionaly shocked quartz, which is only known to form as the result of large impacts, has also been found in the same layer at more than 30 sites. Soot[?] and ash at levels tens of thousands times normal levels were found with the above.\nAnomalies in chromium isotopic ratios found within the C-T boundary layer strongly support the impact theory. Chromium isotopic ratios are homogeneous within the earth, therefore this isotopic anomalies exclude a volcanic origin which was also proposed as a cause for the iridium enrichment. Furthermore the chromium isotopic ratios determined in the C-T boundary are similar to the chromium isotopic ratios found in carbonaceus chondrites[?]. Thus a probable candidate for the impactor is a carbonaceous asteroid but also a comet is possible because comets are assumed to consist of material similar to carbonaceous chondrites[?].\nProbably the most convincing evidence for a worldwide catastrophe was the discovery of the crater which has since been named Chicxulub Crater. This so-called smoking gun is centered on the Yucatan Peninsula of Mexico and was discovered by Tony Camargo and Glen Pentfield while working as geophysicists for the Mexican oil company PEMEX[?]. What they reported as a circular feature later turned out to be a crater estimated to be 180 kilometers in diameter. Other researchers would later find that the end-Cretaceous extinction event that wiped out the dinosaurs had lasted for thousands of years instead of millions of years as had previously been thought. This would be the final piece of evidence that convinced the vast majority of scientists that this extinction resulted from a point event that is most probably an extra-terrestrial impact and not from increased volcanism and climate change (which would spread its main effect over a much longer time period).\nIt was the lack of high concentrations iridium and shocked quartz which has prevented the acceptance of the idea that the Permian extinction (so-called mother of mass extinctions) was also caused by an impact. However, during the late Permian all the continents were combined into one supercontinent named Pangaea and all the oceans formed one superocean, Panthalassa. If an impact occurred in the ocean and not on land at all, then there would be little shocked quartz released (since oceanic crust has relatively little silica) and much less material\nAlthough there is now general agreement that there was a huge impact at the end of the Cretaceous that led to the iridium enrichment of the K-T boundary layer, remnants have been found of other impacts of the same order of magnitude that did not result in any mass extinctions, and in fact there is no clear linkage between an impact and any other incident of mass extinction.\nNonetheless it is now widely believed, if a little on faith, that mass extinctions due to impacts are an occasional event in the history of the Earth. Indeed, in the early history of the Earth, about four billion years ago, they were almost certainly common since the skies were far more full of \"junk\" than at present. Such impacts could have included strikes by asteroids hundreds of kilometers in diameter, with explosions so powerful that they vaporized all the Earth's oceans. It was not until this \"hard rain\" began to slacken, so it seems, that life could have begun to evolve on Earth.\nIn addition to the extremely large impacts that happen every few tens of millions of years, there are many smaller impacts that occur much more frequently but which leave correspondingly smaller traces behind. Due to the strong forces of erosion at work on Earth, only relatively recent examples of these smaller impacts are known. A few of the more famous or interesting examples are:\nThe most significant recorded impact in recent times occurred at Tunguska in Russia, in 1908; see that article for more details. But although the Tunguska event was both spectacular and unparalleled in any historical record, it no longer seems as unique and unusual as it once did. We now know that Earth impacts, fairly big ones, are happening all the time.\nThe late Eugene Shoemaker of the US Geological Survey came up with an estimate of the rate of Earth impacts, and suggested that an event about the size of the nuclear weapon that destroyed Hiroshima occurs about once a year. Such events would seem to be spectacularly obvious, but they generally go unnoticed for a number of reasons: the majority of the Earth's surface is covered by water; a good portion of the land surface is uninhabited; and the explosions generally occur at relatively high altitude, resulting in a huge flash and thunderclap but no real damage.\nSome of have been observed, such as the Revelstoke[?] fireball of 1965, which occurred over the snows of northern Canada. Another fireball blew up over the Australian town of Dubbo[?] in April 1993, shaking things up up a bit but causing no harm.\nOn the dark morning hours of January 18, 2000, a fireball exploded over the town of White Horse[?] in the Canadian Yukon at an altitude of about 26 kilometers, lighting up the night like day and bringing down a third of of the Yukon's electrical power grid, due to the \"electromagnetic pulse\" created by the blast. The meteor that produced the fireball was estimated to be about 4.6 meters in diameter and with a weight of 180 tonnes.\nA particularly interesting fireball was observed moving north over the Rocky Mountains from the US Southwest to Canada on August 10 1972, and was filmed by a tourist at the Grand Teton National Park in Wyoming with an 8-millimeter color movie camera. The object was in the range of size from a car to a house and should have ended its life in a Hiroshima-sized blast, but there was never any explosion, much less a crater. Analysis of the trajectory indicated that it never came much lower than 58 kilometers of the ground, and the conclusion was that it had grazed Earth's atmosphere for about 100 seconds, then skipped back out of the atmosphere to return to its orbit around the Sun.\nMany impact events occur without being observed by anyone on the ground. Between 1975 and 1992, American missile early warning satellites picked up 136 major explosions in the upper atmosphere.\nThe Tunguska event was about a thousand times more powerful than such events. Shoemaker estimated that one of such magnitude occurs about once every 300 years. This is not a long interval even by historical standards, and it is a somewhat nerve-wracking question to consider when the next \"Big One\" will be, and more to the point, where.","Every year, tens of thousands of meteorites fall toward Earth. Most of them are very small, about the size of a stone, and end up disintegrating in the atmosphere. But occasionally, these asteroids can have slightly more worrying dimensions, even reaching a few kilometers long. When a this happens, huge blasts leave enormous craters on the Earth’s surface. The most famous example contributed to the demise of the dinosaurs 65 million years ago. Today, however, we are not out of danger. Indeed, a large asteroid hasrecently been detected, and it’s moving towards us…\nAsteroids or Meteorites?\nWhat’s the difference?\nAsteroids are rocky objects wandering in space, generally orbiting around a star or planet. They are too small to be spherical like planets, a shape that results from the planets’ own gravitational pull. The largest asteroids are about 900 km in diameter, and the smallest, called meteoroids, are even smaller than a stone.\nWhen asteroids cross a planet’s orbit, they are likely to collide with the planet, particularly in the case of meteoroids. You’ve probably seen one entering Earth’s orbit: it zoomsthrough the atmosphere at a high speed, and friction with the air causes it to heat up and ignite, leaving a bright and fleeting trail in the night sky. They are shooting stars.\nGenerally, friction causes them to disintegrate when entering the atmosphere, so they rarely make it to the Earth’s surface. The rocky fragments that reach the Earth’s surface without disintegrating are called meteorites.\nWhat we refer to as “shooting stars” are in truth meteoroids entering Earth’s atmosphere and catching fire. The fragments that manage to reach the Earth’s Surface are called meteorites.\nWhere Are Asteroids?\nThere’s a belt between Mars and Jupiter packed with asteroids orbiting the Sun. Most of the asteroids in the solar system are located there. There are millions of them—many measuring more than 1 km in diameter—, but the total mass of these bodies is less than 6% of the Moon’s mass. Their orbit around the Sun is stable, but some get deflected and cross through the path travelled by the planets. This asteroid belt is thought to have resulted from Jupiter’s imposing gravitational pull; during the first stages of the solar system, the pull was so powerful that it prevented these fragments from aggregating and forming another planet.\nNot all asteroids are in this belt. Others can be found orbiting other planets. These asteroids are called Trojans. Jupiter is the planet with the most Trojans, since it has the greatest gravitational pull of all the planets in the Solar System. There are also centaurs orbiting the Sun, but they are beyond the asteroid belt among thegiant planets. Last but not least, some asteroids labeled as NEO (Near Earth Objects) greatly interest us because they move close to Earth. Their orbits cross our planet’s orbit, so they are monitored closely…\nDepending on its size, composition, and path, an asteroid hitting a planet will form a crater on the planet’s surface. An object measuring a few dozen meters in diameter will produce a very powerful blast, much greater than the power of an atomic bomb.\nToday, tens of thousands of meteorites hit the Earth every year, but this is not an uncommon event. Shortly after the solar system was formed, impacts with relatively large and small asteroids were much more frequent on all the planets. The planets were under intense and relentless bombardment! The craters on the Moon’s surface bear witness to that. So, how is it that there are no craters similar to those on the Moon on the Earth’s surface? Why is it that the Earth’s surface does not resemble the Moon’s, with its distinctiveSwiss cheese look? The answer issimple: Earth experiences erosion, a phenomenon barely found on our satellite. It is a process of wear caused by the air, water, and living organisms on the planet. Together, they are capable of erasing these geological scars from the planet’s surface.\nTo have an idea, erosion over a few hundreds of millions of years could flatten the Pyrenees and transform them into a plain.\nImpacts with Earth\nDuring the first stages of Earth’s formation, intense asteroid showers were commonplace. Fortunately, the rate of impacts decreased over the years and life appeared. The last large impact—a powerful explosion which caused all oceanic water to boil and evaporate—is thought to have occurredaround 4 billionyears ago. Water on Earth has been in the liquid state since then, a necessary condition for the appearance and sustainment of life as we know it.\nImpacts, however, kept occurring. The most famous one contributed to the extinction of the dinosaurs; it hit an area near present-day Mexico about 65 million years ago. The resulting explosion was much more powerful than dozens of thermonuclear bombs together, sending large amounts of dusty debris and vapor into the atmosphere, reducing the amount of sunlight reaching the Earth’s surface over a very long time.\nThat said, this wasn’t the last impa ct to hit the Earth. Smaller asteroids regularly hit the surface, so astronomers closely scan the night sky and calculate the paths followed by the objects nearest to Earth. In fact, a relatively large asteroid coming Earth’s way was recently detected, and it is expected to be rightabove us by 2029. This is not science fiction!\nThe Moon is thought to have formed when a huge asteroid hit the Earth and the impact tore out a fragment that ended up orbiting around it.\nThe Mysterious Tunguska Incident\nAt 7:17 a.m. on June 30, 1908, a huge explosion lit up the skies of Tunguska, a forest region in central Siberia, Russia. The blast knocked down trees and burned forests over an area larger than 2,000 km2. People on horses were knocked down and glass was shattered as far as 400 km away from the blast. The conductor of the Trans-Siberian Express had to stop the train for fear of derailment. The energy from the blast has been estimated as the equivalent of 10 or 15 megatons (the Hiroshima bomb released “only” 0.015 megatons of energy). But strangely enough, no crater was formed. Today, the scientific community believes that a blast occurred shortly before the meteorite impacted the surface, approximately 8 km above it. The meteorite was about 80 meters in diameter, mostly composed of ice, and likely to have been a fragment of a comet. Since then, similar cases have been reported.\nAn Asteroid Approaches Earth\nPresently, about 4,000 objects roaming in space are treated as NEOs. When one of these bodies gets closerthan 0.05 Astronomical Units (7.5 million kilometers) to the Earth, it is classified as a PHA, a Potentially Hazardous Object. Their name is well deserved: if one of these objects hit the Earth, the consequences for our civilization would be devastating. As of today, we know of about 800 objects PHAs. One of them in particularly worrying: Apophis.\nAccording to some reliable calculations, Apophis is a large asteroid that may reach our planet around 2029. Although we know now that there won’t be a full impact, the encounter will be so close that the effects could nonetheless be disastrous. Alarm bells are starting to ring, and scientists are already undertaking measures including projects aimed at deflecting it. One such project is run by a group of Spanish investigators: the Quijote Project.\nIn truth, accurately calculating the path of an asteroid is still a daunting task. Scientists believe that Apophis may not be such a real threat, but bearing in mind that a powerful asteroid impact occurs every 40,000 years, it is not a bad idea to try to be ready for any other similar threat.\nAsteroids or Planets?\nOther rocky bodies are not large enough to be considered planets, or small enough to be labeled as asteroids. Pluto, lurking in the outer fringes of the solar system, is the most paradigmatic example. Until very recently Pluto was considered a planet, despite being smaller than the Moon. Astronomers solved this problem by naming cases such as Pluto ‘dwarf planets’. Pluto attained this status in August, 2006, together with Ceres and Eris, which used to be labeled as asteroids.\nWas Life Hitching a Ride on Meteorites?\nIs it possible that we are all aliens? That’s what panspermia, a scientific hypothesis claiming that life may have appeared on Earth transported by meteorites. Although the theory does not have many proponents, it has recently received some experimental backing. Jacek Wierzchos, a chemist at the Universitat de Lleida (Spain) has taken part in the experiment.\nA sample of lichens and microorganisms was sent into space on the Photon M3 spacecraft that was launched last September from Baikonur (Kazakhstan). Two weeks later, the spacecraft returned to Earth and the living organisms were still thriving. “If organisms are capable of surviving a trip through spapce, we can’t ignore the fact that life may have reached Earth from space,” says Wierzchos, the man who designed this experiment together with Carmen Ascaso and Asunción de los Ríos, from IRN-CSIC (Spain’s Institute of Natural Resources, Madrid), Leopoldo García Sancho, from the Universidad Complutense of Madrid, and Rosa de la Torre, from INTA (Spain’s National Institute for Aerospace Technology).\nMaybe life did not reach Earth traveling inside meteorites, but a large amount of organic matter—the type of matter that living organisms are made of—definitelyhas reached continues to reach Earth—confined inside of meteorites ever since Earth was formed."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:2d77b02a-61a4-4b89-a4b1-35097533a670>","<urn:uuid:b182da61-ec14-48e5-bb4a-82ecf7f5136f>"],"error":null}
{"question":"I've had a difficult birth experience and have been feeling disconnected: What are the warning signs of postpartum depression that require professional help, and what treatment approaches do doctors typically suggest first?","answer":"Warning signs requiring professional help include feeling separate from everything, having difficulty feeling grounded, experiencing inexplicable fears, feeling repeatedly angry with your baby, becoming apathetic, feeling cut off from partner or baby, experiencing time distortion, and feeling constantly tired despite rest. When seeking treatment, good doctors should first run blood tests to rule out thyroid disorders or anemia before prescribing medication. They shouldn't immediately prescribe antidepressants without a thorough evaluation. Treatment typically combines different approaches - medication may be paired with therapy, particularly Cognitive Behavioral Therapy, which has proven especially successful for postpartum women. It's important to remember that asking for help is a sign of strength, not weakness.","context":["- Mental Health»\n- Clinical Depression\nNatural Treatments for Postpartum Depression\nSigns and symptoms of postpartum depression\nIt is normal to feel low and even depressed after childbirth. It can pass by fleetingly as postnatal blues on about the third day after the birth when your milk comes in, or span a longer period while your hormones sort themselves out and you begin to make the emotional adjustments to your new life. We all have different resources for dealing with the stresses of birth and parenthood: it’s a mistake to assume that because you have been through a difficult birth that you will feel depressed - just as it’s a mistake to assume you shouldn’t be depressed because things haven’t been that bad.\nListen to those you love and trust if they tell you that you are looking (and sounding) low–post-natal depression which lasts longer than a few days always needs the help of competent professionals: your doctor, a counselor or psychotherapist and/or a homeopathic practitioner. Don’t ignore your distress by telling yourself (or others) that it isn’t that bad, or that other women have far worse to cope with, or you’ll get over it. Remember it is a sign of strength to ask for help, not a sign of weakness.\nSeek the help of a counselor or psychotherapist to help heal and integrate a particularly difficult birth experience if you are in distress and finding it difficult to bond with your new baby and/or reconnect with your partner, especially if you are suffering from two or more of the following:\n- you feel separate from everybody and everything ... if there is an unpleasant feeling of distance an unreality that affects your life.\n- you cannot feel the floor or pavement solidly under your feet–it is as if you are not connected or are sort of floating.\n- you suffer from inexplicable or overwhelming fears and worries.\n- you feel repeatedly angry with your baby.\n- you feel apathetic and indifferent i.e. nothing matters and what is the point anyway.\n- you feel cut off and unable to respond to your partner or the baby.\n- your sense of time has changed–everything seems to take a long time, even small tasks.\n- you feel tired a lot the time and find it difficult to sleep at night, waking unrefreshed and joyless. Post-natal depression can be mistaken for exhaustion, so if you are dragging yourself around and not sleeping well, or lacking in energy however much rest you get, you may be depressed\nHow to take care of yourself after birth\n- eat well–plenty of fresh foods and protein. Many women find that eating little and often suits them better at this time.\n- invest in a Fast Food Cookbook and learn how to cook healthy meals in minutes.\n- drink plenty of (sugar- and caffeine-free) fluids, especially if you are breastfeeding.\n- only do those chores that are absolutely necessary–delegate as many as you can (and farm out household chores for the first 6-12 weeks, especially if you had a Caesarean.) Remember, the housework will always be there, your baby is only little once!\n- reassess your priorities: these will change with each baby that comes along–the more children you have the more demands on your time and energy, especially emotional energy. A contented mother and baby are much, much more important than a tidy house or a 3-course meal.\nRest relax recharge\n- sleep at night, nap when your baby naps–or at least rest.\n- take some gentle exercise (in the fresh air if possible) every day, this will help your body to recover faster and create energy.\n- do the relaxation or meditation technique that you learnt in pregnancy once a day.\n- have a facial or haircut (at home if you can arrange this).\n- vary your daily activities with your new baby so that you don’t get bored.\n- arrange to spend time each week with a friend doing easy, fun things not associated with work or parenthood.\n- do something just for yourself every day (without the baby): take a bath or shower, sit on your own with a cup of tea, write a letter to a friend, read a magazine or a book–even if it is for ten minutes.\nMothers with special needs\nBabies come in all shapes and sizes: some are quiet and easy-going, others are needy and demanding. All babies are time-consuming–it is more than a full time job, you will be on call 24 hours a day for an indefinite period of time, and this in itself can leave many women feeling completely exhausted. In addition, this job may be one for which you little or even no preparation or training or former experience! Some women have never even held a baby until they hold their own. This makes the job a serious challenge!\nReach out to the support network you set up during your pregnancy–or create one–ask your social worker, GP, midwife, homeopath for local groups and help lines. Use your telephone support system if you don’t have close friends or family living nearby. Make contact with at least one other mother and baby so that you can talk about yourself and your baby and not feel isolated with your small charge. Every new mother needs support–it helps ease the passage into parenthood, and is especially important if you fall into one of the categories below:\n- you have a demanding baby, or a baby with special needs of any sort i.e. a premature baby, a sick or disabled baby, one with colic or one who sleeps during the day but not at night.\n- you are a single parent, or your partner is absent or sick, and especially if you have no close friends or relatives close by who can help out in the early months.\n- this is your first baby–especially if you are a very young mother.\n- you are having difficulties with breastfeeding.\n- you have one or more other children, especially if they are very young as two babies in nappies can be a real handful.\n- you need to return to work within a few weeks or even a few months, especially if you are an older mother.\n- you suffered a lot of stress in your pregnancy, such as moving house or a bereavement or an unexpected change in circumstances.\n- your own health is poor.\n- you had a difficult birth and have found it difficult to recover–i.e. if you are exhausted and still in pain.\n- you are struggling financially.\nHealing after birth\nDon’t fall into the trap of sweeping your distress, your complaints under the carpet while you attend to your baby and her needs. Mothers have needs too, make sure that yours are met and you will find you will recover from the stress of the birth faster and it will make the job of parenting easier.\nThere are many complementary (alternative) therapies that can help with the emotional roller coaster of that post natal period: acupuncture can help with emotional and physical complaints; the healing power of herbs can help with balancing hormones and general healing; homeopathy can help with emotional and physical problems in both mothers and babies and with breastfeeding difficulties; cranial osteopathy is a gentle physical therapy that can balance the body (mothers and the baby) after a difficult labour or where mothers feel achy and ‘out of sorts’; the therapeutic value of massage is well known – an aromatherapy massage is especially delicious for new mothers and can be very healing, as can a reflexology massage.\nChoose a therapy that seems right for you and your needs. Ask your GP or health provider to refer you to a practitioner who is registered with a recognized organization.","Once diagnosed with a Postpartum Mood Disorder, you are then faced with a literal bevy of choices regarding your path to wellness.\nSome doctors may toss pills at you. If that happens, run. Run very fast and very far away from any physician who shoves anti-depressants your way before you’ve even finished describing what’s wrong. A good prescribing doctor will sit down with you and hear you out before grabbing for his pen and pad (or these days, keyboard and internet connection). A good physician should also run a couple of simple blood tests first to rule out thyroid disorders or anemia which need completely different types of medication to show improvement.\nSome doctors may suggest psychotherapy. And that is where things start to get a little sticky. What kind of talk therapy? Will there be a couch? Will it be comfy? Will I have to talk about how my Great Aunt Edna used to kiss me on the cheeks and leave funny lipstick stains? Will I have to talk about things not related at all to my current state of mind? Will I be hypnotized? Or any other strange mumbo jumbo I’ve seen happen on TV or in the movies or from my best friend who found this website and…\nHold the phone there.\nCognitive Behavioral Therapy proved to be the best option out there for me. There was a couch but I didn’t lay down on it. I sat cross-legged on it as I drank coffee and chatted with my therapist. She sat in a really cool rocking chair with a foot stool. I got along fabulously with my therapist. That’s not to say we were bestest of buds but she knew what she was doing, just let me talk and work a lot of my issues out. I did occasionally talk about things in my past but it wasn’t at all like “So, you were born… let’s start there.” She met me where I was and let things fall where they fell. Or at least she seemed to. She did ask questions to get me to think about issues and how I was reacting to them. I had not planned on staying in therapy for long but once I became pregnant again, I made the decision to stay in through my pregnancy. Therapy gradually stopped at about 6 months postpartum of that pregnancy as we scaled our sessions back.\nWhile I will not be covering every single last type of therapy out there, my goal is to provide some basic information for the most common therapies used with Postpartum women.\nAt the top of the list is Cognitive Behavioral Therapy which is actually a blanket term for several types of therapies with similar traits. Primarily Cognitive Behavior Therapy (CBT) promotes that WE have power over our moods through our thoughts. You can read more about it by clicking here. A great resource now available for women and clinicians alike when it comes to treating Postpartum Depression is Karen Kleiman’s Therapy and the Postpartum Woman. You can read more about it by clicking here. (In the interest of full disclosure now required by the FTC, I have not been compensated at all for including this link. I sincerely believe it’s a good resource.)\nEMDR or Eye movement desensitization and reprocessing is gaining popularity as an option. EMDR is most effective with Post Traumatic Stress Syndrome. You can read more about this approach by clicking here.\nPeer Support/Group therapy is also an option. The primary benefit of this option is the realization it provides to women of not being alone. They really aren’t the only ones having a panic attack when they get in a car or experiencing frightening thoughts prancing through their mind at the most inopportune moments. Many times this option is a cost-effective option as well because many groups do not charge. A group led by a therapist may only charge a small fee such as $10-15 for attending. While peer support should absolutely not replace professional medical care for Postpartum Mood Disorders, it is an important aspect to add to recovery. If your area does not have a local peer group, you can find help online. The Online PPD Support Page has a very active forum for postpartum women. You can also visit the iVillage Postpartum or the Pregnant & Depressed/Mental Illness Boards. (Shameless plug on the iVillage boards, I am the Community Leader for both.) Another bonus of peer support? It reduces the recovery time.\nPharmaceutical therapy is also an available option. Some women are against taking medication and that’s perfectly okay. No one should ever be forced to take medication. Typically, pharmaceutical therapy is paired with another type of therapy. In fact, combining pharmaceutical therapy with a type of Cognitive Behavioral Therapy has proven to be one of the most successful approaches for the Postpartum Woman. Sinead O’Connor really put it best during an appearance on Oprah in regards to the function of psychiatric medications. They are the scaffolding holding you up as you revamp yourself. There are risks involved with taking medications and you should absolutely educate yourself, talk with your doctor, and if you end up deciding to take medication, be sure to inform your child’s pediatrician if you are nursing so they can be involved in monitoring for any potential issues.You should also familiarize yourself with the symptoms of Serotonin Syndrome, a fast-acting reaction which occurs for some people when they do not metabolize medication quickly enough. The build up results in a severe toxic situation. You should also avoid stopping any pharmaceutical therapy without consulting with a physician. Stopping suddenly can cause very negative symptoms similar to Serotonin Syndrome. If you have any signs or symptoms of Serotonin Syndrome, get medical help immediately.\nFor more serious cases of Postpartum Depression that do not respond to medication, Electroconvulsive Therapy may be suggested. ECT has come a long way since the 50′s and is a viable choice for many women who do not respond to medication. Now, I am not saying that if you choose not to take medication, you’ll be given ECT. This is for women with severe depression who cannot metabolize or do not respond at all to medication. Choosing not to take medication does not buy you an ECT ticket at all.\nFor women who want to use a more natural approach, there are a lot of choices. Again though, I have to urge you to make sure you are seeing a professional during your recovery. Don’t take something because it worked well for Aunt Martha. Check with your doctor and make sure it’s applicable to your situation and okay for you to take in combination with any other medication you may already be taking. Be sure your naturalist or herbalist is licensed and trained. You’ll also want to make sure that any herbs/natural supplements you are taking are compatible with breastfeeding if you are doing so. You can visit the blog over at Rebuild from Depression for a food/diet based approach.\nNote: I had a reader, Steve, from Noblu.org leave a comment regarding IPT or Interpersonal Therapy. You can click here to read his comment. Thanks, Steve, for stopping by and sharing your knowledge with us!\nAs you can see, there are a lot of options available if you are diagnosed with a Postpartum Mood Disorder. More and more practitioners are becoming familiar with these disorders. More help is available today than even 6 years ago when I was first diagnosed. Remember to ask questions when choosing a therapist, advocate for yourself and what best fits your personal lifestyle philosophy. Don’t settle just because you want to heal. You have the power to say no. It’s your body, your mind, your say.\nTomorrow we’ll be discussing some things you can do on your own to help your recovery along. Stay tuned!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:c4a3ac24-b99b-4ad1-b92f-0bff3de9a0c8>","<urn:uuid:779acf6a-525a-4e35-8b16-643f6e9d4aae>"],"error":null}
{"question":"What are the key adaptations that help trees survive in temperate deciduous forests versus the taiga?","answer":"In temperate deciduous forests, trees like birch, beech, oak, and maple adapt by shedding their leaves in fall and winter, while their seeds go dormant under soil insulation. In the taiga (coniferous forest), conifers have evolved different adaptations - their leaves have a waxy coating to retain water in winter, and their shape helps shed snow to prevent getting weighed down. Additionally, conifer needles contain substances that make the soil acidic when they fall, which prevents other plants from growing on the forest floor.","context":["iPhoneOgraphy – 23 Dec 2016 (Day 358/366)\nDeciduous means “falling off at maturity” ” or “tending to fall off”, and it is typically used in order to refer to trees or shrubs that lose their leaves seasonally (most commonly during autumn) and to the shedding of other plant structures such as petals after flowering or fruit when ripe. In a more general sense, deciduous means “the dropping of a part that is no longer needed” or “falling away after its purpose is finished”. In plants it is the result of natural processes. “Deciduous” has a similar meaning when referring to animal parts, such as deciduous antlers in deer or deciduous teeth, also known as baby teeth, in some mammals (including humans).\nIn botany and horticulture, deciduous plants, including trees, shrubs and herbaceous perennials, are those that lose all of their leaves for part of the year. This process is called abscission. In some cases leaf loss coincides with winter – namely in temperate or polar climates. In other parts of the world, including tropical, subtropical, and arid regions, plants lose their leaves during the dry season or other seasons, depending on variations in rainfall.\nThe converse of deciduous is coniferous, where foliage is shed on a different schedule from deciduous trees, therefore appearing to remain green year round. Plants that are intermediate may be called semi-deciduous; they lose old foliage as new growth begins. Other plants are semi-evergreen and lose their leaves before the next growing season, retaining some during winter or dry periods. Some trees, including a few species of oak, have desiccated leaves that remain on the tree through winter; these dry persistent leaves are called marcescent leaves and are dropped in the spring as new growth begins.\nMany deciduous plants flower during the period when they are leafless, as this increases the effectiveness of pollination. The absence of leaves improves wind transmission of pollen for wind-pollinated plants and increases the visibility of the flowers to insects in insect-pollinated plants. This strategy is not without risks, as the flowers can be damaged by frost or, in dry season regions, result in water stress on the plant. Nevertheless, there is much less branch and trunk breakage from glaze ice storms when leafless, and plants can reduce water loss due to the reduction in availability of liquid water during cold winter days.\nLeaf drop or abscission involves complex physiological signals and changes within plants. The process of photosynthesis steadily degrades the supply of chlorophylls in foliage; plants normally replenish chlorophylls during the summer months. When autumn arrives and the days are shorter or when plants are drought-stressed, deciduous trees decrease chlorophyll pigment production, allowing other pigments present in the leaf to become apparent, resulting in non-green colored foliage. The brightest leaf colors are produced when days grow short and nights are cool, but remain above freezing. These other pigments include carotenoids that are yellow, brown, and orange. Anthocyanin pigments produce red and purple colors, though they are not always present in the leaves. Rather, they are produced in the foliage in late summer, when sugars are trapped in the leaves after the process of abscission begins. Parts of the world that have showy displays of bright autumn colors are limited to locations where days become short and nights are cool. In other parts of the world, the leaves of deciduous trees simply fall off without turning the bright colors produced from the accumulation of anthocyanin pigments.\nPlants with deciduous foliage have advantages and disadvantages compared to plants with evergreen foliage. Since deciduous plants lose their leaves to conserve water or to better survive winter weather conditions, they must regrow new foliage during the next suitable growing season; this uses resources which evergreens do not need to expend. Evergreens suffer greater water loss during the winter and they also can experience greater predation pressure, especially when small. Losing leaves in winter may reduce damage from insects; repairing leaves and keeping them functional may be more costly than just losing and regrowing them. Removing leaves also reduces cavitation which can damage xylem vessels in plants. This then allows deciduous plants to have xylem vessels with larger diameters and therefore a greater rate of transpiration (and hence CO2 uptake as this occurs when stomata are open) during the summer growth period.\nThe deciduous characteristic has developed repeatedly among woody plants. Trees include maple, many oaks and nothofagus, elm, aspen,and birch, among others, as well as a number of coniferous genera, such as larch and Metasequoia. Deciduous shrubs include honeysuckle, viburnum, and many others. Most temperate woody vines are also deciduous, including grapes, poison ivy, Virginia creeper, wisteria, etc. The characteristic is useful in plant identification; for instance in parts of Southern California and the American Southeast, deciduous and evergreen oak species may grow side by side.\nPeriods of leaf fall often coincide with seasons: winter in the case of cool-climate plants or the dry-season in the case of tropical plants, however there are no deciduous species among tree-like monocotyledonous plants, e.g. Palms, yuccas, and dracaenas.\nTrees are significant in many of the world’s mythologies and religions, and have been given deep and sacred meanings throughout the ages. Human beings, observing the growth and death of trees, and the annual death and revival of their foliage, have often seen them as powerful symbols of growth, death and rebirth. Evergreen trees, which largely stay green throughout these cycles, are sometimes considered symbols of the eternal, immortality or fertility. The image of the Tree of life or world tree occurs in many mythologies. Sacred or symbolic trees include the Banyan and the Peepal (Ficus religiosa) trees in Hinduism, the Yule Tree in Germanic mythology, the Tree of Knowledge of Judaism and Christianity, the Bodhi tree in Buddhism and Saglagar tree in Mongolian Tengriism. In folk religion and folklore, trees are often said to be the homes of tree spirits. Germanic paganism as well as Celtic polytheism both appear to have involved cultic practice in sacred groves, especially grove of oak. The term druid itself possibly derives from the Celtic word for oak. The Egyptian Book of the Dead mentions sycamores as part of the scenery where the soul of the deceased finds blissful repose. In many parts of the world travelers have observed the custom of hanging objects upon trees in order to establish some sort of a relationship between themselves and the tree. Throughout Europe, trees are known as sites of pilgrimages, ritual ambulation, and the recital of (Christian) prayers. Wreaths, ribbons or rags are suspended to win favor for sick humans or livestock, or merely for good luck. Popular belief associates the sites with healing, bewitching, or mere wishing.\nF/4, 1/500 sec, ISO – 100, Photoshop CS6\nA parasitic plant is one that derives some or all of its nutritional requirements from another living plant. All parasitic plants have special organs, named haustoria (singular: haustorium), which connect them to the conductive system of their host and provide them with the ability to extract water and nutrient from the hosts. About 4,100 species in approximately 19 families of flowering plants are known. Parasitic plants have a modified root, the haustorium, that penetrates the host plant and connects to the xylem, phloem, or both.\nF/4, 1/8 sec, ISO – 800, Photoshop CS6\nNever cut a tree down in the wintertime. Never make a negative decision in the low time. Never make your most important decisions when you are in your worst moods. Wait. Be patient. The storm will pass. The spring will come. – Robert H. Schuller\nF/7.1, 1/50 sec, ISO – 100, Photoshop CS 6","2 Objectives List three characteristics of tropical rain forests. Name and describe the main layers of a tropical rain forest.Describe one plant in a temperate deciduous forest and an adaptation that helps the plant survive.Describe one adaptation that may help an animal survive in the taiga.\n3 Forest Biomes Most widespread and most diverse biomes Mild to hot temperatures and high rainfallThree main forest biomes of the world: tropical (rain forests), temperate (deciduous), and coniferous (taiga)\n4 Tropical Rain ForestsTropical rain forests - forests or jungles near the equator characterized by large amounts of rain, high temperature, and contain the greatest known diversity of organisms on landHelp regulate world climate and play vital roles in the nitrogen, oxygen, and carbon cyclesHumid, warm, and get strong sunlight which allows them to maintain a fairly constant temperature\n7 Nutrients in Tropical Rain Forests Most nutrients are within the plants, not the soilDecomposers on the rain-forest floor break down dead organisms and return the nutrients to the soil, but plants absorb the nutrientsNutrients from dead organic matter are removed so efficiently that runoff from rain forests is often as pure as distilled water\n8 Nutrients in Tropical Rain Forests Most tropical soils that are cleared of plants for agriculture lack nutrients and cannot support crops for more than a few yearsMany of the trees form above ground roots called buttresses that provide it with extra support in the thin soil\n9 Layers of the Rain Forest Different types of plants grow in different layersThere are four main layers of the rain forest:The Emergent LayerThe Upper CanopyThe Lower CanopyThe Understory\n11 Layers of the Rain Forest Emergent layer - top foliage layer in a forest where the trees extend above surrounding treesTrees in this layer grow and emerge into direct sunlight reaching heights of 60 to 70 m and can measure up to 5 m aroundAnimals such as eagles, bats, monkeys, and snakes live in the emergent layer\n12 Layers of the Rain Forest Canopy - layers of treetops that shade the forest floor, and is considered to be the primary layer of the rain forestThe tall trees, more than 30 m tall, form a dense layer that absorbs up to 95 percent of the sunlightThe canopy can be split into and upper canopy and lower canopy with the lower canopy receiving less of the sunlight\n13 Layers of the Rain Forest Epiphytes - plants that use another plant for support but not for nourishment, and are located on high trees in the canopyMost animals that live in the rain forest live in the canopy because they depend on the abundant flowers and fruits that grow there12 month growing seasoncm precipitation each year\n14 Layers of the Rain Forest Understory - foliage layer that is beneath and shaded by the main canopy of a forestLittle light reaches this layer allowing only trees and shrubs adapted to shade to growMost plants in the understory do not grow more that 3.5 m tallHerbs with large flat leaves that grow on the forest floor capture the small amount of light that penetrates the understory\n15 Species DiversityMost rainforest animals are specialists that use specific resources in particular ways to avoid competition and have adapted amazing ways to capture prey and avoid predatorsExample: Insects use camouflage to avoid predators and may be shaped like leaves or twigs\n20 Threats to Rain Forest100 acres of tropical rainforest are cleared for logging operations, agriculture, and oil exploration each dayExotic-pet trading robs the rain forests of rare and valuable plant and animal speciesHabitat destruction occurs when land inhabited by an organism is destroyed or alteredWhy is it important for scientists to study habitat destruction?\n21 Temperate ForestsTemperate deciduous forests - forests characterized by trees that shed their leaves in the fall, and located between 30º and 50º north latitudeRange of temperatures: summer 35ºC (95 F) and winter: below freezingAnnual Rainfall: cm (30-50 inches) (Helps to decompose dead organic matter allowing the soil to be rich)\n25 Plants of Temperate (Deciduous) Forest Tall trees (birch, beech, oak, maple, etc) that shed their leaves and shrubs on the forest floorAdapted to survive seasonal changes: In the fall and winter, trees shed their leaves and seeds go dormant under the insulation of the soilHumus- layer of organic matter that enriches the soil\n27 Animals of Temperate (Deciduous) Forests Birds cannot survive the harsh winter of the deciduous forests so each fall they fly south for warmer weather and better availability of foodMammals and insects reduce their activity so they do not need as much food for energy, allowing them to survive the winterExamples: fish, amphibians, some reptiles, birds, and mammals\n29 Taiga (Coniferous Forest) Taiga - region of evergreen, coniferous forest below the arctic and subarctic tundra regionsLong winters and little vegetationGrowing season can be as short as 50 days with most plant growth occurring during the summer months because of nearly constant daylight and larger amounts of precipitation\n33 Taiga Plants Conifer - tree that has seeds that develop in cones. Conifer leaves’ waxy coating helps them to retain water in the winter, and the conifer’s shape also helps the tree shed snow to the ground and not get weighed downConifer needles contains substances that make the soil acidic when they fall to the ground preventing plants from growing on the floor\n35 Taiga AnimalsMany lakes and swamps in the summer attract birds that feed on insectsTo avoid the harsh winters, birds migrate, while some year round residents, such as shrews (mammal), burrow underground for better insulationSnowshoe hares have adapted to avoid predation by shedding their brown summer fur and growing white fur that camouflages them in the winter snow\n37 REVIEW!!! List three characteristics of tropical rain forests. Name and describe the main layers of a tropical rain forest.Describe one plant in a temperate deciduous forest and an adaptation that helps the plant survive.Describe one adaptation that may help an animal survive in the taiga.Name two threats to the world’s forest biomes."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:095bacfb-b74f-4af5-82f3-d4fb3aeb5673>","<urn:uuid:23303d8f-ca33-4441-9310-01e289062ee2>"],"error":null}
{"question":"How do governmental competition and population health approaches combine to address disparities, and what evidence exists for their effectiveness?","answer":"In governmental systems, yardstick competition creates a mechanism where jurisdictions compare performance, leading governments (even rent-seeking ones) to adopt superior new policies more frequently when they observe successful implementations in neighboring areas. Similarly, in population health interventions, as shown in Head Start programs, a comprehensive approach combining health literacy with environmental changes has proven effective in reducing disparities. The evidence includes concrete improvements such as reduced emergency room visits, better school attendance, and decreased work loss days among low-income families. The programs demonstrate that multi-component interventions addressing both individual and systemic factors are most effective in creating sustainable positive changes.","context":["Yardstick Competition and Policy Innovation\nA simple model of yardstick competition between jurisdictions is presented. Governments of jurisdictions face the alternative to choose between an old and a new policy with stochastic payoffs. The new policy is superior to the old policy in one state of the world, and inferior in the other. Governments are either benevolent, serving the interest of the voter, or rent-seeking. An equilibrium with yardstick competition is shown to exist where bad governments having a good government in their neighborhood choose the new policy more often compared to an equilibrium without relative performance evaluation. Overall, the probability of policy innovations is increased by yardstick competition. The model has a testable empirical implication saying that policy innovations should show spatial correlation.\nReferences listed on IDEAS\nPlease report citation or reference errors to , or , if you are the registered author of the cited work, log in to your RePEc Author Service profile, click on \"citations\" and make appropriate adjustments.:\n- Besley, Timothy & Case, Anne, 1995.\n\"Incumbent Behavior: Vote-Seeking, Tax-Setting, and Yardstick Competition,\"\nAmerican Economic Review,\nAmerican Economic Association, vol. 85(1), pages 25-45, March.\n- Timothy Besley & Anne Case, 1992. \"Incumbent Behavior: Vote Seeking, Tax Setting and Yardstick Competition,\" NBER Working Papers 4041, National Bureau of Economic Research, Inc.\n- Paul Belleflamme & Jean Hindriks, 2005. \"Yardstick competition and political agency problems,\" Social Choice and Welfare, Springer;The Society for Social Choice and Welfare, vol. 24(1), pages 155-169, 09.\n- Paul Belleflamme & Jean Hindriks, 2001. \"Yardstick Competition and Political Agency Problems,\" Working Papers 441, Queen Mary University of London, School of Economics and Finance.\n- BELLEFLAMME, Paul & HINDRIKS, Jean, 2002. \"Yardstick competition and political agency problems,\" CORE Discussion Papers 2002029, Université catholique de Louvain, Center for Operations Research and Econometrics (CORE).\n- Christos Kotsogiannis & Robert Schwager, 2006. \"Political Uncertainty and Policy Innovation,\" Journal of Public Economic Theory, Association for Public Economic Theory, vol. 8(5), pages 779-805, December.\n- Christos Kotsogiannis & Robert Schwager, 2001. \"Political Uncertainty and Policy Innovation,\" Discussion Papers 0111, Exeter University, Department of Economics.\n- Besley, Timothy J. & Smart, Michael, 2002. \"Does Tax Competition Raise Voter Welfare?,\" CEPR Discussion Papers 3131, C.E.P.R. Discussion Papers.\n- Coate, Stephen & Morris, Stephen, 1995. \"On the Form of Transfers in Special Interests,\" Journal of Political Economy, University of Chicago Press, vol. 103(6), pages 1210-1235, December.\n- Bordignon, Massimo & Cerniglia, Floriana & Revelli, Federico, 2003. \"In search of yardstick competition: a spatial analysis of Italian municipality property tax setting,\" Journal of Urban Economics, Elsevier, vol. 54(2), pages 199-217, September. Full references (including those not matched with items on IDEAS)\nWhen requesting a correction, please mention this item's handle: RePEc:wpa:wuwppe:0511010. See general information about how to correct material in RePEc.\nFor technical questions regarding this item, or to correct its authors, title, abstract, bibliographic or download information, contact: (EconWPA)\nIf you have authored this item and are not yet registered with RePEc, we encourage you to do it here. This allows to link your profile to this item. It also allows you to accept potential citations to this item that we are uncertain about.\nIf references are entirely missing, you can add them using this form.\nIf the full references list an item that is present in RePEc, but the system did not link to it, you can help with this form.\nIf you know of missing items citing this one, you can help us creating those links by adding the relevant references in the same way as above, for each refering item. If you are a registered author of this item, you may also want to check the \"citations\" tab in your profile, as there may be some citations waiting for confirmation.\nPlease note that corrections may take a couple of weeks to filter through the various RePEc services.","How a Population Health Approach Improves Health and Reduces Disparities: The Case of Head Start\nESSAY — Volume 13 — January 21, 2016\nSteven M. Teutsch, MD, MPH; Ariella Herman, PhD; Carol B. Teutsch, MD\nSuggested citation for this article: Teutsch SM, Herman A, Teutsch CB. How a Population Health Approach Improves Health and Reduces Disparities: The Case of Head Start. Prev Chronic Dis 2016;13:150565. DOI: http://dx.doi.org/10.5888/pcd13.150565external icon.\nGood health is a life-long process. Many of the most critical behaviors are established in early childhood and need reinforcing at each life stage. To encourage physical activity, for example, young children should engage in fun, active play daily; schools should ensure that physical activity is a normal part of daily life; parents should participate in physical activity at work, home, or both and include their children; and elders should be encouraged to stretch, move, and improve their strength. Children who understand and demonstrate healthful behaviors will bring those messages home to parents. They can advocate for healthful food (and perhaps not pester parents for unhealthful foods!), encourage parents to stop smoking for their children’s sake, and seek fun active activities rather than more screen time. Thus, the family unit with young children can become an important force for sustaining more healthful living. Amplifying the positive impacts of parents as a child’s first teacher can set a child on a healthful trajectory for life.\nThe health of Americans sadly lags that of most other developed countries (1) and is beset by large disparities among racial/ethnic groups and the socially disadvantaged. Recognition that this problem cannot be solved by better and more accessible medical care alone has led to the resurgence of interest in population health (2) and its underlying determinants: behaviors and social and environmental conditions. The ecologic model of health recognizes the biological determinants of health and emphasizes the importance of family, community, institutions, laws, policies, and customs as well as the built and natural environments. Intrinsically it means that improving health and even disease outcomes requires intervention at multiple levels. According to the Guide to Community Preventive Services, effective interventions almost invariably require multiple components (3). To continue with the physical activity example, an effective strategy might include physician counseling, physical education programs in school, easy access to parks and recreation facilities, safe neighborhoods, complete streets (4), active transportation, education about the importance of physical activity, and encouraging families to participate in activities together. Implementing such multipronged interventions in the community can be challenging. Yet multicomponent and multigenerational approaches have the potential not only to improve the health of children but also can use parents’ and grandparents’ motivation to raise healthy children to improve their own health behaviors and thereby accelerate changes in social norms.\nHealth literacy, the ability of people to understand health and disease that empowers them to take action, is important, but by itself is insufficient. It can provide individuals and families with needed health information, motivate them, enhance communication with providers, and facilitate peer-to-peer communication. Although awareness is growing that health literacy is integral to health, it needs to be embedded in a more comprehensive set of policies, programs, and conditions that promote health and enable individuals to make healthful choices the easy choices.\nVulnerable low-income families in the United States have a disproportionate share of unhealthful determinants and poor health outcomes. While lack of access to medical care is one barrier, health literacy, access to culturally relevant programs, ability to satisfy basic needs, and financial insecurity are other typical barriers this population faces. Head Start and the Special Supplemental Nutrition Program for Women, Infants, and Children (WIC), along with many other agencies, foundations, and community-based organizations, provide health and education services to low-income families. Nurse Family Partnership provides public health nursing and health education services to low-income women. United Way provides workforce development, financial literacy, and health education across the country. First 5 California provides resources and tools to parents to help them navigate health and education for their children aged less than 5 years.\nBut Head Start is one of the longest-standing programs providing health and education services to low-income families. It serves approximately 1 million children aged 0 to 5 years and requires its grantees to coordinate health-related services such as basic screenings, health education, and referrals to health care providers as well as coordinating support for routine home visits and parent education workshops to understand the needs of families and children and promote preventive health services.\nA 2001 survey of Head Start directors in the Johnson & Johnson Head Start Fellows program found that although grantees had access to health education materials and resources to conduct health education trainings, these sessions were often poorly attended and the materials were not well understood (5). In response, the University of California, Los Angeles/Johnson & Johnson Health Care Institute (HCI) was formed to rectify these limitations and improve health literacy among Head Start families.\nHCI is now working in partnership with the American Academy of Pediatrics’ National Center on Early Childhood Health and Wellness. It uses the structured framework it developed for health promotion that builds staff leadership capacity and trains Head Start staff to implement health promotion programs for their families using culturally adapted, low-literacy materials on topics such as management of common childhood illnesses, effective use of the clinical care system, obesity prevention, home safety, mental health, and oral health. Family trainings capitalize on families’ innate motivation to care for their children. The trainings include experiential group learning activities, hands-on skill-building, and creation of social networks. This approach helps not only parents and children but also Head Start staff, who gain knowledge to care for their own children. The staff also see themselves as stronger role models for healthful living for their families, which also motivates family participation and engagement (6). The health literacy components are complemented by environmental changes, such as providing more healthful foods and more physical activity at schools, visiting community grocers to learn about how to buy and prepare healthful, affordable foods, and working with grocers to sell more healthful products (7). Since 2001, HCI trained staff from 300 grantees, who reached more than 120,000 vulnerable families across the United States.\nResults of the health promotion program among more than 9,000 families at 55 sites were impressive: emergency department visits declined by 58% and school days missed were reduced by 29%, enhancing school readiness (8). Parents’ work-loss days decreased by 42% (8); such decreases are critical for low-wage workers at high risk of losing those jobs if they miss work, thus enhancing job security and incomes. Since income is itself a determinant of health and loss of a job a major life stressor, these indirect benefits of the program are also critical to a family’s well-being. Over the longer term, life-long improvements in health behaviors, higher graduation rates, and better job opportunities in healthier, more supportive communities should pay off in reduced rates of major chronic diseases as well. Partially in response to these successes, Head Start has incorporated health literacy into its proposed revised performance standards.\nA comprehensive health literacy program coupled with population health interventions can reduce short-term and long-term disparities between the general population and Head Start children, families, and staff. Short-term benefits include fewer unnecessary emergency department visits, greater self-confidence for parents, better relationships and engagement with Head Start staff, and better health decision making. In the longer term, more healthful behaviors will contribute to reduced rates of cardiovascular disease and obesity. Because the social capital for implementing these programs resides in each Head Start agency, the programs are scalable and sustainable.\nAs this multidimensional health literacy and population health intervention illustrates, once parents have the knowledge, tools, and motivation to protect the health of their children, and barriers are removed, meaningful change can occur. When provided with simple health information in a low-literacy format, thermometers, and tips on how to improve health behaviors on a limited budget, along with changes in their school and community environments, parents were able to take positive action. Their empowerment and knowledge also better enables them to more appropriately access the clinical care system, ask appropriate questions, and understand and adhere to clinical recommendations. We can help set entire families and communities on a better health trajectory. A life-course approach and improved health literacy coupled with healthful programs and policies can reduce health disparities and make a real difference in people’s lives.\nThis work was done with the support from the Johnson & Johnson Family of Companies Contribution Fund.\nCorresponding Author: Steven Teutsch, MD, MPH, 841 Moon Ave, Los Angeles, CA 90065. Telephone: 323-352-8079. Email: email@example.com.\nAuthor Affiliations: Steven M. Teutsch, Fielding School of Public Health, University of California, Los Angeles, California, and Public Health Institute, Oakland, California; Ariella Herman, Carol B. Teutsch, Anderson School of Management, University of California, Los Angeles, California.\n- Organisation for Economic Co-operation and Development. Life expectancy, health risks, health expenditure. Compare your country: United States. http://www.compareyourcountry.org/health?cr=oecd&cr1=oecd&lg=en&page=0. Accessed October 16, 2015.\n- Teutsch SM, Fielding JE. Rediscovering the core of public health. Annu Rev Public Health 2013;34(1):287–99. CrossRefexternal icon PubMedexternal icon\n- Centers for Disease Control and Prevention. The guide to community preventive services. http://www.thecommunityguide.org/. Accessed October 16, 2015.\n- Smart Growth America, National Complete Streets Coalition. What are complete streets? http://www.smartgrowthamerica.org/complete-streets/complete-streets-fundamentals/complete-streets-faq. Accessed December 19, 2015.\n- Herman A. The status of health care in Head Start: a descriptive study. Los Angeles (CA): UCLA Anderson School of Management; 2000.\n- Herman A, Nelson BB, Teutsch C, Chung PJ. A structured management approach to implementation of health promotion interventions in Head Start. Prev Chronic Dis 2013;10:E155. CrossRefexternal icon PubMedexternal icon\n- Herman A, Nelson BB, Teutsch C, Chung PJ. “Eat Healthy, Stay Active!”: a coordinated intervention to improve nutrition and physical activity among Head Start parents, staff, and children. Am J Health Promot 2012;27(1):e27–36. CrossRefexternal icon PubMedexternal icon\n- Herman A, Jackson P. Empowering low-income parents with skills to reduce excess pediatric emergency room and clinic visits through a tailored low literacy training intervention. J Health Commun 2010;15(8):895–910. CrossRefexternal icon PubMedexternal icon\nThe opinions expressed by authors contributing to this journal do not necessarily reflect the opinions of the U.S. Department of Health and Human Services, the Public Health Service, the Centers for Disease Control and Prevention, or the authors’ affiliated institutions."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:3ebb749c-5a57-456e-8943-f9db41738b7e>","<urn:uuid:4d3e18da-0d4c-42e6-a657-ef5570f009f0>"],"error":null}
{"question":"How does Arizona Southern Baptist Disaster Relief collaborate with other organizations during crisis situations?","answer":"Arizona Southern Baptist Disaster Relief partners with Arizona VOAD (Volunteer Organizations Active in Disaster), which includes organizations like the American Red Cross, Salvation Army, Team Rubicon, state and county emergency management agencies, and various corporations. In one recent collaboration, they transported supplies to Arizona's southern border, including PPE from FEMA, Maricopa County and corporations, portable cribs and comfort kits from the Red Cross, and ready-to-eat meals from the Salvation Army. This partnership approach allows them to accomplish more than any single organization could do alone.","context":["DR Update: Arizona Disaster Relief trains and serves in 2021\nBy Irene A. Harkleroad | Jul 6, 2021\nHuman suffering comes in many disturbing ways: fires, floods, displacement, hunger, homelessness. Its consequences affect the general population as well as the people who serve in times of disaster.\nArizona Southern Baptist Disaster Relief is enhancing the ways it prepares to serve in times of crisis. Leaders are doing it through expanded training and collaboration.\nA regional approach to training has led to more volunteers being trained.\nIn February 2020, the annual statewide training was held in Gilbert. Based on a successful training event in Yuma, smaller events have been held this year in Lake Havasu City and Casa Grande. Eighty volunteers were trained in these regional events compared to the average of 45 to 50 in an annual event.\nA volunteer application form and the basic training module “Involving Southern Baptists in Disaster Relief” are available at azsbc.org/disaster-relief/.\nArizona Southern Baptist Disaster Relief continues to partner with Arizona VOAD (Volunteer Organizations Active in Disaster). VOAD includes partnerships with the American Red Cross, Salvation Army, Team Rubicon, Arizona Southern Baptist Disaster Relief, state and county emergency management agencies, corporations and many more.\n“VOAD is a great networking group,” said Patty Kirchner, Arizona Southern Baptist Disaster Relief interim director.\nRecently, Arizona Southern Baptist Disaster Relief transported supplies to Arizona’s southern border. Included were Personal Protective Equipment warehoused at Phoenix Tool Bank and donated by the Federal Emergency Management Agency, Maricopa County and several corporations; portable cribs, crib sheets and comfort kits provided by the Red Cross; and ready-to-eat meals provided by the Salvation Army.\nIn April, an Arizona Southern Baptist Disaster Relief feeding unit was a partner during the Margo Fire in Dudleyville.\nDonations of $4,000 from Southwest Gas and $4,000 from the Episcopal Diocese covered the cost of meals.\n“Team Rubicon finished their work four days early,” Kirchner said. “We had plenty of food left over, most of it in a Shamrock refrigerated trailer.”\nKirchner worked with Pinal County Emergency Management, which made arrangements with the food bank in Superior to pick up the food. Ultimately, the leftover food purchased with that $8,000 was distributed to people in Top of the World, Superior, Miami, Claypool, Globe and El Capitan.\n“Those funds went a lot further than just helping the people in Dudleyville,” Kirchner said. “It helped people in Pinal and Gila County during the Telegraph Fire. God’s hand was in all of that. That’s the beauty of working in VOAD. We accomplish more when we work together than any of us could do alone.”\nDeployments for Arizona Southern Baptist Disaster Relief in 2021 have been limited so far.\nVolunteers did assessments and chainsaw jobs in Granby, Colorado, following up after last summer’s East Troublesome Fire. Arizona ash-out teams are scheduled to return in July and August.\nAt the request of Pinal County Emergency Management, Arizona Disaster Relief’s mobile feeding unit served 815 meals to a Team Rubicon ash-out team and Pinal County employees assigned to the Margo Fire in Dudleyville.\nTeams were placed on alert for the Backbone, Wyrick, Rafael and Telegraph fires in Arizona but were not deployed\nIn addition to sending volunteers, Arizona Southern Baptist Disaster Relief has also deployed equipment this year. The shower unit was sent to Rifle, Colorado, for use by a Southern Baptist mission team and to Dudleyville, along with the feeding unit.\n“God is faithful,” Kirchner said. “We saw the Lord working through all of this. We don’t always work with Christian-based organizations but we do get to live our lives before them.”\nIrene A. Harkleroad, a freelance writer living in Carefree, is a member of Black Mountain Baptist Church, Cave Creek."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:5d73c817-b528-47ce-8983-2b0085431778>"],"error":null}
{"question":"What are the core principles of Equine Assisted Counseling (EAC), and how is it validated by research evidence?","answer":"Equine Assisted Counseling (EAC) is a mental health treatment involving ground activities with horses, conducted by a mental health counselor and an equine professional. The core principles include no use of ropes or treats - clients must communicate through voice and body language to direct horses. The therapy yields benefits like improved self-confidence, communication, trust, anxiety reduction, and spiritual growth. Research evidence strongly supports EAC's effectiveness, with studies showing significant improvements in depression, anxiety, PTSD in veterans, eating disorders, and relationship issues. Studies indicate that EAC treatment duration is often shorter than traditional therapy as issues surface more quickly. For example, one comparative study found couples receiving EAC reported significantly higher relationship improvement than those in solution-focused therapy. Research particularly demonstrates EAC's success with difficult-to-treat clients and at-risk youth, who showed improvements in 17 behavior areas compared to just 5 areas with classroom counseling.","context":["By Karen Frederick, Ph.D., LPC\nGod has put an amazing variety of animals on this earth for our help and pleasure. Most horse owners are well aware of the therapeutic value of horses. Working with horses and participating in their care, feeding, and grooming has been found to reduce stress, lower blood pressure, and improve overall health. It has been clinically documented that simply being in the presence of horses changes human brainwave patterns. Winston Churchill summed it up best when he said, “There’s something about the outside of a horse that is good for the inside of a man.”\nAs Christians, we have a deeper understanding of God’s creations and creatures and the ways He speaks to man’s heart through them. The Bible is very explicit in telling us about the many ways God uses animals to speak His message to us and to reveal Himself to us. We can see the acknowledgement of God as the creator in Psalm 104:24 (The New International Version): “How many are your works, LORD! In wisdom you made them all; the earth is full of your creatures.”\nGod uses his creation and creatures to reveal Himself, His attributes, and His power. Romans 1:20 says: “For since the creation of the world God’s invisible qualities—his eternal power and divine nature—have been clearly seen, being understood from what has been made, so that people are without excuse.”\nEven when mankind fails to honor the Lord, Isaiah 43:20 states, “The wild animals honor me, the jackals and the owls, because I provide water in the wilderness and streams in the wasteland, to give drink to my people, my chosen.”\nThe Bible specifically tells us that animals will teach us; in Job 12:7-10 it states, “But ask the animals, and they will teach you, or the birds in the sky, and they will tell you; or speak to the earth, and it will teach you, or let the fish in the sea inform you. Which of all these does not know that the hand of the LORD has done this? In His hand is the life of every creature and the breath of all mankind.”\nThere is little doubt that God’s creation, the horse, has profoundly impacted the history and well being of mankind. Horses have plowed fields, carried soldiers to battle, transported goods to markets, and given people of every status the ability to travel more quickly and easily. In more recent decades, horses are no longer seen as laborers or beasts of burden. Horses are being used to help people with a wide range of emotional difficulties. No consensus has been reached as to one proper term to be used when equines are involved in mental health treatment. In this article, the term equine-assisted counseling (EAC) is being used as a universal term for interventions that involve the use of a horse in order to benefit the mental or emotional well being of a human participant.\nResearch indicates that therapy involving horses may yield a variety of psychotherapeutic benefits, including the following: self-confidence, self-concept, communication, trust, perspective, anxiety reduction, decreased isolation, self-acceptance, impulse modulation, assertiveness, boundaries, creative freedom, and spiritual growth (Marx & Cumella, 2003; Ewing, MacDonald, Taylor, & Bowers, 2007; Trotter, Chandler, Goodwin-Bond, & Casey, 2008; Bass, Duchowny, & Llabre, 2009).\nThe benefits of equine-assisted counseling (EAC) have been reported in a variety of clinical groups, mostly in the form of observations from the field and participant statements. Tyler (1994) discussed the use of EAC in the treatment of clients with emotional problems, particularly adolescents. McCormick and McCormick (1997) reported on their work implementing EAI with adolescents. Moore, Wagner, and Jeffrey (2009) used EAC with clients attempting to overcome substance abuse. Others have expressed support for the use of EAC with behavioral issues, attention deficit disorder, eating disorders, abuse issues, depression, anxiety, relationship problems, and communication needs (Carpenter, 1997; Katcher & Wilkins, 1998).\nChandler (2005) utilized EAC with male and female juvenile offenders and found that the participants displayed increases in positive behaviors such as communication skills, support and encouragement for others, and increased desire to complete a task. She also noted a reduction or elimination of negative behaviors such as fear and manipulation. Other benefits seen by Chandler included greater courage, stress management, and anxiety-reduction skills.\nTrotter et al. (2008) investigated the efficacy of group EAC with at-risk adolescents and found that at-risk youth who received EAC showed statistically significant improvement in seventeen behavior areas whereas students who received classroom-based counseling showed improvement in only five areas.\nKersten & Thomas (2004) posit that the challenge of controlling the movement of a 1,000-pound creature requires concentration, creativity, and resourcefulness and that success in doing so improves self-esteem, confidence, communication skills, trust, and boundaries. A recurrent theme in the literature seems to indicate that the more difficult a client is to work with in traditional counseling, the more likely it is that that client will do well in EAC (Trotter et al, 2008).\nSo, what exactly IS Equine-Assisted Counseling (EAC)? EAC sessions involve a mental health counselor, an equine professional, and a client. The activities that the therapist chooses should be based on the needs of the client. Through observing the client’s interactions and responses to the horse, the counselor gains a lot of information. For example, if the client approaches the horse and the horse walks away, the counselor is interested in observing how the client responds to the horse walking away. Does the client pursue? Does the client give up and say, “I guess he doesn’t like me”? Whatever the response—the counselor has information (Trotter, 2012).\nIt is important to note that there are different approaches to EAC. Some counselors incorporate horseback riding in their therapy. For a number of reasons, this author does NOT incorporate riding into the therapy process. This can be disappointing to some clients, but in this author’s opinion, safety concerns outweigh the potential benefits of riding. Another important consideration is that Equine Assisted Counseling is not the same as hippotherapy or therapeutic riding—which incorporates horses for the physical benefits of the clients. Hippotherapy is frequently used with clients with a physical handicap. EAC focuses on the mental health benefits of horses.\nSome of the early, critical EAC sessions include clients’ learning about how to initiate, direct, and stop the movement of the horse. This may sound simple, but there IS one stipulation—clients are not permitted to use ropes or halters, and they are not permitted to “bribe” the horses with feed, treats, etc. They must communicate with voice and body language in order to initiate, direct, and stop the movement of the horse. Once the client understands the basics of these skills, the fun activities can begin. One example of a favorite activity includes setting up an obstacle course that the client will have to get a horse through. Clients will identify each obstacle and compare it with an obstacle that they are personally facing in their life (difficulty at school, bullying, relationship troubles, etc.). Once the course is set up and the obstacles are identified, the client has the task of getting the horse through/over/around the obstacles.\nIt may be different for each individual. EAC may be effective because working with God’s creation helps man see God’s invisible qualities. Working with horses may allow God’s creation, the horse, to teach us about ourselves, about God, about our relationships with others, etc. We all have so much to learn! And God, in His wisdom, has infinite methods of revealing Himself and communing with us for His purposes. EAC seems to be yet another way that God can provide emotional healing to those in need.\nKaren Frederick, Ph.D., LPC, is an Assistant Professor of Psychology at Houston Baptist University. Dr. Frederick’s main research interest is Equine Assisted Counseling. She is applying for grants to fund further research on the use of Equine Assisted Counseling with at-risk youth. She has written a chapter in a newly published book entitled: Equine-Assisted Mental Health Interventions (2019) by Trotter, K.S. and Baggerly, J.N. New York, NY: Routledge.\nBass, M. M., Duchowny, C. A., & Llabre, M. M. (2009) The effect of therapeutic horseback riding on social functioning in children with autism. Journal of Autism & Developmental Disorders, 39(9), 1261-1267.\nCarpenter, S. (1997). Therapeutic roles of animals. Journal of the American Veterinary Medical Association, 211, 154-155.\nChandler, C. K. (2005). Animal Assisted Therapy in Counseling. New York: Routledge.\nEwing, C. A., MacDonald, P. M., Taylor, M., & Bowers, M. J. (2007). Equine-facilitated learning for youths with severe emotional disorders: A quantitative and qualitative study. Child and Youth Care Forum, 36, 59-72.\nKatcher, A. H. and Wilkins, G. G. (1998). Animal-assisted therapy in the treatment of disruptive behavior disorders in children. In A. Lundberg (Ed.), The Environment and Mental Health: A Guide for Clinicians pp. 193-204). Mahwah, NJ: Lawrence Erlbaum Associates, Inc.\nKersten, G. & Thomas, L. (2004) Equine Assisted Psychotherapy and Learning Un-Training Manual. Santaquin, UT: Equine Assisted Growth and Learning Association (EAGALA).\nMarx, R. D., & Cumella, E. J. (2003). Questions & answers. Eating Disorders, 11, 143-147.\nMcCormick, A., & McCormick, M. D. (1997). Horse Sense and the Human Heart: What Horses Can Teach Us About Trust, Bonding, Creativity, and Spirituality. Deerfield Beach, FL: Health Communications, Inc.\nMoore, L., Wagner, P., & Jeffrey, H. (2009). Addiction programming model at its best. Paper presented at the 10th annual conference of the Equine Assisted Growth and Learning Association, Asheville, NC.\nTrotter, K.S. (2012). Harnessing the Power of Equine Assisted Counseling. New York, NY: Routledge.\nTrotter, K. S., Chandler, C. K., Goodwin-Bond, D. G., & Casey, J. (2008). A comparative study of the efficacy of group equine assisted counseling with at-risk children and adolescents. Journal of Creativity in Mental Health, 3(3), 254-284.\nTyler, J. J. (1994). Equine psychotherapy: Worth more than just a horse laugh. Women & Therapy, 15, 3-4, 139-146.\n[Editor’s Note: Christianity, Mind and Mental Health image from Van Gogh’s The Pietà (after Delacroix), 1889, found at Wikipedia Commons.}","Equine Time is Sydney’s first Equine Assisted Psychotherapy Programme. Equine Time started on the 6th May 2009 at Mowbray Park Farm, a natural horsemanship property at Picton on the south west outskirts of Sydney. Visit our website at equinetime.com.au.\nI first read about Equine Assisted Psychotherapy in the Australian Journal of Counselling Psychology Summer 2005 (Frewin and Gardiner). Having been a lover of horses since childhood I was fascinated by what I read, so I decided to learn more about Equine Assisted Psychotherapy. Since then I have attended several trainings to become an accredited Equine Assisted Psychotherapist with EAGALA (Equine Assisted Growth and Learning Association). EAGALA is an international association which aims to provide standards of practice, education, innovation, and support to professionals providing services in Equine Assisted Psychotherapy (EAGALA 2008).\nWhat is Equine Assisted Psychotherapy?\nEquine assisted psychotherapy is not a horse riding programme. The EAGALA model of EAP utilizes ground activities in a large enclosed space in which the horses run free. It is conducted by a licensed mental health professional, a horse specialist and a small herd of three to five horses. In a session the client is invited to undertake a groundwork activity with the horses. At the end of the session the client is invited to verbalise their experience and the equine specialist will reflect their observations of the horse’s behaviour during the session. The therapist then picks up on constructs that are important to the client, in line with the client’s therapy goals.\nThe horses are regarded as members of the therapy team. Their size and power demand respect. They are prey animals and will flee the instant something in their surroundings is out of balance. Horses have a natural curiosity, they have different personalities and they are extremely perceptive to human emotions. They are experts at non-verbal communication and body language. They will mirror human behaviour.\nHorses are social animals and live by the rules of the herd. As in human relationships equine relationships require effective communication and co-operation. Co-operation is important because each member of the herd relies on the others for their safety.\nHorses are non-judgemental, they do not have prejudices, they have no expectations, they are not influenced by appearance or life situation. They have no hidden agendas, they have no regard for external measures of success as humans do, they respond immediately without assumption or criticism. They hold people accountable for who they are in the relationship with them at that point in time (Aspen Ranch n.d., Kaleidoscope Learning Circle 2005, Kohanov 2001, Frewin and Gardiner 2005, O’Connor n.d.).\nWhy Equine assisted psychotherapy?\nThe research literature demonstrates the effectiveness of EAP for children with depression and anxiety (McCann 2001), children with difficult behaviours (Tetreault 2006), and children and adolescents “at-risk” with maladaptive behaviours (Trotter 2006). Significant improvement in behaviour was reported for incarcerated adolescents (Mann 1998) and for adolescents with disruptive behaviours (Greenwald 2001). Mann and Williams (2002) found a significant improvement in adolescents with conduct disorders, mood disorders and psychotic disorders who failed to make progress in traditional therapy settings. Other studies found significant improvement in adolescents with depression, anxiety and low self esteem (Crawly et al 1994, Bowers and MacDonald 2001, Kaiser et al 2004 and Schultz 2005, Bullock and Gable 2006). One therapist stated “I have learned more about a teen in one horse session, than in a month of individual work” (Barbara Lester, Woodbury Reports 2002).\nSeveral studies of EAP with adults have shown significant improvement in symptoms of anxiety (Scheidhacker et.al. 2002), unresolved grief (Klontz et al 2007), depression, anxiety and social disorders (Burgon 2003) and eating disorders (Christian 2005).\nRussell-Martin (2006) compared the improvement in the couple relationship between 10 couples who attended six sessions of solution-focused therapy and 10 couples who attended six sessions of EAP. She found that the EAP couples reported significantly higher improvement than the solution-focused therapy couples.\nLancia (2008) demonstrated significant improvement in symptoms of PTSD in war veterans.\nEquine assisted psychotherapy is being used for individual work, couple work and family therapy. Many of the studies are suggesting that treatment duration is minimised as the equine sessions bring issues to the surface more quickly than in talking therapy (Kersten & Thomas 2005a, Trevelyan 2005).\nExploration of some of the concepts from Personal Construct Psychology to underpin the therapeutic value of the EAGALA model of EAP.\nKelly’s Fundamental postulate states “a person’s processes are psychologically channelized by the ways in which they anticipate events”. A horse’s hypervigilence and instantaneous flight response can also be explained by this postulate. The survival instinct of the horse can assist humans to clarify their own processes.\nThe conditions necessary for the formation of new constructs are the use of a fresh set of elements, experimentation and the availability of validating data.\nA fresh set of elements means that the person is not restricted by their existing constructs. Greg Neimeyer used the word “novelty” to describe the quality of this fresh set of elements. The word novelty means “a new and unusual thing” (Websters Dictionary). An implied meaning of the word novelty is that the thing does not produce a fear response but instead gives rise to a person’s curiosity.\nEAP provides an environment that is likely to be outside the client’s experience and while Kelly names the therapist as a fresh element, the horses and the horse specialist are also fresh elements in the novel environment. Kelly cautions that the new context ought not involve “the self” or “members of the immediate family” until such time that the person finds some usefulness in the emerging constructs coming from the new environment. In the EAGALA model of EAP the observations made are “clean” observations of the horses behaviour during the session. The client is invited to reflect on their learning through awareness of the horses behaviour during the session. Much of the psychological processing occurs between therapy sessions as the person reflects on their specific learning and experiments with it in other situations which are likely to be with self or family. Kelly also states that the environment ought not be so complex that the person is unable to use their moment-to-moment anticipations. In the EAGALA model the activities given are stated as simply as “go and meet the horses and choose one”. A followup session may include “choose a horse and bring it back here”. The client may wish to work on the same task over several sessions.\nThe use of stories will also assist the development of the new constructs before the self is involved. In the EAP session the therapist may ask the client to tell a story about what just happened. It is likely that the person will tell the story about the horses. The self is only involved after the elements in the story have gained usefulness, and gradually the new construct from the story will replace the old constructs that have outlived their usefulness.\nKelly states that the playing out of artificial roles is very useful for the formation of new constructs. He states that “The patent artificiality of the role is the very feature which prevents the tender shoots of new ideas from being trampled in the frantic rush to maintain oneself in their previous role.” (p. 161) To attempt the role of being in control of a large and powerful animal that is free to run away is likely to be seen as an artificial role for most people. To believe that this is possible is beyond most people’s anticipations. When the horse responds willingly the client must reconstrue rapidly in order to maintain their anticipatory system.\n“An atmosphere of experimentation” (Kelly 1955/63 p 162) is important for the formation of new constructs. For Kelly, the word experimentation meant that one variable was attempted to be isolated from all other variables and this one variable is the one acted upon. The more careful we are to isolate one construct or anticipation to act upon the more likely we are to gain a precise outcome. When the client can see clearly the process involved and the result, their anticipation will be clearly validated or invalidated. The clear nature of the tasks set in the EAGALA model and the clear outcome provided by the horse allows for such experimental conditions to exclude as many extraneous variables as possible.\nIn an experimental situation the consequences of the experiment are limited. Kelly states “one does not play for keeps” (p.163). Thus a construct may be shifted from what the client believes to be reality as a possible representation of reality. Once this occurs the construct becomes more open to variation or replacement. The horses become metaphors for the client, and as such the client is able to loosen their construing to enable alternative possibilities.\nClients have the opportunity to make a new prediction and experiment with their behaviours to find the best fit. In the EAGALA model a client is offered the freedom to ‘trial’ various strategies with the horses and they quickly learn the relationship between prediction and response through the horse’s immediate response. These trials are experiments in role constructs and are particularly useful for people wishing to improve their relationships as the horses will act to maintain their own safety.\nKelly states “A construct is a framework for making predictions” (p 163). If the outcome doesn’t fit the prediction a person may begin to change their prediction. They may alternatively try to force the outcome so as to make it fit the prediction. Horses are very good at not responding to the way a person wants them to if force is used. The use of force makes the problem more difficult to solve. In a very short time a person will give up completely or begin to change the construct they are using to predict their desired outcome. Thus horses provide clear invalidation for constructs that are not in line with “shared control” and hence validate constructs in line with “shared control”. This construct is important for the well-being of human relationships.\nOften in an EAP session an observer has little insight into what learning is taking place for the client. “The therapist must be careful not to assume learning by results, or results by learning” (Kelly). What the client learns is what is important and necessary to their construct system, and not necessarily noticeable to the therapist. Sometimes the client may need to form intermediate constructs which to an observer may appear as unsuccessful trials. Kelly states that “the availability of validating data implies skill on the part of the therapist” (p. 164) and in an EAGALA model session the therapist may provide validating data, but essentially that is the role of the horses. The horses provide non-verbal validation and invalidation to the client in response to the non-verbal constructs of the client. “Those things that the client has been unaware of are now brought into awareness” (Kelly). Kelly states “the role-playing exchange is an excellent way of enabling the client to try out new constructs which have immediate access to validating material.” The horse’s response is immediate, and helps the client to see more clearly in a construct, its prediction, action and response. The direct link between a client’s action and the horse’s response can provide very precise evidence for the construct on trial. Horses do not confuse their response with some previous event, as humans are often inclined to do which makes for difficulty when a person seeks validation from other humans.\nKelly points out that it would be more helpful to the client for the therapist to ask the client what are the client’s questions. The EAGALA model of EAP offers the client the opportunity to ask their own questions in the experimental environment with the horses. Very often when the client has formulated their own question, they can find an answer that fits for them. Is it possible for a client to ask a question of a horse? Can a horse sense this and provide them with the answer they need?\nThe use of horses in psychotherapy is rapidly gaining acceptance throughout the world as people experience its therapeutic benefit. The body of research evidence is growing and practitioners are gaining a more precise understanding of the important aspects of the therapeutic process. To be accepted as a valid psychological therapy, the EAGALA model of equine assisted psychotherapy needs to be grounded in an historically trusted theory to ensure its ethical sustainability. Personal Construct Psychology provides a substantive foundation for the EAGALA model of equine assisted psychotherapy.\nAspen Ranch n.d. Why are horses therapeutic? Retrieved October 4, 2005, from http://www.aspenranch.com/equine.html.\nBowers M.J. and MacDonald P.M. (2001) The effectiveness of equine facilitated therapy with at risk adolescents: A pilot study. Journal of Psychology and Behavioural Sciences, 15, 62-76.\nBullock L.and Gable R. (2006) Programs for children and adolescents with emotional and behavioural disorders in the United States: A historical overview, current perspectives, and future directions. Preventing School Failure, 50(2), 7-13\nBurgon H. (2003) Case studies of adults receiving horse riding therapy. Anthrozoos, 16, 263-276.\nCrawly R., Crawly D. and Retter K. (1994) Therapeutic horseback riding and self concept in adolescents with special education needs. Anthrozoos, 7, 129-134.\nChristian J.E. (2005) All creatures great and small: Utilizing equine assisted therapy to treat eating disorders. Journal of Psychology and Christianity, 24, 65-67.\nEquine Assisted Growth and Learning Association (EAGALA) 2008 Retrieved 18 January 2008 from http://www.eagala.org.\nFrewin K. and Gardiner B. (2005) New Age or Old Sage? A review of Equine Assisted Psychotherapy, The Australian Journal of Counselling Psychology, Summer 2005.\nGreenwald A.J. (2001) The effect of a therapeutic horsemanship program on emotionally disturbed boys. Dissertation Abstracts International, 62.\nKaiser L., Spence L.J., Lavergne A.G. and Bosch K.L. (2004) Can a week of therapeutic riding make a difference? A pilot study. Anthrozoos, 17, 63-72\nKaleidoscope Learning Circle (2005) Building effective relationships through equine assisted learning. Retrieved June 14, 2006, from http://www.myklc.com.\nKelly G.A. (1955/63) A theory of personality the psychology of personal constructs. Norton N.Y.\nKersten G. and Thomas L. (Eds.). (2005a) Equine assisted mental health resource handbook. (7th Edition) Santaquin, UT: EAGALA, Inc.\nKohanov L. (2001) The tao of equus: A woman’s journey of healing and transformation through the way of the horse. Novato,California: New World Library\nKlontz B.T. Bivens A., Leinart D, Klontz T. (2007) The Effectiveness of Equine-Assisted Experiential Therapy: Results of an Open Clinical Trial in Society and Animals 15, 257-267. 9\nLancia J. (2007) Equine Assisted Psychotherapy Genesse Valley Psychiatric Association Newsletter March 2007.\nMann D. (1998) Measuring outcomes of equine assisted psychotherapy with juvenile delinquents. Unpublished study. Walberg. CO\nMann D. and Williams D. (2002) In L. Thomas, Horseplay can be therapeutic: Equine assisted psychotherapy. Retrieved March 5, 2006 from http://www.strugglingteens.com/opinion/horseplay.html.\nMcCann J. (2001, Spring) Equine equilibrium. Tempe, AZ: Arizona State University, ASU Research Magazine.\nO’Connor C. (n.d.) The silent therapist: A review of the development of equine assisted psychotherapy. Retrieved March 5, 2006, from http://www.catra.net/info/silent.html.\nRussell-Martin L. A. (2006) Equine Facilitated Couples Therapy and Solution Focused Couples Therapy: a comparison study. A dissertation submitted to the graduate faculty of the Department of Psychology in partial fulfilment of the requirement of Doctor of Philosophy. Prescott, Arizona, September 2006.\nScheidhacker M., Friedrich D. and Bander W. (2002) About the treatment of anxiety disorders by psychotherapeutic riding: Long term observations and results of an experiemental clinical study. Krankenhauspsychiatric, 13, 145-152\nShultz B. (2005) The effects of Equine Assisted Psychotherapy on the psychosocial functioning of At-risk Adolescents ages 12-18, Counselling Thesis 2005, Denver Seminary.\nTetreault A. (2006) Horses that Heal: The Effectivenss of Equine Assisted Growth and Learning on the Behaviour of Students diagnosed with Emotional Disorder. Prepared in partial fulfilment for the requirements of the Master of Arts Degree in Multicategorical Special Education. Governors State University, University Park, Illinois, 2006.\nTrevelyan J. (2005) Equine assisted psychotherapy. Retrieved October 3, 2005, from http://www.winningstrides.com/articleframe.html.\nTrotter K.B. (2006) The efficacy of Equine Assisted Group Counselling with at risk children and adolescents. Doctorate of Philosophy (Counselling) University of North Texas.\nWoodbury Reports Inc.(2002) Horseplay can be therapeutic: equine assisted psychotherapy. Retrieved March 25, 2006, from http://www.strugglingteens.com/opinion/hrseplay.html. Barbara Lester Clinical Social Worker"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:646e2f6b-0620-4815-9a7e-3a3aef1a5b69>","<urn:uuid:585b151a-da4a-4a51-a7d7-258c09d70380>"],"error":null}
{"question":"When comparing thread management in Java with memory allocation in C, which programming language provides more direct programmer control over resource management?","answer":"C provides more direct programmer control over resource management compared to Java. In C, programmers have explicit control through dynamic storage allocation functions like malloc and free, allowing them to precisely manage when memory is allocated and released. Java, while offering thread management through features like the Thread class and Runnable interface, handles memory management automatically through its system. The C approach requires more manual intervention but offers finer control, particularly useful for small memory footprint applications, while Java's approach provides higher-level abstractions for thread management but less direct memory control.","context":["In the realm of Java, one of the key features that sets it apart from other programming languages is its robust support for concurrency and multithreading. These concepts allow you to harness the full power of modern multi-core processors, executing multiple tasks at the same time, and making your programs more efficient and responsive.\nConcurrency and Multithreading\nConcurrency refers to the ability of a program to manage multiple tasks at the same time. In Java, this is achieved using threads. A thread is a lightweight, independent unit of execution within a program, and a single process can have multiple threads running concurrently. This is known as multithreading.\nCreating Threads in Java\nThere are two main ways to create threads in Java:\n- Extending the\nThreadclass: You can create a new class that extends the\nThreadclass and override its\nrun()method contains the code that will be executed when the thread starts.\nTo start the thread, create an instance of your class and call the\n- Implementing the\nRunnableinterface: You can create a new class that implements the\nRunnableinterface and implement its\nrun()method. Then, pass an instance of your class to a\nThreadobject and start the thread.\nBoth approaches are common, but implementing the\nRunnable interface is generally preferred, as it allows your class to extend other classes if needed.\nSynchronization and Thread Safety\nWhen multiple threads access shared resources, problems can arise if the resource is not accessed in an orderly fashion. This can lead to unpredictable behavior and hard-to-find bugs, known as race conditions. To avoid these issues, Java provides mechanisms for synchronization and ensuring thread safety.\nsynchronized keyword can be used to ensure that only one thread can access a specific method or block of code at a time. When a thread enters a synchronized method or block, it acquires a lock on the object. Other threads that attempt to enter the same method or block will be blocked until the lock is released.\nAlternatively, you can use a synchronized block:\nvolatile keyword is used to indicate that a variable's value may be changed by multiple threads. It ensures that the value of the variable is always read from and written to the main memory, rather than a cached version in a thread's local memory. This can help prevent inconsistencies in the variable's value between different threads.\nExecutors and Thread Pools\nJava provides a high-level framework for managing multiple threads called the Executor framework. One of the main components of this framework is the ExecutorService, which allows you to manage a pool of threads and submit tasks to be executed by them.\nIn this example, we create a fixed-size thread pool with four threads and submit ten tasks. The tasks are distributed among the available threads, and the executor takes care of managing their execution.\nThese are just the fundamentals of Java concurrency and multithreading. There's a lot more to explore, such as the\njava.util.concurrent package, which offers advanced synchronization constructs, atomic variables, and other powerful tools to help you master concurrent programming in Java.","One of the things that makes C such a versatile language is that the programmer can scale down a program to run with a very small amount of memory. When C was first written, this was an important feature because computers weren't nearly as powerful as they are today. With the current demand for small electronics, from mobile phones to tiny medical devices, there's a renewed interest in keeping the memory requirements small for some software. C is the go-to language for most programmers who need a lot of control over memory usage.\nTo better understand the importance of memory management, consider how a program uses memory. When you first run a program, it loads into your computer's memory and begins to execute by sending and receiving instructions from the computer's processor. When the program needs to run a particular function, it loads that function into yet another part of memory for the duration of its run, then abandons that memory when the function is complete. Plus, each new piece of data used in the main program takes up memory for the duration of the program.\nIf you want more control over all this, you need dynamic storage allocation. C supports dynamic storage allocation, which is the ability to reserve memory as you need it and free that memory as soon as you're finished using it. Many programming languages have automatic memory allocation and garbage collection that handle these memory management tasks. C, though, allows (and in some cases requires) you to be explicit about memory allocation with the following key functions from the standard C library:\n- malloc -- Short for memory allocation, malloc is used to reserve a block of memory of a given size to story a certain type of data your program needs to process. When you use malloc, you're creating a pointer to the allocated memory. This isn't necessary for a single piece of data, such as one integer, which is allocated as soon as you first declare it (as in int i). However, it is an important part of creating and managing data structures such as arrays. Alternate memory allocation options in C are calloc, which also clears the memory when it's reserved, and realloc, which resizes previously reserved memory.\n- free -- Use free to force your program to free the memory previously assigned to a given pointer.\nBest practice when using malloc and free is that anything you allocate should be freed. Whenever you allocate something, even in a temporary function, it remains in memory until the operating system cleans up the space. To ensure that memory is free and ready to use immediately, though, you should free it before the current function exits. This memory management means you can keep your program's memory footprint to a minimum and avoid memory leaks. A memory leak is a program flaw in which it continues using more and more memory until there's none left to allocate, causing the program to stall or crash. On the other hand, don't get so anxious about freeing memory that you free up, and thus lose, something that you need later in the same function.\nThroughout this article, you've learned some of the basic structure and core concepts of the C programming language. We've looked at its history, the characteristics it has in common with other programming languages and the important features that make it a unique and versatile option for coding software. Launch over to the next page for lots more information, including some programming guides that will carry you further on your journey into C."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:cd4439d6-b188-424c-a449-97d9c1f2313f>","<urn:uuid:e2d09143-5a2f-4b3e-838a-dd7ee872460a>"],"error":null}
{"question":"How do basic SDRs and the DX-Patrol MK4 differ in terms of frequency coverage and front-end design?","answer":"Basic SDRs like the RTL-SDR have a tunable RF front end but often suffer from linearity issues due to low-power operation and insufficient current for good RF amplifier performance, leading to interference problems with pagers and FM broadcasts. The DX-Patrol MK4, on the other hand, features a dedicated HF converter allowing coverage from 100 kHz to 2000MHz without gaps, and includes additional bandfilters for improved strong signal handling. It uses two separate antenna connectors optimized for different frequency ranges, with a low-noise pin diode switch for band switching.","context":["Before getting started for #6, something I didn't say last time needs to be said and emphasized. I measured one frequency in one band on one radio. That really doesn't say much. It could be typical of what you measure everywhere, it could be better than most frequencies and it could be worse. A different brand could be better or worse. What I measured is really the first step of what should be done before using a radio in a situation where you're really concerned about being monitored while leaving a radio in receive mode for long periods.\nOn the other hand, the “near/far problem” is a much bigger problem. Your weakest transmit signal is going to be many times stronger than this LO leakage. I go through an example here where I attenuate the transmitter by a factor of one million – 60 dB. That meets a link budget to a friend two miles away. That signal, at about 1 microwatt leaving the transmitter is still 50 dB stronger than the leakage I talked about before.\nLet's get to the subject at hand: software defined radio or SDR. The problem with the subject is that it's so broad, it's hard to simplify. It's really just “radio” but built a different way. The most common definition is a radio in which some of the functions normally performed in hardware are done by software. It's hard to say exactly when the first radio that could be called an SDR hit the market for hams and hobbyists. They were certainly out in the mid 1990s, and I'm sure they were experimented with before that.\nThe most important thing to point out is that an SDR can't do anything that an analog radio can't do, but it generally does them in more repeatable ways, and in ways that can be miniaturized more easily.\nAn important example is the IF filter we've seen in every superheterodyne block diagram. While intricate inductor capacitor (LC) filters, crystal filters, and mechanical resonator filters have been available for all of radio history, they all require effort by skilled technicians to align. Buying filters from a company that specializes in building them outsources the alignment to another factory, arguably one better at building and optimizing those filters, but they're the same hardware.\nOn the other hand, once the signal has been digitized – converted to numbers – the signal can be mathematically filtered in software, what's often called “the digital domain”. The software filters need to be designed and coded once, and there is never another alignment. They're always perfectly identical. In that sense, SDRs are a bigger boon to the manufacturers than to the users. They need to inventory fewer parts, the radios need less alignment time during manufacturing, and the manufacturers have to invest less time in one of the major headaches all manufacturers face: components going obsolete.\nA simplified block diagram of the Icom 756, introduced in 1996. The area circled in red, a “DSP” module taking the fourth IF at 15.625 kHz and providing software defined filters and demodulation, makes this an SDR.\nBefore the signal can go through those filters, it has to be converted into numerical representations of the signals; it has to be digitized. The heart of any SDR today is the ADC, or Analog to Digital Converter, usually just called “the A to D”. These convert the smoothly varying analog voltage from the antenna, called direct sampling, or from an IF, to numbers. One of the most important things to know about converting any signal to digits is how fast you have to sample it, and the most important relationship is the Nyquist limit, which simply says you must sample the signal at least twice as fast as the highest frequency of the signal.\nThere's something vitally important hidden here. Let's pretend we're converting an analog radio to digital filtering and demodulation (among the first applications we call SDR). The radio's final IF where the current analog filtering and demodulation is occurring is 5.000 MHz. I don't need to sample at 10.000 MHz (twice the IF); I can just sample at twice the bandwidth of the IF I want to process. Let's say I want to maintain 15 kHz wide NBFM signals. I only need to sample at higher than 30 kHz, not 10 MHz and 30 kHz A/D converters are an entirely different price class than 10 MHz converters.\nThis is called undersampling. Instead of using a 10 MHz clock for the A/D converter, I can use a 50 kHz, or 100, or whatever is convenient (convenient = a frequency I can generate in my radio from a clock I have already). Undersampling is taking advantage of a phenomenon called aliasing. An example of aliasing everyone has seen is in movies or TV when a car's wheels appear to be turning the backward or slowing and reversing as the car speeds up. The sampling of the video or movie film shutter is aliasing with the image of the moving spokes.\nIn a sampled radio, aliasing causes the sampled bandwidth to repeat over and over, almost forever, like this picture. In this example, imagine we're sampling at 100 kHz. The first band, on the far left, is DC to 50kHz, which is one half the sampling frequency (fs/2 in the figure). But a signal just over 50 kHz is indistinguishable from one just under 50 kHz; that is, 51 kHz is indistinguishable from 49 kHz, 52 from 48 and so on – it's tuning “backwards”. When we get higher than the sampling frequency, a signal at 101 kHz is indistinguishable from one at 1 kHz, 102 from 2, 103 from 3 and so on. When we get above 3fs/2 the tuning direction reverses again. This goes on forever because it's pure math. In reality, the parts get less efficient and we read back lower voltages than are really there at the A/D.\nThis can be used to our advantage, like in sampling the IF with a low frequency clock. I should point out that a 100 kHz clock won't work if the IF is exactly at 5.0000 MHz because the IF is centered at zero, or 0 + 15 kHz, not going from zero to 30 kHz. The clock would need to have a multiple with a sampling band that completely contains the IF bandwidth.\nThe alternating slopes on those bands in the picture is intended to convey that they tune opposite each other. In this case, “repeating forever” means until the ADC stops responding to the signal. How high is that? I tested a converter rated for a 60 MHz clock once, or DC to 30 MHz. I started at 15 MHz (fs/4) and kept increasing the frequency by 30 MHz to find when I couldn't see the signal on the software that decoded the ADC. I never found the limit on the ADC. I ran out of signal generators to test with at almost 10,000 MHz: 10 GHz. The recovered signal was weak but it was the 166th alias.) In a \"professional grade\" SDR, there are many filters to prevent aliases from causing problems.\nThere's now a big handful of hobbyist SDRs on the market, at any price point you'd like to play with from $20 to thousands.\nWhat are the differences? The lowest end, like the RTL-SDR, are typically parts developed for some other use (TV reception in the case of the RTL-SDR) and hacked by dedicated hobbyists to develop ways of getting their data streams out.\nTypically, these radios have 8 bit A/D converters with a tunable RF front end and wideband frequency synthesizer for the LO. The tunable front end helps reduce aliases but doesn't eliminate them. Basically, frequency selectivity performance in a filter comes by the cubic inch and these radios just don't have enough cubic inches for the filters to be very useful. Filtering is the most frequent addition to make low end SDRs better.\nThe RTL-SDR block diagram, derived by one of the early experimenters is in two parts. Analog:\nThe digital portion looks like this:\nThe block diagram is all digital after the A/D on the left. The left hand box is an I/Q downconverter, just like the one in part four's installment with some additions. The abbreviation DDC is “Digital Down Converter”. DI and DQ are Digital I and Q, a FIR is a type of digital filter (Finite Impulse Response) with addition downconversion. Decimation (done in a decimator) is a way of reducing the frequency by intelligently throwing away samples. In both boxes, the down arrows denote this downsampling, reducing the sampling rate from the 28.8 MHz data originally coming out of the ADC. The output of the digital module is the decimated I&Q data streams for demodulation by the PC software.\nWhat distinguishes the thousand dollar SDR from the $20 kind? First, I've mentioned filtering, but there's more. A limitation of the low end radios is that they have low resolution A/D converters. The RTL-SDR shown here has an 8 bit converter. Higher end radios have 10, 12 and even 16 bit A/D converters. What's the big deal? The SNR in a converter never gets better than just over 6 dB/bit: that means an 8 bit converter can give a 48 dB SNR while 12 bit converter can give 72 dB and the 16 bit converter can give 96 dB. While a 48 dB SNR signal is fine to listen to, the world brings wide ranges of signals into a radio and the 8 bit converter is more prone to overload on stronger signals. More bits perform better, but the converters cost more and they impose more costs on the systems because more data is spewing out of the converter making the digital circuitry much harder.\nAnother issue is that these low cost SDRs are also low power radios and the only way to get good linearity (that is, minimum distortion) out of an RF amplifier is to run higher current. You'll read of interference problems with pagers and FM broadcast stations with these radios and there would be fewer of these problems if the front end was designed for higher level signals.\nThink of these lower end radios as equivalents of low cost scanners and other “beginner radios”. They introduce you to listening to things you couldn't hear otherwise, but they may also introduce you to problems, too.\nYou also have to beware of \"Specsmanship\" in these extremely low cost SDR radios. I bought one that advertised \"16-Bit Conversion!!\", but what they didn't tell you was that it was 8-bits on the I-Channel, and 8-Bits on the Q-Channel.....ReplyDelete\nOh, that is evil! I wonder why they didn't include power on/power off and call it 17-bit?Delete\nI think I know which SDR you're talking about, but would you like to leave that here so that readers can know to avoid them?Delete\nTo echo Malatrope, that's pretty awful. Dishonest at best, outright fraud at worst.\nI'm pretty sure it was $5~$10 USB 'dongle' from eBay or Amazon. It was an early one I bought when I started learning about SDR. I've had (quite literally) a dozen different 'dongle' receivers, and ALL of the cheep ones ($25 and under) are pretty crappy for general purpose use. Living in the SoCal \"RF Alley\" environment caused the cheap ones no end of grief. You had to go into the control panel for the app you were using, and cut back the RF gain or they'd go nuts from things like pagers, close by two-way radios, and probably your microwave oven if the door seals were bad.Delete\nAs of two years ago, the best one on the market IMHO was the AirSpy. It offered real 12-bit conversion, some extra hardware filtering on the front-end, a nice TCXO, and it came in an aluminum enclosure.\nThe best of the 'consumer' dongles were the RTL-SDR branded ones. They came with a TCXO, filtering, and were in an aluminum case to help keep their temperature more stable.\nThe \"Fun Cube Dongle Pro\" and \"Pro+\" units are also pretty good, but also pretty pricey at ~$200. I don't want to name the 'worst' one for liability reasons, but it didn't \"Play\" very well, and wasn't an effective \"Signal Processor\".\nAnd their software was unbelievably BAD.....\nAh Ha! Glad I didn't mention it because I thought it was that \"Signal Processor\" one.Delete\nI have one of the unbranded RTL-SDR types that I got from Adafruit a few years ago. It overloads in my FM broadcast band and this is a small city. I can hardly imagine intermod alley where you were. I haven't tuned around the pagers looking for trouble.\nI was thinking of picking up one of the branded RTL-SDR V3 units, since it's $30 with a nifty antenna. If nothing else, I can monitor my local police and sheriff with trunk tracking SW.\nIt's not a great receiver, but more versatile than ones like the old Bearcat scanners.\nYup....that's the one. It stunk as a radio, regardless of the eHam.net reviews!Delete\nI've wondered about the trunking software out there. I remember it being quite primitive some years ago, requiring TWO dongles to be usable; one for the control channel, and one for the talk groups.\nI've got several high-end Uniden digital trunking scanners, and they're wonderful at what they do.\nSiG, you sent me off on a little quest to find more. Analog Devices has an interesting paper that I glanced over and will jump into at a later point. It is here:Delete\nThe marketing that DrJim pointed out is interesting. And thanks for the fill in on different products. I have not had time to mess with the actual hardware in the past but may. My previous job, moving, getting a house built, moving in, more clearing of the land, etc. has seemed to get in the way of radio fun.\nPlease keep these articles going. They are either a quick refresher of what I know; often with a nugget or two of things I didn't know.\nYeah, Analog Devices is the Go To place for this kind of information. Especially since they bought up Linear Tech - who made the absolute best 16 bit A/D on the market (at least through 2015 or so, last time I did a thorough search), the LTC2207 (and family). 100 MHz clock and an honest 105 dB (to full scale) spurious free dynamic range.Delete\nLast full receiver I designed used that converter to sample the entire HF spectrum at just under 100 MHz and did almost everything else in the digital domain. It was also used to undersample the 118 to 152 aviation band.\nThat paper seemed very familiar, and I have it on my PC - dated 2002.\nIt's always difficult for me to tell which articles are going over well. These don't attract anywhere near the number of comments as pieces that I think are pretty innocuous get, so it's especially hard to know if I'm being helpful or useful.\nLet me know if there's anything in particular you're curious about. I might know a thing or two.\nInteresting. I think you do know a thing or two or three (as my late father would add). AD is still producing the LTC2207.Delete\nMost want to comment on the other subjects. As I said before, I know some of this but as I wasn't a designer, I didn't learn a lot of the nuances. That is why you are good to read.\nGood old Linear Technology! I've used many of their products. They made some really good wide-band op amps, too.ReplyDelete","DX-Patrol MK4 SDR (Software Defined Radio) Receiver with wide receiving range\nThe DX-Patrol MK4 is a Software Defined Radio (SDR) receiver with a very wide receiving frequency range. In contrast to the usual cheap USB DVB-T sticks this receiver has an additional converter for shortwave. This is the reason for the wide frequency range from 100 kHz to 2000MHz. For operation with the HF converter additional bandfilters are provided, resulting in a much better dynamic range and good strong signal handling performance.\nFor operation on HF, a frequency shift of -40MHz must be set.\nAnother feature is that the entire frequency range is provided without gaps. With two independent antenna connectors (SMA) you can always use the best suited antennas without reconnecting them when changing the bands. A small switch on the side of the receiver controls a low-noise pin diode switch when changing from HF to VHF or vice versa. The current state (HF/VHF) is shown with a multi coloured LED. The maximum sampling rate supported by the hardware is 3.2MS/s, but this is usually limited by the software. The result is a sampled spectrum range of 96 kHz up to approx. 1 MHz, depending on software.\nOperation of the DX Patrol SDR receiver is possible with any software which supports the RTL2832 based DVB-T stick. Possible programs are (among others):\n- SDR# (Windows)\n- HDSDR (Windows)\n- sdr-radio.com (Windows)\n- SDR Touch (Android)\n- Gnu Radio (Linux)\n- and more\nSpecial purpose programs like rtl1090 or dump1090 can be used to receive the ADS/B beacons sent from airplanes. With this receiver, suitable software and a suitable antenna plus cable a display of the current air situation at the receiving position is easily possible. Further you can participate in networks which provide live flight data to website like fleightradar24.com. Other software allows the reception of low orbit NOAA weather satellites on 137MHz - the possibilities of the Dx Patro lSDR receiver are endless!\nInstallation of the SDR receiver DX patrol is simple. It is recommended not to use the windows USB drivers but those provided through the 'Zadig' installer. The most programs mentioned above are free software products, you will find installation instructions on the various websites of the program authors. own software or drivers are not provided with the receiver. The connection to the computer is done with USB, a cable from USB-A conector to USB-Mini-B is required. This cable is not included. Mk3 version does include a short micro USB OTG cable.\nPlease note that not every smartphone or tablet computer is suitable for use with an OTG cable. The website of SDR Touch offers an incomplete list of compatible smartphones and tablet computer for use with OTG (english). We do use SDR Touch often to make tests with the DX Patrol and found that it works nicely. Please note that SDR Touch is not free, the full version does cost a few Euro. The free demo version is limited in it's functions.\nVersion history DX-Patrol SDR Receiver\n- Changes Mk1 → Mk2\n- improved filters\n- improved HF Design\n- Changes Mk2 → Mk3\n- Two Micro USB connectors for OTG support. One connector for the power supply, one connector for conenction to computer or smartphone.\n- Micro USB cable (OTG) included, allows the use of a smartphone\n- improved sensibility on VHF/UHF\n- New MK4 SDR\nIt offers a better connection via micro-USB cable into a PC\nor a Android Smartphone and Tablets\nThe SDR as two micro-USB A and B.\nUSB-B is data and must be the one connected to PC/Phone/Tablet. USB-A is Power assistance connections. (Charging wile operating)\n|@ 14MHz, CW, 500Hz, SDR#|\n|AGC Threshold:||22 µV (wideband 2MHz w/ max RF gain -45dBm total)|\n|100 kHz Blocking Range:||77dB (useful range, top-bottom = 77dB)|\n|Reciprocal Mixing Dyn. Range:||76dB|\n|Narrow spacing dyn. range IMD3:||66dB|\n|Narrow spacing dyn. range IMD3:||73dB|\n|Narrow spacing dyn. range IMD3:||63dB|\nDX-Patrol SDR (Software Defined Radio) Receiver MKIV with wide receiving range 100 kHz - 2 Ghz\n- Model: dxpatrol\n- Beschikbaarheid: Op voorraad\n- Excl. BTW: € 86,78"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:073a6eb1-88c1-4f4c-bd3a-c8507c38d011>","<urn:uuid:7909c0b2-afef-416f-8657-c59cd898e94b>"],"error":null}
{"question":"In terms of forming processes, what are the main differences between sheet metal fabrication and auto stamping parts manufacturing?","answer":"Sheet metal fabrication involves processes like bending, forming, punching, and hydroforming using equipment such as press brakes and specialized dies. Auto stamping parts manufacturing, on the other hand, involves direct transformation through stamping, followed by additional processes like welding, machining, or painting. While both use similar base materials, stamping specifically focuses on producing automotive components like shock absorber spring trays, spring seats, brackets, and covers through the stamping process.","context":["different types of Auto Stamping Parts?\nAuto stamping Parts, as the name suggests, are metal stampings that make up automotive parts. In automotive stamping parts, some of them are directly transformed into auto parts after being stamped, and the other part is subjected to welding, machining, or painting after being stamped to become auto parts. There are many kinds of automobile stamping parts, such as automobile shock absorber stamping spring tray, spring seat, spring bracket, end cover, cover, compression valve cover, compression valve sleeve, oil seal seat, bottom cover, dust cover, impeller, oil cartridges, lugs, brackets, etc. These are all automotive stampings. In Auto Stamping Parts China, stamping is sometimes referred to as sheet forming, but with a slight difference. The term “sheet forming” refers to the use of sheet material, a thin-walled tube, a thin profile, or the like as raw material. The method of forming plastic work is collectively referred to as sheet forming, and at this time, deformation in the direction of the thick plate is generally not considered. First, the application range of metal stamping parts:\n1. Special stamping enterprises. Such as the stamping of aviation parts, etc. belong to such enterprises, but these craft factories are also owned by some large factories.\n2. Stamping of parts and components in the automotive industry. Mainly punching and forming. Many of the companies in this sector belong to scale factories, and there are also some independent stamping plants. At present, there are many such small factories near some automobile factories or tractor factories.\n3The stamping factory of daily necessities. Do some crafts, tableware, etc. These factories have also grown significantly in recent years.\n4. Stamping in the automotive industry. Mainly drawing. In this part of China, we mainly focus on large factories such as automobile factories, tractor factories, and aircraft manufacturers. Independent large scale stamping and deep drawing plants have not been seen.\n5. Electric stamping plant. This type of factory is a new industry that has developed along with the development of electrical appliances, which are mainly concentrated in the south.\n6. Household appliance parts stamping plant. These factories only emerged after the development of household appliances in China, and most of them are distributed to household appliances enterprises.\nSecond, the detection of metal stamping parts:\nThe hardness of metal stamping parts is measured by a Rockwell hardness tester. Small, complex-shaped stampings can be used to test small planes that cannot be tested on ordinary Rockwell benchtop hardness testers. Stamping parts processing includes punching, bending, drawing, forming, finishing and other processes. The materials processed by stamping parts are mainly hot-rolled or cold-rolled (mainly cold-rolled) metal strip materials, such as carbon steel sheets, alloy steel sheets, spring steel sheets, galvanized sheets, tin-plated sheets, stainless steel sheets, copper and copper alloys. Plate, aluminum and aluminum alloy plates, etc.\nRockwell’s PHP series of portable surface hardness testers are ideal for testing the hardness of these stamped parts. Alloy stampings are commonly used in metal processing and mechanical manufacturing. Stamping is a process that uses a Stamping Mould to separate or form a metal strip. Its application range is very broad.","What Is Sheet Metal?Common MaterialsStandard SizesHot-Rolled vs Cold-Rolled Sheet MetalForming Processes For Sheet MetalSheet metal is one of the shapes and forms metal can be bought in.Sheet metal is any metal that has a thickness in between 0.56 millimetres.There are other measurement units used to categorise metals by thickness,though.See more on fractorySheet Metal Fabrication,Stainless Steel Fabricators We work in all metals and specialize in polished stainless steel cabinets,tanks,sheet metal work for reservoirs,transitions,and enclosures.We do aluminum fabrication,large metal bending projects and metal forming jobs too.Less encountered materials such as nickel,titanium,molybdenum,etc.are equally welcome. results for this questionWhat are the most common uses for sheet metal?What are the most common uses for sheet metal?Commonusesfor SheetMetalAutomotive Industry Sheetmetalsact as the spinal cord of the automotive industry.The thin sheets of metalare ideal for structuring the outer bodies of cars and other vehicles.Even the bodies of railroad cars are made using sheetmetals.What are some common uses for Sheet Metal - Sangeeta results for this questionWhat is sheet metal fabrication process?What is sheet metal fabrication process?Sheet metal fabrication is using sheet metal to build metal machines and structures.It can be a complex process involving many different professionals.Businesses that specialize in sheet metal fabrication are commonly referred to as fabrication shops,or fab shops for short.More about Sheet Metal Fabrication - Thomas Register\nA press brake is a press used to bend,form or punch metal.It is a press that exerts a force on a set of dies.The force can be created by mechanical,hydraulic,electric or manual means.Older systems used dies made to the angle of the bend desired.When sheet metal was pressed between the dies it took the angle of the dies when the dies Automation Capabilities CNC,Robotic Load/UnloadMaximum Sheet Metal Length Max 120Material Thickness Min .004,Max 1.00Maximum Sheet Metal Width Max 60Sheet Metal Fabrication Services IQS DirectoryFounded in 1921,Mid-West Metal Products has been an industry leader in sheet metal fabrication.We do CNC bending,forming,general machining,laser cutting,rolling,tube bending,welding and more on a variety of metals,such as aluminum and galvanized steel,up to .50? thick and measuring 10' x 5'.\n: CNC 6-Axis CNC Forming up to 14 Long @ thicknesses of .250 Steel Can be Processed,Up to 260 US TONS Available : Tolerances of as little as .005 can be held depending on material type and thickness : Polycarbonate forming : Extra deep box forming up to 14+ ( more info) Sheet Metal and Structural FabricationCustom Products - Pro-Forming Sheet MetalAt Pro-Forming,we draw upon 25 plus years experience in sheet metal fabrication to bring your ideas to life.Whether youre interested in a complete prototype or just parts,we can help create it.Contact us today to find out more.Our custom metal sheet products come in many material options Our products can be manufactured from a variety\nSHEET METAL FABRICATION.Acro Industries,Inc.can provide complete sheet metal fabrication services for your project using our wide array of cutting,bending,and punching capabilities.Laser Cutting - Our Cincinnati 707 Laser uses a 3300 watt laser to cut through a maximum material thickness of 7/8.The flying optics allows the material to remain stationary while the cutting laser moves to Fabrication Formulas - SheetMetal.Me Sheet Metal Box Bending The process of bending a 4 sided sheet metal box.Coining One of the three types of bending for sheet metal where the punch penetrates into the sheet metal under high tonnage forming a consistent bend.Cross Break Light bends added to sheet metal in order to stiffen its surface.Local results for forming sheet metal fabrication steels Meta Fab922 W Main St,Hillsboro,OR 97123 (503) 640-2527DIRECTIONSWEBSITEA List Of Common Sheet Metal Fabrication TechniquesHydroforming A forming and fabricating process that uses a specialized type of die molding,which uses highly pressurized fluid to shape metals like steel,stainless steel,steel,aluminum,and brass.Metal punching A process in which metal fabrication equipment punches holes,louvers,or a predetermined shape out of sheet metal.Milling A\nCadet Steel,Inc.in Denver is a custom metal fabricator specializing in light to medium structural steel applications.If your metal project requires shearing,forming,CNC cutting and welding then we are your one-stop shop.We work with a variety of structural materials,plate,and sheet such as Hot Rolled,Cold Rolled,Galvanized Location 407 Zeiter Way Swanton,OH 435585 Factors for Choosing Sheet Metal Fabrication Meta Fab Feb 05,2020·4.Design Considerations for Sheet Metal Fabrication.Engineers designing sheet metal enclosures and assemblies often end up redesigning them so they can be manufactured.Research suggests that manufacturers spend 30-50% of their time and 24% of the errors are due to manufacturability.Metal Fabricating Metal Fabrications by Bassett Stainless Steel (A249,A269,303,304,304 L,309,310,316,316 L,317L,410,416) CNC machining,precision welding,end forming and sheet metal fabrication to optimize the fabrication and assembly process.The result is lower-cost,quick-turnaround,high quality and repeatable ready for assembly components,weldments,and assemblies\nCustom Metal Fabrication in Connecticut Pro-Forming Sheet Metal is your One-Stop Shop for Custom Metal Fabrication in CT.With more than 25 years in the industry,we are one of the most experienced metal fabricators in Connecticut and we understand that it is vital for our customers to get their products manufactured precisely and efficiently.Metal Fabrication and Forming Spraying Systems Co.metal fabrication forming The right spray technology can significantly improve product consistency and worker safety for metalworkers and metal product fabricators.Whether you manufacture automobiles or appliances,solutions from Spraying Systems Co.can help you meet your daily production needs,as well as your overall business goals.Metal Forming Metal Fabrication Steel,Steel More CNC press brake operators skilled at sheet metal forming metal fabrication Steel,mild steel,stainless steel Small large runs 800-513-5416\nMetal Forming and Rolling.Curves,bends,and other shapes require the right equipment,tools,and experienced fabricators to ensure the job is done right.When fabrication requires something other than a flat surface,you can count on All Metals Fabrication for precise,efficient and cost-effective metal forming and rolling services:Metal Forming Services - Addison,Illinois - T/J FabricatorsForming Established in 1967,T/J Fabricators,Inc.has been a leading provider of forming services that require custom tooling for unique projects.We can perform custom sheet metal fabrication and prototyping services using our state-of-the-art press brake forming equipment.Metal Forming Services,Sheet Metal Fabrication,Laser From simple brackets to intricate housings,Classic Sheet Metals Press Brake metal forming capabilities will yield quality assured parts.Our extensive metal forming equipment and highly experienced personnel can produce a variety of shapes including angles,U shapes,hat shapes,multiple bend shapes,C shapes,and off sets.\nYour search is over! You have found Allied Steel,The areas' Best and Most Reliable Steel Fabricator,and custom Metal Supplier! Working with Allied assures that youll always have easy access to reliable fabrication services and stock quality steel,stainless steel and aluminum metal products of flat sheet metal,flat plate,diamond plate,I-beam,pipe and structural steel shapes as well as Metal Rolling Forming Services Swanton WeldingAug 25,2020·Swanton Welding is different.Our diverse range of talents and skills set our services apart from other metal fabricators.Swanton Welding offers our customers comprehensive fabrication services at an affordable price.From robots creating widgets to skilled fabricators handcrafting oversized pieces with precision,Swanton Welding is the team your project deserves.Nanaimo Sheet Metal Quality Customized Metal Solutions Since 1979,Nanaimo Sheet Metal has been providing affordable customized metal solutions for individuals and businesses alike.NSM prides itself on providing quality products and services for commercial kitchens,architectural installations,vehicle and parts repair,marine applications,domestic design and repair,certified steel welding to\nmetal sheet fabricationsheet metal fabrication machinesmetal fabrication steel tablesstainless steel metal fabricationcustom sheet metal fabricationsheet metal fabrication softwaresheet metal fabrication jobsmetal fabricationsSome results are removed in response to a notice of local law requirement.For more information,please see here.12345NextSheet Metal Fabrication - Pro-Type IndustriesSheet metal fabrication refers to the various metalworking processese.g.,bending,cutting,forming,rolling,and weldingused to turn sheet metal into the desired parts,products,and structures by removing,deforming,or joining the material.\nSheet Metal Fabrication Our sheet metal fabrication services include cutting,forming,and finishing for parts,such as brackets,panels,and vents,as well as the turnkey manufacture of products,such as frames and enclosures.Sheet Metal Fabrication 101,a Basic Knowledge Guide Jul 24,2020·Sheet metal fabrication is a broadly used metal forming process that transforms sheets of metal (in varying thicknesses) into parts using different types of equipment.Sheet Metal Fabrication Malaysia Steel Forming Julik Engineering Sdn Bhd was established in 1980 and later form its sister company Julik Metaltech Industries (formerly known as Julik Hardware and Machinery).Over 36 years,Julik is one of the most versatile steel fabricators in Malaysia.In these years of operations,Julik has chartered significant growth and progress through our proven expertise and diversified scope of activities.\nCreating Top-Quality Sheet Metal Forms Marlin Steels engineers have extensive experience in working with a wide variety of materials for sheet metal fabrications,such as plain,stainless,galvanized steel,aluminum,titanium,and a variety of other alloys.Sheet Metal Fabricators,Metal Stamping,Metal Forming Sheet Metal Fabricators.We are a custom sheet metal fabrication shop with a ton of equipment and talent.Sheet metal and steel fabrication is done with a variety of press brakes,several CNC Turret Punch presses,or fiber laser cutting machines and metal cutting shears.No job is too big or too small.Quick turn projects are our specialty.Sheet Metal Forming - Massachusetts Institute ofSheet Metal Forming 2.810 D.Cooper !Sheet Metal Forming Ch.16 Kalpakjian !Design for Sheetmetal Working,Ch.9 Boothroyd,Dewhurst and Knight\nWe supplied Custom Fabricated Steel Bollards,A992 Wide Flange I-Beams,Truss Girders,Stainless Steel C Channels,A36 Flat Plate,Steel Flat Bar,A500 HSS Square Tubing,SCH80Pipe Columns,Diamond Plate,Perforated Metal and Custom Sheet Metal Fabrication.Allied Steel Company understand the importance of going a step beyond the other run Stainless Steel Sheet Metal FabricationWhat is sheet metal fabrication? One of the most common industrial alloys,stainless steel is highly machinable and adaptable to custom applications.The types of processes,transformations,and finishes it undergoes are as varied and unique as its applications.Stainless steel fabricators can transform sheet metal with processes such as:The Forming Potential of Stainless Steelbright-annealed (2R) stainless steel sheet without any additional polishing.The fact that the surface finish survives the forming operation makes the combination of the material and the forming-technique cost-effective.3 This publication is intended to indicate selected processes that make optimum use of stainless steels forming potential.\nAbout product and suppliers 11,144 sheet metal forming products are offered for sale by suppliers on ,of which sheet metal fabrication accounts for 12%,machining accounts for 1%,and electronic instrument enclosures accounts for 1%."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:16c16da0-f45c-4261-9477-9605baa906cf>","<urn:uuid:d96714ca-3247-4dbd-8da4-f2220dc6eb16>"],"error":null}
{"question":"As someone studying autoimmune conditions, what's the connection between vasculitis and temporal arteritis, and what are their distinctive symptoms?","answer":"Temporal arteritis is a specific form of vasculitis, being the most common systemic vasculitis affecting the elderly. While vasculitis broadly causes inflammation of blood vessels leading to weakening, scarring, and narrowing, temporal arteritis specifically affects the head arteries, particularly the temples. The distinctive symptoms of temporal arteritis include headache, visual changes, jaw claudication, scalp tenderness, and potential blindness. In contrast, general vasculitis can present with varied symptoms depending on the affected vessels, including loss of appetite, weight loss, fatigue, joint and muscle pain, and nerve abnormalities.","context":["Aims The purpose of this paper was to recognize the place also to grade the severity of most significant inflammation within positive temporal artery biopsies along with other key clinical and histologic characteristics. few exceptions, granulomatous inflammation in positive temporal artery biopsies is definitely most evident in the press and adventitia or is definitely uniform throughout the layers of the artery. Our study lends support to the theory the muscularis and adventitia may play an inciting part in the pathogenesis of temporal arteritis. strong class=”kwd-title” KEY PHRASES: Temporal arteritis, Giant cell arteritis, Granulomatous swelling, CD68, Vasculitis Intro Temporal arteritis is an inflammatory vasculitis that is regarded as an ophthalmic emergency. It is the most common form of systemic Afatinib irreversible inhibition vasculitis influencing the elderly and can lead to rapidly progressive and long term vision loss. Quick analysis and treatment with systemic corticosteroids is required to prevent vision loss . Clinical manifestations of temporal arteritis include headache, visual changes, jaw claudication, scalp tenderness, polymyalgia rheumatica, Afatinib irreversible inhibition and fatigue . Laboratory screening regularly discloses elevated inflammatory markers, including elevated erythrocyte sedimentation rate (ESR), and C-reactive protein (CRP). The gold standard for analysis is the temporal artery biopsy . The current literature describes a positive biopsy as exposing chronic granulomatous swelling C consisting of epithelioid histiocytes, multinucleated huge cells, T lymphocytes, and macrophages C focused on the known degree of the inner flexible lamina [4,5,6]. Intimal hyperplasia and fragmentation of the inner flexible lamina are generally noticed in histopathology also. Recently, Compact disc68 immunostaining for the current presence of macrophages has been proven to become useful in differentiating between indeterminate and positive temporal artery biopsy specimens . The inner elastic lamina is generally assumed to become the original and feasible inciting site of temporal arteritis predicated on (1) the deposition of large cells and histiocytes along the area of the prior flexible lamina; (2) flexible fragments found using the large cells, and Rabbit Polyclonal to CAD (phospho-Thr456) (3) having less participation of arteries missing an internal flexible lamina (e.g. the intracranial arteries) [4,8,9]. Various other experimental data shows that the disease is set up in the external layer from the arterial wall structure, with Afatinib irreversible inhibition inflammatory cells getting into through the vasa vasorum and infiltrating into all layers from the artery wall  subsequently. The goal of this research is normally to verify the positioning and intensity of granulomatous irritation in positive temporal arteries and also other scientific Afatinib irreversible inhibition and histologic features and to evaluate these results to previous reviews. Methods Sufferers and Specimens The set of sufferers with biopsy-proven temporal arteritis was produced by searching the University or college of Wisconsin (UW) Attention Pathology Laboratory and UW Medical Pathology Laboratory databases for the terms huge cell arteritis and temporal arteritis. Charts for individuals with positive temporal artery biopsies from a 25-yr period, 1989-2014, were examined for demographic info, clinical signs and symptoms, laboratory results, and treatment program. Instances with indeterminate diagnoses were excluded, as were cases where medical info was unavailable. A total of 70 individuals were included in the study. The top limit of normal for ESR was determined by the formula proposed by Miller et al.  in 1983: age/2 in males and (age +10)/2 in ladies. Elevated CRP was defined as 2, and elevated platelets were defined as 450. All biopsies were submitted in 10% formalin. Upon grossing, the cells were examined for size and color, then consequently slice into 2-mm items and regularly processed. They were then inlayed on end and serially sectioned in 25-m intervals having a thickness of 5 m. Initially, 50% of the paraffin block was sectioned. If the pathologist saw no granulomatous swelling in the initial examination, then 90% of the.","What is Vasculitis ?\nVasculitis is a disorder that results in inflammation of the blood vessels. The condition leads to several changes in the blood vessels walls such as weakening, scarring, thickening and narrowing.\nThere are various forms of vasculitis. Some types are chronic and last for an extended period while other forms are acute and may last for a very short duration. Cases of vasculitis can be very severe as the affected blood vessels tend to carry decreased supply of blood to various organs and tissues. This can result in organ and tissue damage as well as fatality.\nAnyone can be affected by vasculitis, though individuals belonging to a certain group may be more vulnerable to the condition. Some types of vasculitis tend to improve by themselves whereas other forms may require medications over a long period of time.\nVasculitis is often referred to by other names such as arteritis or angiitis.\nSymptoms of vasculitis\nThe symptoms of vasculitis vary as per the blood vessel and the organ that is affected. Some of the general signs of the condition are listed below:\n- Loss of appetite\n- Loss of weight\n- Excessive tiredness or fatigue\n- Joint and muscle pain\n- Nerve abnormalities such as weakness or numbness\nThe symptoms of various forms of vasculitis are discussed below:\n- Buerger’s disease: It causes clots and inflammation of the blood vessels present in the extremities. It has a strong association with cigarette smoking and tends to cause pain in the upper and lower limbs, and ulcers on toes and fingers.\n- Behcet’s syndrome: It results in inflammation of the veins and arteries and appears in the twenties or thirties. Symptoms include eye inflammation, genital and oral ulcers and acne-like skin lesions.\n- Churg-Strauss syndrome: Often associated with asthma, the condition affects the lung blood vessels.\n- Giant cell arteritis: It generally affects the elderly and causes inflammation of the head arteries, particularly the temples. Symptoms include pain in jaw while chewing, headaches, double or blurred vision or even blindness and scalp tenderness. Giant cell arteritis is often associated with another condition called PMR which causes inflammation and pain in the large joints. PMR results in muscle stiffness or pain in the thighs, hips, upper arms, shoulders and neck.\n- Cryoglobulinemia: It shows symptoms such as nerve damage, purpura rash on the lower extremities, weakness and arthritis. The condition is mostly associated with infections by hepatitis C.\n- Henoch-Schonlein purpura: It causes inflammation of the blood vessels in the bowels, skin, kidneys and joints. Symptoms include bloody urine, purpura rash on legs, buttocks and feet, joint and abdominal pain.\n- Kawasaki disease: It often affects children below 5 years and shows symptoms such as skin rash, fever and eye inflammation\n- Hypersensitivity vasculitis: The condition may be triggered by an allergy to an infection or a drug and leads to the formation of red spots on the skin\n- Microscopic polyangiitis: It affects the smaller blood vessels in the lungs, kidneys and skin and shows symptoms such as nerve damage, inflammation of smaller blood vessels in the kidneys, fever, skin lesions and weight loss.\n- Takayasu’s arteritis: It typically affects young women and occurs in the largest arteries such as the aorta. Symptoms include visual abnormalities, headaches, diminished or absent pulses, sensation of cold or numbness in the extremities and hypertension.\n- Polyarteritis nodosa: It affects blood vessels that are midsized in various regions of the body such as kidneys, skin, peripheral nerves, heart, intestines and muscles. Symptoms include kidney abnormalities, joint and muscle pain, skin ulcers, abdominal pain and purpura rash.\n- Granulomatosis with polyangiitis [Wegener's]: It results in inflammation of the blood vessels in the sinuses, lungs, throat, kidneys and the nose. Signs include chronic sinus infections, nasal stuffiness, kidney damage and nosebleeds.\nCauses of vasculitis\nVasculitis is caused due to the mistaken recognition of the blood vessel cells as invaders of the body by the immune system. The immune system then attacks the blood vessels resulting in the condition. The exact reasons for this action of the immune system are unknown, but studies suggest that it may be triggered by certain cancers, an allergic reaction or an infection or due to the presence of some immune system abnormalities.\n- Vasculitis results in inflammation of the blood vessels which cause them to become thicker and then narrower. This leads to decreased supply of blood, oxygen and essential nutrients to the various affected organs. Sometimes, the blood flow may be obstructed due to the development of a blood clot, whereas at other times vasculitis may result in weakening of the blood vessels causing fatal aneurysm.\n- There are two types of vasculitis based on the causes. Primary vasculitis has no known cause.\n- Secondary vasculitis develops due to the presence of another disease, which may be caused due to immune system diseases, blood cell cancers, allergic reactions and infections.\nTreatment of vasculitis\nTreatment of vasculitis is specific to the type of vasculitis that affects the patient. Some of the treatment methods are as follows:\n- Steroid medications such as corticosteroids may be given to control inflammation.\n- Severe cases of vasculitis may require immunosuppressant drugs to inhibit the activities of the immune system\n- The above medications have many side effects and hence should be consumed only after consultation with a physician."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:3ea6a92d-32c1-4c9d-90aa-d9b6b368277c>","<urn:uuid:28dfe48b-07fe-415b-809a-bd43c3b7b7d2>"],"error":null}
{"question":"What is the difference between UPC-A and GS1-128 barcodes in terms of their typical usage?","answer":"UPC-A is primarily used for retail products in the USA as the standard symbology, while GS1-128 (formerly UCC/EAN-128) is used for shipping containers of all types. GS1-128 has more advanced capabilities, as it can encode all ASCII alphanumeric characters and share additional information like company details, product information, ship date, and lot/batch numbers.","context":["How To Get A Barcode On\nYour Product or Publication\nBarcode Basics >\nRetail Barcode FAQ\nDo I need a barcode?\nAlthough it is not law that you have a barcode on\nyour retail product or publication, it is\noften required by re-sellers and distributors. They use the barcode to efficiently\nkeep active inventories and sales records.\nWhat kind of barcode should I\nFor retail products, the standard symbology in the U.S.A. is\nUPC-A, or the Universal Product Code.\nInternationally, the standard symbology is EAN-13\n(European Article Numbering international retail product code).\nFor marking shipping cartons of retail\nproducts for distribution, the most common symbol is the UPC\nShipping Container Symbol (ITF-14).\nFor marking shipping containers of all types,\nthe most commonly-used barcode is\nUCC/EAN-128. Different industries often have specific\nrequirements for barcode labeling, so be sure to get details from\nyour customers when they ask you to start marking packages or items\nFor books, the international standard is the\nEAN symbology (ISBN barcode).\nFor periodicals, the international standard symbology is\nISSN (International Standard Serial Numbering ). In\naddition to the ISSN code, SISAC (International Standard Serial Numbering) codes are often\nfound on serial publications.\nWhere do I get the data (the number)\nfor the barcode?\nFor a UPC-A or an\nEAN-13 manufacturer number, contact\nGS1 (formerly the UNIFORM CODE COUNCIL)\nPrinceton Pike Corporate Center\n1009 Lenox Drive\nLawrenceville, NJ 08648\nMain website: www.gs1.org\nNeed a barcode page:\nTo find a local office worldwide:\nBefore you contact GS1, estimate how many\ndifferent numbers you will need for your products. Be sure to get\nenough numbers, but remember that the registration fee goes\nup for more numbers. Every variation of every product will require a\nseparate number. For example, if Product ABC is available in three\nsizes (small, medium, and large) and in three different colors (red, blue,\ngreen), you will need nine (9) separate numbers... one for each size/color\ncombination. GS1 will assign you a manufacturer ID number that you\nwill use as the leading digits in your barcode. You will use\nthe remaining digits to assign a unique number to each of your\nFor an ISBN number in the U.S.A., contact\n121 Chanion Road\nNew Providence, NJ 07974\nTelephone: (908) 665 - 6770\ntoll free: (877) 310 - 7333\nTelefax: (908) 665 - 3502\nISSN number in the U.S.A., contact the\nLIBRARY OF CONGRESS\nNational Serials Data Program\nWashington, D.C. 20540-4160\nTelephone: (202) 707-6452\nTelefax: (202) 707-6333\nFor an ISSN number outside the U.S.A., contact\nISSN INTERNATIONAL CENTRE\n20 rue Bachaumont, 75002 Paris, FRANCE\nTelephone: +33 1 44 88 22 20\nTelefax : +33 1 40 26 32 43\nHow do I print barcodes\non my product or publication?\nIf you will be printing the barcode as part of\nyour product package or label, you will need artwork that you can paste into the\nlayout. If you will be using a lot of barcodes, you may want\nto invest in software. Search for\nbarcode artwork software, also have a look at BarCode Pro, a\nvery good professional program\n. If you need just a few barcodes, try an online service like\nIf you want to print barcode labels and stick\nthem onto your product or packages, look for\nbarcode label printing\nsoftware. We especially like Bar Tender For Windows (www.seagullscientific.com).\nYou can print your labels on a regular laser printer (inkjet labels\ntend to run if the labels get wet). If you will be printing a\nlot of labels in a serious production environment, take a look at\nthermal label printers.\nWe have had good success with Zebra printers (www.zebra.com).","What is GS1?\nGS1 is a not-for-profit organization that sets global standards for businesses to improve efficiency and transparency across the supply chain. GS1 has over 1.5 Million user companies that rely on the organization’s standards to help streamline operations, address industry challenges, and position their businesses to respond to changing market conditions. GS1 barcodes have become the gold standard for food businesses implementing digital business data management and exchange. As a GS1 Solution Partner, FoodLogiQ has built our platform on GS1 standards.\nGS1 is headquartered in Brussels, Belgium and has 114 Member Organizations (M.O.’s) around the globe. These M.O.’s help their local members apply these global standards, and navigate national and local regulatory requirements. FoodLogiQ is a member of GS1 US.\nGS1 Standards in Action with IPC/Subway\nRead the full case study on how IPC/Subway reduced costs by over $1 Million by implementing GS1 Standards.\nUnderstanding GS1 Barcodes\nGS1 introduced the barcode in 1974 in collaboration with leaders from the grocery industry. Barcodes have since become a scalable instrument for businesses to share data in accordance with GS1 open standards. From farmer to retailer, these standards create a common language that enables global systems of exchange. GS1 barcodes are scanned over six billion times each day.\nBarcodes can be applied at all levels of the product hierarchy, from the consumer unit, to the case pack and finally at the pallet level. Global Trade Item Numbers (GTINs) are globally unique identifiers for products that are encoded into the barcode.\nBarcodes can include more than just GTIN information. For example, each section of the GS1-128 barcode can represent a key piece of information related to the product expressed in a standardized format.\nBelow is a sample GS1-128 barcode generated for FoodLogiQ to help illustrate the way data can be communicated. For Foodservice, the industry has agreed on 3 key components:\n- (01) Global Trade Item Number (GTIN)\n- (AI) Date Information\n- (10) Batch/Lot\nRead about the GS1-128 Barcode for the food industry for more information on how to get started.\nGS1 US Case Studies\nGS1 standards make supply chain-wide interoperability possible, codifying inter-business communications and enabling visibility across nodes and food chain events. Industry initiatives like the New Era of Smarter Food Safety emphasize that chain-wide communication and consistency are key. Adopting shared data standards is widely considered the most important step for the food industry to take towards traceability. Without a shared language, traceability programs are less likely to be implemented successfully industry-wide. Traceability standards will improve relations with your trading partners, make staying compliant with regulation easier, and will enable important business practices like product authentication. For a detailed overview of GS1 and traceability, download the Implementation Guideline for Case-Level Traceability Using GS1 Standards.\nRead more key statistics and insights on how the Foodservice industry is leveraging GS1 Standards to remain relevant and competitive.\nGet Started with GS1 Standards\nFoodLogiQ is a GS1 Solution Partner. The FoodLogiQ Connect platform was built on GS1 standards in order to deliver true farm-to-fork traceability with standardized product information. Our traceability solution provides visibility at every step throughout the food supply chain. We have multiple GS1 certified staff members ready to help you get started today.\nFood Industry Resources\n● GS1 US Foodservice Standards Microsite\n● Get Started Guide for Barcodes\n● Implementation Guideline for Case Level Traceability\n● GS1 and Blockchain: What this Means for the Food Industry\n● Common Mistakes on GS1-128 Barcode Implementation\n● GS1 Standards In Action: Traceability\n● GS1 Traceability Standards Document\n● Traceability for Fresh Fruits and Vegetables Implementation Guide\n● GS1 Barcodes Factsheet\nThis graphic is owned by GS1 US and copyright protected. Image Courtesy of GS1 US.\nGS1 utilizes globally unique identifiers for products and locations. These can then be used across any supply chain to look up product information in a database, or be encoded into a data carrier and then capture information through scanning the barcode.\nGTIN®: the Global Trade Item Number (GTIN) is a 14 digit identifier for products or services exchanged in the supply chain. For products, companies will assign a Global Trade Item Number (GTIN). These are comprised of four components: 1) Indicator Digit, 2) Your GS1 Company Prefix, 3) Item Reference Number, 4) Check Digit.\nGTIN Example: 10847976000040\n1 = Indicator Digit\n0847976 = FoodLogiQ GS1 Company Prefix\n00004 = Item Reference Number\n0 = Check Digit\nThe Check Digit is calculated and there are several tools to create them. GTIN is an attribute in FoodLogiQ Connect, and the system can automatically generate the check digit, per the GS1 Standard. Read the GS1 US resource on how to Identify Product with a GTIN for more information.\nGLN: the Global Location Number (GLN) is a 13 digit identifier for locations, both physical or digital, which can be as specific as a location within a store or an instance in a database. GLNs can also be descriptive of legal entities. For products, companies will assign a Global Trade Item Number (GTIN). These are comprised of three components: 1) Your GS1 Company Prefix, 2) Item Reference Number, 3) Check Digit.\nGLN Example: 0847976000005\n0847976 = FoodLogiQ GS1 Company Prefix\n00000 = Location Reference Number\n5 = Check Digit\nThe Check Digit is calculated and there are several tools to create them. GLN is an attribute in FoodLogiQ Connect, and the system can automatically generate the check digit, per the GS1 Standard. Read the GS1 US resource on how to Identify Location with GLN for more information.\nAI: Application Identifiers (AIs) are two-digit numerical prefixes that correlate to specific data elements. AIs are used in barcodes and EPC-Enabled RFID tags to denote the specific type of data being relayed. Read the Voluntary GS1-128 Barcode Guideline to reference the AIs used in the Foodservice Industry.\nU.P.C.: the Universal Product Code (UPC) is a 12 digit number used in barcodes that are human and machine readable to identify unique products at points of sale.\nEAN: European Article Numbers (EANs) are 13 digit numbers used in barcodes that are human and machine readable to identify unique products at points of sale.\nGS1 DataBar®: GS1 DataBar is one of the symbolic languages used in GS1 barcoding to encode data. DataBar barcodes are used for labeling fresh foods and can hold pertinent information like an item’s batch number or expiry date.\nITF-14: GS1 uses “Interleaved 2 of 5 (ITF)” barcoding for encoding GTINs. ITF barcoding encodes data in the white space between black barcode symbols, in addition to the black symbols, in order to store more data. These are traditionally used at the case level.\nGS1-128: the GS1-128 (formerly UCC/EAN-128) is a variant of code 128, which can encode all ASCII alphanumeric characters in barcode format. GS1-128 defines both data types and formats that are used for exchange and logistics between entities. GS1-128 allows companies to share company, product, and shipping information including items like GTIN, ship date, lot/batch number, and more. Read the Foodservice Implementation Guideline for Case-Level Traceability Using GS1 Standards, as well as the Retail Grocery GS1-128 Implementation Guide for more information on how to get started. For tips on how to avoid common mistakes read our Common Mistakes on GS1-128 Barcode Implementation document.\nGS1 DataMatrix: the GS1 Datamatrix is a two dimensional barcode, meaning data is stored across multiple dimensions. Data is encoded in a machine readable square or rectangle in the form of a black and white pattern, which can be read horizontally or vertically. These codes are used in cases where a larger data capacity is required.\nGS1 QR Code: GS1 QR Codes are two dimensional barcodes, meaning data is stored across multiple dimensions. Data is encoded in a machine readable square or rectangle in the form of a black and white pattern, which can be read horizontally or vertically. Though similar in form, these codes have an even higher data capacity than the GS1 DataMatrix. GS1 QR codes are typically used to store extended packaging. GS1 QR codes must store GTIN information.\nEPC®-Enabled RFID: Electronic Product Codes (EPCs) are stored using with Radio Frequency Identification (RFID) sensors to track products across the supply chain. RFID technology uses radio wave-based readers to activate and read tags that store data. These relatively cheap pieces of hardware allow product data transfer without a visual barcode.\nEDI: the Electronic Data Interchange (EDI) is a data messaging system that allows businesses to share standardized data electronically. EDI software is used to share product, logistics, and transaction documentation between businesses.\nXML: eXtensible Markup Language (XML) is a flexible markup language used to encode, describe, and store data using various tags, nodes or elements. XML is similar to other markup languages like HTML, but is a more customizable way to digitize or share data.\nEPCIS: Electronic Product Code Information Services (EPCIS) is a GS1 standard for formatting business event data, as well as the development of interfaces for sharing (capturing and quarrying) this data between multiple stakeholders. Events that may be included in EPCIS visibility data include points of product movement, transformation, or exchange.\nBLOCKCHAIN: Blockchain is an emerging technology for distributed data management and transactions. The technology is a promising tool for companies to transact with each other and move assets around the world in a secure manner. GS1 standards will help enable the use of blockchain technologies by providing a framework for shared formats, processes, and data types."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:71837514-f1af-4608-ab5c-504e4316987b>","<urn:uuid:34b74548-708d-4c4a-9b60-b3d7d5bcddda>"],"error":null}
{"question":"What were Karl Jaspers' key insights about psychopathology methodology?","answer":"Jaspers established psychopathology as both a methodology and methodological criticism. He emphasized the contrast between individual patients with their personal histories and the experience of complex conditions that are independent of individuals. He also worked to develop specific psychopathological terminology by examining three key areas: comparing humans and animals, objectification of the soul, and the interaction between inner and outer worlds of individuals.","context":["Thome J: Molekulare Psychiatrie. Theoretische Grundlagen, Forschung und Klinik. Mit einem Geleitwort von Eric J. Thome J: Conceptualising molecular psychiatry and translational psychiatry.\n- McLean Main Navigation.\n- The Guide of the Perplexed, Volume 2.\n- Research Area: Cellular & Molecular Neuroscience;\nWorld J Biol Psychiatry , 12 Suppl 1 :3—5. Thome J: Humanities and Molecular Psychiatry. In Philosophy and Psychiatry. Edited by: Schramme T, Thome J. New York: Walter de Gruyter; — Schizophr Res , 31— World Psychiatry , 1—3.\nEdited by: Beckmann H. Berlin, New York: Walter de Gruyter; — Fortschr Neurol Psychiatr , — Download references. Correspondence to Johannes Thome.\nThis article is published under license to BioMed Central Ltd. Reprints and Permissions. Search all BMC articles Search. Abstract Modern molecular psychiatry benefits immensely from the scientific and technological advances of general neuroscience including genetics, epigenetics, and proteomics. Karl Jaspers: biography Born in in Oldenburg Germany , Karl Jaspers suffered poor health throughout his youth hereditary bronchiectasis which, according to his own testimony, shaped his character to a certain extent, as it rendered him physically fragile and thus required stringent discipline in order to overcome his weakness.\nBreakthrough in schizophrenia identifies importance of immune cells\nPsychopathology as methodology Jaspers underscored the contrast between an individual patient with their personal history, and the experience of complex states or conditions that are independent of individuals. Terminology Jaspers attempted to derive a specific psychopathological terminology by discussing three central problem areas: comparison of human beings and animals in order to define their similarities and dissimilarities; objectification and organization of the soul; and the interaction between the inner and outer worlds of the individual.\nPrejudices Jaspers listed several prejudices with which psychopathology can be confronted and which need clarification: The philosophical prejudice or misconception assumes that psychopathology employs merely deductive methods; that is, it derives conclusions from a hermetic set of preconceived theoretical ideas, whereas psychopathology, in fact, is based upon a pro-science pro-empirical outlook. Prerequisites After delineating possible routes to the required psychopathological vocabulary and discussing possible stumbling blocks to the project prejudices , Jaspers discussed the necessary prerequisites for successful engagement in psychopathology.\nConclusion For Jaspers, psychopathology consisted of methodology and methodological criticism. References 1. Google Scholar 2. Nervenarzt in press 4. Google Scholar 5. Google Scholar 6.\nCentenary of Karl Jaspers’s general psychopathology: implications for molecular psychiatry\nGoogle Scholar 9. Article PubMed Google Scholar Together, they attest to the rich diversity of Snyder's research while conveying the origins of modern psychopharmacologic practice. Would you like to tell us about a lower price? If you are a seller for this product, would you like to suggest updates through seller support? Read more Read less.\nReview An important aspect of the education and training of each generation of new scientists is understanding the history of a field. Read more. Tell the Publisher! I'd like to read this book on Kindle Don't have a Kindle? Share your thoughts with other customers.\n- Psychological and Brain Sciences: Indiana University Bloomington.\n- Program Goal?\n- The Electrical Engineering Handbook on CD-ROM;\n- The Shapes of Things: A Practical Guide to Differential Geometry and the Shape Derivative.\n- Science and Psychiatry: Groundbreaking Discoveries in Molecular Neuroscience | Psychiatric Services.\nWrite a customer review. Showing of 1 reviews.\nTop Reviews Most recent Top Reviews. There was a problem filtering reviews right now. Please try again later. Format: Hardcover Verified Purchase. The way to understand the present in science is to truly understand its history and its development.\nA Decade after The Decade of the Brain - Dana Foundation\nSee the review. Amazon Giveaway allows you to run promotional giveaways in order to create buzz, reward your audience, and attract new followers and customers. Learn more about Amazon Giveaway. Nexus: small worlds and the groundbreaking science of networks. Problem-based Behavioral Science and Psychiatry. The discoveries in crete. Recommend Documents. The Self in Neuroscience and Psychiatry The Self in Neuroscience and Psychiatry In recent years the clinical and cognitive sciences and neuroscience have cont Molecular Neuroscience Molecular Neuroscience P.\nClose Send. Remember me Forgot password?\nRelated Science and Psychiatry: Groundbreaking Discoveries in Molecluar Neuroscience\nCopyright 2019 - All Right Reserved"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:09c39732-3f39-4562-912a-0ba449716d70>"],"error":null}
{"question":"What physical changes can be observed in activated T lymphocytes compared to resting cells?","answer":"Activated T lymphocytes show several physical changes: their cell volume increases onefold after 24 hours of activation, they develop more obvious and abundant cellular pseudopodia and lamellipodia-like protrusions, and they form nano-concaves or membrane pores on their surface. In contrast, resting T lymphocytes maintain membrane integrity without these features.","context":["Membrane Surface Nanostructures and Adhesion Property of T Lymphocytes Exploited by AFM\n© to the authors 2009\nReceived: 29 March 2009\nAccepted: 5 May 2009\nPublished: 5 June 2009\nThe activation of T lymphocytes plays a very important role in T-cell-mediated immune response. Though there are many related literatures, the changes of membrane surface nanostructures and adhesion property of T lymphocytes at different activation stages have not been reported yet. However, these investigations will help us further understand the biophysical and immunologic function of T lymphocytes in the context of activation. In the present study, the membrane architectures of peripheral blood T lymphocytes were obtained by AFM, and adhesion force of the cell membrane were measured by acquiring force–distance curves. The results indicated that the cell volume increased with the increases of activation time, whereas membrane surface adhesion force decreased, even though the local stiffness for resting and activated cells is similar. The results provided complementary and important data to further understand the variation of biophysical properties of T lymphocytes in the context of in vitro activation.\nKeywordsT lymphocytes Cell activation Membrane nanostructures Adhesion force\nHuman peripheral blood T lymphocytes play a key role in human adaptive immunity. Though the activation process of T lymphocytes in vivo or in vitro has been well-studied immunologically and biochemically, however, whether the membrane surface nanostructures and adhesion property change in the process of T lymphocyte activation in vitro is largely unknown yet. However, the characterization of the nano-mechanical changes in the process of T lymphocytes activation in vitro has been hampered by the lack of sensitive quantitative techniques . Atomic force microscopy (AFM)  is a powerful nano-technology tool that has been applied to observe DNA micropatterns on the polycarbonate surface , to fabricate the nanostructure materials , and to measure the adhesion force, elasticity and stiffness of sample [5–9]. The ultra-high force sensitivity of AFM and its ability to measure properties of individual cell makes the technique particularly appropriate for measuring viscoelastic changes of cell membrane. However, up to now, there are only a few reports of AFM application on T-cell-related studying. Franco-Obregón et al.  reported on the application of AFM to measure distinct ion channel classes on the outer nuclear envelope of human Jurkat T cell, and to determine the density of pore proteins. Wojcikiewicz et al. studied the interaction of leukocyte function-associated antigen-1 (LFA-1), expressed on Jurkat T cells, with intercellular adhesion molecules-1 and -2 using AFM, and the interaction between individual pairs of living T lymphocytes and endothelial cells [1, 11–13]. The studies on biophysical properties (topography, nanostructures, adhesion force, stiffness, and others) of cells will provide fundamental insights into cellular structures and biology functions . However, the variation of membrane surface nanostructures and nano-mechanical property of T lymphocytes in the context of in vitro activation remains unclear.\nIn the present work, we reported on the application of AFM to characterize the topography and to measure the membrane adhesion force in the process of human peripheral blood T lymphocytes upon in vitro activation. Firstly, we evaluated the effect of fixative (glutaraldehyde) and cell isolation process on the adhesion force of cell membrane, indicating the fixative resulted in the increases of adhesion force of cell membrane, whereas cell isolation process decreased the adhesion force. Then, we found that the adhesion force of lymphocytes decreased with the increasing of the activation time. Our results provide complementary and important data for further interpreting the activation time-dependent variation of membrane surface nanostructures and nano-mechanics, which may be helpful in investigating the membrane function of T lymphocytes at the nanoscale resolution.\nMaterials and Methods\nT Lymphocyte Isolation and Preparation\nPeripheral venous blood was drawn from healthy, drug-free adult donors and mixed with an anticoagulant (heparin) immediately. The isolation of T lymphocytes was conducted according to the RosetteSep Procedure: (1) 100 μL of RosetteSep®human CD3+T lymphocyte enrichment cocktail was fully mixed with 2 mL of whole blood, and incubated for 20 min at room temperature; (2) diluted with 2 mL of PBS containing 2% bovine serum albumin (BSA) gently; (3) layered the diluted solution on the top of 3 mL density medium (Ficoll), then centrifuged at 1200g for 20 min; (4) remove the enriched cells from the density medium:blood plasma interface, and washed the enriched cells with 2% PBS (centrifuged at 425g for 10 min) (repeated once). The isolated T lymphocytes (1.44 × 106) were cultured with culture medium RPMI 1640 for the next experiments.\nTo understand the effects of glutaraldehyde fixative on adhesion force, we firstly performed two groups that included unfixed cells and fixed cells respectively (which did not incubate in culture medium), and the group of fixed cells was set as control I. However, because fixative could stabilize cell membrane, glutaraldehyde was still used in the following experiments to acquire the repeatable images and force–distance curves. To estimate the effects of isolation process on cells, we measured the adhesion force of cells that incubated in culture medium for 24 h (no stimulation), and the acquired data were set as control II. Then, three testing (activation) groups, which were stimulated with phorbol dibutyrate (PDB, 1 × 10−7 mol/mL; Calbiochem Co.) plus ionomycin (ION, 0.5 μg/mL; Sigma) for 6, 24, and 48 h were performed. Cells were fixed by 2.5% glutaraldehyde (Sigma) in buffer solution for 10 min and air dried before AFM measurements. The prepared samples were measured immediately by AFM.\nAtomic force microscopy (Autoprobe CP Research, Veeco, USA) was performed using a commercial AFM, which was performed in the contact mode or the tapping mode in air (room temperature, humidity: 75%). The glass substrate carrying cells was mounted onto the XY stage of the AFM and the integral video camera was used to locate the cells. The curvature radius of the silicon tip is less than 10 nm, scan rate is 0.3–1 Hz.\nThe contact mode was for measuring adhesion force (f, pN) cell membrane. Over ten thousands force curves were acquired, each curve representing the mean value of 15 times automatic measurements by the instrument. The tapping mode was for topographical analysis. The acquired images were reproducible during repeated scanning. More than 20 cells were investigated by the same two AFM probes (the tapping-mode probe for imaging and the contact-mode probe for force acquisition) for statistic analysis. And the adhesion force measurement of all samples was carried out with the same contact mode probe in air at room temperature.\nData Processing and Statistics\nThe acquired images (256 × 256 pixels) were only processed with the instrument-equipped software (Image Processing Software Version 2.1, IP 2.1) to eliminate low-frequency background noise in the scanning direction or to level the images (flatten order: 0–2). The data were reported as mean ± SD, and data analysis was conducted using Origin 6.0 software. The cell stiffness was qualitatively analyzed according to reported methods [7, 8, 15].\nTopographical Changes of T Lymphocytes in Activation\nFigure 1d–h indicates topographies and nanostructures of activated T lymphocytes, and the lamellipodia-like protrusion that is found to have a height of about 310 nm (profile 1k) is shown by white dotted line in Fig. 1d and the black arrow in Fig. 1e. Figure 1g is an enlarged view (error-signal mode) of the square frame in Fig. 1f, and cellular pseudopodia are shown by black arrows. Figure 1h displays a representative nanostructural image of membrane surface, displaying a large number of concaves or membrane pores, whose average size is 40.73 ± 10.95 nm in diameter; and the largest concave is about 200 nm in diameter and 62 nm in depth, as shown in height profile Fig. 1l. Figure 1j presents a height profile generated along the black broken line in Fig. 1d, showing the size of cell is 5.469 μm in diameter and 2.34 μm in height.\nAdhesion Force Changes of T Lymphocytes in Activation\nOn the other hand, AFM observation exhibits that the topography of T lymphocytes could be easily affected by the isolation processes (such as centrifugation, washing with PBS). Therefore, to evaluate how the isolation process alters the adhesion property of cell membrane, the difference of adhesion force between control I (non-incubated) and control II (incubated) (Fig. 3b, c) were then analyzed. The results clearly indicated that the adhesion force increased from 618 ± 207.28 pN (control I group) to 1025 ± 399.84 pN (control II group) (Fig. 3h), implying isolation processes lowered the membrane surface adhesion force.\nFigure 3d, e, and f presents representative force–distance curves of T lymphocytes that were stimulated with PDB plus ION for 6, 24 and 48 h, respectively. The statistical analysis (Fig. 3h) suggests that the adhesion force of cell membrane decreased with the increases of stimulation time.\nAFM is not only a surface imaging technique, but also a sensitive force spectrometer. It has emerged as a powerful tool to measure the changes of mechanical property of cell membrane [5, 6, 8, 16–19], cell stiffness [8, 17], cell viscoelasticity [20, 21], and to measure the interaction between cells , by which one could get some valuable information about the biophysical changes of the activated lymphocytes. AFM-based force spectroscopy is also particularly well suited for research in cell adhesion , and can stretch cells thereby allowing measurement of their rheological properties .\nAFM observation indicates that cellular topography changed after PDB plus ION treatment for 24 h (Fig. 2), for example, the cell volume increased due to the cell activation. Cellular pseudopodia and lamellipodia-like protrusion of activated cells become more obvious and abundant, and the nanostructures of nano-concaves or membrane pores formed on the membrane surface of activated cell are readily seen (Fig. 1h); however, the cell membrane of resting T lymphocytes maintains integrity (Fig. 1c). The topographical and nanostructural changes (such as formation of membrane concaves/pores) might correlate with cytoskeleton rearrangement and/or more mass exchange of activated T cells than resting T cells.\nFurthermore, the comparison of adhesion force between fixed cells and unfixed cells reveals that fixative can result in the increases of adhesion force of cell membrane, which is in accordance with the previous literature result . On the other hand, the isolation process also affects the mechanical properties of T lymphocytes, inducing the decreases of the adhesion property of cell membrane. This result implies that the isolation process may affect the membrane biological function of T lymphocytes. Furthermore, as for testing groups, the measured adhesion force is clearly smaller than that of both control I and control II groups; after stimulated by PDB plus ION, the adhesion force decreases with the increases of stimulation time (Fig. 3h), and reaches the lowest at the stimulation time of 24 h, whereas the cell stiffness does not change obviously according to the qualitative analysis of approaching branch of force–distance curves.\nThe human immune system mainly includes cell-mediated immune system and humoral immune system. T lymphocytes play a key role in cell-mediated immune response, and the activation investigation of T lymphocytes in vitro can help researchers interpret the function of the whole immune system. Because the activation process of T cells is a key stage in T-cell mediated immune response, the investigation of biophysical changes of T cells could lead to further understanding of the mechanism of immune response. Phorbol dibutyrate (PDB), an effective T cell mitogen and an activator of protein kinase C (PKC), can enter cells and activate T lymphocytes. Ionomycin (ION) is a Ca2+ ionophore and used in research to raise the intracellular level of Ca2+ and in research on Ca2+ transport across biological membranes (http://en.wikipedia.org/wiki/Ionomycin). Therefore, PDB plus ION can play the role of the “two-signal” of T cell activation. In the process of activation and proliferation of T lymphocytes, the variation of both cellular topography and membrane biophysical properties might correlate with the changes of biological function of T lymphocytes, such as the phosphorylation of signaling molecules, changes of cell polarity, and Ca2+ release [23–26]. Moreover, both PDB and ION are strong pharmaceutical reagents that can quickly upregulate CD69 expression as early as 4 h after stimulation , and following the expression of CD25 and CD71, therefore, the expression of these activation markers and the mitosis of cells might altogether contribute to the changes of cellular topography and the decreases of membrane adhesion force. In this work, the measurement results are useful to further understand the relationship between cellular topography or membrane mechanical property and the function of T lymphocytes in immune response, which provide the complementary data on studying T cell in vitro activation.\nIn the present work, the characterization of cellular topography and measurement of membrane adhesion force in the process of activation and proliferation of T lymphocytes are reported. After stimulated with PDB plus ION for 24 h, the cell volume of T lymphocytes increased onefold; the adhesion force, however, decreased approximately to one-fifth control II. As the activation time increased (6, 24, and 48 h), the adhesion force of lymphocytes decreased, and it was the smallest at the 24 h stimulation time, but the cell stiffness does not alter obviously. The variation in membrane nanostructures adhesion force between resting cells and activated cells might closely correlate with the stimulus-induced changes in immunologic function of T lymphocytes. Taken together, this investigation provides complementary and important data to further interpret the relationship between immune function and the biophysical properties of T lymphocytes.\nThis work was supported by the general project of NSFC (No. 60578025 and No. 30540420311) (J. C.), the general project of NSFC (No. 30572199) and the major project of NSFC (No. 30230350) (X. H.).\n- Zhang X, Wojcikiewicz EP, Moy VT: Exp. Biol. Med.. 2006, 231: 1306.\n- Binnig G, Quate CF, Gerber C: Phys. Rev. Lett.. 1986, 56: 930. Bibcode number [1986PhRvL..56..930B] Bibcode number [1986PhRvL..56..930B] 10.1103/PhysRevLett.56.930View Article\n- Wang Z, Li RX: Nanoscale Res. Lett.. 2007, 2: 69. COI number [1:CAS:528:DC%2BD2sXktVartrc%3D] 10.1007/s11671-006-9032-6View Article\n- Jian SR, Juang JY: Nanoscale Res. Lett.. 2008, 3: 249. ; COI number [1:CAS:528:DC%2BD1cXhsVyhtrzJ]; Bibcode number [2008NRL.....3..249J] 10.1007/s11671-008-9144-2View Article\n- Butt HJ, Cappella B, Kappl M: Surf. Sci. Rep.. 2005, 59: 1. ; COI number [1:CAS:528:DC%2BD2MXht1ahsrrK]; Bibcode number [2005SurSR..59....1B] 10.1016/j.surfrep.2005.08.003View Article\n- Waar K, van der Mei HC, Harmsen HJM, de Vries J, Atema-Smit J, Degener JE, Busscher HJ: Microbiology-Sgm. 2005, 151: 2459. COI number [1:CAS:528:DC%2BD2MXmvV2ls74%3D] 10.1099/mic.0.27877-0View Article\n- Cross SE, Jin YS, Rao J, Gimzewski JK: Nat. Nanotechnol.. 2007, 2: 780. ; COI number [1:CAS:528:DC%2BD2sXhtlyktL7L]; Bibcode number [2007NatNa...2..780C] 10.1038/nnano.2007.388View Article\n- Lam WA, Rosenbluth MJ, Fletcher DA: Blood. 2007, 109: 3505. COI number [1:CAS:528:DC%2BD2sXksFWhs74%3D] 10.1182/blood-2006-08-043570View Article\n- Parot P, Dufrene YF, Hinterdorfer P, Le Grimellec C, Navajas D, Pellequer JL, Scheuring S: J. Mol. Recognit.. 2007, 20: 418. COI number [1:CAS:528:DC%2BD1cXhsFOkt78%3D] 10.1002/jmr.857View Article\n- Franco-Obregon A, Wang HW, Clapham DE: Biophys. J.. 2000, 79: 202. COI number [1:CAS:528:DC%2BD3cXks1Klu7o%3D] 10.1016/S0006-3495(00)76284-9View Article\n- Wojcikiewicz EP, Abdulreda MH, Zhang X, Moy VT: Biomacromolecules. 2006, 7: 3188. COI number [1:CAS:528:DC%2BD28XhtVajt7zO] 10.1021/bm060559cView Article\n- Zhang X, Chen A, De Leon D, Li H, Noiri E, Elitok S, Moy VT, Goligorsky MS: J. Am. Soc. Nephrol.. 2003, 14: 46. 10.1097/01.ASN.0000037401.02391.76View Article\n- Zhang X, Wojcikiewicz E, Moy VT: Biophys. J.. 2002, 83: 2270. ; COI number [1:CAS:528:DC%2BD38XnslSrt7s%3D]; Bibcode number [2002BpJ....83.2270Z] 10.1016/S0006-3495(02)73987-8View Article\n- Heinz WF, Hoh JH: Trends Biotechnol.. 1999, 17: 143. COI number [1:CAS:528:DyaK1MXlt1KjtLo%3D] 10.1016/S0167-7799(99)01304-9View Article\n- Strasser S, Zink A, Kada G, Hinterdorfer P, Peschel O, Heckl WM, Nerlich AG, Thalhammer S: Forensic Sci. Int.. 2007, 170: 8. 10.1016/j.forsciint.2006.08.023View Article\n- Bowen WR, Lovitt RW, Wright CJ: J. Colloid Interface Sci.. 2001, 237: 54. COI number [1:CAS:528:DC%2BD3MXjtFeqsr8%3D] 10.1006/jcis.2001.7437View Article\n- Canetta E, Duperray A, Leyrat A, Verdier C: Biorheology. 2005, 42: 321.\n- Lulevich V, Zink T, Chen HY, Liu FT, Liu GY: Langmuir. 2006, 22: 8151. COI number [1:CAS:528:DC%2BD28XmvFWhtro%3D] 10.1021/la060561pView Article\n- Wojcikiewicz EP, Zhang X, Chen A, Moy VT: J. Cell Sci.. 2003, 116: 2531. COI number [1:CAS:528:DC%2BD3sXltFemtr0%3D] 10.1242/jcs.00465View Article\n- Fritzsche W: Microsc. Res. Tech.. 1999, 44: 357. COI number [1:STN:280:DyaK1M7ovVGqtQ%3D%3D] 10.1002/(SICI)1097-0029(19990301)44:5<357::AID-JEMT7>3.0.CO;2-UView Article\n- Fritzsche W, Henderson E: Ultramicroscopy. 1997, 69: 191. COI number [1:CAS:528:DyaK2sXmvFWmtbk%3D] 10.1016/S0304-3991(97)00043-0View Article\n- Burks GA, Velegol SB, Paramonova E, Lindenmuth BE, Feick JD, Logan BE: Langmuir. 2003, 19: 2366. COI number [1:CAS:528:DC%2BD3sXnsVKisA%3D%3D] 10.1021/la026375aView Article\n- Burkhardt JK, Carrizosa E, Shaffer MH: Annu. Rev. Immunol.. 2008, 26: 233. COI number [1:CAS:528:DC%2BD1cXltlWksbo%3D] 10.1146/annurev.immunol.26.021607.090347View Article\n- Dadsetan S, Zakharova L, Molinski TF, Fomina AF: J. Biol. Chem.. 2008, 283: 12512. COI number [1:CAS:528:DC%2BD1cXltVyqsLc%3D] 10.1074/jbc.M709330200View Article\n- Feske S: Nat. Rev. Immunol.. 2007, 7: 690. COI number [1:CAS:528:DC%2BD2sXpsV2qtLc%3D] 10.1038/nri2152View Article\n- Negulescu PA, Krasieva TB, Khan A, Kerschbaum HH, Cahalan MD: Immunity. 1996, 4: 421. COI number [1:CAS:528:DyaK28Xjt1GhtL4%3D] 10.1016/S1074-7613(00)80409-4View Article\n- Xu L, Liu Y, He X: Cell. Mol. Immunol.. 2005, 2: 295."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:f714fde7-ffb3-46f3-94f7-1a198bb846af>"],"error":null}
{"question":"How do ceramic tiles compare to marble when it comes to their durability and maintenance requirements in kitchen settings?","answer":"Ceramic tiles and marble have distinct characteristics in terms of durability and maintenance. Ceramic tiles are highly durable and perfect for use in all types of rooms, including kitchens. They are very easy to clean and maintain. However, marble, while elegant, can scratch, chip, and stain, even when sealed. Marble is relatively heat resistant and excellent for baking as it stays cool, but it requires more maintenance than ceramic tiles. Marble needs regular sealing and can stain even if sealed, while ceramic tiles, especially glazed varieties, are more resistant to stains and moisture damage.","context":["Tiles are unit area skinny objects, typically are in square or rectangular form. A tile may be a factory-made piece of hard-wearing materials like ceramic, stone, metal, baked clay, glass. They are typically used for covering roofs, floors, walls, or alternative objects like tabletops. Tiles are also made up of lightweight material like perlite, wood, and mineral wool which can be used in wall and ceiling purposes.\nTYPES OF TILES BASED ON MATERIALS AND WORKMANSHIP\nTYPES OF TILES BASED ON ITS APPLICATION\nLARGEST TILES COMPANY IN INDIA\nTYPES OF TILES BASED ON MATERIALS AND WORKMANSHIP\n1. Ceramic Tile\nCeramic tile is a common type of tile that is mostly found in homes. Since this type of tile is highly durable hence is perfect for use in all types of rooms in the house like kitchens, bathrooms, and entryways. It is very easy to install, to clean, and is available in a variety of styles that can be fitted in any design. The price of this type of tiles is not that high and comes within the budget.\n2. Porcelain Tile\nPorcelain tile is another most common type of tile which is different from ceramic tile. This type of tile emulates natural stone, brick, and wood without any maintenance. It has availability in a range of designs, colors, and styles. Since this type of tiles does not freeze, fade, or crack it can be used even outdoors. Porcelain tiles can also be used in the bath or kitchen tiles, high traffic areas, and even in kitchen backsplashes. One of the biggest drawbacks of porcelain tile is that the installation is somewhat tricky.\n3. Glass Tile\nThe glass tile is having stain resistance property which makes it an alternative to natural stone. With the help of this tile red wine and acidic foods like lemon and vinegar can be wiped up without leaving any permanent stains. As glass tiles are chip along the edges hence are not recommended for use in high traffic areas like kitchen and bathroom floors. But are used in less traction such as tabletops or desks, around the fireplace, or as the backsplash.\n4. Cement Tile\nCement tile has been used extensively for decades and currently used widely in modern interior design. Cement tiles are very versatile and hence provides a wide range of colors and patterns. Since these types of tiles are highly porous, a patina develops over time in order to enhance the pattern. Cement tiles are also sanded and resealed like wood floors as they get discolored over time. The biggest drawback of cement tile is they are beast to lay. In addition, cement must be resealed once a month so as to maintain its beauty. This type of tile is best for use in low -traffic areas and that too in small quantities.\n5. Marble Tile\nDespite marble tile being costly they are used for adding elegance and refinement to any room. If you are looking to add beauty to your kitchen or bath, marble tile is the best option. It is also responsible for adding texture and depth. Like the other tiles, marble tiles are also susceptible to scratches and stains and are also difficult to clean.\n6. Mosaic Tile\nMosaic tile is widely used for unique and creative interior designs as it is available in a variety of shapes, sizes, colors, styles, and materials. When an accent is needed mosaic tiles are extensively used in-wall applications.\n7. Granite Tile\nGranite is a natural stone having similarity in appearance and feel to marble but still, there are some notable differences. Granite tile is extensively used due to its availability at a lower price. These tiles are used in a laundry room and other spaces where we need performance but in lower cost\n8. Limestone tile\nLimestone is one of the other types of natural stone tile. This type of tile delivers a natural appearance which is required for ancient architecture and design. Due to their high durability and softness, these are also easy to shape and cut down for some of the specific patterns and placements.\n9. Travertine tile\nSimilar to limestone travertine tile offers a natural kind of aesthetic. Since it is easily affected by water, stains, and traction hence this tile requires extra maintenance and also resealing once in a decade. It is highly recommended to use such tiles in low traffic areas of the home. Designers used to apply these tiles on walls despite floors so as to avoid scratches, etching, or stains.\n10. Quarry Tile\nQuarry tiles are made up of ground materials that are similar to but technically stronger than brick. Ground materials include feldspar, clay, and shale which are 1st grounded together and then are baked at above 2000 degrees. As these types of tiles are fired at a very high temperature, they are dense, nonporous, water-resistant, and also have a lower water absorption rate. They also do not require to be sealed.\n11. Metal Tile\nMetal Tiles used to offer very high durability and a modern kitchen aesthetic. But one of the drawbacks is that as soon as it is installed it gets scratched. As these tiles help in overall softening hence some people prefer this naturally occurring patina. If that is not one of the priority then the metal tile is not always our preference. Metal tiles can be used greatly on work surfaces such as kitchen, bar, or utility room but are not recommended for baths or outdoor use.\n12. Resin Tile\nResin Tiles are one of the great solutions to combine styles. These tiles have an attractive appearance and are water-resistant. It is easier to make a 3D patterns from these tiles which can imitate the look of water and stones. The drawback of this tile is that it gets yellow over time particularly when exposed to the sun. Such tiles are highly recommended for water areas like bathrooms and mudrooms.\nTYPES OF TILES BASED ON ITS APPLICATION\n1. Brick Tile\nBrick tiles that are called brick slips or brick veneers are sort of a skinny silvered regular brick used as a ceramic tile. They are blocks in rectangular shape made up of clay, calcium silicate, or concrete. Bricklaying has been used for decades and bricks are more preferred than stone as a stone being more expensive when used in construction.\n2. Wall Tile\nWall tile is ceramic, porcelain, stone, or glass tile which will be put in on the wall. It is a mosaic, commonplace size tile, or giant format tile. Wall tile will have texture, patterns, or 3D style that adds interest to backsplashes, shower walls, or feature wall.\n3. Floor Tile\nEven though ground tile notions typically recalled for adornment reasons, they really are useful in activities that aim in guarding the flooring covering every single region of your home or construction. The setup of these tiles needs to be accomplished by excess care so as to steer away from possibilities of breakage which can lead to wastage of time and cash within the space.\n4. Partition Tile\nPartition tiles are hollow or solid building blocks that are fabricated from gypsum and are used in a nonbearing partition which used to serve as a base for plastering.\nLARGEST TILES COMPANY IN INDIA\n1. Kajaria Ceramics Ltd\nThe Headquarter of this company is in Delhi, the brand is famous for its valued ceramic and floor tiles as well as polished and glazed glassy tiles. It is the biggest within the list of prime ten tiles companies in the Republic of India 2020. The corporate was established in the year 1985. The leading tiles company is distributed across 9 plants Sikandrabad in Uttar Pradesh, 5 plants in Gujarat, 1 at Vijayawada in Andhra Pradesh, Jaipur & Malutana in Rajasthan.\nThe Company showcases its tiles pan-India, through its in-depth and entrenched dealer network, providing customers with the widest selection of tiles across all value points. It’s the biggest tiles company in the Republic of India by Total Sales.\n2. Somany Ceramic Ltd\nThe company was established within the year 1969. it’s the producing facility in Kadi, Kassar, and different venture plants. The corporate is unfold across the center East, Russia, Africa, India, and the UK. The leading tiles company is giving an entire vary of merchandise together with vitreous Tiles, Digital Tiles, Ceramic Wall & Floor, Glazed vitreous Tiles, bathtub Fittings, and Sanitaryware. The company has its plants in Kadi (Gujarat) and Kassar (Haryana), Republic of India, and different venture plants, generating a complete production c of sixty million sq. meters annually. It’s the second-largest tiles company in the Republic of India.\n3. HSIL Ltd\nIt was established in 1960 as Hindustan Twyfords Ltd, with a technical collaboration with Twyfords Great Britain, to introduce vitreous china sanitaryware in India. The company after that was renamed as HSIL limited in 20009. HSIL is one of the most effective brands of tile in Bharat as a way of sturdiness worries. The corporate is the most revered and leading producer within the sanitaryware section in India.\n4. Johnson Tiles\nThe company was established within the year 1901 as a separate entity of Prism. It has around 10 producing plants unfold across Asian countries and over a thousand dealers. It has forty-nine branches and twenty-eight “House of Johnson” showrooms.\n5. Grindwell Nortan Ltd\nGrindwell Norton (GNO), a corporation listed in Bombay and National Stock Exchanges, pioneered the manufacture of grinding wheels in the Asian nation in 1941. It is the third best tiles company in the Asian nation by total sales.\n6. Asian Granito India Ltd\nAsian Granito is one of the most important makers of Ceramic tiles, shiny tiles, outside tiles, designed Marble and Quartz stone in the Asian countries.\nHeadquartered in Ahmedabad, Gujarat, India. It’s one amongst the highest ten tiles firms in the Asian countries. It’s among the highest ceramic firms in Asian countries. Established within the year 1995, the AGL has emerged as one of the most important ceramic firms in Asian countries during a short span of twenty-six years. It’s India’s quickest growing Ceramic Wall & Floor Tile, Glazed shiny Tiles, Polished shiny Tiles, Composite Marble and Quartz Company and among the world’s fifty most profitable Ceramic tile firms.\n7. Cera Ceramics Tiles Ltd\nCera Sanitaryware Limited was incorporated within the year 1980 to supply customers with an entire creator and designer results. Headquartered in Ahmedabad, the corporate manufactures floor and wall tiles, sanitaryware, faucets, wellness, room sinks, mirrors, and private care. It’s among the highest tiles company in India. Currently, It is having seventy-five showrooms and quite 4000 dealers and sub-dealers. Being a pioneer in transportation and for having the most recent technology, the corporate has fastened high standards. It produces embrace glassy tiles, ceramic floor tiles, glazed glassy tiles, digital wall tiles, composite marble tiles, and quartz marble tiles.\n8. Orient Bell\nFounded in 1977, Orientbell is one of the leading Indian tile brands producing a variety of titles covering a large range of applications. The company has quite 2500 retailers unfold across the country with nine flagship stores referred to as Orientbell Tile Boutiques. Its production capability is getting ready to thirty million sq. meters.\n9. Nitco Limited\nNitco Limited is one of the oldest tile producing corporations in the Asian nation that was established within the year 1953 by Pran Nath Talwar. The Company is headquartered in Mumbai, India. Pan India, it is having twenty-two offices. It’s one of the most effective tiles makers in the Asian nations.\nThe company used to produce Ceramic tiles, glazed tiles, Gres ceramic ware tiles, HD digital tiles, Base tiles, Highlighters, Natural and designed marbles.\n10. Simpolo Tiles\nSimpolo ceramics is Morbi, Gujarat primarily based company supported in 1977, It has received the “Bhartiya Udhyog Ratna” award from Minister of State for Shipping, Govt. of India. This company is having its excellent presence not only in India but also in the international market like Taiwan, Latin America USA, UK, Kenya, Nigeria, Mauritius, Sri Lanka, Singapore and Turkey.\nHence Tiles are squared measure, a style of furnishing that may be used on interior walls, ceilings and floors. Tiles are made up of both soft and hard materials. Examples of hard tiles are marble, clay, slate, metal, ceramic, stone, or glass. Generally, soft tiles are made up of wool, cork, recycled paper, and perlite. Tiles are used as both functional and decorative environments and are available in a range of styles which used to suit all budgets and tastes.","Choosing your kitchen countertop is one the more fun and exciting choices that you’ll make for your new home. Choices should be made based on the material’s appearance, durability, maintenance and price. This week we’ll cover the most common types of materials used for kitchen, and bathroom, countertops, including laminate, ceramic and porcelain tiles, solid surface options, like Corian, butcher block, stainless steel, concrete, soapstone, marble, granite, quartzite and quartz. There’s a difference between quartzite and quartz, you know? We’ll talk about all of those options in just a moment. But let’s begin with this week’s pro term: Edge Return.\nAn edge return is a countertop edge that’s several inches long (from top to bottom) that gives the appearance of a thicker slab. You know those countertops that look like they’re 3 or 4 inches thick? Well, more than likely, those thick-looking countertops are made with an edge return.\nMost stone countertops are about 3 centimeters thick, which translates to about 1 1/4 inches. If you want the more dramatic, luxurious look of a countertop that’s several inches thick, request an edge return.\nWith an edge return, a thin slice of stone, measuring several inches from top to bottom, will be attached to the edge of your slab. When the countertop is set in place, it’ll have the look, but the price, of a thick countertop.\nNow, let’s get into this week mini lesson.\nAlthough there are actually more options for kitchen and bathroom countertops than we’ll cover today, we’ll go over the 11 most common choices. Starting with …\nFor those on a tighter budget, laminate countertops are still a popular option. Today’s laminate doesn't look like the inexpensive, harvest gold countertops that we had in the 70’s and 80’s. Today’s laminate is much more sophisticated. Laminate comes in many colors and patterns, including designs that mimic stone and butcher block.\nLaminate is made of a particle board core that’s covered with a blend of paper and resin. The main advantage of laminate is price. It ranges from $10-$40 per linear foot, installed. It’s also easy to clean and maintain.\nDisadvantages of laminate are that it can be scratched and burned. And wear and tear and exposure to moisture can cause the layers of the laminate to peel. It’s susceptibility to moisture damage also means that laminate countertops cannot be used with undermount sinks. Finally, if the laminate does get damaged, there is no easy way to repair it. In most cases, you’ll have to live with the imperfections or completely replace the countertop.\n2. CERAMIC & PORCELAIN TILES\nCeramic and porcelain tile are made of clay or other naturally occurring materials. Porcelain tile is a version of ceramic tile that is denser, less porous and more expensive than ceramic tile. Ceramic and porcelain tile, like laminate, come in a variety of colors. Tiles are also available in a wide range of sizes, textures, and finishes.\nStarting at less than $10 per linear square foot installed, it too can be a budget friendly choice. But prices can go up to as much as $80 a square foot, for some styles.\nDo-it-yourselfers can save significantly by installing their own tile countertop. Tile is probably the best countertop option for DIYers. You can purchase basic tile for less than $2 per square foot.\nMost tile is heat and scratch resistant, but countertops can be difficult to keep clean, mainly because of the grout lines. Unsealed grout can stain and is prone to moisture damage and bacterial growth. All grout wears over time and it will need to be renewed or replaced periodically.\nMany varieties of tile are glazed, so they are resistant to stains and moisture. But be careful of unglazed varieties which can easily stain and be damaged by standing water. For the lowest maintenance tile countertop, choose glazed tile with darker grout and have your grout sealed.\nAnother disadvantage of tile countertops is their uneven surface, which makes some kitchen tasks, like rolling out dough, challenging.\nTile can break, crack and chip. The good news is, individual tiles can be replaced fairly easily if damaged. So, if you decide to go with tile countertops, or tile flooring, for that matter, buy a few extra tiles so you have them on hand in case you need to replace a damaged tile in the future.\n3. SOLID SURFACES\nBest known by their brand names, Corian and Wilsonart, solid surface countertops are made of resins and mineral fillers. You can choose from many colors, including very bright, bold colors, and several patterns.\nAlthough solid surfaces can be scratched and nicked, those imperfections can be buffed out using a mildly abrasive pad. These surfaces are stain resistant, but can be discolored by high heat. The cost of solid surface countertops is $40 to $65 per linear foot, installed.\n4. BUTCHER BLOCK\nA variety of woods, including cherry, birch, and even mahogany can be used for a butcher block countertop. But maple is that’s the most popular choice.\nButcher block surfaces are made of strips of solid wood glued together. They're susceptible to stains, scratches, dents, and burns. Many people like the look of worn wood that occurs over time with a butcher block countertop. But if you don’t, sanding and resealing the wood can make the countertop like almost new.\nButcher block counters are moderately priced, ranging from $35 to $100 per linear foot installed.\nMoisture and humidity can damage wood countertops, causing them to swell. So sealing the wood with beeswax, or natural waxes or oils, is essential. Most experts don’t recommend sealing butcher block countertops with conventional wood varnishes since most varnishes are not food safe.\n5. STAINLESS STEEL\nStainless steel countertops are commonly seen in commercial kitchens for good reason. They’re resistant to stains, heat and bacteria. For those reasons, some homeowners are now choosing stainless steel countertops for their homes— especially if they want a more industrial, contemporary-looking space.\nStainless steel countertops are custom made, so they’re more expensive than you might think at $65 to $125 per linear foot, installed.\nStainless steel shows fingerprints, so if that bothers you, you should either choose another material and be prepared to frequently wipe down your countertops. It can also dent and make loud clanging noises as pots, pans and heavy dishes are placed on countertops. Some chemicals can discolor stainless steel or cause a whitish etching effect.\nEdgy and unexpected, concrete countertops are next on our list. Like stainless steel, they give the kitchen an more industrial, contemporary look. But concrete countertops can be found in both modern and traditional kitchens.\nConcrete can be cast in unusual shapes and can be tinted with a variety of colors. Interesting items such as sea shells, glass and stones can be added to the poured concrete for a really unique countertop. Although concrete is durable, it is not as heat resistant as some other options.\nOver time, small cracks will naturally develop in concrete. And because it’s porous, concrete can stain, so it has to be regularly sealed. Extra support is needed for concrete countertops because they are so heavy.\nThe price is similar to stainless steel at $75 to $125 per square foot, installed.\nRemember those dark gray or black table tops that you had in high school or college science classes? That’s soapstone. And some homeowners are choosing that material for their kitchen countertops— mainly for its unique warmth.\nIt usually starts out light to medium grey, it darkens over time. Soapstone is relatively soft and can scratch, crack and nick more easily than other countertop options. To maintain soapstone, it needs to be polished with oil on a regular basis.\nSoapstone costs $70 to $100 per linear foot, installed.\nMarble is known for it’s timeless elegance. It can make virtually any kitchen feel more luxurious. Marble comes in a variety of colors and patterns. Although marble tiles can be used for a countertops, it’s much more common to see marble slab countertops.\nMarble is relatively resistant to heat and is an excellent surface for avid bakers because the surface stays relatively cool, allowing dough to hold together nicely.\nBut marble can scratch, chip and stain. In fact, some marble can stain even if it’s sealed.\nMarble ranges from $40 to over $100 per linear foot installed.\nGranite is one of the most popular countertops installed in new kitchens. Granite is a natural stone that’s quarried from the mountains of Italy, the United States, India, and several other countries worldwide. It comes in colors and patterns ranging from muted and subtle to bold and exotic. Granite can cost from $35 per linear foot, for builders’ grade varieties to over $175 per foot for exotic slabs.\nGranite is resistant to nicks, scratches and heat. Although granite is not as susceptible to staining as marble, it CAN stain, so sealing granite once or twice a year is a must.\nDid you know that some granite is dyed? And unfortunately, that dye can fade over time. Black or very dark granite are the varieties that are most often dyed. Always ask if dye has been added to the granite you’re considering. And if the answer is yes, it’s best to avoid those dyed slabs.\nQuartzite is a hard natural stone. It starts as pure quartz sandstone. Then, that sandstone is converted into quartzite through heat and pressure that naturally occurs under the earth’s surface.\nQuartzite is absolutely beautiful. If marble and granite had a baby, it would look like quartzite. It has the veining of marble, but the subtle mottling and strength of granite. In fact, quartzite is harder than granite so it’s resistant to scratches and nicks. Like other natural stones, quartzite can stain and must be sealed once or twice a year.\nQuarzite costs $60 to $100 per linear square foot installed.\nQuartz is a manmade material that is also called engineered stone or manufactured stone. It is made of about 93% crushed, natural quartz combined with pigment and resin. You might know quartz by the brand names Silestone, Ceasarstone or Cambria.\nI used to not be a fan of quartz because I hate what I called “fake marble and fake granite”— the quartz industry’s attempt to mimic natural stone. A few years ago, it looked really fake. But now, those mimics look extremely authentic.\nI talked to several quartz distributors at the International Builders Show last january and they all said that there have been big changes in the last few years that have allowed them to make the quartz look much more like authentic stone. I couldn’t believe how well the new versions of quartz mimic marble and granite. If you decided against quartz a few years ago because, like me, you \"hate the fake\", go take a look at the newest versions of quartz. I think you’ll be pleasantly surprised.\nAnd for those of you who want bold, brightly colored countertops, quartz comes in bright colors like blue and red.\nQuartz has much of the beauty of natural stone, but none of the maintenance. It resists scratches, bacterial growth, heat and stains and never needs to sealed.\nQuartz is about the same price as marble at $80 to over $100 per foot installed.\nLet me caution you: Quartz is a durable, beautiful countertop option, but it is NOT indestructible. Quartz is hard, but since it has some resins added to it, it’s not quite as hard as all natural quartzite.\nQuartz can chip, but not easily. And although it is resistant to stains and heat, its not completely stain and heat proof. I’ve read on a couple of forums that the quartz countertops got discolored when a very hot pot was placed on the quartz. I’ve also read that wet metal pans can leave rust stains on quartz. Sometimes the stains can be removed and sometimes not.\nJust remember that quartz might be more resilient than other materials, but that any countertop, including quartz, can be damaged under the right circumstances.\nWell, that’s it for this week. Hopefully that information will help you narrow down your choices for your kitchen countertop. If you’re going with natural stone, always go to the stone yard and choose the specific slabs that you want because the appearance of natural stone can vary considerably from slab to slab.\nIf you know someone who’s building a new house or remodeling a kitchen, please feel free to share this episode with them. Just look for the share icon if you are on your phone or tablet, or copy and paste the web address and email or text it.\nAlright, let’s see how you do on this week’s quiz.\n1. The main advantage of laminate is\nC. Moisture resistance\nD. It’s easily repaired\nThe answer is A, price is the main advantage of laminate. It’s $10-$40 per linear square foot, installed. Laminate is made with a particle board core covered with a paper-resin blend, so it’s not very durable or moisture resistant when compared to other options. And laminate is not easily repaired. If damage, you’ll have to live with the imperfections or replace the laminate.\n2. Which of the following is false?\nA. Quartzite is a natural quarried stone that starts as sandstone and changes to quartzite as a result of heat and pressure under the earth’s surface\nB. Quartz, also called engineered stone, is a manmade material made of about 93% crushed natural quartz plus pigments and resin\nC. Quartz is indestructible\nD. Quartzite is harder than quartz\nThe answer is C. Quartz is NOT indestructible. It IS very durable and resistant to heat, stains, chips and scratches. But like all countertop materials, quartz can be damaged under the right circumstances. You don’t have to baby a quartz countertop, but you shouldn’t abuse it either. The more careful you are with any countertop material, the longer it will last and the more beautiful it will remain as it ages.\nPlease remember that the purpose of this podcast is simply to educate and inform. It is not a substitute for professional advice. The information that you hear is based the only on the opinions, research and experiences of my guests and myself. That information might be incomplete and it’s subject to change, so it may not apply to your project. In addition, building codes and requirements vary from region to region, so always consult a professional about specific recommendations for your home.\nThank you for joining me this week. I hope you’ll come back for the next addition of Build Your House Yourself University (BYHYU)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:be1e013d-884b-497d-90c5-c8b086504c8c>","<urn:uuid:7d6c8085-36bd-4e5f-ada6-ef25d3a5bd86>"],"error":null}
{"question":"I'm a biology student curious about bees - how do they communicate food locations through dance, and what medical applications has honey shown in wound treatment?","answer":"Bees communicate food locations through different types of dances. For distances over 40 yards, they perform the waggle dance in a figure-8 pattern, where the angle of the dance relative to the sun indicates the food's direction, while the vibrations and circles indicate distance. For food sources within 40 yards, they use the round dance, consisting of circular loops that change direction periodically. As for honey's medical applications, it has proven effective in wound treatment through multiple mechanisms. When applied to wounds, it acts as a sealant keeping the wound moist, provides nutrition through its sugar content and other nutrients, and kills bacteria through its hyperosmotic properties and the production of hydrogen peroxide. Studies have shown honey's effectiveness against antibiotic-resistant bacteria, including MRSA. Clinical trials involving nearly 2000 participants have demonstrated positive results in wound care, particularly with Manuka honey, which has been cleared by the FDA for use in wounds and burns.","context":["As I write this our golden retriever is barking at a car turning around in the driveway. He’s letting me know that someone is here. I tell him “Good boy,… okay, that’s enough.” and pat his head. Still flustered and huffy, he obeys begrudgingly. He quiets down and lays in his bed, ears pricked and alert, he is still listening for further activity in his yard.\nI look at our golden retriever. A 95 pound animal that we’ve welcomed into our home, who sleeps in our bed, and who lives with us as if he was human. I talk to him as if he was one of my kids, and what’s interesting is that my 10 month old has only just begun to understand and respond to our spoken word. In many ways, our dog up until this point, understood more English than our daughter.\nLanguage in the animal world, is fascinating. I think we often view ourselves as the “great communicators” but I wonder if this is only because we are not fluent in the messages that other species are sending? Animals often speak in ways that are too subtle for human recognition. Take the honeybee for example; they speak in pheromones, body language and maybe the most interesting of all…dance.\nIn dance, bees are able to relay incredible messages. They can communicate, distance, food availability, and direction among other things.\nIn this post I’d like to talk about the three fascinating dances of the honey bee. The Waggle Dance, the Tremble Dance and the Round Dance.\nThe waggle dance is perhaps the most well known among beekeepers. The dance is done in a figure8 pattern. Where the bee waggles in a circle to the right, then when it gets back to the starting point, waggles in a circle to the left.\nBy using tiny tracking equipment, scientists have been able to study this dance and have learned that the Waggle communicates to other hive mates where there is a good place to find food. It’s believed that the dance communicates what direction the food is, and how far from the hive.\nScientists have discovered that an angle can be calculated using the direction of the figure 8 in relation to the sun. This angle points to the food source.\nIn addition, it’s said that the amount of vibrations and circles completed tell how far the food is.\nThe Waggle Dance is used when bees need to describe food sources farther distances from the hive, over 40 yards.\nSimilar to the Waggle Dance, the Round Dance is a circular dance used by forager bees to let other bees know where food is within closer distances to the hive, under 40 yards.\nThe Round Dace is circular, but does not display the figure 8 pattern. Instead it is made of tiny loops that change direction periodically. It’s not thought that this dance shows direction.\nA foraging bee will return with food, distribute food to it’s hive mates and perform this dance as if to say, “Here’s dinner, and this is where I got it.”\nThis dance can take up to 30 minutes to perform. The bee shakes as she moves in a line across the hive, turning her body 45 degrees every minute or so.\nThe tremble dance is used to communicate that more help is needed in receiving returning forager bees. Forager bees collect pollen and nectar and when they return to the hive, they pass on their “groceries” to receiver bees at the entrance of the hive. If more bees are needed to collect at the entrance, the Tremble Dance is performed and new bees will stop what they’re doing and help out.","- Category: GLG Medical Services\n- Published: 30 November 2007\n- Written by Eric Gagua\nThe recalcitrant nature and complexity of chronic wounds continue to challenge health practitioners in the field, with many of the standard treatment options often failing to provide good outcomes. Chronic wounds are often infected with bacteria resistant to antibiotics, compounding the problem. Some alternative biologic forms of treatment have been used and are gaining recognition; they include apitherapy (application of honey), maggots, and leeches. In addition to other wound-promoting actions, they all seem to show efficacy against bacteria, such as methicillin-resistant Staphylococcus aureus (MRSA).\nHoney -- A Topical Treatment for Wounds In recent years, there has been a resurgent interest in the use of honey in wound care. Honey, a plant nectar that is modified by the honey bee Apis mellifera, has been used as a treatment for wounds since antiquity, with records of its use dating back to the early Egyptians, Assyrians, Chinese, Greeks, and Romans.\nThere are several mechanisms through which honey is thought to act on and heal wounds. When it is applied directly on a wound surface or via a dressing, it can act as a sealant, keeping the wound moist and free from contamination. In addition, honey is comprised of glucose (35%), fructose (40%), sucrose (5%), and water (20%). This high sugar content plus vitamins, minerals, and amino acids) provides topical nutrition that is thought to promote healing and tissue growth. Honey is also a hyperosmotic agent that draws fluid from the wound bed and underlying circulation, which kills bacteria that cannot thrive in such an environment. It is bactericidal in other ways as well. During the process of honey production, worker bees add the enzyme glucose oxidase to the nectar. When honey is applied to the wound, this enzyme comes into contact with oxygen in the air, which leads to the production of the bactericide hydrogen peroxide. Macroscopically, honey has also shown debriding action.[1-3]\nManuka (Medihoney) is a medicinal honey with enhanced antibacterial properties derived from floral sources in Australia and New Zealand. In June and July 2007, Health Canada and the US Food and Drug Administration (FDA), respectively, cleared it as the first medicinal honey product for use in wounds and burns. Peter Molan, a New Zealand biochemist at the University of Waikato, has reported that it can stop bacterial growth even when diluted up to 56 times. He has conducted studies on this honey in rats and piglets that have suggested that it has anti-inflammatory properties and can stimulate epithelial growth, advancing closure of skin in these animals.\n\"In the last few years, a lot of good science has been done in the area,\" said Shona Blair, a microbiologist at the University of Sydney, Australia in an interview. She has tested various strains of honeys against bacterial strains obtained from hospitals and found that even the strains most resistant to antibiotics failed to grow in the presence of honey. Manuka honey may even be active against MRSA.[5,6]\nA review of the literature suggests positive results for honey in wound care, but more confirming evidence is needed. About 17 randomized controlled trials involving a total of 1965 participants have been published; 5 other types of clinical trials involving 97 participants treated with honey have also been reported in the literature. Furthermore there are about 16 trials of honey on a total of 533 wounds in animal models (which rule out a placebo effect). There are over 270 cases, of mostly chronic wounds cited in the literature that were treated with honey. Honey gave good results in all but 14 of these cases.[7,8]\nFor example, Dr. Jennifer Eddy, associate professor of family medicine at the University of Wisconsin, provided a case study of a patient with a severely gangrenous diabetic foot ulcer that was salvaged following honey treatment. Dr. Eddy is currently recruiting patients with diabetic foot ulcers for a study that will compare honey with hydrogel dressings that appear like honey, having been altered to resemble honey in terms of coloring and smell to maintain objectivity. Not all case studies have been positive, however.\nAn observational study at the University of Bonn, Germany, reported good healing rates in the use of honey as a dressing for wounds in 15 children with cancer, who are prone to weakened immunity and poor wound healing following radiation treatment and chemotherapy. While more studies are needed, the results seen in children looked promising, and study author Arne Simon, MD, says specialists should consider standardized honey when confronted with wounds that refuse to heal.\nAnother study is underway at the Red Cross War Memorial Children's Hospital in Cape Town, South Africa, comparing a standard treatment with honey-based antibacterial wound gel product in approximately 80 children with burns.\nManuka honey has used in Iraq where it produced good results at a makeshift clinic in the treatment of children with burns set up by US armed forces. Honey is an ideal affordable first aid dressing material, especially for emergent situations where standard medications and equipment are not readily available, such as war-torn or earthquake-stricken regions. It is suitable for treatment of burns, where emergency cooling with contaminated water can lead to infection.\nMaggots have been used for centuries to help heal wounds, especially by military surgeons who noted that soldiers whose wounds became infested with maggots healed better. The beneficial effects of therapeutic maggots were first observed during the Napoleonic war by a surgeon who noted that soldiers whose wounds had become infested had an improved prognosis. When novel surgical techniques and antibiotics were discovered during WWII, maggot debridement therapy (MDT) moved into the background.\nMedicinal maggots (sterilized larvae of the green bottle fly Lucilia sericata that do not reproduce nor feed on live tissue) work as biochemical debriding agents. They ingest bacteria and degrade them in their intestinal tract. They also secrete an enzyme that disinfects the wound, dissolves necrotic tissue, and stimulates wound healing. Maggots are now being used against a wide spectrum of wounds and are proving to be effective against MRSA and other multiresistant microorganisms. They also appear to be more cost effective than other methods of wound healing.[12,14,15]\n\"Studies indicate that about 40% to 50% of wounds treated with maggot therapy as the last alternative before amputation were healed, and the limbs were saved,\" according to Dr. Ronald Sherman, a pathologist at UC Irvine who has been breeding and studying maggots for years. The practice has been growing by about 25% a year in the United States according to him.[16,17]\nMaggots received marketing clearance as \"medical devices\" by the FDA in January 2004, making them the first live organism marketed in the United States. Therapy is currently reimbursable by Medicare.\nAbout 50 centers in North America, 400 in the United Kingdom, more than 140 in Germany, and more worldwide currently offer maggot therapy as an option for treatment in wound care.\nLeeches in Wound Healing\nThe leech, once an indispensable part of the practice of medicine in the 19th century only to be abandoned in favor of scientific medical advances, is seeing a renaissance in the area of modern plastic reconstructive surgery -- particularly in microsurgery transplantation.\nIn the United States, medicinal leeches (Hirudo medicinalis) were cleared as a medical device in June 2004 by the FDA (shortly after maggots received clearance) and are used today throughout the world as tools in skin grafts and reattachment microsurgery.\nThe renewed interest in leeches can be ascribed to 2 Slovenian surgeons who described their use to prevent venous congestion of skin-flap transplants in an article in the British Journal of Plastic Surgery in 1960. Leeches work by creating a puncture wound that bleeds for hours, while anesthetizing the wound, preventing clotting and dilating vessels to increase blood flow.\nThen in 1985, Joseph Upton, a Harvard plastic surgeon, used leeches in the reattachment of an ear in a small child. Ears have been notoriously difficult to transplant successfully due to the clotting of minute blood vessels during the procedure. The use of leeches saved the boy's ear.\nThe medical literature describes countless cases of the use of leeches to relieve venous congestions following reattachment or transplantation surgery of fingers, toes, ears, penis, and other skin-flaps; in addition to breast reconstruction, reduction, or augmentation procedures where engorgement of the nipple can be a complication.[21,22]\nLeeches possess properties that make them uniquely able to assist with venous compromised tissues. Their saliva contains:\n* Hirudin, a direct thrombin inhibitor;\n* Hyaluronidase, which increases the local spread of leech saliva through human tissue at the site of the wound and also has antibiotic properties;\n* A histamine-like vasodilator that promotes local bleeding; and\n* A local anesthetic.\nAeromonas hydrophila infections are a recognized complication of postoperative leech application, with reported incidences ranging from 2.4% to 20%. Prophylactic antibiotics are often recommended. In the event infection develops, early diagnosis and immediate initiation of an empirical intravenous antibiotic therapy are essential.[23-25] Another major concern in the use of leeches is their migration from the surgical site, possibly into the body or the wound itself. One study suggested a possible simple solution, which was to attach 1 end of a surgical suture to the leech and tie the free end to a firm object or dressing.\nWhile leeches still aren't a surgeon's first choice, they are considered in a transplant that has failed for lack of venous outflow on the patient that has been put on heparin or other anticoagulants, and has undergone repeat surgeries in which as many of the small veins have been attempted to be connected. Randomized-controlled trials are pending to elucidate the benefit of H medicinalis in accordance with evidence-based criteria.\n1. Lusby PE, Coombes A, Wilkinson JM. Honey: a potent agent for wound healing. J Wound Ostomy Continence Nurs. 2002;29:295-300. Abstract\n2. Fox C. Honey as a dressing for chronic wounds in adults. Br J Commun Nurs. 2002;7:530-534.\n3. Ahmed AK, Hoekstra MJ, Hage JJ, Karim RB. Honey-medicated dressing: transformation of an ancient remedy into modern therapy. Ann Plast Surg. 2003;50:143-147; discussion 147-148.\n4. Molan PC, Clinical usage of honey as a wound dressing: an update. J Wound Care. 2004;13:353-356. Abstract\n5. Natarajan S, Williamson D, Grey J, Harding KG, Cooper RA. Healing of an MRSA-colonized, hydroxyurea-induced leg ulcer with honey. J Dermatol Treat. 2001;12:33-36.\n6. Cooper RA, Molan PC, Harding KG. Antibacterial activity of honey against strains of Staphylococcus aureus from infected wounds. J R Soc Med. 1999;92:283-285. Abstract\n7. Molan PC. The evidence supporting the use of honey as a wound dressing. Int J Low Extrem Wounds. 2006;5:40-54. Abstract\n8. Moore OA, Smith LA, Campbell F, Seers K, McQuay HJ, Moore RA. Systematic review of the use of honey as a wound dressing. BMC Complement Altern Med. 2001;1:2.\n9. Eddy JJ, Gideonsen MD. Observations from practice. Topical honey for diabetic foot ulcers. J Fam Pract. 2005;54:533-535. Abstract\n10. Kingsley A. The use of honey in the treatment of infected wounds: case studies. Br J Nurs. 2001;10:S13-S16, S18, S20. Abstract\n11. Dente, K. Cheap Fix in a War Zone. Los Angeles Times, September 10, 2007. Available at: http://www.latimes.com/features/health/medicine/la-he-labside10sep10,1,511904.story?coll=la-health-medicine Accessed October 24, 2007.\n12. Parnés A, Lagan KM. Larval therapy in wound management: a review. Int J Clin Pract. 2007;61:488-493. Abstract\n13. Sherman RA, Sherman J, Gilead L, Lipo M, Mumcuoglu KY. Maggot debridement therapy in outpatients. Arch Phys Med Rehabil. 2001;82:1226-1229. Abstract\n14. Sherman RA, Wyle F, Vulpe M. Maggot debridement therapy for treating pressure ulcers in spinal cord injury patients. J Spinal Cord Med. 1995;18:71-74. Abstract\n15. Bexfield A, Nigam Y, Thomas S, Ratcliffe NA. Detection and partial characterisation of two antibacterial factors from the excretions/secretions of the medicinal maggot Lucilia sericata and their activity against methicillin-resistant Staphylococcus aureus (MRSA). Microbes Infect. 2004;6:1297-1304. Abstract\n16. Sherman RA, Hall MJR, Thomas S. Medicinal maggots: An ancient remedy for some contemporary afflictions. Annu Rev Entomol. 2000;45:55-81. Abstract\n17. Dente K. Maggot Therapy: Gross? Sure -- But Better Than Losing a Leg. Los Angeles Times, September 10, 2007. Available at: http://www.latimes.com/features/health/medicine/la-he-labbox10sep10,1,7464464.story?coll=la-health-medicine Accessed October 24, 2007.\n18. Grassberger M, Fleischmann W. The biobag -- A new device for the application of medicinal maggots. Dermatology. 2002;204:306.\n19. Derganc M, Zdravic F. Venous congestion of flaps treated by application of leeches. Br J Plast Surg. 1960;13:187-192. Abstract\n20. Banis JC, Upton J. Microsurgical reattachment of totally amputated ears. Plast Reconstr Surg. 1987;79:535-541. Abstract\n21. Knobloch K et al. Hirudo medicinalis-leech application in plastic and reconstructive microsurgery -- a literature review. Handchir Mikroochir Plast Chir. 2007;39:103-107.\n22. Conforti ML, Connor NP, Heisey DM, Hartig GK. Evaluation of performance characteristics of the medicinal leech for the treatment of venous congestion. Plast Reconstr Surg. 2002;109:228-235. Abstract\n23. Bauters TG, Buyle FM, Verschraegen G, et al. Infection risk related to the use of medicinal leeches. Pharm World Sci. 2007;29:122-125. Abstract\n24. Kalbermatten DF, Rieger UM, Uike K, Erba P, Laifer G, Hintermann B. [Infection with Aeromonas hydrophila after use of leeches (Hirudo medicinalis) in a free microvascular osteo-(myo-)cutaneous flap -- suggestions for successful management] Handchir Mikrochir Plast Chir. 2007;39:108-111.\n25. Lineaweaver WC, Hill MK, Buncke GM, et al. Aeromonas hydrophila infections following use of medicinal leeches in replantation and flap surgery. Ann Plast Surg. 1992;29:238-244. Abstract\n26. Granzow JW, Armstrong MB, Panthaki ZJ. A simple method for the control of medicinal leeches. J Reconstr Microsurg. 2004;20:461-462. Abstract\n27. Utley DS, Koch RJ, Goode RL. The failing flap in facial plastic and reconstructive surgery: role of the medicinal leech. Laryngoscope. 1998;108:1129-1135. Abstract"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:5a529df8-b58c-4aaf-a5de-779771dd9111>","<urn:uuid:842d6685-699f-4f09-a766-d41e3e369894>"],"error":null}
{"question":"How do striatum size variations affect learning capabilities, and what implications does this have for rehabilitation strategies?","answer":"Variations in striatum size significantly impact learning capabilities - individuals with larger nucleus accumbens perform better in early learning stages, while those with larger caudate nucleus and putamen show faster learning rates during variable priority training. The striatum acts as a learning machine, becoming active during habit formation and skill acquisition. These findings have important implications for rehabilitation strategies, as they demonstrate that the brain maintains plasticity and can undergo reorganizing changes. This understanding helps guide the development of targeted rehabilitation approaches, suggesting that rehabilitation efforts should focus particularly on supporting later stages of motor learning rather than early plasticity steps.","context":["Brain structure predicts ability to learn video games\nCAMBRIDGE, Mass. — Researchers can predict your performance on a video game simply by measuring the volume of specific structures in your brain, a multi-institutional team reports this week.\nThe new study, in the journal Cerebral Cortex, found that nearly a quarter of the variability in achievement seen among men and women trained on a new video game could be predicted by measuring the volume of parts of the striatum, a collection of brain structures tucked deep inside the cerebral cortex. The study adds to the evidence that the striatum profoundly influences a person’s ability to refine his or her motor skills, learn new procedures, develop useful strategies, and adapt to a quickly changing environment.\n“This is the first time that we’ve been able to take a real-world task like a video game and show that the size of specific brain regions is predictive of performance and learning rates,” said Kirk Erickson, a professor of psychology at the University of Pittsburgh and lead author on the study.\nAnn Graybiel, an Institute Professor at MIT and an Investigator at the McGovern Institute for Brain Research; and Arthur Kramer, a professor of psychology at the Beckman Institute for Advanced Science and Technology at the University of Illinois, were co-principal investigators on the study. Walter Boot, of Florida State University also contributed to the research. The study was conducted at the University of Illinois.\nPast research has shown that expert video gamers outperform novices on many basic measures of attention and perception — even when novices practice the game for twenty hours or more. Those findings led researchers to explore whether pre-existing differences in brain structure play a role in video game performance.\nBased on animal studies conducted by Ann Graybiel and others, the team of researchers zeroed in on three brain structures: the caudate nucleus and the putamen in the dorsal striatum, and the nucleus accumbens in the ventral striatum.\n“Our animal work has shown that the striatum is a kind of learning machine — it becomes active during habit formation and skill acquisition,” Graybiel said. “So it made a lot of sense to explore whether the striatum might also be related to the ability to learn in humans.”\nHalf of the study participants were asked to focus on maximizing their overall score in a video game while paying equal attention to the various components of the game. The other participants had to periodically shift priorities, improving their skills in one area for a period of time while also maximizing their success at the other tasks. The latter approach, called “variable priority training,” encourages the kind of flexibility in decision-making that is commonly required in daily life, according to Kramer.\nThe researchers found that players who had a larger nucleus accumbens did better than their counterparts in the early stages of the training period, regardless of their training group. This makes sense, Erickson said, because the nucleus accumbens is part of the brain’s reward center, and a person’s motivation for excelling at a video game includes the pleasure that results from achieving a specific goal.\nPlayers with a larger caudate nucleus and putamen did best on the variable priority training. Those with the largest structures “learned more quickly and learned more over the training period,” Kramer said.\n“This study tells us a lot about how the brain works when it is trying to learn a complex task,” Erickson said. “We can use information about the brain to predict who is going to learn certain tasks at a more rapid rate.”\n“One of the powerful message that comes out of this study is that very basic scientific research can be important in guiding work in humans,” Graybiel said. “Identifying the parts of the brain that become especially active when we learn complex tasks will help guide the development of new learning strategies in the future.”\nHow they did it: Researchers used high-resolution magnetic resonance imaging (MRI) to analyze the size of the brain regions in healthy adults who had spent less than three hours a week playing video games in the previous two years. Participants were then trained on Space Fortress, a video game developed at the University of Illinois that requires players to try to destroy a fortress without losing their own ship to one of several potential hazards.\nSource: “Striatal volume predicts level of video game skill acquisition,” Erickson KI, Boot WR, Basak C, Neider MB, Prakash RS, Voss MW, Graybiel AM, Simons DJ, Fabiani M, Gratton G, Kramer AF. Cerebral Cortex. Jan. 19, 2010.\nFunding: Office of Naval Research\nThis news content was configured by WebWire editorial staff. Linking is permitted.\nNews Release Distribution and Press Release Distribution Services Provided by WebWire.","Clinical implications of neuroplasticity – the role of rehabilitation in multiple sclerosis\n- Neurological Rehabilitation Center Quellenhof, Bad Wildbad, Baden-Württemberg, Germany\nMultiple sclerosis (MS) is a chronic autoimmune disease of the central nervous system (CNS) that preferably affects young adults and causes a multitude of symptoms including visual disturbances, spasticity, weakness, impairment of walking, coordination difficulties, tremor/ataxia, sensory problems, and bladder disturbances. In addition, “invisible” symptoms such as fatigue, depression, and cognitive dysfunction are also common and may even be present early in the course of the disease (1). These symptoms often cause huge disability and have an impact on family, social, and work activities. Despite the advances of pharmacological treatment, particularly by disease-modifying therapies, the majority of MS patients accumulate new lesions and disabilities along the disease course and thus, there is a continuing need for comprehensive, multidisciplinary treatment, which constitutes the basic concept of rehabilitation (2).\nRehabilitation is defined as a “problem-solving educational process aimed at reducing disability and handicap experienced by someone as a result of disease or injury” (3). The primary goal is to reduce the limitations of activity and participation in order to achieve the highest possible level of independence and to increase and maintain quality of life of MS patients (4). With respect to the large variety of symptoms, a multidisciplinary approach is required for MS rehabilitation that includes physiotherapy, occupational therapy, cognitive rehabilitation, psychological therapy, speech therapy, measures for improving fatigue, and coping programs (2, 5). These measures facilitate the reorganizing mechanisms within the CNS and therefore, rehabilitation may be regarded as “applied neuroplasticity.” This article gives an overview of the most recent scientific evidence and measures of MS rehabilitation, and the relationship between neuroplasticity and functional improvement in MS.\nMultidisciplinary Rehabilitation in MS\nThere is a large interest in scientifically sound studies dealing with the effectiveness of neurorehabilitation. During the last decades, a growing body of research has been performed, mainly in stroke patients, but also in MS. A recent update of a Cochrane review identified 10 randomized controlled trials dealing with multidisciplinary rehabilitation in MS (6). Although data are limited, the available evidence suggests that inpatient rehabilitation may have short-term effects on activity and participation, but not on impairment. Furthermore, there was “moderate evidence” to support inpatient or outpatient rehabilitation programs to improve disability, bladder dysfunction, and participation that may last up to 12 months. Since these effects diminish with time (7), repetition of multidisciplinary rehabilitation seems necessary, preferably on an annual base.\nPhysiotherapy and Exercise Therapy\nPhysiotherapy is one of the basic methods of MS rehabilitation and aims at improving motor function, stability of gait, and walking capabilities. Moreover, endurance and physical fitness may also be strengthened and thus, fatigue may be ameliorated. There are many techniques and methodologies based on neurophysiological concepts (i.e., Bobath, Vojta, Brunkow, and proprioceptive neuromuscular stimulation) as well as newer approaches such as equipment-supported training, treadmill exercises, robot-assisted gait training, and constraint-induced movement therapy (CIMT) (2). Neither of these techniques has shown superiority about another which means that the appropriate method should be chosen according to the capabilities and disabilities of the individual patient, but also to the knowledge and resources of the rehabilitation team. Physiotherapy may also improve breathing dysfunction and bladder disturbances by using training programs specifically directed toward respiratory muscle and pelvic floor function, respectively (2, 8).\nIn numerous studies, the beneficial effects of exercise therapy for persons with MS have been shown. Despite methodological problems (small sample sizes, heterogeneous groups of patients, different interventions), there is good evidence that exercise has positive effects on balance (9), mobility (10), muscle weakness (11–13), depression (14), and fatigue (15). Therefore, persons with MS should be encouraged to participate regularly in endurance and/or resistance training of low to moderate intensity. These interventions are well tolerated and not associated with side effects (16, 17), but could positively influence both, the limitations caused by the disease itself and the additionally deconditioning effects of an inactive lifestyle.\nCognitive Dysfunction and Fatigue\nCognitive dysfunction often accompanies the symptomatology of MS and is not necessarily associated with motor disability. It may occur early in the disease course and significantly affects employment, social life, and the activities of daily living (18). The most commonly affected areas are information processing speed, attention, memory, visuo-constructive performance, and executive functions (19). It is of utmost importance to recognize these problems as early as possible by appropriate neuropsychological tests, and to tailor the rehabilitation measures specifically toward the cognitive deficit. Since drug treatment is disappointing [the promising effects of the anti-cholinesterase agent donepezil could not be reproduced in a large randomized controlled trial (20)], treatment consists of neuropsychological training, provision of aids, and supportive psychotherapy [RIMS (21)]. Albeit with limited evidence, a systematic review indicated that cognitive training can improve memory span, working memory, and immediate visual memory (22). Moreover, benefits were found for specific trainings of attention, executive functions, learning performance, and memory (23, 24).\nFatigue is one of the most common and debilitating symptoms in MS and clearly different from normal tiredness. Patients suffer from feelings of lassitude and abnormal tiredness that may increase during the day as well as lack of energy and motivation, which all may impact activities of daily living and work ability [RIMS (21)]. The pathogenesis is still unknown and may involve different mechanisms such as lesions of cortical and/or subcortical motor pathways with involvement of motor cortex and basal ganglia, decreased energy metabolism in the frontal cortex, autonomic dysfunction, endocrine disturbances, and dysregulation of the hypothalamus–pituitary–adrenal axis [(25), RIMS (21)]. These “primary” fatigue needs to be differentiated from secondary mechanisms such as sleep disorders, anemia, and thyroid dysfunction, but also from depression and cognitive deficits. The subjective dimension of fatigue may be evaluated with standardized questionnaires, and attention tests of alertness may be an objective assessment method (26). Drug treatment is often not efficient. Therefore, management of fatigue consists of non-pharmacological measures such as counseling of patients and caregivers, structuring the day with regular breaks, energy management programs, cooling, specific neuropsychological training (attention), and exercise therapy (26).\nNeurorehabilitation as “Applied Neuroplasticity”\nWithin the last years, our knowledge about the basic mechanisms that may be responsible for the restoration of neurological disabilities is rapidly increasing. It is now generally accepted that even the mature brain can undergo plastic changes (27). Although the majority of studies are dedicated to the dynamic reorganization of the motor system after an acute event, i.e., stroke (28), these neuroplastic changes may also occur in a chronic disease as it is MS. For instance, brain activation was exaggerated in MS patients with normal motor function compared to healthy controls by using a finger tapping paradigm (29). The brain activation pattern changes with both, increasing diffuse brain injury (assessed by relative N-acetylaspartate concentration, a marker of axonal integrity) and increasing hand disability, and was present during active as well as passive finger movements reflecting true brain reorganization (30). The same applies for cognitive function: while MS patients in the early stages of MS performed similarly to healthy controls on clinical outcomes and the visual analog of the Paced Auditory Serial Addition Test (PASAT), brain activation was increased in the patient group indicating that compensatory adaptive mechanisms (i.e., neuronal plasticity) may be present very early in the course of MS (31).\nZeller et al. tried to elucidate the basic mechanisms underlying neuronal plasticity in MS. For this purpose, rapid-onset central motor plasticity was assessed in 22 patients with moderately severe, stable MS and compared to healthy controls using paired associative stimulation (PAS), a protocol that models long-term synaptic potentiation in the cerebral cortex and that combines repetitive electric nerve stimulation with transcranial magnetic stimulation (TMS). In contrast to the above mentioned studies, MS patients performed worse in clinical and paraclinical tests of motor function, but the enhancement of corticospinal excitability and the training-induced increments of motor performance were similar to controls. PAS-induced plasticity and motor learning did not correlate with motor impairment or CNS injury. Based upon their findings, the authors concluded that the early steps of neuronal plasticity are unlikely to limit the extent of compensatory changes in MS and therefore, rehabilitation efforts should focus on mechanisms supporting the later stages of motor learning (32).\nAn intriguing question of current research is whether rehabilitation procedures may induce and/or support compensatory adaptive changes. In this regard, evidence albeit limited is available that the clinical improvements of both, motor and cognitive rehabilitation, correlate with neural plasticity in the CNS of MS patients. Sastre-Garriga et al. investigated 15 MS patients and 5 healthy controls by functional magnetic resonance imaging (fMRI) with the PASAT paradigm. The cognitive rehabilitation program consisted of 15 computer-supported sessions and 5 non-computer-supported cognitive stimulation group sessions. After 5 weeks of cognitive training, patients showed significant clinical improvement of their neuropsychological performance, and this correlated to increased brain fMRI activity in several cerebellar areas (33). In a double-blind, randomized controlled trial of 12 MS patients, computer-assisted cognitive rehabilitation of attention deficits increased fMRI activity in the posterior cerebellum and in the superior parietal lobule in parallel to enhanced performance in attention abilities compared with 11 age- and gender-matched MS patients receiving a placebo intervention (34). Similarly, visuomotor performance improved after the first practice session of a visuomotor task (short-term practice) and after 2 weeks of daily sessions of the same task (longer-term practice) in both, 23 MS patients and 12 healthy controls. However, different relationships between the improvements of function and fMRI activity were found between the groups: in MS patients, increased function was associated with lower activation in the sensorimotor, posterior cingulate, and parahippocampal cortices, whereas in controls, greater long-term improvements correlated with smaller activation reductions in the visual cortex supporting the notion that even in MS patients with a high burden of pathology, brain plasticity is preserved, and that cognitive systems different from those of healthy controls contribute to this plasticity (35). However, despite the promising results that rehabilitation may indeed cause not only clinical improvement of cognitive and motor performance but also has distinct effects on brain activation, the role of fMRI in the context of clinical neurorehabilitation needs to be elucidated.\nWhen summarizing the above mentioned findings, there is little doubt that plastic changes occur in the CNS, and that these changes may be modulated by practice. From a clinical point of view, it is obvious that patients undergoing neurorehabilitation improve with practice. Thus, these observations may bridge the gap between basic science and clinical experience. The results from basic studies may provide the scientific rationale to investigate recovery-oriented strategies in clinical trials and to implement them into rehabilitation measures. Several promising new rehabilitation techniques are examples of this approach: impairment-oriented training, CIMT, electromyogram-triggered neuromuscular stimulation, and robotic interactive therapies (2). It should be kept in mind that most of this evidence came from studies in patients with stroke or spinal cord injuries. However, more and more studies support the usefulness of these measures also in MS patients that reflect the clinical experience that we have made in our rehabilitation center during the last years (5). High-quality, carefully designed studies of the effectiveness of neurorehabilitation are necessary that should include both, clinical outcomes and neuroplastic measures. These studies may further move MS rehabilitation from empirical strategies toward evidence-based interventions and help to elucidate the basic mechanisms that are responsible for the clinical effects. Eventually, further research may provide the base to develop effective therapies that support the neuroplastic changes responsible for functioning, activity, and participation of persons with MS in order to reach and maintain their optimal physical, sensory, intellectual, psychological, and social functioning levels and promote the best possible quality of life.\nConflict of Interest Statement\nThe author declares that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n6. Khan F, Turner-Stokes L, Ng L, Kilpatrick T, Amatya B. Multidisciplinary rehabilitation for adults with multiple sclerosis. Cochrane Database Syst Rev (2007) CD006036. doi:10.1002/14651858.CD006036.pub2\n9. Paltamaa J, Sjogren T, Peurala SH, Heinonen A. Effects of physiotherapy interventions on balance in multiple sclerosis: a systematic review and meta-analysis of randomized controlled trials. J Rehabil Med (2012) 44:811–23. doi:10.2340/16501977-1047\n11. Dalgas U, Stenager E, Ingemann-Hansen T. Multiple sclerosis and physical exercise: recommendations for the application of resistance-, endurance- and combined training. Mult Scler (2008) 14:35–53. doi:10.1177/1352458507079445\n12. Latimer-Cheung AE, Pilutti LA, Hicks AL, Martin Ginis KA, Fenuta AM, MacKibbon KA, et al. Effects of exercise training on fitness, mobility, fatigue, and health-related quality of life among adults with multiple sclerosis: a systematic review to inform guideline development. Arch Phys Med Rehabil (2013) 94:1800–28. doi:10.1016/j.apmr.2013.04.020\n14. Dalgas U, Stenager E, Jakobsen J, Petersen T, Hansen HJ, Knudsen C, et al. Fatigue, mood and quality of life improve in MS patients after progressive resistance training. Mult Scler (2010) 16:480–90. doi:10.1177/1352458509360040\n20. Krupp LB, Christodoulou C, Melville P, Scherl WF, Pai LY, Muenz LR, et al. Multicenter randomized clinical trial of donepezil for memory impairment in multiple sclerosis. Neurology (2011) 76:1500–7. doi:10.1212/WNL.0b013e318218107a\n24. O’Brien AR, Chiaravalloti N, Goverover Y, DeLuca J. Evidenced-based cognitive rehabilitation for persons with multiple sclerosis: a review of the literature. Arch Phys Med Rehabil (2008) 89:761–9. doi:10.1016/j.apmr.2007.10.019\n29. Reddy H, Narayanan S, Arnoutelis R, Jenkinson M, Antel J, Matthews PM, et al. Evidence for adaptive functional changes in the cerebral cortex with axonal injury from multiple sclerosis. Brain (2000) 123:2314–20. doi:10.1093/brain/123.11.2314\n30. Reddy H, Narayanan S, Woolrich M, Mitsumori T, LaPierre Y, Arnold DL, et al. Functional brain reorganization for hand movement in patients with multiple sclerosis: defining distinct effects of injury and disability. Brain (2002) 125:2646–57. doi:10.1093/brain/awf283\n31. Staffen W, Mair A, Zauner H, Unterrainer J, Niederhofer H, Kutzelnigg A, et al. Cognitive function and fMRI in patients with multiple sclerosis: evidence for compensatory cortical activation during an attention task. Brain (2002) 125:1275–82. doi:10.1093/brain/awf125\n33. Sastre-Garriga J, Alonso J, Renom M, Arevalo MJ, Gonzalez I, Galan I, et al. A functional magnetic resonance proof of concept pilot trial of cognitive rehabilitation in multiple sclerosis. Mult Scler (2011) 17:457–67. doi:10.1177/1352458510389219\n34. Cerasa A, Gioia MC, Valentino P, Nistico R, Chiriaco C, Pirritano D, et al. Computer-assisted cognitive rehabilitation of attention deficits for multiple sclerosis: a randomized trial with fMRI correlates. Neurorehabil Neural Repair (2013) 27:284–95. doi:10.1177/1545968312465194\n35. Tomassini V, Johansen-Berg H, Jbabdi S, Wise RG, Pozzilli C, Palace J, et al. Relating brain damage to brain plasticity in patients with multiple sclerosis. Neurorehabil Neural Repair (2012) 26:581–93. doi:10.1177/1545968311433208\nKeywords: multiple sclerosis, rehabilitation, neuronal plasticity, physiotherapy, neuropsychological therapy, exercise therapy, functional imaging studies\nCitation: Flachenecker P (2015) Clinical implications of neuroplasticity – the role of rehabilitation in multiple sclerosis. Front. Neurol. 6:36. doi: 10.3389/fneur.2015.00036\nReceived: 12 January 2015; Accepted: 12 February 2015;\nPublished online: 03 March 2015.\nEdited by:Daniel Zeller, University of Würzburg, Germany\nReviewed by:Jürg Kesselring, Rehabilitation Centre, Switzerland\nCopyright: © 2015 Flachenecker. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:27c49fcb-ff15-4e7d-9c7b-7c825333215e>","<urn:uuid:7fcf253a-87c5-4ab3-af14-e662e5d1a95d>"],"error":null}
{"question":"What's the recommended first action for dealing with mold - contacting maintenance staff in dorms or shutting off central AC systems?","answer":"For dorm rooms, the recommended first action is to promptly contact your Resident Advisor (RA) or submit a maintenance request form according to campus protocols. However, for central AC systems, the EPA specifically recommends shutting off the system immediately upon noticing mold to prevent it from spreading throughout the ductwork. This difference exists because dorm maintenance staff need to assess and handle the situation according to institutional protocols, while with central AC, stopping the spread of mold through the ducts is the critical first priority before professional remediation can begin.","context":["During the first days of college, decorating their dorm room is every student’s focus, and for the most part, rooms won’t require anything more complicated than accessorizing.\n“Overall, the problems students deal with—say, noise or a lack of space—are small compared to the value you get from being part of the residence life experience,” says Harlan Cohen, founder of the website Best First Year in College and author of The Naked Roommate: And 107 Other Issues You Might Run Into in College. “Dorm problems tend to be very manageable.”\nBut sometimes, something more serious than tight living quarters or rowdy roommates can crop up, and students will need to contact university personnel. These issues range from a bedbug infestation to mold, mice, or cockroaches. Here’s what students and parents need to do when faced with dorm room maintenance issues.\nRelated: A Handy Guide to Surviving Dorm Life\nTell your resident advisor promptly\nCampus protocols vary from college to college. If there’s an issue with a dorm, some schools require students to fill out an online submission form that go to facilities staff, while others advise you to alert your RA—or both. “The RA will more than likely explain to students during a first floor meeting exactly how maintenance requests are handled,” says Terri Scanlon, managing director of the website Reslife.net, a site that provides information to university housing and residence life professionals. Whatever system is in place, students should start with their RA if they’re not sure how to proceed.\nIt’s important to report promptly so the school can solve the issue—particularly if it’s a problem like bedbugs that can spread to other rooms if left unchecked, or mold, which poses a health hazard to mold-sensitive people. If the problem isn’t resolved the first time it’s treated, students will need to follow up with another report. “Sometimes there may be a lag in resolving issues, and in that instance students just need to be doing appropriate follow-up,” Scanlon says. “For reporting maintenance, some schools will have manual systems, and some will have online systems.”\nAt Texas Tech University, housing staff is on hand during move-in weekend to handle issues that crop up in the moment, says Sean Duggan, managing director of the University’s student housing. “We try to turn a negative experience positive through staff presence and willingness to do whatever we need to do to solve the problem,” Duggan says. The University also provides abundant student education for room issues that might crop up later.\nFind a confidante if you’re uncomfortable reporting\nIf reaching out to the RA isn’t comfortable for whatever reason, “students need to reach out to the safest and easiest person around them, so that person can help them articulate what it is they need done,” Cohen says. They can find an RA on another floor or another residential resource. Most residence halls have a residence hall association, and there’s always a senator who represents that particular hall, Cohen says.\nDon’t ask your parents to handle it\nMost students don’t have trouble reporting an issue, Duggan says. But often they call their parents to handle it rather than their RA or facilities staff. His staff is accustomed to speaking with parents, but they would rather talk to the student because the process moves faster when parents get out of the middle. Advocating for yourself can feel uncomfortable, but college experts say taking the lead is an important life skill.\n“Life can be uncomfortable and challenging,” Cohen says. “But unless you practice ‘uncomfortable’ and engage with people, you’re never going to get good at it.”\nWhen to involve parent help\nHowever, if students aren’t successful getting a problem resolved, it might be time for a parent to call. Experts prefer parents encourage from behind the scenes to help students start managing their own issues, but if a parent feels like an issue isn’t being addressed, it’s appropriate to follow up on health or safety situations. For example, if a student has allergies or asthma, or lives with a roommate who has an emotional support animal and the student is allergic, “these are situations where the student can advocate but can also include the parent if the situation isn’t being resolved fast enough,” Cohen says. Also, if a student is unable to self-advocate, whether due to learning differences, social anxiety, or documented medical issues, helping the student is appropriate, he says.\nCommon issues—what to know\nThese critters are a big deal, and need to be reported immediately so maintenance staff can inspect and treat if necessary. Bedbugs don’t introduce disease like mosquitos can, but they’re a headache to get rid of and will multiply if left unreported. They aren’t a sign of poor hygiene; rather, they hitchhike in on luggage or furniture and may have been introduced into the room before you arrived.\nNot all students react to bedbug bites, Duggan says, so the problem is students might not even realize they have them because bedbugs hide during the day. “At move-in, we have posters up about bedbugs and what to look for, and information on our website,” Duggan says. “We’re not afraid to talk to students because we need their help. Even if a bug turns out not to be a bedbug, we thank them profusely for calling because we don’t want bedbugs in the building.”\nHeat is the most effective bedbug treatment, and many institutions have a system to heat entire rooms by raising the room temperature to 130 degrees. Students need to do their part by following institutional protocols, such as washing and drying all their bedding and clothing on hot cycles. Housing departments may help with laundry costs or might even handle it for the student. Students will also need to be vigilant about not introducing bedbugs when they travel home.\nAlso a big deal, mold can become a health issue for people sensitive to it, according to the Environmental Protection Agency, leading to throat irritation, coughing, wheezing, asthma, and allergies. If your room has signs of mold, report it to your college’s housing staff. This fall, the University of Maryland had to temporarily relocate students to hotels to treat the building they were living in.\nMice and cockroaches can be a problem too, especially if students don’t keep their room tidy and don’t put food away in sealed containers or in the fridge. Duggan says various causes can send mice indoors. “Construction on campus might kick up mice. In Texas, we’ve had droughts, and they can drive critters in from the country to the city looking for a home,” he says. “We absolutely encourage students to tell us.”\nAt the beginning of the year, students will fill out a room inventory form to verify that furniture and other room elements are in good condition. Be sure to complete this process, because you will be held accountable at the end of the year and could be charged a fee for poor conditions. “After the initial room inventory, staff aren’t going to be walking around and asking students if there’s anything in their room that needs to be repaired,” Scanlon says. “The onus of that is on the student living in the space.”\nRelated: 5 Freshman Dorm Mistakes to Avoid\nColleges and universities want students to have a wonderful experience living in the residence halls. They are ready to solve housing issues that arise, so don’t be afraid to ask for help if you need it.","Mold and mold spores can reduce the air quality in your home, especially if someone in your household has a mold allergy. Mold growing in the bathroom or basement is bad enough, but what if mold grows in your air conditioner or inside the ducts of your HVAC system? We will explain how mold might form in a window-unit air conditioner or in ductwork, how to prevent it, and what to do if you do find mold in your air conditioner.\nThe dangers of mold in your air conditioner\nIf mold is growing in your house, it can release spores that can be easily inhaled. According to the CDC, “molds can cause nasal stuffiness, throat irritation, coughing or wheezing, eye irritation, or, in some cases, skin irritation. People with mold allergies may have more severe reactions. Immune-compromised people and people with chronic lung illnesses, such as obstructive lung disease, may get serious infections in their lungs when they are exposed to mold.”\nMold growing in an AC unit is not necessarily more dangerous than mold growing elsewhere in your house. However, the function of an air conditioner is to spread cool air throughout a room, and the purpose of the HVAC ducts is to distribute air throughout the house. If they become contaminated with mold, they will efficiently distribute mold spores across an entire room or the entire house. If the concentration of mold spores is high enough, you will have a mold problem everywhere, rather than in just one location, and you will be inhaling mold spores in every room, even while you sleep.\nHow mold grows in air conditioners\nMold spores are everywhere. Unfortunately, it is impossible to get rid of all the mold spores in your house, and even if you did, more would come in every time you opened a door or window. When spores grow into mold, more spores are released, and these higher concentrations of spores are what cause the health problems associated with mold. Thus, the key is to prevent the mold from growing in the first place.\nMold needs two things in order to grow: moisture and an organic food source. Moisture can come from high humidity, or a leak or spill that is not cleaned up properly. Condenser and evaporator coils are the main contributors to condensation, and therefore have potential for water leakage if not properly drained. The food source can be the surface the mold is growing on, like wood or carpet, or organic particles found in dust, if there is enough of it.\nUnder most circumstances, air conditioners and HVAC ducts are not hospitable places for mold to grow. Sheet metal ducts and styrofoam channels inside window units do not offer mold a food source. However, dust often collects in these places, which can allow mold to grow.\nHow do I get rid of mold in my air conditioner?\nCleaning up mold can be difficult and messy. The area where you perform the clean-up should be well-ventilated, and you should wear non-porous gloves and a face mask with goggles, especially if you are sensitive to mold. Mold can be wiped up with a household cleaner and a cloth or sponge. Bleach is not needed to remove mold. If mold has grown on a porous surface such as wood, plaster, carpet or upholstery, you will probably not be able to get rid of all the mold. The moldy item or section will need to removed, thrown away and replaced.\nWindow unit: By the time you see small mold spots forming on the air direction vanes or grate of your window air conditioner, it is probably too late. The mold you see is just the tip of the iceberg. You can disassemble the unit and try to clean mold from the internal air ducts, coils, evaporators and other parts, but there is always a chance you will miss some and the mold will simply grow back. A moldy window unit likely needs to be replaced.\nCentral AC: Mold growing in the ductwork of your central AC system will almost certainly require professional remediation. The EPA suggests you shut off the system as soon as you notice mold to prevent it from spreading. The ducts will need to be vacuumed and cleaned, which could become very expensive and difficult if it has spread throughout the entire system. Sheet metal ducts are much easier to clean than fiberglass, plastic or lined ducts. The EPA does not recommend applying biocides or surface treatments to kill or prevent mold in ductwork.\nCar AC: Under normal operating conditions, the AC in your car should drain moisture properly and not get moldy. If your car gets wet because of a flood or leaving the windows open in the rain, clean and dry it out promptly. If mold grows in the AC system, your options are limited. You can disassemble the dashboard and access most of the ductwork, cleaning it with household cleaners and a cloth. Really moldy ducts can often be replaced, but the cost and effort involved varies from car to car. There are chemical products you can spray into the AC system to clean and kill mold, but their effectiveness is questionable, and any chemicals you put into the system will be blown back out again for you to inhale.\nHow do I prevent mold from growing in my air conditioner?\nControlling moisture is the key to preventing mold in air conditioners. Unfortunately, air conditioners can also be a source of moisture. Here are some steps you can take to control moisture when using an air conditioner.\n- Window units should fit the window tightly to prevent rain and humid outdoor air from entering the room.\n- When humid air is cooled in an air conditioner, the water vapor in the air condenses out of the air (cool air can hold less water than warm air, so the air is “wrung out” like a sponge). Window units should be tilted slightly toward the outside to allow this condensation to drain properly.\n- Grates and filters in window units should be cleaned regularly to prevent dust build-up, which can provide a food source for mold and impede air flow.\n- Whole house AC units should have drainage systems, ideally leading to a drain tile, through a basement slab, or to a utility sink. Make sure yours is working properly so moisture does not collect around the unit or get introduced into the ducts. Drains can become clogged by debris or build-up and result in significant flooding in your house.\n- Portable AC units need to emptied periodically. They typically have an auto shut-off and a light to let you know when the reservoir is full. Make sure portable units are empty and dry before storing for winter.\n- HVAC ducts tend to self-regulate moisture, because the air flow dries them out. Keep all grates and air returns unblocked and clean to allow air to flow properly to all parts of the system.\n- Replace air filters regularly. Clogged filters not only provide a food source for mold, but they can impede air flow.\n- Never introduce moisture to your HVAC system. Duct cleaning should use dry vacuuming or dry wiping, never water.\nMold growing in an AC unit or in your home’s HVAC system is a serious problem, because it allows mold spores to be spread throughout the house. Cleaning up an HVAC mold problem is a difficult and possibly expensive task. The best way to deal with mold in an air conditioner is to control moisture and prevent it from happening at all."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:f0f69643-678c-4687-8712-2b5367eefce6>","<urn:uuid:0f5dfea6-8136-4ccd-960a-d7888b96b7ff>"],"error":null}
{"question":"I'm a chemistry student trying to understand isotopes better. Could you explain the differences between Hydrogen-1 and Hydrogen-3 in terms of their structure and stability?","answer":"Hydrogen-1 and Hydrogen-3 have significant differences in their structure and stability. Hydrogen-1 (1H) is the simplest form, consisting of just one proton and one electron, and it is stable. In contrast, Hydrogen-3 (3H) has one proton and two neutrons in its nucleus, along with one electron, and it is radioactive with a half-life of 12.32 years. While both isotopes have the same number of protons (which makes them both hydrogen), the additional neutrons in Hydrogen-3 make it unstable.","context":["Protons Are What Make Elements Distinct\nAll matter, including mineral crystals, is made up of atoms. All atoms are made up of three main particles: protons, neutrons, and electrons. Protons have a positive charge, neutrons have no charge, and electrons have a negative charge. Protons and neutrons have approximately the same mass, but electrons have a mass that is 10,000 times smaller.\nThe element hydrogen (H) has the simplest atoms. Most hydrogen atoms have just one proton and one electron. The proton forms the nucleus (the centre of the atom), while the electron orbits around it (Figure 5.5, left). All other elements have more than one proton in their nucleus. Protons repel each other because they are positively charged, but it is possible to have more than one proton in a nucleus because neutrons hold them together. The next most complex atom, helium (He) has two protons and two neutrons in its nucleus, in its most common form. Some atoms of the same element can have different numbers of neutrons. For example, forms of hydrogen exist with one and two neutrons, and a tiny fraction of He atoms have only one neutron. Forms of an element with different numbers of neutrons are called isotopes.\nThe number of protons in an atom determines what element it will be, so the number of protons is called the atomic number of that element. The total number of protons and neutrons in the nucleus is the mass number. The mass number distinguishes between isotopes of an element. Isotopes of an element are denoted by putting the mass number as a subscript in front of the symbol for that element. For example, the isotopes of hydrogen are 1H (1 proton), 2H (1 proton + 1 neutron), and 3H (1 proton + 2 neutrons).\nFor most of the 16 lightest elements (up to oxygen) the number of neutrons is equal to the number of protons. For most of the remaining elements, there are more neutrons than protons. This is because the more protons that are concentrated in a small space, the more neutrons are needed to keep the nucleus together. The most common isotope of uranium (U), for example, is 238U. It has 92 protons, but requires 146 neutrons to keep them together. The neutrons are only partly successful. Uranium is radioactive, meaning that its nucleus will eventually split apart and release energy. What remains of the nucleus has fewer protons, so after decay the atom is a different element.\nElectrons Are What Control How Atoms Interact\nElectrons orbiting around the nucleus of an atom are arranged in shells (also called energy levels). The first shell can hold only two electrons (as in H and He in Figure 5.5), but the next shell holds up to eight electrons. An atom can have many shells of electrons, but there are never more than 8 outermost electrons interacting with surrounding atoms.\nThe outermost electrons determine how atoms can be bonded together. Elements that have a full outer shell (e.g., neon, Figure 5.6 right) are inert because they do not react with other elements to form compounds. These are the noble gases (including helium, argon, krypton, and radon, in addition to neon) in the far-right column of the periodic table. For elements that do not have a full outer shell (e.g., lithium, Figure 5.6 left), the outermost electrons can interact with the outermost electrons of nearby atoms to create chemical bonds.\nThe electron shell configurations for 29 of the first 36 elements are listed in Table 5.1. Note that some of the shells in the table below have more than 8 electrons. This is because they contain subshells. For example, the third shell can hold up to 18 electrons because it contains one subshell that can hold 2 electrons, and two subshells that can hold 8 electrons each.\n|Table 5.1 Electron shell configurations of some of the elements up to krypton. Inert elements (those with filled outer shells) are shaded.|\n|Number of Electrons in Each Shell|","Talk:Isotopes of hydrogen\n|WikiProject Elements / Isotopes||(Rated List-class, Low-importance)|\nThis article is part of Wikipedia:Wikiproject Isotopes. Please keep style and phrasings consistent across the set of pages. For later reference and improved reliability, data from all considered multiple sources is collected here. References are denoted by these letters:\n- (A) G. Audi, O. Bersillon, J. Blachot, A.H. Wapstra. The Nubase2003 evaluation of nuclear and decay properties, Nuc. Phys. A 729, pp. 3-128 (2003). — Where this source indicates a speculative value, the # mark is also applied to values with weak assignment arguments from other sources, if grouped together. An asterisk after the A means that a comment of some importance may be available in the original.\n- (B) National Nuclear Data Center, Brookhaven National Laboratory, information extracted from the NuDat 2.1 database. (Retrieved Sept. 2005, from the code of the popup boxes).\n- (C) David R. Lide (ed.), Norman E. Holden in CRC Handbook of Chemistry and Physics, 85th Edition, online version. CRC Press. Boca Raton, Florida (2005). Section 11, Table of the Isotopes. — The CRC uses rounded numbers with implied uncertainties, where this concurs with the range of another source it is treated as exactly equal in this comparison.\n- (D) More specific level data from reference B's Levels and Gammas database.\n- (E) Same as B but excitation energy replaced with that from D.\n- (F) The references given for H4 are dead and provide no information. I have had multiple discussions with D.R. Tilley and H.R. Weller. Authors of Energy Levels of Light Nuclei A = 4. \"ground state\" at the nndc is the lowest energy lever at which something has been seen. For H-4 that is 4.6MeV after an 8MeV Pion hits Li-7. I will leave the final edit to someone with time to do so. --begining the elemination of carbon from our energy diet. (talk) 18:52, 12 March 2015 (UTC)\nZ N refs symbol half-life spin excitation energy 1 0 AB |H-1 |STABLE |1/2+ 1 0 C |H-1 |>2.8E+23 a |1/2+ 1 1 ABC |H-2 |STABLE |1+ 1 2 AB |H-3 |12.32(2) a |1/2+ 1 2 C |H-3 |12.33 a |1/2+ 1 3 A |H-4 |139(10)E-24 s [3.28(23)MeV] |2- 1 3 B |H-4 |[4.6(9) MeV] |2- 1 3 C |H-4 |[~3 MeV] |2- 1 4 A* |H-5 |>910E-24 s [<0.5 MeV] |(1/2+) 1 4 B |H-5 |[5.7 MeV] | 1 4 C |H-5 |[1.9(4) MeV] | 1 5 A |H-6 |290(70)E-24 s |2-# 1 5 BC |H-6 |[1.6(4) MeV] |(2-) 1 6 A |H-7 |23(6)E-24# s [20(5)# MeV] |1/2+# 1 6 B |H-7 |29(7)E-23 y [sic] |\nFemto 16:34, 19 November 2005 (UTC)\nSome of the half-lives in the article were of dubious precision. I adjusted them according to above sources, until someone finds more specialized references. Femto 16:34, 19 November 2005 (UTC)\nAlso the half-lives are different than those on the pages for the specific isotopes, don't know which are the correct ones, but it has to be changed at either the specific pages or here. http://en.wikipedia.org/wiki/Hydrogen-5 http://en.wikipedia.org/wiki/Hydrogen-4\nWhy exactly is muonium mentioned in this article, and why only muonium and not also some other exotic atoms like positronium? —Preceding unsigned comment added by 184.108.40.206 (talk) 16:31, 15 September 2007 (UTC)\nI also wonder why Muonium is mentioned here. Does Muonium have some special connection to isotopes of hydrogen?—Preceding unsigned comment added by 220.127.116.11 (talk • contribs) 20:29, 10 November 2007\nDoes Tritium decay by Beta - or Beta +? Statue2 11:55, 8 October 2007 (UTC)\nHalf-life of the proton?\nThe table says that the half-life of the 1H atom is >2.8·1023 years. Does this refer to the proton decay? If yes, then the half-life should be updated since it is most probably >1032 years. If not, then it should be stated while a proton with a bound electron might have a shorter half-life than a naked proton. Or, if it simply indicates a lower border given be the experiments in the source, then this should also be made clear. Since the CRC Handbook Online is not a free source (you need a user login that seems to be given to selected people only) no one can expect the reader to retrieve the original source.--SiriusB (talk) 14:07, 23 June 2008 (UTC)\nIons of Hydrogen-1?\nIs it possible for the following to exist: A Hydrogen-1 atom that has become an ion by having one less electron? I.E. a free proton? Or does an atom always require at least one electron? What about a proton and two electrons? 18.104.22.168 (talk) 19:57, 27 October 2009 (UTC)\nHydrogen 6 Decay branches\nAll references to this indicate n and 3 n decay with 1 resource showing a 50/50 split in probability. I have not been able to find any evidence of a 4 n decay path. if anyone can cite for this it would be most appreciated. 22.214.171.124 (talk) 18:12, 22 July 2011 (UTC)\n- It's from the NUBASE97 paper, , pp. 14-15:\nIn the very special case of 6H we mention as possible decay channels 3 neutrons and 4 neutrons emissions. The reason is that, based on the observed mass values, both its Sn and S2n separation energies are positive, which makes it stable against 1 neutron and 2 neutron emission, but not against 3n or 4n emission. 6H decays with a half-life of 320(60) yoctoseconds. Its mass value is derived from two 7Li(7Li,8B) experiments and one 9Be(11B,14O). If this mass value is confirmed, 6H would be a unique laboratory for searching for simultaneous 3n or 4n emission.\n- It's from the NUBASE97 paper, , pp. 14-15:\nLose the column \"decay energy\"\n- See Notes (last section of article). The second note reads \"Values marked # are not purely derived from experimental data, but at least partly from systematic trends.\" Dirac66 (talk) 18:49, 23 April 2013 (UTC)\nDecay Chains Section\nI would like to create a section on this article showing the complete decay chains of the isotopes (excluding theoretical proton decay for 1H and 2H). The basic draft is:\nMany of the really heavy neutron-leaking isotopes of the light elements are actually unbound. Examples are 4–7H, 5He, 7He, 9–10He, 10Li, 12–13Li, 13Be, 15–16Be, 16B, 18B, 21C, 25–26O, 28F, 30F, 33Ne, 36Na, 39Mg. Double sharp (talk) 09:12, 26 June 2016 (UTC)\nHello fellow Wikipedians,\nI have just modified one external link on Isotopes of hydrogen. Please take a moment to review my edit. If you have any questions, or need the bot to ignore the links, or the page altogether, please visit this simple FaQ for additional information. I made the following changes:\n- Added archive https://web.archive.org/web/20080923135135/http://www.nndc.bnl.gov/amdc/nubase/Nubase2003.pdf to http://www.nndc.bnl.gov/amdc/nubase/Nubase2003.pdf\nWhen you have finished reviewing my changes, you may follow the instructions on the template below to fix any issues with the URLs.\nYou may set the\n|checked=, on this template, to true or failed to let other editors know you reviewed the change. If you find any errors, please use the tools below to fix them or call an editor by setting\n|needhelp= to your help request.\n- If you have discovered URLs which were erroneously considered dead by the bot, you can report them with this tool.\n- If you found an error with any archives or the URLs themselves, you can fix them with this tool.\nIf you are unable to use these tools, you may set\n|needhelp=<your help request> on this template to request help from an experienced user. Please include details about your problem, to help other editors."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:89ea6050-9047-4a6b-a97c-59b612addd4c>","<urn:uuid:c7f0cb53-fdc6-404a-a253-ca400bf0584e>"],"error":null}
{"question":"How do the natural features differ between the meadow section of Opal Hills and the Tahqua Trail area of the North Country Trail?","answer":"The Opal Hills meadow section features no trees, only shrubbery and wildflowers, with panoramic views of symmetrical mountains and views across Maligne Lake. In contrast, the Tahqua Trail area along the Tahquamenon River offers different scenic elements including sparkling river views in summer, maple trees with fall colors on the riverbank, and winter views of ice formations with patches of open water.","context":["- Physical DifficultyThis is the average user-submitted rating on the physical difficulty of this route. In general, green is beginner, blue is intermediate, black is advanced/most difficult and double-black is expert-only. It is recommended that users build up to black and double-black routes.\n- Technical DifficultyThis is the average user-submitted rating on the technical difficulty of this route. In general, green is beginner, blue is intermediate, black is advanced/most difficult and double-black is expert-only. It is recommended that users build up to black and double-black routes.\nThe Opal Hills hike in Jasper National Park is exhilarating, with a unique beauty that casts a spell on the hikers who make it through the steep trail – moving up to a lush meadow and beautiful mountains. This is truly one of the best hikes in Jasper.\nJoin our newsletter\nGet a weekly dose of discounts and inspiration for adventure lovers\nRoute Description for Opal Hills\nFrom the parking lot, the trailhead is on the far-left side of the lot and it is excellently signposted. While the early section of the trail is a short flat approach across a pleasant field, it will quickly be interrupted by a notoriously steep path. This trail will ascend through partially burnt forest for approximately 0.5 km, where you will then encounter a junction. It is best to do the loop counterclockwise, as this will grant the best views and will save your shins on a gentler downhill.\nContinue to the right of the junction and maintain the steep grade to climb for another kilometer. You will find yourself emerging into a stunning mountain meadow. This meadow has no trees, just shrubbery and wildflowers. This is definitely the most beautiful part of the hike, with limited views across the valley but majestic panoramas of the symmetrical mountains, which adorn the meadow. Looking across Maligne Lake you can see Bald Hills, another fantastic hike!\nContinue along the flat meadow and look up to the scree sided mountain which surround the valley. This mountain has the beautiful name of Peak 45-36. Crossing the valley, find the path that begins to descend again down to the tree line. This side of the path has a gentler grade and passes several small clearings blanketed with more wildflowers. Continue down on the only path and make sure you don’t fall on the steep grade!\nInsider Hints for Opal Hills\n- The drive to this hike is incredible, and many people stop to take pictures. Be very careful if you choose to stop and get out of your car, as this road can be busy in summer.\n- This is great to combine with a Maligne Lake Boat Cruise.\n- Snacks can be found at the Maligne Lake Gift shop, just up from the Boat House.\nGetting to the Opal Hills Trailhead\nHead north from Jasper on Highway 16 until you reach Maligne Lake Rd. Turn right on this road and continue along it for its entirety. At the end of the road, park as far to the left as possible in the lot before the hotel (the first lot).\nOpal Hills Elevation Graph\nWeather ForecastCheck Area Weather\nOpal Hills Reviews\nAdd a comment\nYou must be logged in to post a comment.","About the Chapter:\nOur chapter enjoys being out on the trail – working AND hiking. We offer sections of trail for adoption, have a roving crew to take care of the big maintenance and small construction tasks, and hold work weeks and weekends as needed for projects.\nWe hold monthly hikes to help invite and introduce people to the trail as well as to allow us to enjoy the fruits of our labors on the trail. We hold monthly planning and organizational meetings (usually with a pizza buffet) to help prioritize our projects and share our Trail Tales.\nWe have volunteers from all over Michigan that help out in many ways – some with trail building tools and others with cameras and computer keyboards. You have never worked so FUN if you have never worked with us. We have a tool that fits your hand. Connect with us using the links below to learn more about upcoming events and how you can get involved.\nPlease contact us to find out about upcoming events and volunteer opportunities:\n- Email: email@example.com\n- Facebook: www.facebook.com/NCTAHSS/\n- Join our Chapter! Join the NCTA, select Join a Chapter, and choose Hiawatha Shore-to-Shore as your Chapter.\n- View this area of the Trail on our online map\n- Purchase Waterproof Paper Retail Maps MI-08 and MI-09\n- Muskallonge Lake State Park to Tahquamenon Falls State Park – Park to Park Brochure Map\n- PDF Map 1: Mackinac Bridge to East Lake Road (Sections A – E)\n- PDF Map 2: From East Lake Road to Whitefish Bay (Sections F – K)\n- PDF Map 3: From Whitefish Bay to the Two Hearted River (Sections K – R)\n- PDF of Gros Cap Trails: The US Forest Service St. Ignace Ranger Station is located about 7 miles west of St. Ignace on US 2. They have a small network of trails called the Gros Cap trails.\nClick on an event to see more details.\nSt. Ignace – Trail Town\nTrail Town St. Ignace, your Home Port for exploring the Eastern Upper Peninsula of Michigan. Your North Country Trail Adventure begins at the St. Ignace Welcome Center as soon you come north over the majestic Mackinac “Mighty Mac” Bridge.\nThe Hiawatha Shore-to-Shore Chapter’s (HSS) portion of the North Country Trail (NCT) begins at the south end of the Mackinac Bridge and encompasses Straits State Park, Saint Ignace (our Trail Town), the Hiawatha National Forest and north to Whitefish Bay. It passes through Tahquamenon Falls State Park before it turns north again to Lake Superior and the mouth of the Two Hearted River.\nThis portion of the NCT is uniquely composed almost entirely of true foot trail through remote forests free of commercial establishments. You must hike over 80 miles from Saint Ignace before you reach the first restaurant (the Silver Creek Grill and Pub) near Whitefish Bay. The next businesses are 20 and 25 miles up the trail; a summer camp-store at the Lower Tahquamenon Falls, and finally a brewery (Tahquamenon Falls Brewery & Pub) at the Upper Tahquamenon Falls.\nThis Upper Peninsula section of trail features a low population density, few paved road crossings, and several rustic campgrounds. 122 miles of varied topography can be experienced including lakes, streams, ridges, bogs, an outcropping of the Niagara Escarpment, several fixed sand dunes, and more as you cross the Eastern Upper Peninsula. Careful logistical planning is required for longer hikes. There are many access points for day hikes. M123 is your main access highway.\nHiawatha National Forest, Naomikong Creek: The suspension bridge over Naomikong Creek has been closed due to significant safety and structural issues. Forest Service engineers are working on a retrofit design and material price quotes to correct the issues. Until further notice please follow the Curley Lewis Highway between Naomikong Overlook and the Shallows parking area. The road walk is approximately 1.5 miles.\nTahqua Trail Hike\nLength: Up to 5 miles\nWhy Hike this section: I particularly enjoy the Tahqua Trail area west of the Snug Harbor subdivision. The Tahquamenon River sparkles in the summer sun, in fall the maples dapple the opposite river bank, and winter often finds ice on the river with patches of open water. It is always a joy to “discover” the old steel boat. It provides for wonderful goofy photos to remember your NCT Adventure.\nSubmitted by Kay Kujawa\nDriving Directions: (to get to the trailhead, starting location, etc) There is a trail head and parking lot about 5 miles off M-123 on Tahqua Trail Road. Tahqua Trail Road is the first road (dirt) to the west north of the mouth of the Tahquamenon River near Paradise, Michigan.\nHiking Directions: From the parking lot hike east to follow the NCT along the banks of the Tahquamenon River. The trail loops back to Tahqua Trail Road several times in 5 miles as you hike toward the river mouth and Whitefish Bay.\nNiagara Escarpment to Trout Brook Pond\nLength: 5 to 6 miles\nDifficulty: Moderately Easy\nWhy Hike this section: The Niagara Escarpment is an interesting geologic site. A short walk farther up the trail to the east brings the hiker to a glacial debris field. Turn around and enjoy the Escarpment once more before heading toward H-40. You will cross East Lake Road twice. Once back on the east side of East Lake Road you will discover an interesting beaver dam on a short side trail. The beaver “stacked” large sticks of similar sizes all along the down stream side of the dam. Farther in the trail crosses the Little Bear River on a forest road and then meanders along the river and continues on the H-40. You continue on and soon are walking the banks of the Trout Brook Pond. There is a good camp site as you near the dam.\n–Submitted by Stan Kujawa\nDriving Directions: (to get to the trailhead, starting location, etc) H-40 runs between Rudyard, MI and Trout Lake, MI. There is a trail head off of H-40 at Trout Brook Pond with a spur trail to the NCT across the dam. The Niagara Escarpment is just south of FS3323 where there is also a parking area. FS3323 is found off East Lake Road south of H-40 and north of the East Lake community.\nHiking Directions: Hike south from the spur trail after crossing the dam at Trout Brook Pond or hike from the Escarpment north as described above.\nLone Pine Road north to Dick Road\nLength: 5 miles\nDifficulty: Moderately Easy\nWhy Hike this section: I really enjoyed seeing so many different types of habitat within a short day hike. From mature forests to open clearings and from marsh to pines, this section has a little bit of everything. The scenic view overlooking Betchler Lakes is a must see as well. My absolute favorite part of my hikes through that section have been the seclusion. While I’ve only hiked it a couple of times thus far, I’ve never seen another person on the trail. Of course, this isn’t uncommon on many parts of the NCT in the eastern upper peninsula. As you can see from the picture(s) my Labrador retriever, Fletcher, enjoys this section almost as much as I do. God bless and happy hiking.\n– Submitted by Jameson Olson and his four legged hiking buddy, Fletcher\nDriving Directions: Dick Road (FS3139) runs between M-28 west of Soldier Lake Campground and East of Strongs south to H-40 east of Trout Lake and west of Rudyard. Lone Pine Road (FS3141) runs between Dick Road and M-123 north of Trout Lake. Park on Dick Road on the north end of this hike where the NCT crosses or park where the NCT crosses Lone Pine Road west of Dick Road near the Pine River.\nHiking Directions: Hike north from Lone Pine following the NCT to Dick Road or from north to south.\nC-500 to Tahquamenon Falls\nLength: About 7 miles\nWhy Hike this section: A great wilderness hike that provides a true northern experience. Hike hemlock ridges, northern bogs and marshes, pass a huge beaver dam and view the Upper Tahquamenon Falls before getting sustenance and refreshments at the Tahquamenon Falls Brewery located just off the NCT at the Upper Falls.\nDriving Directions: Drive on M-123 west past the entrance to the Upper Tahquamenon Falls to C-500 and drive north to the first crossing of the Little Two Hearted River. Parking along the roadside near the bridge.\nHiking Directions: Hike the NCT from C-500 into Tahquamenon Falls State park until reaching the Upper Tahquamenon Falls. Enjoy all the views!\nBrevort Lake Road to Brevort Lake Dam\nLength: 4 miles (or 8 if you do an out and back)\nWhy Hike this section: A perfect way to get a taste of the fixed dunes and varied forests located north of Lake Michigan, this hike is a pleasant way to spend a morning or an afternoon. Wonderful views of the Brevort river are found all along this route.\nDriving Directions: Take Brevort Lake Road north from US2 (10 miles west of Saint Ignace) to Dam Road, turn left and follow Dam Road to the end and park. There is also parking on the south end of this hike on the east side of Brevort Lake Road on a short dead-end Forest Service Road where the NCT crosses Brevort Lake Road.\nHiking Directions: Hike the NCT north from Brevort Lake Road to the Dam and then turn south to the Dam Road parking lot just before crossing the dam.\nHike Name: Salt Point Road to M-28\nLength: 6 miles\nDifficulty: Moderately easy\nWhy Hike this section: It is an absolutely beautiful hike through an occasional tunnel of trees. The damp earthly smells are wonderful and lift your physical, spiritual, and mental well-being! The forest types change often as you stroll through the immature and mature growth. Flowering plants decorate the forest floor throughout late spring, summer, and early fall. Small meadows offer a change of scenery and plant life. There are even a couple of pot hole lakes to view along the way.\nDriving Directions: The trail crosses M-28 between Raco and Strongs near Soldier Lake USFS Campground. Salt Point Road runs north out of Strongs and the trail can be accessed as it crosses Salt Point Road as well. If you are parking on the south end, park off the shoulder of the highway.\nHiking Directions: Hike north to south or south to north, both directions hike well. Follow the blue blazes!\nMackinac Bridge to M-28\nLength: 68.8 miles\nDifficulty: easy to moderate\nWhy Hike this section: From Terry Cathcart: The trail took me through a variety of forests, often canopied with ground cover of ferns and mosses. Then there were the wetlands where I welcomed the boardwalks that I presume were built by volunteers. The trail was easy to follow with the help of the blue blazes. I kept thinking of Theodore Roosevelt, the President who authorized the creation of the Hiawatha National Forrest and all the forest managers and conservationists and activists over the years who have worked to save a place like this for people like me. There is much that I could say about my five days of backpacking alone on the NCT. Two phrases come to mind. The first is from Psalm 42 and the words deep calls to deep. And the second is from an essay by Ali Schultz in which she writes of a sense of isolation from an expansive sense of connection to the quiet, profound, and intimate magic of the world around us. I experienced a profound sense of connection and emersion into this magic.\nDriving Directions: Cross the Mackinac Bridge (going north) and turn right to the Michigan Welcome Center. The trail starts on the back corner of the parking lot.\nHiking Directions: Follow the blue blazes to M-28! Enjoy!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:5c41511f-9eee-4c72-9f02-31fad8d66608>","<urn:uuid:5634c709-4606-47b2-8e54-6d21f73ecf2c>"],"error":null}
{"question":"In quanto professionista del settore IP, I need to understand both patent protection mechanisms and entertainment law litigation. What's the process for patent protection in the US, and how do entertainment lawyers handle litigation matters?","answer":"Patent protection in the US requires inventors to apply and receive approval from the US Patent and Trademark Office through a complex and time-consuming process. Patents prevent others from making, selling, or using the invention for a specified period. It's advisable to hire an intellectual property attorney to ensure proper filing and protection. Regarding entertainment law litigation, attorneys defend clients from lawsuits and file suits on their clients' behalf. They handle various litigation matters including production liability concerns, labor negotiations with union teams in television, movie, or theater contexts, and protection against costly lawsuits. Entertainment lawyers need to be well-versed in multiple legal fields due to the diverse nature of potential problems in the entertainment world.","context":["Intellectual Property Law\nIntellectual property (IP) is a legal concept which refers to creations of the mind for which exclusive rights are recognized. IP is defined as an intangible form of property, as opposed to personal property or real property, which is concrete and much more easily defined. Under intellectual property law, owners are granted rights to a variety of intangible assets, such as musical, literary, software, and artistic works; discoveries and inventions; as well as words, symbols, industrial processes, and designs. IP is the result of the creation of the brain or the mind, which is then manifested or interpreted in a form that has a physical existence and possesses exclusive property rights.\nIntellectual Property Law is the area of law that deals with the creation of intellectual property patents, copyrights, trademarks and trade secret laws; the protection of intellectual property rights; and the legal pursuit of those who infringe on those rights.\nThe purpose of intellectual property laws are to encourage new technologies, artistic expressions and inventions while promoting economic growth. When individuals know that their creative work will be protected and that they can benefit from their labor, they are more likely to continue to produce things that create jobs, develop new technology, make processes more efficient, and create beauty in the world around us.\nThere are three main mechanisms for protecting intellectual property in the United States: copyrights, patents and trademarks.\nCopyrights protect the expressive arts. They give owners exclusive rights to reproduce their work, publicly display or perform their work, and create derivative works. Such artistic and creative works as paintings, music, books, photographs, movies and software may be protected by copyright law.\nAdditionally, owners are given economic rights to financially benefit from their work and prohibit others from doing so without their permission. It is important to realize that copyrights do not protect ideas, only how they’re expressed.\nPatents protect an invention from being made, sold or used by others for a certain period of time. Inventors may not assume that their creation is patented unless they apply and are approved for a patent by the US Patent and Trademark Office. This process can be complex and time consuming. Copyrights and patents are governed exclusively by the U.S. Constitution and Congressional legislature, while both federal and state laws deal with trademarks and some aspects of unfair competition disputes. It is a good idea to hire an intellectual property attorney to make sure you file the appropriate paperwork and get the patent you need to protect your invention and make it profitable.\nStatute creates and governs trademarks, patents and copyrights, which represents ownership of an original idea for a limited period of time. Trademarks protect the names and identifying marks of products and companies. The purpose of trademarks is to make it easy for consumers to distinguish competitors from each other. Trademarks are automatically assumed once a business begins using a certain mark to identify its company, and may use the symbol TM without filing their symbol or name with the government.\nThere are strict laws in place to protect intellectual property rights. When intellectual property rights are violated, it is important to hire an intellectual property lawyer. An experienced attorney can help you sue for damages that include lost royalties. If your case is successful, the person who violated your intellectual property rights may be required to pay for all of your legal fees in addition to compensating you for using your work without your permission","There are a variety of benefits of hiring an entertainment lawyer. If you want to protect your original works in the media industry, a lawyer’s assistance can be valuable.\nAn entertainment attorney can provide legal assistance to individuals or businesses that are involved in the industry, including television, film, radio, recording, theater, publishing, and digital media. The world of media can be extremely diverse. However, entertainment law generally can be divided into two primary fields: litigation and transactions. Los Angeles entertainment lawyers focus their practices on a diverse number of areas that fall within these broad categories.\nChoose an Entertainment Lawyer in Los Angeles According to Your Niche\nAnyone who decides to become an entertainment attorney generally needs to be well-versed in many legal fields due to the wide variety of potential problems and opportunities that the entertainment world presents.\nLawyers who regularly represent actors and musicians generally need to know the ins and outs of contracts, but they also need to know the details of intellectual property law to protect their clients. Attorneys who represent film producers generally need to know the basics of distribution rights, too. Networks can turn to attorneys to help protect themselves from costly lawsuits.\nWithin these two categories are multitudes of possible job responsibilities for an entertainment attorney. Possible tasks could include talent contracts and agreements; labor negotiations with union teams within the television, movie, or theater context; rental of equipment and spaces for the performing arts; licensing and regulatory affairs; copyright protection; and production liability concerns. The expansion of digital media has also opened up an entirely new field of potential entertainment law concerns.\nTransaction-Based Entertainment Law\nOf the two basic categories of entertainment law, transaction law generally requires entertainment lawyers to focus on contracts and deals. Attorneys in this capacity could be involved in drafting contracts for their clients, negotiating better agreements, or ensuring that agreements are properly enforced. For matters involving litigation, attorneys can defend their clients from lawsuits, as well as file and pursue lawsuits on their clients’ behalf.\nMany entertainment attorneys who are fortunate enough to land positions in this highly competitive field often begin their careers as associates at well-known law firms.\nIn the United States, the majority of attorneys who practice entertainment law are concentrated in Los Angeles and New York, which are the two cities that are responsible for the majority of film, television, music, theater, and publishing productions in the country.\nAreas of Focus for Intellectual Property Lawyers\nIntellectual property largely involves three areas: copyright, patent, and trademark.\nCopyright refers to the legal right over intellectual property that the creator or owner of an original work possesses. The people who use another party’s protected intellectual property are required to have express authorization from the creators or owners of the content. Copyrights in the media industry help creators to further their business by allowing them to monetize their intellectual property through licensing agreements.\nIf someone is involved in creating a technical invention, then they can seek patent protection for their intellectual property. A patent gives the holder the authority to prevent others from using their intellectual property for commercial gain to the patent holder’s detriment. Patents are exclusive rights that are given to an inventor, and that includes decisions about whether third parties may use it.\nA trademark is used to identify goods or services, and it guarantees the owner the exclusive right to use the mark, protecting the trademark owner from third parties’ unauthorized use of the trademark. A person can authorize others to use their trademark in return for monetary compensation. Los Angeles Trademark lawyers can provide valuable guidance to business owners and enterprises.\nBenefits of Trademark Registration\nOnly the trademark owner can use the intellectual property and exploit it for commercial gain. When a mark is properly registered and monitored, the risk of misuse, copying, or imitation can be significantly reduced. The asset holder may take legal action against imitators and misusers.\nThe risk of an identical or similar trademark being used and registered by a third party can be significantly reduced. Investment in advertising can be a long-term benefit to a company, and it can be a solid foundation for building a brand. This is why hiring a trademark lawyer for your enterprise can be so important.\nBranding allows a business to differentiate its products or services from others within the market.\n- Industrial designs\nA trademark or entertainment lawyer can help you register your technical design, as well.\n- Geographical indications\nThese are signs that businesses may use to differentiate products that have a specific geographic origin that makes them possess particular characteristics or qualities.\n- Trade secrets\nTrade secrets are a type of intellectual property that protects confidential information, which may be essential to a business’s success.\nShould I Hire an Intellectual Property Lawyer?\nPatents, copyrights, and trademarks can be important to anyone who may be considering setting up a business or functioning in a sector related to creation and entertainment. These are very important concepts that help intellectual property owners protect their rights, and a trademark lawyer Los Angeles trusts can provide valuable guidance to help your business.\nProperly protecting intellectual property can be challenging to manage, but it can also generate innumerable benefits for companies, allowing brands to differentiate their products or services within the market and monetize their assets. The work focuses on protecting and defending IP owners rights."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:0ae39889-d3d8-4840-a777-e17522ff08e2>","<urn:uuid:fe552844-de36-4ac9-9743-b6fdf60e694e>"],"error":null}
{"question":"Could you compare the architectural significance of Framlingham Castle and Someries Castle in terms of their construction materials and historical importance to English architecture?","answer":"Both castles represent significant but different architectural achievements. Framlingham Castle's walls were built of flint and septaria, reaching approximately 10.5 metres high and 2.3 metres thick. Meanwhile, Someries Castle is notably one of the earliest surviving brick buildings in England, with walls surviving almost to full height of about 10m. While Framlingham Castle features 13 tall towers along its curtain wall in a rough circle, Someries Castle's remaining structure includes a gatehouse with two semi-octagonal bastions and a rectangular chapel with a large perpendicular window.","context":["|Location||Framlingham, Suffolk, England (Google Maps)|\n|Open to Visitors||Yes|\n|Owned by||English Heritage|\n|Official Website||Framlingham Castle|\n|Rooms Available||Yes (Weddings, Events)|\nFramlingham Castle is a magnificent 12th Century Norman Castle surrounded by parklands and estate grounds, attracting visitors from all over the world each year. The castle has a rich and significant history with beautiful stories to relay.\nFramlingham Castle was one of the castles built by Roger Bigod II, a member of the affluent and influential Bigod family also called the Earl of Norfolk. However, no sooner after being built, the castle was sieged by King John after the relations between him and Roger soured. The cause of this distress was that Roger, along with 25 other barons, challenged the higher military taxes levied by the king. The siege was only temporary, after which it was again restored to the Bigod family. Later in the 14th century, the castle passed on to the Brotherton family, and after a brief period of time, it passed on to the Howard family in 1483.\nThe castle came into the hands of Mary Tudor, elder daughter of Henry VIII, in 1552. After being declared as the ruler, she reinstated the estate to the Howard family. In 1635 the castle was bought by Sir Robert Hitcham, a philanthropist, and lawyer and after his death, it was declared as a home for the poor. The home was built after the castle buildings were demolished. The castle has been managed by the English Heritage since 1984 and is open to the public.\nThe medieval castle was built to impress with 13 tall towers along the curtain wall shaped in a rough circle. The main entrance to the castle is the gatehouse, a Tudor re-modelling of the original Norman gateway protected by drawbridge and portcullis. The castle walls are approximately about 10.5 metres high, 2.3 metres thick, and are built of flint and septaria. Presently, there are remains of the windows and fireplace, which gives an idea about the location of the chambers. Today, the largest building remaining inside the castle walls is Framlingham Castle’s workhouse, which was built on the remains of the great hall in the old structure in 1729.\nFrequently Asked Questions\nWhat is Framlingham Castle famous for?\nThe magnificent Framlingham Castle is known as a landmark today as it was the place where Mary Tudor or Mary I was first proclaimed Queen of England.\nHow much does it cost to get into Framlingham Castle?\nThe cost to visit Framlingham Castle is different for adults and children. The standard price for adults is £11.30 per person and £6.80 for children. It is not necessary to book your visit in advance, but you will get the best price and a guaranteed entry by booking online prior to your visit.\nWhy was Framlingham Castle built?\nFramlingham Castle was built as a stronghold and as a symbol of power and status by Roger Bigod in the 12th Century.\nHave you visited this castle before? If yes, why not share some beautiful pictures with us!\nYou can email us your pictures of the castle at firstname.lastname@example.org. Please use the name of the castle in the subject line.\nAlso, don’t forget to mention your name and social media profile link if you want the credits!","Someries Castle: a medieval magnate's residence and formal garden remains\nList Entry Summary\nThis monument is scheduled under the Ancient Monuments and Archaeological Areas Act 1979 as amended as it appears to the Secretary of State to be of national importance. This entry is a copy, the original is held by the Department for Digital, Culture, Media and Sport.\nName: Someries Castle: a medieval magnate's residence and formal garden remains\nList entry Number: 1008452\nThe monument may lie within the boundary of more than one authority.\nDistrict: Central Bedfordshire\nDistrict Type: Unitary Authority\nNational Park: Not applicable to this List entry.\nGrade: Not applicable to this List entry.\nDate first scheduled: 26-Jun-1924\nDate of most recent amendment: 06-Sep-1995\nLegacy System Information\nThe contents of this record have been generated from a legacy data system.\nLegacy System: RSM\nThis list entry does not comprise part of an Asset Grouping. Asset Groupings are not part of the official record but are added later for information.\nList entry Description\nSummary of Monument\nLegacy Record - This information may be included in the List Entry Details.\nReasons for Designation\nMagnates' residences are high status dwellings of domestic rather than\nmilitary character. They date from the Norman Conquest (in some cases forming\na continuation of a Saxon tradition) and throughout the rest of the medieval\nperiod. Individual residences were in use for varying lengths of time; some\ncontinued in use into the post-medieval period. Such dwellings were the houses\nor palaces of royalty, bishops and the highest ranks of the nobility, usually\nthose associated with the monarch. They functioned as luxury residences for\nthe elite and their large retinues, and provided an opportunity to display\nwealth in the form of elaborate architecture and lavish decoration. As such,\nthese palaces formed an impressive setting for audiences with royalty, foreign\nambassadors and other lords and bishops.\nMagnates' residences are located in both rural and urban areas. Bishops'\nresidences are usually in close association with cathedrals, and all\nresidences tend to be located close to good communication routes. Unless\nconstrained by pre-existing structures, magnates' residences comprised an\nelaborate series of buildings, usually of stone, that in general included a\ngreat hall, chambers, kitchens, service rooms, lodgings, a chapel and a\ngatehouse, arranged around a single or double courtyard. As a consequence of\nthe status of these sites, historic documentation is often prolific, and can\nbe of great value for establishing the date of construction and subsequent\nalterations to the buildings, and for investigating the range of activities\nfor which the site was a focus.\nMagnates' residences are widely dispersed throughout England reflecting the\nmobility of royalty and the upper echelons of the nobility. There is a\nconcentration of sites which reflects the growing importance of London as a\npolitical centre, and the majority of magnates' residences tend to be located\nin the south of the country. Despite their wide distribution, magnates'\nresidences are a relatively rare form of monument due to their special social\nstatus. At present only around 236 examples have been identified of which 150\nare ecclesiastical palaces and 86 are connected with royalty. Magnates'\nresidences generally provide an emotive and evocative link with the past,\nespecially through their connections with famous historical figures, and can\nprovide a valuable educational resource, both with respect to the organisation\nand display of political power, and wider aspects of medieval and post-\nmedieval society such as the development of towns and industries and the\ndistribution of dependent agricultural holdings. Examples with surviving\narchaeological potential are considered to be of national importance.\nAlthough only the gatehouse and the chapel at Someries Castle survive as upstanding structures, the positions of the principal range and inner courtyard are indicated through joints and markings in the fabric of the walls. A substantial brick footing lies towards the north east corner of the site indicating the survival of buried foundations. Documentary evidence indicates a predecessor to the known structures which may also exist in the form of buried archaeological features. The surviving remains provide important evidence for the interpretation of similar buildings for which only the ground plan is known. Someries Castle is one of the earliest surviving brick buildings of this type in England and is therefore of great significance for the study of the development of construction techniques in brick. The importance of the monument is further enhanced by its accessibility to the public.\nFormal gardens are usually found in direct association with the dwellings of high-ranking individuals in society and are a further indication of the status of such buildings. Early gardens tend to follow a rigid design and were often elaborate earthworks, with gravel paths and raised borders.\nThe formal garden at Someries Castle is a well preserved example with a central raised mound, traces of paths and flowerbeds and surrounding terraces. The presence of the adjacent remains of the magnate's residence enhances the importance of the gardens by allowing the two related sites to be studied in conjunction with each other.\nLegacy Record - This information may be included in the List Entry Details.\nThe monument includes both upstanding and buried foundations of the late\nmedieval magnate's residence known as Someries Castle and the adjacent\ngarden earthworks to the south west. The monument lies beside an old road\nbetween Luton and Kimpton and is situated on a plateau of the Chilterns to\nthe east of the Lea Valley. The upstanding remains include the gatehouse\nand chapel forming the north west wing of the magnate's residence. Although\nthe roof has gone, the walls survive almost to full height, an estimated 10m.\nThe gatehouse is built in imitation of a castle gateway, with two semi-\noctagonal bastions on either side of the entrance passage which passes through\nthe building and would have given access to an enclosed courtyard. The\nrectangular chapel, measuring 16m long by 5m wide, extends to the north east\nof the gatehouse and has a large perpendicular window opening in the gable.\nOn the outer face of the south east wall of the chapel may be seen the\nabutment of the north east wing which is now demolished to ground level. The\narea occupied by the main block of the residence is defined by a raised\nplatform containing low, irregular earthworks to the north east of the\ngarden earthworks. Traces of a substantial brick wall are visible in the\nnorth east corner of the site.\nThe formal garden remains are represented by a rectangular earthwork,\nmeasuring a maximum of 100m long by 80m wide. A square mound, 40m by 40m, is\nplaced centrally within the earthwork. There is a slight bank forming a border\naround the perimeter of the mound which is quartered by two, 2.5m wide, raised\nwalkways indicating the positions of ornamental flowerbeds. Both the borders\nand the paths are less than 0.2m high. The mound stands about 1m above the\nsurrounding broad, level area which extends beyond the base some 18m to the\nnorth east and south west, and about 8m to the north west and south east. This\nflat area is bounded by a flat-topped bank averaging about 6m wide, though\nboth the corners and the north east sides are slightly wider. From the inside,\nthe bank stands about 1m high but externally it rises to about 1.5m above the\nbottom of a surrounding ditch. This ditch is generally about 4m wide except\nalong the north eastern arm where it is up to 8m wide. A further low bank\ndefines the outside edge of the ditch. It is about 3m wide and survives to a\nheight of 0.3m to 0.4m, except on the north west side where it has been\nincorporated into a later boundary. The circuit of the surrounding banks is\nbroken on the north west side by a 10m wide ramped causeway leading into the\ncentre of the garden. The earthworks are at their largest and most impressive\non the north east side where they face onto the magnate's residence.\nA small excavation was undertaken across the earthworks in 1969. Although they\ndid not proceed much below the topsoil, the investigations revealed that the\nbottom of the ditch was lined with a horizontal bed of stones. Pottery of the\n13th to 16th centuries and small amounts of building material were recovered.\nThe name Someries Castle is derived from William de Someries, whose residence stood on the site in the 13th century. The exact location of his manor house is not known but in the 16th century the antiquarian John Leland noted that the remains of an `old palace' could be seen. The garden earthworks, whilst bearing a superficial resemblance to a medieval moat, are firmly in the tradition of the formal gardens of the 16th and 17th centuries. The adjacent magnate's residence was built by Lord Wenlock, who acquired the Someries estate in the 1430s. The mansion is thus thought to be one of the earliest brick buildings in England. After Wenlock's death, the estate passed to Thomas Rotherham, Bishop of Lincoln and later Archbishop of York; King James I stayed here with one of Rotherham's descendants in 1605. The palace was never completed, although an inventory of 1606 lists 20 rooms in use. Much of the building was pulled down in 1742 and subsequent 18th-century prints show the ruins largely in their present condition.\nThe following items are excluded from the scheduling: the modern sheds overlying the magnate's residence, fences at the sides of both the garden earthworks and the magnate's residence, and the walls and railings around the standing ruins, although the ground beneath all these features is included.\nMAP EXTRACT The site of the monument is shown on the attached map extract.\nBooks and journals\n'The Bedfordshire Magazine' in The Bedfordshire Magazine, , Vol. XI, (1969), 344-347\nSmith, T P, 'Beds Arch Journal' in Someries Castle: some reconsiderations, , Vol. 5, (1970), 109-112\nSmith, T F, 'Journal ofthe British Archaeological Association.' in The Early Brickwork Of Someries Castle, , Vol. CXXIX, (1976), 42-58\nBeds 360 appended report,\nTitle: Ordnance Survey 25\" Series Source Date: 1890 Author: Publisher: Surveyor:\nNational Grid Reference: TL 11916 20141\nThe above map is for quick reference purposes only and may not be to scale. For a copy of the full scale map, please see the attached PDF - 1008452 .pdf\nThe PDF will be generated from our live systems and may take a few minutes to download depending on how busy our servers are. We apologise for this delay.\nThis copy shows the entry on 21-Sep-2018 at 12:30:40.\nEnd of official listing"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:deca13af-1015-46d2-bb04-4553c5f58384>","<urn:uuid:818d6ca1-c2f2-45ee-83de-5476d075feb0>"],"error":null}
{"question":"How do treaties function in US governance, and what role do they play in international environmental protection?","answer":"In US governance, treaties are binding agreements that establish rights, duties, and obligations, requiring presidential negotiation and Senate approval by a two-thirds vote. They can cover various matters like territorial boundaries, trade, and mutual defense. In international environmental protection, treaties serve as crucial tools for addressing transboundary and global environmental problems, establishing standards, and developing environmental law principles. They require international regulation and solutions, particularly because environmental issues transcend national boundaries and affect shared resources.","context":["What does it mean to approve treaties?\nRatification defines the international act in which a state indicates its consent to be bound to a treaty if the parties intended to show their consent by such an act. The term applies to private contract law, international treaties, and constitutions in federal states such as the United States and Canada.\nWhich branch of government can approve treaties?\nThe United States Constitution provides that the president “shall have Power, by and with the Advice and Consent of the Senate, to make Treaties, provided two-thirds of the Senators present concur” (Article II, section 2).\nDoes the legislation implement treaties?\nUnder U.S. law, a treaty is an agreement negotiated and signed by a member of the executive branch that enters into force if it is approved by a two-thirds majority of the Senate and is subsequently ratified by the President.\nCan the legislative branch approve or reject treaties?\nThe Constitution gives the Senate the power to approve, by a two-thirds vote, treaties negotiated by the executive branch. The Senate does not ratify treaties. In debating the issue, the framers addressed concerns that entrusting the appointment power exclusively to the president would encourage monarchical tendencies.\nDo treaties require Senate approval?\nThe Constitution gives to the Senate the sole power to approve, by a two-thirds vote, treaties negotiated by the executive branch. The Senate does not ratify treaties. The Senate of the First Congress set the precedent for how it would handle treaty consideration.\nHow do you implement treaties?\nSteps to Implement an International Treaty\n- Mandate to Enter a Treaty. Before formal negotiations for a treaty commence, the minister who wishes to create and enter into a treaty must seek permission to negotiate the treaty from the Minister of Foreign Affairs or Cabinet.\n- Review by Parliament.\nWhat are the purposes of treaties?\nTreaties are roughly analogous to contracts, in that they establish the rights, duties, and binding obligations of the parties. They vary significantly in form, substance, and complexity, and may govern a wide variety of matters, such as territorial boundaries, trade and commerce, mutual defense, and more.\nWhich branch may reject treaties?\n|Legislative Branch (congress)||Executive Branch: May reject treaties, appointments, refuse funding for presidential presidential initiatives, may impeach president, override veto. Judicial Branch: May propose amendments to overrule judicial decisions, may impeach Supreme Court Justices|\nCan a treaty change?\nAmendments. Treaties can also be amended informally by the treaty executive council when the changes are only procedural, technical change in customary international law can also amend a treaty, where state behavior evinces a new interpretation of the legal obligations under the treaty.\nHow are treaties considered in the legislative process?\nIn the legislative process, treaties are treated very much like bills: they are referred to the Foreign Relations Committee, where they may be considered and reported. The Senate can consider a treaty on the floor under similar procedures used for legislation.\nHow does the United States ratify a treaty?\nThe Constitution gives the President the power to commit the United States to treaties – but only with the advice and consent of two-thirds of the US Senate, and only if the agreement does not contravene the Constitution. The process to ratify a treaty may be lengthy, but it is relatively straight forward:\nWhat is the role of the Senate in a treaty?\nThus, since the early Republic, the Clause has not been interpreted to give the Senate a constitutionally mandated role in advising the President before the conclusion of the treaty. Also of substantial vintage is the practice by which the Senate puts reservations on treaties, in which it modifies or excludes the legal effect of the treaty.\nHow are treaties made in the United States?\nThe United States Constitution provides that the president “shall have Power, by and with the Advice and Consent of the Senate, to make Treaties, provided two-thirds of the Senators present concur” ( Article II, section 2 ). Treaties are binding agreements between nations and become part of international law.","Presentation on theme: \"INTERNATIONAL LAW AND ENVIRONMENTAL PROTECTION 1 Environmental Law.\"— Presentation transcript:\nINTERNATIONAL LAW AND ENVIRONMENTAL PROTECTION 1 Environmental Law\nInternational Environmental Law 2 The Importance of International Environmental Law Regulation at international as opposed to national level Global environmental problems have global /regional /national dimensions Environmental problems not contained within national/territorial boundaries Environment is shared. Need to protect environment is paramount in relationship between States\nInternational Environmental Law 3 Transboundary and global environmental problems require international regulation and solutions International agreements /treaties /conventions establish standards International agreements have developed principles of environmental law Recent focus on procedures and incentives to secure compliance\nInternational Environmental Law 4 What is international environmental law? How is it made? What forms does it take? What is the role of international environmental law? How effective is international law in protecting the environment? How is effect given to it in the nation State? How has it developed?\nInternational Environmental Law 5 Development The Trail Smelter Case (USA v Canada) 1941 A neighbouring State has no right ‘to use or permit the use of its territory in such a manner as to cause injury by fumes in the territory of another or the properties therein.’ Serious harm and the ‘establishing of the facts through clear and convincing evidence.’\nInternational Environmental Law 6 United Nations Conference on the Conservation and Utilisation of Resources (UNCCUR) 1949 Addressed global issues ; used economic concepts to assess minerals, fuels and energy, water, forests and land, wildlife and fish; conservation; new technologies assessed; education strategies adopted; respective economic situations of developed and developing countries determined approach; integrated development of river basins policy.\nInternational Environmental Law 7 Conservation on Law of the Sea 1954 Atmosphere 1955 – issue of nuclear testing = Test Ban Treaties 1955 International Maritime Organisation first met 1954 1971 Ramsar Convention on Wetlands 1972 Stockholm Convention on Human Environment Use and Conservation Action Plan; Declaration (26 Principles) – Principle 21 * United Nations Environment Programme (UNEP)\nInternational Environmental Law 8 1987 World Commission on Environment and Development Our Common Future Brundtland Report Sustainable Development. 1992 UN Conference on Environment and Development - Rio – 176 States attended. Rio Declaration Convention on Biological Diversity Framework Convention on Climate Change Agenda 21\nInternational Environmental Law 9 Relationship with national law International law = relationship between States International law is not directly enforceable in the national legal system in the United Kingdom Treaties need to be ratified by government Need to be given effect by Parliament Treaties are required to be given effect by implementation of national legislation Only then has international law direct application\nInternational Environmental Law 10 The Sources of International Law Hard and Soft Law 1. Treaties –bind State in relations with other States 2. 2. Customary International Law Implicit; Influence; Flexible Facilitative of development of principles of International environmental law Requires State practice + conviction that legally bound\nInternational Environmental Law 11 3. Judicial Decisions – International Court of Justice Three cases heard per year Absence of binding precedent – binding inter partes Authority accepted by less than 1/3 of UN; Delay International Lawyers opinions have considerable influence on development of international law Nuclear II case New Zealand v France  ICJ Rep 288 States have responsibilities not to cause environmental damage beyond national or jurisdictional boundaries\nInternational Environmental Law 12 4.Soft Law (Advantages over binding law) Declarations Consolidate Move principles towards customary status Reflect agreed international political aspirations Principles Sustainable Development-duties to future generations Common but differentiated responsibilities (climate) Recommendations. Standards.\nInternational Environmental Law 13 Effectiveness? No Enforcement Body Limited role of Court Depends on implementation and monitoring provisions in each Treaty Institutions Procedures NGO’s Collating information Liability compensatory regimes / hazardous activities Public participation new direction?"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:bb740c97-51f5-4a5a-8603-24f6380ec259>","<urn:uuid:addd95ba-be2f-417d-8182-f90d8cb46c33>"],"error":null}
{"question":"How do new naval vessel designs address both maintenance efficiency and environmental impact?","answer":"New naval vessel designs incorporate multiple features addressing maintenance and environmental concerns. On the maintenance side, amphibious ships are receiving comprehensive overhauls costing $100 million each, plus $40-50 million for corrective maintenance, focusing on mechanical and electrical systems. Steam heating is being replaced with electric systems to reduce maintenance needs. On the environmental front, innovative hull designs like the Air Supported Vessel (ASV) technology demonstrate significant environmental benefits through markedly reduced hull resistance, with tank testing showing up to 50% reduction in resistance and over 40% reduction in power requirements. These improvements contribute to both reduced maintenance requirements and lower environmental impact through decreased fuel consumption.","context":["working and collaborating with regional maintenance\ncenters, which perform repairs as well as corrective\nand preventative maintenance.\n“The better you maintain the less you have to do for\nrepair,” he said.\nWhile his office takes on the role of “modernizer,” it\nworks “collaboratively” with the regional repair centers to track the readiness of the ships, Graham said.\nPreparing a plan for a midlife overhaul of amphibious ships entails several years of coming up with recommendations and a list of priorities.\n“Our largest collaborative forum is an operational\nadvisory group. That is an opportunity for the warfighter\nor the waterfront fleet personnel … to go over the challenges that they have seen out there,” Graham said.\n“Some things are just a change in a doctrine or maintenance procedure, but when you get to a point where you\nchange hardware on the ship … that is when we step in.”\nThe latest advisory forum took place at the beginning of July.\nMeanwhile, Graham’s office is working to increase the\nlifespan of the Whidbey Island ships. He said the Navy\nplans to overhaul 12 ships in the class at a price of $100\nmillion each, with an additional $40 million to $50 million per vessel for corrective maintenance and repair work.\nThe Navy is mainly tackling mechanical and electrical systems in the ships’ hulls, but also is working on\nmission-enhancement and survivability issues.\nEach ship will receive a new propulsion load-management unit, which allows it to operate more efficiently as it propels through the ocean. It basically is\nmore modern technology that provides for a more proficient interface between the ship’s engine and propellers.\nThe new technology helps the ship go faster and saves\nabout 8 percent in fuel consumption, Graham said.\nThe dock landing ships also will be outfitted with\nnew air conditioning units, and all the steam heating\n(for cooking and laundry) will be replaced with an\nelectric heating system.\n“That is a huge manpower reducer for the ship as far\nas maintaining all those steam systems and operating a\nboiler on primarily a diesel ship,” Graham said.\nThe ship’s helm unit also is being replaced with modern control systems, as well as new control consoles for\nthe propulsion engine and electrical generators.\nAs far as increasing ship survivability, the Navy conducts a so-called inclining experiment by which a ship\nis measured and a weight is placed in it to see how\nmuch it keels over to determine the stress on the structure from loading and offloading equipment.\nThis is especially important as ships handle new\ncargo that is urgently needed by ground forces. A key\nexample is the very heavy, up-armored Humvees and\nthe Mine Resistant Ambush Protected vehicles needed\nAn MV- 22 Osprey attached to Marine Medium Tiltrotor\nSquadron 263 takes to the air from the flight deck of the\nmultipurpose amphibious assault ship USS Wasp Sept. 29,\n2007, in the Mediterranean Sea.\nto protect Marines and Soldiers from improvised\nexplosive devices in Iraq and Afghanistan.\n“Having the incline information will help to load up\nthe ship smartly,” Graham said.\nAdditionally, the Navy is replacing the control system of the crane that places assault boats into the\nwater, which Graham called a “pretty valuable tool.”\nMeanwhile, plans are under way to make changes to\nthe Wasp class LHDs so they can accommodate the V-\n22. The changes involve providing storage for new\nparts as well the machinery needed to support the aircraft on deck. USS Wasp, Essex and Bataan already have\ndeployed with the Osprey.\nIt costs about $45 million per ship to make the\nadjustments to accommodate the V- 22, Graham said.\nThe actual midlife maintenance on the ships will start\nin fiscal 2013.\nThe service’s newest amphibious class, the San Antonio\namphibious transport dock ship, has a couple decades to\ngo before it needs extensive midlife maintenance.\nMeanwhile, the oldest amphibious class, the Tarawa-class amphibious assault ships (LHAs), already had its\nmajor overhaul and two of the original five LHAs have\nbeen decommissioned. The America class LHA will\nreplace the Tarawa class after 2013 and increase the aviation capacity of future big deck amphibious ships in order\nto maximize the Navy’s investment in future aircraft.\nThe America class, also known as the LHA\nReplacement, is the next step in the incremental development of the “big-deck amphib.” The class is being\ndesigned to accommodate the Marine Corps’ future aviation combat element — including the F-35B and MV- 22\nOsprey — with additional aviation maintenance capability and increased fuel capacity, while also providing more\ncargo stowage capacity and a broader, more flexible command and control capability. ■","Effect Ships International AS (ESI) is reporting extraordinary results from tank testing of two Air Supported Vessel (ASV) hull forms, a catamaran- and a mono candidate. A reduction in hull resistance of up to 50%; or more than 40% net powering cut, after deduction of fan powering, has been documented with the ASV mono concept.\nLately, air assisted hulls forms have gained increasingly more interest from the maritime sector. In December 2011, Marine Link, presented results from Marin on air lubrication techniques, reporting claims of up to 15% power reduction for” inland ships operating at normal speeds”. In January 2012 Mitsubishi referred to their Mitsubishi Air Lubrication System (MALS) pumping air bubbles onto a ship’s hull to reduce friction, claimed to reduce the power and fuel consumption by up to 10%.\nSo which one is the better to reduce hull water resistance and fuel consumption, air supported technique, air lubrication or air bubbles?\nUlf Tudem, spokesperson for ESI, comments: “It is unquestionable that a full separation between the vessel’s hull and water, by means of a proper layer of air (ASV) will reduce resistance more than use of an air and water mix (air lubrication) on the same underwater area. “Bubbling the hull” will have the least hull resistance reducing effect of the three concepts. However, a fair assessment must be carried out on vessels of similar size, weight and speed with the same operational conditions. The high fuel cost is forcing the industry to look outside the box for more efficient solutions. A significant reduction in fuel consumption will not only reduce operational cost but will also positively influence the second hand value of the most economical to operate ships. The environmental benefits will also play an important role.”\nIn BB GREEN, a project under EU 7th Framework, a seven partner strong European consortium is developing the world’s first Zero emission fast ASV commuter ferry, to be operated on battery power only; and with a design speed of 30 - 35 knots. The vessel will have a length of approx 20 m with a beam of 6 m; and will be designed to carry up to 100 Pax and a number of bicycles.\nThe first hurdle to overcome is to develop a hull with a markedly reduced hull resistance, and with load carrying capability to handle the weight of the battery pack and passengers.\nThe BB GREEN ASV Mono hull, now tank tested at SSPA, is designed for relatively sheltered waters. Low hull resistance over a wide range of speeds and modest wake wash have been key design objectives. State of the Art planing hulls has been used as the bench mark. Resistance tests were carried out at speeds from 10 knots all the way to 50 knots, full scale values.\nTo the amazement of the SSPA test team the ASV displayed a very low resistance already from 10 knots, corresponding to approx half that of the planing craft. Between 15 and 35 knots the hull resistance curve was almost flat, and above this speed the increase was modest.\nWake wash was also pleasantly low, and well below the levels set by the Dutch Authorities for operating i.e. around Rotterdam, which is a targeted operational area for the BB GREEN. Dutch ferry operator\nAqualiner is the end user partner in the project.\nESI will soon start another ASV Mono project; design development of a 24 m fast ASV Environmental Ferry, for operation on routes along the Norwegian coast. A soft motion hull form will be developed tailor made for use of Volvo Penta\nIPS propulsion system. The project will be supported by Innovation Norway. Collaboration partners will be Br. Aa, Diab and ferry operator Torghatten Nord. SSPA (Sweden) and Studio Sculli (Italy) will also contribute.\nIn Indonesia the first ASV fast crew boat is under construction, a 22 m constructed by Pt. Eka Multi Bahari.\nESI is a leader in design of air supported hulls with more than 10 years dedicated research and development leading to their worldwide patented ASV technology. The company has already successfully tested\na range of ASV catamaran hulls\nfor fast ferries as well as 125 m + RORO/ROPAX designs\n. Tank testing at SSPA Sweden has been frequently used. More than 1.200 fully instrumented test runs have been completed. In addition large manned models have been tested at sea, research supported by EU (5th Framework project EFFISES), Norwegian Research Council and Innovation Norway. ESI has also produced a 20 m full size ASV mono vessel, demonstrating a 50 + % fuel consumption reduction over comparable market leading conventional vessel at a wide range of speeds."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:c88636b6-9de5-4a77-a61d-0e6c7580cc31>","<urn:uuid:a9ba94cb-20ad-48a9-85fb-b6f1f37e64a5>"],"error":null}
{"question":"How does vitamin E supplementation potentially improve the quality of beef and dairy products?","answer":"Vitamin E supplementation has been shown to prolong the shelf life of beef when fed to cattle before slaughter. In dairy cattle, it appears to have a positive effect on both the flavor of milk and cheese yield.","context":["Vitamin E (tocopherol) is best known for its immune-boosting function. It serves as an antioxidant, working with selenium to eliminate free radicals. It also helps to repair damage to the body, and ensures the health of the white blood cells. Because of this important role, and its function as a structural component of various membranes, vitamin E is necessary for the function of just about every system in the body.\nThis vitamin is involved in many complex interactions with other nutrients. Its relationship with selenium has already been mentioned. Research suggests that vitamin E may also aid in the synthesis and metabolism of a number of other vitamins and minerals:\nVitamin E is one nutrient that animals cannot synthesize. Plants, however, produce vitamin E in abundance, making all green, growing forages and fresh, minimally processed grains good sources. Oils derived from grains are also high in vitamin E, provided that they are fresh.\nDogs and cats can use the vitamin E stored in the tissues of other animals. Liver and fatty meats are good sources. Raw or lightly cooked eggs are also suitable, as are nuts, wheat germ, and green vegetables.\nCauses of Deficiency\nOne common cause of vitamin E deficiency is stress, including injury, illness, and high levels of performance.\nIn grazing animals, a deficiency can be brought about by insufficient amounts of fresh forage in the diet. Sometimes this is caused by drought, while in other cases confinement is the problem.\nIn pets, particularly cats, a deficiency can be caused by high levels of unsaturated fats, including those found in tuna. Vitamin E is required to protect the body from free radical damage caused by these types of fats, so the higher the level of unsaturated fat in the diet, the higher the requirement for vitamin E will become.\nAll animals eating grain are at risk for vitamin E deficiency if their rations are not high-quality. Unfortunately, this vitamin is rather unstable and will break down quickly under less-than-ideal conditions. Factors that may cause deterioration of vitamin E in feeds include:\n- Rancid oils (unsaturated fats).\n- High temperatures.\n- Prolonged storage times.\nSymptoms of Deficiency\nUnfortunately, a vitamin E deficiency can sometimes be hard to identify because of its wide range of symptoms. Some of the symptoms that might occur include:\n- Lowered immune system.\n- Fever in cats.\n- Separation from the herd or flock.\n- Eye problems.\n- Difficulty swallowing.\n- Poor skin health.\n- Reduced wool production.\n- Increased levels of external parasites.\n- Muscle pain.\n- Muscular dystrophy (most common symptom in all species).\n- Arched back.\n- Difficulty standing.\n- Muscle tremors.\n- Varying degrees of paralysis.\n- Difficulty breathing.\n- Weak pulse.\n- Increased heart rate.\n- Cardiac arrhythmia.\n- Blue extremities.\n- Lack of appetite.\n- Metabolic disorders.\n- Severe abdominal pain in cats.\n- Lumps in fatty tissues in cats.\n- Dark urine.\n- Low fertility.\n- Retained placentas.\n- Reduced milk production.\n- Weak offspring.\n- Poor growth.\n- Sudden collapse.\nSymptoms of Toxicity\nVitamin E appears to be safe for most pets and farm animals. There are questions as to whether excessive supplementation may reduce milk production and meat tenderness, but this is not certain at the present time. The only known effect of excess vitamin E on pets and most types of livestock is exacerbation of a preexisting vitamin K deficiency.\nChickens, however, have a lower tolerance threshold for vitamin E supplementation than other types of livestock. Symptoms of toxicity include:\n- Exacerbation of preexisting vitamin K deficiency.\n- Waxy feathers.\n- Reduced pigmentation in beaks, legs, and feet.\n- Reduced growth.\nOne of the main uses of vitamin E in livestock is to prevent muscular dystrophy and sudden death in young animals.\nThe immune-boosting role of this vitamin can also be used to advantage in some cases. For instance, vitamin E is routinely used to ward off disease in stressed calves, can help laying hens cope with heat stress, and is often beneficial for pets suffering from allergies, skin problems, heart disease, and a variety of autoimmune problems. It may also help animals return to health after an illness, as well as slow the aging process.\nVitamin E may improve reproductive performance in a number of ways, as well. It is sometimes used to treat infertility in horses. In sheep, it shows potential to improve lamb weaning weights.\nStudies suggest that supplementation may increase the quality of animal-derived foods. For instance, vitamin E is known to prolong the shelf life of beef when fed to cattle before slaughter. It also appears to have a positive effect on the flavor and cheese yield of milk when given to dairy cattle.\nContent regarding medical conditions and treatment is provided for general information purposes only, and is not to be construed as legal, medical, or professional advice. Please consult your veterinarian for advice regarding your specific animal’s needs."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:0cf2cd80-1080-43f7-b3dd-37d7c7166dd4>"],"error":null}
{"question":"I'm working with some math concepts. Could you explain the difference between how functions and antisymmetric relations handle ordered pairs of elements?","answer":"Functions and antisymmetric relations handle ordered pairs differently. A function must map each element in the domain to exactly one output value - meaning for any input, there can only be one corresponding output. Antisymmetric relations, however, allow pairs to go both ways but with a specific restriction: if both (x,y) and (y,x) are present in the relation, then x must equal y. So while functions enforce a one-to-one or one-to-many mapping from domain to codomain, antisymmetric relations allow bidirectional relationships but only between an element and itself.","context":["Difference Between Relations and Functions\nRelations vs Functions\nIn mathematics, relations and functions include the relation between two objects in a certain order. Both are different. Take, for instance, a function. A function is linked with a single quantity. It is also associated with the argument of the function, input, and value of the function, or otherwise known as the input. To put it in simple terms, a function is associated to one specific output for every input. The value could be real numbers or any elements from a provided set. A good example of a function would be f(x) =4x. A function would link to every number four times every number.\nOn the other hand, relations are a group of ordered pairs of elements. It could be a subset of the Cartesian product. Generally speaking, it is the relation between two sets. It could be coined as a dyadic relation or a two-place relation. Relations are utilized in different areas of mathematics just so model concepts are formed. Without relations, there wouldn’t be “greater than,” “is equal to” or even “divides.” In arithmetic, it can be congruent to geometry or adjacent to a graph theory.\nOn a more determined definition, function would pertain to an ordered triple set consisting of the X,Y,F. “X” would be the domain, “Y” as the co-domain, and the “F” would have to be the set of ordered pairs in both “a” and “b.” Each of the ordered pairs would contain a primary element from the “A” set. The second element would come from the co-domain, and it goes along with the necessary condition. It has to have a condition that each single element found in the domain will be the primary element in one ordered pair.\nIn the set “B” it would pertain to the image of the function. It doesn’t have to be the entire co-domain. It can be clearly known as the range. Do bear in mind that the domain and co-domain are both the set of real numbers. Relation, on the other hand, will be the certain properties of items. In a way, there are things that can be linked in some way so that’s why it’s called “relation.” Clearly, it doesn’t imply that there are no in-betweens. One thing good about it is the binary relation. It has all three sets. It includes the “X,” “Y” and “G.” “X” and “Y” are arbitrary classes, and the “G” would just have to be the subset of the Cartesian product, X * Y. They are also coined as the domain or perhaps the set of departure or even co-domain. “G” would simply be understood as a graph.\n“Function” would be the mathematical condition that links arguments to an appropriate output value. The domain has to be finite so that the function “F” can be defined to their respective function values. Oftentimes, the function could be characterized by a formula or any algorithm. The concept of a function could be stretched out to an item that takes a mixture of two argument values that can come up with a single outcome. All the more, the function should have a domain that results from the Cartesian product of two or more sets. Since the sets in a function are clearly understood, here’s what relations can do over a set. “X” is equal to “Y.” The relation would end over “X.” The Endorelations are through with “X.” The set would be the semi-group with involution. So, in return, the involution would be the mapping of a relation. So it is safe to say that relations would have to be spontaneous, congruent, and transitive making it equivalence relation.\n1. A function is linked to a single quantity. Relations are used to form mathematical concepts.\n2. By definition, a function is an ordered triple sets.\n3. Functions are mathematical conditions that connect arguments to an appropriate level.\nSearch DifferenceBetween.net :\nEmail This Post : If you like this article or our site. Please spread the word. Share it with your friends/family.\nLeave a Response","We will explore relations that are antisymmetric and asymmetric in both a real-world context and a mathematical context. We will examine properties of each of these types of relations, and determine how best to tell them apart by their differences.\nSuppose that Riverview Elementary is having a father son picnic, where the fathers and sons sign a guest book when they arrive.\nHere’s something interesting! This list of fathers and sons and how they are related on the guest list is actually mathematical! In mathematics, a relation is a set of ordered pairs, (x, y), such that x is from a set X, and y is from a set Y, where x is related to y by some property or rule.\nIf we let F be the set of all fathers at the picnic, and S be the set of all sons, then the guest book list, call it G, is a relation from set F to set S. That is, G consists of all the ordered pairs (f, s), such that f is related to s by the rule that f is the father of s.Let’s consider another example of a relation in the real world that wouldn’t seem mathematical at first glance. Consider the relation A that is defined by the rule ‘is a relative that came before that individual (an ancestor), or is that individual’. In other words, A is the set of ordered pairs (a, b), such that a is a relative of b that came before b, or is b. Once again, one wouldn’t think a list of pairs such as this would be mathematical, but it is!\nAsymmetric and Antisymmetric Relations\nWhen it comes to relations, there are different types of relations based on specific properties that a relation may satisfy.\nTwo of those types of relations are asymmetric relations and antisymmetric relations. Ot the two relations that we’ve introduced so far, one is asymmetric and one is antisymmetric. Let’s take a look at each of these types of relations and see if we can figure out which one is which.An asymmetric relation, call it R, satisfies the following property:\n- If (x, y) is in R, then (y, x) is not in R.\nTherefore, if an element x is related to an element y by some rule, then y cannot be related to x by that same rule. In other words, in an asymmetric relation, it can’t go both ways.\nAn antisymmetric relation, call it T, satisfies the following property:\n- If (x, y) and (y, x) are in T, then x = y.\nThat is, if an element x is related to an element y, and the element y is also related to the element x, then x and y must be the same element. Thus, in an antisymmetric relation, the only way it can go both ways is if x = y.\nOkay, similar names, but we can see that an asymmetric relation is different from an antisymmetric relation in that an asymmetric relation absolutely cannot go both ways, and an antisymmetric relation can go both ways, but only if the two elements are equal.\nLet’s think about our two real-world examples of relations again, and try to determine which one is asymmetric and which one is antisymmetric. First, consider the relation G consisting of ordered pairs (f, s), such that f is the father of s. Hmmm…for this relation to be asymmetric, it would have to be the case that if (f, s) is in G, then (s, f) cannot be in G. This makes sense! If f is the father of s, then s certainly can’t be the father of f. That would be biologically impossible! Therefore, G is asymmetric, so we know it is not antisymmetric, because the relation absolutely cannot go both ways.Now, consider the relation A that consists of ordered pairs, (a, b), such that a is the relative of b that came before b or a is b.\nIn order for this relation to be antisymmetric, it has to be the case that if (a, b) and (b, a) are in A, then a = b. Again, this makes sense! If a is a relative of b that came before b or is b and b is a relative of a that came before a or is a, then it must be the case that a and b are the same person, because it can’t be the case that a came before b and b came before a. Therefore, the only possibility is that a is b. Since it is possible for it to go both ways in this relation (as long as a = b), the relation is antisymmetric, but can’t be asymmetric.If you’re wondering about some examples that actually seem more mathematical.\nConsider the relations < and ≤, where (a, b) is in < only if a is strictly less than b, and (c, d) is in ≤ only if c is less than or equal to d. The relation < is asymmetric, because it can’t be the case that for two numbers, a and b, a ; b and b ; a, so if (a, b) is in ;, then (b, a) can’t be in <. It absolutely can’t go both ways.On the other hand, the relation ; is antisymmetric, because if for two numbers c and d, both c ; d and d ; c, then it must be the case that c = d.\nThe only way for it to go both ways is if c = d.\nA relation is a set of ordered pairs, (x, y), such that x is related to y by some property or rule. Two types of relations are asymmetric relations and antisymmetric relations, which are defined as follows:\n- Asymmetric: If (a, b) is in R, then (b, a) cannot be in R.\n- Antisymmetric: If (a, b) and (b, a) are in R, then a = b.\nThe easiest way to remember the difference between asymmetric and antisymmetric relations is that an asymmetric relation absolutely cannot go both ways, and an antisymmetric relation can go both ways, but only if the two elements are equal.As we’ve seen, relations (both asymmetric and antisymmetric) can easily show up in the world around us, even in places we wouldn’t expect, so it is great to be familiar with them and their properties!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:b1b398e5-0ac8-415c-9b8a-a5d499925da6>","<urn:uuid:e70c7b65-fa5f-4e5a-a089-46a979d9f952>"],"error":null}