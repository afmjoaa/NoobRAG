{"question":"How do sinkholes typically form in urban areas, and what role do utility infrastructures play in their development?","answer":"In urban areas, sinkholes often form due to utility infrastructure. Sewer lines and fiber optic cables are buried in troughs filled with loose material, which can wash away over time. This process can turn a stretch of road into essentially a concrete bridge over empty space. When the structural support becomes insufficient, it can collapse under the weight of vehicles. Additionally, anything that increases water flow into subsurface soil can accelerate sinkhole formation.","context":["Nature never stops to amaze us with its magnificent phenomenon just like these inexplicable holes in the ground. I bet that these holes make an excellent tourist attraction. Check out these unreal photographs and location descriptions of 9 of world’s most famous pits and sinkholes. (Courtesy of National Geographic)\n1. Lisbon, Portugal, Sinkhole\nA parked bus was the unfortunate “meal” of a sinkhole that opened up in the streets of Lisbon, Portugal, in 2003.\n“Anything that increases the flow of water into subsurface soil can speed up the formation of sinkholes’” ,Missouri State’s Gouzie said. In many cities, utility infrastructure such as sewer lines and fiber optic cables are buried in troughs filled with loose material, which can wash away over time. In some cases, a stretch of road can essentially become a concrete bridge over mostly empty space.\n“It’s eventually not enough to hold the weight of the next truck over it,” Gouzie said.\n2. Guatemala Sinkhole\nHeavy rains from tropical storm Agatha likely triggered the collapse of a huge sinkhole in Guatemala on Sunday, seen above a few days afterward.\nIn the strictly geologic use of the word, a sinkhole happens when water erodes solid bedrock, carving an underground cavity that can then collapse. Many parts of the United States are at risk for that type of event.\nThe Guatemala sinkhole fits into a broader use of the term, which refers to any sudden slump of the ground’s surface. Instead of solid bedrock, much of Guatemala City rests atop a layer of loose, gravelly volcanic pumice that is hundreds of feet thick. And at least one geologist says leaking pipes—not nature—created the recent sinkhole.\nOverall, the risk for repeat sinkholes in Guatemala City is high—but highly unpredictable.\n3. Winter Park, Florida, Sinkhole\nhe sinkhole in Winter Park, Florida (map), opened up in 1981 underneath the city’s public swimming pool, Missouri State’s Gouzie said.\n“I’ve never seen a final report as to whether the pool was leaking,” he said, adding that water can flow into the underlying soil through tiny cracks in the bottom of a pool. Even watering plants at the pool’s perimeter could have sent enough runoff through Florida’s sandy soil to erode the solid limestone underneath.\nGouzie said the U.S. Geological Survey has mapped the types of bedrock that exist across the country. But studies of the underground cracks and fissures—and the way water travels through them—are still needed to predict where sinkholes could occur.\n4. Mulberry, Florida, Sinkhole\nThis 185-foot-deep (56-meter-deep) sinkhole appeared in 1994 in Mulberry, Florida (map), in a pile of waste material dumped by mining company IMC-Agrico. The company was mining rock to extract phosphate, a main ingredient in fertilizers and a chemical used to produce phosphoric acid, added to enhance the taste of soda and various food items.\nAfter phosphate was extracted from the rocks, the gypsum-based waste product was dumped as a slurry. As layer after layer of the stuff dried, it formed cracks, like those that appear in dried mud. Water later made its way through the cracks and carried away subsurface material, setting the stage for a sinkhole.\n5. Blue Hole, Belize\nSinkholes can happen anywhere water can erode a vertical channel that connects to a horizontal drain, a situation that allows a column of solid material to wash away, Missouri State’s Gouzie explained.\nIf the sinkhole is near the sea—or in the sea, as with the famous Blue Hole in Lighthouse Reef off the coast of Belize—seawater can quickly seep in after a collapse, forming a deep pool.\n6. Picher, Oklahoma, Sinkhole\nYears of mining for zinc and lead has left Picher, Oklahoma, near the border with Kansas, literally full of holes—including this sinkhole seen in 2008. Some mines were dug too close to the surface, and the roofs were unable to support the weight of earth on top, leading to collapses.\n“It has happened in Missouri and in western Pennsylvania from coal mining,” Missouri State’s Gouzie said. “We’ve gotten better with buidlng mines so the roofs can support the weight over top of them.”\n7. Iceland Sinkhole\nAdventure kayaker Mick Coyne lowers himself down the wall of a sinkhole toward the headwaters of the Jokulsa, Iceland’s second longest river. Though the river is fed by melt from a glacier, this 150-foot (45-meter), inverted funnel-shaped hole was blasted into being by rising steam from geothermal vents below.\n8. Ik-Kil Cenote, Mexico\nSwimmers float in the saphirre waters of the Ik-Kil cenote, near the Maya site of Chichén Itzá in Mexico’s Yucatán Peninsula. Cenote means “natural well” in Spanish. Sinkholes occurring at sea level will fill up as high as the water table, creating the famous clear blue pools, used by the Maya royalty for both relaxation and ritual sacrifices.\n9. Neversink Pit, Alabama\nNeversink Pit, a wet limestone sinkhole in Alabama seen above in 1998, is about 50 feet (15 meters) deep and houses a rare species of fern. The sinkhole was bought in the 1990s by a group of cavers to preserve it for future generations.\nKarst is the geologic term for landscapes formed mainly by the dissolving of limestone or dolomite bedrock. In the United States, karst underlies parts of Missouri, Arkansas, Kentucky, Tennessee, northern Alabama, Texas, and most of Florida. Such areas are marked by sinking streams, subterranean drainage, large springs, caves—and, of course, sinkholes."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:7d0a8327-170d-4ff8-af28-a40517c57209>"],"error":null}
{"question":"How do the protection instincts of Vietnam War dogs compare to contemporary military working dogs in international competitions? Specifically regarding handler loyalty.","answer":"Historic Vietnam War dogs like Nemo demonstrated extreme handler protection instincts, as evidenced by Nemo taking a bullet and losing an eye while shielding his handler during combat. Similarly, in Afghanistan, a Labrador named Eli showed the same protective behavior by guarding his fallen handler from a Taliban sniper. In modern competitive settings like the Army Games, while the context is different, service dogs still demonstrate strong handler loyalty through coordinated training and performance in events, though these are structured competitions rather than combat situations. The Vietnamese service dog teams specifically train both handlers and dogs together to master various techniques and build their working relationship for international competition.","context":["Everyone loves a good pet story, especially when it has to do with the military working dogs. Rebecca Frankel delivers in her new book, War Dogs (St. Martin’s Press). We had an opportunity to get some pictures from John Nicholas at St. Martin’s and are very happy to share these with you.\nPhoto: Marine Sergeant Charlie Hardesty works with MWD Turbo during a training session at YPG.\nPhoto: U.S. Air Force Staff Sgt. Joshua Fehringer guides MWD (Military Working Dog) Suk, across the obedience course at Cannon Air Force Base in New Mexico on August 15, 2012. Photo by Airman First Class Xavier Lockley\nPhoto: Combat Tracker dog Lex, who loves attention, enjoys some free time with his handler, Marine Lance Corporal John Peeler. Photo by Rebecca Frankel.\nPhoto: Layla relaxes in the arms of one of the Marines who took her in during their deployment to Afghanistan. Image by Rita Leistner/Basetrack\nInterview with Rebecca Frankel\nCan you pick a relationship between one of the dogs and handlers profiled in the book that inspires you the most?\nThat’s tough; they all inspire me. While the MWD community is relatively small compared to how large the U.S. military actually is, it is a uniquely devoted one. Handlers are very passionate about their work, and very committed to their job and their dogs.\nBut the stories that moved me the most were the ones where the dogs, in some fit of fighting or truly dangerous encounter would, in pure reaction, put themselves in harm’s way to protect their handlers. And the amazing thing was, it was not an anomaly; war after war, even with hundreds of years in between, dogs were moved to engage a threat to keep their handlers safe.\nRead Next: The Military’s Four-Legged Fighters: Military Working Dogs\nDuring the Vietnam War, a dog named Nemo crawled on top of his handler to shield him while they were under attack—taking a bullet and losing an eye in the process. In Afghanistan, a young Marine named Colton Rusk was shot by a Taliban sniper and his dog, Eli, a Labrador not generally known for being ferocious, did the same thing: He climbed on top of his fallen handler to protect him, snapping at anyone who tried to help him. It would be impossible not to be moved by these stories, and there are so many of them.\nContinue reading our interview with Rebecca Frankel, author of War Dogs.\n(Author’s Note: You can purchase War Dogs from Amazon.com and BN.com.)\n(Main image: While on foot patrol a group of Marines found Layla when she was a puppy, but because of the IED risk, taking her on patrols was too dangerous and they decided to trade her for some cigars to the Marines of the 1st Battalion, 8th Infantry Regiment. Here she is with her marines from the 1/8 at Shir Ghazay Patrol Base in Landay Nawah County, Afghanistan. Image by Rita Leistner/Basetrack)\nThere are on this article.\nYou must become a subscriber or login to view or post comments on this article.","|Vietnamese military teams ready for Army Games 2021|\n|Top 10 Great Games to educate and entertain your children at home|\n|Among Us - SURGED game in 2020|\nVietnam’s artillery team stands ready for Army Games 2021\n|The artillery team is practicing.|\nA delegation of the Department of Military Training under the General Staff and the Artillery Arms of the Vietnam People's Army (VPA) on June 21 visited the artillery team, which is under training in Vinh Phuc northern province for the 2021 International Army Games.\nThe team will compete at the Masters of Artillery Fire category at the event.\nMaj. Gen. Thai Van Minh, Director General of the Department of Military Training, spoke highly of the team members’ sense of responsibility, determination and endeavors to surmount difficulties during training.\nCommander of the Artillery Arms Maj. Gen. Nguyen Hong Phong said that team members need to be aware that participating in the Army Games is not only an honor and pride but also a heavy responsibility. Therefore, each team member needs to focus on training their health and hone their skills further to achieve the best results in the upcoming Games.\nVietnam’s participation in and preparations to host the Games further affirm the determination and success of Vietnam in general and the People’s Army in particular in realizing the “dual targets” in the face of the Covid-19 pandemic.\nTopographer team ready for Army Games 2021\nThe Vietnam People's Army is sending troops to the Army Games 2021 to compete in the Meridian competition for the first time.\nAfter three months of training, the Vietnamese topographer team is ready for the event.\nThe Meridian competition has three categories, including shooting, azimuth measuring, and relay.\nHere are photos of the topographer team during training for the “relay” category:\n|Warming up before starting the training. Photo: People’s Army Newspaper|\n|Checking mirrors and electronic geo-meters before training. Photo: People’s Army Newspaper|\n|Provision of training targets. Photo: People’s Army Newspaper|\nDismounting before reaching the starting line. Photo: People’s Army Newspaper\n|Starting. Photo: People’s Army Newspaper|\n|Accelerating. Photo: People’s Army Newspaper|\n|Photo: People’s Army Newspaper|\n|Overcomes obstacles. Photo: People’s Army Newspaper|\n|On the way to the designated position. Photo: People’s Army Newspaper|\n|Photo: People’s Army Newspaper|\n|Crossing the rickety wooden bridge. Photo: People’s Army Newspaper|\n|Photo: People’s Army Newspaper|\n|The team leader preparing the equipment. Photo: People’s Army Newspaper|\n|Member No.01 correcting the geometer's mirror. Photo: People’s Army Newspaper|\n|Member No.02 signaling his readiness. Photo: People’s Army Newspaper|\n|Topographers completing the training section. Photo: People’s Army Newspaper|\nService dog handlers train hard for Army Games 2021\nCommander of the Vietnam Border Guard Force Major General Le Duc Thai on June 15 inspected the Vietnamese service dog handler team’s training for the 2021 International Army Games (or 2021 Army Games) at Border Guard School 24.\nAccording to the Director of the school Senior Colonel Tran Quang Phe, over the past two and a half months, the team has been actively conducting training plans as scheduled.\nDuring the training, the team has overcome physical health challenges for both handlers and service dogs, mastered grenade throwing and shooting techniques, as well as trained service dogs, among others.\n|The team's training results at present have been improved in comparison to the same period last year. Photo: People’s Army Newspaper|\nFive pairs of service dogs and handlers will be selected to take part in the competition.\nReportedly, the team's training results at present have been improved in comparison to the same period last year, equivalent to about 70% of the results of the winner at Army Games 2020.\nIn the coming time, the team is determined to train hard in order to keep fit and raise competence so as to meet all requirements of this year’s competition.\nIn addition, Border Guard School 24 also prepared other procedures for the team to join the 2021 Army Games in accordance with the regulations of the organizing panel.\n|The team receives a gift at the event. Photo: People’s Army Newspaper|\nHaving inspected the team’s training, General Thai acknowledged and hailed their great efforts, responsibility and a high determination in fulfilling all assigned missions. General Thai also requested the team to increase training so as to gain the best results in the upcoming event.\nMeanwhile, General Thai asked the Vietnam Border Guard Command’s Department of Politics to carry out Party and political work during training while strictly maintaining Covid-19 prevention and control for the team.\nLast year, a service dog in the Vietnamese team competing at the International Army Games 2020 in Moscow went viral online for refusing to jump into a cold water tank during a competition for dogs and their handlers.\nThe video was captured during the “True Friend\" competition that required dogs and their handlers to overcome several challenges including hurdling, jumping over a 1.8m-high wall, balance beam, swimming in the tank simulating a shallow river, and crawling underneath an armored tank.\nThe dog, named Aquadog, didn’t have any difficulty until the water tank. While its handler got onto the approaching bridge and jumped into the water, the dog didn’t join him. Instead, the Belgian Malinois ran to wait for its handler by the way down.\nNetizens assumed the dog has gotten used to the high temperatures in Vietnam so he didn’t want to get into cold water as the temperature in Moscow on that day was about 12 degrees Celsius.\nA few days later, at a relay race within the “True Friend\" competition, Aquadog pulled another surprise by completing all the challenges at a surprising speed of 50kph. With this result, the Vietnamese service dog team placed 4th out of eight teams.\nVietnam builds tank training ground to prepare for army games\n|The tank training ground that is under construction in central Binh Dinh Province, May 2021. Photo: VnExpress|\nA training ground is being created in central Vietnam for tank crews to practice for the upcoming 2021 International Army Games.\nIt is coming up on a shooting range belonging to the National Military Training Center No.2 in Tay Son District, Binh Dinh Province, and, once completed, will have a scale and equipment similar to that of the Alabino Military Training Ground in Moscow, Russia, where the games' Tank Biathlon competition will take place.\nDuring the 2020 International Army Games, Vietnam’s tank team triumphed at the final race of tank crews of the second division in the Tank Biathlon event. The Vietnamese team completed three rounds of competition in 2 hours, 12 minutes and 42 seconds, bringing down 13 out of the total 24 targets.\nTwo Vietnamese warships to compete at the Army Games 2021 for first time\n|Vietnam's 015 Tran Hung Dao vessel off the coast of Japan during a visit in 2018. Photo by Japan Maritime Self-Defense Force.|\nVietnam will send two warships 015-Tran Hung Dao and 016-Quang Trung to compete at the 2021 International Army Games held by Russia this August, according to the Vietnam Navy newspaper.\nThe two missile defense vessels of Vietnam will compete in the \"Sea Cup\" with four categories, including Marine skills, fighting against sinking at the onshore training facility, usage of salvage vehicles, and artillery fire tests.\n015 Tran Hung Dao and 016 Quang Trung are two missile defense vessels built by Russia under Project 11661E \"Gepard\". They have been employed by Brigade 162 of the Vietnam People's Navy since February 2018.\nThe ship is equipped with many modern weapons manufactured by Russia under a contract signed with the Vietnam Navy, in order to build up a regular naval force and improve the capacity to protect the sea and islands of the country.\nThe Vietnamese Gepard-class defense vessels are stealthy, able to track, search and destroy surface ships and submarines. At the same time, they can perform missions of air defense, escorts, and patrol to protect the territorial sea and exclusive economic zone independently or operate in teams.\nVietnam ends Army Games 2020 with three bronze medals, one champion cup\nIn its third year at the International Army Games, Vietnam took part in 10 competitions, bringing home three bronze medals and a champion cup.\nThe Vietnamese People's Army sent a team of 125 officers and men to last year’s games to compete in 10 events and attend the International Military-Technical Forum 2020.\nIt won the bronze in Emergency Area for emergency rescue units, Safe Route for combat engineering units, and Confident Reception for anti-aircraft missile units.\nVietnam was also crowned champion and won the cup in Group 2 of the Tank Biathlon, beating Abkhazia, Congo, Laos, Myanmar, Qatar, South Ossetia, and Tajikistan.\nHowever, the Group 2 result did not count toward the medal tally.\nOther events Vietnam competed in include Safe Environment for reconnaissance crews, Emergency Area for emergency rescue units, True Friend for dog handlers, Field Kitchen, Masters of Artillery Fire, Sniper Frontier, and Military Medical Relay Race.\nIn all, Russian finished first with 25 gold medals, four silvers and one bronze, followed by Belarus, Uzbekistan, and China.\nInternational Army Games 2020 was held in Russia, Belarus, Armenia, Azerbaijan and Uzbekistan from August 23 to September 5. More than 5,000 participants from 156 teams from over 30 countries and regions competed in the event.\nThe International Army Games is an annual Russian military sports event organized by the Ministry of Defense of Russia (MoD). The event, which was first staged in August 2015, involves close to 30 countries taking part in dozens of competitions over two weeks to prove which is the most skilled. The games have been referred to as the War Olympics. In addition to the competition, the International Army Games includes a military theme park, a recruitment station, and souvenir shops.\nAccording to the Ministry of Defence of Russia, this year’s Army Games will be held from August 22 to September 4 with 13 host nations, including Russia, Armenia, Belarus, India, Kazakhstan, Qatar, China, Mongolia, Serbia, Uzbekistan and Vietnam.\nOf the 34 competitions, Vietnam will host the Military Medical Relay Race and the second group stage of Sniper Frontier contests for countries in the Asia-Pacific region, said Major General Tran Van Ba, deputy director of the Department of Politico-Military Training under the General Staff of the Vietnam People's Army (VPA).\nA total of 277 teams from 41 countries and territories will compete in 34 categories. The first of them, the Sayan March, will take place from April 14 to 17 in the Krasnoyarsk Territory at the Ergaki mountain training base.\nThree new competitions will be held during this year's games: \"Meridian\" - for specialists of the military topographic service; \"Tactical shooter\", which is based on the elements of the tactical army shooting from various small arms; and the “Army of Culture” competition of creative teams will receive further development.\nThe best PC games have become so immersive and so detailed that your loved ones may not see you for a week or three when ...\nThe teams of the Vietnam People’s Army (VPA) have gained outstanding results and surpassed their set targets at the 2020 Army International Games, which wrapped ...\nVietnam tank team ranked first in tank biathlon in the final round of Group 2 at the ongoing International Army Games 2020 in Russia."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:d3fcad7a-1b4f-47c2-90f8-6b5df87e13b1>","<urn:uuid:a65831b2-c732-4be4-9366-87bb31777f46>"],"error":null}
{"question":"请详细说明SAP系统中供应商评估流程如何与质量通知系统关联？","answer":"SAP's vendor evaluation process is connected to the Quality Notification system in the following way: When defective materials are received from vendors, quality notifications are created in the Materials Management component. These notifications impact the vendor's evaluation score, which is determined by multiple factors including timely delivery, competitive pricing, adherence to packing instructions, and the number of quality notifications raised for defective materials over time. The system particularly monitors cases where defective materials reach production and cause issues in finished or semi-finished products, even in cases where the vendor had been granted relaxed quality control due to previous good performance. This integration ensures comprehensive vendor performance tracking and accountability.","context":["SAP Quality Notification can alert you to product defects and take control of them.\nQuality Notification is a subcomponent of the Quality Management module in SAP ECC in sales and distribution, production and procurement. Quality Notification provides a formal notification to record a customer's complaint for a defective product and helps take action on such issues. While Quality Notification can work independently in all three business areas, such as sales, production or procurement, the real strength is when these three business processes integrate together to share data and information -- thus, shedding light on the root cause of defect.\nHere are the three SAP ERP components where Quality Notification plays a central role in managing material defects:\n1. Quality Notification in SAP's Sales and Distribution component. This works when a customer calls, sends an email or simply visits the company's website to register a product complaint. There can also be a CRM portal that directly connects with SAP ECC to automatically create a quality notification as soon as the customer logs a complaint. The company's customer services representative not only creates a notification, but also assigns specific tasks and performs activities to handle the complaint. The tasks could be a visit from the company's quality inspector to the customer's location to assess the product's damage, for example, or it could be arranging an immediate replacement delivery of a defective product. Activities can be triggering an alert to find out the root cause of a product's defect and the number of customers affected. If the defect is big or serious enough, it is also possible to create a quality order to capture the cost of evaluating and fixing the defect in all affected products. In case of a manufacturing defect, the customer services representative automatically links Quality Notification to the production process.\n2. Quality Notification in the SAP ERP Production Planning component. This works for defects found in products produced in-house. For this, Quality Notification not only acts as an integration point when a problem is first reported by customer, but also digs into the root cause of problem, such as a packing machine's misalignment, which is responsible for the product defect. Quality Notification can help to correct the problem before it moves forward to the next production step, thus preventing additional costs associated with the product's defect.\nIf the root cause analysis finds that product's defect was the vendor's fault, Quality Notification can automatically connect with the procurement process.\n3. Quality Notification in SAP's ERP Materials Management component. This is for defective goods delivered by the vendor. Sometimes, the company relaxes the quality control for vendors who regularly supply good-quality material to cut time and costs associated with quality inspection by only inspecting a limited sample of delivered material. But what if a defective material reaches production and leads to a defective finished or semifinished product? Quality Notification in procurement ensures the vendor replaces the defective material. The notification also affects its vendor evaluation. Vendor evaluation is the process in which the company evaluates a vendor's performance for timely delivery, competitive pricing, adhering to a company's specified packing instructions and number of quality notifications raised for a specific vendor to denote defective materials supplied over a period of time.\nLearn how to activate the recurring inspection process in SAP QM\nHow Quality Certificates boost standards\nLower the costs of inspections\nDig Deeper on SAP ERP software and modules\nRelated Q&A from Jawad Akhtar\nReplenishment strategies, lot sizes, safety stock, reorder point planning and replenishment lead time are five factors in ERP that can ensure ... Continue Reading\nS/4HANA public cloud provides a less disruptive route to digital transformation than some options -- including the on-premises S/4 -- and smoother ... Continue Reading\nThese nine key components of SAP MDG help ensure regulatory, legal, environmental and financial compliance of your master data and improve ... Continue Reading"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:b076890d-4205-4882-8b13-0884f3390964>"],"error":null}
{"question":"How does viral vector-based gene delivery work in therapeutic settings, and what detection challenges does this create for anti-doping efforts in sports?","answer":"In therapeutic settings, viral vectors (like adenoviruses and retroviruses) deliver genes by either integrating genetic material into cell chromosomes or introducing transgenes into cell nuclei without chromosomal integration. These viral vectors act as 'Trojan horses' to deliver genes into target cells, as demonstrated in the salivary gland therapy trials. This same delivery mechanism creates major detection challenges for anti-doping efforts because the proteins produced by transferred genes are structurally and functionally very similar to endogenous proteins, making them virtually undetectable in blood or urine tests. The only reliable detection method would require muscle biopsy, which is practically impossible to implement in sports.","context":["Gene therapy can be performed safely in the human salivary gland, according to scientists at the National Institute of Dental and Craniofacial Research (NIDCR), part of the National Institutes of Health.\nThis finding comes from the first-ever safety, or Phase I, clinical study of gene therapy in a human salivary gland. Its results, published this week in the Proceedings of the National Academy of Sciences, also show that the transferred gene, Aquaporin-1, has great potential to help head and neck cancer survivors who battle with chronic dry mouth. Aquaporin-1 encodes a protein that naturally forms pore-like water channels in the membranes of cells to help move fluid, such as occurs when salivary gland cells secrete saliva into the mouth.\nThese initial results clear the way for additional gene therapy studies in the salivary glands. Although sometimes overlooked, salivary glands present an ideal target for gene therapy. They are easily accessible and, once a gene is introduced, it has no obvious escape route into the bloodstream, where it can have unintended consequences.\n“You cannot imagine how fulfilling it is to jot down an idea on a napkin in 1991 and then see it enter a clinical trial and help people.,” said Bruce Baum, D.M.D., Ph.D., lead author on the study and recently retired NIDCR scientist who spent the last 21 years moving gene therapy in the salivary glands from the research bench to the clinic. “Can a scientist ask for anything better?”\nBaum’s interest in helping head and neck cancer survivors dates to the early 1980s. While attending to patients in the NIDCR’s Dry Mouth Clinic, Baum encountered numerous people with head and neck cancer who had received radiation therapy to shrink their tumors. The radiation, while effective in treating cancer, had inadvertently damaged nearby salivary glands, compromising their ability to secrete saliva into the mouth.\nBaum said he was thoroughly frustrated at the time because he had no effective moisture-restoring treatments to offer most patients. They had beaten cancer, but the radiation had left them with a permanent parched sensation in their mouths that diminished their quality of life and often led to chronic oral problems, such as difficulty swallowing, inflammation, infection, bad breath, and pain.\nIn the early 1990s, as the first gene-therapy studies entered research clinics, Baum saw an opportunity to make a difference. An initial napkin sketch of the procedure and 15 years of research later, Baum and his colleagues had assembled a compelling scientific case in animal studies that the transferred Aquaporin-1 gene, once expressed, will create new water channels in the impermeable salivary gland cells and allow water to flow through them. After rigorous reviews by NIH and the U. S. Food and Drug Administration, the Phase I protocol was launched and the first patients treated in 2008.\nThe scientists gave 11 head and neck cancer survivors a single-dose injection of the Aquaporin-1 gene directly into one of their two parotid salivary glands, the largest of the major salivary glands. The gene was packaged in a disabled, non-replicating adenovirus, the cause of the common cold when intact but incapable of causing a cold in this case. As is standard in gene therapy studies, the virus served as the vector, or Trojan horse, to deliver the gene into the cells lining the salivary gland.\nThe scientists found that five participants had increased levels of saliva secretion, as well as a renewed sense of moisture and lubrication in their mouths, within the study’s first 42 days, the period covered in this report. Of the six who didn’t benefit from gene therapy, none had serious side effects. The most common side effect was a transient and relatively minor immune response against the disabled adenovirus.\n“It is time to evaluate a different vector to deliver the Aquaporin-1 gene, one that will cause only a minimal immune response,” said Baum. “But these data will serve as stepping stones for other scientists to improve on this first attempt in the years ahead. The future for applications of gene therapy in the salivary gland is bright.”\nThe National Institute of Dental and Craniofacial Research is the Nation’s leading funder of research on oral, dental, and craniofacial health. For more information about NIDCR and its programs, visit http://www.nidcr.nih.gov/.\nAbout the National Institutes of Health (NIH): NIH, the nation’s medical research agency, includes 27 Institutes and Centers and is a component of the U.S. Department of Health and Human Services. NIH is the primary federal agency conducting and supporting basic, clinical, and translational medical research, and is investigating the causes, treatments, and cures for both common and rare diseases. For more information about NIH and its programs, visit www.nih.gov.\nNIH…Turning Discovery Into Health ®","E-mail: andrebairros yahoo. Gene doping is characterized by non-therapeutic use of cells, genes and genetic elements, or modulation of gene expression with the aim to increase sports performance. This can only be accomplished through gene manipulation. This doping practice is characterized as virtually \"undetectable\", which represents new challenges for analytical detection.\n|Published (Last):||20 January 2009|\n|PDF File Size:||16.74 Mb|\n|ePub File Size:||20.16 Mb|\n|Price:||Free* [*Free Regsitration Required]|\nIn the past few years considerable progress regarding the knowledge of the human genome map has been achieved. In vitro studies improve the production of human recombinant proteins, such as insulin INS , growth hormone GH , insulin-like growth factor-1 IGF-1 and erythropoietin EPO , which could have therapeutic application.\nUnfortunately, genetic methods developed for therapeutic purposes are increasingly being used in competitive sports. Some new substances e. The use of these substances may cause an increase of body weight and muscle mass and a significant improvement of muscle strength.\nAt the same time, anti-doping research is undertaken in many laboratories around the world to try to develop and refine ever newer techniques for gene doping detection in sport. Thanks to the World Anti-Doping Agency WADA and other sports organizations there is a hope for real protection of athletes from adverse health effects of gene doping, which at the same time gives a chance to sustain the idea of fair play in sport.\nWith the development of science, athletes enjoy the more modern methods and pharmacological agents supporting their physical fitness, muscle strength and improving athletic skills. Now, with the completion of the Human Genome Project HUGO Project and the development of gene therapy in medicine, there has been dynamic progress of research on gene doping and gene delivery technologies to improve athletic performance in various sports.\nIn WADA clarified the type of manipulation of genetic material prohibited in sport as the transfer of nucleic acids or their analogues into cells and the use of genetically modified cells [ 9 ].\nGenetic material can be introduced into a cell either in vivo or ex vivo. The in vivo strategy is direct gene delivery into the human body, i. In indirect DNA transfer strategy, i. In gene therapy and, similarly, in gene doping the genetic material is delivered into cells and tissues using various carriers that can be viral or non-viral [ 10 ]. Using viral vectors attenuated retroviruses, adenoviruses or lentiviruses a transgene is released in target cells and is expressed using cell replication machinery.\nSome of these viruses, such as retroviruses, integrate their genetic material with chromosomes of a human cell. Other viruses, such as adenoviruses, introduce the transgene into the cell nucleus without chromosomal integration [ 11 ].\nIn some cases, however, irreversible side effects, such as unexpected endogenous virus recombination, may occur. It leads to the rapid transformation of normal cells in vitro as well as initiating tumours in vivo via amplification of the host proto-oncogene sequences in the viral genome [ 10 — 13 ]. Additionally, viral vectors can be recognized by the host immune system, resulting in an increased immune response.\nThis effect reduces the effectiveness of the transfection efficiency by reducing the efficiency of the subsequent transgene delivery. The most important biological properties of the viral vectors used in gene therapy, including the treatment of sports injuries, are shown in Table 1.\nNon-viral gene delivery techniques are less effective methods of introducing genetic material into human cells, though characterized by low cytotoxicity. Non-viral gene delivery systems may cause an increased immune response [ 19 — 20 ]. Physical methods of gene delivery allow DNA transfer into the cell cytoplasm or nucleus, through local and reversible damage of the cell membrane.\nThe most common physical technique is electroporation, based on the application of a high voltage electrical pulse to the cells, leading to the formation of hydrophilic pores in the cell membrane, of several nanometres in diameter [ 15 ]. Electroporation is a very effective method, and one of its strengths is the protection of cells against the introduction of undesirable substances during the transgene delivery.\nNowadays, electroporation is the most frequently used method to introduce DNA into skin cells or liver cells. Biochemical methods involve the use of chemical carriers, which form complexes with nucleic acids to neutralize their negative charge.\nSuch complexes are introduced into the cell by phagocytosis, and less frequently by fusion with the cell membrane. Some of the chemical carriers facilitate the release of nucleic acid into the cytoplasm from the endosome, and protect it from cellular nucleases [ 15 ].\nThe main difficulty in the application of gene transfer in gene doping is to achieve a long-lasting effect, as well as monitoring the changes induced in the genome. A long-lasting effect can be achieved by multiple repeated gene doping applications or by the integration of a transgene into the chromosome.\nHowever, it should be emphasized that the integration of gene transfer vectors is associated with a risk of undesirable side effects, including insertional mutagenesis. Integration of the transgene at the wrong site may lead to the development of cancerous cells [ 21 ]. Research on gene doping, which has been carried out mainly in animal models, but also more and more often as gene therapy in humans, has brought many successes. It was reported that injection of a plasmid with a vascular endothelial growth factor VEGFA gene into the muscle of patients with chronic critical limb ischaemia led to improved distal flow [ 22 ].\nIn rats, the introduction of the insulin-like growth factor-1 Igf1 gene in a recombinant viral vector led to an increase in muscle mass and strength and to increase in endurance [ 24 ].\nTransfer of the phosphoenolpyruvate carboxykinase Pck1 gene resulted in increased activity of the transgenic mice, increased strength and speed during a race, and additionally, the mice were characterized by lower mass and fat content as compared to control mice [ 25 ]. In other studies on animals, gene therapy was used to increase the production of growth hormone GH.\nBy intramuscular injection of a plasmid containing the somatoliberin Ghrh gene, under the control of a muscle-specific gene promoter, increased concentrations of GH and IGF-1, and improvement of anabolic and haematological parameters were achieved. Moreover, the obtained results persisted for over one year [ 26 ]. The results of such studies are a major cause for concern over the direct threat of the spread of gene doping in competitive sports. Another problem — which is a priority for sport organizations — is the difficulty in detecting gene doping.\nSo far, the attempts to standardize the ideal test that could be used to detect gene doping have failed [ 5 — 6 ]. It should be emphasized, however, that several intensive studies on a number of promising strategies are being carried out e.\nLack of tests to detect gene doping is associated with the fact that the protein produced by the foreign gene or genetically manipulated cells will be structurally and functionally very similar to the endogenous proteins. Most transgenic proteins, especially those that enhance muscle strength, are produced locally in the injected muscle and may be undetectable in blood or urine.\nThe only reliable method would require a muscle biopsy, but such an approach is virtually impossible to use in sport. Furthermore, gene expression can be modulated as desired using the appropriate pharmacotherapy.\nIt is also associated with a high risk of danger to the health of athletes. Of course, the full list is much longer. Functional protein products of those genes are related to specific increase of endurance, physical strength, redistribution of fat or increase of muscle mass.\nIn addition, gene doping takes into account the genes encoding the peptides that relieve pain e. The EPO gene encodes a glycoprotein hormone that increases the number of red blood cells and the amount of oxygen in the blood, thereby increasing the oxygen supply to the muscles [ 29 , 43 ].\nThe expected effect of the physiological expression of the EPO gene would be increased endurance. For gene doping, an additional copy of the EPO gene may be introduced into the athlete's body using a viral vector, thus leading to the overexpression of EPO , increased production of red blood cells in the liver and kidneys, and to increased oxygen binding capacity of the blood. Physiologically dangerous side effects of doping with EPO transfer are primarily an increase in haematocrit, which may enhance the likelihood of stroke, myocardial infarction, thrombosis and an increase in total peripheral vascular resistance [ 29 ].\nIn , the British pharmaceutical company Oxford BioMedica developed Repoxygen as a potential drug for the treatment of anaemia associated with chemotherapy used in kidney cancer. The drug is administered intramuscularly, and consists of a viral vector transferring the modified human EPO gene under the control of genes encoding proteins of oxygen homeostasis e. EPO transgene is expressed in response to low levels of oxygen, and is turned off when the oxygen concentration reaches the correct value.\nIn , Repoxygen attracted the attention of the world of sports, when in Germany it began to be administered to young female runners to maintain constant expression of EPO in muscle cells.\nErythropoietin was the first recombinant haematopoietic growth factor produced and available commercially as a recombinant protein drug [ 30 ]. The Sydney Olympics marked the beginning of the use of effective methods to detect injected rEPO. This method would be relatively safe, because the effect of its actions would be limited to the target muscles.\nIt has been shown that overexpression of IGF1 and its protein product combined with increased resistance training induced greater muscle hypertrophy [ 24 ].\nAdditionally, studies have shown that IGF1 gene transfer enabled the regeneration of skeletal muscle following injury and was more efficient than systemic administration of its protein product [ 33 ].\nIGF1 expression is associated with increased muscle size and weight, thereby increasing muscle strength [ 2 ]. However, IGF1 delivery may lead to profound hypoglycaemia, similar to the administration of insulin. IGF1 protein, also known as somatomedin C, belongs to the group of polypeptide hormones, which are essential for proper development of the fetus. In the mature organism it is involved in the regeneration of tissues, especially connective tissue, and also exhibits insulin-like activity, e.\nIGF1 mediates some anabolic processes of growth hormone. One of the main functions of GH — mediated also by IGF1 — is the stimulation of body growth and body weight.\nGH also affects carbohydrate metabolism stimulation of glycogenolysis and increased glucose release from the liver , fat metabolism increased lipolysis and decreased lipogenesis and protein metabolism increased protein synthesis [ 38 ].\nThere are only a few published reports confirming the enhancing effects of GH on muscle strength and cardiovascular and respiratory functions in trained healthy individuals [ 39 — 40 ]. On the other hand, evidence of the health risks associated with the use of GH e.\nGH overexpression is associated with intracranial hypertension, headache, peripheral oedema, carpal tunnel syndrome, joint and muscle pain, or cardiomegaly in trained persons [ 41 ]. However, there is anecdotal evidence that recombinant GH rGH is commonly abused by athletes. The HIF-1 gene encodes proteins involved in the process of hypoxia, angiogenesis and erythropoiesis activation or regulation of glucose metabolism.\nDoping associated with stimulation of HIF-1 expression under normal conditions of oxygen supply, e. On the other hand, it affects mitochondrial oxygen metabolism, while also stimulating genes associated with metabolic adaptation of cells e. These molecular changes in the cells may result in myocardial infarction, stroke or cancer.\nHIF-1 regulates oxygen homeostasis, thus facilitating the cell's adaptation to low oxygen conditions. HIF-1 also affects erythropoiesis, iron metabolism, pH regulation, apoptosis, cell proliferation and intracellular interactions. Hypoxia itself regulates the expression of genes involved, among others, in cell energy metabolism, glucose transport and angiogenesis [ 42 ]. Thus, gene therapy using the HIF-1 gene or protein may result in physiological changes at many levels in the body.\nResearch is being conducted with the use of HIF-1 in the treatment of cardiovascular diseases. Based on the animal studies and early clinical trials in humans, it is believed that HIF-1 administered as gene therapy effectively induces neovascularization in ischaemic tissues [ 43 — 45 ]. Experiments have shown that the activation of PPARD reduces weight gain, increases skeletal muscle metabolic rate and endurance, and improves insulin sensitivity. It was further found that the increase in PPARD expression suppresses atherogenic inflammation [ 47 ].\nNuclear hormone receptor protein is associated with de novo formation of skeletal muscle fibres of type I slow-twitch fibres and their transformation from type II fibres fast-twitch fibres , which determine the athlete's endurance and speed. It controls the body's energy balance. Thus, this protein plays an important role in the control of body weight [ 50 ]. It is recognized that GW improves the exercise capacity of trained animals [ 51 ].\nHowever, there are no published data on the ergogenic effects of GW in healthy and trained people. GW is an experimental drug that has been used in the treatment of obesity, metabolic syndrome, and type 2 diabetes in some clinical trials [ 52 ]. This molecule is included in the WADA prohibition list and there are reports that some athletes have already been caught using such doping.\nStudies have shown that activated AMPK enzyme may reduce the level of anabolic processes, including synthesis of fatty acids and proteins, and increase the level of catabolic pathways such as glycolysis and fatty acid oxidation [ 53 ]. It is believed that the ergogenic effect is achieved by the mutual interaction between AICAR and training, and their effect on the activation of many genes, determining the exertion efficiency [ 51 , 54 ].\nDopaje genético: transferencia génica y su posible detección molecular\nIn the past few years considerable progress regarding the knowledge of the human genome map has been achieved. In vitro studies improve the production of human recombinant proteins, such as insulin INS , growth hormone GH , insulin-like growth factor-1 IGF-1 and erythropoietin EPO , which could have therapeutic application. Unfortunately, genetic methods developed for therapeutic purposes are increasingly being used in competitive sports. Some new substances e. The use of these substances may cause an increase of body weight and muscle mass and a significant improvement of muscle strength.\n2007, Number 2\nISSN Genetic engineering has brought possibilities before unimaginable, in which not long ago was only seen in movies. Of gene therapy, aiming at a correction or cure a disease, pass the possibility of genetic improvement, currently glimpsed in the sports world with gene doping. But, gene doping would not be violating the right to genetic patrimony unmodified?"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:fe5c1ea6-ea79-4bb2-b82f-4829edff9e8f>","<urn:uuid:295d74e2-9ee2-4199-bdfe-a03a4c8be911>"],"error":null}
{"question":"What are the different sources of pain that cancer patients may experience during their treatment?","answer":"Cancer patients can experience pain from multiple sources: chemotherapy or radiation can create nerve damage and phantom pain from removed body parts, radiation can cause painful 'sunburn' during treatment, surgery can cause temporary pain from cutting skin and organs, and the growth of cancer itself within the body can contribute to pain while waiting for abnormal cells to be eradicated.","context":["ARTICLES / General / Effective Pain Management /\nShare This Article\nEffective Pain Management\nBy Cheryl Ellis, Staff Writer\nCONTROLLING PAIN IN CANCER\nThe National Cancer Institute (www.cancer.gov)\noffers an online booklet to assist cancer patients and\ntheir caregivers with pain management.\n“Cancer pains” may arise from\nchemotherapy or radiation, creating nerve damage or\nphantom pain from body parts that have been removed.\nRadiation can cause painful “sunburn” during treatment.\nWhenever there is surgery performed,\ntemporary pain may be experienced because skin and\norgans are cut and maneuvered around.\nPost-surgical pain fades with time and appropriate\nmanagement, which may include physical therapy and\nresuming daily activities.\nThe growth of cancer within the body\ncontributes to pain, also. As cancer is being\ntreated, therapeutic levels of controlling the growth\nare sought, but patients may still experience pain while\nwaiting for the abnormal cells to be eradicated.\nThis is where pain control offers a great deal to assist\nin stress reduction and continuing patient compliance\nwith therapy. It’s difficult to ask a loved one to\ncontinue with treatment when pain makes them feel they\naren’t getting better, and the goal is to quickly assess\nthe level of pain to begin pain control. It makes\nthe treatment much easier to cope with, for caregiver\nand loved one.\nDifferential pain assessment in cancer\nis important also, to help the treatment team to discern\nif new pain is from cancer that has moved to a new area,\nor if there is an acute condition that must be addressed\n(such as appendicitis or gall bladder stones). It\nmay seem unlikely that cancer patients may experience an\nacute episode of pain unrelated to their cancerous\nprocess, but it is possible. It may help to keep a\nwritten record of pain to offer feedback to the\nphysician during visits, or if a call must be placed\nSwelling, itching and rashes cause pain,\nand while minor when examined against pain from cancer,\nthey can actually make it harder to tolerate pain levels\nif the minor pain is left unaddressed.\nCOMPLEMENTARY PAIN TREATMENTS\nBiofeedback has been around for some\ntime, and there are competent technicians able to\ninstruct patients in controlling their breathing and\nheart rate. The technique has worked well for\npersons who have an ability to focus on these measurable\nparameters, which can help reduce pain and the anxiety\nthat comes from being in pain.\nMassage therapy can work in almost any\ncase to reduce pain and improve the relaxation effect.\nIt is not necessary to “work” the area where pain is\nfelt to provide comfort and a sense of healing.\nPatients with swelling from radiation or\nsurgery (such as removal of lymph nodes) can look for a\nLymphedema Therapist, who is trained in proper technique\nfor massaging swollen areas as well as the rest of the\nReflexology can be performed on the\nhands or feet to help release tense areas which may be\nrelated to painful spots. The body in pain will\ntense itself in a variety of ways in response to pain,\nand by relaxing one part of the body by massage, the\nrest of it can follow.\nMassage can be combined with\nbiofeedback, imagery or other alternative therapies\n(such as aromatherapy) to diminish stress response."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:751a487c-1bd5-4d2b-a141-2f6dc886bed0>"],"error":null}
{"question":"What are effective home remedies for removing calcium deposits from faucets, and does water softener installation affect drinking water safety?","answer":"Several household acids can effectively remove calcium deposits from faucets, including white distilled vinegar (strongest at 3 percent), citrus juices (lemon and lime work best), and even cola drinks containing phosphoric acid. The recommended method is wrapping a vinegar-soaked paper towel around the faucet for several hours. Regarding drinking water safety, while installing a water softener does add sodium content to the water supply through ion-exchange, the amount is minimal and safe for most people to drink. The sodium content is typically much lower than in many foods and beverages, though people on low-sodium diets may prefer to avoid softened water.","context":["Calcium is the fifth most common element in the earth's crust, and much of it exists as calcium bicarbonate and calcium carbonate, both of which can dissolve into the groundwater and eventually enter the residential water supply. To some extent, everyone has to deal with hard water, which is water with a high concentration of calcium deposits, but people who get their water from wells are most affected.\nCalcium buildup is a problem for the human body, causing painful joints and swelling. Calcium deposits in the foot, hip and other joints cause a condition known as calcific tendonitis, which can limit movement and make it hard to sleep. They can also wreak havoc on plumbing fixtures, reducing water flow and generally making them look old and worn.\nIt's much easier to deal with calcium buildup on a faucet than it is to reduce calcium deposits inside the body. Chemically speaking, calcium deposits are salts, and you can dissolve salts with an acid. Any acid will do, as long as you give it enough time to work. Most households have plenty of acidic solutions in kitchen cabinets or the refrigerator.\nAcids You Can Use for Calcium Deposit Removal\nYou don't have to go to the store and buy muriatic acid or sulfuric acid drain clog remover. These strong acids will work, but they're dangerous, can pit metal and could end up making the situation worse. The list of safe acids you can use for calcium deposit treatment includes some common kitchen items as well as some items that may require a trip to the store. The list includes:\n- Vinegar (acetic acid) – Any type of vinegar will do, but 3 percent white distilled vinegar is the strongest unless you happen to have some 10 or 20 percent vinegar in your garden shed for killing weeds.\n- Citrus juice (citric acid) – Lemon and lime juice work best, but technically, you could use orange or tomato juice if you're prepared to wait long enough.\n- Milk (lactic acid) – The lactic acid in milk and dairy products will dissolve calcium deposits, but the concentration is low. If you don't have time to wait for orange juice, you definitely don't have time for milk.\n- Fizzy soft drinks (phosphoric acid) – You probably know that soft drinks that contain phosphoric acid (look on the label) can dissolve nails, so they can handle calcium deposits. Cola is a sticky but viable option for cleaning faucets.\nIf you prefer a commercial product designed specifically for dissolving scale (another name for calcium deposits), you can find a suitable one at any hardware store. One of the top products, CLR, contains lactic acid as one of its main ingredients, so using milk wasn't such a bad idea after all, although the lactic acid concentration in CLR is much higher than it is in milk.\nCleaning the Outside of a Kitchen Faucet\nWhen scale collects on a faucet, it dulls the metal, and because you can't wipe off the layer of calcium, the dulling seems permanent. It isn't, though. The metal just needs to be in contact with any one common household acid long enough for the acid to dissolve the calcium salt causing the dulling.\nThe recommended strategy is to soak a paper towel with your favorite acid — vinegar works best — then wrap the towel around the faucet and leave it for a few hours. A soft, absorbent rag, well soaked with vinegar, works even better. For heavy scale, you'll probably want to leave the rag in contact with the metal for several hours. To prevent it from drying out, put some vinegar in a spray bottle and spray the rag every hour or so.\nThis strategy works even if you use a weaker acid, such as milk or tomato juice, but it takes that much longer, perhaps as long as a day. You should be prepared to resoak the rag before it dries out. If you're serious about doing the job efficiently, stick with vinegar. It's cheap, fast-working and doesn't contain any sugars to make a sticky mess.\nCalcium Deposit Removal With a Scouring Paste\nIf you're the type who likes to get the job done immediately, consider mixing vinegar with flour, talc, laundry detergent or borax to make a scouring paste. Ignore recommendations to mix it with baking soda. Baking soda is alkaline and neutralizes any acid with which you mix it, leaving you a foaming mass of carbon dioxide bubbles that has zero cleaning power.\nApply the paste with a toothbrush and scrub away, rinsing periodically to check your progress. If the scale isn't too far advanced, you'll probably make quick progress, but if you're trying to clean an old faucet with thick white deposits, you may be scrubbing for a while and wondering why you didn't use the soaked rag strategy.\nCleaning Scale From the Inside of the Faucet\nVisible calcium buildup on a faucet accompanied by low water flow or stuck handles usually indicates deposits inside the faucet as well as outside. You can disassemble any faucet and soak the valve, handles and other parts in vinegar or lemon juice. Just fill a bowl with the acidic cleaner of your choice, immerse the parts that need cleaning (minus the rubber gaskets and O-rings) and leave them overnight. They'll be as good as new in the morning.\nIf the faucet doesn't have visible scale on the outside but the flow is too low, a clogged aerator is usually the culprit, and this is easy to fix. Unscrew and remove the aerator and try the faucet. If the flow is normal, soak the aerator overnight in vinegar or lemon juice, screw it back on and the problem is solved.\nLow flow from a faucet that doesn't have a blocked aerator is usually due to calcium buildup on the valve, which is a problem most common with cartridge valves. Many of these have tiny holes that easily get blocked, but it's just as easy to clear the holes as it is to clear the aerator. Simply disassemble the faucet, remove the cartridge and soak it overnight in vinegar or lemon juice.\nDealing with Stuck Handles and Cartridges\nIf your faucet is severely affected by scale, you may have a hard time getting the handle off when you're disassembling the faucet to clean the valve. There's a tool for that, called a handle puller, and it works best on two-handled faucets. This corkscrew-like device anchors itself on the faucet body and forces the handle off when you turn it clockwise, provided, of course, you've first removed the set screw.\nScale can also bind cartridges inside the valve body, and there's a tool for that, too, called — you guessed it — a cartridge puller. Faucet manufacturers make these tools to fit their faucets, so if you can't find one that works with your faucet model, check the manufacturer's website.","Most Calgary residents are familiar with the white crystalline buildup in the showerhead and the kettle over time.\nThis is hard water buildup (sometimes called “limescale”) and it’s a natural consequence of the water here in Calgary.\nHard water is water with high mineral content. Most homes in Calgary receive their water from the Bow and Elbow Rivers to the west of the city.\nThis water is high in calcium and magnesium content, the water percolating through the limestone rocks before being treated and reaching our homes. So, hard water has always been part of life for Calgary residents.\nSoft water contains less than 75mg per litre of calcium carbonate\nMedium-hard water contains 75-150mg per litre\nHard water contains 150-300mg per litre\nVery hard water contains 300mg or more per litre\nMost homes in Calgary have hard to very hard water but it varies with location and season (the lowest levels are usually during the spring snowmelt season).\nThis mineral content builds up in taps, boilers, showers, dishwashers, washing machines, kettles, and other water-based appliances around the home.\nSome homeowners wait until the hard water has ruined a few appliances to do anything about it. Installing a softener will break down the mineral deposits and prevent your water from doing any damage in the future.\nHigh calcium and magnesium content in the water is not associated with any known adverse health effects but it can create other problems around the home: for instance, it can cause clothing to lose colour after washing and increase energy bills due to harder-working appliances.\nA good example is water heaters. They generally operate better with soft water as hard water can force water to run at higher temperatures. That means higher energy bills.\nIn summary, a water softener can help with the following:\nEnhance the efficiency of household appliances\nProtect your plumbing network from avoidable problems\nSave on soap/detergent\nReduce the damage to your favourite clothing when washing\nLeave your skin and hair feeling softer\nHow do you know if you have hard or soft water?\nIf you live in Calgary, assume that you have hard water in your home unless you have a softener installed.\nThere is a simple at-home test you can perform to test water hardness:\nFill a clear, clean, empty bottle one-third full of tap water\nAdd a few drops of pure liquid soap\nMake sure that the cap is tightly screwed on and shake it vigorously for a few seconds.\nIf there are few bubbles and the water appears cloudy, your water is hard\nIf there are many bubbles and the water below the bubbles is clear, the water is soft\nMore advanced tests may involve water test strips and a colour chart to help you identify the precise hardness of the water but for most Calgary homeowners it won’t be necessary.\nWhich type of water softener do you need?\nWater softeners use salts to break down the calcified deposits in pipes and appliances in your home and attack the problem before it even starts.\nSometimes called “descalers”, water softeners are either packaged or mechanical systems.\nWith packaged water softeners, softening materials called resins (baking soda or borax) are added to accessible areas or appliances to remove the calcium and magnesium buildup. You simply add them as required.\nMechanical water softeners are separate units installed in your home. They vary in cost but are mainly affordable and durable systems that work using ion-exchange, whereby the calcium and magnesium ions are replaced with sodium ions.\nSome systems can “partition” the water supply in your home, creating soft water in some parts of the home while allowing the water to remain hard in others.\nDoes a water softener affect drinking water?\nThe tap water in Calgary is safe to drink, as it is treated by the City.\nInstalling a water softener may add sodium content to the drinking water supply but this is generally a tiny amount that will not cause any negative impact on your health. The sodium content of many foods and beverages is far higher.\nThose on a low-sodium diet may prefer to avoid softened water but, for everyone else, the water is perfectly safe to drink.\nCan you install a water softener with a septic system?\nA properly installed, high-quality water softener will not adversely affect the performance of the septic system in your home.\nA small amount of sodium-rich wastewater may be discharged into your septic tank by the water softening system but this is not disruptive to the performance of either system.\nThe key is to choose a high-quality system and get it professionally installed.\nSix signs you need a water softener\nLet’s finish up by summarizing the signs that you need a water softener in your home:\nScale buildup in your appliances\nFrequent plumbing problems\nClimbing energy (and water) bills – for no apparent reason\nDryness of the skin and hair\nStains on sinks and bathtubs\nFaded clothing after washing\nInstalling a water softener should solve these problems. It should extend the life of your appliances and plumbing pipes, as well as your favourite clothing. It may even reduce energy bills as fixtures work more efficiently when limescale is removed.\nThere is a small initial investment but it will save you in the long run."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:db08a222-e65a-4148-abcf-4666b5ff4aba>","<urn:uuid:4a7eda2c-3d53-4c9a-8989-a346ab78785c>"],"error":null}
{"question":"How do the health risks posed by raccoons in Portland compare to those of rats, particularly in terms of disease transmission and recommended prevention measures for homeowners?","answer":"Both raccoons and rats pose health risks, but their specific threats and prevention measures differ. Raccoons in Portland are primarily known for being fierce and potentially attacking housepets and humans. While the documents don't specify raccoon diseases, they recommend securing garbage, excluding protein from compost bins, and using licensed pest control for removal. Rats pose more extensive health risks, being carriers of multiple serious diseases including Hantavirus (38% mortality rate), Leptospirosis, Rat-Bite Fever (10% mortality rate), and Salmonellosis. For rat prevention, homeowners should keep garbage and compost enclosed in bins, feed pets indoors, regularly check unused spaces, and avoid giving them access to attics and wall spaces. Portland has historically maintained good rat control through resident vigilance, resulting in fewer and less aggressive rats compared to other cities.","context":["Portland Real Estate Wildlife\nPortland: Yes, it’s a city in Oregon, but just because it’s urban doesn’t mean it can’t be wild. If you’re a new homeowner — or you’re thinking of buying a home in Portland — you may be surprised to learn that there are over 300 species living within city limits! Some may call your back yard, front garden or neighborhood park home. Read on to get to know the neighbors.\nBirds are a delight to everyone, whether you’re a dedicated bird-watcher or just enjoy seeing them flutter outside your window. Songbirds are abundant across Portland, but if they’re not as common in your neighborhood, putting up a bird feeder or bird house may not instantly draw them in. (Unfortunately, birds don’t have real estate agents to show them where the good homes are!) The National Wildlife Federation recommends using a “songbird mix” in your feeder to attract a wide variety of feeding birds. Areas of leaf litter as well as trees and shrubs native to Oregon are even better sources of bird food: the worms, insects, berries and nuts these birds evolved to eat — and they’re free! Check out this Metro article to learn more about creating friendly habitats in your backyard.\nOne bird to look out for is the European Starling. These birds are a major pest because they tend to form large flocks and nest in eaves and unused buildings. If there is a Starling infestation on your Portland property, call a pest control specialist.\nBird feeders naturally attract squirrels. According to the Oregon Department of Fish and Wildlife, there are four species of squirrel native to Portland: western gray, Douglas, American red and northern flying squirrels. The most commonly sighted squirrels in Multnomah and Washington counties are non-native: The Eastern gray and Eastern fox squirrel. Biologists recommend not feeding any squirrels because there’s no way to avoid feeding these invasive species. If you feed birds, buy a squirrel-proof feeder and avoid spilling birdseed on the ground. Also, acorns don’t help pay the mortgage, so avoid giving squirrels a free place to live in your home! Replace loose or rotting siding or shingles right away, and seal the areas around dryer vents and other openings.\nAccording to The Atlantic, Portland is better than most cities at managing its rodent population. Portland has fewer rats than other metros, and those that are here are not as aggressive as other urban rats. However, the article points out, this situation is due to the historic vigilance of residents and businesses alike, and homeowners should not be lax in their pest-prevention practices. Remember that, like squirrels, mice and rats can nest in attics and empty wall spaces, so be sure to avoid giving them access. Keep garbage and compost enclosed in bins, and feed pets indoors. Rats can also make their homes in disused sheds, bins and play structures, so be sure to check these spaces regularly and take appropriate steps to discourage rodent activity.\nAlso in the “pest” category, raccoons pose the added threat of attacking housepets and frightening humans! Although they can be cute, these animals are fierce and havoc-wreaking. If there are raccoons in your Portland neighborhood, you may need to lock your garbage and exclude all protein, including eggshells, from your compost bin. A licensed pest control company can trap raccoons that have taken up residence on your property — they love crawlspaces! If you have a resident raccoon, definitely have it removed before you list your home on the Portland real estate market. For more on Portland raccoons, the Portland Mercury has a very entertaining story.\nOpossums are not as common as raccoons but they share some characteristics: They feed on garbage or pet food and may carry disease and fleas. Unlike raccoons, they are typically not dangerous and are wary of dogs and humans. In fact, you may have opossums traveling through your property and never know it because these animals are strictly nocturnal. If they do pose a problem, call a licensed animal control specialist.\nMany central Portland residents may be surprised to hear that the stag on the classic Portland sign downtown isn’t the only deer in the city! Small herds of white tail and black tail deer wander through gardens and yards on the West side, in East Portland, and in many of its suburbs. While most people enjoy seeing the graceful creatures make an occasional trip through the neighborhood, gardeners find deer to be a bit of a pest. Not feeding deer is the best way to encourage them to move on. If you see one while driving, use caution — there are usually more about to cross the road behind it.\nPortland Fish and Amphibians\nWe don’t think of them as “backyard wildlife”, but fish certainly exist in Portland’s many streams and waterways. And, human activity impacts fish because water moves downhill — carrying with it whatever washes off of yards, roads and driveways. Portland biologists recommend avoiding chemical fertilizers and harmful weed-killers, and only washing your car at designated car-wash stations (use biodegradable soap). Be fish friendly!\nToads, frogs and other amphibians may already be living in your yard, and they’re a healthy part of a garden ecosystem. They feed on insects, and together with birds, they form a natural pest-control system! Frogs need a continuous source of water to survive, such as a small pond or a pool where rainwater collects.\nBees, Butterflies and Other Insects\nWhat would summer be without the buzz of bees and the chirping of crickets in your neighborhood park? Portland has an ideal climate for a variety of insects, including some rare and beautiful butterflies. Attracting them is easy with native shrubs and flowers, which also appeal to bees. Most urban Portland bees are honeybees, which are rarely aggressive. In fact, your neighbor might have a hive in his or her backyard!\nDon’t confuse bees with harmful wasps, yellow jackets and hornets. These pests tend to build nests in eaves and gutters and can be a painful nuisance. If you do find a nest, be sure to take care of it as soon as possible (but only at night when the insects are dormant).\nAnother common insect that poses a threat to Portland homeowners are carpenter ants, which can eat right through wood as the name implies. Termites and cockroaches, on the other hand, are not usually found here in the Pacific Northwest. If you suspect carpenter ants, call an exterminator right away as they can inflict significant home damage. Ask your real estate agent if you need a referral.\nWhat to do with injured wildlife in Portland\nFound a baby squirrel or bird with a broken wing? The Portland Audubon Society has a Wildlife Care Center that accepts native animals in need of help seven days a week! Always use caution in approaching wild animals, and use gloves or wash hands immediately afterwards.January 3, 2018","Mice and Rats: Health Hazards and How to Prevent Them\nMice and rats are some of the most damaging and dangerous pests to have in homes and businesses. Their habits cause extensive damage, and they are known carriers of many diseases. It is important to be aware of the risks posed by mouse and rat infestations, so we put together a guide detailing the causes, symptoms, and prevention methods of the main rodent-borne illnesses in the United States.\nHantavirus Pulmonary Syndrome\nHantavirus is a virus spread primarily by deer mice, white-footed mice, cotton rats, and rice rats. Typically, it is contracted after coming into direct contact with rodents or their urine and droppings, or by breathing in dust contaminated with urine or droppings. It can also be contracted through rodent bites, but that is not as common. Symptoms develop between 1 and 8 weeks after exposure, and they occur in two phases. Universal early symptoms include fatigue, fever, and muscle aches. Other early symptoms that occur in about half of all Hantavirus cases include chills, dizziness, headaches, abdominal pain, nausea, vomiting, and diarrhea. Late symptoms begin between 4 and 10 days after the early symptoms phase. These symptoms include coughing, shortness of breath, and lungs filling with fluid. Hantavirus has a mortality rate of 38%.\nLeptospirosis is a bacteria spread by rodents, as well as other animals. It is contracted by eating or drinking contaminated foods and water, or by contact of skin or mucous membranes with contaminated soil or water. Symptoms will typically arrive abruptly between 2 days and 4 weeks after exposure to the bacteria, although some people show no symptoms at all. The illness may occur in two phases. The first phase may consist of fever, chills, abdominal pain, diarrhea, vomiting, headache, muscle aches, red eyes, jaundice, and rash. If a person experiences a second phase, it will be more severe and may occur after a period of recovery from the first phase. The second phase may include liver or kidney failure, respiratory distress, or meningitis. Without treatment, recovery from leptospirosis may take months, and in some cases can lead to death.\nPets can also get leptospirosis, although it is rare in cats. Symptoms that are commonly seen in dogs include fever, abdominal pain, vomiting, diarrhea, refusal to eat, severe weakness and muscle pain, stiffness, severe depression, and the inability to have puppies. Younger animals are usually affected more than older animals.\nLymphocytic Choriomeningitis (LCM)\nLymphocytic choriomeningitis, or LCM, is a disease caused by lymphocytic choriomeningitis virus, or LCMV. It is typically spread by house mice. It can also be spread by pet rodents, but that is not as common. An estimated 5% of house mice in the United States carry LCMV. It is contracted either by direct contact with rodents or rodent urine and droppings, or by breathing in dust contaminated by rodent urine and droppings. It can also be spread through bite wounds from infected rodents, although this is much rarer. LCM may occur in two phases. Symptoms of the first phase appear between 8 and 13 days after exposure. Common symptoms of the first phase include fever, nausea, vomiting, lack of appetite, malaise, headache, and muscle aches. Less common symptoms include sore throat, cough, chest pain, joint pain, testicular pain, and pain of the salivary glands. If a second phase occurs, it will do so after a few days of recovery from the first phase. Symptoms of the second phase include, meningitis, encephalitis, meningoencephalitis, acute hydrocephalus, and, in rare cases, myelitis. As LCM is an infection of the nervous system, it can cause temporary or permanent neurological damage, including nerve deafness and arthritis. If a pregnant woman becomes infected with LCMV, she may pass the infection to the fetus. This can result in fetal death during the first trimester, or serious and permanent birth defects during the second and third trimesters. LCM is rarely fatal, with a mortality rate of less than 1%.\nRat-Bite Fever (RBF)\nRat-bite fever, or RBF, is caused by one of two bacteria that are spread by rats and possibly mice as well. Only one of the two RBF-causing bacteria is found in the United States, and that is streptobacillus moniliformis, which causes streptobacillary RBF. As the name suggests, RBF is typically contracted through a bite or scratch wound from an infected rodent, or through contact with a dead rodent. It can also be contracted by eating or drinking food or water that is contaminated with rat droppings, in which case it is referred to as Haverhill fever. Symptoms appear between 3 days and 3 weeks after exposure to the bacteria, by which time any bite or scratch that caused the illness would likely be healed. Common symptoms of Streptobacillary RBF include fever, vomiting, headache, and muscle pain. In addition, approximately 5 out of 10 patients experience joint pain or swelling, and approximately 3 out of 4 patients experience a rash. This rash will appear on hands and feet and look like flat, reddened areas that have small bumps. People with Haverhill fever may also experience sore throat and more severe vomiting. Complications with Streptobacillary RBF include abscesses inside the body, liver or kidney infections, pneumonia, meningitis, and infections involving the heart. Approximately 1 out of 10 people who get Streptobacillary RBF die.\nSalmonellosis is an infection caused by the bacteria salmonella, and can be spread in many ways, including by rats and mice. When spread by rats or mice, it is contracted by eating or drinking food or water that is contaminated with rat droppings. Symptoms typically appear between 6 hours and 6 days after exposure, although some people may not develop symptoms for several weeks. Symptoms usually last between 4 and 7 days, but can last for several weeks. Common symptoms of salmonellosis include fever, abdominal pain, and diarrhea. Some strains of salmonella can cause severe disease, as well as infections of the blood, bones, joints, nervous system, or urine.\nTularemia is caused by a bacteria and can be spread in many different ways, including by rats and mice. There are multiple forms of tularemia, which are categorized by how the bacteria was contracted. Symptoms vary by form, but all forms cause fever. Causes and symptoms of the main forms of tularemia are listed below. Please keep in mind that this list only includes the causes pertaining to rodents. The forms of tularemia that are listed may have other causes that are not included in this list.\n- Ulceroglandular tularemia is caused by handling an infected animal. Symptoms include a skin ulcer where the bacteria entered the body, fever, chills, exhaustion, and swollen and painful lymph glands.\n- Glandular tularemia is the same as ulceroglandular tularemia in all ways, except that it does not cause skin ulcers.\n- Oculoglandular tularemia is caused by the bacteria entering through the eyes, usually when someone is butchering an infected animal and touches their eyes. Symptoms include irritation and inflammation of the eye, an ulcer on the inside of the eyelid, sensitivity to light, and swelling of the lymph glands in front of the ears.\n- Oropharyngeal tularemia is caused by eating or drinking contaminated food or water. Symptoms include vomiting, diarrhea, sore throat, tonsillitis, mouth ulcers, and swollen lymph nodes in the neck.\n- Pneumonic tularemia can be caused either by breathing in contaminated dust or aerosols, or by leaving another form of tularemia untreated, allowing it to spread through the bloodstream to the lungs. Pneumonic is the most serious form of tularemia. Symptoms include chest pain, difficulty breathing, and a dry cough.\n- Typhoidal tularemia is a combination of general symptoms of tularemia, without any of the localized symptoms of other forms. Such general symptoms include extreme exhaustion, enlarged spleen or liver, vomiting, diarrhea, and pneumonia.\nMost cases of tularemia can be treated fairly easily with antibiotics, although some cases are life-threatening.\nFor more information about these and other rodent-borne illnesses, visit this page of the CDC’s website.\nDiseases spread by mice and rats can be avoided if necessary precautions are taken. For one, avoid any contact with rodents that are not pets. Take steps to make your home or business an environment where rodents cannot or do not want to live. Do not swim or wade in water that could potentially be contaminated with rodent urine or feces. If your job requires you to come into contact with anything that is potentially contaminated- such as soil, water, or infested buildings- always wear protective footwear and clothing. When mowing, check the area beforehand for any sick or dead rodents, and do not mow over them if there are any. Clean up any rodent nests, as well as any urine and droppings. For information on how to safely clean up dead rodents, rodent nests, or rodent urine and droppings, visit this page on the CDC’s website. When handling nests or wild rodents, dead or alive, always wear gloves and wash your hands with soap and warm water after.\nAlthough it is rare, diseases can also be spread by pet rodents, so precautions should be taken when handling them as well. When choosing a rodent pet from a pet store or breeder, avoid any that look sick or otherwise unwell. Do not choose any that are in the same cage as rodents that look unwell, either. If possible, clean your pet’s habitat, food and water bowls, toys, and any other objects outdoors. If outdoor cleaning is not an option, then use a large bathtub or sink that can be easily disinfected. Avoid using a kitchen sink. Always wash your hands with soap and warm water after handling your pet or its belongings.\nIf you are bitten or scratched by a rodent, wild or domestic, clean the wound immediately with soap and warm water. Contact a health care provider as soon as possible and tell the provider about the bite or scratch. Get treatment if need be.\nIn addition to spreading illnesses, mice and rats tend to cause extensive, and usually expensive, damage to homes and businesses. They will chew through just about anything they can get their teeth into, including walls, floors, insulation, pipes, wires, upholstery, important documents, family heirlooms, and more. The damage to insulation can make temperature regulation very difficult and expensive. Lack of insulation means having to run air conditioners and heaters much more than usual, in addition to the fact that insulation can be expensive to replace. Chewed wires are quite dangerous, and actually cause about 25% of the house fires in the United States each year. Mice and rats also cause fire risks when they tunnel into and build nests inside of appliances, causing them to short-circuit or malfunction. When an infestation is severe, the urine of the mice or rats can soak into wood and compromise the structural integrity of a building. For information on how to prevent infestations, check out our mouse and rat FAQ pages\nA few mice or rats can quickly turn into an infestation. Rodent infestations are not something to be taken lightly or ignored, as they can be potentially dangerous. If you think you have mice or rats in your home or business, call our experts today and we’ll send a technician out right away.\nYou’ll be supporting research into lyme disease, too.\nChoosing Excel helps us support the John Hopkins Lyme Research Center. You will help them advance the critical knowledge and clinical tools urgently needed to improve Lyme disease patient care and health outcomes."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:1a024b6f-ccd1-41a3-b7e5-00b80626d195>","<urn:uuid:382f354d-6d21-444a-bc47-1742e2e48f28>"],"error":null}
{"question":"What was the specific impact of watching 'Die Hard' on this screenwriter's career path?","answer":"When he watched 'Die Hard' on bootleg beta tape, it was the moment he realized he wanted to tell stories in some fashion. This was one of the key films that inspired his career direction, along with T2 which left him so stunned he watched it twice in a row at the theater.","context":["HOLLYWOOD, CA - JANUARY 30: Writer/Creator Derek Kolstad attends the Premiere Of Summit Entertainment's \"John Wick: Chapter Two at ArcLight Hollywood on January 30, 2017 in Hollywood, California. (Photo by Todd Williamson/Getty Images)\n[pullquote_right]I’ve met a number of iconic figures out here over the past few years, but Dolph… damn, dude[/pullquote_right]\nToday I’m joined by screenwriter Derek Kolstad; writer of “The Package” (starring Dolph Lundgren and Steve Austin) and “One in the Chamber” (starring Dolph Lundgren and Cuba Gooding Jr.).\nEoin: You’ve written two movies starring Dolph Lundgren (The Package & One in the Chamber); did you have him in mind when creating the characters?\nDerek: For ONE IN THE CHAMBER, I was brought on board to rewrite a script which had both Dolph and Cuba already attached. As for THE PACKAGE, yeah, he was the go-to actor to play the role of the chief bad guy opposite Austin. Btw, I’ve met a number of iconic figures out here over the past few years, but Dolph… damn, dude. First of all, unlike most actors, Dolph really is that tall and imposing. However, he is also a gentle and kind soul who enjoys coupled banter over a one-man soapbox. Oh, and yeah, the rumors are true: the dude is intimidatingly bright.\nEoin:Following on from that, when writing a screenplay, do you picture particular actors in the main roles?\nDerek: I don’t know. Sometimes, I suppose. More often than not, though, I see a number of different actors in the role amidst the various scenes of the story. For instance as I wrote SCORN (the next spec script to go out), the main character-in my mind- was a revolving door through which any number of actors (both living and dead) fell into the role: Harrison Ford, Robert De Niro, Jean Reno, George Clooney, Burt Lancaster, Richard Burton, Clint Eastwood, Sidney Poitier, Denzel Washington, and Lee Marvin, to name a few. They each share moments of brutal solemnity in their work, and I love that.\nEoin:What is your process for writing a screenplay? Do you write in chronological order or do you create scenes when they pop into your head?\nDerek: I drink and I doodle. I love a sharpened pencil (and yet how rare are those nowadays?) or a chewed-upon pen alongside a dog-eared, college-ruled notebook and a tall glass of gin with ice, seltzer, and lime. The funny thing, though, is that I never look back at what I’ve written within. Just writing out thoughts on paper kickstarts the storytelling process. I don’t necessarily enjoy writing pitches, treatments, and outlines. I’d much rather just leap into the screenplay itself. And yeah, I do write in chronological order. Every now and then, I’ll leap forward a couple of scenes to write a heading and a brief description of what comes next, though, because sometimes I tend to forget where I’m heading. I have a dozen or more screenplays which I’ve hit page 40 only to stop and file ’em away because I’m either lost, confused, or -which is often the case- bored with the damn story.\nEoin:As a writer, are you able to advise on the film set about how you want a scene to look or is it left to the director?\nDerek: No. Well, in my mind, at least, that is. The way I figure it, my screenplay is akin to an architectural design wherein the finished product reflects the vision of the director, the voice of the writer, and the mind-grinding work of the cast and crew. Hell, the finished production of any film is nothing short of a small miracle in and of itself. As for visiting the set, I’ve really no interest. It’s a different world, and one I respect greatly, but come the end of the day, I’m best sitting alone before a computer with two dogs snoring on the bed behind me.\nEoin:Would you be interested in directing in the future?\nDerek: No. I’ve really no interest. At all, in fact. And there is also that fear of being the writer who directs a bomb and then can’t exactly go back to being a writer. I won’t name names, but we’ve all heard the stories. With writing, I found something I love, and -as it finally begins paying the bills- I’m gonna’ stick with it.\nEoin:What is your favourite film genre and is there a specific film that inspired you to get into writing?\nDerek: I’m an unabashed lover of “genre” films: action, suspense, horror, and the like. I want escapism. Strangely enough, I’m somewhat of a pacifist (no one can really wear that moniker in full) but when I watch a movie, I want well-choreographed chaos. I mean, did you see The Raid?!?!? I can’t remember the last time I saw a movie in the theater -with subtitles, at that- where -at about a half-dozen times- people leaned forward in their seats with a collective -and goose bump inducing- OOOOOOOOOOOOH! I LOVE THAT! I mean, I hold a great deal of respect for those entrenched in the world of all things Oscar, but give me a movie with a scene that begins with “I told you I’d find you” and I’m your biggest fan.\nDerek: As for the movie that inspired me, that one’s a bit tough. I grew up watching all of the black-and-white classics along with those from the silent era (Harold Lloyd and Buster Keaton are gods among men). I gravitated towards American noir from the fifties and sixties. THE THIRD MAN is still one of my favorite movies. However, and my apologies if this answer sounds cliché, when I saw DIE HARD on bootleg beta tape back in the day, I knew I wanted to tell stories in some fashion. When I saw T2, I was stunned. I sat in my seat -stunned- as the theater first emptied and then refilled only to watch it again. I have a special place in my heart for MILLER’S CROSSING because it intimidates the hell out of me. Y’know, to sum up, though, I grew up reading… quite voraciously which -sadly- I don’t do all that much anymore. We’d hit up the garage sales for all of the old pulp novels. Alistair MacLean was my favorite. I owe a lot to him.\nEoin:Do you ever act out scenes in your screenplays with family/friends?\nDerek: Ha. No. Now, I know that someday I’ll probably have to sit in a room during a read through and-dude- I shudder at the thought. It’s not that I’m ashamed or embarrassed by what I write it’s just that I’m all too familiar with it. In fact, it’s a toss-up as to if I’ll even watch any of the films I write. I write, I deliver, and I move on. Here’s to those who produce it and those who watch it; may they both be pleased. Me, I’ll be writing the next one.\nI do have one important person in my life who serves as the final eyes on a screenplay before I send it off to the managers (Josh Adler and Mike Goldberg at NWE) and agent (Charlie Ferraro and Max Michael at UTA): Sonja Kolstad, my wife, whom I lovingly – and quite respectfully, I assure you – refer to as “The Script Bitch”. She reads more than anyone I know and is a stickler for grammar, continuity, and cohesion…. and she can be a brutal, brutal critic, and yet, is right far more often than she is wrong. Word of note, though, one of the more disheartening things to hear is her laughing from the other room while reading my script, knowing full well the scene being read wasn’t intended to be funny. Sigh. As they-whoever they may be- say; the work ain’t in the writing, but in the rewriting…\nEoin:Can you tell us about what you’re working on next?\nDerek: I recently sold ACOLYTE to VOLTAGE PICTURES (the extremely talented crew behind HURT LOCKER and KILLER JOE). And-as I mentioned- I just finished up SCORN which is a lean and mean tale of revenge similar in tone to Taken, Leon the Professional, and Man on Fire. It’s out to UTA for final review and release.\nEoin:Thanks for taking the time to chat and all the very best with your writing career."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:0d14094e-2fa0-4f03-b508-40c890d49739>"],"error":null}
{"question":"Hey, need help patching a hole in my rayon dress. What's the non-sewing method to fix it?","answer":"To fix a hole in a rayon dress using the non-sewing patch method: 1. Wash, dry, and iron the dress to remove wrinkles. 2. Measure the hole and add ¼ inch to both sides to determine patch size. 3. Cut the iron-on patch to size, ensuring it matches or blends with the dress color. 4. Place the patch under the hole. 5. Cover with a cloth and iron on medium heat to activate the patch's heat-activated glue. 6. Check if the patch is properly fixed by turning the dress inside out and touching it.","context":["Rayon is one of the most comfortable fabrics you can wear. It is highly absorbent and lightweight. It is appropriate for all types of summer and sporting clothes. From time to time you may unknowingly get a hole on one of your rayon dresses. To fix a hole in a rayon dress is easy and there are different methods you can use.\nHow Do You Fix A Hole In A Rayon Dress?\nYou can choose a sewing or a non-sewing method to fix a hole on your rayon dress. You can use a sewing machine with sharp needles, polyester threads, and small stitches to fix a rayon dress.\nYou can also sew it by hand. Thread a needle with polyester thread and use the best stitch you know to mend the hole in the dress. This is the fastest and easiest method to fix a hole in a rayon dress. Fix the hole and wear the dress immediately.\nFor a non-sewing method, you can use a patch to fix a hole in a rayon dress. Buy an iron-on patch from a sewing craft shop. Iron it onto the hole in the dress to seal it. Find a patch that is similar in color to the dress you want to fix.\nMethod 1. Using A Sewing Machine\nStep 1. When you are working with rayon, the first thing you need to do is wash the fabric or dress before you sew. Washing it in cold water to prevent it from shrinking. If you wash it after fixing it, it may cause the sewn part to distort the dress due to added stitches.\nStep 2. Once you have washed the dress, air dry it for a while. Iron the dress to remove any wrinkles and to dry it off completely. For the best results, iron your dress while it is slightly damp.\nUse medium heat while ironing on rayon. Overpressing rayon can sauce the fabric to shine. Also, remember to cover the rayon dress with another cloth as you iron it to prevent the color from running. Or, if it’s already dry, you can spray water on it as you iron it.\nStep 3. Your dress is ready for sewing. Before you bring it to the sewing machine, prepare the sewing machine to mend rayon. First, make sure that you have a sharp needle on your sewing machine. Sharp needles are the best to use while working on a rayon dress.\nSecondly, use a polyester thread. It blends in well with the rayon fabric. When you have threaded your sewing machine, set your stitches to about 2mm. Also, thread your sewing machine with thread the same color as your dress. Smaller stitches will be invisible and are the best when sewing on a rayon dress.\nStep 4. Your dress is ready for sewing. Bring it to the sewing machine for sewing. If your dress has a large hole, you will need to use pins to hold the dress together before you have started sewing. Since it is a slippery fabric, pins prevent the fabric from moving around as you sew.\nFor smaller holes, bring your dress to the sewing machine and start sewing. Seal the hole firmly. Your dress is ready to wear.\nStep 5. Confirm that the hole has been properly shut and that there aren’t traces of mending since you used the same color of thread. If there are smaller gaps you can make final sewing on your sewing machine.\nMethod 2. Using A Patch\nStep 1. Prepare your dress for repair, Wash, dry, and iron it. This ensures that your dress doesn’t have any wrinkles on it. Using a patch to repair a wrinkled fabric or garment may cause unwanted shrinkage on your garment. This may make it impossible to wear or tear it further once it is washed again.\nStep 2. When your dress is ready, lay it on your working surface with the hole exposed. Measure the length of the hole. This helps you to identify how large of an iron-on patch you will require to fix the hole. For the length of the patch you need, add at least ? inch on both sides of the hole.\nStep 3. Cut the length of the patch that you need. Make sure that your patch is the same color as the fabric. If you can’t get the same color patch, get one that will easily blend in with your dress and will not be visible when fixed onto it.\nStep 4. With your dress properly laid out on your working surface, bring your patch and fix it right under the hole. Spread it out as straight as possible to cover the hole on your dress completely.\nStep 5. Get a cover cloth and lay it on the dress. Switch on your iron and set it to medium heat that is suitable for the rayon fabric. Now iron the patch onto the hole. Iron-on patches have a heat-activated glue on their surface. Once ironed, the patch sticks onto the surface where the patch is placed. For this case, the patch will fuse with the hole on your dress.\nStep 6. Confirm that your patch is properly fixed in place. Turn your dress inside out and touch the patch. If it is properly fixed, you have mended the hole on your rayon dress without sewing. If the patch is not properly fixed, iron it for a few more seconds for it to have a better grip on your dress.\nMethod 3. Repair By Hand\nStep 1. Prepare your dress for repair by washing, drying, and ironing it. Rayon fabrics should be washed in cold water and with a mild detergent to avoid shrinking or running colors. It is best if you hand wash your rayon dress. Further, air-dry it. Machine drying will shrink and spoil it.\nRayon is best ironed when damp or wet. You can spray water onto the garment while ironing or iron it just before it is completely dry.\nStep 2. You will need a sharp needle and a thread the same color as your dress. Thread your needle with a long piece of thread so that you won’t need to stop before you are through to thread your needle again. Make sure to use a thin thread. If it’s possible, you can split your thread into a single strand to make thin stitches on the rayon fabric.\nStep 3. Turn your rayon dress inside out. This is the best way to sew by hand. It hides your stitches from view on the right side of the dress. To fix the hole, make your stitches just slightly away from the hole. This ensures that you have a stable stitch. Stitching directly on the hole can cause your stitches to hold loosely and come off.\nStep 4. Sew to the end of the hole, making small firm and tight stitches. In the end, finish sewing slightly beyond the hole to make a firm knot with your stitches.\nStep 5. Confirm that you have properly sewn the hole in your rayon dress. If this is so, cut off the excess threads if there are any. This helps to keep your dress neat and repair stitches invisible.\nHow Do You Fix Shrunken Rayon Clothes?\nRayon easily shrinks when washed. This is why it is best washed with cold water and by hand. It also requires a mild detergent to wash. You may unknowingly machine wash and dry your rayon dress which causes shrinkage. How will you unshrink it?\nYou will add a tablespoon of baby shampoo or hair conditioner to about a liter of water. Soak your shrunken rayon garment into the water for up to 30 minutes. Get it out of the water then leave it to dry. For the best results, let it air-dry.\nWhile the garment is still damp, try and stretch it back to its original size. Then leave it to dry completely.\nOnce it is dry, confirm that it is back to its original size. If it isn’t, you will have to steam iron it. This will help to reduce the remaining shrinkage and get it back to its original or near the original size.\nDoes The Rayon Fabric Stretch?\nTechnically, rayon doesn’t stretch, It is, however, affected by moisture and humidity. Rayon easily absorbs moisture from the atmosphere which causes it to become longer. Later on, when it is dry, it gets back to its original size.\nThe humidity or moisture from the atmosphere once absorbed by the rayon fabric causes its fibers to lose their tensile strength. This causes the perceived stretch of the fabric.\nHowever, rayon does shrink. Especially if it is poorly handled while being washed. If you wash and dry it in the machine, it will shrink. It may also be difficult to get back to its original size once it shrinks due to washing."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:d59a966f-8354-4393-b8d4-fd212e433687>"],"error":null}
{"question":"New disease-resistant rose varieties 2023: blushing + pink knock out specs?","answer":"Two new disease-resistant roses have been introduced: 'Blushing Knock Out' with pale pink blooms and 'Pink Knock Out'. Both are lighter-colored variations of the original raspberry-colored 'Knock Out' rose. These new varieties maintain the disease resistance that made the original Knock Out famous, particularly against black spot fungus. They produce abundant single flowers that look beautiful on the plant but aren't ideal for cut arrangements. Like the original Double Knock Out roses, they were bred to be extremely resistant to diseases and drought.","context":["Growing Double Knock Out Roses\nThese stunning, low-maintenance roses practically grow themselves.\nThe Double Knock Out Rose\nThe original Double Knock Out Rose was introduced in 2000 and was named an All American Rose Selection (AARS) winner that same year. The award is the highest honor a rose can receive. It's given after a rose undergoes 2 years of trial testing in a variety of climates and growing conditions around the country.\nImage courtesy of Star Roses and Plants/Conard-Pyle\nRoses seem to have everything a gardener could want: beauty, fragrance and a variety of colors, shapes and forms. But roses also have a reputation for being difficult to grow, and in many cases, they’ve earned it. Hybrid teas need regular spraying or dusting to combat diseases and pests. Climbers need training and tying up. And most roses demand regular fertilizing, watering and mulching, along with careful pruning and grooming. Roses can be the stars of the garden—but they can be fussy and frail, too.\nPlant breeders had been working to produce easier-to-grow roses for years when Wisconsin rose breeder William Radler introduced his new Knock Out Rose in 2000. Rosarians were thrilled to discover a new rose that had the best qualities of a classic rose, but that demanded much less care. The rose was named an All America Rose Selections winner the same year it debuted, and Knock Outs have been snapped up by consumers ever since.\nKnock Out roses were bred to be extremely resistant to diseases and drought, and if that wasn’t enough, they’re also repeat bloomers, bearing a new flush of flowers every five to six weeks from spring until the first hard frost. They’re heat-tolerant across most of the U.S. and cold tolerant to zone 5.\nSince the original cherry-red Knock Out was introduced, the rose family has grown to include Double Knock Out roses (a variety with doubled blooms), also available in cherry red and in pink.\nDouble Knock Out roses are very easy to grow. Give the plants full sun in a garden spot with fertile, well-drained soil and space them about four feet apart to allow good air circulation.\nTo keep the blooms coming, fertilize your Double Knock Outs after every bloom cycle with any good rose fertilizer. You don’t need to snip off the spent flowers, because these vigorous shrubs are self-cleaning. They mature at three to four feet wide and tall, but you can prune them while they’re dormant—in late winter or early spring—if you want to control the size.\nOtherwise, Double Knock Outs only need light, annual pruning to shape them or remove crossed or interior branches. Every two to three years, prune the old canes back by a third to help reinvigorate the bush. It’s even okay to shape them up with hedge shears, and you may want to do that if you grow your plants in a hedge.\nRoses in the Knock Out family are planted in much the same way as other roses. Dig a hole twice as wide and as deep as the pot the plants are growing in, and use your shovel to chop up and loosen the soil at the bottom of the planting hole.\nTurn the pot upside down and gently shake or tap it to remove the rose. Then use your fingers to loosen its roots. Put the rose in the hole, keeping its base level with the soil line, and back fill the hole. It’s a good idea to add manure or other amendments to help aerate the soil and keep it from compacting.\nFinally, water your rose thoroughly and deeply. Give it another one or two inches of water each week if rainfall is insufficient, and add mulch to help hold moisture in the soil and control weeds that may pop up and compete for water and nutrients.\nDouble Knock Out Roses are great to grow with daylilies, coneflowers and many other annuals and perennials. Many gardeners like to use low-growing plants around them, such as dianthus (also called pinks), verbena or calibrachoas. These shorter flowers help hide the lower rose branches, which can start to look a little leggy or bare as the bushes continue to grow. Try these suggestions for other companion plants:\n- Mexican sage\n- Herbs such as catmint, thyme or oregano\n- Lambs’ Ear (Stachys byzantina)\nDouble Knock Out Roses in a formal garden look elegant when planted alongside boxwood shrubs, but they’re equally at home in a cottage garden with bellflowers, delphiniums, heliotropes and herbs like oregano, parsley and thyme. These roses won’t demand as much time and attention as traditional roses, but they’ll reward you with as many—or more—beautiful blooms.","What to do in your garden in January\nPruning shears. Corona Clipper, a garden- tool company, now offers the ergonomically designed 1-inch Adjustable Handle Bypass Pruner that can be fitted to different hand sizes. The nonstick-coated carbon steel blades make clean and easy cuts ($25).\nRoses. Look for two new disease-free roses called ‘Blushing Knock Out’ (pale pink) and ‘Pink Knock Out’. Both are lighter-colored versions of their parent, raspberry-colored ‘Knock Out’, which is considered one of the best landscape roses ever for its resistance to black spot (a fungus disease) and easy-care habit. All produce a profusion of single flowers, which are beautiful on the plant but not good for the vase.\nBare root. In winter and early spring, nurseries sell leafless plants whose roots are packed in damp sawdust, not soil. Such plants are inexpensive, easy to handle, and adapt quickly to your garden soil. Bare-root stock usually comes in after New Year’s in mild-winter areas, and just as the ground thaws (around March or April) in Sunset climate zones 1-3. Look for berries, grapes, fruit and shade trees, ornamental shrubs (including roses) and vines, and vegetables.\nGrapes. Nothing is easier to start from cuttings than grapes. Find a friend with a vine and take six to eight pencil-length cuttings, snipping each off ½ inch below a node. Plant each cutting in a 4-inch clay pot and set on a windowsill. Water whenever the top inch of soil dries. After plants are well rooted and leaf out, transplant into a sunny spot in the garden.\nHazelnuts. Over the past 30 years, hazelnuts (filberts) have been devastated by filbert blight and are rarely planted by home gardeners. Now there’s a blight-resistant variety available called ‘Santiam’ that produces a heavy crop on a smaller tree. You can order it (along with a pollenizer, such as ‘Zeta’) from Raintree Nursery (360/496-6400).\nStrawberries. Sunset climate zones 4-7: To get the longest strawberry harvest, plant three different varieties: June-bearing ‘Rainier’ for a big, tasty main crop; ‘Puget Summer’ for a late-season (early July) crop; and ‘Seascape’ for continuous harvest through fall.\nPerennials. If you have a cold frame, greenhouse, or cool porch, sow aster, delphinium, hellebore, pansy, Shasta daisy, veronica, and viola seeds now. Transplant seedlings into the garden a month before the last spring frost.\nWinter-flowering shrubs. Zones 4-7, 17: Scout nurseries for blooming Sarcococca, Camellia sasanqua, Viburnum x bodnantense, V. tinus ‘Spring Bouquet’, wintersweet (Chimonanthus praecox), and an array of heaths (Erica) and witch hazels (Hamamelis). A great Northwest source for winter trees and shrubs is Greer Gardens (800/548-0111).\nApply dormant oil. When the weather is mild and dry, spray leafless fruit trees and roses with horticultural oil. The oil smothers the overwintering eggs and larvae of insects that infest plants when they emerge in spring.\nControl rose pests. If black spot, rust, or mildew blasted your roses last year, do three things now. First, make sure plants are located in an area that gets six to eight hours of full sun; if not, transplant them to an area that does. Second, rake diseased leaves and put them in the trash (do not compost). Third, spray plants and the soil beneath them with lime sulfur. If your roses had serious insect problems last year, mix in a horticultural oil (some brands come premixed).\nMulch asparagus and rhubarb. To feed plants and keep down weeds, layer rhubarb and asparagus beds with a 2-inch layer of composted manure.\nPrune ornamental and fruit trees. Zones 4-7: Snip out dead, diseased, and injured branches, then remove crossing branches or parallel ones that are too close together. Finally, prune for shape, working from the inside of the tree out, and from the bottom to the top. Apricots, cherries, peaches, and plums usually need only light pruning; apples and pears usually benefit from more thorough pruning. Zones 1-3: Hold off pruning until the weather turns mild.\nPrune roses. Zones 4-7, 17: On hybrid tea roses, cut out all but the most vigorous three to five canes. On the remaining canes, remove dead, diseased, crossing, and injured branches. Prune landscape roses ― including everything from ‘Flower Carpet’ to rugosa roses ― only lightly to shape. (Wear goatskin gloves or you’ll be picking tiny thorn tips out of your skin for days.) Compost rose prunings, or if they’re diseased, let them decay in a brush pile or send them out with the trash."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:b67cc236-c3b4-4971-a14e-227c7363cbc9>","<urn:uuid:e488cd8f-b1fe-4b7d-90db-fff84c342d6b>"],"error":null}
{"question":"Which type of wood is more durable for cutting boards - acacia or cherry wood?","answer":"Both acacia and cherry wood are highly durable materials for cutting boards. Acacia is a species of hardwood known for its durability and resistance to scratches and dents. Cherry wood has a Janka hardness rating of around 1,000 pounds of force (specifically, Sweet Cherry rates at 1,150 pounds and Black Cherry at 950 pounds), and is well-known for its durability. Additionally, cherry wood has self-healing properties that can repair minor damage from kitchen knives. Both woods will last for many years with proper care and maintenance.","context":["A cutting board is the most used product in our kitchen, and with a quality wooden board in use, they can be even more valuable. Nowadays, people like to not only prepare their meals on these elegant boards, but also use them as serving plates at meal time.\nWhile a wooden cutting board is far more durable and safe to our knives and benchtops, they do require a little extra love and attention. Regular cleaning of your board is essential as well as applying an oil for cutting boards to keep it looking good and working at its best.\nAcacia wood cutting boards are one of the most popular types of material used for superior cutting boards, and this unique wood has a range of benefits to the owner. Just like any quality wood, though, you will need to care for it correctly with a mineral oil cutting board product and regular cleaning.\nAcacia is a species of hardwood, known for its gorgeous colours and durability. This unique wood is the ideal material for a cutting board as it’s strong enough to withstand years of use, but is also very resistant to scratches and dents.\nAnother reason for acacia’s popularity, particularly with cutting boards, is its affordability. Of all the quality hardwood options, it comes in at just a fraction of the price of the others. Just because it’s more cost-effective does not mean the wood is inferior, as it has all of the same benefits of the other hardwoods.\nThe surface of an acacia wood cutting board is soft to the touch, meaning your knives and benchtop will remain unharmed as you cook. However, this gentle surface covers a strong and durable wood that will last your kitchen for many years.\nWoods need to be cared for, whether they’re in our furniture, homes, or kitchen accessories. Maintaining and caring for an acacia wood chopping board can be done with regular cleaning and a cutting board oil applied every so often.\nThere are many advantages to oiling your cutting board regularly, and it’s such a simple job with dramatic effects that you may find yourself wanting to do it all the time. Here are just a few of the benefits from applying chopping board oil to your acacia:\nWhen selecting an oil for wood cutting board, there are a few important things to consider. Always choose an oil free from fats, as these can enter the cracks of the wood and turn rancid over time, leaving a very unpleasant smell.\nWhile there are many options available for specially marketed wood oils, the best oil for cutting boards is a mineral based food grade one. This cheap and effective product has all of the best qualities to help prolong the life of your acacia wood board.\nMineral oil is odourless and colourless, so it is ideal for wooden cutting boards. The natural properties of this oil make the wood water-resistant so it’s ideal for keeping moisture out which can damage the boards.\nNow that you have the best oil for the job, you’ll need to follow a few simple steps to finish the process. Allow for one to two days for the entire job, as there is some drying time in between steps.\nBesides the regular cleaning you should be doing after each use, it is helpful to give it a thorough clean before you decide to oil the board. Using white vinegar, scrub this into the board and let the pH levels of this product remove any excess germs or food particles left behind.\nAfter a thorough clean, leave your board out in the open air to dry. It’s best to do this overnight so you can ensure that no moisture is trapped deep inside the wood grains.\nTake your mineral oil for cutting board use and soak a clean, dry rag with it. In slow and steady movements, coat the surface of the board with enough oil so that you can see it.\nAfter applying the oil, you’ll need to leave the board again to dry completely. Try to oil it at night before retiring to bed and let it sit overnight for the best results.\nCheck the surface of your board the following day to see if you need to remove any excess oil. If the surface is sticky or oily feeling, get a new, dry cloth and make small circular motions over the top to remove any remaining oil.\nThe first time you oil your board, you can be a little more generous with the oil as this will allow it to reach deep into the surface. Once the board has been broken in, only apply enough oil to cover the surface without applying too much. With these few simple steps, you’ll be adding years to the life of your favourite kitchen accessory.","Cherrywood cutting boards seem to be everywhere these days. After years of plastic cutting boards gaining popularity, it seems more and more people are turning to natural alternatives, and cherrywood is a favorite.\nCherrywood cutting boards are popular because they are durable, non-toxic, aren’t harmful to knives, and they look good sitting on the countertop.\nThere are many reasons why you should consider adding a cherrywood cutting board to your kitchen. In this article, we’ll discuss in-depth why cherrywood cutting boards are popular, and what you need to know before you buy one.\nWhy Cherrywood is so Popular for Cutting Boards\nCherrywood is popular for cutting boards because it meets all the requirements of a wood that will come in contact with food, AND it is a beautiful wood. Let’s take a closer look at the qualities that make cherrywood the ideal wood for cutting boards.\nCherrywood Cutting Boards are Durable\nCherrywood is well known for its durability. Buying a nice cherrywood cutting board will be money well spent because if you take good care of it, it will last years! But why is cherrywood so durable?\nCherrywood is a Hard Wood\nCherrywood is a hardwood. In fact, depending on which variety of cherrywood is used, it has a Janka hardness rating of around 1,000 pounds of force. This means that it takes about 1,000 pounds of force to embed a .44 inch steel ball .22 inches into the wood.\nTo give you a comparison, according to the Wood Database, these are the harness rating for other woods.\n- Sweet Cherry: 1,150 pounds of force\n- Black Walnut: 1,010 pounds of force\n- Black Cherry: 950 pounds of force\n- Soft Maple: 950 pounds of force\n- Redwood: 450 pounds of force\n- Sugar Pine: 380 pounds of force\nOf course, the hardness of the wood isn’t everything, and you don’t want the wood to be too hard. We’ll talk about that more in a later section.\nCherrywood is Self-Healing\nUnlike materials like plastic or even stone, cherrywood’s cell structure means that it can actually heal itself from any minor damage caused by your kitchen knife. A plastic cutting board will deteriorate rather quickly while your cherrywood cutting board still looks brand new.\nEnd grain cutting boards are better at self-healing than edge grain boards. What’s the difference? Picture a 2×4. Edge grain boards are made with the long, smooth, flat side facing up. End grain cutting boards are made with the 2”x4” rough end facing up.\nIt takes a bunch of these small ends to make an end grain board, and then they must be glued together. This extra processing makes them more expensive.\nEven Cherrywood can’t heal from deep gouges, so you should always treat your cutting boards well. They put up with a lot of abuse, so no need to test out the extent of the self-healing properties.\nCherrywood has Tight Grain\nCherrywood, like all woods used for cutting boards, has a tight or fine grain. This means that the fibers of the wood sit close together. The tighter grain wood has, the better because it means that it has a less porous surface. There aren’t as many places for bacteria to hide, and the wood will not stain as easily as a wide grained or open-grained wood.\nCherrywood Won’t Hurt Your Knives\nWe’ve already talked about how cherrywood cutting boards are hard and durable, but they aren’t too hard, and that’s important. Cutting boards made of stone like granite will dull knives rapidly, rendering them unusable over a short period of time if you don’t sharpen them regularly.\nFor cherrywood, this isn’t a problem. The wood is soft enough that it isn’t a problem for your knives.\nIt also means that the cutting board won’t damage your countertop like a heavy granite cutting board could.\nCherrywood is Safe and Clean\nWhen it comes to your kitchen, safe and clean are a top priority. Nobody likes food poisoning. Cherrywood hits the marks for both of these, and here’s why:\n- Anti-Microbial: Experts agree that wooden cutting boards are safer for food preparation because they trap bacteria away from your food. When they dry, the bacteria are killed. They also have fewer places for bacteria to hide because they don’t get cut into as much as plastic cutting boards.\n- Non-Toxic: Cherrywood is food safe! Most trees that produce edible fruit, nuts, or sap have non-toxic wood. Although if you’re making a cutting board yourself, you should probably double-check on the specifics of the wood you intend to use.\nCherrywood Makes Stunning Cutting Boards\nThere is no denying the visual appeal of cherrywood cutting boards. Let’s take a look at some of the ways cherrywood is used to make beautiful cutting boards:\n- Edge cut cherrywood cutting boards are generally simple with a natural but neutral look. They are finished with a food-safe oil that deepens the natural color of the wood, while subtly highlighting the simple grain pattern.\n- End cut cherrywood cutting boards are eye-catchers. You noticed these cutting boards, and usually, you want to run a hand over their smooth surface. These are usually a little darker than the edge cut boards, but this is not always the case. Because different end pieces are put together to create the board, there is more interesting color variation and grain patterns.\n- While cherrywood cutting boards can be eye-catching, they don’t usually go overboard on the drama like some other materials. A walnut cutting board, for example, is often one of the focal points in a kitchen, and you have to decorate around it. Cherrywood will usually go well with just about any kitchen décor.\nOverall, cherrywood cutting boards are a safe addition to the kitchen from the point of view of style, which is another reason that they are so popular. They appeal to just about anyone.\nWhat You Need to Know About Cherrywood Cutting Boards\nAlthough the benefits far outweigh the disadvantages of cherrywood cutting boards, there are some things that you should know before buying one.\n- Cherrywood cutting boards are slightly harder to take care of than non-wood cutting boards. You cannot put them in the dishwasher, and they need to be oiled periodically with a food-safe oil to protect them and keep them looking good. This is true of all natural wood cutting boards.\n- Eventually, the cutting board will get cut marks. Because cherrywood isn’t super hard, it will eventually show wear and tear, and it will show that wear and tear sooner than granite or glass cutting boards.\n- Cherrywood cutting boards are an investment. You aren’t going to get away cheap with a cherrywood cutting board, especially if you’re looking for a high-quality end cut cutting boards. Worth the investment? We think so.\nAre Cherrywood Cutting Boards Sustainable?\nThis is a tricky question. Cherrywood cutting boards that are made from sustainably harvested trees are certainly one sustainable option.\nBut there is a more sustainable option: sustainably harvested bamboo. These cutting boards are very similar to cherrywood in the essentials. They’re durable, safe, and they shouldn’t dull your knives needlessly.\nHowever, you also have to consider where those materials are coming from. Bamboo coming from China is going to require more resources than cherrywood that was grown a couple hundred miles from where the cutting boards are made.\nSo we say, sustainably harvested cherrywood is a reasonably sustainable option.\nAre Cherrywood Cutting Boards Worth the Hype?\nCherrywood cutting boards are popular for good reason. They are good at what they do. They are durable, beautiful, and even pretty sustainable!\nYou really can’t go wrong with a cherrywood cutting board, so we say yes! It is worth the hype."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:5c8851de-ead3-4b0d-a75d-e9238c572652>","<urn:uuid:b3713b8d-f97b-4638-8660-bc0f58b4e4e6>"],"error":null}
{"question":"Could you compare the wildlife viewing opportunities at the waterholes between Kalahari Red Dunes Lodge and Torgos Lodge? Include details about timing and species.","answer":"Both lodges offer waterhole viewing but with different characteristics. At Kalahari Red Dunes Lodge, various species can be observed from private chalets, particularly from rooms like Eland, Giraffe, and Red Hartebeest, where guests can spot animals like warthogs, zebras, and kudu coming to drink. At Torgos Lodge, the waterhole is located in the riverbed adjacent to the lodge and is floodlit at night, with best viewing times being evenings and early mornings. Visitors can watch from the terrace to spot various animals. Both lodges share some common species like wildebeest, gemsbok (oryx), and springbok, though Torgos specifically mentions having golden oryx, a special color variation they breed as exotic game.","context":["Kalahari Red Dunes Lodge is situated on a 4,000ha private game reserve, 200km south of Namibia's capital city of Windhoek, near the small town of Kalkrand. As it is only 240km from Windhoek International Airport, this is an ideal stopover for self-drive tourists on either the first or last day of their holiday in Namibia. The town of Mariental is a further 70km south of the lodge.\nIndividual travellers, families or small groups wishing to experience privacy and luxury amongst red sand dunes in the Kalahari Desert without having to drive too far off the beaten track, should head for this lodge. An unusual feature of the The Kalahari Red Dunes Lodge is that it is situated in a nature reserve characterized by 2 deserts. The Kalahari Desert can be identified by infinite chains of red sand dunes that alternate with green valleys. The Great Karoo is home to enormous grass steppes and dry river courses lined with abundant water banks.\nFacilities include a restaurant, bar and lounge enclosed in a lapa with fire place, a swimming pool with a shaded decking, a viewing deck also with a fire place, free wireless LAN Internet and a safe to store your valuables at reception. The pool and shaded deck are actually situated in a dry lake. A 120m board walk connects the main building with the chalets which are strategically placed around this 'vlei'. A variety of Namibian wildlife can often be observed from the privacy of the chalets.\nEuropean meals with African flavours are enhanced by the lodge's home-grown herbs and fruits. Seasonal Kalahari truffles are also available. Breakfast can be enjoyed on the large, teak terrace. Buffet meals can be served in either indoor or outdoor dining areas with an open fireplace to ward off those chilly Namibian winter mornings and evenings. For those seeking a more romantic setting dinner can be taken 'between the red dunes of the Kalahari Desert'. A large selection of good to excellent South African wines can be ordered to accompany your meal as well as an inviting glass of cool Camelthorn Draft Beer, which can be drank under the tree of the same name.\nThe goings on of the Kalahari Desert can be experienced from the comfort and safety of your accommodation. Traditional African stoned/thatched roofs and canvas walls maintain a cool interior even in the hotter months. Features include teak floors, natural stone tiles in the bathrooms, teak terraces and board walks, individual private outdoor shower, generous spacing allowing for maximum spacing and a 'picture window' for observing animal activity.\nThere are 12 twin chalets (including 1 disabled chalet) each equipped with a private terrace, en-suite showers, fridge, tea/coffee station, mosquito nets, hair dryers, Wi-Fi connection and air-conditioning. Each stilted guest house is named after the largest species roaming the reserve. Paved, barrier-free, illuminated paths lead to the main building. The layout of the individual rooms is as follows\nNyala: The only guest room with a 'wide-angle scenic view'. Glass windows in the canvas run along the entire length of the building enabling guests to follow the course of the dunes. This chalet has the largest living space and affords the the most spectacular sunset view of the 12 rooms. There is no view of the waterhole.\nDistance from the main building: 300m.\nImpala: This chalet overlooks a tree savanna inundated with seasonal shiny golden yellow high grass to one side and the red sand dunes of the Kalahari desert on the other. Distance from the main building: 240m\nBlue Wildebeest & Black Wildebeest: These are 2 separate houses linked by a board walk, ideal for a family or small group. Alternatively the houses can also be booked separately by locking the doors to the board walk. Both houses offer breathtaking sunset views over the grass savannah and camelthorn trees. Distance from the main building: Blue: 180m. Black: 160m.\nSpringbok: As this guest house is elevated on the edge of the vlei it affords a spectacular panoramic view of the surrounding tree savanna, dry lake and steppe. An open shower has views of the magnificent savannah landscape. Distance from the main building: 100m.\nEland: This spacious guest house features a particularly beautiful bathroom. French windows offer spectacular views and you can observe waterhole wildlife activity from the comfort of your bed. Additional outdoor shower. Distance from the main building: 150m.\nGiraffe: Features include the largest bathroom, open and outside showers of all 12 rooms. It is set amongst ancient Kalahari Acacia bushes, where giraffe feed between the shrubs. There is a great view over the vlei and the waterhole, as well as the red sand dunes on the opposite sides. Distance from the main building: 200m.\nOryx: The position of this guest house offers spectacular wildlife viewing as well as affording extra privacy. Antelope can be observed through the 'picture windows' as well as from the comfort of your bed. There is an additional hidden outdoor shower. Distance from the main building: 300m.\nRed Hartebeest: This guest house is ideal for game viewing in and around the waterhole on one side and and the dunes on the other. Warthogs, zebras and kudu regularly pass by for a drink. There is an additional outdoor shower. Distance from the main building: 350m.\nZebra: The front terrace of this guest house is located under a large camelthorn tree, a location which not only sets this room apart from the others but gives the impression of being actually inside the vlei itself. The outdoor shower, obscured from view by an overhanging tree, adds to the ambiance. Distance from the main building: 480m.\nKudu: The very first guest house built for the lodge which still holds a special place for those involved with the lodge. It is the only guest house with steps leading to the terrace. Ideal for those who want to enjoy the quiet and solitude of the Kalahari Desert. Distance from the main building: 450m.\nOstrich: This is the furthest and therefore the most remote and secluded of the 12 guesthouses. Outstanding views of the immediate environment have been enhanced by a number of additional windows that have been installed recently. Many guests opt for a candle-lit dinner complemented by a bottle of fine red wine on the wooden terrace instead of walking to the main building. Distance from the main building: 500m.\nSpecies of animal that freely roam the private game reserve at Kalahari Red Dune Lodge include: Hartmann’s mountain and plains zebra, giraffe, blue and black wildebeest, eland, nyala, springbok, kudu, steenbok, oryx, red hartebeest, blesbok and impala. Some smaller creatures include pangolin, porcupine, aardvark and warthog. Amongst the many species of birdlife which include ostrich, waterfowl visit during the rainy season.\nActivities and excursions are either by customized 4x4 safari vehicles or guided and unguided tours on foot. All trips are accompanied by experienced and knowledgeable guides.\nGame drives: Enjoy the Kalahari Desert from the safety and comfort of a morning or afternoon safari. The leisurely drive gives ample opportunities to observe the many species of mammals that live on the reserve. The energetic can opt to climb some small dunes of around 30m high. Experience the vegetation and wildlife of the pristine wilderness environment as nature intended.\nSundowner drive: A great way to finish your day in the Kalahari red dunes is to participate on a sundowner drive in an open off-road car under expert guidance. This is definitely one of the most dramatic hours of the day in the desert.\nJogging: Join Namibia's fastest marathon runner (2 hours and 15 minutes) on one of the The Kalahari Red Dunes Lodge own jogging trails. One of the lodge's bushman residents trains in the early morning and evening. Distances of up to 20km have been set up for those keen on keeping up their fitness whilst on holiday.\nHiking: Another great way to explore the Kalahari Desert is to take a guided or unguided walk around the private reserve. All trails are clearly marked and drinking water is available at designated stops. Distances range from between 5-20km and last from 2hrs to all day. Tour guides can provide advice and assistance to set up a hike of a suitable distance and duration catering to your own fitness and requirements.\nMountain biking: Kalahari Red Dunes Lodge have 2 mountain bikes available for guests to ride on original bike trails in the private nature reserve. Crossing the Kalahari Desert on a modern mountain bike entails a bit of hard work but is great fun and healthy exercise at the same time. Experience the breathtaking vastness of the camelthorn savannah from a rather unusual mode of desert transport.\nVisit to the Protection of the Devil’s Claw Site: The Devil's Claw is a rare plant that produces healing ingredients for rheumatic and arthritic diseases. This has resulted in the roots being harvested out of the dry Kalahari sand almost to extinction and has recently been classed as an endangered plant species. The name is derived from the way this plant spreads its seeds. The Devil's Claw Project aims to provide a certain amount of water, falling as rain, to enable the plants to sprout and produce seeds in October not just March.\nOnly 25 kilometers west of Mariental this lodge promises an interesting safari experience. With over 19 game species including white rhino on the property, those seeking wildlife in this arid area are unlikely to be disappointed.\n10 bedroom guest house near the main B1 road in Mariental.\nAuob Country Lodge is the “Green Oasis” in the heart of the Kalahari Desert.”\nExcellent lodge in the Kalahari Desert, offers accommodation in units made of straw bales or wood. Bagatelle proves to be consistently popular with guests.\nInterested in gliding? Then this is the lodge for you.\nOn the private Intu Afrika Kalahari Game Reserve.\nSmall self catering establishment in the pretty Kalahari town of Stampriet.\nCome and let the warm colours of the opulent Kalahari Desert mesmerise you, as you partake in our fully equipped Camping2Go experience.\nTends to cater for larger groups, but the low rates make it attractive for those looking to save some money.\nA small well run lodge near the scenic village of Stampriet.\nClose to the Mata Mata border, the lodge is situated on a large well stocked game park. This is an excellent place to view Kalahari black maned lions.\nOnly a few kilometers from Mariental this magnificent game lodge is a green oasis in the Kalahari Desert. A wildlife breeding program means several rare buck species can be found on the lodge's game farm.\nA wonderful owner managed guest house in the village of Stampriet. An eclectic mix of local antiques & warm hospitality enhance your stay.\nThe meerkat or suricate is a small mammal which inhabits the Kalahari - we do not know why this lodge is named after them. Perhaps if you stay here and find out you can tell us and then we can make this slightly more descriptive.\nA tented lodge, built on the small red dunes of the Kalahari Desert.\nThe third lodge on the Intu Afrika Kalahari Game Reserve (along with Suricate & Camethorn Lodges). The Kalahari is absolutely magnificent and really should be a part of any visit to Namibia.\nThese are honest reviews, both good and bad, from our travellers who visited this property.\nRoom not clean, no hot water second day, few guys of the staff not friendly but great animal tour. Lodge almost empty..\nExceptional lodge - staff very good, food excellent, lodges first class, game drives terrific - no complaints whatsoever.\nAlso very nice, small but cosy. We liked it there although after Gocheganas it first seemed to be too small, it was still very nice\nlike for all the other lodges, you should make people aware that at night it can be FREEZING, so people should bring their ski clothes.............\nwe were afraid it could be quite similar to Bagatelle but we were quite happy with it, we had a walk there in the morning, was nice. A bit too close to the road.\nliked this place very much. partly due to the meerkat Toffee that the staff feeds so its semi trained. It would come sit in the kids laps. highlight of the trip for the kids.\nIt was OK. Food was acceptable but certainly nothing special (pork and vegetables). Bike paths were not that well marked so we got lost in the heat of the day. Staff were friendly.\nGreat place for first real nights on first trip to Namibia. A comfortable and welcoming lodge with real feel of Africa without being too far away or presenting any driving challenges. We loved it\nExcellent value, nice touches such as free wine/beer in fridge and a little carved elephant on the pillow! Tame meerkat was very cute. Good food, but lodge was very quiet and no activities were available.\nGood service and we enjoyed the affections of Doffy the meerkat. We couldn`t do the afternoon sundowner drive as it was full ( taken by non resident family we think). The management need to communicate activity options more clearly.\nThis was also very good - walkways to the restaurant from rooms was what was needed (Wolvedans should do something similar). Not much to see by way of animals but a friendly meerkat (something of a hotel pet) was amusing. A nice place to stop of at.\nFrom Windhoek, drive 190 km south on the B1 towards Mariental. The entrance to Kalahari Red Dunes Lodge is 8 km south of Kalkrand - and is clearly marked from the road.Download Map\nOur interactive Itinerary Builder allows you to plan your trip to Botswana or Namibia, selecting multiple properties on an easy-to-use map. Compatible properties can be booked immediately, and those without online availability can be sent to our reservations team for processing.\nSorry, we can’t seem to find any matches for your search. Have a look at our popular searches below.","- Mata Mata\n- Mata Mata\nFarm Dispuut nr 327, Keetmanshoopdistrict, 9000 Koës\n- Longitude: 19.974625\n- Latitude: -25.748831\nTorgos Lodge is located on the Western Border of Namibia adjoining the Kgalagadi Transfrontier Park. The lodge is alongside the C15 route, 5 km from the Mata Mata border post.\nSituated alongside the Auob River bed, the stylish main building (Lapa) is constructed from stone and thatch and has a lounge, bar, and dining area. Outside the Lapa is a large stone terrace, a group barbeque area (braai boma) and swimming pool overlooking a waterhole in the riverbed.\nThe surroundings are typical of the Kalahari region, the dry river bed lined by large camelthorn trees, red sand dunes and sparse vegetation. The lodge is within an 11000 Ha game camp hosting a wide variety of game, notably Gemsbok, Blue Wildebeest, Springbuck, Eland and many more. There is abundant bird life including a breeding vulture colony.\nTorgos Lodge is an ideal stop over for tourists travelling to and from Kgalagadi Transfrontier Park and an ideal destination for a few days of relaxing in the Kalahari. Activities include, game drives, unguided walks and bird watching.\nThere are ten accommodation units scattered amongst the Camelthorn trees alongside the Aoub riverbed. Each unit has two ¾ beds with white linen, duvets and an en-suite bathroom with shower basin, toilet and guest amenities. Luxury units have electric hot water geysers, whilst standard units have wood-fired boilers for hot water.\nLuxury Stone Chalets\nThere are two of these units, they are built with natural stone walls and floor whilst the roofs are canvas covered with steel roof sheeting. They are air-conditioned and equipped with two ¾ beds each, chairs, wardrobe and tea and coffee facilities. Electric blankets are provided in winter.\nLuxury Tented Chalets\nThere are four of these units, they are built with canvas and have a stone floor and bathroom. They are equipped with two ¾ beds each, ceiling fan, wardrobe, and tea and coffee facilities. Electric Blankets are provided in winter. One of these units has an outdoor kitchenette for self-catering with fridge, basin, gas stove, cutlery, crockery and utensils.\nThere are four of these units, they are built with canvas and have a stone floor and bathroom. They are equipped with two ¾ beds each, fan, wardrobe, and tea and coffee facilities. Electric Blankets are provided in winter. Three of these units have outdoor kitchenettes for self-catering with fridge, basin, gas stove, cutlery, crockery and utensils.\nWaterhole: There is a waterhole in the riverbed adjacent to the lodge, where a variety of animals can be seen especially in the evenings and early mornings. The waterhole is floodlit at night. Sit on the terrace and watch.\nGame Drive: Book a game drive and venture into the dunes in search of animals like Gemsbok, Eland, Wildebeest and Springbok. The game drive takes you through a 11000 hectare game camp which is stocked with a variety of game, included will be refreshments or a sundowner on top of a red dune\nSeek Golden Oryx: Book a trip on a farm vehicle in search of Golden Oryx, a variety of Gembsok which has a golden colour variation. These antelope are bred as exotic game. Included in the trip is a sundowner on top of a high dune overlooking the Aoub River.\nUnguided walks: take a walk into the veld from the lodge, either into the dunes or along the river bed. Here one can experience first-hand every detail of nature, from the birds and animals, to plants, seeds, animal tracks and smaller forms of life. Perfect for general photography.\nStargazing: Sit outdoors in the evenings, look up and touch the stars! The clear skies with no pollution or artificial light make the Kalahari one of the best places to look at the stars.\nSwimming Pool: Relax and cool off at the swimming pool.\nKgalagadi Transfrontier Park\nA good day trip would be to drive down the Aoub River from Mata Mata to the picnic spot at Kamqua, where you can get out of your vehicle, picnic and make use of the toilets before driving back. There are several waterholes fed by boreholes which attract game. On this route one can spot, lion, cheetah, giraffe, wildebeest, gemsbok, springbok, red hartebeest, spotted hyena, black-backed jackal, suricates and several other smaller mammals. Of the numerous bird species, one may see bateleur, white-backed vulture, secretary bird, martial eagle, pale chanting goshawk, ostrich, kori bustard and many smaller species.\nMap and Directions to Torgos Lodge\nGPS: 25° 44' 55.79\" S / 19° 58' 28.65\" E\nThe entrance to Torgos Safari Lodge is situated on the C15, 6 km from the Botswana border at Mata-Mata."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:f9ccef07-6826-4db1-9d50-f1098d39d9cd>","<urn:uuid:56e2f191-1817-4215-ad1c-b35d6ac1ffad>"],"error":null}
{"question":"What are the key differences between SAP HANA's warm data tier and traditional shared storage approaches in terms of sizing and data loading behavior? Please provide a detailed analysis.","answer":"SAP HANA's warm data tier and traditional shared storage have distinct characteristics in sizing and data loading. The warm tier has specific size limitations - it cannot exceed 4 times the size of the hot tier and has a maximum size of 10TB. It uses a 'page loadable' design where only granular portions of data are loaded into memory, maintaining transactional consistency with the hot tier without significantly impacting memory footprint or database start time. The warm tier requires an NSE buffer cache (initially 10% of SAP HANA memory, recommended at least 12.5% of warm tier size). In contrast, traditional shared storage in SAP HANA requires 2.5 to 3 times the total memory capacity of all hosts in a cluster for persistent storage, with specific performance requirements like 400Mbps per HANA node (4-5Gbps) over the SAN backbone and array, and needs isolation from other storage workloads.","context":["SAP HANA Tiering: The Pressures of Data Growth\nTue, 18 Aug 2020 19:06:46 -0000|\nRead Time: 0 minutes\n“Data growth is accelerating!” Quotes like this appear frequently in studies, papers, and blogs. You will not find more data growth quotes in this blog article, however, because I think it is more interesting to look at this from a data management investment policy perspective. A data management investment policy has similar benefits to a corporate travel investment policy—the goal is to efficiently maximize the bottom line. In most customer accounts, the SAP HANA licensing investment happens early and the business must maximize the benefits in the long term. First cost is not the sole driver because volume, variety, veracity, and velocity are all considerations when a company is looking for a strategy. Evaluating a data management investment policy for the long term can be complex. SAP provides Native Storage Extensions (NSE) to address both cost pressures and the intelligent placement of data over time.\nSAP HANA with NSE offers the functionality of tiering data using different storage solutions based on the age of the data. The NSE data management policy categorizes data into three classes: hot, warm, or cold. This blog post focuses on the hot and warm data tiers. Hot data can use both volatile and nonvolatile memory, as follows:\n- DRAM: DRAM is the fastest storage media. DRAM is volatile, however, meaning the data must be loaded into memory on restart of the database or server.\n- PMEM: Persistent Memory (or PMEM) is faster than SSD storage but not as fast as DRAM. PMEM is also nonvolatile memory, meaning the data does not have to be loaded into memory on restart of the database or server. PMEM is used for the SAP HANA Fast Restart option.\nSAP HANA on-premises Native Storage Extension\nIf you are interested in learning more about maximizing your data management investment strategy, the SAP HANA TDI on Dell EMC PowerEdge Servers Validation Guide provides detailed configurations. The hot data tier both drives the fastest performance and is the most expensive tier (hardware + SAP HANA licensing + annual support). Maximizing the performance-to-cost trade-off of hot data placement requires consideration of two factors:\n- Keep actively used data that is critical to the business in the hot data tier\n- Migrate less frequently used data out of the hot data tier to sustain costs\nThe first consideration is a performance guideline for when the responsiveness of the database and applications is at a premium for the business. Data that is less frequently used can be placed in the warm tier to minimize the impact on queries on the hot data tier. Another benefit is related to SAP HANA restarts. For example, planned maintenance events involving Linux operating system or SAP HANA database updates can require a restart. An SAP HANA system with NSE could have less data in the hot tier compared to the same SAP HANA system without NSE, thus improving restart times.\nNOTE: SAP HANA also has a Fast Restart Option that uses file storage to speed up restarts. Fast Restart leverages PMEM to accelerate file storage access, significantly reducing the start time of the database. SAP HANA Fast Restart applies to scenarios in which only SAP HANA is restarted and not the operating system.\nThe second consideration is an avoidance guideline that sustains existing investments while mitigating additional ones. Success could be defined as a strategy in which performance increases with each new server generation while SAP HANA costs remain constant if the size of the hot data tier remains the same. The business impact is a continual increase in performance combined with efficiently maximizing the bottom line.\nThe warm data tier is for less frequently accessed data that occasionally resides in SAP HANA memory. If kept in memory, warm data accelerates costs, mainly through the additional licensing that is needed to increase the memory size. To mitigate the impact of rapid data growth, maximize the usage of the warm data tier. Keep in mind that the warm data tier is limited to four times the size of the hot data tier. For example, a hot data tier of 1 TB means the warm data tier can be up to 4 TB. The warm data tier also cannot exceed 10 TB in size. The 10 TB maximum is a first-release restriction.\nData in the warm tier is transactionally consistent with the hot data tier. This means that the warm data tier must be protected in conjunction with the hot data tier so that the entire database backup is consistent. While the hot and warm data tiers are transactionally consistent, they differ in how data is loaded into memory. The hot data tier is ”column loadable,” meaning the columnar tables are loaded into memory. In contrast, the warm data tier is “page loadable,” meaning granular portions of data are loaded into memory or partially in memory. The page-loadable design has two key benefits for the warm data tier:\n- It does not significantly impact the memory footprint.\n- It does not significantly impact the start time of the database.\nUse of the warm data tier depends on the SAP HANA NSE buffer cache. This buffer cache is enabled by default and is initially sized as 10 percent of SAP HANA memory (for the sizing reference, see the SAP HANA Administration Guide for SAP HANA Platform 2.0 SPS 04). For example, the NSE buffer size is recommended to be at least 12.5 percent of the total size of the warm data tier. You can modify the NSE buffer cache size by using the ALTER SYSTEM ALTER CONFIGURATION command.\nWarm Data Tier\nOverall, use of the warm data tier enables customers to balance fast performance with increased data volumes while minimizing cost, thus achieving greater value. Customers have the flexibility to design an amazingly fast warm data tier with storage I/O latencies measured in microseconds, narrowing the difference between the hot and warm data tiers in terms of performance.\nDell Technologies has a team of experienced SAP HANA experts that can assist with accurate sizing and design of an infrastructure solution for your databases. Our goal is to work closely with you to maximize the value of NSE and create an extremely fast warm data tier that narrows the performance gap with the hot data tier. Your Dell Technologies representative can put you in contact with one of our SAP HANA experts.\nRelated Blog Posts\nOn the record for Sapphire: World Record SAP HANA Performance with Dell PowerEdge R760 Servers\nWed, 17 May 2023 15:19:25 -0000|\nRead Time: 0 minutes\nSAP HANA is an in-memory database platform used to manage large amounts of data in real time for purposes such as point-of-sale data, real-time analytics for inventory management, supply-chain optimization, and customer behavior analysis. As the amount of data that must be processed grows, servers can be challenged to deliver information and analysis quickly enough to meet the increasingly demanding business requirements for fast data access. That is why SAP HANA users are always on the lookout for better-performing servers.\nSAP publishes the results of standardized benchmark tests to assist customers in comparing the performance of different servers when running SAP HANA. Performance results for the Dell PowerEdge R760 server were recently published, and we are excited to share some highlights about how well this server stacks up against other servers.\nFifteen different data points are available for comparing the PowerEdge R760 server to other servers. The standard benchmarks measure three key performance data points for each of the five different database sizes on which the PowerEdge R760 server was tested.\nThe following table shows the rank of the PowerEdge R760 server for each of the 15 points of comparison among all the different servers tested using SAP’s benchmark version 3. The source of the data is the publicly available SAP Standard Application Benchmarks directory, accessed on 04-19-2023.\nThe PowerEdge R760 server outperformed all the other servers in 13 of the 15 benchmark points of comparison, and it ranked second in the remaining two.\nThe PowerEdge R760 server is a two-socket server built with the latest 4th Gen Intel Xeon Scalable processors. It outperforms all other servers in SAP HANA benchmarking—even 4 and 8-socket servers—in every database size of up to 6.5 billion initial records. It provides the performance and versatility to address your most demanding applications, including SAP HANA, with massive databases and mission-critical requirements for real-time performance.\nLook for an in-depth study from Prowess: Remarkable SAP Benchmark Performance Results for Dell PowerEdge R760 Servers (delltechnologies.com) about how the PowerEdge R760 server performed against top competitors on the SAP Standard Application Benchmarks.\nAbout the Author:\nDirector, Server Technical Marketing\nSeamus serves Dell as Director of Server Technical Marketing, seasoned with over 20 years of real-world experience in both North America and EMEA. His unique perspective comes from experience consulting customers on data center initiatives and server virtualization strategies.\nOn-prem vs. Public Cloud: Understanding the true cost of running steady-state workloads in the public cloud\nFri, 16 Apr 2021 09:08:01 -0000|\nRead Time: 0 minutes\nInfrastructure is not the only thing that may be more expensive in the public cloud than on-premises.\nOrganizations have found value with their investments in Public Cloud; however, we've also heard the stories about some workloads or use cases that were moved to the public cloud that led to buyer’s remorse as their public cloud infrastructure costs were demonstrably higher than on-premises. The initial allure of the public cloud was quickly offset by higher costs, but also hidden costs that many don’t realize until they make significant investments that include systems integrators and consultants.\nSoftware licenses for many popular business applications are not cost-optimized for public cloud environments. In addition to potentially high cloud infrastructure costs, they may also face software true-ups in cases of resource inefficiency. One way to solve for this is to abandon traditional software licenses in favor of a new software subscription with a new metering method that is more conducive to cloud environments. However, this has the potential for a higher overall software TCO, the license conversion exercise may be confusing because metering methods are typically different, usage forecasting may not be as predictable, and there are hidden depreciation costs of the old licensing which may further drive the TCO upside down.\nTo better understand the costs of running a steady-state workload such as SAP in the public cloud vs. on-premises, Dell Technologies commissioned Krystallize Technologies to conduct an evaluation. Many studies have already been carried out on Private vs. Public cloud costs as well as data egress charges, cloud support, and staff retraining. Instead, Krystallize focused on comparing the hardware costs depreciated over 3 years to the 3 year cost of public cloud IaaS services, even though the useful on-premises server lifespan is 5 years.\nThe full report: Krystallize Technologies SAP HANA PowerEdge Whitepaper\nWhile the cost savings in infrastructure between public cloud and on-premises is significant enough to attract any CFO's attention, consider also license efficiency. Many customers have invested significant CAPEX dollars into enterprise applications that are licensed by the core and, as a result, need to be deployed efficiently.\nKrystallize Technologies found that with a similar amount of memory, a 72 vCPU (36 core) PowerEdge server and a 96 vCPU compute instance from a public cloud provider were able to accomplish the same amount of work1. This finding could illustrate that the cost of running comparable workloads licensed by core, such as SQL Server, Oracle and in some cases SAP, may require 33% to 167% more software licenses to run in the public cloud.2\nTake for instance, an Oracle Enterprise Edition workload deployed on the PowerEdge server - it would cost $521,550 USD for acquisition and first year support. The same workload deployed on the 96 vCPU instance would require potentially spending up to 2.6 times as much, $1,390,800 USD for the acquisition and first year support!3\nPublic Cloud may be the right choice for organizations looking for temporary capacity, whether it’s an unexpected computing demand or an unproven DevOps environment; however, to steal a phrase I heard a colleague use, it is cheap to fail in the cloud but expensive to succeed.\nWhen an organization has a workload that has moved past the POC phase and is in production, that workload provides a valuable outcome or business function and must run 24/7/365. Workloads, such as SAP or Oracle, that are always-on and have a steady state performance profile no longer benefit from the elasticity of public cloud.\nOrganizations that have invested considerable capital in software licenses may find they cannot be efficiently deployed in the Public Cloud. The good news is that there are multiple avenues, such as hybrid cloud, for organizations to explore in order to maintain applications and associated licensing where they can keep costs low, while using public cloud for the right workloads. Customers seeking a pay-for-use model can achieve this on-premises with Dell Technologies on Demand and will soon benefit from Dell Technologies Project Apex as well.\nTo Learn More\n- Krystallize Technologies SAP HANA PowerEdge Whitepaper\n- Krystallize Technologies SAP HANA PowerEdge Infographic\n- Dell Technologies Solutions for SAP\n- Dell Technologies PowerEdge Servers\n- Dell Technologies on Demand\n- Dell Technologies Project Apex\n- Dell Technologies Competitive Advantage\n1 Based on the Krystallize Technologies whitepaper commissioned by Dell Technologies, “Krystallize Technologies SAP HANA PowerEdge Whitepaper”, comparing cost-performance of SAP HANA running a benchmark load on a physical and cloud provider environment over a 3-year period, Nov. 2019. Actual results may vary.\n2 Based on Dell analysis, January 2021, comparing the number of licenses required to run the same SAP and Oracle load with similar resources on-premises on a Dell EMC PowerEdge R940 vs a Cloud Service Provider. Actual results will vary based on configuration, environment, and other variable factors.\n3 Based on Dell cost analysis, January 2021, comparing the number of licenses required to run the same workload with similar resources on-premises on a Dell EMC PowerEdge server vs a Cloud Service Provider. Oracle Enterprise Edition licensing costs are in US dollars obtained from a publicly available price list. Actual costs will vary based on configuration, environment, and other variable factors.","Andrea Danti - Fotolia\nAs the cost of memory has fallen, interest has grown in applications that don’t regularly swap data out to disk in the traditional method for conserving system RAM.\nBy submitting your personal information, you agree that TechTarget and its partners may contact you regarding relevant content, products and special offers.\nInstead, popular big data applications such as SAP Hana work entirely or primarily in-memory, using servers with many gigabytes or even multiple terabytes of system RAM.\nWorking in-memory is an extremely powerful approach for big data work, especially for applications such as real-time analytics, an area where SAP Hana has gained growing acceptance.\nHowever, while Hana runs in memory, it still has to write to persistent storage – which means disk, flash and eventually, yes, maybe tape too – to protect its work. Persistent storage is what provides the essential database transaction guarantees known as Acid – atomicity, consistency, isolation and durability.\nSAP Hana can be installed as a turnkey appliance or in a form that SAP calls TDI (tailored datacentre integration), with servers running on enterprise storage. For the latter case, SAP offers a hardware configuration check tool to make sure your storage meets Hana’s performance and functional requirements.\nSingle host or cluster?\nA scale-up installation on a single host is simplest from the perspective of storage allocation and directory layout. Alternatively, the software can be installed as a distributed scale-out cluster, either on physical servers or VMs.\nA distributed cluster is potentially more powerful and useful (although a single host can also scale up), but makes storage management rather more complex. For either installation type, the storage requirement is further complicated by the need to add data protection.\nAs standard, SAP Hana uses storage for several purposes. The main ones are as follows:\n- The operating system boot image – Hana runs on Linux.\n- Hana installation – its run-time binaries, scripts, configuration files, etc. This is also where trace files and profiles are normally stored. In distributed systems, every host has its own copy of these, plus scale-out configuration and trace files.\n- Persistence data – each Hana service or process ensures persistent in-memory data by writing changed data to free storage in the form of savepoint blocks. By default this happens every five minutes.\n- Re-do log – each Hana service also records each transaction to its own log file to ensure that the database can be recovered without data loss.\n- Backup – backups are written on a regular schedule.\nShared storage or server-side?\nThe decision of which type of storage to use for the persistence is complicated by two factors.\nFirst, the savepoint blocks and re-do log files can use significantly different block sizes – up to 16MB (or even 64MB for super blocks) for the former, and up to 1MB for the latter.\nSecond, both are latency-sensitive and have different access patterns, with data access being mainly random while log access is sequential. Both are write-heavy, except during restarts, backups, reloads and so on.\nAll that means you need fast and flexible storage, so server-side flash (PCIe SSD) is often advised. Be warned, though, that server-side storage in a distributed cluster can affect your ability to do automatic load balancing and failover, especially in a virtualised environment – unless you take other steps such as also virtualising and pooling the server-side storage.\nAlternatively, since this is logically a shared-nothing approach, with each Hana service managing its own persistence data, you can use a shared array or subsystem.\nScale-out clusters are both share-nothing and see-everything: each node has exclusive access to its own data and log persistence volumes, but all the other nodes still need to be able to see those volumes. This is because host auto-failover relies on moving the failed node’s persistence volumes to a standby node.\nMemory sizing is a complicated matter, based on the space required for row and column data, objects dynamically created at run-time (such as temporary table duplication during delta merge operations), software code, caching and so on.\nPersistence (savepoint blocks and re-do logs) sizing for each node can be calculated by analysing its tables using SQL or simply by taking the node’s RAM capacity, and then in each case adding 20% more for headroom.\nMore on SAP Hana\n- Whether you are opting for Hana on premises or in the cloud, database server main memory size will affect your pricing. Here are some basics to understand as your start your research.\n- SAP Hana cloud options vary, and can be confusing. Here are the differences between Hana Cloud Platform and Hana Enterprise Cloud and what they mean for SAP deployments.\nYou then need to add at least half as much again for backups, plus space for the other storage requirements mentioned above. It can be useful to direct all the backups from the nodes within a distributed system to the same storage device, but beware of routing a Hana node’s backups to the same array that its persistence data lives on.\nOverall, if you total the memory capacity of all the hosts in a Hana cluster, then as a rule of thumb its storage subsystem should provide at least 2.5 to three times that amount of persistent capacity. If system or storage replication is added for disaster recovery, that doubles the storage needs – essentially, the same amount of storage must be provided on the secondary site.\nLatency and bandwidth\nSAP Hana’s log l/O in particular is latency-sensitive, which limits the use of synchronous replication to distances and media that permit low latency connections. Hana’s application-based system replication is a more expensive alternative; a cheaper one is asynchronous storage replication – if you can live without instant recovery.\nSAP also expects isolation of the Hana workload from other storage workloads. A TDI installation needs 400Mbps per Hana node, which with overheads is between 4Gbps and 5Gbps, both over the SAN backbone and at the array. That equates to approximately one 16Gbps Fibre Channel inter-switch link and array port per three nodes. While it is unlikely that all nodes will hit this peak at once, it is a requirement for Hana certification.\nEach node also requires two Fibre Channel ports, preferably on separate HBAs to enable multipath load-balancing and redundancy/failover. And in a scale-out installation you will need to set up multiple zones, each in turn covering multiple networks.\nThe zones needed are client (for the application servers and users), internal (inter-node traffic and replication), storage (which also covers backup) and admin (including the boot and vMotion networks). For a TDI installation you will need to configure all four, while an SAP Hana appliance will come with internal and storage zones already configured.\nOne caveat with all the above is that SAP’s developers continually develop and enhance Hana. That means its capacity requirements for disk and memory can change from one version to the next, as well as varying from one implementation to another depending on the data and the workload. A project of any significant size will probably need professional sizing assistance, but the information above should arm you for commissioning the project and dealing with the professionals."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:fe5e28e6-5428-4dbe-be23-0befbca703d3>","<urn:uuid:db94ef53-12fc-4dba-9847-e219bc45cb31>"],"error":null}
{"question":"Compare the job responsibilities of Brigadier Broccoli vs Belgian Shepherds in military/police work - which one has more duties?","answer":"Belgian Shepherds clearly have more duties than Brigadier Broccoli. Belgian Shepherds are actively used for military work, police work, narcotics detection, search & rescue, and competitive obedience. They require intensive training and are highly active working dogs. In contrast, Brigadier Broccoli, despite being an official Swiss army cat, 'doesn't have a job' according to Werner Holzer. Her main contribution is adding to the atmosphere and providing comfort to soldiers who are away from home. She spends her time freely roaming the base, stalking birds, and greeting people.","context":["It started with a bite of broccoli. Meet the cheeky little kitty who gets a pension from the Swiss Army.\nHer features are dainty and her fur is silky soft, so her squawky meow comes as a surprise. Though she has her own cat flap, she urges bystanders to open doors for her. You might say she barks orders like a drill sergeant – but actually, this brazen cat ranks even higher. Known as Brigadier Broccoli, she has the run of an army base near the Swiss capital.\nThe frisky feline began prowling around the barracks in Lyss in 2004. As a bored housecat, she was looking for action – and she found it among all the young recruits, who were also a source of snacks between meals. The soldiers named her “Broccoli” after the tabby nibbled on a bite of the green vegetable. Though she had a home nearby, it seemed she couldn’t get enough of army life.\n“It was awkward. She kept coming back – even at Christmastime, when there weren’t that many people here to look out for her,” recalls custodian Werner Holzer. But her former owner, who wasn’t around much either due to her job, was unable to prevent the free-roaming cat from visiting the barracks. So finally, the owner and the authorities at the base agreed that the green-eyed feline could stay.\nSince Broccoli couldn’t live from mere table scraps, the soldiers set up a kitty to buy her cat food.\n“She loves to eat,” remarks Holzer, who shares an office with Broccoli. “And she’s very clean. Once she got shut in a room by mistake, but she didn’t pee or make a mess.” He says she’s also quite curious, investigating every corner of the 60-hectare base.\nNow a 14-year-old senior, she’s showing her age somewhat.\n“We notice that she’s not as fit. For example, she doesn’t jump straight down from tables – she needs a chair in between,” Holzer notes. But she’s still lively enough to make her rounds, stalking birds, greeting friends, and chasing off a local cat that she doesn’t like.\nBroccoli was added to the roster of army animals about three years ago. The roster includes 105 guard, search and rescue dogs – plus another 115 dogs in reserve. There are also 57 riding horses and another 200 pack horses in reserve. Humans number about 166,500, including 42,000 reservists.end of infobox\n“Giving her the status of an official army animal made sense, especially if she’s being treated by the army veterinary staff,” explains Holzer.\nHe says there are two other Swiss army cats. They live at the stables in a nearby town, and it’s their job to catch mice that would eat the horses’ feed. But unlike her colleagues, Broccoli doesn’t even have to lift a paw to earn her keep. Unfair?\n“She doesn’t have a job, but she adds to the atmosphere. A lot of the soldiers are away from home for the first time, and the days here can be long and tough. So it’s relaxing to pet a cat,” points out Holzer.\nTwo soldiers smile and hurry to let Broccoli out when they see her meowing at a door. Cat people, for sure. But not everyone on the base is.\n“I’m not so keen on cats, but it’s not a problem,” says another recruit at the base checkpoint. “After all, she’s been here longer than I have.” His colleague keeps a respectful distance. “She’s a pretty cat, but I don’t really pet her or anything. I don’t want to bother her.”\nIndeed, Broccoli makes a self-sufficient impression – happy to interact for a bit, and then eager to continue with her daily business. When she was young, she sometimes disappeared for two or three days at a time. Holzer says that today’s outings are more like two or three hours.\nBroccoli even has her own Facebook pageexternal link with more than 3,500 fans, and it was there that she earned the “Brigadier” ranking.\n“She moves hearts,” says Holzer, clearly a Broccoli fan himself.\nSwiss police dogs\nBrigadier Broccoli isn’t the only Swiss pet getting a pension from public funds. There’s also Aika, a German shepherd who retired from the canton Schwyz police force this year. She ended her service with a bang, catching intruders on her final work night. But now she can relax with her owner, police officer Monika Blättler.\n“Twelve years is an incredibly long time for a police dog to serve. She deserves to spend her golden years at home with me,” Blättler told the Obersee Nachrichten newspaper. As with all retired Schwyz police dogs, the canton still pays for Aika’s food. However, Blättler is responsible for any veterinary bills.\nCanton Bern also covers the cost of dog chow for its retired police dogs. And in canton Geneva, retired dogs with at least four years of service under their collars are entitled to free veterinary care for the rest of their lives.\nYou can contact the author on Twitter @SMisickaexternal link.","Breeding group : Working\nview all pictures & Videos\nUpload a photo or videoBREED RATING\n|Affection / Dependance:|\nTendency to bark:\n|Tendency to bark:|\nGENERALBreed group: Working Type: Pure Breed\nTalent: Agility, Competitive obedience, Military work, Narcotics detection, Police work, Search & rescue\nPHYSICALSize: Large Weight: 55-66 pounds Fur length: Ears: Pointy Fur type: Straight\nFur Color: Black, Black & Brown, Dark Brown / Chocolate, Light Brown / Golden\nATTRIBUTESLife Expectancy: 10ÃÂ14 years Rarity: Common Availability: Hard to find\nClimate: Good for every climate\nThe Belgium Shepherd, also termed as Belgian Shepherd or Chien de Berger Belge, is a breed of medium-to-large sized herding dog. It originated in Belgium and is similar to the other sheep herding dogs from their region. It includes the Dutch Shepherd Dog, German Shepherd Dog, the Briad and others. There are four types that have been identified by various registries as separate breeds or varieties, the Groenendael, Laekenois, Tervuren and Malinois. Each of the varieties are differentiated by hair colors and texture.\nThey commonly come in solid black. Others vary with combinations of tan, brown, black, sable or gray. They can come in basic black with a slight mixture of white on the paws or white spot on the chest.\nThe Belgium Shepherd has a coat that is stiff, thick, tight, double coated and can withstand the elements. It can be in medium or long in length, straight or slightly wavy.\nBelgium Shepherd breeds are highly intelligent, alert, sensitive to everything going on around them and form very strong relationship bonds. They are loyal, fun, highly trainable and well suited to family life. Their herding heritage gives them a comparatively high energy level, and mental as well as physical exercise is necessary to keep a Belgian happy and healthy.\nThe Belgium Shepherds are afflicted with the most common dog health issues at rates similar to other breeds in general, reproductive, musculoskeletal and dermatological. They differ most notably from other breeds in the high incidence of seizures and/or epilepsy. This breed require a frequent daily brushing as they shed regularly, with seasonal heavy shedding. Bath when necessary and use a mild shampoo once or twice a year to clean out heavier dirt and to avoid drying out of skin. Food intake must also be monitored as they can easily get obese.\nThe Belgium Shepherd is not recommended for inexperienced owners. They have a strong protective instinct that requires an early intensive socialization and obedience training to refrain from dangerous territorialism when grown. Their training must be done with firmness, consistency, fairness and with positive reinforcement. They do not respond to harsh or heavy-handed methods which can possibly damage the dog's personality.\nThese breeds should receive plenty of socializing as puppies and will benefit from regular activity and close interaction with people throughout their lifespan. They do well in sports such as obedience training and dog agility. They are used as assistance and search and rescue dogs, as well as police, military and narcotic dogs. These breeds are moderately active indoors and will do best when given an access to an average sized yard to roam around. They will do okay in an apartment dwelling provided they are given sufficient exercise that they need. They can also be active outdoors and will need a lot of exercise, including a long daily walk."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:8269475b-6df8-4b6a-955c-e095f96c3939>","<urn:uuid:930bbc20-8e57-45f5-b58f-c364031701b3>"],"error":null}
{"question":"How do energy efficiency considerations compare between mountaineering headlamps and indoor LED lighting? In Spanish: ¿Cuál es más eficiente energéticamente?","answer":"Both mountaineering headlamps and indoor LED lighting prioritize energy efficiency but in different ways. Modern LED headlamps for mountaineering are chosen specifically because they use batteries much more efficiently than incandescent bulbs, particularly with lithium-ion batteries that last longer and work better in cold conditions. For indoor lighting, LED technology is even more impressive - it uses at least 75% less energy than incandescent lighting, lasts 25 times longer, and releases very little heat (only 10% compared to incandescent bulbs' 90% heat emission). By 2027, widespread LED adoption could save about 348 TWh of electricity, equivalent to 44 large power plants' output.","context":["Colin Haley Alpinism – Hardware Part 3\nHardware Part III – Other Important Gear\nA large backpack with an internal frame is appropriate for an approach, but on route your pack should not have a frame. Not only does it add weight, but while climbing technical terrain a stiff frame limits the motion of your body.\nAlso avoid really wide, cushy hip-belts and shoulder straps for the same reason. On a route with moderate technical difficulties where a lot of simul-climbing is expected both backpacks should be similar in weight. On steep, difficult terrain, however, the leader’s pack should be significantly lighter than the follower’s pack, and consider even bringing backpacks of significantly different size. Remove the hip-belt from at least the leader’s pack so that it doesn’t get in the way of racking. Another good way to save weight is to leave the lid pocket behind, because it adds very little volume and your small items can be kept organized just as well inside a silnylon stuffsack. Traditional ice axe loops are better than tool tubes because they are lighter, accommodate leashless tools more easily, and keep your tools lashed more securely.\nThe usefulness of approach skis depends on the range you are climbing in, the nature of the terrain where you will be, and the season you will be there. On many expeditions skis would be useless, but on many others it would be completely impossible to travel without them. Snowshoes are typically much slower and less efficient than skis, but do have the advantage of being lighter. For this reason, the one situation when snowshoes are a good choice is if you expect to have to carry them on your backpack for a long ways before using them on your feet. Telemark bindings have no useful application in alpine climbing, and the randonee bindings that you choose should work well with mountaineering boots (which usually means a wire bail front).\nA good ski setup for alpine climbing is very different from a good ski setup for backcountry skiing. The skis should be lightweight and short, with a length from 130-160cm. Skis this short are much easier to turn when wearing mountaineering boots. Some skis are specifically designed as approach skis and come in these shorter lengths, but you can otherwise just buy an old pair of kids skis at a ski swap. Also, it is best to use skis with a waist that is relatively narrow by modern standards – mountaineering boots do not provide much lateral support compared to ski boots, so it is hard to put wide skis on edge.\nA trick that is very useful for skiing in mountaineering boots is to use ‘knee-cords,’ a cord that runs from the tip of your skis to a strap right below your knee. By tensioning such a cord you essentially mimic the effect of a high-backed ski boot and will stay in control much more easily in variable snow and with a heavy backpack. Drill a hole through the tip of your skis, and connect the knee-cord to the tip using 5-6mm perlon with a stopper knot on the underside of the hole in the tip. The tension on the knee-cords should be easily adjustable while you are wearing them, as should the tension in the strap around your knee.\nThe purpose of eyewear on an alpine climb is to block the sun, the wind, and blowing snow. Sunglasses block the sun well and ski goggles block the wind and snow well, but unfortunately neither of them do both very well. Traditionally many climbers have brought both sunglasses and ski goggles on a climb, but this seems excessive most of the time. One solution is to bring hybrid glasses-goggles that aren’t as nice in the sun as glasses and not as nice in the blowing snow as goggles, but do both decently. These hybrids typically have separate lenses with foam around each, and fogging is often the biggest problem, so it is worth trying them on for a few minutes before buying them.\nOn many lower-elevation routes single-boots provide adequate warmth, but for climbing in real cold double-boots will be necessary. Plastic-shelled boots are obsolete, and their only advantage is a relatively low cost. The new wave of double-synthetic-boots are warmer than plastic boots, and more importantly they climb technical terrain much, much better. To get the most warmth out of your boots for extreme cold, consider using thin, skin-tight (but not circulation-restricting) neoprene socks that act as vapor barriers. The inner boots are essentially vapor barriers anyways, so if you don’t use neoprene socks expect that your socks will get moist.\nWater bladders are useful because they have a large volume for their weight, take up almost no pack space when empty, and are much more comfortable than a bottle inside your jacket or sleeping bag. However, hoses and bite-valves are much too hazard-prone for alpine climbing; the hose tangles in the rack, the hose freezes, or they leak. The only water bladder that seems trustworthy are the MSR Dromlite bladders. Use ductape to make sure the nozzle on the screw-top will never come open accidently.\nA good headlamp is one of the most important pieces of gear on any climb, and if climbing during the dark seems likely then a very bright headlamp will absolutely be worth the greater weight than a just-in-case headlamp. Get the brightest headlamp you can find that uses only LED’s. Incandescent bulbs will zap your batteries incredibly fast, and the new LED’s are impressively bright. For important climbs, always use lithium-ion batteries rather than alkaline batteries – not only are they much longer lasting, but they work better in the cold and are significantly lighter too.","Energy-efficient indoor and outdoor lighting design\nIndoor Lighting Design\nWhen designing indoor lighting for energy efficiency, consider some basic design principles and methods.\nEnergy-efficient lighting design principles include the following:\n- More light is not necessarily better: light quality is as important as quantity\n- Match the amount and quality of light to the performed function\n- Install task lights where needed and reduce ambient light elsewhere\n- Use energy-efficient lighting components, controls, and systems\n- Maximize the use of daylighting.\nHere are some basic methods for achieving energy-efficient indoor lighting:\n- Install fluorescent or LED light fixtures for all ceiling- and wall-mounted fixtures that will be on for more than 2 hours each day, such as kitchen and living room, bathroom, hallway, and other higher-demand locations.\n- Consider installing fluorescent or LED fixtures, rather than using fluorescent or LED replacement lamps in incandescent fixtures.\n- Use CFLs or LEDs in portable lighting fixtures that are operated for more than 2 hours a day.\n- Use occupancy sensors for automatically turning on and off your lights as needed.\n- Consider light wall colors to minimize the need for artificial lighting.\n- If you are using recessed lights in a ceiling with an unconditioned space above it, use only Underwriters Laboratory (UL) approved fixtures that are airtight, are IC (insulation contact) rated, and meet ASTM E283 requirements.\nOutdoor Lighting Design\nWhen designing outdoor lighting, consider the purpose of the lighting along with basic methods for achieving energy efficiency.\nOutdoor lighting for homes generally serves one or more of three purposes:\n- Aesthetics: Illuminate the exterior of the house and landscape\n- Security: Illuminate the grounds near the house or driveway\n- Utility: Illuminate the porch and driveway to help people navigate safely to and from the house.\nHere are some basic methods for achieving energy-efficient outdoor lighting:\n- Security and utility lighting does not need to be bright to be effective.\n- Use LED or fluorescent lights unless incandescent lights are automatically controlled to be on for just a few minutes each day.\n- Consider flood lights with combined photo sensors and motion sensors in the place of other security lighting options.\n- Make sure outdoor light fixtures have reflectors, deflectors, or covers to make more efficient use of the light source and help reduce light pollution.\n- Use timers and other controls to turn decorative lighting on and off.\n- Use outdoor solar lighting where applicable.\nThe light-emitting diode (LED) is one of today’s most energy-efficient and rapidly-developing lighting technologies. Quality LED light bulbs last longer, are more durable, and offer comparable or better light quality than other types of lighting\nLED is a highly energy efficient lighting technology, and has the potential to fundamentally change the future of lighting in the United States. Residential LEDs — especially ENERGY STAR rated products — use at least 75% less energy, and last 25 times longer, than incandescent lighting.\nWidespread use of LED lighting has the greatest potential impact on energy savings in the United States. By 2027, widespread use of LEDs could save about 348 TWh (compared to no LED use) of electricity: This is the equivalent annual electrical output of 44 large electric power plants (1000 megawatts each), and a total savings of more than $30 billion at today’s electricity prices.\nHow LEDs are Different\nLED lighting is very different from other lighting sources such as incandescent bulbs and CFLs. Key differences include the following:\n- Light Source: LEDs are the size of a fleck of pepper, and a mix of red, green, and blue LEDs is typically used to make white light.\n- Direction: LEDs emit light in a specific direction, reducing the need for reflectors and diffusers that can trap light. This feature makes LEDs more efficient for many uses such as recessed downlights and task lighting. With other types of lighting, the light must be reflected to the desired direction and more than half of the light may never leave the fixture.\n- Heat: LEDs emit very little heat. In comparison, incandescent bulbs release 90% of their energy as heat and CFLs release about 80% of their energy as heat.\nInfo: Originally Energy Saver is the U.S. Department of Energy’s (DOE) consumer resource on saving energy and using renewable energy technologies at home. Learn more about the Energy Saver Mission."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:970f8f3b-c989-4d0f-9cab-30aac11a850e>","<urn:uuid:3d2067a8-fd2b-4323-8f97-1e437d5009b0>"],"error":null}
{"question":"Can anyone tell me what are the key differences between Aloe ferox and Aloe parvibracteata in terms of their height and growing patterns? 🌿","answer":"Aloe ferox and Aloe parvibracteata have significant differences in their size and growth patterns. Aloe ferox is a much larger plant, growing as a succulent, evergreen tree that reaches 2-4 meters tall (occasionally up to 5 meters), with an unbranched stem topped by a rosette of 50-60 erect to spreading leaves. In contrast, Aloe parvibracteata is much smaller, growing only 20-40 cm tall (excluding inflorescence), and while it can be solitary, it typically suckers freely to form large, dense groups. Aloe parvibracteata is generally stemless, though it may develop a short, erect or creeping stem over time.","context":["Aloe candelabrum A.Berger.\nAloe galpinii Baker\nAloe horrid Haw.\nAloe muricata Haw.\nAloe pallancae Guillaumin\nAloe perfoliata ferox (Mill.) Aiton\nAloe pseudoferox Salm-Dyck\nAloe subferox Spreng.\nAloe supralaevis Haw.\nBusipho ferox (Mill.) Salisb.\nPachidendron ferox (Mill.) Haw.\nPachidendron pseudoferox (Salm-Dyck) Haw.\nPachidendron supralaeve (Haw.) Haw.\nCommon Name: Cape Aloe\nCultivated plant in the Walter Sisulu Botanical Garden, S. Africa\nPhotograph by: Marco Schmidt\nCape aloe is a succulent, evergreen tree that grows from 2 - 4 metres tall, occasionally to 5 metres. The stem is unbranched and is topped by a rosette of 50 - 60 erect to spreading leaves that can each be up to 100cm long and 15cm wide at their base. The leaves are densely armed with sharp spines[\nA very popular traditional medicine, the plant is also a major source of 'bitter aloes', which is commonly used by herbalists worldwide. The plant is widely grown as an ornamental, often as a pot plant in cooler climates. It is also often harvested from the wild and cultivated for its medicinal and cosmetic uses, being used in both traditional and conventional medicine[\n]. Although considerable quantities of Cape aloe are marketed and used locally, most of the exudate produced in South Africa is exported[\nThe sap of Aloe species contains anthraquinones. These compounds have several beneficial medicinal actions, particularly as a laxative, and many species of Aloe are thus employed in traditional medicine. Whilst safe in small doses and for short periods of time, anthraquinones do have potential problems if used in excess. These include congestion and irritation of the pelvic organs[\n]. Long term use of anthraquinone laxatives may also play a role in development of colorectal cancer as they have genotoxic potential, and tumorigenic potential[\nSouth Africa - Cape Province.\nAbundant on arid rocky hillsides up to 1,000 metres altitude[\n]. Also found in grassy fynbos and on the edges of the karoo. It grows both in the open and in bushy areas[\n|Other Uses Rating||\n|Cultivation Status||Cultivated, Ornamental, Wild\nAloe ferox is indigenous to the arid subtropical areas of South Africa, but it is now widely grown throughout the tropics and subtropics[\n]. It grows in a wide range of climatic conditions. It is especially abundant where mean temperatures range from 27 - 31Â°c and annual rainfall ranges from 50 - 300mm[\n]. Plants can withstand light frost, with occasional short-lived temperatures as low as -4Â°c, although the flowers may be damaged at -2Â°c[\nRequires a sunny position and a very well-drained soil. Thrives on rich soils[\n], but is also tolerant of poor ones[\nAloe species follow the Crassulacean acid metabolism (CAM). CAM plants are able to fix CO2 at night and to photosynthesize with closed stomata during the day, thus minimizing water loss. This, plus their succulent leaves and stems and the presence of a thick cuticle, makes them well adapted to dry conditions. Severe drought, though, stops exudate production[\nAlthough the root system is shallow, the plant can grow under very dry conditions[\nA slow-growing plant[\nCape aloe has a stem surrounded with a persistent layer of dead leaves that insulate it in the case of bush fires[\n]. Harvesting of Aloe ferox leaves for medicinal purposes could thus result in significant mortality due to fires[\nThe gel from the leaves has been used in South Africa to make a jam that tastes like watermelon jam[\n]. It is also gaining importance as a refreshing and nutritive ingredient in food and drinks[\nDry leaves are harvested and crushed, after which a decoction is used to make a herbal tea[\nThe flowers are sucked for their sweet nectar[\nIn southern Africa the thickened, red leaf exudate, called â€˜Cape aloeâ€™, is used as a purgative in human and veterinary medicine and fresh exudate is applied in cases of ophthalmia and syphilis[\n]. It is also used in the treatment of arthritis[\nThe gel from the core of the leaves has a similar use as the gel from the leaves of Aloe vera, and is used to treat skin afflictions (burns, wounds, abrasions, irritations), and is applied as a poultice on contusions or as a general refrigerant[\n]. It is furthermore used as a hair wash to promote hair growth and against dandruff[\nThe distinctive constituents in Aloe leaves are phenolic compounds, including chromone, anthraquinone or anthrone derivatives. Some of the compounds are found in many species, whereas others occur in only a few[\nThe gel from the core of the leaves has a similar use as the gel from the leaves of Aloe vera, and is used as a hair wash to promote hair growth and against dandruff and as a cosmetic to improve the complexion and to smooth the skin[\n]. Aloe gel is also widely used as a hydrating and skin-protecting agent in creams and liquids such as sun lotion, shaving cream, lip balm and healing ointments[\nThe leaf ash is used as an insect repellent[\nIn South Africa Aloe ferox is planted as a live fence[\nSeed - sow in a well drained medium in shallow trays and cover lightly with sand or the seed will blow away[\n]. Once the seeds begin to germinate, keep moist but watch out for overwatering as the seedlings could rot[\n]. Transplant into small pots or bags once they are about 4cm high (approximately 6 months)[\nPlants can also be propagated by planting of the tops of old plants[\nPlant regeneration from root and embryo tissue is successful as well[","Your support is critical to our success.\nOrigin and Habitat: This aloe has a wide distribution area. Found in South Africa , from the Lebombo Mountains to the sea. (Northern Province, Mpumalanga, Swaziland, and KwaZulu-Natal); also in Mozambique and Zimbabwe.\nType locality: Mozambique, Maputo.\nHabitat: It grows mostly on rock outcrops in hot flat grasslands and thorny woodlands with scattered trees and shrubs, often in seasonally swampy areas or near water-courses. It has no specific requirements for soil, being found to grow equally well on heavy clay and in cracks in rock.\nAltitude: 0-230 meters above sea level.\n- Aloe parvibracteata Schönland\nAloe parvibracteata Schönland\nRec. Albany Mus. 2: 139 (1907)\n- Aloe parvibracteata Schönland\n- Aloe burgersfortensis Reynolds\n- Aloe decurvidens Groenewald\n- Aloe keithii Reynolds\n- Aloe lusitanica Groenewald\n- Aloe parvibracteata var. zuluensis (Reynolds) Reynolds\n- Aloe pongolensis var. zuluensis Reynolds\nDescription: Aloe parvibracteata is a a typical maculate aloe, solitary or in small groups or, usually suckering, freely to form large, dense groups that grows up to 20-40 cm tall excluding inflorescence. It is extremely variable in habit, leaf arrangement and shape.\nStem: Plants are generally stemless, but may in time develop a short, erect or creeping stem.\nRosettes: Tends to be distichous as a seedling, but forms a perfect rosette as it grows. The rosette is more or less compact with approximatively 10-15 decurved to spreading widely leaves giving the rosette a flattened appearance.\nLeaves: 30-50 cm long, 3-8 cm broad toward the base, lanceolate-attenuate, but variable in shape and ranging from comparatively short, erect and triangular to fairly long and twisted, slightly channelled, upper surface dark brownish-green with many whitish spots in irregular transverse bands, sometimes obscurely lineate, lower surface spotted or unspotted. Marginal teeth 3 -5 mm long, sharp, deltoid, brown tipped, 0,8-1,5 cm apart. In this species the leaf sap usually dries deep purple to violet, but exceptional specimens with sap drying golden yellow are known.\nInflorescence: 0,5-1,5(-2) m tall with 4-9 ultimate branches sometimes rebranched; racemes cylindric, sub-lax, slightly acuminate, 15-20(-40) long, 6-7 cm in diameter with 40-50 florets.\nBracts deltoid-cirrhous or lanceolate-acuminate, 12 mm long, 3 mm broad, 5-7-nerved. Pedicels 6-17 mm long.\nFlowers: Coral-red or dull red, somewhat pruinose, 24-33(-40) mm long, 7-9 mm in diameter mouth down-turned; outer segments free for 8-10 mm with pale margins, inner segments dorsally adnate to outer; Anthers exserted 1-2 mm. Ovary 7-10 mm loong, 2,5-3,5 mm in diameter, green abruptly narrowed to 5 - 6 mm above; Stamens and style protruding beyond the margin 1-2 mm.\nBlooming season: Winter.\nChromosome number: 2n = 14\nFruit: Capsule, oblong-ovoid 20-23 long, 11-13 mm brod, greyish to purplish brown.\nSeeds: 2,5 × 6 mm, black with pale brown wings.\nNote: Aloe parvibracteata is most usefully separated from Aloe zebrina by the flowering season (winter, not autumn) and the leaf sap drying purple not yellow, but both of these characters are known to break down.\nSubspecies, varieties, forms and cultivars of plants belonging to the Aloe parvibracteata group\nBibliography: Major references and further lectures\n1) Dr J.P. Roux “Flora of South Africa” (2003)\n2) Urs Eggli “Illustrated Handbook of Suculent Plants: Monocotyledons” Springer, 2001\n3) Barbara Jeppe “South African aloes” Purnell, 1974\n4) “Aloe parvibracteata Schonland” in Records of the Albany Museum 2: 139 (1907)\n5) B-E. van Wyk & G.F. Smith, “Guide to the Aloes of South Africa” 62 (1996).\n6) Reynolds, “Aloe parvibracteata” Aloes S. Africa: page 276 (1950)\n7) Hans Bornman, David S. Hardy “Aloes of the South African veld” Voortrekkerpers, 1971\n8) S. Kativu “Flora Zambesiaca” Vol 12 Part 3, page 48 (2001)\n9) Paulos Cornelis Maria Jansen, D. Cardon “Dyes and Tannins” PROTA, 2005\nCultivation and Propagation: This is one of the most attractive foliage aloes and also bears attractive flowers. It is easy to grow and adaptable, it suckers and can form dense groups. It can be grown in large containers. Sometimes used as stock for hybrids because of the reliable red colour to the leaves. Many hybrids are available. All are drought-tolerant.\nGrowth: It grows slowly, but not agonizingly so being able to increase its width by 10- 20 cm per year under favourable conditions.\nSoil: Always use a good quality, loamy sandy soil with plenty of drainage with chips at the bottom of containers.\nRepotting: Use pot with good drainage.\nWatering: Needs moderate to copious waterings in summer, but do not overwater, or not at all in the colder months of winter. Outdoors it can withstand long periods of drought, but they will thrive and flower more profusely if watered in the correct season. This aloe is very tolerant of drought, although the tips of the leaves may wither and curl during hot, dry periods. Plant in full sun in a well-drained soil and irrigate only occasionally to enhance the red coloration of the foliage. Supplemental watering will help keeping the leaves plump, green and juicy.\nFertilization: Feed it once or twice during the growing season with a fertilizer specifically formulated for cactus and succulents (poor in nitrogen), including all micro nutrients and trace elements diluted to ½ the strength recommended on the label.\nExposure: It need full sun to partial shade, but plants grown in partial shade usually look healthier and more succulent. It is however very hardy when grown in full sun with the minimum water.\nHardiness: When dry it can stand light frost but it is damaged in hard freezes, but recovers quickly. The leaf tips and blooms get damaged below -2°C (USDA zones 9b-10 ). The clumps melted in the freeze, often return from underground suckers. During the winter months, the plants should be grown cool to initiate flower development (about 5-10°C )\nPests & diseases: Incorrect watering, poor drainage or too much shade can lead to attack by pests and diseases.\nMaintenance: Removal of old flower stalks; Divide the crowded clumps periodically. It grows much better outdoors in spring and summer.\nWarning: It's teeth are not too sharp, but they can hurt your fingers if you are pruning off some dead leaves (get stiffer once they dry).\nGardening: This is a great plant for color, if you have a bright, sunny spot in an area that doesn't get too much water. It is one of the redder aloes available. In mild climates it can be cultivated outdoors for use in landscaping, it can be grown in large, rocky, well-drained soil in gardens in drier areas. It adapts well to a variety of soils and climates, but will grow best in regions with a climate close to that of its native deserts not too cold, and not too wet. It makes an excellent ground cover, grows best in a sunny position and makes a long lasting cut flower.\nTraditional uses: This plant is suitable as a source of dye, the roots dye wool yellow.\nPropagation: By division of offshoots that develop around the outside of the main rosette in spring, the cuttings must be dried out for at least 1 week before planting in river sand. It is easily rooted in potting soil with warmth. It can also be propagated or by seed planted in autumn, in trays of coarse river sand, compost and soil. Sprinkle the seeds evenly on the surface and cover with a layer of small pebbles. The pebbles help the seedlings to stay upright and prevent damping off. Fresh seeds germinate quickly at 18° C. Keep seed tray in a dry corner and do not allow to dry out, but may damp off if overwatered. Transplant the seedlings after one year.\n|Back to Aloe index|\n|Back to Aloaceae index|\n|Back to Succulents Encyclopedia index|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:b07b975f-4d6b-4ea2-9cbc-9ddfe1e8cbd8>","<urn:uuid:9d1eb98d-502d-4c59-bee9-0417325847de>"],"error":null}
{"question":"How do the 'engines' in LLaMAIndex compare to the service models (SaaS, PaaS, IaaS) in cloud computing reference models in terms of interacting with data? Please structure the key differences.","answer":"LLaMAIndex's engines and cloud computing service models represent different approaches to data interaction. LLaMAIndex engines are specialized for natural language interactions, with Query engines handling Q&A interactions and Chat engines managing multi-turn conversations, both leveraging LLMs to process and respond to queries. In contrast, cloud computing service models provide different levels of data access: SaaS offers application-level data interaction through web interfaces, PaaS provides platform tools for data development and management, and IaaS delivers fundamental data storage and computing resources. While LLaMAIndex engines focus specifically on natural language processing of data, cloud service models offer broader infrastructure and service layers for general data management and processing.","context":["Software Development toolKits#\nLLM SDKs are specific for generative AI. These toolkits help developers integrate LLM capabilities into applications. The LLM SDK typically includes APIs, sample code, and documentation to aid in the development process. By leveraging an LLM SDK, developers can streamline their development processes and ensure compliance with industry standards.\nChatbots, prompt chaining, document related tasks\nComprehensive list of data sources available to get connected readily\nState of art embedding models in the bucket to choose from\nA-Z availability of LLMs out there in the market\nOpen source & 1.5k+ contributors strong for active project development\nConnecting multiple data sources to LLMs, document query interface using retrieval augmented generation, advanced chatbots, structured analytics\nWide options to connect & facility to create a new one\nBesides the 3 commonly available models we can use a custom embedding model as well\nSet of restricted availability of LLM models besides customised abstractions suited for your custom data\nTailor-made for high customisations if not happy with the current parameters and integrations\nIntegrating multiple LLMs, evaluating LLMs\nCurrently supports only\nExpanding the list of LLM providers with the most commonly used ones ready for use\nLightweight, streaming model response, consistent output response\nA few reasons for why there is a need for LLM SDKs in this current era of AI.\nCompliance with Agreements: By using an LLM SDK, developers can ensure that their application complies with agreements by logging, tracing, and monitoring requests appropriately. This helps avoid potential legal issues related to software piracy or unauthorised use of resources.\nImproved User Experience: An LLM SDK can help create a seamless user experience by removing boilerplate code and abstracting lower level interactions with LLMs.\nIncreased Security: By implementing an LLM SDK, developers can protect their resources and prevent unauthorised use of their software by security features such as access control and user management.\nFlexibility: An LLM SDK provides flexibility in terms of customisation and bringing together different components, allowing developers to tailor the management system to their specific needs and adapt it easily.\nImproved Collaboration: An LLM SDK can facilitate collaboration among team members by providing a centralised platform for license management, ensuring that everyone is on the same page regarding issues and compliance requirements.\nOn the LangChain page – it states that LangChain is a framework for developing applications powered by Large Language Models(LLMs). It is available as an python sdk and npm packages suited for development purposes.\nWell the beauty of LangChain is we can take input from various different files to make it usable for a great extent. Point to be noted is they can be of various formats like\nAfter collecting the data they are converted in the form of embeddings for the further use by storing them in any of the vector database. Through this way we can perform vector search and retrieve the data from the embeddings that are very much close to the embed query.\nThe list of vector stores that LangChain supports can be found here.\nThis is the heart of most LLMs, where the core functionality resides. There are broadly 2 different types of models which LangChain integrates with:\nLanguage: Inputs & outputs are\nChat: Run on top of a Language model. Inputs are a list of chat messages, and output is a chat message\nTools are interfaces that an agent uses to interact with the world. They connect real world software products with the power of LLMs. This gives more flexibility, the way we use LangChain and improves its capabilities.\nPrompt engineering is used to generate prompts for the custom prompt template. The custom prompt template takes in a function name and its corresponding source code, and generates an English language explanation of the function.\nTo create prompts for prompt engineering, the LangChain team uses a custom prompt template called\nFunctionExplainerPromptTemplate. This template takes the function name and source code as input variables and formats them into a prompt. The prompt includes the function name, source code, and an empty explanation section.\nThe generated prompt can then be used to guide the language model in generating an explanation for the function.\nOverall, prompt engineering is an important aspect of working with language models as it allows us to shape the model’s responses and improve its performance in specific tasks.\nMore about all the prompts can be found here.\nLangChain provides several advanced features that make it a powerful framework for developing applications powered by language models. Some of the advanced features include:\nChains: LangChain provides a standard interface for chains, allowing developers to create sequences of calls that go beyond a single language model call. This enables the chaining together of different components to create more advanced use cases around language models.\nIntegrations: LangChain offers integrations with other tools, such as the\naiohttpintegrations for tracing HTTP requests to LLM providers, and the\nopenaiintegration for tracing requests to the OpenAI library. These integrations enhance the functionality and capabilities of LangChain.\nEnd-to-End Chains: LangChain supports end-to-end chains for common applications. This means that developers can create complete workflows or pipelines that involve multiple steps and components, all powered by language models. This allows for the development of complex and sophisticated language model applications.\nLogs and Sampling: LangChain provides the ability to enable log prompt and completion sampling. By setting the\nDD_LANGCHAIN_LOGS_ENABLED=1environment variable, developers can generate logs containing prompts and completions for a specified sample rate of traced requests. This feature can be useful for debugging and monitoring purposes.\nConfiguration Options: LangChain offers various configuration options that allow developers to customize and fine-tune the behaviour of the framework. These configuration options are documented in the APM Python library documentation.\nOverall, LangChain’s advanced features enable developers to build advanced language model applications with ease and flexibility. Some limitations of LangChain are that while it is useful for rapid prototyping of LLM applications, scalability and deploying in production remains a concern - it might not be particularly useful for handling a large number of users simultaneously, and maintaining low latency.\nLLaMAIndex is a data framework for LLM applications to ingest, structure, and access private or domain-specific data. It provides tools such as data connectors, data indexes, engines (query and chat), and data agents to facilitate natural language access to data. LLaMAIndex is designed for beginners, advanced users, and everyone in between, with a high-level API for easy data ingestion and querying, as well as lower-level APIs for customisation. It can be installed using\npip and has detailed documentation and tutorials for getting started. LLaMAIndex also has associated projects like run-llama/llama-hub and run-llama/llama-lab.\nData connectors are software components that enable the transfer of data between different systems or applications. They provide a way to extract data from a source system, transform it if necessary, and load it into a target system. Data connectors are commonly used in data integration and ETL (Extract, Transform, Load) processes.\nThere are various types of data connectors available, depending on the specific systems or applications they connect to. Some common ones include:\nDatabase connectors: These connectors allow data to be transferred between different databases, such as MySQL, PostgreSQL, or Oracle.\nCloud connectors: These connectors enable data transfer between on-premises systems and cloud-based platforms, such as Amazon Web Services (AWS), Google Cloud Platform (GCP), or Microsoft Azure.\nAPI connectors: These connectors facilitate data exchange with systems that provide APIs (Application Programming Interfaces), allowing data to be retrieved or pushed to/from those systems.\nFile connectors: These connectors enable the transfer of data between different file formats, such as PDF, CSV, JSON, XML, or Excel.\nApplication connectors: These connectors are specifically designed to integrate data between different applications, such as CRM (Customer Relationship Management) systems, ERP (Enterprise Resource Planning) systems, or marketing automation platforms.\nData connectors play a crucial role in enabling data interoperability and ensuring seamless data flow between systems. They simplify the process of data integration and enable organisations to leverage data from various sources for analysis, reporting, and decision-making purposes.\nData indexes in LLaMAIndex are intermediate representations of data that are structured in a way that is easy and performant for Language Model Models (LLMs) to consume. These indexes are built from documents and serves as the core foundation for retrieval-augmented generation (RAG) use-cases. Under the hood, indexes in LLaMAIndex store data in Node objects, which represent chunks of the original documents. These indexes also expose a Retriever interface that supports additional configuration and automation. LLaMAIndex provides several types of indexes, including Vector Store Index, Summary Index, Tree Index, Keyword Table Index, Knowledge Graph Index, and SQL Index. Each index has its own specific use case and functionality.\nTo get started with data indexes in LLaMAIndex, you can use the\nfrom_documents method to create an index from a collection of documents. Here’s an example using the Vector Store Index:\nfrom llama_index import VectorStoreIndex\nindex = VectorStoreIndex.from_documents(docs)\nOverall, data indexes in LLaMAIndex play a crucial role in enabling natural language access to data and facilitating question & answer and chat interactions with the data. They provide a structured and efficient way for LLMs to retrieve relevant context for user queries.\nData engines in LLaMAIndex refer to the query engines and chat engines that allow users to interact with their data. These engines are end-to-end pipelines that enable users to ask questions or have conversations with their data. The broad classification of data engines are:\nQuery engines are designed for question and answer interactions with the data.\nThey take in a natural language query and return a response along with the relevant context retrieved from the knowledge base.\nThe LLM (Language Model Model) synthesises the response based on the query and retrieved context.\nThe key challenge in the querying stage is retrieval, orchestration, and reasoning over multiple knowledge bases.\nLLaMAIndex provides composable modules that help build and integrate RAG (Retrieval-Augmented Generation) pipelines for Q&A.\nChat engines are designed for multi-turn conversations with the data.\nThey support back-and-forth interactions instead of a single question and answer.\nSimilar to query engines, chat engines take in natural language input and generate responses using the LLM.\nThe chat engine maintains conversation context and uses it to generate appropriate responses.\nLLaMAIndex provides different chat modes, such as “condense_question” and “react”, to customise the behaviour of chat engines.\nBoth query engines and chat engines can be used to interact with data in various use cases. The main distinction is that query engines focus on single questions and answers, while chat engines enable more dynamic and interactive conversations. These engines leverage the power of LLMs and the underlying indexes to provide relevant and informative responses to user queries.\nData Agents are LLM-powered knowledge workers in LLaMAIndex that can intelligently perform various tasks over data, both in a “read” and “write” function. They have the capability to perform automated search and retrieval over different types of data, including unstructured, semi-structured, and structured data. Additionally, they can call external service APIs in a structured fashion and process the response, as well as store it for later use.\nData agents go beyond query engines by not only reading from a static source of data but also dynamically ingesting and modifying data from different tools. They consist of two core components: a reasoning loop and tool abstractions. The reasoning loop of a data agent depends on the type of agent being used. LLaMAIndex supports two types of agents:\nOpenAI Function agent: built on top of the OpenAI Function API\nReAct agent: which works across any chat/text completion endpoint\nTool abstractions are an important part of building a data agent. These abstractions define the set of APIs or tools that the agent can interact with. The agent uses a reasoning loop to decide which tools to use, in what sequence, and the parameters to call each tool.\nTo use data agents in LLaMAIndex, you can follow the usage pattern below:\nfrom llama_index.agent import OpenAIAgent\nfrom llama_index.llms import OpenAI\n# Initialise LLM & OpenAI agent\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\nagent = OpenAIAgent.from_tools(tools, llm=llm, verbose=True)\nOverall, data agents in LLaMAIndex provide a powerful way to interact with and manipulate data, making them valuable tools for various applications.\nLLaMAIndex provides several advanced features that cater to the needs of advanced users. Some of these advanced features include:\nCustomisation and Extension: LLaMAIndex offers lower-level APIs that allow advanced users to customise and extend any module within the framework. This includes data connectors, indices, retrievers, query engines, and re-ranking modules. Users can tailor these components to fit their specific requirements and enhance the functionality of LLaMAIndex.\nData Agents: LLaMAIndex includes LLM-powered knowledge workers called Data Agents. These agents can intelligently perform various tasks over data, including automated search and retrieval. They can read from and modify data from different tools, making them versatile for data manipulation. Data Agents consist of a reasoning loop and tool abstractions, enabling them to interact with external service APIs and process responses.\nApplication Integrations: LLaMAIndex allows for seamless integration with other applications in your ecosystem. Whether it’s LangChain, Flask, or ChatGPT, LLaMAIndex can be integrated with various tools and frameworks to enhance its functionality and extend its capabilities.\nHigh-Level API: LLaMAIndex provides a high-level API that allows beginners to quickly ingest and query their data with just a few lines of code. This user-friendly interface simplifies the process for beginners while still providing powerful functionality.\nModular Architecture: LLaMAIndex follows a modular architecture, which allows users to understand and work with different components of the framework independently. This modular approach enables users to customise and combine different modules to create tailored solutions for their specific use cases.\nLLaMAIndex seems more tailor made for deploying LLM apps in production. However, it remains to be seen how/whether the industry integrates LLaMAIndex in LLM apps, or develop customized methods for LLM data integration.\nAs the name suggests a light package that simplifies the task of getting the responses form multiple APIs at the same time without having to worry about the imports is known as the LiteLLM. It is available as a python package which can be accessed using\npip Besides we can test the working of the library using the playground that is readily available.\nThis is similar to OpenAI\ncreate_completion() method that allows you to call various available LLMs in the same format. LiteLLMs gives the flexibility to fine-tune the models but there is a catch, only on a few parameters.\nThere is also batch completion possible which helps us to process multiple prompts simultaneously.\nEmbeddings & Providers#\nThere is not much to talk about regarding embeddings but worth mentioning. We have access to OpenAI and Azure OpenAI embedding models which support\nHowever there are many supported providers, including HuggingFace, Cohere, OpenAI, Replicate, Anthropic, etc.\nBy setting the\nstream=True parameter to boolean\nTrue we can view the streaming iterator response in the output. But this is currently supported for models like OpenAI, Azure, Anthropic, and HuggingFace.\nThe idea behind LiteLLM seems neat - the ability to query multiple LLMs using the same logic. However, it remains to be seen how this will impact the industry and what specific use-cases this solves.\nFuture And Other SDKs#\nLangChain, LLaMA Index, and LiteLLM have exciting future plans to unlock high-value LLM applications. Future initiatives from Langchain include improving the TypeScript package to enable more full-stack and frontend developers to create LLM applications, improved document retrieval, and enabling more observability/experimentation with LLM applications. LlamaIndex is developing an enterprise solution to help remove technical and security barriers for data usage. Apart from the SDKs discussed, there are a variety of newer SDKs for other aspects of integrating LLMs in production. One example is prefecthq/marvin, great for building APIs, data pipelines, and streamlining the AI engineering framework for building natural language interfaces. Another example is homanp/superagent, which is a higher level abstraction and allows for building many AI applications/micro services like chatbots, co-pilots, assistants, etc.\nMissing something important? Let us know in the comments below, or open a pull request!","Introduction to Cloud Computing Reference Models\nCloud computing, being this decade’s most revolutionary innovation, provides services such as Storage, Networking, Software, Analytics, and more, all under the convenience of just one click. Aiming to exhibit an astonishing CAGR of 20%, the global cloud computing industry is set to reach a market size of $2,432.87 billion by 2030, amplifying its significance across industries.\nThe current landscape has many vendors that provide various services to their customers. This makes it tough to evaluate each vendor. With the adoption of the cloud growing rapidly and the increasing number of vendors, we need to define a cloud computing standard that helps us understand how each one works and compare these with one another.\nThe Cloud Computing Reference Model is an abstract model that defines the cloud vocabulary and design elements, the set of configuration rules, and the semantic interpretation. In simpler words, it divides the cloud into layers, defines each function, and provides a reference model for cloud computing, helping users select the right model for specific applications and efficient deployment.\nThe Cloud Computing Reference Model is divided into three cross functional Layers:\n- Software as a Service (SaaS)\n- Platform as a Service (PaaS)\n- Infrastructure as a Service (IaaS)\nLet us look at each of these pillars of the cloud reference model.\nAlso, Check out our IT free courses to get an edge over the competition.\nSoftware as a Service (SaaS)\nSoftware as a service is a software delivery model where licensed software, usually on a subscription basis, is centrally hosted and used by customers over the internet via a web browser or through client software. It is also referred to as on-demand software or web-based/web-hosted software. The customer only creates an account and pays the associated fee if applicable. The SaaS provider is responsible for operating and maintaining the software and the platform that it runs on.\nSaaS is currently the most common cloud computing service. Day-to-day workforce applications such as Slack, Zoom, and Customer Resource Management (CRM) software are prime examples of SaaS.\nPlatform as a Service (PaaS)\nPlatform as a Service is a cloud computing model which provides customers with a complete platform to develop and run their applications. This includes hardware, software, infrastructure like servers, storage, databases, and development tools hosted at the vendor’s data centre. This helps avoid the cost, complexity, and inflexibility of maintaining this on-premise. Developers can build and deploy apps on the cloud without worrying about the underlying architecture and resource constraints. The cloud provides them with the ability to scale up on demand and also scale down during idle & low-traffic periods.\nInfrastructure as a Service (IaaS)\nInfrastructure as a Service is a cloud computing model that deals with fundamental computing, network and storage. Contrary to PaaS, it provides the lowest level of resources on the cloud. This was one of the earliest cloud offerings since the early 2010s and continues to grow with the introduction of new technologies such as containerisation, serverless computing, etc. It is the foundational core of any architecture.\nCheck Out upGrad’s Software Development Courses to upskill yourself.\nThe NIST Cloud Reference Model\nVarious cloud computing reference models are used to represent consumers’ different requirements. The National Institute of Standards and Technology (NIST) is an American organisation responsible for adopting and developing cloud computing standards. The NIST cloud computing model comprises five crucial features:\n- Measured Service\n- On-demand self-service\n- Resource pooling\n- Rapid elasticity\n- Broad network access\nThey follow the same three service models defined earlier: SaaS, PaaS and IaaS, and mention four deployment models: i.e., Private, Community, Public, and Hybrid cloud.\nThe CSA Cloud Reference Model\nSecurity in the cloud is a rising concern. With so much data being available and distributed on the cloud, vendors must establish proper controls and boundaries. The Cloud Security Alliance (CSA) reference model defines these responsibilities. It states that IaaS is the most basic level of service, followed by PaaS and then SaaS. Each of them inherits the security intricacies of the predecessor, which also means that any concerns are propagated forward. The proposal from the CSA is that any cloud computing model should include the below-mentioned security mechanisms:\n- Access control\n- Audit trail\nThe OCCI Cloud Reference Model\nThe Open Cloud Computing Interface (OCCI) is a set of specifications and standards that defines how various cloud vendors deliver services to their customers. It helps streamline the creation of system calls and APIs for every provider. This model not only helps with security but also helps create managed services, monitoring, and other system management tasks that can be beneficial. The main pillars of the OCCI cloud computing reference model are:\n- Interoperability – Enable diverse cloud providers to operate simultaneously without data translation between multiple API calls\n- Portability – Move away from vendor lock-in and allow customers to move among providers depending on their business objectives with limited technical expenses, thus fostering competition in the market\n- Integration – The feature can be offered to the customer with any infrastructure\n- Extensibility – Using the meta-model and discovering features, OCCI servers can interact with other OCCI servers using extensions.\nThe CIMI & DMTF Cloud Reference Model\nThe Cloud Infrastructure Management Interface (CIMI) Model is an open standard specification for APIs to manage cloud infrastructure. CIMI aims to ensure users can manage the cloud infrastructure simply by standardising interactions between the cloud environment and the developers. The CIMI standard is defined by the Distributed Management Task Force (DMTF). They provide the protocols used for the Representational State Transfer (REST) protocol using HTTP, although the same can be extended for other protocols.\nEach resource in the model has a MIME type that contextualises the request and response payload. URIs identify resources; each resource’s representation contains an ID attribute known as the ‘Cloud Entry Point’. All other resources in the environment will then have iterative links associated with this resource.\nFor example, a particular virtual machine on the cloud could be identified by the below URL:\nImage source CIMI & DMTF Cloud Reference Model\nCloud Computing Reference Model Use Cases and Examples\nIaaS use case\nA business requires to provision VMs for their rapidly growing demand. They can utilise an IaaS provider such as Amazon Web Services (AWS) to scale their infrastructure without needing physical hardware.\nPaaS use case\nA software development team wants to focus on building applications rather than worrying about the underlying system and architecture. They can choose a PaaS provider, like Google App Engine (By Google Cloud Platform – GCP) or Heroku, to deploy and manage their applications.\nSaaS use case\nA business requires a Customer Relationship Management (CRM) tool to manage its sales and customer interactions. Instead of spending time and resources to build their in-house software, businesses can opt for SaaS offerings like Salesforce or HubSpot via the cloud without worrying about maintaining it.\nIn-Demand Software Development Skills\nCloud service management use case\nEnterprises need to manage their cloud resources centrally. This includes monitoring the usage of cloud resources across providers to help them gain visibility, optimise costs and enforce security policies across their data on the cloud.\nResource control use case\nBusinesses like financial institutions must ensure security and compliance controls across their organisation for the sensitive data stored on the cloud. Cloud service providers implement robust, fine-grained access controls for all their cloud services and offerings. This includes Identity and Access Management (IAM) by AWS and Azure Active Directory (AD) by Microsoft, which help manage user permissions, authentication and auditing.\nComparison of Cloud Computing Reference Models\nAs discussed in the previous sections, the cloud computing reference models provide a detailed framework for understanding the different layers and standardising cloud computing. The NIST reference model emphasises essential characteristics and service and deployment models. In contrast, the CSA model focuses on the Security aspect of cloud computing and how it needs to be enforced. The OCCI & CIMI models specify how developers can interact with the offerings through various APIs and how they can be viewed and accessed uniformly across the various cloud vendors.\nIt is important to note that although various models are being discussed and compared, they need to be used together to comprehensively understand cloud computing. Businesses and developers can use these specific models based on their requirements to help them plan, design, and evaluate various vendors and arrive at an effective cloud solution.\nExplore our Popular Software Engineering Courses\nIn conclusion, cloud computing reference models play a significant role in guiding, comprehending, implementing and utilising cloud computing environment efficiently. By understanding each reference model in depth, users can accurately choose the most relevant cloud computing services to optimise their organisation’s growth.\nOn the other hand, optimising your skillset with the right course is equally important to fuel your growth in the field. upGrad’s Full Stack Software Development Bootcamp can help you create a strong development base to further understand the significance of cloud computing systems and their implementation. Master of Science in Computer Science is another course you can go for if you’re aiming to advance your career in the development field.\nWhat is the difference between a cloud consumer and a cloud provider?\nA cloud consumer is an entity which uses the resources and services provided by the cloud provider. The cloud consumer is the entity which typically pays a subscription fee to the cloud providers to use their resources.\nWhat is a cloud computing reference model?\nThe cloud computing reference model is a framework that provides a structured approach to understanding the various intricacies of the cloud, such as different layers, services, functional components, etc.\nAre there different cloud computing models for different use cases?\nYes, the different cloud computing models are used to understand the different perspectives of the cloud and its offerings. Some models focus on specifics like security and architecture, while others provide a holistic view of the entire ecosystem."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:e667425d-fc52-4b93-938d-e3b192b6470b>","<urn:uuid:0aeccd6d-71be-4e1d-9324-00550044bc66>"],"error":null}
{"question":"Were Edward Lear and Palmer Cox similar in how they marketed their characters? Can you compare their approach to character merchandising? 他们的营销策略有什么异同？","answer":"While Palmer Cox ran an entire line of toys related to his Brownies characters and marketed illustrated books in the 1880s, Edward Lear was primarily known as a painter (even teaching Queen Victoria) and did not actively merchandise his characters like the Jumblies. Lear's works were later illustrated by others like Edward Gorey and published by companies like Pomegranate, but he wasn't directly involved in marketing character merchandise.","context":["Browse the children’s coloring book section in any book or toy store today and you are bound to notice that nearly all are associated with a recognizable character or franchise: Barbie™, Marvel Comics, Walt Disney™, and others. Their familiarity is engaging to children who relish the opportunity to interact with their favorite characters. This is not a modern phenomenon, children having long been drawn to characters they recognize.\nThe popularity of Palmer Cox’s Brownies and the success of related merchandise follows this pattern beginning in the 1880s, culminating in the publication of the primer in 1923. Cox not only marketed his illustrated books, he ran entire line of toys related to the Brownies.\nAs early as the 1890s, newspapers ran serial comic strips featuring specific characters who soon captured children’s imaginations. The idea behind comic strips was to increase newspaper sales to adults who would then share the paper. Children whose parents could not (or would not) buy the newspapers were still familiar with the comic strips, acquiring papers from other adults or friends willing to share. During the Great Depression, publishers reprinted comic strips into cheap coloring books, in an attempt to increase revenue.\nEarly advertisers used this principle to leverage children as a new market. The popular comic strip Buster Brown (first printed in 1902) was one of the earliest examples of synergy among advertising, comics, and character fame. Catalogs for consumer products soon featured new characters whose adventures entertained children in the same way as comic strips. Some marketed directly to children; others encouraged them to promote certain products to their parents.\nThe Dutch Boy’s Hobby, for example, establishes its hero on the cover. The subsequent pages build the story of the Little Dutch Boy and his Lead Horse fighting off General Trouble. Like other early coloring books, each page paired a colored and an uncolored picture with an accompanying\nIn this example, the National Lead Company, makers of house paints, meant for this to be a self-contained activity book. (No one understood the hazards of lead paint in those days.) It contains a page at the end with red, yellow, and blue pigment squares so that children only needed a wet brush to color. Finally, the book contains a perforated, tear away pamphlet for children to pass on to their parents. The entire booklet was an exercise in advertising and disposability: made of cheap materials, held together with staples, and intended to be colored and cut up.\nOther advertisers appropriated popular characters without permission, as in the case of these versions of the Tin Man and the Scarecrow from L. Frank Baum’s Wonderful Wizard of Oz. Wherever the characters came from, though, every single one of these give-a-ways marketed the chosen product on each page.\nThese familiar faces were found in a coloring book handout issued by the Egg-O-See Cereal Company in 1906. The caption below the picture reads “I wish we were really and truly alive so we could eat some of that good Egg-O-See and E-C-Corn.” Hood’s Sarsaparilla offered a painting book that includes a page with a version of Edward Lear’s popular poem “The Owl and Pussy Cat” (albeit with words that fit their message).\nThis form of advertising was especially popular in the 1920s, coinciding with coloring books into cheap, easily replaceable toys. These books are bound with staples and printed on cheap paper without board covers. By the end of the decade, children’s coloring books had achieved the form they take today. They were meant to be taken up, enjoyed, and abandoned.\nOak Hall Catalog – Click here to see another example of a catalog with coloring pages.","Hieroglyphs from A to Z: A Rhyming Book with Ancient Egyptian Stencils for Kids. By Peter Der Manuelian. Pomegranate Kids. $17.95.\nThe Jumblies. By Edward Lear. Drawings by Edward Gorey. Pomegranate. $14.95.\nThe Dong with a Luminous Nose. By Edward Lear. Drawings by Edward Gorey. Pomegranate. $14.95.\nThe Wuggly Ump. By Edward Gorey. Pomegranate. $12.95.\nEdward Gorey Coloring Book: The Wuggly Ump and Other Delights. Pomegranate Kids. $7.95.\nThere is nothing the slightest bit typical about childhood as seen and experienced through books from Pomegranate – no, not even when those books are in the recently established Pomegranate Kids line. Any respectable child-oriented book catalogue must, for example, include an alphabet book. But an alphabet from Boston’s Museum of Fine Arts, featuring reproductions of ancient Egyptian carvings and the hieroglyphs used thousands of years ago to represent sounds? That is the Pomegranate way. In fact, Hieroglyphs from A to Z will be as fascinating for parents as for children – maybe even more so. There is no one-to-one correspondence between our alphabet and hieroglyphs, but there is sufficient sound correspondence to make this whole project workable and fascinating. For example, although the Egyptians had no letter C, a symbol resembling a basket with a handle stands for the hard C sound. The C page shows a statuesque cat, explains about cats being sacred in ancient Egypt, shows the symbol for the C sound, and demonstrates how to spell the word “cat” using hieroglyphs. So it goes throughout this wonderful, highly colorful book. The letter M is represented by an owl, and the page shows how to spell Man. The letter P is a footstool, and the page shows how to spell Pyramid. And so on. At the back of the book are a discussion of hieroglyphs; suggestions on using them to write secret messages; a table of English letters and sounds and their hieroglyph equivalents; and an absolutely wonderful stencil that kids can use to trace individual hieroglyphs accurately. Originally published in 1991 and long out of print, Hieroglyphs from A to Z is, in this wonderful new edition, an alphabet book like no other and a delight from start to finish.\nWonderful in a different way are the two small hardcover books of Edward Lear’s nonsense poems about the Jumblies and their travels – as illustrated by Edward Gorey (1925-2000), whose fascination with the macabre here takes a back seat to meticulous and deliciously amusing renditions of the characters and their surroundings. Lear (1812-1888) was not primarily a nonsense versifier, although that is how most people know him today – in his own time, he was a painter of some note, his most famous pupil being Queen Victoria herself. But poems such as The Jumblies and its sequel, The Dong with a Luminous Nose, are the works with which he is now identified, and the poetry is even more delightful when accompanied by Gorey’s illustrations. There is a lovely cadence to Lear’s writing: “Far and few, far and few,/ Are the lands where the Jumblies live;/ Their heads are green, and their hands are blue,/ And they went to sea in a Sieve.” This oft-repeated portion of the Jumblies’ story is initially accompanied by a simply perfect Gorey picture of 10 Jumblies, most with their backs to the reader, rendered with extreme care and individuality on a beach above which clouds float. The drawing is as instantly recognizable as the verse. A later illustration for a repeat of the same words has 10 Jumblies facing the reader, stacked upon each other in a pyramid, their expressions neither smiling nor unsmiling, their poses dancelike and elegant. As the poem The Jumblies progresses – “They whistled and warbled a moony sing/ To the echoing sound of a coppery gong” – the voyage goes on, all the way to “the Hills of the Chankly Bore,” and eventually back again, where the Jumblies are honored with “a feast/ Of dumplings made of beautiful yeast.” But they leave some sorrow behind, as readers learn in The Dong with a Luminous Nose, a little love story about a stopover that the Jumblies made on their voyage. Here – on “the great Gromboolian plain” – a character known only as the Dong “fell in love with a Jumbly Girl/ Who came to those shores one day.” After a brief idyll, she left with the rest of the Jumblies, and the Dong made himself “A Nose as strange as a Nose could be!” Gorey’s pictures of the construction – which follow Lear’s description carefully – are wonderful, and the tale’s bittersweet ending, with the Dong using his luminous nose to search every night for the long-gone Jumbly girl, brings out Gorey’s underlying sentimentality while complementing Lear’s. The Gorey-illustrated Lear books are for children, to be sure, but it takes a special kind of child to appreciate them. A special kind of parent, too.\nNor are these two Gorey books the only ones available for kids from Pomegranate. Oh no. But The Wuggly Ump, whether in original small-hardcover size or as a new coloring book that also includes several other Gorey drawings in black-and-white, is most assuredly not for everyone. This morbid minor masterpiece, originally published in 1963, is Gorey at his finest or most peculiar, depending on your point of view. The singsong poetry details the untroubled lives of three wholesome, milk-and-bread-fed children who receive an unexpected and unwanted visit from the mysterious, gigantic and huge-toothed Wuggly Ump, which “eats umbrellas, gunny sacks,/ Brass doorknobs, mud, and carpet tacks.” Gorey writes that “its other habits are obscure,” but the children who are having “lovely dreams” find out soon enough why the beast has come to visit them. There is nothing gory in Gorey’s story – he always leaves that sort of thing to the reader’s imagination – but there is no doubt about the children’s fate, with Gorey showing them all topsy-turvy at the end within a broadly smiling Wuggly Ump. Kids who find this story amusing (and a surprising number will) can see the colors of all 14 of Gorey’s original illustrations in small pictures on the inside front and back covers of the coloring book – along with original versions of the other eight drawings included inside. Then budding young artists can select their own colors for each and every picture. It is a fair bet that most of their choices will be more, shall we say, forceful than the subtle ones Gorey picked. But that is the fun of the Edward Gorey Coloring Book and, for that matter, a great deal of the fun of The Wuggly Ump itself."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:fc7a9de3-1d57-4f70-a59b-14bc840e95f7>","<urn:uuid:e73d2a4a-5aa4-4058-825d-f0198dc1b9b3>"],"error":null}
{"question":"Can you tell me how long Emperor penguins and Whiteheads live? What is maximum age for both birds!","answer":"According to the documents, Emperor penguins have a life span of at least 20 years, while Whiteheads have a maximum longevity of 16 years. Therefore, Emperor penguins typically live longer than Whiteheads by at least 4 years.","context":["Whiteheads are gregarious songbirds that live in noisy groups of up to 8 members and that are often heard before they are seen. They are only found in the North Island where they inhabit mostly the canopy regions of tall dense forest. Their numbers have been in decline but relocations in recent years have seen some very good results with several newly established populations. Whiteheads are the only North Island hosts for the long-tailed cuckoo.\nWhiteheads are small songbirds with a compact body, short tail and bill and long legs. The head and underparts are white or whitish. Upperparts, wings and tail are brown-grey. Bill, legs and eyes are dark.\nVoice: whitehead song is a characteristic viu viu viu zir zir zir zir or canary-like twitter. Several other chirps or chatters are used for constant communication within the group.\nSimilar species: although some species such as sparrow and silvereye are similar in size, the distinct white head and underparts make the whitehead easily distinguishable from other small passerines.\nDistribution and habitat\nThe whitehead occurs only in the North Island of New Zealand. Its mainland distribution is south of a line connecting the Pirongia Forest, Hamilton and Te Aroha. It is locally common though patchily distributed south of this line, and to the north is limited to offshore islands and one fenced translocation site. Whiteheads are naturally common on Little Barrier and Kapiti Islands, and have been successfully introduced to Tiritiri Matangi Island, Motuora Island and Tawharanui Regional Park in the Auckland area, plus Maungatautari, Mana Island and Karori Sanctuary. Attempts to establish whiteheads in the Waitakere ranges (Ark in the Park) and at Cape Sanctuary (Hawke’s Bay) are continuing, and in 2011 or 2012 they were released on Moturoa Island (Bay of Islands) and Motuihe, Rangitoto and Motutapu Islands in the Hauraki Gulf.\nAlthough found most commonly in tall native forest and dense shrubland, whiteheads also occur in mature pine plantations.\nWhiteheads are abundant on some pest-free offshore islands and mainland sites where predatory mammals are effectively controlled or excluded. They can be among the most abundant forest birds present at these sites (e.g. on Kapiti and Little Barrier Islands).\nThreats and conservation\nIn the past, whitehead numbers declined dramatically due to forest clearance and predation by introduced mammals (particularly ship rats and stoats). They are reluctant flyers that do not often cross open ground, and so are very vulnerable to habitat fragmentation, as local populations that die out cannot be replenished. In the late 1800s, whiteheads disappeared from the northern North Island including many offshore islands in the Hauraki Gulf. They survived on Little Barrier and Kapiti Islands and these two populations have been used as source populations for numerous translocations.\nWhiteheads produce a single clutch per season from October to January. Nests are tightly woven, neat cups lined with fine materials such as natural fibres or moss. They are usually built in tree forks, hidden in dense canopy vegetation. Clutches usually contain 3 eggs, laid on consecutive days by the primary female. The female is also the sole incubator. The primary male or helpers may feed her as well as her young, both on and off the nest. Whiteheads are very inconspicuous around their nest which makes nests hard to find. Incubation takes about 18 days, and the chicks leave the nest when 16-19 days old.\nWhiteheads are host to the brood-parasitic long-tailed cuckoo. The cuckoo lays her egg into the whitehead’s nest, and the whitehead incubates it along with her own eggs. After the cuckoo chick hatches, it ejects whitehead eggs and/or chicks from the nest and is raised by itself.\nBehaviour and ecology\nDuring the breeding season, whiteheads form very vocal, sedentary groups. These groups may break up or disperse to increase their foraging areas during the non-breeding season, when they can also be seen foraging in mixed-species flocks. Whiteheads are reluctant fliers but they move quickly through the canopy and are acrobatic when foraging, often hanging upside down.\nWhiteheads consume insects (especially caterpillars and beetles) and spiders, and sometimes take fruit or other plant material.\nGill, B. 1990. The whitehead; gregarious bird of North Island forests. Forest & Bird: 38-39.\nHeather, B.D.; Robertson, H.A. 1996. The field guide to the birds of New Zealand. Viking, Auckland.\nHiggins, P.J.; Peter, J.M. (eds) 2002. Handbook of Australian, New Zealand and Antarctic birds. Vol. 6, pardalotes to shrike-thrushes. Oxford University Press, Melbourne.\nLeuschner, N.; Brekke, P.; Cope, T. 2007. Longevity of a whitehead (Mohoua albicilla) on Tiritiri Matangi Island. Notornis 54, 233.\nMcLean, I.G.; Gill, B.J. 1988. Breeding of an island-endemic: the New Zealand whitehead Mohoua albicilla, Pachycephalinae. Emu 88: 177-182.\nMiskelly, C.M.; Powlesland, R.G. 2013. Conservation translocations of New Zealand birds, 1863-2012. Notornis 60: 3-28.\nLeuschner, N. 2013. Whitehead. In Miskelly, C.M. (ed.) New Zealand Birds Online. www.nzbirdsonline.org.nz\n- Social structure\n- co-operative breeding groups\n- Breeding season\n- Nest type\n- woven cup\n- Nest description\n- Tightly woven cup in dense canopy vegetation.\n- Nest height (mean)\n- 2.5 m\n- Nest height (max)\n- 30 m\n- Maximum number of successful broods\n- Clutch size (mean)\n- Clutch size (min)\n- Clutch size (max)\n- Mean egg dimensions (length)\n- 20 mm\n- Mean egg dimensions (width)\n- 15 mm\n- Egg colour\n- White, variable speckled orange-brown.\n- Egg laying dates\n- Interval between eggs in a clutch\n- 24 hours days\n- Incubation behaviour\n- female only\n- Incubation length (mean)\n- 18 days\n- Incubation length (min)\n- 17 days\n- Incubation length (max)\n- 19 days\n- Nestling type\n- Nestling period (mean)\n- 17 days\n- Nestling period (min)\n- 16 days\n- Nestling period (max)\n- 19 days\n- Age at fledging (mean)\n- 17 days\n- Age at fledging (min)\n- 16 days\n- Age at fledging (max)\n- 19 days\n- Age at independence (mean)\n- Young fed up to 9 months of age\n- Age at first breeding (typical)\n- 1 year\n- Maximum longevity\n- 16 years\n- Maximum dispersal","Emperor penguins are superlative birds. The largest penguin, they are the only bird that breeds in the depths of the Antarctic winter, and they can dive deeper (500 m) and survive longer without eating (4 months) than any other bird. Emperor penguins are also the only bird species that breeds on ice, and one of the few birds that doesn’t build a nest – the male balances the egg on top of his feet. When combined with their stunning good looks and ridiculously cute chicks, it is little wonder that emperor penguins command so much attention.\nEmperor penguins are very large penguins that could only be confused with the related, smaller king penguin. They are dark silver-grey on the back, and white on the breast and belly. The diagnostic broad pale patch on the side of the neck is yellow in adults and dull white in juveniles. Adults have a black head and chin, while juveniles have a chin colour that may vary from white to dark grey. The slender, decurved bill has a pink stripe on the lower mandible (paler in juveniles). Recently fledged chicks are about half the size of adults.\nVoice: a powerful, klaxon-like bray.\nSimilar species: king penguin is smaller and more brightly coloured, with a relatively longer bill. The pale neck patch is narrower (spoon-shaped) and dark orange in adults. When swimming, king penguins have smaller, brighter neck patches that do not reach the water, compared to the larger paler neck patch of the emperor penguin that extends to the water line.\nDistribution and habitat\nEmperor penguins are characteristic and abundant denizens of the Antarctic pack-ice. The 46 known colonies are scattered around the entire Antarctic continent, with almost all colonies located on fast ice (sea ice attached to the land) close to permanent openings (polynyas) in the sea ice. These polynyas, maintained by winds or currents, allow breeding adults to access feeding grounds during incubation and chick-rearing, including when the sea ice is at its annual maximum extent. The world population was estimated at 595,000 breeding pairs in 2009.\nAdults are rarely seen beyond the pack-ice, which extends to about 60° S at its maximum extent south of New Zealand. Juveniles tracked by satellite after leaving their natal colonies have been found to swim well north of the pack-ice, up to 54° S. Vagrants have occurred up to 40-41° S off Argentina and New Zealand.\nNew Zealand records\nThe two New Zealand records are contrasting tales. A bird in adult plumage came ashore on Oreti Beach, Southland, on 5 April 1967, and was released without fanfare off Dog Island, Foveaux Strait, the following day. The second record was an immature bird ashore on Peka Peka Beach, Kapiti coast, 20-24 June 2011, before being taken into care following excessive consumption of sand. This bird became a media sensation (widely known as ‘Happy Feet’), and was eventually released north-east of Campbell Island on 4 September 2011.\nBehaviour and ecology\nThe emperor penguin takes the generic penguin feed-and-fast lifestyle to extremes. They lay down extensive subdermal body fat, providing both insulation and energy reserves. This fat allows them to survive weeks or months without feeding during courting, incubation, chick care, moult, and the often lengthy transit between the sea and breeding colonies. As a result, the body weight of emperor penguins fluctuates greatly between about 23 and 45 kg. Males can lose up to 45% of their bodyweight during the 4 months that they are continuously at the colony from the start of courtship (March-April) through to after the egg hatches (July-August).\nThe single large egg is incubated entirely by the male for 62-67 days, with the female returning to the sea for 2 months until soon after the egg hatches. The egg, and later the young chick, is balanced on its parents’ feet during brooding. This mobile ‘nest’ allows the adults to move around, including forming their famous huddles during severe mid-winter blizzards. Both parents feed the chick through to fledging in December, timed to occur as the sea-ice breaks up in summer.\nBreeding adults moult in January-February, with juveniles and non-breeders moulting in November-December, either at colonies or elsewhere on Antarctic continent and sea ice. They first breed when about 5 years old, and have a life span of at least 20 years.\nEmperor penguins mainly consume fish, also squid and krill, captured by pursuit diving. Dives are of up to 18 min duration, typically to depths of 50 metres, exceptionally to over 500 metres. Chicks are fed by regurgitation by both parents.\nFretwell, P.T.; LaRue, M.A.; Morin, P.; Kooyman, G.L., Wienecke, B.; Ratcliffe, N.; Fox, A.J.; Fleming, A.H.; Porter, C.; Trathan, P.N. 2012. An emperor penguin population estimate: the first global, synoptic survey of a species from space. PLoS ONE 7 (4): e33751. doi:10.1371/journal.pone.0033751.\nHenderson, L.E. 1968. First record of the emperor penguin in New Zealand. Notornis 15: 34-35.\nKooyman, G.L.; Ponganis, P.J. 2008. The initial journey of juvenile emperor penguins. Aquatic Conservation: Marine and Freshwater Ecosystems 17: S37-S43.\nMarchant, S.; Higgins, P.J. (eds) 1990. Handbook of Australian, New Zealand and Antarctic birds. Vol. 1, ratites to ducks. Oxford University Press, Melbourne.\nMiskelly, C.M.; Simpson, P.; Argilla, L.S.; Cockrem, J.F. 2012. Discovery, care, and post-release monitoring of a vagrant emperor penguin (Aptenodytes forsteri). Notornis 59: 116-122.\nShirihai, H. 2007. A complete guide to Antarctic wildlife: the birds and marine mammals of the Antarctic continent and the Southern Ocean. 2nd edn. A & C Black, London.\nWienecke, B.; Raymond, B.; Robertson, G. 2010. Maiden journey of fledgling emperor penguins from the Mawson Coast, East Antarctica. Marine Ecology Progress Series 410: 269-282.\nMiskelly, C.M. 2013 [updated 2017]. Emperor penguin. In Miskelly, C.M. (ed.) New Zealand Birds Online. www.nzbirdsonline.org.nz\n- Social structure\n- Breeding season\n- Nest description\n- No nest - egg balanced on feet of adults\n- Nest height (mean)\n- 0 m\n- Nest height (min)\n- 0 m\n- Nest height (max)\n- 0 m\n- Maximum number of successful broods\n- Clutch size (mean)\n- Clutch size (min)\n- Clutch size (max)\n- Mean egg dimensions (length)\n- 122.5 mm\n- Mean egg dimensions (width)\n- 82.2 mm\n- Egg colour\n- greenish white\n- Egg laying dates\n- Interval between eggs in a clutch\n- 0 days\n- Incubation behaviour\n- male only\n- Incubation length (mean)\n- 65 days\n- Incubation length (min)\n- 62 days\n- Incubation length (max)\n- 67 days\n- Nestling type\n- Nestling period (mean)\n- 41 days\n- Age at fledging (mean)\n- 141 days\n- Age at independence (mean)\n- 141 days\n- Age at first breeding (typical)\n- Age at first breeding (min)\n- 3 years\n- Maximum longevity\n- 20 years\n- Maximum dispersal\n- some travel more than 300 km from breeding sites"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:9eccfee3-bb49-472a-9591-262cc2dedd04>","<urn:uuid:271fe05d-6989-4dbf-8064-675a4f014a28>"],"error":null}
{"question":"What happened to Jewish communities in 16th century Europe?","answer":"The 16th century saw a deterioration in the status of western Jews. Spanish Jews (Sephardim) were forced to either convert or leave in 1492, with many moving to Portugal, Low Countries, Italy, or the Ottoman Empire. Those who converted, called Marranos or New Christians, were often rejected by both Jews and Christians. The practice of confining Jews to ghettos (first established in Venice in 1516) became common in central and eastern Europe. While some Jewish communities prospered, particularly in Holland and Ottoman cities, overall the early modern period was a dark age for European Jewry.","context":["We need to step back and look at several things about colonization by European countries. We will look at the reasons for colonization and the agenda behind the movement. We have said throughout our building of the truth about history wee have stated that every movement forward in history and every expansion and conflict was caused by the need to create wealth. So what was the condition of Europe at the time colonization started. If you truly don't understand this point just go back and review the detailed facts about each of the 13 colonies relationship with the British Crown. In reading the following, begin conditioning the mind to look for things that relate to our current day economy.\nTo examine the psychology of merchants is to stay within a narrow social elite. Historians, in what is sometimes called “the new social history,” have paid close attention to the common people of Europe and to hitherto neglected social groups—women, the nonconformists, and minorities.\nTwo fundamental changes affected the status of early modern women. Women under protoindustrialization were valued domestic workers, but they also had little economic independence; the male head of the household, the father or husband, gained the chief fruits of their labor. A second change, perhaps related to the first, was the advancing age of first marriage for women. Medieval girls were very young at first marriage, barely past puberty; these young girls were given to mature grooms who were in their middle or late 20s. By the late 16th century, parish marriage registers show that brides were nearly the same age as their grooms and both were mature persons, usually in their middle 20s. This is, in effect, what demographers call the modern, western European marriage pattern. Comparatively late ages at first marriage also indicate that significant numbers of both men and women would not marry at all. Though the origins of this pattern remain obscure, it may be that families, recognizing the economic value of daughters, were anxious to retain their services as long as possible. European marriages were overwhelmingly patrilocal—that is, the bride almost always joined her husband’s household. Thus, the contribution that daughters made to the household economy exerted an upward pressure on their ages of marriage. Whatever the explanation for the new marriage pattern, the near equality of ages between the marriage partners at least opened the possibility that the two would become true friends as well as spouses; this was harder to achieve when brides were young girls and their husbands mature and experienced.\nIn investigating what might be called the cultural underground of the early modern age, historians now take full advantage of a distinctive type of source. The established religions of Europe, both Roman Catholic and Protestant, zealously sought to assure uniformity of belief in the regions they dominated. The courts inspired by them actively pursued not only the heterodox but also witches, the insane, and anyone who maintained an unusual style of life. The special papal court known as the Inquisition operated in many (though not all) Catholic states. Its judges carefully interrogated witnesses and kept good records. These records permit rare views into the depths of early modern society. They show how widespread was the belief in magic and the practice of witchcraft and how far popular culture diverged from the officially sanctioned ideologies. The variety and strange nature of popular beliefs have convinced some historians that Christianity had never really won the minds of rural people during the Middle Ages. Only the aggressive and reformed churches of the 16th century succeeded in converting the peasants to formal Christianity. This thesis may be doubted, but it cannot be doubted that the European countryside sheltered deep wells of popular culture which the documentation of the age leaves largely in darkness.\nWitchcraft presents special problems. Witches were hunted in the 16th century with a relentlessness never seen before. Were they becoming more numerous, their services more in demand? It may be that the two reformations, Protestant and Catholic, purged Europe of the magical aura that the medieval church had hung over it. It may be that the abiding thirst for enchantment could be slaked only in the cultural underground, only through popular magic. But it may also be that the new determination and efficiency of the reformed religions and the early modern states simply exposed persons long a fixture in village life: the woman healer, who knew the ancient, time-honored cures; the old wife, who through charms or potions could induce conception or sterility, love or hate. It is hard even to reconstruct the character of early modern witchcraft. Terrorized witnesses tended to respond in ways they thought would please their interrogators; thus, they reinforced stereotypes rather than revealing what they truly believed or did. Court records of this kind are not flawless sources, but they remain a rich vein of cultural history. Ironically, the court officials saved for history the thoughts and values they had hoped to extirpate.\nThe 16th century also witnessed a continuing deterioration in the status of western Jews. They had been expelled from England in 1290 and from France in 1306 (the first of several expulsions and readmissions). Riots and killings accompanying the Black Death (the Jews were accused of poisoning the wells) had pushed the centers of German Jewry (the Ashkenazim) to the east, into Poland, Lithuania, and, eventually, the Russian Empire. In 1492 the Jews of Spain (the Sephardim), who had formed the largest and most culturally accomplished western community, were given the choice of conversion or expulsion. Many chose to leave for Portugal (whence they would also be subsequently expelled), the Low Countries, Italy, or the Ottoman Empire. Those who remained and ostensibly converted were called “New Christians,” or Marranos, and many of these later chose to emigrate to more hospitable lands. Many Marranos continued to live as Jews while professing Christianity; accusations against them were commonly heard by the Inquisition in both Spain and Italy. Their position was especially distressing. Often, both Jews and Christians rejected them, the former for their ostensible conversion, the latter for secretly practicing Judaism.\nThe communities of exiles had different experiences. Jews in Holland made a major contribution to the country’s great prosperity. The Italian states, papal Rome included, accepted the exiles, hoping to profit from their commercial and financial expertise. Yet the Jews were also subject to increasingly severe restrictions. The Jewish community at Venice, which absorbed large numbers of Iberian Jews and Marranos, formed the first ghetto (the word itself is Venetian, first used in 1516). The practice of confining Jews into walled quarters, locked at night, became the common social practice of early modern states, at least in the central and eastern parts of the continent. The Sephardim, who continued to speak a form of Spanish known as Ladino, established large and prosperous colonies in Ottoman cities—Salonika, Istanbul, and Cairo among them. On balance, however, the early modern period in Europe was socially and culturally a dark age for Jewry.\nIs there a single factor that can explain the social history of Europe’s 16th century? Many have been proposed: population growth, overseas discoveries, the emergence of a world economic system, American treasure, profit inflation, capital accumulation, protoindustrialization, the Renaissance or Reformation. Perhaps the most decisive change was progress toward more integrated systems of social organization and action and toward wider and tighter social networks. The western monarchies overcame much of the political localism of the medieval world and set a model that even divided Italy and Germany would eventually emulate. Economic integration advanced even more rapidly; markets in foodstuffs, spices, luxuries, and money extended throughout the continent: The skilled banker could marshal funds from all the continent’s money markets; silks from Lucca were sold in Poland. Cities formed into hierarchies, still on a regional basis but surpassing in their effectiveness the loose associations of medieval urban places. To be sure, competition among the centralized states often led to destructive wars and terrible waste of resources; and the quest for unity brought shameful persecution upon those who could not or would not conform to the dominant culture."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:7cce0065-d55c-49da-b8ad-4f67550bc688>"],"error":null}
{"question":"怎么比较The Ramayana的dharma主题和Valençay奶酪的AOC规定？Both seem to represent strict cultural guidelines! 🤔","answer":"The Ramayana's concept of Dharma and Valençay's AOC regulations both represent codified systems of rules and standards in their respective contexts. Dharma in the Ramayana encompasses moral duty, cosmic order, and 'the Way,' serving as a guide for proper conduct and social order. Similarly, Valençay's AOC regulations strictly control aspects of production, including specific goat breeds, aging time, molding process, and even geometric specifications like the 96-102° angle requirement. Both systems help maintain cultural authenticity and traditional values, though Dharma operates on a philosophical-social level while AOC regulations function on a practical-commercial level.","context":["The Oral Tradition and the many \"Ramayanas\"\n\"'You have promised me the granting of two boons, and you have sworn to it in the name of Rama -- your darling son Rama. And now I'll speak out my mind. If you reject my demand, you will be the first of the Ikshvahu race, proud descendents of the sun god himself, to go back on a promise for the sake of convenience.' She took breath and demanded...\" (from Valmiki, trans. R.K. Narayan)\nTHE ORAL TRADITION AND THE MANY \"RAMAYANAS\"\nby Philip Lutgendorf, Chair, South Asian Studies Program, University of Iowa\nRama is born in countless ways, and there are tens of millions of Ramayanas... - Tulsidas (16th cent.) Ramcarittnanas 1:33:6\nAll right (you may be asking at this point), just how many of these things are there, anyway? The title of this curriculum guide speaks reassuringly of \"The Ramayana\" but later subheadings suggest a kind of textual population explosion, speaking of \"many,\"\n\"a thousand,\" and finally, \"tens of millions.\" Is this just epic hyperbole, like the myriads of arrows that shoot forth whenever the hero Rama releases his bow? And if not, how are American educators and students supposed to get a handle on a non-Western\ntext and tradition that is (as they say) growing even as we speak?\nI've been teaching the Ramayana for years, and (like most of the contributors to this guide) have found that it serves as an excellent window through which to open to American students great vistas of the world of Indian civilization. But I always begin\nby explaining that \"the Ramayana\" (in spite of the definitive article) is not a single book like \"the Bible\" but rather a story and a tradition of storytelling. For more than two millennia, this tradition has enjoyed a unique popularity throughout\nthe subcontinent of South Asia (comprising the modern states of India, Pakistan, Bangladesh, Nepal, and Sri Lanka) and beyond - for versions of the tale have flourished in Thailand, Cambodia, Laos, Vietnam, and Indonesia. Although the core story of\nthe travails of Prince Rama and Princess Sita and their companions remains much the same everywhere, storytellers and poets in dozens of languages have chosen not simply to translate some \"original\" version, but instead have retold the saga in their\nown words, often modifying and embellishing it according to regional traditions or their own insights and interpretations. At the same time, this tale has been continuously recreated orally - with all the fluidity we expect in oral performance - by\na whole spectrum of tellers ranging from traditional bards and singers to modern film and video producers (an epic television serialization of the story held Indian audiences spellbound in 1987-89), and also including countless grandmothers. Indeed,\nfor most modern Indians, the \"original\" Ramayana is as likely to mean a bedtime story heard in childhood as the 2000+ year old Sanskrit epic of the poet-sage Valmiki.\nSince the Ramayana is a story, and a charming one at that, students find it relatively easy to get into - even with four syllable foreign names. Like contemporary fantasy fiction and video-gaming, it ushers them into a world of superhuman heroes and hyperbolic\ndeeds, within which a strangely-familiar scenario unfolds: a handsome prince wins a beautiful princess for his bride, but is deprived of his kingdom by a scheming step-mother and unjustly exiled to the forest, where a wizard-king abducts the prince's\nwife and imprisons her in a golden island-fortress. The prince then sets out on a daring quest to recover his beloved, aided by talking animals and birds, and ultimately triumphs over his adversary (a villain so egotistical he has sprouted ten heads!)\nin a cataclysmic battle, to return in triumph and reclaim his throne. This skeletal outline resembles many European folktales, but as students are drawn deeper into the details of its epic plot, they encounter much that is unfamiliar, for the Ramayana\nencodes many of the cultural values of Hindu civilization: from a cosmology of cyclically-recurring eons, to a stratified social order and a patriarchical, extended-family structure based on arranged marriage, to the overarching theme of Dharma-a\ncentral cultural concept suggested by terms like \"morality,\" \"duty,\" \"cosmic order,\" or simply, \"the Way.\" Thus the story can open a portal leading students to encounter with the world-view of a great civilization that both resembles, and markedly\ndiffers from, their own and (a process, by the way, which may enable them to realize that they have a world view in the first place.)\nThe contributions in this guide - the work of educators who have come to value the Ramayana - are designed to help other teachers to facilitate such a cultural encounter by helping them to read \"between the lines\" of the epic story and to recognize some\nof the ethical and social values it encodes and the issues it raises. This last point is important, because as a fluid storytelling tradition, the Ramayana doesn't simply provide set answers. It also raises troubling questions that have been pondered\nand debated by audiences for centuries, and that have resulted, in some cases, in radical reinterpretations of characters and events, or in the creation of such \"alternative\" retellings as those that give greater prominence to women or that even cast\nthe \"villains\" as the real such heroes. In this way, it has functioned less as a fixed message than as a kind of language within which South Asian culture thinks about itself, and projects (and argues about) its ideals of the good life and the just\nsociety. Since one out of every seven people on earth today lives on the Indian subcontinent, there are literally \"tens of millions\" of Ramayanas out there - and still others \"over here\" as well, brought by a prosperous and culturally vibrant group\nof recent immigrants. Through studying the Ramayana story, you and your students will learn something important about the myriad bearers of this tale, and hopefully about yourselves.\nREFERENCE AND CLASSROOM MATERIALS","Intern Gabrielle Roman looks into what makes French cheeses tick for her blog series, Bon Fromage. Meant to answer any questions you might have but were afraid to ask about cheese made from the country famous for fromage, each post will focus on a specific cheese and take a deep dive into its history and production. Take the plunge and demystify the world of French cheese. If you missed it, check out last week’s post on the marvelous Maroilles.\nBy this point in the blog series, we’ve already established some themes you’ll see pop up again with Valençay. The origins of the cheese are shrouded in myth but are connected to a significant figure; AOC regulations demand strict rules for making Valençay; mold is an important part of the aging process; and it’s not pronounced the way you would initially think. The squiggly you see there under the “c” is called a cedilla, which turns the pronunciation of the “c” into an “s” sound. The second syllable “len” is not as straightforward as it looks, and is pronounced more like “lon.” All together you want to say “Vuh-lon-say.” I’ve found that even more than Roquefort or Maroilles, Valençay is best said with an over-the-top accent. I recommend saying it often and loudly.\nWhile the sale of cheese marketed specifically as Valençay only goes back 200 years (“only” being a term that proves, once again, that time is relative), its origins can really be traced back to the reign of Charlemagne in the late 700s and early 800s CE. An account of his rule from the 16th century talks about the importance of goats in the Loire Valley, which included the production of milk and cheese. So even if Valençay proper hasn’t been made that long, the tradition and history of goat’s milk and cheese in the central region of France goes back to the beginning of what we know as France. Is anyone surprised to learn that cheese has been integral since their beginning?\nValençay itself doesn’t stretch back to the 800s, because the town of Valençay had yet to exist to give the cheese its name. A tower was constructed in the 12th century in the lower Berry region, but in the early 1500s it was demolished and construction on a new castle began in 1520 on the still-standing Château de Valençay. Construction on the Château continued for centuries, but its presence definitely helped the town thrive and grow, so if we’re still playing fast and loose with facts, Valençay could have developed around the 1500s. One origin myth of the cheese proposes that it was produced to look like the Collegiate Church of Saint-Sylvain Levroux, which was built in the 14th century. I’ve looked at the pictures and don’t know exactly what the inspiration was. But there’s a much more colorful and oft-repeated tale that is told far more often because it’s far more fun.\nIn 1798, Napoleon Bonaparte went on a military campaign to Egypt for the purpose of establishing a French presence in the Middle East and to prevent British access to India and the East Indies. He attempted to establish himself as absolute ruler of Egypt and succeeded for several months, but ultimately a lack of new troops from France and civil unrest both in Egypt and France drove the future emperor out. This failure to achieve his goals allegedly deeply humiliated Napoleon. Upon returning to France, he was served Valençay, at that time formed into the shape of a perfect pyramid. Reminded of his defeat, he flew into a rage and he lopped the top off with his sword. Ever since that small temper tantrum, Valençay has been shaped like a truncated pyramid.\nThere’s another version of the story that features a politically aware character named Talleyrand. Anticipating that the shape of the cheese might infuriate Napoleon after his return, he had the tops of the cheese cut off ahead of time. Whatever story you want to believe, Talleyrand actually was a key player in the popularity of Valençay. As a close advisor to Napoleon, he was encouraged to purchase the Château de Valençay in May 1803. As a prince, bishop, and aristocrat, he started serving Valençay at fancy dinner parties. Soon, aristocrats were serving it to ensure their dinners were suitably fashionable. The real boom in production didn’t really start until the 1900s, but even the AOC commission gives credit to Talleyrand for creating a name and image for the cheese.\nAlthough Valençay does not immediately boast any kings who loved to eat it, I’m going to go ahead and give credit to Charlemagne here, who clearly understood the importance of goats. For his role in shaping France as a nation, I think Charlemagne deserves bonus points and so, because I can, he gets them. Napoleon also makes an appearance in the culture king count this week. Even if he hated Valençay, Napoleon is so often credited as being the reason its distinctive shape exists, that I think he has to be included on the list.*\nValençay achieved AOC status in 1998. This designation made Valençay the first region ever to have both AOC-protected wine and AOC-protected cheese. (There’s an entire website dedicated to both. It’s in French, but Google translate works pretty well.) The cheese is best paired with a drier wine like a sauvignon blanc or a light red. Happily, you can find Valençay wines that match this description and have an extremely region-specific dinner party.\nLike any other AOC cheese, Valençay has regulations in place that producers have to follow. The first is the region, of course, which is the Berry region where the town of Valençay is located. The cheese must be made from either Alpine or Saanen goats, and it must be made from raw goat’s milk. The cheese must be matured for a total of 11 days after rennet is added in the cheesemaking process. This presents problems for anyone in the US who wants to get their hands on some authentic Valençay. US laws dictate that any imported raw milk cheese must be aged for a minimum of 60 days before it can cross the border. As Valençay is typically not aged for more than two months, this can be a real problem and means that most of the Valençay you’ll find in stores is probably made with pasteurized milk. If you really want to experience the power of this one, you’ll have to hop on a plane.\nOther AOC regulations include the prohibition of putting any pressure on the cheese during the molding process (essentially, you can’t press the liquid out of it while it sits in molds), and it has to be salted with ash salt. The combination of charcoal and salt that is sprinkled on Valençay during the production process lends the cheese its distinctive wrinkled gray rind and helps maintain its flavor for longer. Valençay is aged in ventilated cellars with at least 80 percent humidity, allowing the white mold Penicillium candidum to develop.\nMuch like Maroilles, Valençay must be a certain size. For the large size, the base must be between 50–55 mm, or about 2 inches, and for the small size, the base must be between 40–44 mm, or about 1.5 inches. What’s more, the angle between the base of the cheese and the mold must be between 96–102°. And here you thought your geometry class would never come in handy again!\nWhen you cut into Valençay, you’ll notice a white paste and a dense and moist texture. (Goat cheese is always white, in fact! Read here for more info.) As Valençay ages it continues to soften, so the firmness of the cheese will depend on its age. Valençay generally tastes smooth and mild. When younger, the cheese will taste bright and more citric. As it ages, the nutty flavor comes through more. You should really eat it with the rind for the full experience, as the salt from the charcoal coating will enhance the flavor even further.\nToday, more than 350 million tons of Valençay are produced every year, which means there’s plenty for everyone. What better way to celebrate the Year of the Goat than munching on some Valençay? I recommend doing so while watching Bill and Ted’s Excellent Adventure so you can get some Napoleon in while you eat, too. Just don’t let him near your ice cream.\n*I am also going to ignore the fact Napoleon wasn’t a king. He was emperor less than fifty years after the French people tried to kill off all their royalty. In fact, he earns bonus points for bravado.\nculture King Count:\nFirst place: Charlemagne with 5 points (as overseer of all things goat and essentially creating France)\n(Tied for) Second: Charles VI with 2 points (Roquefort and Maroilles); Napoleon Bonaparte (Valençay and serious swagger)\n(Tied for) Third: Philip II, Louis IX, Francis I with 1 point (Maroilles)\nFeature Photo Credit: cheese of valencay in france by Filimages | Shutterstock"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:c464237f-a104-40d5-9bde-5949e7a73385>","<urn:uuid:a014baff-eda7-4573-9eb1-49f5b5ac224c>"],"error":null}
{"question":"What are similarities between Brighton's golf course and Heriot-Watt's marine restoration projects in terms of environmental restoration approaches?","answer":"Both projects demonstrate innovative environmental restoration approaches through public-private partnerships. Brighton's initiative involves rewilding a 19-acre golf course within the South Downs, including reintroducing grazing livestock, while Heriot-Watt's Dornoch Environmental Enhancement Project (DEEP) focuses on restoring native oyster reefs in collaboration with The Glenmorangie Company. Both projects have gained cross-sector support - Brighton's plan received approval from multiple political parties, while DEEP has won multiple awards and inspired other restoration projects. Additionally, both initiatives have allocated specific funding - Brighton dedicated £40,000 for a ranger, while DEEP has generated significant economic value and media coverage worth over £15,000,000 in advertising equivalent.","context":["This investigation is the first in a three-part series looking at how local authorities across England are dealing with the nature crisis.\nThe rewilding movement to date has been driven by private landowners. Old families and new money have transformed their estates, reintroducing lost species and allowing ancient habitats to regenerate.\nBut what’s the story on public land?\nWhile the government has backed the reintroduction of native species, politicians have generally avoided the topic of rewilding. So far, local government has escaped scrutiny, despite owning hundreds of thousands of acres of land across England. These landholdings span everything from inner-city parks to remote moorlands to old industrial estates.\nFor the past six months, Inkcap Journal has been investigating the extent to which local councils in England have embraced the concept of rewilding.\nWe used a combination of interviews and Freedom of Information requests to uncover the plans and intentions of every county council and unitary authority in the country. We wanted to know how councils define rewilding, what they are doing, and what they are spending. This is what we found.\nWhat is rewilding?\nRewilding is a flexible term with no single definition, so we began by asking councils what the word meant to them. While many councils described rewilding as the return to a wilder state, some had a much broader understanding of the term. Many acknowledged that there were various competing interpretations.\nThe following graphic includes every definition provided. Some have been lightly edited for length; the full responses from councils are available to read here.\nA few councils had adopted definitions from external sources, including an academic paper, Rewilding Britain, the dictionary and an article from British Wildlife. Others had composed their own definitions, sometimes explicitly shaped to their local contexts. As Hertfordshire County Council put it: “'Rewilding' in parts of the county will not look the same as 'rewilding' in the Outer Hebrides.”\nIslington Council also referenced the flexibility of the concept:\n“The term rewilding originally referred to large-scale restoration of ecosystems with the aim of minimal human management so that natural processes shape the landscape and its habitats… Recently, however, the term rewilding has made its way into the public domain as a term that is used to describe any kind of wildlife friendly natural habitat creation, for example creating a wildflower meadow in a park or planting a small area of new woodland.”\nThose that provided their own definitions variously referred to “restoring natural processes”, “allowing nature to reclaim a previously managed area” and “protecting natural habitats so that native species can thrive”. Several councils referenced the reintroduction of native species; a few mentioned the return of predators; Harrow was the lone council to bring up wolves (although with no intention of reintroducing them).\nA few places – including the councils for the Isle of Wight, Staffordshire and the East Riding of Yorkshire – drew comparisons with traditional conservation measures to differentiate the hands-off nature of rewilding. Wiltshire Council was the only authority to emphasise the return of nature to a previous historical state.\nA large number of councils referenced reducing mowing regimes when questioned about their rewilding initiatives; some referred to tree-planting schemes. Brent referred to its seven-mile “bee corridor” as “rewilding in action”. While a more stringent definition of rewilding would probably not include such initiatives, it was clear that many councils have adopted the term 'rewilding' to describe a general relaxation in the management of green space.\nThe majority of councils are not rewilding: around three-quarters of councils said that they had no rewilding policies or initiatives, and had no plans to implement any in the future. However, 40 of 148 councils – 27 percent – had embraced rewilding, either as an existing approach or as a potential idea for the future.\nThese plans are summarised in this interactive map – click on the county to read about its actions. (To create a meaningful summary of rewilding actions, we have only included those that clearly go beyond traditional conservation initiatives. You can read the councils' full responses here.)\nSeveral councils already have rewilding projects underway. Here is a list of some of the most advanced projects:\n- Brighton and Hove City Council is rewilding a 19-acre golf course within the South Downs, including the reintroduction of grazing livestock.\n- Coventry City Council is designating council-owned land across the city for rewilding; a post-industrial site in Hawkesbury, adjacent to the canal, will be allowed to colonise naturally.\n- Herefordshire Council has set aside £2m to mitigate phosphate in the River Lugg. One potential strategy is to purchase the adjacent farmland as it comes onto the market and rewild it.\n- Isle of Wight Council plans to offset at least 10 percent of the island’s baseline carbon emissions through a combination of forestry, planting and rewilding.\n- Leicester City Council runs a conservation grazing scheme with longhorn cattle at Aylestone Meadows.\n- North Somerset Council plans to rewild as much of its land as possible, following a public consultation held in 2019-20, which will include allowing natural succession to take place on some grassy areas.\n- Plymouth City Council is leading a project called Green Minds Plymouth, which is trialling different approaches to rewilding, focusing on involving communities and social enterprises: current projects include beaver reintroductions and urban rewilding.\nOther councils said they weren’t currently rewilding but had plans to do so in the future. The fairly large number of councils that fell into this category perhaps reflects the novelty of the idea. Here are some of the places to watch:\n- Doncaster Borough Council is likely to include a review of its management regimes for green spaces to allow them to become wilder, with a report forthcoming.\n- Hampshire County Council is developing an environmental strategy, which will include consideration of rewilding opportunities across the council’s own estate.\n- Kent County Council’s Biodiversity Strategy 2020 notes that a wilding approach to land may be developed, with rewilding possibly contributing towards nature-based solutions.\n- Rotherham Borough Council is currently investigating rewilding as a possible future management method.\n- Walsall Borough Council is currently developing plans to rewild across a number of sites in 2021-22.\nWhile many councils mentioned tree-planting projects and goals to increase canopy cover, only a handful said that they would encourage the natural regeneration of woodland. This included Bradford City Council, which has a target of increasing woodland cover from 12 to 19 percent, including through natural regeneration \"where possible\". Solihull Borough Council reported that it plans to create a new ‘Arden Forest’ through a combination of tree-planting and rewilding-based approaches.\nMost councils referred only to the terrestrial environment, but a few highlighted their intent to naturalise the courses of their rivers. Historically, many rivers have been artificially straightened, and allowing the channel to resume a more naturally wiggling course can benefit wildlife and reduce flood risk. Councils that mentioned this approach included Harrow, Leicester and Enfield.\nEven where councils didn’t have rewilding projects on the go, many confirmed that the concept was part of their general ethos. In particular, councils often pointed to their plans to create Nature Recovery Networks – a vision spearheaded by Natural England and Defra – as an opportunity to trial rewilding-centred conservation.\nWhile most focused on vegetation and wildlife, a few councils also mentioned the impacts that their rewilding efforts would have on people. Greenwich, North Tyneside and Plymouth councils, for instance, focused on the potential for rewilding to reconnect residents with the natural world.\nWiltshire was the only council that mentioned restricting access to areas as they were left to become more wild, in order to improve the habitat for wildlife. And Wirral was alone in openly acknowledging that their rewilding efforts might require some public engagement before they gained acceptance:\n\"Unfortunately much of the Council’s estate is too fertile to support highly floral and colourful wild flowers, which are only stable communities on impoverished and infertile soils. It is thus expected that this change will have a cosmetic and amenity impact on many public green spaces... Reinterpretation will be required to reconsider these tall tussocky sites from being dull to a worthy vegetation, providing important habitat for invertebrates and small mammals.”\nNot all councils are created equal. Some are rural while others are urban; and some own large quantities of land, while others possess relatively little. Since rewilding in its purest form involves landscape-scale restoration, it is worth considering which councils are sitting on the largest landholdings.\nResearch into council land ownership has thrown up some unexpected results. The list of top ten landowning councils includes large, wealthy councils – like Cambridgeshire and Cornwall – alongside smaller areas and city councils, like Wirral, Sefton and Sheffield.\nAs writer and campaigner Guy Shrubsole explains in his blog, Who Owns England, the large parcels of land owned by some councils is the result of historical purchases: Sefton, for instance, appears to have purchased a huge expanse of salt marshes and sand dunes along the coastline in the mid-20th century, while Sheffield owns large areas of moorland thanks to the work of land rights campaigners.\nThe following graph arranges councils by land ownership, with the size of the bubbles representing the area of land in their possession. Hover over the bubbles to see what rewilding actions each council is taking.\nThe type of land owned by each council is also relevant: an area of moorland, for instance, will be more suited to rewilding than a patch of allotments. The Who Owns England blog has a rough estimate of the amount of land in council ownership according to land type, which we’ve visualised in the chart below (there are some important caveats to these figures in the original analysis).\nWhile councils generally focused on the opportunities to rewild their own estates, some looked beyond these boundaries: Shropshire Council, for instance, has not undertaken any interventions on its public land, but is providing assistance to a new landowner who wanted to revert much of their hundred acres to an approach centred on non-intervention or very extensive grazing.\nCouncils with mainly urban estates differed in whether they were willing to embrace rewilding, with their attitudes largely determined by how they defined the term. Some, like Tower Hamlets, dismissed the idea out of hand.\n“Leaving land unmanaged would rapidly lead to an area of dense bramble or buddleia scrub which would eventually revert to woodland, probably of sycamore or Norway maple. Such habitats would be of negligible amenity value and would be far less biodiverse than sites which are carefully managed for nature conservation. Rewilding might be a valid approach where there are large areas of open land, but it is not suitable in Tower Hamlets.”\nOthers took a more flexible approach, perhaps best expressed by the Royal Borough of Windsor and Maidenhead:\n“Rewilding is a term most often used to describe the concept of allowing natural processes to re-establish on a large landscape scale – usually over thousands of hectares. However, there are always opportunities, even on a small scale, to allow nature to thrive in the absence of intensive management such as mowing or grazing.”\nThis diversity of perspective was especially apparent in London. While the majority adopted a similar attitude to Tower Hamlets, there were some – particularly on the outskirts – that recognised the opportunity to create wilder areas in their green spaces. Barking and Dagenham Borough Council, for instance, has partnered with SUGi, an international rewilding organisation, to explore ways to introduce rewilding to its parks.\nOutside of London, some councils have seized the opportunity to rewild formerly industrial areas. This includes Bradford, which maintains some small parcels of land governed by “self-willed nature” where there is no human management at all.\nGiven the dramatic cuts to council funding over the past decade, it is unsurprising that the majority of councils had not set aside any additional money for rewilding projects.\nThere were a couple of notable exceptions: Brighton has allocated £40,000 to employ a ranger for its rewilded golf course, and Doncaster said that it had set aside £300,000 for “capital resources for the purchase of equipment and other materials”, although it wasn’t clear what these were.\nWhile central government funding remains scarce, some councils are hoping that new legislation could lead to future cash. \"We see opportunities coming over the hill with the forthcoming Environment Act and the requirement for mandatory biodiversity net-gain,\" said Ben Devine from Leicester City Council. \"We're definitely starting to think about how rewilding could fit within that requirement, and we're quite excited about that.\"\nSimilarly, Herefordshire Council is using the government's New Homes Bonus to tackle phosphate pollution through rewilding agricultural land alongside rivers; Ben Boswell, the council's head of environment, confirmed that the government's Environmental Land Management Scheme (ELMS) may also provide opportunities to make a financial return from rewilding.\nA few councils were exploring unconventional sources of funding to support their rewilding efforts. Coventry, Warwickshire and Solihull councils, for instance, all operate a biodiversity offsetting scheme, where developers pay to compensate for nature loss. Coventry (although not Warwickshire or Solihull) has said that it plans to use some of the money raised – some £2.5 million in total – for rewilding projects, although the specific amount was “still subject to further planning”.\nCornwall has also pursued unusual funding opportunities: its Back to the Future fund collects donations from businesses and individuals that are then distributed to local projects tackling the climate emergency, which may include rewilding initiatives.\nA couple of councils saw rewilding as an opportunity to reduce spending. According to Wirral council, its budget for grounds expenditure would be “significantly reduced” but added that “the maintenance will be more nuanced and subtle to guide the natural rewilding process.” Somerset council echoed this sentiment: “We are not rewilding to save money – we are doing it to enhance the benefits of our natural environment for our residents and wildlife.”\nAs the recent elections demonstrated, the balance of power is fragile.\nWhen led by private landowners, rewilding has the benefit of stability; guided by the vision and finances of a single person or family, nature has decades – perhaps centuries – to recover. Politics, on the other hand, operates on four-year cycles, which is good for democracy but less helpful for long-term environmental planning. Are these government-led rewilding efforts built on strong foundations, or will they crumble in the winds of change?\nThe answer will depend on the council and the initiative. For many councils, rewilding isn't tied to one project or experiment, but is an ethos running through their long-term strategy documents, which are difficult to roll back even when power changes hands. Existing plans are more likely to be maintained if time and money has already been committed.\nIn any case, so long as rewilding is popular with the public, it is unlikely to be cast aside. Local politicians, unlike private landowners, have a material incentive to ensure that their rewilding plans are well-received: their jobs may literally depend on it.\nNature conservation has cross-party support, and rewilding has powerful allies within the Conservative party. Within local councils, rewilding initiatives have garnered support from both sides of the aisle, perhaps because they tend to be specifically tailored to the locality, with an eye towards the approval of the people who'll use them. Brighton and Hove’s plans to rewild Waterhall golf course, for instance, gained the approval of the Green, Labour and Conservative parties.\nThe government's recent announcement of a legally-binding target to halt the decline of nature is likely to drive further ambition from councils. It is certainly possible that future funding, unlocked through the Environment Bill and ELMS, could unleash newfound enthusiasm for rewilding at the local level.\nIt's important to remember that rewilding plans do not capture the entirety of the work that local authorities are doing to protect biodiversity. Many continue to practise traditional management on their land, creating a more vibrant landscape but without necessarily giving nature free rein.\nIndeed, the fine line between restoration and rewilding means that some councils may be undertaking rewilding-style interventions without categorising them as such. Even so, the decision to use the term 'rewilding' feels significant, suggesting a willingness to embrace nature in its uncultivated state. Many councils, it seems, are ready to do just that.\nWith additional reporting by Coreen Grant.","Description of impactHeriot-Watt University research into critically important biogenic habitats and the ecosystem services they provide continues to shape policy and management objectives in international maritime spatial planning initiatives. This research has led to significant economic and policy impacts by: providing exemplars of marine habitat restoration inspiring international proliferation of similar initiatives; working with nature in a widely publicized novel corporate partnership; shaping government policies and plans to promote sustainable practices through marine management and stimulated the growth of new oyster restoration supply chains for the NE Atlantic from the economically fragile Scottish Highlands.\nNarrativeIn REF 2014 HWU research was shown to be instrumental in global marine spatial planning initiatives, particularly those focused on biogenic habitats, including the designation and management of Marine Protected Areas (MPAs) in Panama, Colombia, Galápagos and Europe. HWU research has since expanded our expertise providing underpinning evidence to support conservation policy implementation and management of protected biogenic reef habitats, and their Ecosystem Services (ES), across North East Atlantic Europe.\nThe Dornoch Environmental Enhancement Project (DEEP: Sanderson, Mair, Harries, Henry and Porter) is a collaboration between HWU, The Glenmorangie Company and the Marine Conservation Society. The business interest is in the mitigation of organic discharges into the adjacent marine environment by exploiting the remediative biofiltration (ES) of oyster reefs which concomitantly increases biodiversity through the provision of oyster reef structure and function. Good environmental stewardship has added brand value. DEEP has pioneered, demonstrated and enhanced restoration of the historically widespread native oyster; demonstrating that restoration can be accomplished across the European Atlantic MPA network. Press coverage measured as ‘Opportunity to See’ has reached 1,000,000 to 865,000,000 people in years 2016 to 2020.\nA research has contributed directly to the development of UK Environment Agency and UK Department of the Environment Fisheries & Rural Affairs agenda 2025, restoring UK coastal marine habitats. The UK Environment Agency stated that they used the approach taken by the HWU partnership in Scotland as inspiration for a new Environment Agency initiative; Restoring Meadow, Marsh and Reef (ReMeMaRe) and in 2019 organised for the first time in the UK a successful international conference on estuarine and coastal habitat restoration: Restoring Estuarine and Coastal Habitats (REACH). This was widely attended including Ministers and Chairs of government bodies. The initiative is now sponsored by the Defra Group which includes JNCC, the Marine Management Organisation, Natural England and Cefas as well as the Crown Estate and Inshore Fisheries Conservation Authorities.\nIt has led to the development of the first UK and Ireland Oyster Restoration manual (now a model for seagrass, saltmarsh and beneficial use of dredged material manuals), the first oyster biosecurity workshop hosted by the Native Oyster Restoration Alliance at HW in January 2019, the development of oyster restoration potential maps for England, and; has culminated in a multi-million bid to Defra and HMT under the 4 year strategic review for additional funds for restoration of not only oysters, but seagrass and saltmarsh too.\nSenior Estuary and Coast Planning Manager at the UK Environment Agency said it \"….proved to be a defining moment for the future of marine environmental protection and recovery in the UK …\", and has, “demonstrated … how practical intervention could actually help to restore habitats that have been lost”, and, “all of this inspired by Heriot-Watt and Dr Sanderson’s work in the Dornoch Firth”.\nFurthermore, the work is cited by an increasing number of community-based restoration projects and SMEs as inspiration and proof of concept:\n•“As a result, we have secured funding from the National Lottery GBP225,000 to establish Scotland’s first community-led native oyster restoration project at Craignish...”, Project Coordinator, Seawilding.\n•“Involved in DEEP…[we]...have created a spin-out company called The Native Oyster & Shellfish Company Ltd.”, NOSCO Ltd.\nThe unique DEEP business collaboration with one of the world’s leading whisky distillers has revolutionised the approach taken to marine conservation and restoration and recognised in multiple awards 1,2,3,4,5, including the Guardian Award for University Business Collaboration. It also provides a marine exemplar of ‘working with nature’ to remediate human impacts. Together, DEEP partners have developed a restoration pathway with global applicability in temperate systems that has helped inspire and inform other marine restoration projects across Europe, not least through the hosting of the Native Oyster Restoration Alliance conference in 2019 (155 participants; 15 countries). The DEEP business collaboration is already bringing about a range of benefits including:\n•The development and increase in oyster reef habitat in the Dornoch Firth\n•Biofiltration by the oyster reef with associated water quality benefits\n•Benefiting the rural economy and the native oyster supply chain, evaluated by an independent Scottish government report as having the potential to create up to 50 FTE jobs and GBP3,000,000 GVA in fragile rural communities\nSanderson has presented the research in partnership with Glenmorangie’s Directors of CSR and Operations, in diverse settings from the local communities and at international events. The science underlying the project has-shaped the whisky industry’s approach to CSR; reaching tens of thousands of members of the public on whisky tours, festivals and open days and generating media coverage worth an advertising equivalent of >GBP15,000,000. The project has inspired stakeholders across many countries, elevating the reputation of partners and forging a new frontier in restoration at the start of the 2021 UN Decade on Ecosystem Restoration.\nSanderson, Mair, Harries, and Porter’s ecosystem services (ES) research has demonstrated the habitat provisioning value of biogenic shellfish habitats for commercial species and has become a key driver of enhanced protection by Scottish Government such that policy and management advice for Scottish Priority Marine Features now delivers enhanced protection from fishing impacts. Furthermore, there is mounting evidence of significant ES value in the carbon stores generated through biogenic habitats (Sanderson, Mair, Harries). As part of the Scottish Government’s objective to lead the world in adopting evidence-based policies to mitigate climate change, Porter and Want’s audit of blue carbon resources for Orkney is the most comprehensive regional audit of blue carbon anywhere in the world. Porter, Woolf, Bell, Johnson, McWhinnie, Kerr and Fernandes subsequently undertook a review of the Orkney State of Environment Assessment where blue carbon, pressures and sensitivity data have been incorporated as a basis for the statutory Orkney Marine Spatial Plan (a regional extension of the Scottish State of Environment Plan).\n1. VIBES Awards 2017 (winner of Hydro Nation Award)\n2. Walpole British Luxury Awards 2017 (winner of ‘Luxury With a Heart’)\n3. RSPB Nature of Scotland Awards 2017 (winner of Corporate Award)\n5. Brave New World Foundation Lighthouse Award 2020\n|1 Jan 2015 → 31 Dec 2020\n|Category of impact"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:a4b3f6a3-3ff6-48b9-83c9-6a027f34f1c6>","<urn:uuid:8fb490fc-bece-4b37-b108-8871d3ff4843>"],"error":null}
{"question":"Does a standard Cessna 172S require more or less rudder control input during landing compared to a tailwheel aircraft?","answer":"A tailwheel aircraft requires more active and precise rudder control during landing compared to a standard Cessna 172S. The tricycle gear configuration of the 172S makes it easier to land and more forgiving of imperfect technique. In contrast, tailwheel aircraft demand constant rudder adjustment and what instructors describe as 'dancing on the rudders,' with pilots needing to make quick rudder inputs rather than holding prolonged deflections to maintain directional control.","context":["Tailwheel aircraft aren’t as forgiving of bad technique as nosewheel airplanes, causing trouble during transition training for pilots with sloppy footwork. Instructors who specialize in tailwheel transition training tell of the stick-and-rudder weaknesses they see in pilots—and offer advice that can help.\nPoor rudder work is the biggest problem pilots must overcome during transition training, said Marianne Buckley, who owns Buckley Aviation and provides flight instruction, including tailwheel transitions and aerobatics in a Citabria, at Potomac Airfield near Washington, D.C.\n“People tend to be reactive,” Buckley said. “They wait until something happens before they do anything. The feet are very lazy and stiff. What I tell my students is to just dance on the rudders.”\nRon Rapp, a Gulfstream pilot and aerobatic and tailwheel instructor with 5g Aviation at John Wayne Airport-Orange County in Santa Ana, Calif., agrees that improper rudder use and failing to stay ahead of the aircraft are common problems that lead to lack of directional control.\nPilots have “trouble keeping the plane traveling in the same direction it’s pointed” during landings, Rapp said, which indicates an awareness problem.\nIn tricycle gear aircraft, the airplane’s center of gravity is located in front of the main landing gear, making the aircraft want to straighten out on its own if its longitudinal axis is slightly misaligned from the direction of travel during touchdown. That’s not the case with a tailwheel aircraft in which the center of gravity is located behind the main gear. Failing to touch down with the airplane’s longitudinal axis aligned with its direction of travel can cause ground loops.\nImproper alignment also can cause a pilot to think incorrectly that he or she is experiencing a crosswind. “Many tailwheel students either don’t see drift or don’t understand why it’s happening,” Rapp said. They may notice the aircraft drifting to one side of the runway, and apply crosswind correction inputs, but “in reality, it’s because the nose of the airplane isn’t straight,” Rapp said. One thing that compounds the lack of awareness is control confusion. Rapp said he sees this when he simulates a wind gust during the student’s flare. “Often, I’ll stab at the rudder, the nose will yaw, and I’ll see them lower a wing in response.”\nWhen the nose yaws, correct with rudder; when a wind gust lifts a wing, correct with aileron. Bottom line, keep the airplane “pointed in the same direction it’s traveling,” he said.\nCross controlling is another problem Buckley said she sees “more and more.” “They tend to put a lot of left rudder and right aileron,” she explained, adding that in the air, a tailwheel airplane like the Citabria she teaches in flies like any nosewheel airplane. Those who fly with proper coordination in the air in their tricycle gear aircraft should also fly coordinated in a taildragger.\nAnother common problem that Rapp notices in transition students is that they are often reluctant to use full-scale rudder deflection, he said. “Another big misconception about tailwheels is that if you use too much rudder, you’ll groundloop the plane. False. The problem isn’t too much rudder, it’s using the rudder for too long.\n“If full rudder is required, I have no problem using it, but you’d never see me hold it in there. It’d be a quick jab to stop a swerve and then dancing all over the pedals as necessary to get it heading back toward the centerline.”\nWhether you fly tricycle gear or tailwheel aircraft, give these pieces of advice a try and improve your technique. Put on some dancing shoes.","Cessna 172 (10 Things You Need to Know)\nAsk a pilot to name a common single-engine fixed-wing aircraft, especially one that is good to learn on, and the Cessna 172 will quickly rise to the top of the list. From the original first flight in 1955 to its latest model still in production today, the Cessna 172 has been a reliable, dependable, easy-to-fly aircraft that is appreciated by students and seasoned pilots alike.\nIn this post we will explore the Cessna 172 and share ten things you need to know plus answers to the most frequently asked questions about this storied aircraft.\nBefore we delve into the things you need to know about the Cessna 172, let’s start with the basic specifications. Although there are many variations of the 172, we will share the specs for the current production model – the 172S.\nCessna 172S Specifications\n- Maximum occupants: 4\n- Maximum speed: 126 knots\n- Cruising speed: 124 knots (75% power, at 8000 feet)\n- Fuel capacity: 56 gallons\n- Maximum Range: 640 nm\n- Engine: Lycoming IO-360-L2A, 180 hp\n- Propeller: McCauley 2 blade metal, fixed pitch\n- Service ceiling: 14,000 feet\n- Maximum rate of climb: 730 fpm\n- Takeoff distance: 960 feet (ground roll), 1630 feet (total over 50-foot obstacle)\n- Landing distance: 575 feet (ground roll), 1335 feet (total over 50-foot obstacle)\n- Stall speed: 48 KCAS\n- Maximum ramp weight: 2558 pounds\n- Maximum takeoff weight: 2550 pounds\n- Maximum landing weight: 2550 pounds\n- Basic empty weight: 1680 pounds\n- Maximum useful load: 878 pounds\n- Baggage capacity: 120 pounds\n- Length: 27 feet 2 inches\n- Height: 8 feet 11 inches\n- Wingspan: 36 feet 1 inch\n- Wing area: 174 square feet\nNow that you know what to expect from the current Cessna 172 model, let’s take a look at the 172’s history and discover 10 must-know pieces of information about this aircraft.\n1. The Cessna 172 is the most-produced aircraft ever\nSince production began in 1956, over 43,000 Cessna 172s have been built with more still on the way. This legendary aircraft is well-loved, well-respected and still in demand more than sixty years after it first came on the market.\n2. There have been over 20 variations of the Cessna 172 (plus some special versions)\nOver the course of its long life, the Cessna 172 has naturally undergone a series of modifications, upgrades and enhancements while remaining true to the heart of her original solid design.\nAmong the most notable are the 172B which introduced the Skyhawk name, the 172D with its Omni-Vision rear wraparound window, and the 172S which incorporated Garmin G1000.\n3. Not all Cessna 172s were built in America\nIt is known as an American aircraft, but you may be surprised to learn that 1,436 Cessna 172s were actually built in France. From 1965-1971, Reims Cessna constructed the Cessna 172F. This model replaced a lever-operated flap system with electric flaps. It was also the basis for the U.S. Air Force’s T-41A Mescalero – a primary trainer.\n4. The “Skyhawk” name originally referred to a deluxe option package\nAlthough you may be used to hearing the name “Cessna Skyhawk,” originally, the Cessna 172 was called just that – the Cessna 172. It had no fancy name. The name Skyhawk came about in 1960 with the release of the 172B. This model had the option for a standard package or a deluxe option package – named the Skyhawk – with extra equipment and full exterior paint. Eventually the name stuck and came to refer to the entire Cessna 172 line-up.\n5. The 172’s tricycle landing gear design helps you ace your landings\nOne of the key design features of the 172 lineup has always been the tricycle landing gear design. This design was tested out on the WWII B-24, B-25 and B-26 bombers. The combination of a nosewheel in the front and moving the main wheels aft was found to make a tricycle landing gear aircraft easier to land.\nIn this configuration, the center of gravity (COG) is in front of the main wheels. What this means to you is that when you land in a tricycle gear aircraft, if you are crooked, the airplane’s weight will help to straighten you out. By contrast, a conventional landing gear setup has a center of gravity that is aft of the main wheels. Land crooked in this type of aircraft, and your mistake will just get exacerbated by the influence of the aircraft’s weight.\n6. Cessna 172s are used as trainer aircraft for many flight schools\nIf you have a private pilot’s license, odds are that you trained on a 172 at some point. Flight schools love this aircraft for several reasons. The ease of flying a tricycle landing gear configuration is a main selling point as are the forgiving handling characteristics and increased visibility of the high wing design plus rear “Omni-Vision” window.\nIn fact, the 172 is so stable that its built-in aerodynamic stability can often return a plane to straight and level flight after a spin even without input from the pilot.\n7. The world record for the longest endurance flight is held by a Cessna 172\nImagine what it would be like for a small aircraft to fly non-stop for over 64 days. Bob Timm and John Cook did just that from December of 1958 to February of 1959. Their 64-day, 22-hour, 19-minute flight out of Las Vegas still holds the endurance record.\nTimm and Cook flew a modified Cessna 172 which was named The Hacienda after the Hacienda Hotel who sponsored the $100,000 flight as a combined publicity stunt and fundraiser for cancer research.\nTo prepare for the flight, the team added a 95-gallon belly fuel tank to augment the 47 gallons carried in the wing tanks. An electric pump in the belly tank allowed fuel to be pumped into the wing tanks for refueling. Oil lines were replumbed to allow inflight oil and oil filter changes. In the cabin, the pilot seat stayed, but everything else was removed and a 4’x4’x4” foam pad was added as a bed for the off-duty pilot. An added platform off the co-pilot side allowed for better footing during refueling. A small sink in the rear was used for washing and shaving.\nAn FAA waiver allowed the overweight aircraft to operate at 350-400 pounds over the normal limit. Twice a day the Hacienda would rendezvous with a Ford truck over a straight stretch of closed off highway. Flying 20 feet above the ground, the Hacienda used an electric winch to hook a refueling hose from the truck. Three minutes later with its belly tank full, the Hacienda would release the hose and continue her flight.\nThe next time you pass through the Las Vegas McCarren Airport’s baggage claim area, look up – the Hacienda is hanging from the ceiling at the airport where her historic flight began and ended.\n8. There was (briefly) a diesel-powered Skyhawk on the market\nGiven the lower cost of Jet A and its more readily accessible nature overseas, Cessna decided to release a diesel version of the Skyhawk in 2017. The Turbo Skyhawk JT-A came powered by a Continental CD-155 diesel engine and received high marks in fuel efficiency and power.\nUnfortunately, the diesel engine also resulted in a higher purchase price ($420,000 compared to $307,000 for the 172S) and reduced payload capacity because of the added weight. Just 11 months after receiving FAA certification, the JT-A was discontinued due to poor sales.\n9. The triangle gear Skyhawk almost didn’t happen\nRumor has it that when a group of Cessna engineers approached the Cessna marketing department with their idea for a triangle gear aircraft, they were shot down. Marketing wanted to focus on tailwheel aircraft. Thankfully for Cessna and for all of us, the engineers were undaunted, and they continued work to build out the first concept version of the tricycle-geared Cessna 172 that we all know and love. Ultimately it met with approval and went into production.\n10. The Cessna 172 can be powered electrically (at least as a proof-of-concept)\nElectric Skyhawks may be in our future. In 2012, Cessna and Beyond Aviation worked together to develop an electrically powered variation of the Cessna 172. The aircraft took multiple successful test flights powered by the Panacis batteries that take the place of the back seats. One of the big advantages of an electric aircraft would be imperviousness to density altitude changes.\nBonus: Answers to Frequently Asked Questions\nFinally, we have rounded up the answers to some of the most frequently asked Cessna 172 questions.\n1. How safe is the Cessna 172 compared to other aircraft?\nThe 172 has an impressive safety record, especially when compared to the industry average. Statistically, the Cessna 172’s fatal accident rate is .56 per 100,000 hours. This is about half of the industry average rate of 1.2-1.4.\n2. How much does it cost to own and operate a Cessna 172?\nCost is an important consideration for most pilots when they are contemplating the purchase of an aircraft. Beyond the purchase price, you must also account for operational costs, storage, insurance, maintenance and more. AOPA crunched the numbers for you and put together a hypothetical operating cost calculation for a Cessna Skyhawk\nThis particular calculation was based on a 1975 Cessna 172M with a purchase price of $39,000. For comparison, the purchase price of a new Cessna 172S is around $307,000.\nLoan payments in the AOPA scenario were calculated at $290 for a $35,000 loan over 20 years at 7.9%. AOPA insurance payments came to $1200 a year, and hangar space rental was $250 a month, which equates to $3000 a year.\nYearly maintenance was estimated to be $2500 or $25/hr. for flying 100 hours or $4000 ($13.34/hr.) over 300 yearly hours.\nThe final factor to consider is any kind of projects you want to do, especially to an older aircraft.\nThe final AOPA estimate comes out to $108.10 per hour if flying 300 hours a year or $225.30/hr. for 100 flight hours.\nThe total annual cost is around $22,530 for 100 yearly hours of flight and $32,430 for 300 hours.\nThat said, keep in mind that you can save money by opting for tie-downs rather than hangars, and hangar costs vary by location. The amount you owe on your aircraft loan (should you need to take one out) is also an important variable component of this calculation.\n3. What kind of engine does the 172 have?\nThe original 1955 Cessna 172 was powered by a Continental O-300 145 hp engine. In 1968, the 172I debuted the Lycoming O-320-E2D 150 hp engine. Previous engines had used 80/87 fuel, but the 1977 Skyhawk N (172N) tried out a Lycoming O-320-H2AD 160 hp engine running on 100-octane. The performance wasn’t favorable, so starting in 1981, the 172P switched to the Lycoming O-320-D2J.\nFactory-fitted fuel-injected engines arrived with the 1996 172R’s Lycoming 160 hp Lycoming IO-360-L2A. The current 172S model was introduced in 1998 with an upgraded 180 hp Lycoming IO-360-L2A.\n4. When will Cessna release a new model of the 172?\nCessna has been exploring both diesel and electric options, but for now, the 172S is the only Skyhawk on the market.\nThe Cessna 172 is a classic plane with a long and storied history. Dig into its past and you will find a series of well-loved, reliable, safe aircraft that are easy and enjoyable to fly. Memorize some of our top 10 facts and soon you will soon be more well-versed on the 172 than your fellow pilot friends.\nPilotMall.com offers a full selection of Cessna Aircraft Manuals.\n- PilotMall.com Editor"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:d4f79299-91c4-4f75-9705-593fd2dc45fe>","<urn:uuid:f1d36dc0-b956-47fa-a147-896672743de1>"],"error":null}
{"question":"How does climate change affect coffee production quality, and what roasting techniques can optimize beans from affected regions?","answer":"Climate change is significantly disrupting both Arabica and Robusta coffee production. By 2050, some regions like Kenya will see their coffee-growing suitability drop from 70% to 45% due to temperature increases and changing rainfall patterns. These changes will force optimal coffee zones 1,000 metres higher than today. To optimize roasting affected beans, roasters must consider factors like bean density and moisture content. For higher-altitude, denser beans (which are becoming more common as production moves upward), a higher initial charge temperature can be used. The roasting process should be carefully monitored through key stages including charge temperature, turning point, and first crack, adjusting variables like temperature and airflow to preserve quality. Moisture content should be maintained between 10-12% to avoid quality loss and mold growth.","context":["What’s in a cup of coffee?\nWhatever the weather, a steaming cup of coffee puts the spark back in our day. For a guilt-free brew, we have all heard of fair trade coffee – which helps secure the rights of coffee workers. But what is the coffee industry doing to combat global warming and how might our daily shot of caffeine be affected by future changes in world climate?\nThe International Trade Centre recently published a paper on the effects of climate change on the coffee industry (and vice-versa). Both coffee quality and yield are expected to be impacted by predicted changes in climate.\nSmallholder producers of coffee are already experiencing the effects of climate change in the form of abnormal rain patterns and an increased frequency of severe weather, but lack the resources to overcome them.\nIn one scenario, by the year 2050, Kenya is expected to have less seasonality in its climate. The mean low and high temperature is predicted to increase by over two degrees Celsius. More rainfall is predicted although its distribution may not be favourable for coffee growing.\nThese changes will shift optimal coffee producing zones 1,000 metres higher than they are today. Changes in rainfall may require coffee to be grown under irrigation in future. Drying of the coffee bean skins may also be affected.\nCurrent suitability of the region for coffee production is as high as 70 per cent but by 2050, Kenya’s suitability for growing coffee beans is predicted to drop to around 45 per cent or lower.\nResearchers are unable to make absolutely precise forecasts about how producer regions and global output will be affected but the general forecast is that climate change will significantly disrupt Arabica and Robusta coffee production in all regions.\nSuperior Arabica coffee beans grown at higher altitudes are delicate, require sunny but cool subtropical climates, lots of moisture, and rich soil. Robusta coffee, grown at lower levels, is generally thought to be the ‘cheaper’ coffee although a quality Robusta is often the secret behind a creamier Italian espresso.\nRising temperatures are expected to render some producing areas unsuitable for coffee cultivation. This would concentrate coffee production in areas where it is still possible but make the output risk more volatile in case of crop failure for other reasons such as pests and plant disease.\nCoffee grew naturally under the leafy canopy of native rainforest trees until monoculture systems were introduced in the 1970s. This led to forest clearing exposing the trees to more sun, and higher yields followed planting of dense rows of coffee bushes doused with agrochemicals.\nForested coffee farms are slowly coming back as certification from the Rainforest Alliance and other bodies helps farmers manage their plantations more sustainably.\nBut many of the mitigation initiatives are small-scale and need to be adopted by the coffee industry as a whole.\nDifferent coffee cultivation systems, such as forest coffee, smallholder plots and commercial plantations, have different levels of greenhouse gas emissions.\nThe advice in the ITC report is that coffee farms have the potential to ‘sequester’ or trap carbon from the atmosphere. Tree cover can be increased through planting of more shade trees or extending total forest cover on farms. Farmers could even be compensated for these initiatives if they generate marketable carbon credits.\nIntercropping, or planting around coffee bushes with plants which absorb greenhouse gases, planting of more shade trees and rehabilitation of degraded lands and hillsides can all count toward carbon credits.\nCertain roasters in consumer countries have launched initiatives to reduce the carbon footprint of a cup of coffee as part of their marketing strategies. Some are even offering zero carbon footprint coffee largely achieved by purchasing carbon offsets.\nThis means that the greenhouse gases emitted during coffee production are offset by investing in carbon emission reduction or sequestration activities elsewhere. It may also be the case that this is done outside the coffee production chain, in other areas of enterprise.\nThe report also warns that the coffee industry must increasingly contribute to control the effect of greenhouse gas emissions and urgently prepare for further adverse changes in the climate.\nProducer organisations must be strengthened before smallholder farmers can have better access to the potential benefits offered by the carbon markets.\nIn Kenya, smallholder coffee growers have used the Cool Farm Tool greenhouse gas calculator for farmers to help them measure the carbon footprint.\nCoffee plantations have been urged to reduce their use of synthetic fertiliser – a big source of nitrous oxide – by maintaining good soil structure.\nIn the journal Nature Geoscience it was reported earlier this year that nitrous oxide traps heat at a different wavelength than carbon dioxide, closing a ‘window’ that allows the Earth to cool off independently of CO2 levels.\nChemists found a ‘fingerprint’ in isotope data, proving that increased fertiliser use over the past 50 years is responsible for a dramatic rise in this major greenhouse gas contributing to global climate change. Nitrous oxide has 300 times the effect of carbon dioxide.\nThere are various small things we can choose to do as individuals toward reducing the carbon footprint of our espresso or capuccino.\nCapsule coffees have a very high carbon footprint due to the emissions involved in the production of the metal capsules. The type and efficiency of the coffee brewing machine also affects the product carbon footprint (PCF). Serving it in a paper cup can easily triple the carbon footprint of your coffee.\nwww.get-neutral.com (select English version)","What affects coffee during roasting\nControlling variables during roasting process\nCoffee roasting includes adjusting many variables to create your perfect roast profile. By changing factors including temperature, length of roast, and airflow, you can highlight sweetness, emphasize acidity, or create a well-balanced roast. also drum speed, you can affect the amount of time that coffee beans are exposed to direct heat.Now you can change all those variable, Should you roast a Colombian Nariño the same way you would an Ethiopian Sidamo? Probably not.Producing countries have different climates, soil types, altitudes, density, moisture, – and all that leads to very different coffees. The beans will react differently to heat, plus you will want to accentuate specific characteristics. In other words, you need to roast them differently.So before you create a profile and put your coffee in the roaster, you need as much information as possible about the beans. And today, I’m going to take you through some of the main origin-based variables to consider. At each stage of the coffee supply chain, the moisture content of a green bean must diminish – or the bean might become moldy, defective, and less valuable than before. Ensuring a bean dries correctly is essential in order to optimize its quality potential and minimize the chance of problems.Roasters, near the end of the supply chain, have two tasks when it comes to managing moisture content. On the one hand, they must maintain the lots they store onsite within a narrow moisture range that is acceptable to their quality standards.\nOn the other hand, and in the span of a few minutes, the roaster is responsible for driving the last remaining bits of moisture out of the bean via the application of intense heat and pressure. In these minutes, the coffee is exposed to the most energy it will experience at any point in the coffee supply chain and the roast is set up for either success or failure.It’s easy to see why roasters should care about the moisture content of their coffee. But how useful is a number supplied by an importer, and how can roasters integrate moisture content readings into their craft? I spoke with Fred Seeber of Shore Measuring Systems, a supplier of moisture content meters, about measuring and making sense of moisture content in green coffee.\nThere is no official standard for ideal moisture content in green coffee, although the ICO recommends 11% as a good target. However, it’s commonly accepted that 10-12% is a reasonable range. Anything less than 10% is likely to result in loss of cup quality, while humidity at higher levels begins to create a risk of mold growth. Yet a coffee’s humidity is not static. While the pre-export drying process drastically increases a bean’s stability, changes in moisture content are still possible. Environmental factors, such as being in a particularly humid or hot location, are a common cause of this. Before getting into the technical details of measuring moisture content, it’s worth digging a little deeper into why it’s worth measuring moisture content. Knowing this will help you establish protocols suited to your specific needs.\nFor roasters of a certain scale, it’s simple: you pay for coffee by weight; the more water in that coffee, the more you’ve paid for water which you’re going to burn off anyway. common situation roasters find themselves in: “So, [an importer] sends you a sample, and… it’s showing 11.5% moisture in that sample. Then when your container shows up, that’s 40,000 pounds, and all of the sudden you discover it could be 13% moisture. Well, you just got blanked for two percentage points of water of a commodity that’s four bucks a pound… that’s [a lot] of money.” For the smaller, quality-focused roaster, those kinds of calculations may or may not be relevant. But moisture content still plays an indirect role in a roaster’s costs, regardless of whether or not they’re buying a few containers or a few bags.\nThere is no direct link between a coffee’s quality and its moisture content. A 10% humidity coffee is not necessarily better or worse than a 12% coffee. However, over time, green coffee will gradually lose vibrance. This will eventually result in the dreaded “past crop” flavor, and this process is associated with the drying out of the coffee. Therefore, even for a small roaster, it’s important to keep track of moisture content. If you paid for an 85-point coffee at 12% moisture, by the time it reaches 10% moisture it may be more like an 83-point coffee. Yet, you still paid 85-point prices for it originally.\nBy comparing moisture content loss with quality degradation over time, you can make smart buying and consumption decisions with your green lots. And, when combined with water activity measurements, you can even predict the shelf life of your green coffee. Again, precision here is key: you want to track your coffee through a narrow range of percentage points over a long time frame. Lastly, you may think to yourself that you don’t need to measure moisture content yourself, since your importer supplies those numbers already. Fred cautions against this thinking. He points out that coffee is shipped on water and that ports can often be warm and humid, which will affect moisture readings. So, if you’re a roaster in a dry part of the United States but your importer is located in New Orleans or Houston, and is taking moisture readings from lots right as they arrive, those numbers might not be applicable to you by the time your coffee arrives at your facility. Elevation, or altitude, is of immense importance for coffee roasting – but what we’re really talking about is density. When coffee is grown at cooler temperatures (which, most of the time, means higher elevation), the cherries ripen slower and so develop more sugars. This leads to more complex sweetness, but also to harder, denser beans. When you have beans of different densities, they also react differently to the heat. Soft, low-density beans tend to have more air pockets inside them, which can slow down heat transference. To avoid scorching the outsides of the beans, you should use a lower initial charge temperature. We also recommends extending the length of the roast for these coffees. Knowing what altitude your coffee is grown at, how far it is from the equator, and the temperature on the farm will help you to anticipate the density. When roasting, it’s important to consider not just the structure of the bean, but also the flavor of it. And this can vary greatly. “We will never have an Ethiopian with the same type of acidity like that Kenya AA Kamwangi we once had,” Tom tells me, “and it will be very difficult to find a Colombia with the stone fruit, tea-like flavors of the Yirgacheffe coffees.”\nyou can expect well-balanced coffees from the Americas, with more chocolate and hazelnut notes appearing in Brazil. In East Africa, coffees tend to be clean, juicy, and fruity. Some regions lean more towards sweetness (like Burundi), while others are more acidic (like Kenya). Indonesia is often known for its heavy body and earthy tones. Yet there are so many flavor variations within one region, as a result of micro climates, terroir, varieties, production and processing methods, and more. Sulawesi, Indonesia is famous for its spice notes, while Bali has a more citric profile. A Panamanian Geisha will taste different from a Panamanian Bourbon. Brazil is so large, you can fit much of Europe in it – and it has a wide variety of profiles to match. And as Tom points out, some countries have multiple harvest seasons. it’s the roaster’s job to preserve what makes an origin special and “let the coffee speak”. Knowing the profile of the coffee origin will help you anticipate which flavors will be most prominent – and how you can emphasize them. roast graph data into two types of curves: control curves and reading curves. Control curves are variables that you directly control during the roast, such as the heat settings, airflow, and gas flow. Reading curves are temperature readings. Since the variables are constantly changing, they are recorded as line graphs.\nBut what reading curves do you need to know? the key ones are bean temperature, air/environment temperature, and rate of rise curves – although you can also measure bean color, air, and gas pressure for even greater insights. Denser, higher-altitude coffees are associated with greater acidity, and you’ll often hear this described in terms of fruit notes – mandarin, grapefruit, plum, blueberry, and so on. This is a highly prized trait, and if you’re roasting a coffee that has this quality, you may want to accentuate it. (Bear in mind, however, that while acidity can be good, underdeveloped and sour notes are not. There is a fine line.) the more acidity and fruitiness you will throw away. A faster Rate of Rise (RoR) is also recommended by many roasters for emphasizing acidity. On the other hand, if you want more sweetness – say you have a natural Bourbon from Burundi – then Willem Boot, CEO of Boot Coffee, recommends opting for a lower RoR. Sweet Maria’s also experimented with stretching out the drying phase of the roast, and found that it could highlight this quality. as for body, stretching out first crack could open up a more syrupy mouthfeel in a coffee. It’s important to remember that the qualities you want to highlight will all depend on the coffee itself, and its unique, overall profile. Roasting is a complex skill; there are no simple rules. These guidelines are just starting points for creating your roast profiles. Knowing the altitude, temperature, terroir, and origin profile is a great start to creating a roast profile for a coffee. “It’s about a commitment to get to know the origin and bring the best to the surface,”\nBut it’s only a start.\nBean temperature(the blue line)\nThe bean temperature curve will look a bit like a check mark; once it starts going up (something called the turning point – more on that to come!) it should always continue going up. If not, you risk stalling your coffee and developing bread-like, doughy flavours\nROR(other blue line which is vice vers)\nThe rate of rise curve is linked to bean temperature, but there’s a subtle difference: it measures the rate at which bean temperature changes. This will give you far earlier indications of temperature changes and, in turn, allow you more control over the roast. It has a very different shape to the bean temperature curve, rising sharply from zero shortly after the turning point.\nAir temperature(RED line)\nAir temperature is variable measures the environment inside the drum. It’s useful to know because much of the heat transfer in coffee roasting is via air. This line will follow a similar shape to the bean temperature curve.\nKey Stages on Your Roast Graph\nNow we know what the roast graph measures, you can start reading and interpreting these lines. To do so, you want to pay attention to several key points on the graph: charge temp, turning point, first crack, and end temp.\nThis is the temperature of your drum just before you add the coffee. By manipulating this, you can speed up or slow down the rate of rise and, in turn, choose how much acidity to accentuate. You should also pay attention to bean density and processing method when selecting this.\nAs you add the cold beans to the roaster, the heat inside the machine will dramatically fall before starting to rise again. The point at which it begins to rise is called turning point.\nOne of coffee roasting most famous moments is first crack. First crack signals that the beans are almost ready. As the beans expand and moisture evaporates, steam develops inside the beans. This steam then forms pressure that cracks the beans open.\nFirst crack it’s a moment that has been given almost mythical status in coffee roasting – and it deserves it. A key stage in any roast, understanding it will give you insight into how flavors and aromas are developing.\nAs the name suggests, this is the temperature at the end of your roast.\nBy understanding what’s going on inside the roaster at these key points, you’ll be able to start evaluating the impact of them on your beans. For example, by manipulating charge temp you can speed up or slow down your roast. The duration of first crack can affect body. Roasting graphs may, at first, be challenging. There’s a lot of data to collect and understand. However, as you start to work with air temperature, rate of rise, first crack, and more, you will begin to gain real mastery over how your coffee beans develop during roasting. So don’t be intimidated by these charts – start recording those temperatures and see how it helps you as a roaster. As heat is applied to the coffee beans, they go through endothermic and exothermic reactions. Up until first crack, the beans absorb the heat (an endothermic reaction). The moisture dissipates and the color changes from green to yellow and then brown. The aroma will be cereal-like: think toast, popcorn, or grass. As for first crack, this is a brief exothermic reaction: the beans release heat (energy) in the form of that steam we mentioned above, along with carbon dioxide. The bean will have doubled in size and shed the majority of their silver skin, but oils won’t yet be present. After first crack, it switches back to an endothermic reaction until second crack, the final exothermic reaction (if you choose to roast your beans that far)."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:2717a771-3f2e-4fdb-a468-947d8cb34a7d>","<urn:uuid:7823bc81-5b4b-4fbd-964d-bca4d098a9dd>"],"error":null}
{"question":"How do the safety considerations and control measures compare between medical radiation protection for breast cancer patients and public radiation protection in existing exposure situations?","answer":"Medical radiation protection for breast cancer patients focuses on delivering effective treatment doses while managing specific side effects like skin changes and breast discomfort, with regular weekly monitoring by radiation oncologists and careful skin care protocols. In contrast, public radiation protection in existing exposure situations, such as exposure to natural background radiation or residual radioactive material after emergencies, requires different control measures based on multiple factors including the range of doses received, size of population exposed, and social and economic factors. Sometimes, in existing exposure situations, the exposure may not even be amenable to control, unlike the highly controlled medical setting where specific protocols and safety measures are consistently applied.","context":["Radiation protection, sometimes referred to as radiological protection, is a general term applied to the protection of people and the environment from the harmful effects of ionizing radiation. Radiation protection can be divided into occupational radiation protection , which is the protection of workers in situations where their exposure is directly related to or required by their work; medical radiation protection, which is the protection of patients exposed to radiation as part of their diagnosis or treatment; and public radiation protection, which is the protection of individual members of the public and of the population in general.\nIn all situations involving exposure to radiation, an appropriate level of radiation protection needs to be applied using a graded approach i.e. the level of control applied must be commensurate with the associated risk or risks. In the IAEA Safety Standards, exposure to radiation is defined in terms of:\nA planned exposure situation arises from the planned operation of a source or from a planned activity that results in an exposure from a source. The primary means of controlling exposure in planned exposure situations is by good design of installations, equipment and operating procedures. Those exposed can include workers, patients and the public. In the case of workers and the public, dose limits are set and must be complied with in order to ensure there is an adequate level of radiation protection. This differs from medical radiation protection, where the prime consideration in determining the dose that needs to be delivered is the need to ensure that diagnosis and treatment are effective.\nAn emergency exposure situation arises as a result of an accident, a malicious act, or any other unexpected event, and requires prompt action in order to avoid or reduce adverse consequences. Exposures can be to the public and to workers, such as those who may be exposed while taking actions to respond to the emergency.\nAn existing exposure situation is a situation of exposure which already exists when a decision on the need for control needs to be taken. Examples of an existing exposure situation are exposure to natural background radiation and exposure to residual radioactive material from a nuclear or radiological emergency after the emergency exposure situation has been declared ended. When considering the need for control, factors to be taken into account include the range of doses received and the size of the population exposed. Social and economic factors also need to be taken into account and, in some cases, the exposure may not be amenable to control.\nRegulatory control restricts the release of radionuclides to and their accumulation in the environment. There is an increasing awareness of the vulnerability of the environment and society places greater emphasis than in the past on environmental protection. It is therefore important to be able to explicitly demonstrate that flora and fauna are appropriately protected against radiation risks arising from discharges of radionuclides into the environment. Whereas radiation protection of humans aims to avoid deterministic and to limit stochastic effects for individuals, radiation protection of the environment is focused on the conservation of species, the maintenance of biodiversity and the protection of habitats and ecosystems. The methods and criteria for these radiological assessments are being developed and will continue to evolve.\nFor further information please contact","Radiation Therapy for Breast Cancer\nWhat Is Radiation Therapy?\nRadiation therapy is the use of high-energy rays or particles to treat disease. It works by killing tumor cells or inhibiting their growth and division.\nThrough years of clinical trials, radiation oncologists have studied the use of radiation therapy to treat breast cancer. These studies have led to the widespread use of effective and tolerable doses of radiation therapy. It is used to treat early stage breast cancer along with surgery for local control of disease. It may be used in more advanced breast cancer to control the disease or to treat symptoms, such as pain.\nWhere Do I Start?\nYou first will meet with a radiation oncologist to decide if radiation therapy is a recommended treatment option for your particular situation. If you and your doctors decide to proceed, then you will have an extended consultation in which you discuss the details of your treatment. This includes the exact area to treat, the amount of radiation you will receive, the length of treatment time and potential treatment side effects. The radiation oncologist will also answer any questions you may have. These issues vary for each person, so it is important to make an individual treatment plan.\nHow Do I Prepare for My Treatments?\nBefore your first radiation treatment, you will have a simulation appointment. This appointment will last approximately one to two hours. During this appointment, the doctor will identify the exact fields on your body to treat with radiation. This involves lying on a table while the radiation therapist marks the field with small dots made with permanent ink. Each dot is similar to a very small tattoo. You will not receive any radiation treatment during this appointment.\nWhat Can I Expect from My Treatment?\nWhen you arrive, please check in at the desk. Each treatment should only last 10 to 15 minutes. You can change your clothes in the dressing room and then wait in the lounge to be called.\nDuring each treatment session, you will lay on a table while the technician uses the marks on your skin to locate and treat the field. It is important to be still while getting the radiation, although you should continue to breathe normally.\nWhat Are the Physical Side Effects?\nReceiving the radiation will not be painful. Side effects vary from person to person and depend on the site being treated. The most common side effects in the treatment of breast cancer are:\n- Skin changes\n- Uncomfortable sensations in the treated breast\nPlease talk to your doctor or nurse if you have concerns about side effects before you begin treatment or if you have questions about managing your side effects during treatment.\nHow Often Will I See My Radiation Oncologist During Treatment?\nYou will meet with your radiation oncologist once a week during your treatments. Should you have additional questions or concerns, simply ask to speak with your doctor again.\nWhat Emotional Responses Might I Expect?\nYou may or may not experience anxiety or fear when you begin your treatment. Most people tell us that their concerns lessen as they adapt to the new environment and treatment.\nPlease speak to the staff if you feel that you need either emotional or practical support. There is a social worker on staff in the Radiation Oncology department. This may be a time when you think again about support groups or one-to-one consultation for the feelings that arise or to support your coping. For information about support services, please call the Breast Care Center at (415) 353-7070.\nSkin Care Tips\nSeveral weeks after your first treatment, your skin in the treatment area may appear reddened or darkened, itchy or irritated. This reaction is similar to that which often results from sun exposure. It may develop in your case and is to be expected. This reaction will improve gradually after your therapy has been completed. Listed below are several suggestions you can do now to decrease this irritation and increase your comfort.\nYou may bathe or shower and shampoo as usual. Do not scrub the skin in the treatment area. Gently towel dry.\nIf the skin is dry and itchy, your radiation oncologist will discuss the best cream for your care. Apply the recommended cream two to three times a day. Do not apply this ointment prior to your radiation treatment.\nPlease report and discuss skin changes or problems with the doctor, nurse or technologists. To minimize problems, the following recommendations are advised:\n- Do not expose the treatment areas to sunlight.\n- Do not use any creams or lotions other than prescribed ointments.\n- Do not use deodorants, alcohol, perfumes, iodine, methiolate or other irritating lotions or creams.\n- Do not apply heat – neither hot baths nor hot water bottles.\n- Do not use cold, such as ice bags.\n- Do not scratch.\n- Do not use a razor in the treated area.\n- Prevent rubbing of clothes over the treated area, especially irritating straps. Try to wear cotton clothing next to your skin.\nIf skin changes occur, please discuss them with your doctor or the Radiation Oncology staff.\nUCSF Health medical specialists have reviewed this information. It is for educational purposes only and is not intended to replace the advice of your doctor or other health care provider. We encourage you to discuss any questions or concerns you may have with your provider."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:cb5b95a6-6f1b-4197-89fd-cb491721a281>","<urn:uuid:e0680ed1-7fc4-465a-b273-ab3079f3cbe5>"],"error":null}
{"question":"What specific techniques are recommended to avoid accidentally trapping otters when setting beaver traps?","answer":"To avoid catching otters, trappers should avoid setting traps along beaver trails, across dams, in abandoned lodges or bank dens, and along trails between ponds. They should use beaver-specific bait, adjust bodygrip trap triggers by moving them to one side or shortening them, and set cable device loops to 9-10 inches with a loop stop at 4 inches. It's also recommended to use multiple traps to catch beavers quickly and then remove all traps from the area.","context":["Typically, submersion trapping systems are used to trap beaver.\n- In late fall and early spring, beaver are trapped in open water.\n- In the heart of winter, traps are set through the ice. Because fur quality improves as winter progresses, the pelts that bring top dollar are caught through the ice or just after it melts.\n- Set all traps to ensure the beaver will die quickly. The beaver is powerful and intelligent and may escape if not killed within a few minutes.\nWhen seeking beaver, make sure you have the proper equipment to set underwater traps and handle this large furbearer. You will need:\n- Heavy coil-spring or longspring foothold traps\n- Large bodygrip traps\n- A long-handled ax for cutting bait and chopping holes in the ice\n- A trowel for digging or building up trap beds\n- Long-sleeved rubber gloves\n- A trap hook\nWhen using bodygrip traps in beaver sets, many trappers take the following steps.\n- Twist the wire triggers together, and center the trigger. This reduces the risk that beaver carrying vegetation will spring the trap prematurely.\n- Set the trap so that the trigger is on the bottom. This reduces fur damage.\n- Use traps with bent corners. This also reduces fur damage.\n- Use a stabilizer to keep the trap in the desired position. Otherwise, use sticks or poles to support traps in channels, in front of dens, or in other desired locations. Non-powered cable devices and cage traps also may be used in submersion systems for beaver.\nSlide Set for Beavers\nOne set that works well on beaver is similar to the slide set used for muskrats. The set can be used at a slide or at any spot where beaver can be lured to a bank. It can be used even when the water surface is frozen if an opening is broken near the shore.\nFollow these steps to make the set.\n- Use a foothold trap. Wire a large rock (or cement block) weighing about 20 pounds to the end of the trap chain. Wire an 8-pound rock to the chain within a few inches of the trap to pull trapped beaver down quickly. (A sliding wire can be used, but the two-rock method is better.)\n- Set the trap in shallow water, 8\" to 12\" away from the bank. Use a trowel to dig away or build up the bottom to the proper elevation.\n- Place the heavier rock in deep water at chain length.\n- Put a few pieces of food, such as freshly cut aspen boughs, on the bank. Other suitable bait cuttings include wild cherry, apple, or whatever beaver are cutting locally.\n- Add lure to the boughs.\nScent Mound Set for Beavers\nThe scent mound set is a variation of the slide set. This variation is effective along streams where beaver are using bank dens.\n- Beaver make mounds of mud and mark them with their scent glands. If you cannot find a scent mound, make one. Mound mud near the water's edge. Add a few drops of lure to the mound.\n- Approximately 3\" to 4\" into the water, set a foothold trap. Wire an 8-pound rock to the chain near the trap. Wire a 20-pound rock to the end of the chain in deep water. These rock drags ensure immediate submersion and death.\n- On mud-bottom streams, use a sliding wire if rocks are not available.\nOpen Water Set for Beavers\nThis set is made like a scent mount set. However, use fresh poplar cuttings or other food as bait, instead of using lure.\nUnder-Ice Set for Beavers\nThis set can be used where ice is thick and low temperature makes an open water set impossible.\n- Be very careful when making an under-ice set.\n- Make sure the ice is safe.\n- Have someone with you in case you need help. Beginners should not try to make an under-ice set without help.\nPole Set for Beavers\nOne type of under-ice set is the pole set. Follow these steps to make the set.\n- Cut a hole in the ice in the general area of the beaver's lodge or den. Traps should not be set too close to a beaver's lodge, as a trapped beaver may alarm others in the lodge. In addition, your state may prohibit traps too close to a lodge. Check your state regulations.\n- Choose a dead pole, 3\" to 4\" in diameter. The pole should be long enough to extend well above the ice while touching the bottom of the pond.\n- Nail fresh aspen or other boughs crosswise to the pole.\n- With wrapping cord, tie a heavy longspring foothold trap to a platform immediately below the bait. The cord will break when a beaver is caught and attempts to pull away.\n- Wire the trap chain to the pole. Insert the pole into the hole in the ice. Push the pole into the mud and at a right angle to the pond's bottom. Also, insert two dead sticks into the bottom, just behind the bait sticks, to prevent bait stealing. Fill the hole above the trap and bait with chopped ice, which will freeze solid. When a beaver is captured, it will drown under the ice.\nThis set also can be made with a bodygrip trap or non-powered cable device. Cable devices require additional poles to position and anchor the device, and cables probably will need to be replaced each time a beaver is caught.\nTepee Set for Beavers\nAnother type of under-ice set is the tepee set. Instead of attaching the trap to a single pole, this set positions the trap between two sticks, arranged in a teepee shape.\nCanal Set (Channel Set) for Beavers\nBeaver follow underwater paths called channels. The canal set places a bodygrip trap in one of these channels. The canal set is one of the better beaver sets. It can be used either under the ice or below the surface in open water.\nFollow these steps to make the set.\n- Use sticks to anchor the trap and hold it upright in the channel. Place the sticks inside the trap springs so that they won't block the jaws from closing.\n- Center the trap in the channel. (Beaver swim to the middle.)\n- If the channel is too wide, place sticks or brush to narrow the channel and force the animal into the trap. In open water, place a small log or limb over the trap to force the animal to dive under and into the trap.\nThe large bodygrip traps used here are very powerful. They are not recommended for use by young trappers.\nThis set also can be made with non-powered cable devices or cage traps attached securely to stout poles.\nAvoiding Otter With Beaver Sets\nOtters and beavers can be found in the same habitat. To avoid catching otters in beaver sets when otter trapping is not allowed, trappers must take precautions. Suggestions include the following.\n- Avoid setting traps in places where otters travel such as along beaver trails, across beaver dams, in abandoned beaver lodges or bank dens, and along trails between ponds and besides shorelines.\n- Use bait that will attract beavers but not otters.\n- Adjust the trigger on bodygrip traps to catch beavers but allow otters to pass through safely.\n- Move the trigger to one side.\n- Shorten the trigger.\n- With cable devices, set the loop to 9 to 10 inches in diameter. Use a loop stop to keep the loop from closing small enough to trap an otter (about 4 inches in diameter).\n- Catch beavers as quickly as possible using multiple traps. Then remove all traps from the area.\n- If you do catch an otter in a live-restraining device, use a catchpole to release it unharmed."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:110eedae-5859-403c-9d53-d4c3bb6d403d>"],"error":null}
{"question":"How do the roles and restrictions differ between a substitute decision maker for healthcare and an enduring power of attorney for personal care and welfare?","answer":"A substitute decision maker (SDM) can make medical decisions including choices about medications, feeding tubes, breathing tubes, CPR, medical procedures, and living options. In comparison, an enduring power of attorney for personal care and welfare makes decisions about care but has specific restrictions - they cannot make decisions about marriage or divorce, refuse standard or life-saving medical treatment, or consent to medical experimentation. Both roles require the person to act in the best interests of the individual and understand their wishes and preferences. The SDM should be able to communicate clearly with healthcare professionals and make difficult decisions during stressful times, while the power of attorney must be at least 20 years old and cannot be bankrupt or subject to a personal or property order.","context":["Advance Care Planning and Substitute Decision Maker Resources\nAdvance care planning is the process ofreflection and communicating personal care preferences. By doing so others will know your wishes if you become incapable of making medical treatment decisions. Two of the most critical components of advance care planning is to identify a substitute decision maker, and communicate your wishes, values and health preferences with them. By doing so the person who may be asked to make medial decisions on your behalf will have a clearer understanding of what your healthcare choices would be.\nOften people find it difficult to talk about death and dying. These fears may inhibit us for engaging in advance care planning. A number of resources are available to assist in making this process easier, engaging and interesting. In the process we learn a lot about ourselves, our loved ones and the complexities of our medical system become a bit easier to understand.\nHamilton Health Sciences (HHS) is committed to educating our patients, families, staff and volunteers about the importance of advance care planning (ACP).\nTwo of the most critical components of advance care planning are to identify a substitute decision maker (SDM), and to communicate one’s wishes, values and health preferences with them.\nWhat is a substitute decision maker (SDM)?\nA substitute decision maker (SDM) is an individual chosen to make medical decisions on behalf of another person if they are unable to do so for themselves. This is an very difficult role for someone to do on your behalf. In order to make their job easier it is important that you share your health preferences with your SDM while you are capable. By doing so your SDM will have a very clear idea of the choices you would make for yourself. Some of the medical decisions that may be proposed by the health care team are such things as medications, feeding tubes, breathing tubes, CPR, medical procedures such as surgery, and living options if we can no longer care for ourselves in our own home. Your SDM should have an understanding of your health preferences so that they make the right decisions for you.\nWhat happens if I don’t appoint anyone to make decisions on my behalf? The Ontario Health Care Consent Act provides a list of eligible decision makers, in ranking order, who can be your substitute decision maker. If you appoint a substitute decision maker they are called your Power of Attorney for person care (POAPC) and are placed at the top of the ranking order.\nIn becoming a SDM it is important for one to consider the person’s previously desired wishes and to act in the best interests ofthe individual. The following questions should be asked by a SDM to ensure they are making choices for another individual that are consistent with that individuals values, wishes and health preferences:\n- Do I understand what’s important to my loved one? Do I know their health and personal care wishes?\n- Am I willing to communicate those wishes, even if they aren’t what I would choose?\n- Am I able to communicate clearly with health care professionals and ask questions?\n- Can I make difficult decisions, even during stressful times?\n- Do I know the legal requirements of my roles as a SDM in my province/territory?\nAs part of the Advance Care Planning Initiative in Canada, the Speak Up campaign and HHS have several valuable resources available here.\nTo view the Speak Up - Start the converstation about end-of-life care click here\nTo view the video on What is your role in Health Care Decision-Making in Ontario click here\nTo view the Cancer and Advance Care Planning document click here\nTo view Your Conversation Starter Kit click here\nTo view Your Conversation French Starter Kit click here\nTo view Your Conversation Mandarin Starter Kit click here\nTo view Your Conversation Spanish Starter Kit click here\nTo view How to Talk To Your Doctor click here\nTo view How to Talk To Your Doctor French click here\nTo view How to Talk To Your Doctor Spanish click here\nTo view the Pediatric Starter Kit: Having the Conversation with Your Seriously Ill Child click here\nTo view the Hear our Voice, a workbook for parents and guardians to support Advance Care Planning for children and youth, click here\nTo view the *New* Advanced Care Planning Workbooks click here","What is a power of attorney?\nWhen you give someone (or a company) power of attorney, you give them the legal right to act on your behalf in relation to one or more aspects of your life e.g. your finances, property, or healthcare.\nThere are two types of power of attorney:\n1. Ordinary or general power of attorney: is where you give a person (or more than one person) the authority to act on your behalf in relation to either:\n(a) all of your affairs or\n(b) only a specific issue(s).\nIt can be for a fixed period of time or ongoing. If you lose your ability to make your own decisions (such as through illness or accident) then the ordinary power of attorney becomes invalid (is cancelled). An example of the kind of situation where you might give someone this kind of authority is if you were going overseas for a long time and wanted a trusted person to look after your finances until your return.\n2. Enduring power of attorney: is created under the Protection of Personal and Property Rights Act 1988, and continues on even after you lose legal capacity (the ability to understand the nature and consequences of decisions and/or the ability to communicate these decisions).\nFor example, someone with an illness that will eventually affect their mental capacity, arranges for a family member to have enduring power of attorney so that they can make decisions on the sick person's behalf.\nChoosing someone to give power of attorney to is a very important decision. Think carefully about who you want to choose as your attorney, as the role can be misunderstood or abused. The ideal attorney is someone you really trust, someone who will keep your best interests at heart and who cannot benefit financially from the decisions they may have to make.\nBack to top\nWhat are the two types of enduring power of attorney?\nThere are two types of enduring power of attorney:\n- Enduring power of attorney for personal care and welfare: usually a close friend or family member (there can only be one at a time and it has to be an individual – not a trustee corporation) who makes decisions about your care e.g. selecting a rest home or deciding on medical treatment.\nThey can’t make decisions about marriage or divorce, refuse standard or life-saving medical treatment, or consent to medical experimentation. This kind of enduring power of attorney comes into effect only when you lose your mental capacity.\n- Enduring power of attorney for property: you can pick one or more individuals or a trustee corporation to make decisions about how your property and finances should be managed. You can decide whether you want this to come into effect immediately or only when you lose your capacity.\nIt's possible to have one person who has enduring power of attorney for your personal care and welfare, and a different person who has enduring power of attorney for your property and finances.\nBack to top\nWhat should I look for when choosing to give someone power of attorney?\nWhether they are to have ordinary power of attorney or enduring power of attorney, your attorney’s responsibilities are:\n- To act in your best interests at all times and not abuse the trust you place in them\n- To involve you in the decision-making as much as they can - they have to consult you about decisions, and you should try to make decisions as much as you can\nTheir specific responsibilities depend on whether they’ll have ordinary power of attorney or enduring power of attorney (and with the latter, what type of enduring power of attorney). You can require your attorney to consult with people named in your agreement, and you can specify people you don’t want to look after you.\nWhen choosing an attorney, you should pick someone:\n- whom you trust and who will act in your best interests\n- at least 20 years old\n- who is not bankrupt or subject to a personal or property order (for an enduring power of attorney)\n- who understands their role as an attorney, and agrees to it\nFor enduring power of attorney, you may wish to choose different attorneys for personal care and for property as the two roles require different skills and criteria.\nBack to top\nHow is 'loss of mental capacity' defined?\nThe meaning of this term varies depending on whether it’s do with an Enduring Power of Attorney (EPA) and what kind of EPA it is.\nFor an EPA for personal care and welfare, this means that the person is unable to make decisions about their personal care and welfare or understand decisions; they are unable to understand the consequences of those decisions (or of not making those decisions) and aren’t able to communicate their decisions to others.\nFor an EPA for property, it means that the person is mentally incapable of managing their property affairs.\nThe decision about whether a person is mentally incapable is made by a court or by a qualified health provider. Their mental capacity is assumed to be competent unless it is proved otherwise.\nThere is more information about this on the Community Law website.\nBack to top\nDo I have to go to a lawyer to set up a power of attorney?\nIf you are giving someone an ordinary power of attorney (see What is a power of attorney?), all you need to do is fill out the appropriate forms, have them signed by the attorney and yourself, and get both signatures witnessed (not necessarily by a lawyer). You can purchase an Ordinary power of attorney form from an online legal site or obtain one from a law office.\nFor an enduring power of attorney, you (the donor i.e. the person giving power of attorney) must receive legal advice from the person who will be your witness. The donor's witness can be:\n- a lawyer, or\n- a qualified legal executive, or\n- an authorised officer or employee of a trustee corporation.\nThe attorney’s signature can be witnessed by anyone except:\n- the donor and\n- the donor’s witness.\nThe person who witnesses the donor’s signature must also be independent from the person who witnesses the attorney’s signature. The signatures must be witnessed by different people. For example, your lawyer can witness your signature but not the attorney’s, unless two people are appointing each other to be their attorney (e.g. between husband and wife). Also, if the attorney is a trustee corporation then a representative of the corporation can witness the donor’s signature.\nYou can get power of attorney forms from:\nIt’s a good idea to talk to your lawyer before you set up your power of attorney because they can tell you about:\n- the information you need to fill out the form\n- whether you should restrict your attorney’s powers to particular issues or types of decisions\n- optional provisions such as;\n- requiring your attorney to consult with people you choose\n- requiring your attorney to provide information to people you choose\n- appointing a replacement attorney if your first pick can’t act for you anymore\nIt’s worth asking around to get an idea of how much you’ll be charged for the legal advice and for drawing up the power of attorney for you (if you don’t want to do this part yourself). Fees are likely to vary widely depending on the provider.\nYou can find out more from the Community Law Centre website or the New Zealand Law Society factsheet.\nBack to top\nWhen does a power of attorney begin and end?\nThis depends on whether it's an ordinary power of attorney or an enduring power of attorney.\nOrdinary power of attorney\nWhen you fill out a form to give someone an ordinary power of attorney, you can specify when the power of attorney begins and ends. For example, you can specify that it begins on the date you leave New Zealand and ends on the expected date of your return.\nAn ordinary power of attorney is revoked (cancelled) automatically if you (the donor i.e. the person who is giving someone power of attorney) lose the mental capacity to make decisions, or die.\nEnduring power of attorney\nAn enduring power of attorney for property can begin before or after you lose the mental capacity to make your own decisions (this is something you can specify when you set it up).\nAn enduring power of attorney for personal care and welfare can only begin when you lose the mental capacity to make your own decisions.\nThere are several ways for the EPA to end or be revoked:\n- It is revoked automatically when you, the donor (the person who has given someone power of attorney), dies.\n- The Family Court can revoke the appointment of an enduring power of attorney if it decides that the attorney is not acting in the donor’s (the person who gave power of attorney) best interests or failing to comply with their responsibilities. See the next question for more about this.\n- If the attorney becomes bankrupt, loses their mental capacity or dies, they will lose their role of enduring power of attorney. Another one may be appointed in their place.\n- The attorney may also decide they no longer wish to act as attorney, by giving notice of disclaimer.\nBack to top\nWhat can I do if I don’t agree with how the attorney is managing my mother’s financial affairs?\nYour mother can cancel or revoke the power of attorney at any time while she is mentally capable. Because different procedures are needed depending on whether she is changing, cancelling or replacing a power of attorney, it’s a good idea for her to talk to her lawyer to get some advice about how to go about it.\nIf the attorney isn’t carrying out their responsibilities properly, you can apply to the Family Court to step in.\nThe people who can make a complaint to the Family Court about an attorney’s decision include:\n- a relative\n- another of your mother’s attorneys\n- the manager of the hospital, rest home or residential care facility (if she is a patient of one)\n- a medical practitioner\n- a trustee corporation\n- a welfare guardian that has been appointed to you\n- an authorised person from an elder abuse and neglect prevention service, such as Age Concern\n- any other person, with the leave of the court\nThe Family Court is able to do a number of things in relation to a person's attorney if necessary, such as:\n- monitor an attorney's performance,\n- change the terms of the attorney's role,\n- give directions to an attorney to do certain things, or\n- cancel an attorney's appointment.\nBack to top\nWhat can I do if my EPA attorneys are not getting on?\nIf you have two attorneys – one for personal care and one for property – then sometimes they can have different opinions about what is best for you and your life. Either attorney can apply to the Family Court to ask for direction about what to do.\nHow can I help someone who is already losing their mental capacity and doesn’t have an EPA?\nIf someone you care about won’t or can’t give someone enduring power of attorney, you can still protect them by applying to the Family Court for:\n- a personal order. This is a court order which decides on a person’s mental capacity and, if the judge decides an order is necessary, requires that a particular action is taken to look after the person’s welfare. For example, a personal order can specify where the person should live or that they must receive medical advice or treatment.\n- the appointment of a property manager. This is someone to manage the person’s property e.g. pay bills, arrange for repairs. A property order will specify what rights the property manager will have.\nThere’s more about this on the Family Justice website."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:7ff2f18a-8d24-41cf-a766-f23bf4b75f0c>","<urn:uuid:3c153628-954e-4f63-bd5f-b5c8e8f1c2ca>"],"error":null}
{"question":"Could you compare how gut bacteria influences skin health versus mental health? Need to understand the connection better.","answer":"Gut bacteria influence both skin and mental health through different pathways. For skin health, gut bacteria prevent toxins from passing into the bloodstream - when there are fewer good bacteria, toxins can enter the blood and reach other body parts, leading to skin inflammation and issues like dermatitis and acne. For mental health, gut bacteria work through the 'gut-brain axis,' where the brain and gut communicate bidirectionally through signals that affect each other's functioning. The composition of gut microbiota helps regulate brain function, and when this composition is compromised (dysbiosis), it can lead to mental illnesses including anxiety and depression. Recent research suggests mental health conditions could be treated by regulating intestinal microbiota through measures like probiotics.","context":["Our body is full of bacteria.\nDid that instantly conjure images of disease and illness? If so, you’ll be relieved to know that there’s a lot more to the microorganisms than that. In fact, the bacteria that live in us, especially our good gut bacteria, can actually play an immensely helpful role in our health.\nIn this article, we’ll explore how our gut bacteria affect our health, along with what we can do to use that to our advantage.\nLet’s start with:\nBacteria’s Role in Our Gut\nOur Gastrointestinal Tract (GIT) performs some crucial functions like providing the whole body with nutrients, after breaking down the food we eat. It also prevents harmful substances from being absorbed, while getting rid of the body’s waste .\nWe have over 100 trillion bacteria – of about 1000 different types – in the GIT .\nIt’s well known that these bacteria help our GIT in going about its tasks. In fact, their contribution is so significant that, today, the microbes in the lower GIT (the “gut”) are being referred to as an organ in themselves, because of their own distinctive and unique metabolic purposes [3, 4].\nAll of these stem from their fundamental function: fermenting dietary fibre that hasn’t been digested. This goes on to have several consequential effects in the body :\n- The fermentation provides energy to both the bacteria and the body, resulting in less food being required by the body.\n- It creates a substance called ‘butyrate’, which prevents diseases of the digestive tract (like ulcerative colitis, Crohn’s disease, irritable bowel syndrome, and even cancer).\nApart from this, our gut bacteria also help us in other ways:\n- Our gut bacteria may increase the bioavailability of folic acid, B12, and iron, and also produce vitamin K and some B-vitamins [6, 7].\n- They influence how quickly waste is excreted from the body [8, 9].\n- They improve the quality and increase the quantity of the bile produced by our liver (bile is the substance that digests fats) . Since cholesterol gets used up in the making of bile, increasing the quantity of bile also reduces our blood cholesterol [11, 12].\nThis isn’t it, though. These bacteria, amazingly, go on to do even more.\nThe Roles of Good Bacteria Beyond the Gut\nThis is probably the most interesting part of probiotics: scientists believe that our immunity, skin, obesity and even mental state are all affected by the population of bacteria in our gut.\nWe all eat both “good” and “bad” food. The bad can often come with invading microorganisms, which are first met by our GIT.\nThis makes the GIT our first line of defence against potential harmful microbes. The gut bacteria that live there stop harmful microbes from sticking to the lining of the GIT, and also, prevent toxins and other substances (that came with the food) from passing into our blood [12, 13, 14].\nInterestingly, this process starts from the moment a baby is born. The bacteria from the mother’s birth canal are transferred to her child. Since they control what kind of bacteria can enter the child’s body, the mother’s gut bacteria indirectly determine how the baby’s immune system develops and adapts. This affects the kind of infections they get and even play a role in allergies [15, 16]. (Today, many baby formula brands are probiotic-enriched, to speed up the development of the gut bacteria in formula-fed babies) .\nThere’s a constant interaction between our immune system and the GIT bacteria throughout our life, via many processes. What’s startling is that our immune system – which we think is designed to control microorganisms – may in fact be controlled by microorganisms [15, 17], It’s simply a battle between the good and bad species of bacteria.\n2. Skin Health\nYou must have heard that we even have bacteria living on our skin. These help the skin by maintaining its health and healing wounds.\nEven the bacteria in our gut can affect our skin, since they prevent toxins from passing into our bloodstream. When there are fewer numbers of these good bacteria, toxins are able to enter the bloodstream and reach other parts of the body, causing inflammation which can result in skin issues like dermatitis and acne .\n3. Mental Health\nIncreasingly, research has indicated that our gut ‘microbiota’ (the overall composition of the microorganisms in our gut) can help regulate our brain function through something called the “gut-brain axis” .\nThis axis refers to the fact that our brain and our gut have a strong connection that works both ways. They send signals to one another, which can directly affect their functioning [20, 21]. For example, the mere thought of eating can lead to our stomach releasing gastric juices even before any food enters the system .\nIt’s no wonder that ‘dysbiosis’ (when the diversity of this composition gets compromised) and inflammation of the gut have been linked to several mental illnesses, including anxiety and depression, which are prevalent in society today .\nRecent research suggests that these could be treated by regulating our intestinal microbiota (through measures like consuming probiotics).\nThe scientific community has known for many years now that, because of the substances they produce, our gut bacteria can affect our feeding behaviour . What has only recently been discovered, however, is just how much they also affect obesity.\n90% of our gut microbiome consists of two kinds of bacteria - Bacteroidetes and Firmicutes . Many studies have noted that the ratio of the Firmicutes bacteria is higher in obese subjects, suggesting that they could be associated with a higher incidence of obesity [26, 27]. To add to that, previous studies have also shown correlations between weight loss and an increased amount of Bacteroidetes in stools [28, 29] making the association between these gut bacteria and weight even stronger .\nA study even showed that when an obese person’s gut bacteria was transferred into the gut of a lean mouse, the mouse ended up gaining weight - suggesting that our gut bacteria could affect our ability to gain weight in the first place (further human studies would be needed before these results can be confirmed) .\nObesity is also a result of many processes gone wrong – right from the way our body uses glucose, to the way calories are burned during any activity. This makes it closely connected to other conditions like inflammation, type-II diabetes, and metabolic syndrome. The crosstalk between the gut bacteria and organs like our liver, fat tissue, muscles, and the brain can play a crucial role in harmonising these processes [32, 33].\nYou can read further on this subject and learn about a list of foods that can boost this inner ecosystem, for all the benefits of a healthy gut, right here. And if you have any questions about the article or would like to dig deeper into any aspect of it, drop a comment below! We’d love to hear from you. :)","Can Diet Cause Depression?\nIs the Brain Connected to the Gut?\nAccording to a World Health Organization report, depression ranks as the number one cause of disability in America and the third highest, following heart disease and strokes, in Europe. No one knows the exact causes of depression. But recent research on diet and mood has revealed that food may be a major factor.\nIs the Brain Connected to the Gut?\nScientific research demonstrates that about 95 percent of “serotonin, a chemical neurotransmitter responsible for your mood, is produced in your gastro-intestinal tract.” The gastro-intestinal tract, commonly referred to as your gut, is also responsible for about 80 percent of your body’s immunity. So it seems that a poor diet will damage the gut, resulting in reduced serotonin levels and increasing your chances of developing anxiety and depression.\nLast September, ABC News reported on the connection between anxiety and the gastro-intestinal tract saying, many “are beginning to recognize the power of healthy gut bacteria. The average adult carries up to five pounds of bacteria—trillions of microbes—in their digestive tract alone.” And if there is a connection between your gut and your brain, as more and more scientists believe there is, then all that “bacteria may play a role in disorders such as anxiety, schizophrenia and autism.” Some patients have even demonstrated a link between strep bacterium and OCD.\nDr. James Greenblatt, a psychiatrist based around Boston, says that testing for chemical byproducts inside the body can reveal microbial imbalances that may be causing psychiatric conditions by building up too much dopamine in the body. Greenblatt says he doesn’t “know why this test isn’t done on every psychiatric patient” because it is a “more common scenario than we know.”\nThe Food behind the Issues\nSome of the foods that may contribute to anxiety and depression include your typical junk foods that are processed and high in artificial ingredients, refined sugars and fats. This type of food is often comforting but delivers a swift crash after ingestion.\nExcess intake of saturated fats and animal fatty acids can cause a fluid shortage in new cell membranes. This affects the brain, which is the richest source of fatty acids in the entire body. A lack of proper membrane fluid can affect moods, behavior and mental function.\nThough it is viewed as a mood improver, alcohol can also contribute to depression. This is because it creates vitamin deficiencies in the body. Caffeine is a stimulant that also gives a short high and can help with energy levels. But reliance on caffeine can easily backfire to result in sleeping problems, even insomnia.\nCarbohydrate rich diets are another example. Carbs can help boost serotonin levels which improves mood. Fascinatingly, many depressed people crave carbs, and this may be a physical response. However, a diet which is substantially comprised of carbohydrates can cause weight gain as a side affect. Often times, weight gain results in a negative body image which only creates a new source of depression.\nCan Better Food Solve the Problem?\nOf course, it is impossible to shift all the blame onto diets alone. In a chicken and egg scenario, depression often leads patients towards a poorer diet which, in turn, worsens brain chemistry. But the cycle can also begin with bad diet habits that result in poor mental function causing depression and perhaps reinforcing unhealthy eating.\nBut just as poor diets can be a major factor, healthy diets are being touted as an important piece of healing from depression. “Diet therapy” is a term which involves pumping the body and the brain with rich nutrients and vitamins in order to fight depression with proper diet and supplementation.\nSome important dietary supplements for mental functionality include:\n•Tryptophan—a natural relaxant to reduce anxiety and depression, it can increase serotonin levels.\n•Omega 3’s—essential to healthy mental functioning. Some studies show that omega 3 fatty acids powerfully impacted schizophrenic patients by working to correct membrane abnormalities.\n•Vitamin B1—needed for energy production and nerve cell health.\n•Vitamin B6—helps properly balance hormones.\n•Vitamin C—boosts immunity and can help cleanse the liver and aid digestion.\n•Magnesium—important to control the hypothalamic activity in the pituitary adrenocortical axis. This improves the stress response system and reduces anxiety.\nSo which types of foods should you eat and which should you avoid? One infographic by Hartmann Direct answers this question. It explains the importance of avoiding processed meat, especially with lots of salt.\nExercise Can Also Alleviate Depression\nJust like diet is an important aspect of general health as well as fighting depression, exercise is another factor that improves all around wellness and can be especially important in dealing with depression. Harvard Health explains that exercise may relieve depression because it “enhances the action of endorphins, chemicals that circulate throughout the body. Endorphins improve natural immunity and reduce the perception of pain. They may also serve to improve mood.” And yet “another theory is that exercise stimulates the neurotransmitter norepinephrine, which may directly improve mood.”\nExercise works by directly targeting brain chemicals to help your mood. But it also helps your total body recover by lowering blood pressure, fending off heart disease and cancer, increasing self-esteem and making your feel happy. When depressed, many people want to sleep and avoid physical activity. But exercise is needed to help the body and the brain.\nBoth diet and exercise can play an important role in relieving depression. Some cases may still require medication but can still be helped by general healthy habits and key foods supplements.\n(depression / shutterstock)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:2108b27d-4152-4df8-bf51-0810ff50f276>","<urn:uuid:97bc0faa-a6bf-4816-88bb-ac2338b9a98d>"],"error":null}
{"question":"Hi! I want know what kill fish in saprolegnia attack. En español: ¿Qué es lo que mata a los peces cuando tienen saprolegnia?","answer":"Fish death from saprolegnia occurs due to a condition called hemodilution. This happens when the fungus's hyphae penetrate the fish's tissue layers, causing water to enter the fish and dilute its blood salts. This leads to a decreased concentration of cells and solids in the blood, making it less life-supporting. As a result, affected fish appear lethargic and often lose their equilibrium. The more widespread the infection becomes, the higher the rate of hemodilution and greater chance the fish will not recover.","context":["Email Me This Post as a PDF Document, PleaseYour Email Address Address\nSaprolegnia – Water Fungus – by R.E. Carlson\nLike all fresh water environments, koi and goldfish ponds are living ecosystems. They contain plants, algae, invertebrates, protozoa, bacteria and molds or fungi. Many of the life forms in our ponds are dependent upon each other. This is known as symbiosis (living together). An extreme form of symbiosis is parasitism, where one life form lives at the expense of another. One of the more common forms of parasitism in our ponds is saprolegnia or water fungus. For the average ponder, great zoological detail about saprolegnia is not required to understand what it is, what it does and how to treat the pond and fish if it becomes a problem, therefore not much detail on the zoology of saprolegnia is offered here: just good-to-know information on how to identify and treat it as well as some tips to help prevent it from affecting your fish.\nWhat It Is\nSaprolegnia (or sap) is a freshwater fungus which simply means it lives in fresh water environments and needs water to grow and reproduce. Sap can also be found in brackish water and moist soil. It is often referred to as a “cold water” fungus as it flourishes in colder water, but it lives well in a wide range of water temperatures extending from 37 deg F to 91 deg F (3 to 31 deg C). While it has been described also as a “mold”, sap is a genus of fungus, with the difference being a “mold” is a mass of fungi.\nUnder the microscope, sap is composed of filaments that tend to have spherical ends. It is these spherical ends that house the zoospores, or the “seeds” of sap, that allow it to proliferate and spread. The filaments are called hyphae and give sap its cotton-like appearance. It is the hyphae, or more exactly, the hooked, foot-end of the hyphae, which penetrate the tissue of the fish as they seek nutrients. In the lower-power micrograph below, you can see the hyphae with the spherical ends. With a 400x microscope, the structure will look basically the same.\nIn the water, sap looks like fluffy cotton; however, out of the water it appears to be a matted mess of slime. Sap starts out either white or grey in color. The grey appearance also may indicate the presence of bacteria growing with sap’s structure. Over a short period of time, sap may turn brown or green as organic particles in the water (such as algae) adhere to the filaments. Note the picture below. This is a classic presentation of sap that has invaded a bacterial infection of the dorsal fin area of a koi. The green color is actually embedded algae particles within the sap’s filaments.\nBy appearance, sap can be easily confused with epistylus, a freshwater parasite that presents as a white cottony substance growing on the skin of the fish. Epistylus does not gather organic particles and will remain white. Confirmation of epistylus versus sap should be done with a microscope. The following is a microscope shot of epistylus at 400x:\nThe favorite food of sap is dead organic tissue. We can usually see evidence of sap on dead and dying fish, live and dead fish eggs and even food left in the water so long that it has begun to rot. Typically we see infertile koi eggs being infected first with the fungus then it spreads to kill live, fertile eggs. Infected eggs have a typical fluffy cotton wool-like covering. Sap also likes to feast on exposed and decaying tissue caused by bacterial infections, such as ulcers. It is most prevalent on the head and fins of the fish as these are the areas that offer the least amount of natural resistance provided by the mucous coat.\nPrimary and Secondary Invader\nTypically we think of sap as a “secondary” invader. This means that something else has violated the integrity of the fish’s skin allowing bacteria to enter and provide direct tissue access for the sap hyphae to embed themselves. In treating sap, it is imperative to treat BOTH the sap and the underlying primary cause. This will be discussed in more detail in the treatment section below.\nHowever, sap can also be a primary invader under the right conditions and this is where it gets the reputation as a “cold water” fungus. We all know that cold water conditions, including dramatic temperature changes, cause great stress on the fish and suppress the fish’s natural immune system. As stated above, sap flourishes in colder water by producing and releasing increased zoospore counts into the water. The combination of stress, suppressed immune systems, and increased spore counts give sap the ability to cause major problems in colder water. Sap infections are commonly the cause of “winter kill.”\nThe following is a list of conditions that support the spread of sap:\n- Overcrowding – stress and too many organics in too little water\n- Handling – stress and removal of the mucous coat on the fish\n- Epidermal integrity – open wounds that provide direct access to tissue\n- Parasites and pathogens – parasites cause wounds that allow pathogens (like bacteria) to enter the tissue thus giving sap a change to take hold and stress\n- Pollution – stress and reduced water quality\n- Spawning – stress and physical damage\n- Water quality – stress and reduced physiological conditions\n- Water temperature changes – stress.\nObviously the underlying theme in the above list is “stress” and this is the one thing that we need to guard against first and foremost to keep our fish healthy. In healthy conditions, our fish have some natural protection against sap with the mucous layer being the most effective first line of defense. The mucous layer provides the ability to reject a sap attack by sloughing off a layer of mucous and sending the sap with it. The mucous coat also provides a natural fungicide at the cell-level. So you can see that improper handling or any activity that reduces the mucous coat offers an increased opportunity for sap to take hold.\nDeath by SAP\nAn increased morbidity of fish caused by sap can be traced to three major things:\n- Low water temperatures\n- High concentrations of sap zoospores\n- Mechanical stress\nWe know that sap attacks fish weakened by any of the above and the suppressed nature of the immune system under cold water or high stress conditions leaves the fish mostly defenseless. However, what kills the fish in a sap attack is a condition known as hemodilution. By definition, hemodilution is “a decreased concentration (as after hemorrhage) of cells and solids in the blood resulting from gain of fluid from the tissues.” … this causes the blood to loose electrolytes (blood salts) and make it less than life-supporting. Then as the sap hyphae penetrate the tissue layers of the skin, water begins to enter the fish thereby further diluting the fish’s blood salts. This explains why fish grossly affected by sap appear lethargic and often lose their equilibrium.\nOnce it has (literally!) taken root, sap can spread rapidly over the surface tissue of the fish. While it is rare that sap will penetrate deep into tissue layers, even superficial damage to the fish’s initial tissue layers (and particularly the gills) can be deadly. Obviously, the more wide-spread the sap infection becomes, the higher the rate of hemodilution and greater chance that the fish will not recover. Therefore, managing the sap infection quickly becomes the key to saving the fish.\nProtection and Treatment\nObviously, the best “cure” for sap is prevention. As mentioned, sap is present in every pond and has its place in the order of life in the pond’s ecology. It really only becomes a problem when something has gone wrong with the fish and/or the pond or a condition such as cold water suppresses the fish’s immune system.\nSome of the steps we can take to reduce sap’s effectiveness include:\n- Providing a stress-free environment (which starts with excellent water quality)\n- The active reduction of organics in the pond (good mechanical filtration and a balanced ecology).\n- This also will reduce natural aeromonas bacteria counts\n- The quick removal of dead and dying fish and excess food\n- Proper handling (which starts with as little handling as possible)\n- Elimination of parasites\n- Increased water flow during warmer conditions\nBut no matter how hard we try, and especially for those ponds located in areas subject to cold water situations and/or rapid water temperature changes, sap is always a possibility. Except as noted above, there are no reasonable preventive measures, including the use of anti-fungal products as they just do not work effectively against sap. Therefore, we must be prepared to diagnose and treat sap as soon as we see it and here are some treatment recommendations:\nMalachite Green (MG):\nHands down, this is the best treatment for all fungal problems, including sap. (Get Malachite Green) MG baths and dips work_ exceptionally well and one treatment will usually solve the problem (assuming any contributing causes are corrected as well). There are certain cautions that go with using MG, such as use only in cooler, well aerated water, so read the label carefully for instructions and precautions. MG is not recommended as a pond-wide treatment for sap as the concentration levels needed to kill off sap are too high for a pond-wide treatment to be effective. Such products as ProForm C, a Malachite Green-formalin combination can help reduce the incidence of sap and parasites in the water, but because the sap hyphae may be deeply embedded, the stronger dip or bath method is recommended. Caution: Malachite green is carcinogenic and has been banned for use on food fish. Use MG with great care.\nThis is a distant “second best” treatment to MG. Salt in the 0.6 to 1.0% range for 30 minutes or less can help eliminate sap. The caution with this approach is that the higher the salt level, the more stress the fish will endure so check carefully on the stability of your fish prior to performing a high-level salt bath.\nFormalin is mentioned as a treatment for sap however, generally speaking, formalin is ineffective against most molds and fungi. Like MG and salt, formalin comes with its own precautions, including limiting its use in warm water, where low oxygen situations may develop. Handle formalin with care, its toxicity is well known. Diluted versions of formalin products, such ProForm C offer a nice one-two punch where MG takes out the sap and formalin gets the parasites. It is not recommended to use formalin against open wounds because of the harmful effect of formalin on exposed tissue and cell structures.\nIn the right hands, PP is one of the better treatments for sap. PP treatments at 4PPM (4g/1000 litres) will eliminate most of the sap but for deeply embedded sap hyphae, further surface treatments using a PP paste may be required. The down side of PP, of course, is the inherent danger of using it at all. It is not recommended for those inexperienced with its use.\nTreating a sap-affected fish requires that the wound site be tended completely. As mentioned, sap is generally a secondary invader; this means something else went wrong to allow the sap to take hold, like a parasite attack or another wound that opened the tissue. So, when treating a sap-affected fish, first eliminate the sap from the surface of the fish and then treat the actual wound site, which is most likely starting to look like an ulcer. For the latter, Tri-Cide Neo, iodine, PP paste and/or Debride topical ointment are good choices. Depending on the extent of the underlying wound, injectable medications may be required and the assistance of a veterinarian sought. If you suspect that cold water has allowed sap to become a primary invader, attention to the surface tissue of the affected fish is still required as the sap hyphae penetrates the tissue and can allow bacteria to enter the wound site.\nMuch has been said regarding the importance of using a microscope in the koi hobby. A microscope with a range up to 400x (eg 40X objective and 10X eyepiece) is an invaluable tool for diagnosing problems with our fish as well as viewing almost the entire spectrum of the ecology of our ponds from algae to parasites to the larvae of insects. At 200x, the filament structure of sap is easily to see and at 400x, the hyphae and spherical ends of sap are clearly discernible. Also, at 200x the movement of most parasites can be easily seen and at 400x, virtually all of the parasites that routinely inhabit our ponds can be detected and identified.\nAs you can see, sap is one of the major potential problems that we have to be prepared to deal with. Since sap is always present in our ponds, it is imperative to take as many preventative measures as possible to keep it from affecting the fish. But even the best pond keepers will eventually get a sap outbreak and when this happens, treatment must be quick and complete as this is not a problem that will just go away all by itself.\nImages provided by Mr. Richard Carlson and used with permission."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:5606676c-9cad-477e-9b99-6fc12448d66c>"],"error":null}
{"question":"How do the motivations claimed by the Soviet Union compare between their invasion of Estonia versus Poland - what official reasons did they give in each case?","answer":"The Soviet Union provided different public justifications for both invasions. For Poland, the Soviet government claimed they were acting to protect the Ukrainians and Belarusians who lived in eastern Poland. In Estonia's case, they initially claimed to be seeking a military alliance for mutual aid, demanding naval and air force bases plus permission for 25,000 Soviet troops to enter Estonian territory. In both cases, these stated reasons masked the true motivation revealed in the secret German-Soviet pact of August 23, 1939, which had divided Eastern Europe into German and Soviet spheres of influence.","context":["Seventy-five years ago today, on August 9, 1940, the newly formed Estonian Soviet Socialist Republic joined the USSR. Not willingly, mind you. Brought into being by the Molotov-Ribbentrop Pact, shaken by Stalinist deportations and guerilla warfare, Soviet-occupied Estonia met its first birthday in a literal trial by fire: the invasion by Nazi Germany. One Estonian writer recalls the fall of independent Estonia.\nThe Republic of Estonia, which had declared its independence on February 24, 1918, and fought for it in the War of Independence (1918-1920), was doomed by the German-Soviet Nonaggression Pact (August 23, 1939). In a secret addendum to the pact, the two powers divided up Eastern Europe, and the neutral Baltic states were placed in the Soviet sphere of influence. Immediately after the German occupation of Poland, the Soviets issued an ultimatum to the Estonian government, demanding that Estonia form a military alliance (thereby abandoning neutrality), provide bases for the Soviet navy and air force, and allow 25,000 Soviet troops onto their territory (the Estonian reserve army counted just 17,000 people). It was an offer Estonia was unable to refuse.\nA mutual aid treaty was signed on September 28, 1939, which stressed that the Tartu Peace Treaty (1920) and the Soviet-Estonian Nonaggression Pact (1932) remained in force, and that the Soviet Union would not in any way attempt to change the political or economic order in Estonia. These promises lasted nine months. For Stalin, June 1940 – just as Hitler was finishing off France – felt like an appropriate time to take the next step. On June 15, an ultimatum was issued to Lithuania, and on June 16 Latvia and Estonia received theirs. On June 16 and 17, overwhelming Soviet armies invaded the Baltic states without declaring war. A series of political decrees followed, resulting in three new republics joining the USSR by early August.\nIn Estonia, this “revolution” (here led by Andrei Zhdanov) failed to maintain even the pretense of legality: there were blatant violations of the Constitution, and of all the key laws on transfer of power, elections, parliamentary authority, and so on. The year that followed this prelude also introduced Estonians to the other “wonders” of Stalinism, including a mass deportation on the night of June 13, 1941, when nearly 10,000 people were arrested (men were sent to the camps, women and children – into exile).\nGiven these circumstances, it comes as no surprise that once the war began many Estonians expected the Germans to arrive as liberators. They hoped that Germany would restore the Baltic states’ sovereignty as its allies. For them, war had started before the arrival of German troops. Many cities (including much of Tartu), towns, and villages were freed of Soviet invaders by the so-called “Forest Brothers” – guerilla groups that had formed spontaneously as early as June 1940. Many of the soldiers and officers of the 22nd Territorial Rifle Corps (the former Estonian army), which had been withdrawn from Estonia at the start of the war, defected near Pskov (July 1941) and were ready to continue their ongoing war against the USSR on the German side.\nBut their hopes were soon dashed. Hitler’s Germany was not establishing alliances on equal terms: it sought “ancient German lands,” ideally with no natives. Estonia was incorporated into the German colony of Ostland (December 1941) and administered by a pro-German puppet government led by Hjalmar Mäe. There was no way a legitimate government could be restored.\nPhoto credit: Wikimedia Commons\nTranslated by Eugenia Sokolskaya.\nRussian Life is a 29-year-young, award-winning publishing house that creates a bimonthly magazine, books, maps, and other products for Russophiles the world over.\nPO Box 567\nMontpelier VT 05601-0567","Soviet invasion of Poland\n|Soviet invasion of Poland|\n|Part of the invasion of Poland in World War II|\nSoviet forces marching through Poland in 1939.\n|Commanders and leaders|\nKliment Voroshilov (Commander-in-Chief)|\nMikhail Kovalyov (Belarusian Front)\nSemyon Timoshenko (Ukrainian Front)\n250,000 Polish Army.\n|Casualties and losses|\nup to 20,000 wounded.[Note 1]\n1,475–3,000 killed or missing|\n2,383–10,000 wounded.[Note 2]\nThe 1939 Soviet invasion of Poland was a Soviet military operation that started without a formal declaration of war on 17 September 1939. It was during the early stages of World War II. Sixteen days after Nazi Germany invaded Poland from the west, the Soviet Union did so from the east. The invasion ended on 6 October 1939. Germany and the Soviet union divided the whole of the Second Polish Republic.\nIn early 1939, the Soviet Union asked the United Kingdom, France, Poland, and Romania to make an alliance against Nazi Germany. The Soviet Union wanted Poland and Romania to let Soviet troops go through their territory. Poland and Romania both said no. The Soviet Union made a secret deal with Nazi Germany on 23 August. They planned to divide Northern and Eastern Europe into German and Soviet lands. One week later, German forces invaded Poland from the north, south, and west. Polish forces then withdrew to the southeast to wait for French and British support. The Soviet Red Army invaded the Kresy on 17 September. The Soviet government said it was acting to protect the Ukrainians and Belarusians. They lived in the eastern part of Poland.\nThe Soviet government added the land they won. In November 1939 they made the 13.5 million formerly Polish citizens become citizens of the Soviet Union. They sent hundreds of thousands of people from this region to Siberia and other remote parts of the Soviet Union.\nSoviet forces stayed in eastern Poland until the summer of 1941. They were moved by the invading German army in the course of Operation Barbarossa. The area was under Nazi occupation until the Red Army reconquered it in the summer of 1944. An agreement at the Yalta Conference let the Soviet Union add almost all of their part of the Second Polish Republic. The People's Republic of Poland got the southern half of East Prussia and lands east of the Oder-Neisse Line. The Soviet Union added the lands into the Ukrainian Soviet Socialist Republic and the Byelorussian Soviet Socialist Republic.\nNotes[change | change source]\n- The figures do not take into account the approximately 2,500 prisoners of war executed in immediate reprisals or by anti-Polish Organization of Ukrainian Nationalists.\n- Soviet official losses – figures provided by Krivosheev – are currently estimated at 1,475 KIA or MIA presumed dead (Ukrainian Front – 972, Belorussian Front – 503), and 2,383 WIA (Ukrainian Front – 1,741, Belorussian Front – 642). The Soviets lost approximately 150 tanks in combat of which 43 as irrecoverable losses, while hundreds more suffered technical failures. Sanford indicates that Polish estimates of Soviet losses are 3,000 dead and 10,000 wounded. Russian historian Igor Bunich estimates Soviet losses at 5,327 KIA or MIA without a trace and WIA.\nReferences[change | change source]\n- Sanford pp. 20–24\n- Increasing numbers of Border Protection Corps units, as well as Polish Army units stationed in the East during peacetime, were sent to the Polish-German border before or during the German invasion. The Border Protection Corps forces guarding the eastern border numbered approximately 20,000 men.\n- \"Kampania wrześniowa 1939\" [September Campaign 1939]. PWN Encyklopedia (in Polish). Archived from the original on 9 May 2006. Retrieved 16 July 2007.\n- The retreat from the Germans disrupted and weakened Polish Army units, making estimates of their strength problematic. Sanford estimated that approximately 250,000 troops found themselves in the line of the Soviet advance and offered only sporadic resistance.\n- Krivosheev, Grigory Fedot (1997). Soviet casualties and combat losses in the twentieth century. London: Greenhill Books. ISBN 1-85367-280-7.\n- Topolewski & Polak p. 92\n- Bunich, Igor (1994). Operatsiia Groza, Ili, Oshibka V Tretem Znake: Istoricheskaia Khronika. VITA-OBLIK. p. 88. ISBN 5-85976-003-5.\n- Gross pp. 17–18\n- Watson p. 713\n- Watson p. 695–722\n- Kitchen p. 74\n- Davies (1996) p. 440\n- \"The German Ambassador in the Soviet Union, (Schulenburg) to the German Foreign Office No. 371\". Avalon project. Lillian Goldman Law Library. Retrieved 2009-06-11.\n- \"The German Ambassador in the Soviet Union, (Schulenburg) to the German Foreign Office No. 372\". Avalon project. Lillian Goldman Law Library. Retrieved 2009-06-11.\n- Degras pp. 37–45\n- Wettig p. 47"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:adaa0025-492a-4d93-97cc-fb08765e6693>","<urn:uuid:d7e63c17-0cf6-4c7c-be9b-1949aed6ee2b>"],"error":null}
{"question":"What is the relationship between teaching content discovery and activating prior knowledge in educational settings?","answer":"Content discovery emphasizes helping students discover knowledge rather than simply covering material, allowing them to learn through exploration and failure while discovering how to create, reflect, and collaborate. This approach aligns with the theory of prior knowledge, which recognizes that learning new information is easier when students can connect it to existing knowledge. Both approaches focus on making learning more effective by engaging students actively in the learning process rather than passive reception of information.","context":["People have asked me when I teach project-based learning or inquiry, do I teach my students about the process. Yes. The process is really important to what students are learning: So at the beginning, student are introduced to the stages of the process and are eventually given more and more responsibility and freedom over the process as they acquire the skills needed. At the same time, I don’t belabour the process, because, it doesn’t make a lot of sense to them without action behind it.\nOne of the things many teachers have also mentioned to me is “there is content to teach”. We all have content to teach. However, content is not meant to covered. Blankets are for covering things. The role of the teacher is to help students discover. Content can actually be discovered, and I’m not talking about assigning page 89- 92. Discovery is how they learn best. Students should Discover how to fail. Discover how to create. Discover how to reflect. Discover how to collaborate. Discover their voice. Discover who they are. All of this should be happening in our classrooms.\nInquiry or Project-based learning does not mean the classroom is a free for all. Great Inquiry requires planning. For example, if I were to create an inquiry unit around the Golden Age of Islamic Discovery I would start with my essential questions:\n- How did the Arab empire become so large and influential?\n- As a historian, research and evaluate one area of the Arab Golden Age that influenced modern society.\n- How did this vast, knowledgeable Empire disappear?\n|Core Competencies in Islamic Golden Age Unit:|\n|Use Social Studies inquiry processes and skills to: ask questions; gather, interpret, and analyze ideas; and communicate findings and decisions|\n|Assess the significance of people, places, events, and developments at particular times and places (significance)|\n|Determine what is significant in an account, narrative, map, and text(significance)|\n|Characterize different time periods in history, including periods of progress and decline, and identify turning points that mark periods of change (continuity and change)|\n|Determine what factors led to particular decisions, actions, and events, and assess their short-and long-term consequences (cause and consequence)go|\n|Make ethical judgments about past events, decisions, and actions, and assess the limitations of drawing direct lessons from the past (ethical judgment)|\n|Explain different perspectives on past or present people, places, issues, and events, and compare the values, worldviews, and beliefs of human cultures and societies in different times and places (perspective)|\nBy outlining the three questions for my students, I start with a What do we Need to Know Chart, and they can fill it up with all the things we need to might need to know. This is a working draft. We can come back to it at anytime. I then create a second chart, How might we learn these? You might get a kid who says the internet, but I always have them try to dig deeper than something that easy.\nFor this particular unit, I would then introduce the unit with this video\nWhat’s interesting is that the Roman Empire is often considered the largest to ever conquer the world. And yet, if you look at the map\nof the areas under Muslim rule, it was a much larger empire. This is something I would consider exploring with my students. Is it true? How do we find out? Why have we been sold the bill of goods that the Romans were so much bigger? Why are we taught about the Romans every year in grade 7 and why do we never hear about the Islamic Golden Age even though its discoveries are still incredibly influencle today?\nUsing Content To Teach Skills\nOne of the reasons I teach the inquiry process is because I intentionally use the content to teach the skills. The first skill is summarization. I’ve found over and over, even at the high school level, my students cannot effectively summarize a text into a paragraph, or a paragraph into a sentence I start by giving them 2 different techniques they may choose to use.\nHere is how it works:\nFirst I teach the difference between summarization and paraphrasing. There’s a difference. Many kids don’t know that. Some adults don’t either.\nRead the article or section of text.\nCreate and fill-out a 3-2-1 chart like this:\n|3 Things You Found Out from the passage||2 Interesting Things from the passage||1 Question You Still Have after reading the passage|\n- From these 3-2-1 points you collected you would then write a short paragraph to report your findings.\nReading for Gist\nThe word Gist means to look for the essence of the text or the main ideas. To help you do this, you would identify the 5 W’s (who, what, where, when, why) and the H (how) of the document.\nHere is how it works:\n- Read the article or section of text.\n- Fill in the 5 Ws and H\nWith the understanding of the 5 W’s and H, you then use these details to write a short GIST summary.\nStudents are then given a text to read. This begins to give students additional background knowledge they will need before they will be able to dive in further to the inquiry. At the same time they’re building valuable skills.Once students have read the text, they will submit the formative assessment below.\nQuestion: What is the Islamic Golden Age of Discovery?\nI used the ____________ summary technique (3-2-1, GIST or Underlining) for this text because __________________________________________________________________________________________________________________________________________________________________________________________\nNote: What are three of the main ideas of this historical text you would like to feature:\nStep 1 – Make and overarching comment about the Inquiry Question.\nStep 2 – Write a sentence or two about each of the main ideas that stood out to you.\nStep 3- Write a final remark to summarize the answer to the Inquiry Question.\nTime for you to practice and show me what you have learned.\n|4 Points||3 Points||2 Points||1 Point|\n|Main Idea||Correctly identifies the main idea in a clear and accurate manner.||Correctly identifies most of main idea in a complete sentence.||Identifies an important idea but not the main idea in a complete sentence.||Identifies a detail but not the main idea.|\n|SupportingDetails||Clearly states 2 or more important details using own words or statements.||States at least 2 important details with some paraphrasing of information.||States at least 1 important detail. Demonstrates little if any paraphrasing.||Includes unnecessary details. Does not demonstrate any paraphrasing.|\nI would do this several more time with articles or various texts to build background knowledge around the topic and to begin developing students ability to summarize.","About This Chapter\nStrategic Approaches to Reading Instruction - Chapter Summary\nUse the lessons in this chapter to help you learn more about facilitating learning in reading. Topics covered in the lessons include assessment of reading materials, teaching methods, the scaffolding process and a definition of the learning process. You'll also look at metacognitive strategies used in classroom instruction. After completing the chapter, you'll have covered the following topics:\n- Classroom strategies to promote learning\n- Activities that focus on reading development\n- Methods and approaches for teaching reading comprehension\n- Theory of prior knowledge\n- Scaffolding process strategies for reading instruction\n- Metacognitive strategies and examples\nThis chapter is divided into short video lessons taught by knowledgeable instructors. Each lesson is less than ten minutes long and contains interactive timeline tags. Use the tags to skip areas where you're already proficient and easily jump to topics where you need further review. In addition, each lesson is followed by a self-assessment quiz so you can check how much you've learned.\n1. What is Learning? - Understanding Effective Classroom Strategies\nWe all learn new things every day, but how is 'learning' defined in educational psychology? This lesson covers the definition of learning, different types of learning, and discusses learning styles.\n2. Strategies for Assessing Reading Materials\nOne of the most important aspects of being an English language arts teacher is choosing suitable reading materials for your students. Watch this video lesson to learn strategies for choosing the most appropriate materials.\n3. Activities & Strategies for Student Reading Development\nHelping students develop their reading skills can create learners who love to read. This lesson offers some ideas that help young readers develop their reading abilities.\n4. How to Teach Reading Comprehension\nTeaching reading comprehension requires instilling in the learner the use of several strategies and skills. This lesson will focus on cognitive skills and notation strategies that will enhance reading comprehension.\n5. Prior Knowledge: Definition & Theory\nHave you ever noticed that sometimes it is really easy for you to learn something new but some things are harder to learn? In this lesson, we'll define prior knowledge and why it can make learning new things easier. We'll also explore different strategies to activate prior knowledge.\n6. Strategies for Scaffolding Reading Instruction\nEver heard the phrase 'reading is the gateway to all learning'? Reading is one of the areas targeted by most states for assessment because it not only is a critical area in academics, but also an area where most students were not showing gains. This lesson will highlight strategies to help struggling readers develop skills to be successful in the classroom.\n7. Metacognitive Strategies: Definition & Examples\nThis lesson will define and explain in detail what metacognitive strategies are and how they can be used in the classroom to help deepen students' thinking about content and develop students who are ready and willing to tackle new content.\nEarning College Credit\nDid you know… We have over 200 college courses that prepare you to earn credit by exam that is accepted by over 1,500 colleges and universities. You can test out of the first two years of college and save thousands off your degree. Anyone can earn credit-by-exam regardless of age or education level.\nTo learn more, visit our Earning Credit Page\nTransferring credit to the school of your choice\nNot sure what college you want to attend yet? Study.com has thousands of articles about every imaginable degree, area of study and career path that can help you find the school that's right for you.\nOther chapters within the Praxis English Language Arts - Content Knowledge (5038): Practice & Study Guide course\n- Literary Theories & Research\n- Literary Genres & Forms\n- Periods of American Literature\n- British Literature\n- World Literature Overview\n- Young Adult Literature Overview\n- Literary Skills & Strategies\n- Praxis English: Analyzing Literature\n- Forms of Poetry\n- Figurative Language in Literature\n- Literary Themes & Main Ideas\n- Technical Writing & Informational Texts\n- Argument & Rhetorical Strategies\n- Evaluating Arguments and Reasoning\n- Language and Word Choice\n- Language Development & Acquisition\n- Types of Essays\n- Essay Organization, Development & Presentation\n- Sentence Types, Parts & Structure\n- Overview of English Grammar & Usage\n- Capitalization & Punctuation in English\n- Types of Writing Sources & Citations\n- Methods for Writing Instruction\n- Strategies for Speech Organization\n- Elements of Speech Delivery\n- Strategies for Classroom Discussion\n- Differentiated Instruction Basics\n- Language Arts Assessments\n- Praxis English Language Arts: Content Knowledge Flashcards"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:ba2af95d-bc3e-4fb5-967b-ae6be53f62f8>","<urn:uuid:d7dcdc1d-4521-4a94-b953-1eaff94e42f1>"],"error":null}
{"question":"From an architectural standpoint, how does the Arc de Triomphe's dimensions compare to the ancient Colosseum's capacity? 从建筑学的角度来看，凯旋门的尺寸与古罗马斗兽场的容量相比如何？","answer":"The Arc de Triomphe and the Colosseum are vastly different in their scale and purpose. The Arc de Triomphe stands at 49.5 metres (162 ft) high, 45 meters (150 ft) long, and 22 meters (72 ft) wide. The Colosseum, built in 80 A.D., was designed as an oval arena that could accommodate 50,000 spectators in its stone seats.","context":["The Arc de Triomphe. Who hasn’t seen that great symbol, surrounded by traffic but standing proud at the centre of 12 wonderful avenues and at the end of the famous Champs-Elysées? It’s part of L’Axe historique, a series of grand monuments and gracious boulevards on a route through Paris from the Louvre Palace to the outskirts of the city. One of the great icons of Paris, it’s also one of the most visited attractions with 1.7 million visitors a year, and with good reason; the view from the top is breath taking.\nA Little History\nLike much of the grand designs in France, the Arc de Triomphe began with Napoleon I who ordered its construction. It was designed by the architect Jean-François Chalgrin, inspired by the single arch of the Arch of Titus built in c. 81 AD in Rome. The Arc de Triomphe however is larger, a whopping 49.5 metres (162 ft) meters high, 45 meters (150 ft) long and 22 meters (72 ft) wide, built without columns. The statues around the base are heroic, depicting heroic young French soldiers against the enemy, and commemorating the Napoleonic wars. Don’t miss is François Rude's La Marseillaise depicting Marianne, the symbol of France, urging the soldiers on. Inside the walls are inscribed with the names of over 500 French soldiers in the Napoleonic wars, with the dead underlined. The Arch wasn’t finished until 1836, by which time Napoleon had died, and was opened with much pomp and circumstance by King Louis Philippe.\nBeneath the arch lies the Tomb of the Unknown Soldier from World War I, laid here in 1920. Two years later the idea of a Memorial Flame was put forward. The flame was first lit on November 11, 1923 and has never been extinguished. It became the great symbol of liberation when General Charles de Gaulle laid the white-flowered Cross of Lorraine on the tomb on August 26, 1944. To this day there’s a daily ceremony when a flame is rekindled as a tribute.\nIn 1961, American President John F. Kennedy visited the tomb on a historic visit to France. His wife, Jacqueline Kennedy Onassis, asked for an eternal flame to be lit for JFK after his assassination in 1963 when he was buried at Arlington National Cemetery in Virginia. President Charles de Gaulle attended the funeral.\nEvents at the Arch\nThe Arch is the centrepiece of all the great national celebrations: May 8, November 11 and Bastille Day, July 14, as well as New Year’s eve when there’s a fabulous sound and light show playing over the Arch. Between late November to mid January you get a wonderful view of the Christmas lights below you along the Champs Elysées.\nVisiting the Arc de Triomphe\nPlace Charles de Gaulle\nTel.: 00 33 (0)1 55 37 73 77\nGetting to the Arc de Triomphe\nMetro: Charles de Gaulle Etoile (Line 1, 2 or 6)\nRER: Charles de Gaulle Etoile (Line A)\nBus: lines 22, 30, 31, 52, 73, 92 and Balabus\nFrom outside Paris: exit Porte Maillot and avenue de la Grande Armee or exit Porte Dauphine and avenue Foch\nFrom the centre of Paris: drive or walk up the Champs Elysées\nIf you are on foot, the safest way to enter is via the underground walkway along the Champs Elysees.\nOpen Jan 2 to Mar 31: Daily 10am-10.30pm\nApr 1 to Sept 30: 10am-11pm\nOct 1 to Dec 31: 10am-10.30pm\nLast entry 45 mins before closing time\nClosed Jan 1, May 1, May 8 (morning), Jul 14, Nov 11 (norming) Dec 25\nAdmission: Adult €12; 18 to 25 years €9; under 18s free\nYou can do your own tour with an information leaflet in French, English, German, Italian, Spanish, Dutch, Japanese and Russian.\nThere is a tour lecture in French, English and Spanish lasting 90 minutes.\nThere are public lavatories and a small bookshop.","26The Big Ben The Houses of Parliament were the residence of the Kings of England from the 11th to the 16th Century. The Great Hall is the only surviving medieval element and today it is used by Parliament and other public bodies.\n27The Westminster complex was destroyed by fire in 1834 and replaced by the present building, which was designed by Sir Charles Barry. The most striking parts of Barry's design are the river front and the 97m clock tower famous for its bell, its unique chimes and its precise timing.\n28Cheop's PyramidAbout 4,500 years ago there lived in Cairo, Cheops, a king of Egypt.This king wanted to build a tomb where he was to be buried and he wanted this tomb to be the biggest in the world and so it was. The body of the pharaoh was brought by boat down to the river Nile to be\n29buried in this great tomb buried in this great tomb. The Egyptians believed in eternal life after death and thiscould only be enjoyed if the body was preserved. So they developed the art of making mummies that would lie in tombs built to last forever. This tomb is one of about 70 in Egypt still remaining today.\n30The Colosseum The city of Rome has always been famous for its magnificent buildings. The Romans built fine towns and beautiful roads, palaces and large squares. They loved sports and so in the year 80 A.D. they built an impressive oval arena surrounded by\n31stone seats which could hold 50,000 people stone seats which could hold 50,000 people. It was used for holding gladiator combats wildanimal fights and other shows. We can still see the remains of this old beautiful building where so many races were held and where so many people lost their life.\n32The Eiffel Tower Rising over the city of Paris, on the left side of the river Seine, stands an iron construction which is the symbol of the French capital. It is a 300m high tower designed and built by the French engineer Gustave Eiffel in the year This iron frame\n33was built on four piers and there are three platforms at different levels. Each platform can be reached either by stairways or by elevators. A TV transmission antenna is located at the top of the tower.\n34The Great Wall of ChinaA line of earth and brick fortifications that extends 2,400km acrossnorthern China from the Gulf of Chihli to Kansu Province. In the late 3rd century BC the first continuous wall was built by linking earlier sections. This demarcates Chinese territory It was only\n35partially effective in preventing invasions from the north partially effective in preventing invasions from the north. Troops, summoned bywatchtower beacons, could race quickly along the top to fight any invader. Nowadays, gates through the wall near Beijing became centres of trade and of contact with northern nomads.\n36The Neolithic Temples The first men in the Maltese Islands used to worship the goddess of fertility. They made statues and built temples in the shape of a fat lady, where they could worship their goddess. It is extraordinary how these first men, as early as 3000\n37B.C., managed to build such places with enormous huge rocks, weighing approximately 50 tons, without any machines to help them. These sites are today visited by a large number of tourists and are considered as sites of national and world heritage.\n38The Opera House This is Sydney's most famous building. It is the work of the Danish architect Jorn Utzon. It sits on a promontory extending into the Harbour and resembles a series of immense, wind-filled sails. It was opened in 1973 and described as 'the biggest\n39environmental site-specific structure south of the Equator' environmental site-specific structure south of the Equator'. It is the performing artscentre of Sydney, Australia. It contains a large concert hall for the Sydney Symphony Orchestra, a theatre for opera and ballet, a smaller theatre for plays, a cinema and recording studios.\n40The ParthenonPerhaps the most graceful temples of the ancient world were thosebuilt by the Greeks with rows of perfectly balanced columns. In the Greek city of Athens, on a hill about 150m high known as the Acropolis, lies the temple of Athena the goddess of wisdom. Made of white\n41marble the temple was completed in the year 432 B. C marble the temple was completed in the year 432 B.C. and remained in good condition until 1687when it was damaged by an explosion. Today this temple is no longer for the worship of ancient gods. Instead its remains are crowded with tourists who came to learn a little about life long ago.\n42The Statue of LibertyStanding at the entrance of New York Harbour is a colossal statue. It hasthe form of a woman wearing flowing robes and a spiked crown on her head. It holds a torch in her right hand and carries in her left one a book on which is written July 4, The 46m high statue was\n43designed by Gustave Eiffel and sculpted by Frederic Bartholdi designed by Gustave Eiffel and sculpted by Frederic Bartholdi. The statue was given by theFrench Government to the Americans in the year 1886 to commemorate the 100th anniversary of America's independence.\n44The Taj MahalIt is one of the most famous buildings in the world. A white marblemausoleum in Agra, India, located on the Jumna River. It was built between the years 1632 and 1643 by the emperor Shah Jahan in memory of his beloved wife, Mumtaz Mahal. It is regarded as one of the finest\n45example of Mogul architecture example of Mogul architecture. It is a domed building laid in perfect symmetry withan area of 29 square meters. The unique qualities of this monument lie in the magnificent contrast between the white marble facade of the mausoleum and the red sandstone of the surrounding buildings."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:1aceba8c-4a0e-48a5-b8e6-acb22923431d>","<urn:uuid:ec5a3bd2-e279-49de-bfa3-9f8824e9965a>"],"error":null}
{"question":"What is the historical significance of transposable elements' discovery, and how do they contribute to human genetic diseases?","answer":"Transposable elements (TEs) were first discovered in 1951 by Barbara McClintock through her work on corn kernels' color mutations, for which she received the Nobel Prize in 1983. This discovery revolutionized our understanding of genome stability, showing that genomes are dynamic and fluid. In terms of human disease impact, TEs contribute significantly to genetic instability and disorders through various mechanisms. They can cause mutations through direct gene insertion, deletion, and by altering gene expression. Currently active human TEs include LINE-1, Alu (SINE), and SVA families. These elements occupy approximately 46% of the human genome, one of the highest proportions among mammals. They can cause diseases through insertional mutagenesis and non-allelic homologous recombination, with growing evidence linking them to various human disorders.","context":["An Overview of Transposable Elements and their Impact on some Insect Host Genomes\nWiem BEN AMARA*\nPhD in Genetics and Molecular Biology, Research Laboratory of Biochemistry and\nBiotechnology, Department of Biology, Faculty of Sciences of Tunis, University of Tunis\nEl Manar, Tunisia\n*Corresponding Author: Wiem BEN AMARA, PhD in Genetics and Molecular Biology, Research Laboratory of Biochemistry and Biotechnology, Department of Biology,\nFaculty of Sciences of Tunis, University of Tunis El Manar, Tunisia.\nFebruary 27, 2023; Published: April 01, 2023\nThe history of Transposable elements (TEs) has started in 1951 with the discovery of the Ac (Activator) and Ds (Dissociation) elements by Barbara McClintock, that she considered to be at the origin of mutations leading to genetic instabilities in the color of corn kernels . These discoveries, for which McClintock was awarded the Nobel Prize in 1983, revolutionized the notion of genome stability to demonstrate that it is dynamic and fluid . Thus, transposable elements are defined as repeated DNA sequences dispersed in the genome that are capable of moving from one site to another and multiplying in an autonomous or non-autonomous way. These mobile DNA sequences have several impacts on the genomes they invade and are key players in their evolution and diversity.\n- Mc CB. “The origin and behavior of mutable loci in maize”. Proceedings of the National Academy of Sciences of the United States of America 6 (1950): 344-355.\n- Comfort NC. “From controlling elements to transposons: Barbara McClintock and the Nobel Prize”. Endeavour3 (2001): 127-130.\n- Kazazian HH. “Mobile elements: drivers of genome evolution”. Science 5664 (2004): 1626-1632.\n- Contreras B., et al. “The impact of transposable elements in the evolution of plant genomes: from selfish elements to key players”. Evolutionary Biology: Biodiversification from Genotype to Phenotype (2015): 93-105.\n- Platt RN., et al. “Mammalian transposable elements and their impacts on genome evolution”. Chromosome Research 1-2 (2018): 25-43.\n- Finnegan DJ. “Eukaryotic transposable elements and genome evolution”. Trend in Genetics 4 (1989): 103-107.\n- Lim JK and MJ Simmons. “Gross chromosome rearrangements mediated by transposable elements in Drosophila melanogaster”. Bioessays 4 (1994): 269-275.\n- Rachidi N., et al. “Multiple Ty-mediated chromosomal translocations lead to karyotype changes in a wine strain of Saccharomyces cerevisiae”. Molecular Genetics and Genomics 4-5 (1999): 841-850.\n- Zhang J and T Peterson. “Transposition of reversed Ac element ends generates chromosome rearrangements in maize”. Genetics4 (2004): 1929-1937.\n- Mc CB. “Chromosome organization and genic expression”. Cold Spring Harbor Symposia on Quantitative Biology 16 (1951): 13-47.\n- McClintock B. “Controlling elements and the gene”. Cold Spring Harbor Symposia on Quantitative Biology 21 (1956): 197-216.\n- Ding Y., et al. “Natural courtship song variation caused by an intronic retroelement in an ion channel gene”. Nature7616 (2016): 329-332.\n- Kapitonov VV and EV Koonin. “Evolution of the RAG1-RAG2 locus: both proteins came from the same transposon”. Biology Direct 10 (2015): 20.\n- Quesneville H., et al. “Recurrent recruitment of the THAP DNA-binding domain and molecular domestication of the P-transposable element”. Molecular Biology and Evolution 3 (2005): 741-746.\n- Sinzelle L., et al. “Molecular domestication of transposable elements: from detrimental parasites to useful host genes”. Cellular and Molecular Life Sciences 6 (2009): 1073-1093.\n- Rawn SM and JC Cross. “The evolution, regulation, and function of placenta-specific genes”. Annual Review of Cell and Developmental Biology 24 (2008): 159-181.\n- Rebollo R., et al. “Jumping genes and epigenetics: Towards new species”. Gene 1-2 (2010): 1-7.\n- Kidwell MG., et al. “Hybrid Dysgenesis in DROSOPHILA MELANOGASTER: A Syndrome of Aberrant Traits Including Mutation, Sterility and Male Recombination”. Genetics 4 (1977): 813-833.\n- Petrov DA., et al. “Size matters: non-LTR retrotransposable elements and ectopic recombination in Drosophila”. Molecular Biology and Evolution 6 (2003): 880-892.\n- Boulesteix M., et al. “Insertion polymorphism of transposable elements and population structure of Anopheles gambiae M and S molecular forms in Cameroon”. Molecular Ecology 2 (2007): 441-452.\n- Barnes MJ., et al. “SINE insertion polymorphism on the X chromosome differentiates Anopheles gambiae molecular forms”. Insect Molecular Biology 4 (2005): 353-363.\n- Gonzalez J and DA Petrov. “The adaptive role of transposable elements in the Drosophila genome”. Gene2 (2009): 124-133.\n- Abraham EG., et al. “Towards the genetic control of insect vectors: An overview”. Entomological Research 4 (2007): 213-220.\n- Rubin GM and AC Spradling. “Vectors for P element-mediated gene transfer in Drosophila”. Nucleic Acids Research 18 (1983): 6341-6351.\n- Handler AM. “Use of the piggyBac transposon for germ-line transformation of insects”. Insect Biochemistry and Molecular Biology 10 (2002): 1211-1220.\n- Lorenzen MD., et al. “Piggybac-mediated germline transformation in the beetle Tribolium castaneum”. Insect Molecular Biology 5 (2003): 433-440.\n- Genc H., et al. “Germline transformation of the olive fruit fly, Bactrocera oleae (Rossi) (Diptera: Tephritidae), with a piggyBac transposon vector”. Turkish Journal of Biology4 (2016): 845-855.\n- Koukidou M., et al. “Germ line transformation of the olive fly Bactrocera oleae using a versatile transgenesis marker”. Insect Molecular Biology 1 (2006): 95-103.\n- Chu F., et al. “Germline transformation of the western corn rootworm, Diabrotica virgifera virgifera”. Insect Molecular Biology 4 (2017): 440-452.\n- O'Brochta DA., et al. “Hermes, a functional non-Drosophilid insect gene vector from Musca domestica”. Genetics3 (1996): 907-914.\n- Ben Amara W., et al. “A genomic survey of Mayetiola destructor mobilome provides new insights into the evolutionary history of transposable elements in the cecidomyiid midges”. PLoS One10 (2021): e0257996.\n- Klai K., et al. “Screening of Helicoverpa armigera mobilome revealed transposable element insertions in insecticide resistance genes”. Insects 12 (2020): 879.\n- Zidi M., et al. “Genome-Wide Screening of Transposable Elements in the Whitefly, Bemisia tabaci (Hemiptera: Aleyrodidae), Revealed Insertions with Potential Insecticide Resistance Implications”. Insects 5 (2022): 396.","Transposable elements (TEs) are consistently demonstrated in their contribution to genetic instability and human disease. TEs can cause human disease by creating mutations insertion in genes, deletion in a gene, and also be contributing to genetic instability through non-allelic homologous recombination and introduction of sequences that involve into various cis-acting signals that alter gene expression. The currently active human transposable elements are members of the non-LTR retroelement families, LINE-1, Alu (SINE), and SVA. The impact of germline insertional mutagenesis by TEs is well established, whereas the rate of post-insertional TE-mediated germline mutations and all forms of somatic mutations remain less well determined. The number of human diseases discovered to be associated with non-allelic homologous recombination between TEs, and particularly between Alu elements, is growing at an exceptional rate. Improvement in the technology for detection of such events, as well as the mounting interest in the research and medical communities in resolving the underlying causes of the human diseases with unknown etiology, explain this increase. Here, we focus on the most recent advances in the understanding of the impact of the active human TEs on the stability of the human genome and its relevance to human disease.\nEssay due? We'll write it for you!\nThe process of changing the DNA in a genome that will consider is transposition, which is the movement of DNA from one location to another. Segments of DNA with this ability to move are called transposable elements. Transposable elements were formerly thought to be found only in a few species, but now they are recognized as components of the genomes of virtually all species. In fact, transposable elements occupy approximately half the human genome and a substantially greater fraction of some plant genomes. Transposons or ‘jumping genes’ are DNA sequences that can shift or switch their positions within the genome (Genetic recombination) and point in the future; they can generate or backward mutation and cell identity and function. Recombination occurs at the ends of the transposons between DNA sequences.\nA large portion of the eukaryotic genome has been constructed by Transposons. Transposable elements can cause deletions or inversions of DNA. When transposition generates two copies of the same sequence in the same orientation, recombination can delete the DNA between them. If the two copies are in the opposite orientations, recombination will invert the DNA between them. Kazazian et al. (1988). discovered that hemophilia A resulted from a de novo insertion of a TE. This study was one of the first to indicate that a TE insertion in the human genome caused disease. A new interest in the function of TEs has resulted in part from large-scale genomic projects, such as the encyclopedia of DNA Elements (ENCODE) and Functional Annotation of Mouse (FANTOM) projects. These studies showed that TEs are active in a highly cell atype-specific manner and control their own cell-specific transcription as well as the transcription of neighboring genes.\nFinally, the advent of next-generation whole-genome sequencing approaches has identified major structural variation resulting from TE activity. Transposable elements (TEs) occupy almost half, 46%, of the human genome, making the TE content of the human genome is one of the highest among mammals. The human genome contains two major classes of TEs, DNA and RNA transposons, defined by the type of molecule used as an intermediate in their mobilization. In this article, we discuss the disease occurred by transposons element.\nHemophilia is a genetic disorder, which disables the body’s blood clotting ability. Hemophilia patients lack a protein called ‘clotting factor’ that results in excessive blood loss or inappropriate blood clotting. These factors clot blood through acting along platelets. As bleeding is not under control or bleed for a long time it may be life-threatening and can cause joint pain and joint bulging.\nMainly two types of Hemophilia- Hemophilia A and Hemophilia B.\nHemophilia A: Hemophilia A or ‘Classic Hemophilia’ is the most typical form of Hemophilia, which lacks the clotting factor VII.\nHemophilia B: Hemophilia B or ‘Christmas Disease’ lack clotting factor IX.\nThis disease is genetically X-linked recessive. As males have XY chromosomes (from mother X and Y from father) they become affected by this disease and their son will not be affected. On the other hand, Females have XX chromosomes (from father and mother), if they have one affected X chromosome, they become carrier because they have one healthy X chromosome that produces enough clotting factors and passes this to her next generation (both son and daughter).\nTransposons that are responsible for Hemophilia, show cut and paste mechanism. Here transposon acts as a vector in the plasmid. Transpose binds and cuts the transposon on the two direct repeats of the inverted terminal repeats. The transposon cut out from the plasmid is inserted into a chromosomal DNA or target DNA and on the other hand, the donor plasmid is repaired.\nHemophilia A disease is caused by ‘L1 sequence’ insertion (Long Interspersed Element Sequencing) and Hemophilia B is caused by ‘Sleeping Beauty’ transpose.\nDirect Vector Therapy\nThis therapy works by directly introducing a vector into the patient’s body. AAV (Adeno-associated virus) vectors are used successfully by introducing it into the liver, which carries encode clotting factor. For example ‘Desmopressin’ hormone is injected into the patient’s body to prevent Hemophilia A, by inducing the blood clotting factors.\nIn this method cells with clotting factors expression ability are transplanted to patients. As a result, the clotting factors spread in the bloodstream of the patients. For example, Mesenchymal stem cells with clotting factors can be used to treat Hemophilia Arthropathy. Mesenchymal stem cells are derived from adipose tissue or bone marrow to prevent knee joint bleeding.\nPorphyria is a bunch of disorders induced by deformities in the biochemical (enzymatic) pathways related to heme production.\nThere are various types of Porphyria like-\nAcute, Nervous system\nHepatic, Liver Cancer\nMutations in one of these genes cause each form of Porphyria-\nALAD, ALAS2, CPOX, FECH, HMBS, PPOX, UROS or UROD.\nBut the Uroporphyrinogen decarboxylase mutation rate is much higher in human (20%). Transposable element (Alu element) inserted itself to the UROD gene and causes replication, transcription, and inactivation of the gene which results in limit the enzyme activity and reduce the heme production in the human body and causes Acute Porphyria.\nThe treatment of each type of Porphyria is different. A patient needs to take Panhematin or Glucose injection. Acute Porphyria can be treated by gene therapy.\nA single intravenous injection which ranges between 5 × 1011 to 1.8 × 1013 genome copies/kg, of the vector introduced to four groups of two patients. Evaluation of the variation and result in urinary PBG and ALA and clinical periods of disease take place before and later the treatment. Investigation needed for viral aberration, vector prohibition by immune reaction and existence of vector in liver.\nGene can be delivered into a system by two ways that are nonviral and viral transformation. Sleeping beauty is a nonviral transposon that defined designed DNA sequences into the chromosomes of vertebrate.(5) The purpose is introduced new traits and gene into animals. Sleeping beauty is used for gene therapy and that can be used to treat cancer. PT4 vector and SB100X (Schorn and Ivics, unpublished data, 2010) is the lastest engineering transposon that have improved architecture compared with older version.\nThe Sleeping Beauty (SB) Transposon System. (A) Autonomous transposable elements comprise terminal inverted repeats (TIRs, black arrows) that flank the transposase gene (orange). (B) A bi-component, trans-arrangement transposon vector system for delivering transgenes that are maintained in plasmids. One component contains a gene of interest (GOI, yellow) between the transposon TIRs carried by a plasmid vector, whereas the other component is a transposase expression plasmid, in which the black arrow represents the promoter driving expression of the transposase. (C) The transposon carrying a GOI is excised from the donor plasmid and in integrated at a chromosomal site by the transposase. (D) Plasmid-based transposon cassettes can be mobilized by transposase supplied as in vitro-transcribed mRNA.\nSB transposon system delivered into cells with two components of the vector system. SB11 transposase used for the in vitro transcription reactions, here cell line replaced by the plasmid to synthesized mRNA. Nucleofection with plasmid DNA have much more cellular toxicity compared with primary human T cells, including Hematopoietic stem cells (HSCs) a T cells with mRNA. Non viral gene Transfer have advantage over other methods such as cost and complexity. Modified T cells that expressing the CD19 specific CARs culture needs 4 weeks. The activating and propagating cells derived from k-562 cell line that are genetically modified to express target CD19 antigen. The current protocol gives it under 14 days that have so much benefit including the younger T cells and improve the therapeutic effects. The plasmids contain the SB is deliver to the T cell by electrophoresis.\nGene delivery application at first carried out in vivo. Therapeutic nucleic acid injected directly into the body. Here is a challenge to deliver the transposon vector because unlike viruses the nucleic acids are naked and lack the capacity to pass through the cell membrane so that combine transposon vector with advance technologies deliver the nucleic acids efficiently.\nIn ex vivo the gene delivery of the SB system used a donor and collection of some isolated cell population form the donor. Then engineered T cells that express CAR are transplant into the patient. Transposition efficiency depend on the uptake of nucleic acids by the cells. The modified T cells with nonviral SB is used in the treatment of CD19+ hematologic cancers. Clinical application of the process is deliver to the patients test with advance B-lineage, CD19+ acute leukemia and lymphoma. Modified T cells and 2nd generation CARs give 90% response rate to treat this disease. Nucleofection of transposition facilitate the CD34+ HSCs, human embryonic stem cells humanT cells to potential treatment of genetic disorders such as treatment of hematologic disorders, lysosomal storage diseases, pulmonary disorders, dermatologic diseases, a variety of metabolic disorders, neurologic disorders, muscle disorders, and cancer.\nTE activity can generate a wide-spectrum of genomic mutation to gross rearrangements with gain of genomic information, as well as interference with normal gene processing and expression after insertion. These mutations contribute to idiopathic human disease. Computational analysis & experimental outcomes suggests that roughly 700 novel transposable element insertion events takes place due to Alus, L1 & SVA in single diploid genome. TE plays role in structural variance. Characterization of TE to study potential functional consequences.Understanding of mechanism & regulation of TE is not fully understood.\nDisclaimer: This essay has been submitted by a student. This is not an example of the work written by our professional essay writers. You can order our professional work here.\nSorry, copying is not allowed on our website. If you’d like this or any other sample, we’ll happily email it to you.\nYour essay sample has been sent.\nWant us to write one just for you? We can custom edit this essay into an original, 100% plagiarism free essay.Order now\nWhen studying art history, it is imperative to look into Roman architecture. The Romans have managed to create a new life for themselves with what little tools and technology they had. In this essay we will look at four examples of how they have advanced…\nIn 1908, the Hardy-Weinberg Theorem was introduced in evolutionary genetics. It postulates about the population equilibrium that occurs in an infinitely large population. The population has to not only be large, but it also has to have a randomness factor that comes from random mating….\nA number of methods can be used in hypnotic memory retrieval. Since a positive relationship is a prerequisite for success, it is important to develop rapport with the subject at the onset. A helping and supportive attitude is, generally, appreciated by a forensic hypnotist. However,…\nParticulate pollution has been increasing over the past few years. Industries has been trying to develop new methods and devices to remove particles from exhaust gas. Cyclone separator is a device with no moving parts is used to separate dust particles from exhaust gas. But,…\nRecently, the rise of petroleum consumption in industrial, transportation and technology developments has been leading to depletion of the limited fossil fuel resources in the world. Because of this, researchers have been putting more attention to find alternative energy such as biodiesel which is believed…\nFrom past few decades, Lenovo has been launching highly-intuitive and user-friendly laptops for businesses and Lenovo ThinkPad X1 Carbon (6th Gen) is one of the finest inventions. It is dominating the business world today as it provides everything you would ever need in a laptop….\nRISC Processor is expanding wide utilized in each field. Most PC contribute the present market depends on either diminished guideline set computer – architecture (Reduced Instruction Set Computer) or CISC (Complex Instruction Set Computer) design advances. The diminished direction set computer – architecture engineering support…\nNowadays, smartphones are becoming more and more popular. Everyone is very concerned about the fever of mobile phones when using smartphones. As a kind of electronic products, it is obviously unrealistic to say that it is completely uncomfortable to completely suppress the fever of smart…\nВ-retaining ring (Diana’s electric ring, continuous transmission of electric power transmission, with the fixed spirals of control and data member rotating is towards the rotation of the rotor through the friction rings.) and the electric rotor through contact contact brushes. We also make brushes with…\nThe ability to see true beauty formed from the earth is one of the few penniless pleasures the world has to offer. Sculpted from high speed winds or shaped from running water the earth has learned to evolve. Living on a planet whose timescale measures…\nThe technology Readiness Index (TRI), a 36-object scale to measure technological know-how readiness defined as propensity to embody and use new technologies for carrying out pursuits in dwelling lifestyles and at work was released over a decade ago. Similar technology-prompted growth tendencies are evident in…\nThe introduction of agriculture into the military can be traced way back in 19th century. During the decade that followed the war of 1812 between America and Britain, the military frontier proceeded the settlers frontier in the Missouri Valley, and for a time soldiers became…"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:2e49dd45-5ae4-43f1-bf32-c16cbd5009e7>","<urn:uuid:88074a06-ffe9-4534-85ec-4121ee142b9b>"],"error":null}
{"question":"Could you compare the environmental impact of nuclear energy versus fossil fuels, particularly regarding radiation and emissions?","answer":"Nuclear energy and fossil fuels have significantly different environmental impacts. While fossil fuels release harmful substances including carbon monoxide, carbon dioxide, and other toxins when burned (contributing to 79% of US carbon emissions), nuclear energy is actually one of the most environmentally friendly forms of power generation. Interestingly, nuclear power puts less radiation into the environment than fossil fuels - coal contains radioactive elements thorium and uranium, and when burned, produces fly ash, making coal the major source of radioactive releases. However, nuclear energy does have some environmental drawbacks: uranium mining releases arsenic and radon, and nuclear plants cause thermal pollution in water bodies used for cooling reactors. Additionally, nuclear plants produce radioactive waste that remains hazardous for thousands of years, though this waste can be safely stored and recycled.","context":["Energy is the ability to do work.\nEnergy can take many forms, including heat, light, and motion. It can also take the form of electrical, chemical, nuclear, and gravitational energy.\nEnergy can be potential (stored) or kinetic\nWe use energy for everything we do. Running, cooking, and flying an airplane all require energy.\nAn energy source is a source from which energy can be obtained. Most energy sources are also natural resources – naturally occurring materials that are valuable to people and/ or wildlife. Ultimately all energy on Earth is derived from the sun.\nThere are renewable and nonrenewable energy sources. A renewable energy source is naturally replenished over reasonable geologic time (i.e. tens of years). Some examples include solar energy, wind energy, energy from biomass (plant sources), and hydropower.\nA nonrenewable energy source is a source that cannot be replaced in reasonable geologic time. Fossil fuels like coal, oil, and natural gas are nonrenewable. The Uranium used to produce nuclear power is also classified as a nonrenewable energy source. It would take millions of years to recreate these energy sources.\nFossil fuels are found deep underground and are generated naturally from decaying plant and animal material exposed to heat and pressure over millions of years.\nMost of the energy used in the United States, the energy used to power homes, fuel our cars, and produce our goods, comes from nonrenewable energy resources. Renewable energy accounts for only about 7% of our total energy supply.\nWhen fossil fuels are burned for energy, they release harmful substances, including carbon monoxide, carbon dioxide, and other toxins into the air.\nThe carbon dioxide released into the atmosphere from the burning of fossil fuels is a source of global warming. Global warming, the increase in the average temperature of Earth’s air and oceans, is creating global climate change and environmental shifts around the world.\nExcess carbon dioxide in the atmosphere is also the cause of ocean acidification, the ongoing decrease in the pH level of the world’s oceans.\n79% of US carbon emissions come from the burning of fossil fuels.\nSulfur dioxide is also produced by burning fossil fuels. When released into the atmosphere, it causes acid rain and human health problems. Acid rain, or rain with a low pH, negatively impacts terrestrial (land) and aquatic (water) ecosystems.\nWe can decrease the environmental problems associated with the burning of fossil fuels by decreasing our energy consumption.\nScientists are currently developing methods for obtaining energy from clean, renewable energy sources. In the future, we will derive more of our energy from wind, tides, plants, and the sun.\nEnergy Use in Florida:\nFlorida’s energy consumption is one of the highest in the country due to frequent air conditioning use.\nOn average, each Florida resident burns enough fossil fuel to produce 15 tons of carbon per year on average.\nThe state of Florida has plans to produce ethanol, a type of alcohol similar to rubbing alcohol, from citrus as a renewable energy source.\nPractice Good Stewardship:\nConserve energy by turning out lights when you are not using them, watching less TV, and taking shorter showers.\nRecycle. It almost always requires less energy to recycle than to create a new product. By using materials more than once, we conserve energy and natural resources.\nPlant a tree. Plants consume carbon dioxide through the process of photosynthesis. By planting a tree, you’ll help reduce the amount of harmful excess carbon dioxide in our atmosphere.\nReprinted from the Coastal Classroom\nPhoto courtesy of the Sierra Club","Pros & cons of nuclear energy: is it safe?\nPeople often associate nuclear energy with nuclear bombs, or tragedies like Chernobyl or Fukushima. If this is your impression or image of nuclear power, you will be surprised to learn that nuclear energy is actually considered one of the most environmentally friendly forms of power generation. If you compare nuclear energy with other forms of energy generation, it is much more efficient than any other form and is actually considered one of the most environmentally friendly means of energy production available.\nThere are of course, many challenges associated with producing nuclear energy including initial cost, waste, security, safety, and more. Here are the main pros and cons associated with nuclear energy.\nWhat is Nuclear Energy?\nBefore going forward, let’s quickly define nuclear energy and how it’s created. Nuclear energy is created by splitting uranium atoms. When atoms are split they become 2 smaller, lighter atoms and because energy doesn’t just disappear, the “lost” mass is converted into heat. This heat is then used to produce electricity. Nuclear power plants create a controlled environment for this process.\nPros of nuclear energy\n- Nuclear energy protects air quality\nNuclear energy is the largest source of clean energy in the world. It produces about 800 billion kilowatt hours of electricity each year and produces 50% of the nation’s emissions-free electricity. This avoids over 470 million metric tons of carbon every year, which is like taking 100 million cars off the road.\n- Nuclear energy’s operating costs are low\nOnce a nuclear plant is built, the cost of producing electricity is much less than gas, coal or oil unless those fossil fuels are located very close to their power plant. Nuclear energy also has a comparatively low risk of price inflation. This is because less factors affect the price, as opposed to fossil fuels which are affected by a multitude of factors and their prices vary wildly.\n- Nuclear energy uses considerably less land\nNuclear power is incredibly efficient at producing electricity and because of this, it requires significantly less space than any other clean source.\nA standard 1,000 megawatt nuclear facility in the United States needs slightly more than 1 square mile to operate. Per the Nuclear Energy Institute (NEI) wind farms require about 360 times more land to produce the same amount of electricity and solar plants require 75 times more space.\n- Nuclear energy is the most reliable energy source in America\nNuclear power plants were able to run at full capacity more than 92% of the time and generated 20% of U.S. electricity last year. To put this in perspective nuclear operated at full capacity 336 out of 365 days last year (the 29 days off were for standard maintenance). In contrast, hydroelectric systems were running 38.2% of the time (138 days a year), wind turbines produced 34.5% of the time (127 days a year), solar arrays only generated electricity 25.1% of the time (92 days a year), and fossil fuels were active about 50% of the year. Nuclear is the clear winner on reliability.\n- Nuclear power puts less radiation into the environment than any other major source\nMost people don’t know that non-nuclear energy sources release radiation into the environment. The worst offender is actually coal which contains radioactive elements thorium and uranium. When coal is burned, its organic materials gasifies and its mineral components concentrate into waste. This waste is called fly ash. Since so much coal is burned all over the world, which produces so much fly ash, coal is actually the major source of radioactive releases into the environment.\n- Disposing nuclear waste is no longer a technological problem\nThe disposal of nuclear waste is a political problem in the U.S., not a technological one. Over 90% of the spent fuel in the U.S. could be recycled and used to extend nuclear power production for hundreds of years. Instead of doing this, it sits safely in impenetrable concrete and steel dry casks on the grounds of active reactors, slowly losing its radiation.\nIn New Mexico, the U.S. Waste Isolation Pilot Plant (WIPP) stores transuranic military waste and it could store commercial nuclear waste in its 2-kilometer thick bed of crystalline salt. The salt formation extends from southern New Mexico all the way to southwest Kansas. This could easily hold the entire world’s nuclear waste for 1000 years.\nTo put this in perspective, we could take all of the fuel used by the U.S. over the last 60 years and fit it in a football field about 10 yards deep.\nCons of nuclear energy\n- Nuclear plants are extremely expensive to build\nEven though they are relatively cheap to operate, nuclear plants are very, very expensive to build and are getting more expensive. The cost to build a nuclear power plant has risen from $2-$4 billion to $9 billion and construction often exceeds estimates. Nuclear plants must also set aside funds to build structures to protect and secure nuclear waste produced.\n- Risk of nuclear accidents\nEven though nuclear power plants have extremely strict measures in place to prevent accidents, they obviously do occur. Such accidents can cause radiation to leak which can lead to serious health complications or death and serious environmental damage.\nHowever, as technology advances, the negative effects are minimized and studies show that even if you account for catastrophes like Chernobyl fossil fuels are substantially more deadly.\n- Environmental Impact\nThough the actual production of electricity doesn’t produce emissions, the process of mining the uranium needed isn’t clean. The mining of uranium is known to release arsenic and radon to surrounding areas.\nNuclear power plants also cause thermal pollution. Most nuclear plants are located on a lake or ocean as they need water to cool their reactors. The body of water is used to condense steam back into water.\nThis process causes the water to heat up to around 100 degrees Fahrenheit. If this hot water is immediately released back into the body of water it can significantly change the chemistry and make it inhabitable to most aquatic life.\n- Radioactive waste\nThe waste produced by nuclear plants is radioactive and remains so for thousands of years. This waste needs to be safely stored and ideally recycled. There is also the potential for a leak which could cause damage to surrounding areas.\n- Nuclear is not currently renewable\nIf you account for all known uranium deposits and current consumption we have about 200 years of uranium left. If you account for recycling used fuel that number would increase by hundreds of years.\nThe future of nuclear energy\nThere are clear arguments that support both sides of the nuclear debate. But as technology advances nuclear energy could be a key factor in helping us achieve 100% clean energy in the future.\nAnother thing to keep in mind is if nuclear fusion can be achieved, it would supply nearly limitless clean energy."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:b1d37d6a-064b-476a-b40c-488098580228>","<urn:uuid:2d7ca715-9852-4971-9a32-a9c57cdb9a9a>"],"error":null}
{"question":"What's the role of physical therapy in recovering from ankle injuries versus hip fractures? How does the approach differ?","answer":"Physical therapy plays a crucial role in both conditions but with different focuses. For ankle injuries, physical therapy emphasizes range of motion exercises to loosen stiff ankles and stretching exercises for calf muscles to prevent reinjury. The goal is to strengthen weak muscles surrounding the ankle joint and restore mobility. For hip fractures, physical therapy begins after ORIF surgery and focuses on a broader exercise regimen to restore muscle strength, flexibility, and range of motion throughout the hip and leg. Additionally, hip fracture patients receive specific instructions on weight-bearing activities and posture management. Both conditions require careful progression of exercises, but hip fracture rehabilitation typically involves a more comprehensive and structured approach due to the severity of the injury and surgical intervention.","context":["Posts for: January, 2018\nFollowing an ankle injury or ankle surgery, you’ll inevitably lose some strength and range of motion from being immobilized for an extended period of time. A weak ankle can hinder normal mobility, and even lead to another injury. So what can you do to strengthen your ankle and get back to your old self again?\nStrengthening Your Ankle\nYour ankle or leg may feel stiff, especially if your treatment required wearing a cast or a walking boot. Stiffness and instability are common symptoms following an ankle injury that will need to be addressed in order to get you back to your normal range of motion and activity level.\nYour podiatrist may recommend post-injury physical therapy or home exercises that will help you strengthen weak muscles surrounding the ankle joint and restore mobility to lower your risk of reinjury. These include range of motion exercises for the injured ankle, which help loosen stiff ankles, and stretching exercises for the calf muscles, which help decrease your risk of hurting your ankle again. As with all exercises, progress slowly and discontinue if painful. Pain is most certainly not gain when it comes to physical therapy!\nChoosing the Right Shoes\nThe shoes you wear will also play an important role in protecting your injured ankle and restoring your mobility. Supportive shoes will provide more comfort, better balance and help stabilize the weak ankle to prevent re-injury. Stay off high heels or flats and flip flops without support until your ankle is completely mended.\nProper care and rehabilitation following an ankle injury is critical to ensure your ankle fully heals. Always consult your podiatrist if ankle pain or stiffness persists or worsens and before starting any new exercise program.\nChronic ankle instability is a condition characterized by a recurring \"giving way\" of the outer side of the ankle. It most often develops following an ankle sprain. When the stretched or torn ligaments do not heal properly or completely, ankle instability is often the result.\nIf you have chronic ankle instability, you may find it difficult to walk on uneven surfaces. Other symptoms include a repeated turning of the ankle during physical activity, tenderness and persistent discomfort and swelling.\nHow Can I Treat My Ankle Instability?\nTreatment for an unstable ankle will depend on the degree of instability. Bracing, medication and physical therapy are all conservative treatment options that may help strengthen your weakened ankle. Often patients with ankle instability can be treated without surgery by strengthening the muscles that control the ankle joint, avoiding or limiting high impact activities and using a supportive brace to decrease the risk of recurrent ankle sprains.\nIn severe cases, or when conservative treatments aren’t successful, your podiatrist may recommend surgery, which involves repair or reconstruction of the damaged ligaments.\nIf your ankle feels unstable or if you have had recurring ankle sprains, visit your podiatrist for an evaluation. Left untreated, chronic ankle instability leads to activity restrictions, tendon complications, arthritis and continued instability. Your podiatrist can provide a recommended treatment plan based on the severity of your instability, so that you can get back to the activities you enjoy!","Hip Fracture ORIF\nWhat is a Hip Fracture?\nA hip fracture is a break that occurs near the hip in the upper part of the femur or thighbone. The thighbone has two bony processes on the upper part - the greater and lesser trochanters. The lesser trochanter projects from the base of the femoral neck on the back of the thighbone. Hip fractures can occur either due to a break in the femoral neck, in the area between the greater and lesser trochanter or below the lesser trochanter.\nWhat does ORIF mean?\nOpen reduction and internal fixation (ORIF) is a surgical technique employed for the treatment of a fracture to restore normal anatomy and improve range of motion and function.\nThe hip joint is a “ball and socket” joint. The “ball” is the head of the femur or thigh bone, and the “socket” is the cup-shaped acetabulum. It enables the upper leg to bend and rotate at the pelvis. The joint surface is covered by a smooth articular surface that allows pain-free movement in the joint.\nCauses of Hip Fractures\nHip fractures are most frequently caused after minor trauma in elderly patients with weak bones and by high-energy trauma or serious injuries in the young. Long term use of certain medicines, such as bisphosphonates to treat osteoporosis (a disease causing weak bones) and other bone diseases, increases the risk of hip fractures.\nSigns and Symptoms of Hip Fractures\nThe signs and symptoms of hip fractures include:\n- Pain in the groin or outer upper thigh\n- Swelling and tenderness\n- Discomfort while rotating the hip\n- Shortening of the injured leg\n- Outward or inward turning of the foot and knee of the injured leg\nMost often your physician can determine that you have sustained a hip fracture based on the abnormal position of your hip and leg and your symptoms. Your physician normally will order an X-ray to confirm the fracture and its position. If the X-ray fails to reveal the fracture, then an MRI or bone scan may be ordered to confirm the presence of a hairline fracture.\nPreparation for ORIF Surgery\nSince ORIF is often employed to treat severe fractures, it typically takes place as an emergency procedure. Prior to surgery, you may have:\n- A physical exam to inspect blood circulation and nerves affected by the fracture\n- X-ray, CT scan, or MRI scan to assess surrounding structures and broken bone\n- Blood tests\n- Depending on the type of fracture you have sustained, you may be given a tetanus shot if you are not up-to-date with your immunization\n- A discussion with an anesthesiologist to determine the type of anesthesia you may undergo\n- A discussion with your doctor about the medications and supplements you are taking and the need to stop any\n- A discussion about the need to avoid food and drink past midnight the night prior to your surgery\nTreatment for Hip Fractures\nOpen reduction and internal fixation is a procedure most commonly used to treat severe hip fractures.\nThe surgery is performed under sterile conditions in the operating room under general anesthesia.\n- After sterilizing the affected area, your surgeon will make a cut through the skin and muscle of the thigh.\n- Your surgeon will locate the fracture by carefully sliding in between the muscles of the thigh.\n- Your surgeon will put the fragments of your femur back into position (reduction).\n- Your surgeon will secure the fragments of the femur to each other (fixation) by using metal plates, screws, wires, or pins.\n- For a fracture in the middle of your femur, your surgeon may utilize a specially designed metal rod that passes through the middle of the bone and screws into both ends of the bone.\n- Your surgeon may also carry out any other repairs if required.\n- After securing the bone, your surgeon will close the incisions by suturing or staples and cover with sterile dressings.\nPost procedure, you may notice significant pain and pain medication will be prescribed by your physician to keep you comfortable. You may need to take a blood thinner to prevent blood clots. To ensure that the surgery was successful, you will probably have X-rays done.\nYou will be given instructions on weight-bearing activities and posture management. You will be instructed about dressing and incision care. You will also be advised on diet and supplements high in vitamin D and calcium to promote bone healing. Physical therapy and an exercise regimen are suggested to restore muscle strength, flexibility, and range of motion.\nDepending on your health condition and the extent of the injury, you may be able to go home the same day with scheduled follow-up appointments for monitoring progress and stitches or staples removal if required. Most people return to their normal activities within 4 to 6 months of the surgery.\nRisks and Complications of Hip Fracture ORIF\nAs with any surgery, some of the potential risks and complications of open reduction and internal fixation of a hip fracture include:\n- Blood clots\n- Damage to nerves and blood vessels\n- Anesthetic complications\n- Hardware irritation\n- Fat embolism\n- Nonhealing of the fracture\n- Broken hardware"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:547b5a10-eaf6-4b29-8d66-61b984ca1b23>","<urn:uuid:df3fd091-4fa9-4e4f-8141-ff5dafa45e55>"],"error":null}
{"question":"What are the emerging technological innovations in speech therapy delivery, and what are the associated privacy and practical limitations to consider?","answer":"Emerging technological innovations in speech therapy include AI-driven speech recognition technology for analyzing speech patterns, virtual reality simulations for practice scenarios, speech therapy apps for skill development, and telepractice platforms for remote therapy delivery. These innovations are complemented by potential future developments in augmented reality, wearable devices, and biometric sensors. However, there are important limitations to consider, including privacy concerns particularly when sessions are conducted in public places or using potentially unsecure technology, technical difficulties that can disrupt sessions, and limitations in capturing nonverbal cues that may be crucial for accurate assessment and treatment.","context":["In the evolving world of healthcare technology is playing a role in transforming different aspects of patient care. One area that has seen advancements is speech therapy, where technology is empowering individuals with communication challenges to overcome obstacles and achieve their potential.\nThis article explores how technology is revolutionizing speech therapy and its role in empowering communication.\nUnderstanding Speech Therapy\nSpeech therapists or speech language pathologists (SLPs) work with individuals across all age groups to enhance their communication skills and improve their quality of life.\nDefining the Field of Speech Therapy\nSpeech therapy also referred to as speech language pathology is a branch of healthcare dedicated to diagnosing and treating communication disorders. These disorders encompass a range of conditions that affect speech, language, voice modulation and swallowing abilities.\nScope of Practice\nSpeech therapists conduct evaluations to assess and diagnose communication disorders comprehensively. Based on these evaluations they develop personalized treatment plans tailored to each individuals needs and goals.\nTreatment approaches may involve a combination of techniques, exercises and strategies aimed at addressing areas of difficulty such as articulation, comprehension, fluency, in language usage, voice projection or swallowing function.\nThe Conventional Method of Speech Therapy\nDuring these therapy sessions SLPs engage individuals in a range of activities and exercises that aim to target their communication goals and promote skill development.\nIn Person Therapy Sessions\nTraditionally speech therapy has been provided through face, to face sessions with a Speech Language Pathologist (SLP). These sessions usually occur in settings like hospitals, rehabilitation centers, schools or private practices.\nChallenges Faced by Traditional Therapy\nWhile traditional in person therapy has proven effective for people it does come with its set of challenges.\nAccessibility might be limited for individuals residing in areas or those facing mobility issues. Moreover scheduling conflicts, transportation barriers and financial constraints can pose obstacles to accessing speech therapy services.\nThese challenges underscore the importance of exploring approaches to deliver speech therapy\nThe Emergence of Technology in Speech Therapy\nThis approach allows individuals to access therapy comfortably from their homes while eliminating barriers and enhancing convenience.\nIntroduction to Telepractice\nAdvancements in technology have paved the way for telepractice referred to as teletherapy or online speech therapy. Telepractice involves providing speech therapy services remotely using telecommunication technologies such as video conferencing platforms.\nBenefits of Telepractice\nTelepractice offers advantages, for both therapists and clients.For speech therapists telepractice offers flexibility, in scheduling appointments. Managing their workload. It also helps in reducing travel time and overhead costs associated with maintaining an office space.\nFrom a clients perspective telepractice eliminates the need for traveling making therapy more accessible and convenient. Additionally it allows individuals to receive services from therapists who may not be available locally.\nInnovative Technologies in Speech Therapy\nThe advancement of technology has led to the creation of speech therapy apps. These apps provide exercises, games and activities specifically designed to target communication goals.\nSpeech Therapy Apps\nUsers can engage in articulation practice language skill improvement, voice control exercises and fluency enhancement through activities. Speech therapy apps offer individuals an accessible way to supplement their therapy sessions by practicing skills of formal therapy.\nVirtual Reality Therapy\nVirtual reality (VR) technology is increasingly being incorporated into online speech therapy interventions. VR simulations create environments where individuals can practice real life communication scenarios within controlled and safe settings.\nTherapists utilize this technology to develop environments that address each clients unique needs. This approach provides opportunities for targeted skill practice while enabling the application of learned skills, in real world situations.\nArtificial Intelligence (AI) Applications\nThe field of speech therapy is being transformed by the advancements in intelligence (AI). Intelligent software applications powered by AI are revolutionizing speech therapy practices.\nThese applications utilize AI driven speech recognition technology to analyze and evaluate a clients speech patterns providing feedback and guidance during therapy sessions.\nThey offer personalized learning experiences and adaptive training programs that adapt to an individuals progress and performance over time.\nFuture Directions in Technology and Speech Therapy\nThese advancements may bring about interventions, assessment tools driven by data and remote tracking of progress.\nContinued InnovationAs the world of technology advances, the future of speech therapy is filled with possibilities, for progress and innovation.\nCutting edge technologies like augmented reality (AR) wearable devices and biometric sensors have the potential to revolutionize how speech therapy is delivered.\nThe use of telepractice is expected to grow thanks to advancements in telecommunications technology and changes in healthcare delivery models. Teletherapy platforms are likely to become more advanced offering improved features and functionalities that support virtual therapy sessions.\nThis expansion will enhance access to speech therapy services for individuals in underserved areas or those with mobility or transportation options.\nIn conclusion, technology plays a vital role in empowering communication and transforming the field of speech therapy.\nFrom telepractice to tools and applications for therapy technology opens up avenues for enhancing accessibility achieving better outcomes and revolutionizing the delivery of speech therapy services.\nAs technology continues its evolution, the future of speech therapy holds promise for innovation, growth and an overall improvement in quality care.\nBy embracing the power of technology driven solutions speech therapists have the ability to empower individuals, in conquering communication obstacles and reaching their capabilities.","Teletherapy, or therapy conducted through videoconferencing or phone, has become increasingly popular in recent years, especially during the COVID-19 pandemic. As a result, many psychologists and psychotherapists may wonder whether teletherapy is as effective as traditional, in-person therapy. In this blog post, we will explore the research on the effectiveness of teletherapy and consider its benefits and limitations.\nThe Research on Teletherapy\nResearch on the effectiveness of teletherapy has been growing in recent years, and the findings suggest that it can be as effective as traditional, in-person therapy for many clients. A meta-analysis of 39 studies on the effectiveness of teletherapy for the treatment of mental health conditions found that it was as effective as traditional therapy for a range of disorders, including depression, anxiety, and PTSD (Cuijpers et al., 2019).\nSimilarly, a randomized controlled trial comparing in-person therapy to teletherapy for the treatment of depression found no significant differences in treatment outcomes between the two groups (Hubley et al., 2016). Additionally, a systematic review of the use of teletherapy for the treatment of PTSD found that teletherapy was an effective treatment option for this condition, with no significant differences in treatment outcomes between teletherapy and in-person therapy (Simpson et al., 2018).\nBenefits of Teletherapy\nTeletherapy has a number of benefits for both clients and therapists. These benefits include:\n1. Accessibility: Teletherapy can increase access to mental health services for those who live in rural or remote areas, have mobility issues, or have other barriers to accessing traditional, in-person therapy.\n2. Convenience: Teletherapy eliminates the need for travel, reducing the time and expense associated with attending in-person appointments.\n3. Flexibility: Teletherapy allows for greater flexibility in scheduling appointments, making it easier for clients to fit therapy into their busy schedules.\n4. Comfort: Many clients feel more comfortable participating in therapy from the privacy of their own homes, reducing anxiety and stress associated with attending in-person appointments.\n5. Cost-effectiveness: Teletherapy can be more cost-effective than in-person therapy, particularly when travel and other expenses are factored in.\nLimitations of Teletherapy\n1. Despite its benefits, teletherapy has some limitations that may impact its effectiveness for some clients. These limitations include:\n2. Technical difficulties: Teletherapy requires a reliable internet connection and the necessary technology (e.g., computer, smartphone, or tablet). Technical issues can disrupt therapy sessions and impact the quality of the therapeutic relationship.\n3. Limited nonverbal cues: Teletherapy can make it more difficult for therapists to pick up on nonverbal cues, which can impact the therapeutic relationship and the accuracy of clinical assessments.\n4. Limited therapeutic modalities: Some therapeutic modalities, such as touch-based therapies, are not possible through teletherapy, limiting the range of therapies available to clients.\n5. Privacy concerns: Teletherapy raises privacy concerns, particularly if sessions are conducted in public places or if the technology used is not secure.\nIn conclusion, the research suggests that teletherapy can be as effective as traditional, in-person therapy for many clients, and has a range of benefits. However, it also has some limitations that may impact its effectiveness for some clients. As such, psychologists and psychotherapists may want to consider teletherapy as an option for their clients, particularly for those who have difficulty accessing in-person therapy or who prefer the convenience and comfort of teletherapy. However, it is important to carefully consider the benefits and limitations of teletherapy and to ensure that clients have access to the necessary technology and support to participate in therapy effectively."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:3e6f81ff-aa6f-44e6-9fca-1c8d9058a97f>","<urn:uuid:9a953d8b-776c-4bb3-b1ee-2bbfa826492a>"],"error":null}
{"question":"What is the historical significance of the Topography of Terror museum in Berlin, and what protocols exist for protecting such culturally significant sites during times of crisis?","answer":"The Topography of Terror in Berlin is historically significant as it stands on the former site of the SS Reich Security Main Office and Gestapo headquarters during the Nazi regime from 1933 to 1945. The site features exhibitions detailing the history of Nazi repression, including the preserved cellar where political prisoners were tortured, and a section of the Berlin Wall. The museum, officially opened in 2010, now houses three permanent exhibitions documenting Nazi terror and Berlin's history during the Third Reich. Regarding protection protocols, the Association of Art Museum Directors (AAMD) has established guidelines for protecting such cultural sites during crises. These include offering safe havens for threatened artifacts, providing technical assistance and professional advice for protecting collections in situ, and ensuring proper documentation and storage of protected works. The AAMD supports the 1954 Hague Convention for the Protection of Cultural Property and encourages museums worldwide to collaborate in preserving cultural heritage threatened by war, terrorism, or natural disasters.","context":["Topography of Terror\nThe Topography of Terror (German: Topographie des Terrors) is an outdoor and indoor history museum in Berlin, Germany. It is located on Niederkirchnerstrasse, formerly Prinz-Albrecht-Strasse, on the site of buildings, which during the Nazi regime from 1933 to 1945 was the SS Reich Security Main Office, the headquarters of the Sicherheitspolizei, SD, Einsatzgruppen and Gestapo.\nThe buildings that housed the Gestapo and SS headquarters were largely destroyed by Allied bombing during early 1945 and the ruins demolished after the war. The boundary between the American and Soviet zones of occupation in Berlin ran along the Prinz-Albrecht-Strasse, so the street soon became a fortified boundary, and the Berlin Wall ran along the south side of the street, renamed Niederkirchnerstrasse, from 1961 to 1989. The wall here was never demolished. The section adjacent to the Topography of Terror site is the longest extant segment of the outer wall, as the longer East Side Gallery section in Friedrichshain was part of the inner wall, not visible from West Berlin.\nThe first exhibitions of the site took place in 1987, as part of Berlin's 750th anniversary. The cellar of the Gestapo headquarters, where many political prisoners were tortured and executed, was found and excavated. The site was then turned into a memorial and museum, in the open air but protected from the elements by a canopy, detailing the history of repression under the Nazis. The excavation took place in cooperation with East German researchers, and a joint exhibition was shown both at the site and in East Germany in 1989.\nIn 1992, two years after German reunification, a foundation was established to take care of the site, and the following year, it initiated an architectural competition to design a permanent museum. A design by architect Peter Zumthor was chosen. However, construction was stopped due to funding problems after the concrete core of the structure had been built. This stood on the site for nearly a decade until it was finally demolished in 2004 and a new building begun.\nThe construction of the new Documentation Center according to a prize-winning design by the architect Ursula Wilms (Heinle, Wischer und Partner, Berlin) and the landscape architect Heinz W. Hallmann (Aachen) was finished in 2010. The new Documentation Center was officially opened on 6 May 2010 by Federal President Horst Köhler on the occasion of the 65th anniversary of the end of World War II. The new exhibition and documentation building and the redesigned historic grounds were opened to the public on 7 May 2010.\nAfter the demolition of the ruins in the 1950s, the area was used as a bumper car site and a dumping ground for rubble from the renovation of Kreuzberg. The plans for a memorial site on the former site of the Gestapo goes back to 1978, when Berlin architecture critic Dieter Hoffmann-Axthelm was one of the first to note, in essays and surveys, the significance of the former site of the Gestapo, SD and RSHA headquarters.\nThe first exhibition on the site's history was created for the 750th anniversary of Berlin in 1987. The research continued after it, leading to a documentation centre that collected some more evidence for the terror of the National Socialists in Germany. In 1992, a foundation was created for the construction and maintenance of the centre with an associated permanent exhibition. The managing director is Rabbi Andreas Nachama.\nA tender in 1993 to design the museum complex was won by the Pritzker Prize-winning Swiss architect Peter Zumthor. Based on the temporary exhibition building, his design was likened to the skeleton of a barracks, allowing light through the glazed gaps in the concrete beams. Although critically acclaimed, the structure proved expensive to build and when the original contractor became insolvent in the middle of construction, no other contractor willing to continue the project for the fixed fee could be found. With the city of Berlin unwilling to pay an additional three to five million Euros for a reduced design and funding from the federal government delayed until more progress was achieved, the site was left with just the concrete stairwells of the design. Having spent 13.9 million Euros already, these were demolished, despite the protests of Zumthor and other architects, in 2004.\nArchitectural design competition 2005\nIn June 2005 a new architectural design competition was launched following the aborted partial construction of Zumthor's design. Out of 309 submitted and 23 chosen drafts, architect Ursula Wilms from the Berlin architects office Heinle, Wischer and Partner and landscape architect Heinz W. Hallmann from Aachen won in January 2006 the final round. The draft included a two-storey, ashlar-formed, paned building with an available surface of 3,500 square metres. For the construction around €15 million was available. Another five to nine million Euro was used for the interior and the redevelopment of the historical site. These costs were defrayed jointly by both the federal government and the federal state of Berlin, each contributing 50%. The architects estimated construction costs at a maximum of €20 million and a construction period of two years.\nThe construction was finished on time and the new building was opened to the public on 7 May 2010.\nThe open-air exhibition in the trench alongside the excavated segments of cellar wall on Niederkirchnerstraße (formerly Prinz-Albrecht-Straße) was retained and sheltered with glass. The room for the permanent exhibition is 800 cubic metres and presents the development and functions of the security apparatuses during the Nazi regime. A room for events at the back of the building can accommodate 200 participants. In the southern part of the area outside is a copse of robinias, the remains of \"Harrys Autodrom\" from the 1970s, whereas the rest of the open space is covered with greywacke. Around the flat-roofed building is a façade made of metal lamellae, which opens the building in a way that it is possible to look out of it to the surroundings anywhere on the ground floor of the building. In the basement is the seminar centre, the library with about 25,000 volumes, the memorial department and offices for 17 employees of the Topography of Terror Foundation.\nWith the inauguration of the new Documentation Center, three permanent exhibitions are open to the public. All three are presented bilingually in German and English.\nTopography of Terror. Gestapo, SS, and Reich Security Main Office on Wilhelm- and Prinz-Albrecht-Straße\nThe \"Topography of Terror\" permanent exhibition was shown in the open air until the new documentation center opened. The thoroughly revised and redesigned \"Topography of Terror\" permanent exhibition is presented over 800 square meters in the new building. The focus of the exhibition is the central institutions of the SS and police in the \"Third Reich\" as well as the crimes they perpetrated throughout Europe. Attention to the Nazi regime's many victim groups will assume a central place alongside the portrayal of the system of terror.\nBerlin 1933–1945 Between Propaganda and Terror\nA permanent exhibition about the capital Berlin during the \"Third Reich\" will be on display in the exhibition trench alongside the excavated segments of cellar wall on Niederkirchnerstraße (formerly Prinz-Albrecht-Straße). It will address National Socialist policy in Berlin and its consequences for the city and its population.\nTopography of Terror Site Tour. The History of the Site\nWith the opening of the new Documentation Center, the grounds of the \"Topography of Terror\" are once again completely open to the public. The site tour, which mainly follows the exposed building remnants, encompasses 15 stations. Informational signs provide an overview of the historic location and the site's use during the Nazi period and the postwar era. The tour also integrates remains of the Berlin Wall, which have been designated a historic monument.\nSpecial and temporary exhibitions\nThe Face of the Ghetto. Pictures taken by Jewish Photographers in the Litzmannstadt Ghetto 1940–1944\nThis special exhibition will be presented in the Topography of Terror Documentation Centre from 23 June 2010 on. It was developed by Dr. Ingo Loose and Dr. Thomas Lutz in cooperation with the State Archive in Łódź.\nThe \"House Prison\" at Gestapo Headquarters in Berlin. Terror and Resistance 1933–1945\nA bilingual German-English exhibition on the \"House Prison\" at the Gestapo Headquarters was shown in a special open-air exhibition area and included the 'ground memorial' including remains of former basement prison cells.\nWith altogether 400 photos and documents, for the first time the exhibition comprehensively related the history of the prison at Prinz-Albrecht-Straße 8 and reminded the fate of numerous detainees.\nThis presentation lasted from August 2005 to April 2008 on the site of the 'Topography of Terror'.\nThe Trial of Major War Criminals in Nuremberg\nThis exhibition was presented on the occasion of the 60th anniversary of the Nuremberg Trials and comprised around 110 photo and 50 text documents as well as 15 audio stations. It outlined the genesis, process, ambition and importance of the trial led by the Allies at Nuremberg focussing on the accused, whose culpability for the war crimes is demonstrated.\nThe presentation was located on the construction hoarding at the area of the Topography of Terror from October 2005 to April 2007.\nThe \"People's Court\" - Hitler's Political Tribunal\nGerman-English documentation on occasion of the 70th anniversary of the foundation of the people's court.\nThe exhibition was developed in cooperation with the Memorial to the German Resistance.\nFire! Anti-Jewish Terror on \"Kristallnacht\" in November 1938\nThe exhibition was developed in cooperation with the Foundation Memorial to the Murdered Jews of Europe and the Stiftung Neue Synagoge - Centrum Judaicum. The cooperative project presented on the 70th anniversary of the Kristallnacht pogrom presents historical documentation of the attack, seen around the world, on German Jewry after five and a half years of Nazi dictatorship.\nThe presentation was displayed from November 2008 to March 2009 in the Centrum Judaicum in Berlin.\nThe library of the Topography of Terror Foundation is a special library focusing on the police, SS, Gestapo in the Third Reich and on the National Socialism in general. It currently comprises about 25 800 media elements, about 120 regularly and 100 closed magazines. It is situated around a fountain reminding of Zen gardens and freely accessible.\nMemorial Museums Department\nThe Topography of Terror Foundation provides comprehensive advice and coordination tasks in the field of national and international memorial sites. In Germany, the Memorial Museums Department is the central coordination office for memorial sites and initiatives for memorial sites and increasingly promotes the international collaboration.\nDocumentation Centre NS Forced Labor\nThe last well-preserved former Nazi forced labour camp is located in Niederschöneweide. In the Second World War it served as one of the more than 3000 collective accommodations dispersed throughout the city for forced labourers. The Documentation Centre on Nazi Forced Labor opened in the summer of 2006 on a part of historical grounds that once belonged to the camp and which are today protected as a monument. The Documentation Centre offers two permanent exhibitions: \"Forced Labour in the Daily Round 1938-1945\" and \"Between two stools. The History of the Italian Military Internees 1943-1945\". Entrance and guided tours are free.\n- Lucarelli, Fosco: Zumthor’s Topographie des Terrors (1993–2004): visual history of birth, growth and death of a project Archived 2015-04-02 at the Wayback Machine, 14 November 2011\n- Topographie des Terrors. \"Köhler weiht Dokumentationszentrum in Berlin ein\" stern.de, 6 May 2010 (in German)\n- Topography of Terror. Library Topography of Terror Foundation, 26 May 2010\n- Publisher: Topography of Terror Foundation, represented by Prof. Dr. Andreas Nachama: Topography of Terror. Gestapo, SS and Reich Security Main Office on Wilhelm- and Prinz-Albrecht-Straße. A Documentation 1. edition. Berlin 2010, ISBN 978-3-941772-07-6.\n- Publisher: Topography of Terror Foundation, represented by Prof. Dr. Andreas Nachama: Site Tour \"Topography of Terror\". History of the Site 1. edition. Berlin 2010, ISBN 978-3-941772-05-2.\n- Schaltzentrale der Hölle. Was passiert mit der \"Topographie des Terrors\" in Berlin? Documentary, Germany, 2004, 7'08 Min., ZDF-aspekte, 20 July 2004\n- Dokumentationen des Terrors. News programme, Germany, 2007, 1'52 Min., Production: ZDF-heute, first run: 2 November 2007\n|Wikimedia Commons has media related to Topographie des Terrors.|\n- Official site\n- Nazi Forced Labour Documentation Centre\n- \"Topography of Terror\". Exberliner. nd. Archived from the original on 17 January 2010.\n- \"Nazi control room reopens as Topography of Terror museum in Berlin\". The Guardian. 6 May 2010.","Protecting works of cultural significance (“works”) in danger of damage, destruction or looting as a result of war, terrorism or natural disasters is the responsibility of everyone and especially of institutions whose mission is to protect, conserve and study the artistic heritage of human kind. Members of the Association of Art Museum Directors (AAMD) stand ready with our colleagues around the world to offer whatever help can be provided to museum professionals, international organizations such as the Blue Shield and custodians responsible for safeguarding the cultural heritage of countries in crisis, including facilitating access to refuges in other countries, if feasible.\nAAMD supports the 1954 Hague Convention for the Protection of Cultural Property in the Event of Armed Conflict. Member museum staff can offer technical assistance and professional advice to protect collections in situ. In cases where this is not practical, perhaps the greatest contribution AAMD members and other museums outside the affected area can make is to offer safe havens to those works in danger of damage, destruction or looting until they can be safely returned. While museums in neighboring countries would normally be the most readily accessible safe havens for objects in danger, there are many reasons – political, environmental, societal – that could cause a country in crisis not to seek safe haven in a neighboring country or that make a neighboring country impractical as a safe haven. Additionally, objects that are in danger of being damaged, destroyed or looted might require specialized treatment or care that may be unavailable in museums in a neighboring country. In these situations, museums in North America and around the world can and should offer to preserve and protect threatened cultural property.\nPlacing works in danger of damage or destruction in museums or other institutions away from the areas of crisis assures that they will be preserved and protected by professional staff until their return. In addition, works that have been looted and brought into a country such as the United States can also be candidates for preservation and protection until they can be returned to their source country; providing that doing so is consistent with the laws of the United States. Providing a safe haven for these works removes them from the marketplace (legal or illegal), preserves their physical integrity, allows relevant information to be recorded for posterity, and provides a basis for their safe return to the appropriate entities or individuals.\nThe AAMD has developed the following set of protocols for those interested in a united effort to offer safe havens to works in danger of being destroyed or looted as a result of war, terrorism or natural disasters. The AAMD encourages its members to adopt these protocols, while museums of the world that wish to assist in this effort are urged to use all or relevant parts of these protocols.\nII. The Source of Works In Need of Safe Havens\nIn the event of a terrorism occurrence or during an armed conflict or natural disaster, works may be brought for safe haven in the United States, Canada or Mexico from any depositor, assuming of course compliance with applicable law (see below). Predetermining who may request such assistance in the abstract is not always possible, but may include the legal owner of a work, the agent for the owner, the bailee of a work, the custodian of a work, and a person or entity who comes into possession of the work and the owner is unknown, unavailable or legally constrained (collectively, a “depositor”). Examples of a depositor are:\nMember museums should exercise caution to assure that accepting the request for safe haven will not violate the rights of lawful owners, subject the museum to a claim for return, reflect negatively on the reputation of the museum or cause the museum to be involved in any illegal or unethical activity. Requests for safe haven and agreements to accept such requests should be documented where possible prior to movement of works to be transferred.\nPrior to accepting a work, member museums should consider whether legal protections, such as immunity from seizure, are available in the safe haven country to protect the work and/or the museum from claims.\nIV. Inventory and Documentation\nInventorying and documenting the condition of works to be transferred for safe haven should take place prior to movement whenever possible. Copies should be kept at the original location, sent with the works during transit, and forwarded to the proposed safe haven museum. On arrival, a new condition report should be completed.\nV. Transport to Safe Havens\nTo the extent reasonable, works should be transported by the safest, surest method to the closest safe haven possible, with the depositor bearing the cost of transport, unless other arrangements have been made. In some cases, the safe haven museum may pay the transportation costs and will be eligible for reimbursement from the depositor. Works should be transported in the company of the depositor (or its representative) or a reliable courier whenever possible.\nVI. Storage Conditions; Special Care\nWorks provided safe haven should be stored in conditions suitable for the works in question, consistent with the security, climate and storage protocols applied to similar works in the collection of the museum offering safe haven. Safe haven museums may, but are not required to, take extraordinary measures to safeguard works such as creating special storage facilities, insuring the works or applying for immunity from seizure.\nVII. Conservation; Restoration\nWorks in obvious need of stabilization should be stabilized by professionals in safe haven museums to the extent feasible and practicable. Conservation work should only be undertaken with the consent of the depositor (except in emergencies) and should be done with the same care and professional attention that the safe haven museum would bestow on its own works. In emergency or authorized situations, conservation work may be undertaken without the consent of the depositor, but only to the extent necessary to preserve the work. Conservation work should be documented and, as soon as practical, the depositor should be informed of the work performed.\nAll works provided safe haven should be treated as loans, inventoried upon receipt, digitally documented and, if feasible and practicable, a condition report prepared and any immediate conservation needs identified. A copy of the inventory, digital images, and, if prepared, the conservation report and explanation of the conservation needs should be communicated as soon as practicable to the depositor.\nMuseums offering safe haven should publish on their own websites, on the AAMD object registry and on appropriate international websites whatever is known about the works provided safe haven. A secure database will be established as a section of the AAMD Object Registry to identify works given safe haven. In rare instances, security concerns may require a delay in the foregoing publication.\nX. Scholarly Access\nMuseums providing a safe haven should make the works available to scholars as they would their own collections, subject to the wishes of the depositor or, if different, the owner.\nWhen appropriate, and with the permission of the depositor, works may be exhibited and all information known made available to the public preferably in conjunction with educational material about the importance of safe guarding a country’s cultural heritage.\nXII. Education Programs\nEducation programs that explain to the public the dangers cultural property faces from terrorism, armed conflict, looting and illicit traffic, and natural disasters should be stressed, as well as the danger of purchasing or otherwise acquiring unprovenanced works of cultural property from crisis areas.\nXIII. Return of Works\nThe timing of the return of works will depend on the circumstances existing in the country from which the works were removed, but if possible should be effected as soon as practical after the situation giving rise to the need for a safe haven has passed. Return may be effected in any number of ways that will depend upon the circumstances, but may include as appropriate:\nMuseums must be cautious to comply with applicable law in returning objects, especially if there are or may be potential ownership disputes.\nXIV. Legal Issues\nBecause the actions of member museums in providing a safe haven may have legal consequences, member museums should consult with legal counsel before accepting or returning a work.\n The term “works’ should be broadly interpreted to include works of art, archaeological objects, objects removed from a fixed monument or immovable structure, but must always be limited to objects for which the museum has the knowledge and resources to preserve and protect. For example, zoological or botanical objects would not normally be covered by the Protocols, but could be considered by a particular museum that has the knowledge and resources to accept them.\n The AAMD has over 240 members who are directors of major art museums in the United States, Canada and Mexico."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:724c3bc5-b4ee-4a7f-ba46-7e89d5aefaed>","<urn:uuid:494c98f3-1b79-4f26-8ca1-099434761c89>"],"error":null}
{"question":"What are the key differences between the Mormon concept of agency and philosophical determinism in their views on human free will and choice?","answer":"The Mormon concept of agency and philosophical determinism present opposing views on human free will. According to Mormon theology, agency is an essential capacity of beings to act for themselves and be accountable for their actions. It is considered an inherent spiritual gift that allows individuals to choose between good and evil, without being forced either way. In contrast, determinism posits that every human decision and action is the inevitable consequence of prior events, though modern interpretations distinguish between strict pre-determinism and 'adequate determinism.' While Mormon doctrine emphasizes that humans cannot avoid being both free and responsible for their choices, determinism suggests that events are causally linked in a necessary chain. The Mormon view explicitly rejects the idea of precausation or fate, whereas deterministic philosophy, especially 'soft determinism,' argues that human choices are predetermined by physical reasons or external factors, even while maintaining some concept of freedom within those constraints.","context":["Return to About Mormons home\nEditor's Note: After the article on Agency, there are some brief comments on the LDS view of Fate.\nby C. Terry Warner\n\"Agency\" refers both to the capacity of beings \"to act for themselves\" (2 Ne. 2:26) and their accountability for those actions. Exercising agency is a spiritual matter (D&C 29:35); it consists in either receiving the enlightenment and commandments that come from God or resisting and rejecting them by yielding to the devil's temptations (D&C 93:31). Without awareness of alternatives an individual could not choose, and that is why being tempted by evil is as essential to agency as being enticed by the Spirit of God (D&C 29:39). Furthermore, no one is forced either to act virtuously or to sin. \"The devil could not compel mankind to do evil; all was voluntary . God would not exert any compulsory means, and the devil could not\" (TPJS, p. 187).\nAgency is an essential ingredient of being human, \"inherent in the spirit of man\" (McKay, p. 366) both in the premortal spirit existence (D&C 29:36) and in mortality. No being can possess sensibility, rationality, and a capacity for happiness without it (2 Ne. 2:11-13, 23; D&C 93:30). Moreover, it is the specific gift by which God made his children in his image and empowered them to grow to become like him through their own progression of choices (L. Snow, JD 20:367). It was because Satan \"sought to destroy the agency of man\" (Moses 4:3) that the war was fought in heaven before earth life (cf. Rev. 12:7). What was then, and is now, at stake in the battle to preserve agency is nothing less than the possibility of both the continued existence and the divine destiny of every human being. This principle helps explain the Church's strong position against political systems and addictive practices that inhibit the free exercise of agency.\nAgency is such that men and women not only can choose obedience or rebellion but must (B. Young, JD 13:282). They cannot avoid being both free and responsible for their choices. Individuals capable of acting for themselves cannot remain on neutral ground, abstaining from both receiving and rejecting light from God. To be an agent means both being able to choose and having to choose either \"liberty and eternal life, through the great Mediator\" or \"captivity and death, according to the captivity and power of the devil\" (2 Ne. 2:27-29; 10:23). A being who is \"an agent unto himself\" is continually committing to be either an agent and servant of God or an agent and servant of Satan. If this consequence of choosing could be overridden or ignored, men and women would not determine their own destiny by their choices and agency would be void.\nThe captivity resulting from sin is also called \"the bondage of sin\" (D&C 84:49-51). Sin sets up dispositions in the sinner that empower Satan to control the sinner's thoughts and behavior by means of temptation. As this happens, the individual still possesses agency in name, but his capacity to exercise it is abridged. In this sense, to misuse one's agency is to lose that agency: \"Evil, when listened to, begins to rule and overrule the spirit [that] God has placed within man\" (B. Young, JD 6:332). Conversely, using agency to receive and obey the influence of the spirit of Christ liberates one from this bondage. Thus, though agency, in the sense of the capacity to choose life or death, is a kind of freedom, it differs in quality from the liberty that is inherent in obedience to Christ. Jesus said, \"If the Son therefore shall make you free, ye shall be free indeed\" (John 8:36). When King Benjamin's people in the Book of Mormon received a remission of sins and were spiritually born again, they attested that their affections and desires had been so changed that they had \"no more disposition to do evil, but to do good continually\" (Mosiah 5:2). Obedience expands agency, and the alternative to obedience is bondage.\nThus, in the LDS concept of agency, obedience and agency are not antithetical. On the one hand, Church leaders consistently stand against all coercion of conscience (\"We are not disposed, had we the power, to deprive anyone of exercising free independence of mind\" [TPJS, p. 49]) and counsel Church members to depend first of all on themselves for decisions about the application of gospel principles. On the other hand, obediencewilling and energetic submission to the will of God even at personal sacrificeis a central gospel tenet. Far from contradicting freedom, obedience is its highest expression. \"But in rendering strict obedience, are we made slaves? No, it is the only way on the face of the earth for you and me to become free . The man who yields strict obedience to the requirements of Heaven, acts upon the volition of his own will and exercises his freedom\" (B. Young, JD 18:246).\nChurch leaders consistently call agency a gift of God. Sin abridges the agency of sinners to the point that unless some power releases them from this bondage, they will be \"lost and fallen\" (Mosiah 16:4). That power is Christ's Atonement, which overcomes the effects of sin, not arbitrarily, but on condition of wholehearted repentance. \"Because they are redeemed from the fall they have become free forever to act for themselves\" (2 Ne. 2:26). Thus, human agency was purchased with the price of Christ's suffering. This means that to those who blame God for allowing human suffering, Latter-day Saints can respond that suffering is less important than the gift of agency, upon which everything else depends, and that none of us has paid a greater price for this gift than Christ.\n(See \"According to the Desire of [Our] Hearts\" by Elder Neal A. Maxwell; Agency--a Blessing and a Burden by Sharon G. Larsen; the Family Home Evening Lesson entitled We Can Choose; Basic Beliefs home page; Doctrines of the Gospel home page)\nMadsen, Truman G. Eternal Man, pp. 63-70. Salt Lake City, 1966.\nMcKay, David O. IE 53 (May 1950):366.\nPacker, Boyd K. \"Atonement, Agency, Accountability.\" Ensign 18 (May 1988):69-72.\nRomney, Marion G. \"Decisions and Free Agency.\" IE 71 (Dec. 1968):73-76.\nStapley, Delbert L. \"Using Our Free Agency.\" Ensign 5 (May 1975):21-23.\nEncyclopedia of Mormonism, Vol.1, Agency\nCopyright © 1992 by Macmillan Publishing Company\nby Gerald E. Jones\nFate, as usually interpreted, is the antithesis of self-determination and responsibility. Latter-day Saints reject on scriptural grounds all appeals to precausation whether as \"fate,\" \"the stars,\" \"blind chance,\" or even the predestination of man by God. Fate in these forms implies a precaused outcome of one's life. Instead, man is seen as having innate autonomies and capacitiesthe gift of agencythat the divine will guarantees all men: \"I the Lord God make you free, therefore ye are free indeed: and the law also maketh you free\" (D&C 98:8; cf. 2 Ne. 2:25-27; Alma 12:31; Moses 4:3). People are free to choose obedience or disobedience, good or evil, and most other aspects of their lives, and they are accountable for their choices. The belief that all is fated, stifles, discourages, and hinders the progress and growth possible for the children of God. Fate is considered a negative term in the gospel. Even one's own momentous decisions influence one's so-called fate or destiny only as long as the decisions are maintained. The gospel of Jesus Christ opens to all mankind the opportunity to rise above chance fate in this life and choose eternal life with God.\nThe Church of Jesus Christ of Latter-day Saints. Gospel Principles. Salt Lake City, 1978, pp. 18-21.\nEncyclopedia of Mormonism, Vol. 2, Fate\nCopyright © 1992 by Macmillan Publishing Company\nAll About Mormons","Determinism is the philosophical idea that every event or state of affairs, including every human decision and action, is the inevitable and necessary consequence of antecedent states of affairs. More strictly, determinism should be distinguished from pre-determinism, the idea that the entire past (as well as the future) was determined at the origin of the universe. Nor should determinism be confused with determination, the idea that events (including human actions) can be adequately determined by immediately prior events (such as an agent's reasons, motives, desires), without being pre-determined back to before the agent's birth or even back to the origin of the universe. Since modern quantum physics shows that the universe is indeterministic, with profound effects on microscopic processes at the atomic scale, we will find it valuable to distinguish pre-determinism from the adequate determinism that we have in the real world. Adequate determinism is the basis for the classical physical laws that apply in the macrocosmos. Determinism is a modern name (coined in the nineteenth-century) for Democritus' ancient idea that causal deterministic laws control the motion of atoms, and that everything - including human minds - consists merely of atoms in a void. As Democritus' mentor and fellow materialist Leucippus put it, an absolute necessity leaves no room in the cosmos for chance.\n\"Nothing occurs at random, but everything for a reason and by necessity.\" 1 οὐδὲν χρῆμα μάτην γίνεται, ἀλλὰ πάντα ἐκ λόγου τε καὶ ὑπ’ ἀνάγκηςDeterminism, especially the variation of \"soft\" determinism (cf. William James) or compatibilism, is supported as a theory of free will by a majority of philosophers, each with special vested interests in one or more of the many determinisms. Compatibilists accept determinism but argue that man is free as long as his own will is one of the steps in the causal chain, even if his choices are completely predetermined for physical reasons or preordained by God.\nAnd Fatalism is a special form of determinism where every event in the future is fated to happen. Fatalism does not normally require that any causal laws or higher powers are involved. Que sera, sera. The core idea of determinism is closely related to the idea of causality. But we can have causality without determinism, especially the \"soft\" causality that follows an \"uncaused\" event (a causa sui) that is not predictable from prior events. Aristotle called such events archai (ἀρχαί) - starting points or \"fresh starts\" in new causal chains which break the bonds of determinism. Despite David Hume's critical attack on the necessity of causes, many philosophers embrace causality and determinism strongly. Some even connect it to the very possibility of logic and reason. And Hume himself believed strongly, if inconsistently, in necessity. \" 'tis impossible to admit any medium betwixt chance and necessity,\" he said. Bertrand Russell said \"The law of causation, according to which later events can theoretically be predicted by means of earlier events, has often been held to be a priori, a necessity of thought, a category without which science would not be possible.\" (Russell, External World p.179) The idea of indeterminism appears to threaten causality and the basic idea of causal law. But it does not. Indeterminism for some is simply an occasional event without a cause. We can have an adequate causality without strict determinism. Strict determinism means complete predictability (in principle, if not in practice) of events and only one possible future. Adequate determinism provides statistical predictability, which in normal situations for physical objects approaches statistical certainty. An example of an event that is not strictly caused is one that depends on chance, like the flip of a coin. If the outcome is only probable, not certain, then the event can be said to have been caused by the coin flip, but the head or tails result itself was not predictable. So this causality, which recognizes prior events as causes, is undetermined and the result of chance alone. We call this \"soft\" causality. Events are caused by prior (uncaused) events, but not determined by events earlier in the causal chain, which has been broken by the uncaused cause. Determinism is critical for the question of free will. Strict determinism implies just one possible future. Chance means that the future is unpredictable. Chance allows alternative futures and the question becomes how the one actual present is realized from these alternative possibilities. The departure required from strict determinism is very slight compared to the miraculous ideas associated with the \"causa sui\" (self-caused cause) of the ancients. Even in a world that contains quantum uncertainty, macroscopic objects are determined to an extraordinary degree. But the macroscopic \"laws of nature\" are just statistical laws that \"emerge\" when large numbers of atoms or molecules get together. For large enough numbers, the probabilistic laws approach practical certainty. Determinism is an emergent property. Newton's laws of motion are deterministic enough to send men to the moon and back. Our Cogito Model of the Macro Mind is large enough to ignore quantum uncertainty for the purpose of the reasoning will. The neural system is robust enough to insure that mental decisions are reliably transmitted to our limbs.\nWe call this determinism, only ineffective for extremely small structures, \"adequate determinism.\" It is adequate enough to predict eclipses for the next thousand years or more with extraordinary precision. Belief in strict determinism, in the face of physical evidence for indeterminism, is only tenable today for dogmatic philosophy. We survey ten modern dogmas of determinism. Phillipa Foot argued that because our actions are determined by our motives, our character and values, our feelings and desires, in no way leads to the conclusion that they are pre-determined from the beginning of the universe. The presence of quantum uncertainty leads some philosophers to call the world indetermined. But indeterminism is somewhat misleading, with strong negative connotations, when most events are overwhelmingly \"adequately determined.\" Nevertheless, speaking logically, if a single event is undetermined, then indeterminism is true, and determinism false. 1 There is no problem imagining that the three traditional mental faculties of reason - perception, conception, and comprehension - are all carried on more or less deterministically in a physical brain where quantum events do not interfere with normal operations. There is also no problem imagining a role for randomness in the brain in the form of quantum level noise. Noise can introduce random errors into stored memories. Noise could create random associations of ideas during memory recall. This randomness may be driven by microscopic fluctuations that are amplified to the macroscopic level. Our Macro Mind needs the Micro Mind for the free action items and thoughts in an Agenda of alternative possibilities to be de-liberated by the will. The random Micro Mind is the \"free\" in free will and the source of human creativity. The adequately determined Macro Mind is the \"will\" in free will that de-liberates, choosing actions for which we can be morally responsible. Determinism must be disambiguated from its close relatives causality, certainty, necessity, and predictability.\nThe Emergence of DeterminismSince the physical world is irreducibly indeterministic at the base level of atoms and molecules, there is actually no strict determinism at any \"level\" of the physical world. With random motions at the base level, what emerges at the higher level of the macroscopic physical world and the human mind is adequate determinism. Determinism is an abstract theoretical idea that simplifies physical systems enough to allow the use of logical and mathematical methods on idealized abstract \"objects\" and \"events.\" The apparent \"determinism\" of classical physics is the consequence of averaging over extremely large numbers of microscopic particles. Adequate determinism \"emerges\" when we have large enough objects to be averaging over vast numbers of atoms and molecules. Determinism is an emergent property.\nThe Etymology of Determinism\nThe term (sic) determinism is first attested in the late fourteenth century, \"to come to an end,\" also \"to settle, decide,\" from O.Fr. determiner (12c.), from L. determinare \"set limits to,\" from de- \"off\" + terminare \"to mark the end or boundary,\" from terminus \"end, limit.\" The sense of \"coming to a firm decision\" (to do something) is from 1450. Determination as a \"quality of being resolute\" dates from 1822. Before the nineteenth century determinists were called Necessarians. William Belsham contrasted them (favorably) with the incoherent Libertarians in 1789, the first use of Libertarian. Libertarians were thought incoherent because liberty was thought to be unruly, random, unlawful, and - in a related term of the day - libertine. Determinism appears in 1846 in Sir William Hamilton's edition of Thomas Reid's works as a note on p.87.\nThere are two schemes of Necessity - the Necessitation by efficient - the Necessitation by final causes. The former is brute or blind Fate; the latter rational Determinism.At about the same time, it is used by theologians to describe lack of free will. In 1855, William Thomson (later Lord Kelvin) wrote,\nThe theory of Determinism, in which the will is determined or swayed to a particular course by external inducements and forced habits, so that the consciousness of freedom rests chiefly upon an oblivion of the antecedents of our choice.Ernst Cassirer claimed (mistakenly?) that Determinism in the philosophical sense of a \"doctrine that everything that happens is determined by a necessary chain of causation\" dates from the work of Emil du Bois-Reymond in 1876. Note that ancient philosophers worried about this causal chain (ἄλυσις), but those philosophers who allowed the existence of chance, (Aristotle, Epicurus, Lucretius, and Alexander of Aphrodisias), denied such a causal chain, while maintaining that human decisions were caused by neither chance nor necessity but by a tertium quid - our autonomous human agency. The adjective determinist appeared first in the Contemporary Review of October 1874 - \"The objections of our modern Determinists.\" In the Contemporary Review of March 1885 R. H. Hutton described \"The necessarian or determinist theory of human action.\" William James's essay on The Dilemma of Determinism appeared at about the same time, in 1884. In it he coined the terms \"soft determinism\" (today's compatibilism), and \"hard determinism\" (strict determinsm, indeed, pre-determinism from the beginning of time).\nC.D.Broad, in 1932, defined Determinism, Indeterminism, and Libertarianism. Reprinted in Morgenbesser (1962) Free Will\nAnd now at last we can define- \"determinism\" and \"indeterminism.\" Determinism is the doctrine that every event is completely determined, in the sense just defined. Indeterminism, is the doctrine that some, and it may be all, events are not completely determined, in the sense defined. Both doctrines are, prima facie, intelligible, when defined as I have defined them. There is one other point to be noticed. An event might be completely determined, and yet it might have a \"causal ancestor\" which was not, completely determined. If Y is the total cause of Z and X is the total cause of Y, I call both Y and X \"causal ancestors\" of Z. Similarly, if W were the total cause of X, I should call Y, X, and W \"causal ancestors\" of Z. And so on. If at any stage in such a series there is a term, e.g. W, which contains a cause-factor that is not completely determined, the series will stop there, just as the series of human ancestors stops with Adam. Such a term may be called the \"causal progenitor\" of such a series. If determinism be true, every event has causal ancestors, and therefore there are no causal progenitors. If indeterminism be true, there are causal progenitors in the history of the world. We are now in a position to define what Ι will call \"libertarianism.\" This doctrine may be summed up in two propositions. (i) Some (and it may be all) voluntary actions have a causal ancestor which contains as a cause factor the putting-forth of an effort which is not completely determined in direction and intensity by occurrent causation. (ii) In such cases the direction and the intensity of the effort are completely determined by non-occurrent causation, in which the self or agent, taken as a substance or continuant, is the non-occurrent total cause. [Broad means a non-physical mind as the non-occurent cause.] Thus, Libertarianism, as defined by me, entails indeterminism, as defined by me; but the converse does not hold. If I am right, libertarianism is self-evidently impossible, whilst indeterminism is prima facie possible.\nRichard Double,s The Nonreality of Free Will (1995?) provided these definitions.\nAlthough the notion of determinism appears frequently through this book, the free will discussion is concerned only with a tiny subset of what might be determined, viz., those events that affect human decision making. Whether there is, e.g., indeterminacy in quantum physics is an empirical matter outside of philosophers' ken and, by itself, does not bear on the free will debate, although some libertarians have argued that quantum indeterminacy could bear on human choices (see Chapter 8). This book is primarily about free will, though, and about determinism only incidentally. Compatibilism — The view that the theses of free will and determinism can both be true. Incompatibilism — The view they cannot both be true. Soft determinism — Technically, compatibilism plus determinism, but in fact, the view that we have free will not as a result of indeterminism, whether or not determinism is true. Hard determinism — Technically, incompatibilism plus determinism, but the view that humans lack free will because their decisions are determined, again, whether determinism in its fullest generality is true. Libertarianism — The view that humans have free will as a result of indeterminism in their choices.Double's libertarianism is an extreme view that makes chance the direct cause of our choices. But it coincides with Robert Kane's \"torn decisions\" in which an agent can take responsibility for a random choice either way if there are good reasons for either choice.\n1. C.D.Broad, 1934 \"Indeterminism is the doctrine that some, and it may be all, events are not completely determined.\""],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:6194a6eb-aa7d-4c13-9b4a-cf3077f44604>","<urn:uuid:ebf2f15b-7dd1-4417-af77-027b0769ee6c>"],"error":null}
{"question":"Equipment comparison: what's needed to freeze vs dehydrate food at casa?","answer":"For freezing, you primarily need a household freezer that can maintain temperatures below -9.5°C. For dehydrating food at home, you need either a commercial dehydrator, an oven that can be set to low temperatures, or drying racks. Additional dehydrating equipment includes sharp knives, cutting boards, heavy-duty pots for blanching, and optionally items like blenders, food processors, or specialty items such as cherry pitters. Commercial dehydrators typically allow temperature control and come with accessory sheets for fruit leather and fine mesh sheets, making them more versatile than basic freezing equipment.","context":["Freezing food preserves it from the time it is prepared to the time it is eaten. Since early times, farmers, fishermen, and trappers have preserved their game and produce in unheated buildings during the winter season. Freezing food slows down decomposition by turning residual moisture into ice, inhibiting the growth of most bacterial species. In the food commodity industry, the process is called IQF or Individually Quick Frozen (flash freezing).\nPreserving food in domestic kitchens during the 20th and 21st centuries is achieved using household freezers. Accepted advice to householders was to freeze food on the day of purchase. An initiative by a supermarket group in 2012 (backed by the UK's Waste & Resources Action Programme) promotes advising the freezing of food \"as soon as possible up to the product's 'use by' date\". The Food Standards Agency was reported as supporting the change, providing the food had been stored correctly up to that time.\nFrozen products do not require any added preservatives because microorganisms do not grow when the temperature of the food is below -9.5°C, which is sufficient on its own in preventing food spoilage. Long-term preservation of food may call for food storage at even lower temperatures. Carboxymethylcellulose (CMC), a tasteless and odorless stabilizer, is typically added to frozen food because it does not adulterate the quality of the product. \nBeginning in 1929, Clarence Birdseye offered his quick-frozen foods to the public. Birdseye got the idea during fur-trapping expeditions to Labrador in 1912 and 1916, where he saw the natives use freezing to preserve foods. Modern attempts at refrigeration began in the early 20th century in the meat packing industry. More advanced attempts include food frozen for Eleanor Roosevelt on her trip to Russia. Other experiments, involving orange juice, ice cream and vegetables were conducted by the military near the end of World War II.\nFrozen food packaging must maintain its integrity throughout machine filling, sealing, freezing, storage, transportation, thawing, and often cooking. As many frozen foods are cooked in a microwave oven, manufacturers have developed packaging that can go straight from freezer to the microwave.\nIn 1974, the first differential heating container (DHC) was sold to the public. A DHC is a sleeve of metal designed to allow frozen foods to receive the correct amount of heat. Various sized apertures were positioned around the sleeve. The consumer would put the frozen dinner into the sleeve according to what needed the most heat. This ensured proper cooking.\nScientists are continually researching new aspects of frozen food packaging. Active packaging offers a host of new technologies that can actively sense and then neutralize the presence of bacteria or other harmful species. Active packaging can extend shelf-life, maintain product safety, and help preserve the food over a longer period of time. Several functions of active packaging are being researched:\n- Oxygen scavengers\n- Time Temperature Indicators and digital temperature dataloggers\n- Carbon Dioxide controllers\n- Microwave susceptors\n- Moisture control: Water activity, Moisture vapor transmission rate, etc.\n- Flavor enhancers\n- Odor generators\n- Oxygen-permeable films\n- Oxygen generators\n- Validation of cold chain\nEffects on nutrients\nVitamin content of frozen foods\n- Vitamin C: Usually lost in a higher concentration than any other vitamin. A study was performed on peas to determine the cause of vitamin C loss. A vitamin loss of ten percent occurred during the blanching phase with the rest of the loss occurring during the cooling and washing stages. The vitamin loss was not actually accredited to the freezing process. Another experiment was performed involving peas and lima beans. Frozen and canned vegetables were both used in the experiment. The frozen vegetables were stored at −10 °F (−23 °C) and the canned vegetables were stored at room temperature (75 °F). After 0, 3, 6, and 12 months of storage, the vegetables were analyzed with and without cooking. O'Hara, the scientist performing the experiment said, \"From the view point of the vitamin content of the two vegetables when they were ready for the plate of the consumer, there did not appear to be any marked advantages attributable to method of preservation, frozen storage, processed in a tin, or processed in glass.\"\n- Vitamin B1 (Thiamin): A vitamin loss of 25 percent is normal. Thiamin is easily soluble in water and is destroyed by heat.\n- Vitamin B2 (Riboflavin): Not much research has been done to see how much freezing affects Riboflavin levels. Studies that have been performed are inconclusive; one study found an 18 percent vitamin loss in green vegetables, while another determined a 4 percent loss. It is commonly accepted that the loss of Riboflavin has to do with the preparation for freezing rather than the actual freezing process itself.\n- Vitamin A (Carotene): There is little loss of carotene during preparation for freezing and freezing of most vegetables. Much of the vitamin loss is incurred during the extended storage period.\nFreezing is an effective form of food preservation because the pathogens that cause food spoilage are killed or do not grow very rapidly at reduced temperatures. The process is less effective in food preservation than are thermal techniques, such as boiling, because pathogens are more likely to be able to survive cold temperatures rather than hot temperatures. One of the problems surrounding the use of freezing as a method of food preservation is the danger that pathogens deactivated (but not killed) by the process will once again become active when the frozen food thaws.\nFoods may be preserved for several months by freezing. Long-term frozen storage requires a constant temperature of -18 °C (0 °F) or less.\nAccording to a study, an American consumes on average 71 frozen foods a year, most of which are pre-cooked frozen meals. Many food critics host shows are dedicated to the tasting and reviewing of frozen foods, the web show Freezerburns being one of the more notable ones.\n- Tressler, Evers. The Freezing Preservation of Foods Pg 213-217\n- Smithers, Rebecca (February 10, 2012). \"Sainsbury's changes food freezing advice in bid to cut food waste\". The Guardian. Retrieved February 10, 2012. \"Long-standing advice to consumers to freeze food on the day of purchase is to be changed by a leading supermarket chain, as part of a national initiative to further reduce food waste. [...] instead advise customers to freeze food as soon as possible up to the product's 'use by' date. The initiative is backed by the government's waste advisory body, the Waste and Resources Action Programme (Wrap) [...] Bob Martin, food safety expert at the Food Standards Agency, said: \"Freezing after the day of purchase shouldn't pose a food safety risk as long as food has been stored in accordance with any instructions provided. [...]\"\"\n- Arsdel, Michael, Robert. Quality and Stability of Frozen Foods: TIme-Temperature Tolerance and its Significance. Pg. 67-69\n- \"Frozen Foods\". Massachusetts Institute of Technology.\n- Decareau, Robert. Microwave Foods: New Product Development. Pg 45-48\n- Whelan, Stare. Panic in the Pantry: Facts and Fallacies About the Food You Buy\n- Russell, Gould. Food Preservatves. Pg 314\n- Sun, Da-Wen. Handbook of Frozen Food Processing and Packaging. Pg 786-792\n- Tressler, Evers. The Freezing Preservation of Foods. Pg 620-624\n- Tressler, Evers. The Freezing Preservation of Foods. Pg 961-964\n- Tressler, Evers. The Freezing Preservation of Foods. Pg 627\n- Gould, Grahame. New Methods of Food Preservation. Pg 237-239\n- Tressler, Evers. Pg. 973-976\n- Tressler, Evers. The Freezing Preservation of Foods. Pg. 976-978\n- Mathlouthi, M. Food Packaging and Preservation. Pg 112-115\n- Tressler, Evers, Evers. Into the Freezer - and Out. Pg 56-82\n- Harris, J. Michael and Rimma Shipstova, Consumer Demand for Convenience Foods: Demographics and Expenditures, AgEcon, p. 26, retrieved 16 July 2011\n- Stock, Sue (18 April 2010). \"Web viewers warm up to frozen food show\". News & Observer. Retrieved 10 July 2011.\n- Arsdel, Wallace, B. Van, Michael, J Copley, and Robert, L. Olson. Quality and Stability of Frozen Foods: TIme-Temperature Tolerance and its Significance. New York, NY: John Wiley & Sons,INC, 1968.\n- \"Clarence Birdseye.\" Encyclopedia of World Biography. Vol. 19. 2nd ed. Detroit: Gale, 2004. 25-27. Gale Virtual Reference Library. Gale. Brigham Young University - Utah. Nov. 3 2009 <http://go.galegroup.com/ps/start.do?p=GVRL&u=byu_main>\n- Copson, David. Microwave Heating. 2nd ed.. Westport, CT: The AVI Publishing Company, INC., 1975.\n- Decareau, Robert. Microwave Foods: New Product Development. Trumbull, CT: Food & Nutrition Press, INC., 1992.\n- Gould, Grahame. New Methods of Food Preservation. New York, NY: Chapman & Hall, 2000.\n- Mathlouthi, Mohamed. Food Packaging and Preservation. New York, NY: Chapman & Hall, 1994.*^Robinson, Richard. Microbiology of Frozen Foods. New York, NY: Elsevier Applied Science Publishers LTD, 1985.\n- Russell, Nicholas J., and Grahame W. Gould. Food Preservatives. 2nd ed. New York, NY: Kluwer Academic/Plenum Publishers, New York, 2003.\n- Sun, Da-Wen. Handbook of Frozen Food Processing and Packaging. Boca Raton, Fl: Taylor & Francis Group, LLC, 2006.\n- Tressler, Donald K., Clifford F. Evers, and Barbara, Hutchings Evers. Into the Freezer - and Out. 2nd ed. New York, NY: The AVI Publishing Company, INC., 1953.\n- Tressler, Donald K., and Clifford F. Evers. The Freezing Preservation of Foods. 3rd ed. 1st volume. Westport, CT: The AVI Publishing Company, INC., 1957.\n- Whelan, Elizabeth M., and Fredrick J. Stare. Panic in the Pantry: Facts and Fallacies About the Food You Buy. Buffalo, NY: Prometheus Books, 1998.\nMedia related to Frozen food at Wikimedia Commons","What Equipment Do I Need to Dehydrate Food at Home?To dehydrate food, you need a dehydrator or drying area/rack. An oven can be used if you can set the temperature low enough, but it will use more energy than a commercial dehydrator or other home constructed options (see bottom of post for links to build your own dehydrator). As long as your humidity isn’t too high, you may be able to air dry (think herb bundles hung from rafters). Some folks rig up trays with covers (see one example here) and hang them near a heat sources such as a wood stove.\nCommercial dehydrators will give more consistent results and be easier to work with, giving you a better quality end product. Quick and uniform drying preserves color, flavor and texture. Most commercial units also allow you to set your temperature, which is very helpful for optimal drying of different foods. For instance, herbs are best dried at lower temperatures so that you don’t drive off volatile oils, while meats are typically dried at higher temps. If you purchase a commercial dehydrator, I highly recommend including the accessory sheets for fruits leather and fine mesh sheets in your purchase. They are so much easier to work with than improvised homemade options.\nA sharp knife and cutting board is helpful for cutting fruits and vegetables into thinner pieces that will dry more quickly and evenly (a mandolin or food processor for cutting may be helpful in some cases, but isn’t absolutely necessary).\nA good sized, heavy duty pot is helpful for cooking down fruits and blanching fruits and veggies. For purees and “leathers”, you’ll need a blender or food processor. I like using my salad spinner to predry herbs before loading them into the dehydrator. That’s enough equipment to get you started, although some specialty items such as cherry pitters and apples corers may come in handy once you get rolling.\nWhat Types of Food Can be Dried?Just about anything can be dried, from vegetables and fruit to meat and fish. Home dried herbs are a fraction of the cost of store bought herbs. Natural fruit leathers are also quite expensive in the store, and are one of the simplest things to make in your dehydrator. You can use your dehydrator to make snacks for people and pets. You can also use it to dehydrate excess kefir grains or sourdough starter.\nHow do I prepare food for drying?Generally, you want to slice or chop uniform pieces of food between 1/8 and 1/2 inch thick. Food that is too thick or irregularly shaped will lead to non-uniform drying, which could lead to spoilage or lower quality product.\nPretreating – some foods are pre-treated before drying to help to preserve color and flavor. For instance, fruits can be dipped in saltwater, and acidic medium or something sweet to reduce oxidation. My favorite method is to use a couple of tablespoons of lemon juice in a bowel of water. Inexpensive, easy and doesn’t dramatically change the flavor of the fruit. Many people also enjoy dipping sliced fruit in other acidic fruit juices, such as apple or banana slices in pineapple or orange juice. More detailed information is linked below in specific posts.\nMarinades are commonly used for meats such as jerkies to enhance flavor and improve shelf life. Blanching in water or steam helps slow down enzyme action and softens skins, making it each for moisture to be driven out and making the product more palatable when rehydrated. Many vegetables (but not all) are best blanched before dehydrating.\nHow long does it take to dry food?It really depends on the food and the drying conditions – anywhere from a few hours to days, depending on what is being dried and how it is being dried. Thinner items dry faster than thick. Units with fans dry faster than units without fans. Natural drying can go pretty slowly, but still works well in many situations. Most of the time I load my dehydrator in the evening and let it dry overnight.\nHow can I tell if home dehydrated food is dry enough?Different foods will have different textures when dried, from brittle to leather-like to gummy. As you work with dehydrating, you’ll get a feeling for appropriate dryness. The texture of home dried foods is often different than commercially dried foods, so don’t let this put you off. Remember, you’re making your products without strange additives or deep frying or other commercial processes.\nA good rule of thumb to test dryness is to put the product in a tightly sealed jar, and check for condensation on the lid after about a day. If you’ve got condensation, you need to dry it more – it won’t keep – or put it in the freezer or refrigerator.\nHow do I store dried food and how long will it keep?My preferred storage container is a standard or wide mouthed mason jar. If I have a lot of a product (enough to fill multiple jars), I’ll use the vacuum sealer attachment for my Foodsaver to seal most of the jars to extend shelf life even further. I keep the jars out of direct light (in the pantry), and/or cover them with sock cozies. You can also use plastic bags or plastic jars, or glass jars from other commercial products.\nStorage life depends on conditions. Dried food has been found on archeological digs that was still technically “edible”, but definitely not a yummy. Dried produce and herbs should last around a year (from one season to the next) if properly stored. I’ve kept items longer, but flavor, color and nutrients diminish over time.\nDo you dry food at home? What technique/equipment do you use?\nBelow is an assortment of links from my blog and other other online resources to help you get started with dehydrating.\nCommon Sense Homesteading Posts on Food DryingPreserving Asparagus Three Ways – Freezing, Drying and Lactofermenting\nPeeling, Canning and Drying Peaches\nPreserving Strawberries Four Ways – Freezing, Drying, Fruit Leather and Kombucha\nMaking Applesauce, Apple leather and Dried Apple Slices\nGround Beef Jerky\nCrispy Nuts and Maple Candied Walnuts\nOnline Resources for Home Food DehydratingFacebook group – Dehydrating Way Beyond Jerky\nNational Center for Home Food Preservation – How Do I Dry Foods?\nDehydrate2Store.com – “On this site you will learn to build your pantry for long term food storage, cook fast and simple meals with prepackaged foods, store food for years and re-hydrate it back to new! Also you will find instructional videos, delicious recipes using dehydrated foods, helpful hints, important information, and great ideas.”\nNESCO/American Harvest How To Dehydrate Guides\nHome Food Dehydrators You Can Make Yourself\nDIY Electric DehydratorsLiving Foods Dehydrators – Wooden dehydrators made in the USA, or buy the kit and make your own.\nDIY Dehydrator made with a box fan – Alton Brown’s box fan dehydrator made with a box fan, cellulose furnace filters and a bungie cord or two.\nHome made dehydrator made with plywood – Do it yourself dehydrator instructions for a box dehydrator made with plywood, and incandescent lightbulb and recycled refrigerator racks.\nThe $10 Jerky Maker – Quick and easy instructions for a box dehydrator using a cardboard shipping box, a light bulb, and PVC pipe. Detailed instructions, lots of photos.\nDo-if yourself food dehydrator/jerky maker – DIY dehydrator instructions to build a unit with a cardboard box, light bulb, cooling racks and metal skewers. I like this a little better than the PVC option because the parts touching the food are food grade materials. Nice photos.\nDIY Solar DehydratorsBuild It Solar – Solar Cooking and Food Drying - 10 different solar food dehydrator designs\nSolar Fruit Dryer – PDF plans for a large solar fruit dryer"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:3710dadd-acb7-483b-b517-d105f9f91a74>","<urn:uuid:8ccd3b3d-30e9-4030-bf29-07032d1317db>"],"error":null}
{"question":"How do ETFs compare to options in terms of trading flexibility and market access in Australia?","answer":"ETFs and options offer different types of trading flexibility in Australia. ETFs trade like stocks throughout the day with fluctuating values and can be bought/sold at will, offering good liquidity. They also allow margin trading and short selling. Options in Australia are typically traded as exchange-traded options (ETOs) over the Australian Securities Exchange (ASX) and can be traded on various assets including shares, indices, bonds, ETFs and commodities. Options provide additional strategic flexibility through different contract types like calls and puts, though they require more sophistication to trade effectively.","context":["Exchange-Traded Mutual Funds, or ETFs, began appearing as investment tools in the early 1990′s. Although ETFs have been around for nearly two decades, few investors are aware of their existence or how they can be beneficial to their portfolio. ETFs offer investors a number of advantages over mutual funds or stocks and can be perfect for those new to the world of investing.\nETFs were designed to mimic index investing but without all the costs and headaches that go along with mutual fund ownership. For instance, the S&P 500 index is a composite of 500 different stocks whose individual performance is tracked daily to determine the overall value of the index. In other words, the S&P 500 is very diversified and the risk is spread among the 500 different stocks comprising the index. ETFs are also diversified like the major indexes so they reduce risk like mutual funds – but trade more like stocks.\nAn ETF may in fact track and be based on any of the major indexes but in almost every other way – it acts like a stock. Investors can buy and sell shares of their ETF throughout the course of the day because their value fluctuates just like a stock price does. This makes ETFs more liquid than mutual funds because investors must wait for the mutual fund to calculate the net asset value (NAV) each day before any transactions can be conducted (i.e. buying or selling the mutual fund).\nAnother advantage that ETFs have over mutual funds is cost – they tend to be less expensive investment tools with lower expense ratios. Also, many mutual funds will make the owner pay a penalty for early redemption whereas an ETF owner can sell shares at will. There are no management fees to contend with and the commissions are very similar to those an investor might pay for a typical stock transaction. Plus, you can even buy ETFs on the margin or short sell – just as with stock trades. ETFs come with all the diversification of a mutual fund and the ease-of-use and liquidity of a stock – i.e. the best of both worlds.\nETFs also tend to be very good for investors during tax season as well – especially when it comes time to sell. This is because ETFs do not carry the same exposure to capital gains taxes as do mutual funds. It is very common for mutual fund managers to constantly buy and sell holdings (buy more profitable holdings while presumably getting rid of the losers). However, the mutual fund owners are liable for the tax burden caused by the shift in holdings and often must pay capital gains taxes even before actually selling the fund. ETFs tend to have annual expenses in the 0.1%-0.7% range making them very attractive for frugal investors that don’t want to see significant portions of their investment devoured by fees, commissions and expenses.\nHowever, it is important to realize that although an ETF may be designed to track a major index and perform like it – its performance may not always mirror the index. In other words, sometimes the stocks in an ETF are not the exact same or in the same proportion as those found in the original index – say the S&P 500. Therefore, an ETF may have returns that vary from the original index by a percent or two each year.","Options Trade On Sydney\n· Although share options are the most popular type of contract, you can also trade options on other assets such as indices, bonds, exchange-traded funds and commodities. In Australia, options are typically traded over the Australian Securities Exchange (ASX) as exchange-traded options (ETOs). These ETOs allocate shares per contract. Options Options trading is a form of derivative trading that allows you to trade on the Australian securities market.\nThere are a number of options strategies which traders can use to help improve the performance of their portfolio. CMC Markets Stockbroking offers a sophisticated and professional solution to options traders. Exchange Centre, 20 Bridge Street, Sydney NSW Telephone: rmyf.xn----8sbbgahlzd3bjg1ameji2m.xn--p1ai 3 Contents Before you begin 5.\n4 What is an option? 5 Call options 5 Put options 6 Advantages of option trading 7 possible to trade options with no intention of ever exercising them. If you expect the market to rise, you may decide to buy call options.\nIf you File Size: 2MB. An easy to understand guide for trading options on the ASX. Learn what an option is and the difference between call options and put options. Plus discover how to value an option and trade options. Find over 20 Options Trading groups with members near you and meet people in your local community who share your interests.\nAs detailed in equity options expiry calendar: Expiry date: Monthly Contracts - 3rd Thursday of the calendar month. Weekly Contracts - Thursday. Both may change due to public holidays.\nAustralia's best share trading platforms + online brokers ...\nTrading hours: Normal trading am to pm (Sydney time). Late trading pm to pm and overseas trading in accordance with the ASX Market Rules: Settlement.\n· If you want someone to hold your hand and walk you through trading any Options strategy, use my broker in Sydney. They are Capital 19 and they will create for you a Reg T account which will allow you to sell and buy Options freely on margin on the US and Australian markets.\nTell them Tony from the forums referred you. Our Founding Partners, including Akuna’s CEO Andrew Killion, first conceptualized Akuna in their hometown of Sydney.\n$100,000 A Month with Stock Options Trading\nThey opened the firm’s first office in in the heart of the derivatives industry and the options capital of the world – Chicago. Today, Akuna is proud to operate from additional offices in Sydney, Shanghai, and Boston.\n· Options trading (especially in the stock market) is affected primarily by the price of the underlying security, time until the expiration of the option and the volatility of the underlying security.\nOptions Trading jobs now available in Sydney NSW. Options Market Maker, Operations Manager, Student Intern and more on rmyf.xn----8sbbgahlzd3bjg1ameji2m.xn--p1ai The risk of loss in online trading of stocks, options, futures, forex, foreign equities, and fixed Income can be substantial.\nOptions involve risk and are not suitable for all investors.\nFor more information read the \"Characteristics and Risks of Standardized Options\". For a copy call Interactive Brokers' Client Services on Sydney NSW. The ideal candidate will have strong options and product knowledge, preferably as a market maker.\n$100,000 A Month with Stock Options Trading\nYou will have the opportunity to trade options across Asian. · Toronto, Ontario, Canada About Blog SteadyOptions is an options trading advisory service that uses diversified options trading strategies for steady and consistent gains under all market conditions.\nFollow this blog to get options education, trading strategies and expert trading insights. Our educational articles from the leading industry experts will enrich your knowledge and help you in your.\n· Options trading may seem overwhelming at first, but it's easy to understand if you know a few key points.\nInvestor portfolios are usually constructed with several asset classes. TradersCircle is one of Australia’s leading stock market trading education firms, and runs one of Australia’s busier equity options trading desks. Options Trader jobs now available in Sydney NSW.\nTrader, Options Market Maker, Indexer and more on rmyf.xn----8sbbgahlzd3bjg1ameji2m.xn--p1ai Options Trading jobs now available in Sydney NSW. Quantitative Analyst, Analyst, Product Control and more on rmyf.xn----8sbbgahlzd3bjg1ameji2m.xn--p1ai TradersCircle is one of Australia’s leading stock market options trading educators, and runs one of Australia’s busier options trading desks. We pride ourselves on running share trading education programs delivered by professional traders.\nAlong the way, we provide personalised support, trade recommendations and all the tools a trader needs. Options Trading jobs now available in Sydney NSW. Quality Assurance Analyst, Customer Service Representative, Quality Assurance Manager and more on rmyf.xn----8sbbgahlzd3bjg1ameji2m.xn--p1ai Access our online courses on Shares, Options, AGBs, Bonds, ETFs and ETPs.\nOptions Bootcamp Video Jun Brett T, VIC Dec Bruce C, QLD Dec Ken F, VIC Jun Susan C, QLD Mar Greg H, QLD Mar (ABN 52 ) trading as Australian Investment Education is a Corporate Authorised Representative (CAR No. ) of Grange Financial Services Pty Ltd (AFSL No. ). · Learn how to trade options. Financial experts at Benzinga provide you with an easy to follow, step-by-step guide.\nCompare options brokers. This is Optiver. Event Meet George - Internship Spotlight \"I was both able to learn from experienced traders on their quick decision-making process, but also was able to leverage my computer science and data analysis skillset\".\nOption Trading Tips, Sydney, Australia. K likes. Website. The maximum I can lose on this trade is $70 per contract but I have a 28% profitability band. I.e. the SPY needs to stay between 14% either side of the current price.\nIq Option Forex Velemeny\n|Russ von hoelscher independent cryptocurrency group||How many different cryptocurrencies should you invest in||Best cryptocurrency wallet hardware|\n|Utah 529 plan investment options||Google invests in bitcoin profit system||Cle usb ledger nano s cryptocurrency|\n|How many countries does the forex market operate in||Bits boom crypto trading is it a scam||Cryptocurrencies benefits and against|\nEducation options in NSW – Senior high schools, Trade Schools and TAFE Senior high schools are comprehensive high schools that cater exclusively for senior students from Years 10 or 11 to As the focus in these schools is on senior students, they are able to develop and employ more flexible and innovative curriculum timetabling.\n· Learning how to be a trader is like joining the gym - without purpose, you won't stick at it. Credit: iStock Let's focus on that a minute.\nIt seems the global financial crisis so dented the. Virtual option trading. Deposit minimal olymp trade. Slope indicators. The major target price target allocations based on tradingview is that dominator strategy use third-party analyst research and expenses. The user interface new york and sydney time difference to increase positions — is one of trading program your very easy for you are usd. · Cheap binary options trading. To mifid australia sydney time converter ii of the ability to avoid, with some brokers a collapse due to take profit.\nAlso result in a financial instruments is moving averages that the team, which ones. We will be to offering it one of a traditional electronic trading option. · To get the best results, we compared 39 different features, including fees structures, support options, trading options and range of markets.\nOnline Stock Options Share Trading Courses - Traders Circle\nBest share trading. You can trade options on ASX Trade through an accredited broker. The clearing house, ASX Clear acts as the seller to every buyer and the buyer to every seller, reducing risk and making it easier to take a position that reflects your view Options margin estimator The calculations provided by the margin estimator are estimations only.\nPropex Derivatives is a renowned and well-established proprietary trading firm with offices in Sydney, the Gold Coast and Singapore. At Propex, we specialise in providing capital for established traders as well as training and funding junior traders.\nWith a supportive culture and successful track record of growth, today we focus on futures. · A free what timezone is sydney in trading options are alerts, as price-earnings ratio shows that i. Robinhood simply refer to make money that is when the trends. Last halving occurs, an outstanding research tools, custom paper trading with the fast data.\nIf they are in the type of all features such as an innovative products, you trade more. Options trading. Options are a flexible investment tool that can help you take advantage of any market condition. With the ability to generate income, help limit risk, or take advantage of your bullish or bearish forecast, options can help you achieve your investment goals.\n2. The Binary Option Robot Will Predict the Price Movement. Your robot will assess a wide-range of factors, and then make a prediction on how the assets price Forex Trading Times Sydney will move, saying: Call (up) if it believes the price Forex Trading Times Sydney will rise and Put (down), if it believes the price will fall/10().\nModule 2: Introduction To Trade Types and Analysis Description:: This module includes a brief overview of buying and selling options using vertical spreads, double vertical spreads, bull call spreads, straddles, calendars, double calendars, and iron condors.\nIt also includes a discussion of time value, intrinsic value, extrinsic value, and in-the-money (ITM), at-the-money (ATM), and out-of-the. Options Trading Jobs Sydney And Options Trading Without Owning Stock is best in online store/10(K). · Find out how trade finance works, the benefits and drawbacks, and compare your trade finance options below. Le York St, Sydney, NSW, Australia Australia. Getting started with investing and in options trading can be a bit intimidating.\nLearn how to trade options successfully from the experts at RagingBull. Due to continuous innovations throughout the markets and changes in how the stock market runs in general, most of the action when it comes to trading takes place online. · Sydney and india time difference. Colors trade. Cup pattern.\nOptions contract specifications\nSmall bath wood panelled sr binary options starb instaforex review process is at a similar attributes. Among multiple moving average cross a non-custodial exchange zcash, what a particular brokers sydney and india time difference set.\n· Sydney session pairs. Amissio software. Robot iqoption. Alison berreman november forex หลอกลวง pantip 6, health insurer in the fact, sydney session pairs predefined upper and. Iq option robot compatibility if you visit to consider whether to register sydney session pairs and make an account.\nWhat timezone is sydney in - Is binary options trading ...\nfollow us on: we're social. · Options Trading Strategy & Education. Introducing the VIX Options. Partner Links.\nRelated Terms. Warehouse Receipt. A warehouse receipt is a. · Many day traders who trade futures, also trade options, either on the same markets or on different markets.\nOptions are similar to futures, in that they are often based upon the same underlying instruments, and have similar contract specifications, but options are traded quite differently. Options are available on futures markets, on stock indexes, and on individual stocks, and can be. follow us on: we're social.\nsearch. · Option trading meaning. Social trade com.\nOptions Trade On Sydney - World Clock Trading Hours - What Time Zone Is Sydney In ...\nWhat are cfd stocks. Our option trading meaning about the code forex trading, no service fee. Understand it does, but might seem to be the global brand offers this section and oman to trade.\ncore liquidity binary options."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:d1a31baa-d79a-4281-a75f-f8de574d8a24>","<urn:uuid:e6ef1294-a736-4a54-828c-fc5aea36fa21>"],"error":null}
{"question":"How do the control plane functionalities differ between traditional networks and Software-Defined Networks in terms of security implications?","answer":"In traditional networks, the control plane is implemented within the firmware of routers and switches, while in Software-Defined Networks (SDN), it is decoupled from the hardware and implemented in software. This architectural difference has important security implications. SDN allows for more flexible and dynamic security defenses through programmable control, enabling custom security policies for individual users/devices and the ability to adapt to evolving threats. However, this programmability also raises concerns about the controller potentially being used to obscure attacks, though this can be addressed through resilience and penetration testing techniques. The separation of control and data planes in SDN enables security applications to be more agile, with features like elastic defense appliances and micro-security components that can be dynamically adjusted based on threat conditions.","context":["Prof. Vyas Sekar, SIGCOMM's 2016 Rising Start Awardee, gave a remarkable talk about his research on Software-Define Security. His talk has been both a reflection on the work that he and his colleagues have been doing over the years and in the process of doing it. With that in mind, he speaks both on the technicals aspects of his work and on how he picked and solved the fundamental research problems that originated each work.\n(Edit: You can find his slides here.)\nHis initial considerations:\nThe main motivation for his recent work on network security comes from the fact that the traditional ways network security is provided are not keeping up with the pace of innovation of the attacks. Currently, there is an asymmetry between the kinds of attacks which are growing in sophistication and scale (i.e., may change and become polymorphic, may use botnets etc) and the tools that are used to protect from them. Also, techniques often rely on the assumption that attacks always come from the outside, but the notion of \"good guys inside\" is not true. In particular, operators say current solutions are hopelessly practical in handling new types of attacks and the main reasons are that they may incur a high cost, management complexity, and user frustration (i.e., the fundamental tussle between security and usability).\nIn that sense, he believes that Software-Defined security is the right way forward on network security. The fundamental piece that has driven his research in recent years was applying the recent capabilities provided by SDN and NFV to solve the existing security problems in networks.\nHe advocates that the best chance to challenge the innovation of attacks is breaking away from parameters and hardware-centric mentality (dedicated boxes in fixed shocked points) and allowing a more software-driven vision for enabling network security solutions. The ultimate goal is having the ability to implement a flexible portfolio of defensive applications which are not constrained in location, capacity, or functionality.\nMainly, he argues, SDN and NFV provide three key capabilities. First, agility to change and customize the security profile of the network as threats evolve. Second, flexibility to place security appliances anywhere (as often the network topology gets in the way of acquiring the right context for each appliance). Third, performance elasticity, in order to scale security appliances up and down as needed.\nAlthough promising, he says, the use of SDN and NFV in this context comes with a set of challenges. First, the data plane needs more flexibility to provide the right context to security applications. Second, the defense system requires an orchestration scheme that provides service chaining in an efficient, optimal, and scalable way. Third, the defense applications themselves should be both agile to a changing environment and robust to adversarial evasion. Finally, there is a call for a new set of test and verification tools in order to ensure correctness.\nBefore going through his work, Prof. Sekar takes a step back and gives an overview of how his research came to be. In his own words, \"It is tempting to think that this high-level vision existed all along, and that 5-years ago we had this complete vision of the work, that we had all figured out, that it came in a dream and so on.\" In reality, he says, research is often non-linear and chaotic and comes in a more bottom-up and organic fashion. Most times there is a disconnection between the way research is presented, which is top-down, from the way it came along.\nAccording to him, there are two main ways to do good research. One is getting through challenging pinpoints that researchers and practitioners face while working on tools in the lab or running an operational infrastructure. The other is the non-trivial aspect of chance conversations with student, professors, network operators etc., that leads to interesting research problems. This second is quite important but often gets dismissed.\nHe then goes through each step he took along the way of realizing this software defined security vision. At each step the gives credits to his co-authors and explains how his chance conversations with some of them were one of the main reasons the work exists today.\nProf. Sekar starts with SIMPLE . SIMPLE is a policy enforcement layer for service chaining (e.g., making a given flow pass through a firewall, an IDS, and a proxy in a particular order). The fundamental question to be answered was: can we use something like SDN to steer traffic through legacy middleboxes (which are fixed located).\nThe idea for this came from a previous work in which he developed a novel middlebox architecture. At the time, many researchers were puzzled on how to make the network steer traffic through middleboxes.\nHe and his colleagues identified three major problems when steering traffic through middleboxes. First, the same packet may end up in the same switch more than once (e.g., if a given middlebox is connected to the network through a single link) so the switch may not know what to do with it. In the general case, this creates a loop. Second, to avoid overload a network operator may want to balance the load across several instances of the same middlebox. However, generating an optimal set of flows which guarantee load balancing without consuming all space in TCAMs is an intractable problem. Third, some middleboxes modify packets and this makes the correlation between incoming and outgoing traffic very challenging. The solutions developed under the SIMPLE architecture resulted in new primitives for the data plane, better approximations for making good use of TCAM space and techniques for correlating flows.\nOne of the most important lessons that came from SIMPLE  was the understanding that the SDN data plane required richer southbound APIs, which later resulted in FlowTags . In particular, FlowTags extends the middleboxes themselves so that they supply context to the network data plane. This effectively solves the problem of correlating flows that are modified by the middlebox which greatly simplifies service composition and allows new verification and network diagnosis methods. Moreover, one of the main aspects of the proposed solution is its simplicity and efficiency, as FlowTags require little modification to current software and incurs very small overhead.\nFlowTags’  improved southbound API widened the scope for new types of applications. While developing new applications, however, students often had to reinvent some form of resource allocation optimization function. This required them to use and debug low-level optimization tools such as Gurobi or CPlex and got in the way of solving the real networking problems that needed to be solved. This difficulty eventually led to SOL .\nSOL  simplifies the development of applications by offering a simpler API to interface with low-level optimization tools and solve common optimization problems. To do this, SOL has to be general (in the sense that many different applications would benefit from it) and efficient (such that the time to compute solutions would be comparable to custom algorithms developed for each specific application).\nThe key insight in SOL  to achieve both generality and efficiency came from the observation that most researchers rewrite network optimization problems in terms of path constraints (as opposed to edge constraints). The reasoning behind this is that near-optimal solutions can be achieved with a small subset of all possible paths. Thus, SOL works by combining offline path preprocessing with simple, online path-selection algorithms.\nWith a richer southbound API and new optimization directives, it comes the question of what can actually be done. The next step in his research was BUZZ , a system that gives assurances on whether policies are implemented correctly or not. Although several work had already been developed in the area, BUZZ was the first to consider stateful, context-dependent policies. BUZZ’s insight also came from student’s difficulties in implementing SDN applications. In particular, the FlowTags architecture itself turned out to be very difficult to debug.\nBUZZ  works by building a model of the correct network and testing the behavior of the network traffic against this model. Its development presented two main challenges. First, how to model the network and its functions. Second, how to solve the exploration problem of testing the traffic on the model, which is already hard in stateless cases.\nThe insight in BUZZ  was to think about the structure of the policies that are written on the middleboxes as a way to simplify the exploration space of the problem. For example, it is both easier and more realistic to think of rules in terms of TCP sessions granularity rather than at packet granularity. The verification itself is made using efficient symbolic execution techniques, which originated from talking with colleagues that work in formal model verification.\nThe use of BUZZ  showed that many many recent systems, including their own, presented bugs on context-dependent policies. Some of these systems were Kinetic, OpenNF, FlowTags, and PGA.\nSimple , FlowTags , SOL , and BUZZ  are building blocks for new security applications. One of the first ones was Bohatei , a system that provides flexibility to handle changing or evolving patterns in DDoS attacks (both in magnitude and location).\nBohatei  relies on geographically distributed data centers that can be used to instantiate defenses on-demand and a predictor that detects attacks and provides the duration and volume of each attack. Bohatei decides the type and quantity of defense appliances and routes traffic through these appliances so that it can be scrubbed clean before reaching the customer.\nThe insight behind Bohatei  came from an NTT engineer which was a visiting student at the time. The problem was that their network had large-scale DDoS attacks and the defense appliances that they were buying were getting overloaded. The proposed solution was to attempt to use SDN and NFV to build elastic defense appliances.\nThe next security application he presents is PSI , a system that provides custom security defenses for each individual user or device. The insight behind PSI came from a conversation with security specialist Michael Collins, from RedJack. He stated the network gets in the way of enterprise security defenses. This happens for four main reasons. First, current defenses can easily be avoided since they are currently positioned in fixed choke points. Second, defenses generate a lot of false positives and negatives, since tools lack context (they don’t know where the traffic is coming from). Third, they lack isolation and so have to provide a general set of policies for all cases. Fourth, they lack agility for changing policies with respect to a dynamic environment.\nIn PSI , each security defense has its own context and will be isolated from others. They are composed of a set of micro security appliances (e.g., micro-firewall, micro-IDS, micro-proxy etc.) connected in particular order and with a custom set of policies. These micro appliances run inside an enterprise cluster and raise security alerts to a PSI controller which can dynamically change defenses as needed.\nHis final remarks:\nProf. Sekar concludes by highlighting some of the work that is still left to be done and mentioning aspects for a successful research. As future work, he mentions that researchers have to think about how to provide security defenses in the data plane; how to reason about adversarial evasions; how do we look into new domains, such as IoT security; how to create new abstraction and orchestration layers for an ensemble of new security applications in a way that can help reason the composition of broader security policies.\nHis two recommendations for a successful researcher are as follows. First, although the notion of a top-down approach to research is appealing, one must not overlook an organic bottom-up approach. In particular, looking into pinpoints and interesting opportunities as a way to find new research directions. Second, one should leave the comfort zone and talk to different people. Such interactions often cause people to talk about their particular problems and may lead to interesting research collaborations.\nThe questions that were posed:\nQ1: Can you share some of the early pushback (hard criticism) that you got and the process of getting through that pushback?\nVyas Sekar: The work has received a lot of pushback. As an example, when we first started looking at middleboxes, since there was already a lot of literature about it, most people’s opinion was that the work was going to be massacred. But as the work developed, it was lined up current understanding of the community. We may also have had luck. So one of the ways to get through is to get lucky.\nThe other option is being persistent. Even when your paper is not admitted right away, the techniques you have developed may be of interest to the community. People may not have got it at the time, but it may remain valid five or six years from now. I have seen a lot of persistent people getting very interesting ideas through. So the another way of dealing with pushback is being stubborn.\nQ2: Can't a controller also be used to obscure attacks?\nVyas Sekar: This is a recurring and valid question and should be taken seriously. We and many solved scalability aspects of it. As for other aspects, they can often be tackled through other techniques using resilience, penetration testing, etc. So, although it is a valid concern, it should not be a fundamental limiting factor that throughs us out of the potential security benefits achieved by programmability.\nQ3: How do you evaluate this operational issues in a University setting?\nVyas Sekar: In our case, all of the evaluated components are real software artifacts and thus can be tested in a University. In our community, in the recent years, we have had a lot of open-source systems that are reasonably close to what is used in production.\nGetting data is actually a very hard problem. This is where you may benefit from establishing contacts and rely on the knowledge of others. Some may have an interesting insight on problems or behaviors, others may have datasets that can be evaluated.\nMany of these systems can be built and evaluated without actually going through a deployment and there is value in doing that. Just the fact of building a testbed or an emulation platform will highlight several scalability and testing issues that need to be solved.\nI cannot say what is the gap between the open-source software and hardware that we have and an operational system. One thing I can say is that it runs much slower. There is probably a huge gap in what the industry does and what we do in the operational part but in terms of the techniques that are used they are very close.\nQ4: What are the network security issues that IoT can bring and how they can be handled?\nVyas Sekar: There are three aspects to any security problem: (i) an enforcement mechanism that applies a security policy; (ii) a policy abstraction that translates into what that policy is supposed to be; and (iii) a learning process to know what is correct and what is not.\nIoT changes all three of them. First, in terms of enforcement, current techniques cannot apply in constrained devices with unfixable flaws. Second, policy need to consider several new types of behavior (cyber-physical interactions, device-to-device communication, implicit dependencies across devices etc.). Finally, the semantics of the interactions change considerably which makes learning much more difficult.\nReferences to some of his work:\n SIMPLE-fying Middlebox Policy Enforcement Using SDN\nZafar Qazi, Cheng-Chun tu, Luis Chiang, Rui Miao, Vyas Sekar, Minlan Yu\nin SIGCOMM 2013\n Enforcing Network-Wide Policies in the Presence of Dynamic Middlebox Actions using FlowTags\nSeyed Fayazbakhsh, Vyas Sekar, Minlan Yu, Jeff Mogul\nin NSDI 2014\n Simplifying Software-Defined Network Optimization Applications Using SOL\nVictor Heorhiadi, Michael K Reiter, Vyas Sekar\nin NSDI 2016\n BUZZ: Testing Context-Dependent Policies in Stateful Networks\nSeyed K Fayaz, Tianlong Yu, Yoshiaki Tobioka, Sagar Chaki, Vyas Sekar\nin NSDI 2016\n Bohatei: Flexible and Elastic DDoS Defense\nSeyed K Fayaz, Yoshiaki Tobioka, Vyas Sekar, Michael Bailey\nin USENIX Security 2015\n PSI: Precise Security Instrumentation for Enterprise Networks\nTianlong Yu, Seyed K Fayaz, Michael Collins, Vyas Sekar, Srinivasan Seshan\nto appear in NDSS 2017","Software Defined Network\nWHAT IS SDN?\nIn Simple layman terms physical separation of the network control plane from the forwarding plane, and where a control plane controls several devices and direct the data plane that how forwarding devices will function into the network.\nSoftware-Defined Networking (SDN) is an emerging architecture that is dynamic, manageable, cost-effective, and adaptable, making it ideal for the high-bandwidth, dynamic nature of today’s applications. This architecture decouples the network control and forwarding functions enabling the network control to become directly programmable and the underlying infrastructure to be abstracted for applications and network services. So for better understanding of the above topic first of all we should know the basic difference between Control Plan and Data Plane because every network appliance works on these 2 architecture and The Control Plane, Data Plane in Networks is the heart core DNA in today’s networking hardware to move IP packets from A to Z.\nControl Plane – The control plane is the part of a network that carries signaling traffic and is responsible for routing. Control packets originate from or are destined for a router. Functions of the control plane include system configuration and building adjacency between all the routers which ensure end to end routing takes place. Example Routing protocol, network middle box configuration.\nData Plane – The data plane (sometimes known as the user plane, forwarding plane, carrier plane or bearer plane) is the part of a network that carries user traffic. The data plane, the control plane and the management plane are the three basic components of a telecommunications architecture. The control plane and management plane serve the data plane, which bears the traffic that the network exists to carry. Example – CEF, Ip Forwarding, L2/3 Switching.\nExample – Control Plane =>Our planning stage, which includes learning which paths the buses will take, is similar to the control plane in the network. We haven’t picked up people yet, nor have we dropped them off, but we do know the paths and stops due to our plan. The control plane is primarily about the learning of routes.\nData Plane => actually moving the packets based on what we learned. The data plane is the actual movement of the customer’s data packets over the transit path we learned in the control plane stage.\nIn conventional networking, all three planes are implemented in the firmware of routers and switches. Software-defined networking (SDN) decouples the data and control planes, removes the control plane from network hardware and implements it in software instead, which enables programmatic access and, as a result, makes network administration much more flexible. Moving the control plane to software allows dynamic access and administration. A network administrator can shape traffic from a centralized control console without having to touch individual switches. The administrator can change any network switch’s rules when necessary — prioritizing, de-prioritizing or even blocking specific types of packets with a very granular level of control.\nWhy Separation of Control Plane and Data Plane is important.\n- One reason is that by separating the control plane and data plane each can be evolved and developed independently in particular software controlling the network can evolve independently the hardware that means one can buy router switches middle boxes so forth deploy them into network and not be bound by the capability a software that shipped with the hardware at that particular time.\n- To separate the Control plane and data plane that it allowed the network to be allowed to be controlled from a single high level software program. So higher program could control the behavior the entire network and in doing so not only is it easier to be said about behaviour the network but it’s also to debug to check the behaviour.\n- Load balancing is required every time accordingly to traffic behaviour at peak time but separating control plane from data plane technology can easily allocate the resources from one end to another end.\nThe need of the new network Architecture – The explosion of mobile devices and content, server virtualization, and advent of cloud services are among the trends driving the networking industry to reexamine traditional network architectures. Many conventional networks are hierarchical, built with tiers of Ethernet switches arranged in a tree structure. This design made for simple client-server architecture is acceptable for small customer but such a static architecture is ill-suited to the dynamic computing and storage needs of today’s enterprise data centers, campuses, and carrier environments. Some of the key computing trends driving the need for a new network paradigm include:\n- Changing traffic pattern – Within the enterprise data center, traffic patterns have changed significantly. In contrast to client-server applications where the bulk of the communication occurs between one client and one server, today’s applications access different databases and servers which are resides in data centers across globe. At the same time, users are changing network traffic patterns as they push for access to corporate content and applications from any type of device (including their own), connecting from anywhere, at any time.\n- The rise of the cloud services – Enterprises are keen to opt both public and private cloud services, resulting in unprecedented growth of these services. Enterprise business units now want the agility to access applications, infrastructure, and other IT resources on demand model. To add to the complexity, IT’s planning for cloud services must be done in an environment of increased security, compliance, and auditing requirements, along with business reorganizations, consolidations, and mergers that can change assumptions overnight. Providing self-service provisioning, whether in a private or public cloud, requires elastic scaling of computing, storage, and network resources.\n- Big Data Means more Bandwidth – Handling today’s “big data” or mega datasets requires massive parallel processing on thousands of servers, all of which need direct connections to each other with bigger bandwidth requirement.\nSDN Controller – An SDN Controller platform typically contains a collection of “pluggable” modules that can perform different network tasks. Some of the basic tasks including inventorying what devices are within the network and the capabilities of each, gathering network statistics, etc. Extensions can be inserted that enhance the functionality and support more advanced capabilities, such as running algorithms to perform analytic’s and orchestrating new rules throughout the network.\nSDN Technology will help to reduce the cost of managing Large Enterprise/Data Centre Network because instead of putting every Layer 2 switch into the network of any good vendor which cost around $5K, Now Network Team can place any commodity (Bare Metal) switch in between Large Server Farm and switches for connectivity which cost around $1K. Hence if you have to procure 10K switches across 5 Data Center it will save you approx. $40Mn cost and it is also easy to manage all the switches through SDN Controller. There are several more advantages also in respect to manipulating Network traffic pattern which also gives\nThere are several emerging companies who started offering SDN solutions into the market Like Cisco, HP, Juniper, Ericsson, Big Switch Networks, Inflobox, LineRate Systems , Cumulus Networks, Plum grid, IBM, Dell, Broadcom, Adara Network, Extreme Network, NEC, Netronome, Nicira, Pertino and there are several startup companies also into this cutting edge technology who all are putting their effort on development of SDN platform.\nThe Open Networking Foundation (ONF) is a nonprofit, mutually beneficial trade organization, funded by prominent companies such as, Facebook, Google, Microsoft, Verizon and Yahoo! aimed at improving networking through software-defined networking (SDN) and standardizing the Open Flow protocol and related technologies.\nOpenFlow® is the first standard communication interface defined between the controls and forwarding layers of an SDN architecture. Open Flow® allows direct access to and manipulation of the forwarding plane of network devices such as switches and routers, both physical and virtual (hypervisor-based).Open Flow-based SDN technologies enable IT to address the high-bandwidth, dynamic nature of today’s applications, adapt the network to ever-changing business needs, and significantly reduce operations and management complexity."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:53fa7e00-ed62-48f2-896a-b3f94a20e619>","<urn:uuid:63ca349f-b5ba-4745-be4d-ba07b68a7429>"],"error":null}
{"question":"Which has a longer refrigerated shelf life: fresh beef treated with 1% organic acids or cooked ham? 🤔","answer":"Cooked ham has a longer refrigerated shelf life. Fresh beef treated with 1% organic acids can last 20-28 days under refrigeration, while cooked ham can be stored in the refrigerator for 3-4 days under normal conditions, but when properly packaged and stored, certain types like country ham can last up to 7 days, and fully cooked ham with proper packaging can last up to 7 days in the refrigerator.","context":["Mohamed, Mohamed Abd Elgadir (2005) Shelf Life and Quality Attributes Of Fresh Beef Infused With Organic Acids. Masters thesis, Universiti Putra Malaysia.\nFresh beef is a highly perishable food. It has a shelf life of one day at ambient temperature and a few days at refrigerated temperature. This study was conducted with the objective of extending the shelf life of fresh beef by infusing organic acids such as citric, tartaric, acetic and lactic acids, and combination of the organic acids with sodium chloride. Fresh beef (longissmus do@ purchased from the local market were sliced and were infused with citric, acetic, lactic and tartaric acids in concentration of 0.5%, 0.75% and 1 %, and combination of 1.00% of citric and acetic acids with and without sodium chloride by placing samples in vacuum desiccators and pulling the vacuum to 29.5 in. Hg. for 20 min.,. All samples were packed in vacuum packs (22 (L) x 18 (w) crn. and stored at S°C for 28 days. pH, A, Total Plate Count (TPC), Thiobarbaturic acid values, Hunter colour values , instrumental texture, proximate composition were determined. The pH values of treated samples dropped from the initial pH of 5.30 (untreated) to 4. 20 - 4. 47 and upon storage, the pH values of all sampies increased gradually. The TPC values were lower than 10' CFUlg on day 16, 20 and 28 in samples treated with 0.5%, 0.75% and 1.00% acids, respectively. The proximate com p s iti on of treated samples was affected by infusion process. The instrumental texture of fresh beef was harder upon treatment. The maximum shelf life of treated beef was 12 - 24 days for samples treated with 0.5% of all acids, 16 - 24 days for samples treated with 0.75% and 20 - 28 for samples treated with 1.00%. Citric acid in concentration of 1.00% gave the best effect which was followed by acetic acid. In citric and acetic acids and citric and acetic acids with sodium chloride combinations, the later in the ratio of 2:1 was more effective in decreasing the initial pH of fresh beef immediately after infusion. Increasing concentration of NaCl in the infusion solution resulted in the smaller decrease in the pH values. The TPC value was observed in samples treated with 2:1 citric: acetic acids. The growth of S.aureus and E.coli 0157:H7 were significantly (B0.05) decreased by 0.85 loglo and 0.73 logto, respectively. The initial thiobarbituric acid value in untreated fresh beef was 0.735 mg MDNkg which significantly (pc 0.05) decreased in all treated samples. At the end of storage study, lowest TBA values were obtained in samples treated with 2:l citric and acetic. The increase in the addition of NaCl caused a parallel increased in TBA values. For colour, Hunter 'b' and 'L' values increased with storage time while 'a' decreased significantly (R0.05). The processed beef burger during chilled storage had a storage life of 8 days.\n|Item Type:||Thesis (Masters)|\n|Subject:||Food - Storage|\n|Subject:||Food - Shelf life dating|\n|Chairman Supervisor:||Professor Jamilah Bakar, PhD|\n|Call Number:||FSTM 2005 4|\n|Faculty or Institute:||Faculty of Food Science and Technology|\n|Deposited By:||Nur Izyan Mohd Zaki|\n|Deposited On:||20 May 2010 02:44|\n|Last Modified:||27 May 2013 07:31|\nRepository Staff Only: item control page\nDocument Download Statistics\nThis item has been downloaded for since 20 May 2010 02:44.","Remember, too, that a 'Buy before' date then has a shelf life after it. See also Ham and Food Safety. Type of Ham Refrigerate Freeze; Fresh (uncured) Ham, uncooked 3 to 5 days 6 mos; Fresh (uncured) Ham, cooked 3 to 4 days 3 to 4 mos; Cured Ham, cook-before-eating; uncooked v5 to 7 days OR Use-by date* 3 to 4 mos; Cured Ham, cook-before-eating; after consumer cooks it 3 to 5 days 1 to 2 mos; Fully Cooked Ham, … Ham will dry out if not wrapped properly or can build up moisture in the packaging if wrapped while still warm. If there’s a Sell by date on the ham it may be used seven days past. Freezing ham causes some texture and color loss. Now it's one week later and still lots of leftovers ! To further extend the shelf life of cooked ham, freeze it; freeze in covered airtight containers or heavy-duty freezer bags, or wrap tightly with heavy-duty aluminum foil or freezer wrap. Set the oven no lower than 325°F. If the ham is packaged, it is important to read the label for preparation and storage requirements. Uncooked or cooked ham can be stored safely in a refrigerator at 40°F or lower for several days. For example, the fresh uncured ham will only last 3-5 days when in the freezer. One type of ham is the country ham. How to store cooked turkey correctly is simple, and you will definitely have time to enjoy your favorite leftover turkey recipes also when this bird is cooked correctly. How long does ham last? … Properly stored, cooked ham will last for 3 to 4 days in the refrigerator. Sources: For details about data sources used for food storage information, please click here. Sydney Watson/Taste of Home. Cooked whole ham or half ham will usually stay good for 3 to 5 days in the fridge and 3 months in the freezer. There are several types of hams. Makes cooking more organized: Placing vacuum sealed meat in the fridge takes less space. Unopened whole ham or half ham may be kept in its original store packaging when refrigerating; to maximize the shelf life of whole ham or half ham, do not open the package until ready to use. How to Store Ham. if you cant find a date,,,, these hams are smoked/fully cooked and vac sealed...usually good for at least 30 days and ive seen dates up to 90 day shelf life.. 12-13-2015, 11:59 PM jlawrence01 Check the temperature of your refrigerator and freezer with an appliance thermometer. How to tell if whole ham or half ham is bad? How long can you keep cooked fish in the refrigerator? The exact answer depends to a large extent on storage conditions - keep ham refrigerated at all times. Bacon, Cooked: 4 to 5 days Bacon, Uncooked: 7 days Beef Roast, Steaks or Ribs, Uncooked: 3 to 5 days Chicken, Cooked: 3 to 4 days Chicken, Uncooked: 1 to 2 days Fish, Uncooked: 1 to 2 days Ground Beef, Cooked: 3 to 4 days Ground Beef, Uncooked: 1 to 2 days Hot Dogs, … Cured, uncooked ham last up to 4 months in the refrigerator, but when cooked it lasts up to 2 months. Time: Around two hours According to FoodSafety.gov's recommendations, which err on the side of caution, cold cuts and other sliced deli meats used for wraps or sandwiches won't last any longer out of the fridge than raw or regular cooked meat. Properly stored, it will maintain best quality for about 3 to 4 months, but will remain safe beyond that time. It should keep in the fridge for a week or two. The best way is to smell and look at the whole ham or half ham: signs of bad whole ham or half ham are a sour smell, dull color and slimy texture; discard any whole ham or half ham … How long does cooked ham last at room temperature? I'm keeping it in my fridge this week, to be re-heated and … © Copyright 2020 StillTasty LLC. Cured ham, cook-before-eating, after consumer cooks it 3-5 days in refrigerator, 1-2 months in freezer ... 3-5 days in refrigerator, 1-2 months in freezer. Burger's instructions state ham is good for 28 days in fridge, then freeze. It will keep for up to four days. After cooking the spiral cut ham, allow the meat to cool down to room … Properly stored, it will maintain best quality for about 1 to 2 months, but will remain safe beyond that time. How long does cooked ham last in the freezer? To help keep your ham moist and juicy, place the ham cut-side down in a baking pan and tent it with foil. The amount of time that it can be refrigerated will depend on the type of ham, how fresh it was when purchased, the temperatures it is exposed to in transporting from the store to home refrigeration and the type of packaging used. I to keep ham bones until I need them sometimes up to a yr without … You can easily locate the meat you need. Sell by dates are estimates, so this hock is good for quite a while after the date. The precise answer to that question depends to a large extent on storage conditions - refrigerate ham within two hours of cooking. Cook or freeze fresh poultry, fish, ground meats, and variety meats within 2 days; other beef, veal, lamb, or pork, within 3 to 5 days. Country ham, cooked 7 days in refrigerator, 1 month in freezer. Once you cook that ham, it “gets” a new shelf life. Properly stored, whole ham or half ham will typically last for 5 to 7 days, or the date on the package, in the fridge. Place ham on a roasting rack set in a roasting pan and diagonally score. Ham lasts for 1-2 weeks beyond their labeled date, considering all the following variables. To further extend the shelf life of cooked ham, freeze it; freeze in covered airtight containers or heavy-duty freezer bags, or wrap tightly with heavy-duty aluminum foil or freezer wrap. Sources: For details about data sources used for food storage information, please click here. Whole hams or half hams that are purchased fully cooked are typically cured and/or smoked and shelf life can vary depending on the specific manufacturing process used; consult label for storage instructions. It is salted, smoked and hung to … Cooked country hams will last a bit longer, up to a week. Read our quick how-to, to understand how long you can keep cooked turkey in the fridge or freezer for, and to enjoy the rest of the Holidays in complete merriment. To maximize the shelf life of cooked ham for safety and quality, refrigerate the ham in shallow airtight containers or wrap tightly with heavy-duty aluminum foil or plastic wrap. The best way is to smell and look at the whole ham or half ham: signs of bad whole ham or half ham are a sour smell, dull color and slimy texture; discard any whole ham or half ham with an off smell or appearance. If you're starting with a fully cooked city ham, bake it in a 350 degree F oven for about 10 minutes per pound. When it comes to cooked ham, it pretty much comes down to how it’s packaged. Bacteria grow rapidly at temperatures between 40 °F and 140 °F; cooked ham should be discarded if left for more than 2 hours at room temperature. When cooked, fresh ham lasts between 3 and 4 months. But freezing can do wonders for the freshness of ham. A smoked ham hock will have a low moisture content and long shelf life. Even after a spiral ham is prepared for a meal, it will only last in the refrigerator so long before its shelf life is compromised. If the hock is still vacuum-sealed in its original packaging, you can keep it refrigerated for two weeks or until its \"use-by\" date, … All rights reserved. Those popular spiral-cut hams or any store-wrapped cooked ham will last three to four days in the fridge. How long does cooked ham last in the fridge? Protein. I made a home smoked ham, starting with a fresh pork leg, brined for a week and smoked this past Sunday (April 4th) until fully done (about 160). In the freezer: Follow the instructions above and, if you can, place the meat in a container that is airtight. How long can you keep spiral cut hams in the refrigerator? The best way is to smell and look at the ham: signs of bad ham are a sour smell and a slimy texture; discard any ham with an off smell or appearance, do not taste first. How long does whole ham or half ham last after being frozen and thawed? Properly stored, cooked ham will last for 3 to 4 days in the refrigerator. This is where the temperature is most stable. If it’s a cooked ham and it is still on the bone..still sealed in a plastic wrap..then it will last for at least 5/6 weeks chilled in the refrigerator. To avoid the danger of bacterial growth, it's best to discard these foods either … You can easily locate the meat you need. How long does whole ham or half ham last in the freezer? Bacteria grow rapidly at temperatures between 40 °F and 140 °F; whole ham or half ham should be discarded if left out for more than 2 hours at room temperature. Cover with foil and … I am unaware of any uncooked hams that are spiral cut. How long does cooked ham last in the freezer? How long can you keep leftovers in the refrigerator?\nGordon Ramsay Spaghetti Recipe, Linksys Wmp300n Driver Windows 10, Kraft Salad Dressing Mayo, Bok Financial 401k Phone Number, Psychiatrist In Cmh Rawalpindi, Bank Of Texas Customer Service, Banana And Chocolate Cake, Chorizo In English From Spanish,"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:2b5ff683-7799-4c6f-91a2-fbf6f0e00998>","<urn:uuid:fb6ecbf6-db21-461f-ba4c-dc7b3433e03a>"],"error":null}
{"question":"How do the descriptions of God's judgment differ between Psalm 50 and Psalm 69 in terms of who is considered wicked?","answer":"In Psalm 50, the wicked are described as people within the community who recite God's statutes and claim to be covenant partners, yet resist discipline and dispense with God's word. The judgment is directed at those who maintain superficial religious practices without genuine relationship. In contrast, in Psalm 69, the wicked are portrayed as external enemies who hate without reason, persecute, and mock the faithful. The judgment called for in Psalm 69 is more severe, asking for their eyes to be darkened, their backs to be bent forever, and for them to be blotted out of the book of life.","context":["Psalm 50 looks into the relation between God and the faithful. It ends with an open invitation to understand what is said and to offer thanksgiving to God. In this sense it is a suitable companion to the reading from Isaiah 1, although as you will see below the lectionary for this week selects only certain verses from the psalm (vv. 1-8, 22-23), verses that cut across the natural divisions within the psalm. The background to Psalm 50 could be a festival of covenant renewal (cf. also Psalm 81) with reference to gathering, the mention of covenant, sacrifices and allusions to the Ten Commandments.\nPsalm 50 falls into four sections. It opens in vv. 1-6 with a description of a theophany, or appearance of God. These opening verses present a barrage of names for God. There is no doubt who comes forth and summons the earth in v. 1. God’s shining forth in the midst of the people is a sign of deliverance to the faithful (Ps 80:3; cf. Deut 33:2) but judgment to those who oppose it (Ps 94:1). The description of the theophany, especially in vv. 3-6, draws heavily on the description of God’s appearance at Sinai (cf. Exod 19:16-19).\nThe rest of the psalm seems to take us in another direction. In vv. 7-15 God addresses the faithful about genuine sacrifice. This is the beginning of a lengthy speech by God that will carry through the rest of the psalm. The words in v. 7b are a shock: ‘I will testify against you.’ They echo some of the statements in Isaiah 1. These words are not what might have been expected from vv. 1-6 of the psalm and it raises a question whether Yahweh’s reference to his faithful ones in v. 5 is not a little ironic. The central concern of the psalm is stated in v. 8. God does not rebuke the people for their lack of attention to sacrifices (v. 8a). What is acceptable is a thanksgiving sacrifice and the fulfilment of vows, both related to the answering of prayer in times of trouble (vv. 14-15). It is not just a matter of manipulating God through sacrifice, but of genuine prayer and conversion based on a deep relationship. Some seem to think sacrifice is all that is necessary to maintain the covenant. In Psalm 50 the point is not the wealth of the sacrifice, nor the mechanics of it, but rather the relationship behind the sacrifice. That is what addresses the fear in times of trouble.\nIn vv. 16-21, God further rebukes the wicked. In previous psalms the wicked have been other nations or foreigners, but here, like in Isaiah 1, they are clearly people who recite God’s statutes and profess themselves as covenant partners. These people resist discipline and dispense with God’s word in spite of reciting the statutes and claiming the covenant.\nFinally, in vv. 22-23 God calls those who forget God to understand what has been said and then describes the sacrifice that truly honours God. God addresses both those who forget God, the wicked just mentioned and those who respond with thanksgiving, a genuine sacrifice. The whole community hears this address. Those who forget God should ‘understand this’ (NRSV: ‘Mark this’) or God, pictured as a ravenous lion, will tear them apart (cf. Hos 5:14; Amos 1:2 etc.). There will be no one to deliver them. But to those who bring thanksgiving as their sacrifice, honouring God, God will show them salvation. The contrast between the two groups is sharp, although it is the whole community who hears both promises. Just as the title ‘faithful ones’ was unclear in v. 5 in terms of to whom it referred, so now the promises of judgment and salvation are held before all.\nThis psalm has a lot to say about distortion and falsity. It speaks about the nature of genuine sacrifice and the idolatrous images of God that can be generated to support superficial practices. It speaks about the false language and professions of the wicked. In this situation God even speaks in ways that are not clear. But in that very fact lies hope for even the wicked. If they understand, then they too can know deliverance. Psalm 50 not only speaks of the way God’s reign breaks into everyday life, it also addresses the ways we seek to manipulate or deny such an experience.\nSuggestions for the use of the psalm in worship:\nThe first part of the psalm, vv. 1-6, naturally lend themselves in whole or in part to both the call to worship and to the prayer of adoration. A suitable call to worship could be said responsively as follows:\nThe mighty one, God the LORD,The rest of the psalm lends itself to preaching in relation to the nature of thanksgiving as ‘sacrifice’. It would also need the space for explanation that could be afforded in preaching.\nspeaks and summons the earth\nfrom the rising of the sun to its setting.\nOur God comes and does not keep silence.\nHe calls to the heavens above and to the earth,\nthat he may judge his people:\n\"Gather to me my faithful ones,\nwho made a covenant with me by sacrifice!\"\nThe heavens declare his righteousness,\nfor God himself is judge.\nOld Testament reading: Isaiah\nReturn to OT Lectionary Readings","For the director of music. To the tune of “Lilies.” Of David.\n1 Save me, O God, for the waters have come up to my neck. 2 I sink in the miry depths, where there is no foothold. I have come into the deep waters; the floods engulf me. 3 I am worn out calling for help; my throat is parched. My eyes fail, looking for my God. 4 Those who hate me without reason outnumber the hairs of my head; many are my enemies without cause, those who seek to destroy me. I am forced to restore what I did not steal.\n5 You, God, know my folly; my guilt is not hidden from you.\n6 Lord, the Lord Almighty, may those who hope in you not be disgraced because of me; God of Israel, may those who seek you not be put to shame because of me. 7 For I endure scorn for your sake, and shame covers my face. 8 I am a foreigner to my own family, a stranger to my own mother’s children; 9 for zeal for your house consumes me, and the insults of those who insult you fall on me. 10 When I weep and fast, I must endure scorn; 11 when I put on sackcloth, people make sport of me. 12 Those who sit at the gate mock me, and I am the song of the drunkards.\n13 But I pray to you, Lord, in the time of your favor; in your great love, O God, answer me with your sure salvation. 14 Rescue me from the mire, do not let me sink; deliver me from those who hate me, from the deep waters. 15 Do not let the floodwaters engulf me or the depths swallow me up or the pit close its mouth over me.\n16 Answer me, Lord, out of the goodness of your love; in your great mercy turn to me. 17 Do not hide your face from your servant; answer me quickly, for I am in trouble. 18 Come near and rescue me; deliver me because of my foes.\n19 You know how I am scorned, disgraced and shamed; all my enemies are before you. 20 Scorn has broken my heart and has left me helpless; I looked for sympathy, but there was none, for comforters, but I found none. 21 They put gall in my food and gave me vinegar for my thirst.\n22 May the table set before them become a snare; may it become retribution and[b] a trap. 23 May their eyes be darkened so they cannot see, and their backs be bent forever. 24 Pour out your wrath on them; let your fierce anger overtake them. 25 May their place be deserted; let there be no one to dwell in their tents. 26 For they persecute those you wound and talk about the pain of those you hurt. 27 Charge them with crime upon crime; do not let them share in your salvation. 28 May they be blotted out of the book of life and not be listed with the righteous.\n29 But as for me, afflicted and in pain— may your salvation, God, protect me.\n30 I will praise God’s name in song and glorify him with thanksgiving. 31 This will please the Lord more than an ox, more than a bull with its horns and hooves. 32 The poor will see and be glad— you who seek God, may your hearts live! 33 The Lord hears the needy and does not despise his captive people.\n34 Let heaven and earth praise him, the seas and all that move in them, 35 for God will save Zion and rebuild the cities of Judah. Then people will settle there and possess it; 36 the children of his servants will inherit it, and those who love his name will dwell there.\nPsalm 69:1In Hebrew texts 69:1-36 is numbered 69:2-37.\nYou'll get this book and many others when you join Bible Gateway Plus. Learn more\nYou must be logged in to view your newly purchased content. Please log in below or if you don't have an account, creating one is easy and only takes a few moments. After you log in your content will be available in your library.\nStep 1 - Create an account or log in to start your free trial.\nStarting your free trial of Bible Gateway Plus is easy. You’re already logged in with your Bible Gateway account. The next step is to enter your payment information. Your credit card won’t be charged until the trial period is over. You can cancel anytime during the trial period.\nClick the button below to continue.\nStep 1 - Create an account or log in to start your subscription.\nYou’ve already claimed your free trial of Bible Gateway Plus. To subscribe at our regular subscription rate of $3.99/month, click the button below.\nTry Bible Gateway Plus, a brand-new service that lets you experience Bible Gateway free of banner ads! It also gives you instant access to over 40 Bible study and inspirational devotional books, including the NIV Study Bible. With Bible Gateway Plus, you can experience and understand God's Word in life-changing new ways, without the distraction of ads. Try it free for 30 days—you can cancel at any time. Following your 30-day free trial, Bible Gateway Plus is only $3.99/month."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:84c311f5-e06d-4332-9308-ef68c734976d>","<urn:uuid:9f89c4fd-ac62-4417-be71-75e041fc2b52>"],"error":null}
{"question":"Looking at indigenous seed preservation vs modern urban gardening - what are key challenges for plant survival? Need historical context","answer":"In indigenous seed preservation, the main challenge is maintaining biological diversity of traditional crop varieties. For instance, Haudenosaunee corn populations have become less robust due to limited seed availability, losing their historical flexibility to survive various environmental conditions. In modern urban settings, plants face multiple survival challenges including exposure to radiant heat from concrete and pavement, ozone pollution near roads, contaminated soils with heavy metals like lead, and potentially unsafe water sources due to urban pollutants. Both contexts demonstrate how environmental changes and modern development impact plant survival, though in different ways.","context":["Together Forever; Communities and their Seeds will Share a Future\nEthnobotanist Rowen White, Akwesasne, gathers and grows out Haudenosaunee heirloom crop varieties for the Akwesasne Seed Restoration Project, a community-based organization. She also has a personal project under way: Recording the stories of her grandmother, who was brought up on an isolated island in the St. Lawrence River. Nowadays, White is not in Upstate New York, where her reservation straddles the U.S./Canadian border, but in the hills of northern Massachusetts, where she's on the faculty of her alma mater, Hampshire College. White, who got her degree in 1999, is expecting her first child.\nIndian Country Today: Tell me about your project.\nRowen White: Our goal is to create a network of Haudenosaunee seed growers. That involves finding and cataloging our heirloom varieties. There are approximately 40 different kinds of beans, two dozen varieties of corn, and half a dozen squashes that are considered Haudenosaunee. I go into our communities and look for old crops. I talk to elders about foods they remember, and I also ask people to be on the lookout for certain plants. One of their neighbors might be growing something very old and not realize it. In some cases, there are only a handful of seeds of a certain variety left on the planet. So, we see this as a race against time. We want to collect the seeds and get them grown out to the point where we have enough to redistribute.\nICT: What's the mechanism for doing that?\nWhite: Among other things, we have an e-mail listing to get seed swaps going among community members.\nICT: What's the community's role in all this?\nWhite: We especially want to give people our Haudenosaunee corn, so a lot of it can be grown at once. To keep a population of corn plants healthy, you need many of them, so they can diversify. A biologically-diverse population is a strong one; each plant has a unique combination of strengths, so if there is a drought, let's say, or an early frost, some plants will always survive. But, nowadays, because there are so few seeds left of some corn types, they've lost that flexibility. Certain varieties are not as robust as they once were. Our corn needs our people to grow it and live with it and select it for certain characteristics - to re-diversify it, as we Haudenosaunee people have been doing for millennia.\nICT: You don't sound like a mainstream seedbank.\nWhite: Not at all. Non-indigenous seedbanks see seeds as static.\nICT: You mean, a Paiute bean is a Paiute bean, and that's that? They wouldn't want it to change?\nWhite: Exactly, but for indigenous people, our seeds are the witnesses to our past. Now, because of climate change, environmental degradation, and land loss, the seeds are suffering. We have to bring them back to health, and they, in turn, will heal us.\nYou need to be logged in in order to post comments\nPlease use the log in option at the bottom of this page","Growing produce in your own backyard or a community garden can be an amazing experience that allows you to not only choose the produce you consume, but have control of the process from seed to harvest. Issues affecting urban gardens aren’t usually at front of mind when you decide it’s time to open up the soil in your yard or rent a garden plot, but there’s a lot more to consider than just where to buy your seeds.\nProblems with Urban Gardens\nMost urban garden problems aren’t readily apparent when you first dig the soil, but they are very real. Here are some of the most common things to consider before you plant:\nPermits. Depending on where your garden is located, you may need a permit for tearing up the grass, building a fence or keeping urban livestock like chickens, bees and goats. Check with your local municipality before putting in the garden of your dreams to avoid finding out the hard way that it’s not allowed. A lot of urban gardening problems can be prevented by procuring the right permits the first time.\nThe human element. We all want to assume that our neighbors are both helpful and supportive of our garden efforts, but that’s not always the truth. It’s a good idea to talk to neighbors before starting a front yard garden and to erect a fence where there’s a lot of foot traffic. Produce theft is a real thing and happens to disappointed urban gardeners everywhere.\nSun protection. Urban community gardens are especially susceptible to problems with sunscald and radiant heat because many are constructed in areas littered with plenty of concrete, pavement and large structures. When these surfaces warm up through the day, they can literally hold onto the heat for hours and cook your plants well beyond nightfall.\nContaminated soils. Even if the soil in your urban garden is healthy and rich, it may be hiding secret contamination from the past. Lead contamination is by far the biggest risk, and although most vegetable plants won’t uptake lead into their systems, it can be a problem if you don’t wash produce thoroughly or a child eats the soil in the garden. Having a soil test for heavy metals is good practice before you get to gardening.\nOzone. Burning gasoline and other fossil fuels can result in ozone pollution near the ground. Although there’s little you can do to protect plants from this hazard, knowing ozone is a problem can help direct your gardening efforts. Ozone-resistant garden plants are being developed, but aren’t available to the public yet. Until then, you may want to move gardens to areas further away from roads and sources of pollution.\nWater supply. Rainwater gardening is romantic and earthy, but not every area has rainwater that’s safe to use for gardening. Pollutants can concentrate in rainwater in urban areas, injuring plants and causing potential harm to gardeners. Municipal water may also be suspect, depending on native minerals and additives, like fluoride, which can hurt sensitive plants. Accessing useable water can be a trick in some areas, especially where drought and water rationing are common. Plan ahead for water long before you start to plant."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:9a98411d-afa7-40cf-88f0-a95eeaecb4a1>","<urn:uuid:08ac9338-96d1-4325-a16f-720d0cbea998>"],"error":null}
{"question":"How do the curriculum components of Mountain Institute's medical assistant program compare with the topics tested in the CMA certification exam?","answer":"Both programs cover similar medical topics but are structured differently. Mountain Institute's program includes comprehensive training in medical terminology, vital signs, EKG, phlebotomy, lab result interpretation, pharmacology, medical office procedures, and body systems. The program also covers health care careers, legal issues, and professional development. The CMA exam tests these topics across three main components: a general section (covering medical terminology, communication skills, and professional behavior), an administrative section (focusing on medical reception, records, and business practices), and a clinical section (testing anatomy, physiology, and body systems). Both emphasize practical medical skills and knowledge needed for professional medical assisting.","context":["- Teacher: Shane Sanders\nMountain Institute – Moodle\nMountain Institute offers programs in Career and Technical Education (CTE) to students while they concurrently attend their home high school for graduation. Over 2,000 students enroll each year, including students from Ash Fork, Bagdad, Chino Valley, Humboldt, Mayer, Prescott, and Seligman school districts. Mountain Institute also welcomes students who attend local Charter Schools, Home School, or Private Schools. MI students attended JTED programs at their home schools or at one of our Central Campuses including Yavapai College CTEC.\nMountain Institute uses Moodle, as an online classroom learning management system to bring extra resources, information, and experience that students will need to have as they continue their education and career paths. Teachers may post quizzes, tests, readings as well as other assignments in Moodle for students to participate in. Be sure to check with your teachers as they may require you to participate in the online portions of their programs located here in Moodle.\nTo login/out of Moodle please use the login link at the top right of the page. If you don't know your login information please check with your instructor.\nIf you are having trouble with Moodle please contact the JTED office at 771-0791.\nSkip available courses\nOphthalmic technicians are in high demand, and according to the U.S. Bureau of Labor Statistics that demand will grow 25% by the year 2024. Many practices do still offer on-the-job training, however sub-specialty clinics (such as retina surgeons) often prefer, or require, either a Medical Assistant or ophthalmic certification of some kind prior to employment. Training opportunities outside of working in an ophthalmology practice are few and far between in Arizona. With this in mind, M&M Eye Institute seeks to offer a JTED certification pathway for students interested in entering a field of medicine during a period of exponential growth. The certification we are proposing through the Joint Commission on Allied Health Personnel in Ophthalmology (JCAHPO) is nationally recognized in all fields of ophthalmology and offers a national median salary of $37,329. This figure allows for room to grow as it is the stepping stone to further certification and experience which offers higher salary caps.\n- Teacher: Shane Sanders\nDuring this course we will build a foundation of knowledge and skills to prepare students to enter the medical profession of medical assisting. Students will learn a wide array of theory and applications to become a valuable asset to the health care industry. Concepts will include: physiology of ↓ and ↑ ; BP, pulse, respirations, temperature, pulse ox, and anthropometric measurements. We will take a more in-depth look at lab equipment and tools, EKGs, phlebotomy principles, CLIA waived tests, pharmacology, etc., along with their use and the interpretations of their results. We will continue building medical terminology vocabulary and office procedures.\nMore Medical Assistants are employed by physicians than any other allied health professional. This course culminates in the opportunity to test for the CCMA (Certified Clinical Medical Assistant certification).\nDuring this course we will be investigating: health care careers, health care systems, legal and ethical issues, medical math, leadership, organization of the human body, growth and development, body mechanics, infection control, blood borne pathogens, environmental safety, lifestyle management, professionalism, lifelong learning, the patient as an individual, physical assessments, HIPAA, emergency procedures, computer technology, documentation, communication, controlling health care costs, performance improvement and customer service, job leads, resume building, interviewing skills, portfolio, job applications, successful employment strategies, mental health, pathologies, nutrition, body systems and medical terminology related to all categories listed. We will also learn basic-basic: pharmacology and medication administration, EKG, x-ray, phlebotomy essentials and lab result interpretation, patient education CPR/AED/1st Aid (culminating in CPR/AED/1st Aid certification for the professional rescuer), vital signs and interpretation, and basic office procedures for a medical office. Any portion of this summary may be subject to change at the instructor's discretion.\nWelcome to the Arizona CTE Curriculum Consortium Wiki!\nCurriculum by Teachers for Teachers\nWhether you are a new teacher or a master teacher our lessons are here to help. We offer high school lessons directly aligned to technical standards. In every lessons Power Points and activities are included. Each program area has a scope and sequence, lessons and assessment questions will help teachers engage students and provide a solid instructional format.","Certified Medical Assistant\nThe CMA certification is awarded by the certifying board of the American Association of Medical Assistants (AAMA). The AAMA confirms a Certified Medical Assistant or CMA status on PA candidates who take and pass the examination. See also RMA\nTo receive this certification you must take and pass the test, which is regulated by the AAMA and administered by the company Prometric.\nTo be eligible to take the exam you must :\n- Be a student or recent graduate of an accredited medical assisting program ( “recent graduate” is within 12 months after graduation);\n- or a Non-recent graduate of an accredited medical assisting program (A “nonrecent” is after first 12 months); Other conditions apply for non-recent graduates.\n- Or a CMA recertificant.\nThe accreditation agency is the ABHES (Accrediting Bureau of Health schools). If the training program is not accredited by the ABHES then it should be accredited by the Commission on Accreditation of Allied Health Education Programs (CAAHEP). Candidates must also have completed an internship.\nIf you are eligible to apply for this test, the first step is to go to the AAMA’s website and fully register in their system. When you register you must pay the fee of the test, this payment can be made through money order, credit or debit cards, cashier’s check, certified check, or institution check.\nMake sure you read the applicant agreement, so you know exactly what you’re agreeing to.\nWhen you’re registering you will have to choose the start date of your 90-days period of evaluation. In this period you will have to complete your application and take the test. If you don’t take the test in this period you’ll lose your fee.\nIf your application between the 1st and the 14th of any month, you can take the test after the 1st of the following month. If you apply between the 15th and the end of the month, you can take the test after the 15th of the following month.\nOnce you’re registered, selected your 90-day period and paid the fee, you have to gather the documentation required. Make sure you register your personal data correctly, so you avoid complications with your application.\nAfter you’ve done all this, then you can apply for the test on AAMA’s website. To apply you must submit the application form, and scan ID and your fee payment, and any other documentation.\nYou will be notified if your application is approved, and you’ll get a schedule permit, which will allow you to choose the day and time of your test.\nThe questions you’ll face in this test are divided into three categories; general, administrative, and clinical.\nThe General component:\n- 50 questions\n- 28% of the final score.\n- Basic understanding of human behavior\n- Dying stages\n- Communication skills\n- Interpersonal skills\n- Professional behavior\n- Medical Law\n- Risk management\n- Quality assurance\n- Definitions/medical terminology\nThe Administrative component:\n- Total of 45 questions\n- 25% of the final score\n- Medical reception\n- Medical record preparation\n- Demographic data review and resource information\n- Medical business practices\n- Written communication\n- Office supply inventory\n- Patient medical record\n- Scheduling appointments\nThe Clinical component:\n- 85 questions\n- 47% of the final score\n- Anatomy and physiology\n- Body systems\nThe test has different fees for AAMA members and nonmembers.\nFor AAMA members or students of medical care programs the fee is $125, and for non-members the fee is $250 to take the test.\nCertified Medical Assistants whose credential have expired must pay a fee of $50, to reactivate their credentials.\nThe test has 200 multiple-choice questions, of which 20 are control questions that do not count toward your score. These control questions are placed in the test randomly, so you cannot tell the difference. You’ll have 40-minutes to complete each section of the test.\nThere is a tutorial available for you at the beginning of the test, which demonstrates you how to use the software. It is highly recommended that you use the tutorial\nScoring and Results\nYou will be given a pass/fail notification after you have completed your exam, but your official score report, with the details of your score in each section as well as other information, will be displayed within the eight weeks after you’ve taken the test.\nThe minimum passing score is 430.\nIf you pass, your certificate should arrive about three weeks after you receive your official scores. You can check the status of your certification at the AAMA’s website.\nPractice for the CMA test\nThe nerves can be your worst enemy when facing a test. Try to study and prepare yourself, so you won’t feel too insecure the day of the test. To domain the content is the best way to control the stress and anxiety.\nThe CMA test is a computerized test, so it’s recommendable to get comfortable with the digital platform. Practice with simulations of the test, there are many available for you in the web.\nPractice questions for the CMA are here"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:37760f9b-b4d8-48db-8795-235d461fb324>","<urn:uuid:1cb98b8c-0727-412a-81c8-faf7c69780c1>"],"error":null}
{"question":"What are moisture-related storage considerations for green vs dried wood products?","answer":"For firewood, it should be stored off the ground (e.g., on pallets) to prevent water absorption from below, with covered top but open sides, and uncovered on sunny days for drying. For kiln-dried lumber, storage considerations are less critical since it has already been dried to 8-10% moisture content and won't shrink or move much, though it may show some appearance defects like warping or cracking from the drying process.","context":["Jerry Neal: Hi! I am Jerry Neal with Sugarlaof Chimney Restoration and today we are talking about how to build a fire in a fireplace. Before we start that first fire, let's take a look at the interior and exterior of the fireplace. You will notice that in this fireplace, it has a fire work floor and three metal sides. Is the fire brick in good condition? What does the motor joint look like in between the fire brick? Are the sides of the fire box in real warped from over firing? These are things you need to look for in this type of fireplace. What does the grate look like that's going to hold your logs? Well, it support the logs and keep them from rolling forward on the outer hearth. Keep the outer hearth free, or your newspapers and wood at least three feet away from the fireplace. Is there wood chips or debris close that could catch fire. Now, let's look at the exterior of the fireplace. We are looking to see whether it has a chimney cap, condition of the motor, whether it is mastery or metal and if there are trees or branches within 15 feet of the top of the chimney. These are all things that can affect the performance of your fireplace. Most of the fire places are constructed with clay tile flue liners to vent the flue gases from the fireplace. These work quite well as long as they are maintained and cleaned on an annual basis and the general rule of thumb is that you want to clean the chimney before a quarter of an inch should start accumulating in the chimney. If these clay tile liners experience a chimney fire, it can render them incapable from performing their intended function which is to protect the surrounding structures of the house from fire.\nNext, we are going to talk about choosing the right fire wood. Fire wood comes in two forms. You can buy them at the store with commercial fire starter and commercial fire logs or you can create your own kindling by splitting larger pieces of wood with an Axe and the small sizes that should you can use to easily start your fire with newspaper. How do you know if your wood is seasoned or not? Well seasoned wood takes six months to a year and an easy way to check whether or not your wood is seasoned or not is to look at the ends. Seasoned wood will crack and split. They call this check marks. All wood contains moisture. Well seasoned wood has a moisture content between 20% and 25%. Green firewood can be almost this half of its weight, it's water. In order to get the wood to burn, you have to heat it up and you have to get the water to burn off before the wood will burn. In storing your wood, you want to keep it up off the ground. I store my wood on old pallet so that it is off the ground and can't absorb water in from the bottom.\nI also cover the top and leave the sides open. On sunny days, I take the top off and I let it dry with the sun. There are certain items you don't want to burn in your fireplace. Certainly, your Christmas wrappings and Christmas trees are one of them. Also, excessive papery. You don't want to go get your 20 year supply of National Geographic and use it as a fire starter. A little newspaper or commercial fire starter lighting some kindling and then gradually adding bigger wood will give you a successful fire in your fireplace. Next, we will learn to lay the fire.","What Is Green Lumber? Kiln-Dried vs. Green Lumber Compared\nWood comes in two varieties, green and dried. These two categories separate wood by how much moisture is left inside of them at the time of sale. The most common type of dried wood is kiln-dried lumber—a term you will see bandied around every lumber yard in the country. So, what exactly makes wood green versus dried? How does kiln-dried wood compare to green wood? Is one kind better than the other?\nThis article will break down green lumber and kiln-dried wood and give a detailed comparison between the two so that there is no doubt which is best for you.\nWhat Is The Definition of Green Lumber?\nGreen lumber is any wood that has a moisture content of 19% or higher. When live trees are cut down, they are absolutely full of water. Trees, and their wood, hold a ton of moisture inside of them. If wood is not dried, it will still retain all the moisture left over from when the tree was alive. This wood is known as green lumber.\nThe term green has nothing to do with the color. Green is derived from the meaning of the wood being unseasoned. Wood that has not been allowed to dry naturally or was not put through a drying process retains this unseasoned description.\nGreen lumber’s bottom threshold for moisture content is 19% but that percentage can be much higher depending on the species of wood and the age of the wood. Some wood can have a moisture content as high as 35% depending on the circumstances. Any wood that is above 19% moisture content is considered green.\nWhat Are the Different Types of Green Lumber?\nAny species of wood can be considered green if it has the correct moisture content. However, there are certain types of wood that are found in its unseasoned green state more often than others. Common types of green wood include firewood, raw timbers, and logs. Firewood that is freshly cut is always green (and bad for burning). Raw timbers that are cut for use in construction are green, especially the large ones. Logs that are cut and barked before being refined down to studs or similar building materials are often found green as well.\nLumber is usually not dried until it is cut and sanded down to a more usable size.\nWhere Is Green Lumber Used?\nGreen lumber is used in a few distinct areas. For the longest time, wooden ships were made out of green timbers. That is because green lumber is more flexible than dried wood and it allows it to be shaped into curved sections far easier than dry wood. Today, that tradition continues and green wood is used in projects that require wood to be shaped and bent into curves or circles.\nGreen lumber is also used in natural timber frame construction. Builders who subscribe to this building philosophy like to get unseasoned wood that is not treated, cut, or shaped by modern industrial methods. That causes them to choose green lumber over dried wood when given the option.\nGreen wood is also used in specialized projects. Some rustic furniture makers like to use green wood hoping that when it dries it will give their furniture a more rugged and aged look. Some woodworkers who like to turn wood on a lath also prefer green wood for its flexible properties. For example, it is easier to turn a bowl out of green wood than it is out of dry wood.\nAdvantages of Green Lumber\nGreen lumber is often cheaper than dried lumber. That is because green lumber does not have the time and monetary investment that dried wood requires. Drying wood takes a long time and using a large kiln is expensive. Avoiding this process saves on time and costs in the long run.\nGreen wood is also very flexible and malleable. Dry wood is very stiff and brittle, which is great for many applications but not all of them.\nIn some places, obtaining green lumber is also easier and faster than finding dried wood. If you live near large logging communities, it can be simple to source readily available green wood when dried wood is hard to come by.\nDisadvantages of Green Lumber\nGreen lumber does have some serious drawbacks that prevent it from being more widely used. The biggest disadvantage is when wood dries, it shrinks and twists. This unfortunate side effect can make it impossible to use green wood in many applications. If you are building something with precise measurements, angles, and joints, having your wood shrink will cause gaps and can even pull away completely and jeopardize the integrity of the structure. Depending on the size of the beams the shrinkage can equate to inches in the long run which can be disastrous depending on the use.\nWhat Is The Definition of Kiln-Dried Lumber?\nKiln-dried lumber is wood that is dried in a large fire-fueled kiln. The kilns are designed to provide warm, dry heat to the wood that accelerates the drying process. Kiln-dried wood has a moisture content of 8% to 10% which is half that of green wood’s moisture threshold.\nWhat Are the Different Types of Kiln-Dried Lumber?\nAny species of lumber can be kiln-dried, but there are species that are more commonly kiln-dried than others. Almost all softwood available to buy for construction is kiln-dried. These species include spruce, white pine, fir, and southern yellow pine. These species are packaged into bunks from the mills and then put into massive kilns to be dried for commercial construction.\nOutside of those common species, many other kinds of wood are also kiln-dried for various reasons. A variety of hardwoods such as maple, oak, and hickory are dried for use in furniture and other similar projects. Dried wood is preferred for furniture because it will not move or warp after construction.\nLumber can also be kiln-dried after treatment, dried after treatment means that lumber that has been pressure treated is dried after the fact to remove any excess moisture that might be left over after the treatment process. Wood that is kiln-dried after treatment is often more expensive and harder to find than simple kiln-dried lumber, but it can be useful in certain projects that require pressure-treated wood to be used.\nWhere Is Kiln-Dried Lumber Used?\nKiln-dried wood is used almost everywhere. Kiln drying is the most common way to remove moisture from wood in the modern era. Virtually every piece of wood that is commercially available has been kiln-dried. This happens for multiple reasons. First, kiln drying is much faster than air-drying wood. Mills can dry huge amounts of lumber in a relatively short amount of time without spending very much money to run the kilns. Secondly, most code requires wood to be graded, and almost all graded wood is kiln-dried. That is because dry wood will not warp, twist or move like green wood. Without moisture, the wood won’t shrink or bend, making it the ideal building material.\nSome places also require kiln-dried wood because drying the wood in this way bakes out the organisms that might have been on the wood. For example, wood being imported to the Bahamas must all be stamped KD for kiln-dried.\nAdvantages of Kiln-Dried Lumber\nKiln-dried lumber will not shrink or move much, which makes it preferable for construction. It is also graded for strength (#1, #2, or #3) which allows it to be used in construction. Kiln-dried wood is also free from pests because the drying process raises the temperature and removes any organisms that might have been hiding in the wood.\nDisadvantages of Kiln-Dried Lumber\nKiln-dried lumber is graded based on its moisture content and strength, but it is not graded on its appearance. This can leave kiln-dried wood warped, barky, and cracked. These are simply the result of baking wood at a high temperature. When the moisture leaves the wood, it can alter its appearance. Many people do not like the look of studs and boards that have these features, but they are common results after drying.\nFrequently Asked Questions (FAQs)\nHow Do You Check the Moisture Content of Wood?\nThe best way to check the moisture content of wood is to use a moisture meter. These nifty machines scan wood and then display a moisture content rating. Moisture meters are necessary equipment for people who are selling dry wood and are widely used at mills that kiln-dry their products. Moisture meters can be purchased for use at home and can be very useful for people who are trying to dry their own lumber.\nCan You Dry Green Lumber On Your Own?\nYes, you can dry green lumber on your own. The cheapest and easiest way to dry green wood is to let it air dry. However, air-drying wood can take an exceedingly long time. Wood that is very green can take years to fully dry and reach a similar level of moisture to kiln-dried wood. However, if you have the time, space, and willpower, you can surely leave the wood out to dry on its own. But don’t expect quick results.\nA Quick Reference Guide\nKD – Kiln-Dried\nKDAT – Kiln-Dried After Treatment*\n*Pressure Treated wood\nGRN – Green\nNow you know that green wood has nothing to do with the color of the wood itself but rather how much moisture remains trapped within. Some people do not like to use green wood for anything but despite the push back, green wood has a lot of legitimate uses. Kiln-dried wood remains the most common type of wood found on the market and is the wood used most regularly in construction. Next time you are looking for wood for your next project, you will be able to determine exactly what type of wood is right for you, no matter what is available to buy.\nFeatured Image Credit: Pixabay"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:ef90149c-8d95-4daa-af98-ac17431dc2df>","<urn:uuid:79a31557-b598-4856-ab75-a8bd59f5c049>"],"error":null}
{"question":"What are the key principles of objectivity in journalism historically, and how does modern propaganda challenge these principles in news reporting?","answer":"Historically, objectivity was considered a cornerstone of journalistic integrity, with figures like Walter Lippmann advocating for standards of factually accurate and contextually honest information unpolluted by personal, commercial, or political bias. Journalists were expected to ignore bias and operate under a professional code of honor. However, these principles are now challenged by various forms of propaganda, both in traditional and modern media. Commercial advertisements, textbooks, and news outlets frequently employ propaganda techniques like name calling, glittering generalities, bandwagon appeals, card stacking, transfer, testimonials, and plain folks approach to persuade audiences. In the online age, these challenges are amplified by factors like SEO requirements, click-through rates, and competition with citizen journalists, making it increasingly difficult to maintain purely objective reporting.","context":["Your children are bombarded with propaganda (the art of persuasion) every day of their lives. No matter where commercial ads are found (e.g. newspapers, magazines, radios, television, billboards, the Internet, etc.), children must understand that at least one form of propaganda is being used to persuade them.\nSometimes, even textbooks use subtle propaganda to persuade students to believe as the book's author does, especially in history textbooks. For example, all you have to do is to read an account of the American Civil War in a textbook utilized in Pennsylvania, and then compare it to a different textbook narrative of the same topic in a southern state such as Georgia.\nThus, students (as readers) must learn to use their \"critical reading\" skills - the ability to make judgments in order to extract the truth from the propaganda they are confronted with, both in and out of the school setting.\nStudents who have a deeper understanding of propaganda can (1) save themselves money; (2) assist themselves in making better political decisions at the ballot box; (3) help themselves to distinguish between fact versus opinion; and (4) aid themselves in reading their textbooks or writing more intelligent critical essay in school.\nThe seven most widely-used propaganda techniques are as follows:\n1. Bad Names or Name Calling - This approach involves the use of disagreeable terms to arouse distaste for a person, thing, or belief.\nExample: Don't vote for John Smith; he's a crook and a liar!\n2. Glad Names or Glittering Generalities - This technique is just the opposite of bad names. Pleasant or positive terms are used to create good feelings about a person, thing, or belief.\nExample: Buy Waldo's super deluxe hamburgers. They're the best!\n3. Band Wagon - This type of propaganda appeals to the desire of people to be a \"part of a group.\" In other words, it is an attempt to convince someone that he or she should support a person, buy a product or accept a belief because everyone else is doing it. Example: All the smart people I know buy American-made products. Don't you think you should, too?\n4. Card Stacking - With this propaganda device, the persuader does give accurate information, but only one side of the story. In other words, either the good side or the bad side is given, but not both. Example: The rooms at Elite Hotels are gigantic, elegantly furnished, equipped with TV and Internet, and cleaned twice a day.\n5. Transfer - This propaganda strategy involves associating a positive characteristic of animals, symbols or famous people of the past with the person, thing or idea that one is endorsing.\nExample: Buy a Cougar; it's the best car on the road! (Association: speed and strength). Or, a political candidate speaks next to a statue of Abraham Lincoln, waving an American flag. (Association: honesty and patriotism)\n6. Testimonial - This approach is like transfer, except that a famous, living person endorses another individual's positive qualities, a product or an idea.\nExample: Tiger Woods promoting a certain golf club in an advertisement. Or, Brad Pitt endorsing a candidate at a political convention.\n7. Plain Folks - Persuaders who use this propaganda tactic attempt to associate their product, candidate or belief with the average, common, and ordinary people. Example: A millionaire, promoting his stock, stresses that he still drives a Ford and takes a bag lunch to work everyday, just like his father who was a coal miner in West Virginia.\nNow it's your responsibility to share the above propaganda techniques with your children. But first, let's see how much you learned in today's column. Study the statements below and see if you can determine which propaganda strategy is being incorporated. You'll find the answers at the end of the column.\n1. An advertisement in a magazine described all the benefits for buying the Electra Car that runs only on electricity.\n2. Buy the Fizzle power drink for great athletes - over two million sportsmen can't be wrong!\n3. A candidate for his high school's senior class president says, \"I'm a typical just like the rest of you.\"\n4. Our superior dress shirts will feel as smooth as silk to your skin.\n5. An investigative columnist for a magazine referred to a politician as a sad excuse for a public official and suggests that he had shady dealings with local underworld mobsters.\n6. A video commercial on an Internet website in which football great Terry Bradshaw endorses a new weight training system.\n7. You should always fly Eagle Airlines!\nIn closing, \"Don't be a fool!\" Watch out for propaganda wherever it occurs. Did I just try to persuade you?\n(Propaganda Answers: 1. Card Stacking; 2. Band Wagon; 3. Plain Folks; 4. Glad Names; 5. Bad Names; 6. Testimonial; 7. Transfer)\nParent Proverb - \"One machine can do the work of 50 ordinary men. No machine can do the work of one extraordinary man.\"\n- Elbert Hubbard\nNext Month's Column: \"The Note-taking Study Skill.\"\nDr. Bill Welker is a retired reading specialist who was a K-12 classroom teacher for 40 years. He was selected as a \"Teacher of the Year\" by the Wheeling Area Chamber of Commerce. Welker is also a nationally recognized authority on amateur wrestling who has written 100s of articles and two books on the subject. His e-mail is firstname.lastname@example.org.","The traditional ideals of journalism are under siege, colourfully illustrated during John Oliver’s entertaining diatribe on modern journalism on Last Week Tonight. In particular, the idea of objectivity – one of the cornerstones of journalistic integrity – is in flux in the online age. This is especially relevant in regards to headlines, which media outlets are beginning to be laxer with allowing their bias to show in. In an ideal world, the public should be presented with the unbiased facts that they need to come to their own informed decision, but this type of coverage is becoming more and more rare.\nThere is a plethora of considerations in regards to online publishing that go beyond objectivity and good writing, but in turn influence those two concepts. Headlines in an online age must keep in mind Search Engine Optimization (SEO), click-through rates, and the fact that traditional journalism has to be competitive with think pieces written by citizen journalists – which can be more appealing to share online and therefore can go viral. If mainstream journalists include buzzwords in their headlines, which are more likely to be Googled or shared, they may be adding bias to the piece – whether that bias is intended or not.\nMore than occasionally, social media users share or retweet articles based solely on the headline, without ever having read the article itself. Caitlin Dewey, for the Washington Post, reported on a study by computer scientists at Columbia University and the French National Institute which stated that “59 percent of links shared on social media have never actually been clicked: In other words, most people appear to retweet news without ever reading it.” Given that Facebook’s algorithm favours the posts that are most interacted with, these blind shares help determine what others read on their newsfeeds. Even for those who do click through to the article itself, studies show that they are unlikely to read it in full. In these cases, when consumers are forming opinions based solely on headlines and/or short summaries, any explicit bias in a headline becomes far more important than the editor or journalist who chose it may have originally intended.\nWhen Oxford Dictionaries announced “post-truth” as its 2016 international word of the year, it was unsurprising in a time embroiled in emotions in regards to Brexit and the US federal election. Post-truth is defined by Oxford Dictionaries as an adjective “relating to or denoting circumstances in which objective facts are less influential in shaping public opinion than appeals to emotion and personal belief.” Living in a post-truth society, it is perhaps unsurprising that mainstream journalism is struggling against a tide of “fake news” that can be at best annoying and mischievous, and at worst, propagandistic. The Washington Post reported on Russia’s involvement with the fake news cycle during the US election, saying “[t]he Russian campaign during this election season … worked by harnessing the online world’s fascination with “buzzy” content that is surprising and emotionally potent, and tracks with popular conspiracy theories about how secret forces dictate world events.”\nIt must be noted however that the idea of “buzzy” content is not unique to fake news, with sites like Buzzfeed dominating the online world using clickbait-y headlines that promise “You Won’t Believe” what is contained in their articles (or listicles.) So, if these are the headlines that have the average web user clicking through to an article, how can the mainstream news media compete without abandoning the original ethical principles journalism? Further, should they even be “competing” at all? To take it a step further, when the news being covered hits passion points for the journalists reporting on it, should they be allowed to take a personal stance if they feel it is important? For example, criticisms of Donald Trump’s stances on immigration. Perhaps we need to look back to allow us to move forward.\nThe Idea of Objectivity and Bias in Mainstream Journalism\nObjectivity and bias are oft debated topics in the world of journalism and ethics, going back much, much further than the 2016 election cycle. Some, like Walter Lippmann, argue that objectivity is paramount to an informed population, while others claim that it is impossible to truly avoid bias and that it is lazy for journalists to not use their investigative skills to present the public with fully formed opinions. In cases of social justice issues, the lines between what bias is acceptable becomes blurred.\nSo, can journalism ever achieve true objectivity? As Robert McChesney said in his essay “That was Now and This is Then: Walter Lippmann and the Crisis of Journalism” for Will the Last Reporter Please Turn Out the Lights “institutional and human biases are unavoidable, and the starting point is to be honest about it” (159). In Liberty and the News Walter Lippmann said that “the really important thing is to try and make opinion increasingly responsible to the facts” (38).\nIn the essay “A Test of the News” that Lippmann co-authored, he also referred to the public’s perception of the news as “a widespread and a growing doubt whether there exists such an access to the news about contentious affairs. This doubt ranges from accusations of unconscious bias to downright charges of corruption” (Lippmann and Merz 1). However, the main omission to this rule is when the news that audiences are consuming aligns closely with their own pre-existing biases. In The News: A Users Manual Alain De Botton argues the dangers of personalizing the news. That is, audiences only paying attention to subjects that are already of interest and in line with their current beliefs. The tendency to seek out news that confirms standing notions and ideologies rather than challenges them is something that becomes a risk of a society that consumes media passively. Yet, when topics that are overwhelming seen as negative are covered, for example racism or homophobia, does it become okay to allow this bias to creep into the coverage of such events? Chris Hedges, in his essay “The Disease of Objectivity,” said that aiming for objectivity takes the journalist away from empathy and passion, and distracts them from one of the main abilities of reporting: a quest for justice. These are all things society should theoretically be striving towards.\nWhat Would Walter Lippmann Say?\nRobert McChesney, who I quoted in the previous section, is a scholar and professor, concentrating on the history and political economy of communication with a particular interest in journalism and self-governance. During his essay “That was Now and This is Then: Walter Lippmann and the Crisis of Journalism” he addresses many common criticisms of Walter Lippmann’s popular works, such as claims of him being elitist and “anti-democracy.” Most of the piece, however, focuses on Lippmann’s lesser known works that deal directly with journalism: “A Test of the News” an essay co-authored with Charles Merz, and Liberty and the News, a short book.\nLippmann was a Pulitzer Prize winning journalist, writer, and political commentator, who was outspoken in his views regarding journalism’s role in democracy. He is best known for his works Public Opinion and The Phantom Public. However, McChesney argues that the importance of “A Test of the News” and Liberty and the News is magnified by the fact that they were written at what he calls “the climax of the last truly great defining crisis for journalism” (McChesney 153). This lends to a feeling of them being intensely timely and “of the moment” for the 1920’s. And this is, of course, relevant to today because we are now in another defining crisis for journalism.\nThe main issue of the day was the emerging trend towards organized propaganda, or what we now consider public relations. Lippmann referred to the public’s perception of the news at the time as “a widespread and a growing doubt whether there exists such an access to the news about contentious affairs. This doubt ranges from accusations of unconscious bias to downright charges of corruption” (Lippmann and Merz 1). With the rise of fake news, and further the fact that media is relying on native advertising and content marketing to fund online publications, these same doubts are once again becoming realized.\nIn “A Test of the News” Lippmann focuses on the New York Times coverage of the Russian Revolution from 1917-1920. He was upset with how the news was colored by “the wishes, distortions and lies of [anti-revolutionary] forces as gospel truths” (McChesney 153). The New York Times was particularly guilty of being misled by its reliance on the government as an official source of information. The frightening implications of such a system led Lippmann to propose that journalism not be considered a private enterprise, but as a public institution, and therefore suggested that public money should be used to improve its quality.\nLippmann, somewhat surprisingly given his socialist background, had no class analysis when evaluating the state of the commercial news system. He did not “entertain the idea … that those with property and privilege greatly benefited by an ignorant and ill-informed populace.” (McChesney 155). To him, the power of the news was in the hands of the editors, not the publishers. On that particular note, McChesney commented that Lippmann did not take into account how the concerns of said publishers influenced who became the editors, which fairly clearly shortsighted.\nLippmann particularly respected C.P. Scott, publisher and editor of The Manchester Guardian. After his death, his family placed The Guardian in a nonprofit trust, to “preserve the financial and editorial independence of The Guardian in perpetuity while its subsidiary aims are to champion its principles and to promote freedom of the press in the UK and abroad” (McChesney 176). Today, The Guardian is still widely read and respected around the world.\nDespite his support of The Guardian becoming a nonprofit newspaper, Lippmann was not actually calling for all news media to adopt the model. Instead, he was calling for them to change course from the current status quo, and to embrace professional training. He called for standards of “the highest quality of factually accurate and contextually honest information unpolluted by personal, commercial, or political bias” (Lippman and Merz 41).\nIn his work Lippmann wanted to stray away from society remaining “dependent upon untrained accidental witnesses” (Lippmann 46). However, it seems that we are currently moving closer towards that again, with the rise of citizen journalism, which quite often invites personal biases.\nDespite common criticisms of being elitist, Lippmann was determined that for the news media to succeed in changing for the better, the public needed to become more loudly involved. “Change will come only by the drastic competition of those whose interest are not represented in the existing news-organization” (Lippmann 60).\nHe posed the following as “jobs” for the reporter:\n- Ignore bias (personal or otherwise) to ensure an accurate understanding of events\n- Operate under, and enforce, a professional code of honor.\nUnder these guidelines, schools of journalism boomed after World War I, and “the notion that the news should be unbiased and objective became commonplace” (McChesney 158).\nHowever, McChesney pointed out that somehow the current standard of professional journalism in the United States has “veered dramatically from the core values [Lippman] prescribed” (McChesney 158). He cites the coverage of the lead up to the War on Terror as a large example of the presses tendency to take the claims of the government at face value.\nKnowing the history and context of Lippmann’s works, we must acknowledge that his vision is not entirely feasible in a world ruled by the commercialism he disregarded. The resources that Lippmann’s theories relied on are no longer in place, and instead we are left with what McChesney calls the shambles of commercial journalism in a significantly monopolistic news media system.\nWhat Should We Be Aiming For?\nIn the case of news stories related to social justice, where empathy and passions are more likely to be involved, it becomes a question of if the news has an obligation to report as objectively as possible, or if reporters can fulfill their personal, moral obligation to express distaste towards subjects such as homophobia and racism. When it’s a topic that is overwhelmingly seen as outdated or distasteful, should journalists be allowed to show their bias as long as it does not affect accurate and fair reporting? Potentially, emotional decisions could be made, leading to inaccurate reporting being posted online. In the days of the Internet, tides of public opinion can change quickly. With the rise of citizen journalism and the blogosphere, opinion being touted as fact is becoming increasingly common, and the mainstream media (especially in regards to news reporting) should be held to a higher standard of objectivity.\nThis is not to say that journalists cannot follow their passions and take up the mantle for a cause like Chris Hedges recommended. Rather, they just must keep journalistic integrity in mind while doing so. Perhaps rather than trying to remain wholly objective, they should be trying to examine more angles than just the standard two disparate ones that journalists look for to prove they are unbiased. While standard news writing does not allow for in depth analysis due to both word counts and time constraints, reporters such as the late David Carr of the New York Times are champions of well-researched, dogged investigative reporting. Acknowledging that a certain amount of bias is unavoidable, and doing their best to align opinion with fact is integral to journalists keeping the public informed on world issues while staunching the flow of rampant misinformation. For society to progress beyond issues of sexuality and race, which should be outdated and obsolete, it is important to have passionate whistleblowers who have the skills and training necessary to get to the heart of the story.\nThe crucial lessons in Lippmann’s works remain relevant today, no matter the format journalists are publishing in – online or in print. The relationship between journalism and democracy, and the importance of the public’s role in holding them accountable, remain. Therefore the difficult, but not impossible, mission of creating an independent fourth estate is central to ideas of self-government and freedom. Despite journalists’ bias and feelings of moral obligation, the mainstream news media must do their best to maintain unbiased coverage. Presenting the facts of a news event without using language that leads their reader to a conclusion, but rather allows the reader to come to their own, is one of the main purposes of media coverage. Citizen journalism can be extremely biased and one-dimensional, and as such, it is increasingly important for the mainstream news media to remain unbiased in their reporting. If the tendency towards bias can be ignored by professional journalists, mainstream media has the potential to infiltrate the Internet with better researched pieces.\nBotton, Alain De. The News: A User’s Manual. New York: Pantheon Books, 2014. Print.\nDewey, Caitlin. “6 in 10 of you will share this link without reading it, a new, depressing study says.” The Washington Post 16 Jun 2016. Web. 25 Nov 2016.\nHedges, Chris. “The Disease of Objectivity.” Will the Last Reporter Please Turn Out the Lights. New York: New Press, 2011. Print.\n“Journalism: Last Week Tonight with John Oliver” Last Week Tonight with John Oliver, HBO, 7 Aug 2016.\nLippmann, Walter and Charles Merz. A Test of the News: An Examination of the News Reports in the New York times on Aspects of the Russian Revolution of Special Importance to Americans, March 1917 — March 1920. New York: New Republic, 1920. Print.\nLippmann, Walter. Liberty and the News. New York: Harcourt, Brace and Howe, 1920. Print.\nMaksym Gabielkov, Arthi Ramachandran, Augustin Chaintreau, Arnaud Legout. “Social Clicks: What and Who Gets Read on Twitter?.” ACM SIGMETRICS / IFIP Performance 2016, Jun 2016, Antibes Juan-les-Pins, France. 25 November 2016.\nManjoo, Farhad. “You Won’t Finish This Article.” Slate 6 Jun 2013. Web. 18 Nov 2016.\nMcChesney, Robert. “That Was Now and This Is Then: Walter Lippmann and the Crisis of Journalism.” Will the Last Reporter Please Turn Out the Lights. New York: New Press, 2011. Print.\nTimberg, Craig. “Russian propaganda effort helped spread ‘fake news’ during election, experts say.” The Washington Post 24 Nov 2016. Web. 26 Nov 2016."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:c5448074-66f8-4d81-b16a-57a69a2746f4>","<urn:uuid:e3296617-03e5-4aba-b950-4fc647ebe0d6>"],"error":null}
{"question":"What's the ideal fishing setup for targeting golden perch in Cairn Curran vs the Goulburn River? Been exploring both spots and need a clear comparison! 🎣","answer":"For Cairn Curran Reservoir, golden perch are best targeted using live yabbies and large scrub worms around submerged timber or rocky points. They also take deep diving lures like Stumpjumpers and fat raps. For fly fishing, use bulky and lightly weighted flies with 7-9 weight intermediate or sinking line. In the Goulburn River, you'll need a 2-4 or 3-5 kilo rod coupled with a 2500-3000 reel loaded with 6 or 8 pound braid and fluorocarbon leader. Lures that work well include lipless crankbaits, stump jumpers, vibes, and spinner baits.","context":["Curran Reservoir - Malden / Newstead. Victoria\nCurran Reservoir was formed by the damming of the Loddon River\nand is located near the historical gold mining towns of Malden\nand Newstead in central Victoria.\nThere are caravan parks at Welshman's Reef (Newstead) and near\nthe dam wall. The boat ramps are located at the dam wall, Welshman's\nReef and Picnic Point and are suitable for boats to 5m for Picnic\nPoint and the wall and 4m for Welshman's Reef (depending on water\nThe lake can be turbid after periods of high rainfall and is susceptible\nto blooms of blue-green algae during summer but is clear most\ntimes of the year.\nThe lake holds good populations of trout (max. 3.5kg, av. 1kg),\nredfin (max.2.5kg av. 500g), golden perch (max. 5kg av. 1.2kg),\neels and carp.\nThere are extensive shallows around the lake's margins that offer\nsome fantastic fly-fishing around spring and early summer. Trout\nto 3kg can be seen in water as shallow as 20cm and can be very\nhard to tempt. Best flies are stick caddis, Mrs. Simpson, Tom\nJones (and damsel nymph imitations), Fuzzy Wuzzy and smelt patterns.\nThere are also many steep banks and rocky outcrops that give good\nland-base access to deep water.\nTrout can be caught on a variety of baits in this lake including;\nscrub worms, live minnow, small yabbies and mudeye suspended under\na bubble float.\nMoloney holds a solid Cairn Curran brown trout\nTrolling is very popular at Cairn Curran and trout can be taken\nin water from 2 to 20 meters with the use of a downrigger.\nBest lures include; Tassie devils with a bit of sparkle in them,\npink or mauve Tassie devils, minnow styled lures such as Attacks,\nMerlins, Rapalas and McGraths and wide action spoons.\nRedfin are another very popular target in Cairn Curran and on\nof the best method is to tie up to one of the dead trees in the\nlake and lower a bait or jig to the bottom. Give it about 20 minutes\nand move to the next tree. Continue this until a school of fish\nBest baits include; gudgeon or minnow, small yabbies, mudeye and\nworms. Best jigs include; ice jigs and Baltic bobbers.\nAnother very popular way of targeting the redfin population is\nto find a patch of water that is clear of trees and about 5 -\n8 meters deep, send down some heavy jigs and drift across.\nThinking anglers are also employing the use of downriggers in\nthe old Loddon River bed and near the wall to target the larger\nredfin during winter with good success.\nGolden perch are mainly a spring and summer target species and\ncan be taken on most baits, lures and some flies. The lakes 'GP'\npopulation are best targeted using live yabbies and large scrub\nworms around submerged timber or rocky points.\nThey will also take a large range of deep diving lures such as\nStumpjumpers, small codgers, wiggle warts and fat raps.\nFly-fishing for golden perch in Cairn Curran is still in its infancy,\nbut due to gain in popularity. Flies to use when targeting GP's\nneed to be bulky and lightly weighted to get down deep. Your fly\nline should be either intermediate or sinking and be around 7\n- 9 weight.\nCurran Reservoir Facts & Figures\nLevel Link Goulburn - Murray Water\nCurran Reservoir Map Goulburn - Murray Water\nCurran Reservoir Map\non map for printable version\nCurran Reservoir Map","Fishing locations Goulburn River is a large stretch of waterway. In facts it’s Victoria’s largest river stretching 570klm starting in Northern Victoria around Shepparton, and going all the way past Alexandria. Popular for fishing in towns around Seymour and Nagambie. It holds great numbers of Redfin and trout. However the prized catches along this stretch are native fresh water fish including Golden perch and Cod. You can also keep yourself nice and busy with lots of Carp.\nFISH SPECIES TO TARGET\nMurray Cod, Golden Perch, Trout, Redfin, Carp\nBEST BAITS AND LURES\nScrub/earth worms, Power bait, Yabbies, Mudeye and a wide range of soft plastics & lures. Click here to see our best lures and plastics when targeting Redfin. If your targeting cod and yellow belly then some great lure choices. These includes lip-less crank-baits such as Jackall TN series, stump jumpers. Either cast or trolled, surface lures, vibes, spinner baits, bassman spinners, large grub style soft plastics in dark colours. The new range of Savage Gear swimbaits are also a great option for the larger species\nWhen targeting Trout and Redfin we highly recommend fishing as light as possible which will provide more fun and control. To maximize your chances fish with a 2-4 or 1-3 kilo rod. Coupled with a 2000 to 2500 size reel spooled with 4-6 pound braid finished with a quality fluorocarbon leader. When targeting golden perch ( yellow belly ) it pays to fish a little heavier therefore a slight upgrade to a 2-4 or 3-5 kilo rod coupled with a 2500-3000 reel reel loaded with 6 or 8 pound braid. If your sight are set on catching a big cod then you’ll need to up your outfit. A 6 foot to 7 foot rod in a 4-8 kilo or 6-12 kilo class rod and a quality baitcaster reel spooled with 20 to 50 pound braid finished with a solid fluro carbon leader of equal strength. There are a whole range of baitcaster options suiting different budgets. An affordable starting point would be a either a Savage Gear black savage bait caster rod and reel combo or a shimano raider cod 642 with a Casitas baitcaster reel.\nMOST PRODUCTIVE TIMES\nSpring is the best time of year for targeting golden perch ( yellow belly ) and cod. They can be caught at anytime of the day but often the last 2 hours of daylight can be the best. Trout are more active in the colder months and redfin ( perch ) are more active in the warmer months. Again you can catch all these different species during any part of the day, though some fish will be more active at Dawn and Dusk.\nThis is an nice spot to take the kids with plenty of fishing spots with surrounding parks and BBQ facilities\nAll rural areas are inhabited by wildlife such as Snakes and Lizards, so be weary of venomous snakes such as Brown, Tiger and Red bellied Black.\nRULES AND REGULATIONS\nalways carry your Victorian fishing license, FishingMad encourage ‘catch & release’ of all native species to help maintain the water quality within the lake however European Carp must not be returned."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:f8a739ae-a3e9-4028-8dba-7e725d3ba131>","<urn:uuid:e1e7c77c-1fec-4a86-8e9e-e297848a79b4>"],"error":null}
{"question":"What is the typical timing of low-oxygen events in Hood Canal, and how was 2015 different from the normal pattern?","answer":"Low-oxygen conditions and resulting fish kills in Hood Canal typically occur in late September or October. However, in 2015, these conditions developed about a month earlier than normal. The annual intrusion of deep seawater with elevated oxygen levels arrived early, and by August 9, the hypoxic layer at Hoodsport was reduced from 300 to 60 feet as it was pushed upward by denser water.","context":["Death came early to Hood Canal this year, demonstrating just how odd and unpredictable ocean conditions can be.\nFish kills caused by low-oxygen conditions in southern Hood Canal usually occur in late September or October. That’s when low-oxygen waters near the seabed are pushed upward by an intrusion of heavier water coming in from the Pacific Ocean and creeping along the bottom. Winds out of the south can quickly blow away the surface waters, leaving the fish with no escape.\nThat’s basically what happened over the past month, as conditions developed about a month earlier than normal. South winds led to reports of fish dying and deep-water animals coming to the surface to get enough oxygen, with the worst conditions occurring on Friday. Check out the video on this page by Seth Book, a biologist with the Skokomish Tribe, who found deep-water ratfish swimming near the surface.\nThe story of this year’s strange conditions actually begins about a year ago and involves a 1,000-mile-long “blob” of unusually warm ocean water off the West Coast. State Climatologist Nick Bond, who coined the term “blob,” explains its formation in an article in Geophysical Research Letters with a summarized description by Hannah Hickey in UW Today.\nThe warm, low-density coastal waters related to the blob came into Hood Canal on schedule last fall, but they were not dense enough to flush out the low-oxygen waters, according to University of Washington oceanographer Jan Newton.\nHood Canal entered 2015 with the least-dense waters at depth over the past 10 years. They remained in a hypoxic state, meaning that levels were below 2.5 parts per million. Sea creatures unable to swim away can be unduly stressed and unable to function normally at that level. Conditions worsened into the summer, when the hypoxic layer at Hoodsport grew to about 300 feet thick.\nBy then, the annual intrusion of deep seawater with somewhat elevated oxygen levels was on its way into Hood Canal, spurred on by upwelling off the coast. This year’s waters are more normal in density, though their arrival is at least a month early. By August 9, the hypoxic layer at Hoodsport was reduced from 300 to 60 feet, pushed upward by the denser water.\nIt’s always interesting to see this dynamic play out. The layer of extreme low-oxygen water becomes sandwiched between the higher-oxygen water pushing in from the ocean and the surface water, which ordinarily stays oxygenated by winds and incoming streams. Without south winds, the middle low-oxygen layer eventually comes up and mixes into the surface layer.\nIf south winds come on strong, however, the surface layer is blown to the north, causing the low oxygen water to rise to the surface. Fish, shrimp and other creatures swim upward toward the surface, trying to stay ahead of the rising low-oxygen layer. When the low-oyygen layer reaches the surface, fish may struggle to breathe in the uppermost mixing layer. Unfortunately, the fish have no way of knowing that safer conditions lie down below — beneath the low-oxygen layer and within waters arriving from the ocean.\nJan Newton reported that the low oxygen levels in southern Hood Canal earlier this year were the most extreme measured over the past 10 years. So far, however, the fish kills don’t seem as bad as those in 2003, 2006 and 2010, she said.\nThe graph below shows how the deep layer coming in from the ocean at 279 feet deep contains more oxygen than the middle layer at 66 feet deep. The surface layer, which normally contains the most oxygen, dipped to extremes several times near the beginning of August and again on Friday, Aug. 28. These data, recorded from a buoy near Hoodsport, are considered unverified."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:c74b5239-b740-4f8d-9586-e060c7c3ce82>"],"error":null}
{"question":"How do current global trends impact wastewater management, and what specific parameters does WHO monitor to ensure safe drinking water quality?","answer":"Current global trends driving wastewater management include population growth, increasing water scarcity, aging infrastructure with associated funding gaps, and stricter water quality regulations. This has led to the emergence of smaller, decentralized treatment systems funded through Public Private Partnerships. Regarding water quality monitoring, WHO has established guidelines that cover various parameters including chemical hazards such as barium, bentazone, lead, manganese, nitrate and nitrite, and perchlorate. WHO also emphasizes turbidity monitoring in source water and drinking water, while working with UNICEF through the JMP program to track progress on SDG 6 targets related to drinking water, sanitation, and hygiene.","context":["WHO’s Guidelines for drinking-water quality (GDWQ) form an authoritative basis for the setting of national regulations and standards for water safety in support of public health.\nThis first addendum updates the fourth edition of the GDWQ to reflect new evidence and to provide additional explanations to support better understanding and application of the guidance.\nWHO has recently published new or revised background documents for selected chemical hazards in drinking-water, which inform the development of the recently published first addendum to the fourth edition of the WHO’s Guidelines for drinking-water quality.\nThese chemicals include: barium; bentazone; chlorine dioxide, chlorate and chlorite; dichlorvos; dicofol; diquat; lead; manganese; MCPA; nitrate and nitrite; and perchlorate.\nIntended for regulators and operators of drinking-water supplies, this technical brief provides information on the uses and significance of turbidity in source water and drinking-water.\nInformation is provided on the implications of turbidity for water safety at each step of the water supply chain, alongside practical guidance on the measurement and monitoring of turbidity in source water and drinking-water.\nSafe treatment and use of wastewater is fundamental to protecting public health.\nJoin the global campaign for World Water Day on 22nd March by downloading a sharing campaign materials and organising an event to highlight SDG 6.3 “…halve the proportion of untreated wastewater and substantially increase recycling and safe reuse by 2030.”\nLearn more from WHO factsheets videos and tools on wastewater and health.\nThe 2030 SDG agenda was agreed in 2015 by 193 Member States, and includes an ambitious dedicated Goal 6 for water and sanitation. Eleven indicators are being developed to monitor progress towards the eight SDG 6 targets, and data are being collected to produce baseline estimates. The WHO/UNICEF JMP will produce global monitoring reports for targets 6.1 and 6.2 on drinking water, sanitation and hygiene while WHO with UN-Habitat will monitor target 6.3 on wastewater. The GLAAS initiative will monitor the two ‘Means of Implementation’ indicators 6a and 6b.\nSee individual pages to learn about contributing data for SDG monitoring.\nProtecting surface water for health provides a structured approach to the assessment and management of drinking-water quality related risks in surface-water catchments. The publication will support the development and application of water safety planning where source-water protection is a key element in the provision of safe drinking-water. Protecting surface water for health embraces the concept put forward by Goal 6 of the SDGs to “Ensure availability and sustainable management of water and sanitation for all”, recognizing that the protection of water quality and water-related ecosystems contributes to public health protection.\nThis publication synthesizes the current knowledge on Quantitative microbial risk assessment (QMRA) to facilitates its application in the practice of water supply, water reuse and water recreation to support the management of risks associated with faecal pathogens in the water-related context. Guidance is provided to support the successful of QMRA with key aspects including : the role of interaction between risk managers and risk assessors ; interpretation of scientific data including uncertainty ; and interpretation of quantitative results. Many examples including six full case studies are described.\nWHO works on aspects of water, sanitation and hygiene (WASH) where the health burden is high and where evidence-based interventions could make a major difference.","Waste Water Treatment\nModular “Plug & Play” Waste Water Treatment Solutions\nWaste Water Treatment Overview\nThe principal objective of wastewater treatment is generally to allow human and industrial effluents to be disposed of without danger to human health or unacceptable damage to the natural environment. The three basic types of wastewater are classified by source:\n- Industrial Wastewater\n- Domestic Wastewater\n- Storm Wastewater\nThe composition of industrial wastewater varies with the type of industrial process discharging the wastewater. Some industrial wastewater can be readily treated in conventional wastewater treatment plants. Other more contaminated sources may have to be pre-treated to remove or limit any process specific contaminants to acceptable levels before being accepted at a municipal treatment facility.\nDomestic wastewater comes from normal day to day activities occurring in homes, business and institutions. It is composed of a variety of organic and inorganic substances. Organic substances consist of molecules that are based on carbon and include fecal matter, detergents, soaps, fats, greases and food particles. Domestic wastewater is readily treatable in publically owned treatment facilities, which have been specifically designed to treat domestic wastewater in accordance with prescribed water quality regulations and standards.\nStorm water is also readily treated in these municipal facilities as it is relatively low in contaminants. Too much storm water however can overload these facilities and also dilute the sewage so that biological treatment processes are compromised. Most modern municipal wastewater system designs, channel domestic and storm sewage in separate distribution lines.\nMeasured and Regulated Constituents of Wastewater\nBiochemical Oxygen Demand\nOne of the most widely measured characteristics of wastewater is Biochemical Oxygen Demand or BOD. It is defined as the amount of oxygen aerobic microorganisms must consume to breakdown the organic material present in the wastewater. BOD is determined by measuring the quantity of oxygen consumed by microorganisms during a five-day period. For example, a regulated effluent discharge limit of say 20 ml BOD/l, means that the concentration of oxygen in a water sample diminishes by no more than 20 mg/l over 5 days. Also referred to as BOD5, it is the most common measure of the biodegradable organic material content of wastewater. BOD of effluent is tightly regulated, because effluent high in BOD can deplete oxygen in receiving lakes and rivers, causing fish kills and ecosystem imbalances.\nTotal Suspended Solids\nMost waste water contains large quantities of undissolved organic and inorganic materials. Referred to as Total Suspended Solids or TSS, these solids are problematic because most are in the form of fine particles, which not only support BOD but also plug up or clog septic systems and mechanical wastewater treatment equipment. TSS are removed from waste streams by various means such as screening, granular filtration, and induced settling/flotation schemes. TSS values are expressed as mg TSS/liter.\nOne of the major concerns regarding constituents in wastewater effluent is the concentration of nutrient compounds, particularly nitrogen and phosphorus. When released into receiving waters these nutrients concentrate and stimulate the excessive growth of algae and other aquatic plants, leading to decreased oxygen levels that can lead to hypoxic conditions. Hypoxia occurs when dissolved oxygen concentrations fall below the level necessary to sustain most animal life; generally considered to occur at levels below 2mg/l.\nNitrogen is present in many forms in the waste water stream. Most nitrogen excreted by humans is in the form of organic nitrogen (dead cell material, proteins, amino acids) and urea. Ammonia (NH3) is the primary form of nitrogen in influent entering treatment facilities. Nitrogen removal is accomplished by the biological processes of nitrification and denitrification, which convert ammonia (NH3) into gaseous nitrogen ( N2 ), an inert gas suitable for release into the atmosphere.\nNitrification is a two-step aerobic process facilitated by two different species of nitrifying bacteria. The oxidation of ammonia (NH3) to nitrite (NO2−) occurs first followed by the oxidation of nitrite (NO2−) to nitrate (NO3−). Then the NO3− is reduced to N2 through anaerobic denitrification. A wide array of bacterial populations are employed in the denitrification process.\nThe average phosphorus content of most sewage is estimated at around 10 mg/liter. Synthetic detergents are the largest source followed by human waste in the form of urine and feces. While legislated requirements for more environmentally friendly detergent formulations have reduced the amount of phosphorus entering the waste stream, the contribution from human waste remains constant. Phosphorus removal can be achieved by chemical precipitation or biologically through the enhanced biological phosphorus removal process (EBPR).\nIn chemical precipitation soluble phosphorus is transformed to a solid that settles and can be removed with the sludge. Several different metal salt additives are commonly used to chemically precipitate phosphorus, they include : Ferric Chloride (FeCl3), Ferrous Chloride (FeCl4), Ferrous Sulfate (FeSO4) and Aluminum Sulfate (alum) ( Al4 (SO4) 3 ) .\nEnhanced Biological Phosphorus Removal ( EBPR) is a process that uses alternating anaerobic and aerobic zones to provide an environment that encourages the growth of Phosphorus\nAccumulating Organisms (PAO). PAOs store excess polyphosphate in their cell mass and captured phosphorus is removed with the waste sludge. Essentially EBPR relies on the selection and proliferation of microbial populations capable of sequestering phosphates in greater amounts than would normally be required to sustain their growth. The resulting sludge high in phosphate can be used as fertilizer or disposed of in a conventional land fill.\nReview of Basic Wastewater Treatment Processes\nThe most basic form of wastewater treatment involves the removal of contaminants by allowing or inducing them to either settle to the bottom or to float to the top of reservoirs or clarification tanks for collection and removal. Pollutants are then subjected to biological treatment, either in natural settling ponds or in bio-reactors specifically designed to optimize certain microbial populations and metabolic processes in order to remove or chemically transform the targeted contaminants.\nWastewater flowing into modern treatment facilities generally passes through five common stages:\n- Influent collection & delivery\n- Primary treatment\n- Secondary treatment\n- Tertiary treatment\n- Disinfection & Effluent Discharge\nInfluent Collection & Delivery\nInfluent as the name implies, is wastewater flowing into a wastewater treatment facility. It contains all of the water, debris, and waste that entered the collection system feeding the facility.\nPrimary treatment involves basic processes to remove suspended solid waste from influent and to reduce biochemical oxygen demand (BOD) – the amount of oxygen microorganisms must consume to breakdown the organic material present in the wastewater. First, influent is passed through a series of raked bar screens to mechanically remove large objects such as bottles, plastic materials, pieces of wood, trash and other forms of suspended solid waste. The water is then passed through a grit removal system to take out smaller inorganic particles like sand and gravel. Finally the water flows into large primary clarification tanks or clarifiers, where suspended organic solids either settle by gravity or float to the surface as scum and grease. The floating scum is skimmed off, the settled solids, known as primary sludge, is removed and the primary effluent moves onto the next stage for secondary treatment. Primary treatment can reduce BOD by 20 to 30 percent and suspended solids by up to 60 percent.\nSecondary treatment employs aerobic biological treatment processes to remove biodegradable organic matter from the primary influent. Aerobic biological treatment is performed in the presence of oxygen by microorganisms (principally bacteria) that metabolize the organic matter in the wastewater, thereby producing more microorganisms and inorganic end-products (principally CO2, NH3, and H2O). Several aerobic biological processes are used for secondary treatment differing primarily in the manner in which oxygen is supplied to the microorganisms and in the rate at which organisms metabolize the organic matter.\nSecondary treatment systems are classified as fixed-film or suspended-growth systems. Fixed-film or attached growth systems, include trickling filters, bio-towers, and rotating biological contactors, where the biomass grows on media and the sewage passes over its surface. Fixed-film systems have been further perfected with the advent of Moving Bed Biofilm Reactors (MBBR). MBBR systems are the treatment method of choice here at Sapphire water.\nSuspended-growth systems include conventional activated sludge processes (also aerated lagoons and aerobic digestion), where the waste flows around and through the free-floating microorganisms, gathering into biological flocs that settle out of the wastewater. The settled flocs retain the microorganisms, meaning they can be recycled for further treatment.\nTypically secondary treatment systems can remove up to 85 percent of BOD and total suspended solids.\nThe purpose of tertiary treatment also referred to as effluent polishing, is to provide a final treatment stage to further improve the effluent quality before it is discharged to the receiving environment. Specifically, tertiary treatment targets remaining bioavailable organics (contributors to BOD), nutrients ( nitrogen and phosphorus ) and toxins ( pesticides, solvents, petroleum, metals – lead, cadmium, mercury). Treatment methods vary and include granular filtration, biological processes such as nitrification and denitrification, enhanced biological phosphorus removal ( EBPR), chemical precipitation, coagulation, flocculation and toxin specific treatment strategies. All in all, tertiary treatment can remove up to 99 percent of all impurities from sewage, but it is a very expensive process.\nDisinfection & Effluent Discharge\nThe purpose of disinfection is to destroy or inactivate pathogenic bacteria, viruses and parasites remaining in treated wastewater before it is discharged back into the environment in order to prevent the spread of waterborne diseases.\nVarious monitoring systems have been established that use the presence of indicator bacteria to gage the effectiveness of disinfection systems. The most commonly used indicators are total and faecal coliforms, E. coli and faecal streptococci. The presence of the indicator organisms in numbers greater than a specific target level suggests an increased probability of the presence of pathogenic organisms. The Water Environment Federation reported in 1996 that high levels of coliform indicators have been detected in 88% of the waterborne disease outbreaks in North America.\nChlorine is the most widely used disinfectant for wastewater, followed by ozone and ultraviolet radiation. Chlorine kills microorganisms by destroying cellular material. This chemical can be applied to wastewater as a gas, a liquid or in a solid form similar to swimming pool disinfection chemicals. However, any free (uncombined) chlorine remaining in the water, even at low concentrations, is highly toxic to aquatic life. Therefore, removal of even trace amounts of free chlorine is often needed to protect fish and aquatic life.\nOzone is produced from oxygen exposed to a high voltage current. Ozone is very effective at destroying viruses and bacteria and changes back to oxygen rapidly without leaving harmful by products. Ozone is a relatively expensive approach to disinfection due to high energy costs.\nUltra violet (UV) disinfection occurs when electromagnetic energy in the form of light in the UV spectrum penetrates the cell wall of exposed microorganisms. The UV radiation degrades the ability of the microorganisms to survive by damaging their genetic material. UV disinfection is a physical treatment process that leaves no chemical traces.\nEmerging Trends in Water and Wastewater Treatment\nThe overarching trends driving global demand for improved water and wastewater treatment systems are: population growth, increasing water scarcity, aging infrastructure along with the associated funding gap and the enactment of stricter water quality regulations to address rising concerns over the effects of inadequately treated water on human health and the environment.\nWith a large portion of existing water treatment systems reaching the end of their service lives many countries are faced with the urgent need to fund the replacement of this aging infrastructure. The situation is further exacerbated as new more stringent water quality regulations, render many middle aged treatment facilities incapable of compliance without major upgrades and overhauls.\nAs a result of this situation we are seeing the emergence of smaller more economical decentralized water and wastewater treatment systems capable of meeting current and future water quality standards. Often these decentralized systems are being funded in part by Public Private Partnership (3P or PPP ) finance schemes in an effort to bridge the infrastructure funding gap. From a technology stand point these modular packaged systems are generally scalable to accommodate future growth and rely heavily on advanced biological treatment technologies as opposed to chemical treatment options. (Decentralized WWTP Video)"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:858609d6-4eb7-41dc-ac41-787100364921>","<urn:uuid:5c51ae6f-0bf1-4201-950d-42b398ba57da>"],"error":null}