{"question":"What is the dual role of the Migratory Birds Convention Act in both conservation and pollution control, and how has its implementation evolved from 1916 to the present through key amendments and protocols? ü¶Ö","answer":"The Migratory Birds Convention Act serves both conservation and pollution control roles. For conservation, it aims to protect and conserve migratory birds as populations and individuals, their nests, and essential habitats. The Act prohibits taking, injuring, destroying, or disturbing migratory birds, their eggs, and nests within protected areas. Regarding pollution control, the Act's regulations specifically prohibit the deposit of oil, oil wastes, or any harmful substances in waters or areas frequented by migratory birds. The Act's evolution includes its original signing in 1916 between Great Britain (for Canada) and the United States, its revision in 1994, and a significant amendment through the Parksville Protocol in 1995. This Protocol enhanced conservation efforts, updated the list of protected birds, recognized Aboriginal traditional harvesting rights, and expanded Environment and Climate Change Canada's obligations regarding migratory birds.","context":["Acts and Regulations\nLegislative and regulatory direction for the creation of protected areas by Environment and Climate Change Canada is provided under the acts and regulations indicated below:\nCanada Wildlife Act (CWA) ‚Äì The CWA, passed in 1973, empowers the Minister of the Environment to acquire lands to create National Wildlife Areas, in order to establish, manage and protect wildlife areas, and to enable wildlife research activities as well as the conservation and interpretation of wildlife. The Act‚Äôs purpose is to preserve habitats that are critical to migratory birds and other wildlife species, particularly those that are at risk.\nMigratory Birds Convention Act (MBCA) ‚Äì The 1994 MBCA was originally passed in 1917 in order to implement the Migratory Birds Convention of 1916, signed between Great Britain (on behalf of Canada) and the United Sates. The MBCA aims to protect and conserve migratory birds as populations and individuals, their nests, and the habitat necessary for their survival. The Act provides for regulations to prohibit the taking, injuring, destruction or disturbing of migratory birds, their eggs and nests, within any prescribed protected area. That provision forms the basis for establishing sanctuaries for migratory birds and for enacting regulations to control and administer such sanctuaries.\nThe Parksville Protocol is an amendment to the 1916 Migratory Birds Convention. It was signed on December 14, 1995, between Canada and the United States. The amendment came into force in October, 1999, resulting in the addition of the Protocol to the Migratory Birds Convention Act‚Äôs schedule. The Protocol improves the Convention by enhancing conservation efforts to provide for and protect the habitat necessary for migratory birds, and includes an updated list of migratory birds under the Convention's Article I. The Protocol further recognizes and endorses Aboriginal traditional harvesting rights, and clarifies and expands some of Environment and Climate Change Canada‚Äôs obligations in relation to migratory birds (Article II to V of the Convention).\nSpecies At Risk Act (SARA) ‚Äì SARA, passed by Parliament in 2002, aims to prevent ‚Äú ‚Ä¶ wildlife species from being extirpated or becoming extinct, to provide for the recovery of wildlife species that are extirpated, endangered or threatened as a result of human activity and to manage species of special concern to prevent them from becoming endangered or threatened.‚Äù As such, SARA strengthens the CWA for creating National Wildlife Areas to also protect wildlife habitat and empowers the Minister to ‚Äú ‚Ä¶ establish codes of practice, national standards or guidelines with respect to the protection of critical habitat.‚Äù For more information on initiatives and programs related to species at risk, consult the Environment and Climate Change Canada web section on Species at Risk.\nCanadian Environmental Assessment Act (CEAA) - The 1995 CEAA ensures that rigorous environmental assessment is performed for projects carried out by the federal government or Crown corporations where the assessment includes public consultation. With respect to Environment and Climate Change Canada‚Äôs protected areas, such assessment is conducted to evaluate a proposed project‚Äôs potential impacts on the protected area.\nOceans Act - Passed in 1997, the Act addresses Canadian authority over economic zones in Canada‚Äôs coastal regions. The Act also tasks the Minister of Fisheries and Oceans to lead and coordinate the development of a national network of marine protected areas on behalf of the government of Canada.\nWildlife Area Regulations (WAR) ‚Äì These 1977 regulations identify prohibited activities in National Wildlife Areas listed under Schedule 1, i.e., activities that could be harmful to species or their habitat--unless a permit has been issued to authorize the activity. The Regulations are regularly amended to incorporate new protected areas as well as any changes regarding listed National Wildlife Areas, including revisions of a National Wildlife Area‚Äôs boundaries.\nMigratory Bird Sanctuary Regulations (MBSR) - The 1994 regulations prescribe areas for sanctuaries and their governance, and identify prohibited disturbances of migratory birds, their eggs, and their nests within a Migratory Bird Sanctuary. The Regulations also prohibit disturbances of migratory birds‚Äô habitat in Migratory Bird Sanctuaries established on federal lands, unless a permit has been issued for the activity. The MBSR can be amended to incorporate new protected areas and any changes regarding listed sanctuaries, such as the revision of a protected area boundary.\nMigratory Birds Regulations (MBR) - The 1917 MBR implement the MBCA according to its prescribed prohibitions against the harming of migratory birds, their nests and their eggs, including the deposit of harmful substances in any waters or any area frequented by migratory birds. The MBR also provide for the issuance of permits or authorizations for certain activities according to specified criteria and conditions. The Regulations are amended on a regular basis to reflect hunting restrictions. For more information on policies and regulations related to migratory birds, please visit the Environment and Climate Change Canada web section on Migratory Birds.\n- Date modified:","Migratory Birds Convention Act (1994)\nThe Migratory Birds Convention Act, 1994, a federal law, implements for Canada what was originally the 1916 Migratory Birds Convention between the United Kingdom and the United States of America for the Protection of Migratory Birds in Canada and the United States. The 1916 Convention was amended by a Protocol agreement signed by Canada and the United States in 1995, which took into account aboriginal and treaty rights of aboriginal peoples on both sides of the border.\nThe purposes of the Convention were underlined by the 1995 Protocol, the recitals of which read in part that Canada and the United States remained,\n‚Ä¶.COMMITTED to the long-term conservation of shared species of migratory birds for their nutritional, social, cultural, spiritual, ecological, economic, and aesthetic values through a more comprehensive international framework that involves working together to cooperatively manage their populations, regulate their take, protect the lands and waters on which they depend, and share research and survey information‚Ä¶\nJurisdiction for migratory birds is federal, due to the fact that migratory birds cross both provincial and international boundaries. The Act is administered by the Canadian Wildlife Service under the authority of the federal Minister of the Environment. The Act applies to migratory birds across Canada, whether located on federal or provincial lands.\nSection 5 of the Act prohibits the possession, buying, selling, exchange or transfer or a migratory bird or nest, or commercial trade in a migratory bird or nest, except in accordance with the Migratory Bird Regulations. At section 6, the Act establishes offences, and appoints game officers with inspection and other powers, as a means of enforcing the Act‚Äôs provisions.\nThe Migratory Bird Regulations address a variety of issues, including but not limited to:\n- Requirements for permits, and other restrictions, on hunting of migratory birds;\n- A prohibition on disturbing the nests or eggs of migratory birds without a permit from the Minister;\n- a general prohibition against introducing non-indigenous migratory bird species; and\n- a prohibition against pollution (defined as the deposit of oil, oil wastes or any other substance harmful to migratory birds) in any waters or any area frequented by migratory birds.\nAlso passed under the Act is the Migratory Bird Sanctuary Regulations, which prescribe certain areas as sanctuaries for migratory birds, and establish the rules governing the sanctuaries. Seven migratory bird sanctuaries are prescribed for British Columbia, having the following designations: Christie Isle, Esquimalt Lagoon, George C. Reifel, Nechako River, Shoal Harbour, Vaseux Lake and Victoria Harbour.\nSignificance of the Act for Watershed Protection\nThe Migratory Birds Convention Act is a significant statute for watershed protection, due to the fact that many migratory birds rely on aquatic habitats for their survival. In B.C., much of our coastal area is used by migratory birds; and many inland waters as well are frequented by migratory birds. The Act can therefore be raised in support of a concern that a development is going to alter or harm a waterway to the detriment of the ecosystem and life that is supported by the waterway.\nAn important point to note is that the Act does not explicitly or directly protect bird habitat; however, if it can be shown that a development will have a significant, negative impact upon migratory bird populations because of pollution of the waters or land frequented by them, the Act can be raised as an argument for protecting the significant habitat.\nCitizens in Action\nIn the case of Alberta Wilderness Association et al. v. Cardinal River Coals Ltd., (1999) 3 F.C. 425, various conservation groups went to court and successfully challenged the construction of an open pit coal mine to be located near Jasper, Alberta. They argued that s. 35 of the Migratory Birds Regulations prohibited the deposit of oil, oil wastes, or any other substance harmful to migratory birds in any area frequented by them. On the facts, the plan for the mine included a plan to deposit millions of tons of rock waste into the nearby creek beds, in an area used for nesting by migratory birds. It was determined that the deposits would pose a threat to the migratory birds that nested there, and therefore would be considered a ‚Äúharmful substance‚Äù within the meaning of the Regulation, and contrary to its terms.\nFor more information on the Migratory Birds Convention Act or bird protection:\n- Electronic version of Migratory Birds Convention Act, S.C. 1994, c. 22 and Regulations\n- Canadian Wildlife Service ‚Äì Migratory Birds Conservation website\n- Canadian Wildlife Service ‚Äì Birds and Mammals website\n- Environment Canada: Questions and Answers on the Migratory Birds Convention Act and Regulations\nOther International Agreements Affecting Migratory Birds or Wetlands Habitats:"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:a2f29568-e37e-4ed2-bdf4-5f215866099f>","<urn:uuid:bd20e726-0ca2-4db6-987e-db103843cf90>"],"error":null}
{"question":"How does fresh goat cheese storage compare to its traditional preservation methods before refrigeration?","answer":"Fresh goat cheese requires cold storage at 33¬∞F-35¬∞F and will keep for 2-3 weeks in the fridge, or up to 6 months if frozen. In contrast, before refrigeration existed, goat cheese was traditionally preserved by storing it in ceramic pots, or by drying it under salt or a coat of finely ground charcoal for use during times when milk was scarce.","context":["Get it while you can: pumpkin goat cheese\nfor the holidays.\nThe wife of a farmer in Hiram,* Ohio, Jean Mackenzie took her first cheese-making class in June 2007 and was licensed to produce cheese that October.\nTwo weeks later, she entered her ch√®vres (goat cheeses) in the National Cheese Competition sponsored by the American Dairy Goat Association. She won two Best of Show awards, two First Place awards and one Second Place award. Awards continued to roll in, most recently at the 2011 American Cheese Society competition (for her Apricot Ginger Ch√®vre).\nIn addition to plain ch√®vre logs, Mackenzie Creamery makes flavored logs that tempt us to hold a goat-out (really a pig-out, where we dig into every flavor). The flavors include Black Truffle, Blue, Blueberry Lemon, Cranberry Orange, Garlic Chive, Herbes de Provence, Honey, Sweet Piquant and seasonal Toasted Pumpkin.\nThere are also small tubs of flavored ch√®vres: Apricot Ginger, Cognac Fig (with Courvoisier Cognac), Sweet Fire and Tomato. The chutney or syrup flavorings are on the bottom of the cup, so that when the cheese is inverted onto a plate, they turn into a topping. Just add crackers, graham crackers and/or baguette slices and serve.\nToasted Pumpkin and Cranberry Orange chevre logs are wonderful additions to holiday tables. The Toasted Pumpkin tastes like pumpkin cheesecake.\nGOAT CHEESE TIPS\nFresh goat cheese should be kept as cold as possible without freezing (33¬∞F‚Äì35¬∞F). It will keep in the fridge for two to three weeks.\nTo open a plastic-wrapped log, use a scissors to snip off a small bit of one corner to create a ‚ÄùV.‚Äù Run the scissors or a sharp knife around the edges and remove the wrapper.\nIt‚Äôs easy to slice fresh goat cheese cleanly with a piece of dental floss.\nServe all cheese at room temperature. Remove the cheese from the refrigerator one hour before serving.\nStore leftover goat cheese covered tightly in plastic wrap. You need to keep out air, which allows mold to grow. If small specks of mold develop, just trim them away and enjoy the rest of the cheese.\nDiscard any cheese that develops an off-odor, strange colors or more than a touch of mold.\nLike all cheeses, ch√®vre ripens as it ages. It will develop a stronger flavor in a week or two (but won‚Äôt get ‚Äúgoaty‚Äù like aged goat cheese).\nFresh goat cheese freezes beautifully for up to 6 months.\nTips straight from the cheese-maker:\nFor retail locations or to buy online, visit the website, MackenzieCreamery.com.\nFind out why goat cheese is a good choice for lactose-intolerant people.\nFind a trove of cheese information, plus reviews of our favorite cheeses, in our Cheese Section.\n*While Hiram, Ohio may become famous as the location of Mackenzie Creamery, it was also the residence of a U.S. president. James A. Garfield lived there as a college student, instructor and then principal at what is today Hiram College. He also married a Hiram girl, Lucretia Rudolph. Several of their children were born there, including Harry Augustus Garfield, who became president of Williams College, and James Rudolph Garfield, who became the 23rd Secretary of the Interior under President Theodore Roosevelt.","Cheese guru, Will Studd, explains what goat's cheese is, where it comes from, and why it's so great.\nIt‚Äôs hard to beat the rich, creamy flavour and refreshing delicate acidity of carefully made goat milk cheese. Instantly recognisable for its pure white colour, goat‚Äôs milk is rich in proteins, vitamins and minerals, and is easily digestible, due to the unusual structure of its small fat globules.\nGoats have been domesticated since nomadic times. They were introduced to mainland Europe for cheese making by the Saracens during the 5th and 6th century. A legacy of those times are the many types of ‚ÄòChevre‚Äô found south of the Loire River in France, which today is the largest producer of goat cheese in the world. These benchmark cheeses take their name from the closest local village, and have inspired the production of similar goat‚Äôs milk cheese in other European countries, as well as in North America and, of course, Australasia.\nGoat‚Äôs milk cheese is becoming increasingly popular as a healthy alternative to cheese made from cow‚Äôs milk. But it was not always a trendy cheese, associated with great restaurants. In fact, the goat was once known as the ‚Äòcow of the poor‚Äô, providing peasants in the drier regions of France with daily fresh milk, with which they made cheese in the farm kitchen at home. These batches were typically small in size and simple to make, using fresh raw milk and salt, and sometimes rennet.\nMany goat cheeses are enjoyed within a few days of production while still moist and soft; others are deliberately ripened under a thin grey, green or blue wrinkled mould over several weeks. Goats are sensitive to cold and daylight hours, and naturally produce milk only in the warmer months of the year. Before refrigeration, cheese was traditionally stored for later use in ceramic pots, or dried under salt or a coat of finely ground charcoal for use when milk was scarce.\nDairy goats are remarkably efficient milkers in proportion to their body weight. A doe will produce about four times as much milk as a milking ewe and three times as much as a cow. Unlike other dairy breeds, they are selective browsers, rather than grazers, and they have a bad reputation for being difficult to look after, and for chewing away at almost anything. Instead of depending on a diet consisting only of green pasture, they prefer to nibble just the tops of the grasses and happily seek out other nutrients in the bush, including tree foliage and deep-rooted plants. These provide minerals that are essential for the goat‚Äôs wellbeing and, crucially, ensure the production of good quality milk, which is the starting point for all great cheese. Consequently, the finest goat cheeses found in the shops today are generally made from goat‚Äôs milk collected in a controlled farming environment.\nGoat‚Äôs milk is used for making many different types of cheese, including blue and hard cheeses. But by far the most popular example is fresh curd cheese. This is because goat‚Äôs milk is very delicate and easily tainted, and the longer cheese is matured, the stronger and more distinctive the flavour and aroma of goat. A common problem is an unpleasant strong ‚Äòbucky‚Äô flavour, which is often caused by the presence of a courting buck. But don‚Äôt let that put you off! If you have never tasted goat‚Äôs milk cheese before, just make sure you try it really Fresh - with a capital F. You‚Äôre in for a real treat.\nWill Studd is the host of LifeStyle FOOD's Cheese Slices."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:9aa88391-f3f2-41cd-9c81-aabba66a19da>","<urn:uuid:978353e9-ef52-4882-955e-21b5ea57f9c1>"],"error":null}
{"question":"What benefit APIs provide for developers who want to create parking applications with real-time updates?","answer":"APIs give developers a key tool to access data and build applications where the data are always up-to-date. When changes occur, such as when a parking garage becomes full, all applications connected to the API will immediately reflect these changes.","context":["Following our project to interconnect Open Data portals around the world, our team set out on a new adventure. Saemes, the second largest parking provider in the Paris Region, recently became the first parking provider to open up its data. Looking at its new Open Data portal, we wanted to see if the company will succeed in improving parking using open data (hint: it can). Off we go!\nGeolocating parking facilities and parking spaces on the road\nLooking for a parking space can be a trying experience, especially in large cities. One often falls upon restricted spots, narrow streets, full lots, among other challenges. The search for the perfect parking space needs some innovation.\nWhile the geolocations of numerous parking facilities are freely available, their raw data generally are not. The data are often embedded on a map within a mobile-unfriendly website, which cannot be used while driving.\nPlease remember: looking at a map on your mobile phone while driving is dangerous.\nAn example of an embedded map; it‚Äôs hard to read this while moving.\nFinally, geolocalized data are seldom shared by parking providers in open and standard formats. Thus, it is hard for developers to get exhaustive, reliable, and up-to-date data. What if operators used Open Data to improve parking?\nFrom static data to dynamic data\nOpen Data related to parking can generally include: basic information, GPS coordinates, services, payment methods, rates, schedules, availability of electric vehicle chargers, accessibility for persons with reduced mobility, and air quality information.\nWith the spreading of sensors, parking providers will soon be able to measure the percentage of a parking facility occupied in real time. Thanks to platforms built to bring value to data, parking providers will be able to instantly transmit this information to their partners (and to the rest of the world). It will then be possible to develop applications to notify the passengers of a vehicle that there is a parking space available right next to them. All in all, users will save valuable time.\nNumber of parking spaces dedicated to persons with reduced mobility by district (Saemes data)\nCustomized user services\nSystemic customization of user service is a new vector of innovation.\nThe creation of data repositories ‚Äì loaded with metadata, images, video streams, audio capture, and more ‚Äì will give users a service that is increasingly responsive to their needs. By opening these repositories in interoperable formats, such as APIs, operators will allow for the development of increasingly relevant applications.\nA user with reduced mobility will be able to find accessible infrastructure. Subscribers to the automated toll-road payment system ‚ÄòLiber-T‚Äô will know instantly that they can pay for parking via this service.\nAn example of a comprehensive and open repository\nPutting the open data streams from various providers into APIs\nOf course, those network effects will only take place when all the players take part. Beyond the creation of data repositories, it is important to think about how they will be shared, using either visualizations, widget libraries, standard formats of files, RESTful APIs, etc.\nAPIs grant developers a key tool to access the data. Thanks to APIs, developers can build applications in which the data are always up-to-date. A parking garage is suddenly full? All the application connected to an API from Saemes‚Äô Open Data portal will indicate the change.\nSaemes: The first parking provider using Open Data to improve parking\nSaemes, the second largest parking provider in the Paris region, opened its OpenDataSoft-powered Open Data portal dedicated to parking data back in March. Saemes has since unlocked the data on 90 parking facilities in the Paris region (that is 23 000 parking spaces). Check out the data available in the infographic below."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:0b1840a4-e1a5-4600-904c-332e449676fc>"],"error":null}
{"question":"Could you explain what VPAT compliance means for accessibility, and how it relates to the broader social responsibility of organizations serving diverse audiences?","answer":"VPAT (Voluntary Product Accessibility Template) is a self-evaluation tool used to declare compliance with Section 508, which comes in four editions: WCAG, 508, EU, and INT. While VPAT was originally developed for technology agencies dealing with federal government, it has become important for broader accessibility compliance. Organizations must conduct thorough accessibility audits and implement features like captions, keyboard navigation, screen readers, ALT text, appropriate color contrast, and manageable timeouts. The social responsibility aspect is significant as over 285 million people worldwide are visually impaired and 360 million have disabling hearing loss. Organizations that improve web accessibility can become industry leaders, reducing legal risk, demonstrating social responsibility, improving SEO, increasing website usability, and better serving their constituents.","context":["What Is 508 Compliance And How To Make A Website Accessible\nWith the rising number of digital accessibility lawsuits, Section 508 compliance has become a buzzword.\nAlmost every vendor or manufacturer of a technology product is concerned about the VPAT scoring. VPAT (Voluntary Product Accessibility Template) is a self-evaluation tool to declare your compliance with Section 508. The law basically applies to Federal agencies that develop or procure technology products.\nWhen a technology business organization deals with a federal agency or any entity that receives funding from the federal government, Section 508 compliance is mandatory for them. The vendors must abide by the law and declare their accessibility standards via VPAT. In today‚Äôs post, we cover what is VPAT and how to use it to protect your business from lawsuits.\nWhat‚Äôs Covered In Section 508?\nSection 508 is part of the Rehabilitation Act which is also connected to certain other digital accessibility laws. The Americans with Disability (ADA) Act is one of the most important laws that has become the #1 reason for digital accessibility lawsuits and expensive penalties.\nSection 508 standards are applicableto information technology and communication products, such as:\nElectronic content like PDFs\nTo put it simply, if a remote learning app has electronic documents, then the developers need to make sure that the products are easily accessible by users who have hearing difficulties, vision loss or cognitive limitations.\nThe updated version for Section 508 needs accessibility compliance for color, images, tables, lists, headings, forms and PDFs.\nMake Your Website Accessible With A VPAT\nVPAT was originally developed only for technology agencies that are dealing with the federal government. However, compliance with Section 508 through regularly auditing your VPAT accessibility standards is a step in the direction of avoiding expensive legal recourse.\nWhat Is VPAT Compliance?\nThere are four different editions of VPAT including WCAG edition, 508 edition, EU edition and INT edition. Depending on your requirements, you can select the edition and test your products to declare your VPAT compliance.\nThe VPAT template can be filled out after a thorough accessibility audit of the products/offerings. Below is a step by step approach to make your website compliant with Section 508.\nCaptions and transcripts: Make sure that the audio and videos are accessible via written text or transcripts. Speech recognition technologies are useful to make your website 508 compliant.\nNavigation: Make sure that website navigation is hassle free if a user doesn‚Äôt have access to a mouse and uses only the keyboard.\nScreen readers: Access that the available content is easily readable via a screen reading platform. To attain Section 508 compliance, it is important to make things accessible for visually impaired users.\nALT text: Visually impaired users use a screen reader, they must know when the screen is displaying an image. Alt texts are alternative texts that include descriptions that the users are now looking at an image or a video on the screen.\nColor and contrast: Foreground and background color contrast is also a useful element to make a website compliant with Section 508. When filling out a VPAT, make sure to test the colour and contrast. This detail is helpful for users to distinguish easily accessible products and offerings.\nTimeouts: Timed responses are challenging for users with cognitive limitations. Avoid using them if you aim for Section 508 compliance.\nA VPAT testing tool is useful to access your website. Although automated scans are only 30% accurate and can only detect basic errors like missing ALT texts and color contrast. It is best to invest in manual audits to make a website totally compliant.\nRegularly updating your VPAT is essential to reduce the risk of being on the ever increasing list of law violators. Click on the link given below to learn what is VPAT accessibility procedure and how long it takes.","What is web accessibility and why should we be talking about it? Simply put, it means that people of all abilities (including those with disabilities) can use your website. Web accessibility ensures that all users, no matter who they are or what devices they use, have a great user experience on the web.\nThink of web accessibility as the digital equivalent to real-world accessibility solutions such as ramps, greater transportation options, Braille in elevators, sign language interpreters, and so on. For digital devices, these solutions include screen readers, voice recognition software, screen magnifiers, and alternative input devices. More than 285 million people worldwide are estimated to be visually impaired and 360 million people worldwide have disabling hearing loss ‚Äì these are your donors, volunteers, and users of your services. And no constituent deserves to be ignored when it comes to your website.\nThere are internationally recognized guidelines in effect to help anyone with a website ensure it meets at least one of three levels of accessibility criteria. The Web Content Accessibility Guidelines 2.0 (WCAG), which have been in effect since 2008, covers a broad range of recommendations to improve accessibility of web content to a wider range of people with disabilities, from blindness and deafness to learning disabilities, cognitive limitations, and limited movement or speech disabilities, or combinations thereof. You may have already heard of many of them such as providing video captioning or transcripts, text alternatives, or audio recordings.\nNonprofits have a unique responsibility, and face unique risk, when it comes to web accessibility.\nMany nonprofits have a mission to serve diverse audiences, and this includes providing easy access to educational materials and other services for those audiences. While that includes both children and adults with disabilities, it can also include seniors with age-related impairments.\nMissions and social responsibility aside, there could be legal ramifications for organizations that don‚Äôt improve their web accessibility. While organizations‚Äô legal responsibility is still unclear, the number of lawsuits related to accessibility claims against various business websites, including ToysRUs, Bank of America, and Netflix, among others, have been on the rise.\nGet ready for some scary source material: The Americans with Disabilities Act, Title III, Public Accommodations and Commercial Facilities, implies web accessibility requirements, while the U.S. Department of Justice holds that there is a ‚Äúpre-existing‚Äù obligation to make websites accessible, even though the DOJ won‚Äôt have any clear rules for at least another two years or so. The Section 508 of the U.S. Rehabilitation Act requires electronic and information technology be available to people with disabilities, including federal employees and members of the public. Section 504 applies to federal programs or organizations that receive federal funds to ensure people with disabilities receive equal access to those programs and services.\nWhew, now that we are past that, let‚Äôs ask a simpler question. What does this mean for nonprofits?\nWeb accessibility is not going away; in fact, it‚Äôs becoming increasingly necessary, and in certain cases, required. Your organization should be thinking about this issue right now. By evaluating and improving your web accessibility, you can become an industry leader in this area‚Äîwhich comes with several benefits:\n- You can reduce your risk of legal action.\n- You can demonstrate corporate/organizational social responsibility, which is great PR, by the way.\n- You can improve your search engine optimization.\n- You can provide increased website usability, which leads to increased donor conversions.\n- You can realize a potential increase in market share.\n- Most important, you can better serve your constituents.\nNext post, we‚Äôll discuss the main principles of web accessibility and putting those principles into practice."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:dd6af6a2-f4d0-40ba-a1e2-6d97eac08e6d>","<urn:uuid:392d2e89-1046-4786-8189-1b3819c4a8a9>"],"error":null}
{"question":"I'm studying tablet cooling systems for my engineering project. What methods are currently being used to cool high-performance tablets? Can you explain the mixed cooling approach? Êï£ÁÉ≠Á≥ªÁªüÊòØÂ¶Ç‰ΩïÂ∑•‰ΩúÁöÑÔºü","answer":"High-performance tablets use a mixture of forced convection and natural convection cooling. The main cooling system typically involves small blowers coupled with heat pipes and heat spreaders. The heat is transported to a radiator, where air is pushed through by the blower and exhausted out. This forced convection system mainly cools the high-power components (processing, graphics, and Wi-Fi), while lower-powered devices are cooled by natural convection. Usually, a heat-pipe solution is used for two to three chips in the product.","context":["By William Maltz, Electronic Cooling Solutions, and John Parry, Mentor GraphicsAccommodating higher performance computing in small form-factors such as a tablet is a thermal management challenge. Touch temperature is as important as processor temperature. Cooling by natural convection alone isn‚Äôt enough for the higher power density of a high-performance tablet, instead forced convection has to be used. This article examines the thermal management challenges of forced convection in a tablet form factor.\nElectronic Cooling Solutions (ECS) first took apart tablets from different vendors, then focused on one particular tablet from a company in Cupertino, California. We did a thorough teardown and analysis of that particular device. We even depopulated the board to understand the amount of power that was used by the processor. We used the Mentor Graphics thermal transient tester, T3Ster, to get a better understanding of the thermal stack-up so that we could come up with an effective power number and an understanding of how it contributed to the thermal load in that particular tablet .\nThis initial study helped us to understand the limits of what you could do with given volumes in natural convection. It also increased our understanding of the effect of realistic spreading versus ideal spreading. We also learned more about the components that make up a tablet. A fundamental understanding of heat transfer is good, but it needs to be coupled with a good understanding of the actual products for which we‚Äôre designing cooling solutions.\nRecently, we have been taking a look at another class of tablets, the business class of tablets that provide more performance than typical natural convection tablets . This time we focused on a product from a company located in Redmond, Washington, because this tablet is a good example of a product that provides the type of performance that people expect to see in either a notebook or desktop system. We‚Äôve used this product in our work to run CFD models. It can do them as long as the models aren‚Äôt too large or too complex, an indication of the processing power that these tablets can deliver.\nAgain, we took this tablet apart and dissected its innards to understand how it works (Fig. 1). To say that it relies on forced convection for cooling isn‚Äôt totally accurate. A mixture of forced convection and natural convection cooling is used to cool these devices. The need for improving heat spreading remains, whether we are looking at the design of a forced convection tablet or a natural convection tablet. We must also use the surface as effectively as possible is to avoid hot spots on the surface and to maintain a comfortable touch temperature.\nWith this product, we went through many of the same steps that we did with the natural convection devices. However, because of the mixed cooling nature of this product, we wanted to explore other techniques for enhancing the heat spreading, so we examined various materials, including copper (Fig. 2). We also considered graphite and another more recent innovation, thermal ground plane (TGP), that have some promise to provide some better heat spreading, but also currently have serious cost and development issues. We have had difficulty getting samples for our study, but we think these materials are going to be of interest to the industry going forward.\nWe estimate that with a forced convection product, power dissipation can be extended to about 40 Watts, whereas for a natural convection tablet, dissipating more than 17 Watts is difficult. So there‚Äôs a significantly larger capacity associated with the forced convection product. We ruled out from our earlier work the use of synthetic jets in forced convection systems. What‚Äôs being used mainly today are small blowers, not much different than what was done for notebook computing in the 1990s.\nEven the all-in-one systems used a beefier version of that same kind of solution where the heat sources are essentially coupled to a heat pipe and heat spreaders, the heat is transported to a radiator, and then the air is pushed through the radiator with a blower, and exhausted out of the system. Two variations are being implemented, one where the blower is used to move a certain amount of air through the system to cool other components, and the other where the air actually is brought in very close to the intake side of the blower. It‚Äôs then just pushed through the heat exchanger and exhausted through a vent; it‚Äôs only being used to remove heat from the system that‚Äôs transferred by the heat pipes to the heat exchanger. Heat generated by lower powered devices is removed by natural convection.\nThus a mixed convection system is being used to cool the components that have to do with processing, graphics and Wi-Fi. This is typically where the power is concentrated. A heat-pipe solution is normally used for two to three chips in the product (Fig. 3). Eventually this may change to just one chip as all of those functions may be integrated into a single package. It‚Äôs just a matter of time because it will reduce cost, improve the performance and mitigate timing issues between these chips when they communicate with each other.\nCurrent timing issues are exacerbated by chips running at different speeds, temperatures and more. At the end, there will be a reduction in total power, but also likely a higher power density if all these functions are inside one package. Cost and power reduction are mitigated by the power density, but in handheld devices, just as in every other consumer product in the electronics business, cost trumps thermal performance.\nYou certainly save cost on buying one package as opposed to buying three discrete ones and the cost of designing the extra electronics to get them to talk together properly, but there‚Äôs a hidden cost down the line ‚Äî it can only be used if it can be cooled. In the long term, the industry will be able to increase performance by making more effective use of power management. The desire to have even more performance, which means increasing the power, has been present in every single other electronic product that was ever built.\nInterestingly, power management is becoming such an important part of thermal management that we expect to see thermal organizations in the future having a group of software people that are involved in power management working within the thermal team in order to facilitate better communication between all of the people involved in managing the thermal solution. As the products become more integrated, the design teams have to also become more integrated. Certain companies that used to specialize in just software are now doing both software and hardware. They need to have good integration between the software and the hardware. Steps are being taken to ensure that software and hardware are optimized to work well with each other.\n- Guy R. Wagner (2014), ‚ÄúA Study of the Maximum Theoretical Power Dissipation of Tablets under Natural Convection Conditions,‚Äù 20th THERMINIC Workshop, London.\n- B. Nagendran, A. Raghupathy, and W. Maltz (2015), ‚ÄúThermal Management Challenges in Forced Convection Tablets,‚Äù 31st SEMI-THERM Symposium."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:929bcd6b-90f2-4bc0-8791-aec6db620fc9>"],"error":null}
{"question":"What's the connection between Aphrodite and eudaimonia in ancient Greek philosophy?","answer":"In the dialogues, Aphrodite is associated with pleasure, as indicated when Socrates discusses how Philebus says she is called Aphrodite but her real name is Pleasure. Meanwhile, eudaimonia (happiness) is discussed in Aristotle's ethics as the highest good achievable in human action. However, unlike the connection of Aphrodite to pure pleasure, Aristotle argues that true happiness requires activity of the soul in conformity with virtue, particularly wisdom, and must extend over a complete lifetime - 'one swallow does not make spring.' Thus while Aphrodite represents pleasure alone, eudaimonia represents a more complex conception of human flourishing based on reason and virtue.","context":["translated by Benjamin Jowett\nPERSONS OF THE DIALOGUE: SOCRATES; PROTARCHUS; PHILEBUS.\nSocrates. Observe, Protarchus, the nature of the position which\nyou are now going to take from Philebus, and what the other position\nis which I maintain, and which, if you do not approve of it, is to\nbe controverted by you. Shall you and I sum up the two sides?\nProtarchus. By all means.\nSoc. Philebus was saying that enjoyment and pleasure and delight,\nand the class of feelings akin to them, are a good to every living\nbeing, whereas I contend, that not these, but wisdom and\nintelligence and memory, and their kindred, right opinion and true\nreasoning, are better and more desirable than pleasure for all who are\nable to partake of them, and that to all such who are or ever will\nbe they are the most advantageous of all things. Have I not given,\nPhilebus, a fair statement of the two sides of the argument?\nPhilebus Nothing could be fairer, Socrates.\nSoc. And do you, the position which is assigned to you?\nPro. I cannot do otherwise, since our excellent Philebus has left\nSoc. Surely the truth about these matters ought, by all means, to be\nSoc. Shall we further agree-\nPro. To what?\nSoc. That you and I must now try to indicate some state and\ndisposition of the soul, which has the property of making all men\nPro. Yes, by all means.\nSoc. And you say that pleasure and I say that wisdom, is such a\nSoc. And what if there be a third state, which is better than\neither? Then both of us are vanquished-are we not? But if this life,\nwhich really has the power of making men happy, turn out to be more\nakin to pleasure than to wisdom, the life of pleasure may still have\nthe advantage over the life of wisdom.\nSoc. Or suppose that the better life is more nearly allied to\nwisdom, then wisdom conquers, and pleasure is defeated;-do you agree?\nSoc. And what do you say, Philebus?\nPhi. I say; and shall always say, that pleasure is easily the\nconqueror; but you must decide for yourself, Protarchus.\nPro. You, Philebus, have handed over the argument to me, and have no\nlonger a voice in the matter?\nPhi. True enough. Nevertheless I would dear myself and deliver my\nsoul of you; and I call the goddess herself to witness that I now do\nPro. You may appeal to us; we too be the witnesses of your words.\nAnd now, Socrates, whether Philebus is pleased or displeased, we\nwill proceed with the argument.\nSoc. Then let us begin with the goddess herself, of whom Philebus\nsays that she is called Aphrodite, but that her real name is Pleasure.\nPro. Very good.\nSoc. The awe which I always feel, Protarchus, about the names of the\ngods is more than human-it exceeds all other fears. And now I would\nnot sin against Aphrodite by naming her amiss; let her be called\nwhat she pleases. But Pleasure I know to be manifold, and with her, as\nI was just now saying, we must begin, and consider what her nature is.","The End of Our Actions\nThe Good Life and Happiness\nThe Aristotelian corpus contains two works on ethics: the Nicomachean\nEthics and Eudemian Ethics. The titles seem to refer to\nAristotle's friend (Eudemus of Rhodes) and son (Nicomachus). The\nrelationship between the Eudemian Ethics and Nicomachean\nEthics is uncertain. Books IV, V, and VI of the Eudemian Ethics\nare identical to Books V, VI, and VII of the Nicomachean Ethics.\nIt is traditionally thought that Aristotle wrote the\nEudemian Ethics first.\nAn Outline of the Nicomachean Ethics:\nNE I.1095a-I.1096a. The best good\nNE I.1097b-I.1098a. The argument from function\nNE I.1102a-II.1109b. Virtue and the soul\nNE III.1109b-1115a. Necessary conditions for virtue\nNE III.1115a-IV.1128b. Virtues of character\nNE V.1129a-1138b. Justice\nNE VI.1138b-1145a. Virtues of thought\nNE VII.1145a-1154b. Continence, pleasure\nNE VIII.1155a-IX.1172a. Friendship\nNE X.1172a-1181b. Pleasure, happiness, legislation The subject of Aristotle's Nicomachean Ethics is the \"end of the things we pursue in our actions\" and what he calls the \"best good\" for a human being (Nicomachean Ethics I.2.1094a).\nKnowledge of this \"best good,\" Aristotle says, \"is of great importance for the conduct of our lives.\" If we have it, and so know what this good in a human life is, then, \"like archers who have a target, we are more likely to do what is needed\" (Nicomachean Ethics I.2.1094a).\nAristotle says, at the outset, that \"the [life] of contemplation (·ΩÅ Œ∏ŒµœâœÅŒ∑œÑŒπŒ∫œåœÇ)\" is the life he will \"examine in what follows\" (Nicomachean Ethics I.5.1096a). What he means in saying this is not completely clear. It seems, though, that his intention is to examine the life in which action achieves the best good in order to determine whether it is the life of contemplation.\nThe conclusion Aristotle reaches is not easy to see, in part because the Nicomachean Ethics reads like a series of incomplete lecture notes, not a finished work intended for publication. This makes it difficult to follow his train of thought in complete detail, but he seems to conclude that the life in which action achieves the best good is in fact a life of contemplation.\nWe will try to follow the main lines of his argument in this and the next two lectures.\nThe Human Function\n\"[The science of politics] ... ordains which of the sciences are to exist in states, and what branches of knowledge the different classes of the citizens are to learn, and up to what point.... Inasmuch then as the rest of the sciences are employed by this one, and as it moreover lays down laws as to what people shall do and what things they shall refrain from doing, the end of this science must include the ends of all the others and so will be the human good\" (Nicomachean Ethics I.1.1094a).\n\"As far as the name [of the good at which politics aims] goes, we may almost say that the great majority of mankind are agreed about this; for both the multitude and persons of refinement speak of it as happiness, and conceive of living well and doing well as the same thing as being happy. But what constitutes happiness is a matter of dispute; and the popular account of it is not the same as that given by the philosophers\" (Nicomachean Ethics I.2.1095a).\n\"To say that the best good is happiness will probably appear a truism; we still require a more explicit account of what this good is and thus what constitutes happiness. Perhaps we may arrive at this account by ascertaining the function (·ºîœÅŒ≥ŒøŒΩ) of man\" (Nicomachean Ethics I.6.1097b).\n\"Life seems common even to plants, but we are seeking what is peculiar to man. So let us exclude the life of nutrition and growth. Next there would be a life of perception, but this also seems common to the horse, the ox, and every animal. The remaining possibility is a life of action of [the part of the soul] having reason (œÄœÅŒ±Œ∫œÑŒπŒ∫ŒÆ œÑŒπœÇ œÑŒø·ø¶ ŒªœåŒ≥ŒøŒΩ ·ºîœáŒøŒΩœÑŒøœÇ)\" (Nicomachean Ethics I.6.1097b). Aristotle first notes that it is generally agreed that \"happiness\" (Œµ·ΩêŒ¥Œ±ŒπŒºŒøŒΩŒØŒ±) is the best good achievable in action. There are various goods a life can possess. It can be a life in which there is lots of money, for example, if money is a good, but the best of such goods is generally agreed to be happiness. This is the good in life that it benefits us most to achieve.\nThis agreement about what the best good is, however, as Aristotle also notes, is only a first step in the inquiry because there is no general agreement about what happiness is and hence what the good life is. So, to reach a deeper understanding, Aristotle turns his attention to what he calls the \"work\" or \"function\" (·ºîœÅŒ≥ŒøŒΩ) of a human being. He argues that the function of a human being is \"action of [the part of the soul] having reason (œÄœÅŒ±Œ∫œÑŒπŒ∫ŒÆ œÑŒπœÇ œÑŒø·ø¶ ŒªœåŒ≥ŒøŒΩ ·ºîœáŒøŒΩœÑŒøœÇ).\"\nThis function has its basis is in what Aristotle thinks a human being is.\nAristotle thinks, as we have seen, that natural bodies behave in the ways that characterize the natural kind. They have this behavior because they are forms in matter. The form is the organization of the matter according to which there is an object that belongs to the natural kind. For human beings, because they are rational animals, this behavior involves reason.\nThe Function Argument\nWe can better understand the relation between happiness and the human function if we set out in argument form what Aristotle seems to have mind. He argues, it seems, from the premises\n‚Ä¢ the good life is one in which a human being achieves the best good\n‚Ä¢ a human being who in action achieves the best good is a good human being\n‚Ä¢ a good human being is one who performs the human function well\n‚Ä¢ the human function is \"action of [the part of the soul] having reason\"\nto the conclusion that for a human being the good life is\n‚Ä¢ a life of performing \"action of the [part of the soul] having reason\" well\nThis argument shows us premises we might want to reject, but more importantly (for the history of philosophy) it allows us to identify the questions whose answers we must find if we are to understand how Aristotle thinks about happiness and the good life. We need to know\n‚Ä¢ what \"action of the [part of the soul] having reason\" is\n‚Ä¢ what it is to perform this \"action\" well\nOtherwise, we will not be able to understand why Aristotle thinks that the life in which action achieves the best good, and thus the life it benefits us most to live, is the life of contemplation.\n\"If we declare that the function of man is a certain life, and that this is an activity and action of the soul with reason (œàœÖœá·øÜœÇ ·ºêŒΩŒ≠œÅŒ≥ŒµŒπŒ±ŒΩ Œ∫Œ±·Ω∂ œÄœÅŒ¨ŒæŒµŒπœÇ ŒºŒµœÑ·Ω∞ ŒªœåŒ≥ŒøœÖ), and that the good of man is to do this well and beautifully, and that if a function is completed well when it is completed in accordance with its proper virtue, then it follows that the good of man is the activity of his soul in conformity with virtue, or if there are several virtues, then in conformity with the best and most the end (œÑ·Ω¥ŒΩ ·ºÄœÅŒØœÉœÑŒ∑ŒΩ Œ∫Œ±·Ω∂ œÑŒµŒªŒµŒπŒøœÑŒ¨œÑŒ∑ŒΩ). Moreover, to be happy takes a complete lifetime; for one swallow does not make spring, nor does one fine day; and similarly one day or a brief does not make a man supremely blessed and happy\" (Nicomachean Ethics I.6.1098a).\nFunction and Virtue\nGiven that the good life for a human being consists in performing the human function well, and the background premise that things perform their function well only if they have their proper virtue or virtues, Aristotle concludes that \"happiness\" and \"the good of man\" is\n‚Ä¢ \"the activity of the soul in conformity with virtue, or if there are several\nvirtues, in conformity with the best and most the end among them.\"\nAristotle has in mind the \"activity\" or \"action of [the part of the soul] having reason.\" So, to follow Aristotle's thinking, we need to know how he understands what\n‚Ä¢ \"the [part of the soul] having reason\" is\nand what he thinks\n‚Ä¢ the virtues proper to this part of the soul are\nOnce we understand this, we will be in a better position to see what Aristotle thinks actually goes on in a life in which one achieves the best good achievable in action.\nThe Parts of the Soul\nAristotle's thinks of the parts of the soul is in some way the same as Plato's. Aristotle\nthinks that \"the [part of the soul] having reason\" consists in two parts. It has\nThe human soul =\n1. part having reason\n1.a. part with reason\n1.a.1. part with reason about theoretical matters\n1.a.2. part with reason about practical matters\n1.b. part with reason as its controller\n2. part not having reason\n‚Ä¢ a part with reason\n‚Ä¢ a part with reason somehow as its controller\nFurther, he subdivides the \"part with reason\" into what we can describe for now as\n‚Ä¢ a part that reasons about theoretical matters\n‚Ä¢ a part that reasons about practical matters\nOne difference between this division and the one in the Republic is that Socrates separates the part that somehow has reason as its controller into \"spirit\" and \"appetite.\"\nVirtues of Thought and Character\nAristotle also divides the virtues in a way that is familiar from the discussions in Plato. Aristotle divides them into the virtues of \"thought\" and the virtues of \"character.\"\n\"If we should say that this part has reason, then the part that has reason will have two parts, one that has authority in itself, and one that listens as to a father. The distinction between virtues also reflects this difference. We say that some are virtues of thought (Œ¥ŒπŒ±ŒΩŒøŒ∑œÑŒπŒ∫·Ω∞œÇ) and others are virtues of character (·º†Œ∏ŒπŒ∫Œ¨œÇ)\" (Nicomachean Ethics I.13.1103a).\n·º†Œ∏ŒπŒ∫Œ¨œÇ is a plural adjective form of ·º†Œ∏ŒπŒ∫·º†, which is the root the English word 'ethical.'\nOne Virtue is the Best\nAristotle says, as we have already seen, that \"if there are several virtues, then [the good of man is activity] in conformity with the best and most the end.\"\nFurther, in the last book of the Nicomachean Ethics, he refers to what he calls the \"best virtue\" and says that the \"activity in accordance with\" this virtue is \"perfect happiness.\"\nThe noun ·ºêŒΩŒ≠œÅŒ≥ŒµŒπŒ± is formed from ·ºêŒΩ (\"in\") and ·ºîœÅŒ≥ŒøŒΩ (\"function\" or \"work\"). A\nstandard translation is 'activity.'\n\"If happiness is activity (·ºêŒΩŒ≠œÅŒ≥ŒµŒπŒ±) in accordance with virtue, it is\nreasonable it should be in accordance with the best virtue; and this is the\nvirtue of the best part of us. Whether it is intellect (ŒΩŒø·ø¶œÇ), or whatever\nelse seems to rule and lead us by nature and to think what is noble and\ndivine, this itself being divine or as being the divinest part of us, the\nactivity of it in accordance with its proper virtue will be perfect happiness\n\"we have said (Œµ·º¥œÅŒ∑œÑŒ±Œπ)...\"\nThis is puzzling. The Nicomachean Ethics as we now have it contains no previous statement of this view. and we have said this an activity of contemplation\" (Nicomachean Ethics X.7.1177a).\nWe will not worry at this point about what Aristotle means by \"perfect happiness.\"\nThe more immediate problem is to understand what he thinks goes on in the life in which the activity of \"the [part of the soul] having reason\" is in accordance with the \"best virtue.\" To know that, we need to know what virtue Aristotle thinks the \"best virtue\" is.\n\"It seems likely that the man who whose activity is according to the intellect (·ΩÅ Œ¥·Ω≤ Œ∫Œ±œÑ·Ω∞ ŒΩŒø·ø¶ŒΩ ·ºêŒΩŒµœÅŒ≥·ø∂ŒΩ), and who cultivates his intellect and keeps it in the best condition, is also the man most beloved of the gods. For if, as is generally believed, the gods exercise some superintendence over human affairs, it will be reasonable to suppose that they take pleasure in that part of man which is best and most akin to themselves, namely the intellect, and that they recompense with their favors those men who esteem and honor this most, because these care for the things dear to themselves, and act rightly and nobly. Now it is clear that these attributes belong most of all to the wise man. He therefore is most beloved by the gods; and if so, he is naturally most happy. In this way too, then, the wise man is happy most of all\" (Nicomachean Ethics X.8.1179a). Aristotle does not explicitly identify the \"best virtue.\" This makes the interpretation uncertain, but his view seems to be that it is the virtue of thought he calls \"wisdom\" (œÉŒøœÜŒØŒ±).\nThe Search for More Answers\nThis interpretation so far, even if it is correct, does not tell us what goes on in this life of \"activity\" or \"action of [the part of the soul] having reason\" in accordance with the virtue of \"wisdom.\" To know what Aristotle thinks goes on in this life, we need to know\n‚Ä¢ what the virtue \"wisdom\" (œÉŒøœÜŒØŒ±) is\n‚Ä¢ how \"the [part of the soul] with reason\" acquires wisdom\nIn addition, to begin to understand what Aristotle has in mind when he talks about \"perfect happiness,\" we need to know why he thinks that wisdom is the \"best virtue.\"\nWe will try to get these answers in the next two lectures.\nPerseus Digital Library:\nPlato, Euthydemus, Republic\nAristotle, Nicomachean Ethics, Eudemian Ethics\nHenry George Liddell, Robert Scott, A Greek-English Lexicon:\n·ºêŒΩŒ≠œÅŒ≥ŒµŒπŒ±, energeia, noun, \"activity\"\n·ºîœÅŒ≥ŒøŒΩ, ergon, noun, \"work\"\nŒµ·ΩêŒ¥Œ±ŒπŒºŒøŒΩŒØŒ±, eudaimonia, noun, \"happiness\"\n·º†Œ∏ŒπŒ∫ŒÆ, ƒìthikƒì, adjective, \"moral\"\nŒºŒ±Œ∫Œ¨œÅŒπŒøœÇ (derivative of ŒºŒ¨Œ∫Œ±œÅ, epitaph of the gods in Homer, Iliad I.339), makarios, adjective, \"blessed\"\nœÉŒøœÜŒØŒ±, sophia, noun, \"wisdom\"\nœÉŒøœÜœåœÇ, sophos, adjective, \"wise\"\nœÑŒ≠ŒªŒµŒπŒøœÇ, teleios, adjective, \"having reached its end, finished, complete\"\nœÑŒµŒªŒµŒπŒøœÑŒ¨œÑŒ∑ŒΩ, teleiotatƒìn, adjective, superlative of œÑŒ≠ŒªŒµŒπŒøœÇ\nArizona State University Library. Loeb Classical Library:\nAristotle, Parts of Animals\n\"Aristotle thinks objects have a function. We can readily understand what he means in the case of artifacts: they are constructed the way they are constructed to fulfill a certain task or to exhibit a certain kind of behavior. Fulfilling this task or exhibiting this behavior is their function; and if they do exhibit this behavior, we say they are functioning. Aristotle, like Plato before him, extends the notion of function to natural objects, especially to living things. If a living thing is functioning, it will behave in a certain, characteristic way; to behave in this way is its function. In addition, Aristotle thinks that the capacity of an object to behave in this characteristic way depends on its organization, structure, and disposition, indeed, he thinks that it is just this disposition or organization that enables the object to behave the way it does. Now, for Aristotle, the form is this disposition or organization, while the matter is what is thus disposed or organized\" (Michael Frede, \"Individuals in Aristotle,\" 65-66. Essays in Ancient Philosophy, 49-71)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:4c0e74a8-12e2-4240-8148-7ac191431fd9>","<urn:uuid:0be9b268-d154-4756-a77a-72f8d5d5892d>"],"error":null}
{"question":"Could you help me compare Asia and Europe? I'm interested in their population density and geographical connection. Also, ¬øc√≥mo se dividen estos dos continentes geogr√°ficamente?","answer":"Asia and Europe have significant differences in population density - Asia has approximately 203 people per square mile, while Europe has about 134 people per square mile. These continents are physically connected as part of Eurasia, and they are divided by the watershed divides of the Ural and Caucasus Mountains, the Ural River, the Caspian and Black Seas, and the waterways of the Turkish Straits. However, this division is somewhat arbitrary and reflects East-West cultural, linguistic, and ethnic differences rather than a clear dividing line. Several countries, including Turkey, Russia, Azerbaijan, Georgia, and Kazakhstan, are considered transcontinental as they span both continents.","context":["Europe is a continent located certainly in the Northern Hemisphere and mostly in the Eastern Hemisphere. It is bordered by the Arctic Ocean to the north, the Atlantic Ocean to the west, Asia to the east, and the Mediterranean Sea to the south. It comprises the westernmost part of Eurasia.\nEurope is most commonly considered to be divided from Asia by the watershed divides of the Ural and Caucasus Mountains, the Ural River, the Caspian and Black Seas and the waterways of the Turkish Straits. Although the term ‚Äúcontinent‚Äù implies visceral geography, the estate link up is somewhat arbitrary and has been redefined several epoch since its first conception in classical antiquity. The unfriendliness of Eurasia into two continents reflects East-West cultural, linguistic and ethnic differences which amend upon a spectrum rather than past a brilliant dividing line. The geographic attach in the middle of Europe and Asia does not follow any confess boundaries: Turkey, Russia, Azerbaijan, Georgia and Kazakhstan are transcontinental countries. France, Portugal, Netherlands, Spain and associated Kingdom are as well as transcontinental in that the main ration is in Europe even though pockets of their territory are located in other continents.\nEurope covers nearly 10,180,000 square kilometres (3,930,000 sq mi), or 2% of the Earth‚Äôs surface (6.8% of land area). Politically, Europe is at odds into approximately fifty sovereign states of which the Russian Federation is the largest and most populous, spanning 39% of the continent and comprising 15% of its population. Europe had a total population of approximately 741 million (about 11% of the world population) as of 2016. The European climate is largely affected by hot Atlantic currents that temper winters and summers on much of the continent, even at latitudes along which the climate in Asia and North America is severe. new from the sea, seasonal differences are more noticeable than near to the coast.\nEurope, in particular ancient Greece and ancient Rome, was the birthplace of Western civilization. The drop of the Western Roman Empire in 476 AD and the subsequent Migration get older marked the stop of ancient chronicles and the initiation of the middle Ages. Renaissance humanism, exploration, art and science led to the highly developed era. back the Age of Discovery started by Portugal and Spain, Europe played a predominant role in global affairs. amid the 16th and 20th centuries, European powers controlled at various period the Americas, something like every of Africa and Oceania and the majority of Asia.\nThe Age of Enlightenment, the subsequent French revolution and the Napoleonic Wars shaped the continent culturally, politically and economically from the stop of the 17th century until the first half of the 19th century. The Industrial Revolution, which began in great Britain at the stop of the 18th century, gave rise to broadminded economic, cultural and social amend in Western Europe and eventually the wider world. Both world wars took area for the most portion in Europe, contributing to a terminate in Western European dominance in world affairs by the mid-20th century as the Soviet bond and the associated States took prominence. During the chilly War, Europe was separated along the Iron Curtain surrounded by NATO in the West and the Warsaw pact in the East, until the revolutions of 1989 and drop of the Berlin Wall.\nIn 1949 the Council of Europe was founded, once a speech by Sir Winston Churchill, as soon as the idea of unifying Europe to achieve common goals. It includes all European states except for Belarus, Kazakhstan and Vatican City. other European integration by some states led to the formation of the European bond (EU), a remove diplomatic entity that lies amid a confederation and a federation. The EU originated in Western Europe but has been expanding eastward before the drop of the Soviet devotion in 1991. The currency of most countries of the European Union, the euro, is the most commonly used in the middle of Europeans; and the EU‚Äôs Schengen area abolishes link up and immigration controls among most of its believer states.\nMap Of Airports In Europe has a variety pictures that aligned to find out the most recent pictures of Map Of Airports In Europe here, and then you can acquire the pictures through our best map of airports in europe collection. Map Of Airports In Europe pictures in here are posted and uploaded by secretmuseum.net for your map of airports in europe images collection. The images that existed in Map Of Airports In Europe are consisting of best images and high environment pictures.\nThese many pictures of Map Of Airports In Europe list may become your inspiration and informational purpose. We hope you enjoy and satisfied similar to our best picture of Map Of Airports In Europe from our store that posted here and after that you can use it for suitable needs for personal use only. The map center team after that provides the further pictures of Map Of Airports In Europe in high Definition and Best environment that can be downloaded by click on the gallery below the Map Of Airports In Europe picture.\nYou Might Also Like :\nsecretmuseum.net can back you to acquire the latest recommendation more or less Map Of Airports In Europe. restructure Ideas. We allow a summit character high photo taking into account trusted permit and everything if youre discussing the house layout as its formally called. This web is made to approach your unfinished room into a suitably usable room in usefully a brief amount of time. hence lets bow to a augmented deem exactly what the map of airports in europe. is everything not quite and exactly what it can possibly complete for you. later making an beautification to an existing habitat it is hard to develop a well-resolved onslaught if the existing type and design have not been taken into consideration.\nmap of major airports in europe nations online project searchable map and satellite view of european capital city airports and other major airports in europe searchable location map of europe s most busiest and most important airports map of airports in europe ourairports re lfsl thu 26 sep 2019 david at brive souillac france reply to tgd thanks for the update we re a community driven initiative and if you have time you are very welcome to edit the airport entry to make the changes europe airports european airport and flight guide our airport guides include location information and maps car hire and transfer availability plus visitor reviews we welcome your reviews the airport with the top vote having at least 5 votes in europe is map of the airports in europe live arrivals and departures europe is a continent with an area of 6 321 780 square miles and a population of 740 000 000 you have the choice between 347 airports handling over 1 781 807 656 passengers in 46 different european countries airports in europe skyscanner you will find below information about airports in europe use the links below to read detailed information about airports in europe locations routes live departures and arrivals etc use the links below to read detailed information about airports in europe locations routes live departures and arrivals etc the busiest airports in europe worldatlas com travel the busiest airports in europe the heathrow airport of the united kingdom is the busiest airport in europe followed by charles de gaulle airport of france and amsterdam airport schiphol of the netherlands list of airports in europe wikipedia the five european microstates have no airport within their boundaries though san marino does have a small airfield with a grass runway each has at least one heliport and all except monaco are landlocked ryanair route map our european destinations see where we fly with ryanair s flight route map plan your trip and find cheap flight deals to and from our european destinations see where we fly with ryanair s flight route map plan your trip and find cheap flight deals to and from our european destinations list of the busiest airports in europe wikipedia this is a list of the 100 busiest airports in europe ranked by total passengers per year including both terminal and transit passengers data is for 2018 and is sourced individually for each airport and from a variety of sources normally the national aviation authority statistics or those of the airport operator map of europe europe map huge repository of european political map of europe above we have a massive map of europe the size of the map is 2500 pixels by 1761 to get the full view you need to click on the image and then click on the x in the top right corner below are the countries of europe and the respective capital cities","7 continents make this world special, they include North America, Asia, Africa, South America, Europe, Australia, and Antarctica. These continents make up the largest land masses in the world and most of its population.\n‚ÄòThere are seven continents in the world, but can you name them all? Do you know what a continent is? If you want to know more about the seven continents, you have come to the right place.\nFrom 1 Continent to Seven\nDid you know that the current seven continents on Earth were once all connected? About 175 million years ago, there was only one single supercontinent on Earth.\nScientists called that supercontinent Pangea.\nIn a process that lasted millions of years, Pangea broke up into seven pieces that drifted slowly to occupy their present-day positions on the planet.\nBut continents have not stopped drifting, so more continents could be formed in the very distant future.\nWhat Are the Seven Continents?\nAlthough there is some controversy on the subject, it is widely accepted that the 7 continents on Earth the following:\n- North America.\n- South America.\nAfrica occupies 11,670,000 mi2 or 28,489,869 Km2.\nIts estimated total population is 1,119,307,171. And its largest city is Lagos, Nigeria with a population of about 15,118,780.\nAfrica is the second continent on the planet both in terms of size and of the total population.\nThere are 54 different independent countries in Africa.\nAbout 15% of people on Earth live in Africa.\nAfrica has a wide variety of different climates. There is a sharp contrast between the dry climates of Northern Africa that are located over the equator and those more temperate climates in Southern Africa under the equator.\nIf there are dreams about a beautiful South Africa, there are also roads that lead to their goal. Two of these roads could be named Goodness and Forgiveness. ‚Äì Nelson Mandela\nThe continent is known for its many unique species of animals, with more than 7,000 different types of mammals and over 100,000 types of insects. Some of the more well-known African animals include camels, giraffes, elephants, or rhinoceros.\nMost of the African continent is surrounded by water: the Indian Ocean in the East, the Atlantic Ocean in the West, the Red Sea to the Northeast, and the Mediterranean Sea to the North. The closest continent to Africa is Europe. The closest distance between Africa and Europe is just 8.9 miles (or 14.3 kilometers).\nIn contrast, very few people live in Antarctica. The estimated population is around 4,913, and its largest city is the McMurdo Station with an approximate population of only 1,258.\nThe total land area of Antarctica is 5,405,000 mi2 or 12,949,940 km2.\nAntarctica covers the Southern Pole and it is mostly covered in ice all year around. Frigid temperatures make Antarctica‚Äôs weather one of the harshest on the planet.\nWith a total population of 4,494,302,221, Asia has the largest population of all the continents on Earth. About 60% of people of Earth live in Asia. It is also the most densely populated continent in the world with approximately 203 people per square mile.\nIt is also the largest continent, with a landmass of 17,210,000 mi2 or 44,029,797 km2. Asia covers about 9 percent of the planet‚Äôs surface.\nThe largest city in Asia is Tokyo, Japan, with a total population of about 37,126,000.\nIts landmass is the Eastern part of Eurasia (roughly East of the Ural Mountains). To the east, Asia is bordered by the Pacific Ocean, but Asia also borders the Indian Ocean to the South and the Arctic Ocean to the North.\nSome of the world‚Äôs oldest civilizations come from Asia, such is the case of Japan and China.\nThe total population of Australia is 39,901,000. Its land area is 2,970,000 mi2 or 5,179,976 km2. The largest city on the continent is Sidney, Australia with a population of 4,921,000.\nThe mainland is solely occupied by the country of Australia (the country and the continent are two different things), but the continent also includes Tasmania, New Guinea, New Zealand, and other islands.\nWhen the continent was discovered by Europeans, it got its current name from the Latin word ‚Äúaustralis‚Äù, which means southern because of its geographical location. Two oceans surround Australia: The Pacific Ocean on the West and the Indian Ocean on the East.\nOver 80% of all the flora and fauna of Australia is unique in the world. The largest reef in the world, The Great Barrier Reef, is in Australia.\nAustralia has been inhabited for about 45,000 years. European settlers began arriving in the 18th century. Since then, many people from Asia have also settled on the continent.\nKnown as the ‚Äúold world‚Äù, Europe has a land area of 3,931,000 mi2 or 7,769,964 km2. Its total population is about 738,949,000, which is approximately 11% of the world‚Äôs population. Its largest city is Istanbul, Turkey with a population of 14,657,434.\nEurope is the western area of the Eurasian landmass. That corresponds to only about 7% of the planet‚Äôs landmass.\nEurope is the second smallest continent after Australia but it is also the second most densely populated continent with about 134 people per square mile.\nThere are about 50 different countries in Europe, some of them as small in size as a city (Vatican City) or as big as Russia.\nApart from its mainland, Europe also comprises several islands such as the British Isles, Malta, Cyprus, Sicily, or Iceland, and many other smaller islands.\nEurope is bordered by several oceans other bodies of water: the Atlantic Ocean in the West, the Black Sea and the Mediterranean Sea in the South, and the Arctic Ocean in the North.\nAncient civilizations originated in Europe, most notably ancient Greek and Roman civilization. After Islam was eradicated in the Iberian Peninsula, Europe became Christian and European spread their religion throughout the world.\nThe landmass of North America is 9,540,000 mi2 or 23,309,892 km2. Its total population is approximately 579,024,000.\nWith a population of 19,411,000, Mexico City is the largest city in North America.\nNorth America comprises Canada, the United States, Mexico, the island nations of the Caribbean, and several Latin American nations.\nIt is the third largest continent on Earth. It is surrounded by the Pacific Ocean to the West, the Atlantic Ocean to the East, and the Arctic Ocean to the North.\nThe first European settlers arrived in North America in the 17th century, mostly from Britain, Spain, and France.\nThe land area of South America is 6,888,000 mi2 or 15,539,928 km2. Its total population is approximately 414,332,000. Its largest city is Sao Paulo in Brazil, with 21,090,761 people.\nSouth America was colonized by Spain and Portuguese, who left an important imprint in the cultures of the continent."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:53fdf425-12d8-4253-b766-e230e53abefa>","<urn:uuid:c7c373d0-731a-45fe-a463-fc7ae1851d00>"],"error":null}
{"question":"What are the key differences between how DMAIC and PDCA handle quality management implementation?","answer":"DMAIC and PDCA handle quality management implementation differently. DMAIC provides a comprehensive set of specific tools for quality improvement at each phase, including Measurement System Analysis, Process Sigma Calculation, and Control Charts in its later stages. It requires understanding and using these tools effectively when needed. PDCA, meanwhile, serves as the foundation for Total Quality Management and Six Sigma DMAIC initiatives, focusing on statistical analysis and control. PDCA's approach to quality improvement involves planning data collection and conducting statistical analysis to verify and prioritize problems or root causes, helping to identify means to reduce deviation between existing and desired states. The key distinction is that DMAIC offers a more structured, tool-specific approach, while PDCA provides a more flexible framework that can be adapted to various quality management systems.","context":["It‚Äôs not an exaggeration to say that DMAIC is a method for solving almost any kind of business problem. This may seem like hyperbole, until you sees exactly what‚Äôs involved in this exacting methodology.\nThe name itself is, as one could guess, an acronym: D is for Define; M is for Measure; A is for Analyze; I is for Improve: and C is for Control. Thus, each letter stands for a phase you take in trying to solve a problem. Each phase, incidentally, is broken down into different steps.\nThis way of solving problems is far from academic. It has been tested long enough in the real world to be shown to be highly effective in resolving a wide range of initially bewildering business problems. However, with that being said, the dmaic process is most suitable for following types of business problems:\n- ¬∑ One that is an obvious problem, rather than one where there is some disagreement that things need to be improved.\n- ¬∑ One that is worth solving, rather than focusing on fixing things that aren‚Äôt broken. A problem is considered worthy of time and attention if the solution will potentially increase revenues, slash costs, or improve efficiency.\n- ¬∑ One where data can be collected; a quantifiable problem rather than a philosophical or qualitative problem.\nAlthough DMAIC appears linear and sequential in theory, it‚Äôs not exactly a step-by-step approach in practice. Since problem-solving is often a process of discovery and insights, iteration is usually necessary for the problem to be resolved.\nSuppose, for example, you are trying to keep your cloud services secure. When you get to the Analysis phase, you might discover that you don‚Äôt have enough information on all the biggest threats that could affect security. You then iterate back to the earlier stage, Measure, where you identify and collect the data you forgot or that you didn‚Äôt realize you needed.\nLet‚Äôs take a look at each DMAIC phase and the tools you could use for that stage:\nD or Define Phase: This is the stage where you get clear on the nature of your project and your customers. What are your project goals? Who are your internal and external customers? What are your deliverables? At the Define Phase, your choices of tools include: Project Charter, Process Flowchart, SIPOC Diagram, Stakeholder Analysis, DMAIC Work Breakdown Structure, CTQ Definitions, and Voice of the Customer Gathering.\nM or Measure Phase: Here is where you will quantify the problem. You need to measure current performance so that you can measure the process. At the Measure Phase, your choices of tools include: Process Flowchart, Data Collection Plan/Example, Benchmarking, Measurement System Analysis/Gage R&R, Voice of the Customer Gathering, and Process Sigma Calculation.\nA or Analyze Phase: You now analyze and figure out the root cause or causes of the problem or defects. At the Analyze Phase, your choices of tools include: a Histogram, Pareto Chart, Time Series/Run Chart, Scatter Plot, Regression Analysis, Cause and Effect/Fishbone Diagram, 5 Whys, Process Map Review and Analysis, Statistical Analysis, Hypothesis Testing (Continuous and Discrete), and Non-Normal Data Analysis. It‚Äôs a lot of tools, but remember, you don‚Äôt have to use them all; you will probably only need a few tools to analyze the particular problem you‚Äôre working on resolving.\nI or Improve Phase: You are now ready to see how you can improve the process by eliminating the issues that are causing the setbacks in the business issue. At the Improve Phase, your choices of tools include: Brainstorming, Mistake Proofing, Design of Experiments, Pugh Matrix, QFD/House of Quality, Failure Modes and Effects Analysis (FMEA), and Simulation Software.\nC or Control Phase: Finally, you are now at the point where you work out how to control future processes. At the Control Phase, your choices of tools include: Process Sigma Calculation, Control Charts (Variable and Attribute), Cost Savings Calculations, and Control Plan.\nAfter reviewing what goes on at each stage, you‚Äôre now in a position to appreciate the reason why the DMAIC methodology works as well as it does. Since it is so structured and rigorous, there are different degrees of Six Sigma expertise measured by belts, from white belt to black belt and then beyond to master black belt. Besides understanding all the steps to be taken at each phase, each tool has to be understood clearly enough to put to good use when needed.","The uses of plan-do-check-act cycles extend throughout common business processes to include: 1) Process Improvement, 2) Quality Management, 3) Project Control, 4) Performance Management, and 5) Organizational Competitiveness through Agility. Learn how to put this tool to work for your company.\nThe Plan-Do-Check-Act (PDCA) model is a flow diagram for learning and for improvement of a product and a process. It works on a simple concept of planning the required changes (plan), making the changes (do), checking whether the implemented changes have the desired effect (check or study), and institutionalizing the changes (act.)\nW. Edwards Deming, the pioneer of the modern-day plan-do-check-act (PDCA) cycle, advocated its use as a process improvement and quality management tool.\nThe resilience of PDCA for practice at any level or magnitude has contributed to its development as one of the the most popular and evergreen process improvement methodologies, besides extending its use to several other purposes.\nThe PDCA methodology is a continuous loop of planning, doing, checking or studying, and acting. This makes PDCA the ideal model for:\nContinuous improvement: The repeated PDCA cycle drives forward process improvement irrespective of the goals and shuts the door on complacency\nImplementation of new projects or processes: The inbuilt plan, test, and feedback mechanism of PDCA allows fixing snags and improving things at the process implementation stage, without putting entire resources or reputation at stake.\nProcess trails: The PDCA cycle entails checking the implemented changes for consistency before adopting it across the board\nUtilizing the plan-do-check-act cycle allows breakdown of a project into small manageable steps and allows gradual incremental improvements.\nPDCA not only encourages development of innovative and breakthrough changes to ensure quality and performance improvement, it also help manage change effectively.\nThe PDCA model incorporates what needs changing to the methodology of continuous improvement. The change process under PDCA entails incorporating the parameters that require change in the planning component (plan), implementation of a prototype (do), the review of the prototype for suitability and performance (check or learn) and widespread implementation or successful implementation of the prototype (act). This contributes to integrating the change management process within the normal day-to-day organizational activity, making the change process seamless.\nOne of the major uses of this process is for quality management. The continuous feedback loop of PDCA allows analysis, measurement, and identification of sources of variations from customer requirements and enables taking corrective action.\nPDCA is the popular tool for implementing Total Quality Management, and it is the basis for the Six Sigma DMAIC initiative. The implementation of such quality systems depend on the statistical analysis and control that PDCA facilitates. The application of PDCA for quality improvement helps plan data collection and undertakes statistical analysis of the data to verify and prioritize problems or root causes of issues. It identifies the means to reduce the deviation between the existing state and the desired state.\nMaintaining Control over a Project\nThe PDCA model helps project managers maintain greater control over a given project in many ways, such as:\n- Providing answers to the who, what, when, where, and why of the project. This increases knowledge that makes it easy to explore various alternatives and select a suitable method of project implementation.\n- Ensuring that the unknowns at the start of the project remains either proven or discounted.\n- Providing of accurate and timely data to improve decision-making.\n- Enabling a better understanding the cost and effect phenomenon.\nOne recent use of Plan-Do-Check-Act is in performance management of individual employees and project teams on a daily routine basis. The ‚Äúplan\" phase incorporates the targets or deliverables for the employee or team. The ‚Äúdo\" phase is the actual performance, and the ‚Äústudy\" phase reviews the performance. The ‚Äúact\" phase confirms such performance.\nIn most organizations performance management--or its older performance-appraisal version--remain a distinct \"staff\" function. The PDCA approach toward performance management integrates performance management with the day-to-day operational activity and contributes to improving productivity in a big way.\nThe application of the PDCA cycle helps the organization become agile or incorporate closed-loop management with speed.\nAgile PDCA entails identifying sources of variability and their relative negative impacts, and eliminating or reducing such variabilities wherever possible by changing supply chain design, policies, or business rules. Contingency plans are developed that handle the risks that remain.\nThe process also helps integrate the functioning of demand management, supply management, fulfillment management, rapid business reconfiguration, and IT systems in an organization.\nSuch dealing with variability and improving coordination among various processes speeds up business cycles, increasing the organization's competitiveness.\n- American Society for Quality. Plan‚ÄìDo‚ÄìCheck‚ÄìAct Cycle. http://www.asq.org/learn-about-quality/project-planning-tools/overview/pdca-cycle.html\n- Mindtools.com. Plan-Do-Check-Act (PDCA). http://www.mindtools.com/CXCtour/PDCA.php\n- International Community for Project Managers. The PDCA Cycle of Systematic Development. http://www.theicpm.com/quality-management/3413--the-pdca-cycle-of-systematic-development\n- Najmi, Adeel & Sidhu, Sanjiv. Creating Greater Agility with Plan-Do-Check-Act. http://www.i2.com/supplychainleader/issue3/html/SCL3_creating_greater_agility.cfm\nImage Credit: Wikimedia Commons, PDCA Cycle by Karn G. Bulsuk"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:e3ef5fe8-8799-4dee-ac0b-ecbcd848d566>","<urn:uuid:692496f9-e83c-4e56-8f77-b383f450c80f>"],"error":null}
{"question":"How does Japan's education system shape identity, and what economic challenges does it face due to its aging population?","answer":"Japan's education system plays a crucial role in identity formation through apprenticeship and educational processes that focus on 'becoming Japanese.' Meanwhile, Japan faces significant demographic challenges with 25% of its population currently over 65, projected to reach 40% by 2060. This aging population poses economic concerns, leading Prime Minister Abe's administration to implement 'Abenomics,' a revival program aimed at increasing women's workplace participation and supporting new medical technologies to address future healthcare costs while stimulating economic growth.","context":["Culture and Society of Japan\n- Module Code:\n- Year of study:\n- Year 1 or Year 2\n- Taught in:\n- Term 1\nThis module is designed to cover a wide variety of topics relating to Japanese society, beginning with the question of orientalism and representation in the ethnography of Japan to a consideration of family, education, religion, gender, sexuality and ethnic minorities. It concludes with recent concerns with popular culture and the so-called ‚Äúnon-human‚Äù. The module aims to provide both ethnographic detail and theoretical background on past and current debates in the description of Japanese culture(s) and to address questions such as ‚ÄúWhat are the boundaries of Japanese identity?‚Äù and ‚ÄúHow can we understand difference in Japan?‚Äù These issues are addressed in a range of contexts, including the arts, consumption, the body and controversies in the medical anthropology in Japan.\nThis module is one of several regional ethnography modules offered by the Department of Anthropology (currently China, Japan, South Asia, South East Asia, Near & Middle East, West Africa, and East Africa). Each of these focuses on major cultural and social aspects, but varies in detail according to the characteristics of and scholarship on the region. These 0.5 unit regional ethnography modules are designed (in the second year) to be combined - according to student interest and module availability - with a second regional ethnography module taught in a different term to form a compulsory full unit of ethnography modules (e.g., Japan and China; South Asia and Southeast Asia; South Asia and East Africa), or (in the third year) to be taken as a free-standing option.\nThe grasp of theory, method and problem achieved in this module builds on the foundational skills in anthropology attained in the first year, and will enable students' progression, in their following year of study, to an Advanced Ethnographic Study with a focus on Japan or connections between Japan and other regions, and/or to an Independent Study Project.\nTypical module outline:\n- Week 1. Introduction: Representation, Fantasy, Ethnography\n- Week 2. The Japanese House: Lineage, Materiality, Family\n- Week 3. Becoming Japanese: Education, Apprenticeship, Identity\n- Week 4. The Enigma of Belief: Japanese Religions and the Quotidian\n- Week 5. Masculinity and Femininity: the Salaryman Doxa, Sex, Marriage\n- (Reading Week)\n- Week 6. Japanese Diversity: Ethnic, Social, and Queer Minorities\n- Week 7. Deities, Animals, Dolls, Robots: The Non-Human in Japan\n- Week 8. Ageing and the Ethics of Care\n- Week 9. How to live, How to die: Suicide, Death and Illness\n- Week 10. Popular Culture and Otaku Tourism\n- Students enrol via the online Module Sign-Up system.\n- MA Area Studies students wishing to take this module as their ‚Äòmajor‚Äô will normally hold a degree or substantial part-degree in social anthropology or a closely related discipline. Area Studies students wishing to take this module as their ‚Äòmajor‚Äô must contact the module convenor for approval.\nObjectives and learning outcomes of the module\nOn successful completion of this module a student will be able to:\n- critically evaluate a range of theories and ethnographic source material relating to Japanese society\n- locate and use secondary sources relevant to selected topics\n- have a grasp of the key debates in the anthropology of Japan\nThis will form a base which will enable MA Anthropology students to write their dissertations (10,000 words) on a topic relating to Japan should they so wish. Skills in reading and contextualizing works on Japan are readily transferable to other regional studies.\nMethod of assessment\nThere are three marked elements: an essay outline of 500-700 words counts for 20%, an essay of 2‚Äô500 words due on the first day of term 2 counts for 70%, and 10% for class participation.\n- Robertson, Jennifer (ed.) (2005) A Companion to the Anthropology of Japan.Oxford: Blackwell.\n- Sugimoto, Yoshio (2015) An Introduction to Japanese Society (4th edition). Cambridge: Cambridge University Press.\n- Hendry, Joy (2012) Understanding Japanese Society (3rd edition). London: RoutledgeCurzon.","weekly blog--one for the ages\nWith the debate about health care boiling over in the US, we take a look at how Japan is addressing some of the issues of aging via an article in Toronto‚Äôs Globe and Mail. About 25 percent of the country‚Äôs population is currently over the age of 65 with a demographic forecast of 40 percent by the year 2060. Also, between 2010 and 2060, the percent of people over age 75 will double from 11 percent to 27 percent.\nFor businesses, Japan‚Äôs aging society is a reality as well as an opportunity. One company created a hybrid store featuring a seniors‚Äô salon with a blood pressure monitor, pamphlets on municipal health care services and nursing homes, and on-staff social workers.\nThe store also has a special section featuring adult diapers, special wipes for bathing the elderly, straw cups, a gargling basin and detergent that is tough on urine and perfect for bed mats and wheelchair coverings. Staff will also deliver heavier items, such as bags of rice or water, to local residents.\nAdditionally, to attract workers, the company raised its maximum employment age, and is experimenting with lower part-time hours and jobs with very limited tasks.\nConcerned about how Japan‚Äôs aging and shrinking work force will slow down the national economy, Prime Minister Shinzo Abe‚Äôs administration has initiated an ‚ÄúAbenomics‚Äù revival program which includes getting more women in the workplace, and supporting new medical technologies, including experimental regenerative medicine and cell therapy. The hope is that with two new acts governing regenerative medicine to help commercialize technologies more quickly, the government can save money on future health care costs while spurring the creation of a valuable new industry.\n17 years ago, Japan chose to supplement its national pension plan with comprehensive long-term-care insurance (LTCI). People pay into the system starting in their 40s and are eligible to receive benefits starting at 65, or earlier in the case of illness. When they apply, applicants are interviewed by a municipal employee who feeds the resulting information into an algorithm that assigns the person a care level.\nThe information is analyzed by an expert committee of welfare workers. A care plan is then drawn up, allowing the patient to choose between competing institutions and service providers offering everything from home visits, bathing and help getting groceries to paying for short stays in hospitals or long-term residence in nursing homes and specialized group homes for dementia patients.\nThe LTCI system covers up to $2,900 a month in services, as opposed to cash payment, and does require ‚Äúco-payments‚Äù from patients. LTCI co-payments are capped or waived for low-income individuals, and the system saves money by providing options other than full-on institutionalization.\nMeanwhile, Japanese researchers are now looking at whether robots can help as the country ages, from robot suits that help rehabilitation to fully functional humanoid robots. One company currently sells a furry robotic seal called Paro, which has been proven in various settings to reduce anxiety, stress, depression and even patients‚Äô perception of pain during chemotherapy treatments.\nWhat AARP Has To Say About the New Healthcare Bill:\n8 Countries Where $200K will Last 30 Years of Retirement:\nTrumpcare Could Bring Back Epidemic of Nursing Home Abuse:"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:3d3700af-fd1f-41f8-a5b4-de92a7ff83e9>","<urn:uuid:8b6431ad-9e19-499c-99e9-1a8fead6b03e>"],"error":null}
{"question":"How do lifecycle assessment methodologies compare between charitable initiatives and battery production, and what role does data-driven decision making play in both contexts?","answer":"In both domains, there is a strong emphasis on using objective data to measure impact. In charitable giving, effective altruists advocate for evidence-based decisions even when they don't resonate emotionally, focusing on metrics like cost per life saved ($2,500 through top-rated international charities). For batteries, lifecycle assessments use specific metrics like cradle-to-gate and cradle-to-grave analyses, measuring impacts such as CO2e/kWh of battery capacity produced. Both fields acknowledge the challenge of comprehensive impact measurement - effective altruism questions conventional wisdom about which charitable causes do the most good, while battery lifecycle assessments struggle with accurately capturing all environmental and social impacts. The importance of separating different types of impacts is emphasized in both contexts - effective altruists distinguish between emotional satisfaction and actual impact, while battery assessments separate impacts tied to energy use from other activities. Both domains also stress the need to avoid false precision, with battery assessments specifically warning against single-number metrics and emphasizing the importance of documenting underlying assumptions.","context":["Toward the end of the summer, bioethicist Peter Singer raised the hackles of art lovers everywhere with a New York Times op-ed that considered a hypothetical dilemma: should you donate to a charity that combats blindness in the developing world or should you spend that money instead on an art museum? After running through a cost-benefit analysis of each option, he determined that the charity addressing blindness ‚Äúoffers [donors] at least 10 times the value‚Äù of the museum.\nTo no one‚Äôs surprise, the arts community didn‚Äôt exactly roll out the welcome mat for the piece, calling Singer‚Äôs argument ‚Äúa shocker,‚Äù ‚Äúabsurd,‚Äù and ‚Äútyrannical.‚Äù Another round of alarm ensued recently when none other than megaphilanthropist Bill Gates threw his support behind Singer‚Äôs thesis. The responses from our field to date have generally coalesced around two broad counter-arguments:\n- Why does it have to be ‚Äúeither/or‚Äù? Why can‚Äôt we support both? Singer forces a false choice in ‚Äúassuming charitable giving is a zero sum game.‚Äù Weighing the value of saving a life against the value of donating to an art museum is comparing apples to oranges when ‚Äúboth are essential, and if either disappeared you‚Äôd be in bad shape.‚Äù We need a holistic approach to ensure we don‚Äôt ‚Äúsolv[e] Third World crises at the expense of fostering crises right here at home.‚Äù Just as we have ‚Äúmultiple passions in [our] lives,‚Äù donors can and should target multiple causes and direct their charitable dollars in a ‚Äúproportionally prioritized‚Äù manner. Anyway, we can‚Äôt really be sure than curing blindness is more important than inspiring the next Jackson Pollock, and even if we were, concentrating all our resources with one or two tried and true nonprofits runs counter to the ‚Äúmessiness and power of America‚Äôs [decentralized] approach to charity.‚Äù\n- Saving lives is all fine and good ‚Äì but only if those lives have meaning. If we‚Äôre so concerned with making sure that people can see, shouldn‚Äôt we also try to make sure they have beautiful things to look at? Singer‚Äôs logic is dangerous because he fails to acknowledge the ‚Äúcreative outlet[s] and emotional oas[e]s that only art museum[s] can provide.‚Äù If all philanthropic dollars were channeled toward alleviating disease and poverty, arts and culture would languish, society would become monochromatic and dull, and life would cease to be worth living.\nAs satisfying as these rebuttals may feel to arts advocates, they unfortunately miss the point. The crucial assumptions behind Singer‚Äôs argument are that\n- ‚Äúthere are objective reasons for thinking we may be able to do more good in one [sector] than in another,‚Äù and\n- we have a moral obligation to make choices that do as much good as possible.\nIt‚Äôs important to understand this perspective in the context of ‚Äúeffective altruism,‚Äù a relatively nascent but growing area of applied ethics that has been featured more than once on this blog, not to mention a recent edition of This American Life. Besides Gates, fellow philanthropic heavyweight and past Hewlett Foundation President Paul Brest has declared himself a fan. ‚ÄúEffective altruists,‚Äù or EAs, are on a quest to ‚Äúdo good‚Äù by way of hard-nosed rationality. ‚ÄúDoing good‚Äù doesn‚Äôt mean recycling a little more, or occasionally doling out spare change to a beggar on the street. It doesn‚Äôt mean foregoing a high-powered corporate career to work for a nonprofit. It means taking the time to analyze how to do the most amount of good possible with the resources available ‚Äì or, to use a more nerdy turn of phrase, to ‚Äú[use] science and rational decision-making to help as many sentient beings‚Äù as they can.\nMost funders are already in search of a big ‚Äúbang for your buck,‚Äù but in trying to identify the objectively best causes to support, effective altruists stray from the conventional wisdom of mainstream philanthropy. EAs cast a global net when determining where to focus, and often settle on supporting causes in faraway parts of the world, the results of which they may never see in person. They also believe that while human lives are created equal, philanthropic causes are not. Those causes that can save or improve the most lives must take first priority.\nHow does this play out in practice? Let‚Äôs say you donate to the free medical clinic in your area. You do this for good reasons: you care about inequities in the American healthcare system, and want to give back to your community. You like the feeling you get when you walk by that clinic every day. Maybe you even know people who benefit from the services the clinic provides. The clinic gets its donation, and you get warm fuzzies. Everybody wins. Right?\nNot so, an EA would counter. Despite your good intentions, your donation amounts to a near-waste of resources:\nWe understand the sentiment that ‚Äòcharity starts at home,‚Äô and we used to agree with it, until we learned just how different U.S. charity is from charity aimed at the poorest people in the world. Helping people in the U.S. usually involves tackling extremely complex, poorly understood problems‚Ä¶ In the poorest parts of the world, people suffer from very different problems‚Ä¶\nWe estimate that it costs [Givewell‚Äôs] top-rated international charity less than $2,500 to save a human life‚Ä¶ Compare that with even the best U.S. programs‚Ä¶ over $10,000 per child served, and their impact is encouraging but not overwhelming.\nEAs advocate making evidence-based decisions even if they don‚Äôt resonate on an emotional or intuitive level:\nEffective altruism is consistent with believing that giving benefits the giver, but it‚Äôs not consistent with making this the driving goal of giving. Effective altruists often take pride in their willingness to give (either time or money) based on arguments that others might find too intellectual or abstract, and their refusal to give suboptimally even when a pitch is emotionally compelling. The primary/driving goal is to help others, not to feel good about oneself.\nIf this approach leaves you with an empty feeling in the back of your throat, it is by design. ‚ÄúOpportunity costs‚Äù ‚Äì the costs of choosing not to behave in a certain way ‚Äì weigh heavily on EAs. Every time you make a donation, considering where your money could have gone is as important as considering where it will ultimately go (emphasis mine):\nIn the ‚ÄúBuy A Brushstroke‚Äù campaign, eleven thousand British donors gave a total of ¬£550,000 to keep the famous painting ‚ÄúBlue Rigi‚Äù in a UK museum. If they had given that ¬£550,000 to buy better sanitation systems in African villages instead, the latest statistics suggest it would have saved the lives of about one thousand two hundred people from disease‚Ä¶ Most of those 11,000 donors genuinely wanted to help people ‚Ä¶ But these people didn‚Äôt have the proper mental habits to realize that was the choice before them, and so a beautiful painting remains in a British museum and somewhere in the Third World a thousand people are dead.\nWeighing choices isn‚Äôt limited to how we spend our money ‚Äì it also applies to how we spend our time. Just as EAs dispute the notion that people should support whichever charities they feel ‚Äúpassionate‚Äù about, they question whether channeling those passions into a nonprofit or medical career is the best way to make a difference. Many suggest instead that people ‚Äúearn to give,‚Äù saying they ‚Äúmight be better off‚Ä¶in a high-earning job and making a deliberate commitment to give a large portion of what [they] earn away.‚Äú The organization 80,000 Hours, founded to ‚Äúbecome the world‚Äôs number one source for advice on pursuing a career that truly makes a difference in an effective way,‚Äù elaborates,\nWorking at a non-profit can be a great way to make a difference. But it‚Äôs no guarantee. Amazingly, lots of non-profits probably have no impact. And do workers at [a] non-profit have more impact than the people who fund them? The researchers who push forward progress? The entrepreneurs who transform the economy? Policy makers? Maybe. No one stops to ask.\nPutting ideas like these on the table is a great way to make those of us in the arts squirm. While there are echoes of the effective altruism movement in some recent trends within our field, like the ‚Äúuniversal call‚Äù for better data on the impact of the arts and the pointed questions about who ultimately benefits from arts funding, the arts are chock-full of people ‚Äì artists and arts administrators alike ‚Äì who were drawn to their work by that same passion that EAs claim clouds our judgment. The idea of allowing cold rationality to dictate and limit our quest to ‚Äúdo good‚Äù flies in the face of our artistic sensibilities, and challenges the assumptions many of us made when we entered the nonprofit sector in the first place ‚Äì even those of us who have a sincere desire to address social inequities.\nTempting as it may be, it would be short-sighted to dismiss the EA movement as the pet project of a bunch of aesthetically stunted curmudgeons. It‚Äôs hard to dispute the notion that we could improve the human condition if only we could get our act together and commit our resources to a data-driven approach. After all, the nonprofit darling of the moment, collective impact, is based on the same premise. What effective altruism does is counter our cause-specific argument for the arts with a dizzying moral appeal for cause agnosticism. And to be honest, it‚Äôs hard to see how the arts win if they play the game by the EAs‚Äô rules. The ‚Äúboth/and‚Äù argument mentioned previously is unlikely to sway an effective altruist who weighs each decision as a choice between two different futures, one in which a museum gets funded and some lives get saved and one in which the museum struggles and more lives get saved. Even if the museum shut down completely, its patrons could probably find or create an alternative ‚Äúcreative outlet and emotional oasis,‚Äù while the people dying of malaria can‚Äôt very well make the mosquito nets themselves. The ‚Äúwe give lives meaning‚Äù argument likewise rings hollow when we‚Äôre talking about lending privileged lives (anyone living on more than $2 a day is privileged in a global context) a dose of incremental ‚Äúmeaning‚Äù at the expense of giving others a shot at basic survival. It also comes across as incredibly condescending to those others considering that they would likely never get the opportunity to visit or benefit from Singer‚Äôs hypothetical museum. In any case, art is hardly the only possible delivery mechanism for meaning. In the words of one effective altruist,\nTrying to maximize the good I accomplish with both my hours and my dollars is an intellectually engaging challenge. It makes my life feel more meaningful and more important. It‚Äôs a way of trying to have an impact and significance beyond my daily experience. In other words, it meets the sort of non-material needs that many people have.\nWhether the EA movement sputters or gathers steam, taking the time to engage with its principles, even critically, is a healthy exercise. The bottom line is that EAs may actually be onto something when they argue it‚Äôs possible to make a bigger dent in one sector than another. Rather than insisting otherwise or dodging the argument altogether, we could heed the call to examine how altruism really manifests in our work, particularly when examined through the lens of what benefits the people we engage, rather than what benefits our organizations or our donors. Might we, too, have objective reasons for thinking we may be able to do more ‚Äúgood‚Äù in one program, or with one population, than in another? Do we, too, have a moral obligation to maximize that good? How would that change how we operate and who we serve? Do we want to change how we operate?\nIf the effective altruism debate makes anything clear, it‚Äôs that to be able to make art, not to mention argue about it, is to be fortunate. Taking a hard look at our assumptions about what draws and keeps us to this work may not be easy, but if we squirm a little, so be it. In the grand scheme of things, a little squirming is a luxury too.","Life-Cycle Assessment Considerations for Batteries and Battery Materials\nThis is a summary (plus, a few of my own thoughts) of the review article ‚ÄúLife-Cycle Assessment Considerations for Batteries and Battery Materials‚Äù (2021) by J. Porzio and C. D. Scown.\nTypes of battery life-cycle assessment\nThere are two main types of battery life-cycle assessment (LCA): ‚Äúcradle-to-gate‚Äù and ‚Äúcradle-to-grave‚Äù.\nCradle-to-gate (factory gate is assumed here). The example metric is CO2e/kWh of battery capacity produced. In a truly use-agnostic LCA, the system boundary may need to be set at the module assembly stage, since the assembly of the pack or rack (including such components as thermal management and electrical control) will differ substantially depending on how the battery will be used.\n‚ÄúCradle-to-gate and use‚Äù is a variation that incorporates battery manufacturing and lifetime of usage, but not end-of-life recycling.\nCradle-to-grave LCAs consider how batteries will be used and treated at their end of life including collection, recycling and/or disposal.\nThe term cradle-to-cradle has been used to refer to systems that include recycling, but is generally meant to suggest a zero-waste process and thus is not commonly used to refer to battery life cycles, even if they include recycling.\nMidpoint and endpoint metrics in life-cycle impact assessment\nMidpoint and endpoint impact categories (or metrics, but not all impact categories can be converted into metrics) are the concepts in the area of life-cycle assessment studies.\nMidpoint impacts are precursors to some endpoint impacts that we care about. For example, greenhouse gas emissions are a midpoint impact that leads to climate change and, ultimately, to human loss of life due to food shortage, flooding, wildfires, and other catastrophic events, as well as loss of animal life and entire animal and plant species (endpoint impacts). For another example, ozone depletion is midpoint impact and increased cancer rates (because less UV radiation from the sun is blocked) is an endpoint impact.\nSome impacts could be considered both midpoint and endpoint, e. g. loss of ecosystems is both an endpoint impact in itself, but also decreases the quality of life, prosperity, or even leads to famine among people who lived off these ecosystems.\nThe impact categories of raw material production for batteries\nThere are three aspects of raw material assessment of batteries that can‚Äôt be reduced to each other and therefore should not be integrated into a single metric: resource depletion, supply chain risk, and environmental and social impacts of mining.\nOlivetti et al. synthesized the available data on consumption rates relative to available reserves for nickel (Ni), manganese (Mn), cobalt (Co), lithium, (Li), and natural graphite. They found that the ratio of known reserves to primary mine production (also known as the static depletion index) has increased for Co, Li, and natural graphite, suggesting that continued demand has resulted in additional exploration and extraction. Mn and Ni did not show an upward or downward trend, indicating that the ratio of production to known reserves has remained relatively constant.\nInterestingly, lithium iron phosphate (LFP) batteries are often praised to be better than batteries with Nickel-based cathodes because they only require ‚Äúearth-abundant‚Äù materials. However, if we are to produce 2 TWh of LFP batteries per year by 2030, with 500 Wh/kg of cathode energy density of LFP, and Phosphorous being 19.6% of LFP cathode by mass, 784,000 metric tonnes of phosphorous will go yearly into batteries alone. This is comparable to 910,000 tonnes produced presently. Could this contribute to the problem of peak phosphorous? I didn‚Äôt find any discussion of this whatsoever. Phosphorous is abundant in the rocks all over the Earth but is not economical to extract to produce fertilisers. Maybe this is not a problem for batteries, because they can easily withstand become several times more expensive without affecting the total cost of batteries much? Even if so, there could be a market-driven risk here: LFP manufacturers will use cheaper phosphates in the short term, making the future phosphate shortage problem for fertiliser production more acute.\nSupply chain risk is a geopolitical risk associated with highly concentrated production, which can lead to conflict, price instability, and artificial shortages. Cobalt reserves and mining production are concentrated in DR Congo, but 95% of cobalt refining happens in China. China also produces 64% of the world‚Äôs graphite and 55% of aluminium. Morocco has 70% of the world‚Äôs phosphate reserves.\nEnvironmental and social impacts of mining\nIn DR Congo, there have been serious environmental and social consequences of copper and cobalt mining, ranging from child labour to human exposure to heavy metals, particularly from unregulated artisanal and small-scale mining operations.\nCell manufacturing is about two times more energy-intensive than mining and production of the raw materials for the cells\nIn other words, cell manufacturing accounts for two-thirds of energy consumption in cradle-to-gate LCA assessment for cells (source).\nEvaporating the NMP solvent (after coating cathode slurry on the current collector foil) and maintaining the facility‚Äôs dry room conditioning together consume about 80% of energy spent during cell manufacturing. However, the energy usage estimates for dry room conditioning were obtained on small-scale facilities and can drop by an order of magnitude on a very high-throughput cell production line.\nNickel-Manganese-Cobalt (NMC) cathode production can be two to three times more energy-intensive than the production of other cathode materials (LMO and LFP), and therefore also become a major contributor to the total energy spent during cell manufacturing.\nEnergy stored on energy invested (ESOI)\nEnergy stored on energy invested is a metric that has been proposed by Barnhart and Benson for ‚Äúcradle-to-gate and use‚Äù and ‚Äúcradle-to-grave‚Äù life cycle assessments of energy storage technologies:\nFor recyclable batteries, I think that a metric like cradle-to-grave energy efficiency would be more convenient because it could be directly used in downstream calculations such as assessing energy efficiency or EROI (energy return on investment) of renewable or nuclear power installations with accompanying energy storage for daily power balancing and manoeuvring, as well as in lifecycle greenhouse gas emission comparisons between internal combustion, hybrid, and fully electric vehicles for different carbon intensities of the grids in different countries.\nThere are several factors that make it difficult to estimate battery‚Äôs ESOI or cradle-to-grave efficiency:\n- The fact that different batteries are used differently (e. g., charged and discharged slower or faster, different number of hours per day, with different shelf life before they begin operation, at different ambient temperatures, etc.) directly affect the expected lifetime and the round-trip efficiency of the battery.\n- Most batteries originally manufactured for electric vehicles are expected to enter a second-life phase in energy storage with a very different usage pattern, but the exact moment when it happens is uncertain.\n- Battery‚Äôs capacity and internal resistance change during its lifetime. The internal resistance affects the round-trip efficiency directly, and the capacity can affect the usage pattern.\nAs of 2021, there are many things to improve in lifecycle assessments of batteries, both in literature and industry\nLCAs should start using country-specific raw material production impacts rather than the industry averages (or, even worse, the current industry‚Äôs state-of-the-art or best-practice impacts). They should also consider the differences between average, marginal, and incremental sources of key material inputs, in conjunction with projections of the global demands for these materials, as the global Li-ion battery production quickly rumps up. We should also create and use methods for capturing the effect of outliers and ‚Äúsuperemitters‚Äù/‚Äùsuperimpactors‚Äù in mining and material processing.\nThe assessments should correctly present the uncertainty. A single-number metric value conveys false precision. (Steve McConnell advises for exactly the same in his book about software estimations.)\nWe strongly recommend that future LCAs make an attempt to separate impacts tied to energy use with those tied to other activities. If facilities shifting their fuel use to lower-emission alternatives (e.g., from coal to natural gas, or natural gas to renewable fuels), making this distinction in published LCAs will make it easier to adjust the results accordingly.\nWater consumption and withdrawals associated with battery production can be substantial, yet it is often overlooked in LCAs. Battery electric vehicles are associated with over 50% more water use relative to internal combustion engine vehicles over the course of their lifetime. This is mostly associated with the electricity use associated with vehicle charging, but a large contribution of water consumption is attributable to the LIB itself, consisting of 5‚Äì10% of the total water consumption depending on the battery chemistry.\nAs long as underlying assumptions about cycle life are clearly documented, the authors suggest that life cycle assessments would be well served to report results normalised both per kWh of battery capacity and per kWh of lifetime throughput.\nOn including a few most important impact metrics in lifecycle assessments vs. categorising all metrics\nIf a particular assessment doesn‚Äôt cover some impact (aspect, dimension), it should still mention this explicitly. Omitting an impact category may lead readers to believe it is not important.\nOn the other hand, comprehensiveness comes at a cost. Selecting life-cycle inventory, midpoint, and/or endpoint metrics that are likely to yield the greatest insights (and have sufficiently high-quality data to support those conclusions) will make LCAs more interpretable and impactful.\nCounterfactual life-cycle assessment of batteries and electric vehicles vs. internal combustion engine vehicles and fossil fuel power generation\nExhaustive, overly-pedantic categorisation of all the impacts of battery production and use can also confuse the public towards thinking that batteries are actually very ‚Äúdirty‚Äù in production and recycling compared to the lifetime of fossil fuel combustion in ICE cars. Fossil fuel advocates could also refer to these comprehensive battery assessments to spread FUD instead of comparing them counterfactually with the effects of keeping internal combustion vehicles and gas power generation running.\nSo, I think it‚Äôs valuable to include counterfactual comparisons with fossil fuel alternatives in battery and other clean energy LCAs as a protection against such abuse.\nThis summary was originally posted on Substack."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:83bc055e-337a-457c-a230-bf02b8b50555>","<urn:uuid:696a38d0-8b90-4f1d-8afb-8f2b095542c8>"],"error":null}
{"question":"What happens when there's no AC power available in a power inverter system?","answer":"When AC mains power is not available, the inverter system operates by having an oscillator section generate a 50 Hz frequency for the MOS drive signal, converting DC battery voltage to AC. This signal is amplified by a push-pull configured driver section and sent to power amplification. MOSFETs in the power amplifier section, connected to the transformer's primary winding, switch ON/OFF at 50Hz, creating an alternating current that is stepped up to 220V AC by the inverter transformer and sent to the output socket through a changeover relay.","context":["Design and Hardware Implementation of 5kVA Power Inverter\nBackground Introduction of Power Inverter\nSolar energy and battery storage are alternate sources of electricity which leads to the purpose of this project design and construction of 5kVA Inverter with low battery cutoff, Feedback unit for output voltage control, and automatic input changeover and other protective device.\nIn my country, there is unstable supply of electricity by the power supplying company to the consumers. Hence the use of additional electric power source such as rechargeable DC battery storage with inverters are common. With advancements in power electronic switching devices, inverter based power source provides a better additional power supply. It is less noisy, provides complete automatic switchover function, possess no environmental threats. Furthermore, this system is less bulky and less expensive to maintain.\nMost recently the use of semiconductor power devices such as bipolar transistors, thyristors for voltage amplification, particularly the MOSFET as the power switches, make way to the use of Inverter based power.\nWorking Principle Of the Inverter System:\nWhen the AC mains is not available, an oscillator section generates 50 Hz frequency* for metal oxide semiconductor drive signal (MOS drive signal) and converts the DC battery voltage to AC. This MOS drive signal is amplified by the driver section which is configure in push pull and sent it to the power amplification section. The power amplifier section uses metal oxide semiconductor field effect transistor (MOSFET) as a device for its switching operation. These MOSFETs are connected to the primary winding of the inverter transformer , when these MOSFETs receive the MOS drive signal from the driver section, they starts switching ON/OFF at the speed of 50Hz. This switching of MOSFETs starts an alternating current with frequency of 50Hz at primary winding of the inverter transformer and the inverter transformer step it up to 220V AC which is being sent to the output socket through a changeover relay.\n*(note the frequency can be more than 50 Hz but with the help of the variable resistor you can adjust it)\nConstruction of Power Inverter:\n- Resistors (values indicated on the diagram)\n- Capacitors (values indicated on the diagram) c7 after the battery should be a polarized capacitor ranging from 10,000 uf and above for filtering once the inverter enters into charging mode\n- Diodes (values indicated on the diagram)\n- Inductor (values indicated on the diagram)\n- Transistors (values indicated on the diagram)\n- MOSFET (values indicated on the diagram)\n- NE555 timer\n- Relays (220 volts AC coil 60amps)\nNote: the value of all the components is on the diagram and the circuit has different sections which is also indicated on the diagram\nVR1 is used to set the output frequency of the inverter\nVR2 is used to set the output voltage\nVR3 is used to set the battery low voltage shutdown\nCircuit Diagram of Power Interver:\nTools and Instruments used in Power Inverter Construction:\nThe tools and instruments used include:\n- Lead and Soldering Iron\n- Lead sucker\n- Razor blade\n- Digital Multimeter\n- Vero and bread board\nCalculations Analysis for Power Inverter System:\nDetermination Of The Oscillating Frequency in Power inverter:\nBy supplying a 12Volt DC to the IC SG 3525 PWM, the frequency of the oscillating signal was determined using a 10KŒ© variable resistor connected in series with another 56KŒ© resistor and both connected in parallel with 0.22¬µF to form the RC time constant network.\nFrequency, F = 1/1.1*Ct*Rf where\nTime Capacitor (CT) = 0.22¬µF\nFixed Resistor (RF) = 56KŒ©\nVariable Resistor (VR) = 10KŒ©\nTime Resistor (RT) =56KŒ©+10KŒ© = 66KŒ©\nIt should be noted that the potentiometer was varied till the frequency of the signal was 50Hz.\nDetermination Of The Transistor (Mosfet) Switching Current:\nThe MOSFET used is the IRF260 in the power switching circuit due to high switching speed. By using 3.67volts supplied by the two NPN and the two PNP transistors, the switching time (T) is determined from the oscillating frequency as well as the gate switching current IG.\nT= 1/f =1/50Hz\nT = 0.02sec\nIG = Cdv/dt =5000*10¬Ø6*3.67/0.02 = 183.5\nIG = 917.5Œ∑A\nPower Switch Circuit for Construction of Power Inverter\nInverter power output (P) = 5000Watts\nOutput voltage, V = 220V\nInverter Input = battery output voltage =12V\nFrequency = 50Hz\nPower factor = 0.8\nApparent power= Real Power/P.F = 5000/0.8 = 6,250VA\nTherefore, the full load current flowing at the transformer primary;\nReal power (P) = current (I) * voltage\n5000 = I * 12\nHence, I = 5000/12 = 416.66A\nCalculation Of Transformer Parameters\nThe power Rating for the Inverter transformer (KVA) =5.0KA , E2=12V Assuming the efficiency of transformer =85% Then Input rating =output /Efficiency=5000VA/0.85= 5,882.35VA Ip = P/VP = 220V Ip = 5,882.35/ 220 = 26.7A Ip = Po / Vs ; Vs = 12V Ip = 5000 / 12 = 416.66A\nNumber of turns per volt for both primary and secondary winding is given by;\nNT per V= 7/A\nWhere A is the area of transformer former in sq. inch\nFormer area A is 2.3inch by 1.5inch = 7.45sq.inch\nNT per V= 7/3.45=2\nNT per V= 2 (approximate value).\n(Read Complete series of articles on transformer design and hardware implementation here.)\nCharger tapping winding turns\nNp1= NT per V * E1=220V\nNp1 = 2 * 220 = 440turns\nInverter (out) tapping winding turns\nNS2= NT per V * E3=260V\nNS2 = 2 * 260= 520turns\nDifference of Inverting and Charging turns = 520 ‚Äì 440 = 80turns.\nFor the primary windings, charging tapping is brought out after 440 turns and an addition 80 turns is\nmade for the inverter out tapping.\nSecondary turns Ns= NT per V * E2 = 12V\nNs= 2 *12= 24turns. (Bifilar winding)\nSWG Size and Gauge Estimation\n(Learn about Wire Gauge Standards and selection )\nStandard Wire Gauge Weight, SGW, can be estimated as follow;\nConsidering conduction current density J (with fixed value of 2.5A/mm2) and windings coil current.\nFor Ip = 26.7A, the corresponding gauge from tables is 16SWG and\nFor Is = 416A, the corresponding gauge from tables is 8 SWG.\nPrecautions for Longer Life of Power Inverter:\nThe following maintenance practices and safety precautions are suggested to improve the life span of the system and prevent hazards to the users.\n- Dead batteries should not be used with the inverter\n- The battery terminals should not be removed too often. When it is removed, placement of correct polarity must be ensured.\n- The inverter must be kept in a moderate temperature environment.\n- The inverter should be shut down when not in use.\n- The inverter should always be partially loaded (not more than 75% of its maximum capacity)."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:633a4a9d-350d-4f3f-86e3-8d62a15ea7c4>"],"error":null}
{"question":"What are the key quality issues to consider when evaluating a randomized controlled trial (RCT)?","answer":"When assessing an RCT, key quality issues include: whether the setting and study population were clearly described, if assignment was genuinely random with documented similarity between groups, if allocation was adequately concealed, the level of blinding, whether all clinically relevant outcomes were reported, if over 80% of participants were accounted for at conclusion, if intention-to-treat analysis was used, and if both statistical significance and clinical importance were considered.","context":["Appraisal of references typically has a number of stages. For example, ‚Äòfirst appraisal‚Äô based on abstracts: cutting down on 'noise' to hone in on the relevant condition (e.g. chronic asthma; migraines; etc.) and high-quality studies of the correct methodology (e.g. systematic reviews; RCTs; diagnostic studies, etc.)\nOnce a systematic search has been run, the titles/abstracts of retrieved papers need to be assessed using the criteria stated for that particular review/question (often this will be done by the person undertaking the search). If an abstract indicates that the study definitely does not match the criteria, you would exclude it. If the first appraiser is unable to definitively exclude a study using the information in the title/abstract, they would include the reference in the selected set of references which are earmarked for further consideration.\n‚ÄòSecond appraisal‚Äô based on full papers\nReferences for further consideration, are passed on for additional full-text evaluation in order to decide which papers will be used and cited in the final content (often this will be done by the main author). If they are undertaking a systematic review/overview, they will also justify the exclusion of any references they wish to make. They retain these inclusion/exclusion forms for use in their review so that an excluded study list can be generated and their decisions about exclusions recorded.\n‚ÄòThird appraisal‚Äô (QA check) based on full papers\nCompleted systematic research reports are usually subjected to a further review of the selected material, validating the quality and relevance of the included studies as appropriate. This may be done independently by a co-author, or an editor/final assessor before the report is finalized.\nUsually, authors of systematic reviews will have at least two individuals who independently assess references at both abstract and full paper stages, discussing any differences in opinion and resolving them (using an additional assessor to act as final arbitrator if necessary), to come to a consensus on which studies should be included and excluded. If you wish to follow an evidence-based style approach for study selection, it is generally recommended that you should involve more than one person in the appraisal and choice of references to include.\nAppraising the quality of study methods\nIt should be noted that no study is perfect. For practical purposes, it might be helpful to consider three possible scenarios with regard to study methods:\n- If the methods were sound ‚Äì we would include\n- If the methods were suboptimal ‚Äì we would include but would cite reservations and appropriate caveats with regard to interpreting the result\n- If the methods were unsound, that is, there was a fatal flaw or a reasonable possibility of biased results ‚Äì we would exclude.\nStudies are assessed whether they have minimum quality criteria (that is, in terms of the minimum acceptable size, follow-up, level of blinding [if blinding is possible], length of follow-up, etc). However, minimum quality criteria are just that, minimum criteria. For example, it may be that a trial describes itself as randomized but on further reading, it becomes apparent that treatments were allocated by the day of admission or by alternate allocation. We would then describe this trial as quasi-randomized and may exclude it on this basis.\nSimilarly, with regard to systematic reviews, quality may vary widely between reviews with regard to the methods employed and the extent to which data are reported. Indeed, on occasion, it may be difficult to decide whether a review is systematic or not if the search methods used are poorly reported. It is impossible to be comprehensive with regard to all the possible methodological issues that might arise or with regard to what their relative importance might be. For example, one element that is markedly weak may throw doubt on the entire conclusions of the study (a 'fatal flaw').\nQuality issues that you may consider when assessing a systematic review might include:\n- Are the questions and methods of the review clearly stated?\n- Are the search methods described, and are they comprehensive and reproducible?\n- Are explicit methods used to determine which studies are included in the review?\n- Was the methodological quality of primary studies assessed?\n- Was the selection and assessment of primary studies appropriate, reproducible, and free from possible bias?\n- Are differences in individual study results adequately explained?\n- Are the results of primary studies combined appropriately?\n- Are the reviewers' conclusions supported by data cited?\nQuality issues that you may consider when assessing an RCT might include:\n- Were the setting and study population clearly described?\n- Was assignment genuinely random and similarity between groups documented?\n- Was allocation to study groups adequately concealed from participants and investigators?\n- What was the level of blinding?\n- Were all clinically relevant outcomes reported?\n- Where over 80% of people who entered the study accounted for at its conclusion?\n- Did the RCT analyze in groups to which people were randomized to (intention-to-treat analysis)?\n- Were both the statistical significance and the clinical importance of the statistical result considered?\nConsidering evidence on harm\nOf all study types, well-conducted RCTs or systematic reviews of RCTs provide the best evidence of causality, that is, that one treatment causes an effect compared with another treatment. Usually, you would also report any data on adverse effects reported by included RCTs or systematic reviews of RCTs. However, RCTs are often underpowered to detect adverse effects, some of which may be serious but rare. Because of this, you may also need to include, on occasion, non-RCT data that gives information on adverse effects to enhance the practical and clinical relevance of your findings.\nIt should be noted that observational data may be more subject to confounding or bias. Bias due to non-comparability of groups is more likely in cohort studies, and more likely still in case-control studies. Case series or case reports are the weakest forms of evidence, although associations with harms in case reports have often been subsequently confirmed, and have sometimes provided the first indication that a given treatment is associated with a particular adverse effect."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:82d1aeeb-3917-453d-a2b3-8e779429af58>"],"error":null}
{"question":"How do the melting ice caps affect global weather patterns and ocean circulation differently from what was portrayed in 'The Day After Tomorrow' movie?","answer":"The melting of ice caps affects global weather patterns through several mechanisms. When Arctic sea ice melts, heat from the sun is absorbed by the oceans instead of being reflected into space, leading to warming oceans and jet stream changes. Additionally, the melting creates a 'positive feedback loop' that changes atmospheric and ocean circulation. When glaciers melt, the freshwater stays on top of saltier ocean water, affecting thermohaline circulation - the process that moves warm water from the equator to the arctic. While the movie 'The Day After Tomorrow' suggested rapid changes leading to a new ice age, scientists indicate this is unlikely since oceans don't move heat and cold as quickly as the atmosphere does.","context":["When most people think of ice melting at the North and South poles, they automatically think of sea levels rising. But the melting of the ice sheets ‚Äì and lower ice extents during the winter months ‚Äì means much more than just additional water in the oceans, as the lack of ice at the poles also changes the ocean‚Äôs water currents, the jet streams and how weather forms across the planet. How fast polar ice disappears depends upon the world‚Äôs effectiveness at reducing pollution. Without effective programs in place to regulate, reduce and eliminate greenhouse gases ‚Äì carbon dioxide, water vapor, methane, nitrous oxide and ozone ‚Äì oceans across the globe may change more than just sea level.\nConsequences of Ice Caps Melting\nMost people may not know that icebergs in Arctic waters have little to do with rising seas because the ice floats in the water, already displacing it with its size. As the ice melts, the arctic sea levels, and thus the other oceans, stay the same, but the weather changes.\nThe real threat in sea level increases come from the Greenland and the Antarctic ice sheets, which contain close to 99 percent of all the world‚Äôs fresh water. When the Antarctic melts, climate experts state that sea levels can rise to 200 feet and more. Greenland‚Äôs melting ice sheet will add another 20 feet to sea level rise. So all together, the melting of polar ice caps effects would include sea levels rising 220 feet or more worldwide.\nAccording to National Geographic's projections of a 216-feet increase in sea level, the entire Eastern seaboard, the Gulf Coast and Florida would disappear. The hills of San Francisco would become a series of islands, with an inland sea forming in California‚Äôs Central Valley. Los Angeles and San Diego would be underwater, along with Seattle, parts of Portland, Oregon and British Columbia in Canada.\nA recent report by the National Oceanic and Atmospheric Administration predicts that by the time a person born in 2017 reaches 33, sea levels could rise as much as 2 to 4 1/2 feet, doubling by 2100. After 2050, how fast sea levels rise depend on multiple factors. With a climate that continues heating up ‚Äì and coastal erosion ‚Äì these numbers could radically increase. This not only affects coastal communities around the world, covering London and other low-lying areas, but it damages global economies as well, requiring citizen evacuations and relocation of major shipping ports and businesses.\nPolar Ice, Weather and Global Economies\nThe National Snow and Ice Data Center says that the Greenland and Antarctic ice sheets influence both day-to-day weather and long-term climate. The high-altitude tops of the ice caps change storm tracks and create cold downward winds that travel along the ice surface.\nArctic sea ice helps to regulate the climate by keeping it cool. As this sea ice melts, heat from the sun is absorbed by the oceans ‚Äì instead of being reflected into space ‚Äì contributing to warming oceans, water expansion and jet stream changes. Even small temperature changes in the Arctic can drastically effect weather all over the world.\nMore Polar Ice Caps Facts\nAs more heat is absorbed by the oceans, it creates a ‚Äúpositive feedback loop‚Äù that essentially changes the atmosphere‚Äôs and ocean‚Äôs circulation. The salt content of ocean water, including arctic waters, changes when polar ice melts, because it doesn‚Äôt contain any salt. When glaciers melt in the ocean, the freshwater tends to stay on top because salt water is heavier.\nThis affects ocean currents that normally move the warm water at the equator back to the arctic in a heat-and-salt-water process called t__hermohaline circulation. The completion of the cycle occurs when the colder water at depth begins to move south and then rises again at the equator as it warms. One well-known current that would be affected by this is the Gulf Stream. Changes in the Gulf Stream affects North America and Europe, and could lead to cooler weather over time and radical changes in some weather patterns in just weeks. While the Dennis Quaid movie, ‚ÄúThe Day After Tomorrow‚Äù referenced this scenario, scientists feel it unlikely that rapid changes that result in a new ice age are unlikely, as the oceans don‚Äôt move heat and cold as quickly as the atmosphere does.\nChanges to Wildlife and Indigenous Peoples\nImages of emaciated polar bears floating on small ice blocks in the arctic sea represent some of the more radical effects polar ice melt has on wildlife. But polar bears aren‚Äôt the only ones affected. Inuits in the Northern Hemisphere are experiencing reduced hunting seasons because of increased early spring ice melts. Because they mostly live in the coastal regions near the arctic, they depend on sea ice as a means for transportation and hunting. As the ice melts, their means to support themselves decrease. Tribal leaders also point to the last few decades where increased ice melt and global weather changes no longer allow them to accurately predict weather by using clouds, winds and ocean currents.\nConsequences of Melting Permafrost\nIn areas where the ground has stayed frozen for centuries, as in Alaska and Siberia, melting permafrost is also suspected as the cause of new outbreaks of diseases. Anthrax erupted in a small corner of Siberia in August 2016, caused by melting permafrost scientists and doctors theorize. More than 2,000 reindeer became infected and dozens of people hospitalized after a 75-year old reindeer corpse melted and released the spores across the Yamal Peninsula.\nAnthrax is not the only virus frozen beneath the permafrost. Scientists posit that the bubonic plague and smallpox are also buried in Siberia‚Äôs frozen ground. Lands within the arctic circle‚Äôs also trapped methane and other gases when the ground froze. As it thaws, these greenhouse gases get released back into the atmosphere, and add to the global warming cycle. The only way to stop this vicious cycle is for all governments around the world to adhere to regulations that reduce and finally eliminate the release of greenhouse gases into the atmosphere. If humans don‚Äôt stop adding to global warming, in a mere hundred years, the world as it is now known won‚Äôt be the same at all.\n- NSIDC: Quick Facts on Ice Sheets\n- NOAA: Global and Regional Sea Level Rise Scenarios for the United States\n- NSIDC: Quick Facts on Arctic Sea Ice\n- NSIDC: Environment: Climate\n- NSIDC: Indigenous People: Introduction\n- National Public Radio: Anthrax Outbreak in Russia Thought to be Result of Thawing Permafrost\n- Yale Environment: The Global Impacts of Rapidly Disappearing Artic Sea Ice\n- Columbia University: How the Warming Artic Affects Us All\n- National Geographic: What the World Would Look Like if All the Ice Melted"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:53490353-048e-416e-910d-46e7fcc412fd>"],"error":null}
{"question":"How are MEMS cantilevers used in modern medical diagnostics?","answer":"MEMS cantilevers are being developed as biosensors for medical diagnostic applications. They can function as chemical sensors when coated with a recognition receptor layer, such as antibodies that interact with specific immunogens. These sensors can operate in either static mode (measuring beam bending) or dynamic mode (measuring changes in vibration frequency) to detect the presence and concentration of analytes.","context":["A cantilever is a rigid structural element that extends horizontally and is supported at only one end. Typically it extends from a flat vertical surface such as a wall, to which it must be firmly attached. Like other structural elements, a cantilever can be formed as a beam, plate, truss, or slab.\nCantilever construction allows overhanging structures without additional support.\nIn bridges, towers, and buildingsEdit\nCantilevers are widely found in construction, notably in cantilever bridges and balconies (see corbel). In cantilever bridges, the cantilevers are usually built as pairs, with each cantilever used to support one end of a central section. The Forth Bridge in Scotland is an example of a cantilever truss bridge. A cantilever in a traditionally timber framed building is called a jetty or forebay. In the southern United States, a historic barn type is the cantilever barn of log construction.\nTemporary cantilevers are often used in construction. The partially constructed structure creates a cantilever, but the completed structure does not act as a cantilever. This is very helpful when temporary supports, or falsework, cannot be used to support the structure while it is being built (e.g., over a busy roadway or river, or in a deep valley). Therefore, some truss arch bridges (see Navajo Bridge) are built from each side as cantilevers until the spans reach each other and are then jacked apart to stress them in compression before finally joining. Nearly all cable-stayed bridges are built using cantilevers as this is one of their chief advantages. Many box girder bridges are built segmentally, or in short pieces. This type of construction lends itself well to balanced cantilever construction where the bridge is built in both directions from a single support.\nThese structures rely heavily on torque and rotational equilibrium for their stability.\nIn an architectural application, Frank Lloyd Wright's Fallingwater used cantilevers to project large balconies. The East Stand at Elland Road Stadium in Leeds was, when completed, the largest cantilever stand in the world holding 17,000 spectators. The roof built over the stands at Old Trafford uses a cantilever so that no supports will block views of the field. The old (now demolished) Miami Stadium had a similar roof over the spectator area. The largest cantilevered roof in Europe is located at St James' Park in Newcastle-Upon-Tyne, the home stadium of Newcastle United F.C.\nThe Forth Bridge, a cantilever truss bridge.\nA cantilevered railroad deck and fence on the Canton Viaduct\nA cantilever barn in rural Tennessee\nCantilever barn at Cades Cove\nCantilever occurring in the game \"Jenga\"\nBusan Cinema Center in Busan, South Korea, with the world's longest cantilever roof.\nThis radiograph of a \"bridge\" dental restoration features a cantilevered crown to the left\nRonan Point: Structural failure of part of floors cantilevered from a central shaft.\nThis section does not cite any sources. (April 2018) (Learn how and when to remove this template message)\nThe cantilever is commonly used in the wings of fixed-wing aircraft. Early aircraft had light structures which were braced with wires and struts. However, these introduced aerodynamic drag which limited performance. While it is heavier, the cantilever avoids this issue and allows the plane to fly faster.\nHugo Junkers pioneered the cantilever wing in 1915. Only a dozen years after the Wright Brothers' initial flights, Junkers endeavored to eliminate virtually all major external bracing members in order to decrease airframe drag in flight. The result of this endeavor was the Junkers J 1 pioneering all-metal monoplane of late 1915, designed from the start with all-metal cantilever wing panels. About a year after the initial success of the Junkers J 1, Reinhold Platz of Fokker also achieved success with a cantilever-winged sesquiplane built instead with wooden materials, the Fokker V.1.\nIn the cantilever wing one or more strong beams, called spars, run along the span of the wing. The end fixed rigidly to the central fuselage is known as the root and the far end as the tip. In flight, the wings generate vertical lift and the spars carry this load through to the fuselage.\nTo resist horizontal shear stresses from either drag or engine thrust, the wing must also form a stiff cantilever in the horizontal plane. A single-spar design will usually be fitted with a second smaller drag-spar nearer the trailing edge, braced to the main spar via additional internal members or a stressed skin. The wing must also resist twisting forces, achieved by cross-bracing or otherwise stiffening the main structure.\nCantilever wings require much stronger and heavier spars than would otherwise be needed in a wire-braced design. However, as the speed of the aircraft increases, the drag of the bracing increases sharply, while the wing structure must be strengthened, typically by increasing the strength of the spars and the thickness of the skinning. At speeds of around 200 miles per hour (320 km/h) the drag of the bracing becomes excessive and the wing strong enough to be made a cantilever without excess weight penalty. Increases in engine power through the late 1920s and early 1930s raised speeds through this zone and by the late 1930s cantilever wings had almost wholly superseded braced ones. Other changes such as enclosed cockpits, retractable undercarriage, landing flaps and stressed-skin construction furthered the design revolution, with the pivotal moment widely acknowledged to be the MacRobertson England-Australia air race of 1934, which was won by a de Havilland DH.88 Comet.\nPresently, cantilever wings are almost universal with bracing only being used for some slower aircraft where a lighter weight is prioritized over speed, such as in the ultralight class.\nIn microelectromechanical systemsEdit\nCantilevered beams are the most ubiquitous structures in the field of microelectromechanical systems (MEMS). An early example of a MEMS cantilever is the Resonistor, an electromechanical monolithic resonator. MEMS cantilevers are commonly fabricated from silicon (Si), silicon nitride (Si3N4), or polymers. The fabrication process typically involves undercutting the cantilever structure to release it, often with an anisotropic wet or dry etching technique. Without cantilever transducers, atomic force microscopy would not be possible. A large number of research groups are attempting to develop cantilever arrays as biosensors for medical diagnostic applications. MEMS cantilevers are also finding application as radio frequency filters and resonators. The MEMS cantilevers are commonly made as unimorphs or bimorphs.\nTwo equations are key to understanding the behavior of MEMS cantilevers. The first is Stoney's formula, which relates cantilever end deflection Œ¥ to applied stress œÉ:\nwhere is Poisson's ratio, is Young's modulus, is the beam length and is the cantilever thickness. Very sensitive optical and capacitive methods have been developed to measure changes in the static deflection of cantilever beams used in dc-coupled sensors.\nThe second is the formula relating the cantilever spring constant to the cantilever dimensions and material constants:\nwhere is force and is the cantilever width. The spring constant is related to the cantilever resonance frequency by the usual harmonic oscillator formula . A change in the force applied to a cantilever can shift the resonance frequency. The frequency shift can be measured with exquisite accuracy using heterodyne techniques and is the basis of ac-coupled cantilever sensors.\nThe principal advantage of MEMS cantilevers is their cheapness and ease of fabrication in large arrays. The challenge for their practical application lies in the square and cubic dependences of cantilever performance specifications on dimensions. These superlinear dependences mean that cantilevers are quite sensitive to variation in process parameters, particularly the thickness as this is generally difficult to accurately measure. However, it has been shown that microcantilever thicknesses can be precisely measured and that this variation can be quantified. Controlling residual stress can also be difficult.\nChemical sensor applicationsEdit\nA chemical sensor can be obtained by coating a recognition receptor layer over the upper side of a microcantilever beam. A typical application is the immunosensor based on an antibody layer that interacts selectively with a particular immunogen and reports about its content in a specimen. In the static mode of operation, the sensor response is represented by the beam bending with respect to a reference microcantilever. Alternatively, microcantilever sensors can be operated in the dynamic mode. In this case, the beam vibrates at its resonance frequency and a variation in this parameter indicates the concentration of the analyte. Recently, microcantilevers have been fabricated that are porous, allowing for a much larger surface area for analyte to bind to, increasing sensitivity by raising the ratio of the analyte mass to the device mass. Surface stress on microcantilever, due to receptor-target binding, which produces cantilever deflection can be analyzed using optical methods like laser interferometry. Zhao et al., also showed that by changing the attachment protocol of the receptor on the microcantilever surface, the sensitivity can be further improved when the surface stress generated on the microcantilever is taken as the sensor signal.\nIn storage applicationsEdit\nA cantilever rack is a type of warehouse storage system consisting of the vertical column, the base, the arms, and the horizontal and/or cross-bracing. These components are fabricated from both roll formed and structural steel. The horizontal and/or cross bracing are used to connect two or more columns together. They are commonly found in lumber yards, woodworking shops, and plumbing supply warehouses.\nA folding cantilever tray is a type of stacked shelf that can be unfolded to allow convenient access to items on multiple tiers simultaneously. The shelves can be collapsed when not in use for more compact storage. Due to these properties, folding cantilever trays are often used in baggage and toolboxes.\n|Wikimedia Commons has media related to Cantilevers.|\n- Hool, George A.; Johnson, Nathan Clarke (1920). \"Elements of Structural Theory - Definitions\". Handbook of Building Construction (Google Books). vol. 1 (1st ed.). New York: McGraw-Hill. p. 2. Retrieved 2008-10-01.\nA cantilever beam is a beam having one end rigidly fixed and the other end free.\n- \"GMI Construction wins ¬£5.5M Design and Build Contract for Leeds United Football Club's Elland Road East Stand\". Construction News. 6 February 1992. Retrieved 24 September 2012.\n- IStructE The Structural Engineer Volume 77/No 21, 2 November 1999. James's Park a redevelopment challenge\n- The Architects' Journal Existing stadiums: St James' Park, Newcastle. 1 July 2005\n- Stevens, James Hay; The Shape of the Aeroplane, Hutchinson, 1953. pp.78 ff.\n- Davy, M.J.B.; Aeronautics ‚Äì Heavier-Than-Air Aircraft, Part I, Historical Survey, Revised edition, Science Museum/HMSO, December 1949. p.57.\n- ELECTROMECHANICAL MONOLITHIC RESONATOR, US Pat.3417249 - Filed April 29, 1966\n- R.J. Wilfinger, P. H. Bardell and D. S. Chhabra: The resonistor a frequency selective device utilizing the mechanical resonance of a silicon substrate, IBM J. 12, 113‚Äì118 (1968)\n- P. M. Kosaka, J. Tamayo, J. J. Ruiz, S. Puertas, E. Polo, V. Grazu, J. M. de la Fuente and M. Calleja: Tackling reproducibility in microcantilever biosensors: a statistical approach for sensitive and specific end-point detection of immunoreactions, Analyst 138, 863‚Äì872 (2013)\n- A. R. Salmon, M. J. Capener, J. J. Baumberg and S. R. Elliott: Rapid microcantilever-thickness determination by optical interferometry, Measurement Science and Technology 25, 015202 (2014)\n- P. C. Fletcher, Y. Xu, P. Gopinath, J. Williams, B. W. Alphenaar, R. D. Bradshaw, R. S. Keynton, \"Piezoresistive Geometry for Maximizing Microcantilever Array Sensitivity,\" presented at the IEEE Sensors, Lecce, Italy, 2008.\n- B«énic«é, Florinel-Gabriel (2012). Chemical Sensors and Biosensors:Fundamentals and Applications. Chichester, UK: John Wiley & Sons. p. 576. ISBN 9781118354230.\n- Noyce, Steven G.; Vanfleet, Richard R.; Craighead, Harold G.; Davis, Robert C. (1999-02-22). \"High surface-area carbon microcantilevers\". Nanoscale Advances. 1 (3): 1148‚Äì1154. doi:10.1039/C8NA00101D. Retrieved 2019-05-29.\n- Yue Zhao,Agnivo Gosai, Pranav Shrotriya : Effect of Receptor Attachment on Sensitivity of Label Free Microcantilever Based Biosensor Using Malachite Green Aptamer https://doi.org/10.1016/j.snb.2019.126963\n- Inglis, Simon: Football Grounds of Britain. CollinsWillow, 1996. page 206.\n- Madou, Marc J (2002). Fundamentals of Microfabrication. Taylor & Francis. ISBN 0-8493-0826-7.\n- Roth, Leland M (1993). Understanding Architecture: Its Elements History and Meaning. Oxford, UK: Westview Press. pp. 23‚Äì4. ISBN 0-06-430158-3.\n- Sarid, Dror (1994). Scanning Force Microscopy. Oxford University Press. ISBN 0-19-509204-X."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:126e3f62-ac08-4efc-925a-2591d1b39f45>"],"error":null}
{"question":"What are the three new minerals discovered from Moon rocks? üåô","answer":"The three new minerals discovered from Moon rocks were: tranquillityite (named after Mare Tranquillitatis), armalcolite (named for astronauts Armstrong, Aldrin and Collins), and pyroxferroite (an iron-based mineral of the proxene class).","context":["Let's continue with toponyms, specializing with those from heavenly places.\ncockaigne ‚Äì in peasant legand of middle ages: an imaginary country of abundent food and of idle luxury. fig: a place of overflowing abundance. [apparently from older words for cook and cake]\n[The figurative sense is rare and not in the dictionaries, but see our quote.]\nCockaigne is the utopia of the poor and the hungry, \"the medieval peasant's dream ‚Ä¶ where cooked birds fly into one's mouth and the streams flow with wine\", ... \"where the streets are said to be pav‚Äôd with half-peck Loaves, the Houses til‚Äôd with Pancakes, and where the Fowls fly about ready roasted, crying, Come eat me!\" (Edward James, Cambridge Companion to Science Fiction; Benjamin Franklin, Information to Those Who Would Remove to America).\nIt's believed that the song Big Rock Candy Mountain traces to this legend, and to an old song about the similar place called Lubberland.\n‚Äì Rosemary Edghill, Bell, Book, and Murder\nElysium ‚Äì a paradise; a place or condition of ideal happiness (adj. elysian)\n[Also Elysian Fields, which in Greek mythology was the abode of the blessed after death]\n- Andrew Stephen, New Statesman, Nov. 17, 2003\n1. often Paradise The Garden of Eden.\na. The abode of righteous souls after death; heaven.\nb. An intermediate resting place for righteous souls awaiting the Resurrection.\n3. A place of ideal beauty or loveliness.\n4. A state of delight.\n[Middle English paradis, from Old French, from Late Latin paradƒ´sus, from Greek paradeisos, garden, enclosed park, paradise, from Avestan pairidaƒìza-, enclosure, park : pairi-, around + daƒìz≈ç, wall.]\nWORD HISTORY The history of paradise is an extreme example of amelioration, the process by which a word comes to refer to something better than what it used to refer to. The old Iranian language Avestan had a noun pairidaƒìza-, ‚Äúa wall enclosing a garden or orchard,‚Äù which is composed of pairi‚Äì, ‚Äúaround,‚Äù and daƒìza‚Äì ‚Äúwall.‚Äù The adverb and preposition pairi is related to the equivalent Greek form peri, as in perimeter. Daƒìza‚Äì comes from the Indo-European root *dheigh‚Äì, ‚Äúto mold, form, shape.‚Äù Zoroastrian religion encouraged maintaining arbors, orchards, and gardens, and even the kings of austere Sparta were edified by seeing the Great King of Persia planting and maintaining his own trees in his own garden. Xenophon, a Greek mercenary soldier who spent some time in the Persian army and later wrote histories, recorded the pairidaƒìza- surrounding the orchard as paradeisos, using it not to refer to the wall itself but to the huge parks that Persian nobles loved to build and hunt in. This Greek word was used in the Septuagint translation of Genesis to refer to the Garden of Eden, whence Old English eventually borrowed it around 1200.\ntempean ‚Äì (of a place) of great and delightful natural beauty\n[After Tempe, a charming valley in Thessaly, in Greece]\nOED's only cite is \"1864 in WEBSTER; hence in mod. Dicts.\" That is, OED shows no usage of the word outside of dictionaries. (It does give cites for Tempe as \"a beautiful valley [or] any delightful rural spot\".) But here is one, predating Webster by a couple of decades.\nUnveileth its Tempean grace anew\nTo meet the sun ‚Ä¶\n‚Äì Charles Harpur (1813-1868), Regret (1842)(some editions say Temp√®an)\nEden ‚Äì a paradise of innocence and unspoiled, idyllic peace (adj. edenic)\nShakespeare gives a stunning usage-example: \"this scepter'd isle, this earth of majesty, / This other Eden, demi-paradise, / This precious stone set in the silver sea, / This blessed plot, this earth, this realm, this England.\" Here are a couple more, though pale by comparison.\n[All quotes modified for brevity and further, where deletions require, for clarity.]\n‚Äì Charlotte Higgins, Guardian Unlimited, Nov 16, 2005\n[Ogden Nash, on a couple who graduated from an apartment flat to home-ownership:]\nThe Murrays are vague about fuses, / And mechanical matters like that,\nAnd each of them frequently muses / On the days when they lived in a flat.\nWas the plumbing reluctant to plumb? / Was the climate suggestive of Canada?\nDid the radio crackle and hum? / You simply called down to the janada!\nThe Murrays have found no replacement\nFor the genius who lived in the basement.\nThey longed for a hearth and a doorway,\nIn Arden, or maybe in Eden,\nBut the Eden is rather like Norway,\nAnd the Arden like winter in Sweden.\nOh, I don't regret / Being wed to you,\nBut I wish I could wed / A janitor too.\nYou'll probably never have a chance to use today's toponym, but the name is out of this world. Literally. Insofar as I know, it is the only toponym named for a real (non-fictional) place which is not on earth.\ntranquillityite ‚Äì a certain mineral, a silicate of ferrous iron, titanium, zirconium, and yttrium. Named for Mare Tranquillitatis, the Sea of Tranquillity, on the moon.\nThe first astronauts on the moon landed in the Sea of Tranquillity, and they collected rock samples to bring back to earth. Analysis revealed that the rocks contained, in addition to familiar matter, three minerals not known on earth. One of these was named armalcolite, for astronauts Armstrong, Aldrin and Collins.\nAnother was named for the Sea of Tranquillity. It was at first called tranquilite but soon became known as tranquillityite. It may prove important to lunar colonization, for \"Of all lunar minerals, tranquillityite is perhaps the most important carrier of the naturally radiogenic elements, uranium and thorium.\" (P. H. Cadogan, Moon; credit OED)\nBonus Word: The third new mineral, an iron-based mineral of the proxene class, was named pyroxferroite. The name proxene, coined in 1796, means fire-stranger (pyro- œÄœÖœÅŒø- fire + xenos ŒæŒ≠ŒΩŒøœÇ stranger), as these rocks were thought to be formed without volcanic processes, without fire. The name seems especially apt for the lunar pyroxferroite, which is a stranger to earth.\nP.S. Aput, please advise if my Greek is incorrect!This message has been edited. Last edited by: wordcrafter,\nShangri-La ‚Äì 1. an imagined paradise on earth 2. a distant hideaway, secluded, peaceful and beautiful\n[From the utopia in the novel Lost Horizon be James Hilton (1933), and its 1937 movie. La is Tibetan for 'mountain pass', and the movie was set in Tibet. There is a long history of legends of a paradise in the far east, going back to Marco Polo and the tales of Prester John.]\nIt is early 1942, shortly after Pearl Harbor, and Japan is rolling through the Pacific. The US launches the Doolittle bombing raid on Tokyo.\n‚Äì Doris Kearns Goodwin, No Ordinary Time: Franklin and Eleanor Roosevelt: The Home Front in World War II\nAnd when Roosevelt similarly announced that two battleships had gone \"to Shangri-La\", Berlin radio confessed that reported that the German authorities had been unable to find that place on the map. (So says one source; I've not been able to confirm.)\nTwo more-typical examples:\n‚Äì Loren Pope, Colleges That Change Lives‚Ä¶ [etc.]\nBest seen in late spring when the rhododendrons are in full bloom, the lush greenery of Craggy Gardens feels like an Appalachian Shangri-la.\n‚Äì Jamie Jensen, Road Trip USA: Cross-Country Adventures ‚Ä¶[etc.]\nWell, a number of chemical element names count here. There was a group of three (or perhaps more): uranium named for Uranus, the planet discovered by Herschel in 1781 and the element by Klaproth in 1789; cerium for Ceres, the planet discovered in 1801 and the element in 1803; and palladium for Pallas, planet discovered in 1802 and element in 1803. There was also a vestium, which later proved to be illusory or some other substance. And of course with the rush of small planets discovered after Ceres, Pallas, and Vesta, these were soon downgraded to the name of 'asteroids'. More recent names from planets are neptunium and plutonium.\nHelium was named from its 1868 discovery in the Sun's atmosphere, and was originally known only from absorption lines. Another putative element, coronium, was also first identified in the Sun's corona; and was eventually found to be the same line as oxygen.\nNamed after stars and a constellation, we have denebium, aldebaranium, and cassiopeium. They were eventually ditched in favour of our present names like ytterbium."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:6e4f5c46-8f8d-4f44-a06e-326c279741ce>"],"error":null}
{"question":"What are the basic properties of silicon carbide ceramics, and how has it been applied in modern technological applications like electric vehicles?","answer":"Silicon carbide (SiC) is an extremely hard, synthetically produced crystalline compound of silicon and carbon, first discovered in 1891 by Edward G. Acheson. As a technical ceramic, it offers high mechanical strength, abrasion resistance, chemical resistance, and can withstand very high temperatures. In modern applications, silicon carbide has shown promise in electric vehicles, where studies have demonstrated efficiency improvements of 2-3% in high rpm ranges and 3-10% at lower speeds when compared to conventional IGBT inverters.","context":["What are ceramics?\nMention the term ‚Äúceramics‚Äù and most people will think of traditional pottery items such as plates, mugs, plant pots and such like. But ceramics is a very broad term for a wide range of products each with their own characteristics and uses. In terms of their chemistry, ceramics can be defined as any non-metal and non-organic solid including (but not limited to) porcelain, cement, and glass. Ceramics are all around us in daily life.\nWhat are the different types of ceramics?\nTraditional ceramics are also known as structural ceramics. These are mostly clay-based and include bricks, dinnerware, and statues to name a few. They are shaped and formed through being pressed or through extrusion. Their density is influenced by the size of the particles and the firing temperature.\nTechnical ceramics are made to perform a specific job or purpose and are specially engineered through their chemical composition and production process.\nRefractory ceramics are resistant to very high temperatures and hold their shape and form. Found in kilns and furnaces they can hold molten materials such as liquified metal. Constructed with oxides, the purer the oxides the higher the refractory qualities. Being able to withstand temperatures of 3000 degrees centigrade makes them suitable for high-stress situations such as industrial furnaces and jet engines.\nElectrical ceramics are resistant to the flow of an electrical current, and therefore ceramic materials such as porcelain have traditionally been used as electrical insulators. Some ceramics, however, are excellent conductors of electricity and as a result are used as electrical components in a number of devices.\nWhat are technical ceramics?\nTechnical ceramics are sometimes referred to as advanced ceramics. They are also known as high-tech ceramics or high-performance ceramics. Technical ceramics are most commonly used in industrial, commercial and specialist applications that require materials with high mechanical strength, abrasion, chemical resistance, electrical insulation and resistance to high temperatures.\nWhat are the basic ingredients of a glaze?\nEvery glaze is made of the following 3 materials:\nSilica ‚Äì this material creates glass when it is heated past 3100 degrees Fahrenheit.\nAlumina ‚Äì this ingredient solidifies the glaze so it doesn‚Äôt slide off the clayware when fired at high temperatures. Alumina is also used as the specialist material of choice in approximately 80% of engineering applications.\nFlux ‚Äì this ingredient enables the glaze to melt at temperatures low enough to be used in ceramics.\nWhat is kiln furniture?\nKiln furniture is the system of shelving, supports and other paraphernalia which enables multiple layers of ware, or irregularly shaped ceramics to be fired using the entire chamber of a kiln. Without these items you would only be able to fire ware which could sit securely on the base of the kiln. Batts, shelves, tubes, beams, and props are all examples of kiln furniture which is made to withstand temperature tolerances suitable different types of ceramics.\nWhat is Silicon Carbide?\nSilicon carbide is an extremely hard, synthetically produced crystalline compound of silicon and carbon. Its chemical formula is SiC. It was discovered in 1891 by the American inventor Edward G. Acheson while he was trying to make artificial diamonds.","This paper examines the suitability of a Multi-Level Converter (MLC) that house the PE with batteries to gain cost, mass and efficiency benefits over conventional topologies. Chang compared a conventional IGBT inverter with a silicon carbide and multi-level silicon inverter over a simulated driving range [ 2 ] and found a 2% - 3% improvement in the high rpm range and 3% - 10% at lower\n2013/5/15¬∑ Silicon carbide nanowires presented in this paper are grown on n-doped 3C-SiC thin (2 Œºm) films on a Si(100) substrate with a SiO 2 (1.5 Œºm) isolation layer. The 3C-SiC thin films are deposited in a low-pressure chemical vapor deposition (LPCVD) reactor, employing methylsilane as the precursor and in-situ doped using ammonia  .\n8\" x 50 yard roll of ia Abrasive Silicon Carbide Roll. 36 grit Excellent choice for all sort of sanding, does well on clear wood, old hard finishes, and softer finishes. Visit product 8 x 50 yard 36 grit Roll of ia Abrasive Silicon Carbide. and read data.!!\nSilicon carbide (SiC), particularly the 4H polytype (4H-SiC), is one of the key candidates for appliion in such devices, owing to its excellent intrinsic properties, which involve a large bandgap (3.26 eV), high breakdown electric field (3 √ó 10 6 Vcm ‚àí1 7 cm s ‚àí1 ‚àí1\nPowertec is a US based manufacturer of high quality woodworking machines, wood work accessories, and a wide assortment of OEM replacement parts. 3816 Hawthorn Court, Waukegan, IL 60087, United States 847-780-6120\nSuppliers / Providers of Silicon dioxideIf you want to know who sells, deals, distributes or offers Silicon dioxide or similar products, the following is a list of vendors or dealers that are manufacturers (producers), exporters, distributors and general suppliers / providers\nwith silicon carbide devices on a ceramic substrate of AlN. This paper noted the effects of porosity and density of the die attach material on the die stresses.\n2011/11/11¬∑ Yan J, Zhang Z, Kuriyagawa T: Mechanism for material removal in diamond turning of reaction-bonded silicon carbide. Int J Mach Tool Manufac 2009, 49(5):366‚Äì374. 10.1016/j.ijmachtools.2008.12.007 Article Google Scholar\n2011/11/29¬∑ Zinner E, Ming T, Anders E. Large isotopic anomalies of Si, C, N and noble gases in interstellar silicon carbide from the Murray meteorite. Nature. 1987; 330 :730‚Äì732.\nCoorsTek corporate headquarters are loed in Golden, Colorado, USA. CoorsTek, Inc. 14143 Denver West Pkwy. Golden, CO 80401 USA +1 303 271 7000 Office Hours: Monday ‚Äî Friday 8 AM to 5 PM, Mountain Time For all product and service related\nPremium Sanding Belts Direct! We carry Open and Closed coat Aluminum Oxide, Zirconia, Ceramic, Silicon Carbide and specialty materials. Do not see your sanding belt size listed? We custom build any size sanding belt. Click here or call 1-888-223-8768 for a\n2008/10/1¬∑ Title: Superconductivity in heavily boron-doped silicon carbide Authors: M. Kriener, T. Muranaka, J. Kato, Z.A. Ren, J. Akimitsu, Y. Maeno (Submitted on 1 Oct 2008) Abstract: The discoveries of superconductivity in heavily boron-doped diamond (C:B) in 2004 and\nSilicon Carbide Ceramic Non-woven #24--#1200 Coarse,Medium,Fine Overlap Butt Joint Z-lock butt Cotton Blended fabric Polyester fabric 20*520 50*2100 100*915 200*750 200*480 300*750 As request Advantage: Factory directly supply 20years\nHydrogenated amorphous substoichiometric silicon carbide (a‚ÄêSi 1‚àíx C x :H, x < 0,1) thin films and diodes with low carbon content are prepared from a mixture of H 2, SiH 4, and CH 4 by plasma‚Äêenhanced chemical vapor deposition at a relatively high temperature of 400 C on semi‚Äêtransparent boron‚Äêdoped nanocrystalline diamond (B‚ÄêNCD) electrodes with an underlying Ti grid.\n2013/8/28¬∑ Abstract: This paper presents an isolated on-board vehicular battery charger that utilizes silicon carbide (SiC) power devices to achieve high density and high efficiency for appliion in electric vehicles (EVs) and plug-in hybrid EVs (PHEVs). The proposed level 2\n3M Wetordry Abrasive Sheet 413Q is an abrasive sanding paper constructed on a light, A-weight paper backing and features a waterproof resin bonding to help prevent heat buildup. The silicon carbide abrasive and waterproof backing make this paper an ideal product for sanding appliions such as paint prep, sanding, sealer sanding, and solid surface finishing.\nRichardson RFPD has an extensive silicon carbide (SiC) offering, including the latest products and design resources focused exclusively on this emerging technology. Browse our selection of Schottky diodes, MOSFETs and IGBTs and eduional material from industry leading manufacturers Wolfspeed, Microsemi, Vincotech and Powerex.\n2016/7/28¬∑ \"Silicon carbide can be very useful as we go further into autonomous vehicles,\" says Aravind Bharadwaj, power electronics engineer and senior vice-president at Mahindra & Mahindra. Several companies around the world are working on developing the next generation of semiconductors for power electronics, and silicon carbide is only one of the contenders.\nBuy Silicon Carbide Ceramic Foam Filter with Good Quality, Find Details include Size,Weight,Model and Width about Silicon Carbide Ceramic Foam Filter with Good Quality. Make an Inquiry for Silicon Carbide Ceramic Foam Filter with Good Quality at OKorder\n2018/6/28¬∑ The Institute of Material Sciences NTNU has produced an eduional video about the production of silicon, which is an essential material in our society. Silicon is used in a wide array of\n2020/7/31¬∑ Mersen designs and manufactures corrosion resistant and process equipment in a wide range of materials, such as graphite, silicon carbide, tantalum, zirconium, titanium, nickel alloys, stainless steel, carbon steel, and fluoropolymer.\n60063906014, 3M Paper Sheet 405N 3-2/3\" X 9\" 240 Grit Silicon Carbide The smart place to shop Serving you since 2012 Order Assistance Contact us here View Cart Login\n3M offers the full line of durable, dependable Standard AbrasivesTM products. Find quick change discs, flap wheels and other abrasives solutions here. Standard Abrasives offers a full line of abrasives including quick change discs, flap wheels, cartridge rolls, fiber\nBy Kwak Yeon-soo SK Siltron, the semiconductor wafer unit of SK Group, will acquire DuPont''s wafer business in a bid to strengthen its presence in the market, the company said Tuesday. The market\nSilicon carbide (SiC) is a wide bandgap semiconductor base material. It can be used as a bare die substrate, in discrete components like Schottky diodes and MOSFETs, as well as power modules. Historically, silicon (Si) has been used as a semiconductor ‚Ä¶\nChina Sand Paper / Sand Disc alog of Competitive Price Waterproof Silicon Carbide Abrasive Sand Paper, Wet or Dry 9\" X 11\" Sheet Waterproof Abrasive Automotive Sand Paper provided by China manufacturer - Guangdong Sybon New Materials Co., Ltd., page1."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:723eb227-e7ca-4cd2-afe6-15a57aa484f1>","<urn:uuid:b93b21cf-5f5b-495e-a19d-a3624c7577fa>"],"error":null}
{"question":"How does art therapy help with stress regulation, and what are the physical impacts of chronic stress on the body?","answer":"Art therapy helps regulate stress through multiple mechanisms - studies show 45 minutes of art-making reduces cortisol levels, while the therapist helps teach self-regulation techniques involving breath and movement. The arts offer emotional outlets and stress relief in a nurturing environment. Regarding physical impacts, chronic stress can lead to various manifestations including asthma, back pain, fatigue, headaches, and suppressed immune function. It raises blood pressure, increases risk of heart attack and stroke, and can cause anxiety and depression. Chronically elevated cortisol from prolonged stress can impair cognitive performance, suppress thyroid function, decrease bone density and muscle tissue, raise blood pressure, and increase abdominal fat.","context":["by Auriel Sarah Eagelton\nAuriel Sarah Eagleton looks at what neuroscience has to say about the benefits of art therapy\nWhen asked about his experience of art therapy, a young boy with dyslexia replied, ‚ÄúI feel proud‚Äù, while gesturing to his creations. An older boy on the autism spectrum responded to the same question saying: ‚ÄúI feel understood‚Äù. The importance of pride for a child who struggles to keep up at school and suffers low self-esteem, cannot be underestimated. Nor can the significance of feeling understood to a child who struggles with social relationships.\nBoth of these experiences of art therapy are suggestive, not only of the curative potential of the arts but also of the importance of the relationship between therapist and child, supporting the unique and intimate processes of an evolving sense of self.\nWhat is art therapy?\nArt therapy isn‚Äôt simply about making art, teaching art or instructing a child‚Äôs art making. Crucially, art therapy is about making art in the company of a masters level-trained arts therapist who can help to regulate difficult emotions, broaden perspective and work toward equipping the child with the tools they need to navigate life with increased confidence and resilience.\nArt therapy offers children a safe form of emotional expression and communication that is unrestricted by language and communication difficulties.\nSome art therapists work with the broad array of sensory materials available to the visual arts, such as paint, clay, pastels and collage. Others integrate further modalities, including sand play, creative writing, storytelling, puppetry, drama, music, dance and movement. Whichever approach is taken, art therapy provides children with opportunities to explore different sensory materials and to express themselves.\nArt therapy for SEN\nChildren with learning disabilities can struggle with low self-esteem, isolation and behavioural difficulties related to challenges they might face with communication, academic performance and feelings of not fitting in or not understanding social norms and expectations. For children struggling with such difficulties, art therapy offers a bridge between the child‚Äôs inner world and the outside world, enabling them to express their inner turmoil in the company of a safe and regulating adult. The therapist can then act as an ‚Äúauxiliary cortex‚Äù (Diamond et al., 1963), empathetically helping the child to recognise, label and regulate emotions whilst, if appropriate, assisting them to understand and adjust to social and cultural expectations.\nThe art therapist adapts their approach according to the individual needs of the child they are treating and can focus on specific outcomes, for example:\n- building self-esteem\n- supporting mentalization processes (the capacity to read and understand ones own and other people‚Äôs emotions and motivations)\n- developing coping skills\n- working through trauma in a safe, non-intrusive way\n- developing interpersonal skills and reciprocity\n- building frustration tolerance\n- supporting sensory integration\n- promoting internal locus of control (developing the child‚Äôs capacity to identify choice and exercise appropriate levels of control in their life)\n- teaching and supporting self-regulation\n- working with children, teachers and families to attend to specific behavioural difficulties.\nSome of these goals will be particularly relevant to children with SEN. For example, many children with SEN experience higher levels of external control over their lives and have to develop much greater frustration tolerance to cope with the challenges of ‚Äúkeeping up‚Äù with what might seem easy for other children. Emotions associated with feeling different can impact on self-esteem and have an isolating effect, further impacting on the development of interpersonal and mentalization skills.\nThe arts can offer an emotional outlet whilst simultaneously supporting the child‚Äôs sense of being understood. By creating and exploring symbolic images, children are able to develop their own understanding and to communicate their perspective to the arts therapist, without being limited by the words and narratives of the adults in their lives. This can be especially relevant when helping a child to understand and process a diagnosis, for example. Diagnoses are given by adults; children are assessed and spoken about by adults in the process. Art therapy can support children to explore and express their personal narratives around diagnosis, what it means to them, how they experience their additional needs and how they would like others to support them. Since reflective and communication skills may not be sufficiently developed to do this verbally (this can be challenging for the most articulate adult), the arts can support children to find a voice.\nArt therapy for learning\nNeuroscience increasingly demonstrates the importance of the arts for both cognitive and emotional development (Malchiodi, 2012).\nThe creative process of art-making activates multiple areas of the brain (Kaufman, 2013; Bolwerk et al., 2014). Healthy brain functioning is correlated with the integration of different brain structures (Cozolino, 2002). By activating different brain regions, art therapy might provide a means of exercising the whole brain, supporting integration, brain plasticity and healthy brain functioning.\nSpeaking on education, Louis Cozolino, a psychologist and professor renowned for his writing on the neuroscience of psychotherapy and education, suggests that learning is best supported by a multi-modal approach in which cognitive, emotional, sensory and physical experiences combine: ‚ÄúThere is a greater likelihood that learning will generalize outside the classroom if it is organized across sensory, physical, emotional and cognitive networks‚Ä¶‚Äù (Cozolino, 2013).\nCozolino places special emphasis on the significance of visual stimulus for learning: ‚ÄúWe have an amazing capacity for visual memory, and written or spoken information paired with visual information results in better recall‚Ä¶‚Äù (Cozolino, 2013).\nIn art therapy, different modalities and sensory materials are used to explore dominant themes and to support intended outcomes. Even when movement is not explicitly part of the therapy, processes of painting, moulding, playing, gesturing and vocalising add physicality to the areas of emotion, cognition and symbolic representation pursued through the arts. The tactile nature of different art materials and the kinaesthetic processes of creating and embodying art, can provide important opportunities for sensory integration (Hass-Cohen, 2008).\nWhile our cultural perception of the arts often limits creativity to the domain of leisure and recreation, creativity using the arts entails complex thought processes and physical mastery. For example, when painting a picture the brain is engaged in thinking about shape, form, colour, light, scale, relationship, perspective and symbolic meaning. This is an abstract thought process that is then translated into two-dimensional form through careful attention and the action of painting. In art therapy, this is done with the intention of conveying meaning from one mind to another, expressing or eliciting feeling. The process of making art to convey something of depth and importance to another is very powerful and necessitates a high level of cognitive and emotional planning. Additionally, the use of the arts to support communication skills and social development can be furthered through small art therapy groups. This can work well in schools, where children might need extra support to form friendships with peers.\nSelf-regulation for learning\nThe stress reducing and regulating qualities of art therapy directly support learning. ‚ÄúStressful situations trigger the release of the stress hormone cortisol, which interferes with neural growth. Prolonged stress impairs our ability to learn and maintain physical health‚Ä¶ Success in school depends upon a student‚Äôs ability to somehow decrease their stress‚Ä¶‚Äù (Cozolino, 2013).\nStudies have demonstrated the stress-relieving effects of art-making, showing reduced cortisol levels after 45 minutes of engagement with the arts (Kaimal et al., 2016). Furthermore, the art therapist attends very carefully to the body language of children they work with, noticing the impact of different sensory experiences and any physical tension or signs of distress a child might exhibit. Many art therapists are informed by the growing emphasis on self-regulation supported by neuroscience findings. Self-regulation techniques, involving breath, movement, the capacity to observe and tolerate emotional responses and painful thoughts, while maintaining choice over behaviour, can be taught during the course of therapy. It can take time to master self-regulation but children with these skills and capacities are better equipped for navigating life challenges and maintaining an internal equilibrium that is supportive of learning and development.\nWhole brain-body benefits\nAs our understanding of development and wellbeing evolves, there is general consensus that interventions that treat the whole person are most effective. The mind-body integration of the arts therapies certainly offers possibilities for the activation and expression of the whole person. It is also increasingly clear that emotions form a part of cognition and that learning and neural growth and development is best supported by nurturing and enriched environments. As Cozolino suggests, the ‚Äúmagic‚Äù of art therapy is perhaps the combination of a nurturing relationship and the enriching qualities of the arts: ‚Äú‚Ä¶the client-therapist brain can ‚Äòfire together‚Äô in the service of regulating affect, creating new avenues of expression, and enhancing neural connectivity. Pretty good magic‚Ä¶‚Äù (Cozolino, 2015).\nChoosing an art therapist\nThe scope of art therapy is broad and this article offers only a limited definition of it. Art therapy can be offered individually and in groups, at school and privately. In schools, art therapists can be instrumental in developing creative, inclusion-promoting strategies to support both teachers and children.\nIf you are looking for an art therapist to work with your child it is important to ask the therapist about their approach and to explore how they might work with your child‚Äôs needs.\nEarly intervention is important and art therapy can be initiated at any age. Art therapy can be beneficial at any stage in life. It is as valuable to adults as it is to children.\nAuriel Sarah Eagleton is an HCPC registered Integrative Arts Psychotherapist who specialises in learning difficulties. She is based at the London Art Therapy Centre:\nAuriel is also co-founder of the Art Therapy Cabin, a woodland based therapy centre offering environmental arts therapy to adults and children.\nwww.aurieleagleton.com and www.therapycabin.co.uk\nFor further information about art therapy and registered therapists, visit:\n- Bolwerk, A., Mack-Andrick, J., Lang, F. R., D√∂rfler, A. and Maih√∂fner, C. (2014) How art changes your brain: Differential effects of visual art production and cognitive art evaluation on functional brain connectivity. PLoS ONE, 9(7).\n- Cozolino, L. (2002) The neuroscience of psychotherapy : building and rebuilding the human brain. New York: Norton.\n- Cozolino, L. (2013) The social neuroscience of education : optimizing attachment and learning in the classroom. New York: W. W. Norton & Company.\n- Cozolino, L. (2015) Forward. In Hass-Cohen N. & Findlay, J. C. (ed.) Art Therapy and the Neuroscience of Relationships, Creativity and Resiliency. Kindle, New York: W. W. Norton & Company.\n- Diamond, S., Balvin, R. and Diamond, F. (1963) Inhibition and choice. New York: Harper & Row.\n- Hass-Cohen (2008) Partnering of Art Therapy and Clinical Neuroscience. In Carr, R. and Hass-Cohen, N. (eds) Art Therapy and Clinical Neuroscience. Kindle, London: Jessica Kingsley Publishers.\n- Kaimal, G., Ray, K. and Muniz, J. (2016) Reduction of Cortisol Levels and Participants‚Äô Responses Following Art Making. Art Therapy.\n- Kaufman, S. B. (2013) The Real Neuroscience of Creativity. Scientific American. [Online] [Accessed on 2nd October 2017] https://blogs.scientificamerican.com/beautiful-minds/the-real-neuroscience-of-creativity/.\n- Malchiodi, C. (2012) Art Therapy and the Brain. In Handbook of Art Therapy. 2nd edition, New York: Guilford Press.\n- Sousa, D. (2012) How the Brain Learns. 4th ed., Thousand Oaks, CA: Sage.\nThis article was first published in SEN Magazine | Nov/Dec 2017 | Download","Stress is how the body reacts to a real or imagined stressor ‚Äî a stimulus that causes stress. Acute stressors affect a bodily organ in the short term; chronic stressors over the longer term. Chronic stress is the state of prolonged tension from internal or external stressors which may cause various physical manifestations such as asthma, back pain, arrhythmias, fatigue, headaches, irritable bowel syndrome, ulcers, and suppression of the immune system. Chronic stress takes a more significant toll on the body than acute stress. It can raise blood pressure, increase the risk of heart attack and stroke, and induce symptoms of anxiety and depression.\nThe Three Stages of Stress ‚Äì From Acute to Chronic\n- Alarm: In this first stage, when the threat or stressor is first identified or realized, the body‚Äôs stress response is in a state of alarm. During this stage, adrenaline is produced in order to bring about the flight-or-fight response, causing sweating, raised heart rate, etc. The body‚Äôs resistance to the stressor drops temporarily below the normal range and some level of shock may be experienced. There is also some activation of the HPA Axis, producing cortisol, as discussed in our last post.\n- Resistance: If the stressor persists, the body must find some means of coping with the stress. Although it begins to try to adapt to the strains or demands of the environment, the body cannot keep this up indefinitely, so its resources are gradually depleted. As it attempts to cope with the condition that is causing the stress, the mind may try to focus on the problem, which can actually exaggerate the awareness of the problem and make it seem difficult to overcome.\n- Exhaustion: third stage. At this point, all of the body‚Äôs resources are eventually depleted and the body is unable to maintain normal function. The initial symptoms may reappear (sweating, raised heart rate, etc.). Long-term damage may result, as the body‚Äôs immune system becomes exhausted, and bodily functions become impaired. The result can manifest itself in obvious illnesses such as ulcers, depression, diabetes, digestive system problems or cardiovascular problems. It can also manifest as a chronic pain syndrome, guarding/avoidance behavior, and/or sleep disturbance. Hopelessness can set in.\nChronic Stress and Cortisol\nWhen the body‚Äôs HPA-axis cannot overcome a challenge and/or is chronically exposed to a threat, this system becomes overtaxed and can be harmful to the body and brain. An increased level of cortisol is one of the most dangerous outcomes of chronic stress.\nCortisol is an important hormone in the body, secreted by the adrenal glands and involved in some of the following functions: proper glucose metabolism, regulation of blood pressure, insulin release for blood sugar maintenance, immune function and inflammatory response. Normally, cortisol is present in the body at higher levels in the morning and is at its lowest level at night. Although stress is not the only reason that cortisol is secreted into the bloodstream, it has been termed ‚Äúthe stress hormone‚Äù because it‚Äôs also secreted in higher levels during the body‚Äôs ‚Äòfight or flight‚Äô response to stress, and is responsible for several stress-related changes in the body. Small increases of cortisol have some positive effects: a quick burst of energy for survival reasons, heightened memory functions, a burst of increased immunity, lower sensitivity to pain, and helping to maintain homeostasis in the body.\nPeople are biologically ‚Äòwired‚Äô to react differently to stress.\nWhile cortisol is an important part of the body‚Äôs response to stress, it is important that the body‚Äôs relaxation response be activated so the body‚Äôs functions can return to normal following a stressful event. Unfortunately, in our current high-stress culture, the body‚Äôs stress response is activated so often that the body doesn‚Äôt always have a chance to return to normal, resulting in a state of chronic stress, thus producing high chronic cortisol levels.\nHigher and more prolonged levels of cortisol in the bloodstream like those in chronic stress have been shown to have negative effects, such as:\n- Impaired cognitive performance (loss or poor concentration, inability to complete tasks or heightened confusion in mildly stressful situations\n- Suppressed thyroid function\n- Blood sugar imbalances such as hyperglycemia\n- Decreased bone density\n- Decrease in muscle tissue\n- Higher blood pressure\n- Lowered immunity and inflammatory responses in the body, slowed wound healing, and other health consequences\n- Increased abdominal fat, which is associated with a greater amount of health problems than fat deposited in other areas of the body.\nWhen people feel stressed, stress hormones can be over-secreted, dramatically affecting the brain. Cortisol also plays a large part in post-traumatic stress disorder (PTSD) and memory. In a 2002 article in Biological Psychiatry regarding cortisol, PTSD and memory1, cortisol was noted to work with epinephrine (adrenaline) to create memories of short-term emotional events. This effect may serve as a means to help a person remember what situations to avoid in the future. However, long-term exposure to cortisol damages cells in the hippocampus and can create impaired learning ability. It has been shown that cortisol inhibits memory retrieval of already stored information.\nCortisol secretion varies among individuals. People are biologically ‚Äòwired‚Äô to react differently to stress. One person may secrete higher levels of cortisol than another in the same situation. Studies have shown that people who secrete higher levels of cortisol in response to stress also tend to eat more food, and food that is higher in carbohydrates, than people who secrete less cortisol.\n1‚ÄúDepression. What happens in the brain?‚Äù Biological Psychiatry, 2002"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:ebb38ab6-db6f-42c7-9955-ba9bb10245bf>","<urn:uuid:d7c94324-42c7-4519-9ffb-30768ad1d960>"],"error":null}
{"question":"How does postmodernism view truth and hierarchies in both social and scientific contexts, and what challenges arise from these perspectives?","answer":"Postmodernism rejects the idea of objective, universal truth that can be discovered through reason and observation. According to postmodernists, truth is socially constructed through collaborative interactions rather than being something external that corresponds with reality. In science, postmodernists argue that observations are culturally influenced and scientific knowledge cannot describe objective truth - they view science as just another narrative. Regarding hierarchies, while historically societies operated under frameworks like the Great Chain of Being that organized everything from 'lower' to 'higher,' postmodernism challenges these rigid hierarchical structures. The worldview suggests that social hierarchies are not natural or divinely ordained, but rather constructed through power dynamics and cultural contexts. However, this creates challenges as postmodernism's rejection of all universal truths is itself a universal truth claim, making the philosophy self-defeating. Additionally, while postmodernists argue against hierarchical structures, they still must contend with how to organize society and evaluate competing moral claims between different communities.","context":["Friday, December 20, 2019\nI heard the following story while listening to a lecture from Ravi Zacharias on the pursuit of truth in our current culture:\nI remember lecturing at Ohio State University, one of the largest universities in this country. I was minutes away from beginning my lecture, and my host was driving me past a new building called the Wexner Center for the Performing Arts.\nHe said, ‚ÄúThis is America‚Äôs first postmodern building.‚Äù\nI was startled for a moment and I said, ‚ÄúWhat is a postmodern building?‚Äù\nHe said, ‚ÄúWell, the architect said that he designed this building with no design in mind. When the architect was asked, ‚ÄòWhy?‚Äô he said, ‚ÄòIf life itself is capricious, why should our buildings have any design and any meaning?‚Äô So he has pillars that have no purpose. He has stairways that go nowhere. He has a senseless building built and somebody has paid for it.‚Äù\nI said, ‚ÄúSo his argument was that if life has no purpose and design, why should the building have any design?‚Äù\nHe said, ‚ÄúThat is correct.‚Äù\nI said, ‚ÄúDid he do the same with the foundation?‚Äù1\nThe Foundation of Postmodernism\nI fully admit that I am not a professional philosopher and, while I was researching postmodernism, I stopped more than once to ask, ‚ÄúWhat did that just say?‚Äù I find it to be a very mind-bending philosophy, but will try to communicate the basics clearly and concisely.\nPostmodernism rejects the idea that objective, universal truth can be discovered through reason, observation and rational investigation. No person, institution, or discipline is neutral in its pursuit of truth and will therefore always offer an interpretation that is colored by its culture, language, history and gender. Truth is not something external that we can determine, but is socially constructed through our collaborative interactions. There is no ultimate ‚ÄúTruth‚Äù that corresponds with reality, but there are collective ‚Äútruths‚Äù that are built by each individual. Postmodern philosopher Richard Rorty puts it this way, ‚ÄúWe‚Ä¶[should] give up the correspondence theory of truth (i.e. truth is that which corresponds with reality), and start treating moral and scientific beliefs as tools for achieving greater human happiness, rather than as representations of the intrinsic nature of reality.‚Äù2\nLanguage plays a central role in the construction of ‚Äútruth.‚Äù Jeff Myers explains, ‚ÄúPostmodernists think we cannot know the world directly. We only know it as we interpret it. Since our language structures our relationships, our talk about the objects in the world isn‚Äôt really about those objects at all: it‚Äôs really about ourselves.‚Äù3 So when we talk about an object, a moral truth, or a scientific idea, we aren‚Äôt talking about something with an objective, concrete essence but are only communicating our interpretation. Recognizing the role in which language shapes these interpretations, postmodernists hold suspicion about how language is used by the powerful as a tool of oppression to impose ideas on everyone else. One way this is accomplished is by the crafting of metanarratives, which provide a unifying story about reality. Postmodern philosopher Jean-Francois-Lyotard encouraged ‚Äúincredulity towards metanarrative‚Äù4 because people‚Äôs experiences are too varied to provide a general, overarching statement about the world.\nTo postmodern literary critics, ultimately, even words themselves have lost objective meaning. In an essay titled ‚ÄúThe Death of the Author,‚Äù Roland Barthes argues that the original and intended meaning of the text is not important, rather it is the interpretation of the reader that determines the text‚Äôs meaning. Postmodern literary critics claim that words cannot accurately describe the world. The writer cannot communicate about reality, but can only communicate about reality as understood by the reader.5\nOrigin ‚Äì How did we get here?\nPostmodernism is skeptical of claims that science can provide a neutral, objective description of reality. Author Nancy Pearcey recounts the following story from a conference on science and postmodernism:\nPostmodernist philosophers led off by arguing that ‚Äúthere are no metanarratives,‚Äù meaning no overarching, universal truths. Responding on behalf of the scientists was Nobel Prize-winning physicist Steven Weinberg, who replied: But of course there are metanarratives. After all, there‚Äôs evolution ‚Äì a vast metanarrative from the Big Bang to the origin of the solar system to the origin of human life. And since evolution is true, that proves there is at least one metanarrative‚Ä¶.To which the postmodernist philosophers responded, ever so politely: That‚Äôs just your metanarrative. Evolution is merely a social construct, they said, like every other intellectual schema ‚Äì a creation of the human mind.6\nPostmodernists claim that our observations are culturally and linguistically influenced and the knowledge that we gain from science cannot describe an objectively true nature. Terry Eagleton asserts, ‚ÄúScience and philosophy must jettison their grandiose metaphysical claims and view themselves more modestly as just another set of narratives.‚Äù7 Objective ‚ÄúTruth‚Äù about the origin of the universe, our solar system, and life on Earth is beyond our grasp.\nIdentity ‚Äì What does it mean to be human?\nNothing at all. In their book on postmodern economics, David Ruccio and Jack Amariglio claim there is ‚Äúno singular or unique ‚ÄòI.‚Äù‚Äù8 Human beings do not possess a personality or human nature. We do not have souls, but are a ‚Äúcollage of social constructs.‚Äù9 Mitchell Stevens explains, ‚ÄúIt‚Äôs not just that we have different sides to our personality; it‚Äôs that we have no central personality in relation to which all our varied behaviors might be seen as just ‚Äòsides.‚Äô We are, in other words, not absolutely anything.‚Äù10\nFrom a postmodern view, things, including human beings, don‚Äôt have any real, intrinsic essence. Human nature and value is not something that we can objectively describe, but something that is socially constructed and colored by our unique experiences and cultural perspectives.\nMorality ‚Äì How should we live?\nAccording to British essayist Phillips, ‚ÄúUniversal moral principles must be eradicated and reverence for individual and cultural uniqueness inculcated.‚Äù Postmodernism denies the existence of any universal morality against which we might judge right and wrong action. Instead, we must be content to live with what Jean-Francois Lyotard called ‚Äúlittle narratives.‚Äù Moral truth is not revealed by a divine being or discovered by reason, but resides within the community. Each culture and community determines what is moral within its own circumstances and experiences. This leads to the obvious question, however. How does one judge between two communities with opposite, incompatible moral views?\nMeaning ‚Äì Why are we here?\nAlbert Camus once said, ‚ÄúI have seen many people die because life for them was not worth living. From this, I conclude that the question of life‚Äôs meaning is the most urgent question of all.‚Äù11 Can postmodernism provide satisfying answers to this question? The worldview dismisses the existence of any external purpose and meaning for human life that we can apprehend and rejects any metanarrative that would attempt to provide an answer to the question of ultimate purpose.\nWhat we are left with is pragmatism. Since ultimate meaning and purpose are not ‚Äúout there‚Äù waiting to be discovered, we must generate our own purpose, informed by our experiences and culture. In other words, each person must discover purpose, meaning, and significance in a manner that works for them.\nDestiny ‚Äì What happens to us when we die?\nProbably at this point, you‚Äôve noticed a pattern that postmodernism can‚Äôt really provide any answers to the big questions of life. Based on its own central tenets, postmodernists would deem these answers to be unknowable in an objective sense. However, metaphysical truth can be discovered in a pluralistic sense, based on preference rather than objective standards. A person‚Äôs claims about eternal matters may be true for them, but they don‚Äôt apply to everyone else.\nDespite claims of religious plurality, it seems that some postmodern thinkers have no problem rejecting certain metaphysical propositions. Richard Rorty claimed there was ‚Äúno room for obedience to a nonhuman authority (i.e. God)‚Äù and endorses ‚Äúforgetting about eternity.‚Äù12 Matters of heaven, hell, sin, and salvation compose a metanarrative that has been used by institutions to control and oppress. The very idea of God has been socially constructed through language. ‚ÄúGod is a projection. When children have problems, they run to their father for protection. When adults have problems, they project their earthly father into the skies, and they run to this entity for comfort.‚Äù13\nAlthough reading about postmodernism sometimes feels like swimming in the philosophical deep waters, it seems to me that a person can refute the worldview without needing to graduate from ‚Äúswimmies.‚Äù The worldview is self-defeating, which can be shown with simple logic. Postmodernism claims that there is no universal truth that can be known, but in doing so, makes a truth claim of its own that should be universally accepted. By rejecting all metanarratives, aren‚Äôt postmodern philosophers building their own metanarrative that there are no metanarratives? Postmodern literary critics assert that the words of the author have no objective meaning; instead, it is the interpretation of the reader that has meaning. Yet, I suspect that when these critics write books expressing this view they expect that the reader will be able to understand the message they are trying to communicate. If a student completely misinterprets their message, would they correct them or be satisfied that the student had constructed their own meaning?\nTo be charitable, I do think that postmodernism does raise some valid concerns, but takes them too far. We should be humble about the limits of our own knowledge, but that does not mean that truth is unknowable or does not exist. It is worthwhile to recognize how own life experiences and culture impact our own beliefs and pursuit of truth, but again, this does not mean that we are unable to perceive that which corresponds with reality.\nI want to return to the opening example of the Wexner Center for the Performing Arts, the postmodern building at ‚ÄúThe‚Äù Ohio State University (a little joke for Michiganders, there). The architect felt the liberty to do all sorts of cute tricks with the building: false stairways, purposeless rooms, meaningless pillars. Yet, he didn‚Äôt dare do the same thing with the foundation that supported the building, but recognized its objective function and purpose.\nIn the same way, I feel that postmodernism plays a lot of cute, fancy words games while discussing the big questions of life. Yet, do they really live out their worldview? If we were standing in a road and a truck was hurdling towards us, would they say, ‚ÄúThat‚Äôs just your opinion‚Äù if I warned them to move from its path? When they take a flight, do they want the pilot to trust that the instruments on the control panel are providing information that conforms with reality or would they rather the pilot construct their own truth? When the rubber meets the road, postmodernists do live as though objective truth does exist.\nMore than that, what would happen if we were to build the superstructure of human civilization on the foundation proposed by postmodern philosophy? We would be left with a foundation in which there is no intrinsic human nature or value, there is no standard by which to judge moral decisions, and there is no ultimate purpose or meaning to human life. I hope that humanity never needs to rise from the rubble that would ensue.\n1) Gilson, Tom. ‚ÄúThe Wexner Center‚Äôs Foundations.‚Äù The Thinking Christian. October 25, 2012. https://www.thinkingchristian.net/posts/2012/10/the-wexner-centers-foundations/\n2) Rorty, Richard. Achieving Our Country: Leftist Thought in Twentieth-Century America. Cambridge, MA: Harvard University Press, 1998. 96.\n3) Myers, Jeff and Noebel, David A. Understanding the Times: A Survey of Competing Worldviews. Colorado Springs: David C. Cook, 2015. 156.\n4) Lyotard, Jean-Francios. The Postmodern Condition: A Report on Knowledge. Minneapolis: University of Minnesota Press, 1994. xxiv.\n5) Myers, Jeff and Noebel, David A. Understanding the Times: A Survey of Competing Worldviews. Colorado Springs: David C. Cook, 2015. 158.\n6) Pearcey, Nancy. Total Truth: Liberating Christianity from its Cultural Captivity. Wheaton, IL: Crossway Books, 2004. 114.\n7) Eagleton, Terry. ‚ÄúAwakening from Modernity.‚Äù Times Literary Supplement. February 20, 1987. 194.\n8) Ruccio, David F. and Amariglio, Jack. Postmodern Moments in Modern Economics. Princeton, NJ: Princeton University Press, 2003. 167.\n9) Anderson, Walter T. Reality Isn‚Äôt What It Used To Be. New York: Harper Collins, 1991. 3.\n10) Stephens, Mitchell. ‚ÄúTo Thine Own Selves Be True.‚Äù Los Angeles Times Magazine. August 23, 1992.\n11) Gablik, Suzi. ‚ÄúPostmodernism and the Question of Meaning. https://msu.edu/course/ha/452/gablikpostmodernism.htm\n12) Rorty, Richard. Achieving Our Country: Leftist Thought in Twentieth-Century America. Cambridge, MA: Harvard University Press, 1998. 18.\n13) Markham, Ian S. A World Religions Reader. Malden, MA: Blackwell Publishers, 2000. 24.","How is everything in the world related & what is important to me? The Great Chain of Being\nHow are we to rank, value and categorise everything around us ‚Äì where does everything fit in relation to everything else?\nAt the time of British settlement of Australia the grand narrative of Christianity was beginning to accommodate the grand narrative of science that had been gathering momentum during the Renaissance and Enlightenment. However, the European settler view of the world would have been a Christian cosmology that embraced some variant of the Great Chain of Being. The Great Chain of Being was a highly influential grand narrative of European society that still has many echoes in social and scientific Western thinking. The scala naturae or Great Chain of Being, is an idea derived from antiquity, espoused by Greek philosophers Plato and Aristotle (PAiv.5,681a10-15, PAiv.10,686b21-687a4, HA viii.1, 588b12-22), and later modified by the Neoplatonists and Christianity, although elements of this view occur in other cultures and religions.\nIn very general terms everything in existence was asssumed to be organised (and classified) into a continuous hierarchy arranged in a linear and graded order like the rungs of a ladder, but in degrees of perfection. In the material world there were rocks at the bottom, plants a little higher, followed by animals then, at its pinnacle, human beings. Each rung of the ladder (including species) was eternal and immutable as created by God (although alchemy presented the mesmerizing possibility of converting a base metal to gold). In Christianity a spiritual dimension was included called the ‚Äòsoul‚Äô which first appears at the level of humans (animals did not have souls but angels did). The entire edifice of existence was overtopped by the creator God in heaven who was not physical but pure spirit ‚Äì omniscient, omnipresent, omnipotent, transcendent, eternal, and perfect ‚Äì while at the bottom, in a spiritual underworld, there was the devil and fires of hell.\nThe Ladder of Life communicated a vision of the world that was assumed to be fixed and real, not a product of the human imagination: it was a framework or structure through which to understand the messy complexity of ‚Äòeverything‚Äô. This world was organised from ‚Äòlower‚Äô to ‚Äòhigher‚Äô, from material to spiritual, from imperfect to perfect, from irrational to rational, from simple to complex. Everything had a fixed place in the timeless natural order. To challenge this hierarchy was futile; it was simply the way the world was structured. For most people this was the way the world had been created by God ‚Äì and therefore the way it would stay. The task of humans was to become more spiritual and less material, to release the human soul from its prison of matter. On Plato‚Äôs reading in the Timaeus humans were a microcosm of the greater macrocosm, both organized under similar principles: the orderly behaviour of the heavens signalled the need to govern our individual and collective lives in a rational way.\nOur everyday language is infused with the ideas of the past. One probable carry-over from Aristotle‚Äôs scala naturae is the metaphorical language that ranks ideas by altitude, to ‚Äòlevels‚Äô that are ‚Äòhigher‚Äô or ‚Äòlower‚Äô. Hierarchy is deeply embedded in our language and thinking when we speak metaphorically of the ‚Äòrise‚Äô and ‚Äòfall‚Äô of nations, of ‚Äòhigher‚Äô and ‚Äòlower‚Äô organisms, of a ‚Äòsocial ladder‚Äô, ‚Äòglass ceiling‚Äô, ‚Äòtop dog‚Äô, ‚Äòhigh achievement‚Äô, ‚Äòlow-life‚Äô, ‚Äòmiddle management‚Äô. When we take the time to think about the many ways that hierarchy appears in our daily conversations then we can quickly see how it can subtly structure the way we perceive the world.\nColourful metaphors add interest to communication and we are well aware that the idea of some sort of moral or physical altitude is just a figure of speech. But hierarchical language can still carry a moral loading ‚Äì an attached value. It is more informative to speak of complex and less complex organisms, rather than ‚Äòhigher‚Äô and ‚Äòlower‚Äô organisms, if that is what we mean. In fact we would undoubtedly communicate more clearly without metaphorical hierarchies.\nThe social order\nAre social hierarchies the inevitable consequence of a need to maintain social order? How are people to be ranked and organised ‚Äì which people should have power and authority over others and why?\nAnimals develop hierarchies that are always the same within a species and therefore clearly based on biological factors. Humans, in contrast, have devised hierarchies based on many different factors. Even so, moral psychologists point out that hierarchical sentiments related to loyalty and submission may have some innate foundation. How are we to behave towards one-another when the different hierarchies of different societies meet?\nHumans too have displayed strong social hierarchies with some people and races higher up the ‚Äòsocial ladder‚Äô than others. Even within particular societies the organization into different classes was not regarded as simply a practical and convenient way of ordering society, the ‚Äòupper‚Äô classes ‚Äì priests, aristocracy, kings and rulers were generally regarded (implicitly if not explicitly) as ‚Äòhigher‚Äô or ‚Äòbetter‚Äô in a moral or absolute sense than the lower groups or castes and occasionally, as with some Roman Emperors, humans would claim the status of gods.\nThe natural order?\nThroughout history great philosophers and religions have acknowledged the Golden Rule Do as you would be done by as the rational recognition that no individual can reasonably privilege themselves over another. However, this principle of equality is challenged by our real-life differences. Social hierarchies are based on many factors including physical and intellectual difference, religion, race, wealth, gender, caste, occupation, blood line, role in society, or historical tradition. Hierarchies create social order and often reinforced by being considered part of a biological (natural) or religious cosmic order and therefore not to be challenged. Sometimes it is simply more convenient to interact with people according to a social category rather than as individuals on their own merit. Hoiwever, such categories can be taken as the measure of intrinsic worth. A major challenge for future generations is to establish social hierarchies that are as fair as possible and where power of one group or person over another is not abused. Part of this process involves coming to an understanding of the historical circumstances and reasons why such hierarchies arose and what justification exists for their continuation.\nRacial & class arrogance\nAt the time when European colonization was at its peak, and while the British empire flourished, it was generally assumed that white Europeans were at the top of the human hierarchy. Following in a long tradition but derived mainly from the classicalworld, Britain was divided into classes, the landed and wealthy gentry, nobility, and royalty were the natural rulers. Representation in social decision-making (parliament) was decided by sex (males only) and wealth. Gentlemen were accustomed to servants and servant obedience. Well-to-do scientists like Banks and Darwin had manservants wherever they went, including their scientific voyages around the world.\nDiscipline & the law\nGentleman of the aristocracy were not necessarily oppressors, they too were locked into a system which they did not necessarily support or approve. However, the apparent injustice of such a system of privilege was a major factor in the European revolutions of the 18th and 19th centuries and the need to maintain social order could give rise to terrible abuse. This was clearly exposed at sea. Sea captains (generally members of the upper classes in all European navies) would resort to extremes of physical punishment to subdue any undesirable behavior and it included: flogging, keel-hauling, walking the plank, and hanging from the yard-arm (a sail spar), all formally witnessed by the entire crew as a deterrent. The most popular of these was flogging in which the bare back was thrashed with a cat-o-nine-tails (a whip with nine lead-studded leather thongs) salt being rubbed into the lacerations when the punishment was complete. Offenders who lost consciousness were revived with a bucket of water and the process continued. Keel-hauling entailed tying the offender to a rope that looped on both sides of the ship, the offender jumping off the back or side of the ship and his crew-mates pulling on the two ropes to carry him under water along or across the ship‚Äôs keel: it was almost certain death.\nThe European assumption, at the time of settlement of Aboriginal Australian, was that Europeans were superior to Aborigines. This was clearly not just because Europeans had more complex technology, more effective weapons and the like ‚Äì they felt themselves superior and more civilized in an absolute moral sense. They considered themselves ‚Äòhigher‚Äô on the Great Chain of Being and they spoke of ‚Äòmoral education‚Äô and the ‚Äòcivilizing‚Äô influence that agriculture would have on stone age savages and how agriculture was a higher stage of being than the lowest stage ‚Äì which was to be a hunter-gatherer.\nIdeas that were abandoned by Western science nearly 200 years ago still cloud our judgment. The belief that humans are, in some absolute sense, superior to other organisms (speciesism), and that some humans are superior to other humans is still part of what might be called the Western grand narrative. Ideas of this broad kind underpinned the spread of Empire and the global Western society that we live in today. It was only in the early part of the twentieth century, after the Second World War that, in Britain, the ‚Äòupstairs-downstairs‚Äô, ‚Äòupper class, middle class, lower class‚Äô social hierarchy began to break down.\nAlmost all societies, at least since the agricultural revolution, have been patriarchal, men privileged over women and dominating the economic, political and legal systems. For much of history, and across cultures, females were treated as male property to treat at will. Hence in almost all countries, up until recent times, rape of a wife was simply not possible ‚Äì it was a right linked to the woman being property. Why should this apparently universal phenomenon have occurred? Has this hierarchy arisen through historical circumstance and/or biological difference?\nCertainly child-bearing and child care are biologically based but the culturally sanctioned denial of a place for women in political and civic life appears culturally sanctioned since women do not lack intelligence or political skills.\nMen are certainly physically stronger and dominate the economic world in a way that translates into political power. But strength is not universal and women have more stamina. More importantly there is no connection between political ability and physical attributes because social power depends on social skills, not physical strength. Traditionally it has been the physically strong that have done the manual work, not the political negotiation with its dependence on social skills.\nAre males more aggressive and willing to engage in physical conflict? Are men more competitive and do they compete more for partners? Certainly there are hormonal differences between the sexes and men are indeed more violent, but again this does not translate directly to efficient use of political power when women appear to have the necessary skills.\nPerhaps men are more competitive , one example maybe being their competition for women? Perhaps women needed men to care for them during and immediately after pregnancy and this resulted in submissiveness? But it is possible to depend on other women. Female social networking teaches negotiation and compromise while these male skills remain undeveloped (this occurs in bands of bonobos).\nThere is no clear answer.\nThe biological order\nThe Great Chain of Being (or versions of it) were increasingly challenged during the Renaissance and Enlightenment as science and secular ideas strengthened.\nBotanists were among the first to accept that, although there were differing degrees of structural complexity in plants, it did not make sense to give pride of place to some over others because they were in some way more ‚Äòperfect‚Äô or ‚Äòhigher‚Äô in a Great Chain of Being. During the Reformation many botanists were influenced taxonomically by the idea of giving equal weight to each individual in parallel with the view of human equality in the sight of God in a personal relationship that was not mediated by priests of the Church. Zoologists took longer to convince but when, in 1817, the internationally respected French zoologist Cuvier published his authoritative classification of animals, Le R√®gne Animal, he did so acknowledging Aristotle as predecessor. However, he ranked the animal kingdom on the basis of anatomy (not status within the Great Chain of Being) devising four great groups: the Vertebrata, Articulata, Mollusca and Radiata ‚Äì ‚ÄòIt formed no part of my design to arrange the animated tribes according to perceived superiority‚Äò. No group was inherently superior to any other: degrees of perfection were irrelevant. Organisms were simply different ‚Äì more or less complex, yes; some better adapted to their environments than others, maybe ‚Äì but not ‚Äòhigher‚Äô and ‚Äòlower‚Äô in some cosmic absolute, moral or religious sense. This point may seem obvious today but we can still make quick false assumptions. A chimpanzee is not a failed human, a rather pathetic animal on the evolutionary path to a better life as a human, instead it is an animal that has evolved by adapting to its own particular environment in its own particular way.\nThe Postmodern metanarrative & science wars ‚Äì by what authority?\nThere are no facts, only interpretations\nPost-modernism (a panchretic label) of the late twentieth and early twenty-first centuries questions the validity of all metanarratives but especially modernist certainty and its confidence in scientific objectivity. As a form of skepticism it challenges the claim that we can study the world in a neutral way, observing reality and truth by using the power of reason and science: it questions the notion of certain knowledge and also its value. By what authority can any interpretation take precedence over any other, whether it is an interpretation of history, literature, art or science? Science, like all other grand narratives, is perceived as an explanatory quicksand and just like all other grand narratives though seeming ‚Äòreal‚Äô and ‚Äòtrue‚Äô right now will inevitably, in the future, be assessed correctly as simply a product of a particular time, place and circumstance. We create our own truth and our own meaning: neutral, absolute or objective knowledge is illusory. Any claims to ‚Äòtruth‚Äô are simply ways of exerting power and influence of various kinds ‚Äì truth is simply what works for us, or what we can persuade others to believe. Through most of history we have been told what to believe. Control of the societal grand narrative, once in the hands of a priestly class has passed in part across to humanists, secular scientists, and the intelligentsia of the day. Today there seems to be a mix of these ‚Äì although some might claim that it is now the world view of economists that prevails.\nSo postmodernism regards metanarratives (statements about science, history or literature) as legitimations or prescriptions of specific versions of the ‚Äòtruth‚Äô ‚Äì simply narratives (stories or myths) that reflect the culturally embedded viewpoint or conceptual framework of the narrator. Metanarratives are created and reinforced by power structures, they may serve Utopian ideals and tend to dismiss the naturally existing chaotic variety of experience. Metanarratives may be used to reinforce dogma, examples being Marxist theory of historical development, unwarranted presumptions about the meaning of life (religions), or prescribed goals for human activity. There is no grand-narrative other than the one we happen to adopt as individuals or communities acting within a particular cultural context: the diversity of human aspiration and experience is a demonstration of the inevitable variety of grand narratives. Postmodernism as a program offers ‚Äòdeconstruction‚Äô as a means of making underlying agendas self-evident. In the absence of an absolute truth aren‚Äôt we left with some kind of relativism where, say, accepted standards become purely relative to a particular culture or language?\nCritics of postmodernism point out that postmodernism is itself a grand narrative using the tools it attacks to make its case. As a universal skepticism it must confront its own criteria as a self-refuting grand narrative ‚Äì like the liar who says ‚ÄòThis statement is false‚Äô. It uses logic, reason and other theoretical tools to make its case against these things themselves.\nSo what can we believe as having any validity or truth? We could accept living with a variety of legitimated language games ‚Äì a multiplicity of interpretations each equally valid rather than a single, monolithic and all-encompassing theory.\nBut what if these ‚Äòrelative‚Äô truths conflict? Our vision of reality (even the scientific vision) can only be a reflection of our subjective nature and thought processes.\nFor those who value the scientific and Enlightenment mode of thought both religion (God ultimately controls everything going on in the universe) and postmodernism (there can be no such thing as ‚Äòtruth‚Äô) rob people of any individual self-initiated impetus for action. When considering cases like climate change and the construction of nuclear bombs, it does not seem to be helpful to argue that scientific knowledge is a social construct. Post-modernism seems not to understand the underlying skepticism of science and to overestimate its claim to certain knowledge. Science may not be truth but regarding it as just modern myth is simply mistaken (see also The grand narrative of science and Reason & science)."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:86a882d2-c426-4893-9526-7e74f60390e9>","<urn:uuid:272ff5cb-ae23-4295-9f95-163fe593c67a>"],"error":null}
{"question":"How does wage compensation differ between workers' compensation and no-fault car insurance in terms of the percentage of income covered and weekly payment limits?","answer":"For no-fault car insurance in Minnesota, wage loss benefits pay 85% of gross income with a maximum weekly payment of $500, even if 85% of the person's gross income exceeds this amount. In contrast, workers' compensation in Georgia provides temporary total disability benefits at 2/3 (approximately 67%) of average weekly wages for up to 400 weeks or until the person can return to work.","context":["What Does My No-Fault Car Insurance Cover? | No-Fault Series, Part 2: Wage Loss BenefitsJun. 1, 2022\nWhat Does My No-Fault Car Insurance Cover?\nNo-Fault Series, Part 2: Wage Loss Benefits\nBy Melissa Heinlein, Esq.\nWelcome to part two of our four part series about no-fault automobile benefits. Today we are answering the commonly asked question: who covers my wage loss if I miss work because of a car accident?\nWhen you've been injured in a car accident that was not your fault, life's biggest stressors collide. Suddenly, all your attention is going to medical care, recovery, fixing your vehicle, and managing sky-high expenses, and often being unable to work due to injuries. It can feel impossible to look beyond the present moment and consider when it will be possible to go back to work full-time. When that moment comes, and you ask yourself if you're ready to go back, you need to be well-acquainted with the benefits you are entitled to under Minnesota's no-fault insurance statute.\nThe most important thing to know is that it is possible to take time away from work without jeopardizing your finances.\n‚Ä¢ Minnesota No Fault Act: Pursuant to the Minnesota No Fault Act, automobile insurance policies must provide a minimum of $20,000 of wage loss coverage if you are unable to work due to injuries sustained in a car accident. This is a separate pool of funds from the $20,000 no-fault has available for medical treatment, and you are entitled to both under any auto insurance policy in our state. Partial benefits are available to you if you can only return to work on a part-time basis. However, it is important to note that no-fault wage loss benefits only pay 85% of your gross income. The maximum weekly payment they will issue is $500, even if 85% of your gross income is higher than $500.\n‚Ä¢ Proof of wage loss: If you're worried about a shortfall in your income based on the limits of what no-fault can pay, your personal injury attorney can help you make up that difference. With proof of wage loss from your employer and documentation from your doctor stating that the leave is necessary, the shortfall in your income can be addressed in your bodily injury claim against the at-fault driver. It will be factored into the total damages your attorney presents to the liability insurer. Your personal injury attorney will go to bat for you to get every dollar you are owed when it's time to negotiate a settlement or go to trial.\n‚Ä¢ Pursue recommended treatment: All this being said, it is crucial that you give yourself the time and care needed to heal from your injuries. In order for your attorney to make a persuasive case for the severity of your injuries, you need to pursue all the treatment your primary care team recommends and take leave from work as they deem necessary. This is the best way to illustrate the extent of your injuries to the insurance companies. Of course, that's a daunting prospect‚Äîtreatment takes time and energy that many of us don't have to spare. For instance, a recommended course of physical therapy may be 2 sessions per week for 10 weeks and might only be available during normal business hours. It's important to know that you may be entitled to wage loss compensation for the time you take from work to go to appointments for accident-related care. Your attorney can help you document the time and mileage to request reimbursement.\nThere are a few other less-common situations that may apply to you as well. If you're an injured small business owner and you must hire substitute employees to step in, that is also an expense you may reimbursed for‚Äîup to $500 a week. If you were receiving unemployment benefits at the time of the accident and lose eligibility because of losing the ability to work, you are eligible to receive no-fault wage loss benefits matching your previous unemployment rate. This would also max out at $500 a week.\nThe prospect of losing income can make it seem impossible to heal from your accident AND stay afloat financially, but Minnesota state law requires automobile insurers to provide certain benefits to anyone injured in an automobile accident, regardless of fault. The processes are not always straightforward, but your personal injury attorney is here to help you navigate them so you can focus on your recovery and healing.\nIf you have been injured in a car accident and have questions about what benefits you are entitled to through your no-fault benefits, please call for a free consultation. I would be happy to discuss your concerns. At Lord + Heinlein, we are your powerful legal voice.","Can Seasonal Workers Apply for Workers‚Äô Compensation in Georgia?\nMost people think that seasonal workers aren‚Äôt eligible for workers‚Äô compensation. For some reason, a lot of people confuse workers‚Äô comp with unemployment. The two are completely different things.\nUnemployment is benefits you receive if you lose your job. You pay into unemployment. A portion of your wages are taken out each week to cover your unemployment insurance. Unemployment is also paid to you through the State of Georgia. Your employer does not pay your unemployment.\nWith workers‚Äô comp, it works a little bit differently. You don‚Äôt apply for workers‚Äô comp through the state. You apply for these benefits through your employer. And, unlike unemployment, you don‚Äôt pay into workers‚Äô comp. Your employer has to maintain insurance for employee injuries and illnesses.\nBecause your employer pays for this insurance, it costs them money when employees file claims. This is why they‚Äôre not always so quick to pay them. They also hate to pay out claims on workers they only have for a few months a year.\nJust because you work seasonal jobs, doesn‚Äôt mean you‚Äôre not entitled to workers‚Äô comp. If your claim has been denied, you need to contact an experienced workers‚Äô comp lawyer in Atlanta.\nSeasonal Workers Must Still Meet the Criteria for Workers‚Äô Comp\nNo matter what kind of worker you are, in order to get workers‚Äô comp benefits, you need to meet certain requirements. These requirements are the same no matter where you live.\nIn order to be eligible for workers‚Äô comp, you must meet the following requirements:\n- You were on the clock at the time of your injury\n- if you‚Äôre a salaried employee, you got hurt during the course of your employment\n- You weren‚Äôt under the influence of alcohol or drugs at the time of your injury\n- You reported the injury per your company‚Äôs policy\n- You weren‚Äôt horsing around at the time of your accident\n- You didn‚Äôt intentionally get injured\n- You didn‚Äôt suffer your injury outside of work\n- You agree to a drug test following your injury\n- You are treated by a company approved doctor\n- You comply with all treatment recommendations\nThis may seem like a lot ‚Äì and it is. Employers want to make sure you really sustained your injuries while on the job. They don‚Äôt want to pay for medical care or replacement wages if your injury occurred on personal time.\nWhat Benefits are Seasonal Employees Entitled to in Atlanta?\nSeasonal employees are entitled to the same benefits as everyone else. If you‚Äôre a seasonal employee and get injured at work, you are entitled to the following benefits:\n- Medical Benefits\n- Temporary Total Disability ‚Äì If you‚Äôre unable to work, you‚Äôre entitled to receive these benefits. In Georgia, you‚Äôll receive 2/3 of your average weekly wages. These benefits last for either 400 weeks or until you‚Äôre ready to return to work ‚Äì whichever comes first.\n- Temporary Partial Disability Benefits ‚Äì If you‚Äôre unable to earn as much as you did before your injury, you may be eligible for these benefits. This is for people who end up on light duty, part-time hours, or a lower-paying position as a result of their work injury. You‚Äôll receive 2/3 of the wages that you‚Äôre losing. These benefits will last for up to 350 weeks or until you return to your prior position and pay.\n- Permanent Partial Disability Benefits ‚Äì If you end up having a certain part of your body totally and permanently injured, you may get these benefits. You‚Äôll receive a certain number of weeks depending on the body part you injured.\nYour workers‚Äô compensation lawyer in Atlanta will work hard to make sure you get the benefits you‚Äôre entitled to. If your injuries cause permanent disabilities, you can count on your lawyer to make sure you‚Äôre taken care of.\nWhile there‚Äôs no law that says you need a lawyer to handle your workers‚Äô comp case, it‚Äôs a good idea to have one. They‚Äôll negotiate with the insurance company on your behalf. They‚Äôll also make sure your claim is handled properly.\nContact an Experienced Workers‚Äô Comp Attorney in Atlanta, Georgia\nIf you or your spouse are a seasonal worker and get hurt at work, you‚Äôre entitled to workers‚Äô compensation. To make sure you get the benefits you‚Äôre entitled to, call and speak with a skilled workers‚Äô comp lawyer in Atlanta right away.\nCall Workers‚Äô Compensation Lawyer Coalition today and schedule your initial consultation. It‚Äôs absolutely free and you pay nothing until you settle your case. Your employer will have a team of lawyers working for them. Make sure you have one working for you.\nShare this article:"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:045c6e04-3fe3-4299-a7b3-71b304e246f9>","<urn:uuid:5b20c754-5785-41ca-995e-64d98b6311dc>"],"error":null}
{"question":"How do the roles of a seonjisik (Korean Buddhist teacher) and a Karma Kagyu lama compare in guiding meditation practitioners?","answer":"Both seonjisik and Karma Kagyu lamas serve as essential guides for practitioners, but with some distinctive approaches. A seonjisik is described as being like a boatman who ferries one across difficult waters or a guide through strange roads, helping practitioners navigate various favorable and unfavorable conditions. They are particularly crucial in Seon practice for helping students achieve enlightenment through hwadu investigation. Karma Kagyu lamas, on the other hand, follow what's called the 'bee and flower' method, where students (like bees) come to the teacher (the flower) for nourishment and instruction as needed. They guide students through progressive stages of practice, from basic Shinay meditation to advanced practices like Mahamudra, while allowing students to largely direct their own pace and involvement in the practice.","context":["A good master is called a seonjisik (teacher/one of good knowledge). A teacher is like a boatman who ferries one across a river or a guide who leads one along strange roads. If one tries to go on an unfamiliar and strange road, one can come across unexpectedly steep or windy paths, or sheer precipices and rough waters. The road of seeking the way to enlightenment is the same. If one tries to practice, one encounters various favorable and unfavorable environs, and at such times one needs a clear-eyed master, a teacher.\nSeon Master Boshan Wuyi (1574-1630) describes the meeting with a teacher in his Canchan jingyu as follows:\nThe teacher is like a fabulous doctor who nimbly cures severe illnesses, and is like a great donor who can give to his heart‚Äôs content. A practitioner must never have the attitude of being completely satisfied with his own study and not try to meet a teacher. If one is captured by one‚Äôs own opinions and do not try to seek a teacher, there will be a great illness in one‚Äôs Seon practice, and so one must clearly know there is no worse illness than this. (Canchan jingyu 19).\nEven though born as a careful person and having encountered the Buddha-dharma, if that person has no master to guide him towards enlightenment, that practitioner, even if he has ended all the sufferings, not only can he not reach his destination, but also if he makes the slightest error, he can lose his life before he can reach his destination. Therefore, although it is the same with other practices, in the practice of Seon especially one must meet a good teacher and enter through the correct path so that one can be enlightened.\nIf one reads Seon recorded sayings, many processes in which the student meets with a teacher and is awakened are introduced. The meeting of the Seon master and the practitioner, as it is the point that is linked to the enlightenment, at times achieves the core stage of Seon practice.\nThe Sixth Patriarch Huineng tossed up the question, ‚ÄúDo not think of good; do not think of evil. Just then, what is your original face?‚Äù at the monk Huiming who was chasing after him. Hearing these words, Huiming was enlightened then and there and became Huineng‚Äôs disciple, and he changed his Dharma name to Daoming.\nThe role of a good master, an excellent teacher, is so important. Practitioners of meditation must believe in and depend on the teacher.\nThe generations of Seon masters have investigated the hwadu given by their masters, and when their bodies and minds had become a mass of doubt, when they met a certain opportunity, they were enlightened. Here the most important thing is said to be the master making the practitioner produce an earnest doubt. Without solving the problem one gives rise to an unendurable, burning thirst and is made to take up the hwadu. Therefore Seon Master Xiangyan was moved to tears, saying, ‚ÄúMaster, the kindness you have given to me surpasses that from my parents.‚Äù Seon Master Linji, who venerated two masters, Huangbo and Dayu, and was enlightened by them, in this way stressed this kindness:\nAt a blow of Dayu‚Äôs staff I entered the realm of the Buddha. This deep kindness, even if my bones were ground up for a hundred eons and my body broken, and I bore Mt Sumeru on my head round and round, would be difficult to repay. (Zutangji).\nIf one cannot meet a good master\nIf one cannot meet a good teacher despite much effort, one must cherish the earnest thought of establishing the motivation to seek a teacher. If one does not change one‚Äôs mind about earnestly seeking a master, then at some time one will meet a good master. Monks in the past, without knowing who is a teacher and who is a person (seeking) the Way, made a vow to earnestly find a teacher, and so constantly confessed that at a certain decisive moment they were able to meet a teacher.\nThere also were practitioners who venerated the life of the Buddha and the Dharma of the Buddha as their master and proceeded on the path of seeking the Way. The life of the sons of the Buddha and the life of practitioners is to actualize the life of the Buddha. For that reason, practitioners had definite criteria that they had to follow in the career of the Buddha and his thought.\nIf it is difficult to discover a good master around one, the fall-back policy is possible by depending on masters of the past. In recent times, besides reading the recorded sayings, because now one can hear the physical voice of lectures recorded on tape, one can by oneself endlessly excite the indignation and initiation of mind through such Seon lectures.\nThe most important thing the practitioners have to rely on is not humans, it is the Dharma, and it is the kernels of what those words convey, and not the discriminative knowledge of cleverness, but the clear and transparent wisdom. And no matter who sees it, one must depend on the words of the universally valid and true scriptures as some criteria for understanding. When one looks at it in this way, beginning with the essential digest scripture in Seon, the Platform Sutra of the Sixth Patriarch, only the various recorded sayings of the patriarchal teachers are proper.\nWhat should be done when there is no teacher around to examine one?\nWhen there is no proper master in the vicinity, one must seek a bright-eyed master no matter how far away. In the past, practitioners left on distant paths to find a teacher.\nKorean monks also were willing to go over distant paths to find a teacher. Among Gyeongheo‚Äôs students there was a Seon Master Suwol. He practiced the Way at Cheonuen-sa Monastery on Mt Chiri (near south coast), and to find his master Gyeongheo, over a number of years he pursued his master and found him in the northernmost border region.\nAgain, in order to personally see Seon Master Suwol, who had a high reputation as a teacher at that time, the eminent monk of modern Korean Buddhism, Seon Master Geumo (1896-1968), was willing to travel over dangerous roads to distant Manchuria. This is because only a teacher can lead one well on the path of study. And so they went over distant roads and were willing to travel far in their search. Of course, for lay people it is the same. In order to encourage one‚Äôs mental resolution and to examine one‚Äôs study, one must have the proper guidance through the negotiation with the teacher.","|Step by Step: A Summary of the Karma Kagyu Tibetan Buddhist Path as Taught in America\n(By Kathy Wesley. Last revised 7.30.02)\nThe Practice Path of a Kagyu Buddhist\nA student usually begins with quiet sitting meditation, called Shinay in Tibetan and Shamata in Sanskrit. This practice calms the mind and makes it workable for further practice.When the student feels ready to seriously pursue the Buddhist path, the student requests a lama (teacher) to give the Refuge vow, the first formal ceremony of the Buddhist path.\nAfter taking Refuge, the student continues practicing Shinay and adds to his or her practice a set of daily prayers that keep the Refuge vow fresh and strong in their minds. This is a basic means of practice in the Hinayana (Individual Liberation Vehicle).\nWhen the student feels ready to deepen his or her meditation practice, they may ask the lama (or Meditation Instructor) to teach them compassion meditation, called Tong-Len in Tibetan. This meditation increases the student‚Äôs love and compassion for themselves and other beings, and opens the door to the Mahayana (Vehicle for the Liberation of All) teachings. Tong-Len also gives the student a powerful technique for working with afflictive emotions.\nAt any time along this path -- from their first visit to the meditation center until they take Refuge and then afterward -- students may attend sessions of Chenrezig meditation. This meditation of the Bodhisattva of Compassion (called Chenrezig in Tibetan, Kwan Yin in Chinese, and Avalokiteshvara in Sanskrit) also aims to increase compassion and train students in the altruistic motivation (called Jang Chub Sem in Tibetan, or Bodhicitta in Sanskrit) that is the heart of the Mahayana path. This meditation, which employs chanting and visualization, is also the introduction for students to the Vajrayana (or Diamond Vehicle), a series of trainings that help students accomplish spiritual awakening quickly.\nAfter taking Refuge, students can learn other mantra-based meditations, such as Green Tara, Medicine Buddha and so forth. These meditations focus on particular enlightened qualities -- the removal of obstacles for Tara, healing for Medicine Buddha -- and help students train in those qualities.\nEventually, students who wish to undertake the deepest meditation practice of the Karma Kagyu lineage, called Mahamudra, can ask the lama for instruction in the Mahamudra Preliminaries, called Ngondro. These preliminaries, which consist of guided meditations designed to purify negativities, increase awakened qualities, and seek the blessings of the lineage, take several years to complete, and help students create a powerful daily spiritual training regimen.\nAfter completing Ngondro, many other practices -- including lifelong mantra practices -- can be given to the student. These will be explained at the time when they are given.\nMany, though not all, teachers of the Karma Kagyu rely on a training process that some call the ‚Äúbee and flower‚Äù method.\nIn this metaphor for the teaching process, the teacher is the flower, and the student is the bee. When the bee needs nectar, it goes to the flower for nourishment. It takes away nectar, and when it is hungry again, it goes to the flower for more.\nIn the same way, students visit lamas, and get their instructions from that teacher. Then, they go home and practice what they are taught, returning to the teacher for clarifications and to remedy doubts about their practice.\nThis means the path is, in many cases, student-directed. Lamas may make practice suggestions -- and some even give practice-related ‚Äúhomework‚Äù to students -- but it is up to students to choose their teacher, and to decide whether to take on what has been suggested to them by their lama. If a student does not feel ready to take on a practice suggested by the lama, it is important for the student to say so immediately, so the teacher can be advised of the student‚Äôs intentions.\nTeachers want nothing more than for students to enjoy their practice and deepen their commitment to dharma, so students should make use of their teachers whenever they need to.\nLineage, Empowerments, and Samayas\nWhile many Buddhist teachers -- Tibetan, Chinese, Japanese and others -- visit America in any given year, it is important for a student to make a commitment to a particular lineage and set of teachers. Otherwise, the student‚Äôs practice will lack focus, and the student will not make satisfactory progress along the path.\nWhen you have the opportunity to take empowerments or teachings from lamas of other lineages, it is always best to ask your own lama for advice. When you take an empowerment or a teaching from a teacher, you forge a bond (called samaya in Tibetan) with that teacher and his or her lineage. The teacher may then expect you to maintain that connection by visiting him or her often or by taking further teachings with them or visiting their monasteries, etc.\nWhen you take a teaching or empowerment from a lineage master, you become part of that teacher‚Äôs lineage -- the ‚Äúnext in line,‚Äù so to speak, in that lineage. You then bear a responsibility to keep that lineage going.\nThat is why it is important to be very careful when choosing teachers and empowerments. It is not like choosing an evening‚Äôs entertainment -- it is choosing a direction for your spiritual path."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:3bf82075-c5fb-4a4d-af78-55a947995005>","<urn:uuid:b2016b69-623f-4ba1-a4c2-2f663ae774fb>"],"error":null}
{"question":"Âú®ÂÅöÂÆå chemical peel ‰πãÂêéÔºåÂØπ sun exposure ÈúÄË¶ÅÊ≥®ÊÑè‰ªÄ‰πàÔºüWhat are the post-treatment care requirements?","answer":"After a chemical peel, you need to avoid sun exposure as the new skin is more susceptible to damage and discoloration from sunlight. It is important to wear sunscreen every day and limit sun exposure as much as possible.","context":["A chemical peel is a skin-resurfacing technique where a chemical solution is applied to the skin to help remove the outermost layers of the skin.\nA specific peel is chosen to create a controlled injury to the skin. A healing process is created on the skin and the dead skin will eventually peel off subtly.\nThe different chemical peels are measured at different depths, meaning how many layers of surface skin it reaches. Your choice of chemical peel will depend on your desired results. The top layers of skin that regenerates afterwards is generally smoother, brighter, younger looking and less wrinkled.\nSkin peels are most commonly used for Face, Neck, decollete and hands.\nChemical peels are used to treat various skin conditions and concerns such as:\nThere are 3 main types of chemical peels:\nLight chemical peels are the most gentle type of chemical peel and can be used on all skin types. These peels can also be referred to as your superficial peel, as this treatment helps remove dead skin at the most outer surface layer. It may be used to decrease fine wrinkles, acne, skin tone and skin texture\nYou will see results from your first treatment and results will increase with repeated treatments.\nLight Chemical peels can be repeated every week for 6 weeks\nMedium peels are slightly more penetrating on the skin, almost causing a controlled second-degree burn. Thus reaching deeper skin layers than the Light peel. This type of chemical peel helps to remove skin cells from the epidermis and from portions of the upper part of your middle layer of skin. A medium chemical peel will show immediate results, and treats acne scars and uneven skin tone on a deeper lever compared to a light peel.\nMedium chemical peels can be repeated every 6 weeks\nA deep chemical peel penetrates several layers of skin. As a result they require longer recovery time. The deep chemical peel helps to remove skin cells from the epidermis and from portions of the mid to lower layer of your dermis. A deep Chemical peel can be recommended for deeper wrinkles and deeper scars. There will be a dramatic improvement in the look and feel after one treatment.\nDuring all healing periods after a peel, you will need to avoid sun exposure. It is important to wear sunscreen every day and limit sun exposure as much as possible. New skin is more susceptible to damage and discolouration from sunlight.\nDuring the treatment, a chemical solution is applied to the face which causes the damaged layer of skin to be removed.\nThe exact composition of the chemical peel depends on the issue and its severity. There are mild, medium and strong peels. They all can help with fine lines and acne and the strong ones are effective for deeper scars and wrinkles.\nThe results can be quite remarkable and long lasting (some up to 10 years).\nPeels for sensitive skin have to be discussed with a qualified therapist before the treatment is conducted."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:33547a54-0981-4b75-8264-a58baed77044>"],"error":null}
{"question":"What innovative approaches to cybersecurity infrastructure might organizations implement in the future, based on lessons learned from previous security assessments? Please outline the potential strategy.","answer":"Based on past experiences, future cybersecurity infrastructure should focus on implementing the CIS Controls as a foundational approach rather than investing in uncoordinated advanced tools. This strategy has proven that good 'cyber hygiene' is essential for building resilient cyber infrastructure. Key components should include asset tracking, configuration control, and control of administrative privileges. Organizations should first establish these foundational management disciplines before making tailored investments for organization-specific security issues and evolving threat patterns. This approach is more effective than large investments in advanced tools without coordination, as approximately 80% of cyber-attacks historically targeted improperly configured software.","context":["(June 2, 2016) ‚Äì During my initial months as CIO of the Air Force, I thought that our cyber security was pretty good. After all, the Air Force is a highly technical organization and a culture of security was pervasive in the military. My false sense of comfort was punctured by a couple of security penetration tests conducted against the Air Force by the National Security Agency (NSA). In short, they found systemic weaknesses in every area that they evaluated.\nMy initial reaction was one of disbelief. How could we be spending almost a billion dollars on cyber security tools and personnel and still have systemic weaknesses? It was clear that these findings were not the result of a lack of resources. I asked the NSA to advise me on where I should start in getting on a path to improved cyber security. In response to my request, NSA shared that approximately 80% of cyber-attacks targeted software that was not configured properly (i.e., software was not installed with protections enabled or up to date patches were not installed). This clearly was the place to start to improve cyber security in the Air Force.\nThe NSA‚Äôs input became the basis for an initiative to deploy a security-hardened version of Microsoft‚Äôs operating system on all desktops, laptops, and servers. We also implemented automated tools to ensure that all instances of the operating system were updated and patched properly. Fielding the hardened operating system on Air Force desktops and servers took about eighteen months, mostly due to the need to modify applications that had used now disabled operating system functions that were assessed to be a security risk.\nThe results of this project were enlightening. Deploying the hardened operating system and automated configuration management tools resulted in a significant reduction in security breaches. This result was expected. What was not expected, however, was the resulting increased operational availability (i.e., less down time) and significant reductions in cost of operations. These results were a huge ‚Äúaha‚Äù moment for me‚Äîimproved security can also be operationally beneficial and cost less.\nAn Air Force Colonel explained the results this way: ‚ÄúIf you establish standard configurations and you don‚Äôt tinker with them, the systems don‚Äôt break and don‚Äôt require much maintenance‚Äù. In this case, standard configurations and deploying appropriate automated support to ensure that configurations were kept current required far fewer personnel. Thus, we discovered that strong configuration management was not only a good security practice but was also a sound economic investment.\nOther large organizations have found that focused cyber security efforts can yield major improvements in security. In 2012, the Australian Signal Directorate found that implementation of just four controls mitigated at least 85% of cyber threats. In a parallel effort, a community consensus effort developed the Critical Security Controls (CIS Controls) that addressed approximately 80% of the most frequent attack patterns. The Controls have been widely adopted as a sound approach to address most common cyber security threats.\nExperience with implementing the CIS Controls has validated that so-called good ‚Äúcyber hygiene‚Äù is the necessary foundation for building a resilient cyber infrastructure. Many of the Controls, such as asset tracking, configuration control, and control of administrative privileges, can be readily seen as necessary systems and network management practices; you cannot secure a cyber environment without first establishing foundational management disciplines. Anomalous events (attacks) can be identified only if the behaviors of normal operations are well understood. Moreover, as I found with the Air Force implementation of a standard locked down Microsoft operating system, good hygiene can reduce costs in addition to reducing vulnerability to cyber-attacks.\nSo, what are the lessons that I have learned from these experiences. My experiences in the Air Force showed me that large investments in advanced tools and uncoordinated cyber security approaches do not necessarily improve security. Improvements in security require a solid and focused foundation such as implementation of the CIS Controls which makes it is possible to make significant progress by addressing a small number of areas, specifically those tied to the most frequent threat patterns. In addition, the foundation is a necessary prerequisite for tailored investments that target organization-unique security issues and evolving threat patterns. I will address this topic in a future"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:710ee345-34db-4987-99c5-b9b4f8579c88>"],"error":null}
{"question":"Why are ancient habitats considered impossible to meaningfully recreate within a human lifespan?","answer":"Ancient habitats cannot be meaningfully recreated because they contain extraordinarily complex assemblages that develop over centuries, including plants, animals, fungal mycorrhiza, bacteria, and other soil microorganisms and structures. This complexity develops gradually as new species arrive, become established, and create niches for other species to establish, forming what ecologists call a 'bottom up' trophic cascade.","context":["In Part 2 of this series of articles, Ben Kite explained how the concept of ‚Äòbiodiversity offsetting‚Äô came in to being as a potential answer to the failure of the planning system to stem the loss of biodiversity; he also discussed how it raised more questions than it answered. Here, in part 3, he examines how the weaknesses in biodiversity offsetting led to its downfall, and how its proponents have sought to address these when fashioning its successor.\nThe failure of ‚Äòbiodiversity offsetting‚Äô, as it was initially presented, to be welcomed into mainstream ecological practice, was in my view at least in part due to some rather awful high-profile examples of the concept being grossly misused. One well-respected ecologist wrote angrily in a widely read periodical for example[i], about two projects where perverse ecological outcomes were only narrowly averted, thanks to determined and informed opposition.\nThe first example was a project in Kent, where anticipated damage to a fantastically biodiverse complex of ancient woodlands, scrub and species-rich calcareous grasslands, collectively providing the exacting conditions required to support a very large population of Nightingales Luscinia megarhynchos, was proposed to be ‚Äòoffset‚Äô, mainly by some scrub planting in another County (on land that itself had other ecological value that could have been displaced). Why on Earth the proponents of this project thought that creating more of an already super-abundant habitat type, in a different County, might somehow be an adequate substitute for the loss of irreplaceable biological complexity, developed over great lengths of time, or that it might perhaps cause Nightingales to appear out of ‚Äòthin air‚Äô in the new location, I may never know.\nAbove: Nightingale ‚Äì in terminal decline? Photo ¬© Paul Sterry/Nature Photographers Ltd\nThe second example, in Oxfordshire, concerned an ancient, species-rich and unimproved (in the agricultural sense) wet grassland, that first had its value artificially deflated through misrepresentation in a biodiversity offsetting calculator, before insult was added to injury through the ludicrous assertion that a grassland of higher biodiversity value could somehow be created simply by sowing purchased wildflower seeds on an alternative area of arable land. As an ecologist who has been involved in several large-scale grassland restoration and creation projects and having struggled with the inherent difficulties this entails, I find the pretence in that particular claim astonishing. Biodiversity calculators are clearly vulnerable to misuse ‚Äì either through understatement of the value of what is being lost, or the overstatement of the value of what is being offered in their place.\nAbove: species-rich unimproved grassland. Photo ¬© Ben Kite\nNotwithstanding the above, and in fairness to the originators of ‚Äòbiodiversity offsetting‚Äô as a more formalised approach in the UK, they had always been clear that any application of the methodology should adhere to a number of important ‚Äòkey principles‚Äô. At least two of these key principles were conspicuously disregarded in the two wayward case studies outlined above.\nThe first principle that went unobserved, is that the so-called ‚Äòmitigation hierarchy‚Äô[ii] should always be followed. This forms the bedrock of every good ecologist‚Äôs approach to their work, if they are engaged in the business of ecological impact assessment. It holds that any impacts on important ecological features should be avoided first, if possible (e.g. by adjusting the development layout to enable something important to be retained), then mitigated (reduced ‚Äì for example by fitting directional cowls to lights to minimise light spill onto an important habitat), and finally only then compensated for, if it is not possible to reduce an impact to the point of insignificance. Compensation is provided by creating a new feature of ecological value to replace the one that could not be retained.\nCrucially, the mitigation hierarchy holds that the above steps should be applied in the order that they are listed. Biodiversity offsetting, of course, occurs where something has been lost or damaged as a result of development, so it is classed as ‚Äòcompensation‚Äô in the hierarchy ‚Äì i.e. the last resort. An ecologist should be able to demonstrate that they have exhausted any reasonably feasible opportunities at each preceding stage of the hierarchy.\nThe second key principle that went unobserved in the above case examples is that, by definition, biodiversity offsetting cannot be used to ‚Äòreplace‚Äô habitats that are in truth irreplaceable.\nIt is a basic principle of ecology that, broadly speaking, the older a habitat is, the more biodiverse it is likely to be. This is because as time passes new species arrive into a habitat, become established, and then themselves provide the ‚Äòniche‚Äô needed for other species to establish. A recently colonised plant species for example may provide a food source for several species of new invertebrate, which in turn then provide food for new birds (this phenomenon is known as a ‚Äòbottom up‚Äô trophic cascade). This cumulation of complexity produces habitats that are often described in terms of their uniqueness and antiquity as being the natural equivalent of cathedrals or castles ‚Äì and are often every bit as beautiful.\nThere are exceptions to the rule that antiquity is correlated with biodiversity, such as where a habitat has been impacted by abnormal negative influences, such as artificial fertiliser application (see Ben‚Äôs blog The Fat of the Land) that diminishes its ecological interest (these are known in technical parlance as ‚Äòstochastic events‚Äô); but in general, the principle holds good.\nIn view of the above, and of the fact that any land use change at all requires some existing features to be lost, the practice of ecological impact assessment has needed to develop ways to distinguish between features of high and low importance. Ecologists often refer to young, simple, common and easily replaced habitats as ‚Äòconstant natural assets‚Äô ‚Äì it may well be appropriate to compensate for the loss of such features through the process of biodiversity offsetting. Ancient habitats however, or those reliant on unique environmental conditions, such as a particular hydrological regime, simply cannot be meaningfully recreated, at least within a human lifespan. Not even the most skilled ecologist could possibly replicate the extraordinarily complex assemblage of plants, animals, fungal mycorrhiza, bacteria and other soil microorganisms and structures that develop over centuries in an ancient woodland or grassland, for example.\nAbove: Ancient woodlands like the one pictured here, has antique habitat features such as veteran trees, standing deadwood rich in fungi, beetles and other invertebrates, and a richly woven carpet of ground flora comprising slow-colonising species such as Bluebell and Wild Garlic, as seen here. Once lost it cannot be replaced once lost. Photo ¬© Ben Kite\nEcologists sometimes refer to such habitats as ‚Äòcritical natural capital‚Äô, and the originators of biodiversity offsetting always intimated that such places should occupy a somewhat sacrosanct status that exempted them from being ‚Äòoffset‚Äô. Again, this key principle was somehow overlooked in the two case examples outlined above.\nClosing the Loopholes\nAs momentum behind biodiversity offsetting began to stall in the wake of cases like those mentioned above, and in the face of growing professional and public disapproval, the proponents of biodiversity offsetting evidently set to work behind the scenes closing some of the more egregious loopholes that had been exploited in their process.\nA herald of what was to come appeared in July 2018 when the Government‚Äôs National Planning Policy Framework (NPPF) was overhauled. Two discrete changes were made during this update that went unnoticed by many and which, without hindsight, might have seemed only tangentially relevant to biodiversity offsetting as a methodology.\nThe first change was that the previously stated objective of achieving ‚Äòno net loss‚Äô in biodiversity (see Part 1 of this article), was replaced by new text (paragraph 170(d)) stating:\n‚ÄúPlanning policies and decisions should contribute to and enhance the natural and local environment by‚Ä¶.minimising impacts on and providing net gains for biodiversity‚Ä¶..‚Äù\nAlthough similar wording existed in the previous (2012) version of the NPPF, the words ‚Äúif possible‚Äù followed; effectively making the requirement for biodiversity net gain aspirational rather than mandatory. The change made in 2018 thus raised the bar, as development was now expected to provide an overall enhancement to the natural environment.\nThe second change concerned the treatment of ‚Äòirreplaceable habitats‚Äô (regarding the second key principle I outlined above). The original text of the NPPF required development causing the ‚Äòloss or deterioration‚Äô of such habitats to be refused ‚Äú‚Ä¶unless the need for, and benefits of, the development in that location clearly outweigh the loss..‚Äù. This caveat left it open to a decision maker to decide, on a purely subjective and perhaps uninformed basis, that a development was more beneficial than the irreplaceable habitat it sought to remove. The second change in 2018 to the NPPF (paragraph175(c)) tightened up on this caveat, requiring such justifications for the loss of irreplaceable habitats to now be ‚Äúwholly exceptional‚Äù. An example of the sort of project that might fit this description was also given as being a ‚Äúnationally significant infrastructure project‚Äù.\nAlthough this change does not entirely close the second of the two loopholes identified above, and regrettably appears designed to enable exemptions for the Government‚Äôs own flagship projects, it does nonetheless make it harder for the average development proposal to justify impacting an irreplaceable habitat.\nNotwithstanding these positive changes, it ought to be noted that both the original and revised versions of the NPPF specify that ecological impacts should be addressed through the ‚Äòmitigation hierarchy‚Äô, in accordance with the first of my key principles mentioned above\nThis fact did not of course stop the proponents of the two wayward projects mentioned above from overlooking this expectation. What it did do, however, was enable informed opposition to highlight the resultant non-compliance with policy, and in so doing prevent those proposals from achieving consent. To me, this emphasises the reliance of the planning system upon the intervention of informed individuals, be they professional ecologists or otherwise, in reaching satisfactory outcomes. A key potential danger of biodiversity metrics or calculators therefore, is that they can provide the illusion of robustness ‚Äì as if the spreadsheet one is looking at can somehow replace expert ecological knowledge.\nIn the next and final article in this series, I will introduce the successor methodology to ‚Äòbiodiversity offsetting‚Äô that followed on from the above policy amendments ‚Äì a process that is now branded as ‚ÄòBiodiversity Net Gain‚Äô (BNG). I will explain how it differs from its first incarnation, and offer my thoughts on its prospects for making a positive difference.\n[i] Woodfield D (2018) ‚ÄòBiodiversity Accounting‚Äô ‚Äì a tool for transparency or for dumbing down?. British Wildlife. December 2018 pp117-120.\n[ii] Chartered Institute of Ecology and Environmental Management (CIEEM, 2018) Guidelines for Ecological Impact Assessment in the UK and Ireland: Terrestrial, Freshwater, Coastal and Marine."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:48b124f1-ccb1-41e3-99f8-4d0b4b9dc83c>"],"error":null}
{"question":"Could you compare the environmental quality standards between Woolwich Healthy Communities' guiding principles and the Living Building Challenge's certification requirements?","answer":"Woolwich Healthy Communities aims to create a clean, green township by improving soil, air, and water quality in rivers, streams and wells, and preserving woodlands, wetlands, and wildlife habitats. The Living Building Challenge has more specific technical requirements through its Water and Health Petals, requiring net zero water usage, on-site stormwater management and wastewater treatment, and high air quality standards in occupied spaces. Both frameworks emphasize environmental preservation, but LBC sets more rigorous, measurable standards as evidenced by only five buildings nationwide meeting its requirements, while WHC provides broader guidelines for environmental improvement at a township level.","context":["Coming together is a beginning; keeping together is progress; working together is success.Henry Ford\nThe Seven Circles -- Guiding Principles\nThe original seven circles concept was created by Dr. Trevor Hancock, who was instrumental in the creation of the international Healthy Cities/Communities movement. Dr. Hancock and D‚ÄôArcy Farlow facilitated a visioning workshop in Woolwich, which lead to the creation of Woolwich Healthy Communities (WHC) in 1991.\nWHC embraced the health-environment-economy model as it shows the crucial links between health (or social wellbeing) and environmental and economic wellbeing. We adapted the content to reflect the determinants of health in our community and as a summary of our Guiding Principles (link to the principles). The intent is that the circles can serve as quick reference for reflection\nwhen making decisions, to better ensure that the potential impact of the decision for the health and well-being of the community are considered. The WHC circles diagram (above) was presented to Council and senior staff of Woolwich Township who also participated in a group \"Visioning\" that included a practical application fostering productive dialogue amongst community leaders.\nWoolwich Healthy Communities Guiding Principles\nThis group of questions should be used in making decisions. They are meant to be used together. Each question is equally important. They are not listed in any particular order.\nIs this decision/plan likely to:\nBuild a Feeling of Community?\nCreate more opportunities for friendly interaction and neighbourly support among people in Woolwich Township? Support churches, service organizations, neighbourhood groups, cultural activities? Promote interaction among individuals living in the Township?\nGive Voice and Choice?\nEncourage all those affected, including people often left out, to participate in making decisions that affect them? Increase people‚Äôs capacity to choose what‚Äôs best for them?\nProvide opportunities for people to pursue farming, either full-time or part-time and/or pursue other agriculture-related activities for pay or leisure? Increase the amount of food produced and available for purchase within the Township?\nSupport Local Business?\nIncrease the quality and quantity of products and services made available to Township residents by local businesses? Increase locally available employment opportunities that include fair wages and safe and healthy working conditions? Help bring sustainable business opportunities to Woolwich Township?\nTreat Waste as a Resource?\nPromote the 5 R‚Äôs by ‚Äì Re-using local resources as much and as many times as possible? Reducing the amount of waste going to landfills and other waste disposal outlets? Recycling what cannot be reused? Replacing what has been taken (e.g. agricultural lands), so that the amount of local resources is not being diminished? Use waste products or waste treatment processes for Replenishing resources that have been damaged or degraded?\nImprove Community Amenities?\nPromote public transit, bicycle use and other non-car modes of transport? Make main streets, byways, trails and neighbourhoods safe, healthy and attractive ‚Äòpeople places‚Äô? Provide good housing to people of all income levels? Ensure that people have good access to shops and stores where they can buy basic necessities?\nImprove the Quality of the Environment?\nCreate a clean, green township? Improve soil, air and water quality in rivers, streams and wells? Preserve and maintain woodlands, wetlands, river edges, habitats and corridors for wildlife and wild plants? Encourage environmentally sound practices by businesses, industries and individuals?\nProvide for People's Basic Needs?\nChange people‚Äôs capacity to provide for their own basic living requirements? Give access to ‚Äì adequate food, clothing and shelter, clean water, soil and air, educational opportunities, assistance with care for dependent or ill family members? Provide sources of productive, safe and satisfying work with an adequate income?\nHonour the Past, Safeguard the Future?\nPreserve and maintain cultural resources, including rural landscapes, wildlands, buildings and street scapes that connect people to their history and to local cultural heritage? Consider the needs and interests of future generations, so that quality of life and choice for our children‚Äôs children is assured?\nLooking to explore how the decision-making diagram might be useful to your group?","Amazing Space is Indian Creek Nature Center‚Äôs building and campus that opened in September 2016.\nOur building provides endless opportunities for exploration and discovery, and serves as your gateway to the beautiful natural world outside its doors. Relax in the Bird Room, explore at the interactive watershed table, see how much energy the solar panels are producing at the Energy Portal, and pick up some raw honey or maple syrup in our Creekside Shop.\nAmazing Space is not only beautiful, it‚Äôs one of the most environmentally sustainable buildings in the world. As of September 2019, three years after its grand opening, Amazing Space achieved Living Building Challenge Petal Certification ‚Äì a rigorous certification that is years beyond LEED in providing a measure of true sustainability.\nWhether you come here to hike our scenic trails, see a concert in the amphitheater, participate in a yoga class, or to let your children play in the outdoor classroom, we know you‚Äôll want to come back again and again.\nTake a virtual tour of the space below, and then come see it for yourself!\nAs Indian Creek Nature Center set out to create a new facility, we faced a dilemma. How could we design a building and site that comprehensively expanded our mission of sustainability? Long a leader in energy efficiency and runoff prevention design and technologies, the Nature Center is taking the next bold step. It has accepted the Living Building Challenge.\nLiving Buildings don‚Äôt just push the envelope for sustainable design. Those who meet the challenge-and there are only five throughout the country that currently do-break through the barriers of conventional building practices and the standards set by other sustainable initiatives, including the U.S Green Building Council‚Äôs Leadership in Energy and Environmental Design (LEED) rating system. Living Buildings create synergy between nature and the built environment, between individuals and the community, and between current design and future energy use.\nThe challenge is simple, but the standards are high. The Design Team must find creative and innovative solutions to meet the twenty imperatives set by the Institute that are appropriate for the project and region. The solutions the team develops will be a resource for the environment, the community and the future.\nThe Seven Petals of the Challenge:\n1) Site-restoring a healthy coexistence with nature\n- Limits to Growth-construction is limited to appropriate locations, reducing sprawl.\n- Urban Agriculture- integrate agriculture opportunities into the site.\n- Habitat Exchange-an area equal to the amount of land developed for the project is permanently protected.\n- Car Free Living-encourage walking and biking.\n2) Water-creating water independent sites, buildings and communities\n- Net Zero Water-capture and use precipitation.\n- Ecological Water Flow-manage storm water and treat wastewater on site.\n3) Energy-relying only on current solar income\n- Net Zero Energy-create 100 percent of project‚Äôs annual net energy use on-site.\n4) Health-maximizing physical and psychological health and well-being\n- Civilized environment-occupied interior spaces will have operable windows for fresh air and daylight.\n- Healthy air-over the course of an operating year, building must meet high air quality standards.\n- Biophilia include the following design elements: environmental features, natural shapes and forms, natural patterns and processes, light and space, place-based relationships, and evolved human-nature relationships.\n5) Materials-endorsing products and processes which are safe for all species through time\n- Red list-materials or chemicals considered harmful by the ILBI are banned, including everything from Chlorofluorocarbons to polyvinyl chloride.\n- Embodied Carbon Footprint-purchase carbon offset credits to account for construction.\n- Responsible Industry-advocate for sustainable resource extraction and fair labor practices.\n- Appropriate sourcing-use local products and services.\n- Conservation and reuse-develop comprehensive Material Conservation Management Plan.\n6) Equity-supporting a just, equitable world\n- Human scale and human places-experience promotes culture and interaction, not vehicles.\n- Democracy and social justice-accessible to everyone, regardless of background, age, socioeconomic class, and physical disabilities.\n- Rights to nature-will not block access to other buildings‚Äô fresh air and sunlight, or restrict access to waterways.\n7) Beauty-celebrating design that creates transformative change\n- Beauty and spirit-create design features solely for human delight and celebration of place.\n- Inspiration and education-provide education and share the experience to motivate change.\nThe Sense of Wonder Trail, right next to the Indian Creek Nature Center barn, is a trail and playscape designed for children and adults to explore, discover, daydream, and play outdoors together as they connect with our earth.\nMedia & Marketing Archives\n- THE GAZETTE ‚Äì ICNC becomes one of 31 buildings in world to achieve Living Building Challenge Petal Certification\n- KWWL ‚Äì ICNC setting new sustainability standard for future building construction in Iowa\n- RADIO IOWA ‚Äì ICNC wins award for energy efficiency\n- KCRG ‚Äì ICNC receives Living Building Petal Certification\n- THE DAILY IOWAN ‚Äì ICNC becomes only building in Iowa to receive renowned certifcation\n- HIGH PERFORMANCE BUILDING MAGAZINE ‚Äì ASHRAE Award\n- PRESS RELEASE ‚Äì ASHRAE Award\n- GAZETTE EDITORIAL ‚Äì Nature Center‚Äôs Bold Plan Raises Bar on Sustainability\n- PRESS RELEASE ‚Äì Amazing Space to be World‚Äôs Only Living Nature Center\n- GAZETTE ARTICLE ‚Äì Indian Creek Nature Center Aims for Rare Sustainable Building Certification\n- PRESS RELEASE ‚Äì ICNC Selects Solum Lang for Architectural Design Services\n- PRESS RELEASE ‚Äì Indian Creek Nature Center Announces $6.9 Million Amazing Space Campaign\n- GAZETTE ARTICLE ‚Äì Cedar Wapsi Recreation Byway\n- PRESS RELEASE ‚Äì Amazing Space to Highlight Solar Powered Sustainability"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:ff1879b1-98a0-43f8-b9af-f5856166e12d>","<urn:uuid:5d2215b6-6cf3-4dc2-8eca-240bdbf827f8>"],"error":null}
{"question":"How do traditional village funeral practices maintain community bonds, and what modern challenges to food sustainability are they facing in urbanizing areas?","answer":"Traditional village funerals maintain community bonds through collective participation, as seen in how the entire village takes part in ceremonies like drum announcements that bring people from up to 1km away, communal decoration of the funeral car, and shared mourning rituals where women gather in groups to grieve. However, with 66% of the global population expected to live in urban areas by 2050, such community-centered practices face sustainability challenges. The increasing urban population creates unprecedented food demand, requiring new approaches like vertical farming since traditional agricultural land is limited. This urbanization threatens traditional community practices while creating pressure for more efficient food production systems.","context":["Indian Village Funeral: By Richard Clarke\nLast week in the village in which we live a woman died. She was the mother of a man we work with Ramesh, in the Quality of Life Trust. That afternoon we heard the drums, typical of such funerals, and Ramesh called us and asked us to join him. We walked about two hundred meters to the village and spent the next few hours there. We asked for permission to take photos, and some of these are in this article.\nAs we enter the village we see people gathered under an awning. The mother‚Äôs body is in the center of the group on her bed. People are gathered around the body grieving and paying respect.\nRamesh is sitting with the men. He‚Äôs in the middle.\nDrummers are important to the funeral. Their music announces the death to the village. After the drums start, people come from up to one km away to join in the ceremonies.\nOften the sexes are separated. Here naturally the women and men seem to select different areas to sit.\nMuch of the activity of the afternoon was in preparing the car that would take Mother to the crematorium. First a wood frame is built.\nThe village boys seeing the camera naturally want to pose for a picture. Here they are looking tough. We‚Äôll make some prints of this photo and give one to each boy.\nThey have started to decorate the car. Notice in the foreground bamboo sticks covered with flowers. These are bent and inserted into the frame for decoration.\nThe woman, grieving, would approach each other and stand and beat their chest in a gesture of mourning. Then they would get into a group hug circle and sink down into a squat. They would moan and cry together, swaying back and forth. This death was particularly painful to the village women. Mother was only in her mid fifties, young to die, even for an Indian village woman. She had had a hard life ‚Äì her husband died 15 years before and she had to support the kids without much help from anyone. Somehow she was able to send at least one of her boys, Ramesh, through college. Ramesh said that she was very sad though, due to her deep poverty, and especially do to the fact than none of her children were married, and she had no grandchildren.\nThe villagers are working on the decorations for the car. Here they are bending the flower-sticks and inserting them into the frame on the back of the car.\nNow they are adding the flower malas to the central frame on the car.\nDecorations are nearly done.\nAs new people join the funeral the drummers escort them in, and ‚Äòdrum them‚Äô into the group. Here a man is dancing as people bring puja items into the funeral.\nNow they start to prepare Mother‚Äôs body. They will clean up the body, re-dress her in a fine sari, then perform puja, before placing her body on the decorated cart.\nRamesh (second from left) is here helping prepare his mother.\nThe men are getting some puja items ready.\nWater for the puja is being poured. This was not only sprinkled onto mother, but onto the people in the crowd. They especially sought out Mother‚Äôs three children and made sure they got pretty wet.\nNow Mother is fully prepared. Such loving care was taken in this preparation. And this was something that almost everyone in the village took part in. Very much this was a village ceremony, not just something done by the family.\nMother was then carried to the car. I took part in this. She seemed so tiny, so light. She had been ill with cancer, supposedly, and stopped eating three months ago. Ramesh and his two siblings had taken her to several doctors for cures, and, as a last resort, took her to a ‚Äúmiracle shrine‚Äù when the doctors didn‚Äôt improve her health.\nNow the car is off to the crematorium. The drummers will lead the way, then the car and the mourners.","In case you haven‚Äôt noticed, the world‚Äôs population is drastically moving. In two directions: upwards and inwards. By 2050 we will need to feed 9.6 billion people. A whopping 133% more than today‚Äôs 7.2 billion and 2200 times as many mouths than the population of New Zealand right now. It‚Äôs moving inwards too. Today, more than half of us live in densely populated urban environments. By 2050 66% (or 6.3 billion) of us will. This means one thing. An unprecedented demand for food ‚Äì in urban areas.\nA scary thought, given food production and agriculture are already shockingly taxing on the natural environment ‚Äì and in many cases ‚Äì our health too. From water, energy and land use to the nasty issues surrounding fertilizers and pesticides, transportation and waste, conventional agriculture is far from earth friendly.\nSo it comes as no surprise that safeguarding global food security and sustainability for 9.6 billion people will mean doing more with less. And with the masses moving into our city centres, it will also mean doing things differently. Vastly differently. Especially when it comes to producing land and resource intensive (water and fertilizer) staples like horticultural land-based foods, including leafy greens, fruit and veggies. Because, while we can 3D print and bioengineer almost anything now (including the recently hyped Impossible Burger and other forms of juicy beef patties and protein alternatives made from real bovine or plant cells), one hard fact remains. We aren‚Äôt making any more land. And 3D printing can only go so far.\nMuch like the changing dynamics of our population itself, this will likely mean moving arable crop production inward (i.e. into urban centres) ‚Äì and more importantly upward (i.e. into the ether). Think high-rise urban indoor farming ‚Äì on a mass scale. A mixture of hydro, aqua and aeroponics ‚Äì and at lofty heights.\nSome serious food for thought for New Zealand‚Äôs largely pasture and rural based agricultural and horticultural sectors valued at over 7.6 billion dollars ‚Äì and nearly $4.3 of this export revenue (according to Industry publication Fresh Facts).\nData Science Meets Horticulture.\nIndoor (and vertical) farms are essentially highly controlled and automated multi-level growing environments that use a combination of software analytics, energy efficient LED lighting, sensor controls and closed loop moisture and nutrient recirculation systems to allow growers to monitor, nourish and grow plants like lettuces, greens and even fruit now using a fraction of ‚Äì or no- resources such as water, soil and environmentally dubious fertilizers and pesticides. All year round. 24 hours a day. No matter what season and without a drop of real sunlight in sight. Yes, the veritable disruption of traditional field ag as we know it. How will our Kiwi field growers cope with such significant technological and social change?\nAnd before you naysayers out there think the world‚Äôs city dwellers will revolt at such a sterile, technologically complex concept such as industrial food production, think again. We‚Äôve already seen how the ‚ÄúImpossible Burger‚Äù and Beyond Meat‚Äôs succulent meats range, including meatballs, patties and chicken strips are flying off the shelves in supermarkets throughout the States. Why would fruit and veg (which is actually the real thing) be any different? Something our traditional Kiwi horticultural farmers and the entire agricultural industry would be wise to take note of.\nThe arguments for high-rise farming are profound, to say the least. Indoor and vertical farming help to provide some very real and practical solutions to some of most pressing problems facing agriculture today, while being a highly profitable business model. And it‚Äôs happening already. In leaps and bounds.\nMirai, the world‚Äôs largest sensor-controlled hydroponic indoor vertical farm located in Japan, uses a closed nutrient recirculation system that requires 99% less water than traditional farming methods. Yes, 99% less. Spanning 25,000 square feet of vertical garden beds, its 17,500 energy efficient LED lights adapted with wavelengths to control the night-and-day cycle and accelerate growth mean highly productive and nutrient dense plants. 10,000 lettuces in a day productive ‚Äì all bacteria and pesticide free.\nAeroFarms and Green Sense Farms, two (of many) US based mass scale vertical farming companies making huge inroads in this emerging market are also yielding similar environmental benefits. AeroFarm‚Äôs custom UV light spectrums, endless patented growth algorithms and 30,000 data points monitored by plant scientists mean it is able to produce leafy greens, herbs and lettuces en mass, 24/7, using almost no traditional field inputs in sight ‚Äì including soil. ‚ÄúWe use about 95 percent less water to grow the plants, zero soil, about 50 percent less fertilizer as nutrients and zero pesticides, herbicide, fungicides,‚Äù says David Rosenburg, AeroFarm CEO and co-founder. ‚ÄúPlants don‚Äôt need soil, they need nutrients. And they don‚Äôt need sun, they need spectrum of light‚Äù. According to Rosenburg, plants receive the perfect amount of moisture and nutrients misted directly onto their roots in a completely controlled environment. Sacr√© Bleu!\nAnd Green Sense Farm‚Äôs two industrial-sized, climate-controlled growing rooms outside of Chicago (each equipped with seven 12-meter tall grow towers) have over 14,000 LEDs that require less climate control, use less energy and absolutely no GMOs. Its cool burning green LED production modules mean lights can be placed closer to the plants, allowing for more levels to be stacked and more bang for your energy buck.\nCritics of vertical farming worry that the energy use involved in such growing techniques might increase the carbon footprint by an order of magnitude. However, with the energy efficiency of LED lighting increasing exponentially, and as solar powered renewable energy is rapidly reaching mainstream in major markets globally, this trepidation might become redundant before we know it.\nIn world with a constantly growing base of discerning consumers concerned about environmental and sustainability impacts of the food they are consuming, how will Kiwi field farmers compete with such staggeringly impressive resource efficiencies?\nThe Sky‚Äôs your Limit\nBut if environmental benefits aren‚Äôt enough to convince you of the real value of vertical farming then the numbers probably will. According to Caleb Harper, principal research scientist for the Open Agriculture (OpenAG) Initiative and CityFarm at MIT‚Äôs Media Lab, 30-40% of our diet (including greens, tomatoes and capsicums) could be produced in urban or peri-urban environments in the very near future ‚Äì and it would be a lot better for us if it was.\nDubbed the ‚ÄúVegetable Factory‚Äù of Japan, Mirai‚Äôs completely automated (including humidity, temperature, CO2, and irrigation) multi-level system spanning half the size of a football field is already 100 times more productive per square foot than traditional methods.\nRosenburg says AeroFarm‚Äôs indoor leafy crops grow twice as fast as regular field seeds inside its controlled environment and the company has specifically designed customisable stackable modules to get even more greens per square foot. At 12 levels high, this means crop yields that are 75 times greater per square foot than traditional field methods annually. What‚Äôs more, AeroFarm‚Äôs newest operation built in Newark, New Jersey, spans 70,000 square feet (6,503 square meters) of growing space 30 feet high ‚Äì double that of its smaller (already productive) farms and leading Japanese competitors. ‚ÄúIt has the capacity to grow just under 2 million pounds of baby greens annually‚Äù says Rosenburg.\nSignificant vertical economies also allow companies like AeroFarms to spread out operational costs (like HVAC, lighting and rent) amongst a much larger product base as well as reduce the cost of goods sold to the end consumer. ‚ÄúWe sell at the same price that supermarkets buy from field farmers in the category of organics which is typically about a 20% premium‚Äù says Rosenburg. With layer after layer of thriving verdant greens sprouting day in ‚Äì day out, the company says it is already cash-flow positive.\nAnd Green Sense Farms‚Äô unique vertical stacking system in its 30,000-square foot (2,800 square metre) Chicago facility can distribute produce within 100 miles to over 20 million people. ‚ÄúAt capacity, we‚Äôre producing about three to four million pounds of fresh produce a year‚Äù says CEO Robert Colangelo.\nFigures not to be sniffed at by even the most productive of Kiwi growers. Such unheard of levels of food productivity (volume) using a relatively miniscule footprint of land will be a godsend when considering the 9 billion people we‚Äôll soon be having to cater for.\nWhat‚Äôs more, thanks to exponential improvements in robotics technology, Mirai and US vertical farms, including FarmedHere, along with AeroFarms, Green Sense Farms and Spread are also developing the technology to become robot-run farms devoid of human error. With Mirai already (human) hand harvesting over 10,000 heads of fresh lettuce, the mind boggles at just how many more greens these companies will be able to produce with robots in tow.\nTastebuds Gone Wild\nStill not sold? Controlled indoor farms (vertical included) ‚Äì also mean crops are protected from insects, diseases and aren‚Äôt exposed to brutal weather conditions like drought and flooding ‚Äì the bane of many farmers‚Äô existence ‚Äì making toxic chemical use and crop yield instability a thing of the past for growers. And for the consumer, this means healthy and nutritious food. Indoor farms like Aero, Mirai and Green Sense are entirely pesticide, herbicide, insecticide and fungicide free. Good news for health-conscious punters like me, since the last time I checked, no one wants to order a side of herbicide or chemicals with their salad.\nAeroFarms have taken this one step further by focusing as much on consumer nutrition as it does on low environmental impact. Greens are scrupulously macro & micro monitored for nutrient density, providing all the minerals and vitamins you could ask for. And the customers are lapping it up. Even top upmarket US restaurateurs, who would once have shunned the idea of buying indoor crops as part of their chic garden to table, local produce offerings, are sold on the stuff. ‚ÄúThey taste the way greens are supposed to taste, the way I remember them tasting as a kid. There‚Äôs a flavour profile and if you put them up against greens from another big supplier, there‚Äôs no comparison in the freshness factor and in visual appeal‚Äù says Steven Yglesias, owner of a popular restaurant in Newark‚Äôs Ironbound neighbourhood.\nNo Nasty Food Miles\nBut perhaps one of the biggest advantages of vertical farming, at least when it comes to feeding the urban masses, is that you can build an indoor farm anywhere and to whatever size and height you want (within city limits). Without a ray of sun or speck of fertile NZ soil in sight. The sky‚Äôs your limit ‚Äì quite literally. Mirai‚Äôs plant factory is located in an old semi conductor factory in eastern Japan‚Äôs Miyagi Prefecture ‚Äì close to masses of urban mouths. Green Sense Farm‚Äôs green bounty is grown beneath 30 foot ceilings in a leased warehouse centrally located in an industrial park 40 miles outside of Chicago, a massive food distribution hub. And AeroFarm‚Äôs 9th domestic facility (yes 9th!) was built in a nondescript former paintball and laser tag facility in Newark, NY.\nIt also opens up the whole ‚Äúbuy local and fresh‚Äù model to the masses, traditionally a luxury only for the higher income earning echelons of society. Consumers everywhere will soon be able to eat nutrient dense fresh produce without the food miles. ‚ÄúWhen we build a farm, we become a part of the local community, bringing new life, to old buildings and reducing transportation miles‚Äù says Rosenburg.\nWhich begs the million-dollar question for our ag industry: Why buy clean green Kiwi produce when you can buy local and environmentally benign alternatives with no food miles attached? With indoor farms being built inside of, or in the fringes of massive cities, the need to transport (what once was) fresh and highly perishable farm produce (often) thousands of kilometres to urban consumers becomes close to ZERO. A huge plus for consumers and the environment, given the Tesla of the trucking world and mass scale electric transportation logistics have yet to reach mainstream.\nMoreover, what happens to our horticultural exports altogether (to the tune of $4.27 billion plus in 2015) as companies like Green Sense and AeroFarms rapidly gain stronger footholds in the lucrative markets we sell into? Green Sense has already signed a partnership to operate 20 mass scale vertical operations in China. The first farm is set to produce 750,000 to 1 million heads of lettuce and about 1.5 million leafy greens per year.\nOf course, not all of New Zealand‚Äôs horticultural exports are leafy greens suitable for inner city high rises. We export far more palatable plant based goodness than this. But it does beg the question as to how such technologies and bioscience could potentially disrupt these profitable hort subsectors too, and in a way that could possibly erode all our field pasture competitiveness we have steadily worked on over time. Our vital export revenue mainstay may be given a hideous shake up. Whether we like it or not.\nWhere to for Kiwi growers?\nWith stats like this, it is clear that vertical farming could play a key role in helping to avert a looming global food and environmental crisis ‚Äì and one day become the future of agriculture. And with good reason.\nThe unheard of volume (productivity) of nutritious food that can be produced locally on the same footprint of land using a fraction of resources will be vital for feeding the 9 billion mouths we‚Äôll soon have to cater for. And for areas where extreme weather conditions and resource scarcity routinely threaten their agricultural livelihood (think the sub-Saharan Africa, Middle East, United States and Southeast Asia) indoor farming techniques will very likely rise to vertical heights.\nThe question New Zealand now needs to ask itself is: As agrarian outdoor growers, what is our role in this rapidly changing new indoor, urban food producing dynamic? Yes, vertical farming may presently have found a niche in producing smaller lightweight crops that don‚Äôt require a huge amount of indoor real estate, all of which affords our fruit and larger crop growers some breathing space. For now. But we all know how quickly technologies can develop to shake up the status quo and erode industries overnight. Do we need to shift our focus away from bulky crops ill-suited to indoor warehouses for the future, or should we focus on plant varietals that labs and technology simply won‚Äôt be able to mimic in an indoor setting? Do we need to be riding on the coat tails of indoor farming‚Äôs technological success by investing in similar operations and technology? Or does New Zealand need to give up the ghost completely, let go of our entrenched desire to be leaders in agriculture and focus on new industry development altogether?\nThe answers remain to be seen. But such questions are highly worthy of asking ‚Äì and planning for ‚Äì right now."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:8dd1d47a-bc1d-4bf6-8804-efd5b0b02e68>","<urn:uuid:f298393e-a09c-4ed1-9bf5-29662d9e86a3>"],"error":null}
{"question":"What were the three main social classes in European society during Charlemagne's time?","answer":"The three chief classes of society in Europe at that time were the priests, the lords, and the serfs or villeins. The lords or knights earned their estates through military service to the king or prince, while the serfs paid for their land and protection by working on the lord's estate and providing rent in the form of food and other useful items.","context":["Index Previous Page Next Page\nManors, Lords, and Serfs\nWhat was called the Feudal System was gradually being developed in Europe in the turbulent age of Charlemagne, as it had been developed in Egypt and in China ages before.\nThe chief classes of society in Europe at this time were the priests, the lords, and the serfs or villeins. The lords or knights paid for their estates by service in war to the king or prince, and the serfs paid for their land and protection by working on the lord's estate and giving him rent in kind -- that is, food and other useful things.\nSome of the great emperor's decrees or laws still remain, and one of these gives a very lively picture of the life on the estates or manors. Throughout western Europe the land was gradually, and at different times, divided into these manors, with their great, open, hedgeless fields, farmed by the peasants working together as a community. And this old method of farming continued for a thousand years or so -- till the land was \"enclosed\" within hedges, and new methods of farming introduced in the eighteenth century. Today all that remains of the old system in our own country are the \"commons,\" which here and there survive in our villages.\n\"We desire,\" decreed Charlemagne (about 800 A.D.), \"that each steward shall make an annual statement of all our income, giving an account of our lands cultivated by the oxen which our ploughmen drive, and of our lands which the tenants ought to plough; of the pigs, of the rents, of the fines; of the game taken in our forests, without permission; of the mills, of the fields, of the forests, of the bridges and ships; of the freemen, and the districts under obligations of our treasury; of markets; vineyards, and those who owe wine to us; of the hay, firewood, torches, planks, and other kinds of lumber of the waste lands; of the vegetables and millet; of the wool, flax, and hemp; of the fruits of the trees, of the nut trees, larger and smaller; of the grafted trees of all kinds, of the gardens, of the turnips; of the fish-ponds, of the hides, skins, and horns; of the honey and wax.... They shall make all these known to us, set forth separately and in order, at Christmas, so that we may know how much of each thing we have.... Each steward shall have in his district good workmen -- namely, blacksmiths, a goldsmith, a silversmith, shoe-makers, turners, carpenters, sword-makers, fishermen, soap-makers, men who know how to make beer, cider, and perry, and other kinds of liquor good to drink, bakers to make pastry for our table, net-makers who know how to make nets for hunting and fishing; and other sorts of workmen too numerous to be named.\"\nThe details of this document remind us of the Great Survey of the English manors recorded in Domesday Book by William the Conqueror's directions, more than two centuries later.\nWhen Charlemagne died (814) his unwieldy empire broke up. Gradually France and Germany became separate, and were taking roughly the geographical position they have today. Between them there was a large middle-land; stretching from the North Sea to the Alps, the struggle for which has troubled the peoples of Europe all through the ages, especially France and Germany; and Alsace-Lorraine, which figured in the recent great World War, was a part of this middle-land.\nThe crown of the Holy Roman Empire passed to a German prince, Otto the Great (962). Germany was to suffer for centuries for its close and troubled relations with Italy and Rome. Indeed, neither Italy nor Germany became nations till the nineteenth century, whereas France and England were soon to pass out of all connection with the Holy Roman Empire along the path to nationhood."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:e5604194-1e95-47a8-8681-94f4283112dd>"],"error":null}
{"question":"Hey there! I'm curious about jazz history in Washington D.C. - both its glory days on U Street and the challenges it faces today. Can you tell me about how U Street became 'Black Broadway' and what's happening to jazz venues there now?","answer":"U Street earned its nickname 'Black Broadway' during the early 20th century when Washington D.C. became the social and cultural capital of Black America. The area was anchored by venues like the Howard Theater (built in 1910) and Lincoln Theater (1921), which served Black audiences during segregation. The Howard Theater was actually the first known theater built specifically for Black audiences in the country. However, this cultural scene was severely impacted by the 1968 riots following Martin Luther King Jr.'s assassination. Today, while remnants of this jazz history remain through murals and buildings like the Ellington apartment complex, the jazz scene faces significant challenges. Many historic venues have closed, including Bohemian Caverns, Cafe Nema, and HR-57. Contemporary musicians are struggling to maintain the art form, as venues find it cheaper to hire solo DJs than full jazz groups. Musicians are now seeking help from the D.C. government and institutions, lobbying for subsidized artist housing and incentives for venues to host live music.","context":["Ira Aldridge was a teenager discovering his love of theatre before becoming the first of his kind to be known internationally. William Henry Brown established a theatre before writing what many considered to be the first play of its kind. James Hewlett was a tailor by trade before becoming the first of his kind to star in a one-man show. These prominent Black men, during the early part of the 19th century, played a pivotal role in shaping America‚Äôs Black Theatres, especially in Washington, D.C.\nThe history of this movement in the district was a topic briefly mentioned during a discussion last night at the Historical Society of Washington, D.C. (HSW) on K Street NW. The event, ‚ÄúTheatre District: How Washington, D.C. Became a National Stage for the Performing Arts,‚Äù was a look at how the city evolved into ‚Äúa theatre-Mecca second only to New York City,‚Äù according to HSW Executive Director Sandy Bellamy.\n‚ÄúThere are scores of dance, choral music, instrumental music and opera companies in our midst,‚Äù said Linda Levy Grossman, moderator and president/CEO of the Helen Hayes Awards, which honors professional theatre in the Washington, DC metropolitan area. But Monday night‚Äôs discussion, the first of HSW‚Äôs fall programming, was to focus solely on theatre.\nKicking off a brief overview of the city‚Äôs history was an 11-minute video titled ‚ÄúAgain and Again: The Legacy of Washington Theatre.‚Äù According to the film, the city‚Äôs first playhouse was a bare room inside a hotel on E Street NW in the early 1800s. Two new playhouses ‚Äì featuring ‚Äúeverything from acrobats to the finest classical actors from both sides of the Atlantic‚Äù‚Äì were constructed in 1804 and 1822 to accommodate growing audiences. And in 1835, the National Theatre opened three blocks from The White House on Pennsylvania Avenue.\nFollowing its opening, the building was destroyed by fire and rebuilt on the same site five times during the 1800‚Äôs, according to nationaltheatre.org. In the time preceding the Civil War, opera houses and music halls dotted the downtown area. After the war, the city underwent another transformation. Between 1885 and 1915, 37 new theatres opened in a block bordered to the south by 9th Street, to the east by Pennsylvania Avenue, to the north by 15th Street and the west by New York Avenue. And while this enlivened, six-block theatre district was created downtown, an area known as ‚ÄúBlack Broadway‚Äù was taking shape uptown.\nAt the time, Segregation forced African Americans nationwide to establish their own organizations and institutions as a way of supporting their lifestyles. And thanks to William Henry Brown, a West-Indian born U.S. theatre producer and playwright, African-American artists also had a blueprint for establishing their own playhouses. ‚ÄúAs it happens, African-American theater flourished as early as 1821,‚Äù writes Heidi Weiss in a September 2006 Chicago Sun-Times article. That same year, Brown, a retired steam ship steward, created the African Grove from ‚Äúa little tea garden and cabaret‚Äù behind his house in lower Manhattan. African Grove was the first of its kind to allow an all-black casts to perform plays originally written for White actors, which included Shakespeare‚Äôs Richard III and Othello.\nThe company‚Äôs productions soon became a popular diversion with White audiences, which started a rivalry ‚Äúbetween this small theater and Stephen Price‚Äôs Park Theater,‚Äù according to a web lecture on the African Grove Theater. As the story goes, Brown rented a hall right next to the Park Theater for performance of Richard III after being ousted from his house on Thomas Street. Brown‚Äôs production coincided with the Park Theater‚Äôs presentation of the same play. According to the online lecture, ‚ÄúStephen Price hired a mob to stage a ‚Äòriot‚Äô and had the police shut down the African Grove performances.‚Äù Laura Blanchard, vice chair of the American Branch of the Richard III Society, writes on the organization‚Äôs Web site that the African Grove moved to Mercer and Bleecker streets on October 1. The company was again forced to close down in 1823. That same year, Brown wrote The Drama of King Shotaway, the first African American play to be written and produced in the United States. The play is based on a Black Carib revolt on the island of St Vincent in 1796 against both English and French settlers.\nDuring the time of African Grove, Brown‚Äôs company produced two notable actors: James Hewlett, the first African American Shakespearean actor, and Ira Aldridge, a teenager at the time. According to blackpast.org, an online reference guide to African American History, Hewlett and Aldridge honed their skills ‚Äúwhile sitting in the balcony of Stephen Price‚Äôs landmark Park Theatre observing the acting styles of European transports in Shakespearian plays.‚Äù\nBorn 1778, James Hewlett‚Äôs education of theatre came from following behind British actor George Frederick Cooke as a servant boy, when he learned to imitate the actor‚Äôs actions and attitude. But, according to a Dec. 22, 1825 article in The Star, the young man had something else going for him. ‚ÄúHewlett‚Ä¶must have had a natural talent for theatrical performances and an excellent voice, or he could never have surmounted his early difficulties,‚Äù the newspaper reported. Those difficulties were the result of racism. In addition to working as a waiter and tailor by trade, Hewlett was a role model for the African Grove‚Äôs younger member, Ira Aldridge. When Hewlett joined the theatre company in 1821, he attempted Richard III with an all‚Äêblack cast and played the title role in Brown‚Äôs The Drama of King Shotaway. But much of his life after the African Grove is a blur. According to the Oxford Companion to American Theatre, he ‚Äúseems to have confined his appearances to recitals devoted largely to imitations of famous White actors.‚Äù\nAmong his honors, Hewlett was called ‚Äúthe most astonishing phenomena of the age‚Äù by an 1826 advertisement. In addition, the ad goes on to describe him as: ‚Äúa young man, who, notwithstanding the thousands of obstacles which the circumstance of complexion must have thrown in his way of improvement, has, by the mere dint of natural genius and self‚Äêstrengthened assiduity, risen to a successful competition with some of the first actors of the day.‚Äù Later billed as ‚ÄúShakespeare‚Äôs proud Representative,‚Äù he disappeared after a farewell benefit in 1831. According to blackpast.org, Hewlett passed in 1836.\nIra Aldridge, an American stage actor who made his career largely on the London stage, is the only African American actor among the 33 actors of the English stage with bronze plaques at the Shakespeare Memorial Theatre at Stratford-upon-Avon. Born on July 24, 1807 to Reverend Daniel and Luranah Aldridge, Ira‚Äôs first professional acting experience was in the early 1820s with the African Grove, according to various sources. There, he debuted as Rolla in Pizzaro, played Shakespeare‚Äôs Romeo and later gained fame for his portrayal of Hamlet.\nConfronted with persistent racism in the U.S., Ira emigrated to England, where he worked as a dresser to the British actor Henry Wallack. His move from the U.S. sparked a series of tours that started in 1831, when he successfully played in Dublin, along with several locations in southern Ireland, Bath, and Edinburgh. He eventually toured Europe in 1852, and was successful in Germany ‚Äì where he peformed for Frederick William IV of Prussia after being presented to the Duchess Saxe-Coburg-Gotha ‚Äì and in Budapest. Ira spent most of his final years in Russia ‚Äì where he met Leo Tolstoy, Mikhail Shchepkin and Taras Shevchenko ‚Äì and in continental Europe. He died in August 1867.\nThe spirits of Aldridge, Hewlett and Brown‚Äôs African Grove motivated the theatre movement on D.C.‚Äôs ‚ÄúBlack Broadway‚Äù during the dawning of the 20th century, when the city became the social and cultural capital of Black America, according to the PBS documentary, ‚ÄúMelodies and Memories.‚Äù ‚ÄúFrom 1900 to 1920, it was this country‚Äôs largest African American community. Anchored by Howard University and federal government jobs, this community became a magnet for African American intellectuals and sent a stream of shining talents to the nation for generations,‚Äù according to PBS‚Äôs Web site. ‚ÄúIt developed a prosperous Black middle class which forged a strong society of churches, newspapers, businesses and civic institutions.‚Äù\nAmong those institutions were the Howard and Lincoln theaters. Created in 1910, the Howard Theater at 620 T Street NW was a stucco-clad building that originally served ‚Äúas a playhouse for both variety shows and moving pictures catering to African-American audiences,‚Äù according to a January 2008 Staff Report for Howard Theater. ‚ÄúThe Howard is the oldest surviving and the first known theater in the country built just for Black audiences during segregation when Blacks were barred from attending or performing at White theaters.‚Äù Success of the 1,200-seat auditorium helped energize the debuts of other Black-owned theaters, such as the Apollo in Harlem, the Uptown in Philadelphia, and the Royal in Baltimore (or the Chitlin‚Äô Circuit), according to ‚ÄúHistoric U Street Jazz,‚Äù a project of George Washington University. The theater closed its doors when the Great Depression hit in 1929. When it reopened its doors in 1931, the theater moved away from providing variety acts to solely jazz performances. The city‚Äôs desegregation in the early 1960‚Äôs and the 1968 unrest that ensued after the assassination of Dr. Martin Luther King Jr. led to the Howard closing its doors in 1970. The theater is currently closed with plans for renovations.\nLike the Howard, the Lincoln Theater was designed as a movie theater for black patrons in 1921. Initially, it was where African Americans saw vaudeville acts, first-run films, and amateur competitions. When the Lincoln switched owners in 1927, the theater was expanded to include ‚Äúa cabaret, a hot nightspot, and a dance hall called the Lincoln Colonnade,‚Äù according to GWU‚Äôs ‚ÄúHistoric U Street Jazz.‚Äù\nThe Presidential Ball came to the Lincoln in the 1940s, and the first ladies Eleanor Roosevelt and Bess Truman used the theater for a March of Dimes rally. ‚ÄúThe Lincoln‚Äôs name, its decor, its cabaret, and the politically and socially elite visitors all worked to affirm the importance, not only of the Lincoln, but of the community on U. Street,‚Äù according to ‚ÄúHistoric U Street Jazz.‚Äù\nAnd like the Howard, the Lincoln Theater suffered from the city being fully integrated in the 1960‚Äôs. Following the Brown v. Board of Education decision in 1954, Black businesses moved downtown and along with them went majority of the neighborhood‚Äôs prominent residents. The unrest of 1968 also ended the Lincoln‚Äôs golden era. ‚ÄúThe Lincoln played B movies until it was permanently closed in 1982,‚Äù according to Historic U Street Jazz. ‚ÄúCurrently, the Lincoln remains in the custody of the District Government and is awaiting a proposal for restoration.‚Äù\nLast night, Grossman, moderator and president/CEO of Helen Hayes Awards, had a question for the audience. ‚ÄúWho here has, at some time in recent history, attended a Washington theatre performance as an audience member?‚Äù At the sight of every hand raised, she said, ‚ÄúExcellent! A‚Äôs for everyone.‚Äù\nToday, the total number of theatres in D.C. quadrupled from 14 in 1983 to more than 70 now. In 2008, alone, 69 of the city‚Äôs area theatres ‚Äì plus theatre festivals ‚Äì produced 428 productions, 169 readings and 154 festival productions, the moderator said. The total? It‚Äôs around 8,723 performances seen by almost two million audience members. So if everyone in the room attended even one of those productions in 2008, she said, they played a critical role in confirming the city‚Äôs current reputation. ‚ÄúThe quantity of productions maintains Washington‚Äôs tradition as the second most prolific theatre town in the country,‚Äù Grossman said. ‚ÄúBut the quality and the diversity of the work produced here make Washington second to none.‚Äù","By PERRY STEIN The Washington Post\nWASHINGTON ‚Äì A walk down U Street reveals relics of the strip‚Äôs jazzrich history.\nThere‚Äôs the mural in the pizza shop alley that reads ‚ÄúBlack Broadway,‚Äù a tribute to the hallowed corridor‚Äôs once well-known nickname. The Ellington apartment building is an ode to District of Columbia native Duke Ellington. And there‚Äôs the shuttered Bohemian Caverns, whose distinctive saxophone-adorned fa√ßade still stands.\nBut contemporary artists are realizing the city‚Äôs rich history isn‚Äôt enough to sustain jazz in a 21st-century Washington.\nThey‚Äôre scrambling to save what has been called America‚Äôs original art form in a city where it‚Äôs fading from the culture.\nFor a genre that sprung from African-Americans telling stories of oppression, the musicians are seeking help from unlikely sources: D.C. government and city institutions.\nAdvocates are lobbying city agencies and the D.C. Chamber of Commerce to support the cause. They want vacant, city-owned space to be transformed into pop-up jazz venues and are pushing for subsidized housing for artists so the city can retain talent.\n‚ÄúYou do not have D.C. or any other forms of music if you did not have jazz,‚Äù said Aaron Myers II, a D.C.-based jazz musician leading the effort. ‚ÄúIf you lose jazz, you lose the authenticity of Washington.‚Äù\nHiring a solo DJ is cheaper for a business than hiring a full jazz group, so artists are asking the city to consider offering incentives to hotels and bars that host live music.\n‚ÄúWhen I moved back to D.C., nearly all the places that I grew up listening to music were closed,‚Äù said saxophonist Herb Scott. ‚ÄúThere‚Äôs no way we‚Äôre going to be able to maintain an art form like this because it‚Äôs simple math. It‚Äôs just easier to get a DJ, one person, than a quartet.‚Äù\nCity officials say that while they generally support the idea, policies and programs to revive the genre haven‚Äôt been fully developed. A spokesperson for D.C. Council Chairman Phil Mendel- son said members of his staff met with musicians, but he doesn‚Äôt yet have an opinion on the feasibility of such an incentive.\nCouncil member Brandon T. Todd said he created the Ward 4 Advisory Committee on Arts and Humanities so his office could better determine what resources and opportunities artists in his ward need, but he didn‚Äôt comment on musicians‚Äô specific requests.\nMany would argue that jazz has simply passed its hey- day. Musicians concede that a gentrifying District changes the landscape of jazz but insist that demand for the music is still there. The city is flush with new Washingtonians who know little about jazz history, and they say it needs marketing muscle like never before.\nPlaces such as Blues Alley in Georgetown, Twins Jazz on U Street and Mr. Henry‚Äôs on Capitol Hill are still hosting live jazz, but the scene has taken some recent hits. The legendary Bohemian Caverns on U Street shuttered last month. Cafe Nema closed its doors in 2010. HR-57, an old-school jazz venue, closed on H Street NE in 2014.\nThe historic Howard Theatre‚Äôs finances are foundering, and WPFW-FM, which bills itself as D.C.‚Äôs ‚Äújazz and justice‚Äù radio station, is having a fundraising campaign to keep it afloat. The radio station has been ground zero for organizing efforts, and musicians say its airwaves are a crucial platform for them.\nThere was a time when U Street NW was dotted with jazz venues, but the area was decimated in riots that followed the 1968 assassination of Martin Luther King Jr. The street has since transformed into one of the priciest corridors in the District, but it never recovered as the mecca for African American art and culture.\n‚ÄúA lot of this is public awareness. People assume be- cause musicians make magic out of nothing, they don‚Äôt need money,‚Äù said Andy Shallal, owner of Busboys & Poets, a restaurant named for poet Langston Hughes with its flagship location near U Street. Shallal has a weekly show on WPFW and is leading its fundraising efforts.\nIn the next few months, the DC Office of Cable Television, Film, Music and Entertainment will launch a weekly program called ‚ÄúThe Sound‚Äù on the city‚Äôs DC Network. The viewership probably won‚Äôt be high, but Angie Gates, director of the cable television and entertainment office, said the government-funded show will give its professionally filmed segments to artists for use in marketing their work.\n‚ÄúWe are willing to provide them as a resource so they won‚Äôt have to pay for that marketing tool out of their pocket,‚Äù Gates said.\nWashington is hardly the only city whose jazz clubs are struggling, and music, after all, is a business. Margaret Singleton, the interim director of the D.C. Chamber of Commerce, told the musicians she would arrange for them to play at the Chamber‚Äôs events. The events would allow musicians to network with business owners who could potentially book them, she said. `\n`One of the things that we have been able to do is help realize how they can leverage themselves as entrepreneurs,‚Äù Singleton said. ‚ÄúHow can they connect with those entities that are already there to support the arts and humanities?‚Äù\nArthur Espinoza, the head of the D.C. Commission on Arts and the Humanities, which provides grants to artists and nonprofit arts organizations, said the commission is not focused on jazz, but sees it as a critical part of the city‚Äôs history.\nThis year, the commission gave two grants totaling $139,700 to the D.C. Jazz Festival, a multi-day festival in June that attracts acts from across the country."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:c101a550-e6d4-4085-82e3-9426538e9032>","<urn:uuid:28854196-dedb-4db8-a82f-6fe60591b135>"],"error":null}
{"question":"Can you compare the role of leadership in ethical implementation between King IV's framework and IDEA Foundation's ethical guidelines?","answer":"In King IV's framework, leadership responsibility lies with the governing board, which must collectively promote ethical characteristics and embed an ethical culture throughout the organization, including training staff and improving leadership qualities to protect stakeholder interests. For IDEA Foundation, the board of directors holds clear responsibility for establishing, implementing, and monitoring ethical standards, with a specific focus on investment management and project evaluation. While both frameworks place leadership at the center of ethical implementation, King IV emphasizes broader organizational ethical conduct, while IDEA Foundation's leadership focuses more specifically on evaluating and supporting projects against established ethical guidelines and UN Global Compact principles.","context":["Principle 1 of King IV prescribes that the governing board should lead ethically and effectively. King IV recommends that the governing board individually and collectively, should promote the following six ethical characteristics below in their conduct:\n- Integrity ‚Äì act in good faith and in the best interest of the organisation (act ethically beyond mere legal compliance);\n- Competence ‚Äì take steps to ensure that they have sufficient working knowledge of the organisation and the industry it operates;\n- Responsibility ‚Äì assume collective responsibility for steering and setting the direction of the organisation;\n- Accountability ‚Äì be willing to answer for the execution of their responsibilities, even when these were delegated;\n- Fairness ‚Äì adopt a stakeholder-inclusive approach in the execution of their governance role and responsibilities; and\n- Transparency ‚Äì be transparent in the manner in which they exercise their governance role and responsibilities.\nWhat is ethics and compliance in the context of a business?\nMany people associate having ethics with basically ‚Äòdoing a good or right thing‚Äô or ‚Äòmorality‚Äô. Compliance is the act of conforming to compliance obligations relevant to the business in which it operates. Ethics is practical, whereas compliance is responsive.\nWhile the above definitions are certainly true, an effective ethical and compliance system of an organisation extends way beyond ethical behaviour. Organisations have to fully imbed an ethical culture, train staff and communicate in order to improve leadership qualities within its operations in order to protect the interests of its stakeholders. The way in which these practices are rooted and implemented is critical to the organisation‚Äôs ability to strengthen its ethical and compliance performance.\nAn organisation‚Äôs good name and the trust of its stakeholders are two of its most important assets. Creating a workplace where ethical conduct is the norm, can reduce the risk of non-compliance and increase ethical conduct throughout the organisation. Therefore, the solution to this challenge, is to have ethics and compliance central to business strategy.\nHow to make ethics and compliance central to business strategy?\nMost people consider this as a mundane task of creating a framework. Well, yes, that is correct! ‚Äì But surely this is only one portion of what you need to do to instil an ethical culture and get a buy in from stakeholders. Furthermore, a framework should not be a once off exercise that is static.\nHow do you go about this then, you may ask?\nFirst thing one should consider is to have an accurate picture of existing strengths and areas of vulnerability within an organisation. Below is a universal process that you can use to identify and assess the vulnerabilities, develop controls, monitor, rectify and improve on your organisation‚Äôs ethical and compliance performance.\nA risk assessment should be the starting point of your internal efforts, followed by gap analysis and, an ethics and compliance program (E&C Program) assessment. Audit reports are also an essential piece of the puzzle.\nThe above picture is a synopsis of how you can continuously improve. What this means is that, you give yourself an opportunity to keep maintaining the strategy and values of your business through and through; not once off. (You need to ‚Äì identify; assess; implement controls; monitor your controls; evaluate if your controls are efficient; report on those measures; rectify is there is a need; improve the approach and repeat the process.)\nEthics and compliance as a foundation\nEthics and compliance as a foundation should be considered to be an essential element of organisational behaviour. As a result, the ethics and compliance function (where is exists) assumes responsibility for the organisation‚Äôs compliance with the law and regulation, but it does so by serving as a resources and advocate to help leaders across the organisation under their critical role in setting the standard for integrity.\nWhere an Ethics and Compliance Program (E&C Program) exists, it has to be assessed to check if it is designed to complement and support the organisation‚Äôs strategic objectives and not merely as an ‚Äúadd-on‚Äù feature of the organisation.\nE&C Programs have become an important tool for evaluating and mitigating non-compliance and fraud risks, to improve operations and protect an organisation‚Äôs reputations. Organisations that opt to implement E&C Programs, partly mitigate potential penalties and other sanctions that could be imposed against them should something go wrong because they are able to demonstrate what they are striving to; and have measures that are effective to offer protection to its stakeholders.\nIn particular, an E&C Program is designed to integrate with business objectives and can help ensure that an organisation operates within the law and stays true to its own ethical principles that are important to the company‚Äôs business and identity. E&C Programs can benefit companies, their stakeholders, and the public through the prevention, early detection, and resolution of misconduct.\nConsider for a moment the level of ethics and compliance integration within your organisation and what values drive the everyday life of your organisation.\nWritten by Thapelo Mbita\n The King Report IV on Corporate Governance for South Africa\n Rossouw, D., & Van Vuuren, L. (2010); Business Ethics, 4th Ed, pg 4\n Compliance obligations‚Äô is a term that is collectively used to describe requirements that an organisation has to comply with (‚Äòcompliance requirements‚Äô) and chooses to comply with (‚Äòcompliance commitments‚Äô). 2018 Generally Accepted Compliance Practice framework, Compliance Institute SA ‚Äì page 12\n Rossouw, D., & Van Vuuren, L. (2010); Business Ethics, 4th Ed, pg 5","Ethical guidelines for IDEA Foundation\nEthical guidelines and values - IDEA FoundationBackground and definitions\nA code of ethics is a set of principles of conduct within an organization that guide decision making and behavior. The purpose of the code is to provide members and other interested persons with guidelines for making ethical choices in the conduct of their work. Professional integrity is the cornerstone of credibility in a working community. Member of an organization adopt a code of ethics to share a dedication to ethical behavior and adopt this code to declare the organization's principles and standards of practice.\nViews on ethical considerations have changed greatly in recent years and are still evolving. Idea Foundation will work hard to meet our own and our stakeholders expectations to be at the forefront of this development. Establishing and implementing ethical standards and values for Idea will therefor be an ongoing and dynamic process, constantly under revision and improvement. The clear responsibility for this process lies with the board of directors. The board also holds the ultimate responsibility for implementation and monitoring of activities conducted by the Foundation it self, its partners, stakeholders and projects, supported by the Foundation.\nIdea Foundation is a non-profit organization and should not be compared with a traditional investor, maximizing his returns. Our ambition is never the less to influence and contribute to development of sustainable growth and prosperity through out all the projects and geographical areas where we are involved. To be able to successfully reach our long term ambitions The board of directors with Idea Foundation have set ethical standards, that as a minimum must meet the principles of ethical investment management, including endorsement of the UN principles for responsible investment (UN-PRI).\nThe UN Global Compact asks companies to embrace, support and enact, within their sphere of influence, a set of core values in the areas of human rights, labor standards, the environment, and anti-corruption:\nPrinciple 1: Businesses should support and respect the protection of internationally proclaimed human rights; and\nPrinciple 2: make sure that they are not complicit in human rights abuses.\nPrinciple 3: Businesses should uphold the freedom of association and the effective recognition of the right to collective bargaining;\nPrinciple 4: the elimination of all forms of forced and compulsory labor;\nPrinciple 5: the effective abolition of child labor; and\nPrinciple 6: the elimination of discrimination in respect of employment and occupation.\nPrinciple 7: Businesses should support a precautionary approach to environmental challenges;\nPrinciple 8: undertake initiatives to promote greater environmental responsibility; and\nPrinciple 9: encourage the development and diffusion of environmentally friendly technologies.\nPrinciple 10: Businesses should work against corruption in all its forms, including extortion and bribery.\nIn addition to the The Ten Principles of the UN Global Compact, the Idea Foundation has established a set of core values to be followed in all aspects of our behavior and in our relationships internally and externally. Idea Foundation has a clear ambition to take an active stand in implementing the same core values in all our projects and businesses established and developed on the basis of support from Idea Foundation.\nWe want to be a leader in every aspect of our involvement and our business. In the development of our team leadership skills at every level; in our management performance; in the way we design, build, and support our products and services; and in our financial reporting.\nWe are committed to practice the highest ethical standards, and by honoring our commitments. We will take personal responsibility for our actions and treat everyone fairly, with trust and respect.\nWe will strive for continuous quality improvement in all that we do, so that we will rank among the best in customer, employee, and community satisfaction.\nPeople working together\nOur strength and our competitive advantage is and always will be ‚Äì people. We will continually learn, and share, ideas and knowledge. We will encourage cooperative efforts at every level and across all activities in our company.\nGood corporate citizenship\nWe will provide a safe workplace and protect the environment. We will promote the health and well-being of people and their families. We will work with local communities to support education and other worthy causes.\nFundamental equal rights and respect for all individuals Equal rights offering same opportunities to all, despite, race, religion, sex.\nThe Foundation will support business ideas and projects that can document a long term sustainable development.\nCorporate Social Responsibility\nNo matter how small a business is it can have a strong belief in social responsibility.\nThe ethical guidelines for the Idea Foundation are promoted through the following four measures:\nExercise of power to support proposed and established projects\nExclusion of companies and projects\nObservation of companies and projects\nThe role of the board and the investment committee is to provide evaluation on whether or not investment and support in specified companies and projects is inconsistent with the established ethical guidelines and The UN Global Compact. This work shall be based on the following principles:\nHonesty and Integrity: We act with honesty and integrity.\nProfessional Behavior: We operate within the letter and the spirit of applicable laws.\nCompetence: We apply appropriate skills and capabilities to every\ndecision we make\nObjectivity: We are objective in forming our professional opinion\nConfidentiality: We respect the confidentiality of information.\nFair Business Practices: We are committed to fair business practices.\nResponsibility to Society: We recognize and respect the impact we have on the world\nRespect and Fair Treatment:We treat all our colleagues with respect, courtesy and\nAccountability and Decision-Making: We lead by example, using our Core Values as"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:f6e29fbc-b8d3-4dd4-85cb-943ba11165ca>","<urn:uuid:10159761-6257-4e01-b061-4205ae03e2e1>"],"error":null}
{"question":"What deep space objects can both StarSense Explorer and Dobsonian telescopes effectively observe? When conditions are favorable, what specific celestial targets become visible through these instruments?","answer":"Both telescopes can effectively observe several deep space objects. The StarSense Explorer can view Jupiter's Galilean moons, cloud bands, Saturn's rings, the Orion Nebula, Pleiades Open Star Cluster, and under darker skies, the Andromeda Galaxy and Hercules Open Star Cluster. Similarly, Dobsonian telescopes excel at deep-sky observations, revealing detailed views of galaxies like Andromeda, nebulae including the Orion Nebula, and various star clusters. Both instruments also perform well for planetary observations, showing features like Jupiter's cloud bands and Saturn's rings.","context":["**United States Shipping Only**\n**FREE US SHIPPING**\nCelestron has reinvented the manual telescope with StarSense Explorer‚Äîthe first telescope that uses your smartphone to analyze the night sky and calculate its position in real time. StarSense Explorer is ideal for beginners thanks to the app‚Äôs user-friendly interface and detailed tutorials. It‚Äôs like having your own personal tour guide of the night sky.\nDock, Launch, Explore\nLeave complicated star charts, imprecise planetarium apps, and computerized mounts behind. With StarSense Explorer, locating objects has never been easier, faster, or more accurate. Within minutes of setting up the telescope, you‚Äôll be navigating the sky with confidence. Simply place your phone in the unique StarSense dock and launch the StarSense Explorer app. After aligning your phone to the telescope‚Äôs optics (a quick, 2-minute procedure), StarSense Explorer generates a list of celestial objects currently visible. Make your selection and arrows appear onscreen, guiding you as you to move the telescope. When the object is ready to view, the bullseye turns green.\nStarSense Explorer works with most modern smartphones, including iPhone 6 and up and most devices running Android 7.1.2 or later manufactured since 2016. For a complete compatibility list, click here.\nPatent-Pending StarSense Sky Recognition Technology\nStarSense Explorer uses patent-pending technology and your smartphone to determine exactly where the telescope is pointed in the night sky. A Lost in Space Algorithm (LISA), like the ones satellites use in orbit to correctly reorient themselves, helps the app match star patterns it detects overhead to its internal database.\nWhile other astronomy apps may claim that they can help you find objects, they rely exclusively on the phone‚Äôs gyros and accelerometers, which aren‚Äôt as accurate as LISA technology. No other app can accurately tell you when your target is visible in the eyepiece.\nSturdy Altazimuth Mount\nStarSense Explorer LT‚Äôs simple altazimuth mount makes it easy to move the telescope to find your target. A slow-motion altitude adjustment knob helps you fine tune the telescope‚Äôs pointing position and follow targets as they appear to drift across the night sky. It‚Äôs all anchored by an adjustable, full-height tripod.\nDazzling Views with High Quality Optics\nWith a large 114mm (4.5‚Äù) objective lens, this telescope has enough light gathering ability to bring out detail in celestial objects. You can expect sharp, bright views of Jupiter‚Äôs four Galilean moons, its cloud bands and Great Red Spot, the rings of Saturn, the trapezium in the Orion Nebula, and beautiful Pleaides Open Star Cluster.\nPerfect for the City or Dark Sky Sites\nEven if you live in a light polluted city location, StarSense Explorer is advanced enough to be able to pick out Jupiter, Saturn, Venus, the Orion Nebula, double stars, and a few more of the most famous celestial objects.\nBut if you can take the telescope to an even slightly darker location, more objects will become visible. With this 4.5‚Äù Newtonian and relatively dark skies, the Andromeda Galaxy, Hercules Open Star Cluster, and so many more are easily within your reach.\nThe entire telescope kit weighs just 10.4 pounds, so it‚Äôs perfectly portable and easy to bring on your next camping trip or to a remote observing site.\nEverything You Need to Observe Immediately\nWhen you unbox your new StarSense Explorer LT, you‚Äôll find:\n|OPTICAL TUBE INFO:|\n|Optical Design||Newtonian Reflector|\n|Focal Length||1000mm (39.3\")|\n|Focal Length of Eyepiece 1||25mm (0.98\")|\n|Magnification of Eyepiece 1||40x|\n|Focal Length of Eyepiece 2||10mm (0.39\")|\n|Magnification of Eyepiece 2||100x|\n|Barlow Lens||2x (1.25\")|\n|Finderscope||StarPointer‚Ñ¢ red dot finderscope|\n|Highest Useful Magnification||269x|\n|Lowest Useful Magnification||16x|\n|Limiting Stellar Magnitude||12.8|\n|Resolution (Rayleigh)||1.22 arc seconds|\n|Resolution (Dawes)||1.02 arc seconds|\n|Light Gathering Power (Compared to human eye)||265x|\n|Secondary Mirror Obstruction||44mm (1.73\")|\n|Secondary Mirror Obstruction by Diameter||38%|\n|Secondary Mirror Obstruction by Area||14%|\n|Optical Coatings||Glass mirrors coated with aluminum and SiO‚ÇÇ|\n|Optical Tube Length||609.6mm (24\")|\n|Optical Tube Diameter||147mm (5.78\")|\n|Optical Tube Weight||6.6 lbs (2.99 kg)|\n|Mount Type||Manual Alt-Azimuth|\n|Height adjustment range (includes mount and tripod)||Aluminum, 1320.8mm (52\") max height|\n|Tripod Leg Diameter||31.75mm (1.75\") steel|\n|Tripod Weight||3.8 lbs (1.72 kg)|\n|GPS||Uses phone's GPS|\n|Dovetail Compatibility||CG-5 Dovetail bar|\n|Power Requirements||None (Recommend PowerTank Glow to keep phone charged while using app)|\n|Alignment Procedures||Use StarSense Explorer app|\n|Software||StarSense Explorer app | SkyPortal app | Celestron Starry Night Basic Edition Software (Optional Upgrade to Pro Plus 8)|\n|Total Kit Weight||10.4 lbs (4.71 kg)|\n|Included Items||Telescope tube | Mount/tripod (preassembled) | 25mm & 10mm eyepieces | 2x Barlow lens | StarPointer finderscope | Accessory tray | StarSense Explorer phone dock|\n**United States Shipping Only**\n**FREE US SHIPPING**\nLearn more about the world-class desktop planetarium, Starry Night Pro Plus 8, here: http://store.simcur.com/proplus.\nEmail email@example.com with questions.","The night sky has forever captivated the human spirit with its celestial wonders. To explore this captivating expanse, astronomers have crafted numerous telescope designs over the years. Among these, Dobsonian telescopes have carved a unique place, offering an impressive combination of simplicity, affordability, and powerful optics. In this article, we will embark on a cosmic journey to unravel the marvels of Dobsonian astronomy telescopes, examining their features, advantages, and the celestial vistas they unveil for stargazers.\nThe Birth of the Dobsonian Telescope\nThe Dobsonian telescope, often referred to as a ‚ÄúDob‚Äù or ‚ÄúDobsonian,‚Äù pays tribute to its inventor, John Dobson. In the 1960s, Dobson introduced this telescope design to the amateur astronomy community, forever changing the way people observe the night sky. The Dobsonian telescope offers a revolutionary approach to telescope design, focusing on simplicity, ease of use, and affordability while delivering remarkable optical performance.\nThe Anatomy of a Dobsonian Telescope\nThe Dobsonian telescope design embraces several key features that distinguish it from other telescope types:\n- Altitude-Azimuth Mount:\nA Dobsonian telescope employs a simple and sturdy alt-azimuth mount. This mount allows the telescope to move in both vertical (altitude) and horizontal (azimuth) directions. Unlike equatorial mounts, which require polar alignment, Dobsonian mounts are intuitive and easy to use, making them perfect for novice astronomers.\n- Large Aperture:\nOne of the most striking features of Dobsonian telescopes is their large aperture. Aperture refers to the diameter of the primary mirror or lens, which determines the telescope‚Äôs light-gathering capacity. Dobsonian telescopes often come with substantial apertures, providing remarkable clarity and enabling observations of faint celestial objects.\n- Simple Design:\nDobsonian telescopes have a straightforward design, featuring a primary mirror and a secondary mirror or a single lens in the case of refracting Dobsonians. This simplicity results in lower costs, making Dobsonian telescopes an affordable option for both beginners and experienced astronomers.\nThe Dobsonian Advantage\nThe Dobsonian telescope design boasts several advantages that make it a favorite among astronomers:\nDobsonian telescopes are known for their budget-friendly pricing. This affordability means that aspiring astronomers can acquire a telescope with a substantial aperture, providing access to a wealth of celestial wonders without breaking the bank.\n- Ease of Use:\nThe simplicity of Dobsonian telescopes makes them exceptionally user-friendly. Novice astronomers can quickly master the basics of operating a Dobsonian telescope, which typically involves moving the telescope up and down (altitude) and left and right (azimuth) to point it at celestial objects. This ease of use allows beginners to focus on the beauty of the night sky without getting bogged down in complex telescope operation.\n- Light Grasp and Clarity:\nDobsonian telescopes‚Äô large apertures result in exceptional light-gathering capabilities. This feature enables astronomers to observe faint galaxies, nebulae, and star clusters with remarkable clarity. The increased light grasp also provides vivid views of planets and the moon.\nWhile Dobsonian telescopes may be bulkier than some other designs, they are still relatively portable. Many models can be disassembled for transport and reassembled at your observing site. Their alt-azimuth mount is more straightforward to set up compared to equatorial mounts, further enhancing their portability.\nDobsonian telescopes are versatile instruments. While they excel in deep-sky observations, they are also well-suited for lunar and planetary observations. The large aperture allows for detailed views of the moon‚Äôs craters, planets‚Äô surface features, and the rings of Saturn.\nGazing into the Universe with a Dobsonian Telescope\nThe universe unfolds before your eyes as you peer through the eyepiece of a Dobsonian telescope. The following scenarios illustrate the versatility and power of Dobsonian telescopes:\nExploring Deep-Sky Objects:\nDobsonian telescopes are masters at revealing the beauty of deep-space objects. With their large apertures, they capture galaxies, nebulae, and star clusters in remarkable detail. Amateur astronomers are often astonished by the views of objects like the Orion Nebula, the Andromeda Galaxy, and the Beehive Cluster.\nObserving the Moon:\nThe moon‚Äôs surface, with its craters, mountains, and plains, comes to life in a Dobsonian telescope. The lunar terrain, bathed in the soft glow of reflected sunlight, is a captivating sight that never ceases to amaze observers.\nDobsonian telescopes deliver impressive views of the planets in our solar system. You can observe the intricate cloud bands of Jupiter, the polar ice caps of Mars, the iconic rings of Saturn, and the phases of Venus with remarkable clarity.\nWhile Dobsonian telescopes are primarily designed for visual observation, they can also be used for basic astrophotography. Capturing images of the moon and planets is possible with the right equipment and techniques, making Dobsonian telescopes a versatile choice for amateur astronomers interested in both visual and photographic astronomy.\nChoosing Your Dobsonian Telescope\nSelecting the right Dobsonian telescope involves considering factors like aperture, focal length, and the mount‚Äôs stability. Larger apertures provide enhanced light-gathering capacity, while longer focal lengths affect magnification and field of view. It‚Äôs essential to strike a balance that aligns with your astronomical interests.\nAdditionally, the stability of the mount is crucial for smooth and precise tracking of celestial objects. Look for a sturdy Dobsonian base that ensures steady observations and reduces vibrations.\nEmbark on Your Celestial Odyssey\nIn conclusion, Dobsonian astronomy telescopes offer an enchanting gateway to the universe, with their affordable pricing, ease of use, and powerful optics. Their simplicity, combined with the advantage of a large aperture, makes them an excellent choice for both novice and experienced astronomers. The night sky beckons, and with a Dobsonian telescope by your side, you can embark on a celestial odyssey, exploring the depths of space and unveiling the cosmic wonders that grace our cosmos."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:99381b1b-b0cc-4b9c-bfa4-a4acd22e7a98>","<urn:uuid:be2b383f-3abd-4bc2-9675-c62232c593d4>"],"error":null}
{"question":"I'm curious about these two epidemiologists' early career experiences - how do Michelle Williams' and Lorna Thorpe's initial professional paths compare in terms of their international work and research focus?","answer":"Both epidemiologists began their careers with significant international work, but in different regions and focuses. Michelle Williams conducted research studies across Africa, Asia, and South America, focusing on maternal and infant mortality through genomic sciences and epidemiological research methods. Lorna Thorpe, on the other hand, started her career as a CDC Epidemic Intelligence Service (EIS) Officer working on international tuberculosis control, and spent over five years living and working in China and Indonesia, where she focused on designing and evaluating family planning and HIV/AIDS programs.","context":["Michelle A. Williams, S.M. ‚Äô88, Sc.D. ‚Äô91, a distinguished epidemiologist and award-winning educator known for her influential studies of maternal and child health around the world, will become the next dean of the Harvard T.H. Chan School of Public Health, starting in July.\nSince 2011, Williams has been the Stephen B. Kay Family Professor of Public Health and chair of the Epidemiology Department at the Harvard Chan School.\nThe principal investigator on several international research projects and training grants funded by the National Institutes of Health, and co-author of more than 400 published research papers, Williams is also the faculty director of the Harvard Catalyst‚Äôs Population Health Research Program and the Health Disparities Research Program. Her scholarship is especially known for its creative integration of epidemiological, biological, and molecular approaches to a range of public health challenges, and her teaching and mentoring have been recognized with awards from Harvard, the University of Washington, the American Public Health Association, and the White House.\n‚ÄúMichelle Williams is an eminent epidemiologist, an outstanding teacher and mentor, and an energizing leader and institutional citizen, impassioned about the power of public health to change people‚Äôs lives for the better,‚Äù said Harvard President Drew Faust in announcing the appointment.\n‚ÄúShe is a skilled builder of bridges ‚Äî between the theoretical and the practical, the domestic and the international, the different disciplines that drive the School‚Äôs academic endeavors, and the different communities that shape its identity and aspirations,‚Äù Faust added. ‚ÄúI know she will approach her new role with the intelligence, dedication, integrity, and humane spirit that she brings to all she does.‚Äù\n‚ÄúI am honored and excited by the opportunity to lead the Harvard Chan School, and grateful to President Faust for inviting me to serve in this role at such a crucial moment for public health in the United States and around the world,‚Äù said Williams. ‚ÄúAs an alumna and faculty member, I have witnessed the transformative impact that this institution can have in education, research, and discovery related to the health of communities in need. We have an imperative to lead and to serve, and I am looking forward to working even more closely with the School‚Äôs faculty, students, staff, and alumni to build on the School‚Äôs achievements under [prior Dean] Julio Frenk‚Äôs remarkable leadership and to advance our collective commitment to understanding and confronting public health challenges worldwide.‚Äù\nA 1984 graduate of Princeton University, where she majored in biology, Williams went on to receive an M.S. in civil engineering from Tufts University in 1986. Continuing her studies at the Harvard School of Public Health, she earned her S.M. in population science in 1988 and her Sc.D. in epidemiology in 1991. After a postdoctoral research fellowship at the University of Washington School of Public Health and Community Medicine, she joined the UW faculty as an assistant professor of epidemiology in 1992.\nEmerging as an internationally recognized epidemiologist and educator, she rose through the UW faculty ranks, becoming an associate professor in 1996 and a full professor of epidemiology in 2000. While at the UW, she was highly active in the Center for Perinatal Studies at the Swedish Medical Center in Seattle, rising to become co-director from 2000 to 2011, with broad responsibility for a multidisciplinary research program involving clinical investigators, basic scientists, and epidemiologists. From 1992 to 2010, she held an appointment as an affiliate investigator at the Fred Hutchinson Cancer Research Center in Seattle, and from 2008 to 2011 she held a joint appointment in global health at the UW.\nIn 2011, Williams was recruited back to Harvard as the Stephen B. Kay Family Professor of Public Health in epidemiology and to become chair of the Epidemiology Department. Her research focuses on integrating genomic sciences and epidemiological research methods to identify risk factors, diagnostic markers, treatments, and prevention targets for disorders that contribute to maternal and infant mortality. Her work is particularly noted for its sophisticated linkages between epidemiology and allied disciplines and for its broad international scope, encompassing studies in Africa, Asia, and South America as well as the United States.\nAs an educator, Williams has led grants, funded by the National Institutes of Health (NIH), that are designed to enhance the education of members of groups underrepresented in the biomedical and quantitative sciences and to train aspiring epidemiologists and other public health investigators in several dozen countries. Last year, she received the Harvard Chan School‚Äôs Outstanding Mentor Award, having previously been recognized with the UW‚Äôs Brotman Award for excellence in teaching (2007), the American Public Health Association‚Äôs Abraham Lilienfeld Award for education in epidemiology (2007), and the White House‚Äôs Presidential Award for Excellence in Science, Mathematics, and Engineering Mentoring (2012).\nAs department chair, Williams has guided the Epidemiology Department through a period of notable transition, while contributing to the conception and implementation of a range of School-wide initiatives, including recent major reforms in the doctoral and master‚Äôs programs. She remains active with various professional organizations and academic journals, while playing advisory or planning roles for such institutions as the NIH, the Centers for Disease Control and Prevention, the American Diabetes Association, the March of Dimes, and Meharry Medical College.\nIn announcing Williams‚Äô appointment, Faust expressed her gratitude to the many members of the Harvard Chan School community who offered advice during the search, noting that their counsel ‚Äúnot only informed the choice of a dean but also illuminated the School‚Äôs possibilities ahead.‚Äù\nShe offered particular thanks to the members of the faculty advisory committee assembled for the search, and to David Hunter, the Vincent L. Gregory Professor in Cancer Prevention and dean for academic affairs at the Harvard Chan School, who has served as acting dean since Frenk‚Äôs departure last August to become president of the University of Miami. ‚ÄúMy special thanks go to David Hunter, whose leadership, wisdom, and professionalism are so central to the Harvard Chan School‚Äôs ambitions and accomplishments,‚Äù said Faust.\n‚ÄúMichelle has been a valued colleague since she returned to Harvard five years ago,‚Äù said Hunter. ‚ÄúAlong with many others, I‚Äôve come to admire her for her collaborative research, her mentorship of students and faculty colleagues, her work to strengthen her department, her contributions to shaping the new Ph.D. program in population health sciences, and her important focus on health disparities through the Harvard Catalyst. I‚Äôm confident our School will be in excellent hands.‚Äù","Professor, Department of Population Health\nLorna Thorpe, PhD, MPH, is a Professor of Epidemiology, Director of the Division of Epidemiology, as well as Vice Chair of Strategy and Planning in the Department of Population Health.\nDr, Thorpe is a leading expert in population health surveillance and performing population-based studies. Her current research focuses on the intersection between epidemiology and policy, particularly with respect to chronic disease prevention and management and improving modern forms of public health surveillance. She is co-principal investigator of the NYU-CUNY Prevention Research Center funded by the Centers for Disease Control and Prevention, a center aimed at reducing cardiovascular disease disparities through evaluation of innovative community-clinical linkage initiatives in low-income communities. She also serves as principal investigator of the New York City Health and Nutrition Examination Survey (NYC HANES 2013) that aims to evaluate a number of municipal health policies launched in the past decade, as well as validate the use of electronic health records for population health surveillance purposes.\nBefore coming to NYU School of Medicine, she served as chair of the Department of Epidemiology and Biostatistics at the City University of New York‚Äôs School of Public Health for seven years. Prior to that, Dr. Thorpe spent nine years at the New York City Department of Health and Mental Hygiene, including five as deputy commissioner of epidemiology. In her time at the Health Department, Dr. Thorpe led the growth of the Epidemiology Division and oversaw a large portfolio of innovative scientific studies aimed at understanding the health of New York City residents. She also supervised birth and death registration, injury surveillance, epidemiologic consultancies throughout the agency, public health training, and workforce development.\nDr. Thorpe is on the board of directors for the American College of Epidemiology (ACE) and chairs the ACE Policy Committee. She serves as chair of the steering committee for the CDC-funded Prevention Research Center Network, which includes 26 academic institutions around the nation. She has served on Institute of Medicine committees and as an advisor to the CDC on population health surveillance issues.\nDr. Thorpe began her applied research career as a CDC Epidemic Intelligence Service (EIS) Officer in international tuberculosis (TB) control. Dr. Thorpe completed her PhD in epidemiology at the University of Illinois at Chicago, MPH. at University of Michigan, and BA at Johns Hopkins University. Prior to completing her PhD, she lived and worked in China and Indonesia for over five years, focusing on designing and evaluating family planning and HV/AIDS program. Dr. Thorpe has published widely on both chronic and infectious disease topics.\nDirector, Division of Epidemiology\nVice Chair for Strategy and Planning Dept Population Health\nPhD from University of Illinois\nMPH from University of Michigan\nFellowship, Centers for Disease Control and Prevention, Epidemic Intelligence Service Fellowship\nHypertension. 2020 Jul; 76(1):44-50\nJournal of racial & ethnic health disparities. 2020 Jun 02; (),(2020):\nJournal of community health. 2020 Jun; 45(3):635-639\nHealth & place. 2020 Mar 13; 63:102324\nObesity (Silver Spring). 2020 Jan; 28(1):31-39\nScience of the total environment. 2019 Nov 21; 135322"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:c168afde-7bf1-49ed-8cb3-588415f84edf>","<urn:uuid:41a53b8c-b58c-4792-94ce-47f0136304b5>"],"error":null}
{"question":"How small are most no-take Marine Protected Areas (MPAs) worldwide?","answer":"40% of no-take MPAs in the world are smaller than 1 km2, and 64% are smaller than 10 km2. Due to their small size, these MPAs may hold only about 45-56% of the population size implied by their area, making the global no-take MPA network significantly less beneficial than perceived.","context":["Fish on the edge: a meta-analysis reveals edge effects within marine protected areas\nEdge effects degrade the effectiveness of no-take MPAs on a global scale. Improving the planning and management of MPAs can increase their performance and benefits for surrounding fisheries.\nNo-take Marine Protected Areas (MPAs) are a source of hope for our deteriorating oceans. The effectiveness of no-take MPAs in protecting and restoring marine ecosystems is documented in numerous field studies. However, these studies usually examine MPA effectiveness in a discreet manner, finding high biomass inside the MPA versus low biomass in adjacent fished area.\nBut the world is continuous, and MPAs are not fenced, unlike many terrestrial protected areas. So, what exactly happens across MPA borders? This question occupied my mind while reviewing the literature as part of my PhD research focusing on the process of fish spillover from MPAs. Spillover is the net export of fish or invertebrates (as egg, larvae, or adults) from within an MPA to its surrounding areas. Beyond conservation, spillover represents the ability of MPAs to benefit humans by contributing to the recovery of depleted fisheries.\nAs the last meta-analysis on spillover was conducted more than ten years ago, and since new field studies have been published in recent years, I decided that a new synthesis of cross-boundary size-estimates of marine populations would be interesting. Specifically, I wanted to know what exactly is the shape of the gradient from within to outside MPAs. Do fish really ‚Äúspillover‚Äù from MPA boundaries? Does fisher strategy to often fish on the borders of MPAs (‚Äúfishing the line‚Äù) result in decreased fish abundances?\nI started to search the scientific literature for empirical studies with suitable data. There weren‚Äôt many. Cross boundary data on marine populations is very limited. The reason for this shortage is that these kind of field studies are generally very complicated, expensive, and time-consuming to conduct. I know this all too well from my own field research, where I am using both traditional underwater visual census methods and implementing new acoustic methods to identify fish abundance changes across the borders of no-take MPAs in Israel.\nEventually, I identified 24 studies suitable to include in my meta-analysis. These studies contained 1,619 population size estimates belonging to 147 unique samples, which represents the spatial patterns of 72 fish and invertebrate taxa across 27 no-take MPA borders, located in diverse marine realms.\nWhen I saw the results, I immediately understood that we are looking at a pattern of edge effect. Edge effect is a well-studied phenomenon in terrestrial protected areas, where the edges of the reserve experience elevated disturbance, which in turn reduces the size of natural populations. Consequently, edge effect causes a reduction in the actual effective size of the reserve with great implications for reserve planning and management. However, in the oceans, the magnitude of edge effects in MPAs had not been studied empirically.\nOur study not only revealed strong edge effect in MPAs, but also quantified the magnitude of this phenomenon on a global scale. The results suggest that the edge effect can reach up to 1-1.5 km within the MPA and that population sizes on the border are 60% smaller relative to the core areas.\nUsing the MPAtlas database, we also found that 40% of the no-take MPAs in the world are smaller than 1 km2, meaning that they most likely experience edge effect over their entire area! Overall, 64% of no-take MPAs are smaller than 10 km2 and may hold only about half (45-56%) of the population size implied by their area, making the global no-take MPA network significantly less beneficial than perceived.\nAn important point to highlight is that a pattern of edge effect does not mean that spillover from the MPA does not happen. Spillover and fishing most likely occur simultaneously on MPA borders to produce an edge effect pattern. Thus, despite prominent edge effect, spillover may occur, and fishers may still be benefiting from increased catch outside of the MPA boundaries. Nevertheless, the consistency of edge effect patterns implies that the depletion of populations at MPA peripheries is occurring at a faster rate than the buildup of populations outside of the MPA.\nOther evidence presented in the paper indicates that fishing pressure around the MPAs is probably the main cause of edge effect. In fact, when we examined different MPA characteristics, we found the no-take areas with buffer zones around them did not present edge effect but rather a pattern of spillover. In addition, MPAs that were well enforced presented a smaller edge effect than ones that reported some illegal fishing.\nThese findings are encouraging, as they mean that by applying a precautionary buffer zone with regulated fishing activities, and by improving enforcement, we can increase the effectiveness of existing no-take MPAs and increase the benefits they provide via spillover. When planning new MPAs, we recommend the no-take area targeted for protection to be at least 10 km2 and as round as possible, to reduce the proportional area of the total MPA size degraded by edge effect.\nAs the global community begins to implement the post-2020 global biodiversity framework, led by the Convention on Biological Diversity (CBD), our findings provide hands-on, practical guidelines to improve MPA planning and management, so that we can do a better job of protecting our oceans."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:87b44b3b-8f7d-4e56-bb34-e36e38fb1bef>"],"error":null}
{"question":"How do traditional washing and dry cleaning compare in terms of maintaining fabric quality, particularly for delicate materials and items with special features?","answer":"Dry cleaning is generally superior for maintaining fabric quality, especially for delicate materials. It protects delicate fabrics like wool, acetate, leather, taffeta, velvet, silk, and cashmere that can be easily damaged by water. It's also ideal for items with embellishments like sequins, pearls, and embroidery, which can become detached during traditional washing. Dry cleaning reduces fabric distortion and discoloration since it doesn't expose materials to friction and water saturation. In contrast, traditional washing can cause color fading due to friction from agitation and heat exposure. It can also lead to fabric shrinkage or stretching due to water saturation, spinning, and drying processes. For sweaters specifically, even when following care labels, stretching, shrinkage, pulls, and pilling may occur, with softer knits being particularly vulnerable to texture changes during washing.","context":["The Wonderful World of Sweaters\nAs the styles of sweaters change, so do the fibers of this wardrobe staple. Sweaters are made from a variety of fibers, ranging from cotton and wool to silk, rayon, acrylic and more. Natural fibers, such as angora, mohair, cashmere, and Shetland are especially popular. To add to the variety many sweaters contain special decorative trims. Trims such as suede, leather, snakeskin, fur, sequins, and beads add to a sweater's special look. The following tips should make the care and maintenance of sweaters easier:\nA good tip for long lasting sweaters is to check to see if it will withstand your lifestyle. If you're an active person or plan on wearing it to dance parties, go for a harder, tighter yarn. Soft, loose yarns tend to stretch easily and often begin to show signs of wear much faster.\n‚Ä¢ Although not a common occurrence, check to see if the seams on the sweater pull or fray easily. This is also a good indicator of whether or not it will withstand active lifestyles and can tell you of the quality of the overall product.\n‚Ä¢ If the sweater you wish to buy has trim on it, ask the retailer about their return policy. This is recommended because most times the fabric will hold up to the rigors of life in general, but the trim is most often the weakest part. If the there is a problem with the trim, the store may allow you to exchange it depending how long ago it was purchased and the store's return policy.\nFollow your sweater's care label instructions closely to prevent shrinkage and stretching. Many sweaters are hand-wash only. In these cases, it is recommended to allow them to dry naturally by laying them flat. Some sweaters are gentle-cycle washable and others may require drycleaning. In any case, avoid using alkaline-based detergents (usually hard-surface only detergents) on woolens and other animal fibers.\n‚Ä¢ If you have any doubts about the best way to approach an item, you may bring it to us to examine and offer a suitable cleaning method.\n‚Ä¢ Tumble dry only at low temperatures, if recommended on the care label.\n‚Ä¢ Treat stains right away. When spills are blotted immediately and professionally removed, stains won't develop later.\n‚Ä¢ Sweaters with pile may be brushed to lift the fabric and remove any surface soils.\n‚Ä¢ If wool sweaters get wet, let them dry at room temperature away from any direct heat source.\n‚Ä¢ Check knitted sweaters for unraveling and fraying, and secure any loose yarns so the sweater can withstand normal use and care procedures without further unraveling.\n‚Ä¢ Place folded sweaters over padded hangers in a well-ventilated closet or place in drawers. Do not hang sweaters from the shoulders; the weight of the sweater can cause it to stretch. Be sure to empty pockets, remove belts, and close zippers.\n‚Ä¢ When storing sweaters, be sure to use breathable cloth garment storage bags to prevent yellowing and the development of stains.\n‚Ä¢ Be sure to put sweaters away only when they are clean as any stains on the item may develop into worse stains or even attract moths (leading to moths eating through the fabric and creating holes).\n‚Ä¢ Remember that delicate items may require special handling.\nPossible Issues When Cleaning\nWhile we are well versed in cleaning many different types of fabrics and treating multitudes of stains, some items may prove more problematic than others to clean. When the sweater is not cared for as directed or the stains on the sweater go untreated for too long then the likelihood of possible irreversible damage goes up.\nStretching, shrinkage, pulls, and pilling, both from use and cleaning may occur even when following the care labels of the items. Some stretching on knit items should be expected as a normal circumstance of wear and care to a given extent. Generally, the softer the knit, the more likely it is to show some change in texture or feel with normal wear, and this may be aggravated with washing or cleaning procedures.\nIf you have any questions about caring for your sweaters simply come to us and we can give you potential solutions to your needs.","What‚Äôs the difference between traditional washing vs dry cleaning? Apparently, each method involves different steps, products, and machines. They also have their own sets of advantages and disadvantages that you need to consider. Still, one isn‚Äôt really inferior or superior to the other since each one is best used for certain types of fabric material. Let's take a look at these two methods to know when you should dry clean or launder your fabric.\n- Traditional Laundry Washing vs Dry Cleaning\n- Pros and Cons of Washing vs Dry Cleaning\n- Washing vs Dry Cleaning - In Conclusion\n- More Fabric Care Articles\nTraditional Laundry Washing vs Dry Cleaning\nWet washing and dry cleaning of your fabric-made items are two of the most effective and popular ways of keeping them free from dirt, germs, stain, and unwanted odor. Laundry symbols or care instructions can help you determine which one to choose. (What is dry cleaning)\nHowever, some materials can both be washed and dry cleaned. Here are the most notable differences between washing vs dry cleaning:\n- Solvents (Chemicals) Used\n- Drying Methods\n- Stain Removal\nWashing vs Dry Cleaning - The Main Solvent Used\nTraditional laundry washing uses water as the main solvent to dissolve detergent or soap, which in turn will clean your fabric. On the other hand, dry cleaning involves special, water-free chemical solvents or solutions. Thus, the term ‚Äúdry‚Äù entails the absence of water but not of other fluids.\nWashing vs Dry Cleaning - Drying Method\nSince both methods use solvents, every fabric you wash or dry clean would require drying so that you can remove excess water or solution. For wet washing, you either wring and then hang or spin dry the washed item. You can also place the fabric in a tumble dry machine. On the contrary, dry cleaned items are completely dried using a special drying machine.\nWashing vs Dry Cleaning - The General Process\nIn wet washing, you usually pre-wash the fabric with water to remove dirt partially and then place it in water with detergent or soap. You either hand-wash or machine-wash using the appropriate setting to remove any remaining dirt completely. Then, they undergo rinsing and drying. Finally, you can iron the fabric to remove creases and wrinkles. At times, fabrics with stain require spot removal before pre-rinsing them.\nOn the other side of the spectrum, fabrics for dry cleaning are treated with solvents to remove stains, grease, dirt, and more. Then, they undergo the ‚Äúwash‚Äù and tumble cycle followed by solvent removal, filtration, and recycling. After that, they‚Äôre dried in the machine and then undergo steaming or ironing for wrinkle and crease removal.\nWashing vs Dry Cleaning - Stain Removal\nLooking at the general process for both techniques, it‚Äôs obvious that they can effectively remove stains. The difference is in the type of stain.\nWashing is perfect for organic stains, namely urine, mildew, sweat, food coloring, and beverages like tea and coffee. It goes without saying that it‚Äôs the technique of choice for general or daily stains. That‚Äôs because water is a universal solvent, so it can dissolve most stains.\nBasic science tells us that water doesn‚Äôt combine with oil, while chemicals combine with certain chemicals, depending on their affinity.\nTherefore, dry cleaning is recommended for oil-based or grease stains and chemical stains like ink.\nPros and Cons of Washing vs Dry Cleaning\nFrom the main differences between traditional washing vs dry cleaning, you might have already seen positive and negative points for each. That said, here are the significant pros and cons of each method for you to have a better idea.\nThe Benefits of Washing\nWashing fabric materials would not be the first method of choice for a long time if it didn't work as expected. Here are some of the advantages of washing your fabrics:\nWhether you let a professional do the washing vs dry cleaning or do it yourself, dry cleaning is more expensive than traditional laundry washing. This is mainly because dry cleaning requires more expensive products and equipment.\nIn relation to cost, wet laundering, even with all the machines used like the washer, spinner, and dryer, is more energy-efficient than dry cleaning. Remember that in dry cleaning, machines used are bigger, requiring more energy for them to work.\nApplicable for a Wider Range of Fabric\nBeing an older technique, you can safely wash multiple fabric types such as cotton, linen, polyester, and nylon. Obviously, these are commonly used materials in producing necessary items like bed sheets, pillowcases, and clothes.\nUses Milder and Safer Cleaning Products\nAs mentioned, water is a universal solvent. It doesn‚Äôt contain harmful chemicals that can damage most fabrics. Some tap water supplies might have been pre-treated with chlorine, but only at a safe level.\nPowder or liquid detergents and soaps are also made of milder, non-toxic, biodegradable ingredients. Additionally, even if a certain amount of chemical is added, the product is diluted in water.\nWet laundered items will usually have a more pleasant smell than dry cleaned ones. It‚Äôs usually due to the addition of fabric softeners to the water during the last rinsing step. Laundry soaps or detergents also generally have fragrances added to them.\nThe Drawbacks of Washing\nOf course, the process of traditional washing isn't perfect. The following are its disadvantages that you should make a note of:\nWashing fabric in a machine or by hand involves friction, either from agitation or between the item and your hands, which can pull out the color from the material. Some colored materials are also sensitive to heat, so you need to ensure you choose the right water and drying temperature. Similarly, exposure to sunlight can cause fading.\nFabric Shrinkage or Stretching\nWhen washing fabric, it gets saturated with water, leading to stretching. Spinning and tumble-drying can also lead to stretching since some of the fibers get cut or loosen. On the other hand, prolonged exposure to the dryer‚Äôs hot temperature is one of the leading causes of fabric shrinkage. If you opt to hang the item dry, it might get stretched. Thus, either way, you will have ill-fitting clothing, bed sheets, pillowcases, and more.\nThe Benefits of Dry Cleaning\nDiscovered at a later time, here are some of the things you‚Äôll love about dry cleaning are:\nProtects Delicate Fabric\nCertain fabric materials, usually the more expensive ones, get easily damaged when exposed to water. Although you can hand wash some of them, water will shorten their lifespan. Thus, whether they‚Äôre dry-clean-only or can be washed and dry cleaned, it‚Äôs best to dry clean them. These materials include wool, acetate, leather, taffeta, velvet, wool, silk, and cashmere.\nPerfect for Fabric With Embellishments\nDefinitely, water and washers can damage embellishments, like sequins, pearls, and embroidery. They also sometimes get detached from the fabric, so you notice a missing piece or two once you take them out of the washer and/or dryer.\nSince professionals usually do dry cleaning, they‚Äôre trained to handle these embellishments. The process in itself also ensures such pieces are protected from damages or being detached.\nReduces Fabric Distortion and Discoloration\nContrary to washing, dry cleaning won‚Äôt expose fabric materials to friction and agitation and saturate them with water. As such, there‚Äôs minimal fabric shrinkage and swelling, as well as color fading. This leaves you with perfectly fitting clothes, sheets, and more with a \"like-new\" look.\nSofter and Crisper Fabric\nDry cleaned clothes, bed sheets, and other items will be softer than those washed with water. They also have less noticeable wrinkles and creases, or none at all thanks to the last stage of the process.\nThe Drawbacks of Dry Cleaning\nAs perfect as it may sound, the notable issues with dry cleaning include:\nDistinct Chemical Odor\nAs mentioned, chemical-based solvents are used in dry cleaning, which can leave a certain smell. If higher quality solvents are used, though, there is little to no chemical odor.\nMight Cause Skin Irritation\nIn relation to using chemical solvents, people with sensitive skin might react to them, leading to skin irritation or allergies. That said, there are already milder types of chemical solvents produced, thanks to technological advancements.\nHarmful to the Environment\nUndoubtedly, chemicals are harmful to the environment. In fact, the original and first solvent, known as PERC or Perchloroethylene, used in dry cleaning has been shown to contaminate water, soil, and air. Do note, though, that eco-friendly solvents are now available, and most dry cleaning companies already prefer those.\nWashing vs Dry Cleaning - In Conclusion\nApparently, both traditional washing and dry cleaning will ensure your fabric materials are clean, pleasantly smelling, and/or stain-free, as long as you follow the right techniques. Their main differences bring about each of their pros and cons.\nChoosing which one is better would depend on the fabric material and stain. Sometimes, it also boils down to personal preference and budget.\nOverall, laundering or washing is the more practical choice, but dry cleaning can prolong the lifespan and maintain the quality of fabric materials better. Thus, it's more cost-effective when you need to clean expensive and delicate items.\nStill, always keep in mind the manufacturer-provided care instruction since it will tell you the method of choice. If in doubt, consulting a professional or having a professional clean your fabric-made items would be best.\nMore Fabric Care Articles\n- How To Iron a Shirt ‚Äì The Right Way\n- Iron Settings ‚Äì Best Settings & Heat for All Fabrics\n- How to Clean an Iron ‚Äì The Right Way\n- How To Clean Curtains ‚Äì The Right Way\n- How to Wash Jeans ‚Äì The Best Method\n- How to Wash Silk ‚Äì The Right Way\n- How to Wash Lace ‚Äì The Right Way\n- TUMBLE DRY ‚Äì How to Tumble Dry Correctly\n- Laundry Symbols ‚Äì Best Guide to Washing\n- What is Dry Cleaning"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:55852df0-0c6f-4552-bbe1-393ffb22de96>","<urn:uuid:86c0fdec-b650-42aa-8379-87b3f28b555d>"],"error":null}
{"question":"What are the financial impacts of workplace mental health issues compared to ransomware attacks?","answer":"Both workplace mental health issues and ransomware attacks pose significant financial burdens to businesses. Poor mental health costs businesses $46.7 billion in lost productivity, with affected workers taking 12 days off annually compared to the average 2.5 days. Meanwhile, ransomware attacks typically cost between $570,000 and $812,360 per incident, with some cases like Maersk experiencing losses of up to $300 million due to operational downtime. The financial impact includes not only direct costs but also productivity losses, with mental health affecting 41.5% of US adults and ransomware potentially causing up to 20% productivity loss during downtime.","context":["Poor mental health costs businesses more than $45 billion\nNearly 50 percent of US workers cite their job as the primary cause of their poor mental health. In a recent Gallup Poll, a growing number of employees report extreme stress and anxiety at work, with forty percent stating that their job negatively impacts their mental health. Half of these workers are Millenials between 18-29 and account for over one-third of the US workforce.\nWith the incidence of poor mental health cases related to work rising, so does the cost. For example, the average worker calls off work unexpectedly, only 2.5 days annually. By contrast, those under severe mental strain take 12 days off each year, at an estimated $46.7 billion in lost productivity. This growing price tag has business experts wondering if a mental health pandemic is on the horizon.\nThe symptoms of anxiety and depression disorders include prolonged feelings of anger, stress, worry, and sadness. Left unattended, poor mental health can destroy employees‚Äô teams, families, schools, and institutions. Currently impacting 41.5% of US adults, mental health disorders are a growing threat to workplace ideas and energy. Small businesses, which employ 50% of the American workforce, are at the most significant risk and paying a high price tag.\nGlobal Healthcare Organizations call on businesses to address employee mental health.\nIn the last year, global healthcare organizations are recognizing that we are on the edge of a potential mental health crisis at work and are calling on leaders to address their negative impact on the mental health of their employees.\n‚ÄúThe workplace is the missing link in improving population mental health,‚Äù Dr. Leslie Hammer, co-director of the Oregon Healthy Workforce Center and professor of occupational health psychology at Oregon Health & Science University, told ABC News.‚Äù The next steps are for workplaces to look hard at the culture around mental health support.‚Äù\nIn October, the US Surgeon General released the ‚ÄúNew Framework for Mental Health and Wellbeing in the Workplace,‚Äù reinforcing workplaces‚Äô role in supporting their employees‚Äô mental health and well-being. A similar recommendation was issued by the World Health Organization a month earlier, identifying three areas of change that would significantly move toward creating a positive mental health culture at work. They were:\n1. Training for managers to improve their ability to recognize and respond to employees who might be experiencing emotional distress\n2. Training for employees to improve their mental health awareness and knowledge\n3. Easy access to mental health resources within existing health programs to improve individual mental health and reduce its stigma in the workplace.\nTraining builds employee insights\nIt can be challenging for managers to initiate a caring conversation if they notice an employee struggling with negative thoughts and feelings when mental health, anxiety, and depression. Despite growing public recognition and acknowledgment of mental health illnesses, many organizations carry a negative bias towards their discussion at work. However, according to Johann Berlin, CEO at TLEX Institute, organizations were trending away from transactional interactions and repetitive tasks to more adaptive, empathetic, and connected cultures before the Covid19 pandemic and beginning to offer training to build mindfulness and emotional intelligence. Today, nearly 22% of employers now offer meditation and mindfulness training with access to apps like Calm or Headspace to reduce employee anxiety, improve working memory and increase creativity.\nThe business case for mindfulness training remains positive for personal wellness and relationships. But as Mark Sidney notes, the benefits are only possible through sustained practice. ‚ÄúTheory informs practice,‚Äù he states, ‚ÄúTrue mindfulness involves developing a deeper understanding of the processes and foundational attitudes necessary for mindfully living and working.‚Äù\nLasting impact requires more than insight. It requires Mental Fitness.\nMost of our attempts to make positive changes fail. Why? Because we stop at insight and don‚Äôt build habits. We lose momentum after the initial excitement of learning a new skill and return to our former practice. But recent advances in neuroscience research offer hope for lasting change by retraining our brains.\nIn his NY Times Best Selling book, Positive Intelligence, Shirzad Chamine describes how building mental muscles activate and build new neural pathways. Using new functional Magnetic Resource Imaging (fMRI) technology, he describes the research that shows tissue growth in the region of the brain where positive emotions originate.\n‚ÄúAll our negative emotions ‚Äì stress, anxiety, self-doubt, anger, shame, and frustration ‚Äì exist physically in our left brain. In contrast, positive emotions like peace and joy live in the right brain. Building and strengthening the neural pathways that create a positive mindset and reduce negative ones are called mental fitness.‚Äù\nBuilds mental muscles. Increase Mental Fitness. Create positive lasting change.\nMental fitness, by definition, is the ability to handle life‚Äôs challenges from a positive mindset with less stress. Using factor analysis, the breakthrough research by Positive Intelligence identifies three core mental muscles, radically simplifying mental fitness. Validated by more than 500,000 individuals, including students, CEOs, elite athletes, and sales, operations, and technology teams, the Positive Intelligence Mental program is proven to build measurable improvements within six weeks of practice.\nStrengthening the mental fitness of individuals and teams may offer businesses a simple and lasting way to avoid the potential mental health pandemic and improve wellness, relationships, and performance in the process.\nFor BusinessLearn More\nCouncil, Forbes. ‚ÄúThis Expert Says Meditation Is On The Rise Among C-Suite Executives.‚Äù Forbes, Forbes, 20 Oct. 2020, https://www.forbes.com/sites/forbesmarketplace/2020/10/20/this-expert-says-meditation-is-on-the-rise-among-c-suite-executives/?sh=40bf67204281. Accessed 7 Nov. 2022.\nSidney, Mark. ‚ÄúMore than Just Well-Being: The Business Case for Mindfulness at Work.‚Äù LinkedIn, LinkedIn, 8 Apr. 2019, https://www.linkedin.com/pulse/more-than-just-well-being-business-case-mindfulness-work-mark-sidney. Accessed 8 Nov. 2022.\nSutton, MD, Darien. ‚ÄúHow to Spot Work Burnout during the Holidays.‚Äù Good Morning America, Good Morning America, 5 Nov. 2022, https://www.goodmorningamerica.com/wellness/video/spot-work-burnout-holidays-81912402.\n‚ÄúU.S. Surgeon General Releases New Framework for Mental Health & Well-Being In the Workplace.‚Äù U.S. Department of Health & Human Services, 20 Oct. 2022, https://www.hhs.gov/about/news/2022/10/20/us-surgeon-general-releases-new-framework-mental-health-well-being-workplace.html#:~:text=Vivek%20Murthy%20released%20a%20new,of%20workers%20and%20our%20communities. Accessed 7 Nov. 2022.\nYegiants, Dr. Anna. ‚ÄúNearly Half of Workers Say Their Job Hurts Their Mental Health, Survey Finds.‚Äù Good Morning America, Good Morning America, 11 July 2022, https://www.goodmorningamerica.com/wellness/story/half-workers-job-hurts-mental-health-survey-finds-92672959.","Financial Costs of a Ransomware Attack and Breaking the Attack Chain Ransomware is a type of malware that typically utilizes encryption to impede or restrict admittance to information until a payoff is paid.\nFor organizations that experience the ill effects of a ransomware attack, the blow-back to income is in many cases more terrible than the size of the payoff and regardless of whether to pay it. The monetary harm can be far reaching and go a long ways past how much the payment.\nThe Financial Costs of a Ransomware attack can be huge. In addition to the ransom, businesses lose business due to downtime. These losses can quickly compound and spiral out of control. For example, one ransomware attack affected Maersk and left the company unable to operate for weeks. The company estimates that the downtime cost them $300 million.\nSpecialists suggest that organizations don‚Äôt pay ransoms as it gives cybercriminals a thought process to proceed. Organizations that really do wind up paying the payoff are frequently disheartened with the outcomes.\n- The information they recuperate is harmed.\n- The aggressors request more cash.\n- The aggressors disappear, and they don‚Äôt recuperate their information.\nLate investigations by Sophos and Pao Alto put the normal ransomware attack costs at somewhere in the range of $570,000 and $812,360.\nAs cybercriminals now utilize hilter kilter encryption strategies, having the option to unscramble the information is profoundly impossible. If you would rather not pay the payment, you will either need to recuperate the information from reproductions or reinforcements or lose it through and through.\nAt the point when you experience a ransomware attack, it is smarter to pick up and move on and follow your occurrence reaction plan. In the event that you have a viable recuperation plan set up, you might have the option to recuperate your information with negligible disturbance, and you won‚Äôt have to pay the payment. A recuperation plan typically includes five stages: survey, moderate, answer, convey, and hindsight.\nCounteraction is in every case better compared to attempting to manage the broad harm a ransomware attack can cause. Figure out more about how to diminish the gamble of turning into a ransomware casualty in any case at Discernment Point.\nCyber Insurance Academy\nThe cyber insurance industry is in a state of flux as more organizations are exposed to ransomware attacks. These attacks see hackers infect an organization‚Äôs computer network and demand money in return for control. These attacks have resulted in a massive increase in ransom payments, increasing by three-fourths to $412 million by 2020. In response, the cyber insurance industry has started an educational program to prepare students for such attacks.\nCyber insurance could take a cue from other forms of insurance. One professor at King‚Äôs College London studied the phenomenon of kidnap for ransom insurance and discovered that the insurance company‚Äôs ‚Äúdisruptive bargaining‚Äù strategy helped reduce kidnap gangs‚Äô demands.\nWhile ransomware is becoming increasingly widespread, some insurers are beginning to reconsider their policy and stop covering ransom payments. For example, AXA, which insures several large French companies, has decided to stop covering payments to ransomware attackers for future policyholders. This move has come in response to government pressure.\nGovernments are eager to provide adequate cyber insurance coverage but don‚Äôt want insurers‚Äô solvency to suffer. The failure in either direction could lead to a financial burden on governments. Cyber insurance companies are increasingly working with outside firms to vet their insureds‚Äô security protocols and procedures.\nBy restoring your computer and all of its data with NeuShield, you can stop ransomware attacks from destroying your information. Ransomware typically attempts to encrypt and wipe a disk, but NeuShield protects your data by restoring it to the original state. It does this by creating an undetectable overlay over your data. The attacker only has access to the data that is in the overlay ‚Äì all of your original files are preserved. Moreover, NeuShield can be restored to a previous state, allowing you to regain access to your information quickly and easily.\nAnother key aspect of defending your computer is breaking the attack chain. By understanding the structure of cyber attacks, you can identify and block them before they start. The attack chain is also known as the kill chain, and it is originally a military concept. It describes the methods of malware infiltration, deployment, and execution. Basically, breaking the attack chain means to prevent the attacks before they begin, but it is not as easy as it sounds. Whether you are a small or large business, the idea of breaking the attack chain is important and a vital part of cyber security.\nCybercrime has continued to evolve rapidly, and the scope of its attacks increases. As a result, future attacks will be much harder to detect and respond to. This arms race between attackers and defenders is becoming more apparent. In many ways, this is why cyber insurance premiums have skyrocketed.\nWhile traditional endpoint security can prevent the majority of cyberattacks, it may not be enough. Malware has become so sophisticated and evasive that traditional signature-based endpoint security cannot keep up. As a result, organizations need to employ a multi-layered endpoint protection strategy to combat the latest threats. By deploying a multi-layered endpoint security strategy, you can stop threats across multiple attack chains.\nAn innovative multistakeholder approach can effectively disrupt the financial capabilities of malicious actors and help reduce the global impact of ransomware attacks. Such an approach would leverage information-sharing and pooled resources to assess the costs and organizational vulnerabilities of ransomware.\nRansomware is a highly disruptive and costly cyberattack that can lead to crippling downtime and substantial productivity losses. The costs of downtime and recovery are enormous ‚Äì some estimates estimate that they are 50 times higher than the ransom demands. The downtime from a ransomware attack can affect a business for months and may cause it to file for bankruptcy.\nThe recovery process from a ransomware attack is complicated and requires all hands on deck. Depending on the size and scope of the attack, it may involve internal teams, incident response companies, forensic experts, and even the assistance of local and federal law enforcement agencies. Each step in the recovery process carries its own set of costs. Some companies may choose to pay the ransom instead of dealing with the recovery process, avoiding the financial consequences of losing customer data.\nThe impact of ransomware attacks is becoming increasingly widespread and complex. As a result, CISOs are losing confidence in the ability to mitigate ransomware attacks. Moreover, 73 percent of respondents said that failure to mitigate the risk of cyberattacks could expose organizations to fines and legal action. Cybersecurity Ventures estimates that ransomware attacks will cost $265 billion by 2031, which makes it crucial for organizations to prepare for the costs of these attacks.\nRansomware supply chains have become more sophisticated. As a result, cybercriminals are now targeting companies with extensive digital networks. This means that ransomware supply chain attacks will become more prevalent in the future. The SolarWinds ransomware attack, for example, should serve as a warning to all companies with global supply chains. This attack affected 18,000 corporate customers, including Fortune 500 companies and U.S. government agencies.\nIn January 2022, the BlackCat ransomware group infected 233 gas stations in Germany and forced the oil company Shell to reroute supplies. The attack used two vulnerabilities in two different software applications to encrypt data and exfiltrate intellectual property. The resulting disruptions rendered more than half of the organization‚Äôs systems inoperable for 48 hours, forcing Shell to hire security experts to restore access to their systems. The attack was so widespread that German intelligence services feared that the attackers had penetrated the networks of gas stations and oil companies to steal information. In Baltimore, the ransomware attack affected the city‚Äôs official email servers and rendered critical systems inaccessible.\nMany small and medium-sized companies have limited resources to protect themselves from ransomware. Security is costly and time consuming, so they often put off investing in it in favor of other critical business requirements. Unfortunately, the longer they wait to secure their networks, the more expensive it will be to repair the damage. This negative feedback loop has left many organizations unprepared for attacks and paved the way for predatory ransomware groups.\nThe costs of ransomware attacks can be staggering. In the United States, companies face billions of dollars in ransomware losses every year. As a result, ransomware has become a top concern for businesses, affecting both organizations and consumers. In addition to the financial burden of downtime, ransomware can damage a company‚Äôs reputation, and cause customers to lose trust in it.\nThe cost of ransomware attacks is escalating ‚Äì a single attack can cost up to $265 million. Those figures are staggering, and many companies that have been affected go out of business within a year of being infected. Fortunately, there are ways to mitigate the risk of a ransomware attack.\nThe financial costs of a ransomware attack can be staggering. The Cybersecurity Ventures report predicted that ransomware attacks would cost more than $5 billion in 2017, up from $325 million in 2015. This represents a 15X increase in just two years, with a projected total of $8 billion in 2018 and $11.5 billion in 2019. By 2021, ransomware attacks are expected to cost $20 billion, and every 11 seconds, an average business will be hit by ransomware.\nIn addition to the financial cost, ransomware attacks can also have a huge impact on an organization‚Äôs business. For example, an attack on the Colonial Pipeline Company caused a panic buying of fuel on the East Coast because a compromised password had given access to their IT system. The attack resulted in the shutdown of the company‚Äôs operational technology networks and IT systems for several days. Fortunately, the company was able to recover a significant portion of the $4.4 million ransom.\nIn addition to monetary costs, the recovery and downtime costs associated with a ransomware attack are also enormous. This is why it is essential to seek outside legal counsel when dealing with ransomware. A seasoned attorney will be able to guide you through the process and minimize your risk.\nTrend Micro has also recently discovered a new vulnerability impacting e-commerce websites. In April 2021, the company found that BIQS software was vulnerable to an XSS vulnerability, which could allow threat actors to inject malicious code on the servers. In August, the company also discovered that Atlassian Confluence servers were vulnerable to a local file inclusion vulnerability, allowing threat actors to insert arbitrary code on its servers.\nDowntime and labor costs\nWhile your frameworks are down, you will experience monetary misfortunes. Most associations require essentially a week and frequently significantly longer to recuperate information. Until it is reestablished, your entire situation is probably going to be disabled. Client information is essential to maintaining a business easily, and without it, you will fight to sell items, administration clients and substantially more. A regular efficiency misfortune can really depend on 20% during free time.\nIn a 2021 ransomware attack, the Kaseya assault, around 1,500 oversaw specialist organization clients were impacted. This shows how store network assaults cause more broad harm than assaults against single people.\nIT groups frequently need to stay at work past 40 hours to reestablish frameworks, and there is normally an overabundance of work all through an association because of an absence of admittance to information. Extra counseling or expert help might be expected to determine information issues.\nThe cost to brand reputation\nA harmed brand notoriety is difficult to fix, and this can have a broad monetary effect. Any bad exposure about an information break can influence the relationship with clients as well as with representatives, financial backers and different partners. Research from the Public Digital protection Coalition shows that around 60% of little to medium organizations leave business in no less than a half year of encountering an information break.\nThere‚Äôs a developing pattern for cybercriminals to take steps to uncover delicate information they exfiltrate before encryption. Where the information is strategic, for example, in medical clinics, government or crisis call focuses, this can really hurt.\nIn certain enterprises, clients can guarantee direct pay for an information break. Scripps Wellbeing, retail goliath Target, and gas organization Frontier Pipeline are only a portion of the organizations that have confronted legal claims.\nMost cases are privately addressed any remaining issues as organizations would rather not face extended court fights. Administrative and legitimate fines can be especially high for the spilling of individual wellbeing information, monetary data like charge card subtleties, and actually recognizable data.\nData loss and collateral damage\nYou might lose an information totally due to a ransomware attack. The deficiency of information might address many long stretches of work. Regardless of whether you can reestablish records from reinforcements, there‚Äôs an opportunity they were not supported totally or accurately. Today there are ransomware variations that likewise target reinforcement frameworks so you can‚Äôt reestablish information.\nYou should figure out how cybercriminals accessed your frameworks. There are numerous ways they can do as such, from conveying phishing messages and setting up counterfeit sites to straightforwardly going after programming weaknesses.\nContaminated machines might need to be totally reformatted, and programming reinstalled. You will likely need added assurance to ensure another information break doesn‚Äôt happen.\nIn the ongoing monetary circumstance with expansion and downturn, every one of the costs of a ransomware attack might cause a huge monetary misfortune. In 2020 different reports demonstrated that the normal expense of tidying up after a ransomware attack could depend on $1.85 million. In the event that you don‚Äôt tidy up your information and fix any fundamental issues, you could gamble with another assault.\nStep by step instructions to prevent ransomware attacks\n- Having security frameworks set up, representative preparation, and powerful design the executives are a portion of the ways of forestalling ransomware attacks.\n- Keeping awake to date with the most recent working software is vital.\n- Ensure you have total and exceptional reinforcements as they can assist you with recuperating information.\n- Stay up with the latest, and remember to apply security patches.\n- Persistently look at security to ensure you have the right estimates set up.\nIT experts need to adopt a protection strategy as once programmers get inside your association, limiting the damage can be hard. You want to safely safeguard each channel, with email frequently being quite possibly of the most weak one.\nCybercriminals keep on utilizing perpetually complex methods to convey ransomware by means of email. You want to search for cutting edge email security arrangements that utilization quick and successful unique filtering. Arrangements ought to likewise can identify dangers covered somewhere inside happy.\nRansomware can be monetarily harming to organizations in various ways, including pay-off costs, personal time costs, work costs, notoriety harm and legitimate expenses. Associations need to investigate their network protection safeguards. Distinguishing and managing likely dangers and channels, for example, email and cloud coordinated effort apparatuses, can assist with alleviating ransomware attacks.\n- Also Read: Price In India Emo Robot What Is The Cost?\n- Also Read: Kbm 25 Com Know The Latest Authentic Details!\n- Also Read: Is My Derma Dream Legit? Authentic Review!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:8cc70771-6325-4fe4-8449-f669804490f7>","<urn:uuid:a4aad484-a3a3-4984-8feb-404e3a6bba70>"],"error":null}
{"question":"When comparing undergraduate research experiences between the two research groups, what are the similarities and differences in terms of their focus on insect/soil studies and project types?","answer":"Both research groups offer undergraduate research opportunities, but with different focuses. The first group involves students in insect-based research, conducting both laboratory and field work at multiple sites including Oklahoma, New Zealand, and campus locations. Their projects incorporate bioacoustics, ethology, field ecology, and microbiology. The second group focuses on soil microbial ecology, with past undergraduate projects examining fungal competition across different land use types, decomposition abilities of fungi, and plant-fungi interactions. Both groups integrate laboratory and field components, but while one emphasizes insect behavior and communication, the other concentrates on below-ground microbial communities and their ecological roles.","context":["My research focuses in two areas, 1) population and community ecology, and 2) biology education. Students in my laboratory may focus their research in either of these areas, and can even draw captivating connections between the two areas!\nFirst, I am broadly interested in how individual animals in a population interact with one another, how communities of organisms interact, and how each of these levels of biological organization interact with their abiotic environment. In particular, I seek to understand how organisms communicate inter- and intraspecifically, and how changes in their habitat (whether natural or anthropogenic) can influence how they communicate. I am also interested in the co-evolution of microbes and animals, with particular interest in how microbial symbionts can influence the evolution of behavior. I find the use of insect models ideal for the questions that drive my investigations, and thus students who work in my lab will have the opportunity to experience research in the laboratory and in the field. I maintain research investigations at four main field sites which include two sites in Oklahoma, an island field station in New Zealand, and right here at the field sites on campus. The techniques used in my lab draw from the fields of bioacoustics, classic ethology, field ecology, spatial modelling, and microbiology.\nSecond, my explorations in biology education are allowing me to explore, in a multivariate way, how mixed-model teaching practices affect student learning and satisfaction in large introductory biology classes. Additionally, STEM educators across the country and across institutions and agencies recognize that for the United States to gain lost ground in scientific discovery and technological advances, we must begin focusing on training all of our citizens to think critically and to become scientifically literate. To that end, I am interested in teaching methods that work most effectively to remove biases against learning about science in general, and biology in particular. How can we approach the teaching of biology in a way that appeals to non-majors, underrepresented minorities, and reluctant learners? How can we foster an interest in the biological sciences in a way that is accessible, credible, and without sacrificing rigor and depth-of-content, so that more people consider science important, and decide to make scientific advancement a national priority? To address these issues, my pedagogical research is focused across three main themes:\nHow empirically validated teaching practices translate into scientific knowledge, scientific and critical thinking, and retention in the biology major during the introductory and early years of undergraduate training.\nHow involvement in project-based learning and early research experiences improve scientific thinking skills and retention in biology majors, and especially in students who affiliate with minority groups.\nHow longitudinal mentorship and financial support improves retention of minority pre-service and early career secondary science teachers who teach in high-needs schools.\nAnd, from the perspective of the faculty, why do we choose to either change or maintain our teaching methods, and what factors motivate faculty to explore innovative and inquiry-based teaching strategies?\nPh.D., Biological Science, Idaho State University\nM.S., Biochemistry, Univ of Tulsa\nB.S., Biology and Chemistry, Univ of Tulsa\nA.A., Allied Health Sciences, Community College of the Air Force\nBIOL 412/412H: Intro Biol: Evol Biodiv & Ecol\nBIOL 412H: Honors/IntroBioEvolBiodivEcol\nBIOL 675: Medical Botany\nBIOL 999: Doctoral Dissertation Research\nBIOL/LSA 895/900: Biology Special Investigations\nLSA 900: College Teaching\nHoward, D. R., & Hall, C. L. (2019). Examining the Management of Rare Insects Through the Lens of Biotic Interactions: A Comparative Case Study of Nicrophorus americanus (Coleoptera: Silphidae) and Gryllotalpa major (Orthoptera: Gryllotalpidae). Annals of the Entomological Society of America, 112(3), 158-168. doi:10.1093/aesa/saz008\nHoward, D. R., Schmidt, A. P., Hall, C. L., & Mason, A. C. (2018). Substrate-Borne Vibration Mediates Intrasexual Agonism in the New Zealand Cook Strait Giant Weta (Deinacrida rugosa). Journal of Insect Behavior, 31(6), 599-615. doi:10.1007/s10905-018-9700-2\nHoward, D. R., Lee, N., & Hall, C. L. (2018). Making high-stakes decisions in complex acoustic environments: Revisiting the Cocktail Party problem in a multimodal sensory context. The Journal of the Acoustical Society of America, 143(3), 1859. doi:10.1121/1.5036103\nHall, C. L., & Howard, D. (2018). Shaking it up in the classroom: Coupling biotremology and active learning pedagogy to promote authentic discovery. In P. Hill, R. Lakes-Harlan, & V. Mazzoni (Eds.), Biotremology ‚Äì Studying Vibrational Behavior (Vol. 2). Springer.\nWoelber, B. K., Hall, C. L., & Howard, D. R. (2018). Environmental cues influence parental brood structure decisions in the burying beetle Nicrophorus marginatus. Journal of Ethology, 36(1), 55-64. doi:10.1007/s10164-017-0527-7\nHall, C. L. (2016). Science as Process in the Biology Classroom: Using Insects as Teaching Models. American Entomologist, 62(2), 110-111. doi:10.1093/ae/tmw027\nHoward, D. R. (2016). There and Back Again: Fostering Undergraduate Research in Insect Biology Within a Study-Abroad Framework. American Entomologist, 62(2), 114-116. doi:10.1093/ae/tmw043\nHall, C. L., Howard, D. R., Smith, R. J., & Mason, A. C. (2015). Marking by elytral clip changes stridulatory characteristics and reduces reproduction in the American burying beetle, Nicrophorus americanus. Journal of Insect Conservation, 19(1), 155-162. doi:10.1007/s10841-015-9755-8\nHall, C. L., Mason, A. C., Howard, D. R., Padhi, A., & Smith, R. J. (2013). Description of Acoustic Characters and Stridulatory <I>Pars Stridens</I> of <I>Nicrophorus</I> (Coleoptera: Silphidae): A Comparison of Eight North American Species. Annals of the Entomological Society of America, 106(5), 661-669. doi:10.1603/an13001\nHall, C. L., Wadsworth, N. K., Howard, D. R., Jennings, E. M., Farrell, L. D., Magnuson, T. S., & Smith, R. J. (2011). Inhibition of Microorganisms on a Carrion Breeding Resource: The Antimicrobial Peptide Activity of Burying Beetle (Coleoptera: Silphidae) Oral and Anal Secretions. Environmental Entomology, 40(3), 669-678. doi:10.1603/en10137","Academic degrees and fellowships\nPostdoctoral fellow, Bio-Protection Research Centre, Lincoln University, New Zealand, 2012-2013\nDavid H. Smith Postdoctoral fellow, University of Texas at Austin, 2010-2012\nPh.D., Integrative Biology, University of Guelph, Canada, 2010\nB.S., Ecology and Evolutionary Biology, University of Tennessee, 2001\nKU Ecosystems Research Group\nAreas of specialization\nSoil microbial ecology, community ecology of soil microorganisms, plant-soil interactions\nThe vast world below ground has been referred to as the poor man‚Äôs tropical rain forest. Ben studies community ecology of soil microorganisms. Research in the lab explores this diversity and interactions among species there as well as how soil microbial ecology cascades up to aboveground communities and ecosystem processes. He focuses mainly on fungi (and some bacteria) that live in soils, and is interested in understanding the dynamics of microbe-plant symbioses, the role of soil microorganisms in community assembly (above and below ground) and the potential to leverage soil microbes in restoration. The lab uses a combination of study methods in the field, greenhouse and in controlled lab conditions, commonly employing a variety of tools including fungal culturing, next generation DNA sequencing and modeling.\nBen's lab was just established at the University of Kansas in late August 2013, so new projects will develop over time. Past and ongoing projects include the role of mycorrhizal fungi in plant succession, pathogen accumulation in non-native plants over time, benefits of fungal additions on ecosystem restoration, and interactive assembly of plant and root endophyte communities. New projects under way:\n- drivers of root endophytes in wetland plants as analogs to early land plants;\n- feedbacks among fire, fungi and plants in determining fire regime.\nPast undergraduate projects have explored competition among fungi from different land use types (natural, disturbed, converted to agriculture), the ability of fungi from different land uses to decompose above- and below-ground plant material, and the synergistic benefit to plants from functionally different fungi.\nJ.R. Powell and B.A. Sikes. 2014. Method or Madness: Does OTU delineation bias our perceptions of fungal ecology? New Phytologist. 202: 1095-1097.\nB.A. Sikes, H. Maherali, J.N. Klironomos. 2014. Mycorrhizal fungal growth responds to soil characteristics, but not plant host identity, during a primary lacustrine dune succession. Mycorrhiza. 24(3):219-226.\nB.A. Sikes, H. Maherali, J.N. Klironomos. 2012. Arbuscular mycorrhizal fungal communities change among three stages of primary sand dune succession but do not alter plant growth. Oikos. 121:1791-1800.\nK.C. Courtney, L.D. Bainard, B.A. Sikes, A.M. Koch, M.M. Hart, H. Maherali, J.N. Klironomos. 2012. Determining a minimum detection threshold in termal restriction fragment length polymorphism analysis. Journal of Microbiological Methods. 88(1):14-18.\nJ. Harnden, A.S. MacDougall, B.A. Sikes. 2011. Field-based effects of allelopathy in invaded tallgrass prairie. Botany. 89(4):227-234.\nS.A. Schnitzer, J.N. Klironomos, J. HilleRisLambers, L.L. Kinkel, P.B. Reich, K. Xiao, M.C. Rillig, B.A. Sikes, R.M. Callaway. 2011. Soil microbes drive the classic plant diversity-productivity pattern. Ecology. 92(2):296-393. [Selected by Faculty of 1000]\n- - Ambrosia collections 2016\n- - Amending Below for Aboveground Growth: Using Arbuscular Mycorrhizal Fungal Inoculations to Improve Growth and Ecosystem Services in Perennial Polycultures. 2016\n- - CHAT GIS and metadata manager. 2016\n- - CNH-L: Scale-dependent feedbacks among protected areas and surrounding socio-ecological systems. 2016\n- - Collaborative research: Fire-fungal feedbacks in pyrogenic ecosystems. 2016\n- - Collaborative research: Interactive effects of exogenous and endogenous SPA. 2016\n- - Data Sharing and Cooperative Agreement between the State Natural Heritage Program and NatureServe. 2016\n- - Development of wetlands in aging reservoirs: Opportunities to enhance wetland capacity and improve water quality. 2016\n- - Dissertation research: Assessing multi-scale drivers of pollinator assembly and plant-pollinator network architecture in the context of prairie restoration. 2016\n- - Eco-evolutionary dynamics of AMF mutualism. 2016"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:a48b698f-1fd3-4d82-aa02-5ce42ec30ac8>","<urn:uuid:6af8d21f-415e-41b7-9fbc-8129c84598a5>"],"error":null}
{"question":"What role do risk management and cost analysis play in delivering successful projects and maintaining quality standards?","answer":"Risk management and cost analysis are integral to project and quality success. In project management, risk management involves four stages of managing risks, along with response development and control, while cost analysis includes evaluating capital/operational costs, conducting cost-benefit analysis, and utilizing metrics like payback period and return on investment. From a quality perspective, increasing prevention costs and inspection costs through quality cost management can effectively reduce both internal and external quality losses. This preventive approach to quality control and input has been shown to positively correlate with quality management efficiency and overall firm performance.","context":["Project Management ‚Äî A 5 day course\nProject Managers are key to the success of all projects, and hold the responsibility for managing them on behalf of the business organisation which commissioned them. Therefore it is imperative that all Project Managers acquire and can apply certain core competencies necessary to deliver successful projects in today's dynamic business environment.\nThis course aims to take managers with some experience of running small projects and equip them with the key competencies to be successful Project Managers. These competencies include the ability to manage time, cost, people, quality and risk. The experiential nature of the course reinforces and encourages the use of best practice.\nWith the increasing significance being placed on the achievement of professional qualifications, this course represents a significant module in the Project Management Accreditation Programme. This course helps to establish the knowledge base required to proceed to either the Association for Project Management (APM) or the Project Management Institution (PMI) examinations.\nThis course carries the award of 37.5 Professional Development Units (PDU's) for PMI re-certification.\nThis is a comprehensive course extending over five days with a combination of lectures, workshops and exercises which are designed to build on the knowledge and expertise of those attending. It features a major emphasis on project case-study work, enabling participants to gain practical project management experience during the week.\nAfter completing this course the student will be able to:\n- Identify the factors which result in project success\n- Manage effectively the initiation and organisation of projects\n- Apply project planning and control techniques effectively\n- Review, audit and approve project plans developed by team members and other project managers\n- Implement relevant quality management techniques\n- Identify, assess and manage project risks and issues\n- Create and execute an effective project communications plan\n- Recognise the financial and budgetary implications of projects\n- Handle people management issues proficiently\nA residential option is usually available for courses held in Bournemouth. Please contact us if you would like further information.\nExperienced Project Managers, from either an IT or a business environment, who now wish to enhance their existing skills and knowledge to position themselves as effective Project Managers in today's dynamic and challenging environment.\nThis course is intended for those who have already undergone training in the fundamentals of project management and have at least one year's actual project management experience. It is not suitable for those seeking an introduction to project management.\nPublicly scheduled dates, locations, and prices\nA schedule of dates for this subject is not currently available. Please call 0333 210 0140 or use our contact form to enquire about places and availability.\nSuccessful Project Ingredients\n- The various views of success\n- Why projects fail\n- Factors critical to success\n- The Project Balance\nProject Management Competencies\n- The nine management competencies\n- Human Resource\n- Procurement Management\nProject Organisation and Stakeholders\n- Project Stakeholders - Who are they?\n- Project Steering Committee\n- Project Sponsor\n- Customer Manager\n- Project Manager\n- Project Team\n- Roles and Responsibilities\n- Stakeholders and Success Criteria\n- Project Support Office\n- Project Finance/Budget\n- Change Control\n- Project File/Log\n- Quality Management\n- Risk/Issues Management\n- Organisational Structure\n- Team Briefing\nQuality Management Techniques\n- What is Quality?\n- The Quality Plan\n- Quality Assurance reviews\n- Quality Control Reviews\n- Quality Spheres\nRisk and Issue Management\n- The Nature of Risk\n- The four stages of Risk Management\n- Response Development\n- Response Control\n- Issue Management\nProject Communications Planning\n- Outputs of Communication Management Plan\n- The Communications Cycle\n- The Who/Why/What/When of Communication\n- The Role of Communications during Change\nProject Planning Methods\n- Initiating the Planning Process\n- Base Content\n- Resource Levelling\n- Rolling Wave Plan\n- Outputs from Planning\n- Precedence Diagrams and Critical Path Analysis\n- Using the Network and Critical Path to manage the project\n- The Control System\n- Monitoring Project Progress\n- Project Status Evaluation\n- Phase-end Reviews\n- Performance Reporting\n- Exception Planning\n- Identifying appropriate action\nFinancial Justification and Budgeting\n- Why have a Financial Case?\n- Costs - Capital/Operational\n- Benefits - Tangible/Intangible/Indeterminate\n- Cost Benefit Analysis\n- Payback Period\n- Return on Investment\n- Discounted Cashflows\n- Net Present Value\n- Internal Rate of Return\n- Cost Budgeting\n- Cost Control\n- Updating the Cost Baseline\n- Gaining Approval\nProject Review and Recovery\n- Why/When carry out a Project Review\n- The Four Stage approach - Stop the Project, Overview, Detailed Study, Recovery Actions\nAssertiveness and Negotiation\n- Personal Rights and Responsibilities\n- How to behave Assertively\n- Overview of Negotiation\n- Preparing for Negotiation - Objective Setting, Ideal/Realistic/Fallback positions\n- Strengths/Weaknesses Matrix\n- Negotiation Tips\n- Setting up Customer Communication Channels\n- Administrative Close-out\n- Project Review - Successes/Lessons Learnt\n- Product Review - Objectives achieved, Financials, Performance, Improvements?\n- A comprehensive case study exercise is undertaken throughout as an important and integral part of this couse. It is designed to allow delegates practical opportunities to apply and review the use of the techniques covered on the course.","IMPACT OF QUALITY COST MANAGEMENT AND QUALITY MANAGEMENT ON FIRM PERFORMANCE: EVIDENCE FROM CHINA\nJournal of Global Economics, Management and Business Research, Volume 12, Issue 2,\nQuality cost management has a positive impact on enterprise performance, through strengthening quality management for products and services. In the process of quality cost management, increasing the prevention cost and inspection cost (preventive input) for quality can effectively reduce both internal and external quality losses, and contribute to a reduction in the total cost of quality and an increase in the profitability. Such a relationship between quality cost management and firm performance is conceptually accepted but few empirical evidence is available in the literature. Therefore we aim to empirically investigate the positive impact of quality cost management on quality management and firm performance in the context of business practice in China. By taking a questionnaire survey with a sample of enterprises in different regions across China, we perform regression analysis to evaluate the important relationships among quality cost management, quality management and firm performance. The results show that the preventive quality control and input are positively correlated to the efficiency of quality management. Furthermore, quality management and quality cost management are positively associated with firms‚Äô operating performance. We therefore draw out some recommendations on strengthening quality cost management and quality management.\n- Quality management\n- Cost of quality (CoQ)\n- Quality cost management (CoQ management)\n- preventive quality control\n- firm performance\nHow to Cite\nState Council of China, 2016, Implementation of Quality Development Action Plan; 2016.\nXi JP. Report on the 19th National Congress of CCP, October (in Chinese), People‚Äôs Publishing House. Beijing; 2017\nSatanova A, Sedliacikova M. Model for controlling the total costs of quality. Procedia. 2015;26:2-6.\nDahlgaard-Park SM, Reyes L, Chen CK. The evolution and convergence of total quality management and management theories. Total Quality Management & Business Excellence. 2018;29(9-10):1108-1128.\nJuran JM, Godfrey AB. Juran‚Äôs quality control Handbook, New York. McGraw-Hill; 1998.\nJuran JM. Quality control handbook. 1st edition. New York. McGraw-Hill; 1951.\nFeigenbaum AV. Total quality control. Harvard Business Review. 1956;34(6):93-101.\nCrossby P. Quality is free. McGraw-Hill. New York, US; 1979.\nInternational Organization of Standards (ISO). ISQ/TS 16949. Quality Management Systems-Practical Requirements for the Application of IAQ 9001. June. Geneva; 1999.\nConti T. How should quality-related concepts evolve to face the challenges of world globalization? The TQM Journal. 2013;25(6): 641-658.\nShank JK, Govindarajan V. Measuring the ‚Äòcost of quality‚Äô: A strategic cost management perspective. Journal of Cost Management. 1994;8(2):5-17.\nLove PED, Irani Z. A project management quality cost information system for the construction industry. Information & Management. 2003;40(7):649-661.\nDesai DA. Cost of quality in small- and medium-sized enterprises: Case of an Indian engineering company. Production Planning & Control. 2008;19(1):25-34.\nZakluta H. Cost of quality tradeoffs in manufacturing process and inspection strategy selection. Massachusetts Institute of Technology; 2011.\nWaisarayutt C, Wongwiwat T. Potential application of a quality cost model for fresh produce packhouses. Agriculture and Agricultural Science Procedia. 2015;3:26-31.\nWilliams AR, Wiele AV, Der Dale BG, Quality costing: a management review. International Journal of Management Review. 2000;1:441-460.\nSethi R, Sethi A. Can quality‚Äêoriented firms develop innovative new products? Journal of Product Innovation Management. 2009;26(2): 206-221\nOmar K, Murgan S. An improved model for the cost of quality, International Journal of Quality & Reliability Management. 2014;31(4): 395-418.\nSlater SF, Mohr JJ, Sengupta S. Radical product innovation capability: Literature review, synthesis, and illustrative research propositions. Journal of Product Innovation Management. 2014;31(3):552-566.\nFarooq MA, Kirchain R, Novoa H, Araujo A. Cost of quality: Evaluating cost-quality trade-offs for inspection strategies of manufacturing processes. International Journal of Production Economics. 2017;188:156-166.\nSower VE, Quarles R, Broussard E. Cost of quality usage and its relationship to quality system maturity. International Journal of Quality Reliability & Management. 2007;24: 121-140.\nStaiculescu O. A new vision of quality cost: An essential optimization tool for managerial accounting. Procedia - Social and Behavioral Sciences. 2012;62:1276-1280.\nMashwama N, Aigbavboa C, Thwala D. An assessment of the critical success factor for the reduction of Cost of poor quality in construction projects In Swaziland. Procedia Engineering. 2017;196:447-453.\nRezaei AR, √áelik T, Baalousha Y. Performance measurement in a quality management system. Scientia Iranica. 2011;18(3):742-752.\nAl-Dujaili MAA. Study of the relation between types of the quality costs and its impact on productivity and costs: Verification in manu-facturing industries. Total Quality Management & Business Excellence. 2013;24(3-4):397-419.\nPanuwatwanich K, Nguyen TT. Influence of total quality management on performance of Vietnamese construction Firms. Procedia Engineering. 2017;182:548-555.\nMiller JR, Morris JS. Is quality free or profitable? (A company‚Äôs efforts to improve may bring both economic and external social benefit), Quality Progress. 2000;33(1):50-53.\nWeinstein L, Vokurka RJ, Graman GA. Cost of quality and maintenance: Improvement approaches. Total Quality Management & Business Excellence. 2009;20(5):497-507.\nKim DY, Kumar V, Kumar U. Relationship between quality management practices and innovation. Journal of Operations Management. 2012;30(4):295-315.\nJames T, Orea L, Pollitt M. Estimating the marginal cost of quality improvements: The case of the UK electricity distribution companies. Energy Economics. 2012;34(5): 1498-1506.\nShafiq M, Lasrado F, Hafeez K. The effect of TQM on organizational performance: Empirical evidence from the textile sector of a developing country using SEM. Total Quality Management & Business Excellence. 2019; 30(1-2):31-52.\nWang YZ. Enhancing quality cost management to implement the quality responsibility accounting. Studies on Economics and Management (in Chinese). 1990;6:28-34.\nSun QB. A few issues on the theoretical system of cost of quality. Advances in Science and Technology and Policy. (in Chinese) 2002;5: 116-117\nHuang XY, Xu XQ, Zhang XZ. Control and analysis of cost of quality, Value Engineering (in Chinese). 2004;6:76-79.\nWang PX, Liu SW. Comparative study on quality cost control modeling, Journal of Haerbing Industrial University (in Chinese). 2006;9:98-102.\nWang G, Gao ZM, Lin WX. Improving CoQ management to enhance firms‚Äô competitive advantages. Journal of Shanghai Lixin Accounting School. (in Chinese). 2009;1:26-30.\nHuang Mei. The application status and development of CoQ management in Chinese enterprises, Times Financing. (in Chinese). 2013;9:186-187.\nShang SS, You JX. Relationship among the components of CoQ and analysis modeling, Management Review, (in Chinese). 2011;9: 160-166.\nWang YM, Zhao DZ. Control modeling for cost of quality in supply chain with the risk transformation mechanism. Research on Science and Technological Management (in Chinese). 2009;3:155-157.\nDuan YG. Studies on strategic CoQ management for business enterprises. Journal of Beijing United University (Social Science version). (in Chinese). 2017;1:64-69.\nTang XF. Investigation on quality management maturity of Shanghai enterprises, The TOQ Journal. 2015;25(4):417-430.\nLari A, Asllani A. Quality cost management support system: An effective tool for organization performance improvement. Total Quality Management & Business Excellence. 2013;24(3-4):432-451.\nSchiffaurova A, Thomson V. A review of research on cost of quality models and best practices, International Journal of Quality Reliability Management. 2006;23(4): 56-69.\nAbstract View: 1952 times\nPDF Download: 3 times"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:d3f2fc50-0322-4ae6-8013-4f23aa9a9b32>","<urn:uuid:de793ebc-c4b1-4129-85ca-575868e9d5fb>"],"error":null}
{"question":"What are the main benefits of having horses exercise in circular paths, and what are the key surface considerations that need to be addressed for safe training?","answer":"Circular exercise paths offer several benefits for horses. In paddock paradise setups, horses move more naturally and show increased activity levels, which helps manage sugar sensitivity and improves hoof quality. Similarly, in professional horse exercisers like the Equineciser, horses can move freely between gates in a circular path, allowing for natural speed regulation and proper limb loading due to the banked surface against the outside fence. Regarding surfaces, proper footing is crucial for safety. Sand alone is problematic as it compacts and becomes too hard, while wood chips on sand and shredded rubber over sand are unsatisfactory. The surface must provide adequate traction and cushioning, with good drainage and the ability to break up easily in freezing conditions to prevent joint injuries and sore feet.","context":["The benefits of a track or laneway around the perimeter of a paddock or small property\nThe article on spring grass and laminitis briefly looks at the benefits of a paddock paradise setup. This is a more in depth look with an actual example.\nIf your horses are experiencing bouts of low grade laminitis from the sugars and starch in your pasture, particularly in the spring, one option to consider is a ‚Äòpaddock paradise‚Äô type arrangement. This would entail some initial effort and expense but it would mean that your horses could graze in the morning when sugars and starch are at their lowest and then later, your horses could be placed in the laneway and get exercise which a small dirt yard cannot provide.\nIf you have a horse with insulin resistance that is unable to eat grass without laminitis due to to high sugar and starch levels, a laneway system with low sugar and starch hay distributed in several places is far better than a small dirt yard.\nThe paddock paradise idea is where you fence off a laneway around the perimeter of a paddock using electric tape or similar around the perimeter of the whole property. Depending on the sugar sensitivity of your horses, you may have to kill the grass with Roundup or their grazing may limit the grass sufficiently. Grassy hay which is lowest of all the hays on average in sugars and starch could be distributed in the laneway.\nHorses kept in paddock paradise type laneways are reported to move far more than horses in paddocks, happier with the increased activity and the movement is beneficial for managing sugar sensitivity and hoof quality.\nJaime Jackson, a barefoot enthusiast in America came up with the idea of paddock paradise. His book is called ‚ÄòPaddock Paradise, A Guide to Natural Horse Boarding‚Äô.\nAlyssa Brugman offers a barefoot rehabititation centre in the Hunter Valley in NSW. With the time and effort needed daily to rehabilitate hooves, she has worked 'miracles' in bringing chronically lame horses back to soundness.\nAlyssa's experience with paddock paradise\n\"OK, well it started off being about water. I was aware of the Jaime Jackson paddock paradise concept, because I had done some reading, and heard others talk about it, but I always assumed it would be too difficult or too expensive, and I wasn't really sure what the benefits would be other than warm fuzzies. Besides that, we had just spent the last few years changing the fences that we had, because this property used to be a dairy. We changed the barbed wire to nylon sight wire and plain wire, then ran stand-offs on the inside. I was very happy with what we had, and I felt it was safe. We also put in a foaling paddock with mesh fences and a shelter that we could see from the house, and a pea gravel yard, so that had been our priority.\nWe have a creek running right through the middle of the property. If you can imagine there is very lush kikuyu undersown with clover on one (flat) side and then on the other (hill) side, the soil is poorer and we have more native grasses.\nUp until last year, billabongs in our creek provided water to almost every paddock. The whole property is 35 acres. We have seven paddocks (of varying sizes). I run three separate herds by activity level. The numbers change, because horses come and go, but basically one herd is oldies (4 or 5 horses), one of youngies (7 to 9 horses) and one of aggressive or nutty horses (only 2 or 3 together). I was doing a rotation of the paddocks, the way I imagine most people would. I let the horses eat it down to about 5-10cm, move them, then spread the poos with a harrow and rest the paddock. It re-grows to about 20-30 centimetres - give or take, and then I put them back in.\nI was locking up the founder horses overnight in the pea gravel yard, which is about 30 x 15 m (this used to be the cattle yard with the chase). They had soaked hay. They didn't founder, but they also weren't flourishing, and I still struggled with thrush, wall separation and cracks, white line disease, and coat quality. These were horses that before they came here used to spend their springs and summers flat out on the ground in agony, so I wasn't going to quibble over a bit of seedy toe. I had been pleased with getting them through without being lame, but it was still there in the back of my mind that I could do better.\nThen we didn't get any decent rain. The billabongs dried up. I had to keep the horses in the paddocks with dams, or in paddocks adjacent to paddocks with dams, which meant I wasn't able to do my rotation. There was no rain breaking down the spread poos. Paddocks were getting stressed. Horses were getting fat. The dams were becoming little muddy holes because the horses were rolling in them, and squashing any plants that were growing around the edges.\nIt wasn't working.\nWe had bought pigtail posts and electric tape, because we were doing mass plantings of natives to secure the banks of the creek and also to provide shade for the paddocks (this place had almost no trees). We were fencing off these areas and running the tape off the same solar chargers that ran the stand-offs. This was changing the shape of the paddocks to a much more organic shape, rather than squares, because the fence would follow the creek line in a serpentine, and we were planting trees in corners and thus making the paddocks a hexagon-type shape.\nSo one day, after looking at the sad little puddle that was my front dam, I got my left over pigtail posts and my tape and made a long corridor isolating the dam and directing the youngies herd from the middle of the property to a water trough right up here near the house, which I could fill from our tanks. The corridor was about 250 metres long and about 15 - 20 metres wide, with a kind of bulb on the end where the water is. It took about an hour. I used about 25-30 pigtail posts ($50 for a pack of ten) and a 400m reel of econobraid electric tape ($65) and a solar charger ($260), plus a galvanized star picket that I used as an earth ($7). This corridor directed them into a paddock on the hill (on the poor pasture) that was essentially round because of the tree plantings in the corners.\nWhat I found was that most of the time they either cantered along the corridor or galloped. When they hit the open space, if they weren't galloping already they would increase speed. They would follow the fenceline, and instead of pulling up in the corner, they would go around (and around and around).\nComing back the other way, they were cutting the corner at the bottom, and wearing a big divot, so I put a log there, thinking they would go around it. Instead they started jumping it. Gleefully!\nI will just pause here to say that most of the horses that we take are usually ex-dressage horses, showjumpers, show horses, some OTTBs ‚Äì horses disposed towards athleticism, but that have been in shoes from a very young age, ridden in big nasty bits, ridden through lameness with drugs or 'remedial shoeing', grain fed, stabled etc etc. They get to about 15 years old and they fall apart physically, or get sour and mean, or have mysterious incurable conditions. We take them, pull their shoes, balance their feet, put them in a herd and let them be horses, and they usually turn around. We can then send them back to their owners, or find a new home, or if they don't come good then they can stay with us.\nSuddenly these horses were traveling at speed along this corridor several times a day.\nThen I had a baby, and I left the founder horses out while I was in hospital, and when I came back five days later, they looked terrific! So I decided to leave them out and watch closely. We also had a newborn, and it was more convenient.\nFour other things happened simultaneously with my corridor that contributed significantly to the soundness of these horses:\n1. I contacted Carol Layton of Balanced Equine and she balanced minerals for my pasture and prepared a diet for one horse from each herd. Horses that weren't being fed at all up until then got the mineral mix with a handful of chaff. This has made a huge difference.\n2. I found a new dentist who is a mile better than my old one.\n3. I found a new vet/chiro/osteo who was turning around in one visit horses that I had essentially given up on.\n4. I bought a treeless dressage saddle.\nOh, and 5. I put the horses with arthritis on a joint supplement.\nFive weeks after I had my baby I had a dressage lesson on one of my old men. He hadn't been ridden for over six months, and we were asking him to do quite difficult gymnastic, lateral work. He was doing tempi changes and not even breaking a sweat. Different horse!\nIt took a little while to get the diets right, because all the horses here are idiosyncratic (or they wouldn't be here!), but hoof quality improved. Wall cracks were growing out, frogs were more robust. These horses that were not lame, lame but not sound, sound either were running around looking ten years younger. Coats were improving. Horses that always had just a touch of greasy heel most of the time cleared up. Tempers were getting better. There were fewer scuffles. Weights were better all round (except for one welshy who is a different story). Even their manes and tails were tangle free!\nTrailriding they are unflappable, even in large groups, in the wind, with strange dogs. I took the very worst founder horse, who's been out 24/7 for a few months now in Edge boots on the fronts. He was moving forward, ears pricked on road base. Beautiful! Happy! Enjoying himself!\nI took a little mare out who I hadn't been on for a year and a half on hard trail ride up and down mountains, bare. She should have been exhausted or at least footsore, but she wasn't. She was fit.\nSo then I go completely nuts for paddock paradise. Basically I made a racetrack around two of the paddocks. Two of them are long and narrow already. So 4 of the 7 paddocks are now paddock paradise. It cost me about $500 for each one ‚Äì each of which has about 400 metres of electric braid, up to 30 pigtail posts, one solar charger and a galvanised star picket for an earth. With two of them I can use the one solar charger at a gate and attach it to different paddocks.\nI also bought some bungee gates so that I can block sections or to direct horses through gates in to different paddocks (extend the track through a gate to a create figure eight). I've organised it so that three paddocks access water from troughs near the house (still no rain).\nThe horses that I was feeding before paddock paradise are now receiving less in volume than they were receiving before, but now we have these squares in the middle of the paddock that I'm not quite sure what to do with. Then one day I'm talking to my neighbour, Trevor, who is a proper farmer, and he tells me that he is happy to cut and bale hay for me for an hourly rate, because he has all the equipment, and we have an adjoining gate. I asked him if I need to plant something special and he said he is happy to bale anything.\nSo our plan now, over the next twelve months is to remineralise the soil. We have made headway with weeds since we have been here, but we'll try to eliminate them completely. Then we will grow grasses, bale them, get the hay tested and then balance minerals to our own hay. The feed quality will be consistent and balanced, and hopefully in the long run much cheaper! We will know exactly what's in it, and know that there are no chemicals being used.\nIn the tracks we will introduce more obstacles, and a range of surfaces ‚Äì sand, gravel, water, jumps. In some places we will make permanent fences, but I like having the versatility of the pigtail posts.\nI have found this to be so exciting. The difference has been quite dramatic and I haven't even finished yet.\nWith planning and help you could do it in an afternoon. With planning, shopping around and haggling you could probably do it much cheaper than I have too. I did a lot of it on my own, and in a spare hour here or there while my babies were asleep, so you don't need to be a fencing whizz. If you agisted you could buy your own equipment and take it with you. I only wished I had done it years ago.\nI'm grateful to Alyssa for her permission to publish her report on paddock paradise. Her report was originally written for the Myth Busters Natural Horse Care group. If you have a horse in dire need of skilled attention and rehabilitation, contact me for Alyssa's contact details.\nJaime Jackson (2007) ‚ÄòPaddock Paradise, A Guide to Natural Horse Boarding‚Äô\nMyth Busters Natural Horse Care A great resource of information based on science and not on myths or pseudo science. Not entirely on nutrition, also looks at worming and training methods and other aspects of horse management.\nNatural Horse Care - a really neat, no expense spared example but most people economise by just using a strand or two of electric tape.\nNatural Horse Resource\nWolnowsky N Slowly creating paddock paradise\nCarol Layton B.Sc, M.Ed","Equineciser Free Flow Horse Exercisers\nThe Equineciser horse exerciser offers an advantage over earlier versions of this type of device: hot walking machines and typical horse walkers. The older style of hot walker required the horse to be tied to an arm of the walker. If a horse pulled back or balked on one of these walkers, he could receive a neck injury. The machines were designed to go at one speed only, for the walk, so they were not suitable for sport conditioning.\nThe Equineciser horse walker allows the horse to exercise untethered between moving gates, so he can move in a more natural manner, with his head free. A carousel rotates the six gates that provide individual compartments for six horses to exercise and walk freely. There is a distance of 34 feet between each gate, so the horse has plenty of room. When allowed to manage his own speed, a horse will go a little slower at times and a little faster at times. The free flow horse exerciser allows for this natural regulation of energy expenditure, resulting in a more comfortable exercise session.\nThe Centaur Horse Equineciser can go from 0 to 20 miles per hour, allowing the horse to exercise at all speeds, including the walk, trot, jog, and gallop in both directions. The horse moves between outer and inner fences that are set in concentric circles. The outside fence forms a circle with a diameter of 68 feet. As the horse travels the circle, the footing banks against the outside fence. The faster he goes, the more the surface banks, so limb loading remains even. This is the contrast to lunging in the arena, where the surface is flat, the circle is small, and considerable-torquing force is placed on the limbs. The centrifugal forces are more like those on a racetrack and help the racehorse adapt to that strain. The Exerciser offers an advantage over the high-speed treadmill in that it provides the opportunity to train around a curve, rather than continuously going in a straight line. This might help in the adaptation of the cannon bones to the compressive forces of running around the turn on a track-like-surface in a way that is impossible to achieve on a treadmill.\nHorse exercisers can be built with or without a roof, but the roof provides protection from bad weather. Whether the exerciser has a roof or not, the surface is a primary concern so that footing remains good and injuries from bad footing are avoided.\nEquinciser horse walkers have been tried on variety of surfaces, and some have proven better than others:\n- Sand will compact and become too hard. Sand also freezes and does not break up easily. Frozen footprints in the sand create a choppy surface.\n- Wood chips placed on top of sand do not create a satisfactory surface.\n- Shredded rubber provides a resilient surface, but is unsatisfactory when placed over sand.\nUsing the Horse Exerciser\nPlanning your use of the horse exerciser will follow the same guidelines that you would use for any new equestrian training equipment or training technique. The first time your horse goes in the exerciser the goal is to acclimate him to the equipment. Walk the horse until he is comfortable, usually 15 to 20 minutes. 95% of horses take to the exerciser with no problem during the first session. The technique is to put the horse in, release him, and then turn on the exerciser at walking speed. On the first day of using the exerciser with your horse, do not walk him until he is tired.\nThe goal of the first few sessions is simply to give the horse an opportunity to be comfortable in the exerciser. Horsemanship is still needed to use this equipment to the benefit of the horse. Observation and attention to task are necessary just as these skills are in any other training program.\nOnce the horse has become accustomed to walking in the exerciser, plan a gradually increasing program that is based on the fitness goals for each individual horse. Is your goal to maintain the fitness level reached during the summer? Is it to rehabilitate from an injury during the competitive off-season? Is it to increase the horse‚Äôs knowledge of new tasks and environments? Plan your training bouts to increase in duration and intensity gradually. Do not try to accomplish all your fitness goals at once.\nUsing What‚Äôs at Hand\nYou don‚Äôt have an indoor exercise facility? You still should be concerned about the surface on which you train when weather leaves footing unsafe, choppy or frozen. If a training path around your paddock is the route you follow, the minimum investment would be to improve the drainage by grading it to a one degree slope under a surface such as those mentioned above- one that will break up easily when the temperature is below freezing. Do not turn horses loose in the training paddock as they will dig holes in your surface and destroy it.\nA Safe surface is essential for any training program in the winter so the horse will not lose muscle and cardiovascular conditioning. Injuries to both horse and rider can occur on a slick surface. A surface that is frozen and will not break up promotes sore feet and injuries to joints.\nTraining for any equine sport requires rapid changes of direction, increases in speed, or negotiating jumps and concussion of the foot on the ground. A surface that provides adequate traction and cushion for your particular equine sport is the ideal surface."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:9bf44772-b4b0-4804-b2a9-93693822181d>","<urn:uuid:bd1463b7-e7be-4c45-b826-9120010ab338>"],"error":null}
{"question":"How do MEMS cantilevers work as chemical sensors?","answer":"MEMS cantilevers can work as chemical sensors by coating their upper side with a recognition receptor layer, such as an antibody layer. They can operate in two modes: static mode, where the sensor response is measured by the beam bending relative to a reference microcantilever, or dynamic mode, where the beam vibrates at its resonance frequency and variations in this frequency indicate the analyte concentration.","context":["A cantilever is a rigid structural element, such as a beam or a plate, anchored at one end to a (usually vertical) support from which it protrudes; this connection could also be perpendicular to a flat, vertical surface such as a wall. Cantilevers can also be constructed with trusses or slabs. When subjected to a structural load, the cantilever carries the load to the support where it is forced against by a moment and shear stress.\nCantilever construction allows overhanging structures without external bracing, in contrast to constructions supported at both ends with loads applied between the supports, such as a simply supported beam found in a post and lintel system.\nIn bridges, towers, and buildings\nCantilevers are widely found in construction, notably in cantilever bridges and balconies (see corbel). In cantilever bridges, the cantilevers are usually built as pairs, with each cantilever used to support one end of a central section. The Forth Bridge in Scotland is an example of a cantilever truss bridge. A cantilever in a traditionally timber framed building is called a jetty or forebay. In the southern United States, a historic barn type is the cantilever barn of log construction.\nTemporary cantilevers are often used in construction. The partially constructed structure creates a cantilever, but the completed structure does not act as a cantilever. This is very helpful when temporary supports, or falsework, cannot be used to support the structure while it is being built (e.g., over a busy roadway or river, or in a deep valley). So some truss arch bridges (see Navajo Bridge) are built from each side as cantilevers until the spans reach each other and are then jacked apart to stress them in compression before finally joining. Nearly all cable-stayed bridges are built using cantilevers as this is one of their chief advantages. Many box girder bridges are built segmentally, or in short pieces. This type of construction lends itself well to balanced cantilever construction where the bridge is built in both directions from a single support.\nThese structures rely heavily on torque and rotational equilibrium for their stability.\nIn an architectural application, Frank Lloyd Wright's Fallingwater used cantilevers to project large balconies. The East Stand at Elland Road Stadium in Leeds was, when completed, the largest cantilever stand in the world holding 17,000 spectators. The roof built over the stands at Old Trafford uses a cantilever so that no supports will block views of the field. The old, now demolished Miami Stadium had a similar roof over the spectator area. The largest cantilevered roof in Europe is located at St James' Park in Newcastle-Upon-Tyne, the home stadium of Newcastle United F.C.\nAnother use of the cantilever is in fixed-wing aircraft design, pioneered by Hugo Junkers in 1915. Early aircraft wings typically bore their loads by using two (or more) wings in a biplane configuration braced with wires and struts. They were similar to truss bridges, having been developed by Octave Chanute, a railroad bridge engineer. The wings were braced with crossed wires so they would stay parallel, as well as front-to-back to resist twisting, running diagonally between adjacent strut anchorages. The cables and struts generated considerable drag, and there was constant experimentation for ways to eliminate them.\nIt was also desirable to build a monoplane aircraft, as the airflow around one wing negatively affects the other in a biplane's airframe design. Early monoplanes used either struts (as do some current light aircraft), or cables like the 1909 Bleriot XI (as do some modern homebuilt aircraft). The advantage of using struts or cables is a reduction in weight for a given strength, but with the penalty of additional drag. This reduces maximum speed and increases fuel consumption.\nHugo Junkers endeavored to eliminate virtually all major external bracing members, only a dozen years after the Wright Brothers' initial flights, to decrease airframe drag in flight, with the result being the Junkers J 1 pioneering all-metal monoplane of late 1915, designed from the start with all-metal cantilever wing panels. About a year after the initial success of the Junkers J 1, Reinhold Platz of Fokker also achieved success with a cantilever-winged sesquiplane built instead with wooden materials, the Fokker V.1.\nThe most common current wing design is the cantilever. A single large beam, called the main spar, runs through the wing, typically nearer the leading edge at about 25 percent of the total chord. In flight, the wings generate lift, and the wing spars are designed to carry this load through the fuselage to the other wing. To resist fore and aft movement, the wing will usually be fitted with a second smaller drag-spar nearer the trailing edge, tied to the main spar with structural elements or a stressed skin. The wing must also resist twisting forces, done either by a monocoque \"D\" tube structure forming the leading edge, or by the aforementioned linking two spars in some form of box beam or lattice girder structure.\nCantilever wings require a much heavier spar than would otherwise be needed in cable-stayed designs. However, as the size of an aircraft increases, the additional weight penalty decreases. Eventually, a line was crossed in the 1920s, and designs increasingly turned to the cantilever design. By the 1940s almost all larger aircraft used the cantilever exclusively, even on smaller surfaces such as the horizontal stabilizer, with the Messerschmitt Bf 109E of 1939‚Äì41 being one of the last World War II fighters in frontline service to have bracing struts for its stabilizer.\nIn microelectromechanical systems\nCantilevered beams are the most ubiquitous structures in the field of microelectromechanical systems (MEMS). An early example of a MEMS cantilever is the Resonistor, an electromechanical monolithic resonator. MEMS cantilevers are commonly fabricated from silicon (Si), silicon nitride (Si3N4), or polymers. The fabrication process typically involves undercutting the cantilever structure to release it, often with an anisotropic wet or dry etching technique. Without cantilever transducers, atomic force microscopy would not be possible. A large number of research groups are attempting to develop cantilever arrays as biosensors for medical diagnostic applications. MEMS cantilevers are also finding application as radio frequency filters and resonators. The MEMS cantilevers are commonly made as unimorphs or bimorphs.\nTwo equations are key to understanding the behavior of MEMS cantilevers. The first is Stoney's formula, which relates cantilever end deflection Œ¥ to applied stress œÉ:\nwhere is Poisson's ratio, is Young's modulus, is the beam length and is the cantilever thickness. Very sensitive optical and capacitive methods have been developed to measure changes in the static deflection of cantilever beams used in dc-coupled sensors.\nThe second is the formula relating the cantilever spring constant to the cantilever dimensions and material constants:\nwhere is force and is the cantilever width. The spring constant is related to the cantilever resonance frequency by the usual harmonic oscillator formula . A change in the force applied to a cantilever can shift the resonance frequency. The frequency shift can be measured with exquisite accuracy using heterodyne techniques and is the basis of ac-coupled cantilever sensors.\nThe principal advantage of MEMS cantilevers is their cheapness and ease of fabrication in large arrays. The challenge for their practical application lies in the square and cubic dependences of cantilever performance specifications on dimensions. These superlinear dependences mean that cantilevers are quite sensitive to variation in process parameters, particularly the thickness as this is generally difficult to accurately measure. However, it has been shown that microcantilever thicknesses can be precisely measured and that this variation can be quantified. Controlling residual stress can also be difficult.\nChemical sensor applications\nA chemical sensor can be obtained by coating a recognition receptor layer over the upper side of a microcantilever beam. A typical application is the immunosensor based on an antibody layer that interacts selectively with a particular immunogen and reports about its content in a specimen. In the static mode of operation, the sensor response is represented by the beam bending with respect to a reference microcantilever. Alternatively, microcantilever sensors can be operated in the dynamic mode. In this case, the beam vibrates at its resonance frequency and a variation in this parameter indicates the concentration of the analyte. Recently, microcantilevers have been fabricated that are porous, allowing for a much larger surface area for analyte to bind to, increasing sensitivity by raising the ratio of the analyte mass to the device mass. . Surface stress on microcantilever, due to receptor-target binding, which produces cantilever deflection can be analyzed using optical methods like laser interferometry. Zhao et al., also showed that by changing the attachment protocol of the receptor on the microcantilever surface, the sensitivity can be further improved when the surface stress generated on the microcantilever is taken as the sensor signal.\nIn storage applications\nA cantilever rack is a type of warehouse storage system consisting of the vertical column, the base, the arms, and the horizontal and/or cross-bracing. These components are fabricated from both roll formed and structural steel. The horizontal and/or cross bracing are used to connect two or more columns together. They are commonly found in lumber yards, woodworking shops, and plumbing supply warehouses.\nA folding cantilever tray is a type of stacked shelf that can be unfolded to allow convenient access to items on multiple tiers simultaneously. The shelves can be collapsed when not in use for more compact storage. Because of these properties folding cantilever trays are often used in baggage and toolboxes.\n- Applied mechanics\n- Cantilever bicycle brakes\n- Cantilever bicycle frame\n- Cantilever bridge\n- Cantilever chair\n- Cantilever method\n- Corbel arch\n- Euler‚ÄìBernoulli beam theory\n- Glossary of industrial scales and weighing\n- Grand Canyon Skywalk\n- Knudsen force in the context of microcantilevers\n- Moment (physics)\n- Hool, George A.; Johnson, Nathan Clarke (1920). \"Elements of Structural Theory - Definitions\". Handbook of Building Construction (Google Books). vol. 1 (1st ed.). New York: McGraw-Hill. p. 2. Retrieved 2008-10-01.\nA cantilever beam is a beam having one end rigidly fixed and the other end free.\n- \"GMI Construction wins ¬£5.5M Design and Build Contract for Leeds United Football Club's Elland Road East Stand\". Construction News. 6 February 1992. Retrieved 24 September 2012.\n- IStructE The Structural Engineer Volume 77/No 21, 2 November 1999. James's Park a redevelopment challenge\n- The Architects' Journal Existing stadiums: St James' Park, Newcastle. 1 July 2005\n- ELECTROMECHANICAL MONOLITHIC RESONATOR, US Pat.3417249 - Filed April 29, 1966\n- R.J. Wilfinger, P. H. Bardell and D. S. Chhabra: The resonistor a frequency selective device utilizing the mechanical resonance of a silicon substrate, IBM J. 12, 113‚Äì118 (1968)\n- P. M. Kosaka, J. Tamayo, J. J. Ruiz, S. Puertas, E. Polo, V. Grazu, J. M. de la Fuente and M. Calleja: Tackling reproducibility in microcantilever biosensors: a statistical approach for sensitive and specific end-point detection of immunoreactions, Analyst 138, 863‚Äì872 (2013)\n- A. R. Salmon, M. J. Capener, J. J. Baumberg and S. R. Elliott: Rapid microcantilever-thickness determination by optical interferometry, Measurement Science and Technology 25, 015202 (2014)\n- P. C. Fletcher, Y. Xu, P. Gopinath, J. Williams, B. W. Alphenaar, R. D. Bradshaw, R. S. Keynton, \"Piezoresistive Geometry for Maximizing Microcantilever Array Sensitivity,\" presented at the IEEE Sensors, Lecce, Italy, 2008.\n- B«énic«é, Florinel-Gabriel (2012). Chemical Sensors and Biosensors:Fundamentals and Applications. Chichester, UK: John Wiley & Sons. p. 576. ISBN 9781118354230.\n- Noyce, Steven G.; Vanfleet, Richard R.; Craighead, Harold G.; Davis, Robert C. (1999-02-22). \"High surface-area carbon microcantilevers\". Nanoscale Advances. 1 (3): 1148‚Äì1154. doi:10.1039/C8NA00101D. Retrieved 2019-05-29.\n- Yue Zhao,Agnivo Gosai, Pranav Shrotriya : Effect of Receptor Attachment on Sensitivity of Label Free Microcantilever Based Biosensor Using Malachite Green Aptamer https://doi.org/10.1016/j.snb.2019.126963\n- Inglis, Simon: Football Grounds of Britain. CollinsWillow, 1996. page 206.\n- Madou, Marc J (2002). Fundamentals of Microfabrication. Taylor & Francis. ISBN 0-8493-0826-7.\n- Roth, Leland M (1993). Understanding Architecture: Its Elements History and Meaning. Oxford, UK: Westview Press. pp. 23‚Äì4. ISBN 0-06-430158-3.\n- Sarid, Dror (1994). Scanning Force Microscopy. Oxford University Press. ISBN 0-19-509204-X."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:ae6e49d2-e901-4941-a0ed-7c3c55cd7c94>"],"error":null}
{"question":"How do backup power solutions compare between traditional PowerHA setups and modern high-density data centers?","answer":"In PowerHA setups, backup power primarily focuses on ensuring continuous data access during system switches, with the main concern being maintaining IASP functionality between systems. In contrast, modern high-density data centers require more sophisticated backup power solutions due to their intense power demands. They use modular UPS systems that can achieve 95% efficiency even at 20% load and can scale up to 4MVA with parallel expansion of up to 8 units. These modern UPS systems include advanced features like self-diagnosis and aging detection mechanisms for batteries and components, which help prevent malfunctions and power loss. Additionally, high-density data centers must consider both power backup and cooling backup simultaneously, as power failures can lead to heat buildup and server shutdowns due to their concentrated power usage.","context":["Ask An Engineer: PowerHA FAQ\nAs principal software engineer for PowerHA at HelpSystems, it‚Äôs my pleasure to help educate PowerHA users and empower them to take full advantage of this cool technology. I realize not everyone is able to attend my educational sessions at COMMON, and my day job developing this product keeps me pretty busy, so I wanted to share a few great questions that I‚Äôve come across recently. Maybe they are your questions, too. I hope you find the answers helpful!\n1. How do PowerHA clusters work? If I have 10 LPARs‚Äîfive at one site and five at another‚Äîeach a mix of production, development, and test partitions, how should I design the cluster?\nThere are really two schools of thought on this one. The first is, if you put everything in a single cluster, that means that you have a single point of control from any node in the cluster. You can easily control every environment from any one node. This can make it easier to manage the entire environment of 10 LPARs, but it comes with drawbacks.\nFor example, what if someone is on the dev environment and thinks they are switching the dev environment but accidentally switch the production environment instead? Likewise, are credentials the same for all users between all the LPARs? Or do production LPARs have different credentials from development and test environments?\nBecause of this, you‚Äôll often see that people tend to keep a separate cluster for each environment. This separate cluster for each environment is typically the way that IBM Lab Services recommends. One cluster for production, one cluster for development, and one for test. That said, there are a number of customers that have things combined.\nIf you have a single cluster, it‚Äôs easy to have a single partition for FlashCopy. However, if you have separate clusters, then the typical route is to have a FlashCopy LPAR per environment. This is partially for the same data separation reasons I mention above. If you really want a single FlashCopy partition and want to have separate clusters to do FlashCopy, there is something called the independent ASP (IASP) assigner that can be used for doing so, but it isn‚Äôt quite as integrated as the method of having a dedicated FlashCopy partition per environment.\nPowerHA provides many options for how to set up the environment. I recommend working with your business partner to help decide the architecture that is best for your unique environment.\n2. What are RTO/RPO for each PowerHA option in hours/minutes? I read that IASP vary on can take a long time during failover.\nWe don‚Äôt publish specific recovery time objective (RTO) and recovery point objective (RPO) for PowerHA options for a number of reasons. But here‚Äôs what I can tell you.\nWhat your RTO and RPO are going to be all depends on the specific configuration and implementation. This is true for any high availability solution. For example, a synchronous solution (such as Metro Mirror) will provide a near-zero recovery point during normal operation due to the synchronous nature of things. Even if you have a system crash, anything that is journaled locally will recover as part of the vary on of the IASP.\nAs you move systems further apart, if you stuck with a synchronous solution, the performance of your system starts to decrease due to the amount of time it takes for the data to get to both copies, and so you move to a technology such as Global Mirror. With Global Mirror, your recovery point will be dependent upon how much data you are changing and what sort of bandwidth and latency you have between the sites. The PowerHA Redbooks have high-level information on how to determine disk write rates to help determine bandwidth needs. In addition, the IBM Lab Services group does have a bandwidth analysis offering to help give an idea of how much bandwidth is needed for the selected solution to achieve an acceptable recovery point objective (RPO).\nWhen talking about recovery time objective, a synchronous solution will typically provide a lower RTO simply because there is no waiting for data to synchronize as part of the switch. The switch time for a planned switch typically consists of the following:\n- End applications on the production system\n- Perform the switch of the replication product\n- Start applications on the new production system\nWhat we have typically seen in many environments is that steps #1 and #3 are the longer steps. I have seen anything from 30 seconds to start up applications on the new production system to nearly two hours to start up all applications. That is something you have to do regardless of the underlying replication product.\nYou had mentioned that you have heard vary on takes a long time. The vary on of an IASP is almost like a small part of the IPL process for the system, only you aren‚Äôt bringing up the operating system, just user data. So, you can think of the IASP vary on like a small piece of a system IPL. This is an area that has seen lots of improvements over the last few years and has been reduced significantly. In fact, IASP vary on was improved even more in IBM i 7.4. In some instances, this vary on can be just a few seconds. In other instances, it can be longer. It really is dependent upon the system, and the actual data within the IASP. Here is a demo video.\n3. Can we do PowerHA without IASP? What solution looks like with PowerHA without IASP?\nPowerHA is designed around the concept of an IASP and an IASP is the foundation of PowerHA technologies. An IASP is really just a way to separate your application data from the operating system. In a way, it is almost like a USB drive plugged into a computer. You can unplug it from one computer and plug it into another computer and access all your data. The really nice thing about an IASP is that it is a lot more integrated into the system than a USB drive in a PC. When implemented, most users have no idea that their data is in an IASP because to them, they just access their data in the libraries as they did before.\n4. I‚Äôm getting little confused with Global/Metro Mirror options with PowerHA and storage replication Global/Metro options without PowerHA. Can you help clarify?\nThe option without PowerHA is something we might call full system replication. What is happening is you are replicating the entire system. The picture might look something like this:\nYou have a secondary system ready to boot up if you need to switch. The disadvantage of this approach is that you are replicating the operating system and temporary data. With IBM i single-level storage, this means that you could be replicating anything in memory‚Äîincluding temporary storage‚Äîwhich can add up to a significant amount of bandwidth over what PowerHA with an IASP would need. With an IASP, only objects in the IASP are replicated.\nAlso, since you are replicating the operating system, you don‚Äôt have protection against software outages, such as applying fixes or operating system upgrades. Therefore, you must take an outage while upgrading/updating the operating system. With an IASP based approach, you can apply fixes or upgrades to the target system while everyone is accessing the production system, then switch to the target system and upgrade the original production system. This effectively reduces your OS upgrade/update time to just the amount of time it takes to do the switch.\nOne advantage that replicating an IASP with PowerHA and external storage has over logical replication solutions or full system replication solutions is that, when you are upgrading the target system (say doing an OS upgrade to the latest version), all of your data in the IASP is still being replicated. This means that your recovery point is protected even though the target system is down.\nIt really boils down to what types of outages you want to protect yourself against.\n5. Why do we need PowerHA when we can have storage replication Metro/Global Mirror options with V7000?\nPowerHA is the piece that integrates the operating system and the external storage replication together. This allows you to manage everything from IBM i, and helps provide data protection. This way, when doing a switch, PowerHA takes care of the steps in both places to make it a single button switch. In addition, PowerHA provides the interfaces to allow for switching an IASP between systems.\n6. In the case of PowerHA when source (SRC) and target (TGT) systems are up, only IASP is varied off at TGT. Why we don‚Äôt call it an active-active solution as both LPARs are up?\nEven though both the source and target systems are up, the actual user data is in the IASP. Since user data is not accessible on both systems at once, we don‚Äôt typically refer to it as an active-active solution, but rather an active-passive solution. Meaning that the target system is ready to take over in the event the primary system goes down, but you can only access the data in the IASP on the primary system.\nThe number of shops using PowerHA for IBM i high availability has nearly doubled in the last few years. What makes PowerHA so popular? Find out here.","Data center power and cooling strategies for increasing rack power density\nIn recent years, data centers have faced many challenges due to rapid changes in IT technologies and trends. High density data centers have become an issue that enterprises must face.\nAs people have stricter demands for internet services, enterprises must think of ways to satisfy user expectations for 24x7 availability. The number of servers keeps increasing while more computing capabilities and resources are incorporated in smaller and smaller cases. Small Form Factor (SFF), Blade Servers to Hyperscale servers to Composable Infrastructure used to achieve more flexible frames, are all being developed in response to this demand.\nHigher density servers mean higher power consumption is needed for each server. As the world focuses more and more on energy consumption, enterprises have started to treat energy efficiency issues and environmental responsibilities more seriously. Virtualization technology offers solutions for enterprises that allow each server to handle a greater workload so they are utilized to their fullest. At the current stage of the global cloud trend, many enterprises already see ‚ÄúCloud First‚Äù as one of their top strategies. More IT budgets are investing in ‚Äúcloud‚Äù related IT infrastructure and software and some enterprise organizations or IT suppliers even use ‚ÄúCloud Only‚Äù as their main strategy. When servers are densely placed in cloud data centers, it will definitely bring greater maintenance challenges.\nSince the development of mobilization and social media platforms, the data required for massive computing power to analyze and extract has increased rapidly. With the continued development of the Internet of Things (IoT), data collected through sensors will be guided to backend data centers to perform big data analysis. These changes are leading data centers to develop towards high density. With the rapid growth in the density of data center equipment, data centers built along traditional concepts are no longer enough.\nPotential issues from high power density\nAccording to a research report by Colocation America (2014), the power density of a single rack cabinet in data centers was approximately 6kW in 2008, which reached 12kW in 2016. It is estimated that by 2020, the power density of a single rack cabinet in data centers will achieve 16.5kW. For example, when Intel retrofitted two foundries into a green data center with high power density, the power density per rack reached as high as 43kW.\nSource: Colocation America, 2014\nWith the rapid growth of power density per rack in data centers as a leading trend, enterprises must find more effective ways to face the challenges that come with it. For example, high density achieves better space utilization and the response time of system failure is reduced significantly. However, once there is a power failure, the large amounts of heat generated by the equipment cannot be extracted and will result in a server shutdown.\nThe ever-increasing power density has also far exceeded the processing capabilities of most old facilities. In previous years, each rack in a data center was designed for 6kW power density. However, when faced with high density racks of 15kW or above, facilities clearly do not meet requirements. When enterprises use technology that requires massive resources such as cloud computing or big data analysis, they also face expansion problems for the difference between available and needed capacities. In the past data center cooling design assumed that the IT work load was even and well distributed, but the actual operating environment was not so, especially in certain high density rack cabinets. Enterprises are realizing that their cooling capacities are seriously insufficient.\nThe backup power mechanism originally designed for data centers may also disappear due to this deficiency. The original UPS and cooling system designed using N+1 configuration will be forced to become fully operational due to insufficient capacities, and lose their backup functions. In addition, after deploying virtualization solutions, IT staffs can also move virtual machines dynamically. Data center loads will also change due to this and hot spots will become elusive. Power requirements will also change and result in unnecessary shutdowns.\nThe emerging modularization provides higher flexibility\nHigh density data centers still have many potential problems as administrators of data centers face greater pressure. In addition to maintaining an increasingly dense computing environment and improving its availability, they must also reduce cost and increase efficiency. Fortunately, industry professionals are integrating the modularization concept into equipment and products designed for data centers to bring greater flexibility and prepare for future workloads.\nAt the current stage, the main modularization concepts are applied to space and facility designs. Space modularization refers to the use of modules from IT infrastructure, rack cabinets and facilities provided for IT equipment to operate. Each depends on and relates to the other. In practice, the data center spaces at enterprises are used to assess the capacity needs of existing services and future expansion considerations, and are further divided into smaller spaces and viewed as modules. The modularization of facilities refers to the use of modular designs for infrastructure, including power systems such as UPSs, power distribution cabinets, in-row cooling, server racks and cold/hot-aisle containment.\n‚ÄúThe development of IT technology is changing every day, and infrastructure is developing towards ‚Äòmicroservice‚Äô architectures. Simply put, ‚Äòmicroservice‚Äô architecture refers to the use of modularization to form complicated large-scale applications. Modular solutions were developed for data center infrastructure years ago to provide flexibility for enterprises responding to expansion needs and to overcome power and cooling insufficiency and space challenges,‚Äù said Dr. Charles Tsai, the general manager of Delta‚Äôs mission critical infrastructure solutions business unit.\nThe modularization of the UPS system\nAccording to a research conducted by a UPS vendor, approximately 50% of respondents believe that the main cause of power outage at data centers is UPS equipment failure. This shows how important UPS systems are for maintaining data centers. As data centers acquire higher densities, they must replace old UPS systems with efficiency as a major consideration. UPS systems designed ten years ago usually have an efficiency of 85% when operating at 40% load to serve dual power input servers. The energy efficiency of current UPS systems is even greater. Take Delta‚Äôs UPS solution for example, under a light load of 20%, the AC-AC efficiency for the DPH 500kVA series UPS can be around 95% and the peak efficiency can be up to 96.5% for obvious energy cost savings.\nAnother consideration is effective space utilization in the data centers. Generally speaking, power rooms plan to install power facilities even though the space of the power room may be very limited. When data centers develop towards higher density in each rack cabinet, backup power must also increase accordingly. Enterprises can replace their legacy UPSs by new generation units with a higher power capacity. For example, Delta recently released the Modulon DPH 500 kVA modular UPS for large data centers that only takes up a space of a 19‚Äù rack cabinet and provides the world‚Äôs highest power density. The parallel expansion can also be configured up to 8 units, providing a maximum power capacity of 4MVA.\nSince it has self-diagnosis and aging detection mechanisms, it can detect the health of batteries, fan, IGBT module, DC capacitors and AC capacitors for preventive maintenance to reduce the risk of malfunctions and power loss, and protect the customer‚Äôs equipment investment.\nFor enterprises, another advantage of modular UPSs is the ‚Äúplug and play‚Äù design of power modules. Either vertical (within a single system cabinet) or horizontal (in parallel) expansion can be achieved per enterprise needs. Enterprises can flexibly purchase UPSs according to their initial capacity needs and count on future operational expansion to further lower CAPEX.\nRowCool systems near hot spots reduce power losses\nAs server and IT equipment densities become higher, the requirements for facilities are also becoming more rigorous. In addition to higher power supply density, cooling has become an issue in data centers. The cooling design of data centers assumes that the IT work load is even and well distributed, but in real enterprise environments, uneven heat distribution may be generated due to dynamic moving of virtual machines or improper deployment of IT equipment.\nInsufficient cooling will become a common challenge that high-density data centers will face. The advantage of RowCool is that it is close to hot spots, and is different from RoomCool systems where losses are generated in the air delivery path under the raised floor. RowCool systems can provide sufficient cooling capacity nearby to eliminate hot spots. They are equipped with high power-saving DC or EC fans with variable fan speed control for more energy savings. A 10% fan speed reduction can save a maximum 27% of energy consumption. In addition, the N+1 backup design is used for the overall architecture and group control functions that are provided to perform linked control for the RowCool units in the area to solve the hot spot problems caused by sudden load increases.\nRowCool systems also have modular designs. For example, RowCool 29/43kW not only has built-in dual power supplies and can significantly increase the reliability and protection for system power; but it also supports hot-swappable power supplies and fans, and can reduce the maintenance time needed. Its variable fan speed control design can adjust fan speed according to the actual work load. The modularization concept is also applied to RowCool units, which can be added to required spots as needed.\nCase Study: Medium and High Density Zones co-exist in a data center\nAccording to the data center density categories of AFCOM, the data center managers' association, a low density environment is when each cabinet is under 4kW, mid density is 5kW-8kW, high density is 9kW-15kW and ultra-high density is 16kW and above. Different data centers may face different rack power density challenges. In some data centers, there might even be a mix of rack cabinets with different densities, but use the same design concepts for power and cooling systems. A leading IC design company in Taiwan plans to build a new data center at their headquarters because they need to integrate their existing IT equipment and related network and operating environments. According to onsite inspection, there are up to 80 mid-density and ultra-high density rack cabinets in this enterprise‚Äôs data center, with the ultra-high density cabinets up to 25kW.\nDelta recommends that when enterprises need both low-density and high-density/ ultra-high density rack designs for different application needs, it should divide the data center space into a high-density cabinets area and an ultra-high density cabinets area to optimize its design. Facility planning should not only include overall power and cooling needs, but also space usage for the deployment of IT systems. There are different options for the use of cooling solutions. For example, rack cabinets under 4kW may only need RoomCool for effective cooling, while it is better to equip RowCool units for higher density racks from 9kW to 15kW for optimal heat removal.\nIn this case, Delta used the modular design concept to plan the ultra-high density area for its client, and placed all of the ultra-high density rack cabinets in one zone. For its high density applications, the client chose Delta‚Äôs RowCool 95kW with the industry largest cooling capability within a 600mm wide cabinet. Delta also recommended the use of hot-aisle containment technology to prevent the mixing of cold and hot air and ensure optimal cooling efficiency.\nTechnology is developing every day. Emerging IoT, artificial intelligence, AR/VR has integrated cloud, mobile, social media and big data technologies. For enterprises, the challenges for data centers have become more and more difficult. Development towards high-density will definitely continue and infrastructure will become the most important backup when enterprises promote their innovative application services.\nFor data center administrators the development of high-density data centers will definitely bring more maintenance and management issues. The availability of data centers will also be a challenge, while costs must decrease and efficiency must increase. The use of modular designs and related facilities, including space modularization, cold or hot aisle containment technology, RowCool systems and more efficient UPSs, can ensure higher reliability architectures and more deployment flexibility for data centers.\nHow Do I Deploy the Best Back-up Power and Environment Monitoring & Management Systems in a Datacenter?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:5bee2f6c-bfc2-47fd-bf8d-b5311ff05d95>","<urn:uuid:d0fd43e9-4a48-4be7-aa16-1fa00b2dfc77>"],"error":null}
{"question":"Natural vs human climate change - what's difference? Ëá™ÁÑ∂‰∏é‰∫∫‰∏∫Ê∞îÂÄôÂèòÂåñÊúâ‰ΩïÂå∫Âà´Ôºü","answer":"The key difference is that past climate changes were natural in origin, while most of the warming of the past 50 years is attributable to human activities. This is evident in analyzing methane emissions, which account for about 30% of current warming and are primarily driven by five human industries: agriculture, oil and gas, coal mining, solid-waste management, and wastewater management. Together these sectors account for 98% of human methane emissions. Natural climate changes were driven by factors like continental drift over millions of years or changes in solar activity, whereas current change is primarily caused by human greenhouse gas emissions occurring at an unprecedented rate.","context":["As global temperatures continue to rise and physical climate hazards become increasingly frequent and intense, more and more organizations are committing to lower their greenhouse-gas (GHG) emissions. Carbon dioxide commands much of their attention, but methane emissions from human activity are the second-largest driver of global warming, accounting for roughly 30 percent of the temperature increase from preindustrial levels. Curbing emissions of methane, therefore, will be critical to solving the net-zero equation‚Äîthat is, reducing GHG emissions as much as possible, and counterbalancing any remaining emissions with GHG removals‚Äîand stabilizing the climate.\nThe bad news is that methane emissions have risen by about 25 percent in the past 20 years. The current trajectory is far off the 2 percent annual decline that would be required to meet the 1.5¬∞C or 2¬∞C warming objectives of the Paris Agreement.\nHowever, there are reasons for cautious optimism. New McKinsey research shows that five industries could reduce global annual methane emissions by 20 percent by 2030 and 46 percent by 2050‚Äîenough for a significant shift toward a 1.5¬∞C warming pathway. What‚Äôs more, these reductions could be achieved largely with established technologies and at a reasonable cost.\nThe five industries, which together account for 98 percent of humanity‚Äôs methane emissions, are agriculture, oil and gas, coal mining, solid-waste management, and wastewater management. In each of these industries, there is a solid economic case to take abatement action. In this article, we look at methane‚Äôs impact on the climate, potential ways to reduce emissions, and steps that companies can take to begin managing methane effectively.\nReducing methane emissions is essential to stopping climate change‚Äîbut some barriers stand in the way\nGlobal temperatures in 2021 are 1.1¬∞C higher than preindustrial levels, with anthropogenic methane emissions responsible for 30 percent of that warming.\nAs temperatures continue to rise, there is a danger that climate feedbacks could accelerate the warming impact of methane from sources in the Arctic, wetlands, and landfills. In the Arctic, permafrost releases methane as it thaws. On the current emissions trajectory, permafrost release alone could add an incremental 5 to 20 percent to long-term methane emissions.\nIn 2018, the Intergovernmental Panel on Climate Change (IPCC) estimated that the world‚Äôs budget to keep warming below 1.5¬∞C was 570 gigatons (or 570 billion tons) of carbon dioxide (GtCO2).\nHuman activities currently emit about 41 GtCO2 a year, which suggests the budget will be exhausted by 2031. A core element of the IPCC‚Äôs analysis is that pathways to limit global warming to 1.5¬∞C are accompanied by deep reductions in emissions of methane. This means that the more methane that gets emitted, the less ‚Äúroom‚Äù there will be in the atmosphere for other GHGs. Put another way, if methane emissions stay high, the world‚Äôs carbon budget will soon be spent. The IPCC analysis assumes curtailment of methane emissions of more than 2 percent a year, reaching 37 percent below 2017 levels by 2030 and 55 percent by 2050.\nIf these targets aren‚Äôt met, the 1.5¬∞C objective will effectively be beyond reach. On the other hand, if methane emissions can be cut quickly, there will be a sufficient carbon budget remaining for the global economy to reduce CO2 emissions to net zero in an orderly transition (Exhibit 1).\nWhile methane and CO2 have similar warming effects, they are contrasting in several aspects. Methane stays in the atmosphere for just a decade, compared with the centuries-long persistence of CO2, but traps many times more heat. Methane emissions are much more irregular, emitted intermittently from oil wells, cattle, landfills, and coal mines.\nAnother challenge is that sources of methane emissions are highly dispersed across and within the five industries that account for the majority of methane emissions from human activities (Exhibit 2). Agriculture creates 40 to 50 percent of global methane emissions, but these emissions come from millions of farms of different sizes and farming practices around the world.\nAs a result of these challenges, and despite recent technology advancements, methane emissions are notoriously difficult to track and measure. In addition, abatement solutions are rarely cut and dried. Across sectors, abatement measures vary widely in terms of cost per metric ton of methane abated, feasibility, and ease of implementation. Most measures require trade-offs, either between costs and benefits or in terms of environmental impact. Dry seeding in rice farming, for instance, will cut emissions associated with flooding but may boost emissions of nitrous oxide, another GHG. The cost of methane abatement in coal mining is four to five times higher than that of leak detection and repair (LDAR) in oil and gas, because the concentration of methane in released from coal mines is much lower.\nThis creates an uneven playing field that may challenge the business case for methane abatement at individual companies.\nIt is also important to note that reducing methane emissions in time to achieve a 1.5¬∞C warming pathway would require both shifts in demand for commodities and technical solutions (Exhibit 3). The need for action on multiple fronts makes it all the more important to understand the feasibility of technical solutions, which we explore below.\nWe strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: email@example.com\nIndustries could reduce methane emissions with proven technologies at a manageable cost\nDespite practical hurdles, technical abatement solutions are available now across the five industries, and many rely on existing technologies and would support companies as they progress toward their net-zero targets. Moreover, on a 30-year timeline, our analysis shows that more than 90 percent of the potential emissions reductions associated with these solutions could be achieved at a cost of less than $25 per ton of carbon-dioxide equivalent (tCO2e)‚Äîa price sometimes paid in the voluntary carbon markets (Exhibit 4).\nFull deployment of the abatement measures described here would cost an estimated $60 billion to $110 billion annually up to 2030, $150 billion to $220 billion annually by 2040, and $230 billion to $340 billion annually by 2050. These estimates include capital investments, operational costs and savings, as well as potential revenues from recovered methane. Cumulatively, the cost of adopting all technical levers would amount to $3.3 trillion to $5.1 trillion over a 30-year period (Exhibit 5).\nOn 2030 and 2050 horizons, estimated emissions reductions by industry are as follows:\nThe agriculture sector, which emits an estimated 40 to 50 percent of anthropogenic methane, could achieve a 12 percent reduction in these emissions by 2030 and a 30 percent reduction by 2050. Agricultural emissions are primarily the result of ruminant animals (principally cows and sheep), farming practices, and rice production. Ruminants create methane during digestion, along with CO2 and other gasses. The impact is significant: ruminants account for almost 70 percent of agricultural emissions. They are responsible globally for more carbon-dioxide-equivalent (CO2e) emissions than every country except China.\nElsewhere in agriculture, biomass burning is a moderate source of emissions, driven by the expansion of land for pasture and crops, while rice farming produces methane via mechanical flooding, which is used in many countries to manage pests. A large proportion of the emissions from agriculture could be addressed with existing technologies. Several companies are already commercializing feed additives for cattle, for example, while alternative approaches to water, soil carbon, nitrogen, and land management provide proven options to rice and crop farmers.\nOil and gas\nOil and gas accounts for an estimated 20 to 25 percent of anthropogenic methane. Our analysis suggests that the sector could achieve a 40 percent reduction in sectoral emissions by 2030 and a 73 percent reduction by 2050. The oil and gas industry emits ‚Äúfugitive methane‚Äù through venting, leaks, and incomplete combustion during flaring. Since methane is the primary constituent of natural gas, these emissions are an untapped source of value, contingent on the necessary infrastructure being put in place. Moreover, there are numerous options to prevent losses in upstream production, including LDAR, equipment electrification or replacement, instrument air systems, and vapor-recovery units.\nCoal mining produces an estimated 10 to 15 percent of anthropogenic methane. According to our analysis, the sector has the potential to achieve a 2 percent reduction in its methane emissions by 2030 and a 13 percent reduction by 2050. The vast majority of coal-mine-methane (CMM) emissions emanate from either working or abandoned deep mines. There is a significant challenge in measuring and recovering these emissions. However, established technologies can capture CMM and use it to generate power. The investment case is probably strongest for companies in China, which account for about 70 percent of CMM emissions and which have invested in coal gasification for the industrial sector.\nAccounting for an estimated 7 to 10 percent of anthropogenic methane, the solid-waste sector could achieve a 39 percent reduction in sectoral emissions by 2030 and a 91 percent reduction by 2050. The majority of methane emissions from waste originates in landfills and open dumps, where anaerobic organic material generates methane over time. Through biogas markets and other incentives, authorities could capture these emissions and either sell the methane as renewable natural gas or use it in the production of fertilizer. However, revenues may not be sufficient to offset the costs.\nThe wastewater sector now emits an estimated 7 to 10 percent of anthropogenic methane. These emissions could be reduced 27 percent by 2030 and 77 percent by 2050. Wastewater emits methane from the breakdown of organic material in wastewater streams. The primary method of reducing emissions would be to build out modern sanitation infrastructure and technology. However, capital costs and policy requirements would be a significant burden in many countries. Where there is funding and access to technology, alternative abatement approaches could include the use of covered lagoons or the application of microalgae to prevent gas formation. Biosolids responsible for producing methane could be collected and sold as fertilizer or bioenergy.\nCompanies can take three no-regrets actions to begin reducing methane emissions\nTo begin reducing methane emissions and meeting the goals of the Paris Agreement, some essential groundwork is required, comprising three no-regret actions:\n- Expand monitoring, reporting, and verification. First, there must be a concerted effort to expand monitoring, reporting, and verification. To get there, governments and industries would need to upgrade data collection, moving from estimates to observed measurements. Satellite, drone, and sensor monitoring, the costs of which are falling sharply, would be one way to help achieve this. Currently, methane emissions are reported in tandem with CO2 emissions. That needs to change, with methane described under its own methodology. Better measurement would offer the potential to create incentives for rapid methane reduction across industries. It could also support efforts to develop global tradable goods markets that value the carbon intensity of products along a traceable value chain.\n- Support sustainable consumption. Stakeholders could develop mechanisms to differentiate assets and score products based on their methane footprints. If every kilogram of rice, million British thermal units (MMBtu) of natural gas, ton of steel, pound of meat, barrel of oil, and ton of coal came with a methane-intensity label, the market signals could support a more orderly decarbonization transition. With this, retailers and consumers could make more informed purchasing decisions, producers could define new foundations for competitive advantage, and investors could better understand portfolio risk.\n- Increase innovation. Many solutions are sufficiently developed to be effective but are not adopted at scale because of excessive costs or a lack of awareness of available technology. In the oil and gas industry, innovation in methane monitoring‚Äîfor example, leveraging flyovers and on-ground detection‚Äîcould help businesses pinpoint leaks and cut mitigation costs. The beef industry is in the early stages of adopting feed additives, genetic breeding, and methane capture. These technologies would benefit from support to move more speedily from lab to field.\nThe insights here demonstrate that abating methane emissions will be critical to achieving a 1.5¬∞C warming pathway and avoiding the worst effects of climate change. The good news is that there are many practical solutions available. Feed additives for cattle, new rice-farming techniques, advanced approaches to oil and gas leak detection, coal methane capture, and modern water and waste facilities can all be effective. Still, these solutions face implementation challenges.\nThe priority, therefore, is for action where it is practical. Many of the solutions can be implemented at a relatively low or net-negative cost, and these should be a priority. Where costs are prohibitive, there is a need for coordinated action to create the infrastructure and fiscal conditions that would support further action. Across the board, there is a need for more monitoring, reporting, and verification, more support for consumer choices, and more dedication to funding technical solutions. Without these efforts, it is likely that current initiatives will fail and the planet will continue on its collision course with an uncertain and dangerous future.","Frequently Asked Question 6.2\nIs the Current Climate Change Unusual Compared to Earlier Changes in Earth‚Äôs History?\nClimate has changed on all time scales throughout Earth‚Äôs history. Some aspects of the current climate change are not unusual, but others are. The concentration of CO2 in the atmosphere has reached a record high relative to more than the past half-million years, and has done so at an exceptionally fast rate. Current global temperatures are warmer than they have ever been during at least the past five centuries, probably even for more than a millennium. If warming continues unabated, the resulting climate change within this century would be extremely unusual in geological terms. Another unusual aspect of recent climate change is its cause: past climate changes were natural in origin (see FAQ 6.1), whereas most of the warming of the past 50 years is attributable to human activities.\nWhen comparing the current climate change to earlier, natural ones, three distinctions must be made. First, it must be clear which variable is being compared: is it greenhouse gas concentration or temperature (or some other climate parameter), and is it their absolute value or their rate of change? Second, local changes must not be confused with global changes. Local climate changes are often much larger than global ones, since local factors (e.g., changes in oceanic or atmospheric circulation) can shift the delivery of heat or moisture from one place to another and local feedbacks operate (e.g., sea ice feedback). Large changes in global mean temperature, in contrast, require some global forcing (such as a change in greenhouse gas concentration or solar activity). Third, it is necessary to distinguish between time scales. Climate changes over millions of years can be much larger and have different causes (e.g., continental drift) compared to climate changes on a centennial time scale.\nThe main reason for the current concern about climate change is the rise in atmospheric carbon dioxide (CO2) concentration (and some other greenhouse gases), which is very unusual for the Quaternary (about the last two million years). The concentration of CO2 is now known accurately for the past 650,000 years from antarctic ice cores. During this time, CO2 concentration varied between a low of 180 ppm during cold glacial times and a high of 300 ppm during warm interglacials. Over the past century, it rapidly increased well out of this range, and is now 379 ppm (see Chapter 2). For comparison, the approximately 80-ppm rise in CO2 concentration at the end of the past ice ages generally took over 5,000 years. Higher values than at present have only occurred many millions of years ago (see FAQ 6.1).\nTemperature is a more difficult variable to reconstruct than CO2 (a globally well-mixed gas), as it does not have the same value all over the globe, so that a single record (e.g., an ice core) is only of limited value. Local temperature fluctuations, even those over just a few decades, can be several degrees celsius, which is larger than the global warming signal of the past century of about 0.7¬∞C.\nMore meaningful for global changes is an analysis of large-scale (global or hemispheric) averages, where much of the local variation averages out and variability is smaller. Sufficient coverage of instrumental records goes back only about 150 years. Further back in time, compilations of proxy data from tree rings, ice cores, etc., go back more than a thousand years with decreasing spatial coverage for earlier periods (see Section 6.5). While there are differences among those reconstructions and significant uncertainties remain, all published reconstructions find that temperatures were warm during medieval times, cooled to low values in the 17th, 18th and 19th centuries, and warmed rapidly after that. The medieval level of warmth is uncertain, but may have been reached again in the mid-20th century, only to have likely been exceeded since then. These conclusions are supported by climate modelling as well. Before 2,000 years ago, temperature variations have not been systematically compiled into large-scale averages, but they do not provide evidence for warmer-than-present global annual mean temperatures going back through the Holocene (the last 11,600 years; see Section 6.4). There are strong indications that a warmer climate, with greatly reduced global ice cover and higher sea level, prevailed until around 3 million years ago. Hence, current warmth appears unusual in the context of the past millennia, but not unusual on longer time scales for which changes in tectonic activity (which can drive natural, slow variations in greenhouse gas concentration) become relevant (see Box 6.1).\nA different matter is the current rate of warming. Are more rapid global climate changes recorded in proxy data? The largest temperature changes of the past million years are the glacial cycles, during which the global mean temperature changed by 4¬∞C to 7¬∞C between ice ages and warm interglacial periods (local changes were much larger, for example near the continental ice sheets). However, the data indicate that the global warming at the end of an ice age was a gradual process taking about 5,000 years (see Section 6.3). It is thus clear that the current rate of global climate change is much more rapid and very unusual in the context of past changes. The much-discussed abrupt climate shifts during glacial times (see Section 6.3) are not counter-examples, since they were probably due to changes in ocean heat transport, which would be unlikely to affect the global mean temperature.\nFurther back in time, beyond ice core data, the time resolution of sediment cores and other archives does not resolve changes as rapid as the present warming. Hence, although large climate changes have occurred in the past, there is no evidence that these took place at a faster rate than present warming. If projections of approximately 5¬∞C warming in this century (the upper end of the range) are realised, then the Earth will have experienced about the same amount of global mean warming as it did at the end of the last ice age; there is no evidence that this rate of possible future global change was matched by any comparable global temperature increase of the last 50 million years."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:e97f7e36-5560-4dce-89bb-e8a28c4c9c13>","<urn:uuid:3504e0be-1f20-4313-b40b-aa594b9e43e5>"],"error":null}
{"question":"How did Ty Herndon reconcile his Christian faith with his sexuality?","answer":"Herndon struggled with his sexuality from a young age, feeling horrified in church at age 10 about potentially being homosexual. He began coming out to family members in his 20s, but kept it private. After attending a Tony Robbins seminar in 2009, he became more public. Though he initially struggled with his faith, as reflected in his song 'Lies I Told Myself,' he ultimately reconciled his identity, stating that he loves God and God loves him back.","context":["(CNN) ‚Äî There are plenty of country songs about how to be a man. One way is to face the music, and two country crooners did that on Thursday.\nTy Herndon and Billy Gilman came out as being gay.\nHerdon went first, in interviews with People Magazine and Entertainment Tonight. His revelation inspired Gilman to do go public as well.\nGilman posted a message to YouTube, thanking Herndon for breaking the ice. He preferred telling his fans directly, from the comfort of home, to sitting down with the press, he said.\nBut an encounter with a journalist also prodded him to spill the beans before someone else did. The reporter bumped into Gilman in a public place and snapped a photo of him ‚Äî with his partner.\n‚ÄúIt was in that moment that I knew that I‚Äôd rather it be from me than you reading it somewhere else,‚Äù Gilman told fans. He also feared being ripped over his sexuality in an article.\nCountry and LGBTQ\nIn the genre of country, Thursday‚Äôs tune was a tough one to sing, Gilman said. ‚ÄúBeing a gay, male country artist is not the best thing.‚Äù\nAt age 26, he‚Äôs had a long career, having rocketed up the charts at age 11 with his then silky, pre-voice-change alto pipes, according to his biography on AllMusic.com.\nBut currently, he‚Äôs hitting snags.\nRumors about his sexual orientation have been going around, he said, and he thinks major music labels may have thumbed their noses at him over it.\n‚ÄúI knew something was wrong when no major label wanted to sit down and have a meeting and listen to the new stuff,‚Äù he said.\nIn his video, he turned directly to fans with his latest song, giving them a preview on his laptop of the music video to ‚ÄúSay you Will,‚Äù which is still in edit.\nFacing fans on Monday\n‚ÄúToday, I get to tell the world that I‚Äôm an out, proud and happy gay man,‚Äù he told ‚ÄúPeople.‚Äù But he‚Äôs worried how fans will take the news.\nHe may find out in just three days, when he performs at the ‚ÄúMother Church of Country Music,‚Äù the Ryman Auditorium.\nIt‚Äôs home to the Grand Ole Opry.\nHerndon is playing a Christmas charity bash for children in need along with Charlie Daniels, Phil Vassar, Andy Griggs and Jamie O‚ÄôNeal.\nThe Ryman has said the concert would be sold out.\nHerndon, 52, is hopeful he won‚Äôt face outrage, because he thinks attitudes are changing in the country scene.\nSinger Chely Wright came out in 2010 and the open-minded Kacey Musgraves has a song titled ‚ÄúFollow Your Arrow‚Äù that was just named the Country Music Association song of the year.\n‚ÄúI felt so proud of my city,‚Äù he said. ‚ÄúI hope that trend continues; I pray it does.‚Äù\nFaith and fear\nAs a child, Herndon, a devout Christian, was stricken with fear over his sexual feelings.\n‚ÄúI was 10, sitting in church and horrified that I might be a homosexual. Whatever that word meant, I knew that I probably was one,‚Äù Herndon told ‚ÄúPeople.‚Äù ‚ÄúAnd I know there‚Äôs a lot of those kids still out there. Telling my story is an opportunity to help just one of them.‚Äù\nHe started coming out to family members in his 20s. But the ‚ÄúWhat Mattered Most‚Äù singer, who had a number of hits in the 1990s, kept the news close to the vest.\nIt wasn‚Äôt until he attended a Tony Robbins seminar in 2009 that he decided to become more public, he told the magazine.\n‚ÄúI realized I had an incredible story that could possibly help someone‚Äôs son or daughter or grandchild‚Äôs life not be as difficult as mine has been,‚Äù he said. ‚ÄúMaybe they wouldn‚Äôt have to go through as much pain and suffering. It‚Äôs time to tell my truth.‚Äù\nSome of the conflict between Herndon‚Äôs sexuality and his faith bled through a song he published last year ‚Äî ‚ÄúLies I Told Myself.‚Äù A sign with the word ‚ÄúEquality‚Äù has the most prominent place in the music video.\n‚ÄúYeah, praying‚Äôs just a waste of time, so why even start,‚Äù the last verse begins. ‚ÄúThe good Lord ain‚Äôt got time for guys like me. Forgiven‚Äôs something you won‚Äôt ever be.‚Äù\nA handwritten sign appears in that verse. It reads, ‚ÄúI‚Äôm a sinner.‚Äù\nHerndon has since reconciled who he is with God, he said. He loves God, and God loves him back.\nOne of the lies he told himself, he said to ‚ÄúEntertainment Tonight,‚Äù was that he can‚Äôt be gay and be in country music at the same time.\nNow, he thinks that‚Äôs not true."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:0d63f3a6-3982-4395-84fa-6c13894f0b2e>"],"error":null}
{"question":"What's trending rn about ancient Greek hospitality customs? Like how did Nestor demonstrate xenia when Telemachus visited?","answer":"Nestor demonstrated exemplary Greek hospitality by treating Telemachus and his companions with great honor and respect, even though he didn't know who they were. He first ensured they enjoyed their dinner before even asking them questions about their identity or journey.","context":["The Greeks have been known for their hospitality and politeness, especially when treating guests- whether strangers or not. This is demonstrated near the beginning of the Odyssey when Telemachus went to Pylos to visit Nestor. Nestor, not knowing who he was taking into his home as guests, treated them with great honor and respect. \"Now is the time,\" he said, \"for a few questions, now that our young guests have enjoyed their dinner. Who are you, strangers? Where are you sailing from, and where to, down the highways of sea water (p 299)?\" If ever Greeks were to serve themselves before their guests or even a little better than them, then they were breaking the most basic of all Greek customs, for this tradition of hospitality was passed down from generation to generation, and breaking it would bring embarrassment and dishonor upon the home.\nLearning the Greek rituals and after practicing them for many years, Odysseus, Odysseus' shipmates, and Telemachus became very reliant Greek tradition, especially that of treating all guests with great hospitality. At many times Odysseus would not have made it back to his wife and kingdom if it was not for the Greek tradition, that he relied on. After being at sea for seventeen days on a raft he had constructed, Odysseus spotted land. Poseidon then brought about a terrible storm, which wrecked his raft. After two days of battling waves that brought him near death, Odysseus was finally helped by a sea nymph onto the shore of Scheria. Once reaching the shore he kissed the earth, crawled under some olive trees, and fell asleep. Later, Princess Nausicca and her young friends went to the shore of Scheria to wash their clothes. Playin...\n... middle of paper ...\n...o all guests saved Odysseus and helped him return home to his wife, son, and kingdom. Even though people from many different kingdoms and islands took Odysseus in their home and showed him great kindness on his return home, the individual who helped him most was the goddess Athena. In many occasions Athena assisted Odysseus. One such example is when Odysseus was fighting of the suitors and they threw spears at him. \"Re-forming, the suitors threw again with all their strength, but Athena turned their shots, or all but two (p 566).\" Another instance which Athena aided Odysseus was when she disguised him as a beggar on his arrival to his homeland. \"Would even you have guessed that I am Pallas Athena, daughter of Zeus, I that am always with you in times of trial, a shield to you in battle (p 444).\" \"Your goddess-guardian to the end in all your trials (p 539).\"\nNeed Writing Help?\nGet feedback on grammar, clarity, concision and logic instantly.Check your paper ¬ª\n- When it comes to hospitality, Greeks stand atop the list of all cultures for their generosity and politeness towards strangers. ‚ÄúPhiloxenia‚Äù is the Greek word for ‚Äúthe love of strangers‚Äù. Philoxenia is demonstrated in several different cases in Homer‚Äôs The Odyssey. According to Greek customs, hospitality is respected by the immortal gods. If the Greek code of hospitality is not performed correctly, or not performed at all, the consequences may be very severe, gods may unleash their wrath to whoever does not follow this tradition of thoughtfulness.... [tags: essays research papers]\n948 words (2.7 pages)\n- ... Another example later in the story that finally results in Odysseus‚Äô arrival home is the generosity and hospitality that the Phaeacians extend to him. After Odysseus tells the Phaeacians his story they sympathize with him and show him kindness. He is washed and given a new ship to continue sailing home. An unfortunate example of Xenia not being reciprocated to the host is with Penelope, Odysseus‚Äô wife, who thinks her husband has died. She displays generous hospitality to the many suitors who want to marry her and gain Odysseus‚Äô property.... [tags: Odyssey, Odysseus, Trojan War, Greek mythology]\n950 words (2.7 pages)\n- The Odyssey, one of Homer‚Äôs Greatest works, presents an ancient Greek society where righteous conducts of hospitality, or ‚Äúxenia‚Äù, are strongly pursued. Various forms of hospitality, generous or callous, depict how civilized the person is. This concept of treating strangers with warmth was taken so seriously because they traveled frequently away from home and needed assistance along their journey to stay alive. Punishments for those who break the unwritten laws of this tradition are to be expected, as well as rewards for those who abide.... [tags: journey, greek, guests]\n689 words (2 pages)\n- All throughout The Odyssey there are scenes of good and bad xenia, or hospitality. It can be seen that hospitality is extremely important in the Greek culture, both how someone treats their guests and how the guests treat the host. A closer look chronologically into the good, then bad examples will show how one acts affects the actions that are brought upon them when they either follow or disobey Zeus' Law. Right at the beginning of The Odyssey, the reader is shown the hospitality that Telemachus has.... [tags: hospitality, culture, treat, guests, actions]\n1934 words (5.5 pages)\n- ‚ÄúThe world is full of wonders, but nothing is more wonderful than man.‚Äù This quote shows that the Greeks valued themselves, but also their intellect in which they know that the world about them is great. The Greeks valued beauty, art, intellect, honor, and truth; the list is long. Some of these values are shown through the story of the Odyssey, which tells of the adventures of Odysseus and his family. In order to understand Greek values and how they are portrayed in Greek society, one must examine how some values are portrayed in the Odyssey: hospitality, intellect, and beauty.... [tags: oddyssey, values, greek culture, ]\n552 words (1.6 pages)\n- Hospitality in Homer's Odyssey Hospitality: Greek philoxenia; literally ‚Äúlove of strangers.‚Äù Homer might have had such a definition in mind when he introduced the theme of hospitality to his epic poem the Odyssey. A multitude of reasons for the prominent position this theme plays, both in the Odyssey and perhaps in Homer‚Äôs own society, are hinted at in the introductory books, often referred to as the Telemachy. Just two of these, namely the hunger for news and the belief in divinity, are illustrated by the words and actions of the hosts Telemakhos and Nestor.... [tags: Homer Odyssey Essays]\n547 words (1.6 pages)\n- ... Alkinoos has no reason to give Odysseus a ship and crew, yet he is doing it out of his commitment to hospitality. He still has not learned Odysseus‚Äô name yet he already grants a ship to Odysseus for nothing in exchange. To a complete stranger, he has sacrificed one of his most valuable resources. He has no idea if his ship and crew will return or if Odysseus is a thief, but he ignores all the negative possibilities. He wants his guest, whether friend or foe, to have his wish granted. Alkinoos is a very hospitable man to all travelers and is the perfect example as to how a Greek was expected to treat a traveler as a guest.... [tags: reception, greek gods, traveler]\n620 words (1.8 pages)\n- Hospitality in Homer's Odyssey The first four books of Homer‚Äôs Odyssey depict certain instances of hospitality which are filled with generosity. One reason for the importance of this hospitality could have been a respect for foreigners, who were completely at the mercy of their hosts, especially when hosts had themselves been foreigners. A second reason why hospitality may have been important was to see if the guest was disguised as an enemy. In Book 4, Homer tells how Telemakhos and Pallas Athena (disguised as Mentor) visited Menelaos in Sparta.... [tags: Homer Odyssey Essays]\n445 words (1.3 pages)\n- Socrates, a Greek philosopher stated, \"Look death in the face with joyful hope, and consider this a lasting truth: the righteous man has nothing to fear, neither in life, nor in death, and the Gods will not forsake him‚Äù (Socrates). This explains the basis for Greek beliefs that can be carried over to values and qualities of them. As in this, Homer, the author of The Odyssey, portrays many Greek values that make up a righteous man or as, Homer‚Äôs character Odysseus, an epic hero. The Odyssey is the story of King Odysseus' return from the Trojan War to his kingdom of Ithaca.... [tags: Socrates Odyssey Epic Poem]\n1113 words (3.2 pages)\n- Homer's \"The Odyssey\" The Odyssey is a companion to The Iliad, a story of the Trojan War. Both The Iliad and The Odyssey are epic poems written by Homer. In The Odyssey, Homer relates the misadventures of Odysseus, king of Ithaca, that occur during the decade following the defeat of Troy. In doing so, the fates of his fellow warriors are also made known. The Odyssey begins on Mount Olympus, in the palace of Zeus, king of the gods, where a discussion takes place regarding the woes of humans and their determination to blame it on the gods.... [tags: Homer Odyssey Epic Poem Essays]\n1642 words (4.7 pages)"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"}],"document_ids":["<urn:uuid:c112faef-f507-4be4-b567-d0eb90d5a3a6>"],"error":null}
{"question":"What is known about koala habitat monitoring in Eurobodalla, and what specific feeding behaviors have researchers observed in these marsupials?","answer":"In Eurobodalla, habitat monitoring is conducted through citizen science projects, including plot surveys on private properties and the use of QGIS software to map habitat suitability, tree indices, vegetation types, topography, geology, soil, and watercourses. As for feeding behaviors, koalas are extremely selective in their choice of trees, influenced by social organization, tree structure, and leaf chemistry. They identify preferred browse food by smell and tend to favor eucalyptus species found on fertile soils near drainage lines. Koalas consume between 500 grams and 1 kilogram of eucalypt leaf daily, which provides minimal energy - equivalent to a bowl of Cornflakes.","context":["EKP are involved in supporting the latest science in relation to koalas and their habitat.\nWhat we do;\nOur volunteer team:\n- conducts ongoing citizen science projects, such as the East Lynne Carrying Capacity Study 2021 and the Review of Habitat Significance of Bodalla State Forest 2021\n- uses the free software QGIS to map local koala habitat suitability, tree indices, vegetation types, topography, geology, soil and watercourses\n- conducts habitat plot surveys on private properties, helping landholders understand their property‚Äôs contribution to the wider koala habitat landscape, adding to the EKP‚Äôs database, adding to the NSW Government‚Äôs database and ground-truthing wider-scale habitat modelling\n- monitors emerging local knowledge\n- monitors emerging contemporary research\nDatasheets relating to our 2020-2021 plot surveys can be found using this link 2020-2021PlotSurveys\nOur citizen science publications\nThe Eurobodalla Koala Project Pilot Study 2013 is available at this link EKP Pilot Study\nThe pilot study:\n- established a theoretical base for our citizen science approach\n- provided a comprehensive literature search and reference list\n- explored Eurobodalla koala history\n- tested a model of analysis\n- modeled Shire-wide potential habitat\nThe Bendethera Report 2013 is available at this link The Bendethera Report\nThe Bendethera expedition:\n- tested a comprehensive set of habitat factors used for our research\n- drew a conclusion about the habitat suitability of the Bendethera location\nThe Wamban-Nerrigundah Report 2020 is highlighted elsewhere on this website, and available through this link Wamban Nerrigundah Report\nThis Commonwealth-funded study:\n- confirmed the Wamban-Nerrigundah patch as a potential low-density breeding corridor between two places of local koala historical significance\n- gave special attention to the impact of the 2019-2020 wildfire on local koala habitat\n- updated our knowledge and techniques\n- produced a large repository of data, accessible to this website‚Äôs users\nThe Revised Eurobodalla Koala Recovery Strategy 2021 is also highlighted elsewhere on our website, and available through this link\nThe Revised Recovery Strategy:\n- updates the previous 2013 version\n- provides principles, practical actions and resources for all community sectors to engage in local koala recovery\n- sets the stage for our next few years of work\nThe Koala Carrying Capacity Study of the East Lynne Area 2021 is now available at this link LINK\nThe East Lynne Carrying Capacity Study:\n- used GIS mapping, analysed Forestry Corporation NSW Harvest Plans and EKP plot survey data from private properties, examined Murramarang National Park information, and took advice from local landholders\n- concluded the area could support up to four resident koala groups as a best-case scenario, if natural post-wildfire recovery is accompanied by deliberate land management intervention\nThe Review of Koala Habitat Suitability of Bodalla State Forest 2021 is now available at this link .\n- The Review argues Bodalla State Forest, where a sighting was reported in October 2021, must be a priority focus for any Eurobodalla-wide koala population revival.\n- With its remnant habitat and history of koala presence, the forest is a viable location for home ranges of about 350 hectares each.\n- Bodalla State Forest is also needed as a breeding connector for a sustaining regional koala metapopulation.\n- The review lists challenges for land managers in and near Bodalla State Forest if local koalas are to revive. Threats to address are landscape drying, further severe wildfire impacts, atmospheric carbon dioxide affecting leaf nutrients, degraded soils, dieback, historical clearing of the Tuross River lowlands, over-intensive logging and new clearing for urban development.\n- Between 2022 and 2024, the Coastwatchers Great Eastern Ranges Project (see below) hopes to make a start by helping adjacent private property owners survey and rehabilitate their spaces.\nOur next citizen science priority is a community-based survey to check for post-fire koala recovery. This survey will have a 3 to 10-year timeframe. It is intended to operate alongside implementation of the Recovery Strategy. At the end of the survey period, we will know whether the Eurobodalla‚Äôs wild koalas (and their sustaining metapopulation) have returned or not.\nIn the meantime, private property habitat surveys will continue and, if time permits, an analysis of the suitability of the Forestry Corporation NSW Formal and Informal Reserve System will be undertaken.\nFor the years 2022 to 2024, the volunteer Eurobodalla Koala Project is integrating with the Great Eastern Ranges WWF ‚ÄúCores, Corridors and Koalas‚Äù South Coast Project (Eurobodalla ‚Äì lower Shoalhaven), jointly hosted by the Coastwatchers Association Inc.\nUnder contract with Great Eastern Ranges (GER), resourced by the World Wildlife Fund for Nature (WWF), Coastwatchers is delivering multiple on-ground works including revegetation plantings for wildlife connectivity and a strategic wildlife survey. This is supplemented by the Bushfire Local Economic Recovery Fund (BLERF), a Commonwealth and State resourced initiative called ‚ÄúRestoring Country and Communities‚Äù administered by NSW Regional Services.\nAustralian National University ‚Äì Search ‚ÄúANU Koala Research‚Äù Link to search page\nUniversity of Sydney Koala Health Hub link to hub\nKoala Clancy Foundation link to foundation\nNew South Wales Department of Environment, Climate Change and Water link to NSW ECCW","The oldest wild koala recorded by Friends of the Koala was a female over 18 years old. Generally, their lifespan is 8 to 15 years. Koalas are aged by assessing the condition of their teeth.\nNorthern Rivers‚Äô koalas are similar in appearance and size to Queensland koalas. They have a short, thick, grey coat and are smaller than their southern counterparts. A male koala‚Äôs average weight is 7- 8kg and a female‚Äôs 6-7kg. That is a bit bigger than a basketball when they are curled up in a tree.\nAcross the region, koalas mate throughout the year, but the mating season peaks between May and September.\nKoalas are the size of a small jelly bean when born; their eyes are shut, ears stuck to their head and they have no fur. They take a precarious journey, crawling into their mother‚Äôs pouch and attaching themselves to one of their mother‚Äôs two teats. Koala joeys spend 6-8 months in their mother‚Äôs pouch, and during this time grow fur and their eyes open. From 9-12 months they spend their days on their mum‚Äôs tummy, back or close by, learning how to navigate the treetops and adjusting to a diet of eucalyptus leaves. The next few months are spent in the same vicinity as their mother as they become fully independent and weaned. Females often stay in in the same area as their mothers, but young males usually disperse.\nThe koala‚Äôs breeding cycle [344KB]\n(source: Bill Phillips. Aust Govt. Publishing Service. 1990.)\nKoalas survive mainly on a diet of eucalyptus leaves but they do not eat all species of eucalyptus. Their preferred trees in the Northern Rivers are Forest Red Gum, Tallowwood and Swamp Mahogany although they eat many other eucalypts as well. The trees koalas prefer to eat and use for shelter depend on the particular area and its surrounding habitat. For the Northern Rivers, non-eucalypts such as Paperbarks and She Oaks are often used. A koala‚Äôs metabolism is finely balanced between nutritional needs and energy requirements. Habitat disturbance upsets the balance because koalas must range further afield for their food.\nWhy does a koala choose a particular tree in the forest to feed on? Awareness of the extreme fussiness of the koala in its choice of food dates from the time a koala was first taken into captivity in 1803. Failure of early attempts to exhibit koalas overseas where Eucalyptus foliage was not available and the mortality of many koalas in zoos even in Australia in the early 1900‚Äôs reinforced this view. Observations of feeding patterns of koalas in captivity showed that their diet changed at certain times of the year when animals rejected certain species of eucalypt that they showed a strong preference for in other seasons. These same habits have also been observed in the wild.\nField studies seem to indicate that koalas‚Äô tree preference is influenced by their social organization, the structure of the tree and the chemistry of the leaves. Observed differences in tree species preference between sexes, and the preference for individual trees within species, may have their basis in the social organization of the koala. Although adult koalas are rarely seen in the same tree and appear to avoid one another, they nevertheless form clusters in which the home range of the dominant male and several females overlap extensively. Frequent use of a small number of trees by these koalas may provide a means of communication thus maintaining the cohesion of the cluster. Another theory is that the frequent cropping of the tree results in many new shoots being produced, which in turn attracts koalas.\nThe only structural features of trees that seem to attract koalas according to scientists are tree girth and height. Obviously the bigger the tree, the more food available and therefore the need to move between trees is reduced. This then reduces the energy expended by the koala and also reduces the chance of predation.\nThe preference for a narrow range of species within the huge Eucalyptus genus appears to have its basis in the chemistry of the leaves. Attempts to identify this basis have focused on either the nutritional or the toxic qualities of the foliage, and for various reasons no real basis has been identified.\nSome clues as to why they choose one tree over another may be gleaned by studying the animals in their natural environment. Koalas first sample leaves while riding on their mothers‚Äô backs and so become familiar with the foliage of the trees used by their mothers, but whether this influences their later choice of species has not yet been determined. Koalas frequently draw a branch of leaves to the vicinity of the nose before rejecting or accepting foliage. This will occur in a tree of a preferred species as well as when they are confronted by foliage from different species in captivity. This behaviour suggests that preferred browse food is identified by smell, however what they are actually smelling still remains a mystery.\nEucalypt foliage is considered a poor source of nutrients. It has been estimated that the entire amount of food eaten by a koala in a day (between 500grams and 1 kilogram of eucalypt leaf) contains about the same energy as a bowl of Cornflakes! No wonder the animals sit in the tree seemingly sleeping all day ‚Äì they don‚Äôt have any energy to do anything else. The Eucalypt species favoured by koalas are those often found on fertile soils suggesting that nutrient quality may be an ultimate factor in species preference. The preferred species also tend to be associated with drainage lines or shallow water tables ‚Äì an important factor in times of drought and at other times encouraging the growth of new tips which have been shown to be richer in nutrients than older leaves.\nAll in all, mystery still surrounds the whole issue.\nFor further information, please contact Mark Wilson (Nursery Manager) at email@example.com or phone 0413 339 554.\nKoalas are known to live in an area by:\n- scratch marks on tree trunks\n- scats on the ground\n- calls or sounds ‚Äì video of a male koala grunting\n- watch out for all the signs of koala activity and report sightings to us so accurate records of activity and sightings can be maintained.\nMale koalas are larger than females and their genitals are visible. They have a longer, broader face and as adults are more muscular. At sexual maturity (2 -3 years) they develop a scent gland on their chest which looks like a dirty, vertical mark down the middle of their upper chest.\nFemales are smaller, with fluffier ears. They have a rounder, softer face and are less robust.\nKoalas are widely distributed across the Northern Rivers of New South Wales although their numbers vary depending on available habitat. There are regular sightings in all the local government areas of Ballina, sightings in all the local government areas of Ballina, Byron, Kyogle, Lismore, Richmond Valley and Tweed. Koalas are found in in areas with extensive bushland such as Horseshoe Creek, Bonalbo, the Border Ranges, Goonengerry, Myocum, Larnook and the Blackwall Range. They also survive in urban areas.areas.\nKoalas are known to use people‚Äôs yards and even the streets of some towns and villages. Such sightings occur in Byron Bay, Kyogle, Clunes, Dunoon, Federal, Pottsville and Wyrallah, to name a few. In most parts of urban Lismore koalas are commonplace, however there are concerns that koala numbers have decreased in recent times as habitat has been greatly reduced and that which remains is fragmented."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:171fe4a9-28ce-4dc6-9de4-4de01e791cae>","<urn:uuid:33e45d0f-1b8a-4887-bfd3-a0daa63558b5>"],"error":null}
{"question":"What makes saffron so expensive and where does it come from geographically?","answer":"Saffron is the world's most expensive spice because each flower's stigma must be collected by hand. The spice comes from the crocus sativus flower, also known as saffron crocus, and was first cultivated near Greece before spreading to countries across Eurasia, North America, and North Africa. The term 'saffron' derives from the Arab word 'zafaran,' meaning yellow. Currently, while countries like Greece, Morocco, Spain, India, and Italy cultivate saffron, Iran dominates global production, being responsible for approximately 90% of the world's supply and leading in both quantity and quality.","context":["Sunday - Thursday: 11:30 AM - 10:00 PM /\nFriday: 10:00 AM - 4:00 PM /\nSaturday: Closed / 201.569.5600\nstars - based on 77\n10 Middle Eastern Spices\nThe Middle East is famous for its spicy, flavorful dishes\nmainly because Arabian spice traders once monopolized\nthe market on spices and provided that region with access\nto just about every spice available. Spices were highly\nprized in the Middle Ages because food spoiled so quickly\ndue to poor hygiene standards and appalling food preservation\nmethods. Hundreds of years ago, spices helped to mask\nthe flavor of foods that were less than fresh and made\nthem more palatable. Some spices even helped prevent\nfood from deteriorating so quickly in the hot summer\nAromatic and distinctively bitter, cumin is the dried\nfruit or \"seeds\" of a plant belonging to the\nparsley family. As one of the principle ingredients\nin curry powder, the cumin plant is found growing naturally\nin the Nile River Valley and is used in hummus, couscous,\nmeat dishes and mashed tahini and chick pea spread.\nRose petal water adds a sweet, floral taste to Middle\nEastern candies, syrups and rice dishes. This spice\nis found in Moroccan Baklava and carrot salad, sweetened\nsaffron rice and Lokum, also known as Turkish Delight.\nUsed in meat, vegetable, bread and salad dishes, Za'atar\nis a combination of sesame, sumac and thyme that tastes\nnutty and tangy. Sometimes mixed with olive oil as a\nspread for bread, Za'atar is thought to contain medicinal\nqualities that enhance the mind, especially in the Levant\nwhere children traditionally eat bread and Za'atar before\ngoing to school.\nStrong, aromatic and somewhat smoky in flavor, cardamom\nis commonly used in Indian dishes as well as in Scandinavian\nand Finnish breads. Green cardamom powder is also a\nMiddle East staple found in teas, coffees and sweet\ndishes. Black cardamom flavors curries and garnishes\nbasmati rice and various meat dishes. In addition, cardamom\nseeds are often chewed like chewing gum to freshen breath.\nA spice extracted from Rhus coriaria bush berries native\nto the Middle East and Mediterranean, sumac is distantly\nrelated to the toxic plant found in North America but\nis entirely safe to eat. After the berries are dried\nand crushed, the powder is mixed with salt to provide\ndishes with a vividly tart, slightly lemony taste. Sumac\nis often sprinkled over salads or rice kebab and as\na garnish for hummus dishes.\nPossessing a sweet, hay-like aroma and rich, bitter\ntaste, saffron is an expensive Middle Eastern spice\ndue to the fact that each flower's stigma must be collected\nby hand. Currently, Iran is responsible for producing\nmost of the saffron in the world--nearly 90 percent.\nWith over 150 aromatic compounds contributing to its\nunique flavor, saffron is found in Middle Eastern confectionaries,\nliquors and meat dishes. It is also used in India and\nChina as a fabric dye and in perfumes.\nTasting nutty and mildly sweet, fenugreek can be used\nas a spice (ground seeds), herb (fresh or dried leaves)\nor eaten as a vegetable (sprouts and leaves). Indian\ndishes such as pickles, daals and curries often contain\nfenugreek as well as in \"ghormeh sabzi\", the\nnational dish of Iran. Yemenite Jews called fenugreek\n\"yelba\" which they use to make Hilba, a curry-like\nsauce that is eaten during the first or second night\nof the Jewish New Year (Rosh Hashana).\nPeppermint and Spearmint\nLeaves of the spearmint and peppermint plants are traditionally\nused in Middle Easter, Greek and Turkish cuisine, enhancing\nmeat, salads and fruit dishes as well as yogurts. Freshly\nbrewed mint tea is a staple of North African culture\nand is always served in a glass rather than a teacup.\nCloves add a delicious, mildly licorice-like flavor\nto meats, vegetables and drinks in many Egyptian, Turkish,\nMoroccan and Syrian dishes. Immature buds are picked\nthen crushed to release their taste and aroma. When\ncombined with garlic or cinnamon and rubbed on chicken,\nlamb or beef, this spice acts as a strong flavor enhancer\nthat draws out a rich, meaty taste.\nYansoun, Arabic for aniseed, is one of the oldest spices\nknown to originate in the Middle East and is native\nto Spain, Egypt and Greece. Aniseed is the main ingredient\nin licorice and is found in many desserts, drinks and\ncandies served in the Middle East. Aniseed tea is also\nused for relief of colic in babies as well as stomach\ncramps in adults.","The most expensive spice in the world with good reason is saffron. And you know just why when you add it to your food.\nSaffron is derived from a flower called crocus sativus also known as saffron crocus. The stigmas of the flower are called threads and these are used as seasoning and colouring.\nThe word saffron is derived from the Arab word zafaran, meaning yellow. Commonly known as Kesar in hindi, Saffron is one of the most expensive and delicate spice in the world. It‚Äôs eye-catching crimson colour, fine texture, flavour and medicinal properties makes saffron on of the most exquisite spices in the world. Saffron is said to be one of the most primitive spices, with its history dating back to the ancient era of 1500 BC. Many classical writings as well as in the Bible, Saffron was believed to be one of the 14 herbs mentioned in the Bible. Gulshan Kumar, Executive Chef, The Orchid Hotel, Pune adds, ‚Äúin the Middle East it is listed in 12th century botanical dictionary found in the Assure Banipal library as a medicinal entry. In Germany Rocologia a book mentioning its properties was published in 1670.‚Äù Further derivations come from the Old French safran, Medieval Latin safranum, and Middle English safroun. Chef Swasti Aggarwal, Food Strategist, Foodhall India explains, ‚Äúsaffron is harvested from the fall-flowering plant Crocus sativus, a member of the Iris family. It is native to Asia Minor, where it has been cultivated for thousands of years to be used in medicines, perfumes, dyes, and as a wonderful flavoring for foods and beverages. With such miraculous health benefits and medicinal properties, saffron was a prized possession and was majorly used by the elite classes. Saffron was first cultivated near Greece and gradually propagated through countries like Eurasia to North America and North Africa. Over the years, the popularity of this spice has led to a surge in its cultivation across countries like Iran, Greece, Morocco, Spain, India and Italy. At present, Iran is one of the major producers of saffron both, in terms of quantity and quality. The vibrant crimson stigmas of the plant called threads are collected and dried. These dried strands are further used as a food seasoning and food colour.‚Äù Saffron is also known ‚ÄúVarnyaGana‚Äù in the world of Ayurveda meaning one that gives fairness and glow to skin. Vibhore Agarwal, Vice President, ML Kind Food adds, ‚Äúaccording to the traditional Kashmiri legends, saffron was brought to the region by two Sufi ascetics, Khwaja Masood Wali and Hazrat Sheikh Shariffudin, during the 11th and 12th centuries AD. A golden-domed shrine and tomb dedicated to those Sufis can be found in the saffron-trading village of Pampore.‚Äù\nBeing one the strongest and most flavorful of spices, saffron has the ability to take the taste levels of any dish several notches higher. ‚ÄúOnce infused with milk it can created wonders to a desserts (kheer, shrikhand, cheesecake, panna cotta) and is very commonly used in eastern food culture to flavour biryanis and rice dishes to rich the dish,‚Äù says Sahil Wadhwa, Director, Wadhwa Bakers. Saffron has a floral and pungent flavour and it must be used in minute quantities and infused with other ingredients to give best results. Chef Yogender Pal, Executive Chef at JW Marriott Jaipur Resort & Spa avers, ‚Äúsaffron is either added in a powdered form or it is soaked in milk or water and heated, this extracts out the colour and flavour.‚Äù Saffron needs moisture to release its flavour. ‚ÄúI would like to soak the saffron in stock or wine (rather than water) to add to the overall flavour of a dish. For traditional paella recipes, I will first toast the saffron threads in a dry skillet to bring out the volatile flavours,‚Äù says Executive Chef Sheriyar Dotivala, The Resort Hotel, Mumbai.\nMaking the Difference\nInterestingly, saffron is not just used in Indian cooking but can also be effectively part of any Western dish. Saffron has a delicate flavour which needs to be gently handled and should not be mixed with high flavour nodes or very spicy dishes. ‚ÄúSaffron has medicinal benefits for cough, asthma, whopping cough, insomnia, etc. It as well is helpful in softening the hardened arteries and is an aphrodisiac. But, simultaneously, saffron has its share of side-effects. This expensive spice causes dryness, anxiety, dizziness, nausea and at times gives a severe headache,‚Äù says Chef Gautam Chaudhry, Director, Demiurgic Hospitality. Besides biryanis and kheers, saffron is also a delightful addition to fish recipes. ‚ÄúIn fact, you can use saffron with just about any food like chicken broth, potatoes, breads, cakes and ice cream dishes. Not the most common preference but sometimes, a hint of saffron with vegetables such as cauliflower, dried legumes or green beans is also pretty good,‚Äù says Celebrity Chef Amrita Raichand. There are mainly three varieties of saffron in the market ‚Äì Kashmiri Saffron from India, Iranian Saffron from Iran and Spanish Saffron from Spain. Sejal Shah, Co-founder and owner, MAIA Eat, Bake, Mom adds, ‚Äúwhen used with other spices care should be taken that other spices do not over power the musky note of saffron.‚Äù Manish Kusumwal, Corporate Chef, Keys Hotels explains, ‚Äúthe most important rule of using saffron in dishes is avoid adding it in the cooking process, instead add it after or from top or in the end process of cooking which will add more flavour.‚Äù So are you ready to add a flavoursome punch in your food?\nGnocchi with vegetables in saffron sauce (Courtesy MAIA Eat, Bake, Mom)\nFor white sauce\n- All-purpose flour-100gms\n- Butter- 35 gsm35gms\n- Milk- 200 1ml\n- A pinch of saffron\n- Salt- as required\n- White pepper powder-1/4 tea spoon\nVegetables sauteed in butter\n- Zucchini green ‚Äì 30 gms\n- Bell pepper red & yellow- 20gms\n- Broccoli- 20 gsm\n- Boiled mashed potato- 100gms\n- All purposes flour- 45 gms\n- Pinch of salt\nTo make gnocchi\nMix mashed potatoes, salt and flour and incorporate it by mixing lightly, so as not to develop gluten. Roll the dough and cut into small pieces. Put it into the boiling water and remove it as a soon as it starts floating.\nTo make white sauce\nIn a pan take some butter, add flour to it and roast it. Add milk to the flour mix and stir it till it thickens into a velvety sauce. Add seasonings, saffron &saut√©ed vegetables in the sauce. Garnish it with parmesan crisps.\n- Use in very minimum quantities as too much can make the food bitter.\n- Saffron has to be used after roasting or warming the saffron soaked in milk or water. Do not use it directly.\n- For better colour and aroma soak saffron in water before you use it.\n- For each teaspoon of saffron, add 3 tsp of liquid.\n- When adding saffron to soups, stews, salad dressings, and other recipes with a lot of liquid, you can simply toss the crushed threads in with the rest of the ingredients.\n- Saffron should not be burnt.\n- In cooking, do not ever make use of wooden utensils when stirring saffron, as they absorb saffron quickly.\n- Make sure the saffron you are using is Grade 1 Certified on ISO Parameters."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:6ec69cb7-dd2f-4c24-b5ce-39058598e39e>","<urn:uuid:4eea99e4-ea4b-4e11-8f37-728b58864bba>"],"error":null}
{"question":"What are the primary benefits that sailing associations offer to their members, particularly in terms of educational resources and community engagement?","answer":"Sailing associations offer several key benefits to their members. They provide access to educational materials, training courses, and safety equipment. Members can also get discounted rates for boat rentals or charters. The associations create a sense of community by organizing various events like social gatherings, regattas, and races, allowing members to connect with other sailors, share knowledge, and build lasting friendships. Additionally, they serve as a hub for both new and experienced sailors to tap into a wealth of information and support that can help improve sailing skills and maintain safety on the water.","context":["Welcome to the world of sailing associations, where the love for boating and the sea unites a diverse community of individuals. Whether you're a seasoned sailor or just dipping your toes into the world of sailing, being part of a sailing association can open up a whole new world of experiences, friendships, and opportunities. In this article, we will explore the ins and outs of sailing associations and the role they play in the larger boating community. From understanding their purpose and benefits to navigating membership options and finding the right fit for you, we've got you covered. So sit back, hoist the sails, and let's dive into the exciting world of sailing associations together. Sailing associations are an essential part of the boating community, providing a sense of camaraderie, access to resources and events, and support for new and experienced sailors alike. They serve as a hub for individuals who share a passion for sailing and offer a range of benefits to their members.\nIn this article, we will cover the basics of sailing associations, their benefits, and how to find the right one for you. First, let's define what a sailing association is. Simply put, it is an organization that brings together individuals with a common interest in sailing. These associations can be local, national, or even international, and they typically have membership fees that provide access to various services and activities. One of the primary benefits of joining a sailing association is the sense of community it offers. Being part of a group of like-minded individuals who share your love for sailing can enhance your overall boating experience.\nIt allows you to connect with others, share knowledge and experiences, and build lasting friendships. Additionally, sailing associations provide access to resources that can be beneficial for both new and experienced sailors. This can include educational materials, training courses, safety equipment, and discounted rates for boat rentals or charters. By joining an association, you can tap into a wealth of information and support that can help improve your sailing skills and keep you safe on the water. Another significant advantage of being a member of a sailing association is the events they organize. These can range from social gatherings to regattas and races.\nThese events not only provide an opportunity to have fun and compete but also allow you to meet other members and expand your network in the boating community. Now that we've covered the benefits of sailing associations let's discuss how to find the right one for you. The first step is to determine your needs and goals. Are you looking to improve your sailing skills? Do you want to participate in races or cruises? Are you interested in socializing with other sailors? Once you have a clear idea of what you want, you can start researching different associations in your area or beyond. It's essential to consider the focus areas of each sailing association as they can vary significantly. Some may be more focused on racing, while others may prioritize cruising or education.\nIt's crucial to find an association that aligns with your interests and goals so that you can fully benefit from being a member. Furthermore, it's essential to research the reputation and track record of the sailing associations you are considering. You can ask for recommendations from other sailors or do some online research to get a better understanding of their values, activities, and overall community. Remember, joining a sailing association is a commitment, so it's essential to choose one that is reputable and has a strong sense of community. In conclusion, sailing associations play a vital role in the boating community, providing numerous benefits such as a sense of camaraderie, access to resources and events, and support for new and experienced sailors. Whether you are new to sailing or a seasoned sailor, joining a sailing association can enhance your overall boating experience and help you build connections with others who share your passion.\nBy understanding the basics of sailing associations, their benefits, and how to find the right one for you, you can make an informed decision and become an active member of the sailing community.\nWhat Are Sailing Associations?Sailing associations are organizations that bring together individuals who share a common interest in sailing. They provide a community for boating enthusiasts to connect with each other, participate in events and activities, and access resources related to sailing. These associations are typically non-profit and run by volunteers, with the goal of promoting the sport of sailing and fostering a sense of camaraderie among its members. They often have a membership structure, offering different levels of benefits and access based on dues paid. Sailing associations can range from local clubs to national or international organizations, with varying levels of focus and scope. Some may specialize in a specific type of sailing, such as dinghy racing or cruising, while others may cater to a broader range of boating interests. Overall, sailing associations play a vital role in the boating community by providing support, resources, and a sense of belonging to sailors of all levels.\nTypes of Sailing AssociationsWhen it comes to sailing associations, there are various types that cater to different focus areas.\nThese associations can range from local clubs to national organizations, each with their own unique benefits and offerings.\nLocal Sailing Clubs:These associations are typically small and cater to a specific geographic area. They often have a strong sense of community and may offer regular social events, races, and training programs for members.\nNational Sailing Organizations:These associations have a larger reach and may have chapters or affiliates in different regions. They often provide resources such as education, safety guidelines, and racing rules.\nSpecialized Sailing Associations:These associations focus on specific types of sailing, such as dinghy sailing, offshore racing, or cruising. They offer specialized training and resources for their respective disciplines.\nYouth Sailing Associations:These associations are dedicated to promoting sailing among young individuals.\nThey offer training programs and events specifically designed for youth sailors.\nHow to Choose the Right Sailing Association for YouWhen it comes to choosing a sailing association, there are a few key factors that you should consider in order to make the best decision for yourself.\nLocation:One of the most important factors to consider is the location of the sailing association. You want to make sure that it is easily accessible for you and that it is in an area with favorable sailing conditions.\nMembership benefits:Each sailing association may offer different membership benefits.\nSome may focus more on racing events, while others may offer more social gatherings or educational resources. Consider what you are looking to get out of your membership and choose an association that aligns with your goals.\nCommunity:Sailing associations are all about community and camaraderie. Take the time to get to know the members and see if you feel a sense of connection with them.\nThis will greatly enhance your overall experience with the association.\nInstructors and training:If you are new to sailing or looking to improve your skills, it is important to consider the instructors and training programs offered by the association. Look for experienced and certified instructors who can provide quality instruction.\nCulture and values:Each sailing association will have its own unique culture and values.\nMake sure to research and understand the culture of the association and see if it aligns with your own values.\nCost:Finally, consider the cost of membership for each association. While it should not be the deciding factor, it is important to choose an association that fits within your budget.\nThe Benefits of Joining a Sailing AssociationWhen it comes to sailing, being part of a community and having access to resources and events is crucial. And that's exactly what a sailing association offers.\nBut the benefits of joining a sailing association go beyond just these basic perks. Here are some reasons why you should seriously consider becoming a member.\n1.Camaraderie and Networking OpportunitiesSailing associations bring together people who share a passion for sailing. This creates a strong sense of camaraderie and allows for networking opportunities with like-minded individuals.\nNot only can you make new friends, but you can also learn from each other and share valuable experiences.\n2.Access to Resources and ExpertiseSailing associations often have a wealth of resources available to their members, including guides, tips, and information on the latest technology and techniques. They also have experienced sailors who can provide valuable expertise and guidance for both novice and experienced sailors.\n3.Discounts and DealsMany sailing associations offer discounts and deals on equipment, charters, and other services.\nThese savings can add up over time and make your sailing hobby more affordable.\n4.Education and Training OpportunitiesIf you want to improve your sailing skills, joining a sailing association is a great way to do so. Many associations offer educational programs and training courses for various levels of experience. This allows you to continually learn and grow as a sailor.\n5.Support for New Sailors If you're new to sailing, joining an association can provide the necessary support and guidance as you navigate this new hobby. You'll have access to experienced sailors who can answer your questions, offer advice, and help you become a confident and competent sailor. These are just some of the many benefits of joining a sailing association. Not only will you become part of a vibrant and supportive community, but you'll also have access to resources, expertise, and opportunities that can enhance your sailing experience.\nSo if you're considering becoming a member, don't hesitate - it's a decision you won't regret. Sailing associations offer numerous benefits and opportunities for boaters. Whether you are looking for a sense of community, access to resources, or a chance to improve your skills, there is a sailing association out there for you. Take the time to research and find the right one that aligns with your needs and interests."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:02c0f4ab-7d62-43c2-a3c5-3e464806ea7c>"],"error":null}
{"question":"What role do different lighting angles play in lunar crater imaging between Chang'e 2 and LRO maps, and how do LRO's temperature measurements reveal crater characteristics at the poles?","answer":"In Chang'e 2 images, the higher sun angle allows better visibility of crater interiors but makes topography harder to interpret, while LRO's lower sun angle creates more shadows but better shows surface relief. For example, in Sinus Iridum, Chang'e 2's higher lighting revealed the entire interior of a 3-kilometer crater that was partially hidden by shadows in the LRO mosaic. Regarding temperature measurements, LRO's Diviner instrument shows that crater characteristics at the poles significantly affect temperature distribution - sunward-facing slopes of crater walls appear warmer, while poleward-facing slopes and deep craters appear much colder, as revealed in the nighttime temperature measurements of the Moon's north pole.","context":["Comparing Chang'e 2 and Lunar Reconnaissance Orbiter maps of the Moon\nPosted by Phil Stooke\n13-02-2012 10:23 CST\nRecently, the Chinese Space agency released a global map of the Moon with a zoomable interface that would be familiar to anyone who uses popular terrestrial online maps like Google Maps, Yahoo Maps or Bing Maps. You click on the map or use a sliding control to zoom in, drag on the map to move around within it - it has become a very familiar and intuitive interface. In fact it's so useful that it is now being used for several different planetary datasets. There's one for Mercury, one for Mars, and a great one for the Moon. That last one, called Quickmap, consists of images from the Lunar Reconnaissance Orbiter Camera (LROC), including a global map made from LROC Wide Angle Camera images with a resolution of about 100 meters and, if you zoom in enough, closeups made with the LROC Narrow Angle Camera with a resolution of about 50 centimeters wherever they are available.\nThe inevitable question is: how does the LRO lunar map compare with the new Chinese product?\nThe Chinese map is made with images from Chang'e 2, the orbiter launched in October 2010 and currently stationed at the Sun-Earth L2 Lagrange point. It spent eight months mapping the Moon, collecting images for this global map and higher resolution views of potential landing areas for the first Chinese lunar lander, especially in Sinus Iridum. The highest resolution images are not incorporated into this 50-meter-resolution map yet, but perhaps that will happen later. Reports have stated that the global mosaic has a resolution of about 6 m/pixel. If that is correct, we do not yet have access to the full resolution dat\nThe best way to compare maps is to look at the same area in both data sets, so I made a few comparison images. The first one is an image of a chain of elongated pits in Mare Tranquillitatis just east of Sosigenes crater at 8.4 north, 19.0 east.\nI'm interested in this area because LROC narrow-angle images reveal odd features on its floor, strange sharp-edged hollows with mottled floors which resemble the famous Ina (or D-Caldera) depression discovered in Apollo images. These pits are smaller but similar, and I have to wonder if they are also similar to the hollows recently revealed on Mercury. The LROC image shows the pit chain partly covered by a narrow angle image which shows the hollows very clearly. The rest of the big pit and a smaller pit are only seen in the main mosaic from the Wide Angle Camera, and there wouldn't be much evidence of unusual markings in the pit if that's all we had.\nThe Chinese map looks different. It lacks the detail of the narrow-angle LROC images, but it shows more than the wide-angle LROC. Compare the two carefully - the Sun is at a higher angle in the Chinese image, so shadows are missing and topography is harder to interpret, and the range of grey shades is more limited, suggesting the original images had a lower bit depth. But resolution is clearly higher, about twice as high as in the NASA map. There's a real hint of something odd about the floor of the depression which LROC's wide angle images do not pick up.\nThe second comparison is a place I originally looked at because I thought it might be another of those odd hollows. It is in northern Mare Imbrium very close to the highland boundary at 48.1 north, 23.4 west, and it shows as a little white smudge in LROC wide angle images.\nNarrow angle images just graze the western edge of it but don't reveal its nature. The new Chinese map shows quite a bit more detail, again maybe half the pixel size or a bit better. The smudge looks to me like a very shallow hill, a bit of the adjacent highlands almost submerged beneath the dark lava of Mare Imbrium. Probably not a hollow this time! Too bad. Incidentally, the left side of the LROC mosaic shows one problem with the current version of Quickmap. The narrow angle image strips don't match very well. Some craters show up twice, others must be missed altogether, as the images don't overlap properly. If you want to see the original images, or all the overlapping images, just select the search tool, the magnifying glass at upper right. Click where you want on the map, or drag out a box, and all images at that location will appear in a list, with clickable links to fully zoomable versions of those images in a new window. Click back on the map navigation icon to escape that search function. You can do the same on the Mercury Quickmap, but you only get a link to a raw data download which needs a bit of extra skill to use.\nThe third comparison is a pair of images in Sinus Iridum at 43.0 N, 31.0 W.\nA crater about 3 kilometers across dominates the scene, but look first at the smaller craters on the plains outside it. They are clearer in the Chinese map than the NASA map, showing a resolution improvement by about a factor of two. But the big crater looks different as well, because of a different lighting angle. The higher sun in the Chang'e 2 images allows the entire crater interior to be seen, whereas part of it is hidden by shadow in the LROC mosaic. This comparison is a bit misleading, because LROC WAC images are available at multiple lighting angles. It would be possible to make a WAC global mosaic with high sun images, or morning or evening images, in addition to the current version, which is a combination of images at many sun angles. But for what we have now, there are differences in lighting between the two maps. The Chinese mosaic will be less obscured by shadows near the poles than the NASA mosaic.\nWhat should we take from these comparisons? Both online lunar maps are good in their own ways, and anyone interested in this kind of virtual exploration of the lunar surface would probably want to use both of them. There are also some examples of higher-resolution Chang'e 2 images here and here. At the second link, the thumbnails don't link to larger images as you might expect, but if you right-click on them and save the images they save at a much larger size. It would be really nice to see some of the higher-resolution coverage incorporated into the new Chinese map eventually, but even without that it's more than just a duplicate of the LROC map. Go explore the Moon and see what you can find.","To celebrate its 5th Anniversary, the Lunar Reconnaissance Orbiter mission presents the Moon As Art! Click on the thumbnails below to view full image and get more details on each. Choose your favorite, and vote below!\nThe Lunar Orbiter Laser Altimeter (LOLA) aboard the Lunar Reconnaissance Orbiter (LRO) sends laser pulses down to the surface of the Moon from the orbiting spacecraft. These pulses bounce off of the Moon and return to LRO, providing scientists with measurements of the distance from the spacecraft to the lunar surface. As LRO orbits the Moon, LOLA measures the shape of the lunar surface, which includes information about the Moon's surface elevations and slopes.\nLOLA's laser pulse is split into 5 separate beams that hit the lunar surface in a cross-shaped pattern. The reflected pulses from these beams provide 5 parallel profiles along the surface directly beneath LRO. This pattern allows scientists to calculate slopes on the surface of the Moon in a variety of directions on scales of approximately 25 meters.\nThis image shows the slopes found near the south pole of the Moon, poleward of 75 degrees South. The bright red to white areas have the highest slopes (25 degrees or more) while the dark blue to purple areas have the lowest slopes (5 degrees or less). The steepest slopes are found in impact crater rims, which appear as brightly colored circular features throughout the image.\nThe interior wall of the Clerke crater has many distinct flows of granular material which narrow as they reach towards the floor of the crater. The source material originates from the crater rim. The debris appear higher in reflectance compared to the rest of the crater wall, likely due to differences in maturity and perhaps grain size of the material. The debris flows may be younger than the crater floor and walls if the flow was instigated by seismic shaking or a nearby impact crater. The flow may contain more boulders, which may cause the higher reflectance. The crater is 7 km in diameter located at 21.7¬∞N, 29.8¬∞E near the Taurus Littrow Valley where Apollo 17 landed on 11 December 1972 and is named after Agnes Mary Clerke\nThis image features night time temperatures at the Moon's north pole as measured by the Diviner instrument. Areas in blue and purple represent colder temperatures, while areas in orange and red represent warmer temperatures. At any given point in the Moon's orbit, half of the Moon is in daylight, while half of the Moon is in darkness. At the poles, we would see that half of the image would be much hotter than the other. This image was created by using the temperatures as measured at midnight at any given point on the surface. What becomes immediately obvious is the role that elevation plays on surface temperature. Sunward-facing slopes of crater walls appear hotter, while poleward-facing slopes (and in some cases of deep craters) appear much colder.\nLinn√© (2.2 km diameter) is a very young and beautifully preserved impact crater. LROC stereo images provide scientists with the third dimension - information critical for unraveling the physics involved in impact events. The LROC science team presented a first analysis of Linn√© crater topology at the Lunar and Planetary Science Conference last week.\nThe LROC team released a set of NAC stereo derived map products. LROC NAC Digital Terrain Models (DTM) are made from geometric stereo pairs (two images of the same area on the ground, taken from different view angles under nearly the same illumination). LROC was not designed as a stereo system, but can obtain stereo pairs through images acquired from two orbits (with at least one off-nadir slew). Off-nadir rolls interfere with the data collection of the other instruments, so LROC slew opportunities are limited to four per day.\nOn 10 June 2011 the LRO spacecraft slewed 65¬∞ to the west, allowing the LROC NACs to capture this dramatic sunrise view of Tycho crater. A very popular target with amateur astronomers, Tycho is located at 43.37¬∞S, 348.68¬∞E, and is ~82 km (51 miles) in diameter. The summit of the central peak is 2 km (6562 ft) above the crater floor, and the crater floor is about 4700 m (15,420 ft) below the rim. Many \"clasts\" ranging in size from 10 meters to 100s of meters are exposed in the central peak slopes. Were these distinctive outcrops formed as a result of crushing and deformation of the target rock as the peak grew? Or do they represent preexisting rock layers that were brought intact to the surface? Imagine future geologists carefully making their way across these steep slopes, sampling a diversity of rocks brought up from depth.\nTycho's features are so steep and sharp because the crater is young by lunar standards, only about 110 million years old. Over time, micrometeorites, and not so micro meteorites, will grind and erode these steep slopes into smooth mountains. For a preview of what Tycho's central peak may look like in a few billion years, visit Bhabha crater."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:16f3cb68-8dc3-4c39-b5c3-681c65d00767>","<urn:uuid:80e9c3fd-ad9f-47b6-a340-665367639136>"],"error":null}
{"question":"How did the publishing practices and distribution methods compare between The Sacred Harp in Philadelphia and the later Southern Gospel recordings and publications in terms of their reach and impact across the United States?","answer":"The Sacred Harp, published in Philadelphia, sold about 250,000 copies by 1879 through traditional book publishing and distribution methods. The books were typeset, printed, and bound in factories where women operated printing presses and performed binding tasks while men did typesetting and heavy labor. In contrast, Southern Gospel publications and recordings reached audiences through more diverse channels including radio, phonograph records, and live performances. For example, James D. Vaughan sold over a million songbooks annually, established one of the first record companies in the South, and operated radio station WOAN in Tennessee. Both traditions had regional strengths - The Sacred Harp was most popular in the South despite being published in Philadelphia, while Southern Gospel spread through the South via traveling quartets, tent shows, and church performances before reaching national audiences through radio and recordings.","context":["The original 1844 edition of The Sacred Harp bore the name and address of a Philadelphia publishing house: T. K. & P. G. Collins. Although B. F. White‚Äôs journey from Hamilton, Georgia, to Philadelphia would have been several days long, he published four editions of The Sacred Harp with Collins, both before and after the Civil War. As a resident of Philadelphia, I was curious to find out more about the city‚Äôs role in the story of The Sacred Harp. I eventually discovered that Philadelphia had a much deeper connection to shape-note music than I had thought. My research culminated in a November 2016 tour of central Philadelphia publishing sites connected to shape-note music.\nAlthough shape-notes were associated with southern and western music,1 the most successful four- and seven-shape notation systems have their origins in Philadelphia, which was also the place of publication of many bestselling shape-note books. The merchant John Connelly designed the four note shapes used in The Sacred Harp in 1798 and the first edition of The Easy Instructor (1801) was printed in Philadelphia using these shapes. In 1846, Jesse B. Aikin of nearby Chester, Pennsylvania, published The Christian Minstrel, the first book printed in what was to become the most enduring seven-shape notation system. Aikin‚Äôs shapes are used in The Christian Harmony: 2010 Edition and some contemporary church hymnals and gospel books. Several Philadelphia-printed shape-note books were enormously popular. By 1879, William Walker‚Äôs Southern Harmony had sold about 700,000 copies, followed by The Sacred Harp and The Christian Minstrel, which sold about 250,000 and 194,000 copies, respectively.2 These numbers are particularly impressive, given that the population of the United States was about 45 million at the time and shape note music never caught on in New England.\nAlthough Philadelphia had been a hub of the printing trades since colonial times, most early nineteenth-century shape-note books were produced by small presses serving a regional audience in the South or West. This changed in the 1830s and 1840s, when Aikin pioneered seven-shape notation and several southern and western authors turned to two Philadelphia publishers to deliver fine quality typesetting, stereotyping, printing, and binding, using both four- and seven-note systems. The T. K. & P. G. Collins firm published a number of books by southern authors. In 1838, they produced a stereotyped version of the first edition of The Southern Harmony by William Walker of South Carolina, followed by editions in 1840 and 1847.3 Collins also published four editions of The Sacred Harp (1844, 1850, 1859, 1870), The Hesperian Harp (1848), and The Social Harp (1855), all by Georgian authors. Popular Collins seven-shape books include The Christian Minstrel (1846, revised up to 1865), by Jesse B. Aikin of Pennsylvania, and The Sacred Melodeon (1848), by Amos S. Hayden of Ohio. Walker turned to E. W. Miller‚Äôs publishing house for revised 1847 and 1854 editions of The Southern Harmony, and Miller brought out Walker‚Äôs Christian Harmony in 1867, with revisions in 1873 and 1901. Both Collins and Miller printed a number of lesser-known shape-note titles as well.4\nOne difficulty in researching Philadelphia history is that streets were renamed and numbered several times in the nineteenth century. I used the Greater Philadelphia GeoHistory Network‚Äôs Interactive Maps Viewer to reconcile old and modern addresses.5 T. K. & P. G. Collins‚Äô factory, where The Sacred Harp was probably printed, was located at 1 Lodge Alley, later renamed and renumbered as 705-707 Jayne Street. Jayne Street has since been renamed Ranstead Street, so the modern address where the Collins factory stood is 705-707 Ranstead Street. The 1860 edition of The Sacred Harp gives the location ‚ÄúN.E. Corner, Sixth and Minor Streets‚Äù where the book was for sale. Minor Street between Fifth and Sixth was removed in the 1950s to make way for Independence Mall. Collins‚Äô bookstore would have been almost exactly on the spot where the Liberty Bell is now on display. E. W. Miller‚Äôs publishing house was in the Ashmead Building at 1102 & 1104 Sansom Street, formerly called George Street.\nAlthough none of the buildings associated with the Collins and Miller firms survive, there are a number of maps and illustrations that do. An 1872 floor plan and inventory of the Ashmead Building, where Miller rented two floors, was made for insurance purposes and included in the Hexamer General Surveys of Philadelphia.6 We learn that Miller occupied the fourth and fifth floors of the building and employed forty people, of whom twenty-four were women. The Philadelphia Free Library also has an engraving of the Ashmead building.7 Collins‚Äô factory appears in maps,8 an illustration,9 and an 1889 photograph of the 700 block of Ranstead Street, showing a portion of the fa√ßade and signage for Collins‚Äô type foundry and printing house.10 More remarkable still, Cornelius T. Hinckley‚Äôs 1852 article ‚ÄúA Day‚Äôs Ramble Through the Mechanical Department of the ‚ÄòLady‚Äôs Book,‚Äô‚Äù no. V in his ‚ÄúEveryday Actualities‚Äù series for the Godey‚Äôs Lady‚Äôs Book, narrates a visit to the Collins‚Äô brothers‚Äô printing factory (where the Lady‚Äôs Book was printed) with numerous engravings of not only the interior and exterior of the building but also the building‚Äôs occupants at work.11 I imagine that the Collins brothers treated William Walker and B. F. White to a similar tour.\nThis documentation of Philadelphia publishing sites, together with what is known about similar shape-note books allows us, to some extent, to reconstruct The Sacred Harp‚Äôs journey from manuscript to finished product. Before B. F. White visited the Collins factory in Philadelphia, he and E. J. King would have assembled a manuscript for The Sacred Harp. Although their manuscript didn‚Äôt survive, some contemporaneous manuscripts did. Pennsylvania author Samuel Wakefield, composer of ‚ÄúFatherland‚Äù (p. 449 in The Sacred Harp), published his Sacred Choral in 1854. A manuscript copy of it is at the West Overton Museum in Scottdale, Pennsylvania. While this manuscript is entirely handwritten, the copy of Wakefield‚Äôs American Repository in the museum has been cut, presumably for the purpose of pasting songs into a new manuscript.12 White and King‚Äôs Sacred Harp manuscript probably contained a number of pages of (or page references to) The Southern Harmony. For example, the typography‚Äîincluding line breaks and note stem direction‚Äîof ‚ÄúLeander‚Äù (p. 71) is almost identical in The Sacred Harp and The Southern Harmony, which suggests that White and King either pasted the Southern Harmony page into The Sacred Harp manuscript or supplied a page reference.\nAfter arriving in Philadelphia, White and King‚Äôs manuscript was typeset. The process known as mosaic typesetting was used for all the shape-note music set in Philadelphia that I have examined, with the exception of the first edition of The Easy Instructor, which was engraved. Each component of the page, including note heads, stems, staff lines, clef signs, and other characters, was an individual piece of metal type.13\nAlthough specialized note heads were needed for four- and seven-shape music, standard elements made for round-note music typesetting would have been available for everything else on the page. As Hinckley relates, typeset pages were stereotyped (cast in metal) and multiple pages printed on one large sheet of paper.14\nHinckley‚Äôs article in the November 1852 issue of Godey‚Äôs described bookbinding and distribution at the Lippincott firm in Philadelphia.15 Large sheets were folded and sewn together. The assembled stack of pages was then pressed and its edges cut. Finally, binding was attached. Books were sold at Lippincott‚Äôs bookstore or packed to be shipped elsewhere.16 Although all the shape-note books manufactured in Philadelphia were advertised to be sold locally, they clearly had a more specific regional audience. Four-shape books like The Sacred Harp were most popular in the South. Hayden‚Äôs Sacred Melodeon seems to have been more popular in the West, while The Christian Harmony was marketed in the South.\nHinckley‚Äôs account makes clear that factory jobs were gender-specific, as was typical at the time: women operated the large printing presses, folded the sheets, and sewed them together, while men performed heavy labor such as pressing and packing books and skilled work such as typesetting. I was surprised by the sheer number of women employed in printing (about two dozen in each factory). Referring to the Collins factory, Hinckley remarks, ‚ÄúWe cannot say whether the attraction is in the beautiful working of the machinery, or in the faces of the bevy of industrious working girls who attend there.‚Äù17 Although his sentiments are quite dated, the images of women at work are striking, though I can‚Äôt help but think about how uncomfortable their dresses must have been in the summer heat.\nIn addition to publishing books, individuals at the Collins firm contributed directly or indirectly to southern shape-note music. As related in volume 3, no. 2 of the Newsletter, Elphrey Heritage, the composer of ‚ÄúWarning‚Äù (p. 213b) and ‚ÄúThe Savior‚Äôs Call‚Äù (p. 489), was T. K. & P. G. Collins‚Äô bookkeeper.18 He contributed songs to additional books published by Collins: The Hesperian Harp, The Christian Harmony, The Social Harp, The Christian Minstrel, Harmonia Ecclesiae, The Sacred Melodeon, and The Timbrel of Zion.\nTillinghast K. Collins Jr.‚Äôs The Timbrel of Zion (1853) made a lasting contribution to southern shape-note music. The Timbrel was the first book printed in the ‚Äúmodern‚Äù seven-shape style of the Deason-Parris (‚ÄúAlabama‚Äù) and 2010 revisions of The Christian Harmony. The Timbrel combined Aikin‚Äôs shapes with standard staff and key signatures, which Aikin had omitted. It featured old English and New England music, ‚Äúreformed harmony‚Äù tunes in the style of Lowell Mason, and folk hymn arrangements, mostly drawn from Hayden‚Äôs Sacred Melodeon. Walker appears to have pasted several dozen pages from Collins‚Äô book into his Christian Harmony manuscript. In fact, aside from The Southern Harmony, the Timbrel is the greatest source of tunes in Walker‚Äôs Christian Harmony.19\nThe Timbrel of Zion had a small effect on The Sacred Harp. When J. S. James compiled his edition of The Sacred Harp in 1911, he pasted or copied at least two songs from the Timbrel into his manuscript: ‚ÄúGreen Street‚Äù (p. 198) and ‚ÄúBeyond the Starry Skies‚Äù (p. 512 in the James book). As these songs are not in The Christian Harmony, James most likely found them in the Timbrel. James also mentioned the Timbrel a number of times in his commentaries‚Äî‚Äúcheese notes‚Äù‚Äîon individual songs, demonstrating that he had access to a copy. The New Sacred Harp (1884), published in seven shapes by B. F. White Jr. and J. L. White, contains numerous arrangements of songs that exactly match those in the Timbrel. Its authors chose the Timbrel arrangements of familiar songs like ‚ÄúMear‚Äù and ‚ÄúLenox‚Äù (pp. 49b and 40) over the original versions in their father‚Äôs The Sacred Harp and older books.\nThe Philadelphia connection also indirectly accounts for at least two of the alto parts in The Sacred Harp: those for ‚ÄúDevotion‚Äù and ‚ÄúLeander‚Äù (pp. 48t and 71). Amos Sutton Hayden of Ohio included precursors of these altos in his four-shape Introduction to Sacred Music (1835) and seven-shape Sacred Melodeon (1848). The latter book was a Collins publication and source for some of the songs in The Timbrel of Zion. When Walker added altos to three-part songs that he had published in The Southern Harmony, he sometimes turned to arrangements in other books rather than write his own parts. The altos he added to ‚ÄúDevotion‚Äù and ‚ÄúLeander‚Äù in The Christian Harmony match those in the Timbrel. Although attributed to S. M. Denson, the altos in 48t and 71 match those in The Christian Harmony and presumably came into the 1911 Sacred Harp through that book.\nThus, the ‚ÄúPhiladelphia connection‚Äù accounts for a few songs‚Äîand a few stray notes‚Äîin The Sacred Harp, slightly more songs in The New Sacred Harp, and a large number of songs in The Christian Harmony. I conclude this article, as I did the tour, with the skilled Philadelphia artisans who literally ‚Äúshaped‚Äù shape-note music: type founders and setters. The J. M. Armstrong Company continued to design and typeset shape-note books, including hymnals and gospel songbooks, well into the twentieth century.20 Theirs, at 710 Sansom Street, is the one building connected to Philadelphia‚Äôs central role in shape-note music publishing that survives.\nI am grateful to Jesse Polhemus, Robert Vaughn, and Wade Kotter, who assisted with my research on The Timbrel of Zion.\n- In the nineteenth century, ‚Äúwestern‚Äù referred to the region west of the Appalachians, including western Pennsylvania. [‚Ü©]\n- Aldine S. Kieffer, ‚ÄúA Brief History of Patent Notes,‚Äù The Musical Million 10, no. 9 (1879): 136‚Äì37. [‚Ü©]\n- For an overview of the publishing history of The Southern Harmony, see Harry Eskew, ‚ÄúWilliam Walker‚Äôs Southern Harmony: Its Basic Editions,‚Äù Latin American Music Review 7, no. 2 (1986): 137‚Äì48. [‚Ü©]\n- Both firms changed names several times. ‚ÄúCollins‚Äù refers to ‚ÄúT. K. & P. G. Collins,‚Äù ‚ÄúS. C. Collins,‚Äù ‚ÄúT. K. Collins, Jr.‚Äù and ‚ÄúCollins Printing House,‚Äù while ‚ÄúMiller‚Äù refers to ‚ÄúE. W. Miller,‚Äù ‚ÄúMiller & Burlock,‚Äù ‚ÄúE. W. Miller‚Äôs Bible and Publishing House,‚Äù and ‚ÄúEdward W. Miller Company.‚Äù [‚Ü©]\n- ‚ÄúInteractive Maps Viewer,‚Äù Greater Philadelphia GeoHistory Network, accessed August 26, 2017, http://www.philageohistory.org/tiles/viewer/ . [‚Ü©]\n- Ernest Hexamer, Hexamer General Surveys, Volume 7, Plate 612 (1872). Free Library of Philadelphia Map Collection, https://libwww.freelibrary.org/digital/item/12946. [‚Ü©]\n- ‚ÄúHenry B. Ashmead, Book and Job Printer, Sansom Street above Eleventh.‚Äù [graphic] Free Library of Philadelphia Digital Collections, https://libwww.freelibrary.org/digital/item/47891. [‚Ü©]\n- See, in particular, Hexamer & Locher, Maps of the City of Philadelphia, 1858‚Äì1860, Plate 14 (1860). Free Library of Philadelphia Map Collection, http://www.philageohistory.org/rdic-images/view-image.cfm/HXL1860v2-pl14. [‚Ü©]\n- American Publishing and Engraving Co., Illustrated Philadelphia: Its Wealth and Industries (New York: American Publishing and Engraving Co., 1889). Internet Archive, https://archive.org/stream/illustratedphila00amer#page/215/mode/1up. [‚Ü©]\n- ‚ÄúThe Item and The Call, North 7th Street‚Äù [albumen print] (1889). Free Library of Philadelphia Digital Collections, https://libwww.freelibrary.org/digital/item/pdcl00076. [‚Ü©]\n- Cornelius T. Hinckley, ‚ÄúEveryday Actualities, no. V: A Day‚Äôs Ramble Through the Mechanical Department of the ‚ÄòLady‚Äôs Book,‚Äô‚Äù Godey‚Äôs Lady‚Äôs Book 45, October 1852, 307‚Äì15, https://archive.org/details/godeysmagazine45gode. [‚Ü©]\n- I‚Äôve never seen a manuscript with pasted pages, but such manuscripts exist. See Wade Kotter, August 6, 2015 (7:18 PM), comment on Robert Vaughan, ‚ÄúPreparing to print a Sacred Harp, early 1900s,‚Äù Fasola-discussions (Google group), August 5, 2015 (8:42 AM), https://groups.google.com/forum/#!msg/fasola-discussions/3qofTRHM3qw/Z5wRzsKNBwAJ. [‚Ü©]\n- For further description of music typography and images of type, see Thomas MacKellar, The American Printer: A Manual of Typography (Philadelphia: MacKellar, Smiths & Jordan, 1887), 114‚Äì19 https://archive.org/stream/americanprinterm1878mack#page/114/mode/1up and George Barnard, ‚ÄúMusic Notes Defy Mechanical Typesetting,‚Äù Popular Mechanics, September 1923, 433‚Äì34, https://archive.org/stream/PopularMechanics1923/Popular_Mechanics_09_1923#page/n171/mode/2up. [‚Ü©]\n- Hinckley, ‚ÄúA Ramble,‚Äù 307‚Äì13. [‚Ü©]\n- Although Lippincott did not publish any major shape-note titles, they did publish William Walker‚Äôs children‚Äôs book Fruits and Flowers (1873). [‚Ü©]\n- Cornelius T. Hinckley, ‚ÄúEveryday Actualities, no. VI: A Day at the Bookbindery of Lippincott, Grambo, & Co.,‚Äù Godey‚Äôs Lady‚Äôs Book 45, November 1852, 403‚Äì12, https://archive.org/details/godeysmagazine45gode. [‚Ü©]\n- Hinckley, ‚ÄúA Ramble,‚Äù 311. [‚Ü©]\n- Jesse P. Karlsberg and Christopher Sawula, ‚ÄúElphrey Heritage: Northern Contributor to the Nineteenth-century Sacred Harp,‚Äù Sacred Harp Publishing Company Newsletter 3, no. 2 (November 12, 2014), http://originalsacredharp.com/2014/11/12/elphrey-heritage-northern-contributor-to-the-nineteenth-century-sacred-harp/. [‚Ü©]\n- The Timbrel of Zion was squarely aimed at the southern and western market. Its cover and title page advertise that the book was sold in western Pennsylvania, Ohio, western Virginia, South Carolina, and Georgia. Newspaper accounts from the Carolinas show that the Timbrel continued to be used there into the early twentieth century, sometimes alongside The Southern Harmony or The Christian Harmony. For example, the Gaffney Ledger reports of a singing in 1917, ‚ÄúAmong the books were the old Timbrel of Zion, which was the book used by the fathers and grandfathers of most of those who were present.‚Äù See ‚ÄúAll Day Singing Largely Attended,‚Äù Gaffney Ledger, September 18, 1917, 1. Gaffney is a small town in South Carolina about twenty miles from Spartanburg. On The Timbrel of Zion as a key source for William Walker, see John Hollingsworth, et al., eds., The Christian Harmony: 2010 Revised Edition, second printing, with attributions by Robert Kelley and Rachel Hall (Bishop, GA: Christian Harmony Music Company, 2016 ). [‚Ü©]\n- The typesetter is rarely given credit, but after looking at a number of books where J. M. Armstrong is identified, I believe it is possible that the Armstrong company typeset not only all the shape-note books published in Philadelphia after 1850 or so, but also, together with their branch in Cincinnati, the majority of shape-note books printed and published elsewhere into the early twentieth century. See Historical and Commercial Philadelphia Handsomely Illustrated: With Supplement of the World‚Äôs Columbian Exposition (New York: Parsons, 1892), 171, https://archive.org/stream/historicalcommer00newy#page/171/mode/1up. [‚Ü©]","First Great Awakening. The first religious revival in the United States is followed by others in the Eighteenth and Nineteenth centuries. They lead to new denominations, new hymns, and a sharp upturn in church membership. Belief is refocused from intellectual to emotional. Many of the new hymns have easily remembered choruses, and some are set to folk melodies.\nShape note singing introduced in ‚ÄúThe Easy Instructor.‚Äù William Smith and William Little‚Äôs hymnal introduces notes as printed shapes to enable the singers to find pitch.\nThe Sacred Harp. Benjamin Franklin White‚Äôs collection of hymns published in the four-note Fa-Sol-La format is judged one hundred years later as the book ‚Äúaside from the Holy Bible found oftenest in the homes of rural southern people.‚Äù The hymnal becomes so popular that shape-note singing becomes known as Sacred Harp.\nSinging conventions start in the 1840s. They take root in the South.\nCharles Tillman hears ‚ÄúOld Time Religion.‚Äù In Lexington, South Carolina, Tillman and his father sponsor tent shows and lend their tent to an African American quartet who sing ‚ÄúOld Time Religion.‚Äù Tillman copyrights it in 1891 and introduces it to white worship music. He later cowrites ‚ÄúLife‚Äôs Railway to Heaven‚Äù and popularizes ‚ÄúI Am a Poor Wayfaring Stranger.‚Äù\nR.E. Winsett starts a publishing company in Dayton, Tennessee. With ties to the Assembly of God, Winsett publishes Southern Gospel and Black Gospel songs. Later, he becomes the first to bring the work of African American hymnodist Thomas A. Dorsey to white congregations.\nJames D. Vaughan organizes a quartet to tour southern white churches to promote his songbooks. Its success leads Vaughan to establish as many as sixteen Vaughan Quartets to tour the South in tent shows and church halls.\nFirst Southern Gospel Recordings. James D. Vaughan establishes Vaughan Phonograph Records‚Äîprobably the first record company in the South, and makes the first known Southern Gospel recordings. They are recorded by the Vaughan Quartet with piano accompaniment. Vaughan now sells in excess of one million songbooks annually, and becomes the first radio station operator in Tennessee when he starts WOAN in Lawrenceburg in 1923. Vaughan shares his radio frequency with a new Nashville station, WSM, later the parent station of the Grand Ole Opry, and Vaughan‚Äôs quartets appear often on WSM.\nVirgil Stamps leaves the Vaughan Company. Stamps, the head of Vaughan‚Äôs operations west of the Mississippi, leaves to start his own publishing company in Jacksonville, Texas. Two years later, he‚Äôs joined by Jesse Randall Baxter to create Stamps-Baxter. Like Vaughan, Baxter promotes his hymns with his own quartets. His songbooks include ‚ÄúPrecious Memories,‚Äù ‚ÄúIf We Never Meet Again,‚Äù ‚ÄúFarther Along,‚Äù and many other classics of Southern worship music.\nSmith‚Äôs Sacred Quartet begins recording. An amateur shape-note group led by J. Frank Smith‚Äîa Methodist teacher in Braselton, Georgia, makes their first recordings. One of them, ‚ÄúPicture from Life‚Äôs Other Side,‚Äù sells exceptionally well and is later recorded by Hank Williams. Its success ignites interest in recording rural gospel music. Smith‚Äôs Sacred Singers make over one hundred recordings, mostly with guitar instead of piano, and introduce many songs that will be recorded often in the years ahead.\nStamps discovers Virgil Brock. A pianist, Brock incorporates a rhythmic style based on Ragtime to his work with the Stamps Quartet. The Stamps also record what will become their theme song, ‚ÄúGive the World a Smile.‚Äù Virgil Stamps buys the song from the composers for ten dollars.\nTennessee Music and Printing launched. In Cleveland, Tennessee, home of the Church of God, The company, started by Otis McCoy, buys up assets of other music publishers, including Vaughan. He also signs an African American preacher, Cleavant Derricks, who writes ‚ÄúWhen God Dips His Love in My Heart‚Äù and ‚ÄúJust a Little Talk with Jesus.‚Äù Derricks later says that McCoy paid him only in songbooks.\nAlbert E. Brumley publishes ‚ÄúI‚Äôll Fly Away.‚Äù It‚Äôs the first ‚Äúhit‚Äù for Brumley, originally from Spiro, Oklahoma. He goes on to write ‚ÄúJesus, Hold My Hand,‚Äù ‚ÄúTurn Your Radio On,‚Äù ‚ÄúI‚Äôve Found a Hiding Place,‚Äù ‚ÄúRank Stranger,‚Äù and ‚ÄúIf We Never Meet Again.‚Äù At the time of his death in 1977, he has more than seven hundred hymns in his catalog and is dubbed the ‚ÄúGershwin of the Rural Route.‚Äù\nFormation of the Blackwood Brothers Quartet and other quartets. Formed in Choctaw County, Mississippi, the Blackwoods, who relocate to Memphis in 1950, remain the best-known Southern Gospel group. Founding member James Blackwood retired the name ‚ÄúBlackwood Brothers‚Äù in 2000, but a descendant group, the Blackwood Quartet, tours to this day.\nMany other quartets form during the 1920s and ‚Äò30s, including the Speers, Lefevres, the Chuck Wagon Gang, the John Daniel Quartet and the Swanee River Boys. The Chuck Wagon Gang begins recording for Columbia in 1936, continuing with the label into the 1970s. Music publishers often supply salaries and automobiles in exchange for selling their songbooks and promoting their hymns, but the Chuck Wagon Gang remains unaffiliated with a publisher. The John Daniel Quartet later breaks free of its deal with Stamps-Baxter to join the Grand Ole Opry, where it becomes one of the best-known quartets.\nThe Oak Ridge Quartet. Singer and promoter Wally Fowler forms the Oak Ridge Quartet, who become the Oak Ridge Boys. Fowler sells the rights to the name in 1958. Many changes of personnel later, they go secular in 1975.\nGospel Boogie. Lee Roy Abernathy from Canton, Georgia, writes and records a Southern Gospel standard, ‚ÄúGospel Boogie‚Äù aka ‚ÄúWonderful Time up There.‚Äù It breaks from tradition by incorporating Pop and R&B influences. Abernathy records it for Chicago‚Äôs White Church Records, and it sells 200,000 copies, passing into Black Gospel music (Sister Rosetta Tharpe, Pilgrim Travelers) and Pop (Pat Boone‚Äôs version reached No.4 in 1958). Abernathy‚Äôs follow-up, ‚ÄúTerrible Time down There,‚Äù doesn‚Äôt do as well.\nSouthern Gospel from the Ryman. Wally Fowler starts his All Night Sings at Nashville‚Äôs Ryman Auditorium. Some of the program is broadcast on WSM. Fowler includes a few Black Gospel artists, such as the Fairfield Four, on his programs, but his mainstays are Southern Gospel quartets. Fowler takes his All-Night format to other cities in the South, attracting two million attendees a year by the mid-1950s.\nThe Statesmen. Pianist Hovie Lister forms the group in Atlanta with lead singer Jake Hess. He includes Black Gospel songs, and creates a dynamic stage presence. They tour as a package show with the Blackwood Brothers. Both sign with RCA Victor.\nThe Jordanaires join the Grand Ole Opry as one of the show‚Äôs Southern Gospel groups. They soon begin working Nashville record sessions as background vocalists, including many of Elvis Presley‚Äôs sessions.\nPeace in the Valley. A landmark Southern Gospel recording, ‚ÄúPeace in the Valley‚Äù was written by African American preacher Thomas A. Dorsey and first recorded by a Black Gospel quartet, the Flying Clouds of Detroit, in 1947. The Jordanaires cover it in 1950, but Red Foley‚Äôs 1951 Nashville recording with the Sunshine Boys makes the song into a Southern Gospel standard.\nThe Lewis Family. Blending Southern Gospel and Bluegrass, the Lewis Family from Lincolnton, Georgia, make a big impact on Wally Fowler‚Äôs All Night Sings at the Ryman. Unusually for quartets, the Lewises blend male and female voices.\nWord Records founded in Waco, Texas. Word becomes the largest religious record label. In 1995, its new owner, Thomas Nelson, moves the company to Nashville. It is now a division of the Warner Music Group.\nCecil Blackwood forms the Songfellows in Memphis. Elvis Presley auditions unsuccessfully. The Blackwoods buy an airplane, but two of their members, R.W. Blackwood and Bill Lyles, are killed when it crashes in Clanton, Alabama. This creates an opening in the Blackwoods, filled by the Songfellows. Elvis auditions again and performs a few shows with the Songfellows, but lands a contract with Sun Records.\nElvis Presley performs on a July 4 bill with the Statesmen and Blackwoods. It‚Äôs a morning event in DeLeon, Texas and the only time Elvis performs three shows in three towns in one day. At DeLeon, he only sings Southern Gospel. He later cites the Statesmen‚Äôs second tenor, Jake Hess, as one of his big influences.\nTennessee Ernie Ford releases ‚ÄúHymns.‚Äù A landmark LP rooted in Southern Gospel standards, it remains in print for decades and is on the Billboard album chart for 277 weeks, making it the eleventh best-charting LP of all time. Ford follows it with a similar album, Spirituals.\nFirst National Quartet Convention. Organized by the Blackwoods‚Äô J.D. Sumner, it is held in Memphis, and soon becomes a week-long festival. Later, the event relocates to Louisville, Kentucky and moved to Pigeon Forge, Tennessee, in 2014.\nThe Blackwoods and the Statesmen start Skylite Records. Based in Memphis, the label signs the Oak Ridge Quartet, the Speer Family, and others. After the Oaks became successful in secular music, the Skylite masters are repackaged.\nJake Hess leaves the Statesmen to form the Imperials. He draws members from the Speer Family, Oak Ridge Boys, and the Weatherfords. Based in Nashville, they record with Elvis on his later gospel albums, How Great Thou Art and He Touched Me, and tour with him when he returns to live performing in 1969. They embrace fuller instrumentation and modern presentation.\nJ.D. Sumner of the Stamps Quartet and James Blackwood form the Gospel Music Association. At the instigation of GMA member Bill Gaither, the GMA launches the Dove awards in 1969, offering recognition to all styles of Christian music. The Association and its Hall of Fame are in Franklin, Tennessee.\nThe Blackwood Brothers gather 193,000 signatures on a God and Country petition to stop the ban of prayer in school. By this point, the Blackwoods have recorded 50 LPs and sold more than two million records.\nHee-Haw. Although ridiculed by mainstream media and dropped by CBS-TV, the show is enormously successful in syndication. One of the show‚Äôs highlights is the Hee Haw Gospel Quartet comprising Grandpa Jones, Buck Owens, Roy Clark, and Kenny Price singing in the traditional quartet style.\nThe Oak Ridge Boys switch from sacred to secular music. They score seventeen No.1 Country hits.\nGaither Homecoming. Following a Gaither Vocal Band recording session for the album Homecoming, many of the musicians stay to reminisce about the golden days of Quartet singing. Among the participants are the Speers, Jake Hess, J.D. Sumner and the Stamps, the Gatlins, and Hovie Lister. The impromptu session is videotaped and becomes a hit VHS tape, leading to a series of taped concerts dubbed Gaither Homecoming. The 2004 tour draws half-a-million attendees. The Gaithers are categorized as Progressive Southern Gospel, an increasingly powerful movement within the Christian music community.\nSouthern Gospel increasingly blends into Contemporary Christian music, although authentic Southern Gospel quartet singing can still be heard. In 2014, the National Quartet Convention, established by the Blackwoods in 1957, moved to Pigeon Forge, TN. Nationally, 285 radio stations identify themselves as Southern Gospel stations."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"}],"document_ids":["<urn:uuid:650f4942-1bd9-453c-b18f-3e8a0f3c461f>","<urn:uuid:08a7fae3-4548-4d3c-8b54-7ca4e098b7d0>"],"error":null}
{"question":"How does Likferr 100 iron supplement work in the body, and what dietary restrictions should be followed when taking it?","answer":"Likferr 100 works through spheroidal iron-carbohydrate nanoparticles with an iron (III) hydroxide nucleus surrounded by sucrose. The iron dissociates in the reticuloendothelial system and transfers to transferrin, with about 31 mg of iron being utilized over 24 hours. Regarding dietary restrictions, Likferr 100 should not be used simultaneously with oral iron supplements as this decreases iron absorption from the gastrointestinal tract. Oral iron treatments can only begin 5 days after the last injection. Additionally, patients should be mindful of calcium-rich foods, caffeinated products, and foods high in polyphenols or phytates, as these can interfere with iron absorption.","context":["Description pharmaceutical form:\nA colloidal solution from red-brown to brown.\nAfter a single on/in the introduction of the drug Likferr 100 containing 100 mg iron, iron Cmax (on average, 538 mol) is reached after 10 min after injection. T1/2 is 6 h. the VSS at steady state is approximately 8 l that indicates low iron distribution in liquid media of the organism.\nRelease of iron by the kidneys the first 4 h after injection is less than 5% of total clearance. After 24 h of serum iron content is returned to the original (before the introduction) value, and approximately 75% of the sucrose leaves the bloodstream.\nDescription pharmacological action:\nDrug gland regulates metabolic processes. Is a colloidal solution, which consists of spheroidal iron-carbohydrate nanoparticles. In the nucleus (center) of each particle is iron (III) hydroxide. The nucleus is surrounded by a shell of sucrose, which stabilizes the iron (III)-hydroxide slowly releases the bioactive iron, and maintains the resulting particles in colloidal solution. The result is a complex molecular mass of approximately 43 kDa, resulting in its excretion via the kidneys in unchanged form is not possible. Iron (III) in this complex is associated with structures similar to the natural San.\nThe active ingredient of the drug is iron (III)-hydroxide sucrose complex ‚Äî when ingested, dissociates in the reticuloendothelial system into iron and sucrose. Due to the lower stability of iron saharata compared to transferrin is observed in competitive exchange of iron to transferrin favor. As a result, 24 hours over about 31 mg of iron. Polycyclic ferric hydroxide (III) is partially preserved in the form of ferritin after complex formation with the protein ligand ‚Äî apoferritin liver mitochondria. The rate of hemoglobin increases faster and with more certainty than after the therapy, drugs containing iron (II). The introduction of 100 mg of iron (III) leads to an increase of hemoglobin of 2-3% during pregnancy by 2%. The toxicity of the drug is very low. Therapeutic index equal to 30 (200/7).\nIron deficiency States (including iron deficiency and acute post-hemorrhagic anemia) patients with the following conditions:\nApplication of pregnancy and breast-feeding:\nThe drug is contraindicated in the first trimester of pregnancy. In II and III trimester of pregnancy only if the expected benefit to the mother outweighs the potential risk to the fetus. Lactation the safety of the drug is not installed. It is recommended to stop breast-feeding (if necessary, use of the drug) or stop the drug.\nCNS: dizziness, headache, loss of consciousness, paresthesia.\nFrom the side of cardiovascular system: palpitations, tachycardia, decreased blood pressure, kollaptoidnoe state, feeling heat, tides blood to a person, peripheral edema.\nThe respiratory system: bronchospasm, shortness of breath.\nFrom the digestive system: transient taste disturbances (especially metallic taste in the mouth), ‚Äúspilled‚Äù abdominal pain, epigastric pain, diarrhea, dysgeusia, nausea, vomiting.\nWith the skin: erythema, pruritus, rash, pigmentation disorders, increased sweating.\nFrom the musculoskeletal: arthralgia, back pain, swelling of joints, myalgia, pain in extremities.\nAllergic reactions: anaphylactoid reaction, facial swelling, laryngeal edema.\nOther: asthenia, chest pain, back, a feeling of heaviness in the chest, weakness, feeling of malaise, pallor, fever, chills.\nLocal reactions: pain and swelling at the injection site (especially when ekstrawazalnoe contact of the drug), phlebitis, burning sensation, hematoma.\nIf any of these side effects worsen or develop any other side effects, you should inform the doctor.\nUnacceptable simultaneous use of the drug Likferr 100 with medicinal forms of iron intake, because it decreases iron absorption from the gastrointestinal tract. Treatment with oral iron preparations can begin no earlier than 5 days after the last injection.\nLikferr 100 can be mixed in the same syringe only with 0.9% sodium chloride solution. No other solution for I/V administration and therapeutic products add not allowed because there is a risk of precipitation and/or other pharmaceutical interaction. Compatibility with containers of other materials than glass, PE and PVC, has not been studied.\nIf the patient takes other medications, you should consult with your doctor.\nMethod of application and dose:\nIn/in (slow struino or drip) and in the venous phase of dialysis system. The drug is not intended for the/m introduction. Unacceptable simultaneous introduction of full (cumulative) therapeutic doses of the drug.\nBefore the introduction of the first therapeutic dose, it is necessary to assign a test dose. If during the observation period appeared the phenomenon of intolerance, the drug should be discontinued immediately. Before opening, ampoules should examine her for possible sediment and damage. You can use only a brown solution without sediment.\nLikferr 100 preferable to introduce in the course of drip infusion in order to reduce the risk of pronounced blood pressure reduction and the risk of contact with okolovenoznoe space. Just before infusion Likferr 100 should be diluted with 0.9% sodium chloride solution in ratio of 1:20, e.g. 1 ml (20 mg iron) in 20 ml of 0.9% solution of sodium chloride. The resulting solution is introduced with the following speed: 100 mg of iron is not less than 15 min 200 mg over 30 min 300 mg for 1.5 h, 400 mg over 2.5 h 500 mg for 3.5 h. The introduction of the maximum tolerated dose, estimated at 7 mg iron/kg should be made for at least 3.5 h, regardless of the total dose.\nBefore the first drip by introduction of a therapeutic dose of the drug Likferr 100 you must enter test dose: 1 ml Likferr 100 (20 mg iron) in adults and children weighing more than 14 kg and half the daily dose (1.5 mg iron/kg) to children with body weight less than 14 kg, for 15 min. in the absence of undesirable phenomena, the remaining solution should be administered with the recommended speed.\nThe drug Likferr 100 you can also enter in the form of undiluted solution in/in slowly, with a speed of 1 ml Likferr 100 (20 mg iron) per minute, for example 5 ml Likferr 100 (100 mg iron) injected within 5 min, the Maximum volume should not exceed 10 ml Likferr 100 (200 mg iron) per injection.\nAfter injection, the patient is recommended some time to fix arm in extended position.\nBefore the first jet by the introduction of the therapeutic dose should be administered Likferr 100 test dose: 1 ml Likferr 100 (20 mg iron) in adults and children weighing more than 14 kg and half the daily dose (1.5 mg iron/kg) to children with body weight less than 14 kg over 1-2 min If no adverse effects during subsequent 15 min of observation the remainder of the solution should be administered with the recommended speed. After injection, the patient is recommended to stabilize the hand in a stretched position.\nIntroduction to dialysis system\nLikferr 100 possible to enter directly into the venous phase of dialysis system, strictly observing the rules outlined for intravenous injection.\nThe calculation of the dose\nBefore the introduction it is necessary to individually calculate the total body iron deficiency according to the following formula:\nTotal iron deficit (mg) = body weight (kg) ? (–ùb OK ‚Äî –ùb patient (g/l) ? 0,24 + deposited iron (mg)\nFor patients with body weight less than 35 kg:\n‚Äì the number of the deposited iron = 15 mg/kg,\n‚Äì the normal rate –ùb = 130 g/l.\nFor patients weighing over 35 kg:\n‚Äì the number of the deposited iron = 500 mg,\n‚Äì the normal rate –ùb = 150 g/l.\nThe coefficient 0,24 = 0,0034 ? 0,07 ? 1000 (iron content of hemoglobin = 0.34 percent blood volume = 7% of body weight factor 1000 = conversion from the grams in miligram).\nYou then need to calculate the cumulative (course) dose of the drug Likferr 100 that you need to enter to fill the deficit of iron in the body, according to the following formula:\nTotal volume (ml) = Total iron deficit (mg)/ 20 mg/ml\nApproximate values of total iron deficiency and the total amount of the preparation for the introduction of the course of therapy are shown in table:\nThe total amount of the drug for the treatment of Likferr 100Body weight, kgCumulative (foreign exchange) therapeutic dose Likferr 100 for the introduction–ùb 60 –≥g/l–ùb 75 g/l–ùb 90 g/l–ùb g/lFe, mgmlFe, mgmlFe, mgmlFe, mgml51608140712061005103201628014240122201115480244202138019320162064032560285002542021258004070035620315202630960488404274037640323512606311405710005088044401360681220611080549404745148074132066114057980495015807914007012206110405255168084150075130065110055601800901580791360681140576519009516808414407212006070202010117608815007512606375212010618609315807913206680222011119409716608313606885234011720401021720861420719024401222120106180090148074\nThe frequency of administration is determined by a physician, but not more often than every other day.\nAdults, including elderly (over 65 years) patients: Likferr 100 5-10 ml (100-200 mg iron) 1-3 times a week.\nChildren: there are limited data on the use of drugs in children. If necessary, it is recommended to enter a maximum of 0.15 ml Likferr 100 (3 mg iron)/kg 1-3 times per week depending on the indicator –ùb.\nThe maximum tolerated single dose for adults, including elderly (>65 years) patients\nFor jet injection: 10 ml Likferr 100 (200 mg iron), the duration of administration ‚Äî not less than 10 min.\nFor intravenous injection: depending on indications, a single dose can be 500 mg of iron. The maximum allowable single dose of 7 mg iron/kg, and is injected once a week, but not more than 500 mg of iron.\nUsually, higher doses are associated with a higher frequency of adverse events.\nIn the case when the total therapeutic dose exceeds the maximum allowed single dose, it is recommended that the fractional drug.\nIf after 1-2 weeks after the start of drug treatment Likferr 100 is no improvement of hematological parameters, it is necessary to reconsider the initial diagnosis.\nThe calculation of the dose to compensate the iron content after the blood loss or even autologous blood\nDose Likferr 100 needed to compensate for the iron deficiency, is calculated by the following formula:\nIf the amount of blood lost is known: in/with the introduction of 200 mg iron (10 ml Likferr 100) leads to the same increase in the concentration –ùb as the transfusion of 1 unit of blood (400 ml with the concentration of –ùb 150 g/l).\nThe amount of iron that needs to be filled up, mg = number of units blood lost x 200 or the necessary amount of the drug Likferr 100, ml = number of blood units lost x 10.\nWhile reducing the content of –ùb: use the previous formula, provided that the depot iron Supplement is required.\nThe amount of iron that need to be filled in mg = body weight, kg x 0.24 x (normal rate Hb ‚Äî patient Hb), g/l,\nFor example: weight 60 kg, Hb deficit = 10 g/l the necessary amount of iron = 150 ppm, the necessary amount of the drug Likferr 100 = 7.5 ml.\nTreatment of patients with chronic renal disease undergoing hemodialysis and receiving erythropoietin treatment additional\nThe drug is administered strictly in a/V. the injection Itself should be performed as slowly as possible, the duration of injection increases with increasing dose. The procedure is not particularly difficult for hemodialysis patients, because they usually contain a suitable intravenous access. The drug is administered in 0.9% sodium chloride solution for at least 15 min during the last 2 hours of each dialysis session.\nAbsolute iron deficiency (phase of correction of anemia)\n30-50 mg of iron/session dialysis\n‚Äì 1000 mg of iron within 6-10 weeks.\nPhase of maintenance therapy\nAre assigned to different doses, in different modes:\n‚Äì 10-25 mg of iron/session dialysis\n‚Äì 100 mg of iron/ 1 time per month (depending on the ferritin concentration in serum).\nPhase correction of hemoglobin\n‚Äì 150 mg of iron to increase the concentration to 10 g/L.\nSymptoms: decrease in blood pressure (signs of collapse seen within 30 min), symptoms of hemosiderosis.\nTreatment: symptomatic, if necessary ‚Äî drugs that bind iron (chelators), such as deferoxamine.\nShould strictly observe the speed of the drug Likferr 100 (with the rapid introduction of the drug may drop BP). A higher incidence of undesirable side reactions (especially lower blood pressure), including and heavy, associated with increasing doses. Thus, the time of administration of the drug contained in the section ‚ÄúMethod of application and dosage‚Äù should be strictly adhered to, even if the patient receives the drug at the maximum tolerated dose.\nDuring the period of drug administration Likferr 100 need to monitor hemodynamic parameters.\nLikferr 100 should be administered only to patients in whom the diagnosis of anaemia is confirmed by corresponding laboratory data (e.g. the results of determination of ferritin in serum or indicators of hemoglobin and hematocrit, number of erythrocytes and their parameters ‚Äî average corpuscular volume or mean hemoglobin in the erythrocyte).\nIntravenous iron preparations can cause allergic or anaphylactoid reactions that can be potentially life-threatening. Patients with asthma, eczema, atopic diseases, polyvalent Allergy, allergic reactions to other iron preparations, and patients with low iron binding capacity the ability of serum/or insufficiency of folic acid have an increased risk of allergic or anaphylactoid reactions (see section ‚ÄúContraindications‚Äù, subsection ‚ÄúWith caution‚Äù).\nStudies conducted in patients who have hypersensitivity reactions to iron dextran showed no complications on the background of drug treatment.\nAvoid penetration of the drug into okolovenoznoe space, since getting Likferr 100 beyond the vessel leading to tissue necrosis and brown staining of the skin. In the case of the development of this complication is recommended (if the needle is in the vessel) to introduce a small amount of 0.9% sodium chloride solution. To accelerate chelate iron and prevent its further penetration into surrounding tissue is recommended the application of the injection site geparinoterapii preparations (gel or ointment is applied lightly, not rubbing).\nUnacceptable the introduction of the drug in the presence of sediment.\nIn 1 ml product contains Likferr 100 from 260 to 340 mg of sucrose. These data should be considered in patients with diabetes. In drip administered drug, depending on the indications, the maximum tolerated single dose can be 500 mg of iron, which corresponds to the introduction of 8.5 g of sucrose. In terms of the amount of carbohydrates in HYE (1 bread unit = 12 g of carbohydrates), it corresponds to 0.7 HEH.\nDuring therapy with stimulants of erythropoiesis and iron metabolism is controlled by such factors as the concentration of serum ferritin and transferrin saturation with iron (scientific-technical journal+). Determining the number of hypochromic red blood cells and hemoglobin concentration in reticulocytes helps to make a decision about the necessity of appointment of iron preparations intravenously, when a scientific-technical journal + hyperferritinemia and low. The risk of iron overload kompensiruet blood loss during the procedures associated with dialysis (lost 1-3 g of iron per year). Should regularly monitor the concentration of ferritin in serum. The serum ferritin concentration above 500 ¬µg/l (normal C-reactive protein counts), continuing for a long period of time can indicate the iatrogenic iron overload. In such cases the preparations of iron should be lifted (therapy with stimulants of erythropoiesis must continue). Due to the fact that iron stimulates the growth of most microorganisms, iron preparations should be discontinued in the development of acute bacterial infections. Also therapy with intravenous iron preparations should be used with caution in patients with permanent dialysis catheters.\nEffects on ability to drive a vehicle or work with potentially dangerous machinery. We recommend caution when driving or operating potentially dangerous machinery.\n|The purpose of the medication||Hematotropics|","What Makes Iron Absorption Difficult During Pregnancy?\nPregnancy incorporates a lot of changes in your body. With all the physiological and hormonal changes taking place in you, your requirement for more vitality and energy certainly increases and one way to ensure you‚Äôre supplying yourself with enough of it is to keep a strict check on your diet, especially your nutrient intake.\nWhat is it that boosts your vitality during pregnancy?\nTalking about foods, one of the nutrients that supplies you with enough energy during pregnancy is iron, and its intake anyway is extremely important for any woman (pregnant or not). For a woman who‚Äôs menstruating before pregnancy, it is the significant amount of blood loss on regular intervals that increases her requirement for iron intake. Being the catalyst that boosts your hemoglobin - basically the rate at which your red blood cells circulate oxygen into the whole body - iron becomes a must for every woman.\nDuring pregnancy, iron intake becomes highly important for another set of reasons. In case the mother doesn‚Äôt consume enough iron during her pregnancy, she‚Äôs inevitably putting her baby‚Äôs life at risk. If you didn‚Äôt know this already, iron deficiency can lead to severe consequences such as poor fetal development. Iron is the most important nutrient for the development of the brain and it is therefore crucial. The development issues can range from a delay in your child‚Äôs speech to severe cases of depression and anxiety when they grows up. Hence, iron intake is something that must not be neglected during pregnancy at all.\nIron deficiency also causes anemia, which affects your hemoglobin drastically and can have dangerous consequences during pregnancy such as preterm labour, infant mortality or an underweight infant. It can also be fatal to the mother.\nHaving understood the importance of iron, for both gestational purposes and otherwise, let us understand what hinders iron absorption in your body. There exist a lot of nutrients and chemical compounds that absolutely negate any effect iron is supposed to have on your body and hence, it is important you know about them in order to avoid their consumption in the future, especially during pregnancy.\n1. Foods with calcium\nCalcium hinders both the absorption of heme and nonheme irons (heme being a protein required for growth and energy). You must cut down on foods such as milk, cheese, soy, and broccoli. We know calcium is important for you, but having a balance of both calcium and iron in your body to ensure proper fetal development is important. Don‚Äôt consume anything in excess is what we‚Äôre saying and you must pay attention to it.\n2. Caffeinated products\nYou must limit your intake of food and beverages that contain high amounts of caffeine. The reason being that caffeine contains certain elements that hinder your body from absorbing iron, thereby weakening your body.\nIt has been found that women who consume caffeine more than the required amount tend to experience stillbirths, spontaneous abortions and even miscarriages during or after their third trimester. They may also deliver an underweight or underdeveloped baby. So, if you‚Äôre a coffee addict and are going to a mom soon, we‚Äôre sorry to tell you but, ‚ÄúQuit it!‚Äù\n3. Foods with polyphenols and phenolic acid\nBoth these chemical compounds have been found to hinder iron absorption in your body and hence, you must stay away from any food item that contains any of these two, or both. A few of them include dark chocolates (cocoa contains huge amounts of polyphenols), strawberries, hazelnuts and soy yogurt.\n4. Food with phytates\nAnother compound that hinders the effects of iron absorption in the body during pregnancy is phytates or phytic acid. The foods that contain this chemical compound include whole grain wheat, nuts and potatoes.\nMake sure you eat plenty of foods that are rich in Vitamin C, as they counter attack phytic acid, helping you absorb more iron.\nAlso, eat foods that are rich in ascorbic acid for this chemical compound enhances your iron intake the highest. Foods such as meat, fish, oranges and green vegetables will help you intake enough ascorbic acid. Make sure to include these foods in your diet."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"}],"document_ids":["<urn:uuid:8acf466a-7cbe-4971-934f-8509c36923fa>","<urn:uuid:43d7e959-65cc-424c-a86c-5be139ac159d>"],"error":null}
{"question":"¬øPodr√≠as explicar las diferencias entre la fitorremediaci√≥n para suelos s√≥dicos y la aplicaci√≥n de calcio como soluci√≥n? ¬°Me interesa mucho entender estas t√©cnicas! üíö","answer":"Phytoremediation and calcium application are two distinct approaches to treating sodic soils. Phytoremediation uses certain plant species tolerant to soil salinity and sodicity, working through plant roots increasing calcite dissolution rates and generating protons at the soil-root interface. This process is driven by carbon dioxide pressure in the root zone and improves physical properties and hydraulic conductivity. In contrast, the direct calcium application approach (through lime and gypsum) provides an immediate soluble source of calcium to replace excess sodium on the cation exchange complex. This solution needs to be part of a longer-term focused program and can be enhanced with modern technology using combinations of chelated and complexed calcium ions to significantly increase soil calcium levels on a per crop basis.","context":["Crop-Based Management Opportunities for Sodium- and Boron-Affected Soils.\nManzoor Qadir, International Center for Agricultural Research in the Dry Areas (ICARDA), Aleppo, P.O.Box 5466, Syria, Andrew Noble, International Water Management Institute (IWMI), South East Asia Office, Kasetsart University, Bangkok, P.O.Box 1025, Thailand, Sui-Kwong Yau, American Univ. of Beirut - FAFS, Bliss St., Beirut, 1107-2303, Lebanon, and Ghulam Murtaza, Institute of Soil and Environmental Sciences, University of Agriculture, Faisalabad, 38040, Pakistan.\nWith worldwide occurrence, sodium-affected soils (sodic soils) are characterized by the occurrence of sodium (Na) to levels that result in poor physical properties and fertility problems thereby adversely affecting the growth and yield of most crops. These soils can be ameliorated by providing a soluble source of calcium (Ca) to replace excess Na on the cation exchange complex. Many sodic soils contain inherent or precipitated sources of Ca, i.e. calcite at varying depths within the profile. Unlike other Ca sources used in the amelioration of sodic soils, calcite is not sufficiently soluble to effect the displacement of Na from the exchange complex and hence amelioration. In recent years, phytoremediation ‚Äî removal of Na by the cultivation of certain plant species tolerant to ambient soil salinity and sodicity levels ‚Äî has shown promise as a ‚Äòpay-as-you-go' option in the amelioration of calcareous sodic soils. In contrast to phytoremediation of soils contaminated by heavy metals, phytoremediation of sodic soils is achieved by the ability of plant roots to increase the rate of calcite dissolution, thereby resulting in enhanced levels of Ca in soil solution. The process of Na+ removal from calcareous sodic soils through phytoremediation has been found to be driven by the partial pressure of carbon dioxide within the root zone, and the generation of protons by roots of certain plant species at the soil-root interface. Both assist in increasing the dissolution rate of calcite with the added benefit of improved physical properties within the root zone, enhancing the hydraulic conductivity of these soils and allowing the leaching of Na below the effective rooting depth. Although shoot uptake of Na provides a direct source of Na removal from the soil, it is a minor component of sodic soil amelioration. Several plant species of agricultural significance have been found to be effective in the amelioration of calcareous sodic soils. Being common in soils and irrigation waters in dry areas, boron (B) at high levels causes toxicity in plants with subsequent impacts on crop yields. Boron can be leached out of the root zone only in higher rainfall areas or under excessive irrigations. In dry areas or in soils with impermeable sub-soil layers, B concentrations in the root zone can be high, making amelioration extremely difficult. In recent decades, screening of large numbers of accessions or cultivars of different crop species revealed wide variation in B-toxicity tolerance. In few studies, geographical diversity in B-toxicity tolerance among accessions could be attributed to selection over years by the soils of the different regions/countries. Breeding for B-toxicity tolerance has been attempted, and cultivars which give higher yields when grown in boron-affected soils were bred. In dry areas with high soil B, breeding for crop tolerance to B toxicity, in addition to drought tolerance, could make a contribution to improved productivity.","The Higher the Sodium, the Higher Need for Calcium\nThe Impact Calcium has on Sodium\nPreviously we have stated the importance of calcium and the balance of nutrients in soils being the key for maximum crop production and ultimate soil health. In this blog we look into the impact calcium has on sodium. This is an important example of nutrient balance and the effect one nutrient can have on another.\nSodium levels in our soils here in Australia is a growing issue and one that is causing loss of production across both dryland and irrigated crops.\nThe estimated loss in agricultural production from salt-affected farms is approximately $130 million (across Australia) and rising. (https://www.qld.gov.au/environment/land/soil/salinity/impacts)\nSo what does excess salt do to plants and soils? The below is a little technical but does help explain the role of calcium on salt toxicity.\nSalt toxicity comprises osmotic and ionic components both of which can severely affect root and shoot growth. Uptake of Na+ across the plasma membrane is very fast resulting in physiological effects on extracellular as well as intracellular sites. Sodium reduces binding of Ca2+ to the plasma membrane, inhibits influx while increasing efflux of Ca2+, and depletes the internal stores of Ca2+ from endomembranes. These changes in the cell Ca2+ homeostasis are suggested here to be the primary responses to salt stress that are perceived by root cells. Salt would almost instantly reduce the amount of Ca2+ being transferred to the leaf cells, with Ca2+ activity dropping and Na+ activity rising in the apoplasm of leaf cells. This Ca2+signal would be transported to leaves together with, if not preceding, the signal of limited water supply. (Z. Rengel, Department of Plant Science, Waite Agricultural Research Institute, University of Adelaide, Glen Osmond, SA 5064, Australia.)\nThere is a quick chemistry and plant physiology lesson for us.\nExcessive levels of soluble salts in the soil, particularly sodium chloride, cause poor plant growth. A build-up of salts in the soil interferes with water and nutrient uptake by plants because of osmotic effects (i.e. high concentrations of salts in the soil make the soil water less available for plant uptake). Affected plants wilt or show salt burn symptoms on the older leaves. Crops vary in their tolerance to soil salinity.\nNutrient uptake is effected on a number of levels with the main cause being the physical problems in soils (such as dispersion) and the restriction of rooting depth and root hair development which then obviously limits plant growth.\nSodium tends to displace exchangeable cations, such as calcium, from the sites where they are attached to soil particles. Exchangeable calcium helps to keep soil particles bound together in aggregates, but in soils with excess sodium, the sodium causes clay particles to break away from soil aggregates and disperse. This has the effect of reducing pore spaces and reducing the movement of water through the soil profile. In sodic topsoils, a hard crust may form when the soil surface dries out.\nThe Solution ‚Äì More Calcium\nThe solution is reasonably simple, the higher the sodium in a soil, the more calcium is needed. Lime and gypsum are the obvious choice and need to be part of a longer term focused program. There is also technology today that can enhance and improve these longer term product applications. This works on a crop by crop basis as well as making more available the calcium in our soils. Through combinations of chelated and complexed calcium ions in high quality products, soil calcium levels can be significantly increased on a per crop basis making a big difference to the effect of sodium."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:64ffc8a1-8713-4151-9df9-13405e62a948>","<urn:uuid:84210af5-bf3f-43cb-8d04-27b97dafe969>"],"error":null}
{"question":"¬øCan you compare the audio output configuration options between Final Cut Pro y Logic Pro X for professional sound work?","answer":"Final Cut Pro allows configuration of 5.1-channel surround sound outputs through two methods: using the 5.1 monitoring audio preset or the Match Audio Outputs command. Logic Pro X, on the other hand, focuses on resolution configuration, offering options for bit depth (16 or 24-bit) and sampling rates, with additional features like dithering algorithms (POW-r and UV22HR) for converting between different bit depths.","context":["Final Cut Pro: Understanding External Audio Monitors\nThe first step to understanding and manipulating audio in Final Cut Pro is to know how to properly connect the external audio monitors to your editing system. When you connect your external audio monitors or your speakers, always make sure that they are properly connected to the built-in computer audio output or audio interface. It is also important that the audio interface is properly configured in Final Cut Pro for you to maximize the use of this program.\nStep 1: Setting up the Audio Monitoring Environment\nAside from having a good quality or high performance speaker, it is also important that you have a good audio monitoring environment. The shape as well as the material of the room is important.\nStep 2: Connecting Self-Powered Speakers\nTo connect self-powered speakers to your computer, you first need to connect the main left audio output of your audio interface to the left speaker. After connecting the left audio output, you then need to connect the main right output of the audio interface to the right speaker.\nStep 3: Configuring Sequence Audio Outputs\nAlthough Final Cut Pro is unable to support editing of speaker assignments or multi-channel surround sound mixing, you can configure your system so that you can monitor certain types of 5.1-channel surround sound files.\nThere are 2 ways you can configure your sequence audio outputs. The first is to use the 5.1 monitoring audio preset. This way is suitable if you already know that you will be dealing with a 5.1-channel surround sound audio file in your sequence. All you need to do is just assign to your sequence the 5.1-Monitoring audio preset.\nThe second way you can configure your audio outputs to 5.1-channel surround sound audio files is to use the Match Audio Outputs command in Final Cut Pro. This will help you automatically configure the sequence audio outputs.\nStep 4: Configuring 5.1-Channel Surround Sound Monitoring\nTo configure 5.1-channel surround sound monitoring using the Media Audio Outputs command, you first need to import a multichannel surround sound audio file to Final Cut Pro. After importing the multichannel surround sound QuickTime audio file, edit the multichannel clip in the Timeline. You then need to choose Sequence and then Match Audio Outputs. You will see a notification stating that changes will be made to the audio outputs. Just click OK.\nOnce you see an alert stating that the changes have been made, verify the audio output assignment of each track. To do this, just control-click the Auto Select control or Lock Track control of the track. After this is done, you can now connect your 5.1-channel surround sound speaker system.\nStep 5: Setting the Muting the Sound System and Monitoring Levels\nMixing audio often requires you to monitor a consistent volume setting. It is important to remember that any changes to the volume should be done through Final Cut Pro and not through the volume setting of the speaker or the external audio outputs itself. However, if your entire audio track needs some adjustment, you may need to make adjustments on the overall volume setting of your audio.Popular P&S Cameras for High Quality Photos:","I received an email asking me how to choose the resolution in Logic Pro X.\n16 or 24 bit resolution?\nBefore recording your guitar or voice in Logic, you can choose in the Preferences menu, Recording what is called the recording resolution. I already talked in a previous article about Logic‚Äôs audio recording formats.\nMost sound cards offer 16 or 24-bit resolution and sampling rates up to 192 kHz. Below is the yellow resolution of my Universal Audio Apollo 16 card.\nIf your sound card only offers 16 bits / 44.1 kHz. For example, you will not be able to choose another resolution in your sequencer. Because Logic Pro X will determine the resolution of your sound card!\nWhy record with 24-bit resolution?\nWe know that a CD is in 16-bit / 44.1 kHz format. So why choose to record with a 24-bit resolution?\nSimply because it offers you a wider dynamic range. Thanks to this wider dynamic range, this allows you to record less close to 0 dB. The 0 dB being a value not to be exceeded in digital under the risk of non-musical saturation.\nTo better understand‚Ä¶.\nThe signal-to-noise ratio is an indicator of the quality of information transmission. It is the ratio of powers between:\n- the signal of maximum amplitude for which the distortion at the output remains below a limit value.\n- background noise, which is not significant information that generally corresponds to the signal present at the output of the device. In the absence of a signal at the input.\nIt is generally measured in decibels (dB).\nLet‚Äôs consider that 1 bit corresponds to about 6 dB, I mean about ! So when calculating, 16 bits allow a dynamic range of 16 x 6 = 96 dB approximately. Because in reality we are closer to 98 dB.\nSo 24 bits allow 24 x 6 = 144 dB of dynamics. With 24-bit, you earn 44dB of margin. It is therefore a significant comfort! Since you no longer have to try to get absolutely close to 0 dB to get better quality.\nYou can thus gain in dynamics. This does not prevent the use of a console slice. For the color of its preamp, its equalization to refine frequencies during recording. Or its compressor to reduce peaks by 2/3 dB.\nEQ and compression should be applied slightly, but they are not necessary! This is one of the practical aspects of Apollo sound cards. Apply in the mixer an EQ + Compression treatment (perso I use a lot of Cambridge EQ and LA2A or 1176LN compressors). With the UAD Rec option to save the processing in the Logic audio file. And / or UAD My only for the monitoring and comfort of the artist‚Ä¶. Processing chain obviously reusable in Logic on playback if it has not been applied to the recording‚Ä¶. Sorry, I‚Äôm getting off topic‚Ä¶.\nWhy do some software have 32-bit resolutions?\nThe resolution of your sound card will not exceed 24 bits. There is no sound card that has a 32-bit resolution. So your 24-bit recordings will be encoded in a 32-bit floating point format by some software. This will not change the quality of the initial records themselves. But will create audio files in this format before they are processed by plug-ins.\nMy Mac works in 64 bits!\nThe computing resolution of your computer‚Äôs processor is probably 64-bit. This has no influence on the resolution of the 24-bit audio file recorded. This brings you more processing with your plug-ins and increased speed of your computer‚Ä¶\nWhat about the sampling frequency?\nThe sampling frequency is the number of samples recorded per second:\n- 44.1 kHz = at 44100 samples per second\n- 48 kHz = at 48000 samples per second\nthe debate is more open. A frequency of 44.1 kHz is theoretically sufficient to recover the entire spectrum audible by the human ear. Now, some people perceive other things when recording in 96 or 192 kHz. Only your ear is the judge personally I work in 24 bits 44.1kHz. Simply the higher the files are in terms of sampling frequency, the more space they take up on the hard disk. This requires more processor resources for their processing through your plug-in chains. I prefer to save space on my hard disk by staying at 44.1 kHz. Knowing that very often I deliver a wav and mp3 file‚Ä¶.\nFor your information, I made a 96 kHz recording once in my career. For SYLVANIA‚Äôs Marcus OPUS 1 album. A classical guitar album. My client‚Äôs request was to get closer to the quality of Alexandre LAGOYA‚Äôs recordings. I must admit that I had a very beautiful experience‚Ä¶.\nThis is in Logic where you set the sampling rate.\nPerform a blind test with a file recorded at 44.1, 48 and 96 KHz. Ask a friend to do this test! Without knowing the frequencies to avoid being influenced. Maybe the difference will not exist in your ears.\nSound card and sound card!\nChoosing the resolution in Logic Pro X requires quality! The converters play on the quality of the retranscription of the analog signal into digital. 2 sound cards of different brands working in 24 bits/96 kHz will not necessarily give the same rendering. This depends on the quality of the converters.\nIf we‚Äôre in 16 bits and we want to go to 24 bits. Logic will add 8 bits in the form of zero, this does not change the sound quality of the file. If recorded in 24 bits 44.1kHz to make an audio CD. We are obliged to lower the 24-bit resolution to 16-bit resolution. You have to go through a dithering algorithm. The algorithm is independent of the quality of the sound card, it is different according to the sequencers. In Logic Pro X, we have access as shown in the image below to different dithering algorithms.\n- POWr for Psychoacoustically Optimized Wordlength Reduction\n- POW-r #1 Dithering: uses a special dithering curve to minimize the noise induced by quantification.\n- POW-r #1 Noise Shaping: uses an additional process to shape sound over a wide frequency range. This extends the dynamic range of the file from 5 to 10 dB.\n- POW-r #1 Noise Shaping: uses an additional and optimized sound shaping process to extend the dynamic range by 20 dB within a range of 2 to 4 kHz (Range to which the human ear is most sensitive).\n- UV22HR: adds an inaudible energy concentration, generated algorithmically, around 22 kHz. Technically, it is known as ‚ÄúSub-Nyquist-band dither‚Äù. It is a proprietary dithering to the Apogee brand.\nIn the image above, UV22HR appears grayed out because I don‚Äôt have an Apogee card.\nNow you know how to choose the resolution in Logic Pro X!\nI hope these explanations have helped you understand the importance of choosing the right resolution before making your recordings. And finally, the resolution setting in Logic is permanent. Unlike sampling frequency, which can vary from one project to another. In what resolution now will I receive your audio tracks to make your mix or mastering?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:93230a16-7d38-4bd6-88cf-1b5ac14c377d>","<urn:uuid:b54640a7-1581-4cb1-a159-316cec7b689f>"],"error":null}
{"question":"How can travelers maintain proper iron intake while being environmentally conscious? Trying to be healthy AND green! üå±","answer":"Iron intake can be maintained through plant-based sources like green leafy vegetables, peas, whole grains, and legumes, though this iron isn't absorbed as well as meat iron. To enhance absorption, combine these foods with vitamin C-rich foods and consider cooking in cast iron cookware. From an environmental perspective, reducing meat consumption helps fight climate change since animal agriculture is a major source of greenhouse gas emissions. You don't need to eliminate meat entirely - even reducing consumption by one or two meals per week can have a positive impact on both personal health and the planet.","context":["Whether you‚Äôre travelling 6 kilometres or 6000. Adopt these simple habits to help fight climate change, reduce pollution and help ease other forms of pressure on our planet.\nBring your own reusable water bottle. Fill it up at home or after you‚Äôve gone through airport security. Unless you‚Äôre running a marathon, 500ml should last you at least a couple of hours. According to Businessinsider.com, bottled water costs between 300 to 2000 times more than tap water. That‚Äôs a lot of money and a lot of plastic that won‚Äôt go away. If you are concerned about the quality of tap water, restaurants, bars ‚Äì even some mosques can give you a refill of filtered water. Hotel gyms usually have tanks of filtered water that you can use for refills. Let your hotel know you value a place to refill your reusable water bottle, not single-use plastic bottles.\nWelcome to Boot Camp: Know Your Green Basics Before You Leave Home\nArticle by Mary Picard\nWalk, ride a bicycle or paddle whenever you can. Go motorless! Its good for you and even a 5 minute car journey adds particulates and carbon into the atmosphere. Walking even short distances is a great way to add moderate physical activity into your day ‚Äì something health experts say adds years to your life. Slowing down has the added benefit of allowing you to see details you would not see from a car or bus. Isn‚Äôt that what vacation is all about?\nAvoid single-use plastic, like water bottles, carrier bags and drinking straws. Just think, every piece of plastic you have ever used is still out there somewhere. Alarmingly, more and more of our food now comes covered in plastic. Tell your server ‚ÄúNo Straw Please‚Äù. If you are buying a single portion drink, try to choose one in an aluminum can or glass bottle. Both these options are more easily recycled. If you travel with a backpack, buy some bamboo chopsticks and a spork and carry them with you to avoid disposable eating utensils. Carrying a small reusable carrier bag will save you from needing dozens of plastic bags throughout the course of a year. Just think, if you buy one single use bottle of water per day, and then switch to carrying your own tap or filtered water, just one can person eliminate 365 empty plastic bottles from rattling around our planet. That‚Äôs a lot of plastic, and that‚Äôs only one person.\nEat less meat. Animal agriculture is a huge source of greenhouse gas emissions. Reducing your meat consumption even by just one or two meals a week can have an impact. Health experts say that eating less meat is better for us. Remember too that if you‚Äôre travelling in a warm climate, spoiled meat is often times the cause of food poisoning. And when on vacation, never eat bush meat or endangered seafood. It encourages poaching and threatens the wildlife you are there to visit. Remember, you don‚Äôt have to cut meat consumption out of your life entirely, but even just reducing a bit is good for both person and planet.\nAt hotels and at home, always turn off the lights and minimize the climate control settings as you leave for the day. Its pretty basic stuff, but when you add up the numbers of us stepping out for the day, this little habit adds up to big carbon savings. Unplug any chargers not in use and turn off your aircon. That electricity, aircon or heat is being produced by some sort of carbon emitting power generation, so keep usage to a minimum.\nLeave a note on your pillow and sheets reminding hotel staff not to change them unless they truly need it. The same goes for towels --only change them when they need it. It‚Äôs one of our pet peeves here at Wild Creatures. How many times do you go to a hotel with the nice little eco-friendly placard stating they don‚Äôt change the linens everyday ‚Äì only to find out that, yes they do? This is a huge waste of water, electricity and cleaning products. Become a mini-activist and politely ask housekeeping not to swap stuff out. Your comments will eventually work its way up the chain of command.\nTip hotel housekeeping staff at the time of your departure. This item doesn‚Äôt apply in all parts of the world ‚Äì definitely check out local tipping and gratuity customs before you visit. When is it appropriate? Theoretically, we‚Äôd all like to think that hotels pay their workers a living wage, and perhaps they do. But in many places hotels rely on students, rural or migrant workers to take on cleaning roles. These people oftentimes support extended family networks and the tip money will go to paying for medical expenses, food, school fees and books, etc. So ask yourself ‚Äìwhat is the custom in this country and who are the people doing the cleaning? 1 USD per day of your hotel stay as a baseline calculation and leave it in an envelope at the end of your stay. Chances are, the money will be going to improve the lives of others.\nMake eco-friendly choices for accommodation, tours and all aspects of your life. You have power as the consumer to pick tours, hotels, lodges that are sustainable and environmentally friendly. By supporting these green businesses you are supporting the environment. Organisations like Toftigers in India list all the most environmentally sound accommodation and tour options. Follow the link below to learn more. If you find you are perhaps in not the most energy efficient establishment then let hotel management, tour operators and restaurants know that environmental considerations are important to you! As more of us do this, it gives the tourism industry permission to make these best practices commonplace. You can tell them in person, through surveys, online reviews or other forms of social media. Be polite and friendly about it. Celebrate the good stuff as well as highlighting the bad. Businesses and organizations are paying attention. Beyond this, make eco-friendly choices in all aspects of your life. Buy products that don't have harmful microbeads, are not tested on animals and are bio-degradable. Don't buy clothes made in sweatshops, or shell jewellery that has been stolen from the sea. We as consumers have the power to change businesses and organisations for the better.\nThese 8 green basics are as important in everyday life as on holiday ‚Äì and they really are right at your fingertips. Not only will you be helping reduce pollution and carbon emissions, but by doing things like walking more and eating less meat, you will be boosting your own wellness too. So remember, a green basic isn‚Äôt just better the planet, its better for you too!\nIn Asia you would never find a lionfish on your plate. However, they have become a prolific invasive species spreading down further and further, from North to South America. Locals and tourists alike are now being encouraged to hunt and eat this venomous fish. Of course removing their venomous spines first, before eating the delicious white meat (it makes great ceviche)!\nMake eco-friendly choices: never buy shells, dried seahorses or any Chinese medicine that uses endangered and threatened aniamls in its ingredients.","Vitamins & Minerals\nA solid vegetarian diet is possible if enough nutrients are consumed from a wide variety of foods. Since this is not always possible, some vegetarians choose to supplement their diet with vitamins to ensure adequate nutrients for performance and recovery. Vegetarians must take extra care to avoid deficiencies of iron, calcium, zinc, vitamin B12, and vitamin D, which can hurt exercise and strength training performance.\nNOTE: Please consult your doctor to be tested on before taking supplements. The information below explains what may be lacking in a vegetarian runner‚Äôs diet.\nVitamin B12 is essential to vegetarian runners because red blood cells are so important to muscle repair, oxygen delivery, blood lactate clearance, and other mechanisms associated with continued, injury-free physical activity. Since vitamin B12 is available only from animal products, it is one of the most common nutrients missing from the diets of vegetarian athletes. If vegetarians don‚Äôt obtain their B12 requirements from food, they are advised to take B12 supplements. Vitamin B12 absorption becomes less efficient as we age, so supplements may also be needed by older vegetarians.\nNo active form of vitamin B12 is found naturally in plant foods (including soy products), however, if you eat dairy products and eggs they will provide you with sufficient amounts of vitamin B12. There are also fortified foods such as some soy beverages and some vegetarian sausages and burgers. Mushrooms, tempeh, miso, and sea vegetables are often claimed to be a source of B12, however, they actually contain a compound with a similar structure to B12 but it doesn‚Äôt work like B12 in the body.\nThe main source of vitamin D is sunlight so vegetarians may require a dietary source of vitamin D when sun exposure is insufficient. There are few foods that contain significant amounts of vitamin D which means there is very little vitamin D in most people‚Äôs diets unless they eat fatty fish, eggs, liver or vitamin D fortified foods (such as margarine). Vitamin D deficiency can be avoided by choosing fortified nondairy milks and breakfast cereals as well. Vegetarians may wish to choose these and other animal-based vitamin D supplements.\nVegetarian diets are usually high in iron from plant foods, although this iron is not absorbed as well as the iron in meat. Vegetarian athletes are at more risk of iron deficient anemia than non-vegetarian athletes who eat red meat and should be aware that underlying iron deficiencies can be noticeable in athletes as they become more lethargic and their performance decreases.\nGood food sources of iron include green leafy vegetables, peas and whole grains, enriched cereals and legumes. Combining these foods with foods high in vitamin C and food acids, such as fruit and vegetables, will help your body absorb the iron. Some foods contain substances that block the absorption of iron in the intestine. Coffee, whole grains, bran, legumes, and spinach all interfere with iron absorption and should be combined with vitamin C to increase iron absorption.\nCooking in cast iron cookware every once and a while rather than stainless steel can leach absorbable iron into simmering food. Look at also taking iron supplements but be careful that too much iron can be toxic. Speak to a well-qualified nutritionist or dietician if you are unsure.\nSome reports say that vegetarians have a lower zinc levels than non-vegetarians. This may be due to the fact that cereals, legumes, nuts, soy products and eggs are secondary sources of zinc. However, there is no suggestion that vegetarian athletes need to include zinc supplements in the diet. The best vegetarian sources of zinc are nuts, tofu, miso, legumes, wheat germ and wholegrain foods.\nCalcium is necessary for strong bones and teeth, as well as to help muscles relax and contract and nerves conduct messages. Good vegetarian sources of calcium include dairy products, fortified cereals and fruits juices, fortified soymilk, tahini and some brands of tofu. Leafy dark green vegetables (especially Asian greens), legumes, almonds and Brazil nuts also contain calcium."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"}],"document_ids":["<urn:uuid:a89eb899-1a20-4835-9e2e-52978daf7d41>","<urn:uuid:de6f5725-27aa-4861-9f9d-9b7aa8133d40>"],"error":null}